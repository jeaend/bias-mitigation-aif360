{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53b8bcc",
   "metadata": {},
   "source": [
    "## Inprocessing - Adversial Debiasing  -  Compas Model\n",
    "- for 'sex' and 'race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a779c2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import reset_default_graph\n",
    "import pandas as pd\n",
    "from src.data_loading import load_adult_sex, load_adult_race\n",
    "from src.modeling import adversial_debiasing_train_and_predict\n",
    "from src.metrics import compute_metrics, compare_viz_metrics_2x3, save_agg_metrics, save_raw_metrics\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb6c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'adult'\n",
    "mitigation_name   = 'adversial debiasing'\n",
    "pipeline_stage    = 'inprocessing'  \n",
    "out_dir_plots    = '../../reports/plots_adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e287ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_race_agg = pd.read_csv('../../reports/baseline_agg/adult_race_metrics_agg.csv', index_col=0)\n",
    "baseline_sex_agg = pd.read_csv('../../reports/baseline_agg/adult_sex_metrics_agg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec69a2",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785d3da",
   "metadata": {},
   "source": [
    "## default adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4efb8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 23:04:08.598863: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 8.748365; batch adversarial loss: 1.165482\n",
      "epoch 0; iter: 200; batch classifier loss: 6.454572; batch adversarial loss: 0.808165\n",
      "epoch 1; iter: 0; batch classifier loss: 12.336330; batch adversarial loss: 0.819133\n",
      "epoch 1; iter: 200; batch classifier loss: 1.856112; batch adversarial loss: 0.607399\n",
      "epoch 2; iter: 0; batch classifier loss: 5.440185; batch adversarial loss: 0.580480\n",
      "epoch 2; iter: 200; batch classifier loss: 8.410544; batch adversarial loss: 0.534191\n",
      "epoch 3; iter: 0; batch classifier loss: 2.364002; batch adversarial loss: 0.522211\n",
      "epoch 3; iter: 200; batch classifier loss: 3.387826; batch adversarial loss: 0.504678\n",
      "epoch 4; iter: 0; batch classifier loss: 3.893385; batch adversarial loss: 0.503538\n",
      "epoch 4; iter: 200; batch classifier loss: 1.528632; batch adversarial loss: 0.453159\n",
      "epoch 5; iter: 0; batch classifier loss: 1.086459; batch adversarial loss: 0.454493\n",
      "epoch 5; iter: 200; batch classifier loss: 1.369414; batch adversarial loss: 0.401544\n",
      "epoch 6; iter: 0; batch classifier loss: 2.757173; batch adversarial loss: 0.487968\n",
      "epoch 6; iter: 200; batch classifier loss: 0.800299; batch adversarial loss: 0.422230\n",
      "epoch 7; iter: 0; batch classifier loss: 0.762928; batch adversarial loss: 0.410840\n",
      "epoch 7; iter: 200; batch classifier loss: 1.104578; batch adversarial loss: 0.505699\n",
      "epoch 8; iter: 0; batch classifier loss: 0.686518; batch adversarial loss: 0.396074\n",
      "epoch 8; iter: 200; batch classifier loss: 0.734743; batch adversarial loss: 0.389521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.651219; batch adversarial loss: 0.390224\n",
      "epoch 9; iter: 200; batch classifier loss: 1.555996; batch adversarial loss: 0.435492\n",
      "epoch 10; iter: 0; batch classifier loss: 1.527269; batch adversarial loss: 0.500939\n",
      "epoch 10; iter: 200; batch classifier loss: 0.562906; batch adversarial loss: 0.480642\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505555; batch adversarial loss: 0.459114\n",
      "epoch 11; iter: 200; batch classifier loss: 0.520787; batch adversarial loss: 0.318881\n",
      "epoch 12; iter: 0; batch classifier loss: 0.668138; batch adversarial loss: 0.378447\n",
      "epoch 12; iter: 200; batch classifier loss: 0.547869; batch adversarial loss: 0.403683\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465955; batch adversarial loss: 0.404580\n",
      "epoch 13; iter: 200; batch classifier loss: 0.491184; batch adversarial loss: 0.408938\n",
      "epoch 14; iter: 0; batch classifier loss: 0.446601; batch adversarial loss: 0.353519\n",
      "epoch 14; iter: 200; batch classifier loss: 0.413482; batch adversarial loss: 0.388552\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381980; batch adversarial loss: 0.492493\n",
      "epoch 15; iter: 200; batch classifier loss: 0.596192; batch adversarial loss: 0.366848\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332507; batch adversarial loss: 0.362725\n",
      "epoch 16; iter: 200; batch classifier loss: 0.317922; batch adversarial loss: 0.435074\n",
      "epoch 17; iter: 0; batch classifier loss: 0.457572; batch adversarial loss: 0.405074\n",
      "epoch 17; iter: 200; batch classifier loss: 0.392121; batch adversarial loss: 0.392972\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391624; batch adversarial loss: 0.523032\n",
      "epoch 18; iter: 200; batch classifier loss: 0.301783; batch adversarial loss: 0.471097\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379704; batch adversarial loss: 0.424629\n",
      "epoch 19; iter: 200; batch classifier loss: 0.406030; batch adversarial loss: 0.369412\n",
      "epoch 20; iter: 0; batch classifier loss: 0.355930; batch adversarial loss: 0.429889\n",
      "epoch 20; iter: 200; batch classifier loss: 0.321341; batch adversarial loss: 0.384672\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481352; batch adversarial loss: 0.328766\n",
      "epoch 21; iter: 200; batch classifier loss: 0.408048; batch adversarial loss: 0.360579\n",
      "epoch 22; iter: 0; batch classifier loss: 0.284373; batch adversarial loss: 0.451603\n",
      "epoch 22; iter: 200; batch classifier loss: 0.330862; batch adversarial loss: 0.405271\n",
      "epoch 23; iter: 0; batch classifier loss: 0.491334; batch adversarial loss: 0.417987\n",
      "epoch 23; iter: 200; batch classifier loss: 0.401138; batch adversarial loss: 0.426653\n",
      "epoch 24; iter: 0; batch classifier loss: 0.416721; batch adversarial loss: 0.496359\n",
      "epoch 24; iter: 200; batch classifier loss: 0.422100; batch adversarial loss: 0.443661\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344661; batch adversarial loss: 0.503343\n",
      "epoch 25; iter: 200; batch classifier loss: 0.367211; batch adversarial loss: 0.403908\n",
      "epoch 26; iter: 0; batch classifier loss: 0.308093; batch adversarial loss: 0.319131\n",
      "epoch 26; iter: 200; batch classifier loss: 0.449696; batch adversarial loss: 0.333038\n",
      "epoch 27; iter: 0; batch classifier loss: 0.313756; batch adversarial loss: 0.509006\n",
      "epoch 27; iter: 200; batch classifier loss: 0.298737; batch adversarial loss: 0.372436\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362527; batch adversarial loss: 0.450353\n",
      "epoch 28; iter: 200; batch classifier loss: 0.409679; batch adversarial loss: 0.387725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244392; batch adversarial loss: 0.403041\n",
      "epoch 29; iter: 200; batch classifier loss: 0.249630; batch adversarial loss: 0.472562\n",
      "epoch 30; iter: 0; batch classifier loss: 0.337519; batch adversarial loss: 0.429141\n",
      "epoch 30; iter: 200; batch classifier loss: 0.421214; batch adversarial loss: 0.486111\n",
      "epoch 31; iter: 0; batch classifier loss: 0.351338; batch adversarial loss: 0.348498\n",
      "epoch 31; iter: 200; batch classifier loss: 0.346274; batch adversarial loss: 0.485502\n",
      "epoch 32; iter: 0; batch classifier loss: 0.358903; batch adversarial loss: 0.345561\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397895; batch adversarial loss: 0.369972\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318492; batch adversarial loss: 0.387311\n",
      "epoch 33; iter: 200; batch classifier loss: 0.336167; batch adversarial loss: 0.374817\n",
      "epoch 34; iter: 0; batch classifier loss: 0.406762; batch adversarial loss: 0.402191\n",
      "epoch 34; iter: 200; batch classifier loss: 0.464837; batch adversarial loss: 0.340814\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376312; batch adversarial loss: 0.415124\n",
      "epoch 35; iter: 200; batch classifier loss: 0.393763; batch adversarial loss: 0.432639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430915; batch adversarial loss: 0.399257\n",
      "epoch 36; iter: 200; batch classifier loss: 0.279754; batch adversarial loss: 0.456701\n",
      "epoch 37; iter: 0; batch classifier loss: 0.309863; batch adversarial loss: 0.463865\n",
      "epoch 37; iter: 200; batch classifier loss: 0.380004; batch adversarial loss: 0.371655\n",
      "epoch 38; iter: 0; batch classifier loss: 0.443361; batch adversarial loss: 0.419519\n",
      "epoch 38; iter: 200; batch classifier loss: 0.307373; batch adversarial loss: 0.484085\n",
      "epoch 39; iter: 0; batch classifier loss: 0.388822; batch adversarial loss: 0.384081\n",
      "epoch 39; iter: 200; batch classifier loss: 0.493098; batch adversarial loss: 0.379035\n",
      "epoch 40; iter: 0; batch classifier loss: 0.347495; batch adversarial loss: 0.430152\n",
      "epoch 40; iter: 200; batch classifier loss: 0.421875; batch adversarial loss: 0.334803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.231839; batch adversarial loss: 0.420075\n",
      "epoch 41; iter: 200; batch classifier loss: 0.333811; batch adversarial loss: 0.320144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.362436; batch adversarial loss: 0.439677\n",
      "epoch 42; iter: 200; batch classifier loss: 0.463051; batch adversarial loss: 0.349866\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438157; batch adversarial loss: 0.450749\n",
      "epoch 43; iter: 200; batch classifier loss: 0.297959; batch adversarial loss: 0.495360\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369825; batch adversarial loss: 0.443107\n",
      "epoch 44; iter: 200; batch classifier loss: 0.420918; batch adversarial loss: 0.501243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430422; batch adversarial loss: 0.336383\n",
      "epoch 45; iter: 200; batch classifier loss: 0.450971; batch adversarial loss: 0.347626\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396355; batch adversarial loss: 0.441492\n",
      "epoch 46; iter: 200; batch classifier loss: 0.370782; batch adversarial loss: 0.371852\n",
      "epoch 47; iter: 0; batch classifier loss: 0.381818; batch adversarial loss: 0.402719\n",
      "epoch 47; iter: 200; batch classifier loss: 0.406840; batch adversarial loss: 0.415008\n",
      "epoch 48; iter: 0; batch classifier loss: 0.361064; batch adversarial loss: 0.425716\n",
      "epoch 48; iter: 200; batch classifier loss: 0.456356; batch adversarial loss: 0.486958\n",
      "epoch 49; iter: 0; batch classifier loss: 0.340583; batch adversarial loss: 0.357579\n",
      "epoch 49; iter: 200; batch classifier loss: 0.454989; batch adversarial loss: 0.440668\n",
      "epoch 0; iter: 0; batch classifier loss: 53.227837; batch adversarial loss: 0.967963\n",
      "epoch 0; iter: 200; batch classifier loss: 7.748729; batch adversarial loss: 0.859512\n",
      "epoch 1; iter: 0; batch classifier loss: 2.440472; batch adversarial loss: 0.756189\n",
      "epoch 1; iter: 200; batch classifier loss: 2.839532; batch adversarial loss: 0.644381\n",
      "epoch 2; iter: 0; batch classifier loss: 1.620184; batch adversarial loss: 0.562298\n",
      "epoch 2; iter: 200; batch classifier loss: 6.999735; batch adversarial loss: 0.496279\n",
      "epoch 3; iter: 0; batch classifier loss: 6.003704; batch adversarial loss: 0.477398\n",
      "epoch 3; iter: 200; batch classifier loss: 3.126594; batch adversarial loss: 0.449001\n",
      "epoch 4; iter: 0; batch classifier loss: 4.272280; batch adversarial loss: 0.467658\n",
      "epoch 4; iter: 200; batch classifier loss: 2.447542; batch adversarial loss: 0.469596\n",
      "epoch 5; iter: 0; batch classifier loss: 0.930175; batch adversarial loss: 0.430827\n",
      "epoch 5; iter: 200; batch classifier loss: 4.695626; batch adversarial loss: 0.460064\n",
      "epoch 6; iter: 0; batch classifier loss: 2.135890; batch adversarial loss: 0.472553\n",
      "epoch 6; iter: 200; batch classifier loss: 0.587862; batch adversarial loss: 0.368277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.600712; batch adversarial loss: 0.370835\n",
      "epoch 7; iter: 200; batch classifier loss: 1.089706; batch adversarial loss: 0.405734\n",
      "epoch 8; iter: 0; batch classifier loss: 0.746559; batch adversarial loss: 0.352339\n",
      "epoch 8; iter: 200; batch classifier loss: 0.487880; batch adversarial loss: 0.386641\n",
      "epoch 9; iter: 0; batch classifier loss: 1.047674; batch adversarial loss: 0.373596\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426255; batch adversarial loss: 0.364188\n",
      "epoch 10; iter: 0; batch classifier loss: 0.381719; batch adversarial loss: 0.371079\n",
      "epoch 10; iter: 200; batch classifier loss: 0.436133; batch adversarial loss: 0.353477\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413291; batch adversarial loss: 0.384369\n",
      "epoch 11; iter: 200; batch classifier loss: 0.380369; batch adversarial loss: 0.368875\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367355; batch adversarial loss: 0.337173\n",
      "epoch 12; iter: 200; batch classifier loss: 0.280648; batch adversarial loss: 0.475010\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407803; batch adversarial loss: 0.432438\n",
      "epoch 13; iter: 200; batch classifier loss: 0.491407; batch adversarial loss: 0.402684\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396031; batch adversarial loss: 0.383049\n",
      "epoch 14; iter: 200; batch classifier loss: 0.476909; batch adversarial loss: 0.526287\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361842; batch adversarial loss: 0.500802\n",
      "epoch 15; iter: 200; batch classifier loss: 0.372788; batch adversarial loss: 0.440452\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367992; batch adversarial loss: 0.396139\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357476; batch adversarial loss: 0.426155\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367581; batch adversarial loss: 0.428446\n",
      "epoch 17; iter: 200; batch classifier loss: 0.310471; batch adversarial loss: 0.492131\n",
      "epoch 18; iter: 0; batch classifier loss: 0.428046; batch adversarial loss: 0.373510\n",
      "epoch 18; iter: 200; batch classifier loss: 0.280279; batch adversarial loss: 0.278977\n",
      "epoch 19; iter: 0; batch classifier loss: 0.388349; batch adversarial loss: 0.434620\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372175; batch adversarial loss: 0.351303\n",
      "epoch 20; iter: 0; batch classifier loss: 0.407495; batch adversarial loss: 0.363856\n",
      "epoch 20; iter: 200; batch classifier loss: 0.305993; batch adversarial loss: 0.512743\n",
      "epoch 21; iter: 0; batch classifier loss: 0.399755; batch adversarial loss: 0.445736\n",
      "epoch 21; iter: 200; batch classifier loss: 0.337359; batch adversarial loss: 0.398517\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427821; batch adversarial loss: 0.470212\n",
      "epoch 22; iter: 200; batch classifier loss: 0.392158; batch adversarial loss: 0.384386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379394; batch adversarial loss: 0.437578\n",
      "epoch 23; iter: 200; batch classifier loss: 0.351797; batch adversarial loss: 0.506021\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329503; batch adversarial loss: 0.421084\n",
      "epoch 24; iter: 200; batch classifier loss: 0.387914; batch adversarial loss: 0.399599\n",
      "epoch 25; iter: 0; batch classifier loss: 0.350498; batch adversarial loss: 0.365007\n",
      "epoch 25; iter: 200; batch classifier loss: 0.417353; batch adversarial loss: 0.369054\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406318; batch adversarial loss: 0.329830\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336780; batch adversarial loss: 0.344953\n",
      "epoch 27; iter: 0; batch classifier loss: 0.407089; batch adversarial loss: 0.520030\n",
      "epoch 27; iter: 200; batch classifier loss: 0.334228; batch adversarial loss: 0.367370\n",
      "epoch 28; iter: 0; batch classifier loss: 0.363796; batch adversarial loss: 0.507750\n",
      "epoch 28; iter: 200; batch classifier loss: 0.299928; batch adversarial loss: 0.297168\n",
      "epoch 29; iter: 0; batch classifier loss: 0.328038; batch adversarial loss: 0.367572\n",
      "epoch 29; iter: 200; batch classifier loss: 0.288561; batch adversarial loss: 0.492232\n",
      "epoch 30; iter: 0; batch classifier loss: 0.267453; batch adversarial loss: 0.474443\n",
      "epoch 30; iter: 200; batch classifier loss: 0.424057; batch adversarial loss: 0.408652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387005; batch adversarial loss: 0.479731\n",
      "epoch 31; iter: 200; batch classifier loss: 0.287141; batch adversarial loss: 0.393701\n",
      "epoch 32; iter: 0; batch classifier loss: 0.335990; batch adversarial loss: 0.360772\n",
      "epoch 32; iter: 200; batch classifier loss: 0.211090; batch adversarial loss: 0.417581\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323498; batch adversarial loss: 0.366729\n",
      "epoch 33; iter: 200; batch classifier loss: 0.260365; batch adversarial loss: 0.472029\n",
      "epoch 34; iter: 0; batch classifier loss: 0.328664; batch adversarial loss: 0.417704\n",
      "epoch 34; iter: 200; batch classifier loss: 0.384537; batch adversarial loss: 0.453817\n",
      "epoch 35; iter: 0; batch classifier loss: 0.309845; batch adversarial loss: 0.493092\n",
      "epoch 35; iter: 200; batch classifier loss: 0.308935; batch adversarial loss: 0.443922\n",
      "epoch 36; iter: 0; batch classifier loss: 0.303535; batch adversarial loss: 0.441153\n",
      "epoch 36; iter: 200; batch classifier loss: 0.259964; batch adversarial loss: 0.421438\n",
      "epoch 37; iter: 0; batch classifier loss: 0.357702; batch adversarial loss: 0.449267\n",
      "epoch 37; iter: 200; batch classifier loss: 0.308111; batch adversarial loss: 0.462667\n",
      "epoch 38; iter: 0; batch classifier loss: 0.347549; batch adversarial loss: 0.383394\n",
      "epoch 38; iter: 200; batch classifier loss: 0.297385; batch adversarial loss: 0.415261\n",
      "epoch 39; iter: 0; batch classifier loss: 0.332555; batch adversarial loss: 0.365784\n",
      "epoch 39; iter: 200; batch classifier loss: 0.309656; batch adversarial loss: 0.424812\n",
      "epoch 40; iter: 0; batch classifier loss: 0.360966; batch adversarial loss: 0.409628\n",
      "epoch 40; iter: 200; batch classifier loss: 0.307633; batch adversarial loss: 0.486224\n",
      "epoch 41; iter: 0; batch classifier loss: 0.333019; batch adversarial loss: 0.366334\n",
      "epoch 41; iter: 200; batch classifier loss: 0.284545; batch adversarial loss: 0.505851\n",
      "epoch 42; iter: 0; batch classifier loss: 0.484395; batch adversarial loss: 0.299373\n",
      "epoch 42; iter: 200; batch classifier loss: 0.470144; batch adversarial loss: 0.395666\n",
      "epoch 43; iter: 0; batch classifier loss: 0.311599; batch adversarial loss: 0.448824\n",
      "epoch 43; iter: 200; batch classifier loss: 0.338820; batch adversarial loss: 0.385501\n",
      "epoch 44; iter: 0; batch classifier loss: 0.326121; batch adversarial loss: 0.349870\n",
      "epoch 44; iter: 200; batch classifier loss: 0.286062; batch adversarial loss: 0.436731\n",
      "epoch 45; iter: 0; batch classifier loss: 0.270147; batch adversarial loss: 0.305322\n",
      "epoch 45; iter: 200; batch classifier loss: 0.428837; batch adversarial loss: 0.358010\n",
      "epoch 46; iter: 0; batch classifier loss: 0.439868; batch adversarial loss: 0.391870\n",
      "epoch 46; iter: 200; batch classifier loss: 0.356382; batch adversarial loss: 0.333271\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505635; batch adversarial loss: 0.358001\n",
      "epoch 47; iter: 200; batch classifier loss: 0.471651; batch adversarial loss: 0.488949\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447279; batch adversarial loss: 0.296696\n",
      "epoch 48; iter: 200; batch classifier loss: 0.460878; batch adversarial loss: 0.454144\n",
      "epoch 49; iter: 0; batch classifier loss: 0.531203; batch adversarial loss: 0.424598\n",
      "epoch 49; iter: 200; batch classifier loss: 0.437889; batch adversarial loss: 0.414781\n",
      "epoch 0; iter: 0; batch classifier loss: 118.210991; batch adversarial loss: 0.702842\n",
      "epoch 0; iter: 200; batch classifier loss: 5.330793; batch adversarial loss: 0.618992\n",
      "epoch 1; iter: 0; batch classifier loss: 13.906013; batch adversarial loss: 0.573209\n",
      "epoch 1; iter: 200; batch classifier loss: 2.312444; batch adversarial loss: 0.531674\n",
      "epoch 2; iter: 0; batch classifier loss: 6.974186; batch adversarial loss: 0.532180\n",
      "epoch 2; iter: 200; batch classifier loss: 7.548691; batch adversarial loss: 0.525755\n",
      "epoch 3; iter: 0; batch classifier loss: 1.509589; batch adversarial loss: 0.554255\n",
      "epoch 3; iter: 200; batch classifier loss: 7.220432; batch adversarial loss: 0.530727\n",
      "epoch 4; iter: 0; batch classifier loss: 6.174406; batch adversarial loss: 0.465778\n",
      "epoch 4; iter: 200; batch classifier loss: 8.169775; batch adversarial loss: 0.388577\n",
      "epoch 5; iter: 0; batch classifier loss: 2.615153; batch adversarial loss: 0.395168\n",
      "epoch 5; iter: 200; batch classifier loss: 1.695204; batch adversarial loss: 0.452929\n",
      "epoch 6; iter: 0; batch classifier loss: 1.216194; batch adversarial loss: 0.343640\n",
      "epoch 6; iter: 200; batch classifier loss: 0.804146; batch adversarial loss: 0.464848\n",
      "epoch 7; iter: 0; batch classifier loss: 0.409326; batch adversarial loss: 0.436876\n",
      "epoch 7; iter: 200; batch classifier loss: 0.606858; batch adversarial loss: 0.510137\n",
      "epoch 8; iter: 0; batch classifier loss: 1.474701; batch adversarial loss: 0.430468\n",
      "epoch 8; iter: 200; batch classifier loss: 0.555893; batch adversarial loss: 0.399394\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437042; batch adversarial loss: 0.341023\n",
      "epoch 9; iter: 200; batch classifier loss: 0.536764; batch adversarial loss: 0.442572\n",
      "epoch 10; iter: 0; batch classifier loss: 0.377885; batch adversarial loss: 0.334820\n",
      "epoch 10; iter: 200; batch classifier loss: 0.392525; batch adversarial loss: 0.338398\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473533; batch adversarial loss: 0.383978\n",
      "epoch 11; iter: 200; batch classifier loss: 0.505307; batch adversarial loss: 0.423209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335057; batch adversarial loss: 0.397559\n",
      "epoch 12; iter: 200; batch classifier loss: 0.482910; batch adversarial loss: 0.557955\n",
      "epoch 13; iter: 0; batch classifier loss: 0.533208; batch adversarial loss: 0.377203\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326177; batch adversarial loss: 0.499978\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376691; batch adversarial loss: 0.469047\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378188; batch adversarial loss: 0.423265\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379591; batch adversarial loss: 0.418281\n",
      "epoch 15; iter: 200; batch classifier loss: 0.286985; batch adversarial loss: 0.431455\n",
      "epoch 16; iter: 0; batch classifier loss: 0.277981; batch adversarial loss: 0.452442\n",
      "epoch 16; iter: 200; batch classifier loss: 0.363045; batch adversarial loss: 0.379327\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377705; batch adversarial loss: 0.479411\n",
      "epoch 17; iter: 200; batch classifier loss: 0.288840; batch adversarial loss: 0.371043\n",
      "epoch 18; iter: 0; batch classifier loss: 0.448634; batch adversarial loss: 0.360496\n",
      "epoch 18; iter: 200; batch classifier loss: 0.394044; batch adversarial loss: 0.383590\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264154; batch adversarial loss: 0.369468\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347988; batch adversarial loss: 0.522342\n",
      "epoch 20; iter: 0; batch classifier loss: 0.317513; batch adversarial loss: 0.402397\n",
      "epoch 20; iter: 200; batch classifier loss: 0.333915; batch adversarial loss: 0.447947\n",
      "epoch 21; iter: 0; batch classifier loss: 0.365380; batch adversarial loss: 0.389573\n",
      "epoch 21; iter: 200; batch classifier loss: 0.375726; batch adversarial loss: 0.414041\n",
      "epoch 22; iter: 0; batch classifier loss: 0.335007; batch adversarial loss: 0.361582\n",
      "epoch 22; iter: 200; batch classifier loss: 0.360683; batch adversarial loss: 0.368945\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311861; batch adversarial loss: 0.413099\n",
      "epoch 23; iter: 200; batch classifier loss: 0.389905; batch adversarial loss: 0.421927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.385133; batch adversarial loss: 0.388577\n",
      "epoch 24; iter: 200; batch classifier loss: 0.383341; batch adversarial loss: 0.516028\n",
      "epoch 25; iter: 0; batch classifier loss: 0.381782; batch adversarial loss: 0.446422\n",
      "epoch 25; iter: 200; batch classifier loss: 0.305732; batch adversarial loss: 0.362982\n",
      "epoch 26; iter: 0; batch classifier loss: 0.345879; batch adversarial loss: 0.402668\n",
      "epoch 26; iter: 200; batch classifier loss: 0.287064; batch adversarial loss: 0.501415\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352224; batch adversarial loss: 0.441106\n",
      "epoch 27; iter: 200; batch classifier loss: 0.269828; batch adversarial loss: 0.302601\n",
      "epoch 28; iter: 0; batch classifier loss: 0.324237; batch adversarial loss: 0.482717\n",
      "epoch 28; iter: 200; batch classifier loss: 0.294859; batch adversarial loss: 0.422021\n",
      "epoch 29; iter: 0; batch classifier loss: 0.316270; batch adversarial loss: 0.528044\n",
      "epoch 29; iter: 200; batch classifier loss: 0.310985; batch adversarial loss: 0.445834\n",
      "epoch 30; iter: 0; batch classifier loss: 0.339212; batch adversarial loss: 0.406666\n",
      "epoch 30; iter: 200; batch classifier loss: 0.385261; batch adversarial loss: 0.344788\n",
      "epoch 31; iter: 0; batch classifier loss: 0.281542; batch adversarial loss: 0.443400\n",
      "epoch 31; iter: 200; batch classifier loss: 0.339498; batch adversarial loss: 0.480084\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409736; batch adversarial loss: 0.363694\n",
      "epoch 32; iter: 200; batch classifier loss: 0.377051; batch adversarial loss: 0.409807\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409131; batch adversarial loss: 0.330231\n",
      "epoch 33; iter: 200; batch classifier loss: 0.357958; batch adversarial loss: 0.303853\n",
      "epoch 34; iter: 0; batch classifier loss: 0.345218; batch adversarial loss: 0.456333\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338723; batch adversarial loss: 0.369608\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257302; batch adversarial loss: 0.396753\n",
      "epoch 35; iter: 200; batch classifier loss: 0.384342; batch adversarial loss: 0.385638\n",
      "epoch 36; iter: 0; batch classifier loss: 0.297048; batch adversarial loss: 0.409309\n",
      "epoch 36; iter: 200; batch classifier loss: 0.328670; batch adversarial loss: 0.421241\n",
      "epoch 37; iter: 0; batch classifier loss: 0.328650; batch adversarial loss: 0.399559\n",
      "epoch 37; iter: 200; batch classifier loss: 0.314929; batch adversarial loss: 0.565589\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467807; batch adversarial loss: 0.310489\n",
      "epoch 38; iter: 200; batch classifier loss: 0.311984; batch adversarial loss: 0.430520\n",
      "epoch 39; iter: 0; batch classifier loss: 0.253580; batch adversarial loss: 0.388680\n",
      "epoch 39; iter: 200; batch classifier loss: 0.259673; batch adversarial loss: 0.487370\n",
      "epoch 40; iter: 0; batch classifier loss: 0.373718; batch adversarial loss: 0.405437\n",
      "epoch 40; iter: 200; batch classifier loss: 0.372039; batch adversarial loss: 0.563585\n",
      "epoch 41; iter: 0; batch classifier loss: 0.284683; batch adversarial loss: 0.387514\n",
      "epoch 41; iter: 200; batch classifier loss: 0.306571; batch adversarial loss: 0.418863\n",
      "epoch 42; iter: 0; batch classifier loss: 0.334676; batch adversarial loss: 0.381890\n",
      "epoch 42; iter: 200; batch classifier loss: 0.475625; batch adversarial loss: 0.440521\n",
      "epoch 43; iter: 0; batch classifier loss: 0.283044; batch adversarial loss: 0.471130\n",
      "epoch 43; iter: 200; batch classifier loss: 0.412960; batch adversarial loss: 0.407942\n",
      "epoch 44; iter: 0; batch classifier loss: 0.237779; batch adversarial loss: 0.395239\n",
      "epoch 44; iter: 200; batch classifier loss: 0.273830; batch adversarial loss: 0.361387\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374960; batch adversarial loss: 0.468131\n",
      "epoch 45; iter: 200; batch classifier loss: 0.378309; batch adversarial loss: 0.407377\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476183; batch adversarial loss: 0.409769\n",
      "epoch 46; iter: 200; batch classifier loss: 0.338910; batch adversarial loss: 0.378634\n",
      "epoch 47; iter: 0; batch classifier loss: 0.334359; batch adversarial loss: 0.333115\n",
      "epoch 47; iter: 200; batch classifier loss: 0.307909; batch adversarial loss: 0.439799\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424742; batch adversarial loss: 0.356532\n",
      "epoch 48; iter: 200; batch classifier loss: 0.390175; batch adversarial loss: 0.468818\n",
      "epoch 49; iter: 0; batch classifier loss: 0.406080; batch adversarial loss: 0.435062\n",
      "epoch 49; iter: 200; batch classifier loss: 0.373846; batch adversarial loss: 0.435093\n",
      "epoch 0; iter: 0; batch classifier loss: 13.270406; batch adversarial loss: 0.885168\n",
      "epoch 0; iter: 200; batch classifier loss: 7.648065; batch adversarial loss: 0.708514\n",
      "epoch 1; iter: 0; batch classifier loss: 4.819318; batch adversarial loss: 0.639772\n",
      "epoch 1; iter: 200; batch classifier loss: 6.090617; batch adversarial loss: 0.578101\n",
      "epoch 2; iter: 0; batch classifier loss: 2.323834; batch adversarial loss: 0.547488\n",
      "epoch 2; iter: 200; batch classifier loss: 2.817363; batch adversarial loss: 0.493403\n",
      "epoch 3; iter: 0; batch classifier loss: 2.644083; batch adversarial loss: 0.472472\n",
      "epoch 3; iter: 200; batch classifier loss: 1.329797; batch adversarial loss: 0.453769\n",
      "epoch 4; iter: 0; batch classifier loss: 2.198604; batch adversarial loss: 0.470567\n",
      "epoch 4; iter: 200; batch classifier loss: 2.657253; batch adversarial loss: 0.511061\n",
      "epoch 5; iter: 0; batch classifier loss: 2.265857; batch adversarial loss: 0.434197\n",
      "epoch 5; iter: 200; batch classifier loss: 1.006551; batch adversarial loss: 0.395380\n",
      "epoch 6; iter: 0; batch classifier loss: 0.934031; batch adversarial loss: 0.449531\n",
      "epoch 6; iter: 200; batch classifier loss: 2.910891; batch adversarial loss: 0.404241\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545156; batch adversarial loss: 0.340643\n",
      "epoch 7; iter: 200; batch classifier loss: 0.583968; batch adversarial loss: 0.400394\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570614; batch adversarial loss: 0.488019\n",
      "epoch 8; iter: 200; batch classifier loss: 0.532945; batch adversarial loss: 0.386726\n",
      "epoch 9; iter: 0; batch classifier loss: 0.397849; batch adversarial loss: 0.396436\n",
      "epoch 9; iter: 200; batch classifier loss: 0.541211; batch adversarial loss: 0.438965\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516091; batch adversarial loss: 0.417632\n",
      "epoch 10; iter: 200; batch classifier loss: 0.437364; batch adversarial loss: 0.480093\n",
      "epoch 11; iter: 0; batch classifier loss: 0.630438; batch adversarial loss: 0.419946\n",
      "epoch 11; iter: 200; batch classifier loss: 0.396284; batch adversarial loss: 0.465142\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491573; batch adversarial loss: 0.417008\n",
      "epoch 12; iter: 200; batch classifier loss: 0.450387; batch adversarial loss: 0.405513\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384546; batch adversarial loss: 0.402743\n",
      "epoch 13; iter: 200; batch classifier loss: 0.437288; batch adversarial loss: 0.398746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397224; batch adversarial loss: 0.433474\n",
      "epoch 14; iter: 200; batch classifier loss: 0.432820; batch adversarial loss: 0.368554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.365086; batch adversarial loss: 0.404879\n",
      "epoch 15; iter: 200; batch classifier loss: 0.410770; batch adversarial loss: 0.426953\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452372; batch adversarial loss: 0.376415\n",
      "epoch 16; iter: 200; batch classifier loss: 0.277870; batch adversarial loss: 0.448739\n",
      "epoch 17; iter: 0; batch classifier loss: 0.370401; batch adversarial loss: 0.505319\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345405; batch adversarial loss: 0.371630\n",
      "epoch 18; iter: 0; batch classifier loss: 0.364472; batch adversarial loss: 0.328553\n",
      "epoch 18; iter: 200; batch classifier loss: 0.345941; batch adversarial loss: 0.478599\n",
      "epoch 19; iter: 0; batch classifier loss: 0.285557; batch adversarial loss: 0.489273\n",
      "epoch 19; iter: 200; batch classifier loss: 0.382468; batch adversarial loss: 0.391959\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347242; batch adversarial loss: 0.442832\n",
      "epoch 20; iter: 200; batch classifier loss: 0.301501; batch adversarial loss: 0.464407\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312358; batch adversarial loss: 0.365452\n",
      "epoch 21; iter: 200; batch classifier loss: 0.321710; batch adversarial loss: 0.422510\n",
      "epoch 22; iter: 0; batch classifier loss: 0.282101; batch adversarial loss: 0.448510\n",
      "epoch 22; iter: 200; batch classifier loss: 0.341344; batch adversarial loss: 0.442152\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308460; batch adversarial loss: 0.326908\n",
      "epoch 23; iter: 200; batch classifier loss: 0.383858; batch adversarial loss: 0.478719\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315801; batch adversarial loss: 0.328955\n",
      "epoch 24; iter: 200; batch classifier loss: 0.320588; batch adversarial loss: 0.392936\n",
      "epoch 25; iter: 0; batch classifier loss: 0.397681; batch adversarial loss: 0.369738\n",
      "epoch 25; iter: 200; batch classifier loss: 0.339961; batch adversarial loss: 0.435699\n",
      "epoch 26; iter: 0; batch classifier loss: 0.308646; batch adversarial loss: 0.465955\n",
      "epoch 26; iter: 200; batch classifier loss: 0.359721; batch adversarial loss: 0.329118\n",
      "epoch 27; iter: 0; batch classifier loss: 0.312793; batch adversarial loss: 0.292612\n",
      "epoch 27; iter: 200; batch classifier loss: 0.374910; batch adversarial loss: 0.428025\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445460; batch adversarial loss: 0.411615\n",
      "epoch 28; iter: 200; batch classifier loss: 0.312055; batch adversarial loss: 0.368262\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263619; batch adversarial loss: 0.344244\n",
      "epoch 29; iter: 200; batch classifier loss: 0.302366; batch adversarial loss: 0.383618\n",
      "epoch 30; iter: 0; batch classifier loss: 0.426991; batch adversarial loss: 0.443364\n",
      "epoch 30; iter: 200; batch classifier loss: 0.351619; batch adversarial loss: 0.405722\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302298; batch adversarial loss: 0.427069\n",
      "epoch 31; iter: 200; batch classifier loss: 0.324155; batch adversarial loss: 0.384473\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381209; batch adversarial loss: 0.387749\n",
      "epoch 32; iter: 200; batch classifier loss: 0.436232; batch adversarial loss: 0.372088\n",
      "epoch 33; iter: 0; batch classifier loss: 0.342753; batch adversarial loss: 0.357765\n",
      "epoch 33; iter: 200; batch classifier loss: 0.417883; batch adversarial loss: 0.419588\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363160; batch adversarial loss: 0.388750\n",
      "epoch 34; iter: 200; batch classifier loss: 0.308677; batch adversarial loss: 0.488541\n",
      "epoch 35; iter: 0; batch classifier loss: 0.347051; batch adversarial loss: 0.445238\n",
      "epoch 35; iter: 200; batch classifier loss: 0.390675; batch adversarial loss: 0.424565\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368254; batch adversarial loss: 0.385897\n",
      "epoch 36; iter: 200; batch classifier loss: 0.368356; batch adversarial loss: 0.464804\n",
      "epoch 37; iter: 0; batch classifier loss: 0.289770; batch adversarial loss: 0.427707\n",
      "epoch 37; iter: 200; batch classifier loss: 0.236116; batch adversarial loss: 0.284643\n",
      "epoch 38; iter: 0; batch classifier loss: 0.314085; batch adversarial loss: 0.397627\n",
      "epoch 38; iter: 200; batch classifier loss: 0.283558; batch adversarial loss: 0.470077\n",
      "epoch 39; iter: 0; batch classifier loss: 0.529958; batch adversarial loss: 0.393568\n",
      "epoch 39; iter: 200; batch classifier loss: 0.330466; batch adversarial loss: 0.496548\n",
      "epoch 40; iter: 0; batch classifier loss: 0.312241; batch adversarial loss: 0.397986\n",
      "epoch 40; iter: 200; batch classifier loss: 0.344585; batch adversarial loss: 0.371596\n",
      "epoch 41; iter: 0; batch classifier loss: 0.319342; batch adversarial loss: 0.398019\n",
      "epoch 41; iter: 200; batch classifier loss: 0.410291; batch adversarial loss: 0.427668\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364808; batch adversarial loss: 0.531339\n",
      "epoch 42; iter: 200; batch classifier loss: 0.449684; batch adversarial loss: 0.437350\n",
      "epoch 43; iter: 0; batch classifier loss: 0.290259; batch adversarial loss: 0.463511\n",
      "epoch 43; iter: 200; batch classifier loss: 0.354342; batch adversarial loss: 0.367552\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365249; batch adversarial loss: 0.363595\n",
      "epoch 44; iter: 200; batch classifier loss: 0.366532; batch adversarial loss: 0.403048\n",
      "epoch 45; iter: 0; batch classifier loss: 0.311104; batch adversarial loss: 0.553772\n",
      "epoch 45; iter: 200; batch classifier loss: 0.285846; batch adversarial loss: 0.424011\n",
      "epoch 46; iter: 0; batch classifier loss: 0.223581; batch adversarial loss: 0.451736\n",
      "epoch 46; iter: 200; batch classifier loss: 0.450809; batch adversarial loss: 0.362293\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441348; batch adversarial loss: 0.322442\n",
      "epoch 47; iter: 200; batch classifier loss: 0.379599; batch adversarial loss: 0.445838\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335483; batch adversarial loss: 0.487990\n",
      "epoch 48; iter: 200; batch classifier loss: 0.350415; batch adversarial loss: 0.473536\n",
      "epoch 49; iter: 0; batch classifier loss: 0.350417; batch adversarial loss: 0.393465\n",
      "epoch 49; iter: 200; batch classifier loss: 0.314502; batch adversarial loss: 0.494202\n",
      "epoch 0; iter: 0; batch classifier loss: 3.842689; batch adversarial loss: 0.515610\n",
      "epoch 0; iter: 200; batch classifier loss: 0.878388; batch adversarial loss: 0.542171\n",
      "epoch 1; iter: 0; batch classifier loss: 8.984373; batch adversarial loss: 0.545440\n",
      "epoch 1; iter: 200; batch classifier loss: 3.413948; batch adversarial loss: 0.513277\n",
      "epoch 2; iter: 0; batch classifier loss: 2.513541; batch adversarial loss: 0.455387\n",
      "epoch 2; iter: 200; batch classifier loss: 4.170790; batch adversarial loss: 0.397621\n",
      "epoch 3; iter: 0; batch classifier loss: 3.252618; batch adversarial loss: 0.541759\n",
      "epoch 3; iter: 200; batch classifier loss: 1.983861; batch adversarial loss: 0.403811\n",
      "epoch 4; iter: 0; batch classifier loss: 0.956052; batch adversarial loss: 0.431272\n",
      "epoch 4; iter: 200; batch classifier loss: 1.219857; batch adversarial loss: 0.438736\n",
      "epoch 5; iter: 0; batch classifier loss: 1.132687; batch adversarial loss: 0.455256\n",
      "epoch 5; iter: 200; batch classifier loss: 0.763922; batch adversarial loss: 0.446538\n",
      "epoch 6; iter: 0; batch classifier loss: 0.462628; batch adversarial loss: 0.459044\n",
      "epoch 6; iter: 200; batch classifier loss: 0.659758; batch adversarial loss: 0.416936\n",
      "epoch 7; iter: 0; batch classifier loss: 0.433903; batch adversarial loss: 0.460568\n",
      "epoch 7; iter: 200; batch classifier loss: 0.439274; batch adversarial loss: 0.422105\n",
      "epoch 8; iter: 0; batch classifier loss: 0.592815; batch adversarial loss: 0.407477\n",
      "epoch 8; iter: 200; batch classifier loss: 0.392029; batch adversarial loss: 0.402070\n",
      "epoch 9; iter: 0; batch classifier loss: 0.316360; batch adversarial loss: 0.386752\n",
      "epoch 9; iter: 200; batch classifier loss: 0.515138; batch adversarial loss: 0.333143\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492119; batch adversarial loss: 0.473009\n",
      "epoch 10; iter: 200; batch classifier loss: 0.347312; batch adversarial loss: 0.379916\n",
      "epoch 11; iter: 0; batch classifier loss: 0.417630; batch adversarial loss: 0.417026\n",
      "epoch 11; iter: 200; batch classifier loss: 0.375460; batch adversarial loss: 0.365697\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472908; batch adversarial loss: 0.434386\n",
      "epoch 12; iter: 200; batch classifier loss: 0.594141; batch adversarial loss: 0.397716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324321; batch adversarial loss: 0.427374\n",
      "epoch 13; iter: 200; batch classifier loss: 0.333547; batch adversarial loss: 0.411000\n",
      "epoch 14; iter: 0; batch classifier loss: 0.410414; batch adversarial loss: 0.416861\n",
      "epoch 14; iter: 200; batch classifier loss: 0.328880; batch adversarial loss: 0.388242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.303424; batch adversarial loss: 0.430671\n",
      "epoch 15; iter: 200; batch classifier loss: 0.336316; batch adversarial loss: 0.423794\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356501; batch adversarial loss: 0.351478\n",
      "epoch 16; iter: 200; batch classifier loss: 0.322224; batch adversarial loss: 0.409702\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382972; batch adversarial loss: 0.499595\n",
      "epoch 17; iter: 200; batch classifier loss: 0.370124; batch adversarial loss: 0.317967\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334533; batch adversarial loss: 0.422093\n",
      "epoch 18; iter: 200; batch classifier loss: 0.316881; batch adversarial loss: 0.391419\n",
      "epoch 19; iter: 0; batch classifier loss: 0.395291; batch adversarial loss: 0.339376\n",
      "epoch 19; iter: 200; batch classifier loss: 0.366417; batch adversarial loss: 0.386370\n",
      "epoch 20; iter: 0; batch classifier loss: 0.298014; batch adversarial loss: 0.338927\n",
      "epoch 20; iter: 200; batch classifier loss: 0.273166; batch adversarial loss: 0.452271\n",
      "epoch 21; iter: 0; batch classifier loss: 0.314355; batch adversarial loss: 0.360414\n",
      "epoch 21; iter: 200; batch classifier loss: 0.410929; batch adversarial loss: 0.454069\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305796; batch adversarial loss: 0.395686\n",
      "epoch 22; iter: 200; batch classifier loss: 0.358529; batch adversarial loss: 0.422830\n",
      "epoch 23; iter: 0; batch classifier loss: 0.293509; batch adversarial loss: 0.471504\n",
      "epoch 23; iter: 200; batch classifier loss: 0.352316; batch adversarial loss: 0.384558\n",
      "epoch 24; iter: 0; batch classifier loss: 0.316504; batch adversarial loss: 0.470200\n",
      "epoch 24; iter: 200; batch classifier loss: 0.335447; batch adversarial loss: 0.451386\n",
      "epoch 25; iter: 0; batch classifier loss: 0.343692; batch adversarial loss: 0.441704\n",
      "epoch 25; iter: 200; batch classifier loss: 0.351089; batch adversarial loss: 0.480667\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419207; batch adversarial loss: 0.425158\n",
      "epoch 26; iter: 200; batch classifier loss: 0.291575; batch adversarial loss: 0.375649\n",
      "epoch 27; iter: 0; batch classifier loss: 0.382096; batch adversarial loss: 0.480440\n",
      "epoch 27; iter: 200; batch classifier loss: 0.285106; batch adversarial loss: 0.403581\n",
      "epoch 28; iter: 0; batch classifier loss: 0.391342; batch adversarial loss: 0.425625\n",
      "epoch 28; iter: 200; batch classifier loss: 0.361505; batch adversarial loss: 0.344373\n",
      "epoch 29; iter: 0; batch classifier loss: 0.403503; batch adversarial loss: 0.378329\n",
      "epoch 29; iter: 200; batch classifier loss: 0.267977; batch adversarial loss: 0.456708\n",
      "epoch 30; iter: 0; batch classifier loss: 0.366698; batch adversarial loss: 0.429163\n",
      "epoch 30; iter: 200; batch classifier loss: 0.329446; batch adversarial loss: 0.438795\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320770; batch adversarial loss: 0.413256\n",
      "epoch 31; iter: 200; batch classifier loss: 0.302518; batch adversarial loss: 0.488664\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393228; batch adversarial loss: 0.405145\n",
      "epoch 32; iter: 200; batch classifier loss: 0.346081; batch adversarial loss: 0.357478\n",
      "epoch 33; iter: 0; batch classifier loss: 0.259968; batch adversarial loss: 0.353992\n",
      "epoch 33; iter: 200; batch classifier loss: 0.399734; batch adversarial loss: 0.369935\n",
      "epoch 34; iter: 0; batch classifier loss: 0.356134; batch adversarial loss: 0.337389\n",
      "epoch 34; iter: 200; batch classifier loss: 0.295455; batch adversarial loss: 0.430713\n",
      "epoch 35; iter: 0; batch classifier loss: 0.380665; batch adversarial loss: 0.358413\n",
      "epoch 35; iter: 200; batch classifier loss: 0.436867; batch adversarial loss: 0.387201\n",
      "epoch 36; iter: 0; batch classifier loss: 0.456156; batch adversarial loss: 0.385581\n",
      "epoch 36; iter: 200; batch classifier loss: 0.496995; batch adversarial loss: 0.379700\n",
      "epoch 37; iter: 0; batch classifier loss: 0.367676; batch adversarial loss: 0.379242\n",
      "epoch 37; iter: 200; batch classifier loss: 0.443432; batch adversarial loss: 0.482924\n",
      "epoch 38; iter: 0; batch classifier loss: 0.365483; batch adversarial loss: 0.471177\n",
      "epoch 38; iter: 200; batch classifier loss: 0.350586; batch adversarial loss: 0.559955\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423397; batch adversarial loss: 0.412139\n",
      "epoch 39; iter: 200; batch classifier loss: 0.403728; batch adversarial loss: 0.428273\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470313; batch adversarial loss: 0.320435\n",
      "epoch 40; iter: 200; batch classifier loss: 0.405982; batch adversarial loss: 0.435942\n",
      "epoch 41; iter: 0; batch classifier loss: 0.375471; batch adversarial loss: 0.390567\n",
      "epoch 41; iter: 200; batch classifier loss: 0.433509; batch adversarial loss: 0.270029\n",
      "epoch 42; iter: 0; batch classifier loss: 0.514949; batch adversarial loss: 0.499979\n",
      "epoch 42; iter: 200; batch classifier loss: 0.562916; batch adversarial loss: 0.486008\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365094; batch adversarial loss: 0.477994\n",
      "epoch 43; iter: 200; batch classifier loss: 0.501834; batch adversarial loss: 0.390082\n",
      "epoch 44; iter: 0; batch classifier loss: 0.535151; batch adversarial loss: 0.430677\n",
      "epoch 44; iter: 200; batch classifier loss: 0.377057; batch adversarial loss: 0.366908\n",
      "epoch 45; iter: 0; batch classifier loss: 0.435165; batch adversarial loss: 0.520419\n",
      "epoch 45; iter: 200; batch classifier loss: 0.418592; batch adversarial loss: 0.373346\n",
      "epoch 46; iter: 0; batch classifier loss: 0.502803; batch adversarial loss: 0.417331\n",
      "epoch 46; iter: 200; batch classifier loss: 0.444817; batch adversarial loss: 0.419704\n",
      "epoch 47; iter: 0; batch classifier loss: 0.498344; batch adversarial loss: 0.492577\n",
      "epoch 47; iter: 200; batch classifier loss: 0.366014; batch adversarial loss: 0.400881\n",
      "epoch 48; iter: 0; batch classifier loss: 0.566755; batch adversarial loss: 0.437905\n",
      "epoch 48; iter: 200; batch classifier loss: 0.409362; batch adversarial loss: 0.408300\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443509; batch adversarial loss: 0.445077\n",
      "epoch 49; iter: 200; batch classifier loss: 0.400096; batch adversarial loss: 0.372081\n",
      "epoch 0; iter: 0; batch classifier loss: 15.455381; batch adversarial loss: 0.639820\n",
      "epoch 0; iter: 200; batch classifier loss: 7.155517; batch adversarial loss: 0.583176\n",
      "epoch 1; iter: 0; batch classifier loss: 1.608236; batch adversarial loss: 0.513727\n",
      "epoch 1; iter: 200; batch classifier loss: 2.449796; batch adversarial loss: 0.547579\n",
      "epoch 2; iter: 0; batch classifier loss: 1.996648; batch adversarial loss: 0.509122\n",
      "epoch 2; iter: 200; batch classifier loss: 5.413888; batch adversarial loss: 0.460604\n",
      "epoch 3; iter: 0; batch classifier loss: 1.104453; batch adversarial loss: 0.458331\n",
      "epoch 3; iter: 200; batch classifier loss: 1.712452; batch adversarial loss: 0.400784\n",
      "epoch 4; iter: 0; batch classifier loss: 1.277662; batch adversarial loss: 0.404174\n",
      "epoch 4; iter: 200; batch classifier loss: 0.825259; batch adversarial loss: 0.383335\n",
      "epoch 5; iter: 0; batch classifier loss: 4.314993; batch adversarial loss: 0.441209\n",
      "epoch 5; iter: 200; batch classifier loss: 1.549007; batch adversarial loss: 0.526666\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572641; batch adversarial loss: 0.406804\n",
      "epoch 6; iter: 200; batch classifier loss: 0.479200; batch adversarial loss: 0.420043\n",
      "epoch 7; iter: 0; batch classifier loss: 0.811313; batch adversarial loss: 0.454177\n",
      "epoch 7; iter: 200; batch classifier loss: 0.610901; batch adversarial loss: 0.495143\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549085; batch adversarial loss: 0.364075\n",
      "epoch 8; iter: 200; batch classifier loss: 0.620643; batch adversarial loss: 0.419618\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407428; batch adversarial loss: 0.480567\n",
      "epoch 9; iter: 200; batch classifier loss: 0.373046; batch adversarial loss: 0.478808\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374847; batch adversarial loss: 0.431807\n",
      "epoch 10; iter: 200; batch classifier loss: 0.465696; batch adversarial loss: 0.373677\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348988; batch adversarial loss: 0.482578\n",
      "epoch 11; iter: 200; batch classifier loss: 0.466310; batch adversarial loss: 0.368485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.424182; batch adversarial loss: 0.412611\n",
      "epoch 12; iter: 200; batch classifier loss: 0.473609; batch adversarial loss: 0.391389\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363016; batch adversarial loss: 0.342308\n",
      "epoch 13; iter: 200; batch classifier loss: 0.371630; batch adversarial loss: 0.360523\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395454; batch adversarial loss: 0.375735\n",
      "epoch 14; iter: 200; batch classifier loss: 0.403782; batch adversarial loss: 0.544710\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313739; batch adversarial loss: 0.339304\n",
      "epoch 15; iter: 200; batch classifier loss: 0.317133; batch adversarial loss: 0.490546\n",
      "epoch 16; iter: 0; batch classifier loss: 0.284188; batch adversarial loss: 0.480104\n",
      "epoch 16; iter: 200; batch classifier loss: 0.324635; batch adversarial loss: 0.491244\n",
      "epoch 17; iter: 0; batch classifier loss: 0.369567; batch adversarial loss: 0.351759\n",
      "epoch 17; iter: 200; batch classifier loss: 0.299652; batch adversarial loss: 0.456788\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306874; batch adversarial loss: 0.391830\n",
      "epoch 18; iter: 200; batch classifier loss: 0.369596; batch adversarial loss: 0.375698\n",
      "epoch 19; iter: 0; batch classifier loss: 0.380269; batch adversarial loss: 0.373304\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316393; batch adversarial loss: 0.534721\n",
      "epoch 20; iter: 0; batch classifier loss: 0.309326; batch adversarial loss: 0.375718\n",
      "epoch 20; iter: 200; batch classifier loss: 0.371802; batch adversarial loss: 0.422913\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392944; batch adversarial loss: 0.537151\n",
      "epoch 21; iter: 200; batch classifier loss: 0.310128; batch adversarial loss: 0.412364\n",
      "epoch 22; iter: 0; batch classifier loss: 0.309580; batch adversarial loss: 0.390717\n",
      "epoch 22; iter: 200; batch classifier loss: 0.337376; batch adversarial loss: 0.410252\n",
      "epoch 23; iter: 0; batch classifier loss: 0.384057; batch adversarial loss: 0.349636\n",
      "epoch 23; iter: 200; batch classifier loss: 0.413608; batch adversarial loss: 0.545139\n",
      "epoch 24; iter: 0; batch classifier loss: 0.344282; batch adversarial loss: 0.536286\n",
      "epoch 24; iter: 200; batch classifier loss: 0.377515; batch adversarial loss: 0.407558\n",
      "epoch 25; iter: 0; batch classifier loss: 0.353653; batch adversarial loss: 0.450025\n",
      "epoch 25; iter: 200; batch classifier loss: 0.332377; batch adversarial loss: 0.427157\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319564; batch adversarial loss: 0.428715\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343379; batch adversarial loss: 0.322726\n",
      "epoch 27; iter: 0; batch classifier loss: 0.377523; batch adversarial loss: 0.296766\n",
      "epoch 27; iter: 200; batch classifier loss: 0.347137; batch adversarial loss: 0.392753\n",
      "epoch 28; iter: 0; batch classifier loss: 0.304867; batch adversarial loss: 0.386853\n",
      "epoch 28; iter: 200; batch classifier loss: 0.345634; batch adversarial loss: 0.401164\n",
      "epoch 29; iter: 0; batch classifier loss: 0.370612; batch adversarial loss: 0.312713\n",
      "epoch 29; iter: 200; batch classifier loss: 0.334850; batch adversarial loss: 0.394417\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320032; batch adversarial loss: 0.365892\n",
      "epoch 30; iter: 200; batch classifier loss: 0.285508; batch adversarial loss: 0.430077\n",
      "epoch 31; iter: 0; batch classifier loss: 0.308493; batch adversarial loss: 0.405024\n",
      "epoch 31; iter: 200; batch classifier loss: 0.344698; batch adversarial loss: 0.435795\n",
      "epoch 32; iter: 0; batch classifier loss: 0.343343; batch adversarial loss: 0.372303\n",
      "epoch 32; iter: 200; batch classifier loss: 0.361309; batch adversarial loss: 0.476169\n",
      "epoch 33; iter: 0; batch classifier loss: 0.320294; batch adversarial loss: 0.330972\n",
      "epoch 33; iter: 200; batch classifier loss: 0.316229; batch adversarial loss: 0.350772\n",
      "epoch 34; iter: 0; batch classifier loss: 0.338926; batch adversarial loss: 0.356783\n",
      "epoch 34; iter: 200; batch classifier loss: 0.314645; batch adversarial loss: 0.424800\n",
      "epoch 35; iter: 0; batch classifier loss: 0.338296; batch adversarial loss: 0.413271\n",
      "epoch 35; iter: 200; batch classifier loss: 0.323371; batch adversarial loss: 0.515296\n",
      "epoch 36; iter: 0; batch classifier loss: 0.308332; batch adversarial loss: 0.343687\n",
      "epoch 36; iter: 200; batch classifier loss: 0.284397; batch adversarial loss: 0.374893\n",
      "epoch 37; iter: 0; batch classifier loss: 0.249755; batch adversarial loss: 0.410781\n",
      "epoch 37; iter: 200; batch classifier loss: 0.348736; batch adversarial loss: 0.362447\n",
      "epoch 38; iter: 0; batch classifier loss: 0.249609; batch adversarial loss: 0.395024\n",
      "epoch 38; iter: 200; batch classifier loss: 0.385171; batch adversarial loss: 0.506721\n",
      "epoch 39; iter: 0; batch classifier loss: 0.380394; batch adversarial loss: 0.341069\n",
      "epoch 39; iter: 200; batch classifier loss: 0.251658; batch adversarial loss: 0.395181\n",
      "epoch 40; iter: 0; batch classifier loss: 0.400710; batch adversarial loss: 0.462802\n",
      "epoch 40; iter: 200; batch classifier loss: 0.392007; batch adversarial loss: 0.401991\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401429; batch adversarial loss: 0.332479\n",
      "epoch 41; iter: 200; batch classifier loss: 0.335634; batch adversarial loss: 0.462069\n",
      "epoch 42; iter: 0; batch classifier loss: 0.351726; batch adversarial loss: 0.404649\n",
      "epoch 42; iter: 200; batch classifier loss: 0.421138; batch adversarial loss: 0.352939\n",
      "epoch 43; iter: 0; batch classifier loss: 0.269261; batch adversarial loss: 0.364510\n",
      "epoch 43; iter: 200; batch classifier loss: 0.271285; batch adversarial loss: 0.365839\n",
      "epoch 44; iter: 0; batch classifier loss: 0.371512; batch adversarial loss: 0.445865\n",
      "epoch 44; iter: 200; batch classifier loss: 0.412593; batch adversarial loss: 0.410972\n",
      "epoch 45; iter: 0; batch classifier loss: 0.379073; batch adversarial loss: 0.359420\n",
      "epoch 45; iter: 200; batch classifier loss: 0.369781; batch adversarial loss: 0.387821\n",
      "epoch 46; iter: 0; batch classifier loss: 0.327944; batch adversarial loss: 0.417250\n",
      "epoch 46; iter: 200; batch classifier loss: 0.273330; batch adversarial loss: 0.500131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350967; batch adversarial loss: 0.380307\n",
      "epoch 47; iter: 200; batch classifier loss: 0.392067; batch adversarial loss: 0.422927\n",
      "epoch 48; iter: 0; batch classifier loss: 0.595536; batch adversarial loss: 0.480538\n",
      "epoch 48; iter: 200; batch classifier loss: 0.251454; batch adversarial loss: 0.418537\n",
      "epoch 49; iter: 0; batch classifier loss: 0.281150; batch adversarial loss: 0.445530\n",
      "epoch 49; iter: 200; batch classifier loss: 0.368841; batch adversarial loss: 0.493254\n",
      "epoch 0; iter: 0; batch classifier loss: 7.172602; batch adversarial loss: 0.635281\n",
      "epoch 0; iter: 200; batch classifier loss: 10.754128; batch adversarial loss: 0.590168\n",
      "epoch 1; iter: 0; batch classifier loss: 4.073946; batch adversarial loss: 0.494289\n",
      "epoch 1; iter: 200; batch classifier loss: 2.840365; batch adversarial loss: 0.469696\n",
      "epoch 2; iter: 0; batch classifier loss: 7.080370; batch adversarial loss: 0.464963\n",
      "epoch 2; iter: 200; batch classifier loss: 4.255282; batch adversarial loss: 0.441600\n",
      "epoch 3; iter: 0; batch classifier loss: 3.966500; batch adversarial loss: 0.381690\n",
      "epoch 3; iter: 200; batch classifier loss: 4.836324; batch adversarial loss: 0.427898\n",
      "epoch 4; iter: 0; batch classifier loss: 2.040226; batch adversarial loss: 0.358172\n",
      "epoch 4; iter: 200; batch classifier loss: 1.091627; batch adversarial loss: 0.441249\n",
      "epoch 5; iter: 0; batch classifier loss: 2.106684; batch adversarial loss: 0.405764\n",
      "epoch 5; iter: 200; batch classifier loss: 1.962581; batch adversarial loss: 0.536027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532653; batch adversarial loss: 0.443322\n",
      "epoch 6; iter: 200; batch classifier loss: 1.927784; batch adversarial loss: 0.455001\n",
      "epoch 7; iter: 0; batch classifier loss: 1.481192; batch adversarial loss: 0.437014\n",
      "epoch 7; iter: 200; batch classifier loss: 0.510867; batch adversarial loss: 0.375591\n",
      "epoch 8; iter: 0; batch classifier loss: 0.471399; batch adversarial loss: 0.374086\n",
      "epoch 8; iter: 200; batch classifier loss: 0.711563; batch adversarial loss: 0.449237\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335248; batch adversarial loss: 0.398743\n",
      "epoch 9; iter: 200; batch classifier loss: 0.591220; batch adversarial loss: 0.459402\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460686; batch adversarial loss: 0.398664\n",
      "epoch 10; iter: 200; batch classifier loss: 0.398535; batch adversarial loss: 0.461544\n",
      "epoch 11; iter: 0; batch classifier loss: 0.685590; batch adversarial loss: 0.460718\n",
      "epoch 11; iter: 200; batch classifier loss: 0.384513; batch adversarial loss: 0.430602\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379486; batch adversarial loss: 0.482101\n",
      "epoch 12; iter: 200; batch classifier loss: 0.505796; batch adversarial loss: 0.399391\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350037; batch adversarial loss: 0.406435\n",
      "epoch 13; iter: 200; batch classifier loss: 0.531989; batch adversarial loss: 0.401963\n",
      "epoch 14; iter: 0; batch classifier loss: 0.450703; batch adversarial loss: 0.345996\n",
      "epoch 14; iter: 200; batch classifier loss: 0.472048; batch adversarial loss: 0.356241\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381339; batch adversarial loss: 0.354636\n",
      "epoch 15; iter: 200; batch classifier loss: 0.381823; batch adversarial loss: 0.421102\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330884; batch adversarial loss: 0.433841\n",
      "epoch 16; iter: 200; batch classifier loss: 0.323792; batch adversarial loss: 0.308602\n",
      "epoch 17; iter: 0; batch classifier loss: 0.442211; batch adversarial loss: 0.288443\n",
      "epoch 17; iter: 200; batch classifier loss: 0.323820; batch adversarial loss: 0.359193\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354293; batch adversarial loss: 0.352796\n",
      "epoch 18; iter: 200; batch classifier loss: 0.301488; batch adversarial loss: 0.303407\n",
      "epoch 19; iter: 0; batch classifier loss: 0.407255; batch adversarial loss: 0.363926\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376716; batch adversarial loss: 0.336949\n",
      "epoch 20; iter: 0; batch classifier loss: 0.271564; batch adversarial loss: 0.429467\n",
      "epoch 20; iter: 200; batch classifier loss: 0.332838; batch adversarial loss: 0.440847\n",
      "epoch 21; iter: 0; batch classifier loss: 0.409426; batch adversarial loss: 0.419493\n",
      "epoch 21; iter: 200; batch classifier loss: 0.340063; batch adversarial loss: 0.376088\n",
      "epoch 22; iter: 0; batch classifier loss: 0.290560; batch adversarial loss: 0.421719\n",
      "epoch 22; iter: 200; batch classifier loss: 0.298867; batch adversarial loss: 0.397560\n",
      "epoch 23; iter: 0; batch classifier loss: 0.371317; batch adversarial loss: 0.342515\n",
      "epoch 23; iter: 200; batch classifier loss: 0.325477; batch adversarial loss: 0.331919\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361429; batch adversarial loss: 0.422863\n",
      "epoch 24; iter: 200; batch classifier loss: 0.317571; batch adversarial loss: 0.442480\n",
      "epoch 25; iter: 0; batch classifier loss: 0.380796; batch adversarial loss: 0.347421\n",
      "epoch 25; iter: 200; batch classifier loss: 0.320760; batch adversarial loss: 0.420056\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343072; batch adversarial loss: 0.375378\n",
      "epoch 26; iter: 200; batch classifier loss: 0.372183; batch adversarial loss: 0.306578\n",
      "epoch 27; iter: 0; batch classifier loss: 0.316891; batch adversarial loss: 0.418632\n",
      "epoch 27; iter: 200; batch classifier loss: 0.295398; batch adversarial loss: 0.373819\n",
      "epoch 28; iter: 0; batch classifier loss: 0.378830; batch adversarial loss: 0.387387\n",
      "epoch 28; iter: 200; batch classifier loss: 0.411527; batch adversarial loss: 0.442992\n",
      "epoch 29; iter: 0; batch classifier loss: 0.308490; batch adversarial loss: 0.403940\n",
      "epoch 29; iter: 200; batch classifier loss: 0.315015; batch adversarial loss: 0.477998\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448824; batch adversarial loss: 0.389903\n",
      "epoch 30; iter: 200; batch classifier loss: 0.378075; batch adversarial loss: 0.345456\n",
      "epoch 31; iter: 0; batch classifier loss: 0.336494; batch adversarial loss: 0.457765\n",
      "epoch 31; iter: 200; batch classifier loss: 0.348844; batch adversarial loss: 0.445574\n",
      "epoch 32; iter: 0; batch classifier loss: 0.350669; batch adversarial loss: 0.307417\n",
      "epoch 32; iter: 200; batch classifier loss: 0.346629; batch adversarial loss: 0.488529\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330075; batch adversarial loss: 0.393329\n",
      "epoch 33; iter: 200; batch classifier loss: 0.408710; batch adversarial loss: 0.414676\n",
      "epoch 34; iter: 0; batch classifier loss: 0.341172; batch adversarial loss: 0.325620\n",
      "epoch 34; iter: 200; batch classifier loss: 0.353898; batch adversarial loss: 0.407861\n",
      "epoch 35; iter: 0; batch classifier loss: 0.270215; batch adversarial loss: 0.359750\n",
      "epoch 35; iter: 200; batch classifier loss: 0.348670; batch adversarial loss: 0.389223\n",
      "epoch 36; iter: 0; batch classifier loss: 0.318058; batch adversarial loss: 0.408227\n",
      "epoch 36; iter: 200; batch classifier loss: 0.339756; batch adversarial loss: 0.419568\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394673; batch adversarial loss: 0.436438\n",
      "epoch 37; iter: 200; batch classifier loss: 0.294997; batch adversarial loss: 0.394283\n",
      "epoch 38; iter: 0; batch classifier loss: 0.250581; batch adversarial loss: 0.429542\n",
      "epoch 38; iter: 200; batch classifier loss: 0.387733; batch adversarial loss: 0.435466\n",
      "epoch 39; iter: 0; batch classifier loss: 0.367385; batch adversarial loss: 0.423789\n",
      "epoch 39; iter: 200; batch classifier loss: 0.436281; batch adversarial loss: 0.426489\n",
      "epoch 40; iter: 0; batch classifier loss: 0.303907; batch adversarial loss: 0.409996\n",
      "epoch 40; iter: 200; batch classifier loss: 0.268804; batch adversarial loss: 0.450585\n",
      "epoch 41; iter: 0; batch classifier loss: 0.298806; batch adversarial loss: 0.396434\n",
      "epoch 41; iter: 200; batch classifier loss: 0.406084; batch adversarial loss: 0.412815\n",
      "epoch 42; iter: 0; batch classifier loss: 0.323674; batch adversarial loss: 0.448023\n",
      "epoch 42; iter: 200; batch classifier loss: 0.287537; batch adversarial loss: 0.397651\n",
      "epoch 43; iter: 0; batch classifier loss: 0.304210; batch adversarial loss: 0.429819\n",
      "epoch 43; iter: 200; batch classifier loss: 0.405897; batch adversarial loss: 0.524281\n",
      "epoch 44; iter: 0; batch classifier loss: 0.306436; batch adversarial loss: 0.312000\n",
      "epoch 44; iter: 200; batch classifier loss: 0.342461; batch adversarial loss: 0.491590\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336045; batch adversarial loss: 0.328192\n",
      "epoch 45; iter: 200; batch classifier loss: 0.348115; batch adversarial loss: 0.451694\n",
      "epoch 46; iter: 0; batch classifier loss: 0.334765; batch adversarial loss: 0.436037\n",
      "epoch 46; iter: 200; batch classifier loss: 0.328577; batch adversarial loss: 0.405656\n",
      "epoch 47; iter: 0; batch classifier loss: 0.297241; batch adversarial loss: 0.438260\n",
      "epoch 47; iter: 200; batch classifier loss: 0.342574; batch adversarial loss: 0.378637\n",
      "epoch 48; iter: 0; batch classifier loss: 0.357118; batch adversarial loss: 0.415453\n",
      "epoch 48; iter: 200; batch classifier loss: 0.320618; batch adversarial loss: 0.328332\n",
      "epoch 49; iter: 0; batch classifier loss: 0.316597; batch adversarial loss: 0.318153\n",
      "epoch 49; iter: 200; batch classifier loss: 0.288316; batch adversarial loss: 0.475847\n",
      "epoch 0; iter: 0; batch classifier loss: 35.043953; batch adversarial loss: 0.550505\n",
      "epoch 0; iter: 200; batch classifier loss: 18.104752; batch adversarial loss: 0.483669\n",
      "epoch 1; iter: 0; batch classifier loss: 7.019398; batch adversarial loss: 0.492082\n",
      "epoch 1; iter: 200; batch classifier loss: 4.182251; batch adversarial loss: 0.396822\n",
      "epoch 2; iter: 0; batch classifier loss: 4.996115; batch adversarial loss: 0.483642\n",
      "epoch 2; iter: 200; batch classifier loss: 3.090558; batch adversarial loss: 0.504264\n",
      "epoch 3; iter: 0; batch classifier loss: 3.308601; batch adversarial loss: 0.491533\n",
      "epoch 3; iter: 200; batch classifier loss: 1.079180; batch adversarial loss: 0.426764\n",
      "epoch 4; iter: 0; batch classifier loss: 1.944220; batch adversarial loss: 0.490629\n",
      "epoch 4; iter: 200; batch classifier loss: 1.663579; batch adversarial loss: 0.466115\n",
      "epoch 5; iter: 0; batch classifier loss: 1.000420; batch adversarial loss: 0.310149\n",
      "epoch 5; iter: 200; batch classifier loss: 1.407961; batch adversarial loss: 0.390308\n",
      "epoch 6; iter: 0; batch classifier loss: 0.690176; batch adversarial loss: 0.435432\n",
      "epoch 6; iter: 200; batch classifier loss: 0.611653; batch adversarial loss: 0.320578\n",
      "epoch 7; iter: 0; batch classifier loss: 0.599460; batch adversarial loss: 0.437385\n",
      "epoch 7; iter: 200; batch classifier loss: 0.535363; batch adversarial loss: 0.429042\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403091; batch adversarial loss: 0.413456\n",
      "epoch 8; iter: 200; batch classifier loss: 0.780990; batch adversarial loss: 0.399603\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440067; batch adversarial loss: 0.416782\n",
      "epoch 9; iter: 200; batch classifier loss: 0.398094; batch adversarial loss: 0.477596\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480746; batch adversarial loss: 0.326182\n",
      "epoch 10; iter: 200; batch classifier loss: 0.330040; batch adversarial loss: 0.362500\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333826; batch adversarial loss: 0.457911\n",
      "epoch 11; iter: 200; batch classifier loss: 0.411449; batch adversarial loss: 0.347392\n",
      "epoch 12; iter: 0; batch classifier loss: 0.324777; batch adversarial loss: 0.456035\n",
      "epoch 12; iter: 200; batch classifier loss: 0.345076; batch adversarial loss: 0.432997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293805; batch adversarial loss: 0.472940\n",
      "epoch 13; iter: 200; batch classifier loss: 0.385124; batch adversarial loss: 0.464244\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342713; batch adversarial loss: 0.335266\n",
      "epoch 14; iter: 200; batch classifier loss: 0.316153; batch adversarial loss: 0.419178\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364707; batch adversarial loss: 0.431108\n",
      "epoch 15; iter: 200; batch classifier loss: 0.279590; batch adversarial loss: 0.442205\n",
      "epoch 16; iter: 0; batch classifier loss: 0.407845; batch adversarial loss: 0.336505\n",
      "epoch 16; iter: 200; batch classifier loss: 0.458663; batch adversarial loss: 0.477904\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333467; batch adversarial loss: 0.432366\n",
      "epoch 17; iter: 200; batch classifier loss: 0.388163; batch adversarial loss: 0.406246\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328051; batch adversarial loss: 0.454726\n",
      "epoch 18; iter: 200; batch classifier loss: 0.563696; batch adversarial loss: 0.397491\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277014; batch adversarial loss: 0.382404\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387319; batch adversarial loss: 0.302323\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347100; batch adversarial loss: 0.403173\n",
      "epoch 20; iter: 200; batch classifier loss: 0.345082; batch adversarial loss: 0.353013\n",
      "epoch 21; iter: 0; batch classifier loss: 0.348752; batch adversarial loss: 0.394360\n",
      "epoch 21; iter: 200; batch classifier loss: 0.331846; batch adversarial loss: 0.456511\n",
      "epoch 22; iter: 0; batch classifier loss: 0.328874; batch adversarial loss: 0.435903\n",
      "epoch 22; iter: 200; batch classifier loss: 0.345897; batch adversarial loss: 0.419937\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333925; batch adversarial loss: 0.366122\n",
      "epoch 23; iter: 200; batch classifier loss: 0.314162; batch adversarial loss: 0.387220\n",
      "epoch 24; iter: 0; batch classifier loss: 0.380439; batch adversarial loss: 0.474772\n",
      "epoch 24; iter: 200; batch classifier loss: 0.339850; batch adversarial loss: 0.420711\n",
      "epoch 25; iter: 0; batch classifier loss: 0.255802; batch adversarial loss: 0.462344\n",
      "epoch 25; iter: 200; batch classifier loss: 0.411434; batch adversarial loss: 0.379948\n",
      "epoch 26; iter: 0; batch classifier loss: 0.320904; batch adversarial loss: 0.366879\n",
      "epoch 26; iter: 200; batch classifier loss: 0.300648; batch adversarial loss: 0.479611\n",
      "epoch 27; iter: 0; batch classifier loss: 0.320257; batch adversarial loss: 0.465129\n",
      "epoch 27; iter: 200; batch classifier loss: 0.332184; batch adversarial loss: 0.364901\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315267; batch adversarial loss: 0.422919\n",
      "epoch 28; iter: 200; batch classifier loss: 0.328357; batch adversarial loss: 0.455238\n",
      "epoch 29; iter: 0; batch classifier loss: 0.342794; batch adversarial loss: 0.472954\n",
      "epoch 29; iter: 200; batch classifier loss: 0.264633; batch adversarial loss: 0.403055\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315161; batch adversarial loss: 0.463351\n",
      "epoch 30; iter: 200; batch classifier loss: 0.327522; batch adversarial loss: 0.467539\n",
      "epoch 31; iter: 0; batch classifier loss: 0.348485; batch adversarial loss: 0.430811\n",
      "epoch 31; iter: 200; batch classifier loss: 0.308575; batch adversarial loss: 0.383518\n",
      "epoch 32; iter: 0; batch classifier loss: 0.404848; batch adversarial loss: 0.425751\n",
      "epoch 32; iter: 200; batch classifier loss: 0.333906; batch adversarial loss: 0.374492\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347761; batch adversarial loss: 0.351513\n",
      "epoch 33; iter: 200; batch classifier loss: 0.393771; batch adversarial loss: 0.511805\n",
      "epoch 34; iter: 0; batch classifier loss: 0.373257; batch adversarial loss: 0.314708\n",
      "epoch 34; iter: 200; batch classifier loss: 0.344897; batch adversarial loss: 0.361615\n",
      "epoch 35; iter: 0; batch classifier loss: 0.272930; batch adversarial loss: 0.347128\n",
      "epoch 35; iter: 200; batch classifier loss: 0.315825; batch adversarial loss: 0.425571\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261972; batch adversarial loss: 0.562593\n",
      "epoch 36; iter: 200; batch classifier loss: 0.363109; batch adversarial loss: 0.501963\n",
      "epoch 37; iter: 0; batch classifier loss: 0.324614; batch adversarial loss: 0.509591\n",
      "epoch 37; iter: 200; batch classifier loss: 0.305151; batch adversarial loss: 0.475796\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389544; batch adversarial loss: 0.354419\n",
      "epoch 38; iter: 200; batch classifier loss: 0.369174; batch adversarial loss: 0.365278\n",
      "epoch 39; iter: 0; batch classifier loss: 0.304354; batch adversarial loss: 0.375545\n",
      "epoch 39; iter: 200; batch classifier loss: 0.364186; batch adversarial loss: 0.329274\n",
      "epoch 40; iter: 0; batch classifier loss: 0.359537; batch adversarial loss: 0.331774\n",
      "epoch 40; iter: 200; batch classifier loss: 0.311329; batch adversarial loss: 0.373144\n",
      "epoch 41; iter: 0; batch classifier loss: 0.339041; batch adversarial loss: 0.365085\n",
      "epoch 41; iter: 200; batch classifier loss: 0.380807; batch adversarial loss: 0.410167\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385301; batch adversarial loss: 0.317822\n",
      "epoch 42; iter: 200; batch classifier loss: 0.303219; batch adversarial loss: 0.403750\n",
      "epoch 43; iter: 0; batch classifier loss: 0.370486; batch adversarial loss: 0.439247\n",
      "epoch 43; iter: 200; batch classifier loss: 0.296663; batch adversarial loss: 0.383334\n",
      "epoch 44; iter: 0; batch classifier loss: 0.352094; batch adversarial loss: 0.348671\n",
      "epoch 44; iter: 200; batch classifier loss: 0.343722; batch adversarial loss: 0.328270\n",
      "epoch 45; iter: 0; batch classifier loss: 0.348185; batch adversarial loss: 0.405221\n",
      "epoch 45; iter: 200; batch classifier loss: 0.274419; batch adversarial loss: 0.371575\n",
      "epoch 46; iter: 0; batch classifier loss: 0.225298; batch adversarial loss: 0.450920\n",
      "epoch 46; iter: 200; batch classifier loss: 0.398950; batch adversarial loss: 0.311066\n",
      "epoch 47; iter: 0; batch classifier loss: 0.326760; batch adversarial loss: 0.291444\n",
      "epoch 47; iter: 200; batch classifier loss: 0.428138; batch adversarial loss: 0.359729\n",
      "epoch 48; iter: 0; batch classifier loss: 0.472265; batch adversarial loss: 0.360481\n",
      "epoch 48; iter: 200; batch classifier loss: 0.296437; batch adversarial loss: 0.458399\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401142; batch adversarial loss: 0.429349\n",
      "epoch 49; iter: 200; batch classifier loss: 0.353234; batch adversarial loss: 0.389622\n",
      "epoch 0; iter: 0; batch classifier loss: 3.471185; batch adversarial loss: 0.525175\n",
      "epoch 0; iter: 200; batch classifier loss: 8.126499; batch adversarial loss: 0.531741\n",
      "epoch 1; iter: 0; batch classifier loss: 12.162294; batch adversarial loss: 0.538036\n",
      "epoch 1; iter: 200; batch classifier loss: 3.816070; batch adversarial loss: 0.511297\n",
      "epoch 2; iter: 0; batch classifier loss: 7.334718; batch adversarial loss: 0.488957\n",
      "epoch 2; iter: 200; batch classifier loss: 7.521632; batch adversarial loss: 0.451478\n",
      "epoch 3; iter: 0; batch classifier loss: 5.562899; batch adversarial loss: 0.484280\n",
      "epoch 3; iter: 200; batch classifier loss: 3.426312; batch adversarial loss: 0.446565\n",
      "epoch 4; iter: 0; batch classifier loss: 7.229003; batch adversarial loss: 0.392334\n",
      "epoch 4; iter: 200; batch classifier loss: 1.569863; batch adversarial loss: 0.442783\n",
      "epoch 5; iter: 0; batch classifier loss: 9.329781; batch adversarial loss: 0.528518\n",
      "epoch 5; iter: 200; batch classifier loss: 2.894060; batch adversarial loss: 0.434410\n",
      "epoch 6; iter: 0; batch classifier loss: 1.774145; batch adversarial loss: 0.451802\n",
      "epoch 6; iter: 200; batch classifier loss: 0.995361; batch adversarial loss: 0.436483\n",
      "epoch 7; iter: 0; batch classifier loss: 1.299032; batch adversarial loss: 0.483492\n",
      "epoch 7; iter: 200; batch classifier loss: 0.811196; batch adversarial loss: 0.439517\n",
      "epoch 8; iter: 0; batch classifier loss: 0.854943; batch adversarial loss: 0.493417\n",
      "epoch 8; iter: 200; batch classifier loss: 0.474497; batch adversarial loss: 0.472590\n",
      "epoch 9; iter: 0; batch classifier loss: 0.588443; batch adversarial loss: 0.429982\n",
      "epoch 9; iter: 200; batch classifier loss: 0.523168; batch adversarial loss: 0.381858\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582232; batch adversarial loss: 0.490864\n",
      "epoch 10; iter: 200; batch classifier loss: 0.589208; batch adversarial loss: 0.339956\n",
      "epoch 11; iter: 0; batch classifier loss: 0.613081; batch adversarial loss: 0.406804\n",
      "epoch 11; iter: 200; batch classifier loss: 0.544579; batch adversarial loss: 0.372297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.420672; batch adversarial loss: 0.509453\n",
      "epoch 12; iter: 200; batch classifier loss: 0.513265; batch adversarial loss: 0.345243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.423087; batch adversarial loss: 0.366147\n",
      "epoch 13; iter: 200; batch classifier loss: 0.361402; batch adversarial loss: 0.465919\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367817; batch adversarial loss: 0.423310\n",
      "epoch 14; iter: 200; batch classifier loss: 0.430631; batch adversarial loss: 0.414014\n",
      "epoch 15; iter: 0; batch classifier loss: 0.340164; batch adversarial loss: 0.490531\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366124; batch adversarial loss: 0.416719\n",
      "epoch 16; iter: 0; batch classifier loss: 0.415734; batch adversarial loss: 0.455587\n",
      "epoch 16; iter: 200; batch classifier loss: 0.363566; batch adversarial loss: 0.553464\n",
      "epoch 17; iter: 0; batch classifier loss: 0.315849; batch adversarial loss: 0.443186\n",
      "epoch 17; iter: 200; batch classifier loss: 0.394636; batch adversarial loss: 0.444378\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313655; batch adversarial loss: 0.467424\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326250; batch adversarial loss: 0.413499\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294699; batch adversarial loss: 0.330577\n",
      "epoch 19; iter: 200; batch classifier loss: 0.467081; batch adversarial loss: 0.446688\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304623; batch adversarial loss: 0.446723\n",
      "epoch 20; iter: 200; batch classifier loss: 0.283724; batch adversarial loss: 0.335040\n",
      "epoch 21; iter: 0; batch classifier loss: 0.371326; batch adversarial loss: 0.380580\n",
      "epoch 21; iter: 200; batch classifier loss: 0.333282; batch adversarial loss: 0.323584\n",
      "epoch 22; iter: 0; batch classifier loss: 0.346171; batch adversarial loss: 0.543180\n",
      "epoch 22; iter: 200; batch classifier loss: 0.354858; batch adversarial loss: 0.414595\n",
      "epoch 23; iter: 0; batch classifier loss: 0.316396; batch adversarial loss: 0.434870\n",
      "epoch 23; iter: 200; batch classifier loss: 0.307936; batch adversarial loss: 0.365123\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361833; batch adversarial loss: 0.376011\n",
      "epoch 24; iter: 200; batch classifier loss: 0.286210; batch adversarial loss: 0.431440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.273775; batch adversarial loss: 0.373947\n",
      "epoch 25; iter: 200; batch classifier loss: 0.395514; batch adversarial loss: 0.445677\n",
      "epoch 26; iter: 0; batch classifier loss: 0.382620; batch adversarial loss: 0.456219\n",
      "epoch 26; iter: 200; batch classifier loss: 0.420613; batch adversarial loss: 0.383717\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362945; batch adversarial loss: 0.346053\n",
      "epoch 27; iter: 200; batch classifier loss: 0.361665; batch adversarial loss: 0.383788\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342518; batch adversarial loss: 0.406309\n",
      "epoch 28; iter: 200; batch classifier loss: 0.334259; batch adversarial loss: 0.343354\n",
      "epoch 29; iter: 0; batch classifier loss: 0.331410; batch adversarial loss: 0.390376\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338484; batch adversarial loss: 0.513663\n",
      "epoch 30; iter: 0; batch classifier loss: 0.319978; batch adversarial loss: 0.324898\n",
      "epoch 30; iter: 200; batch classifier loss: 0.335775; batch adversarial loss: 0.402962\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328958; batch adversarial loss: 0.464288\n",
      "epoch 31; iter: 200; batch classifier loss: 0.287895; batch adversarial loss: 0.356575\n",
      "epoch 32; iter: 0; batch classifier loss: 0.287194; batch adversarial loss: 0.394045\n",
      "epoch 32; iter: 200; batch classifier loss: 0.302139; batch adversarial loss: 0.413249\n",
      "epoch 33; iter: 0; batch classifier loss: 0.359885; batch adversarial loss: 0.359869\n",
      "epoch 33; iter: 200; batch classifier loss: 0.314105; batch adversarial loss: 0.435714\n",
      "epoch 34; iter: 0; batch classifier loss: 0.317187; batch adversarial loss: 0.424834\n",
      "epoch 34; iter: 200; batch classifier loss: 0.345756; batch adversarial loss: 0.492469\n",
      "epoch 35; iter: 0; batch classifier loss: 0.367807; batch adversarial loss: 0.312808\n",
      "epoch 35; iter: 200; batch classifier loss: 0.430697; batch adversarial loss: 0.378213\n",
      "epoch 36; iter: 0; batch classifier loss: 0.331439; batch adversarial loss: 0.413318\n",
      "epoch 36; iter: 200; batch classifier loss: 0.286725; batch adversarial loss: 0.394799\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386127; batch adversarial loss: 0.431346\n",
      "epoch 37; iter: 200; batch classifier loss: 0.324162; batch adversarial loss: 0.402899\n",
      "epoch 38; iter: 0; batch classifier loss: 0.301879; batch adversarial loss: 0.418471\n",
      "epoch 38; iter: 200; batch classifier loss: 0.494098; batch adversarial loss: 0.390380\n",
      "epoch 39; iter: 0; batch classifier loss: 0.276479; batch adversarial loss: 0.557323\n",
      "epoch 39; iter: 200; batch classifier loss: 0.428057; batch adversarial loss: 0.331432\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394856; batch adversarial loss: 0.332263\n",
      "epoch 40; iter: 200; batch classifier loss: 0.425022; batch adversarial loss: 0.396826\n",
      "epoch 41; iter: 0; batch classifier loss: 0.340432; batch adversarial loss: 0.385638\n",
      "epoch 41; iter: 200; batch classifier loss: 0.520654; batch adversarial loss: 0.371012\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396401; batch adversarial loss: 0.546767\n",
      "epoch 42; iter: 200; batch classifier loss: 0.448834; batch adversarial loss: 0.320768\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419886; batch adversarial loss: 0.454254\n",
      "epoch 43; iter: 200; batch classifier loss: 0.409711; batch adversarial loss: 0.336488\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463266; batch adversarial loss: 0.360938\n",
      "epoch 44; iter: 200; batch classifier loss: 0.422848; batch adversarial loss: 0.465504\n",
      "epoch 45; iter: 0; batch classifier loss: 0.510894; batch adversarial loss: 0.456384\n",
      "epoch 45; iter: 200; batch classifier loss: 0.415829; batch adversarial loss: 0.366819\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405702; batch adversarial loss: 0.456162\n",
      "epoch 46; iter: 200; batch classifier loss: 0.402839; batch adversarial loss: 0.447256\n",
      "epoch 47; iter: 0; batch classifier loss: 0.537429; batch adversarial loss: 0.378082\n",
      "epoch 47; iter: 200; batch classifier loss: 0.465019; batch adversarial loss: 0.410560\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447701; batch adversarial loss: 0.483177\n",
      "epoch 48; iter: 200; batch classifier loss: 0.383842; batch adversarial loss: 0.436339\n",
      "epoch 49; iter: 0; batch classifier loss: 0.498164; batch adversarial loss: 0.408894\n",
      "epoch 49; iter: 200; batch classifier loss: 0.488130; batch adversarial loss: 0.473545\n",
      "epoch 0; iter: 0; batch classifier loss: 53.782665; batch adversarial loss: 0.605454\n",
      "epoch 0; iter: 200; batch classifier loss: 17.079199; batch adversarial loss: 0.542096\n",
      "epoch 1; iter: 0; batch classifier loss: 15.987015; batch adversarial loss: 0.566736\n",
      "epoch 1; iter: 200; batch classifier loss: 10.213972; batch adversarial loss: 0.545259\n",
      "epoch 2; iter: 0; batch classifier loss: 3.768796; batch adversarial loss: 0.536451\n",
      "epoch 2; iter: 200; batch classifier loss: 3.750030; batch adversarial loss: 0.459577\n",
      "epoch 3; iter: 0; batch classifier loss: 2.163090; batch adversarial loss: 0.471055\n",
      "epoch 3; iter: 200; batch classifier loss: 2.197120; batch adversarial loss: 0.433389\n",
      "epoch 4; iter: 0; batch classifier loss: 1.070547; batch adversarial loss: 0.440346\n",
      "epoch 4; iter: 200; batch classifier loss: 1.461632; batch adversarial loss: 0.417017\n",
      "epoch 5; iter: 0; batch classifier loss: 2.440336; batch adversarial loss: 0.387939\n",
      "epoch 5; iter: 200; batch classifier loss: 0.932352; batch adversarial loss: 0.412817\n",
      "epoch 6; iter: 0; batch classifier loss: 1.067382; batch adversarial loss: 0.394933\n",
      "epoch 6; iter: 200; batch classifier loss: 0.612091; batch adversarial loss: 0.443143\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632735; batch adversarial loss: 0.509437\n",
      "epoch 7; iter: 200; batch classifier loss: 0.557809; batch adversarial loss: 0.462086\n",
      "epoch 8; iter: 0; batch classifier loss: 0.387955; batch adversarial loss: 0.397259\n",
      "epoch 8; iter: 200; batch classifier loss: 0.546628; batch adversarial loss: 0.385923\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479603; batch adversarial loss: 0.378239\n",
      "epoch 9; iter: 200; batch classifier loss: 0.440199; batch adversarial loss: 0.332195\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526962; batch adversarial loss: 0.356413\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420424; batch adversarial loss: 0.380192\n",
      "epoch 11; iter: 0; batch classifier loss: 0.455594; batch adversarial loss: 0.453643\n",
      "epoch 11; iter: 200; batch classifier loss: 0.368939; batch adversarial loss: 0.443513\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404139; batch adversarial loss: 0.461842\n",
      "epoch 12; iter: 200; batch classifier loss: 0.414808; batch adversarial loss: 0.445195\n",
      "epoch 13; iter: 0; batch classifier loss: 0.609155; batch adversarial loss: 0.341173\n",
      "epoch 13; iter: 200; batch classifier loss: 0.567419; batch adversarial loss: 0.257986\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376008; batch adversarial loss: 0.372840\n",
      "epoch 14; iter: 200; batch classifier loss: 0.603580; batch adversarial loss: 0.436691\n",
      "epoch 15; iter: 0; batch classifier loss: 0.399337; batch adversarial loss: 0.364217\n",
      "epoch 15; iter: 200; batch classifier loss: 0.376321; batch adversarial loss: 0.384846\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330637; batch adversarial loss: 0.318226\n",
      "epoch 16; iter: 200; batch classifier loss: 0.400461; batch adversarial loss: 0.405962\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337643; batch adversarial loss: 0.515970\n",
      "epoch 17; iter: 200; batch classifier loss: 0.326877; batch adversarial loss: 0.414165\n",
      "epoch 18; iter: 0; batch classifier loss: 0.336173; batch adversarial loss: 0.427792\n",
      "epoch 18; iter: 200; batch classifier loss: 0.419650; batch adversarial loss: 0.477984\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352252; batch adversarial loss: 0.435686\n",
      "epoch 19; iter: 200; batch classifier loss: 0.319959; batch adversarial loss: 0.471627\n",
      "epoch 20; iter: 0; batch classifier loss: 0.425727; batch adversarial loss: 0.461497\n",
      "epoch 20; iter: 200; batch classifier loss: 0.383715; batch adversarial loss: 0.481013\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280894; batch adversarial loss: 0.368928\n",
      "epoch 21; iter: 200; batch classifier loss: 0.341901; batch adversarial loss: 0.366592\n",
      "epoch 22; iter: 0; batch classifier loss: 0.337593; batch adversarial loss: 0.411270\n",
      "epoch 22; iter: 200; batch classifier loss: 0.386642; batch adversarial loss: 0.320626\n",
      "epoch 23; iter: 0; batch classifier loss: 0.287431; batch adversarial loss: 0.404421\n",
      "epoch 23; iter: 200; batch classifier loss: 0.471635; batch adversarial loss: 0.369581\n",
      "epoch 24; iter: 0; batch classifier loss: 0.279400; batch adversarial loss: 0.435163\n",
      "epoch 24; iter: 200; batch classifier loss: 0.309913; batch adversarial loss: 0.377908\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428129; batch adversarial loss: 0.393747\n",
      "epoch 25; iter: 200; batch classifier loss: 0.307404; batch adversarial loss: 0.405587\n",
      "epoch 26; iter: 0; batch classifier loss: 0.332423; batch adversarial loss: 0.441618\n",
      "epoch 26; iter: 200; batch classifier loss: 0.327593; batch adversarial loss: 0.405405\n",
      "epoch 27; iter: 0; batch classifier loss: 0.251906; batch adversarial loss: 0.445324\n",
      "epoch 27; iter: 200; batch classifier loss: 0.245479; batch adversarial loss: 0.471841\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315636; batch adversarial loss: 0.427818\n",
      "epoch 28; iter: 200; batch classifier loss: 0.375682; batch adversarial loss: 0.420285\n",
      "epoch 29; iter: 0; batch classifier loss: 0.356317; batch adversarial loss: 0.370969\n",
      "epoch 29; iter: 200; batch classifier loss: 0.391142; batch adversarial loss: 0.442816\n",
      "epoch 30; iter: 0; batch classifier loss: 0.339401; batch adversarial loss: 0.486550\n",
      "epoch 30; iter: 200; batch classifier loss: 0.299483; batch adversarial loss: 0.482318\n",
      "epoch 31; iter: 0; batch classifier loss: 0.323128; batch adversarial loss: 0.398044\n",
      "epoch 31; iter: 200; batch classifier loss: 0.374403; batch adversarial loss: 0.433056\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299970; batch adversarial loss: 0.424933\n",
      "epoch 32; iter: 200; batch classifier loss: 0.382387; batch adversarial loss: 0.447561\n",
      "epoch 33; iter: 0; batch classifier loss: 0.279507; batch adversarial loss: 0.418759\n",
      "epoch 33; iter: 200; batch classifier loss: 0.321384; batch adversarial loss: 0.466940\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331502; batch adversarial loss: 0.383482\n",
      "epoch 34; iter: 200; batch classifier loss: 0.400847; batch adversarial loss: 0.374577\n",
      "epoch 35; iter: 0; batch classifier loss: 0.368989; batch adversarial loss: 0.389983\n",
      "epoch 35; iter: 200; batch classifier loss: 0.321136; batch adversarial loss: 0.348285\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353959; batch adversarial loss: 0.432710\n",
      "epoch 36; iter: 200; batch classifier loss: 0.310064; batch adversarial loss: 0.432983\n",
      "epoch 37; iter: 0; batch classifier loss: 0.270069; batch adversarial loss: 0.315377\n",
      "epoch 37; iter: 200; batch classifier loss: 0.309892; batch adversarial loss: 0.401612\n",
      "epoch 38; iter: 0; batch classifier loss: 0.259067; batch adversarial loss: 0.383151\n",
      "epoch 38; iter: 200; batch classifier loss: 0.332616; batch adversarial loss: 0.421417\n",
      "epoch 39; iter: 0; batch classifier loss: 0.287033; batch adversarial loss: 0.470537\n",
      "epoch 39; iter: 200; batch classifier loss: 0.328370; batch adversarial loss: 0.464386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.214335; batch adversarial loss: 0.517293\n",
      "epoch 40; iter: 200; batch classifier loss: 0.316548; batch adversarial loss: 0.447005\n",
      "epoch 41; iter: 0; batch classifier loss: 0.339271; batch adversarial loss: 0.388888\n",
      "epoch 41; iter: 200; batch classifier loss: 0.368436; batch adversarial loss: 0.370854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.311885; batch adversarial loss: 0.424795\n",
      "epoch 42; iter: 200; batch classifier loss: 0.234000; batch adversarial loss: 0.390702\n",
      "epoch 43; iter: 0; batch classifier loss: 0.307983; batch adversarial loss: 0.444523\n",
      "epoch 43; iter: 200; batch classifier loss: 0.375229; batch adversarial loss: 0.401833\n",
      "epoch 44; iter: 0; batch classifier loss: 0.377491; batch adversarial loss: 0.356080\n",
      "epoch 44; iter: 200; batch classifier loss: 0.323523; batch adversarial loss: 0.415680\n",
      "epoch 45; iter: 0; batch classifier loss: 0.381270; batch adversarial loss: 0.491370\n",
      "epoch 45; iter: 200; batch classifier loss: 0.438387; batch adversarial loss: 0.342416\n",
      "epoch 46; iter: 0; batch classifier loss: 0.310601; batch adversarial loss: 0.473103\n",
      "epoch 46; iter: 200; batch classifier loss: 0.349460; batch adversarial loss: 0.362612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.344736; batch adversarial loss: 0.406047\n",
      "epoch 47; iter: 200; batch classifier loss: 0.404964; batch adversarial loss: 0.403701\n",
      "epoch 48; iter: 0; batch classifier loss: 0.337212; batch adversarial loss: 0.450111\n",
      "epoch 48; iter: 200; batch classifier loss: 0.340102; batch adversarial loss: 0.439876\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366474; batch adversarial loss: 0.353736\n",
      "epoch 49; iter: 200; batch classifier loss: 0.367866; batch adversarial loss: 0.457150\n",
      "epoch 0; iter: 0; batch classifier loss: 330.611389; batch adversarial loss: 0.695401\n",
      "epoch 0; iter: 200; batch classifier loss: 8.985958; batch adversarial loss: 0.611021\n",
      "epoch 1; iter: 0; batch classifier loss: 2.517064; batch adversarial loss: 0.589178\n",
      "epoch 1; iter: 200; batch classifier loss: 1.760690; batch adversarial loss: 0.568637\n",
      "epoch 2; iter: 0; batch classifier loss: 8.256386; batch adversarial loss: 0.513919\n",
      "epoch 2; iter: 200; batch classifier loss: 0.817377; batch adversarial loss: 0.501695\n",
      "epoch 3; iter: 0; batch classifier loss: 8.373700; batch adversarial loss: 0.480355\n",
      "epoch 3; iter: 200; batch classifier loss: 2.397083; batch adversarial loss: 0.419399\n",
      "epoch 4; iter: 0; batch classifier loss: 1.725461; batch adversarial loss: 0.478833\n",
      "epoch 4; iter: 200; batch classifier loss: 2.199470; batch adversarial loss: 0.422827\n",
      "epoch 5; iter: 0; batch classifier loss: 0.966703; batch adversarial loss: 0.493601\n",
      "epoch 5; iter: 200; batch classifier loss: 0.965940; batch adversarial loss: 0.419498\n",
      "epoch 6; iter: 0; batch classifier loss: 1.961205; batch adversarial loss: 0.430831\n",
      "epoch 6; iter: 200; batch classifier loss: 0.782122; batch adversarial loss: 0.395593\n",
      "epoch 7; iter: 0; batch classifier loss: 0.967180; batch adversarial loss: 0.366936\n",
      "epoch 7; iter: 200; batch classifier loss: 0.643298; batch adversarial loss: 0.427511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.617178; batch adversarial loss: 0.404373\n",
      "epoch 8; iter: 200; batch classifier loss: 0.397933; batch adversarial loss: 0.383590\n",
      "epoch 9; iter: 0; batch classifier loss: 0.652018; batch adversarial loss: 0.401446\n",
      "epoch 9; iter: 200; batch classifier loss: 0.407695; batch adversarial loss: 0.440280\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369091; batch adversarial loss: 0.345408\n",
      "epoch 10; iter: 200; batch classifier loss: 0.624895; batch adversarial loss: 0.422028\n",
      "epoch 11; iter: 0; batch classifier loss: 0.408471; batch adversarial loss: 0.451815\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449804; batch adversarial loss: 0.486711\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382180; batch adversarial loss: 0.498952\n",
      "epoch 12; iter: 200; batch classifier loss: 0.694324; batch adversarial loss: 0.417356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.296292; batch adversarial loss: 0.453643\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326626; batch adversarial loss: 0.337737\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412241; batch adversarial loss: 0.422365\n",
      "epoch 14; iter: 200; batch classifier loss: 0.331554; batch adversarial loss: 0.329439\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458620; batch adversarial loss: 0.482583\n",
      "epoch 15; iter: 200; batch classifier loss: 0.405287; batch adversarial loss: 0.405110\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371065; batch adversarial loss: 0.425958\n",
      "epoch 16; iter: 200; batch classifier loss: 0.413175; batch adversarial loss: 0.518344\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336443; batch adversarial loss: 0.346071\n",
      "epoch 17; iter: 200; batch classifier loss: 0.311076; batch adversarial loss: 0.412421\n",
      "epoch 18; iter: 0; batch classifier loss: 0.376082; batch adversarial loss: 0.488175\n",
      "epoch 18; iter: 200; batch classifier loss: 0.342475; batch adversarial loss: 0.445225\n",
      "epoch 19; iter: 0; batch classifier loss: 0.388726; batch adversarial loss: 0.345349\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342758; batch adversarial loss: 0.412221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304535; batch adversarial loss: 0.360228\n",
      "epoch 20; iter: 200; batch classifier loss: 0.325712; batch adversarial loss: 0.411912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312298; batch adversarial loss: 0.408642\n",
      "epoch 21; iter: 200; batch classifier loss: 0.301315; batch adversarial loss: 0.438906\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441022; batch adversarial loss: 0.360018\n",
      "epoch 22; iter: 200; batch classifier loss: 0.389418; batch adversarial loss: 0.527738\n",
      "epoch 23; iter: 0; batch classifier loss: 0.363259; batch adversarial loss: 0.495984\n",
      "epoch 23; iter: 200; batch classifier loss: 0.350420; batch adversarial loss: 0.362648\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343633; batch adversarial loss: 0.367686\n",
      "epoch 24; iter: 200; batch classifier loss: 0.284955; batch adversarial loss: 0.526324\n",
      "epoch 25; iter: 0; batch classifier loss: 0.404010; batch adversarial loss: 0.438658\n",
      "epoch 25; iter: 200; batch classifier loss: 0.308458; batch adversarial loss: 0.405981\n",
      "epoch 26; iter: 0; batch classifier loss: 0.361492; batch adversarial loss: 0.520573\n",
      "epoch 26; iter: 200; batch classifier loss: 0.320364; batch adversarial loss: 0.355950\n",
      "epoch 27; iter: 0; batch classifier loss: 0.324529; batch adversarial loss: 0.419038\n",
      "epoch 27; iter: 200; batch classifier loss: 0.388407; batch adversarial loss: 0.394200\n",
      "epoch 28; iter: 0; batch classifier loss: 0.370491; batch adversarial loss: 0.356606\n",
      "epoch 28; iter: 200; batch classifier loss: 0.407812; batch adversarial loss: 0.437492\n",
      "epoch 29; iter: 0; batch classifier loss: 0.335140; batch adversarial loss: 0.414603\n",
      "epoch 29; iter: 200; batch classifier loss: 0.379247; batch adversarial loss: 0.419509\n",
      "epoch 30; iter: 0; batch classifier loss: 0.340786; batch adversarial loss: 0.437966\n",
      "epoch 30; iter: 200; batch classifier loss: 0.412097; batch adversarial loss: 0.460867\n",
      "epoch 31; iter: 0; batch classifier loss: 0.381719; batch adversarial loss: 0.414062\n",
      "epoch 31; iter: 200; batch classifier loss: 0.251430; batch adversarial loss: 0.318996\n",
      "epoch 32; iter: 0; batch classifier loss: 0.363345; batch adversarial loss: 0.368614\n",
      "epoch 32; iter: 200; batch classifier loss: 0.463171; batch adversarial loss: 0.498911\n",
      "epoch 33; iter: 0; batch classifier loss: 0.273144; batch adversarial loss: 0.496087\n",
      "epoch 33; iter: 200; batch classifier loss: 0.357608; batch adversarial loss: 0.534476\n",
      "epoch 34; iter: 0; batch classifier loss: 0.237884; batch adversarial loss: 0.394306\n",
      "epoch 34; iter: 200; batch classifier loss: 0.284041; batch adversarial loss: 0.431009\n",
      "epoch 35; iter: 0; batch classifier loss: 0.305955; batch adversarial loss: 0.358360\n",
      "epoch 35; iter: 200; batch classifier loss: 0.337943; batch adversarial loss: 0.430754\n",
      "epoch 36; iter: 0; batch classifier loss: 0.370026; batch adversarial loss: 0.369820\n",
      "epoch 36; iter: 200; batch classifier loss: 0.292419; batch adversarial loss: 0.442630\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271120; batch adversarial loss: 0.379043\n",
      "epoch 37; iter: 200; batch classifier loss: 0.366091; batch adversarial loss: 0.425293\n",
      "epoch 38; iter: 0; batch classifier loss: 0.355987; batch adversarial loss: 0.483626\n",
      "epoch 38; iter: 200; batch classifier loss: 0.366051; batch adversarial loss: 0.420555\n",
      "epoch 39; iter: 0; batch classifier loss: 0.343828; batch adversarial loss: 0.381313\n",
      "epoch 39; iter: 200; batch classifier loss: 0.330586; batch adversarial loss: 0.297493\n",
      "epoch 40; iter: 0; batch classifier loss: 0.324223; batch adversarial loss: 0.452513\n",
      "epoch 40; iter: 200; batch classifier loss: 0.339970; batch adversarial loss: 0.528290\n",
      "epoch 41; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.361483\n",
      "epoch 41; iter: 200; batch classifier loss: 0.347055; batch adversarial loss: 0.444600\n",
      "epoch 42; iter: 0; batch classifier loss: 0.322669; batch adversarial loss: 0.329216\n",
      "epoch 42; iter: 200; batch classifier loss: 0.413366; batch adversarial loss: 0.360527\n",
      "epoch 43; iter: 0; batch classifier loss: 0.360003; batch adversarial loss: 0.346802\n",
      "epoch 43; iter: 200; batch classifier loss: 0.320061; batch adversarial loss: 0.472519\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401638; batch adversarial loss: 0.376346\n",
      "epoch 44; iter: 200; batch classifier loss: 0.251999; batch adversarial loss: 0.316381\n",
      "epoch 45; iter: 0; batch classifier loss: 0.324735; batch adversarial loss: 0.448973\n",
      "epoch 45; iter: 200; batch classifier loss: 0.298300; batch adversarial loss: 0.401903\n",
      "epoch 46; iter: 0; batch classifier loss: 0.262015; batch adversarial loss: 0.322786\n",
      "epoch 46; iter: 200; batch classifier loss: 0.387399; batch adversarial loss: 0.419150\n",
      "epoch 47; iter: 0; batch classifier loss: 0.346892; batch adversarial loss: 0.374721\n",
      "epoch 47; iter: 200; batch classifier loss: 0.314309; batch adversarial loss: 0.427966\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425105; batch adversarial loss: 0.330444\n",
      "epoch 48; iter: 200; batch classifier loss: 0.351354; batch adversarial loss: 0.438538\n",
      "epoch 49; iter: 0; batch classifier loss: 0.346224; batch adversarial loss: 0.376511\n",
      "epoch 49; iter: 200; batch classifier loss: 0.374418; batch adversarial loss: 0.276267\n",
      "epoch 0; iter: 0; batch classifier loss: 9.703810; batch adversarial loss: 0.961036\n",
      "epoch 0; iter: 200; batch classifier loss: 13.154762; batch adversarial loss: 0.867461\n",
      "epoch 1; iter: 0; batch classifier loss: 14.333836; batch adversarial loss: 0.796191\n",
      "epoch 1; iter: 200; batch classifier loss: 7.277426; batch adversarial loss: 0.639806\n",
      "epoch 2; iter: 0; batch classifier loss: 8.873091; batch adversarial loss: 0.540857\n",
      "epoch 2; iter: 200; batch classifier loss: 8.230305; batch adversarial loss: 0.524645\n",
      "epoch 3; iter: 0; batch classifier loss: 3.587981; batch adversarial loss: 0.473764\n",
      "epoch 3; iter: 200; batch classifier loss: 3.354721; batch adversarial loss: 0.473027\n",
      "epoch 4; iter: 0; batch classifier loss: 2.671104; batch adversarial loss: 0.464860\n",
      "epoch 4; iter: 200; batch classifier loss: 2.246291; batch adversarial loss: 0.505523\n",
      "epoch 5; iter: 0; batch classifier loss: 2.167053; batch adversarial loss: 0.431579\n",
      "epoch 5; iter: 200; batch classifier loss: 1.903794; batch adversarial loss: 0.504970\n",
      "epoch 6; iter: 0; batch classifier loss: 1.197487; batch adversarial loss: 0.418240\n",
      "epoch 6; iter: 200; batch classifier loss: 1.009097; batch adversarial loss: 0.461898\n",
      "epoch 7; iter: 0; batch classifier loss: 0.848181; batch adversarial loss: 0.394929\n",
      "epoch 7; iter: 200; batch classifier loss: 0.638708; batch adversarial loss: 0.476995\n",
      "epoch 8; iter: 0; batch classifier loss: 0.764550; batch adversarial loss: 0.456316\n",
      "epoch 8; iter: 200; batch classifier loss: 0.722815; batch adversarial loss: 0.508607\n",
      "epoch 9; iter: 0; batch classifier loss: 1.354330; batch adversarial loss: 0.420766\n",
      "epoch 9; iter: 200; batch classifier loss: 0.571490; batch adversarial loss: 0.425105\n",
      "epoch 10; iter: 0; batch classifier loss: 0.604518; batch adversarial loss: 0.389107\n",
      "epoch 10; iter: 200; batch classifier loss: 0.613127; batch adversarial loss: 0.423274\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580044; batch adversarial loss: 0.387991\n",
      "epoch 11; iter: 200; batch classifier loss: 0.524447; batch adversarial loss: 0.488396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407021; batch adversarial loss: 0.319605\n",
      "epoch 12; iter: 200; batch classifier loss: 0.417735; batch adversarial loss: 0.473447\n",
      "epoch 13; iter: 0; batch classifier loss: 0.447356; batch adversarial loss: 0.379144\n",
      "epoch 13; iter: 200; batch classifier loss: 0.398501; batch adversarial loss: 0.333835\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560290; batch adversarial loss: 0.386616\n",
      "epoch 14; iter: 200; batch classifier loss: 0.437136; batch adversarial loss: 0.318520\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370955; batch adversarial loss: 0.384306\n",
      "epoch 15; iter: 200; batch classifier loss: 0.371692; batch adversarial loss: 0.353031\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370276; batch adversarial loss: 0.386419\n",
      "epoch 16; iter: 200; batch classifier loss: 0.525069; batch adversarial loss: 0.364848\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338033; batch adversarial loss: 0.420035\n",
      "epoch 17; iter: 200; batch classifier loss: 0.342889; batch adversarial loss: 0.418112\n",
      "epoch 18; iter: 0; batch classifier loss: 0.423698; batch adversarial loss: 0.489666\n",
      "epoch 18; iter: 200; batch classifier loss: 0.361423; batch adversarial loss: 0.453619\n",
      "epoch 19; iter: 0; batch classifier loss: 0.493453; batch adversarial loss: 0.464943\n",
      "epoch 19; iter: 200; batch classifier loss: 0.368910; batch adversarial loss: 0.386457\n",
      "epoch 20; iter: 0; batch classifier loss: 0.407332; batch adversarial loss: 0.471409\n",
      "epoch 20; iter: 200; batch classifier loss: 0.351911; batch adversarial loss: 0.445218\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352282; batch adversarial loss: 0.512045\n",
      "epoch 21; iter: 200; batch classifier loss: 0.325351; batch adversarial loss: 0.468835\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250504; batch adversarial loss: 0.399597\n",
      "epoch 22; iter: 200; batch classifier loss: 0.459829; batch adversarial loss: 0.313166\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279988; batch adversarial loss: 0.404035\n",
      "epoch 23; iter: 200; batch classifier loss: 0.381221; batch adversarial loss: 0.317167\n",
      "epoch 24; iter: 0; batch classifier loss: 0.275037; batch adversarial loss: 0.372892\n",
      "epoch 24; iter: 200; batch classifier loss: 0.373456; batch adversarial loss: 0.350923\n",
      "epoch 25; iter: 0; batch classifier loss: 0.378352; batch adversarial loss: 0.341261\n",
      "epoch 25; iter: 200; batch classifier loss: 0.281179; batch adversarial loss: 0.386005\n",
      "epoch 26; iter: 0; batch classifier loss: 0.370181; batch adversarial loss: 0.347671\n",
      "epoch 26; iter: 200; batch classifier loss: 0.341105; batch adversarial loss: 0.350468\n",
      "epoch 27; iter: 0; batch classifier loss: 0.289078; batch adversarial loss: 0.514169\n",
      "epoch 27; iter: 200; batch classifier loss: 0.339672; batch adversarial loss: 0.462576\n",
      "epoch 28; iter: 0; batch classifier loss: 0.319319; batch adversarial loss: 0.352383\n",
      "epoch 28; iter: 200; batch classifier loss: 0.411026; batch adversarial loss: 0.404379\n",
      "epoch 29; iter: 0; batch classifier loss: 0.359024; batch adversarial loss: 0.412609\n",
      "epoch 29; iter: 200; batch classifier loss: 0.336697; batch adversarial loss: 0.419897\n",
      "epoch 30; iter: 0; batch classifier loss: 0.362083; batch adversarial loss: 0.403350\n",
      "epoch 30; iter: 200; batch classifier loss: 0.276647; batch adversarial loss: 0.459188\n",
      "epoch 31; iter: 0; batch classifier loss: 0.273422; batch adversarial loss: 0.356040\n",
      "epoch 31; iter: 200; batch classifier loss: 0.390377; batch adversarial loss: 0.503367\n",
      "epoch 32; iter: 0; batch classifier loss: 0.390834; batch adversarial loss: 0.348491\n",
      "epoch 32; iter: 200; batch classifier loss: 0.386841; batch adversarial loss: 0.328503\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401004; batch adversarial loss: 0.529566\n",
      "epoch 33; iter: 200; batch classifier loss: 0.360169; batch adversarial loss: 0.330938\n",
      "epoch 34; iter: 0; batch classifier loss: 0.339227; batch adversarial loss: 0.518335\n",
      "epoch 34; iter: 200; batch classifier loss: 0.290411; batch adversarial loss: 0.480021\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395582; batch adversarial loss: 0.543547\n",
      "epoch 35; iter: 200; batch classifier loss: 0.323448; batch adversarial loss: 0.450804\n",
      "epoch 36; iter: 0; batch classifier loss: 0.345024; batch adversarial loss: 0.397001\n",
      "epoch 36; iter: 200; batch classifier loss: 0.334922; batch adversarial loss: 0.495404\n",
      "epoch 37; iter: 0; batch classifier loss: 0.341987; batch adversarial loss: 0.373813\n",
      "epoch 37; iter: 200; batch classifier loss: 0.308019; batch adversarial loss: 0.450974\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286247; batch adversarial loss: 0.372638\n",
      "epoch 38; iter: 200; batch classifier loss: 0.392530; batch adversarial loss: 0.450241\n",
      "epoch 39; iter: 0; batch classifier loss: 0.327606; batch adversarial loss: 0.348499\n",
      "epoch 39; iter: 200; batch classifier loss: 0.399013; batch adversarial loss: 0.425163\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466410; batch adversarial loss: 0.395021\n",
      "epoch 40; iter: 200; batch classifier loss: 0.356366; batch adversarial loss: 0.383712\n",
      "epoch 41; iter: 0; batch classifier loss: 0.368694; batch adversarial loss: 0.473500\n",
      "epoch 41; iter: 200; batch classifier loss: 0.371227; batch adversarial loss: 0.455036\n",
      "epoch 42; iter: 0; batch classifier loss: 0.362111; batch adversarial loss: 0.353555\n",
      "epoch 42; iter: 200; batch classifier loss: 0.470281; batch adversarial loss: 0.500019\n",
      "epoch 43; iter: 0; batch classifier loss: 0.512974; batch adversarial loss: 0.413422\n",
      "epoch 43; iter: 200; batch classifier loss: 0.519673; batch adversarial loss: 0.370851\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516512; batch adversarial loss: 0.428039\n",
      "epoch 44; iter: 200; batch classifier loss: 0.482589; batch adversarial loss: 0.466697\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436082; batch adversarial loss: 0.402503\n",
      "epoch 45; iter: 200; batch classifier loss: 0.359751; batch adversarial loss: 0.380735\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468149; batch adversarial loss: 0.390203\n",
      "epoch 46; iter: 200; batch classifier loss: 0.448369; batch adversarial loss: 0.396526\n",
      "epoch 47; iter: 0; batch classifier loss: 0.536234; batch adversarial loss: 0.429028\n",
      "epoch 47; iter: 200; batch classifier loss: 0.430210; batch adversarial loss: 0.359441\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366576; batch adversarial loss: 0.372530\n",
      "epoch 48; iter: 200; batch classifier loss: 0.427524; batch adversarial loss: 0.411051\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466950; batch adversarial loss: 0.450208\n",
      "epoch 49; iter: 200; batch classifier loss: 0.474238; batch adversarial loss: 0.411519\n",
      "epoch 0; iter: 0; batch classifier loss: 37.708981; batch adversarial loss: 0.797570\n",
      "epoch 0; iter: 200; batch classifier loss: 6.314992; batch adversarial loss: 0.687806\n",
      "epoch 1; iter: 0; batch classifier loss: 9.861368; batch adversarial loss: 0.637530\n",
      "epoch 1; iter: 200; batch classifier loss: 7.273182; batch adversarial loss: 0.583612\n",
      "epoch 2; iter: 0; batch classifier loss: 5.400673; batch adversarial loss: 0.532075\n",
      "epoch 2; iter: 200; batch classifier loss: 2.197357; batch adversarial loss: 0.495585\n",
      "epoch 3; iter: 0; batch classifier loss: 7.606759; batch adversarial loss: 0.535544\n",
      "epoch 3; iter: 200; batch classifier loss: 1.600451; batch adversarial loss: 0.441484\n",
      "epoch 4; iter: 0; batch classifier loss: 4.431704; batch adversarial loss: 0.528374\n",
      "epoch 4; iter: 200; batch classifier loss: 2.648665; batch adversarial loss: 0.541643\n",
      "epoch 5; iter: 0; batch classifier loss: 1.506197; batch adversarial loss: 0.374019\n",
      "epoch 5; iter: 200; batch classifier loss: 0.422285; batch adversarial loss: 0.454806\n",
      "epoch 6; iter: 0; batch classifier loss: 1.237553; batch adversarial loss: 0.431377\n",
      "epoch 6; iter: 200; batch classifier loss: 0.687126; batch adversarial loss: 0.490694\n",
      "epoch 7; iter: 0; batch classifier loss: 0.774237; batch adversarial loss: 0.390618\n",
      "epoch 7; iter: 200; batch classifier loss: 1.087755; batch adversarial loss: 0.442887\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513604; batch adversarial loss: 0.400755\n",
      "epoch 8; iter: 200; batch classifier loss: 0.653030; batch adversarial loss: 0.368725\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590572; batch adversarial loss: 0.393693\n",
      "epoch 9; iter: 200; batch classifier loss: 0.576908; batch adversarial loss: 0.369342\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419062; batch adversarial loss: 0.423523\n",
      "epoch 10; iter: 200; batch classifier loss: 0.706199; batch adversarial loss: 0.365543\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574417; batch adversarial loss: 0.391496\n",
      "epoch 11; iter: 200; batch classifier loss: 0.382132; batch adversarial loss: 0.376196\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500944; batch adversarial loss: 0.441477\n",
      "epoch 12; iter: 200; batch classifier loss: 0.473089; batch adversarial loss: 0.387717\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485577; batch adversarial loss: 0.451828\n",
      "epoch 13; iter: 200; batch classifier loss: 0.506368; batch adversarial loss: 0.432597\n",
      "epoch 14; iter: 0; batch classifier loss: 0.332159; batch adversarial loss: 0.376876\n",
      "epoch 14; iter: 200; batch classifier loss: 0.400760; batch adversarial loss: 0.414212\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566885; batch adversarial loss: 0.448587\n",
      "epoch 15; iter: 200; batch classifier loss: 0.388093; batch adversarial loss: 0.334977\n",
      "epoch 16; iter: 0; batch classifier loss: 0.439146; batch adversarial loss: 0.468389\n",
      "epoch 16; iter: 200; batch classifier loss: 0.254831; batch adversarial loss: 0.460136\n",
      "epoch 17; iter: 0; batch classifier loss: 0.342473; batch adversarial loss: 0.390100\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364321; batch adversarial loss: 0.361330\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361216; batch adversarial loss: 0.338441\n",
      "epoch 18; iter: 200; batch classifier loss: 0.375802; batch adversarial loss: 0.298191\n",
      "epoch 19; iter: 0; batch classifier loss: 0.466754; batch adversarial loss: 0.488224\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316320; batch adversarial loss: 0.379204\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368659; batch adversarial loss: 0.403330\n",
      "epoch 20; iter: 200; batch classifier loss: 0.223403; batch adversarial loss: 0.477206\n",
      "epoch 21; iter: 0; batch classifier loss: 0.324785; batch adversarial loss: 0.358215\n",
      "epoch 21; iter: 200; batch classifier loss: 0.406277; batch adversarial loss: 0.423700\n",
      "epoch 22; iter: 0; batch classifier loss: 0.400417; batch adversarial loss: 0.356686\n",
      "epoch 22; iter: 200; batch classifier loss: 0.285709; batch adversarial loss: 0.394610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379400; batch adversarial loss: 0.394699\n",
      "epoch 23; iter: 200; batch classifier loss: 0.350566; batch adversarial loss: 0.417064\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360681; batch adversarial loss: 0.374565\n",
      "epoch 24; iter: 200; batch classifier loss: 0.364639; batch adversarial loss: 0.402463\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344799; batch adversarial loss: 0.463564\n",
      "epoch 25; iter: 200; batch classifier loss: 0.332420; batch adversarial loss: 0.370619\n",
      "epoch 26; iter: 0; batch classifier loss: 0.335009; batch adversarial loss: 0.381026\n",
      "epoch 26; iter: 200; batch classifier loss: 0.366011; batch adversarial loss: 0.423381\n",
      "epoch 27; iter: 0; batch classifier loss: 0.372445; batch adversarial loss: 0.344748\n",
      "epoch 27; iter: 200; batch classifier loss: 0.386708; batch adversarial loss: 0.386947\n",
      "epoch 28; iter: 0; batch classifier loss: 0.330788; batch adversarial loss: 0.446622\n",
      "epoch 28; iter: 200; batch classifier loss: 0.349318; batch adversarial loss: 0.508497\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315324; batch adversarial loss: 0.368141\n",
      "epoch 29; iter: 200; batch classifier loss: 0.315951; batch adversarial loss: 0.368856\n",
      "epoch 30; iter: 0; batch classifier loss: 0.338764; batch adversarial loss: 0.371514\n",
      "epoch 30; iter: 200; batch classifier loss: 0.318926; batch adversarial loss: 0.368711\n",
      "epoch 31; iter: 0; batch classifier loss: 0.306961; batch adversarial loss: 0.345238\n",
      "epoch 31; iter: 200; batch classifier loss: 0.320765; batch adversarial loss: 0.433031\n",
      "epoch 32; iter: 0; batch classifier loss: 0.308639; batch adversarial loss: 0.357903\n",
      "epoch 32; iter: 200; batch classifier loss: 0.408841; batch adversarial loss: 0.374573\n",
      "epoch 33; iter: 0; batch classifier loss: 0.304260; batch adversarial loss: 0.402290\n",
      "epoch 33; iter: 200; batch classifier loss: 0.338668; batch adversarial loss: 0.411480\n",
      "epoch 34; iter: 0; batch classifier loss: 0.317490; batch adversarial loss: 0.441741\n",
      "epoch 34; iter: 200; batch classifier loss: 0.326465; batch adversarial loss: 0.369051\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435354; batch adversarial loss: 0.436881\n",
      "epoch 35; iter: 200; batch classifier loss: 0.362480; batch adversarial loss: 0.472476\n",
      "epoch 36; iter: 0; batch classifier loss: 0.287853; batch adversarial loss: 0.449761\n",
      "epoch 36; iter: 200; batch classifier loss: 0.377030; batch adversarial loss: 0.455932\n",
      "epoch 37; iter: 0; batch classifier loss: 0.328045; batch adversarial loss: 0.390609\n",
      "epoch 37; iter: 200; batch classifier loss: 0.265448; batch adversarial loss: 0.399625\n",
      "epoch 38; iter: 0; batch classifier loss: 0.308021; batch adversarial loss: 0.413488\n",
      "epoch 38; iter: 200; batch classifier loss: 0.325516; batch adversarial loss: 0.475346\n",
      "epoch 39; iter: 0; batch classifier loss: 0.348952; batch adversarial loss: 0.434790\n",
      "epoch 39; iter: 200; batch classifier loss: 0.356551; batch adversarial loss: 0.611925\n",
      "epoch 40; iter: 0; batch classifier loss: 0.356054; batch adversarial loss: 0.416474\n",
      "epoch 40; iter: 200; batch classifier loss: 0.304009; batch adversarial loss: 0.403217\n",
      "epoch 41; iter: 0; batch classifier loss: 0.387881; batch adversarial loss: 0.359014\n",
      "epoch 41; iter: 200; batch classifier loss: 0.237103; batch adversarial loss: 0.437414\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438643; batch adversarial loss: 0.496752\n",
      "epoch 42; iter: 200; batch classifier loss: 0.523306; batch adversarial loss: 0.534274\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459791; batch adversarial loss: 0.454583\n",
      "epoch 43; iter: 200; batch classifier loss: 0.496095; batch adversarial loss: 0.338400\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464458; batch adversarial loss: 0.484361\n",
      "epoch 44; iter: 200; batch classifier loss: 0.378152; batch adversarial loss: 0.377117\n",
      "epoch 45; iter: 0; batch classifier loss: 0.533611; batch adversarial loss: 0.282714\n",
      "epoch 45; iter: 200; batch classifier loss: 0.504452; batch adversarial loss: 0.445793\n",
      "epoch 46; iter: 0; batch classifier loss: 0.524312; batch adversarial loss: 0.406501\n",
      "epoch 46; iter: 200; batch classifier loss: 0.481832; batch adversarial loss: 0.399864\n",
      "epoch 47; iter: 0; batch classifier loss: 0.503191; batch adversarial loss: 0.537426\n",
      "epoch 47; iter: 200; batch classifier loss: 0.528260; batch adversarial loss: 0.349868\n",
      "epoch 48; iter: 0; batch classifier loss: 0.390468; batch adversarial loss: 0.462813\n",
      "epoch 48; iter: 200; batch classifier loss: 0.554444; batch adversarial loss: 0.399376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.597844; batch adversarial loss: 0.466163\n",
      "epoch 49; iter: 200; batch classifier loss: 0.463637; batch adversarial loss: 0.568894\n",
      "epoch 0; iter: 0; batch classifier loss: 6.684295; batch adversarial loss: 0.855773\n",
      "epoch 0; iter: 200; batch classifier loss: 6.800762; batch adversarial loss: 0.707089\n",
      "epoch 1; iter: 0; batch classifier loss: 1.130484; batch adversarial loss: 0.626667\n",
      "epoch 1; iter: 200; batch classifier loss: 2.130701; batch adversarial loss: 0.581278\n",
      "epoch 2; iter: 0; batch classifier loss: 3.148646; batch adversarial loss: 0.577412\n",
      "epoch 2; iter: 200; batch classifier loss: 4.383566; batch adversarial loss: 0.486401\n",
      "epoch 3; iter: 0; batch classifier loss: 5.408153; batch adversarial loss: 0.522958\n",
      "epoch 3; iter: 200; batch classifier loss: 3.771063; batch adversarial loss: 0.473987\n",
      "epoch 4; iter: 0; batch classifier loss: 1.786071; batch adversarial loss: 0.458261\n",
      "epoch 4; iter: 200; batch classifier loss: 1.881412; batch adversarial loss: 0.482110\n",
      "epoch 5; iter: 0; batch classifier loss: 1.741824; batch adversarial loss: 0.450265\n",
      "epoch 5; iter: 200; batch classifier loss: 2.399467; batch adversarial loss: 0.383806\n",
      "epoch 6; iter: 0; batch classifier loss: 1.292410; batch adversarial loss: 0.419900\n",
      "epoch 6; iter: 200; batch classifier loss: 0.726059; batch adversarial loss: 0.358847\n",
      "epoch 7; iter: 0; batch classifier loss: 0.720847; batch adversarial loss: 0.447048\n",
      "epoch 7; iter: 200; batch classifier loss: 0.552590; batch adversarial loss: 0.370001\n",
      "epoch 8; iter: 0; batch classifier loss: 0.423572; batch adversarial loss: 0.355142\n",
      "epoch 8; iter: 200; batch classifier loss: 0.582216; batch adversarial loss: 0.360795\n",
      "epoch 9; iter: 0; batch classifier loss: 0.559695; batch adversarial loss: 0.571938\n",
      "epoch 9; iter: 200; batch classifier loss: 0.430671; batch adversarial loss: 0.318668\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481779; batch adversarial loss: 0.454012\n",
      "epoch 10; iter: 200; batch classifier loss: 0.315399; batch adversarial loss: 0.378779\n",
      "epoch 11; iter: 0; batch classifier loss: 0.411424; batch adversarial loss: 0.421586\n",
      "epoch 11; iter: 200; batch classifier loss: 0.501758; batch adversarial loss: 0.416000\n",
      "epoch 12; iter: 0; batch classifier loss: 0.445319; batch adversarial loss: 0.399264\n",
      "epoch 12; iter: 200; batch classifier loss: 0.401130; batch adversarial loss: 0.430479\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430432; batch adversarial loss: 0.427778\n",
      "epoch 13; iter: 200; batch classifier loss: 0.378882; batch adversarial loss: 0.464805\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396058; batch adversarial loss: 0.402920\n",
      "epoch 14; iter: 200; batch classifier loss: 0.335504; batch adversarial loss: 0.389158\n",
      "epoch 15; iter: 0; batch classifier loss: 0.587234; batch adversarial loss: 0.332228\n",
      "epoch 15; iter: 200; batch classifier loss: 0.431642; batch adversarial loss: 0.438429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337249; batch adversarial loss: 0.429294\n",
      "epoch 16; iter: 200; batch classifier loss: 0.375088; batch adversarial loss: 0.359970\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328023; batch adversarial loss: 0.409533\n",
      "epoch 17; iter: 200; batch classifier loss: 0.365751; batch adversarial loss: 0.444890\n",
      "epoch 18; iter: 0; batch classifier loss: 0.390076; batch adversarial loss: 0.414879\n",
      "epoch 18; iter: 200; batch classifier loss: 0.344251; batch adversarial loss: 0.420188\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344459; batch adversarial loss: 0.322413\n",
      "epoch 19; iter: 200; batch classifier loss: 0.267259; batch adversarial loss: 0.421839\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299371; batch adversarial loss: 0.416967\n",
      "epoch 20; iter: 200; batch classifier loss: 0.390170; batch adversarial loss: 0.450578\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424480; batch adversarial loss: 0.323052\n",
      "epoch 21; iter: 200; batch classifier loss: 0.349854; batch adversarial loss: 0.399775\n",
      "epoch 22; iter: 0; batch classifier loss: 0.371691; batch adversarial loss: 0.371951\n",
      "epoch 22; iter: 200; batch classifier loss: 0.372788; batch adversarial loss: 0.449961\n",
      "epoch 23; iter: 0; batch classifier loss: 0.382242; batch adversarial loss: 0.521277\n",
      "epoch 23; iter: 200; batch classifier loss: 0.258564; batch adversarial loss: 0.437058\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362973; batch adversarial loss: 0.373356\n",
      "epoch 24; iter: 200; batch classifier loss: 0.272167; batch adversarial loss: 0.415779\n",
      "epoch 25; iter: 0; batch classifier loss: 0.257086; batch adversarial loss: 0.396232\n",
      "epoch 25; iter: 200; batch classifier loss: 0.327484; batch adversarial loss: 0.369757\n",
      "epoch 26; iter: 0; batch classifier loss: 0.376992; batch adversarial loss: 0.421713\n",
      "epoch 26; iter: 200; batch classifier loss: 0.382221; batch adversarial loss: 0.403838\n",
      "epoch 27; iter: 0; batch classifier loss: 0.239871; batch adversarial loss: 0.320237\n",
      "epoch 27; iter: 200; batch classifier loss: 0.407888; batch adversarial loss: 0.367201\n",
      "epoch 28; iter: 0; batch classifier loss: 0.333106; batch adversarial loss: 0.446951\n",
      "epoch 28; iter: 200; batch classifier loss: 0.364289; batch adversarial loss: 0.491484\n",
      "epoch 29; iter: 0; batch classifier loss: 0.328991; batch adversarial loss: 0.422640\n",
      "epoch 29; iter: 200; batch classifier loss: 0.415983; batch adversarial loss: 0.423113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450726; batch adversarial loss: 0.479347\n",
      "epoch 30; iter: 200; batch classifier loss: 0.332686; batch adversarial loss: 0.359455\n",
      "epoch 31; iter: 0; batch classifier loss: 0.373247; batch adversarial loss: 0.377940\n",
      "epoch 31; iter: 200; batch classifier loss: 0.378524; batch adversarial loss: 0.488381\n",
      "epoch 32; iter: 0; batch classifier loss: 0.243121; batch adversarial loss: 0.431656\n",
      "epoch 32; iter: 200; batch classifier loss: 0.278818; batch adversarial loss: 0.332332\n",
      "epoch 33; iter: 0; batch classifier loss: 0.326842; batch adversarial loss: 0.396966\n",
      "epoch 33; iter: 200; batch classifier loss: 0.286658; batch adversarial loss: 0.426735\n",
      "epoch 34; iter: 0; batch classifier loss: 0.352282; batch adversarial loss: 0.386131\n",
      "epoch 34; iter: 200; batch classifier loss: 0.316413; batch adversarial loss: 0.490695\n",
      "epoch 35; iter: 0; batch classifier loss: 0.227509; batch adversarial loss: 0.435240\n",
      "epoch 35; iter: 200; batch classifier loss: 0.299763; batch adversarial loss: 0.498273\n",
      "epoch 36; iter: 0; batch classifier loss: 0.327085; batch adversarial loss: 0.368758\n",
      "epoch 36; iter: 200; batch classifier loss: 0.374017; batch adversarial loss: 0.377119\n",
      "epoch 37; iter: 0; batch classifier loss: 0.329760; batch adversarial loss: 0.358335\n",
      "epoch 37; iter: 200; batch classifier loss: 0.342558; batch adversarial loss: 0.539730\n",
      "epoch 38; iter: 0; batch classifier loss: 0.376872; batch adversarial loss: 0.400914\n",
      "epoch 38; iter: 200; batch classifier loss: 0.281146; batch adversarial loss: 0.414870\n",
      "epoch 39; iter: 0; batch classifier loss: 0.339021; batch adversarial loss: 0.508816\n",
      "epoch 39; iter: 200; batch classifier loss: 0.302585; batch adversarial loss: 0.406939\n",
      "epoch 40; iter: 0; batch classifier loss: 0.327946; batch adversarial loss: 0.319246\n",
      "epoch 40; iter: 200; batch classifier loss: 0.256876; batch adversarial loss: 0.422006\n",
      "epoch 41; iter: 0; batch classifier loss: 0.315621; batch adversarial loss: 0.400263\n",
      "epoch 41; iter: 200; batch classifier loss: 0.323489; batch adversarial loss: 0.392177\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453891; batch adversarial loss: 0.357003\n",
      "epoch 42; iter: 200; batch classifier loss: 0.355312; batch adversarial loss: 0.394601\n",
      "epoch 43; iter: 0; batch classifier loss: 0.326024; batch adversarial loss: 0.356976\n",
      "epoch 43; iter: 200; batch classifier loss: 0.274158; batch adversarial loss: 0.484565\n",
      "epoch 44; iter: 0; batch classifier loss: 0.304803; batch adversarial loss: 0.425745\n",
      "epoch 44; iter: 200; batch classifier loss: 0.356756; batch adversarial loss: 0.415555\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364778; batch adversarial loss: 0.323288\n",
      "epoch 45; iter: 200; batch classifier loss: 0.331631; batch adversarial loss: 0.384822\n",
      "epoch 46; iter: 0; batch classifier loss: 0.299008; batch adversarial loss: 0.333943\n",
      "epoch 46; iter: 200; batch classifier loss: 0.319998; batch adversarial loss: 0.385694\n",
      "epoch 47; iter: 0; batch classifier loss: 0.332370; batch adversarial loss: 0.417067\n",
      "epoch 47; iter: 200; batch classifier loss: 0.340046; batch adversarial loss: 0.295457\n",
      "epoch 48; iter: 0; batch classifier loss: 0.319111; batch adversarial loss: 0.418673\n",
      "epoch 48; iter: 200; batch classifier loss: 0.253944; batch adversarial loss: 0.386665\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417487; batch adversarial loss: 0.425810\n",
      "epoch 49; iter: 200; batch classifier loss: 0.274445; batch adversarial loss: 0.383625\n",
      "epoch 0; iter: 0; batch classifier loss: 34.548248; batch adversarial loss: 0.637572\n",
      "epoch 0; iter: 200; batch classifier loss: 5.545534; batch adversarial loss: 0.591250\n",
      "epoch 1; iter: 0; batch classifier loss: 2.615148; batch adversarial loss: 0.572290\n",
      "epoch 1; iter: 200; batch classifier loss: 5.933918; batch adversarial loss: 0.568166\n",
      "epoch 2; iter: 0; batch classifier loss: 9.085625; batch adversarial loss: 0.459875\n",
      "epoch 2; iter: 200; batch classifier loss: 5.657192; batch adversarial loss: 0.525558\n",
      "epoch 3; iter: 0; batch classifier loss: 3.410931; batch adversarial loss: 0.540612\n",
      "epoch 3; iter: 200; batch classifier loss: 2.996669; batch adversarial loss: 0.505907\n",
      "epoch 4; iter: 0; batch classifier loss: 2.789467; batch adversarial loss: 0.444193\n",
      "epoch 4; iter: 200; batch classifier loss: 4.462342; batch adversarial loss: 0.385340\n",
      "epoch 5; iter: 0; batch classifier loss: 1.624212; batch adversarial loss: 0.406703\n",
      "epoch 5; iter: 200; batch classifier loss: 1.578802; batch adversarial loss: 0.518352\n",
      "epoch 6; iter: 0; batch classifier loss: 1.043773; batch adversarial loss: 0.470889\n",
      "epoch 6; iter: 200; batch classifier loss: 1.211429; batch adversarial loss: 0.355656\n",
      "epoch 7; iter: 0; batch classifier loss: 0.781052; batch adversarial loss: 0.347532\n",
      "epoch 7; iter: 200; batch classifier loss: 0.750783; batch adversarial loss: 0.395746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.632613; batch adversarial loss: 0.333840\n",
      "epoch 8; iter: 200; batch classifier loss: 0.392522; batch adversarial loss: 0.381326\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496366; batch adversarial loss: 0.427561\n",
      "epoch 9; iter: 200; batch classifier loss: 0.496364; batch adversarial loss: 0.358528\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503181; batch adversarial loss: 0.489708\n",
      "epoch 10; iter: 200; batch classifier loss: 0.400780; batch adversarial loss: 0.543334\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426356; batch adversarial loss: 0.428955\n",
      "epoch 11; iter: 200; batch classifier loss: 0.355623; batch adversarial loss: 0.401717\n",
      "epoch 12; iter: 0; batch classifier loss: 0.442852; batch adversarial loss: 0.431793\n",
      "epoch 12; iter: 200; batch classifier loss: 0.483712; batch adversarial loss: 0.457126\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505337; batch adversarial loss: 0.431765\n",
      "epoch 13; iter: 200; batch classifier loss: 0.395408; batch adversarial loss: 0.499418\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471943; batch adversarial loss: 0.343076\n",
      "epoch 14; iter: 200; batch classifier loss: 0.289601; batch adversarial loss: 0.391759\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348030; batch adversarial loss: 0.364772\n",
      "epoch 15; iter: 200; batch classifier loss: 0.447498; batch adversarial loss: 0.350420\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335844; batch adversarial loss: 0.466229\n",
      "epoch 16; iter: 200; batch classifier loss: 0.391689; batch adversarial loss: 0.304061\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312707; batch adversarial loss: 0.444371\n",
      "epoch 17; iter: 200; batch classifier loss: 0.310479; batch adversarial loss: 0.431658\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371785; batch adversarial loss: 0.471512\n",
      "epoch 18; iter: 200; batch classifier loss: 0.365806; batch adversarial loss: 0.396333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430446; batch adversarial loss: 0.469000\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376574; batch adversarial loss: 0.418438\n",
      "epoch 20; iter: 0; batch classifier loss: 0.380742; batch adversarial loss: 0.376733\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379948; batch adversarial loss: 0.438168\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291256; batch adversarial loss: 0.415015\n",
      "epoch 21; iter: 200; batch classifier loss: 0.349930; batch adversarial loss: 0.474833\n",
      "epoch 22; iter: 0; batch classifier loss: 0.340437; batch adversarial loss: 0.409548\n",
      "epoch 22; iter: 200; batch classifier loss: 0.313961; batch adversarial loss: 0.536552\n",
      "epoch 23; iter: 0; batch classifier loss: 0.252906; batch adversarial loss: 0.388052\n",
      "epoch 23; iter: 200; batch classifier loss: 0.333084; batch adversarial loss: 0.430774\n",
      "epoch 24; iter: 0; batch classifier loss: 0.397331; batch adversarial loss: 0.475364\n",
      "epoch 24; iter: 200; batch classifier loss: 0.323463; batch adversarial loss: 0.342428\n",
      "epoch 25; iter: 0; batch classifier loss: 0.292479; batch adversarial loss: 0.427545\n",
      "epoch 25; iter: 200; batch classifier loss: 0.308545; batch adversarial loss: 0.450205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.371928; batch adversarial loss: 0.336659\n",
      "epoch 26; iter: 200; batch classifier loss: 0.456715; batch adversarial loss: 0.464711\n",
      "epoch 27; iter: 0; batch classifier loss: 0.336323; batch adversarial loss: 0.427682\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310613; batch adversarial loss: 0.395327\n",
      "epoch 28; iter: 0; batch classifier loss: 0.311770; batch adversarial loss: 0.390373\n",
      "epoch 28; iter: 200; batch classifier loss: 0.458510; batch adversarial loss: 0.441751\n",
      "epoch 29; iter: 0; batch classifier loss: 0.307093; batch adversarial loss: 0.454598\n",
      "epoch 29; iter: 200; batch classifier loss: 0.391825; batch adversarial loss: 0.491118\n",
      "epoch 30; iter: 0; batch classifier loss: 0.373597; batch adversarial loss: 0.351213\n",
      "epoch 30; iter: 200; batch classifier loss: 0.340680; batch adversarial loss: 0.395468\n",
      "epoch 31; iter: 0; batch classifier loss: 0.411326; batch adversarial loss: 0.473507\n",
      "epoch 31; iter: 200; batch classifier loss: 0.285791; batch adversarial loss: 0.385172\n",
      "epoch 32; iter: 0; batch classifier loss: 0.315045; batch adversarial loss: 0.372759\n",
      "epoch 32; iter: 200; batch classifier loss: 0.394362; batch adversarial loss: 0.390665\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405038; batch adversarial loss: 0.464241\n",
      "epoch 33; iter: 200; batch classifier loss: 0.369325; batch adversarial loss: 0.319810\n",
      "epoch 34; iter: 0; batch classifier loss: 0.400249; batch adversarial loss: 0.442742\n",
      "epoch 34; iter: 200; batch classifier loss: 0.344214; batch adversarial loss: 0.515966\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452699; batch adversarial loss: 0.453707\n",
      "epoch 35; iter: 200; batch classifier loss: 0.561992; batch adversarial loss: 0.430274\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515954; batch adversarial loss: 0.497354\n",
      "epoch 36; iter: 200; batch classifier loss: 0.372436; batch adversarial loss: 0.422786\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448009; batch adversarial loss: 0.370250\n",
      "epoch 37; iter: 200; batch classifier loss: 0.520196; batch adversarial loss: 0.383615\n",
      "epoch 38; iter: 0; batch classifier loss: 0.532400; batch adversarial loss: 0.396208\n",
      "epoch 38; iter: 200; batch classifier loss: 0.508157; batch adversarial loss: 0.499093\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407301; batch adversarial loss: 0.427905\n",
      "epoch 39; iter: 200; batch classifier loss: 0.505192; batch adversarial loss: 0.425508\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421654; batch adversarial loss: 0.497190\n",
      "epoch 40; iter: 200; batch classifier loss: 0.388106; batch adversarial loss: 0.364278\n",
      "epoch 41; iter: 0; batch classifier loss: 0.322198; batch adversarial loss: 0.397614\n",
      "epoch 41; iter: 200; batch classifier loss: 0.485936; batch adversarial loss: 0.374372\n",
      "epoch 42; iter: 0; batch classifier loss: 0.435482; batch adversarial loss: 0.506567\n",
      "epoch 42; iter: 200; batch classifier loss: 0.486247; batch adversarial loss: 0.468490\n",
      "epoch 43; iter: 0; batch classifier loss: 0.524222; batch adversarial loss: 0.392450\n",
      "epoch 43; iter: 200; batch classifier loss: 0.388526; batch adversarial loss: 0.292776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.379041; batch adversarial loss: 0.467383\n",
      "epoch 44; iter: 200; batch classifier loss: 0.410934; batch adversarial loss: 0.456247\n",
      "epoch 45; iter: 0; batch classifier loss: 0.457423; batch adversarial loss: 0.381652\n",
      "epoch 45; iter: 200; batch classifier loss: 0.634155; batch adversarial loss: 0.395360\n",
      "epoch 46; iter: 0; batch classifier loss: 0.363657; batch adversarial loss: 0.497446\n",
      "epoch 46; iter: 200; batch classifier loss: 0.387840; batch adversarial loss: 0.330401\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471419; batch adversarial loss: 0.379315\n",
      "epoch 47; iter: 200; batch classifier loss: 0.505493; batch adversarial loss: 0.449469\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460126; batch adversarial loss: 0.374991\n",
      "epoch 48; iter: 200; batch classifier loss: 0.403293; batch adversarial loss: 0.490667\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443013; batch adversarial loss: 0.547808\n",
      "epoch 49; iter: 200; batch classifier loss: 0.396785; batch adversarial loss: 0.361702\n",
      "epoch 0; iter: 0; batch classifier loss: 30.851482; batch adversarial loss: 0.669334\n",
      "epoch 0; iter: 200; batch classifier loss: 9.107895; batch adversarial loss: 0.571365\n",
      "epoch 1; iter: 0; batch classifier loss: 3.234214; batch adversarial loss: 0.535039\n",
      "epoch 1; iter: 200; batch classifier loss: 4.522779; batch adversarial loss: 0.490090\n",
      "epoch 2; iter: 0; batch classifier loss: 8.945023; batch adversarial loss: 0.372450\n",
      "epoch 2; iter: 200; batch classifier loss: 4.346598; batch adversarial loss: 0.404030\n",
      "epoch 3; iter: 0; batch classifier loss: 2.953438; batch adversarial loss: 0.430741\n",
      "epoch 3; iter: 200; batch classifier loss: 3.031252; batch adversarial loss: 0.450592\n",
      "epoch 4; iter: 0; batch classifier loss: 2.631448; batch adversarial loss: 0.461927\n",
      "epoch 4; iter: 200; batch classifier loss: 1.465002; batch adversarial loss: 0.474039\n",
      "epoch 5; iter: 0; batch classifier loss: 1.695322; batch adversarial loss: 0.411375\n",
      "epoch 5; iter: 200; batch classifier loss: 0.891661; batch adversarial loss: 0.430548\n",
      "epoch 6; iter: 0; batch classifier loss: 1.163223; batch adversarial loss: 0.439254\n",
      "epoch 6; iter: 200; batch classifier loss: 0.746442; batch adversarial loss: 0.347780\n",
      "epoch 7; iter: 0; batch classifier loss: 0.862729; batch adversarial loss: 0.402852\n",
      "epoch 7; iter: 200; batch classifier loss: 0.596568; batch adversarial loss: 0.472776\n",
      "epoch 8; iter: 0; batch classifier loss: 0.456280; batch adversarial loss: 0.458805\n",
      "epoch 8; iter: 200; batch classifier loss: 0.454437; batch adversarial loss: 0.365417\n",
      "epoch 9; iter: 0; batch classifier loss: 0.459991; batch adversarial loss: 0.436561\n",
      "epoch 9; iter: 200; batch classifier loss: 0.464659; batch adversarial loss: 0.476574\n",
      "epoch 10; iter: 0; batch classifier loss: 0.392079; batch adversarial loss: 0.434223\n",
      "epoch 10; iter: 200; batch classifier loss: 0.438961; batch adversarial loss: 0.445810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.417559; batch adversarial loss: 0.363102\n",
      "epoch 11; iter: 200; batch classifier loss: 0.365374; batch adversarial loss: 0.334943\n",
      "epoch 12; iter: 0; batch classifier loss: 0.400944; batch adversarial loss: 0.495320\n",
      "epoch 12; iter: 200; batch classifier loss: 0.606172; batch adversarial loss: 0.369300\n",
      "epoch 13; iter: 0; batch classifier loss: 0.404222; batch adversarial loss: 0.429151\n",
      "epoch 13; iter: 200; batch classifier loss: 0.237999; batch adversarial loss: 0.464509\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311083; batch adversarial loss: 0.436553\n",
      "epoch 14; iter: 200; batch classifier loss: 0.335132; batch adversarial loss: 0.329458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.418950; batch adversarial loss: 0.465247\n",
      "epoch 15; iter: 200; batch classifier loss: 0.292760; batch adversarial loss: 0.451206\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355413; batch adversarial loss: 0.319715\n",
      "epoch 16; iter: 200; batch classifier loss: 0.277175; batch adversarial loss: 0.394479\n",
      "epoch 17; iter: 0; batch classifier loss: 0.300161; batch adversarial loss: 0.383148\n",
      "epoch 17; iter: 200; batch classifier loss: 0.285236; batch adversarial loss: 0.383609\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317187; batch adversarial loss: 0.319941\n",
      "epoch 18; iter: 200; batch classifier loss: 0.278014; batch adversarial loss: 0.481558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376549; batch adversarial loss: 0.442674\n",
      "epoch 19; iter: 200; batch classifier loss: 0.424927; batch adversarial loss: 0.400908\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325402; batch adversarial loss: 0.383042\n",
      "epoch 20; iter: 200; batch classifier loss: 0.425425; batch adversarial loss: 0.452063\n",
      "epoch 21; iter: 0; batch classifier loss: 0.444242; batch adversarial loss: 0.392450\n",
      "epoch 21; iter: 200; batch classifier loss: 0.400118; batch adversarial loss: 0.362628\n",
      "epoch 22; iter: 0; batch classifier loss: 0.341563; batch adversarial loss: 0.444752\n",
      "epoch 22; iter: 200; batch classifier loss: 0.276240; batch adversarial loss: 0.326957\n",
      "epoch 23; iter: 0; batch classifier loss: 0.349005; batch adversarial loss: 0.380619\n",
      "epoch 23; iter: 200; batch classifier loss: 0.300319; batch adversarial loss: 0.411873\n",
      "epoch 24; iter: 0; batch classifier loss: 0.354668; batch adversarial loss: 0.423712\n",
      "epoch 24; iter: 200; batch classifier loss: 0.265869; batch adversarial loss: 0.419860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.314352; batch adversarial loss: 0.472960\n",
      "epoch 25; iter: 200; batch classifier loss: 0.449819; batch adversarial loss: 0.355042\n",
      "epoch 26; iter: 0; batch classifier loss: 0.388217; batch adversarial loss: 0.448299\n",
      "epoch 26; iter: 200; batch classifier loss: 0.430168; batch adversarial loss: 0.407964\n",
      "epoch 27; iter: 0; batch classifier loss: 0.297897; batch adversarial loss: 0.421422\n",
      "epoch 27; iter: 200; batch classifier loss: 0.335011; batch adversarial loss: 0.448730\n",
      "epoch 28; iter: 0; batch classifier loss: 0.361879; batch adversarial loss: 0.369677\n",
      "epoch 28; iter: 200; batch classifier loss: 0.340796; batch adversarial loss: 0.401225\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247338; batch adversarial loss: 0.321992\n",
      "epoch 29; iter: 200; batch classifier loss: 0.368216; batch adversarial loss: 0.530498\n",
      "epoch 30; iter: 0; batch classifier loss: 0.393807; batch adversarial loss: 0.420983\n",
      "epoch 30; iter: 200; batch classifier loss: 0.336166; batch adversarial loss: 0.378395\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387320; batch adversarial loss: 0.407485\n",
      "epoch 31; iter: 200; batch classifier loss: 0.409687; batch adversarial loss: 0.471257\n",
      "epoch 32; iter: 0; batch classifier loss: 0.321802; batch adversarial loss: 0.384794\n",
      "epoch 32; iter: 200; batch classifier loss: 0.349622; batch adversarial loss: 0.451792\n",
      "epoch 33; iter: 0; batch classifier loss: 0.303751; batch adversarial loss: 0.432149\n",
      "epoch 33; iter: 200; batch classifier loss: 0.346722; batch adversarial loss: 0.475049\n",
      "epoch 34; iter: 0; batch classifier loss: 0.346626; batch adversarial loss: 0.315522\n",
      "epoch 34; iter: 200; batch classifier loss: 0.391820; batch adversarial loss: 0.460955\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341760; batch adversarial loss: 0.418606\n",
      "epoch 35; iter: 200; batch classifier loss: 0.253999; batch adversarial loss: 0.365061\n",
      "epoch 36; iter: 0; batch classifier loss: 0.382784; batch adversarial loss: 0.391915\n",
      "epoch 36; iter: 200; batch classifier loss: 0.372049; batch adversarial loss: 0.408483\n",
      "epoch 37; iter: 0; batch classifier loss: 0.332043; batch adversarial loss: 0.485971\n",
      "epoch 37; iter: 200; batch classifier loss: 0.281618; batch adversarial loss: 0.395998\n",
      "epoch 38; iter: 0; batch classifier loss: 0.324868; batch adversarial loss: 0.522958\n",
      "epoch 38; iter: 200; batch classifier loss: 0.333639; batch adversarial loss: 0.459749\n",
      "epoch 39; iter: 0; batch classifier loss: 0.309419; batch adversarial loss: 0.514300\n",
      "epoch 39; iter: 200; batch classifier loss: 0.323452; batch adversarial loss: 0.440881\n",
      "epoch 40; iter: 0; batch classifier loss: 0.313009; batch adversarial loss: 0.422802\n",
      "epoch 40; iter: 200; batch classifier loss: 0.421098; batch adversarial loss: 0.282114\n",
      "epoch 41; iter: 0; batch classifier loss: 0.319673; batch adversarial loss: 0.457752\n",
      "epoch 41; iter: 200; batch classifier loss: 0.350224; batch adversarial loss: 0.457808\n",
      "epoch 42; iter: 0; batch classifier loss: 0.312273; batch adversarial loss: 0.415504\n",
      "epoch 42; iter: 200; batch classifier loss: 0.379296; batch adversarial loss: 0.431814\n",
      "epoch 43; iter: 0; batch classifier loss: 0.430254; batch adversarial loss: 0.483699\n",
      "epoch 43; iter: 200; batch classifier loss: 0.359804; batch adversarial loss: 0.346779\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394534; batch adversarial loss: 0.411537\n",
      "epoch 44; iter: 200; batch classifier loss: 0.267988; batch adversarial loss: 0.454887\n",
      "epoch 45; iter: 0; batch classifier loss: 0.328938; batch adversarial loss: 0.358696\n",
      "epoch 45; iter: 200; batch classifier loss: 0.252025; batch adversarial loss: 0.521841\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317075; batch adversarial loss: 0.377446\n",
      "epoch 46; iter: 200; batch classifier loss: 0.317059; batch adversarial loss: 0.430572\n",
      "epoch 47; iter: 0; batch classifier loss: 0.349628; batch adversarial loss: 0.403626\n",
      "epoch 47; iter: 200; batch classifier loss: 0.299235; batch adversarial loss: 0.504224\n",
      "epoch 48; iter: 0; batch classifier loss: 0.369536; batch adversarial loss: 0.378896\n",
      "epoch 48; iter: 200; batch classifier loss: 0.403139; batch adversarial loss: 0.406542\n",
      "epoch 49; iter: 0; batch classifier loss: 0.285166; batch adversarial loss: 0.415646\n",
      "epoch 49; iter: 200; batch classifier loss: 0.320371; batch adversarial loss: 0.318454\n",
      "epoch 0; iter: 0; batch classifier loss: 53.401459; batch adversarial loss: 0.494491\n",
      "epoch 0; iter: 200; batch classifier loss: 8.834371; batch adversarial loss: 0.545010\n",
      "epoch 1; iter: 0; batch classifier loss: 12.215047; batch adversarial loss: 0.550553\n",
      "epoch 1; iter: 200; batch classifier loss: 7.735289; batch adversarial loss: 0.537304\n",
      "epoch 2; iter: 0; batch classifier loss: 10.121437; batch adversarial loss: 0.482079\n",
      "epoch 2; iter: 200; batch classifier loss: 1.795045; batch adversarial loss: 0.476072\n",
      "epoch 3; iter: 0; batch classifier loss: 2.566362; batch adversarial loss: 0.421044\n",
      "epoch 3; iter: 200; batch classifier loss: 1.936593; batch adversarial loss: 0.390549\n",
      "epoch 4; iter: 0; batch classifier loss: 1.930070; batch adversarial loss: 0.404636\n",
      "epoch 4; iter: 200; batch classifier loss: 2.726893; batch adversarial loss: 0.477542\n",
      "epoch 5; iter: 0; batch classifier loss: 1.656632; batch adversarial loss: 0.501919\n",
      "epoch 5; iter: 200; batch classifier loss: 0.746594; batch adversarial loss: 0.397395\n",
      "epoch 6; iter: 0; batch classifier loss: 1.635513; batch adversarial loss: 0.400769\n",
      "epoch 6; iter: 200; batch classifier loss: 1.153136; batch adversarial loss: 0.354928\n",
      "epoch 7; iter: 0; batch classifier loss: 0.436721; batch adversarial loss: 0.459223\n",
      "epoch 7; iter: 200; batch classifier loss: 0.596546; batch adversarial loss: 0.473155\n",
      "epoch 8; iter: 0; batch classifier loss: 0.913348; batch adversarial loss: 0.435936\n",
      "epoch 8; iter: 200; batch classifier loss: 0.433235; batch adversarial loss: 0.494734\n",
      "epoch 9; iter: 0; batch classifier loss: 0.736328; batch adversarial loss: 0.426575\n",
      "epoch 9; iter: 200; batch classifier loss: 0.376840; batch adversarial loss: 0.416525\n",
      "epoch 10; iter: 0; batch classifier loss: 0.406542; batch adversarial loss: 0.430261\n",
      "epoch 10; iter: 200; batch classifier loss: 0.770586; batch adversarial loss: 0.400207\n",
      "epoch 11; iter: 0; batch classifier loss: 1.160993; batch adversarial loss: 0.444259\n",
      "epoch 11; iter: 200; batch classifier loss: 0.614689; batch adversarial loss: 0.353762\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529583; batch adversarial loss: 0.490404\n",
      "epoch 12; iter: 200; batch classifier loss: 0.341609; batch adversarial loss: 0.393010\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383783; batch adversarial loss: 0.404183\n",
      "epoch 13; iter: 200; batch classifier loss: 0.457204; batch adversarial loss: 0.366172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432564; batch adversarial loss: 0.434182\n",
      "epoch 14; iter: 200; batch classifier loss: 0.382542; batch adversarial loss: 0.470453\n",
      "epoch 15; iter: 0; batch classifier loss: 0.403033; batch adversarial loss: 0.395253\n",
      "epoch 15; iter: 200; batch classifier loss: 0.394224; batch adversarial loss: 0.400714\n",
      "epoch 16; iter: 0; batch classifier loss: 0.429885; batch adversarial loss: 0.404923\n",
      "epoch 16; iter: 200; batch classifier loss: 0.365390; batch adversarial loss: 0.494591\n",
      "epoch 17; iter: 0; batch classifier loss: 0.370903; batch adversarial loss: 0.385657\n",
      "epoch 17; iter: 200; batch classifier loss: 0.509706; batch adversarial loss: 0.388889\n",
      "epoch 18; iter: 0; batch classifier loss: 0.479381; batch adversarial loss: 0.427764\n",
      "epoch 18; iter: 200; batch classifier loss: 0.380267; batch adversarial loss: 0.402892\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321804; batch adversarial loss: 0.425956\n",
      "epoch 19; iter: 200; batch classifier loss: 0.344859; batch adversarial loss: 0.430476\n",
      "epoch 20; iter: 0; batch classifier loss: 0.367213; batch adversarial loss: 0.351513\n",
      "epoch 20; iter: 200; batch classifier loss: 0.283098; batch adversarial loss: 0.411644\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338320; batch adversarial loss: 0.485488\n",
      "epoch 21; iter: 200; batch classifier loss: 0.402004; batch adversarial loss: 0.405857\n",
      "epoch 22; iter: 0; batch classifier loss: 0.357959; batch adversarial loss: 0.450458\n",
      "epoch 22; iter: 200; batch classifier loss: 0.355468; batch adversarial loss: 0.495165\n",
      "epoch 23; iter: 0; batch classifier loss: 0.294475; batch adversarial loss: 0.426541\n",
      "epoch 23; iter: 200; batch classifier loss: 0.337098; batch adversarial loss: 0.452347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.324250; batch adversarial loss: 0.496403\n",
      "epoch 24; iter: 200; batch classifier loss: 0.338488; batch adversarial loss: 0.442283\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349156; batch adversarial loss: 0.446154\n",
      "epoch 25; iter: 200; batch classifier loss: 0.355817; batch adversarial loss: 0.424982\n",
      "epoch 26; iter: 0; batch classifier loss: 0.320563; batch adversarial loss: 0.331878\n",
      "epoch 26; iter: 200; batch classifier loss: 0.317837; batch adversarial loss: 0.556574\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321307; batch adversarial loss: 0.387022\n",
      "epoch 27; iter: 200; batch classifier loss: 0.340051; batch adversarial loss: 0.407605\n",
      "epoch 28; iter: 0; batch classifier loss: 0.283439; batch adversarial loss: 0.399982\n",
      "epoch 28; iter: 200; batch classifier loss: 0.371459; batch adversarial loss: 0.391598\n",
      "epoch 29; iter: 0; batch classifier loss: 0.301844; batch adversarial loss: 0.487314\n",
      "epoch 29; iter: 200; batch classifier loss: 0.408134; batch adversarial loss: 0.359704\n",
      "epoch 30; iter: 0; batch classifier loss: 0.339193; batch adversarial loss: 0.418173\n",
      "epoch 30; iter: 200; batch classifier loss: 0.319416; batch adversarial loss: 0.405687\n",
      "epoch 31; iter: 0; batch classifier loss: 0.344896; batch adversarial loss: 0.335968\n",
      "epoch 31; iter: 200; batch classifier loss: 0.426541; batch adversarial loss: 0.343366\n",
      "epoch 32; iter: 0; batch classifier loss: 0.492197; batch adversarial loss: 0.414014\n",
      "epoch 32; iter: 200; batch classifier loss: 0.303819; batch adversarial loss: 0.380620\n",
      "epoch 33; iter: 0; batch classifier loss: 0.304291; batch adversarial loss: 0.411594\n",
      "epoch 33; iter: 200; batch classifier loss: 0.259629; batch adversarial loss: 0.457801\n",
      "epoch 34; iter: 0; batch classifier loss: 0.321806; batch adversarial loss: 0.422855\n",
      "epoch 34; iter: 200; batch classifier loss: 0.286566; batch adversarial loss: 0.379202\n",
      "epoch 35; iter: 0; batch classifier loss: 0.329024; batch adversarial loss: 0.422772\n",
      "epoch 35; iter: 200; batch classifier loss: 0.298291; batch adversarial loss: 0.376198\n",
      "epoch 36; iter: 0; batch classifier loss: 0.283088; batch adversarial loss: 0.423312\n",
      "epoch 36; iter: 200; batch classifier loss: 0.343773; batch adversarial loss: 0.374789\n",
      "epoch 37; iter: 0; batch classifier loss: 0.327914; batch adversarial loss: 0.462892\n",
      "epoch 37; iter: 200; batch classifier loss: 0.370349; batch adversarial loss: 0.341051\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399451; batch adversarial loss: 0.458148\n",
      "epoch 38; iter: 200; batch classifier loss: 0.321433; batch adversarial loss: 0.383619\n",
      "epoch 39; iter: 0; batch classifier loss: 0.379725; batch adversarial loss: 0.333411\n",
      "epoch 39; iter: 200; batch classifier loss: 0.328173; batch adversarial loss: 0.392957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.356622; batch adversarial loss: 0.444388\n",
      "epoch 40; iter: 200; batch classifier loss: 0.393102; batch adversarial loss: 0.422414\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389750; batch adversarial loss: 0.512364\n",
      "epoch 41; iter: 200; batch classifier loss: 0.370187; batch adversarial loss: 0.570527\n",
      "epoch 42; iter: 0; batch classifier loss: 0.310755; batch adversarial loss: 0.304804\n",
      "epoch 42; iter: 200; batch classifier loss: 0.395573; batch adversarial loss: 0.340151\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428668; batch adversarial loss: 0.511420\n",
      "epoch 43; iter: 200; batch classifier loss: 0.394025; batch adversarial loss: 0.457263\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458562; batch adversarial loss: 0.434752\n",
      "epoch 44; iter: 200; batch classifier loss: 0.451576; batch adversarial loss: 0.377640\n",
      "epoch 45; iter: 0; batch classifier loss: 0.344143; batch adversarial loss: 0.477058\n",
      "epoch 45; iter: 200; batch classifier loss: 0.462730; batch adversarial loss: 0.418508\n",
      "epoch 46; iter: 0; batch classifier loss: 0.404412; batch adversarial loss: 0.399691\n",
      "epoch 46; iter: 200; batch classifier loss: 0.460403; batch adversarial loss: 0.482674\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439155; batch adversarial loss: 0.459882\n",
      "epoch 47; iter: 200; batch classifier loss: 0.370106; batch adversarial loss: 0.380482\n",
      "epoch 48; iter: 0; batch classifier loss: 0.425969; batch adversarial loss: 0.447584\n",
      "epoch 48; iter: 200; batch classifier loss: 0.453209; batch adversarial loss: 0.378889\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403210; batch adversarial loss: 0.401401\n",
      "epoch 49; iter: 200; batch classifier loss: 0.500594; batch adversarial loss: 0.374456\n",
      "epoch 0; iter: 0; batch classifier loss: 7.625230; batch adversarial loss: 0.436801\n",
      "epoch 0; iter: 200; batch classifier loss: 10.211551; batch adversarial loss: 0.510127\n",
      "epoch 1; iter: 0; batch classifier loss: 9.161020; batch adversarial loss: 0.485318\n",
      "epoch 1; iter: 200; batch classifier loss: 1.774850; batch adversarial loss: 0.482298\n",
      "epoch 2; iter: 0; batch classifier loss: 4.549918; batch adversarial loss: 0.458517\n",
      "epoch 2; iter: 200; batch classifier loss: 5.182672; batch adversarial loss: 0.436254\n",
      "epoch 3; iter: 0; batch classifier loss: 2.467261; batch adversarial loss: 0.491751\n",
      "epoch 3; iter: 200; batch classifier loss: 1.427254; batch adversarial loss: 0.506339\n",
      "epoch 4; iter: 0; batch classifier loss: 6.044398; batch adversarial loss: 0.359148\n",
      "epoch 4; iter: 200; batch classifier loss: 1.368201; batch adversarial loss: 0.438518\n",
      "epoch 5; iter: 0; batch classifier loss: 1.590163; batch adversarial loss: 0.403145\n",
      "epoch 5; iter: 200; batch classifier loss: 1.462445; batch adversarial loss: 0.385862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.680174; batch adversarial loss: 0.356639\n",
      "epoch 6; iter: 200; batch classifier loss: 0.965316; batch adversarial loss: 0.438214\n",
      "epoch 7; iter: 0; batch classifier loss: 0.710178; batch adversarial loss: 0.452875\n",
      "epoch 7; iter: 200; batch classifier loss: 0.605604; batch adversarial loss: 0.372449\n",
      "epoch 8; iter: 0; batch classifier loss: 0.707545; batch adversarial loss: 0.403122\n",
      "epoch 8; iter: 200; batch classifier loss: 0.393651; batch adversarial loss: 0.354204\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589620; batch adversarial loss: 0.370430\n",
      "epoch 9; iter: 200; batch classifier loss: 0.397869; batch adversarial loss: 0.434243\n",
      "epoch 10; iter: 0; batch classifier loss: 0.347875; batch adversarial loss: 0.411545\n",
      "epoch 10; iter: 200; batch classifier loss: 0.572662; batch adversarial loss: 0.422612\n",
      "epoch 11; iter: 0; batch classifier loss: 0.396225; batch adversarial loss: 0.418733\n",
      "epoch 11; iter: 200; batch classifier loss: 0.392676; batch adversarial loss: 0.285005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372646; batch adversarial loss: 0.416362\n",
      "epoch 12; iter: 200; batch classifier loss: 0.415780; batch adversarial loss: 0.335406\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328469; batch adversarial loss: 0.490461\n",
      "epoch 13; iter: 200; batch classifier loss: 0.341980; batch adversarial loss: 0.569020\n",
      "epoch 14; iter: 0; batch classifier loss: 0.453054; batch adversarial loss: 0.453566\n",
      "epoch 14; iter: 200; batch classifier loss: 0.420787; batch adversarial loss: 0.365353\n",
      "epoch 15; iter: 0; batch classifier loss: 0.387280; batch adversarial loss: 0.341944\n",
      "epoch 15; iter: 200; batch classifier loss: 0.321359; batch adversarial loss: 0.565454\n",
      "epoch 16; iter: 0; batch classifier loss: 0.302928; batch adversarial loss: 0.349811\n",
      "epoch 16; iter: 200; batch classifier loss: 0.319451; batch adversarial loss: 0.355644\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368081; batch adversarial loss: 0.405024\n",
      "epoch 17; iter: 200; batch classifier loss: 0.379361; batch adversarial loss: 0.379460\n",
      "epoch 18; iter: 0; batch classifier loss: 0.413957; batch adversarial loss: 0.489147\n",
      "epoch 18; iter: 200; batch classifier loss: 0.320050; batch adversarial loss: 0.351669\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335723; batch adversarial loss: 0.428414\n",
      "epoch 19; iter: 200; batch classifier loss: 0.378948; batch adversarial loss: 0.393130\n",
      "epoch 20; iter: 0; batch classifier loss: 0.357568; batch adversarial loss: 0.474164\n",
      "epoch 20; iter: 200; batch classifier loss: 0.389674; batch adversarial loss: 0.381946\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354562; batch adversarial loss: 0.384949\n",
      "epoch 21; iter: 200; batch classifier loss: 0.329381; batch adversarial loss: 0.372205\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372645; batch adversarial loss: 0.451039\n",
      "epoch 22; iter: 200; batch classifier loss: 0.255595; batch adversarial loss: 0.434184\n",
      "epoch 23; iter: 0; batch classifier loss: 0.317239; batch adversarial loss: 0.352762\n",
      "epoch 23; iter: 200; batch classifier loss: 0.311205; batch adversarial loss: 0.409209\n",
      "epoch 24; iter: 0; batch classifier loss: 0.314603; batch adversarial loss: 0.409531\n",
      "epoch 24; iter: 200; batch classifier loss: 0.340719; batch adversarial loss: 0.481397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.364405; batch adversarial loss: 0.433544\n",
      "epoch 25; iter: 200; batch classifier loss: 0.299530; batch adversarial loss: 0.399527\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378956; batch adversarial loss: 0.407061\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343586; batch adversarial loss: 0.414993\n",
      "epoch 27; iter: 0; batch classifier loss: 0.332148; batch adversarial loss: 0.301297\n",
      "epoch 27; iter: 200; batch classifier loss: 0.393800; batch adversarial loss: 0.509889\n",
      "epoch 28; iter: 0; batch classifier loss: 0.392966; batch adversarial loss: 0.422659\n",
      "epoch 28; iter: 200; batch classifier loss: 0.384167; batch adversarial loss: 0.398040\n",
      "epoch 29; iter: 0; batch classifier loss: 0.266132; batch adversarial loss: 0.467624\n",
      "epoch 29; iter: 200; batch classifier loss: 0.354724; batch adversarial loss: 0.450137\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390887; batch adversarial loss: 0.465277\n",
      "epoch 30; iter: 200; batch classifier loss: 0.322439; batch adversarial loss: 0.417820\n",
      "epoch 31; iter: 0; batch classifier loss: 0.346566; batch adversarial loss: 0.447324\n",
      "epoch 31; iter: 200; batch classifier loss: 0.411535; batch adversarial loss: 0.372853\n",
      "epoch 32; iter: 0; batch classifier loss: 0.326403; batch adversarial loss: 0.436799\n",
      "epoch 32; iter: 200; batch classifier loss: 0.300190; batch adversarial loss: 0.370069\n",
      "epoch 33; iter: 0; batch classifier loss: 0.215877; batch adversarial loss: 0.461691\n",
      "epoch 33; iter: 200; batch classifier loss: 0.384556; batch adversarial loss: 0.457544\n",
      "epoch 34; iter: 0; batch classifier loss: 0.318659; batch adversarial loss: 0.409545\n",
      "epoch 34; iter: 200; batch classifier loss: 0.272118; batch adversarial loss: 0.387776\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454154; batch adversarial loss: 0.368163\n",
      "epoch 35; iter: 200; batch classifier loss: 0.339191; batch adversarial loss: 0.391340\n",
      "epoch 36; iter: 0; batch classifier loss: 0.323703; batch adversarial loss: 0.494161\n",
      "epoch 36; iter: 200; batch classifier loss: 0.301544; batch adversarial loss: 0.496953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436217; batch adversarial loss: 0.398015\n",
      "epoch 37; iter: 200; batch classifier loss: 0.302773; batch adversarial loss: 0.301930\n",
      "epoch 38; iter: 0; batch classifier loss: 0.454896; batch adversarial loss: 0.345874\n",
      "epoch 38; iter: 200; batch classifier loss: 0.315853; batch adversarial loss: 0.461520\n",
      "epoch 39; iter: 0; batch classifier loss: 0.335288; batch adversarial loss: 0.385121\n",
      "epoch 39; iter: 200; batch classifier loss: 0.278363; batch adversarial loss: 0.458011\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361515; batch adversarial loss: 0.433147\n",
      "epoch 40; iter: 200; batch classifier loss: 0.303190; batch adversarial loss: 0.437642\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419099; batch adversarial loss: 0.324476\n",
      "epoch 41; iter: 200; batch classifier loss: 0.292304; batch adversarial loss: 0.379653\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396574; batch adversarial loss: 0.401288\n",
      "epoch 42; iter: 200; batch classifier loss: 0.394576; batch adversarial loss: 0.515773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.289539; batch adversarial loss: 0.312240\n",
      "epoch 43; iter: 200; batch classifier loss: 0.345179; batch adversarial loss: 0.410606\n",
      "epoch 44; iter: 0; batch classifier loss: 0.286930; batch adversarial loss: 0.447514\n",
      "epoch 44; iter: 200; batch classifier loss: 0.318956; batch adversarial loss: 0.456111\n",
      "epoch 45; iter: 0; batch classifier loss: 0.291949; batch adversarial loss: 0.372293\n",
      "epoch 45; iter: 200; batch classifier loss: 0.433254; batch adversarial loss: 0.415346\n",
      "epoch 46; iter: 0; batch classifier loss: 0.365832; batch adversarial loss: 0.443659\n",
      "epoch 46; iter: 200; batch classifier loss: 0.316398; batch adversarial loss: 0.345008\n",
      "epoch 47; iter: 0; batch classifier loss: 0.324635; batch adversarial loss: 0.468688\n",
      "epoch 47; iter: 200; batch classifier loss: 0.305373; batch adversarial loss: 0.415286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.325553; batch adversarial loss: 0.393766\n",
      "epoch 48; iter: 200; batch classifier loss: 0.308584; batch adversarial loss: 0.316425\n",
      "epoch 49; iter: 0; batch classifier loss: 0.306519; batch adversarial loss: 0.375588\n",
      "epoch 49; iter: 200; batch classifier loss: 0.318911; batch adversarial loss: 0.374092\n",
      "epoch 0; iter: 0; batch classifier loss: 13.866199; batch adversarial loss: 0.942005\n",
      "epoch 0; iter: 200; batch classifier loss: 6.207134; batch adversarial loss: 0.717265\n",
      "epoch 1; iter: 0; batch classifier loss: 3.217040; batch adversarial loss: 0.652369\n",
      "epoch 1; iter: 200; batch classifier loss: 10.048113; batch adversarial loss: 0.606568\n",
      "epoch 2; iter: 0; batch classifier loss: 5.756506; batch adversarial loss: 0.561648\n",
      "epoch 2; iter: 200; batch classifier loss: 4.261647; batch adversarial loss: 0.569586\n",
      "epoch 3; iter: 0; batch classifier loss: 6.354754; batch adversarial loss: 0.523299\n",
      "epoch 3; iter: 200; batch classifier loss: 2.436475; batch adversarial loss: 0.546671\n",
      "epoch 4; iter: 0; batch classifier loss: 2.135854; batch adversarial loss: 0.473986\n",
      "epoch 4; iter: 200; batch classifier loss: 6.082105; batch adversarial loss: 0.498317\n",
      "epoch 5; iter: 0; batch classifier loss: 2.198663; batch adversarial loss: 0.528559\n",
      "epoch 5; iter: 200; batch classifier loss: 0.576199; batch adversarial loss: 0.408323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.840597; batch adversarial loss: 0.365862\n",
      "epoch 6; iter: 200; batch classifier loss: 0.756734; batch adversarial loss: 0.345195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614186; batch adversarial loss: 0.397732\n",
      "epoch 7; iter: 200; batch classifier loss: 0.846033; batch adversarial loss: 0.474312\n",
      "epoch 8; iter: 0; batch classifier loss: 1.369297; batch adversarial loss: 0.494564\n",
      "epoch 8; iter: 200; batch classifier loss: 0.483447; batch adversarial loss: 0.381955\n",
      "epoch 9; iter: 0; batch classifier loss: 0.473824; batch adversarial loss: 0.440634\n",
      "epoch 9; iter: 200; batch classifier loss: 0.496234; batch adversarial loss: 0.331337\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443994; batch adversarial loss: 0.334017\n",
      "epoch 10; iter: 200; batch classifier loss: 0.569786; batch adversarial loss: 0.477299\n",
      "epoch 11; iter: 0; batch classifier loss: 0.432705; batch adversarial loss: 0.299088\n",
      "epoch 11; iter: 200; batch classifier loss: 0.394231; batch adversarial loss: 0.457555\n",
      "epoch 12; iter: 0; batch classifier loss: 0.387641; batch adversarial loss: 0.464086\n",
      "epoch 12; iter: 200; batch classifier loss: 0.429004; batch adversarial loss: 0.403129\n",
      "epoch 13; iter: 0; batch classifier loss: 0.443160; batch adversarial loss: 0.440208\n",
      "epoch 13; iter: 200; batch classifier loss: 0.479079; batch adversarial loss: 0.387084\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349688; batch adversarial loss: 0.467446\n",
      "epoch 14; iter: 200; batch classifier loss: 0.425927; batch adversarial loss: 0.338538\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494826; batch adversarial loss: 0.401559\n",
      "epoch 15; iter: 200; batch classifier loss: 0.346245; batch adversarial loss: 0.441543\n",
      "epoch 16; iter: 0; batch classifier loss: 0.417397; batch adversarial loss: 0.439329\n",
      "epoch 16; iter: 200; batch classifier loss: 0.334877; batch adversarial loss: 0.397525\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336895; batch adversarial loss: 0.508842\n",
      "epoch 17; iter: 200; batch classifier loss: 0.307054; batch adversarial loss: 0.382584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.375939; batch adversarial loss: 0.415777\n",
      "epoch 18; iter: 200; batch classifier loss: 0.300270; batch adversarial loss: 0.445620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327016; batch adversarial loss: 0.500071\n",
      "epoch 19; iter: 200; batch classifier loss: 0.407968; batch adversarial loss: 0.401356\n",
      "epoch 20; iter: 0; batch classifier loss: 0.374615; batch adversarial loss: 0.371039\n",
      "epoch 20; iter: 200; batch classifier loss: 0.403817; batch adversarial loss: 0.370672\n",
      "epoch 21; iter: 0; batch classifier loss: 0.297425; batch adversarial loss: 0.400974\n",
      "epoch 21; iter: 200; batch classifier loss: 0.308490; batch adversarial loss: 0.445560\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414478; batch adversarial loss: 0.357470\n",
      "epoch 22; iter: 200; batch classifier loss: 0.368925; batch adversarial loss: 0.418668\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285809; batch adversarial loss: 0.446719\n",
      "epoch 23; iter: 200; batch classifier loss: 0.384154; batch adversarial loss: 0.332546\n",
      "epoch 24; iter: 0; batch classifier loss: 0.345694; batch adversarial loss: 0.454740\n",
      "epoch 24; iter: 200; batch classifier loss: 0.445524; batch adversarial loss: 0.457446\n",
      "epoch 25; iter: 0; batch classifier loss: 0.385006; batch adversarial loss: 0.430141\n",
      "epoch 25; iter: 200; batch classifier loss: 0.371770; batch adversarial loss: 0.421014\n",
      "epoch 26; iter: 0; batch classifier loss: 0.314817; batch adversarial loss: 0.400966\n",
      "epoch 26; iter: 200; batch classifier loss: 0.298942; batch adversarial loss: 0.498049\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284740; batch adversarial loss: 0.425786\n",
      "epoch 27; iter: 200; batch classifier loss: 0.329656; batch adversarial loss: 0.351044\n",
      "epoch 28; iter: 0; batch classifier loss: 0.370581; batch adversarial loss: 0.433315\n",
      "epoch 28; iter: 200; batch classifier loss: 0.354998; batch adversarial loss: 0.413853\n",
      "epoch 29; iter: 0; batch classifier loss: 0.341973; batch adversarial loss: 0.395033\n",
      "epoch 29; iter: 200; batch classifier loss: 0.354212; batch adversarial loss: 0.406808\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378489; batch adversarial loss: 0.389000\n",
      "epoch 30; iter: 200; batch classifier loss: 0.445981; batch adversarial loss: 0.430298\n",
      "epoch 31; iter: 0; batch classifier loss: 0.289518; batch adversarial loss: 0.346490\n",
      "epoch 31; iter: 200; batch classifier loss: 0.343057; batch adversarial loss: 0.421918\n",
      "epoch 32; iter: 0; batch classifier loss: 0.386780; batch adversarial loss: 0.382427\n",
      "epoch 32; iter: 200; batch classifier loss: 0.285873; batch adversarial loss: 0.473806\n",
      "epoch 33; iter: 0; batch classifier loss: 0.326710; batch adversarial loss: 0.383728\n",
      "epoch 33; iter: 200; batch classifier loss: 0.301409; batch adversarial loss: 0.503648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.347652; batch adversarial loss: 0.496201\n",
      "epoch 34; iter: 200; batch classifier loss: 0.382510; batch adversarial loss: 0.447147\n",
      "epoch 35; iter: 0; batch classifier loss: 0.344148; batch adversarial loss: 0.375273\n",
      "epoch 35; iter: 200; batch classifier loss: 0.315299; batch adversarial loss: 0.408964\n",
      "epoch 36; iter: 0; batch classifier loss: 0.350198; batch adversarial loss: 0.438102\n",
      "epoch 36; iter: 200; batch classifier loss: 0.313449; batch adversarial loss: 0.431697\n",
      "epoch 37; iter: 0; batch classifier loss: 0.396240; batch adversarial loss: 0.506890\n",
      "epoch 37; iter: 200; batch classifier loss: 0.339295; batch adversarial loss: 0.478209\n",
      "epoch 38; iter: 0; batch classifier loss: 0.471332; batch adversarial loss: 0.356804\n",
      "epoch 38; iter: 200; batch classifier loss: 0.303990; batch adversarial loss: 0.329047\n",
      "epoch 39; iter: 0; batch classifier loss: 0.390090; batch adversarial loss: 0.457036\n",
      "epoch 39; iter: 200; batch classifier loss: 0.298859; batch adversarial loss: 0.374762\n",
      "epoch 40; iter: 0; batch classifier loss: 0.322932; batch adversarial loss: 0.421395\n",
      "epoch 40; iter: 200; batch classifier loss: 0.367825; batch adversarial loss: 0.361370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.250466; batch adversarial loss: 0.405837\n",
      "epoch 41; iter: 200; batch classifier loss: 0.332302; batch adversarial loss: 0.374461\n",
      "epoch 42; iter: 0; batch classifier loss: 0.307036; batch adversarial loss: 0.455872\n",
      "epoch 42; iter: 200; batch classifier loss: 0.343854; batch adversarial loss: 0.481598\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328452; batch adversarial loss: 0.409750\n",
      "epoch 43; iter: 200; batch classifier loss: 0.415576; batch adversarial loss: 0.431957\n",
      "epoch 44; iter: 0; batch classifier loss: 0.348874; batch adversarial loss: 0.391165\n",
      "epoch 44; iter: 200; batch classifier loss: 0.236375; batch adversarial loss: 0.424867\n",
      "epoch 45; iter: 0; batch classifier loss: 0.380565; batch adversarial loss: 0.402329\n",
      "epoch 45; iter: 200; batch classifier loss: 0.327642; batch adversarial loss: 0.394674\n",
      "epoch 46; iter: 0; batch classifier loss: 0.261232; batch adversarial loss: 0.449433\n",
      "epoch 46; iter: 200; batch classifier loss: 0.389416; batch adversarial loss: 0.392860\n",
      "epoch 47; iter: 0; batch classifier loss: 0.294728; batch adversarial loss: 0.425647\n",
      "epoch 47; iter: 200; batch classifier loss: 0.419713; batch adversarial loss: 0.450583\n",
      "epoch 48; iter: 0; batch classifier loss: 0.333806; batch adversarial loss: 0.444622\n",
      "epoch 48; iter: 200; batch classifier loss: 0.297962; batch adversarial loss: 0.377526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.386431; batch adversarial loss: 0.395628\n",
      "epoch 49; iter: 200; batch classifier loss: 0.297638; batch adversarial loss: 0.495182\n",
      "epoch 0; iter: 0; batch classifier loss: 6.746259; batch adversarial loss: 0.762280\n",
      "epoch 0; iter: 200; batch classifier loss: 8.664506; batch adversarial loss: 0.658728\n",
      "epoch 1; iter: 0; batch classifier loss: 8.315485; batch adversarial loss: 0.602185\n",
      "epoch 1; iter: 200; batch classifier loss: 7.247137; batch adversarial loss: 0.562310\n",
      "epoch 2; iter: 0; batch classifier loss: 4.777339; batch adversarial loss: 0.523018\n",
      "epoch 2; iter: 200; batch classifier loss: 5.355895; batch adversarial loss: 0.484737\n",
      "epoch 3; iter: 0; batch classifier loss: 2.036035; batch adversarial loss: 0.490647\n",
      "epoch 3; iter: 200; batch classifier loss: 3.140635; batch adversarial loss: 0.475224\n",
      "epoch 4; iter: 0; batch classifier loss: 4.039331; batch adversarial loss: 0.473436\n",
      "epoch 4; iter: 200; batch classifier loss: 2.072315; batch adversarial loss: 0.404217\n",
      "epoch 5; iter: 0; batch classifier loss: 1.079701; batch adversarial loss: 0.450178\n",
      "epoch 5; iter: 200; batch classifier loss: 1.477792; batch adversarial loss: 0.506176\n",
      "epoch 6; iter: 0; batch classifier loss: 1.172644; batch adversarial loss: 0.456068\n",
      "epoch 6; iter: 200; batch classifier loss: 0.657666; batch adversarial loss: 0.356677\n",
      "epoch 7; iter: 0; batch classifier loss: 0.801412; batch adversarial loss: 0.414437\n",
      "epoch 7; iter: 200; batch classifier loss: 0.571169; batch adversarial loss: 0.402162\n",
      "epoch 8; iter: 0; batch classifier loss: 0.492604; batch adversarial loss: 0.442340\n",
      "epoch 8; iter: 200; batch classifier loss: 0.614394; batch adversarial loss: 0.405006\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409960; batch adversarial loss: 0.475109\n",
      "epoch 9; iter: 200; batch classifier loss: 0.458488; batch adversarial loss: 0.417429\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538923; batch adversarial loss: 0.479473\n",
      "epoch 10; iter: 200; batch classifier loss: 0.378506; batch adversarial loss: 0.467523\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360850; batch adversarial loss: 0.421543\n",
      "epoch 11; iter: 200; batch classifier loss: 0.358282; batch adversarial loss: 0.428754\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337751; batch adversarial loss: 0.433036\n",
      "epoch 12; iter: 200; batch classifier loss: 0.431254; batch adversarial loss: 0.373397\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396481; batch adversarial loss: 0.478644\n",
      "epoch 13; iter: 200; batch classifier loss: 0.351283; batch adversarial loss: 0.353230\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406528; batch adversarial loss: 0.419832\n",
      "epoch 14; iter: 200; batch classifier loss: 0.333050; batch adversarial loss: 0.407405\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428015; batch adversarial loss: 0.422748\n",
      "epoch 15; iter: 200; batch classifier loss: 0.314271; batch adversarial loss: 0.370873\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377208; batch adversarial loss: 0.392488\n",
      "epoch 16; iter: 200; batch classifier loss: 0.359511; batch adversarial loss: 0.387724\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338415; batch adversarial loss: 0.503246\n",
      "epoch 17; iter: 200; batch classifier loss: 0.368477; batch adversarial loss: 0.402697\n",
      "epoch 18; iter: 0; batch classifier loss: 0.294767; batch adversarial loss: 0.434546\n",
      "epoch 18; iter: 200; batch classifier loss: 0.352581; batch adversarial loss: 0.449632\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325457; batch adversarial loss: 0.451229\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347555; batch adversarial loss: 0.421642\n",
      "epoch 20; iter: 0; batch classifier loss: 0.359635; batch adversarial loss: 0.392172\n",
      "epoch 20; iter: 200; batch classifier loss: 0.360455; batch adversarial loss: 0.431431\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275333; batch adversarial loss: 0.400770\n",
      "epoch 21; iter: 200; batch classifier loss: 0.317190; batch adversarial loss: 0.411293\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307291; batch adversarial loss: 0.413873\n",
      "epoch 22; iter: 200; batch classifier loss: 0.364450; batch adversarial loss: 0.422196\n",
      "epoch 23; iter: 0; batch classifier loss: 0.329249; batch adversarial loss: 0.442337\n",
      "epoch 23; iter: 200; batch classifier loss: 0.348310; batch adversarial loss: 0.369211\n",
      "epoch 24; iter: 0; batch classifier loss: 0.386884; batch adversarial loss: 0.419978\n",
      "epoch 24; iter: 200; batch classifier loss: 0.311529; batch adversarial loss: 0.291694\n",
      "epoch 25; iter: 0; batch classifier loss: 0.332678; batch adversarial loss: 0.317850\n",
      "epoch 25; iter: 200; batch classifier loss: 0.369139; batch adversarial loss: 0.450242\n",
      "epoch 26; iter: 0; batch classifier loss: 0.420026; batch adversarial loss: 0.387280\n",
      "epoch 26; iter: 200; batch classifier loss: 0.332059; batch adversarial loss: 0.336817\n",
      "epoch 27; iter: 0; batch classifier loss: 0.361786; batch adversarial loss: 0.509335\n",
      "epoch 27; iter: 200; batch classifier loss: 0.312241; batch adversarial loss: 0.376582\n",
      "epoch 28; iter: 0; batch classifier loss: 0.353665; batch adversarial loss: 0.435698\n",
      "epoch 28; iter: 200; batch classifier loss: 0.297325; batch adversarial loss: 0.510680\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444585; batch adversarial loss: 0.337651\n",
      "epoch 29; iter: 200; batch classifier loss: 0.375472; batch adversarial loss: 0.493887\n",
      "epoch 30; iter: 0; batch classifier loss: 0.328309; batch adversarial loss: 0.337492\n",
      "epoch 30; iter: 200; batch classifier loss: 0.529054; batch adversarial loss: 0.469003\n",
      "epoch 31; iter: 0; batch classifier loss: 0.518953; batch adversarial loss: 0.428041\n",
      "epoch 31; iter: 200; batch classifier loss: 0.334373; batch adversarial loss: 0.470241\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405949; batch adversarial loss: 0.414203\n",
      "epoch 32; iter: 200; batch classifier loss: 0.447134; batch adversarial loss: 0.345376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.395472; batch adversarial loss: 0.323944\n",
      "epoch 33; iter: 200; batch classifier loss: 0.358530; batch adversarial loss: 0.359522\n",
      "epoch 34; iter: 0; batch classifier loss: 0.395308; batch adversarial loss: 0.434453\n",
      "epoch 34; iter: 200; batch classifier loss: 0.336321; batch adversarial loss: 0.414103\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444561; batch adversarial loss: 0.464763\n",
      "epoch 35; iter: 200; batch classifier loss: 0.488830; batch adversarial loss: 0.377616\n",
      "epoch 36; iter: 0; batch classifier loss: 0.429005; batch adversarial loss: 0.407255\n",
      "epoch 36; iter: 200; batch classifier loss: 0.493736; batch adversarial loss: 0.371593\n",
      "epoch 37; iter: 0; batch classifier loss: 0.431389; batch adversarial loss: 0.385605\n",
      "epoch 37; iter: 200; batch classifier loss: 0.591480; batch adversarial loss: 0.425376\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447832; batch adversarial loss: 0.429736\n",
      "epoch 38; iter: 200; batch classifier loss: 0.472075; batch adversarial loss: 0.400692\n",
      "epoch 39; iter: 0; batch classifier loss: 0.353517; batch adversarial loss: 0.474445\n",
      "epoch 39; iter: 200; batch classifier loss: 0.475418; batch adversarial loss: 0.469304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405774; batch adversarial loss: 0.406259\n",
      "epoch 40; iter: 200; batch classifier loss: 0.479893; batch adversarial loss: 0.373695\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397702; batch adversarial loss: 0.431877\n",
      "epoch 41; iter: 200; batch classifier loss: 0.478377; batch adversarial loss: 0.464392\n",
      "epoch 42; iter: 0; batch classifier loss: 0.494619; batch adversarial loss: 0.512881\n",
      "epoch 42; iter: 200; batch classifier loss: 0.349825; batch adversarial loss: 0.462009\n",
      "epoch 43; iter: 0; batch classifier loss: 0.500780; batch adversarial loss: 0.401839\n",
      "epoch 43; iter: 200; batch classifier loss: 0.424188; batch adversarial loss: 0.444644\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417307; batch adversarial loss: 0.465399\n",
      "epoch 44; iter: 200; batch classifier loss: 0.553333; batch adversarial loss: 0.526856\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411535; batch adversarial loss: 0.523633\n",
      "epoch 45; iter: 200; batch classifier loss: 0.492889; batch adversarial loss: 0.405829\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428591; batch adversarial loss: 0.488082\n",
      "epoch 46; iter: 200; batch classifier loss: 0.487194; batch adversarial loss: 0.498420\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465243; batch adversarial loss: 0.392727\n",
      "epoch 47; iter: 200; batch classifier loss: 0.517215; batch adversarial loss: 0.353316\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380232; batch adversarial loss: 0.457066\n",
      "epoch 48; iter: 200; batch classifier loss: 0.506039; batch adversarial loss: 0.361977\n",
      "epoch 49; iter: 0; batch classifier loss: 0.499442; batch adversarial loss: 0.335147\n",
      "epoch 49; iter: 200; batch classifier loss: 0.456860; batch adversarial loss: 0.349605\n",
      "epoch 0; iter: 0; batch classifier loss: 20.233316; batch adversarial loss: 0.855250\n",
      "epoch 0; iter: 200; batch classifier loss: 2.310581; batch adversarial loss: 0.683096\n",
      "epoch 1; iter: 0; batch classifier loss: 10.366592; batch adversarial loss: 0.611779\n",
      "epoch 1; iter: 200; batch classifier loss: 5.683445; batch adversarial loss: 0.567337\n",
      "epoch 2; iter: 0; batch classifier loss: 1.965518; batch adversarial loss: 0.508088\n",
      "epoch 2; iter: 200; batch classifier loss: 3.592752; batch adversarial loss: 0.496280\n",
      "epoch 3; iter: 0; batch classifier loss: 3.312469; batch adversarial loss: 0.521000\n",
      "epoch 3; iter: 200; batch classifier loss: 1.213711; batch adversarial loss: 0.456429\n",
      "epoch 4; iter: 0; batch classifier loss: 1.301426; batch adversarial loss: 0.448396\n",
      "epoch 4; iter: 200; batch classifier loss: 1.379485; batch adversarial loss: 0.477824\n",
      "epoch 5; iter: 0; batch classifier loss: 0.751423; batch adversarial loss: 0.418047\n",
      "epoch 5; iter: 200; batch classifier loss: 1.310598; batch adversarial loss: 0.376145\n",
      "epoch 6; iter: 0; batch classifier loss: 0.727717; batch adversarial loss: 0.358290\n",
      "epoch 6; iter: 200; batch classifier loss: 0.626169; batch adversarial loss: 0.398351\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550599; batch adversarial loss: 0.377620\n",
      "epoch 7; iter: 200; batch classifier loss: 0.548243; batch adversarial loss: 0.395488\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553956; batch adversarial loss: 0.401476\n",
      "epoch 8; iter: 200; batch classifier loss: 0.384128; batch adversarial loss: 0.471956\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470436; batch adversarial loss: 0.428564\n",
      "epoch 9; iter: 200; batch classifier loss: 0.356953; batch adversarial loss: 0.468304\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430410; batch adversarial loss: 0.342889\n",
      "epoch 10; iter: 200; batch classifier loss: 0.375846; batch adversarial loss: 0.471498\n",
      "epoch 11; iter: 0; batch classifier loss: 0.415980; batch adversarial loss: 0.372744\n",
      "epoch 11; iter: 200; batch classifier loss: 0.379132; batch adversarial loss: 0.448388\n",
      "epoch 12; iter: 0; batch classifier loss: 0.330509; batch adversarial loss: 0.387691\n",
      "epoch 12; iter: 200; batch classifier loss: 0.341105; batch adversarial loss: 0.404812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421047; batch adversarial loss: 0.350922\n",
      "epoch 13; iter: 200; batch classifier loss: 0.428938; batch adversarial loss: 0.361685\n",
      "epoch 14; iter: 0; batch classifier loss: 0.383322; batch adversarial loss: 0.399400\n",
      "epoch 14; iter: 200; batch classifier loss: 0.279842; batch adversarial loss: 0.380214\n",
      "epoch 15; iter: 0; batch classifier loss: 0.400540; batch adversarial loss: 0.429255\n",
      "epoch 15; iter: 200; batch classifier loss: 0.367273; batch adversarial loss: 0.447625\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418905; batch adversarial loss: 0.377077\n",
      "epoch 16; iter: 200; batch classifier loss: 0.396794; batch adversarial loss: 0.460565\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373059; batch adversarial loss: 0.459027\n",
      "epoch 17; iter: 200; batch classifier loss: 0.421996; batch adversarial loss: 0.481155\n",
      "epoch 18; iter: 0; batch classifier loss: 0.377686; batch adversarial loss: 0.397825\n",
      "epoch 18; iter: 200; batch classifier loss: 0.348482; batch adversarial loss: 0.363041\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355986; batch adversarial loss: 0.400084\n",
      "epoch 19; iter: 200; batch classifier loss: 0.319012; batch adversarial loss: 0.494137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324805; batch adversarial loss: 0.429895\n",
      "epoch 20; iter: 200; batch classifier loss: 0.335165; batch adversarial loss: 0.333538\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263777; batch adversarial loss: 0.344943\n",
      "epoch 21; iter: 200; batch classifier loss: 0.416684; batch adversarial loss: 0.414462\n",
      "epoch 22; iter: 0; batch classifier loss: 0.340764; batch adversarial loss: 0.361135\n",
      "epoch 22; iter: 200; batch classifier loss: 0.357722; batch adversarial loss: 0.426487\n",
      "epoch 23; iter: 0; batch classifier loss: 0.323109; batch adversarial loss: 0.382071\n",
      "epoch 23; iter: 200; batch classifier loss: 0.385404; batch adversarial loss: 0.426515\n",
      "epoch 24; iter: 0; batch classifier loss: 0.347563; batch adversarial loss: 0.351490\n",
      "epoch 24; iter: 200; batch classifier loss: 0.286422; batch adversarial loss: 0.466670\n",
      "epoch 25; iter: 0; batch classifier loss: 0.357630; batch adversarial loss: 0.416180\n",
      "epoch 25; iter: 200; batch classifier loss: 0.330772; batch adversarial loss: 0.301675\n",
      "epoch 26; iter: 0; batch classifier loss: 0.314416; batch adversarial loss: 0.357461\n",
      "epoch 26; iter: 200; batch classifier loss: 0.315073; batch adversarial loss: 0.399578\n",
      "epoch 27; iter: 0; batch classifier loss: 0.358469; batch adversarial loss: 0.324773\n",
      "epoch 27; iter: 200; batch classifier loss: 0.472102; batch adversarial loss: 0.463840\n",
      "epoch 28; iter: 0; batch classifier loss: 0.384927; batch adversarial loss: 0.502002\n",
      "epoch 28; iter: 200; batch classifier loss: 0.262810; batch adversarial loss: 0.505275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436920; batch adversarial loss: 0.419497\n",
      "epoch 29; iter: 200; batch classifier loss: 0.314618; batch adversarial loss: 0.478086\n",
      "epoch 30; iter: 0; batch classifier loss: 0.286586; batch adversarial loss: 0.422567\n",
      "epoch 30; iter: 200; batch classifier loss: 0.399891; batch adversarial loss: 0.381852\n",
      "epoch 31; iter: 0; batch classifier loss: 0.362797; batch adversarial loss: 0.522180\n",
      "epoch 31; iter: 200; batch classifier loss: 0.331859; batch adversarial loss: 0.501331\n",
      "epoch 32; iter: 0; batch classifier loss: 0.371851; batch adversarial loss: 0.463189\n",
      "epoch 32; iter: 200; batch classifier loss: 0.320830; batch adversarial loss: 0.322077\n",
      "epoch 33; iter: 0; batch classifier loss: 0.357570; batch adversarial loss: 0.480518\n",
      "epoch 33; iter: 200; batch classifier loss: 0.314885; batch adversarial loss: 0.449664\n",
      "epoch 34; iter: 0; batch classifier loss: 0.291373; batch adversarial loss: 0.425630\n",
      "epoch 34; iter: 200; batch classifier loss: 0.337512; batch adversarial loss: 0.449925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.409768; batch adversarial loss: 0.381663\n",
      "epoch 35; iter: 200; batch classifier loss: 0.388049; batch adversarial loss: 0.305833\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280015; batch adversarial loss: 0.453542\n",
      "epoch 36; iter: 200; batch classifier loss: 0.411605; batch adversarial loss: 0.395735\n",
      "epoch 37; iter: 0; batch classifier loss: 0.308756; batch adversarial loss: 0.383425\n",
      "epoch 37; iter: 200; batch classifier loss: 0.360302; batch adversarial loss: 0.332053\n",
      "epoch 38; iter: 0; batch classifier loss: 0.304038; batch adversarial loss: 0.375672\n",
      "epoch 38; iter: 200; batch classifier loss: 0.360523; batch adversarial loss: 0.481672\n",
      "epoch 39; iter: 0; batch classifier loss: 0.296522; batch adversarial loss: 0.444696\n",
      "epoch 39; iter: 200; batch classifier loss: 0.260670; batch adversarial loss: 0.386529\n",
      "epoch 40; iter: 0; batch classifier loss: 0.305528; batch adversarial loss: 0.311607\n",
      "epoch 40; iter: 200; batch classifier loss: 0.387025; batch adversarial loss: 0.459893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.368527; batch adversarial loss: 0.511786\n",
      "epoch 41; iter: 200; batch classifier loss: 0.381771; batch adversarial loss: 0.453413\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405847; batch adversarial loss: 0.348952\n",
      "epoch 42; iter: 200; batch classifier loss: 0.329539; batch adversarial loss: 0.444814\n",
      "epoch 43; iter: 0; batch classifier loss: 0.373239; batch adversarial loss: 0.551094\n",
      "epoch 43; iter: 200; batch classifier loss: 0.363079; batch adversarial loss: 0.406681\n",
      "epoch 44; iter: 0; batch classifier loss: 0.380977; batch adversarial loss: 0.481419\n",
      "epoch 44; iter: 200; batch classifier loss: 0.433634; batch adversarial loss: 0.434142\n",
      "epoch 45; iter: 0; batch classifier loss: 0.310698; batch adversarial loss: 0.368294\n",
      "epoch 45; iter: 200; batch classifier loss: 0.520874; batch adversarial loss: 0.282672\n",
      "epoch 46; iter: 0; batch classifier loss: 0.334427; batch adversarial loss: 0.371732\n",
      "epoch 46; iter: 200; batch classifier loss: 0.304293; batch adversarial loss: 0.402163\n",
      "epoch 47; iter: 0; batch classifier loss: 0.419582; batch adversarial loss: 0.442561\n",
      "epoch 47; iter: 200; batch classifier loss: 0.297409; batch adversarial loss: 0.519718\n",
      "epoch 48; iter: 0; batch classifier loss: 0.368997; batch adversarial loss: 0.368373\n",
      "epoch 48; iter: 200; batch classifier loss: 0.473721; batch adversarial loss: 0.342818\n",
      "epoch 49; iter: 0; batch classifier loss: 0.337646; batch adversarial loss: 0.513381\n",
      "epoch 49; iter: 200; batch classifier loss: 0.381188; batch adversarial loss: 0.377160\n",
      "epoch 0; iter: 0; batch classifier loss: 9.778334; batch adversarial loss: 0.654614\n",
      "epoch 0; iter: 200; batch classifier loss: 43.121826; batch adversarial loss: 0.596262\n",
      "epoch 1; iter: 0; batch classifier loss: 13.886348; batch adversarial loss: 0.557386\n",
      "epoch 1; iter: 200; batch classifier loss: 3.199456; batch adversarial loss: 0.533756\n",
      "epoch 2; iter: 0; batch classifier loss: 10.064987; batch adversarial loss: 0.553413\n",
      "epoch 2; iter: 200; batch classifier loss: 4.167595; batch adversarial loss: 0.505131\n",
      "epoch 3; iter: 0; batch classifier loss: 3.193923; batch adversarial loss: 0.456182\n",
      "epoch 3; iter: 200; batch classifier loss: 5.322476; batch adversarial loss: 0.448091\n",
      "epoch 4; iter: 0; batch classifier loss: 5.113381; batch adversarial loss: 0.400117\n",
      "epoch 4; iter: 200; batch classifier loss: 3.184983; batch adversarial loss: 0.426264\n",
      "epoch 5; iter: 0; batch classifier loss: 1.249566; batch adversarial loss: 0.404259\n",
      "epoch 5; iter: 200; batch classifier loss: 1.528644; batch adversarial loss: 0.366591\n",
      "epoch 6; iter: 0; batch classifier loss: 0.905173; batch adversarial loss: 0.397115\n",
      "epoch 6; iter: 200; batch classifier loss: 4.339827; batch adversarial loss: 0.411915\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536620; batch adversarial loss: 0.448416\n",
      "epoch 7; iter: 200; batch classifier loss: 0.659794; batch adversarial loss: 0.454717\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521689; batch adversarial loss: 0.375202\n",
      "epoch 8; iter: 200; batch classifier loss: 0.506930; batch adversarial loss: 0.334711\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487257; batch adversarial loss: 0.465982\n",
      "epoch 9; iter: 200; batch classifier loss: 0.315402; batch adversarial loss: 0.432347\n",
      "epoch 10; iter: 0; batch classifier loss: 0.345773; batch adversarial loss: 0.400431\n",
      "epoch 10; iter: 200; batch classifier loss: 0.340095; batch adversarial loss: 0.407993\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343307; batch adversarial loss: 0.395388\n",
      "epoch 11; iter: 200; batch classifier loss: 0.291909; batch adversarial loss: 0.438122\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440301; batch adversarial loss: 0.391881\n",
      "epoch 12; iter: 200; batch classifier loss: 0.394937; batch adversarial loss: 0.344941\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491390; batch adversarial loss: 0.381698\n",
      "epoch 13; iter: 200; batch classifier loss: 0.412460; batch adversarial loss: 0.351701\n",
      "epoch 14; iter: 0; batch classifier loss: 0.398256; batch adversarial loss: 0.394813\n",
      "epoch 14; iter: 200; batch classifier loss: 0.418324; batch adversarial loss: 0.424237\n",
      "epoch 15; iter: 0; batch classifier loss: 0.357123; batch adversarial loss: 0.595001\n",
      "epoch 15; iter: 200; batch classifier loss: 0.407485; batch adversarial loss: 0.360939\n",
      "epoch 16; iter: 0; batch classifier loss: 0.373397; batch adversarial loss: 0.480824\n",
      "epoch 16; iter: 200; batch classifier loss: 0.401273; batch adversarial loss: 0.342338\n",
      "epoch 17; iter: 0; batch classifier loss: 0.369681; batch adversarial loss: 0.465911\n",
      "epoch 17; iter: 200; batch classifier loss: 0.242453; batch adversarial loss: 0.363367\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349080; batch adversarial loss: 0.328387\n",
      "epoch 18; iter: 200; batch classifier loss: 0.337104; batch adversarial loss: 0.417171\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501882; batch adversarial loss: 0.433183\n",
      "epoch 19; iter: 200; batch classifier loss: 0.318671; batch adversarial loss: 0.432237\n",
      "epoch 20; iter: 0; batch classifier loss: 0.372244; batch adversarial loss: 0.405906\n",
      "epoch 20; iter: 200; batch classifier loss: 0.366773; batch adversarial loss: 0.490065\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464069; batch adversarial loss: 0.402229\n",
      "epoch 21; iter: 200; batch classifier loss: 0.257006; batch adversarial loss: 0.457137\n",
      "epoch 22; iter: 0; batch classifier loss: 0.281169; batch adversarial loss: 0.355353\n",
      "epoch 22; iter: 200; batch classifier loss: 0.305572; batch adversarial loss: 0.504165\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313699; batch adversarial loss: 0.367526\n",
      "epoch 23; iter: 200; batch classifier loss: 0.347326; batch adversarial loss: 0.467219\n",
      "epoch 24; iter: 0; batch classifier loss: 0.322720; batch adversarial loss: 0.422006\n",
      "epoch 24; iter: 200; batch classifier loss: 0.345413; batch adversarial loss: 0.383869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.263825; batch adversarial loss: 0.427630\n",
      "epoch 25; iter: 200; batch classifier loss: 0.198821; batch adversarial loss: 0.439022\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319945; batch adversarial loss: 0.491078\n",
      "epoch 26; iter: 200; batch classifier loss: 0.307543; batch adversarial loss: 0.457741\n",
      "epoch 27; iter: 0; batch classifier loss: 0.378245; batch adversarial loss: 0.385702\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328363; batch adversarial loss: 0.446673\n",
      "epoch 28; iter: 0; batch classifier loss: 0.358764; batch adversarial loss: 0.369292\n",
      "epoch 28; iter: 200; batch classifier loss: 0.338920; batch adversarial loss: 0.381790\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406241; batch adversarial loss: 0.357935\n",
      "epoch 29; iter: 200; batch classifier loss: 0.432154; batch adversarial loss: 0.376546\n",
      "epoch 30; iter: 0; batch classifier loss: 0.332731; batch adversarial loss: 0.435728\n",
      "epoch 30; iter: 200; batch classifier loss: 0.320685; batch adversarial loss: 0.366529\n",
      "epoch 31; iter: 0; batch classifier loss: 0.253730; batch adversarial loss: 0.376829\n",
      "epoch 31; iter: 200; batch classifier loss: 0.337645; batch adversarial loss: 0.430083\n",
      "epoch 32; iter: 0; batch classifier loss: 0.317509; batch adversarial loss: 0.425905\n",
      "epoch 32; iter: 200; batch classifier loss: 0.411932; batch adversarial loss: 0.394558\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388454; batch adversarial loss: 0.403698\n",
      "epoch 33; iter: 200; batch classifier loss: 0.353967; batch adversarial loss: 0.373580\n",
      "epoch 34; iter: 0; batch classifier loss: 0.368872; batch adversarial loss: 0.354409\n",
      "epoch 34; iter: 200; batch classifier loss: 0.294795; batch adversarial loss: 0.450136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.384925; batch adversarial loss: 0.438300\n",
      "epoch 35; iter: 200; batch classifier loss: 0.311113; batch adversarial loss: 0.386405\n",
      "epoch 36; iter: 0; batch classifier loss: 0.386168; batch adversarial loss: 0.377716\n",
      "epoch 36; iter: 200; batch classifier loss: 0.397553; batch adversarial loss: 0.455709\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400140; batch adversarial loss: 0.459738\n",
      "epoch 37; iter: 200; batch classifier loss: 0.300401; batch adversarial loss: 0.446452\n",
      "epoch 38; iter: 0; batch classifier loss: 0.290306; batch adversarial loss: 0.526279\n",
      "epoch 38; iter: 200; batch classifier loss: 0.403465; batch adversarial loss: 0.387690\n",
      "epoch 39; iter: 0; batch classifier loss: 0.348217; batch adversarial loss: 0.340206\n",
      "epoch 39; iter: 200; batch classifier loss: 0.332410; batch adversarial loss: 0.419361\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413139; batch adversarial loss: 0.390232\n",
      "epoch 40; iter: 200; batch classifier loss: 0.304433; batch adversarial loss: 0.374015\n",
      "epoch 41; iter: 0; batch classifier loss: 0.285877; batch adversarial loss: 0.440422\n",
      "epoch 41; iter: 200; batch classifier loss: 0.336112; batch adversarial loss: 0.455483\n",
      "epoch 42; iter: 0; batch classifier loss: 0.340473; batch adversarial loss: 0.411921\n",
      "epoch 42; iter: 200; batch classifier loss: 0.326266; batch adversarial loss: 0.363553\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377071; batch adversarial loss: 0.330109\n",
      "epoch 43; iter: 200; batch classifier loss: 0.368105; batch adversarial loss: 0.406327\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402071; batch adversarial loss: 0.391399\n",
      "epoch 44; iter: 200; batch classifier loss: 0.456879; batch adversarial loss: 0.366963\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451972; batch adversarial loss: 0.437680\n",
      "epoch 45; iter: 200; batch classifier loss: 0.310249; batch adversarial loss: 0.403949\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356522; batch adversarial loss: 0.450958\n",
      "epoch 46; iter: 200; batch classifier loss: 0.340689; batch adversarial loss: 0.412082\n",
      "epoch 47; iter: 0; batch classifier loss: 0.279784; batch adversarial loss: 0.484401\n",
      "epoch 47; iter: 200; batch classifier loss: 0.365576; batch adversarial loss: 0.427412\n",
      "epoch 48; iter: 0; batch classifier loss: 0.274292; batch adversarial loss: 0.413182\n",
      "epoch 48; iter: 200; batch classifier loss: 0.311137; batch adversarial loss: 0.401531\n",
      "epoch 49; iter: 0; batch classifier loss: 0.356416; batch adversarial loss: 0.495155\n",
      "epoch 49; iter: 200; batch classifier loss: 0.587671; batch adversarial loss: 0.376393\n",
      "epoch 0; iter: 0; batch classifier loss: 18.047157; batch adversarial loss: 0.839340\n",
      "epoch 0; iter: 200; batch classifier loss: 3.881002; batch adversarial loss: 0.641321\n",
      "epoch 1; iter: 0; batch classifier loss: 11.539154; batch adversarial loss: 0.606030\n",
      "epoch 1; iter: 200; batch classifier loss: 5.571320; batch adversarial loss: 0.528540\n",
      "epoch 2; iter: 0; batch classifier loss: 1.979006; batch adversarial loss: 0.540943\n",
      "epoch 2; iter: 200; batch classifier loss: 12.070917; batch adversarial loss: 0.495256\n",
      "epoch 3; iter: 0; batch classifier loss: 9.091101; batch adversarial loss: 0.476517\n",
      "epoch 3; iter: 200; batch classifier loss: 3.328835; batch adversarial loss: 0.474618\n",
      "epoch 4; iter: 0; batch classifier loss: 2.450656; batch adversarial loss: 0.514135\n",
      "epoch 4; iter: 200; batch classifier loss: 1.671214; batch adversarial loss: 0.430535\n",
      "epoch 5; iter: 0; batch classifier loss: 1.900825; batch adversarial loss: 0.432113\n",
      "epoch 5; iter: 200; batch classifier loss: 0.619134; batch adversarial loss: 0.446075\n",
      "epoch 6; iter: 0; batch classifier loss: 0.959307; batch adversarial loss: 0.430719\n",
      "epoch 6; iter: 200; batch classifier loss: 0.778273; batch adversarial loss: 0.413398\n",
      "epoch 7; iter: 0; batch classifier loss: 0.483996; batch adversarial loss: 0.421626\n",
      "epoch 7; iter: 200; batch classifier loss: 0.448858; batch adversarial loss: 0.402658\n",
      "epoch 8; iter: 0; batch classifier loss: 0.969362; batch adversarial loss: 0.449088\n",
      "epoch 8; iter: 200; batch classifier loss: 0.529288; batch adversarial loss: 0.454565\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478580; batch adversarial loss: 0.501529\n",
      "epoch 9; iter: 200; batch classifier loss: 0.744744; batch adversarial loss: 0.451694\n",
      "epoch 10; iter: 0; batch classifier loss: 0.621485; batch adversarial loss: 0.415971\n",
      "epoch 10; iter: 200; batch classifier loss: 0.367095; batch adversarial loss: 0.488902\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489618; batch adversarial loss: 0.297386\n",
      "epoch 11; iter: 200; batch classifier loss: 0.401007; batch adversarial loss: 0.443485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.494891; batch adversarial loss: 0.360944\n",
      "epoch 12; iter: 200; batch classifier loss: 0.455760; batch adversarial loss: 0.346866\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369281; batch adversarial loss: 0.351748\n",
      "epoch 13; iter: 200; batch classifier loss: 0.376611; batch adversarial loss: 0.426198\n",
      "epoch 14; iter: 0; batch classifier loss: 0.375473; batch adversarial loss: 0.318828\n",
      "epoch 14; iter: 200; batch classifier loss: 0.359461; batch adversarial loss: 0.346717\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432152; batch adversarial loss: 0.336448\n",
      "epoch 15; iter: 200; batch classifier loss: 0.370305; batch adversarial loss: 0.374167\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332691; batch adversarial loss: 0.439141\n",
      "epoch 16; iter: 200; batch classifier loss: 0.421323; batch adversarial loss: 0.416978\n",
      "epoch 17; iter: 0; batch classifier loss: 0.388718; batch adversarial loss: 0.385679\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341958; batch adversarial loss: 0.398995\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366652; batch adversarial loss: 0.403545\n",
      "epoch 18; iter: 200; batch classifier loss: 0.385741; batch adversarial loss: 0.471776\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365273; batch adversarial loss: 0.367258\n",
      "epoch 19; iter: 200; batch classifier loss: 0.441306; batch adversarial loss: 0.451002\n",
      "epoch 20; iter: 0; batch classifier loss: 0.359202; batch adversarial loss: 0.287753\n",
      "epoch 20; iter: 200; batch classifier loss: 0.283492; batch adversarial loss: 0.349333\n",
      "epoch 21; iter: 0; batch classifier loss: 0.402553; batch adversarial loss: 0.395493\n",
      "epoch 21; iter: 200; batch classifier loss: 0.431900; batch adversarial loss: 0.369954\n",
      "epoch 22; iter: 0; batch classifier loss: 0.357221; batch adversarial loss: 0.394349\n",
      "epoch 22; iter: 200; batch classifier loss: 0.405018; batch adversarial loss: 0.515331\n",
      "epoch 23; iter: 0; batch classifier loss: 0.383605; batch adversarial loss: 0.383394\n",
      "epoch 23; iter: 200; batch classifier loss: 0.303489; batch adversarial loss: 0.377001\n",
      "epoch 24; iter: 0; batch classifier loss: 0.348582; batch adversarial loss: 0.377210\n",
      "epoch 24; iter: 200; batch classifier loss: 0.377131; batch adversarial loss: 0.469248\n",
      "epoch 25; iter: 0; batch classifier loss: 0.405043; batch adversarial loss: 0.381704\n",
      "epoch 25; iter: 200; batch classifier loss: 0.317198; batch adversarial loss: 0.349800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.272103; batch adversarial loss: 0.442636\n",
      "epoch 26; iter: 200; batch classifier loss: 0.374955; batch adversarial loss: 0.344248\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284533; batch adversarial loss: 0.361069\n",
      "epoch 27; iter: 200; batch classifier loss: 0.352854; batch adversarial loss: 0.461712\n",
      "epoch 28; iter: 0; batch classifier loss: 0.358960; batch adversarial loss: 0.418950\n",
      "epoch 28; iter: 200; batch classifier loss: 0.286418; batch adversarial loss: 0.486407\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315668; batch adversarial loss: 0.426375\n",
      "epoch 29; iter: 200; batch classifier loss: 0.275148; batch adversarial loss: 0.425159\n",
      "epoch 30; iter: 0; batch classifier loss: 0.312245; batch adversarial loss: 0.388005\n",
      "epoch 30; iter: 200; batch classifier loss: 0.323673; batch adversarial loss: 0.411472\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406161; batch adversarial loss: 0.431502\n",
      "epoch 31; iter: 200; batch classifier loss: 0.364382; batch adversarial loss: 0.328825\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441920; batch adversarial loss: 0.385722\n",
      "epoch 32; iter: 200; batch classifier loss: 0.293865; batch adversarial loss: 0.354405\n",
      "epoch 33; iter: 0; batch classifier loss: 0.348471; batch adversarial loss: 0.401462\n",
      "epoch 33; iter: 200; batch classifier loss: 0.419053; batch adversarial loss: 0.493033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.346858; batch adversarial loss: 0.494331\n",
      "epoch 34; iter: 200; batch classifier loss: 0.297254; batch adversarial loss: 0.352744\n",
      "epoch 35; iter: 0; batch classifier loss: 0.339720; batch adversarial loss: 0.442935\n",
      "epoch 35; iter: 200; batch classifier loss: 0.324446; batch adversarial loss: 0.554462\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397521; batch adversarial loss: 0.369466\n",
      "epoch 36; iter: 200; batch classifier loss: 0.358725; batch adversarial loss: 0.361381\n",
      "epoch 37; iter: 0; batch classifier loss: 0.369109; batch adversarial loss: 0.440444\n",
      "epoch 37; iter: 200; batch classifier loss: 0.274211; batch adversarial loss: 0.494285\n",
      "epoch 38; iter: 0; batch classifier loss: 0.310831; batch adversarial loss: 0.455404\n",
      "epoch 38; iter: 200; batch classifier loss: 0.336787; batch adversarial loss: 0.420435\n",
      "epoch 39; iter: 0; batch classifier loss: 0.302067; batch adversarial loss: 0.476769\n",
      "epoch 39; iter: 200; batch classifier loss: 0.334046; batch adversarial loss: 0.472341\n",
      "epoch 40; iter: 0; batch classifier loss: 0.328407; batch adversarial loss: 0.400289\n",
      "epoch 40; iter: 200; batch classifier loss: 0.253352; batch adversarial loss: 0.386357\n",
      "epoch 41; iter: 0; batch classifier loss: 0.362506; batch adversarial loss: 0.460664\n",
      "epoch 41; iter: 200; batch classifier loss: 0.347187; batch adversarial loss: 0.530252\n",
      "epoch 42; iter: 0; batch classifier loss: 0.349334; batch adversarial loss: 0.490822\n",
      "epoch 42; iter: 200; batch classifier loss: 0.311249; batch adversarial loss: 0.303007\n",
      "epoch 43; iter: 0; batch classifier loss: 0.367402; batch adversarial loss: 0.372260\n",
      "epoch 43; iter: 200; batch classifier loss: 0.279978; batch adversarial loss: 0.443612\n",
      "epoch 44; iter: 0; batch classifier loss: 0.326364; batch adversarial loss: 0.353074\n",
      "epoch 44; iter: 200; batch classifier loss: 0.442004; batch adversarial loss: 0.445396\n",
      "epoch 45; iter: 0; batch classifier loss: 0.360666; batch adversarial loss: 0.418795\n",
      "epoch 45; iter: 200; batch classifier loss: 0.345784; batch adversarial loss: 0.358835\n",
      "epoch 46; iter: 0; batch classifier loss: 0.294241; batch adversarial loss: 0.304705\n",
      "epoch 46; iter: 200; batch classifier loss: 0.319482; batch adversarial loss: 0.368399\n",
      "epoch 47; iter: 0; batch classifier loss: 0.314558; batch adversarial loss: 0.455177\n",
      "epoch 47; iter: 200; batch classifier loss: 0.297475; batch adversarial loss: 0.399549\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393843; batch adversarial loss: 0.467956\n",
      "epoch 48; iter: 200; batch classifier loss: 0.348672; batch adversarial loss: 0.454251\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394583; batch adversarial loss: 0.449841\n",
      "epoch 49; iter: 200; batch classifier loss: 0.285224; batch adversarial loss: 0.532002\n",
      "epoch 0; iter: 0; batch classifier loss: 103.565979; batch adversarial loss: 0.486941\n",
      "epoch 0; iter: 200; batch classifier loss: 5.148754; batch adversarial loss: 0.519617\n",
      "epoch 1; iter: 0; batch classifier loss: 2.616210; batch adversarial loss: 0.570352\n",
      "epoch 1; iter: 200; batch classifier loss: 7.966131; batch adversarial loss: 0.578620\n",
      "epoch 2; iter: 0; batch classifier loss: 10.709147; batch adversarial loss: 0.480097\n",
      "epoch 2; iter: 200; batch classifier loss: 3.817913; batch adversarial loss: 0.503207\n",
      "epoch 3; iter: 0; batch classifier loss: 2.660907; batch adversarial loss: 0.490547\n",
      "epoch 3; iter: 200; batch classifier loss: 3.138770; batch adversarial loss: 0.431093\n",
      "epoch 4; iter: 0; batch classifier loss: 1.828823; batch adversarial loss: 0.442369\n",
      "epoch 4; iter: 200; batch classifier loss: 2.190810; batch adversarial loss: 0.486425\n",
      "epoch 5; iter: 0; batch classifier loss: 1.265855; batch adversarial loss: 0.422730\n",
      "epoch 5; iter: 200; batch classifier loss: 1.705029; batch adversarial loss: 0.456305\n",
      "epoch 6; iter: 0; batch classifier loss: 1.719012; batch adversarial loss: 0.517172\n",
      "epoch 6; iter: 200; batch classifier loss: 1.032738; batch adversarial loss: 0.509852\n",
      "epoch 7; iter: 0; batch classifier loss: 0.821324; batch adversarial loss: 0.482989\n",
      "epoch 7; iter: 200; batch classifier loss: 0.685867; batch adversarial loss: 0.398769\n",
      "epoch 8; iter: 0; batch classifier loss: 0.664920; batch adversarial loss: 0.447552\n",
      "epoch 8; iter: 200; batch classifier loss: 0.470446; batch adversarial loss: 0.554753\n",
      "epoch 9; iter: 0; batch classifier loss: 0.639669; batch adversarial loss: 0.399000\n",
      "epoch 9; iter: 200; batch classifier loss: 0.544043; batch adversarial loss: 0.359699\n",
      "epoch 10; iter: 0; batch classifier loss: 0.621776; batch adversarial loss: 0.404581\n",
      "epoch 10; iter: 200; batch classifier loss: 0.426620; batch adversarial loss: 0.496811\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454257; batch adversarial loss: 0.374920\n",
      "epoch 11; iter: 200; batch classifier loss: 0.470677; batch adversarial loss: 0.458824\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578067; batch adversarial loss: 0.344982\n",
      "epoch 12; iter: 200; batch classifier loss: 0.382599; batch adversarial loss: 0.461457\n",
      "epoch 13; iter: 0; batch classifier loss: 0.608871; batch adversarial loss: 0.353989\n",
      "epoch 13; iter: 200; batch classifier loss: 0.488250; batch adversarial loss: 0.373831\n",
      "epoch 14; iter: 0; batch classifier loss: 0.530963; batch adversarial loss: 0.443013\n",
      "epoch 14; iter: 200; batch classifier loss: 0.359237; batch adversarial loss: 0.418989\n",
      "epoch 15; iter: 0; batch classifier loss: 0.296167; batch adversarial loss: 0.393228\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366548; batch adversarial loss: 0.405966\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350864; batch adversarial loss: 0.447368\n",
      "epoch 16; iter: 200; batch classifier loss: 0.457157; batch adversarial loss: 0.325945\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309189; batch adversarial loss: 0.368149\n",
      "epoch 17; iter: 200; batch classifier loss: 0.271195; batch adversarial loss: 0.441597\n",
      "epoch 18; iter: 0; batch classifier loss: 0.418970; batch adversarial loss: 0.456157\n",
      "epoch 18; iter: 200; batch classifier loss: 0.421172; batch adversarial loss: 0.537316\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374981; batch adversarial loss: 0.335913\n",
      "epoch 19; iter: 200; batch classifier loss: 0.244925; batch adversarial loss: 0.456527\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469070; batch adversarial loss: 0.263678\n",
      "epoch 20; iter: 200; batch classifier loss: 0.383941; batch adversarial loss: 0.348319\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311649; batch adversarial loss: 0.468648\n",
      "epoch 21; iter: 200; batch classifier loss: 0.322121; batch adversarial loss: 0.312705\n",
      "epoch 22; iter: 0; batch classifier loss: 0.336011; batch adversarial loss: 0.595361\n",
      "epoch 22; iter: 200; batch classifier loss: 0.239099; batch adversarial loss: 0.365670\n",
      "epoch 23; iter: 0; batch classifier loss: 0.364777; batch adversarial loss: 0.381658\n",
      "epoch 23; iter: 200; batch classifier loss: 0.373736; batch adversarial loss: 0.476288\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280857; batch adversarial loss: 0.387603\n",
      "epoch 24; iter: 200; batch classifier loss: 0.335041; batch adversarial loss: 0.396834\n",
      "epoch 25; iter: 0; batch classifier loss: 0.269793; batch adversarial loss: 0.378872\n",
      "epoch 25; iter: 200; batch classifier loss: 0.273858; batch adversarial loss: 0.371010\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356562; batch adversarial loss: 0.536164\n",
      "epoch 26; iter: 200; batch classifier loss: 0.323982; batch adversarial loss: 0.412602\n",
      "epoch 27; iter: 0; batch classifier loss: 0.384400; batch adversarial loss: 0.368669\n",
      "epoch 27; iter: 200; batch classifier loss: 0.355059; batch adversarial loss: 0.366634\n",
      "epoch 28; iter: 0; batch classifier loss: 0.357995; batch adversarial loss: 0.476851\n",
      "epoch 28; iter: 200; batch classifier loss: 0.344460; batch adversarial loss: 0.510921\n",
      "epoch 29; iter: 0; batch classifier loss: 0.354696; batch adversarial loss: 0.442823\n",
      "epoch 29; iter: 200; batch classifier loss: 0.329848; batch adversarial loss: 0.480233\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404830; batch adversarial loss: 0.361331\n",
      "epoch 30; iter: 200; batch classifier loss: 0.388629; batch adversarial loss: 0.385355\n",
      "epoch 31; iter: 0; batch classifier loss: 0.272942; batch adversarial loss: 0.396883\n",
      "epoch 31; iter: 200; batch classifier loss: 0.444441; batch adversarial loss: 0.291744\n",
      "epoch 32; iter: 0; batch classifier loss: 0.286914; batch adversarial loss: 0.410215\n",
      "epoch 32; iter: 200; batch classifier loss: 0.303621; batch adversarial loss: 0.487053\n",
      "epoch 33; iter: 0; batch classifier loss: 0.312814; batch adversarial loss: 0.428062\n",
      "epoch 33; iter: 200; batch classifier loss: 0.264339; batch adversarial loss: 0.325783\n",
      "epoch 34; iter: 0; batch classifier loss: 0.332838; batch adversarial loss: 0.400528\n",
      "epoch 34; iter: 200; batch classifier loss: 0.331232; batch adversarial loss: 0.358715\n",
      "epoch 35; iter: 0; batch classifier loss: 0.399284; batch adversarial loss: 0.381636\n",
      "epoch 35; iter: 200; batch classifier loss: 0.339644; batch adversarial loss: 0.387905\n",
      "epoch 36; iter: 0; batch classifier loss: 0.270558; batch adversarial loss: 0.399035\n",
      "epoch 36; iter: 200; batch classifier loss: 0.289524; batch adversarial loss: 0.458060\n",
      "epoch 37; iter: 0; batch classifier loss: 0.303698; batch adversarial loss: 0.434870\n",
      "epoch 37; iter: 200; batch classifier loss: 0.307699; batch adversarial loss: 0.450626\n",
      "epoch 38; iter: 0; batch classifier loss: 0.298685; batch adversarial loss: 0.433966\n",
      "epoch 38; iter: 200; batch classifier loss: 0.358827; batch adversarial loss: 0.386666\n",
      "epoch 39; iter: 0; batch classifier loss: 0.332175; batch adversarial loss: 0.310015\n",
      "epoch 39; iter: 200; batch classifier loss: 0.294215; batch adversarial loss: 0.372304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416551; batch adversarial loss: 0.350665\n",
      "epoch 40; iter: 200; batch classifier loss: 0.297649; batch adversarial loss: 0.388439\n",
      "epoch 41; iter: 0; batch classifier loss: 0.289494; batch adversarial loss: 0.378530\n",
      "epoch 41; iter: 200; batch classifier loss: 0.348198; batch adversarial loss: 0.402002\n",
      "epoch 42; iter: 0; batch classifier loss: 0.376900; batch adversarial loss: 0.514708\n",
      "epoch 42; iter: 200; batch classifier loss: 0.364748; batch adversarial loss: 0.515867\n",
      "epoch 43; iter: 0; batch classifier loss: 0.327031; batch adversarial loss: 0.468871\n",
      "epoch 43; iter: 200; batch classifier loss: 0.388125; batch adversarial loss: 0.397633\n",
      "epoch 44; iter: 0; batch classifier loss: 0.366196; batch adversarial loss: 0.418035\n",
      "epoch 44; iter: 200; batch classifier loss: 0.373090; batch adversarial loss: 0.399557\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407045; batch adversarial loss: 0.379456\n",
      "epoch 45; iter: 200; batch classifier loss: 0.498864; batch adversarial loss: 0.376883\n",
      "epoch 46; iter: 0; batch classifier loss: 0.503827; batch adversarial loss: 0.501009\n",
      "epoch 46; iter: 200; batch classifier loss: 0.399839; batch adversarial loss: 0.460257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424929; batch adversarial loss: 0.428976\n",
      "epoch 47; iter: 200; batch classifier loss: 0.544942; batch adversarial loss: 0.410360\n",
      "epoch 48; iter: 0; batch classifier loss: 0.396764; batch adversarial loss: 0.395496\n",
      "epoch 48; iter: 200; batch classifier loss: 0.425275; batch adversarial loss: 0.412645\n",
      "epoch 49; iter: 0; batch classifier loss: 0.440196; batch adversarial loss: 0.352837\n",
      "epoch 49; iter: 200; batch classifier loss: 0.424419; batch adversarial loss: 0.494407\n",
      "epoch 0; iter: 0; batch classifier loss: 18.520262; batch adversarial loss: 0.577013\n",
      "epoch 0; iter: 200; batch classifier loss: 7.224277; batch adversarial loss: 0.547975\n",
      "epoch 1; iter: 0; batch classifier loss: 0.767926; batch adversarial loss: 0.534184\n",
      "epoch 1; iter: 200; batch classifier loss: 1.157319; batch adversarial loss: 0.510695\n",
      "epoch 2; iter: 0; batch classifier loss: 4.597893; batch adversarial loss: 0.520447\n",
      "epoch 2; iter: 200; batch classifier loss: 4.900550; batch adversarial loss: 0.471202\n",
      "epoch 3; iter: 0; batch classifier loss: 0.997981; batch adversarial loss: 0.454867\n",
      "epoch 3; iter: 200; batch classifier loss: 1.476425; batch adversarial loss: 0.542307\n",
      "epoch 4; iter: 0; batch classifier loss: 1.053748; batch adversarial loss: 0.459369\n",
      "epoch 4; iter: 200; batch classifier loss: 2.245213; batch adversarial loss: 0.458277\n",
      "epoch 5; iter: 0; batch classifier loss: 1.700627; batch adversarial loss: 0.459005\n",
      "epoch 5; iter: 200; batch classifier loss: 1.896166; batch adversarial loss: 0.394830\n",
      "epoch 6; iter: 0; batch classifier loss: 1.192493; batch adversarial loss: 0.473463\n",
      "epoch 6; iter: 200; batch classifier loss: 0.788104; batch adversarial loss: 0.410235\n",
      "epoch 7; iter: 0; batch classifier loss: 0.759201; batch adversarial loss: 0.401366\n",
      "epoch 7; iter: 200; batch classifier loss: 0.519218; batch adversarial loss: 0.408331\n",
      "epoch 8; iter: 0; batch classifier loss: 1.512090; batch adversarial loss: 0.341233\n",
      "epoch 8; iter: 200; batch classifier loss: 0.909867; batch adversarial loss: 0.460984\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524594; batch adversarial loss: 0.381463\n",
      "epoch 9; iter: 200; batch classifier loss: 0.563132; batch adversarial loss: 0.393589\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446406; batch adversarial loss: 0.498174\n",
      "epoch 10; iter: 200; batch classifier loss: 0.398373; batch adversarial loss: 0.395164\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416148; batch adversarial loss: 0.391074\n",
      "epoch 11; iter: 200; batch classifier loss: 0.716249; batch adversarial loss: 0.417923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571640; batch adversarial loss: 0.416883\n",
      "epoch 12; iter: 200; batch classifier loss: 0.467732; batch adversarial loss: 0.471882\n",
      "epoch 13; iter: 0; batch classifier loss: 0.393895; batch adversarial loss: 0.471035\n",
      "epoch 13; iter: 200; batch classifier loss: 0.441154; batch adversarial loss: 0.463734\n",
      "epoch 14; iter: 0; batch classifier loss: 0.385015; batch adversarial loss: 0.440196\n",
      "epoch 14; iter: 200; batch classifier loss: 0.454530; batch adversarial loss: 0.370556\n",
      "epoch 15; iter: 0; batch classifier loss: 0.380653; batch adversarial loss: 0.383335\n",
      "epoch 15; iter: 200; batch classifier loss: 0.417116; batch adversarial loss: 0.370112\n",
      "epoch 16; iter: 0; batch classifier loss: 0.384232; batch adversarial loss: 0.360415\n",
      "epoch 16; iter: 200; batch classifier loss: 0.473037; batch adversarial loss: 0.322064\n",
      "epoch 17; iter: 0; batch classifier loss: 0.376980; batch adversarial loss: 0.429295\n",
      "epoch 17; iter: 200; batch classifier loss: 0.422815; batch adversarial loss: 0.435834\n",
      "epoch 18; iter: 0; batch classifier loss: 0.388984; batch adversarial loss: 0.392188\n",
      "epoch 18; iter: 200; batch classifier loss: 0.302650; batch adversarial loss: 0.442703\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325546; batch adversarial loss: 0.523960\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347133; batch adversarial loss: 0.408434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.351113; batch adversarial loss: 0.483373\n",
      "epoch 20; iter: 200; batch classifier loss: 0.350554; batch adversarial loss: 0.288884\n",
      "epoch 21; iter: 0; batch classifier loss: 0.349081; batch adversarial loss: 0.316706\n",
      "epoch 21; iter: 200; batch classifier loss: 0.403074; batch adversarial loss: 0.346334\n",
      "epoch 22; iter: 0; batch classifier loss: 0.281849; batch adversarial loss: 0.469324\n",
      "epoch 22; iter: 200; batch classifier loss: 0.337646; batch adversarial loss: 0.468055\n",
      "epoch 23; iter: 0; batch classifier loss: 0.338028; batch adversarial loss: 0.395376\n",
      "epoch 23; iter: 200; batch classifier loss: 0.438973; batch adversarial loss: 0.466338\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331160; batch adversarial loss: 0.394135\n",
      "epoch 24; iter: 200; batch classifier loss: 0.427216; batch adversarial loss: 0.351016\n",
      "epoch 25; iter: 0; batch classifier loss: 0.276339; batch adversarial loss: 0.465905\n",
      "epoch 25; iter: 200; batch classifier loss: 0.377377; batch adversarial loss: 0.399743\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338915; batch adversarial loss: 0.531247\n",
      "epoch 26; iter: 200; batch classifier loss: 0.364837; batch adversarial loss: 0.432151\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465808; batch adversarial loss: 0.303710\n",
      "epoch 27; iter: 200; batch classifier loss: 0.415577; batch adversarial loss: 0.419813\n",
      "epoch 28; iter: 0; batch classifier loss: 0.353179; batch adversarial loss: 0.428620\n",
      "epoch 28; iter: 200; batch classifier loss: 0.259522; batch adversarial loss: 0.370692\n",
      "epoch 29; iter: 0; batch classifier loss: 0.306671; batch adversarial loss: 0.355087\n",
      "epoch 29; iter: 200; batch classifier loss: 0.341833; batch adversarial loss: 0.468389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.346967; batch adversarial loss: 0.412333\n",
      "epoch 30; iter: 200; batch classifier loss: 0.223573; batch adversarial loss: 0.532743\n",
      "epoch 31; iter: 0; batch classifier loss: 0.326230; batch adversarial loss: 0.442083\n",
      "epoch 31; iter: 200; batch classifier loss: 0.337836; batch adversarial loss: 0.426658\n",
      "epoch 32; iter: 0; batch classifier loss: 0.333844; batch adversarial loss: 0.397850\n",
      "epoch 32; iter: 200; batch classifier loss: 0.367624; batch adversarial loss: 0.415746\n",
      "epoch 33; iter: 0; batch classifier loss: 0.273837; batch adversarial loss: 0.433021\n",
      "epoch 33; iter: 200; batch classifier loss: 0.264080; batch adversarial loss: 0.442641\n",
      "epoch 34; iter: 0; batch classifier loss: 0.302100; batch adversarial loss: 0.357404\n",
      "epoch 34; iter: 200; batch classifier loss: 0.357837; batch adversarial loss: 0.382628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.344686; batch adversarial loss: 0.448499\n",
      "epoch 35; iter: 200; batch classifier loss: 0.312998; batch adversarial loss: 0.399195\n",
      "epoch 36; iter: 0; batch classifier loss: 0.321237; batch adversarial loss: 0.367570\n",
      "epoch 36; iter: 200; batch classifier loss: 0.267757; batch adversarial loss: 0.405176\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421593; batch adversarial loss: 0.318229\n",
      "epoch 37; iter: 200; batch classifier loss: 0.399267; batch adversarial loss: 0.308090\n",
      "epoch 38; iter: 0; batch classifier loss: 0.421728; batch adversarial loss: 0.409802\n",
      "epoch 38; iter: 200; batch classifier loss: 0.288348; batch adversarial loss: 0.485811\n",
      "epoch 39; iter: 0; batch classifier loss: 0.332780; batch adversarial loss: 0.557633\n",
      "epoch 39; iter: 200; batch classifier loss: 0.446332; batch adversarial loss: 0.460223\n",
      "epoch 40; iter: 0; batch classifier loss: 0.469109; batch adversarial loss: 0.415649\n",
      "epoch 40; iter: 200; batch classifier loss: 0.488435; batch adversarial loss: 0.411888\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419809; batch adversarial loss: 0.492900\n",
      "epoch 41; iter: 200; batch classifier loss: 0.531750; batch adversarial loss: 0.316471\n",
      "epoch 42; iter: 0; batch classifier loss: 0.574028; batch adversarial loss: 0.382080\n",
      "epoch 42; iter: 200; batch classifier loss: 0.429778; batch adversarial loss: 0.419680\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397798; batch adversarial loss: 0.400740\n",
      "epoch 43; iter: 200; batch classifier loss: 0.434345; batch adversarial loss: 0.366302\n",
      "epoch 44; iter: 0; batch classifier loss: 0.492108; batch adversarial loss: 0.348349\n",
      "epoch 44; iter: 200; batch classifier loss: 0.432922; batch adversarial loss: 0.363528\n",
      "epoch 45; iter: 0; batch classifier loss: 0.380609; batch adversarial loss: 0.419784\n",
      "epoch 45; iter: 200; batch classifier loss: 0.532333; batch adversarial loss: 0.376761\n",
      "epoch 46; iter: 0; batch classifier loss: 0.418682; batch adversarial loss: 0.481521\n",
      "epoch 46; iter: 200; batch classifier loss: 0.497285; batch adversarial loss: 0.345314\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436383; batch adversarial loss: 0.334253\n",
      "epoch 47; iter: 200; batch classifier loss: 0.415263; batch adversarial loss: 0.416796\n",
      "epoch 48; iter: 0; batch classifier loss: 0.368014; batch adversarial loss: 0.497354\n",
      "epoch 48; iter: 200; batch classifier loss: 0.501252; batch adversarial loss: 0.457421\n",
      "epoch 49; iter: 0; batch classifier loss: 0.500085; batch adversarial loss: 0.403327\n",
      "epoch 49; iter: 200; batch classifier loss: 0.500642; batch adversarial loss: 0.402650\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.823466  0.533153 -0.002884  0.996126  0.119844  0.069477\n",
      "std   0.022549  0.090666  0.021924  0.151547  0.048525  0.029764\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate\n",
    "adult_race_metrics = pd.DataFrame(results)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62585541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/f4jl4tln3yn9fd_1yjrwwkp40000gn/T/ipykernel_80188/3087497998.py:6: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_title = 'Adult Inprocessing Adversial Debiasing: Baseline - Race'\n",
    "fig = compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', plot_title)\n",
    "fname    = plot_title.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "out_path = os.path.join(out_dir_plots, f'{fname}.png')\n",
    "fig.savefig(out_path)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fce3f2",
   "metadata": {},
   "source": [
    "## default adversial debiaser, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d433b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 21.102566; batch adversarial loss: 0.809936\n",
      "epoch 0; iter: 200; batch classifier loss: 0.916611; batch adversarial loss: 0.677311\n",
      "epoch 1; iter: 0; batch classifier loss: 2.508135; batch adversarial loss: 0.657597\n",
      "epoch 1; iter: 200; batch classifier loss: 3.177804; batch adversarial loss: 0.611946\n",
      "epoch 2; iter: 0; batch classifier loss: 1.186335; batch adversarial loss: 0.626295\n",
      "epoch 2; iter: 200; batch classifier loss: 9.130921; batch adversarial loss: 0.609920\n",
      "epoch 3; iter: 0; batch classifier loss: 3.458728; batch adversarial loss: 0.594239\n",
      "epoch 3; iter: 200; batch classifier loss: 1.344764; batch adversarial loss: 0.636964\n",
      "epoch 4; iter: 0; batch classifier loss: 3.495619; batch adversarial loss: 0.629476\n",
      "epoch 4; iter: 200; batch classifier loss: 3.673924; batch adversarial loss: 0.607659\n",
      "epoch 5; iter: 0; batch classifier loss: 1.948946; batch adversarial loss: 0.635383\n",
      "epoch 5; iter: 200; batch classifier loss: 1.636258; batch adversarial loss: 0.584541\n",
      "epoch 6; iter: 0; batch classifier loss: 1.042151; batch adversarial loss: 0.590100\n",
      "epoch 6; iter: 200; batch classifier loss: 1.215972; batch adversarial loss: 0.607988\n",
      "epoch 7; iter: 0; batch classifier loss: 0.814425; batch adversarial loss: 0.675947\n",
      "epoch 7; iter: 200; batch classifier loss: 0.524753; batch adversarial loss: 0.568745\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482352; batch adversarial loss: 0.621700\n",
      "epoch 8; iter: 200; batch classifier loss: 0.584018; batch adversarial loss: 0.582240\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546419; batch adversarial loss: 0.607850\n",
      "epoch 9; iter: 200; batch classifier loss: 0.558476; batch adversarial loss: 0.653601\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470514; batch adversarial loss: 0.603560\n",
      "epoch 10; iter: 200; batch classifier loss: 0.476464; batch adversarial loss: 0.618784\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361917; batch adversarial loss: 0.656209\n",
      "epoch 11; iter: 200; batch classifier loss: 0.465256; batch adversarial loss: 0.602481\n",
      "epoch 12; iter: 0; batch classifier loss: 0.395454; batch adversarial loss: 0.657802\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420022; batch adversarial loss: 0.599820\n",
      "epoch 13; iter: 0; batch classifier loss: 0.446164; batch adversarial loss: 0.632923\n",
      "epoch 13; iter: 200; batch classifier loss: 0.344072; batch adversarial loss: 0.652143\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384019; batch adversarial loss: 0.611719\n",
      "epoch 14; iter: 200; batch classifier loss: 0.402584; batch adversarial loss: 0.593132\n",
      "epoch 15; iter: 0; batch classifier loss: 0.414881; batch adversarial loss: 0.604568\n",
      "epoch 15; iter: 200; batch classifier loss: 0.436246; batch adversarial loss: 0.594158\n",
      "epoch 16; iter: 0; batch classifier loss: 0.474952; batch adversarial loss: 0.629551\n",
      "epoch 16; iter: 200; batch classifier loss: 0.344486; batch adversarial loss: 0.654349\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332071; batch adversarial loss: 0.671119\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364987; batch adversarial loss: 0.595716\n",
      "epoch 18; iter: 0; batch classifier loss: 0.373246; batch adversarial loss: 0.570229\n",
      "epoch 18; iter: 200; batch classifier loss: 0.318386; batch adversarial loss: 0.610981\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340250; batch adversarial loss: 0.577723\n",
      "epoch 19; iter: 200; batch classifier loss: 0.339976; batch adversarial loss: 0.590393\n",
      "epoch 20; iter: 0; batch classifier loss: 0.286874; batch adversarial loss: 0.613397\n",
      "epoch 20; iter: 200; batch classifier loss: 0.346996; batch adversarial loss: 0.631649\n",
      "epoch 21; iter: 0; batch classifier loss: 0.389948; batch adversarial loss: 0.624492\n",
      "epoch 21; iter: 200; batch classifier loss: 0.299640; batch adversarial loss: 0.620478\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262849; batch adversarial loss: 0.655096\n",
      "epoch 22; iter: 200; batch classifier loss: 0.367214; batch adversarial loss: 0.644784\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344658; batch adversarial loss: 0.733606\n",
      "epoch 23; iter: 200; batch classifier loss: 0.282844; batch adversarial loss: 0.598137\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338470; batch adversarial loss: 0.592577\n",
      "epoch 24; iter: 200; batch classifier loss: 0.440749; batch adversarial loss: 0.647348\n",
      "epoch 25; iter: 0; batch classifier loss: 0.368651; batch adversarial loss: 0.630182\n",
      "epoch 25; iter: 200; batch classifier loss: 0.410605; batch adversarial loss: 0.634167\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495360; batch adversarial loss: 0.589170\n",
      "epoch 26; iter: 200; batch classifier loss: 0.324802; batch adversarial loss: 0.635555\n",
      "epoch 27; iter: 0; batch classifier loss: 0.401669; batch adversarial loss: 0.582932\n",
      "epoch 27; iter: 200; batch classifier loss: 0.311292; batch adversarial loss: 0.585214\n",
      "epoch 28; iter: 0; batch classifier loss: 0.371485; batch adversarial loss: 0.548889\n",
      "epoch 28; iter: 200; batch classifier loss: 0.367379; batch adversarial loss: 0.600853\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338919; batch adversarial loss: 0.627706\n",
      "epoch 29; iter: 200; batch classifier loss: 0.386016; batch adversarial loss: 0.603138\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410739; batch adversarial loss: 0.653056\n",
      "epoch 30; iter: 200; batch classifier loss: 0.312433; batch adversarial loss: 0.638750\n",
      "epoch 31; iter: 0; batch classifier loss: 0.327290; batch adversarial loss: 0.641610\n",
      "epoch 31; iter: 200; batch classifier loss: 0.334742; batch adversarial loss: 0.608357\n",
      "epoch 32; iter: 0; batch classifier loss: 0.396854; batch adversarial loss: 0.677025\n",
      "epoch 32; iter: 200; batch classifier loss: 0.331902; batch adversarial loss: 0.595381\n",
      "epoch 33; iter: 0; batch classifier loss: 0.375441; batch adversarial loss: 0.590389\n",
      "epoch 33; iter: 200; batch classifier loss: 0.350749; batch adversarial loss: 0.619142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426944; batch adversarial loss: 0.609049\n",
      "epoch 34; iter: 200; batch classifier loss: 0.438342; batch adversarial loss: 0.702901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372327; batch adversarial loss: 0.647138\n",
      "epoch 35; iter: 200; batch classifier loss: 0.424407; batch adversarial loss: 0.603408\n",
      "epoch 36; iter: 0; batch classifier loss: 0.346932; batch adversarial loss: 0.584757\n",
      "epoch 36; iter: 200; batch classifier loss: 0.366931; batch adversarial loss: 0.564321\n",
      "epoch 37; iter: 0; batch classifier loss: 0.304922; batch adversarial loss: 0.616810\n",
      "epoch 37; iter: 200; batch classifier loss: 0.444725; batch adversarial loss: 0.588465\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406450; batch adversarial loss: 0.647768\n",
      "epoch 38; iter: 200; batch classifier loss: 0.314184; batch adversarial loss: 0.602403\n",
      "epoch 39; iter: 0; batch classifier loss: 0.691949; batch adversarial loss: 0.663513\n",
      "epoch 39; iter: 200; batch classifier loss: 0.379727; batch adversarial loss: 0.654069\n",
      "epoch 40; iter: 0; batch classifier loss: 0.496495; batch adversarial loss: 0.592387\n",
      "epoch 40; iter: 200; batch classifier loss: 0.613402; batch adversarial loss: 0.662329\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389889; batch adversarial loss: 0.652384\n",
      "epoch 41; iter: 200; batch classifier loss: 0.324114; batch adversarial loss: 0.611620\n",
      "epoch 42; iter: 0; batch classifier loss: 0.346528; batch adversarial loss: 0.591734\n",
      "epoch 42; iter: 200; batch classifier loss: 0.313841; batch adversarial loss: 0.661193\n",
      "epoch 43; iter: 0; batch classifier loss: 0.323784; batch adversarial loss: 0.620828\n",
      "epoch 43; iter: 200; batch classifier loss: 0.330708; batch adversarial loss: 0.656228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.331250; batch adversarial loss: 0.600833\n",
      "epoch 44; iter: 200; batch classifier loss: 0.365754; batch adversarial loss: 0.592097\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374713; batch adversarial loss: 0.618863\n",
      "epoch 45; iter: 200; batch classifier loss: 0.371791; batch adversarial loss: 0.599238\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394248; batch adversarial loss: 0.645739\n",
      "epoch 46; iter: 200; batch classifier loss: 0.323161; batch adversarial loss: 0.566470\n",
      "epoch 47; iter: 0; batch classifier loss: 0.296747; batch adversarial loss: 0.632101\n",
      "epoch 47; iter: 200; batch classifier loss: 0.604935; batch adversarial loss: 0.600458\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426328; batch adversarial loss: 0.657397\n",
      "epoch 48; iter: 200; batch classifier loss: 0.468354; batch adversarial loss: 0.609863\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407570; batch adversarial loss: 0.549900\n",
      "epoch 49; iter: 200; batch classifier loss: 0.461750; batch adversarial loss: 0.581644\n",
      "epoch 0; iter: 0; batch classifier loss: 88.637833; batch adversarial loss: 0.885274\n",
      "epoch 0; iter: 200; batch classifier loss: 12.859579; batch adversarial loss: 0.812128\n",
      "epoch 1; iter: 0; batch classifier loss: 12.059073; batch adversarial loss: 0.782879\n",
      "epoch 1; iter: 200; batch classifier loss: 7.893271; batch adversarial loss: 0.728019\n",
      "epoch 2; iter: 0; batch classifier loss: 4.244270; batch adversarial loss: 0.634786\n",
      "epoch 2; iter: 200; batch classifier loss: 2.228331; batch adversarial loss: 0.733293\n",
      "epoch 3; iter: 0; batch classifier loss: 1.746649; batch adversarial loss: 0.660408\n",
      "epoch 3; iter: 200; batch classifier loss: 2.906803; batch adversarial loss: 0.653709\n",
      "epoch 4; iter: 0; batch classifier loss: 3.504104; batch adversarial loss: 0.589026\n",
      "epoch 4; iter: 200; batch classifier loss: 1.351904; batch adversarial loss: 0.601571\n",
      "epoch 5; iter: 0; batch classifier loss: 4.128112; batch adversarial loss: 0.620833\n",
      "epoch 5; iter: 200; batch classifier loss: 1.176601; batch adversarial loss: 0.621090\n",
      "epoch 6; iter: 0; batch classifier loss: 0.900609; batch adversarial loss: 0.598678\n",
      "epoch 6; iter: 200; batch classifier loss: 0.993963; batch adversarial loss: 0.580820\n",
      "epoch 7; iter: 0; batch classifier loss: 0.669686; batch adversarial loss: 0.631100\n",
      "epoch 7; iter: 200; batch classifier loss: 0.368441; batch adversarial loss: 0.631754\n",
      "epoch 8; iter: 0; batch classifier loss: 0.690174; batch adversarial loss: 0.606271\n",
      "epoch 8; iter: 200; batch classifier loss: 0.618912; batch adversarial loss: 0.601643\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538467; batch adversarial loss: 0.569249\n",
      "epoch 9; iter: 200; batch classifier loss: 0.731625; batch adversarial loss: 0.628158\n",
      "epoch 10; iter: 0; batch classifier loss: 0.352685; batch adversarial loss: 0.645047\n",
      "epoch 10; iter: 200; batch classifier loss: 0.476719; batch adversarial loss: 0.589667\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548105; batch adversarial loss: 0.629881\n",
      "epoch 11; iter: 200; batch classifier loss: 0.401646; batch adversarial loss: 0.637197\n",
      "epoch 12; iter: 0; batch classifier loss: 0.387722; batch adversarial loss: 0.580986\n",
      "epoch 12; iter: 200; batch classifier loss: 0.465919; batch adversarial loss: 0.584985\n",
      "epoch 13; iter: 0; batch classifier loss: 0.406673; batch adversarial loss: 0.650640\n",
      "epoch 13; iter: 200; batch classifier loss: 0.564597; batch adversarial loss: 0.603985\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430397; batch adversarial loss: 0.587741\n",
      "epoch 14; iter: 200; batch classifier loss: 0.311645; batch adversarial loss: 0.610024\n",
      "epoch 15; iter: 0; batch classifier loss: 0.414319; batch adversarial loss: 0.542386\n",
      "epoch 15; iter: 200; batch classifier loss: 0.474850; batch adversarial loss: 0.574522\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404141; batch adversarial loss: 0.606729\n",
      "epoch 16; iter: 200; batch classifier loss: 0.410804; batch adversarial loss: 0.599963\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377143; batch adversarial loss: 0.636015\n",
      "epoch 17; iter: 200; batch classifier loss: 0.406391; batch adversarial loss: 0.559039\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284986; batch adversarial loss: 0.559661\n",
      "epoch 18; iter: 200; batch classifier loss: 0.398902; batch adversarial loss: 0.644394\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338794; batch adversarial loss: 0.626610\n",
      "epoch 19; iter: 200; batch classifier loss: 0.375573; batch adversarial loss: 0.679973\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333054; batch adversarial loss: 0.619228\n",
      "epoch 20; iter: 200; batch classifier loss: 0.347240; batch adversarial loss: 0.614601\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280346; batch adversarial loss: 0.611695\n",
      "epoch 21; iter: 200; batch classifier loss: 0.249025; batch adversarial loss: 0.600210\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361754; batch adversarial loss: 0.609061\n",
      "epoch 22; iter: 200; batch classifier loss: 0.333824; batch adversarial loss: 0.629059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342890; batch adversarial loss: 0.586229\n",
      "epoch 23; iter: 200; batch classifier loss: 0.321213; batch adversarial loss: 0.698785\n",
      "epoch 24; iter: 0; batch classifier loss: 0.346476; batch adversarial loss: 0.577957\n",
      "epoch 24; iter: 200; batch classifier loss: 0.342148; batch adversarial loss: 0.632198\n",
      "epoch 25; iter: 0; batch classifier loss: 0.386747; batch adversarial loss: 0.564997\n",
      "epoch 25; iter: 200; batch classifier loss: 0.330037; batch adversarial loss: 0.567993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303464; batch adversarial loss: 0.590715\n",
      "epoch 26; iter: 200; batch classifier loss: 0.270870; batch adversarial loss: 0.650397\n",
      "epoch 27; iter: 0; batch classifier loss: 0.288982; batch adversarial loss: 0.605625\n",
      "epoch 27; iter: 200; batch classifier loss: 0.287179; batch adversarial loss: 0.596421\n",
      "epoch 28; iter: 0; batch classifier loss: 0.354529; batch adversarial loss: 0.619546\n",
      "epoch 28; iter: 200; batch classifier loss: 0.357893; batch adversarial loss: 0.616644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303721; batch adversarial loss: 0.683372\n",
      "epoch 29; iter: 200; batch classifier loss: 0.305367; batch adversarial loss: 0.637421\n",
      "epoch 30; iter: 0; batch classifier loss: 0.335799; batch adversarial loss: 0.695240\n",
      "epoch 30; iter: 200; batch classifier loss: 0.346846; batch adversarial loss: 0.680017\n",
      "epoch 31; iter: 0; batch classifier loss: 0.313241; batch adversarial loss: 0.652696\n",
      "epoch 31; iter: 200; batch classifier loss: 0.285029; batch adversarial loss: 0.654115\n",
      "epoch 32; iter: 0; batch classifier loss: 0.281539; batch adversarial loss: 0.586092\n",
      "epoch 32; iter: 200; batch classifier loss: 0.303103; batch adversarial loss: 0.602290\n",
      "epoch 33; iter: 0; batch classifier loss: 0.316548; batch adversarial loss: 0.601473\n",
      "epoch 33; iter: 200; batch classifier loss: 0.283143; batch adversarial loss: 0.613191\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363031; batch adversarial loss: 0.590014\n",
      "epoch 34; iter: 200; batch classifier loss: 0.351447; batch adversarial loss: 0.619055\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404996; batch adversarial loss: 0.659005\n",
      "epoch 35; iter: 200; batch classifier loss: 0.398989; batch adversarial loss: 0.598441\n",
      "epoch 36; iter: 0; batch classifier loss: 0.337356; batch adversarial loss: 0.632949\n",
      "epoch 36; iter: 200; batch classifier loss: 0.293943; batch adversarial loss: 0.610837\n",
      "epoch 37; iter: 0; batch classifier loss: 0.311232; batch adversarial loss: 0.622440\n",
      "epoch 37; iter: 200; batch classifier loss: 0.342057; batch adversarial loss: 0.623141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340094; batch adversarial loss: 0.610525\n",
      "epoch 38; iter: 200; batch classifier loss: 0.354725; batch adversarial loss: 0.566791\n",
      "epoch 39; iter: 0; batch classifier loss: 0.346386; batch adversarial loss: 0.626048\n",
      "epoch 39; iter: 200; batch classifier loss: 0.407758; batch adversarial loss: 0.656199\n",
      "epoch 40; iter: 0; batch classifier loss: 0.319389; batch adversarial loss: 0.635322\n",
      "epoch 40; iter: 200; batch classifier loss: 0.294178; batch adversarial loss: 0.620633\n",
      "epoch 41; iter: 0; batch classifier loss: 0.288626; batch adversarial loss: 0.617171\n",
      "epoch 41; iter: 200; batch classifier loss: 0.401327; batch adversarial loss: 0.599215\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418729; batch adversarial loss: 0.662645\n",
      "epoch 42; iter: 200; batch classifier loss: 0.282628; batch adversarial loss: 0.653120\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362957; batch adversarial loss: 0.668531\n",
      "epoch 43; iter: 200; batch classifier loss: 0.270163; batch adversarial loss: 0.564737\n",
      "epoch 44; iter: 0; batch classifier loss: 0.308586; batch adversarial loss: 0.597255\n",
      "epoch 44; iter: 200; batch classifier loss: 0.414255; batch adversarial loss: 0.595992\n",
      "epoch 45; iter: 0; batch classifier loss: 0.328948; batch adversarial loss: 0.571046\n",
      "epoch 45; iter: 200; batch classifier loss: 0.372602; batch adversarial loss: 0.605062\n",
      "epoch 46; iter: 0; batch classifier loss: 0.314280; batch adversarial loss: 0.605402\n",
      "epoch 46; iter: 200; batch classifier loss: 0.356033; batch adversarial loss: 0.527565\n",
      "epoch 47; iter: 0; batch classifier loss: 0.329943; batch adversarial loss: 0.573383\n",
      "epoch 47; iter: 200; batch classifier loss: 0.322364; batch adversarial loss: 0.650230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.286248; batch adversarial loss: 0.618432\n",
      "epoch 48; iter: 200; batch classifier loss: 0.295388; batch adversarial loss: 0.533938\n",
      "epoch 49; iter: 0; batch classifier loss: 0.373822; batch adversarial loss: 0.630709\n",
      "epoch 49; iter: 200; batch classifier loss: 0.303673; batch adversarial loss: 0.655928\n",
      "epoch 0; iter: 0; batch classifier loss: 172.395081; batch adversarial loss: 0.733379\n",
      "epoch 0; iter: 200; batch classifier loss: 3.698165; batch adversarial loss: 0.680376\n",
      "epoch 1; iter: 0; batch classifier loss: 10.385983; batch adversarial loss: 0.680192\n",
      "epoch 1; iter: 200; batch classifier loss: 3.487457; batch adversarial loss: 0.635317\n",
      "epoch 2; iter: 0; batch classifier loss: 4.062231; batch adversarial loss: 0.647182\n",
      "epoch 2; iter: 200; batch classifier loss: 6.476583; batch adversarial loss: 0.639331\n",
      "epoch 3; iter: 0; batch classifier loss: 4.466136; batch adversarial loss: 0.555842\n",
      "epoch 3; iter: 200; batch classifier loss: 2.910137; batch adversarial loss: 0.623539\n",
      "epoch 4; iter: 0; batch classifier loss: 1.595480; batch adversarial loss: 0.613912\n",
      "epoch 4; iter: 200; batch classifier loss: 2.197903; batch adversarial loss: 0.604908\n",
      "epoch 5; iter: 0; batch classifier loss: 1.538564; batch adversarial loss: 0.657120\n",
      "epoch 5; iter: 200; batch classifier loss: 1.309081; batch adversarial loss: 0.571482\n",
      "epoch 6; iter: 0; batch classifier loss: 1.224290; batch adversarial loss: 0.644040\n",
      "epoch 6; iter: 200; batch classifier loss: 1.088510; batch adversarial loss: 0.609240\n",
      "epoch 7; iter: 0; batch classifier loss: 0.622539; batch adversarial loss: 0.656420\n",
      "epoch 7; iter: 200; batch classifier loss: 0.927096; batch adversarial loss: 0.612030\n",
      "epoch 8; iter: 0; batch classifier loss: 1.269454; batch adversarial loss: 0.695900\n",
      "epoch 8; iter: 200; batch classifier loss: 0.391078; batch adversarial loss: 0.563991\n",
      "epoch 9; iter: 0; batch classifier loss: 1.197938; batch adversarial loss: 0.647370\n",
      "epoch 9; iter: 200; batch classifier loss: 0.562102; batch adversarial loss: 0.676418\n",
      "epoch 10; iter: 0; batch classifier loss: 0.475213; batch adversarial loss: 0.600480\n",
      "epoch 10; iter: 200; batch classifier loss: 0.432392; batch adversarial loss: 0.625935\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389294; batch adversarial loss: 0.622220\n",
      "epoch 11; iter: 200; batch classifier loss: 0.401902; batch adversarial loss: 0.659693\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333538; batch adversarial loss: 0.555452\n",
      "epoch 12; iter: 200; batch classifier loss: 0.349235; batch adversarial loss: 0.647585\n",
      "epoch 13; iter: 0; batch classifier loss: 0.409784; batch adversarial loss: 0.665465\n",
      "epoch 13; iter: 200; batch classifier loss: 0.296600; batch adversarial loss: 0.634939\n",
      "epoch 14; iter: 0; batch classifier loss: 0.451020; batch adversarial loss: 0.615784\n",
      "epoch 14; iter: 200; batch classifier loss: 0.373118; batch adversarial loss: 0.618337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.399030; batch adversarial loss: 0.631183\n",
      "epoch 15; iter: 200; batch classifier loss: 0.362912; batch adversarial loss: 0.606753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352764; batch adversarial loss: 0.702505\n",
      "epoch 16; iter: 200; batch classifier loss: 0.423739; batch adversarial loss: 0.644454\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453578; batch adversarial loss: 0.664056\n",
      "epoch 17; iter: 200; batch classifier loss: 0.333765; batch adversarial loss: 0.638340\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282027; batch adversarial loss: 0.626446\n",
      "epoch 18; iter: 200; batch classifier loss: 0.272604; batch adversarial loss: 0.590665\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354843; batch adversarial loss: 0.658363\n",
      "epoch 19; iter: 200; batch classifier loss: 0.380163; batch adversarial loss: 0.614673\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337242; batch adversarial loss: 0.605429\n",
      "epoch 20; iter: 200; batch classifier loss: 0.469604; batch adversarial loss: 0.630284\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336886; batch adversarial loss: 0.599710\n",
      "epoch 21; iter: 200; batch classifier loss: 0.383569; batch adversarial loss: 0.614228\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481604; batch adversarial loss: 0.654461\n",
      "epoch 22; iter: 200; batch classifier loss: 0.353669; batch adversarial loss: 0.591801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.388879; batch adversarial loss: 0.591407\n",
      "epoch 23; iter: 200; batch classifier loss: 0.280798; batch adversarial loss: 0.608561\n",
      "epoch 24; iter: 0; batch classifier loss: 0.255915; batch adversarial loss: 0.604562\n",
      "epoch 24; iter: 200; batch classifier loss: 0.374986; batch adversarial loss: 0.647397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.354213; batch adversarial loss: 0.607840\n",
      "epoch 25; iter: 200; batch classifier loss: 0.423713; batch adversarial loss: 0.621409\n",
      "epoch 26; iter: 0; batch classifier loss: 0.260714; batch adversarial loss: 0.605440\n",
      "epoch 26; iter: 200; batch classifier loss: 0.391665; batch adversarial loss: 0.600765\n",
      "epoch 27; iter: 0; batch classifier loss: 0.316560; batch adversarial loss: 0.643379\n",
      "epoch 27; iter: 200; batch classifier loss: 0.321759; batch adversarial loss: 0.671351\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351989; batch adversarial loss: 0.621795\n",
      "epoch 28; iter: 200; batch classifier loss: 0.349241; batch adversarial loss: 0.601785\n",
      "epoch 29; iter: 0; batch classifier loss: 0.359563; batch adversarial loss: 0.632044\n",
      "epoch 29; iter: 200; batch classifier loss: 0.279320; batch adversarial loss: 0.588507\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323226; batch adversarial loss: 0.688568\n",
      "epoch 30; iter: 200; batch classifier loss: 0.346132; batch adversarial loss: 0.633285\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406660; batch adversarial loss: 0.589005\n",
      "epoch 31; iter: 200; batch classifier loss: 0.363421; batch adversarial loss: 0.705034\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410888; batch adversarial loss: 0.619751\n",
      "epoch 32; iter: 200; batch classifier loss: 0.350113; batch adversarial loss: 0.643085\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346437; batch adversarial loss: 0.613357\n",
      "epoch 33; iter: 200; batch classifier loss: 0.437812; batch adversarial loss: 0.607408\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398256; batch adversarial loss: 0.573871\n",
      "epoch 34; iter: 200; batch classifier loss: 0.289426; batch adversarial loss: 0.628928\n",
      "epoch 35; iter: 0; batch classifier loss: 0.343312; batch adversarial loss: 0.610374\n",
      "epoch 35; iter: 200; batch classifier loss: 0.291802; batch adversarial loss: 0.641232\n",
      "epoch 36; iter: 0; batch classifier loss: 0.363792; batch adversarial loss: 0.599242\n",
      "epoch 36; iter: 200; batch classifier loss: 0.500439; batch adversarial loss: 0.652887\n",
      "epoch 37; iter: 0; batch classifier loss: 0.331802; batch adversarial loss: 0.627875\n",
      "epoch 37; iter: 200; batch classifier loss: 0.330718; batch adversarial loss: 0.657426\n",
      "epoch 38; iter: 0; batch classifier loss: 0.250657; batch adversarial loss: 0.658487\n",
      "epoch 38; iter: 200; batch classifier loss: 0.385218; batch adversarial loss: 0.576372\n",
      "epoch 39; iter: 0; batch classifier loss: 0.321378; batch adversarial loss: 0.616440\n",
      "epoch 39; iter: 200; batch classifier loss: 0.376952; batch adversarial loss: 0.682136\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420588; batch adversarial loss: 0.593697\n",
      "epoch 40; iter: 200; batch classifier loss: 0.344271; batch adversarial loss: 0.591909\n",
      "epoch 41; iter: 0; batch classifier loss: 0.332375; batch adversarial loss: 0.654101\n",
      "epoch 41; iter: 200; batch classifier loss: 0.457338; batch adversarial loss: 0.660782\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299773; batch adversarial loss: 0.550063\n",
      "epoch 42; iter: 200; batch classifier loss: 0.368259; batch adversarial loss: 0.603200\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380308; batch adversarial loss: 0.604711\n",
      "epoch 43; iter: 200; batch classifier loss: 0.322281; batch adversarial loss: 0.627776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.427420; batch adversarial loss: 0.638312\n",
      "epoch 44; iter: 200; batch classifier loss: 0.362827; batch adversarial loss: 0.563371\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289097; batch adversarial loss: 0.629694\n",
      "epoch 45; iter: 200; batch classifier loss: 0.373555; batch adversarial loss: 0.606033\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331534; batch adversarial loss: 0.646915\n",
      "epoch 46; iter: 200; batch classifier loss: 0.319264; batch adversarial loss: 0.562025\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407953; batch adversarial loss: 0.611272\n",
      "epoch 47; iter: 200; batch classifier loss: 0.452550; batch adversarial loss: 0.647915\n",
      "epoch 48; iter: 0; batch classifier loss: 0.281640; batch adversarial loss: 0.637053\n",
      "epoch 48; iter: 200; batch classifier loss: 0.453426; batch adversarial loss: 0.597442\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403147; batch adversarial loss: 0.619577\n",
      "epoch 49; iter: 200; batch classifier loss: 0.354243; batch adversarial loss: 0.617634\n",
      "epoch 0; iter: 0; batch classifier loss: 10.400563; batch adversarial loss: 0.747248\n",
      "epoch 0; iter: 200; batch classifier loss: 10.351541; batch adversarial loss: 0.686044\n",
      "epoch 1; iter: 0; batch classifier loss: 5.521062; batch adversarial loss: 0.669612\n",
      "epoch 1; iter: 200; batch classifier loss: 4.764025; batch adversarial loss: 0.641053\n",
      "epoch 2; iter: 0; batch classifier loss: 12.294146; batch adversarial loss: 0.681227\n",
      "epoch 2; iter: 200; batch classifier loss: 5.835129; batch adversarial loss: 0.609740\n",
      "epoch 3; iter: 0; batch classifier loss: 2.938004; batch adversarial loss: 0.657478\n",
      "epoch 3; iter: 200; batch classifier loss: 0.862210; batch adversarial loss: 0.612875\n",
      "epoch 4; iter: 0; batch classifier loss: 7.196097; batch adversarial loss: 0.609838\n",
      "epoch 4; iter: 200; batch classifier loss: 1.300488; batch adversarial loss: 0.619469\n",
      "epoch 5; iter: 0; batch classifier loss: 5.617136; batch adversarial loss: 0.634507\n",
      "epoch 5; iter: 200; batch classifier loss: 1.080638; batch adversarial loss: 0.634615\n",
      "epoch 6; iter: 0; batch classifier loss: 0.877852; batch adversarial loss: 0.556357\n",
      "epoch 6; iter: 200; batch classifier loss: 0.701187; batch adversarial loss: 0.563796\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538574; batch adversarial loss: 0.628855\n",
      "epoch 7; iter: 200; batch classifier loss: 0.830209; batch adversarial loss: 0.565153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.734494; batch adversarial loss: 0.665927\n",
      "epoch 8; iter: 200; batch classifier loss: 0.455607; batch adversarial loss: 0.569112\n",
      "epoch 9; iter: 0; batch classifier loss: 0.451288; batch adversarial loss: 0.666189\n",
      "epoch 9; iter: 200; batch classifier loss: 0.503294; batch adversarial loss: 0.600164\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498179; batch adversarial loss: 0.672187\n",
      "epoch 10; iter: 200; batch classifier loss: 0.494752; batch adversarial loss: 0.603268\n",
      "epoch 11; iter: 0; batch classifier loss: 0.733163; batch adversarial loss: 0.601172\n",
      "epoch 11; iter: 200; batch classifier loss: 0.387177; batch adversarial loss: 0.630277\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469819; batch adversarial loss: 0.566761\n",
      "epoch 12; iter: 200; batch classifier loss: 0.457047; batch adversarial loss: 0.634082\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430516; batch adversarial loss: 0.553526\n",
      "epoch 13; iter: 200; batch classifier loss: 0.331289; batch adversarial loss: 0.588965\n",
      "epoch 14; iter: 0; batch classifier loss: 0.232951; batch adversarial loss: 0.651939\n",
      "epoch 14; iter: 200; batch classifier loss: 0.329687; batch adversarial loss: 0.638389\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465383; batch adversarial loss: 0.657220\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387883; batch adversarial loss: 0.578394\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391572; batch adversarial loss: 0.616785\n",
      "epoch 16; iter: 200; batch classifier loss: 0.452666; batch adversarial loss: 0.559294\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330793; batch adversarial loss: 0.683978\n",
      "epoch 17; iter: 200; batch classifier loss: 0.398085; batch adversarial loss: 0.633480\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361173; batch adversarial loss: 0.576263\n",
      "epoch 18; iter: 200; batch classifier loss: 0.340483; batch adversarial loss: 0.604188\n",
      "epoch 19; iter: 0; batch classifier loss: 0.395433; batch adversarial loss: 0.602885\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316542; batch adversarial loss: 0.648412\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314426; batch adversarial loss: 0.601986\n",
      "epoch 20; iter: 200; batch classifier loss: 0.326236; batch adversarial loss: 0.610522\n",
      "epoch 21; iter: 0; batch classifier loss: 0.316820; batch adversarial loss: 0.570017\n",
      "epoch 21; iter: 200; batch classifier loss: 0.314037; batch adversarial loss: 0.638004\n",
      "epoch 22; iter: 0; batch classifier loss: 0.375775; batch adversarial loss: 0.610720\n",
      "epoch 22; iter: 200; batch classifier loss: 0.351782; batch adversarial loss: 0.601076\n",
      "epoch 23; iter: 0; batch classifier loss: 0.416453; batch adversarial loss: 0.612816\n",
      "epoch 23; iter: 200; batch classifier loss: 0.323050; batch adversarial loss: 0.612636\n",
      "epoch 24; iter: 0; batch classifier loss: 0.345539; batch adversarial loss: 0.628662\n",
      "epoch 24; iter: 200; batch classifier loss: 0.324079; batch adversarial loss: 0.667559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.345206; batch adversarial loss: 0.572289\n",
      "epoch 25; iter: 200; batch classifier loss: 0.455346; batch adversarial loss: 0.618838\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366490; batch adversarial loss: 0.654384\n",
      "epoch 26; iter: 200; batch classifier loss: 0.473716; batch adversarial loss: 0.592896\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436017; batch adversarial loss: 0.603247\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328053; batch adversarial loss: 0.631704\n",
      "epoch 28; iter: 0; batch classifier loss: 0.349065; batch adversarial loss: 0.629103\n",
      "epoch 28; iter: 200; batch classifier loss: 0.387706; batch adversarial loss: 0.595292\n",
      "epoch 29; iter: 0; batch classifier loss: 0.339032; batch adversarial loss: 0.615768\n",
      "epoch 29; iter: 200; batch classifier loss: 0.337751; batch adversarial loss: 0.621681\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378842; batch adversarial loss: 0.581645\n",
      "epoch 30; iter: 200; batch classifier loss: 0.378318; batch adversarial loss: 0.555226\n",
      "epoch 31; iter: 0; batch classifier loss: 0.384976; batch adversarial loss: 0.648201\n",
      "epoch 31; iter: 200; batch classifier loss: 0.317515; batch adversarial loss: 0.593082\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348118; batch adversarial loss: 0.626634\n",
      "epoch 32; iter: 200; batch classifier loss: 0.306635; batch adversarial loss: 0.606644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363302; batch adversarial loss: 0.611401\n",
      "epoch 33; iter: 200; batch classifier loss: 0.333692; batch adversarial loss: 0.647518\n",
      "epoch 34; iter: 0; batch classifier loss: 0.377991; batch adversarial loss: 0.606125\n",
      "epoch 34; iter: 200; batch classifier loss: 0.434105; batch adversarial loss: 0.595317\n",
      "epoch 35; iter: 0; batch classifier loss: 0.300167; batch adversarial loss: 0.602779\n",
      "epoch 35; iter: 200; batch classifier loss: 0.361508; batch adversarial loss: 0.608621\n",
      "epoch 36; iter: 0; batch classifier loss: 0.253535; batch adversarial loss: 0.622772\n",
      "epoch 36; iter: 200; batch classifier loss: 0.321719; batch adversarial loss: 0.611825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495894; batch adversarial loss: 0.637061\n",
      "epoch 37; iter: 200; batch classifier loss: 0.421164; batch adversarial loss: 0.644230\n",
      "epoch 38; iter: 0; batch classifier loss: 0.289123; batch adversarial loss: 0.687224\n",
      "epoch 38; iter: 200; batch classifier loss: 0.420241; batch adversarial loss: 0.635152\n",
      "epoch 39; iter: 0; batch classifier loss: 0.271476; batch adversarial loss: 0.690299\n",
      "epoch 39; iter: 200; batch classifier loss: 0.497511; batch adversarial loss: 0.608905\n",
      "epoch 40; iter: 0; batch classifier loss: 0.324482; batch adversarial loss: 0.574542\n",
      "epoch 40; iter: 200; batch classifier loss: 0.309238; batch adversarial loss: 0.657459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.342807; batch adversarial loss: 0.605088\n",
      "epoch 41; iter: 200; batch classifier loss: 0.387131; batch adversarial loss: 0.642230\n",
      "epoch 42; iter: 0; batch classifier loss: 0.335339; batch adversarial loss: 0.668619\n",
      "epoch 42; iter: 200; batch classifier loss: 0.401545; batch adversarial loss: 0.636817\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432682; batch adversarial loss: 0.564814\n",
      "epoch 43; iter: 200; batch classifier loss: 0.325482; batch adversarial loss: 0.662168\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499590; batch adversarial loss: 0.574459\n",
      "epoch 44; iter: 200; batch classifier loss: 0.390487; batch adversarial loss: 0.631352\n",
      "epoch 45; iter: 0; batch classifier loss: 0.346997; batch adversarial loss: 0.679974\n",
      "epoch 45; iter: 200; batch classifier loss: 0.354054; batch adversarial loss: 0.623607\n",
      "epoch 46; iter: 0; batch classifier loss: 0.352412; batch adversarial loss: 0.621935\n",
      "epoch 46; iter: 200; batch classifier loss: 0.422634; batch adversarial loss: 0.585106\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370893; batch adversarial loss: 0.631603\n",
      "epoch 47; iter: 200; batch classifier loss: 0.369026; batch adversarial loss: 0.592807\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468103; batch adversarial loss: 0.579356\n",
      "epoch 48; iter: 200; batch classifier loss: 0.281420; batch adversarial loss: 0.643543\n",
      "epoch 49; iter: 0; batch classifier loss: 0.551059; batch adversarial loss: 0.602365\n",
      "epoch 49; iter: 200; batch classifier loss: 0.452399; batch adversarial loss: 0.617600\n",
      "epoch 0; iter: 0; batch classifier loss: 17.808922; batch adversarial loss: 0.675700\n",
      "epoch 0; iter: 200; batch classifier loss: 10.272038; batch adversarial loss: 0.611954\n",
      "epoch 1; iter: 0; batch classifier loss: 10.772802; batch adversarial loss: 0.590176\n",
      "epoch 1; iter: 200; batch classifier loss: 8.660297; batch adversarial loss: 0.508930\n",
      "epoch 2; iter: 0; batch classifier loss: 3.534927; batch adversarial loss: 0.597091\n",
      "epoch 2; iter: 200; batch classifier loss: 4.313733; batch adversarial loss: 0.543150\n",
      "epoch 3; iter: 0; batch classifier loss: 4.652192; batch adversarial loss: 0.575716\n",
      "epoch 3; iter: 200; batch classifier loss: 2.360902; batch adversarial loss: 0.516906\n",
      "epoch 4; iter: 0; batch classifier loss: 2.438870; batch adversarial loss: 0.600520\n",
      "epoch 4; iter: 200; batch classifier loss: 1.324963; batch adversarial loss: 0.614651\n",
      "epoch 5; iter: 0; batch classifier loss: 0.955616; batch adversarial loss: 0.595020\n",
      "epoch 5; iter: 200; batch classifier loss: 0.636949; batch adversarial loss: 0.617469\n",
      "epoch 6; iter: 0; batch classifier loss: 0.735250; batch adversarial loss: 0.588596\n",
      "epoch 6; iter: 200; batch classifier loss: 0.616102; batch adversarial loss: 0.685291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435792; batch adversarial loss: 0.683184\n",
      "epoch 7; iter: 200; batch classifier loss: 0.566919; batch adversarial loss: 0.683080\n",
      "epoch 8; iter: 0; batch classifier loss: 0.687975; batch adversarial loss: 0.628240\n",
      "epoch 8; iter: 200; batch classifier loss: 0.500095; batch adversarial loss: 0.645044\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450291; batch adversarial loss: 0.630277\n",
      "epoch 9; iter: 200; batch classifier loss: 0.373436; batch adversarial loss: 0.643372\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634859; batch adversarial loss: 0.635931\n",
      "epoch 10; iter: 200; batch classifier loss: 0.368450; batch adversarial loss: 0.629079\n",
      "epoch 11; iter: 0; batch classifier loss: 0.377643; batch adversarial loss: 0.589177\n",
      "epoch 11; iter: 200; batch classifier loss: 0.346964; batch adversarial loss: 0.600018\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385808; batch adversarial loss: 0.612864\n",
      "epoch 12; iter: 200; batch classifier loss: 0.644637; batch adversarial loss: 0.624156\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330545; batch adversarial loss: 0.653080\n",
      "epoch 13; iter: 200; batch classifier loss: 0.433312; batch adversarial loss: 0.613955\n",
      "epoch 14; iter: 0; batch classifier loss: 0.392703; batch adversarial loss: 0.574134\n",
      "epoch 14; iter: 200; batch classifier loss: 0.315949; batch adversarial loss: 0.628980\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462059; batch adversarial loss: 0.634901\n",
      "epoch 15; iter: 200; batch classifier loss: 0.362857; batch adversarial loss: 0.589590\n",
      "epoch 16; iter: 0; batch classifier loss: 0.393387; batch adversarial loss: 0.608910\n",
      "epoch 16; iter: 200; batch classifier loss: 0.322268; batch adversarial loss: 0.669321\n",
      "epoch 17; iter: 0; batch classifier loss: 0.415920; batch adversarial loss: 0.611416\n",
      "epoch 17; iter: 200; batch classifier loss: 0.286265; batch adversarial loss: 0.602865\n",
      "epoch 18; iter: 0; batch classifier loss: 0.395051; batch adversarial loss: 0.617148\n",
      "epoch 18; iter: 200; batch classifier loss: 0.335216; batch adversarial loss: 0.595386\n",
      "epoch 19; iter: 0; batch classifier loss: 0.260846; batch adversarial loss: 0.600859\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346675; batch adversarial loss: 0.629204\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342961; batch adversarial loss: 0.624725\n",
      "epoch 20; iter: 200; batch classifier loss: 0.377508; batch adversarial loss: 0.603373\n",
      "epoch 21; iter: 0; batch classifier loss: 0.301035; batch adversarial loss: 0.625734\n",
      "epoch 21; iter: 200; batch classifier loss: 0.418856; batch adversarial loss: 0.603303\n",
      "epoch 22; iter: 0; batch classifier loss: 0.330617; batch adversarial loss: 0.607351\n",
      "epoch 22; iter: 200; batch classifier loss: 0.379871; batch adversarial loss: 0.578398\n",
      "epoch 23; iter: 0; batch classifier loss: 0.419335; batch adversarial loss: 0.619845\n",
      "epoch 23; iter: 200; batch classifier loss: 0.318466; batch adversarial loss: 0.596178\n",
      "epoch 24; iter: 0; batch classifier loss: 0.322066; batch adversarial loss: 0.634898\n",
      "epoch 24; iter: 200; batch classifier loss: 0.375238; batch adversarial loss: 0.586648\n",
      "epoch 25; iter: 0; batch classifier loss: 0.307236; batch adversarial loss: 0.614993\n",
      "epoch 25; iter: 200; batch classifier loss: 0.383035; batch adversarial loss: 0.523969\n",
      "epoch 26; iter: 0; batch classifier loss: 0.305066; batch adversarial loss: 0.564858\n",
      "epoch 26; iter: 200; batch classifier loss: 0.301193; batch adversarial loss: 0.668820\n",
      "epoch 27; iter: 0; batch classifier loss: 0.340936; batch adversarial loss: 0.653973\n",
      "epoch 27; iter: 200; batch classifier loss: 0.471487; batch adversarial loss: 0.591338\n",
      "epoch 28; iter: 0; batch classifier loss: 0.331163; batch adversarial loss: 0.624727\n",
      "epoch 28; iter: 200; batch classifier loss: 0.419201; batch adversarial loss: 0.630352\n",
      "epoch 29; iter: 0; batch classifier loss: 0.314391; batch adversarial loss: 0.639124\n",
      "epoch 29; iter: 200; batch classifier loss: 0.308626; batch adversarial loss: 0.599489\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421443; batch adversarial loss: 0.611188\n",
      "epoch 30; iter: 200; batch classifier loss: 0.315481; batch adversarial loss: 0.645566\n",
      "epoch 31; iter: 0; batch classifier loss: 0.284244; batch adversarial loss: 0.642195\n",
      "epoch 31; iter: 200; batch classifier loss: 0.310296; batch adversarial loss: 0.640102\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419768; batch adversarial loss: 0.609021\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397691; batch adversarial loss: 0.525112\n",
      "epoch 33; iter: 0; batch classifier loss: 0.292356; batch adversarial loss: 0.623032\n",
      "epoch 33; iter: 200; batch classifier loss: 0.382172; batch adversarial loss: 0.586951\n",
      "epoch 34; iter: 0; batch classifier loss: 0.271238; batch adversarial loss: 0.602247\n",
      "epoch 34; iter: 200; batch classifier loss: 0.637049; batch adversarial loss: 0.643155\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376033; batch adversarial loss: 0.592590\n",
      "epoch 35; iter: 200; batch classifier loss: 0.357964; batch adversarial loss: 0.652196\n",
      "epoch 36; iter: 0; batch classifier loss: 0.332820; batch adversarial loss: 0.637638\n",
      "epoch 36; iter: 200; batch classifier loss: 0.352288; batch adversarial loss: 0.628825\n",
      "epoch 37; iter: 0; batch classifier loss: 0.344467; batch adversarial loss: 0.596129\n",
      "epoch 37; iter: 200; batch classifier loss: 0.272254; batch adversarial loss: 0.640624\n",
      "epoch 38; iter: 0; batch classifier loss: 0.275279; batch adversarial loss: 0.683803\n",
      "epoch 38; iter: 200; batch classifier loss: 0.438181; batch adversarial loss: 0.651877\n",
      "epoch 39; iter: 0; batch classifier loss: 0.248567; batch adversarial loss: 0.609128\n",
      "epoch 39; iter: 200; batch classifier loss: 0.268354; batch adversarial loss: 0.636049\n",
      "epoch 40; iter: 0; batch classifier loss: 0.329015; batch adversarial loss: 0.656840\n",
      "epoch 40; iter: 200; batch classifier loss: 0.373940; batch adversarial loss: 0.656283\n",
      "epoch 41; iter: 0; batch classifier loss: 0.360049; batch adversarial loss: 0.669249\n",
      "epoch 41; iter: 200; batch classifier loss: 0.346472; batch adversarial loss: 0.614213\n",
      "epoch 42; iter: 0; batch classifier loss: 0.327951; batch adversarial loss: 0.595455\n",
      "epoch 42; iter: 200; batch classifier loss: 0.395068; batch adversarial loss: 0.662490\n",
      "epoch 43; iter: 0; batch classifier loss: 0.266864; batch adversarial loss: 0.627613\n",
      "epoch 43; iter: 200; batch classifier loss: 0.370730; batch adversarial loss: 0.608289\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429631; batch adversarial loss: 0.588514\n",
      "epoch 44; iter: 200; batch classifier loss: 0.266406; batch adversarial loss: 0.599271\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373007; batch adversarial loss: 0.606372\n",
      "epoch 45; iter: 200; batch classifier loss: 0.386713; batch adversarial loss: 0.646763\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380194; batch adversarial loss: 0.606365\n",
      "epoch 46; iter: 200; batch classifier loss: 0.417361; batch adversarial loss: 0.556823\n",
      "epoch 47; iter: 0; batch classifier loss: 0.612392; batch adversarial loss: 0.657430\n",
      "epoch 47; iter: 200; batch classifier loss: 0.365558; batch adversarial loss: 0.607383\n",
      "epoch 48; iter: 0; batch classifier loss: 0.346680; batch adversarial loss: 0.641693\n",
      "epoch 48; iter: 200; batch classifier loss: 0.419537; batch adversarial loss: 0.605703\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369125; batch adversarial loss: 0.620817\n",
      "epoch 49; iter: 200; batch classifier loss: 0.406454; batch adversarial loss: 0.597426\n",
      "epoch 0; iter: 0; batch classifier loss: 9.348824; batch adversarial loss: 0.765297\n",
      "epoch 0; iter: 200; batch classifier loss: 10.542971; batch adversarial loss: 0.671461\n",
      "epoch 1; iter: 0; batch classifier loss: 20.311705; batch adversarial loss: 0.666469\n",
      "epoch 1; iter: 200; batch classifier loss: 10.100873; batch adversarial loss: 0.642423\n",
      "epoch 2; iter: 0; batch classifier loss: 2.864057; batch adversarial loss: 0.644522\n",
      "epoch 2; iter: 200; batch classifier loss: 3.364803; batch adversarial loss: 0.640077\n",
      "epoch 3; iter: 0; batch classifier loss: 2.221114; batch adversarial loss: 0.623162\n",
      "epoch 3; iter: 200; batch classifier loss: 0.537922; batch adversarial loss: 0.601330\n",
      "epoch 4; iter: 0; batch classifier loss: 0.417652; batch adversarial loss: 0.572373\n",
      "epoch 4; iter: 200; batch classifier loss: 1.440889; batch adversarial loss: 0.636918\n",
      "epoch 5; iter: 0; batch classifier loss: 0.967416; batch adversarial loss: 0.704023\n",
      "epoch 5; iter: 200; batch classifier loss: 0.686523; batch adversarial loss: 0.607449\n",
      "epoch 6; iter: 0; batch classifier loss: 0.754867; batch adversarial loss: 0.625276\n",
      "epoch 6; iter: 200; batch classifier loss: 0.701674; batch adversarial loss: 0.639654\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512424; batch adversarial loss: 0.606385\n",
      "epoch 7; iter: 200; batch classifier loss: 0.436132; batch adversarial loss: 0.673555\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359345; batch adversarial loss: 0.605681\n",
      "epoch 8; iter: 200; batch classifier loss: 0.443940; batch adversarial loss: 0.564453\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409137; batch adversarial loss: 0.583525\n",
      "epoch 9; iter: 200; batch classifier loss: 0.517637; batch adversarial loss: 0.615999\n",
      "epoch 10; iter: 0; batch classifier loss: 0.395842; batch adversarial loss: 0.599609\n",
      "epoch 10; iter: 200; batch classifier loss: 0.522535; batch adversarial loss: 0.642845\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420491; batch adversarial loss: 0.632795\n",
      "epoch 11; iter: 200; batch classifier loss: 0.296101; batch adversarial loss: 0.682180\n",
      "epoch 12; iter: 0; batch classifier loss: 0.375775; batch adversarial loss: 0.564492\n",
      "epoch 12; iter: 200; batch classifier loss: 0.377264; batch adversarial loss: 0.599281\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336151; batch adversarial loss: 0.582616\n",
      "epoch 13; iter: 200; batch classifier loss: 0.506514; batch adversarial loss: 0.577758\n",
      "epoch 14; iter: 0; batch classifier loss: 0.404614; batch adversarial loss: 0.667064\n",
      "epoch 14; iter: 200; batch classifier loss: 0.371832; batch adversarial loss: 0.591912\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471887; batch adversarial loss: 0.602088\n",
      "epoch 15; iter: 200; batch classifier loss: 0.396266; batch adversarial loss: 0.592517\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333382; batch adversarial loss: 0.609563\n",
      "epoch 16; iter: 200; batch classifier loss: 0.311792; batch adversarial loss: 0.605591\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372259; batch adversarial loss: 0.641369\n",
      "epoch 17; iter: 200; batch classifier loss: 0.331883; batch adversarial loss: 0.599171\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391295; batch adversarial loss: 0.593971\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326586; batch adversarial loss: 0.580866\n",
      "epoch 19; iter: 0; batch classifier loss: 0.300649; batch adversarial loss: 0.613681\n",
      "epoch 19; iter: 200; batch classifier loss: 0.445583; batch adversarial loss: 0.596220\n",
      "epoch 20; iter: 0; batch classifier loss: 0.264916; batch adversarial loss: 0.592034\n",
      "epoch 20; iter: 200; batch classifier loss: 0.337468; batch adversarial loss: 0.654680\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300695; batch adversarial loss: 0.602633\n",
      "epoch 21; iter: 200; batch classifier loss: 0.265636; batch adversarial loss: 0.615649\n",
      "epoch 22; iter: 0; batch classifier loss: 0.310871; batch adversarial loss: 0.632587\n",
      "epoch 22; iter: 200; batch classifier loss: 0.294999; batch adversarial loss: 0.597159\n",
      "epoch 23; iter: 0; batch classifier loss: 0.326755; batch adversarial loss: 0.608522\n",
      "epoch 23; iter: 200; batch classifier loss: 0.290227; batch adversarial loss: 0.592988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331509; batch adversarial loss: 0.658298\n",
      "epoch 24; iter: 200; batch classifier loss: 0.355761; batch adversarial loss: 0.648577\n",
      "epoch 25; iter: 0; batch classifier loss: 0.245781; batch adversarial loss: 0.643020\n",
      "epoch 25; iter: 200; batch classifier loss: 0.385430; batch adversarial loss: 0.625248\n",
      "epoch 26; iter: 0; batch classifier loss: 0.278588; batch adversarial loss: 0.621067\n",
      "epoch 26; iter: 200; batch classifier loss: 0.340796; batch adversarial loss: 0.588679\n",
      "epoch 27; iter: 0; batch classifier loss: 0.364926; batch adversarial loss: 0.608220\n",
      "epoch 27; iter: 200; batch classifier loss: 0.349868; batch adversarial loss: 0.608424\n",
      "epoch 28; iter: 0; batch classifier loss: 0.405447; batch adversarial loss: 0.596988\n",
      "epoch 28; iter: 200; batch classifier loss: 0.550913; batch adversarial loss: 0.578566\n",
      "epoch 29; iter: 0; batch classifier loss: 0.365318; batch adversarial loss: 0.617628\n",
      "epoch 29; iter: 200; batch classifier loss: 0.310304; batch adversarial loss: 0.601090\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396264; batch adversarial loss: 0.616815\n",
      "epoch 30; iter: 200; batch classifier loss: 0.248940; batch adversarial loss: 0.563379\n",
      "epoch 31; iter: 0; batch classifier loss: 0.361828; batch adversarial loss: 0.546226\n",
      "epoch 31; iter: 200; batch classifier loss: 0.383196; batch adversarial loss: 0.604052\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329394; batch adversarial loss: 0.618362\n",
      "epoch 32; iter: 200; batch classifier loss: 0.303824; batch adversarial loss: 0.590533\n",
      "epoch 33; iter: 0; batch classifier loss: 0.287612; batch adversarial loss: 0.615842\n",
      "epoch 33; iter: 200; batch classifier loss: 0.457367; batch adversarial loss: 0.559724\n",
      "epoch 34; iter: 0; batch classifier loss: 0.360666; batch adversarial loss: 0.616562\n",
      "epoch 34; iter: 200; batch classifier loss: 0.289237; batch adversarial loss: 0.645870\n",
      "epoch 35; iter: 0; batch classifier loss: 0.366304; batch adversarial loss: 0.592880\n",
      "epoch 35; iter: 200; batch classifier loss: 0.333779; batch adversarial loss: 0.630888\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425525; batch adversarial loss: 0.603313\n",
      "epoch 36; iter: 200; batch classifier loss: 0.264385; batch adversarial loss: 0.646451\n",
      "epoch 37; iter: 0; batch classifier loss: 0.774322; batch adversarial loss: 0.599981\n",
      "epoch 37; iter: 200; batch classifier loss: 0.393282; batch adversarial loss: 0.661853\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279499; batch adversarial loss: 0.599951\n",
      "epoch 38; iter: 200; batch classifier loss: 0.404591; batch adversarial loss: 0.622814\n",
      "epoch 39; iter: 0; batch classifier loss: 0.200674; batch adversarial loss: 0.624413\n",
      "epoch 39; iter: 200; batch classifier loss: 0.439522; batch adversarial loss: 0.613172\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399971; batch adversarial loss: 0.628044\n",
      "epoch 40; iter: 200; batch classifier loss: 0.373854; batch adversarial loss: 0.573425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.321455; batch adversarial loss: 0.605164\n",
      "epoch 41; iter: 200; batch classifier loss: 0.436529; batch adversarial loss: 0.655935\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447437; batch adversarial loss: 0.663798\n",
      "epoch 42; iter: 200; batch classifier loss: 0.326317; batch adversarial loss: 0.645806\n",
      "epoch 43; iter: 0; batch classifier loss: 0.413601; batch adversarial loss: 0.659807\n",
      "epoch 43; iter: 200; batch classifier loss: 0.344992; batch adversarial loss: 0.611322\n",
      "epoch 44; iter: 0; batch classifier loss: 0.350603; batch adversarial loss: 0.542853\n",
      "epoch 44; iter: 200; batch classifier loss: 0.333139; batch adversarial loss: 0.619276\n",
      "epoch 45; iter: 0; batch classifier loss: 0.363946; batch adversarial loss: 0.589340\n",
      "epoch 45; iter: 200; batch classifier loss: 0.413108; batch adversarial loss: 0.604702\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440746; batch adversarial loss: 0.588782\n",
      "epoch 46; iter: 200; batch classifier loss: 0.405970; batch adversarial loss: 0.562467\n",
      "epoch 47; iter: 0; batch classifier loss: 0.319403; batch adversarial loss: 0.642220\n",
      "epoch 47; iter: 200; batch classifier loss: 0.269384; batch adversarial loss: 0.592807\n",
      "epoch 48; iter: 0; batch classifier loss: 0.365692; batch adversarial loss: 0.632128\n",
      "epoch 48; iter: 200; batch classifier loss: 0.342106; batch adversarial loss: 0.629996\n",
      "epoch 49; iter: 0; batch classifier loss: 0.285088; batch adversarial loss: 0.619988\n",
      "epoch 49; iter: 200; batch classifier loss: 0.342592; batch adversarial loss: 0.628262\n",
      "epoch 0; iter: 0; batch classifier loss: 17.395769; batch adversarial loss: 0.820271\n",
      "epoch 0; iter: 200; batch classifier loss: 8.721958; batch adversarial loss: 0.688831\n",
      "epoch 1; iter: 0; batch classifier loss: 6.858146; batch adversarial loss: 0.696874\n",
      "epoch 1; iter: 200; batch classifier loss: 26.640888; batch adversarial loss: 0.667046\n",
      "epoch 2; iter: 0; batch classifier loss: 4.827997; batch adversarial loss: 0.652298\n",
      "epoch 2; iter: 200; batch classifier loss: 4.600633; batch adversarial loss: 0.634529\n",
      "epoch 3; iter: 0; batch classifier loss: 3.742397; batch adversarial loss: 0.629536\n",
      "epoch 3; iter: 200; batch classifier loss: 3.480457; batch adversarial loss: 0.634411\n",
      "epoch 4; iter: 0; batch classifier loss: 2.531517; batch adversarial loss: 0.603688\n",
      "epoch 4; iter: 200; batch classifier loss: 1.402047; batch adversarial loss: 0.655073\n",
      "epoch 5; iter: 0; batch classifier loss: 1.283617; batch adversarial loss: 0.646992\n",
      "epoch 5; iter: 200; batch classifier loss: 1.411827; batch adversarial loss: 0.672379\n",
      "epoch 6; iter: 0; batch classifier loss: 0.887110; batch adversarial loss: 0.605345\n",
      "epoch 6; iter: 200; batch classifier loss: 0.631771; batch adversarial loss: 0.609113\n",
      "epoch 7; iter: 0; batch classifier loss: 0.690128; batch adversarial loss: 0.639553\n",
      "epoch 7; iter: 200; batch classifier loss: 0.584837; batch adversarial loss: 0.655898\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588838; batch adversarial loss: 0.671433\n",
      "epoch 8; iter: 200; batch classifier loss: 0.546452; batch adversarial loss: 0.613844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.605153; batch adversarial loss: 0.649160\n",
      "epoch 9; iter: 200; batch classifier loss: 0.432755; batch adversarial loss: 0.625186\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543416; batch adversarial loss: 0.585814\n",
      "epoch 10; iter: 200; batch classifier loss: 0.341203; batch adversarial loss: 0.653960\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573023; batch adversarial loss: 0.614328\n",
      "epoch 11; iter: 200; batch classifier loss: 0.401089; batch adversarial loss: 0.592255\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398661; batch adversarial loss: 0.620704\n",
      "epoch 12; iter: 200; batch classifier loss: 0.283020; batch adversarial loss: 0.629268\n",
      "epoch 13; iter: 0; batch classifier loss: 0.656925; batch adversarial loss: 0.695071\n",
      "epoch 13; iter: 200; batch classifier loss: 0.455744; batch adversarial loss: 0.629957\n",
      "epoch 14; iter: 0; batch classifier loss: 0.357805; batch adversarial loss: 0.667982\n",
      "epoch 14; iter: 200; batch classifier loss: 0.400495; batch adversarial loss: 0.619190\n",
      "epoch 15; iter: 0; batch classifier loss: 0.429273; batch adversarial loss: 0.600299\n",
      "epoch 15; iter: 200; batch classifier loss: 0.352723; batch adversarial loss: 0.552678\n",
      "epoch 16; iter: 0; batch classifier loss: 0.369868; batch adversarial loss: 0.615362\n",
      "epoch 16; iter: 200; batch classifier loss: 0.371385; batch adversarial loss: 0.582948\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371599; batch adversarial loss: 0.580553\n",
      "epoch 17; iter: 200; batch classifier loss: 0.388650; batch adversarial loss: 0.645984\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320145; batch adversarial loss: 0.668949\n",
      "epoch 18; iter: 200; batch classifier loss: 0.446169; batch adversarial loss: 0.634747\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480587; batch adversarial loss: 0.565998\n",
      "epoch 19; iter: 200; batch classifier loss: 0.323784; batch adversarial loss: 0.644747\n",
      "epoch 20; iter: 0; batch classifier loss: 0.353550; batch adversarial loss: 0.676470\n",
      "epoch 20; iter: 200; batch classifier loss: 0.314548; batch adversarial loss: 0.616939\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388592; batch adversarial loss: 0.619027\n",
      "epoch 21; iter: 200; batch classifier loss: 0.444363; batch adversarial loss: 0.635322\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450528; batch adversarial loss: 0.657826\n",
      "epoch 22; iter: 200; batch classifier loss: 0.388285; batch adversarial loss: 0.625108\n",
      "epoch 23; iter: 0; batch classifier loss: 0.369664; batch adversarial loss: 0.639980\n",
      "epoch 23; iter: 200; batch classifier loss: 0.260326; batch adversarial loss: 0.581238\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323213; batch adversarial loss: 0.600669\n",
      "epoch 24; iter: 200; batch classifier loss: 0.274378; batch adversarial loss: 0.690853\n",
      "epoch 25; iter: 0; batch classifier loss: 0.308629; batch adversarial loss: 0.582027\n",
      "epoch 25; iter: 200; batch classifier loss: 0.377888; batch adversarial loss: 0.654188\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343346; batch adversarial loss: 0.633994\n",
      "epoch 26; iter: 200; batch classifier loss: 0.378953; batch adversarial loss: 0.579452\n",
      "epoch 27; iter: 0; batch classifier loss: 0.336955; batch adversarial loss: 0.592637\n",
      "epoch 27; iter: 200; batch classifier loss: 0.378696; batch adversarial loss: 0.627891\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440373; batch adversarial loss: 0.582544\n",
      "epoch 28; iter: 200; batch classifier loss: 0.446734; batch adversarial loss: 0.642839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.302113; batch adversarial loss: 0.567304\n",
      "epoch 29; iter: 200; batch classifier loss: 0.296506; batch adversarial loss: 0.620653\n",
      "epoch 30; iter: 0; batch classifier loss: 0.330122; batch adversarial loss: 0.595528\n",
      "epoch 30; iter: 200; batch classifier loss: 0.305817; batch adversarial loss: 0.636271\n",
      "epoch 31; iter: 0; batch classifier loss: 0.385971; batch adversarial loss: 0.609167\n",
      "epoch 31; iter: 200; batch classifier loss: 0.322192; batch adversarial loss: 0.590895\n",
      "epoch 32; iter: 0; batch classifier loss: 0.308995; batch adversarial loss: 0.558767\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397966; batch adversarial loss: 0.603625\n",
      "epoch 33; iter: 0; batch classifier loss: 0.421030; batch adversarial loss: 0.624570\n",
      "epoch 33; iter: 200; batch classifier loss: 0.406722; batch adversarial loss: 0.559070\n",
      "epoch 34; iter: 0; batch classifier loss: 0.340434; batch adversarial loss: 0.625749\n",
      "epoch 34; iter: 200; batch classifier loss: 0.472767; batch adversarial loss: 0.595322\n",
      "epoch 35; iter: 0; batch classifier loss: 0.331959; batch adversarial loss: 0.596797\n",
      "epoch 35; iter: 200; batch classifier loss: 0.414679; batch adversarial loss: 0.586755\n",
      "epoch 36; iter: 0; batch classifier loss: 0.328409; batch adversarial loss: 0.615799\n",
      "epoch 36; iter: 200; batch classifier loss: 0.447113; batch adversarial loss: 0.552306\n",
      "epoch 37; iter: 0; batch classifier loss: 0.328779; batch adversarial loss: 0.596409\n",
      "epoch 37; iter: 200; batch classifier loss: 0.396042; batch adversarial loss: 0.606674\n",
      "epoch 38; iter: 0; batch classifier loss: 0.350787; batch adversarial loss: 0.612510\n",
      "epoch 38; iter: 200; batch classifier loss: 0.266343; batch adversarial loss: 0.649949\n",
      "epoch 39; iter: 0; batch classifier loss: 0.346116; batch adversarial loss: 0.631392\n",
      "epoch 39; iter: 200; batch classifier loss: 0.346819; batch adversarial loss: 0.676030\n",
      "epoch 40; iter: 0; batch classifier loss: 0.358756; batch adversarial loss: 0.644504\n",
      "epoch 40; iter: 200; batch classifier loss: 0.362959; batch adversarial loss: 0.639977\n",
      "epoch 41; iter: 0; batch classifier loss: 0.293276; batch adversarial loss: 0.640403\n",
      "epoch 41; iter: 200; batch classifier loss: 0.358773; batch adversarial loss: 0.639141\n",
      "epoch 42; iter: 0; batch classifier loss: 0.330990; batch adversarial loss: 0.633042\n",
      "epoch 42; iter: 200; batch classifier loss: 0.332462; batch adversarial loss: 0.629070\n",
      "epoch 43; iter: 0; batch classifier loss: 0.354696; batch adversarial loss: 0.607951\n",
      "epoch 43; iter: 200; batch classifier loss: 0.324211; batch adversarial loss: 0.628158\n",
      "epoch 44; iter: 0; batch classifier loss: 0.353075; batch adversarial loss: 0.690813\n",
      "epoch 44; iter: 200; batch classifier loss: 0.404962; batch adversarial loss: 0.659363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.370039; batch adversarial loss: 0.657176\n",
      "epoch 45; iter: 200; batch classifier loss: 0.356224; batch adversarial loss: 0.643722\n",
      "epoch 46; iter: 0; batch classifier loss: 0.355885; batch adversarial loss: 0.597284\n",
      "epoch 46; iter: 200; batch classifier loss: 0.563443; batch adversarial loss: 0.603291\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398776; batch adversarial loss: 0.610703\n",
      "epoch 47; iter: 200; batch classifier loss: 0.445232; batch adversarial loss: 0.565550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.331222; batch adversarial loss: 0.628148\n",
      "epoch 48; iter: 200; batch classifier loss: 0.473262; batch adversarial loss: 0.629083\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369022; batch adversarial loss: 0.591844\n",
      "epoch 49; iter: 200; batch classifier loss: 0.400533; batch adversarial loss: 0.591567\n",
      "epoch 0; iter: 0; batch classifier loss: 223.639587; batch adversarial loss: 0.717242\n",
      "epoch 0; iter: 200; batch classifier loss: 5.728817; batch adversarial loss: 0.694808\n",
      "epoch 1; iter: 0; batch classifier loss: 11.775114; batch adversarial loss: 0.685982\n",
      "epoch 1; iter: 200; batch classifier loss: 3.647779; batch adversarial loss: 0.668287\n",
      "epoch 2; iter: 0; batch classifier loss: 6.266036; batch adversarial loss: 0.649126\n",
      "epoch 2; iter: 200; batch classifier loss: 3.999871; batch adversarial loss: 0.589040\n",
      "epoch 3; iter: 0; batch classifier loss: 3.201132; batch adversarial loss: 0.599857\n",
      "epoch 3; iter: 200; batch classifier loss: 4.831862; batch adversarial loss: 0.564637\n",
      "epoch 4; iter: 0; batch classifier loss: 4.292672; batch adversarial loss: 0.692317\n",
      "epoch 4; iter: 200; batch classifier loss: 1.838568; batch adversarial loss: 0.615568\n",
      "epoch 5; iter: 0; batch classifier loss: 2.759743; batch adversarial loss: 0.590402\n",
      "epoch 5; iter: 200; batch classifier loss: 0.958881; batch adversarial loss: 0.681349\n",
      "epoch 6; iter: 0; batch classifier loss: 1.132762; batch adversarial loss: 0.682871\n",
      "epoch 6; iter: 200; batch classifier loss: 1.163289; batch adversarial loss: 0.635064\n",
      "epoch 7; iter: 0; batch classifier loss: 0.845846; batch adversarial loss: 0.624800\n",
      "epoch 7; iter: 200; batch classifier loss: 0.775772; batch adversarial loss: 0.594635\n",
      "epoch 8; iter: 0; batch classifier loss: 0.629737; batch adversarial loss: 0.646557\n",
      "epoch 8; iter: 200; batch classifier loss: 0.675603; batch adversarial loss: 0.620714\n",
      "epoch 9; iter: 0; batch classifier loss: 0.701381; batch adversarial loss: 0.629280\n",
      "epoch 9; iter: 200; batch classifier loss: 0.599372; batch adversarial loss: 0.609994\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517068; batch adversarial loss: 0.599051\n",
      "epoch 10; iter: 200; batch classifier loss: 0.598098; batch adversarial loss: 0.642356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.604166; batch adversarial loss: 0.656680\n",
      "epoch 11; iter: 200; batch classifier loss: 1.147939; batch adversarial loss: 0.660596\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481671; batch adversarial loss: 0.630186\n",
      "epoch 12; iter: 200; batch classifier loss: 0.354637; batch adversarial loss: 0.654400\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483519; batch adversarial loss: 0.637745\n",
      "epoch 13; iter: 200; batch classifier loss: 0.399953; batch adversarial loss: 0.570233\n",
      "epoch 14; iter: 0; batch classifier loss: 0.455385; batch adversarial loss: 0.624418\n",
      "epoch 14; iter: 200; batch classifier loss: 0.423809; batch adversarial loss: 0.616279\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363055; batch adversarial loss: 0.615827\n",
      "epoch 15; iter: 200; batch classifier loss: 0.319320; batch adversarial loss: 0.593764\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341038; batch adversarial loss: 0.537308\n",
      "epoch 16; iter: 200; batch classifier loss: 0.308732; batch adversarial loss: 0.629747\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525643; batch adversarial loss: 0.584612\n",
      "epoch 17; iter: 200; batch classifier loss: 0.354385; batch adversarial loss: 0.640069\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391961; batch adversarial loss: 0.601975\n",
      "epoch 18; iter: 200; batch classifier loss: 0.361783; batch adversarial loss: 0.554978\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378872; batch adversarial loss: 0.619931\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387192; batch adversarial loss: 0.614277\n",
      "epoch 20; iter: 0; batch classifier loss: 0.458838; batch adversarial loss: 0.595203\n",
      "epoch 20; iter: 200; batch classifier loss: 0.336149; batch adversarial loss: 0.583149\n",
      "epoch 21; iter: 0; batch classifier loss: 0.347358; batch adversarial loss: 0.564837\n",
      "epoch 21; iter: 200; batch classifier loss: 0.299872; batch adversarial loss: 0.570482\n",
      "epoch 22; iter: 0; batch classifier loss: 0.322035; batch adversarial loss: 0.638992\n",
      "epoch 22; iter: 200; batch classifier loss: 0.344445; batch adversarial loss: 0.600756\n",
      "epoch 23; iter: 0; batch classifier loss: 0.220707; batch adversarial loss: 0.581622\n",
      "epoch 23; iter: 200; batch classifier loss: 0.369942; batch adversarial loss: 0.649830\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340980; batch adversarial loss: 0.684374\n",
      "epoch 24; iter: 200; batch classifier loss: 0.220357; batch adversarial loss: 0.588762\n",
      "epoch 25; iter: 0; batch classifier loss: 0.387968; batch adversarial loss: 0.664108\n",
      "epoch 25; iter: 200; batch classifier loss: 0.382154; batch adversarial loss: 0.631430\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363786; batch adversarial loss: 0.622778\n",
      "epoch 26; iter: 200; batch classifier loss: 0.275774; batch adversarial loss: 0.649417\n",
      "epoch 27; iter: 0; batch classifier loss: 0.367535; batch adversarial loss: 0.562394\n",
      "epoch 27; iter: 200; batch classifier loss: 0.286337; batch adversarial loss: 0.598353\n",
      "epoch 28; iter: 0; batch classifier loss: 0.384197; batch adversarial loss: 0.588486\n",
      "epoch 28; iter: 200; batch classifier loss: 0.293509; batch adversarial loss: 0.647619\n",
      "epoch 29; iter: 0; batch classifier loss: 0.389313; batch adversarial loss: 0.638747\n",
      "epoch 29; iter: 200; batch classifier loss: 0.413042; batch adversarial loss: 0.694836\n",
      "epoch 30; iter: 0; batch classifier loss: 0.358092; batch adversarial loss: 0.590108\n",
      "epoch 30; iter: 200; batch classifier loss: 0.314875; batch adversarial loss: 0.610553\n",
      "epoch 31; iter: 0; batch classifier loss: 0.329561; batch adversarial loss: 0.581583\n",
      "epoch 31; iter: 200; batch classifier loss: 0.305169; batch adversarial loss: 0.633388\n",
      "epoch 32; iter: 0; batch classifier loss: 0.267906; batch adversarial loss: 0.627518\n",
      "epoch 32; iter: 200; batch classifier loss: 0.312294; batch adversarial loss: 0.598277\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347750; batch adversarial loss: 0.640216\n",
      "epoch 33; iter: 200; batch classifier loss: 0.501825; batch adversarial loss: 0.611349\n",
      "epoch 34; iter: 0; batch classifier loss: 0.442772; batch adversarial loss: 0.634769\n",
      "epoch 34; iter: 200; batch classifier loss: 0.343381; batch adversarial loss: 0.618610\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421871; batch adversarial loss: 0.612389\n",
      "epoch 35; iter: 200; batch classifier loss: 0.354148; batch adversarial loss: 0.578676\n",
      "epoch 36; iter: 0; batch classifier loss: 0.369783; batch adversarial loss: 0.634807\n",
      "epoch 36; iter: 200; batch classifier loss: 0.347871; batch adversarial loss: 0.553498\n",
      "epoch 37; iter: 0; batch classifier loss: 0.306433; batch adversarial loss: 0.656044\n",
      "epoch 37; iter: 200; batch classifier loss: 0.289375; batch adversarial loss: 0.603939\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247575; batch adversarial loss: 0.642299\n",
      "epoch 38; iter: 200; batch classifier loss: 0.380645; batch adversarial loss: 0.651912\n",
      "epoch 39; iter: 0; batch classifier loss: 0.331665; batch adversarial loss: 0.581575\n",
      "epoch 39; iter: 200; batch classifier loss: 0.394228; batch adversarial loss: 0.602900\n",
      "epoch 40; iter: 0; batch classifier loss: 0.445154; batch adversarial loss: 0.578523\n",
      "epoch 40; iter: 200; batch classifier loss: 0.366398; batch adversarial loss: 0.640239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.300342; batch adversarial loss: 0.650676\n",
      "epoch 41; iter: 200; batch classifier loss: 0.478312; batch adversarial loss: 0.617271\n",
      "epoch 42; iter: 0; batch classifier loss: 0.357350; batch adversarial loss: 0.597666\n",
      "epoch 42; iter: 200; batch classifier loss: 0.342851; batch adversarial loss: 0.627595\n",
      "epoch 43; iter: 0; batch classifier loss: 0.335550; batch adversarial loss: 0.686844\n",
      "epoch 43; iter: 200; batch classifier loss: 0.313460; batch adversarial loss: 0.580232\n",
      "epoch 44; iter: 0; batch classifier loss: 0.363239; batch adversarial loss: 0.622501\n",
      "epoch 44; iter: 200; batch classifier loss: 0.432966; batch adversarial loss: 0.640175\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395907; batch adversarial loss: 0.588788\n",
      "epoch 45; iter: 200; batch classifier loss: 0.374170; batch adversarial loss: 0.660624\n",
      "epoch 46; iter: 0; batch classifier loss: 0.510463; batch adversarial loss: 0.614095\n",
      "epoch 46; iter: 200; batch classifier loss: 0.319751; batch adversarial loss: 0.627051\n",
      "epoch 47; iter: 0; batch classifier loss: 0.310189; batch adversarial loss: 0.577081\n",
      "epoch 47; iter: 200; batch classifier loss: 0.456486; batch adversarial loss: 0.680396\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371899; batch adversarial loss: 0.629810\n",
      "epoch 48; iter: 200; batch classifier loss: 0.315652; batch adversarial loss: 0.632052\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393645; batch adversarial loss: 0.699849\n",
      "epoch 49; iter: 200; batch classifier loss: 0.358233; batch adversarial loss: 0.632884\n",
      "epoch 0; iter: 0; batch classifier loss: 40.598610; batch adversarial loss: 0.676504\n",
      "epoch 0; iter: 200; batch classifier loss: 8.823673; batch adversarial loss: 0.627455\n",
      "epoch 1; iter: 0; batch classifier loss: 0.914369; batch adversarial loss: 0.595433\n",
      "epoch 1; iter: 200; batch classifier loss: 8.433691; batch adversarial loss: 0.596588\n",
      "epoch 2; iter: 0; batch classifier loss: 6.648720; batch adversarial loss: 0.640160\n",
      "epoch 2; iter: 200; batch classifier loss: 6.237137; batch adversarial loss: 0.632160\n",
      "epoch 3; iter: 0; batch classifier loss: 2.389543; batch adversarial loss: 0.651816\n",
      "epoch 3; iter: 200; batch classifier loss: 3.455816; batch adversarial loss: 0.609568\n",
      "epoch 4; iter: 0; batch classifier loss: 1.540129; batch adversarial loss: 0.608371\n",
      "epoch 4; iter: 200; batch classifier loss: 1.886704; batch adversarial loss: 0.654792\n",
      "epoch 5; iter: 0; batch classifier loss: 2.024037; batch adversarial loss: 0.647931\n",
      "epoch 5; iter: 200; batch classifier loss: 0.981465; batch adversarial loss: 0.634714\n",
      "epoch 6; iter: 0; batch classifier loss: 7.339575; batch adversarial loss: 0.607924\n",
      "epoch 6; iter: 200; batch classifier loss: 1.121110; batch adversarial loss: 0.616460\n",
      "epoch 7; iter: 0; batch classifier loss: 1.370678; batch adversarial loss: 0.599703\n",
      "epoch 7; iter: 200; batch classifier loss: 0.680399; batch adversarial loss: 0.661897\n",
      "epoch 8; iter: 0; batch classifier loss: 1.168177; batch adversarial loss: 0.644709\n",
      "epoch 8; iter: 200; batch classifier loss: 0.814381; batch adversarial loss: 0.630692\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506536; batch adversarial loss: 0.668951\n",
      "epoch 9; iter: 200; batch classifier loss: 1.090287; batch adversarial loss: 0.615330\n",
      "epoch 10; iter: 0; batch classifier loss: 0.483930; batch adversarial loss: 0.575890\n",
      "epoch 10; iter: 200; batch classifier loss: 0.532989; batch adversarial loss: 0.682138\n",
      "epoch 11; iter: 0; batch classifier loss: 0.351743; batch adversarial loss: 0.618616\n",
      "epoch 11; iter: 200; batch classifier loss: 0.341389; batch adversarial loss: 0.568058\n",
      "epoch 12; iter: 0; batch classifier loss: 0.584605; batch adversarial loss: 0.603489\n",
      "epoch 12; iter: 200; batch classifier loss: 0.365831; batch adversarial loss: 0.672308\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418052; batch adversarial loss: 0.597663\n",
      "epoch 13; iter: 200; batch classifier loss: 0.310201; batch adversarial loss: 0.648423\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360951; batch adversarial loss: 0.598751\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416218; batch adversarial loss: 0.577703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469669; batch adversarial loss: 0.606273\n",
      "epoch 15; iter: 200; batch classifier loss: 0.420510; batch adversarial loss: 0.608673\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394859; batch adversarial loss: 0.599878\n",
      "epoch 16; iter: 200; batch classifier loss: 0.431145; batch adversarial loss: 0.555923\n",
      "epoch 17; iter: 0; batch classifier loss: 0.402236; batch adversarial loss: 0.535383\n",
      "epoch 17; iter: 200; batch classifier loss: 0.353847; batch adversarial loss: 0.565439\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334319; batch adversarial loss: 0.592086\n",
      "epoch 18; iter: 200; batch classifier loss: 0.312319; batch adversarial loss: 0.562408\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343618; batch adversarial loss: 0.591031\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387695; batch adversarial loss: 0.606323\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338768; batch adversarial loss: 0.624334\n",
      "epoch 20; iter: 200; batch classifier loss: 0.286802; batch adversarial loss: 0.649691\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265739; batch adversarial loss: 0.625379\n",
      "epoch 21; iter: 200; batch classifier loss: 0.417945; batch adversarial loss: 0.592111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.381715; batch adversarial loss: 0.604539\n",
      "epoch 22; iter: 200; batch classifier loss: 0.340848; batch adversarial loss: 0.608127\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381625; batch adversarial loss: 0.597837\n",
      "epoch 23; iter: 200; batch classifier loss: 0.328074; batch adversarial loss: 0.578813\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282566; batch adversarial loss: 0.652029\n",
      "epoch 24; iter: 200; batch classifier loss: 0.297587; batch adversarial loss: 0.618072\n",
      "epoch 25; iter: 0; batch classifier loss: 0.361204; batch adversarial loss: 0.630367\n",
      "epoch 25; iter: 200; batch classifier loss: 0.408788; batch adversarial loss: 0.609443\n",
      "epoch 26; iter: 0; batch classifier loss: 0.280668; batch adversarial loss: 0.605579\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336437; batch adversarial loss: 0.602069\n",
      "epoch 27; iter: 0; batch classifier loss: 0.385504; batch adversarial loss: 0.630486\n",
      "epoch 27; iter: 200; batch classifier loss: 0.287458; batch adversarial loss: 0.674605\n",
      "epoch 28; iter: 0; batch classifier loss: 0.339635; batch adversarial loss: 0.576591\n",
      "epoch 28; iter: 200; batch classifier loss: 0.459054; batch adversarial loss: 0.614727\n",
      "epoch 29; iter: 0; batch classifier loss: 0.316953; batch adversarial loss: 0.633464\n",
      "epoch 29; iter: 200; batch classifier loss: 0.316923; batch adversarial loss: 0.565290\n",
      "epoch 30; iter: 0; batch classifier loss: 0.273468; batch adversarial loss: 0.581271\n",
      "epoch 30; iter: 200; batch classifier loss: 0.322768; batch adversarial loss: 0.613216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.350749; batch adversarial loss: 0.564390\n",
      "epoch 31; iter: 200; batch classifier loss: 0.363222; batch adversarial loss: 0.590968\n",
      "epoch 32; iter: 0; batch classifier loss: 0.316994; batch adversarial loss: 0.622456\n",
      "epoch 32; iter: 200; batch classifier loss: 0.412298; batch adversarial loss: 0.654214\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346758; batch adversarial loss: 0.646396\n",
      "epoch 33; iter: 200; batch classifier loss: 0.309252; batch adversarial loss: 0.629630\n",
      "epoch 34; iter: 0; batch classifier loss: 0.378247; batch adversarial loss: 0.598775\n",
      "epoch 34; iter: 200; batch classifier loss: 0.373319; batch adversarial loss: 0.602298\n",
      "epoch 35; iter: 0; batch classifier loss: 0.322802; batch adversarial loss: 0.610068\n",
      "epoch 35; iter: 200; batch classifier loss: 0.338214; batch adversarial loss: 0.602290\n",
      "epoch 36; iter: 0; batch classifier loss: 0.356480; batch adversarial loss: 0.682171\n",
      "epoch 36; iter: 200; batch classifier loss: 0.276360; batch adversarial loss: 0.622846\n",
      "epoch 37; iter: 0; batch classifier loss: 0.427583; batch adversarial loss: 0.631909\n",
      "epoch 37; iter: 200; batch classifier loss: 0.331040; batch adversarial loss: 0.589646\n",
      "epoch 38; iter: 0; batch classifier loss: 0.288324; batch adversarial loss: 0.668326\n",
      "epoch 38; iter: 200; batch classifier loss: 0.376375; batch adversarial loss: 0.581064\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407938; batch adversarial loss: 0.591450\n",
      "epoch 39; iter: 200; batch classifier loss: 0.503948; batch adversarial loss: 0.603866\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405694; batch adversarial loss: 0.564337\n",
      "epoch 40; iter: 200; batch classifier loss: 0.271556; batch adversarial loss: 0.636438\n",
      "epoch 41; iter: 0; batch classifier loss: 0.329591; batch adversarial loss: 0.647588\n",
      "epoch 41; iter: 200; batch classifier loss: 0.259497; batch adversarial loss: 0.656679\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483377; batch adversarial loss: 0.575597\n",
      "epoch 42; iter: 200; batch classifier loss: 0.344389; batch adversarial loss: 0.641555\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416401; batch adversarial loss: 0.629872\n",
      "epoch 43; iter: 200; batch classifier loss: 0.285742; batch adversarial loss: 0.622677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.345144; batch adversarial loss: 0.617155\n",
      "epoch 44; iter: 200; batch classifier loss: 0.447638; batch adversarial loss: 0.651376\n",
      "epoch 45; iter: 0; batch classifier loss: 0.372843; batch adversarial loss: 0.596703\n",
      "epoch 45; iter: 200; batch classifier loss: 0.317603; batch adversarial loss: 0.575480\n",
      "epoch 46; iter: 0; batch classifier loss: 0.630913; batch adversarial loss: 0.566236\n",
      "epoch 46; iter: 200; batch classifier loss: 0.413941; batch adversarial loss: 0.615962\n",
      "epoch 47; iter: 0; batch classifier loss: 0.349512; batch adversarial loss: 0.598548\n",
      "epoch 47; iter: 200; batch classifier loss: 0.397830; batch adversarial loss: 0.622844\n",
      "epoch 48; iter: 0; batch classifier loss: 0.361961; batch adversarial loss: 0.619477\n",
      "epoch 48; iter: 200; batch classifier loss: 0.275728; batch adversarial loss: 0.654125\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417813; batch adversarial loss: 0.649680\n",
      "epoch 49; iter: 200; batch classifier loss: 0.320885; batch adversarial loss: 0.635786\n",
      "epoch 0; iter: 0; batch classifier loss: 42.324421; batch adversarial loss: 0.710294\n",
      "epoch 0; iter: 200; batch classifier loss: 10.973666; batch adversarial loss: 0.717464\n",
      "epoch 1; iter: 0; batch classifier loss: 10.403104; batch adversarial loss: 0.672588\n",
      "epoch 1; iter: 200; batch classifier loss: 10.444738; batch adversarial loss: 0.706008\n",
      "epoch 2; iter: 0; batch classifier loss: 15.042559; batch adversarial loss: 0.685460\n",
      "epoch 2; iter: 200; batch classifier loss: 4.961072; batch adversarial loss: 0.654686\n",
      "epoch 3; iter: 0; batch classifier loss: 0.816788; batch adversarial loss: 0.605281\n",
      "epoch 3; iter: 200; batch classifier loss: 0.956196; batch adversarial loss: 0.632766\n",
      "epoch 4; iter: 0; batch classifier loss: 3.751198; batch adversarial loss: 0.644729\n",
      "epoch 4; iter: 200; batch classifier loss: 1.959304; batch adversarial loss: 0.587788\n",
      "epoch 5; iter: 0; batch classifier loss: 1.184725; batch adversarial loss: 0.613888\n",
      "epoch 5; iter: 200; batch classifier loss: 0.715822; batch adversarial loss: 0.612220\n",
      "epoch 6; iter: 0; batch classifier loss: 1.124421; batch adversarial loss: 0.658114\n",
      "epoch 6; iter: 200; batch classifier loss: 0.841885; batch adversarial loss: 0.609338\n",
      "epoch 7; iter: 0; batch classifier loss: 1.048433; batch adversarial loss: 0.615815\n",
      "epoch 7; iter: 200; batch classifier loss: 0.957996; batch adversarial loss: 0.629997\n",
      "epoch 8; iter: 0; batch classifier loss: 0.852133; batch adversarial loss: 0.696156\n",
      "epoch 8; iter: 200; batch classifier loss: 1.526089; batch adversarial loss: 0.618188\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476744; batch adversarial loss: 0.639424\n",
      "epoch 9; iter: 200; batch classifier loss: 0.551619; batch adversarial loss: 0.627859\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462740; batch adversarial loss: 0.614141\n",
      "epoch 10; iter: 200; batch classifier loss: 0.389364; batch adversarial loss: 0.584958\n",
      "epoch 11; iter: 0; batch classifier loss: 0.278026; batch adversarial loss: 0.671248\n",
      "epoch 11; iter: 200; batch classifier loss: 0.382073; batch adversarial loss: 0.659359\n",
      "epoch 12; iter: 0; batch classifier loss: 0.464972; batch adversarial loss: 0.620777\n",
      "epoch 12; iter: 200; batch classifier loss: 0.386993; batch adversarial loss: 0.618862\n",
      "epoch 13; iter: 0; batch classifier loss: 0.416004; batch adversarial loss: 0.627040\n",
      "epoch 13; iter: 200; batch classifier loss: 0.302812; batch adversarial loss: 0.636150\n",
      "epoch 14; iter: 0; batch classifier loss: 0.400487; batch adversarial loss: 0.615188\n",
      "epoch 14; iter: 200; batch classifier loss: 0.348005; batch adversarial loss: 0.615918\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364542; batch adversarial loss: 0.629431\n",
      "epoch 15; iter: 200; batch classifier loss: 0.385244; batch adversarial loss: 0.637794\n",
      "epoch 16; iter: 0; batch classifier loss: 0.435850; batch adversarial loss: 0.579129\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352200; batch adversarial loss: 0.664573\n",
      "epoch 17; iter: 0; batch classifier loss: 0.455313; batch adversarial loss: 0.647690\n",
      "epoch 17; iter: 200; batch classifier loss: 0.427785; batch adversarial loss: 0.602527\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325757; batch adversarial loss: 0.616648\n",
      "epoch 18; iter: 200; batch classifier loss: 0.339834; batch adversarial loss: 0.598128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436860; batch adversarial loss: 0.598162\n",
      "epoch 19; iter: 200; batch classifier loss: 0.324042; batch adversarial loss: 0.615392\n",
      "epoch 20; iter: 0; batch classifier loss: 0.363190; batch adversarial loss: 0.570621\n",
      "epoch 20; iter: 200; batch classifier loss: 0.354687; batch adversarial loss: 0.663036\n",
      "epoch 21; iter: 0; batch classifier loss: 0.491651; batch adversarial loss: 0.615355\n",
      "epoch 21; iter: 200; batch classifier loss: 0.304895; batch adversarial loss: 0.631997\n",
      "epoch 22; iter: 0; batch classifier loss: 0.328267; batch adversarial loss: 0.627160\n",
      "epoch 22; iter: 200; batch classifier loss: 0.278409; batch adversarial loss: 0.600820\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454193; batch adversarial loss: 0.627208\n",
      "epoch 23; iter: 200; batch classifier loss: 0.303858; batch adversarial loss: 0.638928\n",
      "epoch 24; iter: 0; batch classifier loss: 0.378306; batch adversarial loss: 0.600449\n",
      "epoch 24; iter: 200; batch classifier loss: 0.354529; batch adversarial loss: 0.595906\n",
      "epoch 25; iter: 0; batch classifier loss: 0.414508; batch adversarial loss: 0.619171\n",
      "epoch 25; iter: 200; batch classifier loss: 0.331542; batch adversarial loss: 0.574849\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329369; batch adversarial loss: 0.579517\n",
      "epoch 26; iter: 200; batch classifier loss: 0.417412; batch adversarial loss: 0.619523\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330537; batch adversarial loss: 0.602036\n",
      "epoch 27; iter: 200; batch classifier loss: 0.417149; batch adversarial loss: 0.694821\n",
      "epoch 28; iter: 0; batch classifier loss: 0.361238; batch adversarial loss: 0.633489\n",
      "epoch 28; iter: 200; batch classifier loss: 0.379073; batch adversarial loss: 0.648762\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322525; batch adversarial loss: 0.646173\n",
      "epoch 29; iter: 200; batch classifier loss: 0.310257; batch adversarial loss: 0.599082\n",
      "epoch 30; iter: 0; batch classifier loss: 0.297224; batch adversarial loss: 0.626302\n",
      "epoch 30; iter: 200; batch classifier loss: 0.279243; batch adversarial loss: 0.611645\n",
      "epoch 31; iter: 0; batch classifier loss: 0.353198; batch adversarial loss: 0.634691\n",
      "epoch 31; iter: 200; batch classifier loss: 0.356532; batch adversarial loss: 0.647350\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318610; batch adversarial loss: 0.588566\n",
      "epoch 32; iter: 200; batch classifier loss: 0.308709; batch adversarial loss: 0.579938\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442798; batch adversarial loss: 0.626801\n",
      "epoch 33; iter: 200; batch classifier loss: 0.345734; batch adversarial loss: 0.673804\n",
      "epoch 34; iter: 0; batch classifier loss: 0.335030; batch adversarial loss: 0.613833\n",
      "epoch 34; iter: 200; batch classifier loss: 0.321900; batch adversarial loss: 0.591944\n",
      "epoch 35; iter: 0; batch classifier loss: 0.255693; batch adversarial loss: 0.593090\n",
      "epoch 35; iter: 200; batch classifier loss: 0.407090; batch adversarial loss: 0.642181\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365259; batch adversarial loss: 0.659914\n",
      "epoch 36; iter: 200; batch classifier loss: 0.333383; batch adversarial loss: 0.601174\n",
      "epoch 37; iter: 0; batch classifier loss: 0.393350; batch adversarial loss: 0.599258\n",
      "epoch 37; iter: 200; batch classifier loss: 0.533094; batch adversarial loss: 0.625465\n",
      "epoch 38; iter: 0; batch classifier loss: 0.358276; batch adversarial loss: 0.703344\n",
      "epoch 38; iter: 200; batch classifier loss: 0.391788; batch adversarial loss: 0.594826\n",
      "epoch 39; iter: 0; batch classifier loss: 0.279955; batch adversarial loss: 0.675372\n",
      "epoch 39; iter: 200; batch classifier loss: 0.451959; batch adversarial loss: 0.574197\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240830; batch adversarial loss: 0.662896\n",
      "epoch 40; iter: 200; batch classifier loss: 0.354547; batch adversarial loss: 0.621039\n",
      "epoch 41; iter: 0; batch classifier loss: 0.341210; batch adversarial loss: 0.651646\n",
      "epoch 41; iter: 200; batch classifier loss: 0.383399; batch adversarial loss: 0.599382\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374629; batch adversarial loss: 0.548536\n",
      "epoch 42; iter: 200; batch classifier loss: 0.328630; batch adversarial loss: 0.665789\n",
      "epoch 43; iter: 0; batch classifier loss: 0.246665; batch adversarial loss: 0.638637\n",
      "epoch 43; iter: 200; batch classifier loss: 0.353496; batch adversarial loss: 0.613899\n",
      "epoch 44; iter: 0; batch classifier loss: 0.478608; batch adversarial loss: 0.629041\n",
      "epoch 44; iter: 200; batch classifier loss: 0.382584; batch adversarial loss: 0.647649\n",
      "epoch 45; iter: 0; batch classifier loss: 0.319922; batch adversarial loss: 0.681254\n",
      "epoch 45; iter: 200; batch classifier loss: 0.298284; batch adversarial loss: 0.609056\n",
      "epoch 46; iter: 0; batch classifier loss: 0.358256; batch adversarial loss: 0.612948\n",
      "epoch 46; iter: 200; batch classifier loss: 0.317883; batch adversarial loss: 0.606754\n",
      "epoch 47; iter: 0; batch classifier loss: 0.324384; batch adversarial loss: 0.643448\n",
      "epoch 47; iter: 200; batch classifier loss: 0.353897; batch adversarial loss: 0.662876\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414627; batch adversarial loss: 0.585429\n",
      "epoch 48; iter: 200; batch classifier loss: 0.398613; batch adversarial loss: 0.619375\n",
      "epoch 49; iter: 0; batch classifier loss: 0.253121; batch adversarial loss: 0.620188\n",
      "epoch 49; iter: 200; batch classifier loss: 0.303194; batch adversarial loss: 0.644235\n",
      "epoch 0; iter: 0; batch classifier loss: 18.703735; batch adversarial loss: 0.771669\n",
      "epoch 0; iter: 200; batch classifier loss: 9.301399; batch adversarial loss: 0.754529\n",
      "epoch 1; iter: 0; batch classifier loss: 49.765594; batch adversarial loss: 0.738617\n",
      "epoch 1; iter: 200; batch classifier loss: 5.532290; batch adversarial loss: 0.645777\n",
      "epoch 2; iter: 0; batch classifier loss: 4.947753; batch adversarial loss: 0.638586\n",
      "epoch 2; iter: 200; batch classifier loss: 8.081103; batch adversarial loss: 0.630519\n",
      "epoch 3; iter: 0; batch classifier loss: 16.005295; batch adversarial loss: 0.635884\n",
      "epoch 3; iter: 200; batch classifier loss: 1.882229; batch adversarial loss: 0.605723\n",
      "epoch 4; iter: 0; batch classifier loss: 10.148849; batch adversarial loss: 0.603985\n",
      "epoch 4; iter: 200; batch classifier loss: 0.878996; batch adversarial loss: 0.565777\n",
      "epoch 5; iter: 0; batch classifier loss: 1.423519; batch adversarial loss: 0.608820\n",
      "epoch 5; iter: 200; batch classifier loss: 1.099657; batch adversarial loss: 0.563392\n",
      "epoch 6; iter: 0; batch classifier loss: 1.504239; batch adversarial loss: 0.644118\n",
      "epoch 6; iter: 200; batch classifier loss: 0.656352; batch adversarial loss: 0.616919\n",
      "epoch 7; iter: 0; batch classifier loss: 1.321019; batch adversarial loss: 0.614485\n",
      "epoch 7; iter: 200; batch classifier loss: 0.907695; batch adversarial loss: 0.655319\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511348; batch adversarial loss: 0.631326\n",
      "epoch 8; iter: 200; batch classifier loss: 0.583181; batch adversarial loss: 0.611906\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551806; batch adversarial loss: 0.640274\n",
      "epoch 9; iter: 200; batch classifier loss: 0.554015; batch adversarial loss: 0.590469\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537954; batch adversarial loss: 0.642926\n",
      "epoch 10; iter: 200; batch classifier loss: 0.569965; batch adversarial loss: 0.636407\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539529; batch adversarial loss: 0.624731\n",
      "epoch 11; iter: 200; batch classifier loss: 0.551509; batch adversarial loss: 0.669731\n",
      "epoch 12; iter: 0; batch classifier loss: 0.411373; batch adversarial loss: 0.611433\n",
      "epoch 12; iter: 200; batch classifier loss: 0.537053; batch adversarial loss: 0.618194\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487940; batch adversarial loss: 0.614549\n",
      "epoch 13; iter: 200; batch classifier loss: 0.582685; batch adversarial loss: 0.607204\n",
      "epoch 14; iter: 0; batch classifier loss: 0.407596; batch adversarial loss: 0.627124\n",
      "epoch 14; iter: 200; batch classifier loss: 0.386821; batch adversarial loss: 0.619623\n",
      "epoch 15; iter: 0; batch classifier loss: 0.271156; batch adversarial loss: 0.618250\n",
      "epoch 15; iter: 200; batch classifier loss: 0.312006; batch adversarial loss: 0.640829\n",
      "epoch 16; iter: 0; batch classifier loss: 0.415155; batch adversarial loss: 0.566289\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399656; batch adversarial loss: 0.647526\n",
      "epoch 17; iter: 0; batch classifier loss: 0.380858; batch adversarial loss: 0.592017\n",
      "epoch 17; iter: 200; batch classifier loss: 0.316648; batch adversarial loss: 0.631673\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398328; batch adversarial loss: 0.600405\n",
      "epoch 18; iter: 200; batch classifier loss: 0.367854; batch adversarial loss: 0.645316\n",
      "epoch 19; iter: 0; batch classifier loss: 0.417311; batch adversarial loss: 0.618582\n",
      "epoch 19; iter: 200; batch classifier loss: 0.352978; batch adversarial loss: 0.626686\n",
      "epoch 20; iter: 0; batch classifier loss: 0.339051; batch adversarial loss: 0.595863\n",
      "epoch 20; iter: 200; batch classifier loss: 0.293160; batch adversarial loss: 0.638334\n",
      "epoch 21; iter: 0; batch classifier loss: 0.326545; batch adversarial loss: 0.583492\n",
      "epoch 21; iter: 200; batch classifier loss: 0.301102; batch adversarial loss: 0.621836\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490350; batch adversarial loss: 0.619145\n",
      "epoch 22; iter: 200; batch classifier loss: 0.397040; batch adversarial loss: 0.609928\n",
      "epoch 23; iter: 0; batch classifier loss: 0.361310; batch adversarial loss: 0.608975\n",
      "epoch 23; iter: 200; batch classifier loss: 0.333025; batch adversarial loss: 0.649542\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329620; batch adversarial loss: 0.611885\n",
      "epoch 24; iter: 200; batch classifier loss: 0.344500; batch adversarial loss: 0.576358\n",
      "epoch 25; iter: 0; batch classifier loss: 0.382624; batch adversarial loss: 0.612755\n",
      "epoch 25; iter: 200; batch classifier loss: 0.401805; batch adversarial loss: 0.559593\n",
      "epoch 26; iter: 0; batch classifier loss: 0.280348; batch adversarial loss: 0.586842\n",
      "epoch 26; iter: 200; batch classifier loss: 0.374625; batch adversarial loss: 0.598387\n",
      "epoch 27; iter: 0; batch classifier loss: 0.288794; batch adversarial loss: 0.581586\n",
      "epoch 27; iter: 200; batch classifier loss: 0.212118; batch adversarial loss: 0.612416\n",
      "epoch 28; iter: 0; batch classifier loss: 0.276503; batch adversarial loss: 0.564441\n",
      "epoch 28; iter: 200; batch classifier loss: 0.318292; batch adversarial loss: 0.555865\n",
      "epoch 29; iter: 0; batch classifier loss: 0.402007; batch adversarial loss: 0.533767\n",
      "epoch 29; iter: 200; batch classifier loss: 0.308205; batch adversarial loss: 0.633666\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414259; batch adversarial loss: 0.643750\n",
      "epoch 30; iter: 200; batch classifier loss: 0.363477; batch adversarial loss: 0.635956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.368970; batch adversarial loss: 0.621362\n",
      "epoch 31; iter: 200; batch classifier loss: 0.320896; batch adversarial loss: 0.664603\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329675; batch adversarial loss: 0.636193\n",
      "epoch 32; iter: 200; batch classifier loss: 0.350729; batch adversarial loss: 0.605588\n",
      "epoch 33; iter: 0; batch classifier loss: 0.320787; batch adversarial loss: 0.657549\n",
      "epoch 33; iter: 200; batch classifier loss: 0.382500; batch adversarial loss: 0.643704\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481800; batch adversarial loss: 0.607123\n",
      "epoch 34; iter: 200; batch classifier loss: 0.360276; batch adversarial loss: 0.615000\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395896; batch adversarial loss: 0.632253\n",
      "epoch 35; iter: 200; batch classifier loss: 0.356980; batch adversarial loss: 0.634935\n",
      "epoch 36; iter: 0; batch classifier loss: 0.342047; batch adversarial loss: 0.602252\n",
      "epoch 36; iter: 200; batch classifier loss: 0.359811; batch adversarial loss: 0.600727\n",
      "epoch 37; iter: 0; batch classifier loss: 0.305243; batch adversarial loss: 0.591949\n",
      "epoch 37; iter: 200; batch classifier loss: 0.288370; batch adversarial loss: 0.635970\n",
      "epoch 38; iter: 0; batch classifier loss: 0.322014; batch adversarial loss: 0.611152\n",
      "epoch 38; iter: 200; batch classifier loss: 0.441114; batch adversarial loss: 0.653482\n",
      "epoch 39; iter: 0; batch classifier loss: 0.292362; batch adversarial loss: 0.548465\n",
      "epoch 39; iter: 200; batch classifier loss: 0.477783; batch adversarial loss: 0.652381\n",
      "epoch 40; iter: 0; batch classifier loss: 0.313417; batch adversarial loss: 0.626755\n",
      "epoch 40; iter: 200; batch classifier loss: 0.365511; batch adversarial loss: 0.676104\n",
      "epoch 41; iter: 0; batch classifier loss: 0.341143; batch adversarial loss: 0.603901\n",
      "epoch 41; iter: 200; batch classifier loss: 0.385414; batch adversarial loss: 0.645556\n",
      "epoch 42; iter: 0; batch classifier loss: 0.388924; batch adversarial loss: 0.623259\n",
      "epoch 42; iter: 200; batch classifier loss: 0.277256; batch adversarial loss: 0.634719\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475380; batch adversarial loss: 0.613232\n",
      "epoch 43; iter: 200; batch classifier loss: 0.320046; batch adversarial loss: 0.650449\n",
      "epoch 44; iter: 0; batch classifier loss: 0.282037; batch adversarial loss: 0.645759\n",
      "epoch 44; iter: 200; batch classifier loss: 0.405499; batch adversarial loss: 0.618360\n",
      "epoch 45; iter: 0; batch classifier loss: 0.334187; batch adversarial loss: 0.613765\n",
      "epoch 45; iter: 200; batch classifier loss: 0.317323; batch adversarial loss: 0.661171\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385394; batch adversarial loss: 0.611359\n",
      "epoch 46; iter: 200; batch classifier loss: 0.294622; batch adversarial loss: 0.579030\n",
      "epoch 47; iter: 0; batch classifier loss: 0.358981; batch adversarial loss: 0.566835\n",
      "epoch 47; iter: 200; batch classifier loss: 0.294678; batch adversarial loss: 0.593574\n",
      "epoch 48; iter: 0; batch classifier loss: 0.358147; batch adversarial loss: 0.655201\n",
      "epoch 48; iter: 200; batch classifier loss: 0.485735; batch adversarial loss: 0.701660\n",
      "epoch 49; iter: 0; batch classifier loss: 0.342917; batch adversarial loss: 0.617989\n",
      "epoch 49; iter: 200; batch classifier loss: 0.464822; batch adversarial loss: 0.605781\n",
      "epoch 0; iter: 0; batch classifier loss: 98.408859; batch adversarial loss: 0.690148\n",
      "epoch 0; iter: 200; batch classifier loss: 2.605902; batch adversarial loss: 0.660805\n",
      "epoch 1; iter: 0; batch classifier loss: 7.140872; batch adversarial loss: 0.649182\n",
      "epoch 1; iter: 200; batch classifier loss: 11.203651; batch adversarial loss: 0.617178\n",
      "epoch 2; iter: 0; batch classifier loss: 3.696997; batch adversarial loss: 0.622889\n",
      "epoch 2; iter: 200; batch classifier loss: 3.894589; batch adversarial loss: 0.635941\n",
      "epoch 3; iter: 0; batch classifier loss: 5.655149; batch adversarial loss: 0.654833\n",
      "epoch 3; iter: 200; batch classifier loss: 2.199255; batch adversarial loss: 0.629229\n",
      "epoch 4; iter: 0; batch classifier loss: 2.101919; batch adversarial loss: 0.617697\n",
      "epoch 4; iter: 200; batch classifier loss: 2.366574; batch adversarial loss: 0.643007\n",
      "epoch 5; iter: 0; batch classifier loss: 4.348544; batch adversarial loss: 0.587231\n",
      "epoch 5; iter: 200; batch classifier loss: 2.182909; batch adversarial loss: 0.619802\n",
      "epoch 6; iter: 0; batch classifier loss: 1.191642; batch adversarial loss: 0.663792\n",
      "epoch 6; iter: 200; batch classifier loss: 0.498131; batch adversarial loss: 0.583219\n",
      "epoch 7; iter: 0; batch classifier loss: 0.639628; batch adversarial loss: 0.614395\n",
      "epoch 7; iter: 200; batch classifier loss: 0.460699; batch adversarial loss: 0.647468\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538773; batch adversarial loss: 0.604179\n",
      "epoch 8; iter: 200; batch classifier loss: 0.426981; batch adversarial loss: 0.665291\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506009; batch adversarial loss: 0.629103\n",
      "epoch 9; iter: 200; batch classifier loss: 0.408037; batch adversarial loss: 0.592074\n",
      "epoch 10; iter: 0; batch classifier loss: 0.439136; batch adversarial loss: 0.603267\n",
      "epoch 10; iter: 200; batch classifier loss: 0.475666; batch adversarial loss: 0.600305\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429228; batch adversarial loss: 0.545993\n",
      "epoch 11; iter: 200; batch classifier loss: 0.360550; batch adversarial loss: 0.660956\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427949; batch adversarial loss: 0.600568\n",
      "epoch 12; iter: 200; batch classifier loss: 0.341297; batch adversarial loss: 0.611680\n",
      "epoch 13; iter: 0; batch classifier loss: 0.636010; batch adversarial loss: 0.562086\n",
      "epoch 13; iter: 200; batch classifier loss: 0.294669; batch adversarial loss: 0.638828\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370712; batch adversarial loss: 0.644138\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351256; batch adversarial loss: 0.626073\n",
      "epoch 15; iter: 0; batch classifier loss: 0.384528; batch adversarial loss: 0.649697\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353448; batch adversarial loss: 0.609502\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349343; batch adversarial loss: 0.592507\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383170; batch adversarial loss: 0.623356\n",
      "epoch 17; iter: 0; batch classifier loss: 0.433842; batch adversarial loss: 0.624310\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346401; batch adversarial loss: 0.626126\n",
      "epoch 18; iter: 0; batch classifier loss: 0.646939; batch adversarial loss: 0.652607\n",
      "epoch 18; iter: 200; batch classifier loss: 0.391743; batch adversarial loss: 0.581603\n",
      "epoch 19; iter: 0; batch classifier loss: 0.304369; batch adversarial loss: 0.598222\n",
      "epoch 19; iter: 200; batch classifier loss: 0.454432; batch adversarial loss: 0.615731\n",
      "epoch 20; iter: 0; batch classifier loss: 0.353496; batch adversarial loss: 0.576684\n",
      "epoch 20; iter: 200; batch classifier loss: 0.419485; batch adversarial loss: 0.579941\n",
      "epoch 21; iter: 0; batch classifier loss: 0.346220; batch adversarial loss: 0.639941\n",
      "epoch 21; iter: 200; batch classifier loss: 0.391033; batch adversarial loss: 0.641656\n",
      "epoch 22; iter: 0; batch classifier loss: 0.290796; batch adversarial loss: 0.657656\n",
      "epoch 22; iter: 200; batch classifier loss: 0.430097; batch adversarial loss: 0.585386\n",
      "epoch 23; iter: 0; batch classifier loss: 0.355775; batch adversarial loss: 0.587523\n",
      "epoch 23; iter: 200; batch classifier loss: 0.362632; batch adversarial loss: 0.632978\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360186; batch adversarial loss: 0.676969\n",
      "epoch 24; iter: 200; batch classifier loss: 0.370849; batch adversarial loss: 0.645515\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360170; batch adversarial loss: 0.654013\n",
      "epoch 25; iter: 200; batch classifier loss: 0.260057; batch adversarial loss: 0.597720\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343673; batch adversarial loss: 0.623860\n",
      "epoch 26; iter: 200; batch classifier loss: 0.419094; batch adversarial loss: 0.605300\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424998; batch adversarial loss: 0.622477\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328916; batch adversarial loss: 0.563277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.379085; batch adversarial loss: 0.617598\n",
      "epoch 28; iter: 200; batch classifier loss: 0.251502; batch adversarial loss: 0.646256\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358537; batch adversarial loss: 0.626340\n",
      "epoch 29; iter: 200; batch classifier loss: 0.353524; batch adversarial loss: 0.616190\n",
      "epoch 30; iter: 0; batch classifier loss: 0.311282; batch adversarial loss: 0.586414\n",
      "epoch 30; iter: 200; batch classifier loss: 0.367808; batch adversarial loss: 0.649978\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320883; batch adversarial loss: 0.619750\n",
      "epoch 31; iter: 200; batch classifier loss: 0.454229; batch adversarial loss: 0.648752\n",
      "epoch 32; iter: 0; batch classifier loss: 0.379706; batch adversarial loss: 0.672570\n",
      "epoch 32; iter: 200; batch classifier loss: 0.327610; batch adversarial loss: 0.629547\n",
      "epoch 33; iter: 0; batch classifier loss: 0.250344; batch adversarial loss: 0.646007\n",
      "epoch 33; iter: 200; batch classifier loss: 0.243516; batch adversarial loss: 0.583234\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446797; batch adversarial loss: 0.619451\n",
      "epoch 34; iter: 200; batch classifier loss: 0.370043; batch adversarial loss: 0.657049\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390186; batch adversarial loss: 0.575209\n",
      "epoch 35; iter: 200; batch classifier loss: 0.363100; batch adversarial loss: 0.623210\n",
      "epoch 36; iter: 0; batch classifier loss: 0.380220; batch adversarial loss: 0.641308\n",
      "epoch 36; iter: 200; batch classifier loss: 0.291707; batch adversarial loss: 0.618836\n",
      "epoch 37; iter: 0; batch classifier loss: 0.279434; batch adversarial loss: 0.605864\n",
      "epoch 37; iter: 200; batch classifier loss: 0.392497; batch adversarial loss: 0.593613\n",
      "epoch 38; iter: 0; batch classifier loss: 0.257675; batch adversarial loss: 0.542577\n",
      "epoch 38; iter: 200; batch classifier loss: 1.000198; batch adversarial loss: 0.608090\n",
      "epoch 39; iter: 0; batch classifier loss: 0.354918; batch adversarial loss: 0.632736\n",
      "epoch 39; iter: 200; batch classifier loss: 0.344124; batch adversarial loss: 0.582434\n",
      "epoch 40; iter: 0; batch classifier loss: 0.350763; batch adversarial loss: 0.591131\n",
      "epoch 40; iter: 200; batch classifier loss: 0.400199; batch adversarial loss: 0.576774\n",
      "epoch 41; iter: 0; batch classifier loss: 0.331733; batch adversarial loss: 0.673115\n",
      "epoch 41; iter: 200; batch classifier loss: 0.350263; batch adversarial loss: 0.626261\n",
      "epoch 42; iter: 0; batch classifier loss: 0.612432; batch adversarial loss: 0.657628\n",
      "epoch 42; iter: 200; batch classifier loss: 0.364700; batch adversarial loss: 0.634351\n",
      "epoch 43; iter: 0; batch classifier loss: 0.318416; batch adversarial loss: 0.625596\n",
      "epoch 43; iter: 200; batch classifier loss: 0.379533; batch adversarial loss: 0.643901\n",
      "epoch 44; iter: 0; batch classifier loss: 0.370095; batch adversarial loss: 0.646131\n",
      "epoch 44; iter: 200; batch classifier loss: 0.522151; batch adversarial loss: 0.616216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354478; batch adversarial loss: 0.632068\n",
      "epoch 45; iter: 200; batch classifier loss: 0.318355; batch adversarial loss: 0.639693\n",
      "epoch 46; iter: 0; batch classifier loss: 0.442386; batch adversarial loss: 0.659658\n",
      "epoch 46; iter: 200; batch classifier loss: 0.377915; batch adversarial loss: 0.612721\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459926; batch adversarial loss: 0.623623\n",
      "epoch 47; iter: 200; batch classifier loss: 0.365331; batch adversarial loss: 0.635050\n",
      "epoch 48; iter: 0; batch classifier loss: 0.492675; batch adversarial loss: 0.615401\n",
      "epoch 48; iter: 200; batch classifier loss: 0.472145; batch adversarial loss: 0.589547\n",
      "epoch 49; iter: 0; batch classifier loss: 0.348965; batch adversarial loss: 0.646774\n",
      "epoch 49; iter: 200; batch classifier loss: 0.381441; batch adversarial loss: 0.596606\n",
      "epoch 0; iter: 0; batch classifier loss: 2.141611; batch adversarial loss: 0.717468\n",
      "epoch 0; iter: 200; batch classifier loss: 20.639107; batch adversarial loss: 0.656756\n",
      "epoch 1; iter: 0; batch classifier loss: 2.567836; batch adversarial loss: 0.654321\n",
      "epoch 1; iter: 200; batch classifier loss: 8.481429; batch adversarial loss: 0.607670\n",
      "epoch 2; iter: 0; batch classifier loss: 11.781008; batch adversarial loss: 0.632209\n",
      "epoch 2; iter: 200; batch classifier loss: 3.994877; batch adversarial loss: 0.651472\n",
      "epoch 3; iter: 0; batch classifier loss: 8.393094; batch adversarial loss: 0.603190\n",
      "epoch 3; iter: 200; batch classifier loss: 4.443850; batch adversarial loss: 0.613997\n",
      "epoch 4; iter: 0; batch classifier loss: 1.337583; batch adversarial loss: 0.627060\n",
      "epoch 4; iter: 200; batch classifier loss: 1.525695; batch adversarial loss: 0.624316\n",
      "epoch 5; iter: 0; batch classifier loss: 1.265748; batch adversarial loss: 0.594827\n",
      "epoch 5; iter: 200; batch classifier loss: 2.259401; batch adversarial loss: 0.619028\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513772; batch adversarial loss: 0.671989\n",
      "epoch 6; iter: 200; batch classifier loss: 0.839314; batch adversarial loss: 0.594800\n",
      "epoch 7; iter: 0; batch classifier loss: 1.032097; batch adversarial loss: 0.558190\n",
      "epoch 7; iter: 200; batch classifier loss: 0.952316; batch adversarial loss: 0.598024\n",
      "epoch 8; iter: 0; batch classifier loss: 0.488918; batch adversarial loss: 0.618188\n",
      "epoch 8; iter: 200; batch classifier loss: 0.480666; batch adversarial loss: 0.590539\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389462; batch adversarial loss: 0.657292\n",
      "epoch 9; iter: 200; batch classifier loss: 0.374510; batch adversarial loss: 0.599678\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307485; batch adversarial loss: 0.603095\n",
      "epoch 10; iter: 200; batch classifier loss: 0.751175; batch adversarial loss: 0.562289\n",
      "epoch 11; iter: 0; batch classifier loss: 0.385944; batch adversarial loss: 0.629258\n",
      "epoch 11; iter: 200; batch classifier loss: 0.471862; batch adversarial loss: 0.564914\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397046; batch adversarial loss: 0.621056\n",
      "epoch 12; iter: 200; batch classifier loss: 0.295676; batch adversarial loss: 0.599004\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384346; batch adversarial loss: 0.603931\n",
      "epoch 13; iter: 200; batch classifier loss: 0.234107; batch adversarial loss: 0.589595\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294272; batch adversarial loss: 0.600233\n",
      "epoch 14; iter: 200; batch classifier loss: 0.316399; batch adversarial loss: 0.540167\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424991; batch adversarial loss: 0.677373\n",
      "epoch 15; iter: 200; batch classifier loss: 0.355721; batch adversarial loss: 0.654219\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362773; batch adversarial loss: 0.603803\n",
      "epoch 16; iter: 200; batch classifier loss: 0.442791; batch adversarial loss: 0.608583\n",
      "epoch 17; iter: 0; batch classifier loss: 0.288441; batch adversarial loss: 0.612181\n",
      "epoch 17; iter: 200; batch classifier loss: 0.274703; batch adversarial loss: 0.639058\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387473; batch adversarial loss: 0.614836\n",
      "epoch 18; iter: 200; batch classifier loss: 0.374937; batch adversarial loss: 0.594041\n",
      "epoch 19; iter: 0; batch classifier loss: 0.328192; batch adversarial loss: 0.643829\n",
      "epoch 19; iter: 200; batch classifier loss: 0.358391; batch adversarial loss: 0.668131\n",
      "epoch 20; iter: 0; batch classifier loss: 0.355355; batch adversarial loss: 0.583574\n",
      "epoch 20; iter: 200; batch classifier loss: 0.331933; batch adversarial loss: 0.593987\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355953; batch adversarial loss: 0.610630\n",
      "epoch 21; iter: 200; batch classifier loss: 0.332534; batch adversarial loss: 0.615347\n",
      "epoch 22; iter: 0; batch classifier loss: 0.619266; batch adversarial loss: 0.616686\n",
      "epoch 22; iter: 200; batch classifier loss: 0.305955; batch adversarial loss: 0.700612\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445873; batch adversarial loss: 0.644724\n",
      "epoch 23; iter: 200; batch classifier loss: 0.335207; batch adversarial loss: 0.634588\n",
      "epoch 24; iter: 0; batch classifier loss: 0.317543; batch adversarial loss: 0.621715\n",
      "epoch 24; iter: 200; batch classifier loss: 0.408304; batch adversarial loss: 0.606995\n",
      "epoch 25; iter: 0; batch classifier loss: 0.345523; batch adversarial loss: 0.632254\n",
      "epoch 25; iter: 200; batch classifier loss: 0.383919; batch adversarial loss: 0.656154\n",
      "epoch 26; iter: 0; batch classifier loss: 0.526174; batch adversarial loss: 0.611975\n",
      "epoch 26; iter: 200; batch classifier loss: 0.354706; batch adversarial loss: 0.598015\n",
      "epoch 27; iter: 0; batch classifier loss: 0.256449; batch adversarial loss: 0.656535\n",
      "epoch 27; iter: 200; batch classifier loss: 0.419845; batch adversarial loss: 0.548787\n",
      "epoch 28; iter: 0; batch classifier loss: 0.424752; batch adversarial loss: 0.588393\n",
      "epoch 28; iter: 200; batch classifier loss: 0.414752; batch adversarial loss: 0.548259\n",
      "epoch 29; iter: 0; batch classifier loss: 0.368972; batch adversarial loss: 0.597507\n",
      "epoch 29; iter: 200; batch classifier loss: 0.294502; batch adversarial loss: 0.621264\n",
      "epoch 30; iter: 0; batch classifier loss: 0.332607; batch adversarial loss: 0.586491\n",
      "epoch 30; iter: 200; batch classifier loss: 0.348490; batch adversarial loss: 0.633457\n",
      "epoch 31; iter: 0; batch classifier loss: 0.359136; batch adversarial loss: 0.653198\n",
      "epoch 31; iter: 200; batch classifier loss: 0.365095; batch adversarial loss: 0.655127\n",
      "epoch 32; iter: 0; batch classifier loss: 0.331757; batch adversarial loss: 0.633811\n",
      "epoch 32; iter: 200; batch classifier loss: 0.367014; batch adversarial loss: 0.590640\n",
      "epoch 33; iter: 0; batch classifier loss: 0.430852; batch adversarial loss: 0.645720\n",
      "epoch 33; iter: 200; batch classifier loss: 0.422004; batch adversarial loss: 0.555520\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276878; batch adversarial loss: 0.607029\n",
      "epoch 34; iter: 200; batch classifier loss: 0.418524; batch adversarial loss: 0.573437\n",
      "epoch 35; iter: 0; batch classifier loss: 0.278335; batch adversarial loss: 0.645106\n",
      "epoch 35; iter: 200; batch classifier loss: 0.313048; batch adversarial loss: 0.658318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.305721; batch adversarial loss: 0.620146\n",
      "epoch 36; iter: 200; batch classifier loss: 0.327092; batch adversarial loss: 0.578391\n",
      "epoch 37; iter: 0; batch classifier loss: 0.396973; batch adversarial loss: 0.641531\n",
      "epoch 37; iter: 200; batch classifier loss: 0.798980; batch adversarial loss: 0.598623\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417182; batch adversarial loss: 0.656416\n",
      "epoch 38; iter: 200; batch classifier loss: 0.397678; batch adversarial loss: 0.639626\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386558; batch adversarial loss: 0.618392\n",
      "epoch 39; iter: 200; batch classifier loss: 0.356521; batch adversarial loss: 0.642704\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361974; batch adversarial loss: 0.594747\n",
      "epoch 40; iter: 200; batch classifier loss: 0.394198; batch adversarial loss: 0.626060\n",
      "epoch 41; iter: 0; batch classifier loss: 0.353727; batch adversarial loss: 0.610241\n",
      "epoch 41; iter: 200; batch classifier loss: 0.303568; batch adversarial loss: 0.602193\n",
      "epoch 42; iter: 0; batch classifier loss: 0.350507; batch adversarial loss: 0.636352\n",
      "epoch 42; iter: 200; batch classifier loss: 0.282524; batch adversarial loss: 0.608494\n",
      "epoch 43; iter: 0; batch classifier loss: 0.424733; batch adversarial loss: 0.652132\n",
      "epoch 43; iter: 200; batch classifier loss: 0.407461; batch adversarial loss: 0.639494\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461856; batch adversarial loss: 0.572118\n",
      "epoch 44; iter: 200; batch classifier loss: 0.279681; batch adversarial loss: 0.664188\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428775; batch adversarial loss: 0.547218\n",
      "epoch 45; iter: 200; batch classifier loss: 0.277940; batch adversarial loss: 0.610217\n",
      "epoch 46; iter: 0; batch classifier loss: 0.287592; batch adversarial loss: 0.668991\n",
      "epoch 46; iter: 200; batch classifier loss: 0.389147; batch adversarial loss: 0.660209\n",
      "epoch 47; iter: 0; batch classifier loss: 0.338650; batch adversarial loss: 0.663592\n",
      "epoch 47; iter: 200; batch classifier loss: 0.395447; batch adversarial loss: 0.580879\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391052; batch adversarial loss: 0.614929\n",
      "epoch 48; iter: 200; batch classifier loss: 0.449284; batch adversarial loss: 0.613885\n",
      "epoch 49; iter: 0; batch classifier loss: 0.270648; batch adversarial loss: 0.600880\n",
      "epoch 49; iter: 200; batch classifier loss: 0.436727; batch adversarial loss: 0.608301\n",
      "epoch 0; iter: 0; batch classifier loss: 70.913689; batch adversarial loss: 0.668266\n",
      "epoch 0; iter: 200; batch classifier loss: 10.380091; batch adversarial loss: 0.613784\n",
      "epoch 1; iter: 0; batch classifier loss: 2.822990; batch adversarial loss: 0.593092\n",
      "epoch 1; iter: 200; batch classifier loss: 5.313148; batch adversarial loss: 0.578085\n",
      "epoch 2; iter: 0; batch classifier loss: 4.128261; batch adversarial loss: 0.586823\n",
      "epoch 2; iter: 200; batch classifier loss: 3.138798; batch adversarial loss: 0.619275\n",
      "epoch 3; iter: 0; batch classifier loss: 3.804492; batch adversarial loss: 0.636466\n",
      "epoch 3; iter: 200; batch classifier loss: 2.972173; batch adversarial loss: 0.653328\n",
      "epoch 4; iter: 0; batch classifier loss: 1.794093; batch adversarial loss: 0.650809\n",
      "epoch 4; iter: 200; batch classifier loss: 1.863046; batch adversarial loss: 0.622459\n",
      "epoch 5; iter: 0; batch classifier loss: 0.706593; batch adversarial loss: 0.627111\n",
      "epoch 5; iter: 200; batch classifier loss: 1.617216; batch adversarial loss: 0.687777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.997239; batch adversarial loss: 0.613820\n",
      "epoch 6; iter: 200; batch classifier loss: 0.591514; batch adversarial loss: 0.638650\n",
      "epoch 7; iter: 0; batch classifier loss: 0.476878; batch adversarial loss: 0.652441\n",
      "epoch 7; iter: 200; batch classifier loss: 0.446179; batch adversarial loss: 0.618434\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396976; batch adversarial loss: 0.660566\n",
      "epoch 8; iter: 200; batch classifier loss: 0.558530; batch adversarial loss: 0.591002\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442065; batch adversarial loss: 0.620306\n",
      "epoch 9; iter: 200; batch classifier loss: 0.463804; batch adversarial loss: 0.643629\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445613; batch adversarial loss: 0.654072\n",
      "epoch 10; iter: 200; batch classifier loss: 0.434942; batch adversarial loss: 0.628512\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398618; batch adversarial loss: 0.655681\n",
      "epoch 11; iter: 200; batch classifier loss: 0.343034; batch adversarial loss: 0.628570\n",
      "epoch 12; iter: 0; batch classifier loss: 0.458989; batch adversarial loss: 0.602853\n",
      "epoch 12; iter: 200; batch classifier loss: 0.325487; batch adversarial loss: 0.607301\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369429; batch adversarial loss: 0.584232\n",
      "epoch 13; iter: 200; batch classifier loss: 0.339480; batch adversarial loss: 0.647032\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342861; batch adversarial loss: 0.622650\n",
      "epoch 14; iter: 200; batch classifier loss: 0.281329; batch adversarial loss: 0.652942\n",
      "epoch 15; iter: 0; batch classifier loss: 0.426434; batch adversarial loss: 0.600740\n",
      "epoch 15; iter: 200; batch classifier loss: 0.350047; batch adversarial loss: 0.617909\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346907; batch adversarial loss: 0.628498\n",
      "epoch 16; iter: 200; batch classifier loss: 0.360868; batch adversarial loss: 0.563067\n",
      "epoch 17; iter: 0; batch classifier loss: 0.359547; batch adversarial loss: 0.674186\n",
      "epoch 17; iter: 200; batch classifier loss: 0.306110; batch adversarial loss: 0.648575\n",
      "epoch 18; iter: 0; batch classifier loss: 0.381357; batch adversarial loss: 0.562663\n",
      "epoch 18; iter: 200; batch classifier loss: 0.333369; batch adversarial loss: 0.626428\n",
      "epoch 19; iter: 0; batch classifier loss: 0.339076; batch adversarial loss: 0.564001\n",
      "epoch 19; iter: 200; batch classifier loss: 0.327868; batch adversarial loss: 0.631886\n",
      "epoch 20; iter: 0; batch classifier loss: 0.255533; batch adversarial loss: 0.590443\n",
      "epoch 20; iter: 200; batch classifier loss: 0.270895; batch adversarial loss: 0.645403\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319491; batch adversarial loss: 0.668300\n",
      "epoch 21; iter: 200; batch classifier loss: 0.381199; batch adversarial loss: 0.627278\n",
      "epoch 22; iter: 0; batch classifier loss: 0.507255; batch adversarial loss: 0.640433\n",
      "epoch 22; iter: 200; batch classifier loss: 0.503007; batch adversarial loss: 0.612757\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288763; batch adversarial loss: 0.587343\n",
      "epoch 23; iter: 200; batch classifier loss: 0.315051; batch adversarial loss: 0.572943\n",
      "epoch 24; iter: 0; batch classifier loss: 0.365241; batch adversarial loss: 0.592254\n",
      "epoch 24; iter: 200; batch classifier loss: 0.434625; batch adversarial loss: 0.626222\n",
      "epoch 25; iter: 0; batch classifier loss: 0.329378; batch adversarial loss: 0.617494\n",
      "epoch 25; iter: 200; batch classifier loss: 0.419192; batch adversarial loss: 0.630293\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343034; batch adversarial loss: 0.614538\n",
      "epoch 26; iter: 200; batch classifier loss: 0.305095; batch adversarial loss: 0.644785\n",
      "epoch 27; iter: 0; batch classifier loss: 0.311235; batch adversarial loss: 0.607311\n",
      "epoch 27; iter: 200; batch classifier loss: 0.422711; batch adversarial loss: 0.631392\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375704; batch adversarial loss: 0.616421\n",
      "epoch 28; iter: 200; batch classifier loss: 0.301889; batch adversarial loss: 0.655725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.265348; batch adversarial loss: 0.624101\n",
      "epoch 29; iter: 200; batch classifier loss: 0.368241; batch adversarial loss: 0.588688\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424391; batch adversarial loss: 0.622734\n",
      "epoch 30; iter: 200; batch classifier loss: 0.394506; batch adversarial loss: 0.558432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.292580; batch adversarial loss: 0.686094\n",
      "epoch 31; iter: 200; batch classifier loss: 0.280581; batch adversarial loss: 0.621279\n",
      "epoch 32; iter: 0; batch classifier loss: 0.324083; batch adversarial loss: 0.585031\n",
      "epoch 32; iter: 200; batch classifier loss: 0.363662; batch adversarial loss: 0.609266\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355462; batch adversarial loss: 0.602728\n",
      "epoch 33; iter: 200; batch classifier loss: 0.307624; batch adversarial loss: 0.584264\n",
      "epoch 34; iter: 0; batch classifier loss: 0.365851; batch adversarial loss: 0.563102\n",
      "epoch 34; iter: 200; batch classifier loss: 0.363012; batch adversarial loss: 0.611293\n",
      "epoch 35; iter: 0; batch classifier loss: 0.339562; batch adversarial loss: 0.640754\n",
      "epoch 35; iter: 200; batch classifier loss: 0.340128; batch adversarial loss: 0.637016\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405638; batch adversarial loss: 0.577931\n",
      "epoch 36; iter: 200; batch classifier loss: 0.296100; batch adversarial loss: 0.577119\n",
      "epoch 37; iter: 0; batch classifier loss: 0.374186; batch adversarial loss: 0.578089\n",
      "epoch 37; iter: 200; batch classifier loss: 0.289022; batch adversarial loss: 0.674839\n",
      "epoch 38; iter: 0; batch classifier loss: 0.302913; batch adversarial loss: 0.586737\n",
      "epoch 38; iter: 200; batch classifier loss: 0.361211; batch adversarial loss: 0.645632\n",
      "epoch 39; iter: 0; batch classifier loss: 0.342776; batch adversarial loss: 0.660850\n",
      "epoch 39; iter: 200; batch classifier loss: 0.299291; batch adversarial loss: 0.605387\n",
      "epoch 40; iter: 0; batch classifier loss: 0.322719; batch adversarial loss: 0.684593\n",
      "epoch 40; iter: 200; batch classifier loss: 0.397572; batch adversarial loss: 0.604873\n",
      "epoch 41; iter: 0; batch classifier loss: 0.352841; batch adversarial loss: 0.582763\n",
      "epoch 41; iter: 200; batch classifier loss: 0.314634; batch adversarial loss: 0.631113\n",
      "epoch 42; iter: 0; batch classifier loss: 0.239955; batch adversarial loss: 0.638267\n",
      "epoch 42; iter: 200; batch classifier loss: 0.462102; batch adversarial loss: 0.644309\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419704; batch adversarial loss: 0.623102\n",
      "epoch 43; iter: 200; batch classifier loss: 0.405801; batch adversarial loss: 0.688568\n",
      "epoch 44; iter: 0; batch classifier loss: 0.370340; batch adversarial loss: 0.645596\n",
      "epoch 44; iter: 200; batch classifier loss: 0.350519; batch adversarial loss: 0.632348\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426377; batch adversarial loss: 0.604947\n",
      "epoch 45; iter: 200; batch classifier loss: 0.362551; batch adversarial loss: 0.642429\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200983; batch adversarial loss: 0.650327\n",
      "epoch 46; iter: 200; batch classifier loss: 0.343625; batch adversarial loss: 0.605332\n",
      "epoch 47; iter: 0; batch classifier loss: 0.313666; batch adversarial loss: 0.650907\n",
      "epoch 47; iter: 200; batch classifier loss: 0.465906; batch adversarial loss: 0.626279\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415588; batch adversarial loss: 0.639157\n",
      "epoch 48; iter: 200; batch classifier loss: 0.481718; batch adversarial loss: 0.606405\n",
      "epoch 49; iter: 0; batch classifier loss: 0.284001; batch adversarial loss: 0.652635\n",
      "epoch 49; iter: 200; batch classifier loss: 0.330475; batch adversarial loss: 0.663206\n",
      "epoch 0; iter: 0; batch classifier loss: 30.513111; batch adversarial loss: 0.664207\n",
      "epoch 0; iter: 200; batch classifier loss: 2.342237; batch adversarial loss: 0.695074\n",
      "epoch 1; iter: 0; batch classifier loss: 9.220347; batch adversarial loss: 0.677633\n",
      "epoch 1; iter: 200; batch classifier loss: 6.014393; batch adversarial loss: 0.681974\n",
      "epoch 2; iter: 0; batch classifier loss: 5.977682; batch adversarial loss: 0.644715\n",
      "epoch 2; iter: 200; batch classifier loss: 3.152742; batch adversarial loss: 0.565113\n",
      "epoch 3; iter: 0; batch classifier loss: 2.960490; batch adversarial loss: 0.620958\n",
      "epoch 3; iter: 200; batch classifier loss: 1.396542; batch adversarial loss: 0.613380\n",
      "epoch 4; iter: 0; batch classifier loss: 1.536241; batch adversarial loss: 0.581015\n",
      "epoch 4; iter: 200; batch classifier loss: 1.273240; batch adversarial loss: 0.601387\n",
      "epoch 5; iter: 0; batch classifier loss: 1.089948; batch adversarial loss: 0.578522\n",
      "epoch 5; iter: 200; batch classifier loss: 0.989848; batch adversarial loss: 0.670958\n",
      "epoch 6; iter: 0; batch classifier loss: 0.816093; batch adversarial loss: 0.656852\n",
      "epoch 6; iter: 200; batch classifier loss: 0.536638; batch adversarial loss: 0.626492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.394227; batch adversarial loss: 0.648779\n",
      "epoch 7; iter: 200; batch classifier loss: 0.405134; batch adversarial loss: 0.583034\n",
      "epoch 8; iter: 0; batch classifier loss: 0.392857; batch adversarial loss: 0.676919\n",
      "epoch 8; iter: 200; batch classifier loss: 0.474830; batch adversarial loss: 0.593300\n",
      "epoch 9; iter: 0; batch classifier loss: 0.666452; batch adversarial loss: 0.596112\n",
      "epoch 9; iter: 200; batch classifier loss: 0.364692; batch adversarial loss: 0.652572\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426636; batch adversarial loss: 0.618807\n",
      "epoch 10; iter: 200; batch classifier loss: 0.385964; batch adversarial loss: 0.651486\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393889; batch adversarial loss: 0.655966\n",
      "epoch 11; iter: 200; batch classifier loss: 0.329880; batch adversarial loss: 0.608396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368972; batch adversarial loss: 0.630436\n",
      "epoch 12; iter: 200; batch classifier loss: 0.383861; batch adversarial loss: 0.598034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.242111; batch adversarial loss: 0.638789\n",
      "epoch 13; iter: 200; batch classifier loss: 0.407839; batch adversarial loss: 0.631336\n",
      "epoch 14; iter: 0; batch classifier loss: 0.365823; batch adversarial loss: 0.629596\n",
      "epoch 14; iter: 200; batch classifier loss: 0.461011; batch adversarial loss: 0.584503\n",
      "epoch 15; iter: 0; batch classifier loss: 0.397682; batch adversarial loss: 0.582318\n",
      "epoch 15; iter: 200; batch classifier loss: 0.331713; batch adversarial loss: 0.622906\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344031; batch adversarial loss: 0.598835\n",
      "epoch 16; iter: 200; batch classifier loss: 0.398841; batch adversarial loss: 0.559207\n",
      "epoch 17; iter: 0; batch classifier loss: 0.321611; batch adversarial loss: 0.590988\n",
      "epoch 17; iter: 200; batch classifier loss: 0.337922; batch adversarial loss: 0.637448\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309942; batch adversarial loss: 0.524881\n",
      "epoch 18; iter: 200; batch classifier loss: 0.292824; batch adversarial loss: 0.621898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.388522; batch adversarial loss: 0.681245\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376664; batch adversarial loss: 0.603327\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314192; batch adversarial loss: 0.635428\n",
      "epoch 20; iter: 200; batch classifier loss: 0.410183; batch adversarial loss: 0.629406\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305696; batch adversarial loss: 0.634401\n",
      "epoch 21; iter: 200; batch classifier loss: 0.397052; batch adversarial loss: 0.578699\n",
      "epoch 22; iter: 0; batch classifier loss: 0.269232; batch adversarial loss: 0.644572\n",
      "epoch 22; iter: 200; batch classifier loss: 0.402185; batch adversarial loss: 0.584605\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275253; batch adversarial loss: 0.656361\n",
      "epoch 23; iter: 200; batch classifier loss: 0.445015; batch adversarial loss: 0.628340\n",
      "epoch 24; iter: 0; batch classifier loss: 0.264866; batch adversarial loss: 0.555471\n",
      "epoch 24; iter: 200; batch classifier loss: 0.420253; batch adversarial loss: 0.617913\n",
      "epoch 25; iter: 0; batch classifier loss: 0.414020; batch adversarial loss: 0.643595\n",
      "epoch 25; iter: 200; batch classifier loss: 0.245265; batch adversarial loss: 0.573476\n",
      "epoch 26; iter: 0; batch classifier loss: 0.371863; batch adversarial loss: 0.618387\n",
      "epoch 26; iter: 200; batch classifier loss: 0.298129; batch adversarial loss: 0.710595\n",
      "epoch 27; iter: 0; batch classifier loss: 0.331758; batch adversarial loss: 0.619301\n",
      "epoch 27; iter: 200; batch classifier loss: 0.338219; batch adversarial loss: 0.587657\n",
      "epoch 28; iter: 0; batch classifier loss: 0.294065; batch adversarial loss: 0.636230\n",
      "epoch 28; iter: 200; batch classifier loss: 0.450019; batch adversarial loss: 0.624561\n",
      "epoch 29; iter: 0; batch classifier loss: 0.345183; batch adversarial loss: 0.604724\n",
      "epoch 29; iter: 200; batch classifier loss: 0.332293; batch adversarial loss: 0.607112\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402398; batch adversarial loss: 0.638977\n",
      "epoch 30; iter: 200; batch classifier loss: 0.346388; batch adversarial loss: 0.658960\n",
      "epoch 31; iter: 0; batch classifier loss: 0.298600; batch adversarial loss: 0.660859\n",
      "epoch 31; iter: 200; batch classifier loss: 0.524485; batch adversarial loss: 0.637674\n",
      "epoch 32; iter: 0; batch classifier loss: 0.379143; batch adversarial loss: 0.583063\n",
      "epoch 32; iter: 200; batch classifier loss: 0.305032; batch adversarial loss: 0.645444\n",
      "epoch 33; iter: 0; batch classifier loss: 0.394499; batch adversarial loss: 0.592207\n",
      "epoch 33; iter: 200; batch classifier loss: 0.310675; batch adversarial loss: 0.604087\n",
      "epoch 34; iter: 0; batch classifier loss: 0.332972; batch adversarial loss: 0.610793\n",
      "epoch 34; iter: 200; batch classifier loss: 0.331905; batch adversarial loss: 0.645733\n",
      "epoch 35; iter: 0; batch classifier loss: 0.331458; batch adversarial loss: 0.644486\n",
      "epoch 35; iter: 200; batch classifier loss: 0.292638; batch adversarial loss: 0.642315\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293585; batch adversarial loss: 0.596959\n",
      "epoch 36; iter: 200; batch classifier loss: 0.318827; batch adversarial loss: 0.609515\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479785; batch adversarial loss: 0.606657\n",
      "epoch 37; iter: 200; batch classifier loss: 0.357746; batch adversarial loss: 0.582003\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279851; batch adversarial loss: 0.579470\n",
      "epoch 38; iter: 200; batch classifier loss: 0.507338; batch adversarial loss: 0.611914\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413485; batch adversarial loss: 0.642959\n",
      "epoch 39; iter: 200; batch classifier loss: 0.284087; batch adversarial loss: 0.588537\n",
      "epoch 40; iter: 0; batch classifier loss: 0.346473; batch adversarial loss: 0.620516\n",
      "epoch 40; iter: 200; batch classifier loss: 0.370710; batch adversarial loss: 0.646525\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265111; batch adversarial loss: 0.599886\n",
      "epoch 41; iter: 200; batch classifier loss: 0.271908; batch adversarial loss: 0.649843\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372540; batch adversarial loss: 0.636582\n",
      "epoch 42; iter: 200; batch classifier loss: 0.414172; batch adversarial loss: 0.660968\n",
      "epoch 43; iter: 0; batch classifier loss: 0.339585; batch adversarial loss: 0.611317\n",
      "epoch 43; iter: 200; batch classifier loss: 0.317256; batch adversarial loss: 0.584439\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398237; batch adversarial loss: 0.607489\n",
      "epoch 44; iter: 200; batch classifier loss: 0.356810; batch adversarial loss: 0.586141\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420464; batch adversarial loss: 0.634872\n",
      "epoch 45; iter: 200; batch classifier loss: 0.379613; batch adversarial loss: 0.647351\n",
      "epoch 46; iter: 0; batch classifier loss: 0.329445; batch adversarial loss: 0.607547\n",
      "epoch 46; iter: 200; batch classifier loss: 0.262211; batch adversarial loss: 0.686131\n",
      "epoch 47; iter: 0; batch classifier loss: 0.341052; batch adversarial loss: 0.625190\n",
      "epoch 47; iter: 200; batch classifier loss: 0.503883; batch adversarial loss: 0.663886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398712; batch adversarial loss: 0.631240\n",
      "epoch 48; iter: 200; batch classifier loss: 0.281413; batch adversarial loss: 0.645126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380248; batch adversarial loss: 0.648840\n",
      "epoch 49; iter: 200; batch classifier loss: 0.283265; batch adversarial loss: 0.620021\n",
      "epoch 0; iter: 0; batch classifier loss: 10.013691; batch adversarial loss: 0.691478\n",
      "epoch 0; iter: 200; batch classifier loss: 4.092746; batch adversarial loss: 0.645060\n",
      "epoch 1; iter: 0; batch classifier loss: 1.967465; batch adversarial loss: 0.631162\n",
      "epoch 1; iter: 200; batch classifier loss: 14.375051; batch adversarial loss: 0.609854\n",
      "epoch 2; iter: 0; batch classifier loss: 25.458511; batch adversarial loss: 0.626053\n",
      "epoch 2; iter: 200; batch classifier loss: 10.635826; batch adversarial loss: 0.637530\n",
      "epoch 3; iter: 0; batch classifier loss: 3.649726; batch adversarial loss: 0.615840\n",
      "epoch 3; iter: 200; batch classifier loss: 2.707994; batch adversarial loss: 0.593322\n",
      "epoch 4; iter: 0; batch classifier loss: 3.784877; batch adversarial loss: 0.631787\n",
      "epoch 4; iter: 200; batch classifier loss: 1.487867; batch adversarial loss: 0.606148\n",
      "epoch 5; iter: 0; batch classifier loss: 3.131609; batch adversarial loss: 0.581881\n",
      "epoch 5; iter: 200; batch classifier loss: 1.818246; batch adversarial loss: 0.658974\n",
      "epoch 6; iter: 0; batch classifier loss: 1.693532; batch adversarial loss: 0.627927\n",
      "epoch 6; iter: 200; batch classifier loss: 0.781941; batch adversarial loss: 0.685408\n",
      "epoch 7; iter: 0; batch classifier loss: 0.711364; batch adversarial loss: 0.584229\n",
      "epoch 7; iter: 200; batch classifier loss: 0.747121; batch adversarial loss: 0.634833\n",
      "epoch 8; iter: 0; batch classifier loss: 0.459970; batch adversarial loss: 0.591815\n",
      "epoch 8; iter: 200; batch classifier loss: 0.469534; batch adversarial loss: 0.627420\n",
      "epoch 9; iter: 0; batch classifier loss: 0.425746; batch adversarial loss: 0.645731\n",
      "epoch 9; iter: 200; batch classifier loss: 0.545335; batch adversarial loss: 0.636526\n",
      "epoch 10; iter: 0; batch classifier loss: 0.423698; batch adversarial loss: 0.596206\n",
      "epoch 10; iter: 200; batch classifier loss: 0.435106; batch adversarial loss: 0.610329\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308346; batch adversarial loss: 0.584597\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449002; batch adversarial loss: 0.631744\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404993; batch adversarial loss: 0.635618\n",
      "epoch 12; iter: 200; batch classifier loss: 0.445183; batch adversarial loss: 0.623362\n",
      "epoch 13; iter: 0; batch classifier loss: 0.371338; batch adversarial loss: 0.622774\n",
      "epoch 13; iter: 200; batch classifier loss: 0.455672; batch adversarial loss: 0.600517\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367477; batch adversarial loss: 0.603854\n",
      "epoch 14; iter: 200; batch classifier loss: 0.396625; batch adversarial loss: 0.620575\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362840; batch adversarial loss: 0.621441\n",
      "epoch 15; iter: 200; batch classifier loss: 0.342582; batch adversarial loss: 0.682716\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349327; batch adversarial loss: 0.631080\n",
      "epoch 16; iter: 200; batch classifier loss: 0.350997; batch adversarial loss: 0.578414\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352796; batch adversarial loss: 0.606161\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321387; batch adversarial loss: 0.637985\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342203; batch adversarial loss: 0.555618\n",
      "epoch 18; iter: 200; batch classifier loss: 0.392392; batch adversarial loss: 0.577743\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306311; batch adversarial loss: 0.685061\n",
      "epoch 19; iter: 200; batch classifier loss: 0.379824; batch adversarial loss: 0.636746\n",
      "epoch 20; iter: 0; batch classifier loss: 0.418172; batch adversarial loss: 0.614607\n",
      "epoch 20; iter: 200; batch classifier loss: 0.384139; batch adversarial loss: 0.586529\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265769; batch adversarial loss: 0.626468\n",
      "epoch 21; iter: 200; batch classifier loss: 0.332699; batch adversarial loss: 0.625514\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339992; batch adversarial loss: 0.635229\n",
      "epoch 22; iter: 200; batch classifier loss: 0.422106; batch adversarial loss: 0.619443\n",
      "epoch 23; iter: 0; batch classifier loss: 0.329411; batch adversarial loss: 0.608383\n",
      "epoch 23; iter: 200; batch classifier loss: 0.372341; batch adversarial loss: 0.627318\n",
      "epoch 24; iter: 0; batch classifier loss: 0.344016; batch adversarial loss: 0.624894\n",
      "epoch 24; iter: 200; batch classifier loss: 0.441981; batch adversarial loss: 0.574151\n",
      "epoch 25; iter: 0; batch classifier loss: 0.368961; batch adversarial loss: 0.714493\n",
      "epoch 25; iter: 200; batch classifier loss: 0.479290; batch adversarial loss: 0.625920\n",
      "epoch 26; iter: 0; batch classifier loss: 0.405961; batch adversarial loss: 0.570190\n",
      "epoch 26; iter: 200; batch classifier loss: 0.384029; batch adversarial loss: 0.575471\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392132; batch adversarial loss: 0.623100\n",
      "epoch 27; iter: 200; batch classifier loss: 0.314084; batch adversarial loss: 0.599080\n",
      "epoch 28; iter: 0; batch classifier loss: 0.344756; batch adversarial loss: 0.610183\n",
      "epoch 28; iter: 200; batch classifier loss: 0.378618; batch adversarial loss: 0.666238\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386418; batch adversarial loss: 0.579213\n",
      "epoch 29; iter: 200; batch classifier loss: 0.339880; batch adversarial loss: 0.639568\n",
      "epoch 30; iter: 0; batch classifier loss: 0.307613; batch adversarial loss: 0.611130\n",
      "epoch 30; iter: 200; batch classifier loss: 0.364957; batch adversarial loss: 0.609721\n",
      "epoch 31; iter: 0; batch classifier loss: 0.258776; batch adversarial loss: 0.643561\n",
      "epoch 31; iter: 200; batch classifier loss: 0.405599; batch adversarial loss: 0.625893\n",
      "epoch 32; iter: 0; batch classifier loss: 0.390457; batch adversarial loss: 0.608754\n",
      "epoch 32; iter: 200; batch classifier loss: 0.496213; batch adversarial loss: 0.641974\n",
      "epoch 33; iter: 0; batch classifier loss: 0.331523; batch adversarial loss: 0.614330\n",
      "epoch 33; iter: 200; batch classifier loss: 0.454820; batch adversarial loss: 0.644139\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266655; batch adversarial loss: 0.566716\n",
      "epoch 34; iter: 200; batch classifier loss: 0.268829; batch adversarial loss: 0.610473\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437662; batch adversarial loss: 0.595170\n",
      "epoch 35; iter: 200; batch classifier loss: 0.331137; batch adversarial loss: 0.644180\n",
      "epoch 36; iter: 0; batch classifier loss: 0.372853; batch adversarial loss: 0.626276\n",
      "epoch 36; iter: 200; batch classifier loss: 0.399839; batch adversarial loss: 0.601204\n",
      "epoch 37; iter: 0; batch classifier loss: 0.324688; batch adversarial loss: 0.612664\n",
      "epoch 37; iter: 200; batch classifier loss: 0.387582; batch adversarial loss: 0.645718\n",
      "epoch 38; iter: 0; batch classifier loss: 0.378628; batch adversarial loss: 0.614759\n",
      "epoch 38; iter: 200; batch classifier loss: 0.354901; batch adversarial loss: 0.665731\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446010; batch adversarial loss: 0.661600\n",
      "epoch 39; iter: 200; batch classifier loss: 0.409085; batch adversarial loss: 0.578872\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425127; batch adversarial loss: 0.595055\n",
      "epoch 40; iter: 200; batch classifier loss: 0.386480; batch adversarial loss: 0.643394\n",
      "epoch 41; iter: 0; batch classifier loss: 0.345528; batch adversarial loss: 0.607217\n",
      "epoch 41; iter: 200; batch classifier loss: 0.363404; batch adversarial loss: 0.644807\n",
      "epoch 42; iter: 0; batch classifier loss: 0.290963; batch adversarial loss: 0.669321\n",
      "epoch 42; iter: 200; batch classifier loss: 0.265302; batch adversarial loss: 0.643724\n",
      "epoch 43; iter: 0; batch classifier loss: 0.490116; batch adversarial loss: 0.597040\n",
      "epoch 43; iter: 200; batch classifier loss: 0.352843; batch adversarial loss: 0.638572\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410186; batch adversarial loss: 0.636431\n",
      "epoch 44; iter: 200; batch classifier loss: 0.432930; batch adversarial loss: 0.626148\n",
      "epoch 45; iter: 0; batch classifier loss: 0.461585; batch adversarial loss: 0.671028\n",
      "epoch 45; iter: 200; batch classifier loss: 0.427099; batch adversarial loss: 0.605317\n",
      "epoch 46; iter: 0; batch classifier loss: 0.373042; batch adversarial loss: 0.577927\n",
      "epoch 46; iter: 200; batch classifier loss: 0.386885; batch adversarial loss: 0.580910\n",
      "epoch 47; iter: 0; batch classifier loss: 0.337088; batch adversarial loss: 0.580451\n",
      "epoch 47; iter: 200; batch classifier loss: 0.349715; batch adversarial loss: 0.592988\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483617; batch adversarial loss: 0.633764\n",
      "epoch 48; iter: 200; batch classifier loss: 0.395087; batch adversarial loss: 0.607443\n",
      "epoch 49; iter: 0; batch classifier loss: 0.305075; batch adversarial loss: 0.590080\n",
      "epoch 49; iter: 200; batch classifier loss: 0.483371; batch adversarial loss: 0.635294\n",
      "epoch 0; iter: 0; batch classifier loss: 15.952399; batch adversarial loss: 0.655755\n",
      "epoch 0; iter: 200; batch classifier loss: 9.669757; batch adversarial loss: 0.624305\n",
      "epoch 1; iter: 0; batch classifier loss: 10.676305; batch adversarial loss: 0.619427\n",
      "epoch 1; iter: 200; batch classifier loss: 8.431413; batch adversarial loss: 0.626298\n",
      "epoch 2; iter: 0; batch classifier loss: 2.632646; batch adversarial loss: 0.681149\n",
      "epoch 2; iter: 200; batch classifier loss: 4.696147; batch adversarial loss: 0.642929\n",
      "epoch 3; iter: 0; batch classifier loss: 4.318190; batch adversarial loss: 0.624841\n",
      "epoch 3; iter: 200; batch classifier loss: 4.423240; batch adversarial loss: 0.601567\n",
      "epoch 4; iter: 0; batch classifier loss: 1.087542; batch adversarial loss: 0.622726\n",
      "epoch 4; iter: 200; batch classifier loss: 1.474189; batch adversarial loss: 0.660415\n",
      "epoch 5; iter: 0; batch classifier loss: 2.365420; batch adversarial loss: 0.617088\n",
      "epoch 5; iter: 200; batch classifier loss: 1.698058; batch adversarial loss: 0.659411\n",
      "epoch 6; iter: 0; batch classifier loss: 0.951783; batch adversarial loss: 0.632003\n",
      "epoch 6; iter: 200; batch classifier loss: 0.905404; batch adversarial loss: 0.592438\n",
      "epoch 7; iter: 0; batch classifier loss: 0.660935; batch adversarial loss: 0.589023\n",
      "epoch 7; iter: 200; batch classifier loss: 0.586707; batch adversarial loss: 0.628043\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583160; batch adversarial loss: 0.593003\n",
      "epoch 8; iter: 200; batch classifier loss: 0.863036; batch adversarial loss: 0.622288\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392889; batch adversarial loss: 0.662495\n",
      "epoch 9; iter: 200; batch classifier loss: 0.399364; batch adversarial loss: 0.599768\n",
      "epoch 10; iter: 0; batch classifier loss: 0.417983; batch adversarial loss: 0.609762\n",
      "epoch 10; iter: 200; batch classifier loss: 0.643885; batch adversarial loss: 0.621455\n",
      "epoch 11; iter: 0; batch classifier loss: 0.401459; batch adversarial loss: 0.625361\n",
      "epoch 11; iter: 200; batch classifier loss: 0.424000; batch adversarial loss: 0.620368\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391370; batch adversarial loss: 0.645328\n",
      "epoch 12; iter: 200; batch classifier loss: 0.356288; batch adversarial loss: 0.622802\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348913; batch adversarial loss: 0.590585\n",
      "epoch 13; iter: 200; batch classifier loss: 0.392980; batch adversarial loss: 0.602731\n",
      "epoch 14; iter: 0; batch classifier loss: 0.439513; batch adversarial loss: 0.675017\n",
      "epoch 14; iter: 200; batch classifier loss: 0.393791; batch adversarial loss: 0.527420\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326538; batch adversarial loss: 0.588521\n",
      "epoch 15; iter: 200; batch classifier loss: 0.334224; batch adversarial loss: 0.638719\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362287; batch adversarial loss: 0.590413\n",
      "epoch 16; iter: 200; batch classifier loss: 0.320547; batch adversarial loss: 0.628300\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301533; batch adversarial loss: 0.550178\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343857; batch adversarial loss: 0.625632\n",
      "epoch 18; iter: 0; batch classifier loss: 0.379101; batch adversarial loss: 0.590784\n",
      "epoch 18; iter: 200; batch classifier loss: 0.381979; batch adversarial loss: 0.552103\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310307; batch adversarial loss: 0.643585\n",
      "epoch 19; iter: 200; batch classifier loss: 0.297921; batch adversarial loss: 0.674912\n",
      "epoch 20; iter: 0; batch classifier loss: 0.377814; batch adversarial loss: 0.601866\n",
      "epoch 20; iter: 200; batch classifier loss: 0.397372; batch adversarial loss: 0.631231\n",
      "epoch 21; iter: 0; batch classifier loss: 0.373370; batch adversarial loss: 0.644646\n",
      "epoch 21; iter: 200; batch classifier loss: 0.379841; batch adversarial loss: 0.618007\n",
      "epoch 22; iter: 0; batch classifier loss: 0.333265; batch adversarial loss: 0.593118\n",
      "epoch 22; iter: 200; batch classifier loss: 0.382000; batch adversarial loss: 0.616366\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311399; batch adversarial loss: 0.610159\n",
      "epoch 23; iter: 200; batch classifier loss: 0.455713; batch adversarial loss: 0.611090\n",
      "epoch 24; iter: 0; batch classifier loss: 0.344338; batch adversarial loss: 0.673399\n",
      "epoch 24; iter: 200; batch classifier loss: 0.268993; batch adversarial loss: 0.616750\n",
      "epoch 25; iter: 0; batch classifier loss: 0.370229; batch adversarial loss: 0.655514\n",
      "epoch 25; iter: 200; batch classifier loss: 0.320025; batch adversarial loss: 0.602354\n",
      "epoch 26; iter: 0; batch classifier loss: 0.418557; batch adversarial loss: 0.617255\n",
      "epoch 26; iter: 200; batch classifier loss: 0.389698; batch adversarial loss: 0.608375\n",
      "epoch 27; iter: 0; batch classifier loss: 0.303925; batch adversarial loss: 0.641179\n",
      "epoch 27; iter: 200; batch classifier loss: 0.291370; batch adversarial loss: 0.670540\n",
      "epoch 28; iter: 0; batch classifier loss: 0.377073; batch adversarial loss: 0.586375\n",
      "epoch 28; iter: 200; batch classifier loss: 0.299206; batch adversarial loss: 0.589149\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388374; batch adversarial loss: 0.686644\n",
      "epoch 29; iter: 200; batch classifier loss: 0.301377; batch adversarial loss: 0.611451\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320682; batch adversarial loss: 0.608546\n",
      "epoch 30; iter: 200; batch classifier loss: 0.442545; batch adversarial loss: 0.581990\n",
      "epoch 31; iter: 0; batch classifier loss: 0.331087; batch adversarial loss: 0.601134\n",
      "epoch 31; iter: 200; batch classifier loss: 0.321099; batch adversarial loss: 0.644131\n",
      "epoch 32; iter: 0; batch classifier loss: 0.353340; batch adversarial loss: 0.583705\n",
      "epoch 32; iter: 200; batch classifier loss: 0.259730; batch adversarial loss: 0.677149\n",
      "epoch 33; iter: 0; batch classifier loss: 0.375912; batch adversarial loss: 0.640877\n",
      "epoch 33; iter: 200; batch classifier loss: 0.359314; batch adversarial loss: 0.701465\n",
      "epoch 34; iter: 0; batch classifier loss: 0.384709; batch adversarial loss: 0.624214\n",
      "epoch 34; iter: 200; batch classifier loss: 0.429993; batch adversarial loss: 0.631055\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393502; batch adversarial loss: 0.638119\n",
      "epoch 35; iter: 200; batch classifier loss: 0.327652; batch adversarial loss: 0.627359\n",
      "epoch 36; iter: 0; batch classifier loss: 0.337346; batch adversarial loss: 0.623715\n",
      "epoch 36; iter: 200; batch classifier loss: 0.405908; batch adversarial loss: 0.606372\n",
      "epoch 37; iter: 0; batch classifier loss: 0.341973; batch adversarial loss: 0.633259\n",
      "epoch 37; iter: 200; batch classifier loss: 0.374680; batch adversarial loss: 0.616846\n",
      "epoch 38; iter: 0; batch classifier loss: 0.347369; batch adversarial loss: 0.655095\n",
      "epoch 38; iter: 200; batch classifier loss: 0.437225; batch adversarial loss: 0.619252\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377936; batch adversarial loss: 0.599477\n",
      "epoch 39; iter: 200; batch classifier loss: 0.352933; batch adversarial loss: 0.632937\n",
      "epoch 40; iter: 0; batch classifier loss: 0.385424; batch adversarial loss: 0.636521\n",
      "epoch 40; iter: 200; batch classifier loss: 0.402739; batch adversarial loss: 0.620416\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384297; batch adversarial loss: 0.630304\n",
      "epoch 41; iter: 200; batch classifier loss: 0.374899; batch adversarial loss: 0.665483\n",
      "epoch 42; iter: 0; batch classifier loss: 0.317076; batch adversarial loss: 0.598396\n",
      "epoch 42; iter: 200; batch classifier loss: 0.393545; batch adversarial loss: 0.639057\n",
      "epoch 43; iter: 0; batch classifier loss: 0.213483; batch adversarial loss: 0.676317\n",
      "epoch 43; iter: 200; batch classifier loss: 0.313303; batch adversarial loss: 0.620756\n",
      "epoch 44; iter: 0; batch classifier loss: 0.260635; batch adversarial loss: 0.653412\n",
      "epoch 44; iter: 200; batch classifier loss: 0.422621; batch adversarial loss: 0.577732\n",
      "epoch 45; iter: 0; batch classifier loss: 0.685736; batch adversarial loss: 0.603017\n",
      "epoch 45; iter: 200; batch classifier loss: 0.270905; batch adversarial loss: 0.620356\n",
      "epoch 46; iter: 0; batch classifier loss: 0.290105; batch adversarial loss: 0.607693\n",
      "epoch 46; iter: 200; batch classifier loss: 0.377055; batch adversarial loss: 0.594672\n",
      "epoch 47; iter: 0; batch classifier loss: 0.439748; batch adversarial loss: 0.597117\n",
      "epoch 47; iter: 200; batch classifier loss: 0.302384; batch adversarial loss: 0.624976\n",
      "epoch 48; iter: 0; batch classifier loss: 0.319807; batch adversarial loss: 0.610804\n",
      "epoch 48; iter: 200; batch classifier loss: 0.272643; batch adversarial loss: 0.595092\n",
      "epoch 49; iter: 0; batch classifier loss: 0.340915; batch adversarial loss: 0.643251\n",
      "epoch 49; iter: 200; batch classifier loss: 0.443815; batch adversarial loss: 0.640950\n",
      "epoch 0; iter: 0; batch classifier loss: 48.715206; batch adversarial loss: 0.875689\n",
      "epoch 0; iter: 200; batch classifier loss: 7.522872; batch adversarial loss: 0.809688\n",
      "epoch 1; iter: 0; batch classifier loss: 19.476770; batch adversarial loss: 0.749706\n",
      "epoch 1; iter: 200; batch classifier loss: 5.819310; batch adversarial loss: 0.716204\n",
      "epoch 2; iter: 0; batch classifier loss: 6.802121; batch adversarial loss: 0.675163\n",
      "epoch 2; iter: 200; batch classifier loss: 5.869424; batch adversarial loss: 0.655440\n",
      "epoch 3; iter: 0; batch classifier loss: 6.478032; batch adversarial loss: 0.654247\n",
      "epoch 3; iter: 200; batch classifier loss: 2.743716; batch adversarial loss: 0.626757\n",
      "epoch 4; iter: 0; batch classifier loss: 6.053108; batch adversarial loss: 0.669012\n",
      "epoch 4; iter: 200; batch classifier loss: 1.957737; batch adversarial loss: 0.657260\n",
      "epoch 5; iter: 0; batch classifier loss: 0.938992; batch adversarial loss: 0.611927\n",
      "epoch 5; iter: 200; batch classifier loss: 1.857539; batch adversarial loss: 0.664195\n",
      "epoch 6; iter: 0; batch classifier loss: 1.159755; batch adversarial loss: 0.644364\n",
      "epoch 6; iter: 200; batch classifier loss: 0.925934; batch adversarial loss: 0.649334\n",
      "epoch 7; iter: 0; batch classifier loss: 1.267635; batch adversarial loss: 0.636918\n",
      "epoch 7; iter: 200; batch classifier loss: 1.423245; batch adversarial loss: 0.634715\n",
      "epoch 8; iter: 0; batch classifier loss: 0.902695; batch adversarial loss: 0.639000\n",
      "epoch 8; iter: 200; batch classifier loss: 1.062411; batch adversarial loss: 0.680316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.795138; batch adversarial loss: 0.625822\n",
      "epoch 9; iter: 200; batch classifier loss: 0.773287; batch adversarial loss: 0.637460\n",
      "epoch 10; iter: 0; batch classifier loss: 0.740889; batch adversarial loss: 0.564333\n",
      "epoch 10; iter: 200; batch classifier loss: 0.580637; batch adversarial loss: 0.582317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.728545; batch adversarial loss: 0.669758\n",
      "epoch 11; iter: 200; batch classifier loss: 0.555327; batch adversarial loss: 0.625667\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522050; batch adversarial loss: 0.615000\n",
      "epoch 12; iter: 200; batch classifier loss: 0.442137; batch adversarial loss: 0.642080\n",
      "epoch 13; iter: 0; batch classifier loss: 0.549123; batch adversarial loss: 0.569093\n",
      "epoch 13; iter: 200; batch classifier loss: 0.487778; batch adversarial loss: 0.624390\n",
      "epoch 14; iter: 0; batch classifier loss: 0.590948; batch adversarial loss: 0.693744\n",
      "epoch 14; iter: 200; batch classifier loss: 0.473932; batch adversarial loss: 0.641302\n",
      "epoch 15; iter: 0; batch classifier loss: 0.392414; batch adversarial loss: 0.616529\n",
      "epoch 15; iter: 200; batch classifier loss: 0.543805; batch adversarial loss: 0.600356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344169; batch adversarial loss: 0.637531\n",
      "epoch 16; iter: 200; batch classifier loss: 0.364766; batch adversarial loss: 0.618549\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366953; batch adversarial loss: 0.567655\n",
      "epoch 17; iter: 200; batch classifier loss: 0.320693; batch adversarial loss: 0.681696\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300177; batch adversarial loss: 0.649615\n",
      "epoch 18; iter: 200; batch classifier loss: 0.333728; batch adversarial loss: 0.634179\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352837; batch adversarial loss: 0.600118\n",
      "epoch 19; iter: 200; batch classifier loss: 0.382743; batch adversarial loss: 0.594211\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338866; batch adversarial loss: 0.614777\n",
      "epoch 20; iter: 200; batch classifier loss: 0.340753; batch adversarial loss: 0.555634\n",
      "epoch 21; iter: 0; batch classifier loss: 0.347184; batch adversarial loss: 0.633580\n",
      "epoch 21; iter: 200; batch classifier loss: 0.419370; batch adversarial loss: 0.632294\n",
      "epoch 22; iter: 0; batch classifier loss: 0.449406; batch adversarial loss: 0.608979\n",
      "epoch 22; iter: 200; batch classifier loss: 0.314480; batch adversarial loss: 0.580832\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308231; batch adversarial loss: 0.626201\n",
      "epoch 23; iter: 200; batch classifier loss: 0.394969; batch adversarial loss: 0.584948\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323555; batch adversarial loss: 0.570977\n",
      "epoch 24; iter: 200; batch classifier loss: 0.378654; batch adversarial loss: 0.604865\n",
      "epoch 25; iter: 0; batch classifier loss: 0.607678; batch adversarial loss: 0.660134\n",
      "epoch 25; iter: 200; batch classifier loss: 0.342606; batch adversarial loss: 0.649337\n",
      "epoch 26; iter: 0; batch classifier loss: 0.287988; batch adversarial loss: 0.591041\n",
      "epoch 26; iter: 200; batch classifier loss: 0.324271; batch adversarial loss: 0.615459\n",
      "epoch 27; iter: 0; batch classifier loss: 0.348444; batch adversarial loss: 0.637966\n",
      "epoch 27; iter: 200; batch classifier loss: 0.293118; batch adversarial loss: 0.619714\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351359; batch adversarial loss: 0.627810\n",
      "epoch 28; iter: 200; batch classifier loss: 0.264726; batch adversarial loss: 0.614538\n",
      "epoch 29; iter: 0; batch classifier loss: 0.311815; batch adversarial loss: 0.598363\n",
      "epoch 29; iter: 200; batch classifier loss: 0.386272; batch adversarial loss: 0.600863\n",
      "epoch 30; iter: 0; batch classifier loss: 0.388319; batch adversarial loss: 0.619826\n",
      "epoch 30; iter: 200; batch classifier loss: 0.464119; batch adversarial loss: 0.611664\n",
      "epoch 31; iter: 0; batch classifier loss: 0.361149; batch adversarial loss: 0.675637\n",
      "epoch 31; iter: 200; batch classifier loss: 0.424580; batch adversarial loss: 0.645743\n",
      "epoch 32; iter: 0; batch classifier loss: 0.325596; batch adversarial loss: 0.603658\n",
      "epoch 32; iter: 200; batch classifier loss: 0.401825; batch adversarial loss: 0.633494\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330728; batch adversarial loss: 0.606073\n",
      "epoch 33; iter: 200; batch classifier loss: 0.454955; batch adversarial loss: 0.580185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408454; batch adversarial loss: 0.675355\n",
      "epoch 34; iter: 200; batch classifier loss: 0.383023; batch adversarial loss: 0.636598\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403622; batch adversarial loss: 0.624974\n",
      "epoch 35; iter: 200; batch classifier loss: 0.432430; batch adversarial loss: 0.602404\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366129; batch adversarial loss: 0.567715\n",
      "epoch 36; iter: 200; batch classifier loss: 0.353029; batch adversarial loss: 0.590901\n",
      "epoch 37; iter: 0; batch classifier loss: 0.267086; batch adversarial loss: 0.598706\n",
      "epoch 37; iter: 200; batch classifier loss: 0.311582; batch adversarial loss: 0.617024\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418198; batch adversarial loss: 0.606335\n",
      "epoch 38; iter: 200; batch classifier loss: 0.333445; batch adversarial loss: 0.618033\n",
      "epoch 39; iter: 0; batch classifier loss: 0.349847; batch adversarial loss: 0.603340\n",
      "epoch 39; iter: 200; batch classifier loss: 0.406222; batch adversarial loss: 0.615903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383606; batch adversarial loss: 0.646995\n",
      "epoch 40; iter: 200; batch classifier loss: 0.366918; batch adversarial loss: 0.618891\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487873; batch adversarial loss: 0.610655\n",
      "epoch 41; iter: 200; batch classifier loss: 0.340677; batch adversarial loss: 0.631868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.359576; batch adversarial loss: 0.624094\n",
      "epoch 42; iter: 200; batch classifier loss: 0.441451; batch adversarial loss: 0.566741\n",
      "epoch 43; iter: 0; batch classifier loss: 0.267885; batch adversarial loss: 0.624864\n",
      "epoch 43; iter: 200; batch classifier loss: 0.366494; batch adversarial loss: 0.653466\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441017; batch adversarial loss: 0.582141\n",
      "epoch 44; iter: 200; batch classifier loss: 0.376328; batch adversarial loss: 0.552483\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403973; batch adversarial loss: 0.621662\n",
      "epoch 45; iter: 200; batch classifier loss: 0.345185; batch adversarial loss: 0.625018\n",
      "epoch 46; iter: 0; batch classifier loss: 0.332995; batch adversarial loss: 0.657390\n",
      "epoch 46; iter: 200; batch classifier loss: 0.315306; batch adversarial loss: 0.577585\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411686; batch adversarial loss: 0.619255\n",
      "epoch 47; iter: 200; batch classifier loss: 0.299128; batch adversarial loss: 0.594553\n",
      "epoch 48; iter: 0; batch classifier loss: 0.296779; batch adversarial loss: 0.592638\n",
      "epoch 48; iter: 200; batch classifier loss: 0.321633; batch adversarial loss: 0.555694\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413146; batch adversarial loss: 0.558103\n",
      "epoch 49; iter: 200; batch classifier loss: 0.296160; batch adversarial loss: 0.590037\n",
      "epoch 0; iter: 0; batch classifier loss: 20.197281; batch adversarial loss: 0.665640\n",
      "epoch 0; iter: 200; batch classifier loss: 4.339611; batch adversarial loss: 0.630854\n",
      "epoch 1; iter: 0; batch classifier loss: 10.542610; batch adversarial loss: 0.590293\n",
      "epoch 1; iter: 200; batch classifier loss: 3.299980; batch adversarial loss: 0.582963\n",
      "epoch 2; iter: 0; batch classifier loss: 3.216283; batch adversarial loss: 0.628350\n",
      "epoch 2; iter: 200; batch classifier loss: 2.583226; batch adversarial loss: 0.643211\n",
      "epoch 3; iter: 0; batch classifier loss: 7.306859; batch adversarial loss: 0.624532\n",
      "epoch 3; iter: 200; batch classifier loss: 3.099153; batch adversarial loss: 0.592083\n",
      "epoch 4; iter: 0; batch classifier loss: 3.433203; batch adversarial loss: 0.686826\n",
      "epoch 4; iter: 200; batch classifier loss: 5.380117; batch adversarial loss: 0.697641\n",
      "epoch 5; iter: 0; batch classifier loss: 2.368446; batch adversarial loss: 0.634778\n",
      "epoch 5; iter: 200; batch classifier loss: 0.851999; batch adversarial loss: 0.652624\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579334; batch adversarial loss: 0.643605\n",
      "epoch 6; iter: 200; batch classifier loss: 0.448882; batch adversarial loss: 0.578116\n",
      "epoch 7; iter: 0; batch classifier loss: 1.874135; batch adversarial loss: 0.606815\n",
      "epoch 7; iter: 200; batch classifier loss: 0.578822; batch adversarial loss: 0.649248\n",
      "epoch 8; iter: 0; batch classifier loss: 0.719013; batch adversarial loss: 0.625157\n",
      "epoch 8; iter: 200; batch classifier loss: 0.519125; batch adversarial loss: 0.573764\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454875; batch adversarial loss: 0.697004\n",
      "epoch 9; iter: 200; batch classifier loss: 0.381557; batch adversarial loss: 0.616855\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419578; batch adversarial loss: 0.612467\n",
      "epoch 10; iter: 200; batch classifier loss: 0.410522; batch adversarial loss: 0.633645\n",
      "epoch 11; iter: 0; batch classifier loss: 0.375739; batch adversarial loss: 0.672728\n",
      "epoch 11; iter: 200; batch classifier loss: 0.322490; batch adversarial loss: 0.576955\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376995; batch adversarial loss: 0.615945\n",
      "epoch 12; iter: 200; batch classifier loss: 0.397106; batch adversarial loss: 0.639280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421163; batch adversarial loss: 0.588097\n",
      "epoch 13; iter: 200; batch classifier loss: 0.847684; batch adversarial loss: 0.568488\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367696; batch adversarial loss: 0.650217\n",
      "epoch 14; iter: 200; batch classifier loss: 0.329942; batch adversarial loss: 0.674637\n",
      "epoch 15; iter: 0; batch classifier loss: 0.706210; batch adversarial loss: 0.615609\n",
      "epoch 15; iter: 200; batch classifier loss: 0.317466; batch adversarial loss: 0.605052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336327; batch adversarial loss: 0.619520\n",
      "epoch 16; iter: 200; batch classifier loss: 0.429294; batch adversarial loss: 0.571884\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409623; batch adversarial loss: 0.578307\n",
      "epoch 17; iter: 200; batch classifier loss: 0.303086; batch adversarial loss: 0.622599\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334013; batch adversarial loss: 0.620699\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371674; batch adversarial loss: 0.581310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.328489; batch adversarial loss: 0.665095\n",
      "epoch 19; iter: 200; batch classifier loss: 0.371506; batch adversarial loss: 0.596178\n",
      "epoch 20; iter: 0; batch classifier loss: 0.329475; batch adversarial loss: 0.646840\n",
      "epoch 20; iter: 200; batch classifier loss: 0.465045; batch adversarial loss: 0.575067\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282700; batch adversarial loss: 0.619846\n",
      "epoch 21; iter: 200; batch classifier loss: 0.295114; batch adversarial loss: 0.585441\n",
      "epoch 22; iter: 0; batch classifier loss: 0.426662; batch adversarial loss: 0.637227\n",
      "epoch 22; iter: 200; batch classifier loss: 0.411108; batch adversarial loss: 0.548542\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322986; batch adversarial loss: 0.620847\n",
      "epoch 23; iter: 200; batch classifier loss: 0.295301; batch adversarial loss: 0.586319\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405311; batch adversarial loss: 0.591017\n",
      "epoch 24; iter: 200; batch classifier loss: 0.285990; batch adversarial loss: 0.613011\n",
      "epoch 25; iter: 0; batch classifier loss: 0.413795; batch adversarial loss: 0.601690\n",
      "epoch 25; iter: 200; batch classifier loss: 0.310201; batch adversarial loss: 0.611709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.414747; batch adversarial loss: 0.618047\n",
      "epoch 26; iter: 200; batch classifier loss: 0.250118; batch adversarial loss: 0.582341\n",
      "epoch 27; iter: 0; batch classifier loss: 0.363858; batch adversarial loss: 0.593009\n",
      "epoch 27; iter: 200; batch classifier loss: 0.318823; batch adversarial loss: 0.675965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.408366; batch adversarial loss: 0.641468\n",
      "epoch 28; iter: 200; batch classifier loss: 0.347270; batch adversarial loss: 0.665957\n",
      "epoch 29; iter: 0; batch classifier loss: 0.333583; batch adversarial loss: 0.589219\n",
      "epoch 29; iter: 200; batch classifier loss: 0.333905; batch adversarial loss: 0.606894\n",
      "epoch 30; iter: 0; batch classifier loss: 0.401670; batch adversarial loss: 0.602916\n",
      "epoch 30; iter: 200; batch classifier loss: 0.362971; batch adversarial loss: 0.592668\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328446; batch adversarial loss: 0.652855\n",
      "epoch 31; iter: 200; batch classifier loss: 0.312306; batch adversarial loss: 0.645007\n",
      "epoch 32; iter: 0; batch classifier loss: 0.349763; batch adversarial loss: 0.626542\n",
      "epoch 32; iter: 200; batch classifier loss: 0.348922; batch adversarial loss: 0.620208\n",
      "epoch 33; iter: 0; batch classifier loss: 0.393993; batch adversarial loss: 0.589669\n",
      "epoch 33; iter: 200; batch classifier loss: 0.437697; batch adversarial loss: 0.639199\n",
      "epoch 34; iter: 0; batch classifier loss: 0.359265; batch adversarial loss: 0.669657\n",
      "epoch 34; iter: 200; batch classifier loss: 0.297033; batch adversarial loss: 0.628865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.348703; batch adversarial loss: 0.629860\n",
      "epoch 35; iter: 200; batch classifier loss: 0.291971; batch adversarial loss: 0.636497\n",
      "epoch 36; iter: 0; batch classifier loss: 0.385152; batch adversarial loss: 0.619425\n",
      "epoch 36; iter: 200; batch classifier loss: 0.342173; batch adversarial loss: 0.663393\n",
      "epoch 37; iter: 0; batch classifier loss: 0.269852; batch adversarial loss: 0.688806\n",
      "epoch 37; iter: 200; batch classifier loss: 0.299337; batch adversarial loss: 0.630027\n",
      "epoch 38; iter: 0; batch classifier loss: 0.334387; batch adversarial loss: 0.694698\n",
      "epoch 38; iter: 200; batch classifier loss: 0.578901; batch adversarial loss: 0.640005\n",
      "epoch 39; iter: 0; batch classifier loss: 0.341856; batch adversarial loss: 0.642531\n",
      "epoch 39; iter: 200; batch classifier loss: 0.330832; batch adversarial loss: 0.688975\n",
      "epoch 40; iter: 0; batch classifier loss: 0.315514; batch adversarial loss: 0.612635\n",
      "epoch 40; iter: 200; batch classifier loss: 0.445322; batch adversarial loss: 0.575366\n",
      "epoch 41; iter: 0; batch classifier loss: 0.286645; batch adversarial loss: 0.617993\n",
      "epoch 41; iter: 200; batch classifier loss: 0.372142; batch adversarial loss: 0.620725\n",
      "epoch 42; iter: 0; batch classifier loss: 0.352405; batch adversarial loss: 0.614926\n",
      "epoch 42; iter: 200; batch classifier loss: 0.354578; batch adversarial loss: 0.565729\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451552; batch adversarial loss: 0.649172\n",
      "epoch 43; iter: 200; batch classifier loss: 0.312745; batch adversarial loss: 0.658402\n",
      "epoch 44; iter: 0; batch classifier loss: 0.313236; batch adversarial loss: 0.571848\n",
      "epoch 44; iter: 200; batch classifier loss: 0.294342; batch adversarial loss: 0.629094\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426213; batch adversarial loss: 0.688389\n",
      "epoch 45; iter: 200; batch classifier loss: 0.435736; batch adversarial loss: 0.624158\n",
      "epoch 46; iter: 0; batch classifier loss: 0.285733; batch adversarial loss: 0.607493\n",
      "epoch 46; iter: 200; batch classifier loss: 0.386247; batch adversarial loss: 0.572674\n",
      "epoch 47; iter: 0; batch classifier loss: 0.448950; batch adversarial loss: 0.638211\n",
      "epoch 47; iter: 200; batch classifier loss: 0.394605; batch adversarial loss: 0.662496\n",
      "epoch 48; iter: 0; batch classifier loss: 0.308323; batch adversarial loss: 0.619030\n",
      "epoch 48; iter: 200; batch classifier loss: 0.268278; batch adversarial loss: 0.603228\n",
      "epoch 49; iter: 0; batch classifier loss: 0.329898; batch adversarial loss: 0.602158\n",
      "epoch 49; iter: 200; batch classifier loss: 0.638477; batch adversarial loss: 0.571694\n",
      "epoch 0; iter: 0; batch classifier loss: 3.804695; batch adversarial loss: 0.648262\n",
      "epoch 0; iter: 200; batch classifier loss: 5.963564; batch adversarial loss: 0.633381\n",
      "epoch 1; iter: 0; batch classifier loss: 27.799414; batch adversarial loss: 0.629397\n",
      "epoch 1; iter: 200; batch classifier loss: 17.920221; batch adversarial loss: 0.601309\n",
      "epoch 2; iter: 0; batch classifier loss: 9.675249; batch adversarial loss: 0.663428\n",
      "epoch 2; iter: 200; batch classifier loss: 4.589621; batch adversarial loss: 0.712913\n",
      "epoch 3; iter: 0; batch classifier loss: 2.508041; batch adversarial loss: 0.661848\n",
      "epoch 3; iter: 200; batch classifier loss: 2.989965; batch adversarial loss: 0.593914\n",
      "epoch 4; iter: 0; batch classifier loss: 3.886148; batch adversarial loss: 0.598996\n",
      "epoch 4; iter: 200; batch classifier loss: 4.797644; batch adversarial loss: 0.624834\n",
      "epoch 5; iter: 0; batch classifier loss: 2.369609; batch adversarial loss: 0.621241\n",
      "epoch 5; iter: 200; batch classifier loss: 2.620292; batch adversarial loss: 0.630046\n",
      "epoch 6; iter: 0; batch classifier loss: 1.666392; batch adversarial loss: 0.627905\n",
      "epoch 6; iter: 200; batch classifier loss: 0.949946; batch adversarial loss: 0.570408\n",
      "epoch 7; iter: 0; batch classifier loss: 1.086417; batch adversarial loss: 0.627174\n",
      "epoch 7; iter: 200; batch classifier loss: 2.483988; batch adversarial loss: 0.585392\n",
      "epoch 8; iter: 0; batch classifier loss: 2.022806; batch adversarial loss: 0.671520\n",
      "epoch 8; iter: 200; batch classifier loss: 0.555957; batch adversarial loss: 0.669034\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572971; batch adversarial loss: 0.642915\n",
      "epoch 9; iter: 200; batch classifier loss: 0.684827; batch adversarial loss: 0.695784\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505743; batch adversarial loss: 0.593268\n",
      "epoch 10; iter: 200; batch classifier loss: 0.388479; batch adversarial loss: 0.608520\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605020; batch adversarial loss: 0.648973\n",
      "epoch 11; iter: 200; batch classifier loss: 0.480351; batch adversarial loss: 0.565862\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537509; batch adversarial loss: 0.648056\n",
      "epoch 12; iter: 200; batch classifier loss: 0.355249; batch adversarial loss: 0.627383\n",
      "epoch 13; iter: 0; batch classifier loss: 0.352526; batch adversarial loss: 0.604617\n",
      "epoch 13; iter: 200; batch classifier loss: 0.418560; batch adversarial loss: 0.644716\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475109; batch adversarial loss: 0.566246\n",
      "epoch 14; iter: 200; batch classifier loss: 0.361877; batch adversarial loss: 0.554507\n",
      "epoch 15; iter: 0; batch classifier loss: 0.357510; batch adversarial loss: 0.564732\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387972; batch adversarial loss: 0.599539\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376594; batch adversarial loss: 0.569774\n",
      "epoch 16; iter: 200; batch classifier loss: 0.434904; batch adversarial loss: 0.525977\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339293; batch adversarial loss: 0.631625\n",
      "epoch 17; iter: 200; batch classifier loss: 0.442186; batch adversarial loss: 0.628520\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359623; batch adversarial loss: 0.641014\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373189; batch adversarial loss: 0.570294\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374593; batch adversarial loss: 0.575846\n",
      "epoch 19; iter: 200; batch classifier loss: 0.267885; batch adversarial loss: 0.679705\n",
      "epoch 20; iter: 0; batch classifier loss: 0.386985; batch adversarial loss: 0.591244\n",
      "epoch 20; iter: 200; batch classifier loss: 0.484553; batch adversarial loss: 0.590020\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319043; batch adversarial loss: 0.651166\n",
      "epoch 21; iter: 200; batch classifier loss: 0.327338; batch adversarial loss: 0.636585\n",
      "epoch 22; iter: 0; batch classifier loss: 0.380814; batch adversarial loss: 0.601836\n",
      "epoch 22; iter: 200; batch classifier loss: 0.364307; batch adversarial loss: 0.635131\n",
      "epoch 23; iter: 0; batch classifier loss: 0.349728; batch adversarial loss: 0.628047\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374956; batch adversarial loss: 0.570142\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307790; batch adversarial loss: 0.655038\n",
      "epoch 24; iter: 200; batch classifier loss: 0.528996; batch adversarial loss: 0.616979\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521026; batch adversarial loss: 0.633098\n",
      "epoch 25; iter: 200; batch classifier loss: 0.339719; batch adversarial loss: 0.601555\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397877; batch adversarial loss: 0.560086\n",
      "epoch 26; iter: 200; batch classifier loss: 0.434774; batch adversarial loss: 0.578793\n",
      "epoch 27; iter: 0; batch classifier loss: 0.305601; batch adversarial loss: 0.652006\n",
      "epoch 27; iter: 200; batch classifier loss: 0.361524; batch adversarial loss: 0.666339\n",
      "epoch 28; iter: 0; batch classifier loss: 0.320670; batch adversarial loss: 0.617425\n",
      "epoch 28; iter: 200; batch classifier loss: 0.380124; batch adversarial loss: 0.640598\n",
      "epoch 29; iter: 0; batch classifier loss: 0.499267; batch adversarial loss: 0.614370\n",
      "epoch 29; iter: 200; batch classifier loss: 0.348069; batch adversarial loss: 0.647548\n",
      "epoch 30; iter: 0; batch classifier loss: 0.301698; batch adversarial loss: 0.623728\n",
      "epoch 30; iter: 200; batch classifier loss: 0.305411; batch adversarial loss: 0.655804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.391535; batch adversarial loss: 0.604264\n",
      "epoch 31; iter: 200; batch classifier loss: 0.377454; batch adversarial loss: 0.674157\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393790; batch adversarial loss: 0.615249\n",
      "epoch 32; iter: 200; batch classifier loss: 0.379482; batch adversarial loss: 0.687569\n",
      "epoch 33; iter: 0; batch classifier loss: 0.334213; batch adversarial loss: 0.613319\n",
      "epoch 33; iter: 200; batch classifier loss: 0.308040; batch adversarial loss: 0.602054\n",
      "epoch 34; iter: 0; batch classifier loss: 0.292126; batch adversarial loss: 0.662051\n",
      "epoch 34; iter: 200; batch classifier loss: 0.359425; batch adversarial loss: 0.578873\n",
      "epoch 35; iter: 0; batch classifier loss: 0.248477; batch adversarial loss: 0.630354\n",
      "epoch 35; iter: 200; batch classifier loss: 0.352091; batch adversarial loss: 0.644900\n",
      "epoch 36; iter: 0; batch classifier loss: 0.352333; batch adversarial loss: 0.624590\n",
      "epoch 36; iter: 200; batch classifier loss: 0.284641; batch adversarial loss: 0.634724\n",
      "epoch 37; iter: 0; batch classifier loss: 0.304216; batch adversarial loss: 0.598867\n",
      "epoch 37; iter: 200; batch classifier loss: 0.425178; batch adversarial loss: 0.631713\n",
      "epoch 38; iter: 0; batch classifier loss: 0.341199; batch adversarial loss: 0.692739\n",
      "epoch 38; iter: 200; batch classifier loss: 0.470978; batch adversarial loss: 0.657003\n",
      "epoch 39; iter: 0; batch classifier loss: 0.356335; batch adversarial loss: 0.580573\n",
      "epoch 39; iter: 200; batch classifier loss: 0.232331; batch adversarial loss: 0.606232\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465033; batch adversarial loss: 0.633793\n",
      "epoch 40; iter: 200; batch classifier loss: 0.439659; batch adversarial loss: 0.589227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382386; batch adversarial loss: 0.611190\n",
      "epoch 41; iter: 200; batch classifier loss: 0.316659; batch adversarial loss: 0.657783\n",
      "epoch 42; iter: 0; batch classifier loss: 0.328792; batch adversarial loss: 0.637305\n",
      "epoch 42; iter: 200; batch classifier loss: 0.358959; batch adversarial loss: 0.623067\n",
      "epoch 43; iter: 0; batch classifier loss: 0.322368; batch adversarial loss: 0.646044\n",
      "epoch 43; iter: 200; batch classifier loss: 0.491969; batch adversarial loss: 0.588308\n",
      "epoch 44; iter: 0; batch classifier loss: 0.420182; batch adversarial loss: 0.609187\n",
      "epoch 44; iter: 200; batch classifier loss: 0.376918; batch adversarial loss: 0.606032\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405419; batch adversarial loss: 0.684382\n",
      "epoch 45; iter: 200; batch classifier loss: 0.270752; batch adversarial loss: 0.627982\n",
      "epoch 46; iter: 0; batch classifier loss: 0.340029; batch adversarial loss: 0.696909\n",
      "epoch 46; iter: 200; batch classifier loss: 0.433401; batch adversarial loss: 0.611695\n",
      "epoch 47; iter: 0; batch classifier loss: 0.338559; batch adversarial loss: 0.660085\n",
      "epoch 47; iter: 200; batch classifier loss: 0.428920; batch adversarial loss: 0.614600\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386442; batch adversarial loss: 0.583876\n",
      "epoch 48; iter: 200; batch classifier loss: 0.370164; batch adversarial loss: 0.645184\n",
      "epoch 49; iter: 0; batch classifier loss: 0.339948; batch adversarial loss: 0.656073\n",
      "epoch 49; iter: 200; batch classifier loss: 0.272490; batch adversarial loss: 0.612027\n",
      "epoch 0; iter: 0; batch classifier loss: 9.448139; batch adversarial loss: 0.727216\n",
      "epoch 0; iter: 200; batch classifier loss: 6.792449; batch adversarial loss: 0.682024\n",
      "epoch 1; iter: 0; batch classifier loss: 9.057828; batch adversarial loss: 0.661347\n",
      "epoch 1; iter: 200; batch classifier loss: 1.948390; batch adversarial loss: 0.615201\n",
      "epoch 2; iter: 0; batch classifier loss: 5.370617; batch adversarial loss: 0.653459\n",
      "epoch 2; iter: 200; batch classifier loss: 3.084967; batch adversarial loss: 0.608201\n",
      "epoch 3; iter: 0; batch classifier loss: 1.673591; batch adversarial loss: 0.612477\n",
      "epoch 3; iter: 200; batch classifier loss: 1.277777; batch adversarial loss: 0.641462\n",
      "epoch 4; iter: 0; batch classifier loss: 1.768190; batch adversarial loss: 0.583456\n",
      "epoch 4; iter: 200; batch classifier loss: 0.837220; batch adversarial loss: 0.642524\n",
      "epoch 5; iter: 0; batch classifier loss: 1.236248; batch adversarial loss: 0.585943\n",
      "epoch 5; iter: 200; batch classifier loss: 0.820024; batch adversarial loss: 0.672573\n",
      "epoch 6; iter: 0; batch classifier loss: 0.827524; batch adversarial loss: 0.626271\n",
      "epoch 6; iter: 200; batch classifier loss: 0.657763; batch adversarial loss: 0.635169\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626262; batch adversarial loss: 0.660651\n",
      "epoch 7; iter: 200; batch classifier loss: 0.555444; batch adversarial loss: 0.650817\n",
      "epoch 8; iter: 0; batch classifier loss: 0.405922; batch adversarial loss: 0.583815\n",
      "epoch 8; iter: 200; batch classifier loss: 0.495620; batch adversarial loss: 0.637421\n",
      "epoch 9; iter: 0; batch classifier loss: 0.451835; batch adversarial loss: 0.603477\n",
      "epoch 9; iter: 200; batch classifier loss: 0.414845; batch adversarial loss: 0.592828\n",
      "epoch 10; iter: 0; batch classifier loss: 0.382300; batch adversarial loss: 0.642659\n",
      "epoch 10; iter: 200; batch classifier loss: 0.406302; batch adversarial loss: 0.593997\n",
      "epoch 11; iter: 0; batch classifier loss: 0.786378; batch adversarial loss: 0.608301\n",
      "epoch 11; iter: 200; batch classifier loss: 0.334271; batch adversarial loss: 0.611047\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327791; batch adversarial loss: 0.598722\n",
      "epoch 12; iter: 200; batch classifier loss: 0.340340; batch adversarial loss: 0.680514\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372935; batch adversarial loss: 0.605447\n",
      "epoch 13; iter: 200; batch classifier loss: 0.330116; batch adversarial loss: 0.667422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.362000; batch adversarial loss: 0.610926\n",
      "epoch 14; iter: 200; batch classifier loss: 0.325228; batch adversarial loss: 0.644708\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382677; batch adversarial loss: 0.692119\n",
      "epoch 15; iter: 200; batch classifier loss: 0.372619; batch adversarial loss: 0.608150\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333095; batch adversarial loss: 0.658200\n",
      "epoch 16; iter: 200; batch classifier loss: 0.337808; batch adversarial loss: 0.664566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347053; batch adversarial loss: 0.568425\n",
      "epoch 17; iter: 200; batch classifier loss: 0.410074; batch adversarial loss: 0.686737\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303364; batch adversarial loss: 0.617399\n",
      "epoch 18; iter: 200; batch classifier loss: 0.262994; batch adversarial loss: 0.638126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327198; batch adversarial loss: 0.566804\n",
      "epoch 19; iter: 200; batch classifier loss: 0.314783; batch adversarial loss: 0.610237\n",
      "epoch 20; iter: 0; batch classifier loss: 0.423793; batch adversarial loss: 0.664282\n",
      "epoch 20; iter: 200; batch classifier loss: 0.384511; batch adversarial loss: 0.651100\n",
      "epoch 21; iter: 0; batch classifier loss: 0.384821; batch adversarial loss: 0.658531\n",
      "epoch 21; iter: 200; batch classifier loss: 0.310362; batch adversarial loss: 0.616898\n",
      "epoch 22; iter: 0; batch classifier loss: 0.381405; batch adversarial loss: 0.599665\n",
      "epoch 22; iter: 200; batch classifier loss: 0.502394; batch adversarial loss: 0.595800\n",
      "epoch 23; iter: 0; batch classifier loss: 0.316911; batch adversarial loss: 0.618843\n",
      "epoch 23; iter: 200; batch classifier loss: 0.353744; batch adversarial loss: 0.643099\n",
      "epoch 24; iter: 0; batch classifier loss: 0.379429; batch adversarial loss: 0.605746\n",
      "epoch 24; iter: 200; batch classifier loss: 0.322899; batch adversarial loss: 0.664771\n",
      "epoch 25; iter: 0; batch classifier loss: 0.260038; batch adversarial loss: 0.658791\n",
      "epoch 25; iter: 200; batch classifier loss: 0.300612; batch adversarial loss: 0.630049\n",
      "epoch 26; iter: 0; batch classifier loss: 0.399775; batch adversarial loss: 0.638640\n",
      "epoch 26; iter: 200; batch classifier loss: 0.361154; batch adversarial loss: 0.540060\n",
      "epoch 27; iter: 0; batch classifier loss: 0.329881; batch adversarial loss: 0.654241\n",
      "epoch 27; iter: 200; batch classifier loss: 0.380185; batch adversarial loss: 0.589510\n",
      "epoch 28; iter: 0; batch classifier loss: 0.325745; batch adversarial loss: 0.619363\n",
      "epoch 28; iter: 200; batch classifier loss: 0.367572; batch adversarial loss: 0.600834\n",
      "epoch 29; iter: 0; batch classifier loss: 0.297811; batch adversarial loss: 0.618472\n",
      "epoch 29; iter: 200; batch classifier loss: 0.360495; batch adversarial loss: 0.638710\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275927; batch adversarial loss: 0.629078\n",
      "epoch 30; iter: 200; batch classifier loss: 0.352683; batch adversarial loss: 0.611170\n",
      "epoch 31; iter: 0; batch classifier loss: 0.313959; batch adversarial loss: 0.650837\n",
      "epoch 31; iter: 200; batch classifier loss: 0.324065; batch adversarial loss: 0.645391\n",
      "epoch 32; iter: 0; batch classifier loss: 0.277069; batch adversarial loss: 0.600548\n",
      "epoch 32; iter: 200; batch classifier loss: 0.434454; batch adversarial loss: 0.607386\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363383; batch adversarial loss: 0.585712\n",
      "epoch 33; iter: 200; batch classifier loss: 0.332500; batch adversarial loss: 0.604980\n",
      "epoch 34; iter: 0; batch classifier loss: 0.375172; batch adversarial loss: 0.585188\n",
      "epoch 34; iter: 200; batch classifier loss: 0.339221; batch adversarial loss: 0.623914\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392187; batch adversarial loss: 0.613276\n",
      "epoch 35; iter: 200; batch classifier loss: 0.375169; batch adversarial loss: 0.552330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.274064; batch adversarial loss: 0.675773\n",
      "epoch 36; iter: 200; batch classifier loss: 0.336100; batch adversarial loss: 0.593923\n",
      "epoch 37; iter: 0; batch classifier loss: 0.680339; batch adversarial loss: 0.642735\n",
      "epoch 37; iter: 200; batch classifier loss: 0.352206; batch adversarial loss: 0.635667\n",
      "epoch 38; iter: 0; batch classifier loss: 0.338055; batch adversarial loss: 0.594289\n",
      "epoch 38; iter: 200; batch classifier loss: 0.323754; batch adversarial loss: 0.576049\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422177; batch adversarial loss: 0.601002\n",
      "epoch 39; iter: 200; batch classifier loss: 0.474342; batch adversarial loss: 0.576499\n",
      "epoch 40; iter: 0; batch classifier loss: 0.312237; batch adversarial loss: 0.661778\n",
      "epoch 40; iter: 200; batch classifier loss: 0.286885; batch adversarial loss: 0.662018\n",
      "epoch 41; iter: 0; batch classifier loss: 0.301872; batch adversarial loss: 0.616828\n",
      "epoch 41; iter: 200; batch classifier loss: 0.307989; batch adversarial loss: 0.671848\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364743; batch adversarial loss: 0.597744\n",
      "epoch 42; iter: 200; batch classifier loss: 0.484347; batch adversarial loss: 0.619806\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399251; batch adversarial loss: 0.629371\n",
      "epoch 43; iter: 200; batch classifier loss: 0.355312; batch adversarial loss: 0.682836\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422938; batch adversarial loss: 0.621075\n",
      "epoch 44; iter: 200; batch classifier loss: 0.300389; batch adversarial loss: 0.604865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392023; batch adversarial loss: 0.588910\n",
      "epoch 45; iter: 200; batch classifier loss: 0.504123; batch adversarial loss: 0.618945\n",
      "epoch 46; iter: 0; batch classifier loss: 0.304264; batch adversarial loss: 0.590563\n",
      "epoch 46; iter: 200; batch classifier loss: 0.369230; batch adversarial loss: 0.611692\n",
      "epoch 47; iter: 0; batch classifier loss: 0.312351; batch adversarial loss: 0.615092\n",
      "epoch 47; iter: 200; batch classifier loss: 0.266106; batch adversarial loss: 0.607028\n",
      "epoch 48; iter: 0; batch classifier loss: 0.354749; batch adversarial loss: 0.611698\n",
      "epoch 48; iter: 200; batch classifier loss: 0.438339; batch adversarial loss: 0.631333\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385442; batch adversarial loss: 0.601825\n",
      "epoch 49; iter: 200; batch classifier loss: 0.398046; batch adversarial loss: 0.638342\n",
      "epoch 0; iter: 0; batch classifier loss: 66.228043; batch adversarial loss: 0.949794\n",
      "epoch 0; iter: 200; batch classifier loss: 3.712705; batch adversarial loss: 0.805491\n",
      "epoch 1; iter: 0; batch classifier loss: 7.899765; batch adversarial loss: 0.735401\n",
      "epoch 1; iter: 200; batch classifier loss: 7.711002; batch adversarial loss: 0.685026\n",
      "epoch 2; iter: 0; batch classifier loss: 1.360696; batch adversarial loss: 0.689360\n",
      "epoch 2; iter: 200; batch classifier loss: 1.656434; batch adversarial loss: 0.672466\n",
      "epoch 3; iter: 0; batch classifier loss: 3.871783; batch adversarial loss: 0.642276\n",
      "epoch 3; iter: 200; batch classifier loss: 2.160157; batch adversarial loss: 0.612459\n",
      "epoch 4; iter: 0; batch classifier loss: 0.979971; batch adversarial loss: 0.634043\n",
      "epoch 4; iter: 200; batch classifier loss: 4.497118; batch adversarial loss: 0.624573\n",
      "epoch 5; iter: 0; batch classifier loss: 2.453124; batch adversarial loss: 0.575750\n",
      "epoch 5; iter: 200; batch classifier loss: 1.249115; batch adversarial loss: 0.641480\n",
      "epoch 6; iter: 0; batch classifier loss: 0.778760; batch adversarial loss: 0.641176\n",
      "epoch 6; iter: 200; batch classifier loss: 0.817011; batch adversarial loss: 0.606639\n",
      "epoch 7; iter: 0; batch classifier loss: 0.718632; batch adversarial loss: 0.654018\n",
      "epoch 7; iter: 200; batch classifier loss: 1.140926; batch adversarial loss: 0.593227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588441; batch adversarial loss: 0.655597\n",
      "epoch 8; iter: 200; batch classifier loss: 0.356396; batch adversarial loss: 0.666312\n",
      "epoch 9; iter: 0; batch classifier loss: 0.336829; batch adversarial loss: 0.683536\n",
      "epoch 9; iter: 200; batch classifier loss: 0.514789; batch adversarial loss: 0.612772\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443495; batch adversarial loss: 0.626293\n",
      "epoch 10; iter: 200; batch classifier loss: 0.400285; batch adversarial loss: 0.648612\n",
      "epoch 11; iter: 0; batch classifier loss: 0.358314; batch adversarial loss: 0.605878\n",
      "epoch 11; iter: 200; batch classifier loss: 0.386448; batch adversarial loss: 0.607772\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512518; batch adversarial loss: 0.566239\n",
      "epoch 12; iter: 200; batch classifier loss: 0.550173; batch adversarial loss: 0.596019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327933; batch adversarial loss: 0.602118\n",
      "epoch 13; iter: 200; batch classifier loss: 0.328201; batch adversarial loss: 0.612720\n",
      "epoch 14; iter: 0; batch classifier loss: 0.357547; batch adversarial loss: 0.610231\n",
      "epoch 14; iter: 200; batch classifier loss: 0.356270; batch adversarial loss: 0.624013\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398582; batch adversarial loss: 0.567334\n",
      "epoch 15; iter: 200; batch classifier loss: 0.359977; batch adversarial loss: 0.627251\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495717; batch adversarial loss: 0.610290\n",
      "epoch 16; iter: 200; batch classifier loss: 0.350410; batch adversarial loss: 0.579839\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322999; batch adversarial loss: 0.571105\n",
      "epoch 17; iter: 200; batch classifier loss: 0.360690; batch adversarial loss: 0.606187\n",
      "epoch 18; iter: 0; batch classifier loss: 0.390212; batch adversarial loss: 0.614756\n",
      "epoch 18; iter: 200; batch classifier loss: 0.342225; batch adversarial loss: 0.654749\n",
      "epoch 19; iter: 0; batch classifier loss: 0.380438; batch adversarial loss: 0.626722\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385244; batch adversarial loss: 0.609846\n",
      "epoch 20; iter: 0; batch classifier loss: 0.389708; batch adversarial loss: 0.623531\n",
      "epoch 20; iter: 200; batch classifier loss: 0.265247; batch adversarial loss: 0.609928\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338937; batch adversarial loss: 0.613450\n",
      "epoch 21; iter: 200; batch classifier loss: 0.262770; batch adversarial loss: 0.612976\n",
      "epoch 22; iter: 0; batch classifier loss: 0.313493; batch adversarial loss: 0.571300\n",
      "epoch 22; iter: 200; batch classifier loss: 0.336169; batch adversarial loss: 0.614718\n",
      "epoch 23; iter: 0; batch classifier loss: 0.353197; batch adversarial loss: 0.619269\n",
      "epoch 23; iter: 200; batch classifier loss: 0.307346; batch adversarial loss: 0.600576\n",
      "epoch 24; iter: 0; batch classifier loss: 0.301098; batch adversarial loss: 0.654147\n",
      "epoch 24; iter: 200; batch classifier loss: 0.358931; batch adversarial loss: 0.554380\n",
      "epoch 25; iter: 0; batch classifier loss: 0.309557; batch adversarial loss: 0.558785\n",
      "epoch 25; iter: 200; batch classifier loss: 0.414516; batch adversarial loss: 0.642097\n",
      "epoch 26; iter: 0; batch classifier loss: 0.263254; batch adversarial loss: 0.658916\n",
      "epoch 26; iter: 200; batch classifier loss: 0.344855; batch adversarial loss: 0.576984\n",
      "epoch 27; iter: 0; batch classifier loss: 0.355375; batch adversarial loss: 0.592899\n",
      "epoch 27; iter: 200; batch classifier loss: 0.389453; batch adversarial loss: 0.604371\n",
      "epoch 28; iter: 0; batch classifier loss: 0.489854; batch adversarial loss: 0.589360\n",
      "epoch 28; iter: 200; batch classifier loss: 0.421927; batch adversarial loss: 0.597766\n",
      "epoch 29; iter: 0; batch classifier loss: 0.339752; batch adversarial loss: 0.599563\n",
      "epoch 29; iter: 200; batch classifier loss: 0.257965; batch adversarial loss: 0.661785\n",
      "epoch 30; iter: 0; batch classifier loss: 0.318320; batch adversarial loss: 0.621511\n",
      "epoch 30; iter: 200; batch classifier loss: 0.261746; batch adversarial loss: 0.624481\n",
      "epoch 31; iter: 0; batch classifier loss: 0.317511; batch adversarial loss: 0.630591\n",
      "epoch 31; iter: 200; batch classifier loss: 0.367375; batch adversarial loss: 0.651905\n",
      "epoch 32; iter: 0; batch classifier loss: 0.222352; batch adversarial loss: 0.715306\n",
      "epoch 32; iter: 200; batch classifier loss: 0.551406; batch adversarial loss: 0.668243\n",
      "epoch 33; iter: 0; batch classifier loss: 0.342742; batch adversarial loss: 0.588488\n",
      "epoch 33; iter: 200; batch classifier loss: 0.318259; batch adversarial loss: 0.573068\n",
      "epoch 34; iter: 0; batch classifier loss: 0.308705; batch adversarial loss: 0.624184\n",
      "epoch 34; iter: 200; batch classifier loss: 0.256428; batch adversarial loss: 0.651796\n",
      "epoch 35; iter: 0; batch classifier loss: 0.318522; batch adversarial loss: 0.602100\n",
      "epoch 35; iter: 200; batch classifier loss: 0.289850; batch adversarial loss: 0.595783\n",
      "epoch 36; iter: 0; batch classifier loss: 0.383528; batch adversarial loss: 0.648405\n",
      "epoch 36; iter: 200; batch classifier loss: 0.340309; batch adversarial loss: 0.605811\n",
      "epoch 37; iter: 0; batch classifier loss: 0.329910; batch adversarial loss: 0.602747\n",
      "epoch 37; iter: 200; batch classifier loss: 0.302204; batch adversarial loss: 0.584419\n",
      "epoch 38; iter: 0; batch classifier loss: 0.314082; batch adversarial loss: 0.548035\n",
      "epoch 38; iter: 200; batch classifier loss: 0.282551; batch adversarial loss: 0.668477\n",
      "epoch 39; iter: 0; batch classifier loss: 0.354523; batch adversarial loss: 0.594681\n",
      "epoch 39; iter: 200; batch classifier loss: 0.355408; batch adversarial loss: 0.605374\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270144; batch adversarial loss: 0.626783\n",
      "epoch 40; iter: 200; batch classifier loss: 0.324620; batch adversarial loss: 0.641388\n",
      "epoch 41; iter: 0; batch classifier loss: 0.248924; batch adversarial loss: 0.582510\n",
      "epoch 41; iter: 200; batch classifier loss: 0.298757; batch adversarial loss: 0.605281\n",
      "epoch 42; iter: 0; batch classifier loss: 0.355295; batch adversarial loss: 0.645038\n",
      "epoch 42; iter: 200; batch classifier loss: 0.335771; batch adversarial loss: 0.649489\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433427; batch adversarial loss: 0.559042\n",
      "epoch 43; iter: 200; batch classifier loss: 0.289993; batch adversarial loss: 0.667804\n",
      "epoch 44; iter: 0; batch classifier loss: 0.285469; batch adversarial loss: 0.613628\n",
      "epoch 44; iter: 200; batch classifier loss: 0.388461; batch adversarial loss: 0.561323\n",
      "epoch 45; iter: 0; batch classifier loss: 0.240261; batch adversarial loss: 0.608427\n",
      "epoch 45; iter: 200; batch classifier loss: 0.315488; batch adversarial loss: 0.598967\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356148; batch adversarial loss: 0.644421\n",
      "epoch 46; iter: 200; batch classifier loss: 0.303722; batch adversarial loss: 0.592151\n",
      "epoch 47; iter: 0; batch classifier loss: 0.318490; batch adversarial loss: 0.641158\n",
      "epoch 47; iter: 200; batch classifier loss: 0.295640; batch adversarial loss: 0.664787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.297016; batch adversarial loss: 0.617959\n",
      "epoch 48; iter: 200; batch classifier loss: 0.264314; batch adversarial loss: 0.628094\n",
      "epoch 49; iter: 0; batch classifier loss: 0.307307; batch adversarial loss: 0.669138\n",
      "epoch 49; iter: 200; batch classifier loss: 0.346515; batch adversarial loss: 0.645606\n",
      "epoch 0; iter: 0; batch classifier loss: 4.353722; batch adversarial loss: 0.600812\n",
      "epoch 0; iter: 200; batch classifier loss: 10.149106; batch adversarial loss: 0.550274\n",
      "epoch 1; iter: 0; batch classifier loss: 18.119064; batch adversarial loss: 0.581879\n",
      "epoch 1; iter: 200; batch classifier loss: 2.361516; batch adversarial loss: 0.571935\n",
      "epoch 2; iter: 0; batch classifier loss: 8.977550; batch adversarial loss: 0.614917\n",
      "epoch 2; iter: 200; batch classifier loss: 4.802622; batch adversarial loss: 0.582825\n",
      "epoch 3; iter: 0; batch classifier loss: 4.498603; batch adversarial loss: 0.618989\n",
      "epoch 3; iter: 200; batch classifier loss: 5.259400; batch adversarial loss: 0.653197\n",
      "epoch 4; iter: 0; batch classifier loss: 2.322729; batch adversarial loss: 0.621328\n",
      "epoch 4; iter: 200; batch classifier loss: 1.906790; batch adversarial loss: 0.625036\n",
      "epoch 5; iter: 0; batch classifier loss: 11.404278; batch adversarial loss: 0.574977\n",
      "epoch 5; iter: 200; batch classifier loss: 0.496742; batch adversarial loss: 0.635492\n",
      "epoch 6; iter: 0; batch classifier loss: 1.924783; batch adversarial loss: 0.676703\n",
      "epoch 6; iter: 200; batch classifier loss: 0.651255; batch adversarial loss: 0.623470\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539770; batch adversarial loss: 0.648102\n",
      "epoch 7; iter: 200; batch classifier loss: 1.085871; batch adversarial loss: 0.652417\n",
      "epoch 8; iter: 0; batch classifier loss: 0.856757; batch adversarial loss: 0.603852\n",
      "epoch 8; iter: 200; batch classifier loss: 0.394829; batch adversarial loss: 0.684218\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342860; batch adversarial loss: 0.606852\n",
      "epoch 9; iter: 200; batch classifier loss: 0.338159; batch adversarial loss: 0.595312\n",
      "epoch 10; iter: 0; batch classifier loss: 0.420734; batch adversarial loss: 0.571936\n",
      "epoch 10; iter: 200; batch classifier loss: 0.386761; batch adversarial loss: 0.590885\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388677; batch adversarial loss: 0.602849\n",
      "epoch 11; iter: 200; batch classifier loss: 0.369811; batch adversarial loss: 0.583409\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352840; batch adversarial loss: 0.664701\n",
      "epoch 12; iter: 200; batch classifier loss: 0.431091; batch adversarial loss: 0.650882\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390423; batch adversarial loss: 0.661134\n",
      "epoch 13; iter: 200; batch classifier loss: 0.509791; batch adversarial loss: 0.589620\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505513; batch adversarial loss: 0.660488\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388023; batch adversarial loss: 0.582430\n",
      "epoch 15; iter: 0; batch classifier loss: 0.392416; batch adversarial loss: 0.585575\n",
      "epoch 15; iter: 200; batch classifier loss: 0.339474; batch adversarial loss: 0.637417\n",
      "epoch 16; iter: 0; batch classifier loss: 0.369019; batch adversarial loss: 0.622866\n",
      "epoch 16; iter: 200; batch classifier loss: 0.364794; batch adversarial loss: 0.618432\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371619; batch adversarial loss: 0.601767\n",
      "epoch 17; iter: 200; batch classifier loss: 0.407745; batch adversarial loss: 0.589758\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410086; batch adversarial loss: 0.643725\n",
      "epoch 18; iter: 200; batch classifier loss: 0.459381; batch adversarial loss: 0.564643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294927; batch adversarial loss: 0.641967\n",
      "epoch 19; iter: 200; batch classifier loss: 0.254694; batch adversarial loss: 0.688879\n",
      "epoch 20; iter: 0; batch classifier loss: 0.307422; batch adversarial loss: 0.666163\n",
      "epoch 20; iter: 200; batch classifier loss: 0.395054; batch adversarial loss: 0.637266\n",
      "epoch 21; iter: 0; batch classifier loss: 0.353638; batch adversarial loss: 0.599323\n",
      "epoch 21; iter: 200; batch classifier loss: 0.341169; batch adversarial loss: 0.636320\n",
      "epoch 22; iter: 0; batch classifier loss: 0.384646; batch adversarial loss: 0.561390\n",
      "epoch 22; iter: 200; batch classifier loss: 0.324625; batch adversarial loss: 0.594153\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247052; batch adversarial loss: 0.606733\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371208; batch adversarial loss: 0.567716\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303759; batch adversarial loss: 0.595286\n",
      "epoch 24; iter: 200; batch classifier loss: 0.582604; batch adversarial loss: 0.635815\n",
      "epoch 25; iter: 0; batch classifier loss: 0.376808; batch adversarial loss: 0.596854\n",
      "epoch 25; iter: 200; batch classifier loss: 0.367309; batch adversarial loss: 0.653030\n",
      "epoch 26; iter: 0; batch classifier loss: 0.342878; batch adversarial loss: 0.685953\n",
      "epoch 26; iter: 200; batch classifier loss: 0.313021; batch adversarial loss: 0.652811\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330547; batch adversarial loss: 0.678378\n",
      "epoch 27; iter: 200; batch classifier loss: 0.308792; batch adversarial loss: 0.661593\n",
      "epoch 28; iter: 0; batch classifier loss: 0.389021; batch adversarial loss: 0.581853\n",
      "epoch 28; iter: 200; batch classifier loss: 0.308569; batch adversarial loss: 0.641696\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376260; batch adversarial loss: 0.626545\n",
      "epoch 29; iter: 200; batch classifier loss: 0.526227; batch adversarial loss: 0.571475\n",
      "epoch 30; iter: 0; batch classifier loss: 0.376320; batch adversarial loss: 0.591383\n",
      "epoch 30; iter: 200; batch classifier loss: 0.283802; batch adversarial loss: 0.653460\n",
      "epoch 31; iter: 0; batch classifier loss: 0.370174; batch adversarial loss: 0.675948\n",
      "epoch 31; iter: 200; batch classifier loss: 0.276052; batch adversarial loss: 0.604547\n",
      "epoch 32; iter: 0; batch classifier loss: 0.373648; batch adversarial loss: 0.654446\n",
      "epoch 32; iter: 200; batch classifier loss: 0.347177; batch adversarial loss: 0.627568\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400940; batch adversarial loss: 0.587717\n",
      "epoch 33; iter: 200; batch classifier loss: 0.348551; batch adversarial loss: 0.608212\n",
      "epoch 34; iter: 0; batch classifier loss: 0.282508; batch adversarial loss: 0.636755\n",
      "epoch 34; iter: 200; batch classifier loss: 0.369601; batch adversarial loss: 0.686975\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412081; batch adversarial loss: 0.631288\n",
      "epoch 35; iter: 200; batch classifier loss: 0.334232; batch adversarial loss: 0.673481\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280949; batch adversarial loss: 0.591686\n",
      "epoch 36; iter: 200; batch classifier loss: 0.413615; batch adversarial loss: 0.585457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.320335; batch adversarial loss: 0.626395\n",
      "epoch 37; iter: 200; batch classifier loss: 0.339327; batch adversarial loss: 0.543256\n",
      "epoch 38; iter: 0; batch classifier loss: 0.455644; batch adversarial loss: 0.619789\n",
      "epoch 38; iter: 200; batch classifier loss: 0.355493; batch adversarial loss: 0.710051\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322253; batch adversarial loss: 0.594199\n",
      "epoch 39; iter: 200; batch classifier loss: 0.314365; batch adversarial loss: 0.639361\n",
      "epoch 40; iter: 0; batch classifier loss: 0.314492; batch adversarial loss: 0.633395\n",
      "epoch 40; iter: 200; batch classifier loss: 0.275198; batch adversarial loss: 0.636613\n",
      "epoch 41; iter: 0; batch classifier loss: 0.469523; batch adversarial loss: 0.573207\n",
      "epoch 41; iter: 200; batch classifier loss: 0.454153; batch adversarial loss: 0.644482\n",
      "epoch 42; iter: 0; batch classifier loss: 0.331866; batch adversarial loss: 0.629101\n",
      "epoch 42; iter: 200; batch classifier loss: 0.349562; batch adversarial loss: 0.598051\n",
      "epoch 43; iter: 0; batch classifier loss: 0.333962; batch adversarial loss: 0.659640\n",
      "epoch 43; iter: 200; batch classifier loss: 0.390938; batch adversarial loss: 0.605248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400803; batch adversarial loss: 0.643880\n",
      "epoch 44; iter: 200; batch classifier loss: 0.457378; batch adversarial loss: 0.608196\n",
      "epoch 45; iter: 0; batch classifier loss: 0.487718; batch adversarial loss: 0.602980\n",
      "epoch 45; iter: 200; batch classifier loss: 0.319350; batch adversarial loss: 0.626851\n",
      "epoch 46; iter: 0; batch classifier loss: 0.261790; batch adversarial loss: 0.717507\n",
      "epoch 46; iter: 200; batch classifier loss: 0.380542; batch adversarial loss: 0.643726\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325662; batch adversarial loss: 0.587194\n",
      "epoch 47; iter: 200; batch classifier loss: 0.295548; batch adversarial loss: 0.647098\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366406; batch adversarial loss: 0.567823\n",
      "epoch 48; iter: 200; batch classifier loss: 0.407437; batch adversarial loss: 0.574855\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472511; batch adversarial loss: 0.653996\n",
      "epoch 49; iter: 200; batch classifier loss: 0.332718; batch adversarial loss: 0.621452\n",
      "epoch 0; iter: 0; batch classifier loss: 12.771307; batch adversarial loss: 0.614429\n",
      "epoch 0; iter: 200; batch classifier loss: 8.368082; batch adversarial loss: 0.579345\n",
      "epoch 1; iter: 0; batch classifier loss: 2.275934; batch adversarial loss: 0.638309\n",
      "epoch 1; iter: 200; batch classifier loss: 2.273362; batch adversarial loss: 0.656834\n",
      "epoch 2; iter: 0; batch classifier loss: 3.756082; batch adversarial loss: 0.644275\n",
      "epoch 2; iter: 200; batch classifier loss: 3.391791; batch adversarial loss: 0.671619\n",
      "epoch 3; iter: 0; batch classifier loss: 2.393294; batch adversarial loss: 0.648557\n",
      "epoch 3; iter: 200; batch classifier loss: 3.381701; batch adversarial loss: 0.646333\n",
      "epoch 4; iter: 0; batch classifier loss: 2.282827; batch adversarial loss: 0.593129\n",
      "epoch 4; iter: 200; batch classifier loss: 1.135142; batch adversarial loss: 0.595920\n",
      "epoch 5; iter: 0; batch classifier loss: 1.830605; batch adversarial loss: 0.582865\n",
      "epoch 5; iter: 200; batch classifier loss: 2.004546; batch adversarial loss: 0.581655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.781001; batch adversarial loss: 0.633491\n",
      "epoch 6; iter: 200; batch classifier loss: 0.451537; batch adversarial loss: 0.609833\n",
      "epoch 7; iter: 0; batch classifier loss: 0.932435; batch adversarial loss: 0.579316\n",
      "epoch 7; iter: 200; batch classifier loss: 0.797136; batch adversarial loss: 0.601648\n",
      "epoch 8; iter: 0; batch classifier loss: 0.604250; batch adversarial loss: 0.601436\n",
      "epoch 8; iter: 200; batch classifier loss: 0.492985; batch adversarial loss: 0.556003\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417631; batch adversarial loss: 0.603947\n",
      "epoch 9; iter: 200; batch classifier loss: 0.413149; batch adversarial loss: 0.664058\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443471; batch adversarial loss: 0.611631\n",
      "epoch 10; iter: 200; batch classifier loss: 0.465834; batch adversarial loss: 0.650203\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323167; batch adversarial loss: 0.606656\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412718; batch adversarial loss: 0.645435\n",
      "epoch 12; iter: 0; batch classifier loss: 0.386718; batch adversarial loss: 0.610859\n",
      "epoch 12; iter: 200; batch classifier loss: 0.309377; batch adversarial loss: 0.716319\n",
      "epoch 13; iter: 0; batch classifier loss: 0.447693; batch adversarial loss: 0.651003\n",
      "epoch 13; iter: 200; batch classifier loss: 0.370117; batch adversarial loss: 0.632108\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290710; batch adversarial loss: 0.624978\n",
      "epoch 14; iter: 200; batch classifier loss: 0.440388; batch adversarial loss: 0.591135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334991; batch adversarial loss: 0.670089\n",
      "epoch 15; iter: 200; batch classifier loss: 0.398709; batch adversarial loss: 0.581923\n",
      "epoch 16; iter: 0; batch classifier loss: 0.353283; batch adversarial loss: 0.561714\n",
      "epoch 16; iter: 200; batch classifier loss: 0.314567; batch adversarial loss: 0.638838\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287014; batch adversarial loss: 0.641346\n",
      "epoch 17; iter: 200; batch classifier loss: 0.460057; batch adversarial loss: 0.622610\n",
      "epoch 18; iter: 0; batch classifier loss: 0.372025; batch adversarial loss: 0.631751\n",
      "epoch 18; iter: 200; batch classifier loss: 0.387815; batch adversarial loss: 0.589799\n",
      "epoch 19; iter: 0; batch classifier loss: 0.401123; batch adversarial loss: 0.591919\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350756; batch adversarial loss: 0.651665\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378442; batch adversarial loss: 0.599582\n",
      "epoch 20; iter: 200; batch classifier loss: 0.366899; batch adversarial loss: 0.591678\n",
      "epoch 21; iter: 0; batch classifier loss: 0.335277; batch adversarial loss: 0.607485\n",
      "epoch 21; iter: 200; batch classifier loss: 0.359916; batch adversarial loss: 0.707663\n",
      "epoch 22; iter: 0; batch classifier loss: 0.318823; batch adversarial loss: 0.609249\n",
      "epoch 22; iter: 200; batch classifier loss: 0.406218; batch adversarial loss: 0.647591\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380945; batch adversarial loss: 0.678809\n",
      "epoch 23; iter: 200; batch classifier loss: 0.398937; batch adversarial loss: 0.614783\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338633; batch adversarial loss: 0.600702\n",
      "epoch 24; iter: 200; batch classifier loss: 0.323637; batch adversarial loss: 0.626858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.354344; batch adversarial loss: 0.615276\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360891; batch adversarial loss: 0.645152\n",
      "epoch 26; iter: 0; batch classifier loss: 0.268845; batch adversarial loss: 0.615904\n",
      "epoch 26; iter: 200; batch classifier loss: 0.284090; batch adversarial loss: 0.630760\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383704; batch adversarial loss: 0.576713\n",
      "epoch 27; iter: 200; batch classifier loss: 0.242295; batch adversarial loss: 0.685244\n",
      "epoch 28; iter: 0; batch classifier loss: 0.326937; batch adversarial loss: 0.599771\n",
      "epoch 28; iter: 200; batch classifier loss: 0.386106; batch adversarial loss: 0.654276\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358223; batch adversarial loss: 0.617213\n",
      "epoch 29; iter: 200; batch classifier loss: 0.388835; batch adversarial loss: 0.616189\n",
      "epoch 30; iter: 0; batch classifier loss: 0.321698; batch adversarial loss: 0.653062\n",
      "epoch 30; iter: 200; batch classifier loss: 0.298919; batch adversarial loss: 0.607232\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328745; batch adversarial loss: 0.647015\n",
      "epoch 31; iter: 200; batch classifier loss: 0.331865; batch adversarial loss: 0.614034\n",
      "epoch 32; iter: 0; batch classifier loss: 0.380698; batch adversarial loss: 0.571337\n",
      "epoch 32; iter: 200; batch classifier loss: 0.322732; batch adversarial loss: 0.598675\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344283; batch adversarial loss: 0.618704\n",
      "epoch 33; iter: 200; batch classifier loss: 0.294270; batch adversarial loss: 0.585121\n",
      "epoch 34; iter: 0; batch classifier loss: 0.376357; batch adversarial loss: 0.625231\n",
      "epoch 34; iter: 200; batch classifier loss: 0.377941; batch adversarial loss: 0.622713\n",
      "epoch 35; iter: 0; batch classifier loss: 0.336487; batch adversarial loss: 0.627238\n",
      "epoch 35; iter: 200; batch classifier loss: 0.287646; batch adversarial loss: 0.605407\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365229; batch adversarial loss: 0.584652\n",
      "epoch 36; iter: 200; batch classifier loss: 0.255777; batch adversarial loss: 0.571868\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407839; batch adversarial loss: 0.653902\n",
      "epoch 37; iter: 200; batch classifier loss: 0.366704; batch adversarial loss: 0.537804\n",
      "epoch 38; iter: 0; batch classifier loss: 0.354730; batch adversarial loss: 0.633421\n",
      "epoch 38; iter: 200; batch classifier loss: 0.345625; batch adversarial loss: 0.622958\n",
      "epoch 39; iter: 0; batch classifier loss: 0.348243; batch adversarial loss: 0.593535\n",
      "epoch 39; iter: 200; batch classifier loss: 0.389212; batch adversarial loss: 0.575058\n",
      "epoch 40; iter: 0; batch classifier loss: 0.309377; batch adversarial loss: 0.648668\n",
      "epoch 40; iter: 200; batch classifier loss: 0.243086; batch adversarial loss: 0.645363\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438309; batch adversarial loss: 0.611506\n",
      "epoch 41; iter: 200; batch classifier loss: 0.268382; batch adversarial loss: 0.603613\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433710; batch adversarial loss: 0.634294\n",
      "epoch 42; iter: 200; batch classifier loss: 0.364718; batch adversarial loss: 0.603811\n",
      "epoch 43; iter: 0; batch classifier loss: 0.346448; batch adversarial loss: 0.585650\n",
      "epoch 43; iter: 200; batch classifier loss: 0.344981; batch adversarial loss: 0.630383\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433402; batch adversarial loss: 0.614576\n",
      "epoch 44; iter: 200; batch classifier loss: 0.364993; batch adversarial loss: 0.562852\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383828; batch adversarial loss: 0.625249\n",
      "epoch 45; iter: 200; batch classifier loss: 0.453692; batch adversarial loss: 0.634054\n",
      "epoch 46; iter: 0; batch classifier loss: 0.344973; batch adversarial loss: 0.614335\n",
      "epoch 46; iter: 200; batch classifier loss: 0.368498; batch adversarial loss: 0.631276\n",
      "epoch 47; iter: 0; batch classifier loss: 0.312867; batch adversarial loss: 0.602780\n",
      "epoch 47; iter: 200; batch classifier loss: 0.373072; batch adversarial loss: 0.645879\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371005; batch adversarial loss: 0.624395\n",
      "epoch 48; iter: 200; batch classifier loss: 0.318962; batch adversarial loss: 0.558858\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444000; batch adversarial loss: 0.673967\n",
      "epoch 49; iter: 200; batch classifier loss: 0.297514; batch adversarial loss: 0.579138\n",
      "epoch 0; iter: 0; batch classifier loss: 45.907597; batch adversarial loss: 0.758063\n",
      "epoch 0; iter: 200; batch classifier loss: 14.645283; batch adversarial loss: 0.664932\n",
      "epoch 1; iter: 0; batch classifier loss: 9.447186; batch adversarial loss: 0.680172\n",
      "epoch 1; iter: 200; batch classifier loss: 7.010439; batch adversarial loss: 0.643931\n",
      "epoch 2; iter: 0; batch classifier loss: 3.234488; batch adversarial loss: 0.636152\n",
      "epoch 2; iter: 200; batch classifier loss: 5.371395; batch adversarial loss: 0.599438\n",
      "epoch 3; iter: 0; batch classifier loss: 3.149962; batch adversarial loss: 0.636092\n",
      "epoch 3; iter: 200; batch classifier loss: 2.724568; batch adversarial loss: 0.651346\n",
      "epoch 4; iter: 0; batch classifier loss: 3.496395; batch adversarial loss: 0.645466\n",
      "epoch 4; iter: 200; batch classifier loss: 1.510904; batch adversarial loss: 0.637647\n",
      "epoch 5; iter: 0; batch classifier loss: 2.612076; batch adversarial loss: 0.612149\n",
      "epoch 5; iter: 200; batch classifier loss: 2.304384; batch adversarial loss: 0.625101\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580330; batch adversarial loss: 0.626605\n",
      "epoch 6; iter: 200; batch classifier loss: 4.279244; batch adversarial loss: 0.607305\n",
      "epoch 7; iter: 0; batch classifier loss: 1.481535; batch adversarial loss: 0.651639\n",
      "epoch 7; iter: 200; batch classifier loss: 0.525819; batch adversarial loss: 0.596777\n",
      "epoch 8; iter: 0; batch classifier loss: 0.548256; batch adversarial loss: 0.634510\n",
      "epoch 8; iter: 200; batch classifier loss: 0.468146; batch adversarial loss: 0.637402\n",
      "epoch 9; iter: 0; batch classifier loss: 0.640385; batch adversarial loss: 0.607679\n",
      "epoch 9; iter: 200; batch classifier loss: 0.627193; batch adversarial loss: 0.625729\n",
      "epoch 10; iter: 0; batch classifier loss: 0.389812; batch adversarial loss: 0.652394\n",
      "epoch 10; iter: 200; batch classifier loss: 0.423784; batch adversarial loss: 0.640486\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359007; batch adversarial loss: 0.618915\n",
      "epoch 11; iter: 200; batch classifier loss: 0.404579; batch adversarial loss: 0.572740\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476120; batch adversarial loss: 0.640473\n",
      "epoch 12; iter: 200; batch classifier loss: 0.365902; batch adversarial loss: 0.607737\n",
      "epoch 13; iter: 0; batch classifier loss: 0.345724; batch adversarial loss: 0.589281\n",
      "epoch 13; iter: 200; batch classifier loss: 0.427211; batch adversarial loss: 0.650617\n",
      "epoch 14; iter: 0; batch classifier loss: 0.411327; batch adversarial loss: 0.658596\n",
      "epoch 14; iter: 200; batch classifier loss: 0.334766; batch adversarial loss: 0.599277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337242; batch adversarial loss: 0.602604\n",
      "epoch 15; iter: 200; batch classifier loss: 0.447009; batch adversarial loss: 0.627364\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385613; batch adversarial loss: 0.561778\n",
      "epoch 16; iter: 200; batch classifier loss: 0.370816; batch adversarial loss: 0.613757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.387999; batch adversarial loss: 0.581865\n",
      "epoch 17; iter: 200; batch classifier loss: 0.363466; batch adversarial loss: 0.577465\n",
      "epoch 18; iter: 0; batch classifier loss: 0.276658; batch adversarial loss: 0.589834\n",
      "epoch 18; iter: 200; batch classifier loss: 0.329774; batch adversarial loss: 0.603753\n",
      "epoch 19; iter: 0; batch classifier loss: 0.387750; batch adversarial loss: 0.574701\n",
      "epoch 19; iter: 200; batch classifier loss: 0.291345; batch adversarial loss: 0.593626\n",
      "epoch 20; iter: 0; batch classifier loss: 0.371389; batch adversarial loss: 0.610506\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368251; batch adversarial loss: 0.537793\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369511; batch adversarial loss: 0.633693\n",
      "epoch 21; iter: 200; batch classifier loss: 0.368671; batch adversarial loss: 0.630529\n",
      "epoch 22; iter: 0; batch classifier loss: 0.312908; batch adversarial loss: 0.660393\n",
      "epoch 22; iter: 200; batch classifier loss: 0.367945; batch adversarial loss: 0.664743\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342223; batch adversarial loss: 0.601215\n",
      "epoch 23; iter: 200; batch classifier loss: 0.376366; batch adversarial loss: 0.640807\n",
      "epoch 24; iter: 0; batch classifier loss: 0.382300; batch adversarial loss: 0.597151\n",
      "epoch 24; iter: 200; batch classifier loss: 0.402070; batch adversarial loss: 0.640804\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266062; batch adversarial loss: 0.644544\n",
      "epoch 25; iter: 200; batch classifier loss: 0.318130; batch adversarial loss: 0.621488\n",
      "epoch 26; iter: 0; batch classifier loss: 0.332353; batch adversarial loss: 0.655401\n",
      "epoch 26; iter: 200; batch classifier loss: 0.340519; batch adversarial loss: 0.630837\n",
      "epoch 27; iter: 0; batch classifier loss: 0.316182; batch adversarial loss: 0.646797\n",
      "epoch 27; iter: 200; batch classifier loss: 0.450227; batch adversarial loss: 0.687847\n",
      "epoch 28; iter: 0; batch classifier loss: 0.376829; batch adversarial loss: 0.564215\n",
      "epoch 28; iter: 200; batch classifier loss: 0.365258; batch adversarial loss: 0.740049\n",
      "epoch 29; iter: 0; batch classifier loss: 0.326042; batch adversarial loss: 0.678127\n",
      "epoch 29; iter: 200; batch classifier loss: 0.280226; batch adversarial loss: 0.631016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.358658; batch adversarial loss: 0.623975\n",
      "epoch 30; iter: 200; batch classifier loss: 0.316931; batch adversarial loss: 0.632215\n",
      "epoch 31; iter: 0; batch classifier loss: 0.359436; batch adversarial loss: 0.601129\n",
      "epoch 31; iter: 200; batch classifier loss: 0.349901; batch adversarial loss: 0.555875\n",
      "epoch 32; iter: 0; batch classifier loss: 0.380825; batch adversarial loss: 0.588506\n",
      "epoch 32; iter: 200; batch classifier loss: 0.381992; batch adversarial loss: 0.581312\n",
      "epoch 33; iter: 0; batch classifier loss: 0.345032; batch adversarial loss: 0.586665\n",
      "epoch 33; iter: 200; batch classifier loss: 0.385691; batch adversarial loss: 0.555875\n",
      "epoch 34; iter: 0; batch classifier loss: 0.307929; batch adversarial loss: 0.619420\n",
      "epoch 34; iter: 200; batch classifier loss: 0.404192; batch adversarial loss: 0.605392\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441095; batch adversarial loss: 0.592650\n",
      "epoch 35; iter: 200; batch classifier loss: 0.304896; batch adversarial loss: 0.568429\n",
      "epoch 36; iter: 0; batch classifier loss: 0.275024; batch adversarial loss: 0.581507\n",
      "epoch 36; iter: 200; batch classifier loss: 0.398012; batch adversarial loss: 0.641689\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343108; batch adversarial loss: 0.617628\n",
      "epoch 37; iter: 200; batch classifier loss: 0.357185; batch adversarial loss: 0.671505\n",
      "epoch 38; iter: 0; batch classifier loss: 0.332541; batch adversarial loss: 0.650427\n",
      "epoch 38; iter: 200; batch classifier loss: 0.374128; batch adversarial loss: 0.660663\n",
      "epoch 39; iter: 0; batch classifier loss: 0.309396; batch adversarial loss: 0.651705\n",
      "epoch 39; iter: 200; batch classifier loss: 0.460810; batch adversarial loss: 0.675278\n",
      "epoch 40; iter: 0; batch classifier loss: 0.342949; batch adversarial loss: 0.598301\n",
      "epoch 40; iter: 200; batch classifier loss: 0.280669; batch adversarial loss: 0.614273\n",
      "epoch 41; iter: 0; batch classifier loss: 0.292814; batch adversarial loss: 0.674374\n",
      "epoch 41; iter: 200; batch classifier loss: 0.309723; batch adversarial loss: 0.635632\n",
      "epoch 42; iter: 0; batch classifier loss: 0.337471; batch adversarial loss: 0.655994\n",
      "epoch 42; iter: 200; batch classifier loss: 0.339369; batch adversarial loss: 0.606519\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390526; batch adversarial loss: 0.574352\n",
      "epoch 43; iter: 200; batch classifier loss: 0.363614; batch adversarial loss: 0.605767\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428502; batch adversarial loss: 0.643306\n",
      "epoch 44; iter: 200; batch classifier loss: 0.304788; batch adversarial loss: 0.553014\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393540; batch adversarial loss: 0.657574\n",
      "epoch 45; iter: 200; batch classifier loss: 0.286788; batch adversarial loss: 0.651626\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385732; batch adversarial loss: 0.621691\n",
      "epoch 46; iter: 200; batch classifier loss: 0.427740; batch adversarial loss: 0.554025\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350515; batch adversarial loss: 0.630332\n",
      "epoch 47; iter: 200; batch classifier loss: 0.355833; batch adversarial loss: 0.602537\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438030; batch adversarial loss: 0.603195\n",
      "epoch 48; iter: 200; batch classifier loss: 0.320790; batch adversarial loss: 0.629928\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371197; batch adversarial loss: 0.631100\n",
      "epoch 49; iter: 200; batch classifier loss: 0.285520; batch adversarial loss: 0.659913\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.823466  0.533153 -0.002884  0.996126  0.119844  0.069477\n",
      "std   0.022549  0.090666  0.021924  0.151547  0.048525  0.029764\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'sex'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','sex')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate\n",
    "adult_sex_metrics = pd.DataFrame(results)\n",
    "adult_sex_metrics_agg = adult_sex_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae1c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pr/f4jl4tln3yn9fd_1yjrwwkp40000gn/T/ipykernel_80188/1046569785.py:6: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_title = 'Adult Inprocessing Adversial Debiasing: Baseline - Sex'\n",
    "fig = compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', plot_title)\n",
    "fname    = plot_title.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "out_path = os.path.join(out_dir_plots, f'{fname}.png')\n",
    "fig.savefig(out_path)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c9f19",
   "metadata": {},
   "source": [
    "# -------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc15775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Save the aggregated metrics \n",
    "save_agg_metrics(\n",
    "    dataset_name      = dataset_name,\n",
    "    mitigation_name   = mitigation_name,\n",
    "    race_agg_df       = adult_race_metrics_agg,\n",
    "    sex_agg_df        = adult_sex_metrics_agg,\n",
    "    pipeline_stage    = pipeline_stage   \n",
    ")\n",
    "\n",
    "# 2) Save the raw metrics\n",
    "save_raw_metrics(\n",
    "    dataset_name      = dataset_name,\n",
    "    mitigation_name   = mitigation_name,\n",
    "    race_raw_df       = adult_race_metrics,\n",
    "    sex_raw_df        = adult_sex_metrics,\n",
    "    pipeline_stage    = pipeline_stage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc244a",
   "metadata": {},
   "source": [
    "# -------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a28cb",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedShuffleSplit, StratifiedKFold\n",
    "from src.metrics import best_hyperparameter_advdeb\n",
    "\n",
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Hyperparameter Search\n",
    "param_grid = {\n",
    "    'adversary_loss_weight': [0.5, 1.0],\n",
    "    'num_epochs':            [10, 20, 50],\n",
    "    'batch_size':            [64, 128]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "grid_results = []\n",
    "# Perform hyperparameter search with 15 stratified shuffle splits\n",
    "for params in grid:\n",
    "    print(f\"Testing config: {params}\")\n",
    "    fold_metrics = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            privileged_groups, unprivileged_groups,\n",
    "            scope_name='adv',\n",
    "            num_epochs=params['num_epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            adversary_loss_weight=params['adversary_loss_weight']\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "    \n",
    "    df_fm = pd.DataFrame(fold_metrics)\n",
    "    agg = df_fm.agg(['mean', 'std'])\n",
    "    \n",
    "    grid_results.append({\n",
    "        **params,\n",
    "        'acc_mean':   agg.loc['mean', 'accuracy'],\n",
    "        'acc_std':    agg.loc['std',  'accuracy'],\n",
    "        'f1_mean':    agg.loc['mean', 'f1_score'],\n",
    "        'f1_std':     agg.loc['std',  'f1_score'],\n",
    "        'SPD_mean':   agg.loc['mean', 'SPD'],\n",
    "        'SPD_std':    agg.loc['std',  'SPD'],\n",
    "        'DI_mean':    agg.loc['mean', 'DI'],\n",
    "        'DI_std':     agg.loc['std',  'DI'],\n",
    "        'EOD_mean':   agg.loc['mean', 'EOD'],\n",
    "        'EOD_std':    agg.loc['std',  'EOD'],\n",
    "        'AOD_mean':   agg.loc['mean', 'AOD'],\n",
    "        'AOD_std':    agg.loc['std',  'AOD'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Hyperparameter Selection\n",
    "best_param = best_hyperparameter_advdeb(results_df)\n",
    "print(f\"Best parameters: {best_param}\")\n",
    "\n",
    "# Final evaluation with StratifiedKFold\n",
    "loss_weight = best_param['adversary_loss_weight']\n",
    "n_epochs    = int(best_param['num_epochs'])\n",
    "batch_sz    = int(best_param['batch_size'])\n",
    "\n",
    "# 4) Run experiment, Evaluate\n",
    "results = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        privileged_groups, unprivileged_groups,\n",
    "        scope_name='adv',\n",
    "        num_epochs=n_epochs,\n",
    "        batch_size=batch_sz,\n",
    "        adversary_loss_weight=loss_weight\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "    \n",
    "# 5) Aggregate results\n",
    "adult_race_metrics = pd.DataFrame(results)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', 'Hyperparametertuned Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a3525",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedShuffleSplit, StratifiedKFold\n",
    "from src.metrics import best_hyperparameter_advdeb\n",
    "\n",
    "# 1) Retrieve data\n",
    "protected           = 'sex'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','sex')]\n",
    "\n",
    "# 2) Hyperparameter Search\n",
    "param_grid = {\n",
    "    'adversary_loss_weight': [0.5, 1.0],\n",
    "    'num_epochs':            [10, 20, 50],\n",
    "    'batch_size':            [64, 128]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "grid_results = []\n",
    "# Perform hyperparameter search with 15 stratified shuffle splits\n",
    "for params in grid:\n",
    "    print(f\"Testing config: {params}\")\n",
    "    fold_metrics = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=15, test_size=0.3, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            privileged_groups, unprivileged_groups,\n",
    "            scope_name='adv',\n",
    "            num_epochs=params['num_epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            adversary_loss_weight=params['adversary_loss_weight']\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "    \n",
    "    df_fm = pd.DataFrame(fold_metrics)\n",
    "    agg = df_fm.agg(['mean', 'std'])\n",
    "\n",
    "    grid_results.append({\n",
    "        **params,\n",
    "        'acc_mean':   agg.loc['mean', 'accuracy'],\n",
    "        'acc_std':    agg.loc['std',  'accuracy'],\n",
    "        'f1_mean':    agg.loc['mean', 'f1_score'],\n",
    "        'f1_std':     agg.loc['std',  'f1_score'],\n",
    "        'SPD_mean':   agg.loc['mean', 'SPD'],\n",
    "        'SPD_std':    agg.loc['std',  'SPD'],\n",
    "        'DI_mean':    agg.loc['mean', 'DI'],\n",
    "        'DI_std':     agg.loc['std',  'DI'],\n",
    "        'EOD_mean':   agg.loc['mean', 'EOD'],\n",
    "        'EOD_std':    agg.loc['std',  'EOD'],\n",
    "        'AOD_mean':   agg.loc['mean', 'AOD'],\n",
    "        'AOD_std':    agg.loc['std',  'AOD'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Hyperparameter Selection\n",
    "best_param = best_hyperparameter_advdeb(results_df)\n",
    "print(f\"Best parameters: {best_param}\")\n",
    "\n",
    "# Final evaluation with StratifiedKFold\n",
    "loss_weight = best_param['adversary_loss_weight']\n",
    "n_epochs    = int(best_param['num_epochs'])\n",
    "batch_sz    = int(best_param['batch_size'])\n",
    "\n",
    "# 4) Run experiment, Evaluate\n",
    "results = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        privileged_groups, unprivileged_groups,\n",
    "        scope_name='adv',\n",
    "        num_epochs=n_epochs,\n",
    "        batch_size=batch_sz,\n",
    "        adversary_loss_weight=loss_weight\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 5) Aggregate results\n",
    "adult_sex_metrics       = pd.DataFrame(results)\n",
    "adult_sex_metrics_agg   = adult_sex_metrics.agg(['mean','std'])\n",
    "print(adult_sex_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2435e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', 'Hyperparametertuned Adversial Debiasing Adult: Baseline - Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d97e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
