{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53b8bcc",
   "metadata": {},
   "source": [
    "## Inprocessing - Adversial Debiasing  -  Compas Model\n",
    "- for 'sex' and 'race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a779c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import reset_default_graph\n",
    "import pandas as pd\n",
    "from src.data_loading import load_adult_sex, load_adult_race\n",
    "from src.modeling import adversial_debiasing_train_and_predict\n",
    "from src.metrics import compute_metrics, compare_viz_metrics_2x3\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e287ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_race_agg = pd.read_csv('../../reports/baseline_agg/adult_race_metrics_agg.csv', index_col=0)\n",
    "baseline_sex_agg = pd.read_csv('../../reports/baseline_agg/adult_sex_metrics_agg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec69a2",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785d3da",
   "metadata": {},
   "source": [
    "## default adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4efb8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 33.336464; batch adversarial loss: 0.698576\n",
      "epoch 0; iter: 200; batch classifier loss: 5.936798; batch adversarial loss: 0.652281\n",
      "epoch 1; iter: 0; batch classifier loss: 5.579461; batch adversarial loss: 0.601110\n",
      "epoch 1; iter: 200; batch classifier loss: 2.696638; batch adversarial loss: 0.553113\n",
      "epoch 2; iter: 0; batch classifier loss: 8.840158; batch adversarial loss: 0.536361\n",
      "epoch 2; iter: 200; batch classifier loss: 3.363139; batch adversarial loss: 0.498092\n",
      "epoch 3; iter: 0; batch classifier loss: 4.014528; batch adversarial loss: 0.455007\n",
      "epoch 3; iter: 200; batch classifier loss: 1.884238; batch adversarial loss: 0.470924\n",
      "epoch 4; iter: 0; batch classifier loss: 0.388041; batch adversarial loss: 0.448188\n",
      "epoch 4; iter: 200; batch classifier loss: 1.080223; batch adversarial loss: 0.399339\n",
      "epoch 5; iter: 0; batch classifier loss: 4.836834; batch adversarial loss: 0.460488\n",
      "epoch 5; iter: 200; batch classifier loss: 1.055685; batch adversarial loss: 0.492148\n",
      "epoch 6; iter: 0; batch classifier loss: 0.812547; batch adversarial loss: 0.393964\n",
      "epoch 6; iter: 200; batch classifier loss: 0.526532; batch adversarial loss: 0.446735\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549878; batch adversarial loss: 0.444487\n",
      "epoch 7; iter: 200; batch classifier loss: 0.587617; batch adversarial loss: 0.447056\n",
      "epoch 8; iter: 0; batch classifier loss: 0.687169; batch adversarial loss: 0.384321\n",
      "epoch 8; iter: 200; batch classifier loss: 0.558126; batch adversarial loss: 0.376676\n",
      "epoch 9; iter: 0; batch classifier loss: 0.491366; batch adversarial loss: 0.401300\n",
      "epoch 9; iter: 200; batch classifier loss: 0.442938; batch adversarial loss: 0.397589\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474097; batch adversarial loss: 0.411127\n",
      "epoch 10; iter: 200; batch classifier loss: 0.390738; batch adversarial loss: 0.437200\n",
      "epoch 11; iter: 0; batch classifier loss: 0.683096; batch adversarial loss: 0.424648\n",
      "epoch 11; iter: 200; batch classifier loss: 0.455628; batch adversarial loss: 0.442275\n",
      "epoch 12; iter: 0; batch classifier loss: 0.340029; batch adversarial loss: 0.496945\n",
      "epoch 12; iter: 200; batch classifier loss: 0.418416; batch adversarial loss: 0.418552\n",
      "epoch 13; iter: 0; batch classifier loss: 0.933148; batch adversarial loss: 0.409336\n",
      "epoch 13; iter: 200; batch classifier loss: 0.391515; batch adversarial loss: 0.437112\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267072; batch adversarial loss: 0.359314\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351571; batch adversarial loss: 0.482857\n",
      "epoch 15; iter: 0; batch classifier loss: 0.426825; batch adversarial loss: 0.460974\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341618; batch adversarial loss: 0.407410\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297163; batch adversarial loss: 0.364021\n",
      "epoch 16; iter: 200; batch classifier loss: 0.476570; batch adversarial loss: 0.359854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322283; batch adversarial loss: 0.350067\n",
      "epoch 17; iter: 200; batch classifier loss: 0.313242; batch adversarial loss: 0.369510\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329703; batch adversarial loss: 0.378556\n",
      "epoch 18; iter: 200; batch classifier loss: 0.356530; batch adversarial loss: 0.412471\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356365; batch adversarial loss: 0.363051\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342982; batch adversarial loss: 0.349119\n",
      "epoch 20; iter: 0; batch classifier loss: 0.371319; batch adversarial loss: 0.402342\n",
      "epoch 20; iter: 200; batch classifier loss: 0.398274; batch adversarial loss: 0.398705\n",
      "epoch 21; iter: 0; batch classifier loss: 0.414613; batch adversarial loss: 0.548556\n",
      "epoch 21; iter: 200; batch classifier loss: 0.326982; batch adversarial loss: 0.359135\n",
      "epoch 22; iter: 0; batch classifier loss: 0.355555; batch adversarial loss: 0.535314\n",
      "epoch 22; iter: 200; batch classifier loss: 0.310876; batch adversarial loss: 0.416333\n",
      "epoch 23; iter: 0; batch classifier loss: 0.330837; batch adversarial loss: 0.487691\n",
      "epoch 23; iter: 200; batch classifier loss: 0.314030; batch adversarial loss: 0.349510\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361668; batch adversarial loss: 0.417689\n",
      "epoch 24; iter: 200; batch classifier loss: 0.414010; batch adversarial loss: 0.315458\n",
      "epoch 25; iter: 0; batch classifier loss: 0.342453; batch adversarial loss: 0.362868\n",
      "epoch 25; iter: 200; batch classifier loss: 0.310438; batch adversarial loss: 0.403418\n",
      "epoch 26; iter: 0; batch classifier loss: 0.409329; batch adversarial loss: 0.351563\n",
      "epoch 26; iter: 200; batch classifier loss: 0.352035; batch adversarial loss: 0.414935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394209; batch adversarial loss: 0.364212\n",
      "epoch 27; iter: 200; batch classifier loss: 0.266736; batch adversarial loss: 0.434717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386043; batch adversarial loss: 0.420930\n",
      "epoch 28; iter: 200; batch classifier loss: 0.318345; batch adversarial loss: 0.399394\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338542; batch adversarial loss: 0.399350\n",
      "epoch 29; iter: 200; batch classifier loss: 0.384526; batch adversarial loss: 0.288888\n",
      "epoch 30; iter: 0; batch classifier loss: 0.356593; batch adversarial loss: 0.476645\n",
      "epoch 30; iter: 200; batch classifier loss: 0.372507; batch adversarial loss: 0.367509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.244955; batch adversarial loss: 0.363854\n",
      "epoch 31; iter: 200; batch classifier loss: 0.341259; batch adversarial loss: 0.372333\n",
      "epoch 32; iter: 0; batch classifier loss: 0.338581; batch adversarial loss: 0.484459\n",
      "epoch 32; iter: 200; batch classifier loss: 0.272143; batch adversarial loss: 0.475553\n",
      "epoch 33; iter: 0; batch classifier loss: 0.281073; batch adversarial loss: 0.402616\n",
      "epoch 33; iter: 200; batch classifier loss: 0.312497; batch adversarial loss: 0.413051\n",
      "epoch 34; iter: 0; batch classifier loss: 0.347096; batch adversarial loss: 0.373888\n",
      "epoch 34; iter: 200; batch classifier loss: 0.369842; batch adversarial loss: 0.553229\n",
      "epoch 35; iter: 0; batch classifier loss: 0.363419; batch adversarial loss: 0.422978\n",
      "epoch 35; iter: 200; batch classifier loss: 0.346102; batch adversarial loss: 0.327117\n",
      "epoch 36; iter: 0; batch classifier loss: 0.333799; batch adversarial loss: 0.408293\n",
      "epoch 36; iter: 200; batch classifier loss: 0.314853; batch adversarial loss: 0.442809\n",
      "epoch 37; iter: 0; batch classifier loss: 0.345836; batch adversarial loss: 0.409531\n",
      "epoch 37; iter: 200; batch classifier loss: 0.373914; batch adversarial loss: 0.484579\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428304; batch adversarial loss: 0.421873\n",
      "epoch 38; iter: 200; batch classifier loss: 0.455957; batch adversarial loss: 0.438217\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473340; batch adversarial loss: 0.390547\n",
      "epoch 39; iter: 200; batch classifier loss: 0.350509; batch adversarial loss: 0.523228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399096; batch adversarial loss: 0.340537\n",
      "epoch 40; iter: 200; batch classifier loss: 0.335555; batch adversarial loss: 0.445581\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438830; batch adversarial loss: 0.328221\n",
      "epoch 41; iter: 200; batch classifier loss: 0.386839; batch adversarial loss: 0.401674\n",
      "epoch 42; iter: 0; batch classifier loss: 0.291579; batch adversarial loss: 0.348268\n",
      "epoch 42; iter: 200; batch classifier loss: 0.377876; batch adversarial loss: 0.459830\n",
      "epoch 43; iter: 0; batch classifier loss: 0.556511; batch adversarial loss: 0.394595\n",
      "epoch 43; iter: 200; batch classifier loss: 0.363932; batch adversarial loss: 0.392304\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443190; batch adversarial loss: 0.486619\n",
      "epoch 44; iter: 200; batch classifier loss: 0.253927; batch adversarial loss: 0.346586\n",
      "epoch 45; iter: 0; batch classifier loss: 0.366343; batch adversarial loss: 0.459372\n",
      "epoch 45; iter: 200; batch classifier loss: 0.332783; batch adversarial loss: 0.561614\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331073; batch adversarial loss: 0.360872\n",
      "epoch 46; iter: 200; batch classifier loss: 0.366941; batch adversarial loss: 0.463900\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417475; batch adversarial loss: 0.471418\n",
      "epoch 47; iter: 200; batch classifier loss: 0.354285; batch adversarial loss: 0.382440\n",
      "epoch 48; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.344851\n",
      "epoch 48; iter: 200; batch classifier loss: 0.322291; batch adversarial loss: 0.387951\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430504; batch adversarial loss: 0.384474\n",
      "epoch 49; iter: 200; batch classifier loss: 0.357741; batch adversarial loss: 0.317664\n",
      "epoch 0; iter: 0; batch classifier loss: 180.800735; batch adversarial loss: 0.693273\n",
      "epoch 0; iter: 200; batch classifier loss: 18.058052; batch adversarial loss: 0.574485\n",
      "epoch 1; iter: 0; batch classifier loss: 3.650878; batch adversarial loss: 0.528974\n",
      "epoch 1; iter: 200; batch classifier loss: 3.128374; batch adversarial loss: 0.576741\n",
      "epoch 2; iter: 0; batch classifier loss: 10.273624; batch adversarial loss: 0.498278\n",
      "epoch 2; iter: 200; batch classifier loss: 1.328314; batch adversarial loss: 0.505657\n",
      "epoch 3; iter: 0; batch classifier loss: 1.465533; batch adversarial loss: 0.413914\n",
      "epoch 3; iter: 200; batch classifier loss: 4.382961; batch adversarial loss: 0.418745\n",
      "epoch 4; iter: 0; batch classifier loss: 0.688451; batch adversarial loss: 0.557466\n",
      "epoch 4; iter: 200; batch classifier loss: 1.749379; batch adversarial loss: 0.445067\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613285; batch adversarial loss: 0.374364\n",
      "epoch 5; iter: 200; batch classifier loss: 1.912110; batch adversarial loss: 0.364018\n",
      "epoch 6; iter: 0; batch classifier loss: 1.176810; batch adversarial loss: 0.450966\n",
      "epoch 6; iter: 200; batch classifier loss: 1.103156; batch adversarial loss: 0.317330\n",
      "epoch 7; iter: 0; batch classifier loss: 1.188073; batch adversarial loss: 0.347744\n",
      "epoch 7; iter: 200; batch classifier loss: 0.802513; batch adversarial loss: 0.462359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.395174; batch adversarial loss: 0.478198\n",
      "epoch 8; iter: 200; batch classifier loss: 0.478065; batch adversarial loss: 0.382491\n",
      "epoch 9; iter: 0; batch classifier loss: 3.394211; batch adversarial loss: 0.484636\n",
      "epoch 9; iter: 200; batch classifier loss: 0.487269; batch adversarial loss: 0.452796\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397788; batch adversarial loss: 0.371666\n",
      "epoch 10; iter: 200; batch classifier loss: 0.802155; batch adversarial loss: 0.457956\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379429; batch adversarial loss: 0.357696\n",
      "epoch 11; iter: 200; batch classifier loss: 0.484510; batch adversarial loss: 0.311720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.554804; batch adversarial loss: 0.419562\n",
      "epoch 12; iter: 200; batch classifier loss: 0.411517; batch adversarial loss: 0.425558\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339037; batch adversarial loss: 0.439092\n",
      "epoch 13; iter: 200; batch classifier loss: 0.462108; batch adversarial loss: 0.429200\n",
      "epoch 14; iter: 0; batch classifier loss: 0.312019; batch adversarial loss: 0.498918\n",
      "epoch 14; iter: 200; batch classifier loss: 0.324133; batch adversarial loss: 0.518610\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471704; batch adversarial loss: 0.475467\n",
      "epoch 15; iter: 200; batch classifier loss: 0.418761; batch adversarial loss: 0.469620\n",
      "epoch 16; iter: 0; batch classifier loss: 0.309007; batch adversarial loss: 0.402548\n",
      "epoch 16; iter: 200; batch classifier loss: 0.374195; batch adversarial loss: 0.355907\n",
      "epoch 17; iter: 0; batch classifier loss: 0.301452; batch adversarial loss: 0.399064\n",
      "epoch 17; iter: 200; batch classifier loss: 0.353040; batch adversarial loss: 0.502610\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396271; batch adversarial loss: 0.383490\n",
      "epoch 18; iter: 200; batch classifier loss: 0.296803; batch adversarial loss: 0.357146\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378469; batch adversarial loss: 0.366459\n",
      "epoch 19; iter: 200; batch classifier loss: 0.360357; batch adversarial loss: 0.409950\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441223; batch adversarial loss: 0.343517\n",
      "epoch 20; iter: 200; batch classifier loss: 0.353892; batch adversarial loss: 0.396262\n",
      "epoch 21; iter: 0; batch classifier loss: 0.357313; batch adversarial loss: 0.363226\n",
      "epoch 21; iter: 200; batch classifier loss: 0.251300; batch adversarial loss: 0.402478\n",
      "epoch 22; iter: 0; batch classifier loss: 0.349886; batch adversarial loss: 0.405547\n",
      "epoch 22; iter: 200; batch classifier loss: 0.351823; batch adversarial loss: 0.546014\n",
      "epoch 23; iter: 0; batch classifier loss: 0.394672; batch adversarial loss: 0.440561\n",
      "epoch 23; iter: 200; batch classifier loss: 0.346206; batch adversarial loss: 0.515362\n",
      "epoch 24; iter: 0; batch classifier loss: 0.306048; batch adversarial loss: 0.422673\n",
      "epoch 24; iter: 200; batch classifier loss: 0.674674; batch adversarial loss: 0.372821\n",
      "epoch 25; iter: 0; batch classifier loss: 0.305513; batch adversarial loss: 0.487625\n",
      "epoch 25; iter: 200; batch classifier loss: 0.286927; batch adversarial loss: 0.388110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.287625; batch adversarial loss: 0.370480\n",
      "epoch 26; iter: 200; batch classifier loss: 0.304080; batch adversarial loss: 0.408720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327104; batch adversarial loss: 0.441107\n",
      "epoch 27; iter: 200; batch classifier loss: 0.319946; batch adversarial loss: 0.418720\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342920; batch adversarial loss: 0.507962\n",
      "epoch 28; iter: 200; batch classifier loss: 0.313593; batch adversarial loss: 0.365730\n",
      "epoch 29; iter: 0; batch classifier loss: 0.304724; batch adversarial loss: 0.314413\n",
      "epoch 29; iter: 200; batch classifier loss: 0.388639; batch adversarial loss: 0.385766\n",
      "epoch 30; iter: 0; batch classifier loss: 0.368220; batch adversarial loss: 0.432509\n",
      "epoch 30; iter: 200; batch classifier loss: 0.402379; batch adversarial loss: 0.445688\n",
      "epoch 31; iter: 0; batch classifier loss: 0.253565; batch adversarial loss: 0.453805\n",
      "epoch 31; iter: 200; batch classifier loss: 0.416527; batch adversarial loss: 0.383411\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415947; batch adversarial loss: 0.419210\n",
      "epoch 32; iter: 200; batch classifier loss: 0.331982; batch adversarial loss: 0.447412\n",
      "epoch 33; iter: 0; batch classifier loss: 0.361105; batch adversarial loss: 0.445128\n",
      "epoch 33; iter: 200; batch classifier loss: 0.318204; batch adversarial loss: 0.396952\n",
      "epoch 34; iter: 0; batch classifier loss: 0.481234; batch adversarial loss: 0.280879\n",
      "epoch 34; iter: 200; batch classifier loss: 0.370737; batch adversarial loss: 0.414501\n",
      "epoch 35; iter: 0; batch classifier loss: 0.307122; batch adversarial loss: 0.384625\n",
      "epoch 35; iter: 200; batch classifier loss: 0.277037; batch adversarial loss: 0.428737\n",
      "epoch 36; iter: 0; batch classifier loss: 0.343380; batch adversarial loss: 0.470453\n",
      "epoch 36; iter: 200; batch classifier loss: 0.321236; batch adversarial loss: 0.423179\n",
      "epoch 37; iter: 0; batch classifier loss: 0.339159; batch adversarial loss: 0.325863\n",
      "epoch 37; iter: 200; batch classifier loss: 0.316620; batch adversarial loss: 0.404883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.305555; batch adversarial loss: 0.355809\n",
      "epoch 38; iter: 200; batch classifier loss: 0.386664; batch adversarial loss: 0.429987\n",
      "epoch 39; iter: 0; batch classifier loss: 0.339802; batch adversarial loss: 0.516778\n",
      "epoch 39; iter: 200; batch classifier loss: 0.448573; batch adversarial loss: 0.420330\n",
      "epoch 40; iter: 0; batch classifier loss: 0.338038; batch adversarial loss: 0.429285\n",
      "epoch 40; iter: 200; batch classifier loss: 0.367653; batch adversarial loss: 0.434838\n",
      "epoch 41; iter: 0; batch classifier loss: 0.335268; batch adversarial loss: 0.423143\n",
      "epoch 41; iter: 200; batch classifier loss: 0.387401; batch adversarial loss: 0.471171\n",
      "epoch 42; iter: 0; batch classifier loss: 0.297504; batch adversarial loss: 0.475420\n",
      "epoch 42; iter: 200; batch classifier loss: 0.474836; batch adversarial loss: 0.407491\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408758; batch adversarial loss: 0.348756\n",
      "epoch 43; iter: 200; batch classifier loss: 0.373508; batch adversarial loss: 0.312768\n",
      "epoch 44; iter: 0; batch classifier loss: 0.318965; batch adversarial loss: 0.460524\n",
      "epoch 44; iter: 200; batch classifier loss: 0.728521; batch adversarial loss: 0.311402\n",
      "epoch 45; iter: 0; batch classifier loss: 0.317721; batch adversarial loss: 0.432223\n",
      "epoch 45; iter: 200; batch classifier loss: 0.264424; batch adversarial loss: 0.421488\n",
      "epoch 46; iter: 0; batch classifier loss: 0.354221; batch adversarial loss: 0.478251\n",
      "epoch 46; iter: 200; batch classifier loss: 0.311657; batch adversarial loss: 0.530963\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425727; batch adversarial loss: 0.373997\n",
      "epoch 47; iter: 200; batch classifier loss: 0.335873; batch adversarial loss: 0.440460\n",
      "epoch 48; iter: 0; batch classifier loss: 0.330075; batch adversarial loss: 0.402490\n",
      "epoch 48; iter: 200; batch classifier loss: 0.412133; batch adversarial loss: 0.467884\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487770; batch adversarial loss: 0.424845\n",
      "epoch 49; iter: 200; batch classifier loss: 0.331019; batch adversarial loss: 0.372907\n",
      "epoch 0; iter: 0; batch classifier loss: 30.969568; batch adversarial loss: 0.683022\n",
      "epoch 0; iter: 200; batch classifier loss: 17.711456; batch adversarial loss: 0.619470\n",
      "epoch 1; iter: 0; batch classifier loss: 7.245746; batch adversarial loss: 0.594571\n",
      "epoch 1; iter: 200; batch classifier loss: 8.970858; batch adversarial loss: 0.553992\n",
      "epoch 2; iter: 0; batch classifier loss: 1.467486; batch adversarial loss: 0.528181\n",
      "epoch 2; iter: 200; batch classifier loss: 7.702506; batch adversarial loss: 0.457814\n",
      "epoch 3; iter: 0; batch classifier loss: 0.746811; batch adversarial loss: 0.532101\n",
      "epoch 3; iter: 200; batch classifier loss: 1.242549; batch adversarial loss: 0.445528\n",
      "epoch 4; iter: 0; batch classifier loss: 1.048498; batch adversarial loss: 0.438615\n",
      "epoch 4; iter: 200; batch classifier loss: 2.021498; batch adversarial loss: 0.347032\n",
      "epoch 5; iter: 0; batch classifier loss: 0.930044; batch adversarial loss: 0.376142\n",
      "epoch 5; iter: 200; batch classifier loss: 0.650857; batch adversarial loss: 0.446984\n",
      "epoch 6; iter: 0; batch classifier loss: 1.226007; batch adversarial loss: 0.405624\n",
      "epoch 6; iter: 200; batch classifier loss: 0.489228; batch adversarial loss: 0.440561\n",
      "epoch 7; iter: 0; batch classifier loss: 3.269400; batch adversarial loss: 0.388544\n",
      "epoch 7; iter: 200; batch classifier loss: 0.443717; batch adversarial loss: 0.427520\n",
      "epoch 8; iter: 0; batch classifier loss: 0.471834; batch adversarial loss: 0.513020\n",
      "epoch 8; iter: 200; batch classifier loss: 0.606853; batch adversarial loss: 0.429760\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499499; batch adversarial loss: 0.580634\n",
      "epoch 9; iter: 200; batch classifier loss: 0.573569; batch adversarial loss: 0.411190\n",
      "epoch 10; iter: 0; batch classifier loss: 0.252938; batch adversarial loss: 0.490325\n",
      "epoch 10; iter: 200; batch classifier loss: 0.363133; batch adversarial loss: 0.332770\n",
      "epoch 11; iter: 0; batch classifier loss: 0.613568; batch adversarial loss: 0.410860\n",
      "epoch 11; iter: 200; batch classifier loss: 0.438474; batch adversarial loss: 0.475191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476491; batch adversarial loss: 0.391011\n",
      "epoch 12; iter: 200; batch classifier loss: 0.385661; batch adversarial loss: 0.440784\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361356; batch adversarial loss: 0.495823\n",
      "epoch 13; iter: 200; batch classifier loss: 0.462870; batch adversarial loss: 0.396157\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358841; batch adversarial loss: 0.426030\n",
      "epoch 14; iter: 200; batch classifier loss: 0.444352; batch adversarial loss: 0.305238\n",
      "epoch 15; iter: 0; batch classifier loss: 0.649549; batch adversarial loss: 0.389924\n",
      "epoch 15; iter: 200; batch classifier loss: 0.396371; batch adversarial loss: 0.417676\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367388; batch adversarial loss: 0.390356\n",
      "epoch 16; iter: 200; batch classifier loss: 0.358738; batch adversarial loss: 0.374861\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397123; batch adversarial loss: 0.380294\n",
      "epoch 17; iter: 200; batch classifier loss: 0.258961; batch adversarial loss: 0.298390\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313457; batch adversarial loss: 0.402457\n",
      "epoch 18; iter: 200; batch classifier loss: 0.376750; batch adversarial loss: 0.386778\n",
      "epoch 19; iter: 0; batch classifier loss: 0.339807; batch adversarial loss: 0.411868\n",
      "epoch 19; iter: 200; batch classifier loss: 0.508974; batch adversarial loss: 0.376103\n",
      "epoch 20; iter: 0; batch classifier loss: 0.348342; batch adversarial loss: 0.429630\n",
      "epoch 20; iter: 200; batch classifier loss: 0.264578; batch adversarial loss: 0.386906\n",
      "epoch 21; iter: 0; batch classifier loss: 0.346384; batch adversarial loss: 0.380910\n",
      "epoch 21; iter: 200; batch classifier loss: 0.317874; batch adversarial loss: 0.467698\n",
      "epoch 22; iter: 0; batch classifier loss: 0.306578; batch adversarial loss: 0.410624\n",
      "epoch 22; iter: 200; batch classifier loss: 0.349230; batch adversarial loss: 0.355450\n",
      "epoch 23; iter: 0; batch classifier loss: 0.375399; batch adversarial loss: 0.415256\n",
      "epoch 23; iter: 200; batch classifier loss: 0.348404; batch adversarial loss: 0.432828\n",
      "epoch 24; iter: 0; batch classifier loss: 0.365331; batch adversarial loss: 0.370406\n",
      "epoch 24; iter: 200; batch classifier loss: 0.336206; batch adversarial loss: 0.391252\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333902; batch adversarial loss: 0.375895\n",
      "epoch 25; iter: 200; batch classifier loss: 0.288257; batch adversarial loss: 0.392817\n",
      "epoch 26; iter: 0; batch classifier loss: 0.293897; batch adversarial loss: 0.356335\n",
      "epoch 26; iter: 200; batch classifier loss: 0.358117; batch adversarial loss: 0.525883\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475257; batch adversarial loss: 0.480069\n",
      "epoch 27; iter: 200; batch classifier loss: 0.293920; batch adversarial loss: 0.428710\n",
      "epoch 28; iter: 0; batch classifier loss: 0.412466; batch adversarial loss: 0.376953\n",
      "epoch 28; iter: 200; batch classifier loss: 0.396815; batch adversarial loss: 0.512072\n",
      "epoch 29; iter: 0; batch classifier loss: 0.304029; batch adversarial loss: 0.394102\n",
      "epoch 29; iter: 200; batch classifier loss: 0.318217; batch adversarial loss: 0.419575\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283269; batch adversarial loss: 0.454258\n",
      "epoch 30; iter: 200; batch classifier loss: 0.273519; batch adversarial loss: 0.465746\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315930; batch adversarial loss: 0.474557\n",
      "epoch 31; iter: 200; batch classifier loss: 0.405607; batch adversarial loss: 0.425573\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348648; batch adversarial loss: 0.461077\n",
      "epoch 32; iter: 200; batch classifier loss: 0.281497; batch adversarial loss: 0.353662\n",
      "epoch 33; iter: 0; batch classifier loss: 0.281274; batch adversarial loss: 0.355503\n",
      "epoch 33; iter: 200; batch classifier loss: 0.294071; batch adversarial loss: 0.396657\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455208; batch adversarial loss: 0.425320\n",
      "epoch 34; iter: 200; batch classifier loss: 0.278401; batch adversarial loss: 0.466075\n",
      "epoch 35; iter: 0; batch classifier loss: 0.335059; batch adversarial loss: 0.398516\n",
      "epoch 35; iter: 200; batch classifier loss: 0.340824; batch adversarial loss: 0.372560\n",
      "epoch 36; iter: 0; batch classifier loss: 0.345258; batch adversarial loss: 0.373206\n",
      "epoch 36; iter: 200; batch classifier loss: 0.292323; batch adversarial loss: 0.399712\n",
      "epoch 37; iter: 0; batch classifier loss: 0.352321; batch adversarial loss: 0.533713\n",
      "epoch 37; iter: 200; batch classifier loss: 0.286038; batch adversarial loss: 0.383518\n",
      "epoch 38; iter: 0; batch classifier loss: 0.364824; batch adversarial loss: 0.441767\n",
      "epoch 38; iter: 200; batch classifier loss: 0.383425; batch adversarial loss: 0.362581\n",
      "epoch 39; iter: 0; batch classifier loss: 0.327517; batch adversarial loss: 0.313394\n",
      "epoch 39; iter: 200; batch classifier loss: 0.282134; batch adversarial loss: 0.470592\n",
      "epoch 40; iter: 0; batch classifier loss: 0.345842; batch adversarial loss: 0.395015\n",
      "epoch 40; iter: 200; batch classifier loss: 0.434490; batch adversarial loss: 0.429946\n",
      "epoch 41; iter: 0; batch classifier loss: 0.263835; batch adversarial loss: 0.373790\n",
      "epoch 41; iter: 200; batch classifier loss: 0.289992; batch adversarial loss: 0.391046\n",
      "epoch 42; iter: 0; batch classifier loss: 0.277836; batch adversarial loss: 0.495098\n",
      "epoch 42; iter: 200; batch classifier loss: 0.298222; batch adversarial loss: 0.418948\n",
      "epoch 43; iter: 0; batch classifier loss: 0.320312; batch adversarial loss: 0.395960\n",
      "epoch 43; iter: 200; batch classifier loss: 0.302470; batch adversarial loss: 0.343625\n",
      "epoch 44; iter: 0; batch classifier loss: 0.337634; batch adversarial loss: 0.403225\n",
      "epoch 44; iter: 200; batch classifier loss: 0.377494; batch adversarial loss: 0.368234\n",
      "epoch 45; iter: 0; batch classifier loss: 0.311550; batch adversarial loss: 0.429041\n",
      "epoch 45; iter: 200; batch classifier loss: 0.393559; batch adversarial loss: 0.444958\n",
      "epoch 46; iter: 0; batch classifier loss: 0.457278; batch adversarial loss: 0.430505\n",
      "epoch 46; iter: 200; batch classifier loss: 0.330135; batch adversarial loss: 0.475767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407095; batch adversarial loss: 0.429362\n",
      "epoch 47; iter: 200; batch classifier loss: 0.503776; batch adversarial loss: 0.528667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347007; batch adversarial loss: 0.431049\n",
      "epoch 48; iter: 200; batch classifier loss: 0.342761; batch adversarial loss: 0.351051\n",
      "epoch 49; iter: 0; batch classifier loss: 0.322729; batch adversarial loss: 0.373603\n",
      "epoch 49; iter: 200; batch classifier loss: 0.350683; batch adversarial loss: 0.401207\n",
      "epoch 0; iter: 0; batch classifier loss: 22.786980; batch adversarial loss: 0.773618\n",
      "epoch 0; iter: 200; batch classifier loss: 10.067736; batch adversarial loss: 0.631447\n",
      "epoch 1; iter: 0; batch classifier loss: 5.952898; batch adversarial loss: 0.618843\n",
      "epoch 1; iter: 200; batch classifier loss: 6.276573; batch adversarial loss: 0.526956\n",
      "epoch 2; iter: 0; batch classifier loss: 3.022904; batch adversarial loss: 0.466556\n",
      "epoch 2; iter: 200; batch classifier loss: 5.631431; batch adversarial loss: 0.492270\n",
      "epoch 3; iter: 0; batch classifier loss: 1.388640; batch adversarial loss: 0.490331\n",
      "epoch 3; iter: 200; batch classifier loss: 2.138257; batch adversarial loss: 0.430676\n",
      "epoch 4; iter: 0; batch classifier loss: 1.343697; batch adversarial loss: 0.445900\n",
      "epoch 4; iter: 200; batch classifier loss: 0.950043; batch adversarial loss: 0.414557\n",
      "epoch 5; iter: 0; batch classifier loss: 1.152909; batch adversarial loss: 0.420468\n",
      "epoch 5; iter: 200; batch classifier loss: 0.522519; batch adversarial loss: 0.393895\n",
      "epoch 6; iter: 0; batch classifier loss: 0.861672; batch adversarial loss: 0.423315\n",
      "epoch 6; iter: 200; batch classifier loss: 1.281265; batch adversarial loss: 0.370938\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465154; batch adversarial loss: 0.405567\n",
      "epoch 7; iter: 200; batch classifier loss: 0.457151; batch adversarial loss: 0.367477\n",
      "epoch 8; iter: 0; batch classifier loss: 0.620446; batch adversarial loss: 0.351483\n",
      "epoch 8; iter: 200; batch classifier loss: 0.412457; batch adversarial loss: 0.373848\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359283; batch adversarial loss: 0.542181\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386215; batch adversarial loss: 0.428308\n",
      "epoch 10; iter: 0; batch classifier loss: 0.364690; batch adversarial loss: 0.409241\n",
      "epoch 10; iter: 200; batch classifier loss: 0.298022; batch adversarial loss: 0.451397\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379503; batch adversarial loss: 0.446330\n",
      "epoch 11; iter: 200; batch classifier loss: 0.511677; batch adversarial loss: 0.354901\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362808; batch adversarial loss: 0.398983\n",
      "epoch 12; iter: 200; batch classifier loss: 0.587387; batch adversarial loss: 0.489611\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340992; batch adversarial loss: 0.325228\n",
      "epoch 13; iter: 200; batch classifier loss: 0.371627; batch adversarial loss: 0.482283\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373014; batch adversarial loss: 0.456699\n",
      "epoch 14; iter: 200; batch classifier loss: 0.422851; batch adversarial loss: 0.262438\n",
      "epoch 15; iter: 0; batch classifier loss: 0.353130; batch adversarial loss: 0.360660\n",
      "epoch 15; iter: 200; batch classifier loss: 0.307111; batch adversarial loss: 0.490222\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304532; batch adversarial loss: 0.386999\n",
      "epoch 16; iter: 200; batch classifier loss: 0.428129; batch adversarial loss: 0.417869\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346676; batch adversarial loss: 0.527119\n",
      "epoch 17; iter: 200; batch classifier loss: 0.315925; batch adversarial loss: 0.450990\n",
      "epoch 18; iter: 0; batch classifier loss: 0.312366; batch adversarial loss: 0.341577\n",
      "epoch 18; iter: 200; batch classifier loss: 0.392368; batch adversarial loss: 0.420519\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350831; batch adversarial loss: 0.349270\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387529; batch adversarial loss: 0.386276\n",
      "epoch 20; iter: 0; batch classifier loss: 0.313420; batch adversarial loss: 0.499089\n",
      "epoch 20; iter: 200; batch classifier loss: 0.388565; batch adversarial loss: 0.437328\n",
      "epoch 21; iter: 0; batch classifier loss: 0.419022; batch adversarial loss: 0.336872\n",
      "epoch 21; iter: 200; batch classifier loss: 0.327854; batch adversarial loss: 0.443687\n",
      "epoch 22; iter: 0; batch classifier loss: 0.318195; batch adversarial loss: 0.386385\n",
      "epoch 22; iter: 200; batch classifier loss: 0.362235; batch adversarial loss: 0.481348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.360756; batch adversarial loss: 0.414396\n",
      "epoch 23; iter: 200; batch classifier loss: 0.373535; batch adversarial loss: 0.446047\n",
      "epoch 24; iter: 0; batch classifier loss: 0.306479; batch adversarial loss: 0.426984\n",
      "epoch 24; iter: 200; batch classifier loss: 0.317449; batch adversarial loss: 0.377431\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396391; batch adversarial loss: 0.320936\n",
      "epoch 25; iter: 200; batch classifier loss: 0.329400; batch adversarial loss: 0.480577\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303429; batch adversarial loss: 0.365610\n",
      "epoch 26; iter: 200; batch classifier loss: 0.317812; batch adversarial loss: 0.408719\n",
      "epoch 27; iter: 0; batch classifier loss: 0.326045; batch adversarial loss: 0.349630\n",
      "epoch 27; iter: 200; batch classifier loss: 0.307653; batch adversarial loss: 0.396907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.373379; batch adversarial loss: 0.457763\n",
      "epoch 28; iter: 200; batch classifier loss: 0.294354; batch adversarial loss: 0.460972\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320276; batch adversarial loss: 0.288760\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338229; batch adversarial loss: 0.426622\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283796; batch adversarial loss: 0.411879\n",
      "epoch 30; iter: 200; batch classifier loss: 0.325282; batch adversarial loss: 0.412850\n",
      "epoch 31; iter: 0; batch classifier loss: 0.324017; batch adversarial loss: 0.378253\n",
      "epoch 31; iter: 200; batch classifier loss: 0.369903; batch adversarial loss: 0.354842\n",
      "epoch 32; iter: 0; batch classifier loss: 0.379684; batch adversarial loss: 0.482550\n",
      "epoch 32; iter: 200; batch classifier loss: 0.323268; batch adversarial loss: 0.455951\n",
      "epoch 33; iter: 0; batch classifier loss: 0.226304; batch adversarial loss: 0.428898\n",
      "epoch 33; iter: 200; batch classifier loss: 0.278457; batch adversarial loss: 0.384284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.383632; batch adversarial loss: 0.376389\n",
      "epoch 34; iter: 200; batch classifier loss: 0.364070; batch adversarial loss: 0.355751\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299689; batch adversarial loss: 0.420431\n",
      "epoch 35; iter: 200; batch classifier loss: 0.325699; batch adversarial loss: 0.370434\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391716; batch adversarial loss: 0.444670\n",
      "epoch 36; iter: 200; batch classifier loss: 0.351867; batch adversarial loss: 0.402743\n",
      "epoch 37; iter: 0; batch classifier loss: 0.283749; batch adversarial loss: 0.322938\n",
      "epoch 37; iter: 200; batch classifier loss: 0.263148; batch adversarial loss: 0.450977\n",
      "epoch 38; iter: 0; batch classifier loss: 0.356737; batch adversarial loss: 0.527326\n",
      "epoch 38; iter: 200; batch classifier loss: 0.386587; batch adversarial loss: 0.397218\n",
      "epoch 39; iter: 0; batch classifier loss: 0.370854; batch adversarial loss: 0.347603\n",
      "epoch 39; iter: 200; batch classifier loss: 0.448629; batch adversarial loss: 0.454359\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351930; batch adversarial loss: 0.422767\n",
      "epoch 40; iter: 200; batch classifier loss: 0.317392; batch adversarial loss: 0.465395\n",
      "epoch 41; iter: 0; batch classifier loss: 0.352839; batch adversarial loss: 0.368013\n",
      "epoch 41; iter: 200; batch classifier loss: 0.379401; batch adversarial loss: 0.311615\n",
      "epoch 42; iter: 0; batch classifier loss: 0.395900; batch adversarial loss: 0.470793\n",
      "epoch 42; iter: 200; batch classifier loss: 0.362793; batch adversarial loss: 0.488133\n",
      "epoch 43; iter: 0; batch classifier loss: 0.316929; batch adversarial loss: 0.415435\n",
      "epoch 43; iter: 200; batch classifier loss: 0.330474; batch adversarial loss: 0.365585\n",
      "epoch 44; iter: 0; batch classifier loss: 0.288581; batch adversarial loss: 0.305062\n",
      "epoch 44; iter: 200; batch classifier loss: 0.376059; batch adversarial loss: 0.370179\n",
      "epoch 45; iter: 0; batch classifier loss: 0.273224; batch adversarial loss: 0.478110\n",
      "epoch 45; iter: 200; batch classifier loss: 0.356192; batch adversarial loss: 0.425436\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437261; batch adversarial loss: 0.376912\n",
      "epoch 46; iter: 200; batch classifier loss: 0.546081; batch adversarial loss: 0.393882\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367379; batch adversarial loss: 0.387802\n",
      "epoch 47; iter: 200; batch classifier loss: 0.310081; batch adversarial loss: 0.450391\n",
      "epoch 48; iter: 0; batch classifier loss: 0.262590; batch adversarial loss: 0.408669\n",
      "epoch 48; iter: 200; batch classifier loss: 0.226120; batch adversarial loss: 0.405657\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377896; batch adversarial loss: 0.437633\n",
      "epoch 49; iter: 200; batch classifier loss: 0.354359; batch adversarial loss: 0.451756\n",
      "epoch 0; iter: 0; batch classifier loss: 23.318691; batch adversarial loss: 0.578492\n",
      "epoch 0; iter: 200; batch classifier loss: 3.990505; batch adversarial loss: 0.536172\n",
      "epoch 1; iter: 0; batch classifier loss: 4.239579; batch adversarial loss: 0.464993\n",
      "epoch 1; iter: 200; batch classifier loss: 1.719263; batch adversarial loss: 0.496086\n",
      "epoch 2; iter: 0; batch classifier loss: 3.842093; batch adversarial loss: 0.512519\n",
      "epoch 2; iter: 200; batch classifier loss: 0.991020; batch adversarial loss: 0.423657\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556883; batch adversarial loss: 0.451530\n",
      "epoch 3; iter: 200; batch classifier loss: 2.451113; batch adversarial loss: 0.427101\n",
      "epoch 4; iter: 0; batch classifier loss: 0.515841; batch adversarial loss: 0.433852\n",
      "epoch 4; iter: 200; batch classifier loss: 1.503490; batch adversarial loss: 0.383926\n",
      "epoch 5; iter: 0; batch classifier loss: 3.505105; batch adversarial loss: 0.421880\n",
      "epoch 5; iter: 200; batch classifier loss: 0.284704; batch adversarial loss: 0.374856\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564800; batch adversarial loss: 0.450165\n",
      "epoch 6; iter: 200; batch classifier loss: 0.377251; batch adversarial loss: 0.469884\n",
      "epoch 7; iter: 0; batch classifier loss: 0.730448; batch adversarial loss: 0.435031\n",
      "epoch 7; iter: 200; batch classifier loss: 0.396738; batch adversarial loss: 0.391073\n",
      "epoch 8; iter: 0; batch classifier loss: 0.331962; batch adversarial loss: 0.440999\n",
      "epoch 8; iter: 200; batch classifier loss: 0.434287; batch adversarial loss: 0.416458\n",
      "epoch 9; iter: 0; batch classifier loss: 0.777782; batch adversarial loss: 0.457964\n",
      "epoch 9; iter: 200; batch classifier loss: 0.444139; batch adversarial loss: 0.470223\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335432; batch adversarial loss: 0.428508\n",
      "epoch 10; iter: 200; batch classifier loss: 0.653285; batch adversarial loss: 0.370270\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448025; batch adversarial loss: 0.457440\n",
      "epoch 11; iter: 200; batch classifier loss: 0.421374; batch adversarial loss: 0.404230\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364740; batch adversarial loss: 0.423741\n",
      "epoch 12; iter: 200; batch classifier loss: 0.476987; batch adversarial loss: 0.386007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417756; batch adversarial loss: 0.403955\n",
      "epoch 13; iter: 200; batch classifier loss: 0.344567; batch adversarial loss: 0.361386\n",
      "epoch 14; iter: 0; batch classifier loss: 0.415157; batch adversarial loss: 0.397574\n",
      "epoch 14; iter: 200; batch classifier loss: 0.324043; batch adversarial loss: 0.438487\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428548; batch adversarial loss: 0.417024\n",
      "epoch 15; iter: 200; batch classifier loss: 0.642699; batch adversarial loss: 0.457547\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394209; batch adversarial loss: 0.446630\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383951; batch adversarial loss: 0.406621\n",
      "epoch 17; iter: 0; batch classifier loss: 0.429989; batch adversarial loss: 0.475134\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345520; batch adversarial loss: 0.376902\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251476; batch adversarial loss: 0.364110\n",
      "epoch 18; iter: 200; batch classifier loss: 0.308685; batch adversarial loss: 0.441538\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375612; batch adversarial loss: 0.331700\n",
      "epoch 19; iter: 200; batch classifier loss: 0.418006; batch adversarial loss: 0.406457\n",
      "epoch 20; iter: 0; batch classifier loss: 0.331602; batch adversarial loss: 0.397722\n",
      "epoch 20; iter: 200; batch classifier loss: 0.512563; batch adversarial loss: 0.482388\n",
      "epoch 21; iter: 0; batch classifier loss: 0.358404; batch adversarial loss: 0.520735\n",
      "epoch 21; iter: 200; batch classifier loss: 0.351144; batch adversarial loss: 0.321982\n",
      "epoch 22; iter: 0; batch classifier loss: 0.355207; batch adversarial loss: 0.415523\n",
      "epoch 22; iter: 200; batch classifier loss: 0.338790; batch adversarial loss: 0.471790\n",
      "epoch 23; iter: 0; batch classifier loss: 0.372151; batch adversarial loss: 0.293454\n",
      "epoch 23; iter: 200; batch classifier loss: 0.360964; batch adversarial loss: 0.389677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.319414; batch adversarial loss: 0.397544\n",
      "epoch 24; iter: 200; batch classifier loss: 0.391896; batch adversarial loss: 0.419025\n",
      "epoch 25; iter: 0; batch classifier loss: 0.308941; batch adversarial loss: 0.437626\n",
      "epoch 25; iter: 200; batch classifier loss: 0.335180; batch adversarial loss: 0.364820\n",
      "epoch 26; iter: 0; batch classifier loss: 0.347730; batch adversarial loss: 0.485997\n",
      "epoch 26; iter: 200; batch classifier loss: 0.379189; batch adversarial loss: 0.386315\n",
      "epoch 27; iter: 0; batch classifier loss: 0.408605; batch adversarial loss: 0.434860\n",
      "epoch 27; iter: 200; batch classifier loss: 0.363244; batch adversarial loss: 0.389862\n",
      "epoch 28; iter: 0; batch classifier loss: 0.261481; batch adversarial loss: 0.408063\n",
      "epoch 28; iter: 200; batch classifier loss: 0.414306; batch adversarial loss: 0.417898\n",
      "epoch 29; iter: 0; batch classifier loss: 0.418415; batch adversarial loss: 0.369071\n",
      "epoch 29; iter: 200; batch classifier loss: 0.289787; batch adversarial loss: 0.489039\n",
      "epoch 30; iter: 0; batch classifier loss: 0.462243; batch adversarial loss: 0.379084\n",
      "epoch 30; iter: 200; batch classifier loss: 0.424561; batch adversarial loss: 0.552134\n",
      "epoch 31; iter: 0; batch classifier loss: 0.491390; batch adversarial loss: 0.360489\n",
      "epoch 31; iter: 200; batch classifier loss: 0.615929; batch adversarial loss: 0.385461\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418935; batch adversarial loss: 0.428370\n",
      "epoch 32; iter: 200; batch classifier loss: 0.509598; batch adversarial loss: 0.403892\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448725; batch adversarial loss: 0.433824\n",
      "epoch 33; iter: 200; batch classifier loss: 0.419570; batch adversarial loss: 0.372000\n",
      "epoch 34; iter: 0; batch classifier loss: 0.288333; batch adversarial loss: 0.460907\n",
      "epoch 34; iter: 200; batch classifier loss: 0.576094; batch adversarial loss: 0.305077\n",
      "epoch 35; iter: 0; batch classifier loss: 0.532807; batch adversarial loss: 0.445664\n",
      "epoch 35; iter: 200; batch classifier loss: 0.547206; batch adversarial loss: 0.402442\n",
      "epoch 36; iter: 0; batch classifier loss: 0.444866; batch adversarial loss: 0.303057\n",
      "epoch 36; iter: 200; batch classifier loss: 0.582743; batch adversarial loss: 0.333252\n",
      "epoch 37; iter: 0; batch classifier loss: 0.317972; batch adversarial loss: 0.477967\n",
      "epoch 37; iter: 200; batch classifier loss: 0.427011; batch adversarial loss: 0.442317\n",
      "epoch 38; iter: 0; batch classifier loss: 0.505783; batch adversarial loss: 0.320787\n",
      "epoch 38; iter: 200; batch classifier loss: 0.363338; batch adversarial loss: 0.418118\n",
      "epoch 39; iter: 0; batch classifier loss: 0.475507; batch adversarial loss: 0.475534\n",
      "epoch 39; iter: 200; batch classifier loss: 0.401551; batch adversarial loss: 0.504194\n",
      "epoch 40; iter: 0; batch classifier loss: 0.606778; batch adversarial loss: 0.413104\n",
      "epoch 40; iter: 200; batch classifier loss: 0.640965; batch adversarial loss: 0.367432\n",
      "epoch 41; iter: 0; batch classifier loss: 0.429783; batch adversarial loss: 0.441001\n",
      "epoch 41; iter: 200; batch classifier loss: 0.376479; batch adversarial loss: 0.407955\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365530; batch adversarial loss: 0.385501\n",
      "epoch 42; iter: 200; batch classifier loss: 0.509643; batch adversarial loss: 0.387002\n",
      "epoch 43; iter: 0; batch classifier loss: 0.518598; batch adversarial loss: 0.361947\n",
      "epoch 43; iter: 200; batch classifier loss: 0.605381; batch adversarial loss: 0.354691\n",
      "epoch 44; iter: 0; batch classifier loss: 0.590205; batch adversarial loss: 0.427971\n",
      "epoch 44; iter: 200; batch classifier loss: 0.703922; batch adversarial loss: 0.420158\n",
      "epoch 45; iter: 0; batch classifier loss: 0.504687; batch adversarial loss: 0.512470\n",
      "epoch 45; iter: 200; batch classifier loss: 0.612913; batch adversarial loss: 0.387326\n",
      "epoch 46; iter: 0; batch classifier loss: 0.515184; batch adversarial loss: 0.352241\n",
      "epoch 46; iter: 200; batch classifier loss: 0.386789; batch adversarial loss: 0.444448\n",
      "epoch 47; iter: 0; batch classifier loss: 0.579125; batch adversarial loss: 0.380540\n",
      "epoch 47; iter: 200; batch classifier loss: 0.453561; batch adversarial loss: 0.443140\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372245; batch adversarial loss: 0.316441\n",
      "epoch 48; iter: 200; batch classifier loss: 0.470222; batch adversarial loss: 0.473138\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435793; batch adversarial loss: 0.440270\n",
      "epoch 49; iter: 200; batch classifier loss: 0.497812; batch adversarial loss: 0.412807\n",
      "epoch 0; iter: 0; batch classifier loss: 55.984428; batch adversarial loss: 0.530138\n",
      "epoch 0; iter: 200; batch classifier loss: 7.649136; batch adversarial loss: 0.468078\n",
      "epoch 1; iter: 0; batch classifier loss: 6.812336; batch adversarial loss: 0.454086\n",
      "epoch 1; iter: 200; batch classifier loss: 0.849137; batch adversarial loss: 0.536305\n",
      "epoch 2; iter: 0; batch classifier loss: 6.324157; batch adversarial loss: 0.456838\n",
      "epoch 2; iter: 200; batch classifier loss: 2.810326; batch adversarial loss: 0.495554\n",
      "epoch 3; iter: 0; batch classifier loss: 1.564249; batch adversarial loss: 0.387245\n",
      "epoch 3; iter: 200; batch classifier loss: 2.592507; batch adversarial loss: 0.421740\n",
      "epoch 4; iter: 0; batch classifier loss: 0.888025; batch adversarial loss: 0.453772\n",
      "epoch 4; iter: 200; batch classifier loss: 0.703948; batch adversarial loss: 0.364876\n",
      "epoch 5; iter: 0; batch classifier loss: 0.972317; batch adversarial loss: 0.406341\n",
      "epoch 5; iter: 200; batch classifier loss: 1.133123; batch adversarial loss: 0.494482\n",
      "epoch 6; iter: 0; batch classifier loss: 4.505007; batch adversarial loss: 0.479254\n",
      "epoch 6; iter: 200; batch classifier loss: 0.585946; batch adversarial loss: 0.419532\n",
      "epoch 7; iter: 0; batch classifier loss: 0.452330; batch adversarial loss: 0.398315\n",
      "epoch 7; iter: 200; batch classifier loss: 0.702239; batch adversarial loss: 0.379127\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535116; batch adversarial loss: 0.425900\n",
      "epoch 8; iter: 200; batch classifier loss: 0.264373; batch adversarial loss: 0.483830\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359157; batch adversarial loss: 0.354438\n",
      "epoch 9; iter: 200; batch classifier loss: 0.294508; batch adversarial loss: 0.374793\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369768; batch adversarial loss: 0.381213\n",
      "epoch 10; iter: 200; batch classifier loss: 0.413232; batch adversarial loss: 0.436086\n",
      "epoch 11; iter: 0; batch classifier loss: 0.301066; batch adversarial loss: 0.313757\n",
      "epoch 11; iter: 200; batch classifier loss: 0.284438; batch adversarial loss: 0.319435\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408015; batch adversarial loss: 0.353799\n",
      "epoch 12; iter: 200; batch classifier loss: 0.372952; batch adversarial loss: 0.419595\n",
      "epoch 13; iter: 0; batch classifier loss: 0.304240; batch adversarial loss: 0.477663\n",
      "epoch 13; iter: 200; batch classifier loss: 0.360121; batch adversarial loss: 0.379224\n",
      "epoch 14; iter: 0; batch classifier loss: 0.436238; batch adversarial loss: 0.574545\n",
      "epoch 14; iter: 200; batch classifier loss: 0.687254; batch adversarial loss: 0.435712\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364727; batch adversarial loss: 0.349068\n",
      "epoch 15; iter: 200; batch classifier loss: 0.492560; batch adversarial loss: 0.416572\n",
      "epoch 16; iter: 0; batch classifier loss: 0.313833; batch adversarial loss: 0.355133\n",
      "epoch 16; iter: 200; batch classifier loss: 0.361206; batch adversarial loss: 0.495651\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371363; batch adversarial loss: 0.461296\n",
      "epoch 17; iter: 200; batch classifier loss: 0.398143; batch adversarial loss: 0.366826\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410704; batch adversarial loss: 0.338552\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336066; batch adversarial loss: 0.344850\n",
      "epoch 19; iter: 0; batch classifier loss: 0.403077; batch adversarial loss: 0.545308\n",
      "epoch 19; iter: 200; batch classifier loss: 0.306293; batch adversarial loss: 0.430672\n",
      "epoch 20; iter: 0; batch classifier loss: 0.383473; batch adversarial loss: 0.550639\n",
      "epoch 20; iter: 200; batch classifier loss: 0.353606; batch adversarial loss: 0.359307\n",
      "epoch 21; iter: 0; batch classifier loss: 0.489507; batch adversarial loss: 0.377223\n",
      "epoch 21; iter: 200; batch classifier loss: 0.265428; batch adversarial loss: 0.313509\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348921; batch adversarial loss: 0.422187\n",
      "epoch 22; iter: 200; batch classifier loss: 0.334078; batch adversarial loss: 0.456832\n",
      "epoch 23; iter: 0; batch classifier loss: 0.442415; batch adversarial loss: 0.453653\n",
      "epoch 23; iter: 200; batch classifier loss: 0.260322; batch adversarial loss: 0.433239\n",
      "epoch 24; iter: 0; batch classifier loss: 0.298801; batch adversarial loss: 0.486301\n",
      "epoch 24; iter: 200; batch classifier loss: 0.297252; batch adversarial loss: 0.385920\n",
      "epoch 25; iter: 0; batch classifier loss: 0.343420; batch adversarial loss: 0.334303\n",
      "epoch 25; iter: 200; batch classifier loss: 0.330606; batch adversarial loss: 0.392270\n",
      "epoch 26; iter: 0; batch classifier loss: 0.351723; batch adversarial loss: 0.385235\n",
      "epoch 26; iter: 200; batch classifier loss: 0.401364; batch adversarial loss: 0.418522\n",
      "epoch 27; iter: 0; batch classifier loss: 0.501652; batch adversarial loss: 0.416100\n",
      "epoch 27; iter: 200; batch classifier loss: 0.360246; batch adversarial loss: 0.410209\n",
      "epoch 28; iter: 0; batch classifier loss: 0.249184; batch adversarial loss: 0.486409\n",
      "epoch 28; iter: 200; batch classifier loss: 0.330884; batch adversarial loss: 0.321490\n",
      "epoch 29; iter: 0; batch classifier loss: 0.341819; batch adversarial loss: 0.323082\n",
      "epoch 29; iter: 200; batch classifier loss: 0.279986; batch adversarial loss: 0.389576\n",
      "epoch 30; iter: 0; batch classifier loss: 0.252811; batch adversarial loss: 0.468666\n",
      "epoch 30; iter: 200; batch classifier loss: 0.340358; batch adversarial loss: 0.360983\n",
      "epoch 31; iter: 0; batch classifier loss: 0.330590; batch adversarial loss: 0.514751\n",
      "epoch 31; iter: 200; batch classifier loss: 0.366762; batch adversarial loss: 0.248784\n",
      "epoch 32; iter: 0; batch classifier loss: 0.332852; batch adversarial loss: 0.434610\n",
      "epoch 32; iter: 200; batch classifier loss: 0.248938; batch adversarial loss: 0.430218\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415336; batch adversarial loss: 0.390864\n",
      "epoch 33; iter: 200; batch classifier loss: 0.359067; batch adversarial loss: 0.443657\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245746; batch adversarial loss: 0.478980\n",
      "epoch 34; iter: 200; batch classifier loss: 0.389683; batch adversarial loss: 0.307776\n",
      "epoch 35; iter: 0; batch classifier loss: 0.368250; batch adversarial loss: 0.360974\n",
      "epoch 35; iter: 200; batch classifier loss: 0.278622; batch adversarial loss: 0.413360\n",
      "epoch 36; iter: 0; batch classifier loss: 0.352788; batch adversarial loss: 0.437324\n",
      "epoch 36; iter: 200; batch classifier loss: 0.388233; batch adversarial loss: 0.344557\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425824; batch adversarial loss: 0.562825\n",
      "epoch 37; iter: 200; batch classifier loss: 0.377946; batch adversarial loss: 0.459935\n",
      "epoch 38; iter: 0; batch classifier loss: 0.333401; batch adversarial loss: 0.502645\n",
      "epoch 38; iter: 200; batch classifier loss: 0.353634; batch adversarial loss: 0.377638\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288713; batch adversarial loss: 0.415183\n",
      "epoch 39; iter: 200; batch classifier loss: 0.460950; batch adversarial loss: 0.317957\n",
      "epoch 40; iter: 0; batch classifier loss: 0.261829; batch adversarial loss: 0.403263\n",
      "epoch 40; iter: 200; batch classifier loss: 0.347378; batch adversarial loss: 0.331260\n",
      "epoch 41; iter: 0; batch classifier loss: 0.370820; batch adversarial loss: 0.390991\n",
      "epoch 41; iter: 200; batch classifier loss: 0.389253; batch adversarial loss: 0.434677\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424757; batch adversarial loss: 0.358802\n",
      "epoch 42; iter: 200; batch classifier loss: 0.374216; batch adversarial loss: 0.414255\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421364; batch adversarial loss: 0.397554\n",
      "epoch 43; iter: 200; batch classifier loss: 0.318215; batch adversarial loss: 0.390292\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429838; batch adversarial loss: 0.425773\n",
      "epoch 44; iter: 200; batch classifier loss: 0.286206; batch adversarial loss: 0.369554\n",
      "epoch 45; iter: 0; batch classifier loss: 0.285452; batch adversarial loss: 0.455731\n",
      "epoch 45; iter: 200; batch classifier loss: 0.340255; batch adversarial loss: 0.422241\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406123; batch adversarial loss: 0.365643\n",
      "epoch 46; iter: 200; batch classifier loss: 0.359093; batch adversarial loss: 0.398797\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385821; batch adversarial loss: 0.366489\n",
      "epoch 47; iter: 200; batch classifier loss: 0.308001; batch adversarial loss: 0.409448\n",
      "epoch 48; iter: 0; batch classifier loss: 0.278690; batch adversarial loss: 0.382390\n",
      "epoch 48; iter: 200; batch classifier loss: 0.376353; batch adversarial loss: 0.366159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351273; batch adversarial loss: 0.417621\n",
      "epoch 49; iter: 200; batch classifier loss: 0.427876; batch adversarial loss: 0.424821\n",
      "epoch 0; iter: 0; batch classifier loss: 66.161041; batch adversarial loss: 1.601074\n",
      "epoch 0; iter: 200; batch classifier loss: 11.210468; batch adversarial loss: 1.091447\n",
      "epoch 1; iter: 0; batch classifier loss: 11.614179; batch adversarial loss: 1.266391\n",
      "epoch 1; iter: 200; batch classifier loss: 3.782114; batch adversarial loss: 0.663525\n",
      "epoch 2; iter: 0; batch classifier loss: 6.110937; batch adversarial loss: 0.771203\n",
      "epoch 2; iter: 200; batch classifier loss: 3.039631; batch adversarial loss: 0.565821\n",
      "epoch 3; iter: 0; batch classifier loss: 0.670145; batch adversarial loss: 0.652592\n",
      "epoch 3; iter: 200; batch classifier loss: 1.399199; batch adversarial loss: 0.500620\n",
      "epoch 4; iter: 0; batch classifier loss: 3.571749; batch adversarial loss: 0.503106\n",
      "epoch 4; iter: 200; batch classifier loss: 1.210527; batch adversarial loss: 0.487583\n",
      "epoch 5; iter: 0; batch classifier loss: 0.529733; batch adversarial loss: 0.455691\n",
      "epoch 5; iter: 200; batch classifier loss: 1.064390; batch adversarial loss: 0.432525\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604283; batch adversarial loss: 0.477115\n",
      "epoch 6; iter: 200; batch classifier loss: 0.605150; batch adversarial loss: 0.446633\n",
      "epoch 7; iter: 0; batch classifier loss: 0.721104; batch adversarial loss: 0.436236\n",
      "epoch 7; iter: 200; batch classifier loss: 1.086606; batch adversarial loss: 0.403876\n",
      "epoch 8; iter: 0; batch classifier loss: 0.375862; batch adversarial loss: 0.449324\n",
      "epoch 8; iter: 200; batch classifier loss: 0.381393; batch adversarial loss: 0.474423\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426094; batch adversarial loss: 0.388580\n",
      "epoch 9; iter: 200; batch classifier loss: 0.374626; batch adversarial loss: 0.468698\n",
      "epoch 10; iter: 0; batch classifier loss: 0.404597; batch adversarial loss: 0.358895\n",
      "epoch 10; iter: 200; batch classifier loss: 0.441402; batch adversarial loss: 0.367694\n",
      "epoch 11; iter: 0; batch classifier loss: 0.468970; batch adversarial loss: 0.357134\n",
      "epoch 11; iter: 200; batch classifier loss: 0.367578; batch adversarial loss: 0.414416\n",
      "epoch 12; iter: 0; batch classifier loss: 0.473861; batch adversarial loss: 0.338855\n",
      "epoch 12; iter: 200; batch classifier loss: 0.397756; batch adversarial loss: 0.551157\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431905; batch adversarial loss: 0.374428\n",
      "epoch 13; iter: 200; batch classifier loss: 0.487691; batch adversarial loss: 0.306015\n",
      "epoch 14; iter: 0; batch classifier loss: 0.416484; batch adversarial loss: 0.421828\n",
      "epoch 14; iter: 200; batch classifier loss: 0.514075; batch adversarial loss: 0.460081\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381378; batch adversarial loss: 0.421147\n",
      "epoch 15; iter: 200; batch classifier loss: 0.448761; batch adversarial loss: 0.477739\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370202; batch adversarial loss: 0.354002\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380009; batch adversarial loss: 0.398127\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424163; batch adversarial loss: 0.478345\n",
      "epoch 17; iter: 200; batch classifier loss: 0.370252; batch adversarial loss: 0.554409\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354644; batch adversarial loss: 0.393880\n",
      "epoch 18; iter: 200; batch classifier loss: 0.333950; batch adversarial loss: 0.419354\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375485; batch adversarial loss: 0.390462\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347139; batch adversarial loss: 0.483942\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347493; batch adversarial loss: 0.437294\n",
      "epoch 20; iter: 200; batch classifier loss: 0.300327; batch adversarial loss: 0.424301\n",
      "epoch 21; iter: 0; batch classifier loss: 0.379034; batch adversarial loss: 0.343240\n",
      "epoch 21; iter: 200; batch classifier loss: 0.347061; batch adversarial loss: 0.374621\n",
      "epoch 22; iter: 0; batch classifier loss: 0.380248; batch adversarial loss: 0.351224\n",
      "epoch 22; iter: 200; batch classifier loss: 0.315460; batch adversarial loss: 0.407776\n",
      "epoch 23; iter: 0; batch classifier loss: 0.356438; batch adversarial loss: 0.440535\n",
      "epoch 23; iter: 200; batch classifier loss: 0.358214; batch adversarial loss: 0.450057\n",
      "epoch 24; iter: 0; batch classifier loss: 0.335811; batch adversarial loss: 0.354996\n",
      "epoch 24; iter: 200; batch classifier loss: 0.313180; batch adversarial loss: 0.409539\n",
      "epoch 25; iter: 0; batch classifier loss: 0.343991; batch adversarial loss: 0.485849\n",
      "epoch 25; iter: 200; batch classifier loss: 0.321471; batch adversarial loss: 0.439776\n",
      "epoch 26; iter: 0; batch classifier loss: 0.373378; batch adversarial loss: 0.306923\n",
      "epoch 26; iter: 200; batch classifier loss: 0.353073; batch adversarial loss: 0.445043\n",
      "epoch 27; iter: 0; batch classifier loss: 0.295198; batch adversarial loss: 0.454786\n",
      "epoch 27; iter: 200; batch classifier loss: 0.363775; batch adversarial loss: 0.357832\n",
      "epoch 28; iter: 0; batch classifier loss: 0.303108; batch adversarial loss: 0.558025\n",
      "epoch 28; iter: 200; batch classifier loss: 0.275266; batch adversarial loss: 0.468095\n",
      "epoch 29; iter: 0; batch classifier loss: 0.343959; batch adversarial loss: 0.464793\n",
      "epoch 29; iter: 200; batch classifier loss: 0.307297; batch adversarial loss: 0.374143\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448652; batch adversarial loss: 0.406809\n",
      "epoch 30; iter: 200; batch classifier loss: 0.386484; batch adversarial loss: 0.404585\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315498; batch adversarial loss: 0.365652\n",
      "epoch 31; iter: 200; batch classifier loss: 0.343481; batch adversarial loss: 0.368603\n",
      "epoch 32; iter: 0; batch classifier loss: 0.353864; batch adversarial loss: 0.425403\n",
      "epoch 32; iter: 200; batch classifier loss: 0.426628; batch adversarial loss: 0.345772\n",
      "epoch 33; iter: 0; batch classifier loss: 0.297933; batch adversarial loss: 0.346343\n",
      "epoch 33; iter: 200; batch classifier loss: 0.362400; batch adversarial loss: 0.395944\n",
      "epoch 34; iter: 0; batch classifier loss: 0.346169; batch adversarial loss: 0.376883\n",
      "epoch 34; iter: 200; batch classifier loss: 0.435650; batch adversarial loss: 0.483024\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429530; batch adversarial loss: 0.409822\n",
      "epoch 35; iter: 200; batch classifier loss: 0.353932; batch adversarial loss: 0.372434\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451155; batch adversarial loss: 0.428768\n",
      "epoch 36; iter: 200; batch classifier loss: 0.372306; batch adversarial loss: 0.400604\n",
      "epoch 37; iter: 0; batch classifier loss: 0.327444; batch adversarial loss: 0.484111\n",
      "epoch 37; iter: 200; batch classifier loss: 0.410974; batch adversarial loss: 0.393397\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437427; batch adversarial loss: 0.359591\n",
      "epoch 38; iter: 200; batch classifier loss: 0.333231; batch adversarial loss: 0.438180\n",
      "epoch 39; iter: 0; batch classifier loss: 0.352793; batch adversarial loss: 0.469011\n",
      "epoch 39; iter: 200; batch classifier loss: 0.499027; batch adversarial loss: 0.380986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.437181; batch adversarial loss: 0.385821\n",
      "epoch 40; iter: 200; batch classifier loss: 0.406445; batch adversarial loss: 0.375043\n",
      "epoch 41; iter: 0; batch classifier loss: 0.365265; batch adversarial loss: 0.314958\n",
      "epoch 41; iter: 200; batch classifier loss: 0.379680; batch adversarial loss: 0.360113\n",
      "epoch 42; iter: 0; batch classifier loss: 0.343030; batch adversarial loss: 0.376915\n",
      "epoch 42; iter: 200; batch classifier loss: 0.448940; batch adversarial loss: 0.361332\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409091; batch adversarial loss: 0.317089\n",
      "epoch 43; iter: 200; batch classifier loss: 0.354390; batch adversarial loss: 0.415817\n",
      "epoch 44; iter: 0; batch classifier loss: 0.275320; batch adversarial loss: 0.407288\n",
      "epoch 44; iter: 200; batch classifier loss: 0.460795; batch adversarial loss: 0.365586\n",
      "epoch 45; iter: 0; batch classifier loss: 0.353003; batch adversarial loss: 0.504884\n",
      "epoch 45; iter: 200; batch classifier loss: 0.404980; batch adversarial loss: 0.435224\n",
      "epoch 46; iter: 0; batch classifier loss: 0.390784; batch adversarial loss: 0.347855\n",
      "epoch 46; iter: 200; batch classifier loss: 0.500384; batch adversarial loss: 0.299911\n",
      "epoch 47; iter: 0; batch classifier loss: 0.442742; batch adversarial loss: 0.423406\n",
      "epoch 47; iter: 200; batch classifier loss: 0.418544; batch adversarial loss: 0.429651\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397146; batch adversarial loss: 0.392906\n",
      "epoch 48; iter: 200; batch classifier loss: 0.489619; batch adversarial loss: 0.409736\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420174; batch adversarial loss: 0.505952\n",
      "epoch 49; iter: 200; batch classifier loss: 0.401296; batch adversarial loss: 0.322961\n",
      "epoch 0; iter: 0; batch classifier loss: 11.809919; batch adversarial loss: 0.698260\n",
      "epoch 0; iter: 200; batch classifier loss: 9.614371; batch adversarial loss: 0.648254\n",
      "epoch 1; iter: 0; batch classifier loss: 8.492031; batch adversarial loss: 0.590173\n",
      "epoch 1; iter: 200; batch classifier loss: 5.801171; batch adversarial loss: 0.560644\n",
      "epoch 2; iter: 0; batch classifier loss: 1.983199; batch adversarial loss: 0.481764\n",
      "epoch 2; iter: 200; batch classifier loss: 2.902725; batch adversarial loss: 0.526590\n",
      "epoch 3; iter: 0; batch classifier loss: 1.333437; batch adversarial loss: 0.501927\n",
      "epoch 3; iter: 200; batch classifier loss: 2.163576; batch adversarial loss: 0.426175\n",
      "epoch 4; iter: 0; batch classifier loss: 0.719142; batch adversarial loss: 0.490210\n",
      "epoch 4; iter: 200; batch classifier loss: 0.610031; batch adversarial loss: 0.419012\n",
      "epoch 5; iter: 0; batch classifier loss: 1.948777; batch adversarial loss: 0.505538\n",
      "epoch 5; iter: 200; batch classifier loss: 0.856657; batch adversarial loss: 0.461158\n",
      "epoch 6; iter: 0; batch classifier loss: 1.746593; batch adversarial loss: 0.394666\n",
      "epoch 6; iter: 200; batch classifier loss: 0.459019; batch adversarial loss: 0.351718\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377010; batch adversarial loss: 0.528885\n",
      "epoch 7; iter: 200; batch classifier loss: 0.897130; batch adversarial loss: 0.392374\n",
      "epoch 8; iter: 0; batch classifier loss: 0.686380; batch adversarial loss: 0.372834\n",
      "epoch 8; iter: 200; batch classifier loss: 0.398787; batch adversarial loss: 0.497071\n",
      "epoch 9; iter: 0; batch classifier loss: 0.339337; batch adversarial loss: 0.360985\n",
      "epoch 9; iter: 200; batch classifier loss: 0.908269; batch adversarial loss: 0.339776\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468181; batch adversarial loss: 0.430379\n",
      "epoch 10; iter: 200; batch classifier loss: 0.346883; batch adversarial loss: 0.320794\n",
      "epoch 11; iter: 0; batch classifier loss: 0.621874; batch adversarial loss: 0.440702\n",
      "epoch 11; iter: 200; batch classifier loss: 0.339553; batch adversarial loss: 0.359968\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359610; batch adversarial loss: 0.489823\n",
      "epoch 12; iter: 200; batch classifier loss: 0.472171; batch adversarial loss: 0.412461\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439598; batch adversarial loss: 0.412988\n",
      "epoch 13; iter: 200; batch classifier loss: 0.468254; batch adversarial loss: 0.487421\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297377; batch adversarial loss: 0.316046\n",
      "epoch 14; iter: 200; batch classifier loss: 0.342031; batch adversarial loss: 0.418839\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358851; batch adversarial loss: 0.322800\n",
      "epoch 15; iter: 200; batch classifier loss: 0.383668; batch adversarial loss: 0.337899\n",
      "epoch 16; iter: 0; batch classifier loss: 0.596932; batch adversarial loss: 0.467482\n",
      "epoch 16; iter: 200; batch classifier loss: 0.345454; batch adversarial loss: 0.452629\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322666; batch adversarial loss: 0.406428\n",
      "epoch 17; iter: 200; batch classifier loss: 0.384851; batch adversarial loss: 0.389957\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342731; batch adversarial loss: 0.467480\n",
      "epoch 18; iter: 200; batch classifier loss: 0.296230; batch adversarial loss: 0.378297\n",
      "epoch 19; iter: 0; batch classifier loss: 0.359936; batch adversarial loss: 0.454720\n",
      "epoch 19; iter: 200; batch classifier loss: 0.356823; batch adversarial loss: 0.337027\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426225; batch adversarial loss: 0.374240\n",
      "epoch 20; iter: 200; batch classifier loss: 0.412023; batch adversarial loss: 0.386962\n",
      "epoch 21; iter: 0; batch classifier loss: 0.446046; batch adversarial loss: 0.460050\n",
      "epoch 21; iter: 200; batch classifier loss: 0.324847; batch adversarial loss: 0.358935\n",
      "epoch 22; iter: 0; batch classifier loss: 0.286643; batch adversarial loss: 0.385132\n",
      "epoch 22; iter: 200; batch classifier loss: 0.256621; batch adversarial loss: 0.392205\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381305; batch adversarial loss: 0.352124\n",
      "epoch 23; iter: 200; batch classifier loss: 0.428296; batch adversarial loss: 0.441872\n",
      "epoch 24; iter: 0; batch classifier loss: 0.334173; batch adversarial loss: 0.404021\n",
      "epoch 24; iter: 200; batch classifier loss: 0.325651; batch adversarial loss: 0.393887\n",
      "epoch 25; iter: 0; batch classifier loss: 0.347929; batch adversarial loss: 0.355545\n",
      "epoch 25; iter: 200; batch classifier loss: 0.298002; batch adversarial loss: 0.316944\n",
      "epoch 26; iter: 0; batch classifier loss: 0.317753; batch adversarial loss: 0.508526\n",
      "epoch 26; iter: 200; batch classifier loss: 0.326299; batch adversarial loss: 0.428068\n",
      "epoch 27; iter: 0; batch classifier loss: 0.285931; batch adversarial loss: 0.359795\n",
      "epoch 27; iter: 200; batch classifier loss: 0.409233; batch adversarial loss: 0.358356\n",
      "epoch 28; iter: 0; batch classifier loss: 0.282124; batch adversarial loss: 0.415496\n",
      "epoch 28; iter: 200; batch classifier loss: 0.351388; batch adversarial loss: 0.464990\n",
      "epoch 29; iter: 0; batch classifier loss: 0.427935; batch adversarial loss: 0.363722\n",
      "epoch 29; iter: 200; batch classifier loss: 0.352350; batch adversarial loss: 0.415447\n",
      "epoch 30; iter: 0; batch classifier loss: 0.286440; batch adversarial loss: 0.385609\n",
      "epoch 30; iter: 200; batch classifier loss: 0.358408; batch adversarial loss: 0.349879\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398429; batch adversarial loss: 0.367035\n",
      "epoch 31; iter: 200; batch classifier loss: 0.396900; batch adversarial loss: 0.337814\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405800; batch adversarial loss: 0.374840\n",
      "epoch 32; iter: 200; batch classifier loss: 0.307025; batch adversarial loss: 0.372404\n",
      "epoch 33; iter: 0; batch classifier loss: 0.312610; batch adversarial loss: 0.435952\n",
      "epoch 33; iter: 200; batch classifier loss: 0.342609; batch adversarial loss: 0.380679\n",
      "epoch 34; iter: 0; batch classifier loss: 0.365491; batch adversarial loss: 0.455981\n",
      "epoch 34; iter: 200; batch classifier loss: 0.351587; batch adversarial loss: 0.331661\n",
      "epoch 35; iter: 0; batch classifier loss: 0.332684; batch adversarial loss: 0.417781\n",
      "epoch 35; iter: 200; batch classifier loss: 0.428100; batch adversarial loss: 0.489440\n",
      "epoch 36; iter: 0; batch classifier loss: 0.327020; batch adversarial loss: 0.512598\n",
      "epoch 36; iter: 200; batch classifier loss: 0.445457; batch adversarial loss: 0.408695\n",
      "epoch 37; iter: 0; batch classifier loss: 0.317550; batch adversarial loss: 0.345781\n",
      "epoch 37; iter: 200; batch classifier loss: 0.390817; batch adversarial loss: 0.435668\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392579; batch adversarial loss: 0.417121\n",
      "epoch 38; iter: 200; batch classifier loss: 0.278291; batch adversarial loss: 0.476962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288360; batch adversarial loss: 0.318663\n",
      "epoch 39; iter: 200; batch classifier loss: 0.319510; batch adversarial loss: 0.464289\n",
      "epoch 40; iter: 0; batch classifier loss: 0.254429; batch adversarial loss: 0.487664\n",
      "epoch 40; iter: 200; batch classifier loss: 0.369618; batch adversarial loss: 0.368189\n",
      "epoch 41; iter: 0; batch classifier loss: 0.371490; batch adversarial loss: 0.339102\n",
      "epoch 41; iter: 200; batch classifier loss: 0.370062; batch adversarial loss: 0.439583\n",
      "epoch 42; iter: 0; batch classifier loss: 0.296017; batch adversarial loss: 0.434952\n",
      "epoch 42; iter: 200; batch classifier loss: 0.354492; batch adversarial loss: 0.491931\n",
      "epoch 43; iter: 0; batch classifier loss: 0.309380; batch adversarial loss: 0.316223\n",
      "epoch 43; iter: 200; batch classifier loss: 0.321079; batch adversarial loss: 0.425991\n",
      "epoch 44; iter: 0; batch classifier loss: 0.601894; batch adversarial loss: 0.408076\n",
      "epoch 44; iter: 200; batch classifier loss: 0.345610; batch adversarial loss: 0.486387\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432593; batch adversarial loss: 0.453868\n",
      "epoch 45; iter: 200; batch classifier loss: 0.333700; batch adversarial loss: 0.437075\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434567; batch adversarial loss: 0.414937\n",
      "epoch 46; iter: 200; batch classifier loss: 0.292319; batch adversarial loss: 0.399954\n",
      "epoch 47; iter: 0; batch classifier loss: 0.363123; batch adversarial loss: 0.496895\n",
      "epoch 47; iter: 200; batch classifier loss: 0.372426; batch adversarial loss: 0.499752\n",
      "epoch 48; iter: 0; batch classifier loss: 0.384560; batch adversarial loss: 0.390700\n",
      "epoch 48; iter: 200; batch classifier loss: 0.312813; batch adversarial loss: 0.363628\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410732; batch adversarial loss: 0.413225\n",
      "epoch 49; iter: 200; batch classifier loss: 0.309689; batch adversarial loss: 0.409590\n",
      "epoch 0; iter: 0; batch classifier loss: 31.783199; batch adversarial loss: 0.580868\n",
      "epoch 0; iter: 200; batch classifier loss: 7.089113; batch adversarial loss: 0.588630\n",
      "epoch 1; iter: 0; batch classifier loss: 4.264585; batch adversarial loss: 0.603950\n",
      "epoch 1; iter: 200; batch classifier loss: 3.816255; batch adversarial loss: 0.490217\n",
      "epoch 2; iter: 0; batch classifier loss: 3.288895; batch adversarial loss: 0.513502\n",
      "epoch 2; iter: 200; batch classifier loss: 3.181846; batch adversarial loss: 0.453108\n",
      "epoch 3; iter: 0; batch classifier loss: 3.749997; batch adversarial loss: 0.500511\n",
      "epoch 3; iter: 200; batch classifier loss: 3.091202; batch adversarial loss: 0.461804\n",
      "epoch 4; iter: 0; batch classifier loss: 3.033032; batch adversarial loss: 0.416936\n",
      "epoch 4; iter: 200; batch classifier loss: 1.098299; batch adversarial loss: 0.425093\n",
      "epoch 5; iter: 0; batch classifier loss: 1.338203; batch adversarial loss: 0.353307\n",
      "epoch 5; iter: 200; batch classifier loss: 1.192993; batch adversarial loss: 0.468305\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606685; batch adversarial loss: 0.352661\n",
      "epoch 6; iter: 200; batch classifier loss: 0.545701; batch adversarial loss: 0.400665\n",
      "epoch 7; iter: 0; batch classifier loss: 0.443384; batch adversarial loss: 0.411443\n",
      "epoch 7; iter: 200; batch classifier loss: 0.753746; batch adversarial loss: 0.420968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518473; batch adversarial loss: 0.407289\n",
      "epoch 8; iter: 200; batch classifier loss: 0.374878; batch adversarial loss: 0.439220\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528683; batch adversarial loss: 0.413571\n",
      "epoch 9; iter: 200; batch classifier loss: 0.513748; batch adversarial loss: 0.468579\n",
      "epoch 10; iter: 0; batch classifier loss: 1.159661; batch adversarial loss: 0.501825\n",
      "epoch 10; iter: 200; batch classifier loss: 0.427099; batch adversarial loss: 0.531945\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414413; batch adversarial loss: 0.435549\n",
      "epoch 11; iter: 200; batch classifier loss: 0.408420; batch adversarial loss: 0.411006\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347811; batch adversarial loss: 0.418406\n",
      "epoch 12; iter: 200; batch classifier loss: 0.402509; batch adversarial loss: 0.409980\n",
      "epoch 13; iter: 0; batch classifier loss: 0.424625; batch adversarial loss: 0.417224\n",
      "epoch 13; iter: 200; batch classifier loss: 0.409067; batch adversarial loss: 0.380124\n",
      "epoch 14; iter: 0; batch classifier loss: 0.346568; batch adversarial loss: 0.485988\n",
      "epoch 14; iter: 200; batch classifier loss: 0.369935; batch adversarial loss: 0.489808\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395378; batch adversarial loss: 0.289621\n",
      "epoch 15; iter: 200; batch classifier loss: 0.332548; batch adversarial loss: 0.346401\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385314; batch adversarial loss: 0.358329\n",
      "epoch 16; iter: 200; batch classifier loss: 0.562714; batch adversarial loss: 0.471120\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260888; batch adversarial loss: 0.459696\n",
      "epoch 17; iter: 200; batch classifier loss: 0.323984; batch adversarial loss: 0.374519\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326382; batch adversarial loss: 0.467732\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373669; batch adversarial loss: 0.372708\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400828; batch adversarial loss: 0.338481\n",
      "epoch 19; iter: 200; batch classifier loss: 0.388596; batch adversarial loss: 0.331005\n",
      "epoch 20; iter: 0; batch classifier loss: 0.349501; batch adversarial loss: 0.489854\n",
      "epoch 20; iter: 200; batch classifier loss: 0.498330; batch adversarial loss: 0.349892\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298016; batch adversarial loss: 0.469670\n",
      "epoch 21; iter: 200; batch classifier loss: 0.375634; batch adversarial loss: 0.418663\n",
      "epoch 22; iter: 0; batch classifier loss: 0.335690; batch adversarial loss: 0.470890\n",
      "epoch 22; iter: 200; batch classifier loss: 0.317619; batch adversarial loss: 0.399132\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288008; batch adversarial loss: 0.360018\n",
      "epoch 23; iter: 200; batch classifier loss: 0.411625; batch adversarial loss: 0.389430\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340821; batch adversarial loss: 0.429884\n",
      "epoch 24; iter: 200; batch classifier loss: 0.331321; batch adversarial loss: 0.531066\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339149; batch adversarial loss: 0.431008\n",
      "epoch 25; iter: 200; batch classifier loss: 0.273030; batch adversarial loss: 0.407528\n",
      "epoch 26; iter: 0; batch classifier loss: 0.353064; batch adversarial loss: 0.303263\n",
      "epoch 26; iter: 200; batch classifier loss: 0.314583; batch adversarial loss: 0.364800\n",
      "epoch 27; iter: 0; batch classifier loss: 0.297486; batch adversarial loss: 0.351182\n",
      "epoch 27; iter: 200; batch classifier loss: 0.364209; batch adversarial loss: 0.461610\n",
      "epoch 28; iter: 0; batch classifier loss: 0.390524; batch adversarial loss: 0.403838\n",
      "epoch 28; iter: 200; batch classifier loss: 0.333933; batch adversarial loss: 0.439732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412908; batch adversarial loss: 0.397590\n",
      "epoch 29; iter: 200; batch classifier loss: 0.376195; batch adversarial loss: 0.379553\n",
      "epoch 30; iter: 0; batch classifier loss: 0.330200; batch adversarial loss: 0.407308\n",
      "epoch 30; iter: 200; batch classifier loss: 0.299804; batch adversarial loss: 0.305847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.341527; batch adversarial loss: 0.517569\n",
      "epoch 31; iter: 200; batch classifier loss: 0.285803; batch adversarial loss: 0.404029\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393510; batch adversarial loss: 0.329024\n",
      "epoch 32; iter: 200; batch classifier loss: 0.285222; batch adversarial loss: 0.459155\n",
      "epoch 33; iter: 0; batch classifier loss: 0.310438; batch adversarial loss: 0.390403\n",
      "epoch 33; iter: 200; batch classifier loss: 0.426710; batch adversarial loss: 0.460510\n",
      "epoch 34; iter: 0; batch classifier loss: 0.315169; batch adversarial loss: 0.504680\n",
      "epoch 34; iter: 200; batch classifier loss: 0.397575; batch adversarial loss: 0.350392\n",
      "epoch 35; iter: 0; batch classifier loss: 0.328076; batch adversarial loss: 0.356579\n",
      "epoch 35; iter: 200; batch classifier loss: 0.386042; batch adversarial loss: 0.471891\n",
      "epoch 36; iter: 0; batch classifier loss: 0.302656; batch adversarial loss: 0.365448\n",
      "epoch 36; iter: 200; batch classifier loss: 0.314925; batch adversarial loss: 0.339631\n",
      "epoch 37; iter: 0; batch classifier loss: 0.266652; batch adversarial loss: 0.482191\n",
      "epoch 37; iter: 200; batch classifier loss: 0.390479; batch adversarial loss: 0.399501\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399582; batch adversarial loss: 0.378808\n",
      "epoch 38; iter: 200; batch classifier loss: 0.406447; batch adversarial loss: 0.432102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.341689; batch adversarial loss: 0.378677\n",
      "epoch 39; iter: 200; batch classifier loss: 0.336481; batch adversarial loss: 0.358912\n",
      "epoch 40; iter: 0; batch classifier loss: 0.313508; batch adversarial loss: 0.429781\n",
      "epoch 40; iter: 200; batch classifier loss: 0.362470; batch adversarial loss: 0.362862\n",
      "epoch 41; iter: 0; batch classifier loss: 0.362069; batch adversarial loss: 0.444619\n",
      "epoch 41; iter: 200; batch classifier loss: 0.380925; batch adversarial loss: 0.361704\n",
      "epoch 42; iter: 0; batch classifier loss: 0.339722; batch adversarial loss: 0.520634\n",
      "epoch 42; iter: 200; batch classifier loss: 0.410783; batch adversarial loss: 0.474934\n",
      "epoch 43; iter: 0; batch classifier loss: 0.280778; batch adversarial loss: 0.428495\n",
      "epoch 43; iter: 200; batch classifier loss: 0.291299; batch adversarial loss: 0.424228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.355223; batch adversarial loss: 0.492872\n",
      "epoch 44; iter: 200; batch classifier loss: 0.328134; batch adversarial loss: 0.438298\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454913; batch adversarial loss: 0.394811\n",
      "epoch 45; iter: 200; batch classifier loss: 0.390099; batch adversarial loss: 0.344891\n",
      "epoch 46; iter: 0; batch classifier loss: 0.326902; batch adversarial loss: 0.420684\n",
      "epoch 46; iter: 200; batch classifier loss: 0.330737; batch adversarial loss: 0.489924\n",
      "epoch 47; iter: 0; batch classifier loss: 0.322543; batch adversarial loss: 0.412767\n",
      "epoch 47; iter: 200; batch classifier loss: 0.416792; batch adversarial loss: 0.461800\n",
      "epoch 48; iter: 0; batch classifier loss: 0.368716; batch adversarial loss: 0.331702\n",
      "epoch 48; iter: 200; batch classifier loss: 0.449224; batch adversarial loss: 0.375933\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392789; batch adversarial loss: 0.350252\n",
      "epoch 49; iter: 200; batch classifier loss: 0.316983; batch adversarial loss: 0.386256\n",
      "epoch 0; iter: 0; batch classifier loss: 17.025936; batch adversarial loss: 1.404332\n",
      "epoch 0; iter: 200; batch classifier loss: 6.960260; batch adversarial loss: 0.676768\n",
      "epoch 1; iter: 0; batch classifier loss: 8.049053; batch adversarial loss: 0.921350\n",
      "epoch 1; iter: 200; batch classifier loss: 7.854647; batch adversarial loss: 0.779616\n",
      "epoch 2; iter: 0; batch classifier loss: 1.735731; batch adversarial loss: 0.609658\n",
      "epoch 2; iter: 200; batch classifier loss: 3.828384; batch adversarial loss: 0.528636\n",
      "epoch 3; iter: 0; batch classifier loss: 1.560751; batch adversarial loss: 0.478475\n",
      "epoch 3; iter: 200; batch classifier loss: 3.459487; batch adversarial loss: 0.452088\n",
      "epoch 4; iter: 0; batch classifier loss: 0.706557; batch adversarial loss: 0.487978\n",
      "epoch 4; iter: 200; batch classifier loss: 0.783379; batch adversarial loss: 0.424225\n",
      "epoch 5; iter: 0; batch classifier loss: 0.959604; batch adversarial loss: 0.460041\n",
      "epoch 5; iter: 200; batch classifier loss: 0.814706; batch adversarial loss: 0.380977\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561401; batch adversarial loss: 0.497590\n",
      "epoch 6; iter: 200; batch classifier loss: 0.427914; batch adversarial loss: 0.419898\n",
      "epoch 7; iter: 0; batch classifier loss: 0.896957; batch adversarial loss: 0.396872\n",
      "epoch 7; iter: 200; batch classifier loss: 0.938950; batch adversarial loss: 0.406925\n",
      "epoch 8; iter: 0; batch classifier loss: 0.413424; batch adversarial loss: 0.455134\n",
      "epoch 8; iter: 200; batch classifier loss: 0.415787; batch adversarial loss: 0.417401\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516179; batch adversarial loss: 0.451876\n",
      "epoch 9; iter: 200; batch classifier loss: 0.554724; batch adversarial loss: 0.434290\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472935; batch adversarial loss: 0.430113\n",
      "epoch 10; iter: 200; batch classifier loss: 0.365645; batch adversarial loss: 0.380356\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420818; batch adversarial loss: 0.367294\n",
      "epoch 11; iter: 200; batch classifier loss: 0.490835; batch adversarial loss: 0.377029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452051; batch adversarial loss: 0.468850\n",
      "epoch 12; iter: 200; batch classifier loss: 0.466747; batch adversarial loss: 0.377223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420465; batch adversarial loss: 0.424355\n",
      "epoch 13; iter: 200; batch classifier loss: 1.944695; batch adversarial loss: 0.442901\n",
      "epoch 14; iter: 0; batch classifier loss: 0.600238; batch adversarial loss: 0.414131\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351395; batch adversarial loss: 0.399420\n",
      "epoch 15; iter: 0; batch classifier loss: 0.429441; batch adversarial loss: 0.399703\n",
      "epoch 15; iter: 200; batch classifier loss: 0.707342; batch adversarial loss: 0.394301\n",
      "epoch 16; iter: 0; batch classifier loss: 0.375375; batch adversarial loss: 0.381170\n",
      "epoch 16; iter: 200; batch classifier loss: 0.417623; batch adversarial loss: 0.356029\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304952; batch adversarial loss: 0.429568\n",
      "epoch 17; iter: 200; batch classifier loss: 0.295118; batch adversarial loss: 0.320293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396149; batch adversarial loss: 0.414527\n",
      "epoch 18; iter: 200; batch classifier loss: 0.398156; batch adversarial loss: 0.386545\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356583; batch adversarial loss: 0.349277\n",
      "epoch 19; iter: 200; batch classifier loss: 0.296299; batch adversarial loss: 0.404437\n",
      "epoch 20; iter: 0; batch classifier loss: 0.411396; batch adversarial loss: 0.490271\n",
      "epoch 20; iter: 200; batch classifier loss: 0.390516; batch adversarial loss: 0.303675\n",
      "epoch 21; iter: 0; batch classifier loss: 0.331434; batch adversarial loss: 0.451057\n",
      "epoch 21; iter: 200; batch classifier loss: 0.394056; batch adversarial loss: 0.393050\n",
      "epoch 22; iter: 0; batch classifier loss: 0.288095; batch adversarial loss: 0.458094\n",
      "epoch 22; iter: 200; batch classifier loss: 0.381180; batch adversarial loss: 0.506138\n",
      "epoch 23; iter: 0; batch classifier loss: 0.353098; batch adversarial loss: 0.399194\n",
      "epoch 23; iter: 200; batch classifier loss: 0.453738; batch adversarial loss: 0.387903\n",
      "epoch 24; iter: 0; batch classifier loss: 0.376177; batch adversarial loss: 0.483139\n",
      "epoch 24; iter: 200; batch classifier loss: 0.329305; batch adversarial loss: 0.372832\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349529; batch adversarial loss: 0.438127\n",
      "epoch 25; iter: 200; batch classifier loss: 0.321630; batch adversarial loss: 0.371205\n",
      "epoch 26; iter: 0; batch classifier loss: 0.375999; batch adversarial loss: 0.290106\n",
      "epoch 26; iter: 200; batch classifier loss: 0.427221; batch adversarial loss: 0.404638\n",
      "epoch 27; iter: 0; batch classifier loss: 0.334562; batch adversarial loss: 0.434413\n",
      "epoch 27; iter: 200; batch classifier loss: 0.382472; batch adversarial loss: 0.338144\n",
      "epoch 28; iter: 0; batch classifier loss: 0.266492; batch adversarial loss: 0.404264\n",
      "epoch 28; iter: 200; batch classifier loss: 0.366002; batch adversarial loss: 0.371652\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263365; batch adversarial loss: 0.418675\n",
      "epoch 29; iter: 200; batch classifier loss: 0.272387; batch adversarial loss: 0.562703\n",
      "epoch 30; iter: 0; batch classifier loss: 0.301067; batch adversarial loss: 0.416463\n",
      "epoch 30; iter: 200; batch classifier loss: 0.279058; batch adversarial loss: 0.337952\n",
      "epoch 31; iter: 0; batch classifier loss: 0.358298; batch adversarial loss: 0.468136\n",
      "epoch 31; iter: 200; batch classifier loss: 0.360379; batch adversarial loss: 0.418294\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309417; batch adversarial loss: 0.403631\n",
      "epoch 32; iter: 200; batch classifier loss: 0.419665; batch adversarial loss: 0.427625\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272350; batch adversarial loss: 0.495912\n",
      "epoch 33; iter: 200; batch classifier loss: 0.249308; batch adversarial loss: 0.391179\n",
      "epoch 34; iter: 0; batch classifier loss: 0.334654; batch adversarial loss: 0.346749\n",
      "epoch 34; iter: 200; batch classifier loss: 0.517628; batch adversarial loss: 0.407425\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425695; batch adversarial loss: 0.387869\n",
      "epoch 35; iter: 200; batch classifier loss: 0.376625; batch adversarial loss: 0.484015\n",
      "epoch 36; iter: 0; batch classifier loss: 0.329410; batch adversarial loss: 0.407662\n",
      "epoch 36; iter: 200; batch classifier loss: 0.303528; batch adversarial loss: 0.345345\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416478; batch adversarial loss: 0.416994\n",
      "epoch 37; iter: 200; batch classifier loss: 0.381129; batch adversarial loss: 0.397100\n",
      "epoch 38; iter: 0; batch classifier loss: 0.379110; batch adversarial loss: 0.382012\n",
      "epoch 38; iter: 200; batch classifier loss: 0.351929; batch adversarial loss: 0.519838\n",
      "epoch 39; iter: 0; batch classifier loss: 0.335220; batch adversarial loss: 0.460351\n",
      "epoch 39; iter: 200; batch classifier loss: 0.323359; batch adversarial loss: 0.328431\n",
      "epoch 40; iter: 0; batch classifier loss: 0.350866; batch adversarial loss: 0.417116\n",
      "epoch 40; iter: 200; batch classifier loss: 0.355052; batch adversarial loss: 0.435127\n",
      "epoch 41; iter: 0; batch classifier loss: 0.343355; batch adversarial loss: 0.447791\n",
      "epoch 41; iter: 200; batch classifier loss: 0.379959; batch adversarial loss: 0.352412\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432781; batch adversarial loss: 0.460413\n",
      "epoch 42; iter: 200; batch classifier loss: 0.397435; batch adversarial loss: 0.422530\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402478; batch adversarial loss: 0.468307\n",
      "epoch 43; iter: 200; batch classifier loss: 0.409209; batch adversarial loss: 0.403489\n",
      "epoch 44; iter: 0; batch classifier loss: 0.355371; batch adversarial loss: 0.417545\n",
      "epoch 44; iter: 200; batch classifier loss: 0.500422; batch adversarial loss: 0.465100\n",
      "epoch 45; iter: 0; batch classifier loss: 0.350051; batch adversarial loss: 0.361714\n",
      "epoch 45; iter: 200; batch classifier loss: 0.339882; batch adversarial loss: 0.411126\n",
      "epoch 46; iter: 0; batch classifier loss: 0.474906; batch adversarial loss: 0.456395\n",
      "epoch 46; iter: 200; batch classifier loss: 0.402605; batch adversarial loss: 0.488744\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437059; batch adversarial loss: 0.348795\n",
      "epoch 47; iter: 200; batch classifier loss: 0.485035; batch adversarial loss: 0.414454\n",
      "epoch 48; iter: 0; batch classifier loss: 0.307485; batch adversarial loss: 0.443719\n",
      "epoch 48; iter: 200; batch classifier loss: 0.378325; batch adversarial loss: 0.391181\n",
      "epoch 49; iter: 0; batch classifier loss: 0.287841; batch adversarial loss: 0.433325\n",
      "epoch 49; iter: 200; batch classifier loss: 0.224149; batch adversarial loss: 0.445205\n",
      "epoch 0; iter: 0; batch classifier loss: 37.870529; batch adversarial loss: 0.616461\n",
      "epoch 0; iter: 200; batch classifier loss: 11.767739; batch adversarial loss: 0.559102\n",
      "epoch 1; iter: 0; batch classifier loss: 5.729509; batch adversarial loss: 0.585580\n",
      "epoch 1; iter: 200; batch classifier loss: 1.219650; batch adversarial loss: 0.502208\n",
      "epoch 2; iter: 0; batch classifier loss: 2.263586; batch adversarial loss: 0.515955\n",
      "epoch 2; iter: 200; batch classifier loss: 1.902006; batch adversarial loss: 0.498042\n",
      "epoch 3; iter: 0; batch classifier loss: 2.841896; batch adversarial loss: 0.427907\n",
      "epoch 3; iter: 200; batch classifier loss: 2.429440; batch adversarial loss: 0.506092\n",
      "epoch 4; iter: 0; batch classifier loss: 0.783008; batch adversarial loss: 0.391004\n",
      "epoch 4; iter: 200; batch classifier loss: 0.742175; batch adversarial loss: 0.441490\n",
      "epoch 5; iter: 0; batch classifier loss: 0.875463; batch adversarial loss: 0.497033\n",
      "epoch 5; iter: 200; batch classifier loss: 0.771650; batch adversarial loss: 0.389862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484152; batch adversarial loss: 0.460381\n",
      "epoch 6; iter: 200; batch classifier loss: 0.440329; batch adversarial loss: 0.364031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.921584; batch adversarial loss: 0.496109\n",
      "epoch 7; iter: 200; batch classifier loss: 0.660802; batch adversarial loss: 0.376195\n",
      "epoch 8; iter: 0; batch classifier loss: 0.382425; batch adversarial loss: 0.429462\n",
      "epoch 8; iter: 200; batch classifier loss: 0.351464; batch adversarial loss: 0.448293\n",
      "epoch 9; iter: 0; batch classifier loss: 0.379443; batch adversarial loss: 0.426570\n",
      "epoch 9; iter: 200; batch classifier loss: 0.368823; batch adversarial loss: 0.480811\n",
      "epoch 10; iter: 0; batch classifier loss: 0.428316; batch adversarial loss: 0.360875\n",
      "epoch 10; iter: 200; batch classifier loss: 0.396767; batch adversarial loss: 0.273864\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371907; batch adversarial loss: 0.361951\n",
      "epoch 11; iter: 200; batch classifier loss: 0.344798; batch adversarial loss: 0.364481\n",
      "epoch 12; iter: 0; batch classifier loss: 0.984882; batch adversarial loss: 0.465911\n",
      "epoch 12; iter: 200; batch classifier loss: 0.393048; batch adversarial loss: 0.411951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356356; batch adversarial loss: 0.431988\n",
      "epoch 13; iter: 200; batch classifier loss: 0.454652; batch adversarial loss: 0.409149\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301372; batch adversarial loss: 0.436258\n",
      "epoch 14; iter: 200; batch classifier loss: 0.399528; batch adversarial loss: 0.353572\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516425; batch adversarial loss: 0.512346\n",
      "epoch 15; iter: 200; batch classifier loss: 0.331580; batch adversarial loss: 0.409935\n",
      "epoch 16; iter: 0; batch classifier loss: 0.398473; batch adversarial loss: 0.470883\n",
      "epoch 16; iter: 200; batch classifier loss: 0.317244; batch adversarial loss: 0.335478\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426544; batch adversarial loss: 0.374403\n",
      "epoch 17; iter: 200; batch classifier loss: 0.361412; batch adversarial loss: 0.358446\n",
      "epoch 18; iter: 0; batch classifier loss: 0.365897; batch adversarial loss: 0.361638\n",
      "epoch 18; iter: 200; batch classifier loss: 0.286780; batch adversarial loss: 0.401273\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487842; batch adversarial loss: 0.346365\n",
      "epoch 19; iter: 200; batch classifier loss: 0.362810; batch adversarial loss: 0.390532\n",
      "epoch 20; iter: 0; batch classifier loss: 0.353769; batch adversarial loss: 0.440398\n",
      "epoch 20; iter: 200; batch classifier loss: 0.309041; batch adversarial loss: 0.325637\n",
      "epoch 21; iter: 0; batch classifier loss: 0.367915; batch adversarial loss: 0.494214\n",
      "epoch 21; iter: 200; batch classifier loss: 0.335541; batch adversarial loss: 0.391875\n",
      "epoch 22; iter: 0; batch classifier loss: 0.377215; batch adversarial loss: 0.404788\n",
      "epoch 22; iter: 200; batch classifier loss: 0.362038; batch adversarial loss: 0.387180\n",
      "epoch 23; iter: 0; batch classifier loss: 0.338425; batch adversarial loss: 0.323470\n",
      "epoch 23; iter: 200; batch classifier loss: 0.284176; batch adversarial loss: 0.452426\n",
      "epoch 24; iter: 0; batch classifier loss: 0.381757; batch adversarial loss: 0.375925\n",
      "epoch 24; iter: 200; batch classifier loss: 0.317021; batch adversarial loss: 0.392068\n",
      "epoch 25; iter: 0; batch classifier loss: 0.334005; batch adversarial loss: 0.418567\n",
      "epoch 25; iter: 200; batch classifier loss: 0.309362; batch adversarial loss: 0.386705\n",
      "epoch 26; iter: 0; batch classifier loss: 0.384367; batch adversarial loss: 0.463258\n",
      "epoch 26; iter: 200; batch classifier loss: 0.346089; batch adversarial loss: 0.447442\n",
      "epoch 27; iter: 0; batch classifier loss: 0.332196; batch adversarial loss: 0.244109\n",
      "epoch 27; iter: 200; batch classifier loss: 0.392702; batch adversarial loss: 0.426859\n",
      "epoch 28; iter: 0; batch classifier loss: 0.333865; batch adversarial loss: 0.383742\n",
      "epoch 28; iter: 200; batch classifier loss: 0.329812; batch adversarial loss: 0.440324\n",
      "epoch 29; iter: 0; batch classifier loss: 0.346699; batch adversarial loss: 0.337466\n",
      "epoch 29; iter: 200; batch classifier loss: 0.332424; batch adversarial loss: 0.322507\n",
      "epoch 30; iter: 0; batch classifier loss: 0.341964; batch adversarial loss: 0.414488\n",
      "epoch 30; iter: 200; batch classifier loss: 0.260494; batch adversarial loss: 0.382134\n",
      "epoch 31; iter: 0; batch classifier loss: 0.350802; batch adversarial loss: 0.422460\n",
      "epoch 31; iter: 200; batch classifier loss: 0.331434; batch adversarial loss: 0.417035\n",
      "epoch 32; iter: 0; batch classifier loss: 0.345699; batch adversarial loss: 0.493587\n",
      "epoch 32; iter: 200; batch classifier loss: 0.394769; batch adversarial loss: 0.391235\n",
      "epoch 33; iter: 0; batch classifier loss: 0.328800; batch adversarial loss: 0.415291\n",
      "epoch 33; iter: 200; batch classifier loss: 0.312567; batch adversarial loss: 0.418828\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380457; batch adversarial loss: 0.396641\n",
      "epoch 34; iter: 200; batch classifier loss: 0.407472; batch adversarial loss: 0.356151\n",
      "epoch 35; iter: 0; batch classifier loss: 0.347644; batch adversarial loss: 0.440442\n",
      "epoch 35; iter: 200; batch classifier loss: 0.315856; batch adversarial loss: 0.402340\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443606; batch adversarial loss: 0.423334\n",
      "epoch 36; iter: 200; batch classifier loss: 0.292336; batch adversarial loss: 0.417046\n",
      "epoch 37; iter: 0; batch classifier loss: 0.348650; batch adversarial loss: 0.326443\n",
      "epoch 37; iter: 200; batch classifier loss: 0.404346; batch adversarial loss: 0.452877\n",
      "epoch 38; iter: 0; batch classifier loss: 0.374440; batch adversarial loss: 0.470640\n",
      "epoch 38; iter: 200; batch classifier loss: 0.374575; batch adversarial loss: 0.375485\n",
      "epoch 39; iter: 0; batch classifier loss: 0.378066; batch adversarial loss: 0.468142\n",
      "epoch 39; iter: 200; batch classifier loss: 0.268679; batch adversarial loss: 0.436291\n",
      "epoch 40; iter: 0; batch classifier loss: 0.370862; batch adversarial loss: 0.398812\n",
      "epoch 40; iter: 200; batch classifier loss: 0.369989; batch adversarial loss: 0.475088\n",
      "epoch 41; iter: 0; batch classifier loss: 0.386048; batch adversarial loss: 0.509947\n",
      "epoch 41; iter: 200; batch classifier loss: 0.310189; batch adversarial loss: 0.327862\n",
      "epoch 42; iter: 0; batch classifier loss: 0.251244; batch adversarial loss: 0.543813\n",
      "epoch 42; iter: 200; batch classifier loss: 0.480607; batch adversarial loss: 0.357914\n",
      "epoch 43; iter: 0; batch classifier loss: 0.280862; batch adversarial loss: 0.472480\n",
      "epoch 43; iter: 200; batch classifier loss: 0.386939; batch adversarial loss: 0.389046\n",
      "epoch 44; iter: 0; batch classifier loss: 0.349078; batch adversarial loss: 0.369758\n",
      "epoch 44; iter: 200; batch classifier loss: 0.383885; batch adversarial loss: 0.472479\n",
      "epoch 45; iter: 0; batch classifier loss: 0.234912; batch adversarial loss: 0.359315\n",
      "epoch 45; iter: 200; batch classifier loss: 0.319300; batch adversarial loss: 0.374350\n",
      "epoch 46; iter: 0; batch classifier loss: 0.355927; batch adversarial loss: 0.365076\n",
      "epoch 46; iter: 200; batch classifier loss: 0.473211; batch adversarial loss: 0.446516\n",
      "epoch 47; iter: 0; batch classifier loss: 0.374285; batch adversarial loss: 0.353372\n",
      "epoch 47; iter: 200; batch classifier loss: 0.345341; batch adversarial loss: 0.330114\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391028; batch adversarial loss: 0.402207\n",
      "epoch 48; iter: 200; batch classifier loss: 0.427110; batch adversarial loss: 0.453246\n",
      "epoch 49; iter: 0; batch classifier loss: 0.312636; batch adversarial loss: 0.384312\n",
      "epoch 49; iter: 200; batch classifier loss: 0.286983; batch adversarial loss: 0.455825\n",
      "epoch 0; iter: 0; batch classifier loss: 16.568281; batch adversarial loss: 0.404243\n",
      "epoch 0; iter: 200; batch classifier loss: 3.718182; batch adversarial loss: 0.603382\n",
      "epoch 1; iter: 0; batch classifier loss: 12.909781; batch adversarial loss: 0.434091\n",
      "epoch 1; iter: 200; batch classifier loss: 4.346368; batch adversarial loss: 0.556254\n",
      "epoch 2; iter: 0; batch classifier loss: 4.385667; batch adversarial loss: 0.503919\n",
      "epoch 2; iter: 200; batch classifier loss: 8.722281; batch adversarial loss: 0.504678\n",
      "epoch 3; iter: 0; batch classifier loss: 3.611466; batch adversarial loss: 0.521803\n",
      "epoch 3; iter: 200; batch classifier loss: 1.716874; batch adversarial loss: 0.477337\n",
      "epoch 4; iter: 0; batch classifier loss: 1.800344; batch adversarial loss: 0.402965\n",
      "epoch 4; iter: 200; batch classifier loss: 2.214835; batch adversarial loss: 0.516090\n",
      "epoch 5; iter: 0; batch classifier loss: 4.646543; batch adversarial loss: 0.454978\n",
      "epoch 5; iter: 200; batch classifier loss: 0.533370; batch adversarial loss: 0.467468\n",
      "epoch 6; iter: 0; batch classifier loss: 0.729530; batch adversarial loss: 0.462392\n",
      "epoch 6; iter: 200; batch classifier loss: 0.942528; batch adversarial loss: 0.429540\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393114; batch adversarial loss: 0.341201\n",
      "epoch 7; iter: 200; batch classifier loss: 0.414785; batch adversarial loss: 0.458176\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541979; batch adversarial loss: 0.494985\n",
      "epoch 8; iter: 200; batch classifier loss: 0.492735; batch adversarial loss: 0.455329\n",
      "epoch 9; iter: 0; batch classifier loss: 1.315049; batch adversarial loss: 0.422092\n",
      "epoch 9; iter: 200; batch classifier loss: 0.350431; batch adversarial loss: 0.319249\n",
      "epoch 10; iter: 0; batch classifier loss: 0.417904; batch adversarial loss: 0.370287\n",
      "epoch 10; iter: 200; batch classifier loss: 0.384917; batch adversarial loss: 0.353786\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346479; batch adversarial loss: 0.443692\n",
      "epoch 11; iter: 200; batch classifier loss: 0.301208; batch adversarial loss: 0.377986\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427138; batch adversarial loss: 0.418301\n",
      "epoch 12; iter: 200; batch classifier loss: 0.366150; batch adversarial loss: 0.389155\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407891; batch adversarial loss: 0.392639\n",
      "epoch 13; iter: 200; batch classifier loss: 0.374414; batch adversarial loss: 0.494439\n",
      "epoch 14; iter: 0; batch classifier loss: 0.550942; batch adversarial loss: 0.419576\n",
      "epoch 14; iter: 200; batch classifier loss: 0.337036; batch adversarial loss: 0.366779\n",
      "epoch 15; iter: 0; batch classifier loss: 0.251861; batch adversarial loss: 0.420700\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430059; batch adversarial loss: 0.406950\n",
      "epoch 16; iter: 0; batch classifier loss: 0.369883; batch adversarial loss: 0.339579\n",
      "epoch 16; iter: 200; batch classifier loss: 0.463779; batch adversarial loss: 0.473940\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375652; batch adversarial loss: 0.401567\n",
      "epoch 17; iter: 200; batch classifier loss: 0.350248; batch adversarial loss: 0.488837\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455433; batch adversarial loss: 0.397419\n",
      "epoch 18; iter: 200; batch classifier loss: 0.214352; batch adversarial loss: 0.476499\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309233; batch adversarial loss: 0.426860\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376133; batch adversarial loss: 0.370749\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259780; batch adversarial loss: 0.399289\n",
      "epoch 20; iter: 200; batch classifier loss: 0.546193; batch adversarial loss: 0.410273\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298122; batch adversarial loss: 0.408780\n",
      "epoch 21; iter: 200; batch classifier loss: 0.312828; batch adversarial loss: 0.419157\n",
      "epoch 22; iter: 0; batch classifier loss: 0.357589; batch adversarial loss: 0.380170\n",
      "epoch 22; iter: 200; batch classifier loss: 0.407303; batch adversarial loss: 0.482588\n",
      "epoch 23; iter: 0; batch classifier loss: 0.314589; batch adversarial loss: 0.406937\n",
      "epoch 23; iter: 200; batch classifier loss: 0.375897; batch adversarial loss: 0.438020\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303372; batch adversarial loss: 0.420169\n",
      "epoch 24; iter: 200; batch classifier loss: 0.378520; batch adversarial loss: 0.396241\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339597; batch adversarial loss: 0.409019\n",
      "epoch 25; iter: 200; batch classifier loss: 0.334851; batch adversarial loss: 0.384847\n",
      "epoch 26; iter: 0; batch classifier loss: 0.246434; batch adversarial loss: 0.365966\n",
      "epoch 26; iter: 200; batch classifier loss: 0.396141; batch adversarial loss: 0.458727\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445570; batch adversarial loss: 0.398817\n",
      "epoch 27; iter: 200; batch classifier loss: 0.365717; batch adversarial loss: 0.437995\n",
      "epoch 28; iter: 0; batch classifier loss: 0.353469; batch adversarial loss: 0.417985\n",
      "epoch 28; iter: 200; batch classifier loss: 0.275323; batch adversarial loss: 0.341068\n",
      "epoch 29; iter: 0; batch classifier loss: 0.362127; batch adversarial loss: 0.431577\n",
      "epoch 29; iter: 200; batch classifier loss: 0.250068; batch adversarial loss: 0.381927\n",
      "epoch 30; iter: 0; batch classifier loss: 0.237937; batch adversarial loss: 0.435209\n",
      "epoch 30; iter: 200; batch classifier loss: 0.376802; batch adversarial loss: 0.427477\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410589; batch adversarial loss: 0.437068\n",
      "epoch 31; iter: 200; batch classifier loss: 0.278892; batch adversarial loss: 0.334445\n",
      "epoch 32; iter: 0; batch classifier loss: 0.346917; batch adversarial loss: 0.445755\n",
      "epoch 32; iter: 200; batch classifier loss: 0.334925; batch adversarial loss: 0.475896\n",
      "epoch 33; iter: 0; batch classifier loss: 0.365902; batch adversarial loss: 0.344450\n",
      "epoch 33; iter: 200; batch classifier loss: 0.358719; batch adversarial loss: 0.346722\n",
      "epoch 34; iter: 0; batch classifier loss: 0.327103; batch adversarial loss: 0.402288\n",
      "epoch 34; iter: 200; batch classifier loss: 0.248382; batch adversarial loss: 0.366489\n",
      "epoch 35; iter: 0; batch classifier loss: 0.288626; batch adversarial loss: 0.379494\n",
      "epoch 35; iter: 200; batch classifier loss: 0.273930; batch adversarial loss: 0.430043\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347183; batch adversarial loss: 0.490011\n",
      "epoch 36; iter: 200; batch classifier loss: 0.405985; batch adversarial loss: 0.396448\n",
      "epoch 37; iter: 0; batch classifier loss: 0.376958; batch adversarial loss: 0.423545\n",
      "epoch 37; iter: 200; batch classifier loss: 0.320403; batch adversarial loss: 0.366779\n",
      "epoch 38; iter: 0; batch classifier loss: 0.394068; batch adversarial loss: 0.365771\n",
      "epoch 38; iter: 200; batch classifier loss: 0.270799; batch adversarial loss: 0.481554\n",
      "epoch 39; iter: 0; batch classifier loss: 0.302195; batch adversarial loss: 0.377075\n",
      "epoch 39; iter: 200; batch classifier loss: 0.291681; batch adversarial loss: 0.475302\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423430; batch adversarial loss: 0.421033\n",
      "epoch 40; iter: 200; batch classifier loss: 0.329701; batch adversarial loss: 0.442500\n",
      "epoch 41; iter: 0; batch classifier loss: 0.283700; batch adversarial loss: 0.452660\n",
      "epoch 41; iter: 200; batch classifier loss: 0.386570; batch adversarial loss: 0.362385\n",
      "epoch 42; iter: 0; batch classifier loss: 0.349054; batch adversarial loss: 0.407075\n",
      "epoch 42; iter: 200; batch classifier loss: 0.296581; batch adversarial loss: 0.466141\n",
      "epoch 43; iter: 0; batch classifier loss: 0.387195; batch adversarial loss: 0.402965\n",
      "epoch 43; iter: 200; batch classifier loss: 0.279906; batch adversarial loss: 0.464588\n",
      "epoch 44; iter: 0; batch classifier loss: 0.310026; batch adversarial loss: 0.472786\n",
      "epoch 44; iter: 200; batch classifier loss: 0.386966; batch adversarial loss: 0.372715\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364017; batch adversarial loss: 0.449532\n",
      "epoch 45; iter: 200; batch classifier loss: 0.432629; batch adversarial loss: 0.440135\n",
      "epoch 46; iter: 0; batch classifier loss: 0.325238; batch adversarial loss: 0.392729\n",
      "epoch 46; iter: 200; batch classifier loss: 0.336516; batch adversarial loss: 0.376319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405822; batch adversarial loss: 0.457372\n",
      "epoch 47; iter: 200; batch classifier loss: 0.319673; batch adversarial loss: 0.573319\n",
      "epoch 48; iter: 0; batch classifier loss: 0.317715; batch adversarial loss: 0.414511\n",
      "epoch 48; iter: 200; batch classifier loss: 0.294874; batch adversarial loss: 0.450949\n",
      "epoch 49; iter: 0; batch classifier loss: 0.320103; batch adversarial loss: 0.499526\n",
      "epoch 49; iter: 200; batch classifier loss: 0.441169; batch adversarial loss: 0.401954\n",
      "epoch 0; iter: 0; batch classifier loss: 157.550507; batch adversarial loss: 0.793078\n",
      "epoch 0; iter: 200; batch classifier loss: 11.223516; batch adversarial loss: 0.640758\n",
      "epoch 1; iter: 0; batch classifier loss: 6.778726; batch adversarial loss: 0.627789\n",
      "epoch 1; iter: 200; batch classifier loss: 2.567173; batch adversarial loss: 0.556970\n",
      "epoch 2; iter: 0; batch classifier loss: 1.418531; batch adversarial loss: 0.530455\n",
      "epoch 2; iter: 200; batch classifier loss: 2.756893; batch adversarial loss: 0.514475\n",
      "epoch 3; iter: 0; batch classifier loss: 2.416579; batch adversarial loss: 0.437179\n",
      "epoch 3; iter: 200; batch classifier loss: 1.186266; batch adversarial loss: 0.409763\n",
      "epoch 4; iter: 0; batch classifier loss: 7.393788; batch adversarial loss: 0.445289\n",
      "epoch 4; iter: 200; batch classifier loss: 2.343739; batch adversarial loss: 0.338737\n",
      "epoch 5; iter: 0; batch classifier loss: 1.262253; batch adversarial loss: 0.361480\n",
      "epoch 5; iter: 200; batch classifier loss: 1.069588; batch adversarial loss: 0.429807\n",
      "epoch 6; iter: 0; batch classifier loss: 1.683663; batch adversarial loss: 0.440106\n",
      "epoch 6; iter: 200; batch classifier loss: 0.368554; batch adversarial loss: 0.466974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510089; batch adversarial loss: 0.391391\n",
      "epoch 7; iter: 200; batch classifier loss: 0.790861; batch adversarial loss: 0.413490\n",
      "epoch 8; iter: 0; batch classifier loss: 0.631010; batch adversarial loss: 0.430545\n",
      "epoch 8; iter: 200; batch classifier loss: 0.396349; batch adversarial loss: 0.467536\n",
      "epoch 9; iter: 0; batch classifier loss: 0.431056; batch adversarial loss: 0.402851\n",
      "epoch 9; iter: 200; batch classifier loss: 0.376889; batch adversarial loss: 0.384333\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430249; batch adversarial loss: 0.411596\n",
      "epoch 10; iter: 200; batch classifier loss: 0.415847; batch adversarial loss: 0.405247\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371578; batch adversarial loss: 0.429567\n",
      "epoch 11; iter: 200; batch classifier loss: 0.326192; batch adversarial loss: 0.419770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.358223; batch adversarial loss: 0.436879\n",
      "epoch 12; iter: 200; batch classifier loss: 0.492508; batch adversarial loss: 0.469060\n",
      "epoch 13; iter: 0; batch classifier loss: 0.433639; batch adversarial loss: 0.362418\n",
      "epoch 13; iter: 200; batch classifier loss: 0.482746; batch adversarial loss: 0.362846\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538040; batch adversarial loss: 0.426854\n",
      "epoch 14; iter: 200; batch classifier loss: 0.353150; batch adversarial loss: 0.425178\n",
      "epoch 15; iter: 0; batch classifier loss: 0.417824; batch adversarial loss: 0.398107\n",
      "epoch 15; iter: 200; batch classifier loss: 0.406754; batch adversarial loss: 0.428086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350104; batch adversarial loss: 0.370332\n",
      "epoch 16; iter: 200; batch classifier loss: 0.277239; batch adversarial loss: 0.400951\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314663; batch adversarial loss: 0.400160\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345515; batch adversarial loss: 0.425685\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331112; batch adversarial loss: 0.406846\n",
      "epoch 18; iter: 200; batch classifier loss: 0.388329; batch adversarial loss: 0.441526\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362472; batch adversarial loss: 0.453173\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376868; batch adversarial loss: 0.433554\n",
      "epoch 20; iter: 0; batch classifier loss: 0.383237; batch adversarial loss: 0.392650\n",
      "epoch 20; iter: 200; batch classifier loss: 0.319812; batch adversarial loss: 0.420121\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372265; batch adversarial loss: 0.353363\n",
      "epoch 21; iter: 200; batch classifier loss: 0.329441; batch adversarial loss: 0.477498\n",
      "epoch 22; iter: 0; batch classifier loss: 0.353397; batch adversarial loss: 0.388547\n",
      "epoch 22; iter: 200; batch classifier loss: 0.326203; batch adversarial loss: 0.427219\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310912; batch adversarial loss: 0.444424\n",
      "epoch 23; iter: 200; batch classifier loss: 0.352352; batch adversarial loss: 0.418341\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266737; batch adversarial loss: 0.387235\n",
      "epoch 24; iter: 200; batch classifier loss: 0.299182; batch adversarial loss: 0.408093\n",
      "epoch 25; iter: 0; batch classifier loss: 0.343023; batch adversarial loss: 0.418717\n",
      "epoch 25; iter: 200; batch classifier loss: 0.366174; batch adversarial loss: 0.313944\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366220; batch adversarial loss: 0.479227\n",
      "epoch 26; iter: 200; batch classifier loss: 0.342829; batch adversarial loss: 0.428778\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330821; batch adversarial loss: 0.330187\n",
      "epoch 27; iter: 200; batch classifier loss: 0.399774; batch adversarial loss: 0.314351\n",
      "epoch 28; iter: 0; batch classifier loss: 0.310809; batch adversarial loss: 0.356412\n",
      "epoch 28; iter: 200; batch classifier loss: 0.359296; batch adversarial loss: 0.345465\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295078; batch adversarial loss: 0.469628\n",
      "epoch 29; iter: 200; batch classifier loss: 0.350389; batch adversarial loss: 0.510572\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323429; batch adversarial loss: 0.461287\n",
      "epoch 30; iter: 200; batch classifier loss: 0.289519; batch adversarial loss: 0.388377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.294554; batch adversarial loss: 0.514431\n",
      "epoch 31; iter: 200; batch classifier loss: 0.352223; batch adversarial loss: 0.333962\n",
      "epoch 32; iter: 0; batch classifier loss: 0.368311; batch adversarial loss: 0.447064\n",
      "epoch 32; iter: 200; batch classifier loss: 0.350120; batch adversarial loss: 0.320335\n",
      "epoch 33; iter: 0; batch classifier loss: 0.368584; batch adversarial loss: 0.394354\n",
      "epoch 33; iter: 200; batch classifier loss: 0.329341; batch adversarial loss: 0.355600\n",
      "epoch 34; iter: 0; batch classifier loss: 0.317269; batch adversarial loss: 0.476491\n",
      "epoch 34; iter: 200; batch classifier loss: 0.336102; batch adversarial loss: 0.363006\n",
      "epoch 35; iter: 0; batch classifier loss: 0.315656; batch adversarial loss: 0.488172\n",
      "epoch 35; iter: 200; batch classifier loss: 0.328537; batch adversarial loss: 0.471879\n",
      "epoch 36; iter: 0; batch classifier loss: 0.399231; batch adversarial loss: 0.438076\n",
      "epoch 36; iter: 200; batch classifier loss: 0.335841; batch adversarial loss: 0.415301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.359498; batch adversarial loss: 0.362087\n",
      "epoch 37; iter: 200; batch classifier loss: 0.310541; batch adversarial loss: 0.472988\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428622; batch adversarial loss: 0.448047\n",
      "epoch 38; iter: 200; batch classifier loss: 0.277132; batch adversarial loss: 0.452911\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408314; batch adversarial loss: 0.345834\n",
      "epoch 39; iter: 200; batch classifier loss: 0.343954; batch adversarial loss: 0.442895\n",
      "epoch 40; iter: 0; batch classifier loss: 0.345235; batch adversarial loss: 0.503724\n",
      "epoch 40; iter: 200; batch classifier loss: 0.266687; batch adversarial loss: 0.395707\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325676; batch adversarial loss: 0.387661\n",
      "epoch 41; iter: 200; batch classifier loss: 0.435269; batch adversarial loss: 0.558420\n",
      "epoch 42; iter: 0; batch classifier loss: 0.346180; batch adversarial loss: 0.360102\n",
      "epoch 42; iter: 200; batch classifier loss: 0.367410; batch adversarial loss: 0.500018\n",
      "epoch 43; iter: 0; batch classifier loss: 0.308201; batch adversarial loss: 0.460468\n",
      "epoch 43; iter: 200; batch classifier loss: 0.305028; batch adversarial loss: 0.415038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.643859; batch adversarial loss: 0.420033\n",
      "epoch 44; iter: 200; batch classifier loss: 0.434498; batch adversarial loss: 0.419606\n",
      "epoch 45; iter: 0; batch classifier loss: 0.370411; batch adversarial loss: 0.431782\n",
      "epoch 45; iter: 200; batch classifier loss: 0.383428; batch adversarial loss: 0.348647\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431051; batch adversarial loss: 0.391588\n",
      "epoch 46; iter: 200; batch classifier loss: 0.335258; batch adversarial loss: 0.419972\n",
      "epoch 47; iter: 0; batch classifier loss: 0.377608; batch adversarial loss: 0.438324\n",
      "epoch 47; iter: 200; batch classifier loss: 0.391641; batch adversarial loss: 0.352004\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385746; batch adversarial loss: 0.496623\n",
      "epoch 48; iter: 200; batch classifier loss: 0.289249; batch adversarial loss: 0.528312\n",
      "epoch 49; iter: 0; batch classifier loss: 0.354657; batch adversarial loss: 0.402001\n",
      "epoch 49; iter: 200; batch classifier loss: 0.358056; batch adversarial loss: 0.543016\n",
      "epoch 0; iter: 0; batch classifier loss: 266.227997; batch adversarial loss: 0.688363\n",
      "epoch 0; iter: 200; batch classifier loss: 5.604262; batch adversarial loss: 0.599527\n",
      "epoch 1; iter: 0; batch classifier loss: 9.633862; batch adversarial loss: 0.560313\n",
      "epoch 1; iter: 200; batch classifier loss: 6.054588; batch adversarial loss: 0.412732\n",
      "epoch 2; iter: 0; batch classifier loss: 1.422014; batch adversarial loss: 0.474145\n",
      "epoch 2; iter: 200; batch classifier loss: 1.932149; batch adversarial loss: 0.366737\n",
      "epoch 3; iter: 0; batch classifier loss: 1.355839; batch adversarial loss: 0.487784\n",
      "epoch 3; iter: 200; batch classifier loss: 0.839854; batch adversarial loss: 0.401573\n",
      "epoch 4; iter: 0; batch classifier loss: 1.152215; batch adversarial loss: 0.478163\n",
      "epoch 4; iter: 200; batch classifier loss: 0.875729; batch adversarial loss: 0.424063\n",
      "epoch 5; iter: 0; batch classifier loss: 2.678273; batch adversarial loss: 0.414172\n",
      "epoch 5; iter: 200; batch classifier loss: 0.420153; batch adversarial loss: 0.438474\n",
      "epoch 6; iter: 0; batch classifier loss: 2.529892; batch adversarial loss: 0.364233\n",
      "epoch 6; iter: 200; batch classifier loss: 0.497059; batch adversarial loss: 0.466794\n",
      "epoch 7; iter: 0; batch classifier loss: 0.656612; batch adversarial loss: 0.416703\n",
      "epoch 7; iter: 200; batch classifier loss: 0.976929; batch adversarial loss: 0.409091\n",
      "epoch 8; iter: 0; batch classifier loss: 0.701872; batch adversarial loss: 0.371169\n",
      "epoch 8; iter: 200; batch classifier loss: 0.840977; batch adversarial loss: 0.377279\n",
      "epoch 9; iter: 0; batch classifier loss: 5.186538; batch adversarial loss: 0.457087\n",
      "epoch 9; iter: 200; batch classifier loss: 0.346023; batch adversarial loss: 0.437174\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519212; batch adversarial loss: 0.379467\n",
      "epoch 10; iter: 200; batch classifier loss: 0.471045; batch adversarial loss: 0.348352\n",
      "epoch 11; iter: 0; batch classifier loss: 0.240324; batch adversarial loss: 0.446216\n",
      "epoch 11; iter: 200; batch classifier loss: 0.468757; batch adversarial loss: 0.401377\n",
      "epoch 12; iter: 0; batch classifier loss: 0.394835; batch adversarial loss: 0.404550\n",
      "epoch 12; iter: 200; batch classifier loss: 0.434796; batch adversarial loss: 0.491631\n",
      "epoch 13; iter: 0; batch classifier loss: 0.849882; batch adversarial loss: 0.446459\n",
      "epoch 13; iter: 200; batch classifier loss: 0.368210; batch adversarial loss: 0.391694\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430046; batch adversarial loss: 0.516965\n",
      "epoch 14; iter: 200; batch classifier loss: 0.372054; batch adversarial loss: 0.527821\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474212; batch adversarial loss: 0.421824\n",
      "epoch 15; iter: 200; batch classifier loss: 0.355039; batch adversarial loss: 0.433284\n",
      "epoch 16; iter: 0; batch classifier loss: 0.359866; batch adversarial loss: 0.321153\n",
      "epoch 16; iter: 200; batch classifier loss: 0.265177; batch adversarial loss: 0.413875\n",
      "epoch 17; iter: 0; batch classifier loss: 0.341385; batch adversarial loss: 0.436729\n",
      "epoch 17; iter: 200; batch classifier loss: 0.433579; batch adversarial loss: 0.409661\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354414; batch adversarial loss: 0.394297\n",
      "epoch 18; iter: 200; batch classifier loss: 0.315770; batch adversarial loss: 0.443709\n",
      "epoch 19; iter: 0; batch classifier loss: 0.372416; batch adversarial loss: 0.317395\n",
      "epoch 19; iter: 200; batch classifier loss: 0.394495; batch adversarial loss: 0.355245\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324170; batch adversarial loss: 0.376207\n",
      "epoch 20; iter: 200; batch classifier loss: 0.244744; batch adversarial loss: 0.344122\n",
      "epoch 21; iter: 0; batch classifier loss: 0.318715; batch adversarial loss: 0.426512\n",
      "epoch 21; iter: 200; batch classifier loss: 0.396648; batch adversarial loss: 0.335817\n",
      "epoch 22; iter: 0; batch classifier loss: 0.358346; batch adversarial loss: 0.495988\n",
      "epoch 22; iter: 200; batch classifier loss: 0.428100; batch adversarial loss: 0.425638\n",
      "epoch 23; iter: 0; batch classifier loss: 0.273655; batch adversarial loss: 0.391338\n",
      "epoch 23; iter: 200; batch classifier loss: 0.299741; batch adversarial loss: 0.497605\n",
      "epoch 24; iter: 0; batch classifier loss: 0.297969; batch adversarial loss: 0.292282\n",
      "epoch 24; iter: 200; batch classifier loss: 0.276615; batch adversarial loss: 0.407502\n",
      "epoch 25; iter: 0; batch classifier loss: 0.350095; batch adversarial loss: 0.434788\n",
      "epoch 25; iter: 200; batch classifier loss: 0.391765; batch adversarial loss: 0.446305\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329934; batch adversarial loss: 0.464455\n",
      "epoch 26; iter: 200; batch classifier loss: 0.300847; batch adversarial loss: 0.371491\n",
      "epoch 27; iter: 0; batch classifier loss: 0.387426; batch adversarial loss: 0.385224\n",
      "epoch 27; iter: 200; batch classifier loss: 0.338474; batch adversarial loss: 0.418451\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274799; batch adversarial loss: 0.403937\n",
      "epoch 28; iter: 200; batch classifier loss: 0.386088; batch adversarial loss: 0.340079\n",
      "epoch 29; iter: 0; batch classifier loss: 0.343985; batch adversarial loss: 0.456601\n",
      "epoch 29; iter: 200; batch classifier loss: 0.335144; batch adversarial loss: 0.277953\n",
      "epoch 30; iter: 0; batch classifier loss: 0.284432; batch adversarial loss: 0.343669\n",
      "epoch 30; iter: 200; batch classifier loss: 0.328262; batch adversarial loss: 0.425648\n",
      "epoch 31; iter: 0; batch classifier loss: 0.370294; batch adversarial loss: 0.366691\n",
      "epoch 31; iter: 200; batch classifier loss: 0.356696; batch adversarial loss: 0.341872\n",
      "epoch 32; iter: 0; batch classifier loss: 0.408597; batch adversarial loss: 0.451537\n",
      "epoch 32; iter: 200; batch classifier loss: 0.469878; batch adversarial loss: 0.460293\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318729; batch adversarial loss: 0.450848\n",
      "epoch 33; iter: 200; batch classifier loss: 0.305277; batch adversarial loss: 0.364563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.335658; batch adversarial loss: 0.346829\n",
      "epoch 34; iter: 200; batch classifier loss: 0.270036; batch adversarial loss: 0.431886\n",
      "epoch 35; iter: 0; batch classifier loss: 0.294983; batch adversarial loss: 0.498241\n",
      "epoch 35; iter: 200; batch classifier loss: 0.290435; batch adversarial loss: 0.359797\n",
      "epoch 36; iter: 0; batch classifier loss: 0.394515; batch adversarial loss: 0.483411\n",
      "epoch 36; iter: 200; batch classifier loss: 0.360304; batch adversarial loss: 0.358214\n",
      "epoch 37; iter: 0; batch classifier loss: 0.321553; batch adversarial loss: 0.368511\n",
      "epoch 37; iter: 200; batch classifier loss: 0.367958; batch adversarial loss: 0.416743\n",
      "epoch 38; iter: 0; batch classifier loss: 0.265009; batch adversarial loss: 0.378576\n",
      "epoch 38; iter: 200; batch classifier loss: 0.381445; batch adversarial loss: 0.389113\n",
      "epoch 39; iter: 0; batch classifier loss: 0.345904; batch adversarial loss: 0.384842\n",
      "epoch 39; iter: 200; batch classifier loss: 0.403354; batch adversarial loss: 0.511229\n",
      "epoch 40; iter: 0; batch classifier loss: 0.328061; batch adversarial loss: 0.373878\n",
      "epoch 40; iter: 200; batch classifier loss: 0.324235; batch adversarial loss: 0.462071\n",
      "epoch 41; iter: 0; batch classifier loss: 0.355949; batch adversarial loss: 0.420609\n",
      "epoch 41; iter: 200; batch classifier loss: 0.436637; batch adversarial loss: 0.407770\n",
      "epoch 42; iter: 0; batch classifier loss: 0.322847; batch adversarial loss: 0.513393\n",
      "epoch 42; iter: 200; batch classifier loss: 0.408289; batch adversarial loss: 0.387913\n",
      "epoch 43; iter: 0; batch classifier loss: 0.288408; batch adversarial loss: 0.431119\n",
      "epoch 43; iter: 200; batch classifier loss: 0.259049; batch adversarial loss: 0.485698\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369537; batch adversarial loss: 0.374173\n",
      "epoch 44; iter: 200; batch classifier loss: 0.450136; batch adversarial loss: 0.542410\n",
      "epoch 45; iter: 0; batch classifier loss: 0.351149; batch adversarial loss: 0.433274\n",
      "epoch 45; iter: 200; batch classifier loss: 0.350166; batch adversarial loss: 0.337937\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398762; batch adversarial loss: 0.376788\n",
      "epoch 46; iter: 200; batch classifier loss: 0.338034; batch adversarial loss: 0.365504\n",
      "epoch 47; iter: 0; batch classifier loss: 0.298032; batch adversarial loss: 0.422855\n",
      "epoch 47; iter: 200; batch classifier loss: 0.428932; batch adversarial loss: 0.459744\n",
      "epoch 48; iter: 0; batch classifier loss: 0.343129; batch adversarial loss: 0.441865\n",
      "epoch 48; iter: 200; batch classifier loss: 0.451967; batch adversarial loss: 0.415865\n",
      "epoch 49; iter: 0; batch classifier loss: 0.372636; batch adversarial loss: 0.437525\n",
      "epoch 49; iter: 200; batch classifier loss: 0.353154; batch adversarial loss: 0.475961\n",
      "epoch 0; iter: 0; batch classifier loss: 15.894308; batch adversarial loss: 0.654898\n",
      "epoch 0; iter: 200; batch classifier loss: 13.456060; batch adversarial loss: 0.641656\n",
      "epoch 1; iter: 0; batch classifier loss: 3.492466; batch adversarial loss: 0.560802\n",
      "epoch 1; iter: 200; batch classifier loss: 5.031294; batch adversarial loss: 0.499749\n",
      "epoch 2; iter: 0; batch classifier loss: 4.589989; batch adversarial loss: 0.532595\n",
      "epoch 2; iter: 200; batch classifier loss: 4.099362; batch adversarial loss: 0.454524\n",
      "epoch 3; iter: 0; batch classifier loss: 4.259551; batch adversarial loss: 0.429013\n",
      "epoch 3; iter: 200; batch classifier loss: 1.391469; batch adversarial loss: 0.465960\n",
      "epoch 4; iter: 0; batch classifier loss: 0.994201; batch adversarial loss: 0.442367\n",
      "epoch 4; iter: 200; batch classifier loss: 1.058805; batch adversarial loss: 0.476732\n",
      "epoch 5; iter: 0; batch classifier loss: 0.758453; batch adversarial loss: 0.388776\n",
      "epoch 5; iter: 200; batch classifier loss: 0.535745; batch adversarial loss: 0.369885\n",
      "epoch 6; iter: 0; batch classifier loss: 1.585216; batch adversarial loss: 0.409330\n",
      "epoch 6; iter: 200; batch classifier loss: 0.754068; batch adversarial loss: 0.358087\n",
      "epoch 7; iter: 0; batch classifier loss: 0.676454; batch adversarial loss: 0.387770\n",
      "epoch 7; iter: 200; batch classifier loss: 0.320640; batch adversarial loss: 0.482111\n",
      "epoch 8; iter: 0; batch classifier loss: 0.413372; batch adversarial loss: 0.459181\n",
      "epoch 8; iter: 200; batch classifier loss: 0.363549; batch adversarial loss: 0.542739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453782; batch adversarial loss: 0.357831\n",
      "epoch 9; iter: 200; batch classifier loss: 0.368638; batch adversarial loss: 0.427535\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551577; batch adversarial loss: 0.364289\n",
      "epoch 10; iter: 200; batch classifier loss: 0.229319; batch adversarial loss: 0.390085\n",
      "epoch 11; iter: 0; batch classifier loss: 0.391005; batch adversarial loss: 0.485418\n",
      "epoch 11; iter: 200; batch classifier loss: 0.332680; batch adversarial loss: 0.383656\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359457; batch adversarial loss: 0.505308\n",
      "epoch 12; iter: 200; batch classifier loss: 0.338577; batch adversarial loss: 0.414150\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373727; batch adversarial loss: 0.362219\n",
      "epoch 13; iter: 200; batch classifier loss: 0.412821; batch adversarial loss: 0.442744\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358930; batch adversarial loss: 0.378955\n",
      "epoch 14; iter: 200; batch classifier loss: 0.381912; batch adversarial loss: 0.501068\n",
      "epoch 15; iter: 0; batch classifier loss: 0.425890; batch adversarial loss: 0.384554\n",
      "epoch 15; iter: 200; batch classifier loss: 0.302133; batch adversarial loss: 0.344559\n",
      "epoch 16; iter: 0; batch classifier loss: 0.338765; batch adversarial loss: 0.342258\n",
      "epoch 16; iter: 200; batch classifier loss: 0.347781; batch adversarial loss: 0.485955\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368120; batch adversarial loss: 0.361506\n",
      "epoch 17; iter: 200; batch classifier loss: 0.372295; batch adversarial loss: 0.503134\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313374; batch adversarial loss: 0.430532\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321815; batch adversarial loss: 0.360595\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275438; batch adversarial loss: 0.403435\n",
      "epoch 19; iter: 200; batch classifier loss: 0.386098; batch adversarial loss: 0.419992\n",
      "epoch 20; iter: 0; batch classifier loss: 0.349741; batch adversarial loss: 0.359430\n",
      "epoch 20; iter: 200; batch classifier loss: 0.294548; batch adversarial loss: 0.386583\n",
      "epoch 21; iter: 0; batch classifier loss: 0.329446; batch adversarial loss: 0.455074\n",
      "epoch 21; iter: 200; batch classifier loss: 0.296343; batch adversarial loss: 0.406502\n",
      "epoch 22; iter: 0; batch classifier loss: 0.382663; batch adversarial loss: 0.444132\n",
      "epoch 22; iter: 200; batch classifier loss: 0.358132; batch adversarial loss: 0.355636\n",
      "epoch 23; iter: 0; batch classifier loss: 0.318084; batch adversarial loss: 0.380297\n",
      "epoch 23; iter: 200; batch classifier loss: 0.314563; batch adversarial loss: 0.389832\n",
      "epoch 24; iter: 0; batch classifier loss: 0.366954; batch adversarial loss: 0.475883\n",
      "epoch 24; iter: 200; batch classifier loss: 0.352820; batch adversarial loss: 0.419348\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266635; batch adversarial loss: 0.357762\n",
      "epoch 25; iter: 200; batch classifier loss: 0.393553; batch adversarial loss: 0.375367\n",
      "epoch 26; iter: 0; batch classifier loss: 0.423647; batch adversarial loss: 0.419924\n",
      "epoch 26; iter: 200; batch classifier loss: 0.371651; batch adversarial loss: 0.414721\n",
      "epoch 27; iter: 0; batch classifier loss: 0.348556; batch adversarial loss: 0.471203\n",
      "epoch 27; iter: 200; batch classifier loss: 0.319109; batch adversarial loss: 0.381643\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315332; batch adversarial loss: 0.482681\n",
      "epoch 28; iter: 200; batch classifier loss: 0.328386; batch adversarial loss: 0.362841\n",
      "epoch 29; iter: 0; batch classifier loss: 0.312123; batch adversarial loss: 0.416081\n",
      "epoch 29; iter: 200; batch classifier loss: 0.317886; batch adversarial loss: 0.311608\n",
      "epoch 30; iter: 0; batch classifier loss: 0.353321; batch adversarial loss: 0.388179\n",
      "epoch 30; iter: 200; batch classifier loss: 0.468090; batch adversarial loss: 0.338330\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432207; batch adversarial loss: 0.335717\n",
      "epoch 31; iter: 200; batch classifier loss: 0.453541; batch adversarial loss: 0.504781\n",
      "epoch 32; iter: 0; batch classifier loss: 0.306843; batch adversarial loss: 0.513508\n",
      "epoch 32; iter: 200; batch classifier loss: 0.358331; batch adversarial loss: 0.498680\n",
      "epoch 33; iter: 0; batch classifier loss: 0.353293; batch adversarial loss: 0.485426\n",
      "epoch 33; iter: 200; batch classifier loss: 0.442970; batch adversarial loss: 0.399651\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392434; batch adversarial loss: 0.387191\n",
      "epoch 34; iter: 200; batch classifier loss: 0.378608; batch adversarial loss: 0.368045\n",
      "epoch 35; iter: 0; batch classifier loss: 0.428111; batch adversarial loss: 0.438160\n",
      "epoch 35; iter: 200; batch classifier loss: 0.358775; batch adversarial loss: 0.451898\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366105; batch adversarial loss: 0.485036\n",
      "epoch 36; iter: 200; batch classifier loss: 0.369201; batch adversarial loss: 0.375660\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407757; batch adversarial loss: 0.265628\n",
      "epoch 37; iter: 200; batch classifier loss: 0.357578; batch adversarial loss: 0.455742\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409574; batch adversarial loss: 0.397986\n",
      "epoch 38; iter: 200; batch classifier loss: 0.358058; batch adversarial loss: 0.380650\n",
      "epoch 39; iter: 0; batch classifier loss: 0.279735; batch adversarial loss: 0.477903\n",
      "epoch 39; iter: 200; batch classifier loss: 0.353502; batch adversarial loss: 0.375998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.349620; batch adversarial loss: 0.402691\n",
      "epoch 40; iter: 200; batch classifier loss: 0.278159; batch adversarial loss: 0.492221\n",
      "epoch 41; iter: 0; batch classifier loss: 0.493100; batch adversarial loss: 0.340513\n",
      "epoch 41; iter: 200; batch classifier loss: 0.504379; batch adversarial loss: 0.372638\n",
      "epoch 42; iter: 0; batch classifier loss: 0.280399; batch adversarial loss: 0.389015\n",
      "epoch 42; iter: 200; batch classifier loss: 0.444848; batch adversarial loss: 0.456608\n",
      "epoch 43; iter: 0; batch classifier loss: 0.330177; batch adversarial loss: 0.364202\n",
      "epoch 43; iter: 200; batch classifier loss: 0.448453; batch adversarial loss: 0.455927\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415239; batch adversarial loss: 0.531507\n",
      "epoch 44; iter: 200; batch classifier loss: 0.336535; batch adversarial loss: 0.442528\n",
      "epoch 45; iter: 0; batch classifier loss: 0.451261; batch adversarial loss: 0.333450\n",
      "epoch 45; iter: 200; batch classifier loss: 0.274529; batch adversarial loss: 0.453836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.297875; batch adversarial loss: 0.464649\n",
      "epoch 46; iter: 200; batch classifier loss: 0.347041; batch adversarial loss: 0.367172\n",
      "epoch 47; iter: 0; batch classifier loss: 0.382068; batch adversarial loss: 0.379033\n",
      "epoch 47; iter: 200; batch classifier loss: 0.458995; batch adversarial loss: 0.433869\n",
      "epoch 48; iter: 0; batch classifier loss: 0.228005; batch adversarial loss: 0.368034\n",
      "epoch 48; iter: 200; batch classifier loss: 0.363769; batch adversarial loss: 0.453011\n",
      "epoch 49; iter: 0; batch classifier loss: 0.326127; batch adversarial loss: 0.457657\n",
      "epoch 49; iter: 200; batch classifier loss: 0.475540; batch adversarial loss: 0.404356\n",
      "epoch 0; iter: 0; batch classifier loss: 27.006502; batch adversarial loss: 0.597400\n",
      "epoch 0; iter: 200; batch classifier loss: 9.774507; batch adversarial loss: 0.628899\n",
      "epoch 1; iter: 0; batch classifier loss: 20.531052; batch adversarial loss: 0.545436\n",
      "epoch 1; iter: 200; batch classifier loss: 5.838521; batch adversarial loss: 0.536323\n",
      "epoch 2; iter: 0; batch classifier loss: 3.463946; batch adversarial loss: 0.478089\n",
      "epoch 2; iter: 200; batch classifier loss: 1.052289; batch adversarial loss: 0.424477\n",
      "epoch 3; iter: 0; batch classifier loss: 3.690460; batch adversarial loss: 0.379406\n",
      "epoch 3; iter: 200; batch classifier loss: 4.115692; batch adversarial loss: 0.381827\n",
      "epoch 4; iter: 0; batch classifier loss: 1.679675; batch adversarial loss: 0.424531\n",
      "epoch 4; iter: 200; batch classifier loss: 1.523494; batch adversarial loss: 0.390683\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418300; batch adversarial loss: 0.393226\n",
      "epoch 5; iter: 200; batch classifier loss: 0.497631; batch adversarial loss: 0.429117\n",
      "epoch 6; iter: 0; batch classifier loss: 0.617658; batch adversarial loss: 0.455333\n",
      "epoch 6; iter: 200; batch classifier loss: 0.831874; batch adversarial loss: 0.411521\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532525; batch adversarial loss: 0.466798\n",
      "epoch 7; iter: 200; batch classifier loss: 0.803796; batch adversarial loss: 0.440161\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434562; batch adversarial loss: 0.432155\n",
      "epoch 8; iter: 200; batch classifier loss: 1.690014; batch adversarial loss: 0.485330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.424500; batch adversarial loss: 0.377091\n",
      "epoch 9; iter: 200; batch classifier loss: 0.413653; batch adversarial loss: 0.432248\n",
      "epoch 10; iter: 0; batch classifier loss: 0.389713; batch adversarial loss: 0.383996\n",
      "epoch 10; iter: 200; batch classifier loss: 0.360488; batch adversarial loss: 0.331771\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345045; batch adversarial loss: 0.398230\n",
      "epoch 11; iter: 200; batch classifier loss: 0.537187; batch adversarial loss: 0.382531\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405035; batch adversarial loss: 0.387079\n",
      "epoch 12; iter: 200; batch classifier loss: 0.348279; batch adversarial loss: 0.395983\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420269; batch adversarial loss: 0.389584\n",
      "epoch 13; iter: 200; batch classifier loss: 0.356913; batch adversarial loss: 0.424639\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322247; batch adversarial loss: 0.377566\n",
      "epoch 14; iter: 200; batch classifier loss: 0.322438; batch adversarial loss: 0.392421\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374122; batch adversarial loss: 0.462763\n",
      "epoch 15; iter: 200; batch classifier loss: 0.396794; batch adversarial loss: 0.388842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.390067; batch adversarial loss: 0.421637\n",
      "epoch 16; iter: 200; batch classifier loss: 0.280305; batch adversarial loss: 0.517914\n",
      "epoch 17; iter: 0; batch classifier loss: 0.280723; batch adversarial loss: 0.471097\n",
      "epoch 17; iter: 200; batch classifier loss: 0.344789; batch adversarial loss: 0.323800\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301015; batch adversarial loss: 0.460887\n",
      "epoch 18; iter: 200; batch classifier loss: 0.418682; batch adversarial loss: 0.389242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355329; batch adversarial loss: 0.404658\n",
      "epoch 19; iter: 200; batch classifier loss: 0.344549; batch adversarial loss: 0.453813\n",
      "epoch 20; iter: 0; batch classifier loss: 0.427974; batch adversarial loss: 0.456700\n",
      "epoch 20; iter: 200; batch classifier loss: 0.326743; batch adversarial loss: 0.410524\n",
      "epoch 21; iter: 0; batch classifier loss: 0.265543; batch adversarial loss: 0.456496\n",
      "epoch 21; iter: 200; batch classifier loss: 0.459935; batch adversarial loss: 0.402872\n",
      "epoch 22; iter: 0; batch classifier loss: 0.401822; batch adversarial loss: 0.323327\n",
      "epoch 22; iter: 200; batch classifier loss: 0.247003; batch adversarial loss: 0.382406\n",
      "epoch 23; iter: 0; batch classifier loss: 0.485618; batch adversarial loss: 0.400099\n",
      "epoch 23; iter: 200; batch classifier loss: 0.346053; batch adversarial loss: 0.426935\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266732; batch adversarial loss: 0.400238\n",
      "epoch 24; iter: 200; batch classifier loss: 0.361673; batch adversarial loss: 0.423541\n",
      "epoch 25; iter: 0; batch classifier loss: 0.338520; batch adversarial loss: 0.285579\n",
      "epoch 25; iter: 200; batch classifier loss: 0.317479; batch adversarial loss: 0.470398\n",
      "epoch 26; iter: 0; batch classifier loss: 0.347110; batch adversarial loss: 0.395235\n",
      "epoch 26; iter: 200; batch classifier loss: 0.387018; batch adversarial loss: 0.457515\n",
      "epoch 27; iter: 0; batch classifier loss: 0.336043; batch adversarial loss: 0.447578\n",
      "epoch 27; iter: 200; batch classifier loss: 0.275670; batch adversarial loss: 0.418507\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352536; batch adversarial loss: 0.378151\n",
      "epoch 28; iter: 200; batch classifier loss: 0.367984; batch adversarial loss: 0.517927\n",
      "epoch 29; iter: 0; batch classifier loss: 0.287352; batch adversarial loss: 0.378247\n",
      "epoch 29; iter: 200; batch classifier loss: 0.332012; batch adversarial loss: 0.308612\n",
      "epoch 30; iter: 0; batch classifier loss: 0.307810; batch adversarial loss: 0.370066\n",
      "epoch 30; iter: 200; batch classifier loss: 0.293501; batch adversarial loss: 0.437509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.351304; batch adversarial loss: 0.424480\n",
      "epoch 31; iter: 200; batch classifier loss: 0.392129; batch adversarial loss: 0.383197\n",
      "epoch 32; iter: 0; batch classifier loss: 0.270723; batch adversarial loss: 0.375136\n",
      "epoch 32; iter: 200; batch classifier loss: 0.309859; batch adversarial loss: 0.375744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404117; batch adversarial loss: 0.394557\n",
      "epoch 33; iter: 200; batch classifier loss: 0.346550; batch adversarial loss: 0.401411\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415795; batch adversarial loss: 0.544042\n",
      "epoch 34; iter: 200; batch classifier loss: 0.309504; batch adversarial loss: 0.346163\n",
      "epoch 35; iter: 0; batch classifier loss: 0.314545; batch adversarial loss: 0.362747\n",
      "epoch 35; iter: 200; batch classifier loss: 0.271043; batch adversarial loss: 0.425737\n",
      "epoch 36; iter: 0; batch classifier loss: 0.305103; batch adversarial loss: 0.486945\n",
      "epoch 36; iter: 200; batch classifier loss: 0.311558; batch adversarial loss: 0.415954\n",
      "epoch 37; iter: 0; batch classifier loss: 0.246456; batch adversarial loss: 0.446981\n",
      "epoch 37; iter: 200; batch classifier loss: 0.268542; batch adversarial loss: 0.456668\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435724; batch adversarial loss: 0.332394\n",
      "epoch 38; iter: 200; batch classifier loss: 0.488804; batch adversarial loss: 0.399535\n",
      "epoch 39; iter: 0; batch classifier loss: 0.356317; batch adversarial loss: 0.358047\n",
      "epoch 39; iter: 200; batch classifier loss: 0.406168; batch adversarial loss: 0.407501\n",
      "epoch 40; iter: 0; batch classifier loss: 0.307804; batch adversarial loss: 0.427226\n",
      "epoch 40; iter: 200; batch classifier loss: 0.297377; batch adversarial loss: 0.510738\n",
      "epoch 41; iter: 0; batch classifier loss: 0.371990; batch adversarial loss: 0.389968\n",
      "epoch 41; iter: 200; batch classifier loss: 0.333658; batch adversarial loss: 0.471289\n",
      "epoch 42; iter: 0; batch classifier loss: 0.315005; batch adversarial loss: 0.377360\n",
      "epoch 42; iter: 200; batch classifier loss: 0.394118; batch adversarial loss: 0.335828\n",
      "epoch 43; iter: 0; batch classifier loss: 0.311663; batch adversarial loss: 0.498666\n",
      "epoch 43; iter: 200; batch classifier loss: 0.316979; batch adversarial loss: 0.391596\n",
      "epoch 44; iter: 0; batch classifier loss: 0.333187; batch adversarial loss: 0.460927\n",
      "epoch 44; iter: 200; batch classifier loss: 0.383116; batch adversarial loss: 0.452670\n",
      "epoch 45; iter: 0; batch classifier loss: 0.228614; batch adversarial loss: 0.531529\n",
      "epoch 45; iter: 200; batch classifier loss: 0.307298; batch adversarial loss: 0.451145\n",
      "epoch 46; iter: 0; batch classifier loss: 0.316989; batch adversarial loss: 0.497990\n",
      "epoch 46; iter: 200; batch classifier loss: 0.279560; batch adversarial loss: 0.452540\n",
      "epoch 47; iter: 0; batch classifier loss: 0.365925; batch adversarial loss: 0.358507\n",
      "epoch 47; iter: 200; batch classifier loss: 0.313184; batch adversarial loss: 0.359132\n",
      "epoch 48; iter: 0; batch classifier loss: 0.346466; batch adversarial loss: 0.435265\n",
      "epoch 48; iter: 200; batch classifier loss: 0.291529; batch adversarial loss: 0.333053\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357653; batch adversarial loss: 0.363472\n",
      "epoch 49; iter: 200; batch classifier loss: 0.341857; batch adversarial loss: 0.484289\n",
      "epoch 0; iter: 0; batch classifier loss: 16.904261; batch adversarial loss: 1.035542\n",
      "epoch 0; iter: 200; batch classifier loss: 9.893253; batch adversarial loss: 0.693636\n",
      "epoch 1; iter: 0; batch classifier loss: 2.141113; batch adversarial loss: 0.682166\n",
      "epoch 1; iter: 200; batch classifier loss: 1.617054; batch adversarial loss: 0.593809\n",
      "epoch 2; iter: 0; batch classifier loss: 7.382661; batch adversarial loss: 0.585806\n",
      "epoch 2; iter: 200; batch classifier loss: 1.955094; batch adversarial loss: 0.536474\n",
      "epoch 3; iter: 0; batch classifier loss: 3.565088; batch adversarial loss: 0.467966\n",
      "epoch 3; iter: 200; batch classifier loss: 2.013922; batch adversarial loss: 0.468316\n",
      "epoch 4; iter: 0; batch classifier loss: 0.681989; batch adversarial loss: 0.444573\n",
      "epoch 4; iter: 200; batch classifier loss: 0.955278; batch adversarial loss: 0.456517\n",
      "epoch 5; iter: 0; batch classifier loss: 0.963666; batch adversarial loss: 0.487770\n",
      "epoch 5; iter: 200; batch classifier loss: 0.441294; batch adversarial loss: 0.472185\n",
      "epoch 6; iter: 0; batch classifier loss: 0.752650; batch adversarial loss: 0.469427\n",
      "epoch 6; iter: 200; batch classifier loss: 0.327261; batch adversarial loss: 0.405459\n",
      "epoch 7; iter: 0; batch classifier loss: 0.552223; batch adversarial loss: 0.402973\n",
      "epoch 7; iter: 200; batch classifier loss: 0.306109; batch adversarial loss: 0.456630\n",
      "epoch 8; iter: 0; batch classifier loss: 0.261407; batch adversarial loss: 0.481156\n",
      "epoch 8; iter: 200; batch classifier loss: 0.345257; batch adversarial loss: 0.367684\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418552; batch adversarial loss: 0.373472\n",
      "epoch 9; iter: 200; batch classifier loss: 0.409310; batch adversarial loss: 0.391225\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466207; batch adversarial loss: 0.441769\n",
      "epoch 10; iter: 200; batch classifier loss: 0.384556; batch adversarial loss: 0.447417\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404772; batch adversarial loss: 0.267111\n",
      "epoch 11; iter: 200; batch classifier loss: 0.484980; batch adversarial loss: 0.433905\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335016; batch adversarial loss: 0.318983\n",
      "epoch 12; iter: 200; batch classifier loss: 0.384663; batch adversarial loss: 0.444958\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309981; batch adversarial loss: 0.434608\n",
      "epoch 13; iter: 200; batch classifier loss: 0.321262; batch adversarial loss: 0.431269\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435870; batch adversarial loss: 0.359615\n",
      "epoch 14; iter: 200; batch classifier loss: 0.316314; batch adversarial loss: 0.484887\n",
      "epoch 15; iter: 0; batch classifier loss: 0.394632; batch adversarial loss: 0.422213\n",
      "epoch 15; iter: 200; batch classifier loss: 0.346168; batch adversarial loss: 0.426394\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333127; batch adversarial loss: 0.419520\n",
      "epoch 16; iter: 200; batch classifier loss: 0.343028; batch adversarial loss: 0.413573\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426865; batch adversarial loss: 0.478107\n",
      "epoch 17; iter: 200; batch classifier loss: 0.447648; batch adversarial loss: 0.421791\n",
      "epoch 18; iter: 0; batch classifier loss: 0.336798; batch adversarial loss: 0.390393\n",
      "epoch 18; iter: 200; batch classifier loss: 0.554433; batch adversarial loss: 0.491829\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310089; batch adversarial loss: 0.428307\n",
      "epoch 19; iter: 200; batch classifier loss: 0.315299; batch adversarial loss: 0.456255\n",
      "epoch 20; iter: 0; batch classifier loss: 0.402030; batch adversarial loss: 0.367119\n",
      "epoch 20; iter: 200; batch classifier loss: 0.367304; batch adversarial loss: 0.323893\n",
      "epoch 21; iter: 0; batch classifier loss: 0.345238; batch adversarial loss: 0.446649\n",
      "epoch 21; iter: 200; batch classifier loss: 0.314303; batch adversarial loss: 0.434759\n",
      "epoch 22; iter: 0; batch classifier loss: 0.397290; batch adversarial loss: 0.379720\n",
      "epoch 22; iter: 200; batch classifier loss: 0.300258; batch adversarial loss: 0.434098\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310959; batch adversarial loss: 0.370610\n",
      "epoch 23; iter: 200; batch classifier loss: 0.331903; batch adversarial loss: 0.523822\n",
      "epoch 24; iter: 0; batch classifier loss: 0.325298; batch adversarial loss: 0.412491\n",
      "epoch 24; iter: 200; batch classifier loss: 0.318071; batch adversarial loss: 0.384676\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291091; batch adversarial loss: 0.306703\n",
      "epoch 25; iter: 200; batch classifier loss: 0.387614; batch adversarial loss: 0.331611\n",
      "epoch 26; iter: 0; batch classifier loss: 0.345658; batch adversarial loss: 0.383628\n",
      "epoch 26; iter: 200; batch classifier loss: 0.317692; batch adversarial loss: 0.426041\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284127; batch adversarial loss: 0.384656\n",
      "epoch 27; iter: 200; batch classifier loss: 0.369826; batch adversarial loss: 0.363667\n",
      "epoch 28; iter: 0; batch classifier loss: 0.326247; batch adversarial loss: 0.479885\n",
      "epoch 28; iter: 200; batch classifier loss: 0.395439; batch adversarial loss: 0.307917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.331607; batch adversarial loss: 0.422838\n",
      "epoch 29; iter: 200; batch classifier loss: 0.285710; batch adversarial loss: 0.361443\n",
      "epoch 30; iter: 0; batch classifier loss: 0.400809; batch adversarial loss: 0.534608\n",
      "epoch 30; iter: 200; batch classifier loss: 0.375313; batch adversarial loss: 0.413148\n",
      "epoch 31; iter: 0; batch classifier loss: 0.318172; batch adversarial loss: 0.398656\n",
      "epoch 31; iter: 200; batch classifier loss: 0.341368; batch adversarial loss: 0.407746\n",
      "epoch 32; iter: 0; batch classifier loss: 0.346333; batch adversarial loss: 0.394102\n",
      "epoch 32; iter: 200; batch classifier loss: 0.293273; batch adversarial loss: 0.405119\n",
      "epoch 33; iter: 0; batch classifier loss: 0.348911; batch adversarial loss: 0.385746\n",
      "epoch 33; iter: 200; batch classifier loss: 0.314565; batch adversarial loss: 0.438713\n",
      "epoch 34; iter: 0; batch classifier loss: 0.360546; batch adversarial loss: 0.412079\n",
      "epoch 34; iter: 200; batch classifier loss: 0.380607; batch adversarial loss: 0.324648\n",
      "epoch 35; iter: 0; batch classifier loss: 0.309467; batch adversarial loss: 0.479067\n",
      "epoch 35; iter: 200; batch classifier loss: 0.476404; batch adversarial loss: 0.435453\n",
      "epoch 36; iter: 0; batch classifier loss: 0.344227; batch adversarial loss: 0.467750\n",
      "epoch 36; iter: 200; batch classifier loss: 0.374857; batch adversarial loss: 0.411483\n",
      "epoch 37; iter: 0; batch classifier loss: 0.364380; batch adversarial loss: 0.333920\n",
      "epoch 37; iter: 200; batch classifier loss: 0.240902; batch adversarial loss: 0.477296\n",
      "epoch 38; iter: 0; batch classifier loss: 0.352600; batch adversarial loss: 0.358656\n",
      "epoch 38; iter: 200; batch classifier loss: 0.331114; batch adversarial loss: 0.371694\n",
      "epoch 39; iter: 0; batch classifier loss: 0.310877; batch adversarial loss: 0.407241\n",
      "epoch 39; iter: 200; batch classifier loss: 0.346039; batch adversarial loss: 0.362356\n",
      "epoch 40; iter: 0; batch classifier loss: 0.451072; batch adversarial loss: 0.427561\n",
      "epoch 40; iter: 200; batch classifier loss: 0.342962; batch adversarial loss: 0.381961\n",
      "epoch 41; iter: 0; batch classifier loss: 0.304606; batch adversarial loss: 0.368120\n",
      "epoch 41; iter: 200; batch classifier loss: 0.335583; batch adversarial loss: 0.495243\n",
      "epoch 42; iter: 0; batch classifier loss: 0.301416; batch adversarial loss: 0.382162\n",
      "epoch 42; iter: 200; batch classifier loss: 0.300234; batch adversarial loss: 0.465036\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400569; batch adversarial loss: 0.398594\n",
      "epoch 43; iter: 200; batch classifier loss: 0.383277; batch adversarial loss: 0.528383\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397467; batch adversarial loss: 0.417774\n",
      "epoch 44; iter: 200; batch classifier loss: 0.416907; batch adversarial loss: 0.372513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394851; batch adversarial loss: 0.303060\n",
      "epoch 45; iter: 200; batch classifier loss: 0.399751; batch adversarial loss: 0.341173\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378543; batch adversarial loss: 0.488050\n",
      "epoch 46; iter: 200; batch classifier loss: 0.345810; batch adversarial loss: 0.369055\n",
      "epoch 47; iter: 0; batch classifier loss: 0.332899; batch adversarial loss: 0.515541\n",
      "epoch 47; iter: 200; batch classifier loss: 0.361861; batch adversarial loss: 0.349718\n",
      "epoch 48; iter: 0; batch classifier loss: 0.369305; batch adversarial loss: 0.457633\n",
      "epoch 48; iter: 200; batch classifier loss: 0.393069; batch adversarial loss: 0.359147\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376797; batch adversarial loss: 0.555398\n",
      "epoch 49; iter: 200; batch classifier loss: 0.428554; batch adversarial loss: 0.390925\n",
      "epoch 0; iter: 0; batch classifier loss: 20.368462; batch adversarial loss: 0.573416\n",
      "epoch 0; iter: 200; batch classifier loss: 6.394904; batch adversarial loss: 0.583087\n",
      "epoch 1; iter: 0; batch classifier loss: 3.702848; batch adversarial loss: 0.602758\n",
      "epoch 1; iter: 200; batch classifier loss: 2.218670; batch adversarial loss: 0.518510\n",
      "epoch 2; iter: 0; batch classifier loss: 0.882926; batch adversarial loss: 0.481763\n",
      "epoch 2; iter: 200; batch classifier loss: 1.940784; batch adversarial loss: 0.489731\n",
      "epoch 3; iter: 0; batch classifier loss: 3.606686; batch adversarial loss: 0.470893\n",
      "epoch 3; iter: 200; batch classifier loss: 2.427458; batch adversarial loss: 0.422717\n",
      "epoch 4; iter: 0; batch classifier loss: 5.162926; batch adversarial loss: 0.454087\n",
      "epoch 4; iter: 200; batch classifier loss: 0.607931; batch adversarial loss: 0.432763\n",
      "epoch 5; iter: 0; batch classifier loss: 1.214122; batch adversarial loss: 0.406395\n",
      "epoch 5; iter: 200; batch classifier loss: 1.124133; batch adversarial loss: 0.402653\n",
      "epoch 6; iter: 0; batch classifier loss: 0.792547; batch adversarial loss: 0.453193\n",
      "epoch 6; iter: 200; batch classifier loss: 0.675835; batch adversarial loss: 0.415245\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512415; batch adversarial loss: 0.439643\n",
      "epoch 7; iter: 200; batch classifier loss: 0.579589; batch adversarial loss: 0.435027\n",
      "epoch 8; iter: 0; batch classifier loss: 0.856107; batch adversarial loss: 0.375198\n",
      "epoch 8; iter: 200; batch classifier loss: 0.360316; batch adversarial loss: 0.419008\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338480; batch adversarial loss: 0.372680\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386578; batch adversarial loss: 0.446395\n",
      "epoch 10; iter: 0; batch classifier loss: 0.628390; batch adversarial loss: 0.395130\n",
      "epoch 10; iter: 200; batch classifier loss: 0.352701; batch adversarial loss: 0.391007\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491736; batch adversarial loss: 0.476332\n",
      "epoch 11; iter: 200; batch classifier loss: 0.419648; batch adversarial loss: 0.436075\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377552; batch adversarial loss: 0.441526\n",
      "epoch 12; iter: 200; batch classifier loss: 0.316976; batch adversarial loss: 0.381143\n",
      "epoch 13; iter: 0; batch classifier loss: 0.318298; batch adversarial loss: 0.381364\n",
      "epoch 13; iter: 200; batch classifier loss: 0.321275; batch adversarial loss: 0.441501\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306706; batch adversarial loss: 0.348219\n",
      "epoch 14; iter: 200; batch classifier loss: 0.541519; batch adversarial loss: 0.389433\n",
      "epoch 15; iter: 0; batch classifier loss: 0.278951; batch adversarial loss: 0.438452\n",
      "epoch 15; iter: 200; batch classifier loss: 0.293127; batch adversarial loss: 0.375784\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453313; batch adversarial loss: 0.420666\n",
      "epoch 16; iter: 200; batch classifier loss: 0.463869; batch adversarial loss: 0.545288\n",
      "epoch 17; iter: 0; batch classifier loss: 0.355452; batch adversarial loss: 0.390496\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343059; batch adversarial loss: 0.321238\n",
      "epoch 18; iter: 0; batch classifier loss: 0.312851; batch adversarial loss: 0.364027\n",
      "epoch 18; iter: 200; batch classifier loss: 0.386816; batch adversarial loss: 0.383333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.349812; batch adversarial loss: 0.452218\n",
      "epoch 19; iter: 200; batch classifier loss: 0.318201; batch adversarial loss: 0.497218\n",
      "epoch 20; iter: 0; batch classifier loss: 0.303053; batch adversarial loss: 0.470463\n",
      "epoch 20; iter: 200; batch classifier loss: 0.393698; batch adversarial loss: 0.447340\n",
      "epoch 21; iter: 0; batch classifier loss: 0.368570; batch adversarial loss: 0.463419\n",
      "epoch 21; iter: 200; batch classifier loss: 0.300507; batch adversarial loss: 0.476296\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262587; batch adversarial loss: 0.402927\n",
      "epoch 22; iter: 200; batch classifier loss: 0.334702; batch adversarial loss: 0.369271\n",
      "epoch 23; iter: 0; batch classifier loss: 0.363671; batch adversarial loss: 0.412247\n",
      "epoch 23; iter: 200; batch classifier loss: 0.509013; batch adversarial loss: 0.371600\n",
      "epoch 24; iter: 0; batch classifier loss: 0.321767; batch adversarial loss: 0.356512\n",
      "epoch 24; iter: 200; batch classifier loss: 0.362253; batch adversarial loss: 0.477994\n",
      "epoch 25; iter: 0; batch classifier loss: 0.371044; batch adversarial loss: 0.454684\n",
      "epoch 25; iter: 200; batch classifier loss: 0.339131; batch adversarial loss: 0.360491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319216; batch adversarial loss: 0.429525\n",
      "epoch 26; iter: 200; batch classifier loss: 0.233176; batch adversarial loss: 0.434995\n",
      "epoch 27; iter: 0; batch classifier loss: 0.292004; batch adversarial loss: 0.393292\n",
      "epoch 27; iter: 200; batch classifier loss: 0.457470; batch adversarial loss: 0.426183\n",
      "epoch 28; iter: 0; batch classifier loss: 0.304230; batch adversarial loss: 0.324237\n",
      "epoch 28; iter: 200; batch classifier loss: 0.397094; batch adversarial loss: 0.320913\n",
      "epoch 29; iter: 0; batch classifier loss: 0.384948; batch adversarial loss: 0.351906\n",
      "epoch 29; iter: 200; batch classifier loss: 0.256288; batch adversarial loss: 0.421581\n",
      "epoch 30; iter: 0; batch classifier loss: 0.353767; batch adversarial loss: 0.346325\n",
      "epoch 30; iter: 200; batch classifier loss: 0.400430; batch adversarial loss: 0.423814\n",
      "epoch 31; iter: 0; batch classifier loss: 0.303940; batch adversarial loss: 0.497508\n",
      "epoch 31; iter: 200; batch classifier loss: 0.324293; batch adversarial loss: 0.472227\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364368; batch adversarial loss: 0.427829\n",
      "epoch 32; iter: 200; batch classifier loss: 0.456781; batch adversarial loss: 0.356688\n",
      "epoch 33; iter: 0; batch classifier loss: 0.320013; batch adversarial loss: 0.438152\n",
      "epoch 33; iter: 200; batch classifier loss: 0.462974; batch adversarial loss: 0.333432\n",
      "epoch 34; iter: 0; batch classifier loss: 0.327798; batch adversarial loss: 0.338787\n",
      "epoch 34; iter: 200; batch classifier loss: 0.374189; batch adversarial loss: 0.361696\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400521; batch adversarial loss: 0.391903\n",
      "epoch 35; iter: 200; batch classifier loss: 0.361140; batch adversarial loss: 0.376793\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505035; batch adversarial loss: 0.400964\n",
      "epoch 36; iter: 200; batch classifier loss: 0.373535; batch adversarial loss: 0.332873\n",
      "epoch 37; iter: 0; batch classifier loss: 0.553054; batch adversarial loss: 0.428385\n",
      "epoch 37; iter: 200; batch classifier loss: 0.450250; batch adversarial loss: 0.347485\n",
      "epoch 38; iter: 0; batch classifier loss: 0.379059; batch adversarial loss: 0.372399\n",
      "epoch 38; iter: 200; batch classifier loss: 0.574675; batch adversarial loss: 0.414251\n",
      "epoch 39; iter: 0; batch classifier loss: 0.526928; batch adversarial loss: 0.492399\n",
      "epoch 39; iter: 200; batch classifier loss: 0.538759; batch adversarial loss: 0.349143\n",
      "epoch 40; iter: 0; batch classifier loss: 0.566155; batch adversarial loss: 0.345448\n",
      "epoch 40; iter: 200; batch classifier loss: 0.499995; batch adversarial loss: 0.355818\n",
      "epoch 41; iter: 0; batch classifier loss: 0.471686; batch adversarial loss: 0.447360\n",
      "epoch 41; iter: 200; batch classifier loss: 0.384444; batch adversarial loss: 0.497287\n",
      "epoch 42; iter: 0; batch classifier loss: 0.485713; batch adversarial loss: 0.469936\n",
      "epoch 42; iter: 200; batch classifier loss: 0.469422; batch adversarial loss: 0.417532\n",
      "epoch 43; iter: 0; batch classifier loss: 0.317609; batch adversarial loss: 0.322043\n",
      "epoch 43; iter: 200; batch classifier loss: 0.309482; batch adversarial loss: 0.370862\n",
      "epoch 44; iter: 0; batch classifier loss: 0.339306; batch adversarial loss: 0.569381\n",
      "epoch 44; iter: 200; batch classifier loss: 0.408490; batch adversarial loss: 0.338576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371079; batch adversarial loss: 0.480569\n",
      "epoch 45; iter: 200; batch classifier loss: 0.405047; batch adversarial loss: 0.428993\n",
      "epoch 46; iter: 0; batch classifier loss: 0.493985; batch adversarial loss: 0.372847\n",
      "epoch 46; iter: 200; batch classifier loss: 0.375262; batch adversarial loss: 0.375569\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395058; batch adversarial loss: 0.308480\n",
      "epoch 47; iter: 200; batch classifier loss: 0.415032; batch adversarial loss: 0.501523\n",
      "epoch 48; iter: 0; batch classifier loss: 0.362168; batch adversarial loss: 0.434340\n",
      "epoch 48; iter: 200; batch classifier loss: 0.357882; batch adversarial loss: 0.397624\n",
      "epoch 49; iter: 0; batch classifier loss: 0.318243; batch adversarial loss: 0.315662\n",
      "epoch 49; iter: 200; batch classifier loss: 0.387846; batch adversarial loss: 0.480933\n",
      "epoch 0; iter: 0; batch classifier loss: 58.230949; batch adversarial loss: 1.601671\n",
      "epoch 0; iter: 200; batch classifier loss: 5.395179; batch adversarial loss: 1.112305\n",
      "epoch 1; iter: 0; batch classifier loss: 6.673461; batch adversarial loss: 0.747416\n",
      "epoch 1; iter: 200; batch classifier loss: 5.248461; batch adversarial loss: 0.649545\n",
      "epoch 2; iter: 0; batch classifier loss: 2.663250; batch adversarial loss: 0.848989\n",
      "epoch 2; iter: 200; batch classifier loss: 2.048753; batch adversarial loss: 0.652284\n",
      "epoch 3; iter: 0; batch classifier loss: 2.811717; batch adversarial loss: 0.661408\n",
      "epoch 3; iter: 200; batch classifier loss: 0.577946; batch adversarial loss: 0.535389\n",
      "epoch 4; iter: 0; batch classifier loss: 0.959084; batch adversarial loss: 0.498157\n",
      "epoch 4; iter: 200; batch classifier loss: 1.287394; batch adversarial loss: 0.471627\n",
      "epoch 5; iter: 0; batch classifier loss: 1.239995; batch adversarial loss: 0.420597\n",
      "epoch 5; iter: 200; batch classifier loss: 1.067042; batch adversarial loss: 0.463045\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641315; batch adversarial loss: 0.442582\n",
      "epoch 6; iter: 200; batch classifier loss: 0.993999; batch adversarial loss: 0.465239\n",
      "epoch 7; iter: 0; batch classifier loss: 0.687898; batch adversarial loss: 0.405279\n",
      "epoch 7; iter: 200; batch classifier loss: 0.485555; batch adversarial loss: 0.408035\n",
      "epoch 8; iter: 0; batch classifier loss: 0.678221; batch adversarial loss: 0.387030\n",
      "epoch 8; iter: 200; batch classifier loss: 0.457487; batch adversarial loss: 0.413445\n",
      "epoch 9; iter: 0; batch classifier loss: 0.870415; batch adversarial loss: 0.411812\n",
      "epoch 9; iter: 200; batch classifier loss: 0.411650; batch adversarial loss: 0.412706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.458741; batch adversarial loss: 0.405192\n",
      "epoch 10; iter: 200; batch classifier loss: 0.358110; batch adversarial loss: 0.367998\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426733; batch adversarial loss: 0.406334\n",
      "epoch 11; iter: 200; batch classifier loss: 0.372746; batch adversarial loss: 0.388507\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526186; batch adversarial loss: 0.469080\n",
      "epoch 12; iter: 200; batch classifier loss: 0.332891; batch adversarial loss: 0.432726\n",
      "epoch 13; iter: 0; batch classifier loss: 0.388100; batch adversarial loss: 0.432477\n",
      "epoch 13; iter: 200; batch classifier loss: 0.375722; batch adversarial loss: 0.366349\n",
      "epoch 14; iter: 0; batch classifier loss: 0.471742; batch adversarial loss: 0.401393\n",
      "epoch 14; iter: 200; batch classifier loss: 0.313262; batch adversarial loss: 0.406249\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318846; batch adversarial loss: 0.406018\n",
      "epoch 15; iter: 200; batch classifier loss: 0.335122; batch adversarial loss: 0.401374\n",
      "epoch 16; iter: 0; batch classifier loss: 0.383920; batch adversarial loss: 0.428302\n",
      "epoch 16; iter: 200; batch classifier loss: 0.396543; batch adversarial loss: 0.384302\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327546; batch adversarial loss: 0.339738\n",
      "epoch 17; iter: 200; batch classifier loss: 0.348226; batch adversarial loss: 0.365530\n",
      "epoch 18; iter: 0; batch classifier loss: 0.360340; batch adversarial loss: 0.369724\n",
      "epoch 18; iter: 200; batch classifier loss: 0.358537; batch adversarial loss: 0.452295\n",
      "epoch 19; iter: 0; batch classifier loss: 0.391037; batch adversarial loss: 0.414764\n",
      "epoch 19; iter: 200; batch classifier loss: 0.328293; batch adversarial loss: 0.584744\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279480; batch adversarial loss: 0.550862\n",
      "epoch 20; iter: 200; batch classifier loss: 0.348642; batch adversarial loss: 0.343130\n",
      "epoch 21; iter: 0; batch classifier loss: 0.279750; batch adversarial loss: 0.426457\n",
      "epoch 21; iter: 200; batch classifier loss: 0.370782; batch adversarial loss: 0.455277\n",
      "epoch 22; iter: 0; batch classifier loss: 0.396875; batch adversarial loss: 0.307710\n",
      "epoch 22; iter: 200; batch classifier loss: 0.438275; batch adversarial loss: 0.366411\n",
      "epoch 23; iter: 0; batch classifier loss: 0.332283; batch adversarial loss: 0.398673\n",
      "epoch 23; iter: 200; batch classifier loss: 0.346696; batch adversarial loss: 0.339947\n",
      "epoch 24; iter: 0; batch classifier loss: 0.385382; batch adversarial loss: 0.412384\n",
      "epoch 24; iter: 200; batch classifier loss: 0.379440; batch adversarial loss: 0.412483\n",
      "epoch 25; iter: 0; batch classifier loss: 0.310365; batch adversarial loss: 0.531776\n",
      "epoch 25; iter: 200; batch classifier loss: 0.372236; batch adversarial loss: 0.460929\n",
      "epoch 26; iter: 0; batch classifier loss: 0.471859; batch adversarial loss: 0.430100\n",
      "epoch 26; iter: 200; batch classifier loss: 0.329014; batch adversarial loss: 0.391554\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315408; batch adversarial loss: 0.415089\n",
      "epoch 27; iter: 200; batch classifier loss: 0.366658; batch adversarial loss: 0.427653\n",
      "epoch 28; iter: 0; batch classifier loss: 0.287417; batch adversarial loss: 0.456278\n",
      "epoch 28; iter: 200; batch classifier loss: 0.383344; batch adversarial loss: 0.401634\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281082; batch adversarial loss: 0.438582\n",
      "epoch 29; iter: 200; batch classifier loss: 0.330537; batch adversarial loss: 0.487518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.299079; batch adversarial loss: 0.339721\n",
      "epoch 30; iter: 200; batch classifier loss: 0.277691; batch adversarial loss: 0.343747\n",
      "epoch 31; iter: 0; batch classifier loss: 0.363759; batch adversarial loss: 0.545532\n",
      "epoch 31; iter: 200; batch classifier loss: 0.354569; batch adversarial loss: 0.523948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.365662; batch adversarial loss: 0.425238\n",
      "epoch 32; iter: 200; batch classifier loss: 0.327282; batch adversarial loss: 0.433524\n",
      "epoch 33; iter: 0; batch classifier loss: 0.282922; batch adversarial loss: 0.449944\n",
      "epoch 33; iter: 200; batch classifier loss: 0.438259; batch adversarial loss: 0.493073\n",
      "epoch 34; iter: 0; batch classifier loss: 0.334792; batch adversarial loss: 0.387513\n",
      "epoch 34; iter: 200; batch classifier loss: 0.396250; batch adversarial loss: 0.469475\n",
      "epoch 35; iter: 0; batch classifier loss: 0.336663; batch adversarial loss: 0.396926\n",
      "epoch 35; iter: 200; batch classifier loss: 0.314523; batch adversarial loss: 0.404693\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496672; batch adversarial loss: 0.428406\n",
      "epoch 36; iter: 200; batch classifier loss: 0.331544; batch adversarial loss: 0.355176\n",
      "epoch 37; iter: 0; batch classifier loss: 0.294849; batch adversarial loss: 0.450068\n",
      "epoch 37; iter: 200; batch classifier loss: 0.322093; batch adversarial loss: 0.416881\n",
      "epoch 38; iter: 0; batch classifier loss: 0.300966; batch adversarial loss: 0.362867\n",
      "epoch 38; iter: 200; batch classifier loss: 0.336872; batch adversarial loss: 0.472891\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382654; batch adversarial loss: 0.440255\n",
      "epoch 39; iter: 200; batch classifier loss: 0.354892; batch adversarial loss: 0.389059\n",
      "epoch 40; iter: 0; batch classifier loss: 0.301932; batch adversarial loss: 0.492393\n",
      "epoch 40; iter: 200; batch classifier loss: 0.379889; batch adversarial loss: 0.560115\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441503; batch adversarial loss: 0.373343\n",
      "epoch 41; iter: 200; batch classifier loss: 0.343239; batch adversarial loss: 0.519334\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415173; batch adversarial loss: 0.321005\n",
      "epoch 42; iter: 200; batch classifier loss: 0.392416; batch adversarial loss: 0.422872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.372993; batch adversarial loss: 0.392944\n",
      "epoch 43; iter: 200; batch classifier loss: 0.333863; batch adversarial loss: 0.396321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.377871; batch adversarial loss: 0.511376\n",
      "epoch 44; iter: 200; batch classifier loss: 0.314877; batch adversarial loss: 0.441958\n",
      "epoch 45; iter: 0; batch classifier loss: 0.489483; batch adversarial loss: 0.465875\n",
      "epoch 45; iter: 200; batch classifier loss: 0.320191; batch adversarial loss: 0.565512\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378048; batch adversarial loss: 0.379603\n",
      "epoch 46; iter: 200; batch classifier loss: 0.435088; batch adversarial loss: 0.402640\n",
      "epoch 47; iter: 0; batch classifier loss: 0.253573; batch adversarial loss: 0.411317\n",
      "epoch 47; iter: 200; batch classifier loss: 0.391338; batch adversarial loss: 0.373334\n",
      "epoch 48; iter: 0; batch classifier loss: 0.343143; batch adversarial loss: 0.434334\n",
      "epoch 48; iter: 200; batch classifier loss: 0.329694; batch adversarial loss: 0.533840\n",
      "epoch 49; iter: 0; batch classifier loss: 0.345956; batch adversarial loss: 0.347688\n",
      "epoch 49; iter: 200; batch classifier loss: 0.349450; batch adversarial loss: 0.396361\n",
      "epoch 0; iter: 0; batch classifier loss: 11.271145; batch adversarial loss: 0.852052\n",
      "epoch 0; iter: 200; batch classifier loss: 4.130480; batch adversarial loss: 0.649839\n",
      "epoch 1; iter: 0; batch classifier loss: 5.608546; batch adversarial loss: 0.617153\n",
      "epoch 1; iter: 200; batch classifier loss: 3.805425; batch adversarial loss: 0.555506\n",
      "epoch 2; iter: 0; batch classifier loss: 6.650237; batch adversarial loss: 0.537532\n",
      "epoch 2; iter: 200; batch classifier loss: 1.655867; batch adversarial loss: 0.544701\n",
      "epoch 3; iter: 0; batch classifier loss: 0.638312; batch adversarial loss: 0.475297\n",
      "epoch 3; iter: 200; batch classifier loss: 1.078755; batch adversarial loss: 0.455709\n",
      "epoch 4; iter: 0; batch classifier loss: 2.441211; batch adversarial loss: 0.478937\n",
      "epoch 4; iter: 200; batch classifier loss: 0.382063; batch adversarial loss: 0.461796\n",
      "epoch 5; iter: 0; batch classifier loss: 0.805505; batch adversarial loss: 0.412486\n",
      "epoch 5; iter: 200; batch classifier loss: 0.392222; batch adversarial loss: 0.430760\n",
      "epoch 6; iter: 0; batch classifier loss: 0.897868; batch adversarial loss: 0.303930\n",
      "epoch 6; iter: 200; batch classifier loss: 0.862591; batch adversarial loss: 0.432494\n",
      "epoch 7; iter: 0; batch classifier loss: 0.765350; batch adversarial loss: 0.353916\n",
      "epoch 7; iter: 200; batch classifier loss: 0.531644; batch adversarial loss: 0.425032\n",
      "epoch 8; iter: 0; batch classifier loss: 0.416956; batch adversarial loss: 0.456821\n",
      "epoch 8; iter: 200; batch classifier loss: 0.425627; batch adversarial loss: 0.345273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.900961; batch adversarial loss: 0.373334\n",
      "epoch 9; iter: 200; batch classifier loss: 0.385948; batch adversarial loss: 0.439547\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486476; batch adversarial loss: 0.347367\n",
      "epoch 10; iter: 200; batch classifier loss: 0.371856; batch adversarial loss: 0.273199\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493794; batch adversarial loss: 0.454524\n",
      "epoch 11; iter: 200; batch classifier loss: 0.337381; batch adversarial loss: 0.387917\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327031; batch adversarial loss: 0.412621\n",
      "epoch 12; iter: 200; batch classifier loss: 0.438185; batch adversarial loss: 0.485936\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384553; batch adversarial loss: 0.386430\n",
      "epoch 13; iter: 200; batch classifier loss: 0.386421; batch adversarial loss: 0.319208\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340105; batch adversarial loss: 0.409534\n",
      "epoch 14; iter: 200; batch classifier loss: 0.462454; batch adversarial loss: 0.453238\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286766; batch adversarial loss: 0.451619\n",
      "epoch 15; iter: 200; batch classifier loss: 0.352065; batch adversarial loss: 0.367898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.305235; batch adversarial loss: 0.393329\n",
      "epoch 16; iter: 200; batch classifier loss: 0.295519; batch adversarial loss: 0.436051\n",
      "epoch 17; iter: 0; batch classifier loss: 0.437815; batch adversarial loss: 0.378266\n",
      "epoch 17; iter: 200; batch classifier loss: 0.331136; batch adversarial loss: 0.527515\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439520; batch adversarial loss: 0.468589\n",
      "epoch 18; iter: 200; batch classifier loss: 0.251980; batch adversarial loss: 0.479563\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451250; batch adversarial loss: 0.419775\n",
      "epoch 19; iter: 200; batch classifier loss: 0.534128; batch adversarial loss: 0.424207\n",
      "epoch 20; iter: 0; batch classifier loss: 0.265980; batch adversarial loss: 0.352446\n",
      "epoch 20; iter: 200; batch classifier loss: 0.240141; batch adversarial loss: 0.400819\n",
      "epoch 21; iter: 0; batch classifier loss: 0.334055; batch adversarial loss: 0.451610\n",
      "epoch 21; iter: 200; batch classifier loss: 0.325602; batch adversarial loss: 0.414503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.368249; batch adversarial loss: 0.465427\n",
      "epoch 22; iter: 200; batch classifier loss: 0.246883; batch adversarial loss: 0.464512\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313983; batch adversarial loss: 0.400929\n",
      "epoch 23; iter: 200; batch classifier loss: 0.392534; batch adversarial loss: 0.389892\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307819; batch adversarial loss: 0.375784\n",
      "epoch 24; iter: 200; batch classifier loss: 0.385255; batch adversarial loss: 0.511777\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484732; batch adversarial loss: 0.466931\n",
      "epoch 25; iter: 200; batch classifier loss: 0.357155; batch adversarial loss: 0.331966\n",
      "epoch 26; iter: 0; batch classifier loss: 0.405734; batch adversarial loss: 0.389669\n",
      "epoch 26; iter: 200; batch classifier loss: 0.360817; batch adversarial loss: 0.561223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.357408; batch adversarial loss: 0.363354\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310123; batch adversarial loss: 0.437235\n",
      "epoch 28; iter: 0; batch classifier loss: 0.319763; batch adversarial loss: 0.334650\n",
      "epoch 28; iter: 200; batch classifier loss: 0.344295; batch adversarial loss: 0.458310\n",
      "epoch 29; iter: 0; batch classifier loss: 0.321272; batch adversarial loss: 0.509887\n",
      "epoch 29; iter: 200; batch classifier loss: 0.287085; batch adversarial loss: 0.403794\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323138; batch adversarial loss: 0.417877\n",
      "epoch 30; iter: 200; batch classifier loss: 0.318020; batch adversarial loss: 0.388098\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421788; batch adversarial loss: 0.380024\n",
      "epoch 31; iter: 200; batch classifier loss: 0.351818; batch adversarial loss: 0.414276\n",
      "epoch 32; iter: 0; batch classifier loss: 0.308609; batch adversarial loss: 0.432258\n",
      "epoch 32; iter: 200; batch classifier loss: 0.219511; batch adversarial loss: 0.415622\n",
      "epoch 33; iter: 0; batch classifier loss: 0.302872; batch adversarial loss: 0.416162\n",
      "epoch 33; iter: 200; batch classifier loss: 0.309116; batch adversarial loss: 0.480879\n",
      "epoch 34; iter: 0; batch classifier loss: 0.369818; batch adversarial loss: 0.509399\n",
      "epoch 34; iter: 200; batch classifier loss: 0.395471; batch adversarial loss: 0.363287\n",
      "epoch 35; iter: 0; batch classifier loss: 0.265856; batch adversarial loss: 0.385561\n",
      "epoch 35; iter: 200; batch classifier loss: 0.307432; batch adversarial loss: 0.404209\n",
      "epoch 36; iter: 0; batch classifier loss: 0.315670; batch adversarial loss: 0.501003\n",
      "epoch 36; iter: 200; batch classifier loss: 0.402826; batch adversarial loss: 0.347394\n",
      "epoch 37; iter: 0; batch classifier loss: 0.306562; batch adversarial loss: 0.460770\n",
      "epoch 37; iter: 200; batch classifier loss: 0.338212; batch adversarial loss: 0.400380\n",
      "epoch 38; iter: 0; batch classifier loss: 0.347463; batch adversarial loss: 0.444182\n",
      "epoch 38; iter: 200; batch classifier loss: 0.387788; batch adversarial loss: 0.407377\n",
      "epoch 39; iter: 0; batch classifier loss: 0.283505; batch adversarial loss: 0.334612\n",
      "epoch 39; iter: 200; batch classifier loss: 0.393270; batch adversarial loss: 0.374929\n",
      "epoch 40; iter: 0; batch classifier loss: 0.433928; batch adversarial loss: 0.403078\n",
      "epoch 40; iter: 200; batch classifier loss: 0.365093; batch adversarial loss: 0.321198\n",
      "epoch 41; iter: 0; batch classifier loss: 0.355096; batch adversarial loss: 0.507152\n",
      "epoch 41; iter: 200; batch classifier loss: 0.287429; batch adversarial loss: 0.365167\n",
      "epoch 42; iter: 0; batch classifier loss: 0.281139; batch adversarial loss: 0.493479\n",
      "epoch 42; iter: 200; batch classifier loss: 0.486578; batch adversarial loss: 0.476476\n",
      "epoch 43; iter: 0; batch classifier loss: 0.334732; batch adversarial loss: 0.357933\n",
      "epoch 43; iter: 200; batch classifier loss: 0.403384; batch adversarial loss: 0.465214\n",
      "epoch 44; iter: 0; batch classifier loss: 0.216543; batch adversarial loss: 0.334206\n",
      "epoch 44; iter: 200; batch classifier loss: 0.372342; batch adversarial loss: 0.377308\n",
      "epoch 45; iter: 0; batch classifier loss: 0.309404; batch adversarial loss: 0.376953\n",
      "epoch 45; iter: 200; batch classifier loss: 0.296343; batch adversarial loss: 0.472709\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331872; batch adversarial loss: 0.374539\n",
      "epoch 46; iter: 200; batch classifier loss: 0.464806; batch adversarial loss: 0.389897\n",
      "epoch 47; iter: 0; batch classifier loss: 0.320115; batch adversarial loss: 0.400688\n",
      "epoch 47; iter: 200; batch classifier loss: 0.517243; batch adversarial loss: 0.413196\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421726; batch adversarial loss: 0.419638\n",
      "epoch 48; iter: 200; batch classifier loss: 0.339568; batch adversarial loss: 0.481732\n",
      "epoch 49; iter: 0; batch classifier loss: 0.322152; batch adversarial loss: 0.410926\n",
      "epoch 49; iter: 200; batch classifier loss: 0.442269; batch adversarial loss: 0.334773\n",
      "epoch 0; iter: 0; batch classifier loss: 116.947433; batch adversarial loss: 0.693162\n",
      "epoch 0; iter: 200; batch classifier loss: 25.647192; batch adversarial loss: 0.645229\n",
      "epoch 1; iter: 0; batch classifier loss: 2.616760; batch adversarial loss: 0.699868\n",
      "epoch 1; iter: 200; batch classifier loss: 29.680986; batch adversarial loss: 0.734770\n",
      "epoch 2; iter: 0; batch classifier loss: 2.117802; batch adversarial loss: 0.590453\n",
      "epoch 2; iter: 200; batch classifier loss: 36.255402; batch adversarial loss: 0.511241\n",
      "epoch 3; iter: 0; batch classifier loss: 2.585550; batch adversarial loss: 0.509933\n",
      "epoch 3; iter: 200; batch classifier loss: 1.035220; batch adversarial loss: 0.505731\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596208; batch adversarial loss: 0.454780\n",
      "epoch 4; iter: 200; batch classifier loss: 0.725767; batch adversarial loss: 0.459599\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589351; batch adversarial loss: 0.435081\n",
      "epoch 5; iter: 200; batch classifier loss: 0.738103; batch adversarial loss: 0.419825\n",
      "epoch 6; iter: 0; batch classifier loss: 0.873697; batch adversarial loss: 0.428245\n",
      "epoch 6; iter: 200; batch classifier loss: 1.071063; batch adversarial loss: 0.447122\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587052; batch adversarial loss: 0.516358\n",
      "epoch 7; iter: 200; batch classifier loss: 0.676355; batch adversarial loss: 0.451808\n",
      "epoch 8; iter: 0; batch classifier loss: 0.671243; batch adversarial loss: 0.515620\n",
      "epoch 8; iter: 200; batch classifier loss: 0.623167; batch adversarial loss: 0.482646\n",
      "epoch 9; iter: 0; batch classifier loss: 0.260262; batch adversarial loss: 0.399138\n",
      "epoch 9; iter: 200; batch classifier loss: 0.513428; batch adversarial loss: 0.408533\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523298; batch adversarial loss: 0.442373\n",
      "epoch 10; iter: 200; batch classifier loss: 0.639807; batch adversarial loss: 0.373302\n",
      "epoch 11; iter: 0; batch classifier loss: 1.404385; batch adversarial loss: 0.452454\n",
      "epoch 11; iter: 200; batch classifier loss: 0.439420; batch adversarial loss: 0.430324\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599116; batch adversarial loss: 0.347524\n",
      "epoch 12; iter: 200; batch classifier loss: 0.472443; batch adversarial loss: 0.433729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471754; batch adversarial loss: 0.418808\n",
      "epoch 13; iter: 200; batch classifier loss: 0.339131; batch adversarial loss: 0.426764\n",
      "epoch 14; iter: 0; batch classifier loss: 0.457524; batch adversarial loss: 0.540547\n",
      "epoch 14; iter: 200; batch classifier loss: 0.423873; batch adversarial loss: 0.332077\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302278; batch adversarial loss: 0.468427\n",
      "epoch 15; iter: 200; batch classifier loss: 0.374184; batch adversarial loss: 0.524554\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354283; batch adversarial loss: 0.301302\n",
      "epoch 16; iter: 200; batch classifier loss: 0.457457; batch adversarial loss: 0.434231\n",
      "epoch 17; iter: 0; batch classifier loss: 0.417183; batch adversarial loss: 0.497467\n",
      "epoch 17; iter: 200; batch classifier loss: 0.370868; batch adversarial loss: 0.368315\n",
      "epoch 18; iter: 0; batch classifier loss: 0.364589; batch adversarial loss: 0.429240\n",
      "epoch 18; iter: 200; batch classifier loss: 0.346419; batch adversarial loss: 0.361734\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400455; batch adversarial loss: 0.455987\n",
      "epoch 19; iter: 200; batch classifier loss: 0.410308; batch adversarial loss: 0.439463\n",
      "epoch 20; iter: 0; batch classifier loss: 0.393594; batch adversarial loss: 0.497327\n",
      "epoch 20; iter: 200; batch classifier loss: 0.359901; batch adversarial loss: 0.444877\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372554; batch adversarial loss: 0.289107\n",
      "epoch 21; iter: 200; batch classifier loss: 0.411437; batch adversarial loss: 0.454368\n",
      "epoch 22; iter: 0; batch classifier loss: 0.366442; batch adversarial loss: 0.451854\n",
      "epoch 22; iter: 200; batch classifier loss: 0.392741; batch adversarial loss: 0.358130\n",
      "epoch 23; iter: 0; batch classifier loss: 0.401830; batch adversarial loss: 0.506039\n",
      "epoch 23; iter: 200; batch classifier loss: 0.394857; batch adversarial loss: 0.363400\n",
      "epoch 24; iter: 0; batch classifier loss: 0.383157; batch adversarial loss: 0.549857\n",
      "epoch 24; iter: 200; batch classifier loss: 0.262158; batch adversarial loss: 0.487533\n",
      "epoch 25; iter: 0; batch classifier loss: 0.272614; batch adversarial loss: 0.392943\n",
      "epoch 25; iter: 200; batch classifier loss: 0.331033; batch adversarial loss: 0.411846\n",
      "epoch 26; iter: 0; batch classifier loss: 0.291276; batch adversarial loss: 0.348823\n",
      "epoch 26; iter: 200; batch classifier loss: 0.363284; batch adversarial loss: 0.429950\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325876; batch adversarial loss: 0.363365\n",
      "epoch 27; iter: 200; batch classifier loss: 0.405618; batch adversarial loss: 0.381385\n",
      "epoch 28; iter: 0; batch classifier loss: 0.367032; batch adversarial loss: 0.301019\n",
      "epoch 28; iter: 200; batch classifier loss: 0.418442; batch adversarial loss: 0.268056\n",
      "epoch 29; iter: 0; batch classifier loss: 0.375524; batch adversarial loss: 0.445713\n",
      "epoch 29; iter: 200; batch classifier loss: 0.371010; batch adversarial loss: 0.425662\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458108; batch adversarial loss: 0.439065\n",
      "epoch 30; iter: 200; batch classifier loss: 0.395979; batch adversarial loss: 0.457276\n",
      "epoch 31; iter: 0; batch classifier loss: 0.355130; batch adversarial loss: 0.420830\n",
      "epoch 31; iter: 200; batch classifier loss: 0.363173; batch adversarial loss: 0.474805\n",
      "epoch 32; iter: 0; batch classifier loss: 0.341238; batch adversarial loss: 0.437156\n",
      "epoch 32; iter: 200; batch classifier loss: 0.359470; batch adversarial loss: 0.443849\n",
      "epoch 33; iter: 0; batch classifier loss: 0.315547; batch adversarial loss: 0.556059\n",
      "epoch 33; iter: 200; batch classifier loss: 0.259430; batch adversarial loss: 0.425951\n",
      "epoch 34; iter: 0; batch classifier loss: 0.332424; batch adversarial loss: 0.331871\n",
      "epoch 34; iter: 200; batch classifier loss: 0.374863; batch adversarial loss: 0.385503\n",
      "epoch 35; iter: 0; batch classifier loss: 0.310625; batch adversarial loss: 0.411362\n",
      "epoch 35; iter: 200; batch classifier loss: 0.381844; batch adversarial loss: 0.401179\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347806; batch adversarial loss: 0.312699\n",
      "epoch 36; iter: 200; batch classifier loss: 0.313991; batch adversarial loss: 0.399534\n",
      "epoch 37; iter: 0; batch classifier loss: 0.276566; batch adversarial loss: 0.363630\n",
      "epoch 37; iter: 200; batch classifier loss: 0.277857; batch adversarial loss: 0.420465\n",
      "epoch 38; iter: 0; batch classifier loss: 0.260954; batch adversarial loss: 0.392538\n",
      "epoch 38; iter: 200; batch classifier loss: 0.343498; batch adversarial loss: 0.477424\n",
      "epoch 39; iter: 0; batch classifier loss: 0.316881; batch adversarial loss: 0.413095\n",
      "epoch 39; iter: 200; batch classifier loss: 0.365786; batch adversarial loss: 0.413587\n",
      "epoch 40; iter: 0; batch classifier loss: 0.388663; batch adversarial loss: 0.382025\n",
      "epoch 40; iter: 200; batch classifier loss: 0.382632; batch adversarial loss: 0.329124\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414769; batch adversarial loss: 0.373470\n",
      "epoch 41; iter: 200; batch classifier loss: 0.255044; batch adversarial loss: 0.305251\n",
      "epoch 42; iter: 0; batch classifier loss: 0.373273; batch adversarial loss: 0.425503\n",
      "epoch 42; iter: 200; batch classifier loss: 0.414445; batch adversarial loss: 0.360221\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401048; batch adversarial loss: 0.374354\n",
      "epoch 43; iter: 200; batch classifier loss: 0.374036; batch adversarial loss: 0.405238\n",
      "epoch 44; iter: 0; batch classifier loss: 0.417225; batch adversarial loss: 0.385709\n",
      "epoch 44; iter: 200; batch classifier loss: 0.418990; batch adversarial loss: 0.367088\n",
      "epoch 45; iter: 0; batch classifier loss: 0.245874; batch adversarial loss: 0.353678\n",
      "epoch 45; iter: 200; batch classifier loss: 0.386338; batch adversarial loss: 0.399836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.345493; batch adversarial loss: 0.351531\n",
      "epoch 46; iter: 200; batch classifier loss: 0.399034; batch adversarial loss: 0.346802\n",
      "epoch 47; iter: 0; batch classifier loss: 0.258804; batch adversarial loss: 0.402199\n",
      "epoch 47; iter: 200; batch classifier loss: 0.265536; batch adversarial loss: 0.443438\n",
      "epoch 48; iter: 0; batch classifier loss: 0.431209; batch adversarial loss: 0.477577\n",
      "epoch 48; iter: 200; batch classifier loss: 0.328628; batch adversarial loss: 0.448364\n",
      "epoch 49; iter: 0; batch classifier loss: 0.309430; batch adversarial loss: 0.349261\n",
      "epoch 49; iter: 200; batch classifier loss: 0.292352; batch adversarial loss: 0.417085\n",
      "epoch 0; iter: 0; batch classifier loss: 61.896492; batch adversarial loss: 1.308627\n",
      "epoch 0; iter: 200; batch classifier loss: 6.186624; batch adversarial loss: 0.670238\n",
      "epoch 1; iter: 0; batch classifier loss: 0.542507; batch adversarial loss: 0.660010\n",
      "epoch 1; iter: 200; batch classifier loss: 1.715928; batch adversarial loss: 0.613891\n",
      "epoch 2; iter: 0; batch classifier loss: 4.411317; batch adversarial loss: 0.562164\n",
      "epoch 2; iter: 200; batch classifier loss: 3.271655; batch adversarial loss: 0.604326\n",
      "epoch 3; iter: 0; batch classifier loss: 2.169324; batch adversarial loss: 0.579292\n",
      "epoch 3; iter: 200; batch classifier loss: 2.448600; batch adversarial loss: 0.467938\n",
      "epoch 4; iter: 0; batch classifier loss: 3.830491; batch adversarial loss: 0.490641\n",
      "epoch 4; iter: 200; batch classifier loss: 1.477551; batch adversarial loss: 0.484484\n",
      "epoch 5; iter: 0; batch classifier loss: 1.783283; batch adversarial loss: 0.471356\n",
      "epoch 5; iter: 200; batch classifier loss: 1.405027; batch adversarial loss: 0.449598\n",
      "epoch 6; iter: 0; batch classifier loss: 1.431172; batch adversarial loss: 0.460403\n",
      "epoch 6; iter: 200; batch classifier loss: 0.441916; batch adversarial loss: 0.455645\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474045; batch adversarial loss: 0.412570\n",
      "epoch 7; iter: 200; batch classifier loss: 0.376134; batch adversarial loss: 0.343578\n",
      "epoch 8; iter: 0; batch classifier loss: 0.898987; batch adversarial loss: 0.420568\n",
      "epoch 8; iter: 200; batch classifier loss: 0.403481; batch adversarial loss: 0.327472\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437583; batch adversarial loss: 0.418846\n",
      "epoch 9; iter: 200; batch classifier loss: 0.801488; batch adversarial loss: 0.401868\n",
      "epoch 10; iter: 0; batch classifier loss: 0.637472; batch adversarial loss: 0.281836\n",
      "epoch 10; iter: 200; batch classifier loss: 0.483691; batch adversarial loss: 0.335995\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364372; batch adversarial loss: 0.385771\n",
      "epoch 11; iter: 200; batch classifier loss: 0.442017; batch adversarial loss: 0.354075\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367300; batch adversarial loss: 0.368465\n",
      "epoch 12; iter: 200; batch classifier loss: 0.419585; batch adversarial loss: 0.422818\n",
      "epoch 13; iter: 0; batch classifier loss: 0.393005; batch adversarial loss: 0.431188\n",
      "epoch 13; iter: 200; batch classifier loss: 0.515885; batch adversarial loss: 0.389071\n",
      "epoch 14; iter: 0; batch classifier loss: 0.382725; batch adversarial loss: 0.433432\n",
      "epoch 14; iter: 200; batch classifier loss: 0.429506; batch adversarial loss: 0.356026\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314872; batch adversarial loss: 0.514050\n",
      "epoch 15; iter: 200; batch classifier loss: 0.467724; batch adversarial loss: 0.416689\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377379; batch adversarial loss: 0.436123\n",
      "epoch 16; iter: 200; batch classifier loss: 0.409755; batch adversarial loss: 0.386158\n",
      "epoch 17; iter: 0; batch classifier loss: 0.394936; batch adversarial loss: 0.423907\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341942; batch adversarial loss: 0.423473\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348817; batch adversarial loss: 0.363896\n",
      "epoch 18; iter: 200; batch classifier loss: 0.332151; batch adversarial loss: 0.379147\n",
      "epoch 19; iter: 0; batch classifier loss: 0.328726; batch adversarial loss: 0.350968\n",
      "epoch 19; iter: 200; batch classifier loss: 0.482147; batch adversarial loss: 0.490197\n",
      "epoch 20; iter: 0; batch classifier loss: 0.386700; batch adversarial loss: 0.316855\n",
      "epoch 20; iter: 200; batch classifier loss: 0.317262; batch adversarial loss: 0.430827\n",
      "epoch 21; iter: 0; batch classifier loss: 0.390945; batch adversarial loss: 0.522699\n",
      "epoch 21; iter: 200; batch classifier loss: 0.269397; batch adversarial loss: 0.405687\n",
      "epoch 22; iter: 0; batch classifier loss: 0.352896; batch adversarial loss: 0.374988\n",
      "epoch 22; iter: 200; batch classifier loss: 0.344157; batch adversarial loss: 0.341282\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310071; batch adversarial loss: 0.422474\n",
      "epoch 23; iter: 200; batch classifier loss: 0.377176; batch adversarial loss: 0.462668\n",
      "epoch 24; iter: 0; batch classifier loss: 0.334389; batch adversarial loss: 0.466738\n",
      "epoch 24; iter: 200; batch classifier loss: 0.381079; batch adversarial loss: 0.333959\n",
      "epoch 25; iter: 0; batch classifier loss: 0.296912; batch adversarial loss: 0.346566\n",
      "epoch 25; iter: 200; batch classifier loss: 0.436646; batch adversarial loss: 0.495660\n",
      "epoch 26; iter: 0; batch classifier loss: 0.336060; batch adversarial loss: 0.453296\n",
      "epoch 26; iter: 200; batch classifier loss: 0.400343; batch adversarial loss: 0.552238\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352404; batch adversarial loss: 0.466592\n",
      "epoch 27; iter: 200; batch classifier loss: 0.367057; batch adversarial loss: 0.473317\n",
      "epoch 28; iter: 0; batch classifier loss: 0.335306; batch adversarial loss: 0.422115\n",
      "epoch 28; iter: 200; batch classifier loss: 0.356620; batch adversarial loss: 0.444172\n",
      "epoch 29; iter: 0; batch classifier loss: 0.269360; batch adversarial loss: 0.308475\n",
      "epoch 29; iter: 200; batch classifier loss: 0.397744; batch adversarial loss: 0.428599\n",
      "epoch 30; iter: 0; batch classifier loss: 0.302456; batch adversarial loss: 0.377894\n",
      "epoch 30; iter: 200; batch classifier loss: 0.391650; batch adversarial loss: 0.412237\n",
      "epoch 31; iter: 0; batch classifier loss: 0.255302; batch adversarial loss: 0.406008\n",
      "epoch 31; iter: 200; batch classifier loss: 0.318134; batch adversarial loss: 0.472133\n",
      "epoch 32; iter: 0; batch classifier loss: 0.349639; batch adversarial loss: 0.467278\n",
      "epoch 32; iter: 200; batch classifier loss: 0.432506; batch adversarial loss: 0.371794\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426829; batch adversarial loss: 0.491288\n",
      "epoch 33; iter: 200; batch classifier loss: 0.378214; batch adversarial loss: 0.465948\n",
      "epoch 34; iter: 0; batch classifier loss: 0.383204; batch adversarial loss: 0.374965\n",
      "epoch 34; iter: 200; batch classifier loss: 0.266475; batch adversarial loss: 0.447090\n",
      "epoch 35; iter: 0; batch classifier loss: 0.340226; batch adversarial loss: 0.453874\n",
      "epoch 35; iter: 200; batch classifier loss: 0.373091; batch adversarial loss: 0.394067\n",
      "epoch 36; iter: 0; batch classifier loss: 0.369025; batch adversarial loss: 0.400287\n",
      "epoch 36; iter: 200; batch classifier loss: 0.370196; batch adversarial loss: 0.453541\n",
      "epoch 37; iter: 0; batch classifier loss: 0.337838; batch adversarial loss: 0.345980\n",
      "epoch 37; iter: 200; batch classifier loss: 0.374123; batch adversarial loss: 0.382835\n",
      "epoch 38; iter: 0; batch classifier loss: 0.325477; batch adversarial loss: 0.430440\n",
      "epoch 38; iter: 200; batch classifier loss: 0.388838; batch adversarial loss: 0.331486\n",
      "epoch 39; iter: 0; batch classifier loss: 0.324380; batch adversarial loss: 0.435064\n",
      "epoch 39; iter: 200; batch classifier loss: 0.281322; batch adversarial loss: 0.406247\n",
      "epoch 40; iter: 0; batch classifier loss: 0.352301; batch adversarial loss: 0.363866\n",
      "epoch 40; iter: 200; batch classifier loss: 0.367298; batch adversarial loss: 0.469435\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402384; batch adversarial loss: 0.405846\n",
      "epoch 41; iter: 200; batch classifier loss: 0.308957; batch adversarial loss: 0.417839\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391958; batch adversarial loss: 0.425933\n",
      "epoch 42; iter: 200; batch classifier loss: 0.278526; batch adversarial loss: 0.349886\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402511; batch adversarial loss: 0.391798\n",
      "epoch 43; iter: 200; batch classifier loss: 0.338914; batch adversarial loss: 0.370878\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336245; batch adversarial loss: 0.419924\n",
      "epoch 44; iter: 200; batch classifier loss: 0.427978; batch adversarial loss: 0.445181\n",
      "epoch 45; iter: 0; batch classifier loss: 0.359042; batch adversarial loss: 0.336746\n",
      "epoch 45; iter: 200; batch classifier loss: 0.279627; batch adversarial loss: 0.374464\n",
      "epoch 46; iter: 0; batch classifier loss: 0.310564; batch adversarial loss: 0.399756\n",
      "epoch 46; iter: 200; batch classifier loss: 0.419867; batch adversarial loss: 0.304206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.341059; batch adversarial loss: 0.384661\n",
      "epoch 47; iter: 200; batch classifier loss: 0.301791; batch adversarial loss: 0.486699\n",
      "epoch 48; iter: 0; batch classifier loss: 0.341543; batch adversarial loss: 0.471596\n",
      "epoch 48; iter: 200; batch classifier loss: 0.442277; batch adversarial loss: 0.382515\n",
      "epoch 49; iter: 0; batch classifier loss: 0.337362; batch adversarial loss: 0.415941\n",
      "epoch 49; iter: 200; batch classifier loss: 0.323479; batch adversarial loss: 0.390370\n",
      "epoch 0; iter: 0; batch classifier loss: 101.619003; batch adversarial loss: 0.626399\n",
      "epoch 0; iter: 200; batch classifier loss: 7.259393; batch adversarial loss: 0.572650\n",
      "epoch 1; iter: 0; batch classifier loss: 4.483171; batch adversarial loss: 0.566387\n",
      "epoch 1; iter: 200; batch classifier loss: 3.459625; batch adversarial loss: 0.442783\n",
      "epoch 2; iter: 0; batch classifier loss: 2.666586; batch adversarial loss: 0.489707\n",
      "epoch 2; iter: 200; batch classifier loss: 1.711616; batch adversarial loss: 0.474214\n",
      "epoch 3; iter: 0; batch classifier loss: 4.867948; batch adversarial loss: 0.450502\n",
      "epoch 3; iter: 200; batch classifier loss: 2.272675; batch adversarial loss: 0.510676\n",
      "epoch 4; iter: 0; batch classifier loss: 2.362647; batch adversarial loss: 0.508986\n",
      "epoch 4; iter: 200; batch classifier loss: 2.335845; batch adversarial loss: 0.461229\n",
      "epoch 5; iter: 0; batch classifier loss: 2.381460; batch adversarial loss: 0.466046\n",
      "epoch 5; iter: 200; batch classifier loss: 0.611490; batch adversarial loss: 0.370479\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494226; batch adversarial loss: 0.406055\n",
      "epoch 6; iter: 200; batch classifier loss: 1.096759; batch adversarial loss: 0.382375\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498479; batch adversarial loss: 0.422261\n",
      "epoch 7; iter: 200; batch classifier loss: 0.496113; batch adversarial loss: 0.490315\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611054; batch adversarial loss: 0.468249\n",
      "epoch 8; iter: 200; batch classifier loss: 0.474334; batch adversarial loss: 0.407399\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416690; batch adversarial loss: 0.437026\n",
      "epoch 9; iter: 200; batch classifier loss: 0.502156; batch adversarial loss: 0.412126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.399079; batch adversarial loss: 0.439057\n",
      "epoch 10; iter: 200; batch classifier loss: 0.488167; batch adversarial loss: 0.479074\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548832; batch adversarial loss: 0.482281\n",
      "epoch 11; iter: 200; batch classifier loss: 0.356984; batch adversarial loss: 0.363572\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535444; batch adversarial loss: 0.465237\n",
      "epoch 12; iter: 200; batch classifier loss: 0.414551; batch adversarial loss: 0.469241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420845; batch adversarial loss: 0.360038\n",
      "epoch 13; iter: 200; batch classifier loss: 0.337137; batch adversarial loss: 0.402522\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297083; batch adversarial loss: 0.458786\n",
      "epoch 14; iter: 200; batch classifier loss: 0.299217; batch adversarial loss: 0.356493\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376554; batch adversarial loss: 0.389285\n",
      "epoch 15; iter: 200; batch classifier loss: 0.316778; batch adversarial loss: 0.429503\n",
      "epoch 16; iter: 0; batch classifier loss: 0.401112; batch adversarial loss: 0.373009\n",
      "epoch 16; iter: 200; batch classifier loss: 0.295115; batch adversarial loss: 0.437837\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335885; batch adversarial loss: 0.366374\n",
      "epoch 17; iter: 200; batch classifier loss: 0.253564; batch adversarial loss: 0.381411\n",
      "epoch 18; iter: 0; batch classifier loss: 0.293262; batch adversarial loss: 0.533922\n",
      "epoch 18; iter: 200; batch classifier loss: 0.365286; batch adversarial loss: 0.356406\n",
      "epoch 19; iter: 0; batch classifier loss: 0.284041; batch adversarial loss: 0.425763\n",
      "epoch 19; iter: 200; batch classifier loss: 0.336026; batch adversarial loss: 0.392165\n",
      "epoch 20; iter: 0; batch classifier loss: 0.420903; batch adversarial loss: 0.417636\n",
      "epoch 20; iter: 200; batch classifier loss: 0.335624; batch adversarial loss: 0.404241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285747; batch adversarial loss: 0.432018\n",
      "epoch 21; iter: 200; batch classifier loss: 0.344712; batch adversarial loss: 0.383559\n",
      "epoch 22; iter: 0; batch classifier loss: 0.390735; batch adversarial loss: 0.466325\n",
      "epoch 22; iter: 200; batch classifier loss: 0.343967; batch adversarial loss: 0.408365\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351256; batch adversarial loss: 0.458171\n",
      "epoch 23; iter: 200; batch classifier loss: 0.365366; batch adversarial loss: 0.337990\n",
      "epoch 24; iter: 0; batch classifier loss: 0.354301; batch adversarial loss: 0.279273\n",
      "epoch 24; iter: 200; batch classifier loss: 0.349747; batch adversarial loss: 0.426429\n",
      "epoch 25; iter: 0; batch classifier loss: 0.364459; batch adversarial loss: 0.476856\n",
      "epoch 25; iter: 200; batch classifier loss: 0.369807; batch adversarial loss: 0.398529\n",
      "epoch 26; iter: 0; batch classifier loss: 0.410546; batch adversarial loss: 0.468256\n",
      "epoch 26; iter: 200; batch classifier loss: 0.415424; batch adversarial loss: 0.506535\n",
      "epoch 27; iter: 0; batch classifier loss: 0.357955; batch adversarial loss: 0.455128\n",
      "epoch 27; iter: 200; batch classifier loss: 0.351368; batch adversarial loss: 0.460249\n",
      "epoch 28; iter: 0; batch classifier loss: 0.361645; batch adversarial loss: 0.367207\n",
      "epoch 28; iter: 200; batch classifier loss: 0.296226; batch adversarial loss: 0.351578\n",
      "epoch 29; iter: 0; batch classifier loss: 0.326991; batch adversarial loss: 0.398429\n",
      "epoch 29; iter: 200; batch classifier loss: 0.320665; batch adversarial loss: 0.408899\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407205; batch adversarial loss: 0.416131\n",
      "epoch 30; iter: 200; batch classifier loss: 0.386823; batch adversarial loss: 0.430765\n",
      "epoch 31; iter: 0; batch classifier loss: 0.265766; batch adversarial loss: 0.434807\n",
      "epoch 31; iter: 200; batch classifier loss: 0.253562; batch adversarial loss: 0.536720\n",
      "epoch 32; iter: 0; batch classifier loss: 0.339207; batch adversarial loss: 0.432470\n",
      "epoch 32; iter: 200; batch classifier loss: 0.648985; batch adversarial loss: 0.366891\n",
      "epoch 33; iter: 0; batch classifier loss: 0.328725; batch adversarial loss: 0.500851\n",
      "epoch 33; iter: 200; batch classifier loss: 0.502009; batch adversarial loss: 0.400962\n",
      "epoch 34; iter: 0; batch classifier loss: 0.335519; batch adversarial loss: 0.498098\n",
      "epoch 34; iter: 200; batch classifier loss: 0.418837; batch adversarial loss: 0.356859\n",
      "epoch 35; iter: 0; batch classifier loss: 0.330575; batch adversarial loss: 0.453906\n",
      "epoch 35; iter: 200; batch classifier loss: 0.309798; batch adversarial loss: 0.390041\n",
      "epoch 36; iter: 0; batch classifier loss: 0.384194; batch adversarial loss: 0.392882\n",
      "epoch 36; iter: 200; batch classifier loss: 0.275940; batch adversarial loss: 0.339790\n",
      "epoch 37; iter: 0; batch classifier loss: 0.240092; batch adversarial loss: 0.466142\n",
      "epoch 37; iter: 200; batch classifier loss: 0.299144; batch adversarial loss: 0.372978\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453159; batch adversarial loss: 0.463778\n",
      "epoch 38; iter: 200; batch classifier loss: 0.302106; batch adversarial loss: 0.400993\n",
      "epoch 39; iter: 0; batch classifier loss: 0.297557; batch adversarial loss: 0.476913\n",
      "epoch 39; iter: 200; batch classifier loss: 0.203437; batch adversarial loss: 0.390305\n",
      "epoch 40; iter: 0; batch classifier loss: 0.289127; batch adversarial loss: 0.481959\n",
      "epoch 40; iter: 200; batch classifier loss: 0.291603; batch adversarial loss: 0.388820\n",
      "epoch 41; iter: 0; batch classifier loss: 0.324802; batch adversarial loss: 0.408912\n",
      "epoch 41; iter: 200; batch classifier loss: 0.338843; batch adversarial loss: 0.362310\n",
      "epoch 42; iter: 0; batch classifier loss: 0.249766; batch adversarial loss: 0.392531\n",
      "epoch 42; iter: 200; batch classifier loss: 0.311884; batch adversarial loss: 0.445872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.315476; batch adversarial loss: 0.432444\n",
      "epoch 43; iter: 200; batch classifier loss: 0.229984; batch adversarial loss: 0.411337\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396437; batch adversarial loss: 0.341772\n",
      "epoch 44; iter: 200; batch classifier loss: 0.386823; batch adversarial loss: 0.420374\n",
      "epoch 45; iter: 0; batch classifier loss: 0.313023; batch adversarial loss: 0.350356\n",
      "epoch 45; iter: 200; batch classifier loss: 0.254328; batch adversarial loss: 0.366000\n",
      "epoch 46; iter: 0; batch classifier loss: 0.366911; batch adversarial loss: 0.432730\n",
      "epoch 46; iter: 200; batch classifier loss: 0.403608; batch adversarial loss: 0.434162\n",
      "epoch 47; iter: 0; batch classifier loss: 0.361594; batch adversarial loss: 0.367597\n",
      "epoch 47; iter: 200; batch classifier loss: 0.366315; batch adversarial loss: 0.402338\n",
      "epoch 48; iter: 0; batch classifier loss: 0.295370; batch adversarial loss: 0.415977\n",
      "epoch 48; iter: 200; batch classifier loss: 0.272648; batch adversarial loss: 0.445792\n",
      "epoch 49; iter: 0; batch classifier loss: 0.329120; batch adversarial loss: 0.402707\n",
      "epoch 49; iter: 200; batch classifier loss: 0.441643; batch adversarial loss: 0.390966\n",
      "epoch 0; iter: 0; batch classifier loss: 14.621469; batch adversarial loss: 0.497429\n",
      "epoch 0; iter: 200; batch classifier loss: 12.416837; batch adversarial loss: 0.519232\n",
      "epoch 1; iter: 0; batch classifier loss: 6.718459; batch adversarial loss: 0.543818\n",
      "epoch 1; iter: 200; batch classifier loss: 12.321181; batch adversarial loss: 0.501458\n",
      "epoch 2; iter: 0; batch classifier loss: 3.701050; batch adversarial loss: 0.493165\n",
      "epoch 2; iter: 200; batch classifier loss: 4.707971; batch adversarial loss: 0.475881\n",
      "epoch 3; iter: 0; batch classifier loss: 4.754768; batch adversarial loss: 0.470470\n",
      "epoch 3; iter: 200; batch classifier loss: 3.423002; batch adversarial loss: 0.460002\n",
      "epoch 4; iter: 0; batch classifier loss: 0.732368; batch adversarial loss: 0.397211\n",
      "epoch 4; iter: 200; batch classifier loss: 1.226161; batch adversarial loss: 0.431432\n",
      "epoch 5; iter: 0; batch classifier loss: 1.803593; batch adversarial loss: 0.400393\n",
      "epoch 5; iter: 200; batch classifier loss: 0.633714; batch adversarial loss: 0.460246\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557282; batch adversarial loss: 0.455581\n",
      "epoch 6; iter: 200; batch classifier loss: 3.503223; batch adversarial loss: 0.451721\n",
      "epoch 7; iter: 0; batch classifier loss: 0.450413; batch adversarial loss: 0.480480\n",
      "epoch 7; iter: 200; batch classifier loss: 0.688892; batch adversarial loss: 0.403911\n",
      "epoch 8; iter: 0; batch classifier loss: 0.672178; batch adversarial loss: 0.347368\n",
      "epoch 8; iter: 200; batch classifier loss: 0.611868; batch adversarial loss: 0.478478\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602781; batch adversarial loss: 0.542401\n",
      "epoch 9; iter: 200; batch classifier loss: 0.302828; batch adversarial loss: 0.380058\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367087; batch adversarial loss: 0.413582\n",
      "epoch 10; iter: 200; batch classifier loss: 0.453933; batch adversarial loss: 0.405763\n",
      "epoch 11; iter: 0; batch classifier loss: 0.510076; batch adversarial loss: 0.504089\n",
      "epoch 11; iter: 200; batch classifier loss: 0.330417; batch adversarial loss: 0.423929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346512; batch adversarial loss: 0.396867\n",
      "epoch 12; iter: 200; batch classifier loss: 0.397523; batch adversarial loss: 0.369572\n",
      "epoch 13; iter: 0; batch classifier loss: 0.322269; batch adversarial loss: 0.371237\n",
      "epoch 13; iter: 200; batch classifier loss: 0.423570; batch adversarial loss: 0.305967\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395296; batch adversarial loss: 0.434748\n",
      "epoch 14; iter: 200; batch classifier loss: 0.584772; batch adversarial loss: 0.385729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.283969; batch adversarial loss: 0.382847\n",
      "epoch 15; iter: 200; batch classifier loss: 0.433856; batch adversarial loss: 0.379031\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364911; batch adversarial loss: 0.374051\n",
      "epoch 16; iter: 200; batch classifier loss: 0.297495; batch adversarial loss: 0.334701\n",
      "epoch 17; iter: 0; batch classifier loss: 0.355880; batch adversarial loss: 0.361515\n",
      "epoch 17; iter: 200; batch classifier loss: 0.323289; batch adversarial loss: 0.619099\n",
      "epoch 18; iter: 0; batch classifier loss: 0.280423; batch adversarial loss: 0.418049\n",
      "epoch 18; iter: 200; batch classifier loss: 0.320200; batch adversarial loss: 0.476434\n",
      "epoch 19; iter: 0; batch classifier loss: 0.347415; batch adversarial loss: 0.501454\n",
      "epoch 19; iter: 200; batch classifier loss: 0.364693; batch adversarial loss: 0.332192\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288919; batch adversarial loss: 0.468477\n",
      "epoch 20; iter: 200; batch classifier loss: 0.496722; batch adversarial loss: 0.418593\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387791; batch adversarial loss: 0.353570\n",
      "epoch 21; iter: 200; batch classifier loss: 0.402892; batch adversarial loss: 0.472222\n",
      "epoch 22; iter: 0; batch classifier loss: 0.383758; batch adversarial loss: 0.419706\n",
      "epoch 22; iter: 200; batch classifier loss: 0.311349; batch adversarial loss: 0.422784\n",
      "epoch 23; iter: 0; batch classifier loss: 0.346054; batch adversarial loss: 0.375776\n",
      "epoch 23; iter: 200; batch classifier loss: 0.313863; batch adversarial loss: 0.467082\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364027; batch adversarial loss: 0.321061\n",
      "epoch 24; iter: 200; batch classifier loss: 0.433749; batch adversarial loss: 0.390036\n",
      "epoch 25; iter: 0; batch classifier loss: 0.307158; batch adversarial loss: 0.325608\n",
      "epoch 25; iter: 200; batch classifier loss: 0.381281; batch adversarial loss: 0.405622\n",
      "epoch 26; iter: 0; batch classifier loss: 0.409471; batch adversarial loss: 0.363056\n",
      "epoch 26; iter: 200; batch classifier loss: 0.337804; batch adversarial loss: 0.411813\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330447; batch adversarial loss: 0.457211\n",
      "epoch 27; iter: 200; batch classifier loss: 0.356014; batch adversarial loss: 0.405074\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342061; batch adversarial loss: 0.394200\n",
      "epoch 28; iter: 200; batch classifier loss: 0.384206; batch adversarial loss: 0.361289\n",
      "epoch 29; iter: 0; batch classifier loss: 0.247793; batch adversarial loss: 0.547323\n",
      "epoch 29; iter: 200; batch classifier loss: 0.391420; batch adversarial loss: 0.312109\n",
      "epoch 30; iter: 0; batch classifier loss: 0.368652; batch adversarial loss: 0.553070\n",
      "epoch 30; iter: 200; batch classifier loss: 0.405882; batch adversarial loss: 0.433631\n",
      "epoch 31; iter: 0; batch classifier loss: 0.682613; batch adversarial loss: 0.403942\n",
      "epoch 31; iter: 200; batch classifier loss: 0.261990; batch adversarial loss: 0.521618\n",
      "epoch 32; iter: 0; batch classifier loss: 0.294597; batch adversarial loss: 0.464970\n",
      "epoch 32; iter: 200; batch classifier loss: 0.372275; batch adversarial loss: 0.461755\n",
      "epoch 33; iter: 0; batch classifier loss: 0.354824; batch adversarial loss: 0.321780\n",
      "epoch 33; iter: 200; batch classifier loss: 0.356412; batch adversarial loss: 0.481995\n",
      "epoch 34; iter: 0; batch classifier loss: 0.361535; batch adversarial loss: 0.359582\n",
      "epoch 34; iter: 200; batch classifier loss: 0.386124; batch adversarial loss: 0.301020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.360331; batch adversarial loss: 0.423411\n",
      "epoch 35; iter: 200; batch classifier loss: 0.398793; batch adversarial loss: 0.513998\n",
      "epoch 36; iter: 0; batch classifier loss: 0.331281; batch adversarial loss: 0.362861\n",
      "epoch 36; iter: 200; batch classifier loss: 0.517882; batch adversarial loss: 0.428130\n",
      "epoch 37; iter: 0; batch classifier loss: 0.401946; batch adversarial loss: 0.397402\n",
      "epoch 37; iter: 200; batch classifier loss: 0.438182; batch adversarial loss: 0.308906\n",
      "epoch 38; iter: 0; batch classifier loss: 0.545983; batch adversarial loss: 0.361067\n",
      "epoch 38; iter: 200; batch classifier loss: 0.458328; batch adversarial loss: 0.379174\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423615; batch adversarial loss: 0.460730\n",
      "epoch 39; iter: 200; batch classifier loss: 0.529250; batch adversarial loss: 0.375707\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394977; batch adversarial loss: 0.481581\n",
      "epoch 40; iter: 200; batch classifier loss: 0.484634; batch adversarial loss: 0.429811\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460330; batch adversarial loss: 0.431627\n",
      "epoch 41; iter: 200; batch classifier loss: 0.536861; batch adversarial loss: 0.424121\n",
      "epoch 42; iter: 0; batch classifier loss: 0.451766; batch adversarial loss: 0.362324\n",
      "epoch 42; iter: 200; batch classifier loss: 0.506354; batch adversarial loss: 0.451143\n",
      "epoch 43; iter: 0; batch classifier loss: 0.550195; batch adversarial loss: 0.396928\n",
      "epoch 43; iter: 200; batch classifier loss: 0.492076; batch adversarial loss: 0.458939\n",
      "epoch 44; iter: 0; batch classifier loss: 0.673191; batch adversarial loss: 0.358234\n",
      "epoch 44; iter: 200; batch classifier loss: 0.523166; batch adversarial loss: 0.498414\n",
      "epoch 45; iter: 0; batch classifier loss: 0.505747; batch adversarial loss: 0.333827\n",
      "epoch 45; iter: 200; batch classifier loss: 0.648032; batch adversarial loss: 0.506785\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383181; batch adversarial loss: 0.478189\n",
      "epoch 46; iter: 200; batch classifier loss: 0.470615; batch adversarial loss: 0.443593\n",
      "epoch 47; iter: 0; batch classifier loss: 0.606532; batch adversarial loss: 0.434159\n",
      "epoch 47; iter: 200; batch classifier loss: 0.561533; batch adversarial loss: 0.379769\n",
      "epoch 48; iter: 0; batch classifier loss: 0.513968; batch adversarial loss: 0.450125\n",
      "epoch 48; iter: 200; batch classifier loss: 0.421348; batch adversarial loss: 0.338061\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451352; batch adversarial loss: 0.488275\n",
      "epoch 49; iter: 200; batch classifier loss: 0.491773; batch adversarial loss: 0.497945\n",
      "epoch 0; iter: 0; batch classifier loss: 19.029253; batch adversarial loss: 1.266970\n",
      "epoch 0; iter: 200; batch classifier loss: 19.205563; batch adversarial loss: 0.956952\n",
      "epoch 1; iter: 0; batch classifier loss: 5.088072; batch adversarial loss: 0.823494\n",
      "epoch 1; iter: 200; batch classifier loss: 6.517323; batch adversarial loss: 0.592358\n",
      "epoch 2; iter: 0; batch classifier loss: 7.381807; batch adversarial loss: 0.600734\n",
      "epoch 2; iter: 200; batch classifier loss: 0.873527; batch adversarial loss: 0.524786\n",
      "epoch 3; iter: 0; batch classifier loss: 1.056704; batch adversarial loss: 0.517443\n",
      "epoch 3; iter: 200; batch classifier loss: 2.661552; batch adversarial loss: 0.502647\n",
      "epoch 4; iter: 0; batch classifier loss: 1.052504; batch adversarial loss: 0.516826\n",
      "epoch 4; iter: 200; batch classifier loss: 1.951190; batch adversarial loss: 0.399148\n",
      "epoch 5; iter: 0; batch classifier loss: 0.404895; batch adversarial loss: 0.423497\n",
      "epoch 5; iter: 200; batch classifier loss: 0.659396; batch adversarial loss: 0.456795\n",
      "epoch 6; iter: 0; batch classifier loss: 1.181468; batch adversarial loss: 0.474917\n",
      "epoch 6; iter: 200; batch classifier loss: 1.268504; batch adversarial loss: 0.412955\n",
      "epoch 7; iter: 0; batch classifier loss: 0.665487; batch adversarial loss: 0.363175\n",
      "epoch 7; iter: 200; batch classifier loss: 0.358242; batch adversarial loss: 0.442427\n",
      "epoch 8; iter: 0; batch classifier loss: 0.406946; batch adversarial loss: 0.409210\n",
      "epoch 8; iter: 200; batch classifier loss: 0.867717; batch adversarial loss: 0.495705\n",
      "epoch 9; iter: 0; batch classifier loss: 0.459227; batch adversarial loss: 0.427134\n",
      "epoch 9; iter: 200; batch classifier loss: 0.482909; batch adversarial loss: 0.377805\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310516; batch adversarial loss: 0.504232\n",
      "epoch 10; iter: 200; batch classifier loss: 0.364516; batch adversarial loss: 0.451170\n",
      "epoch 11; iter: 0; batch classifier loss: 0.397918; batch adversarial loss: 0.519123\n",
      "epoch 11; iter: 200; batch classifier loss: 0.413864; batch adversarial loss: 0.457411\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365564; batch adversarial loss: 0.386131\n",
      "epoch 12; iter: 200; batch classifier loss: 0.422647; batch adversarial loss: 0.427122\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285631; batch adversarial loss: 0.320182\n",
      "epoch 13; iter: 200; batch classifier loss: 0.340538; batch adversarial loss: 0.368677\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403585; batch adversarial loss: 0.448916\n",
      "epoch 14; iter: 200; batch classifier loss: 0.348154; batch adversarial loss: 0.428393\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507829; batch adversarial loss: 0.456446\n",
      "epoch 15; iter: 200; batch classifier loss: 0.448299; batch adversarial loss: 0.539380\n",
      "epoch 16; iter: 0; batch classifier loss: 0.388709; batch adversarial loss: 0.361961\n",
      "epoch 16; iter: 200; batch classifier loss: 0.401900; batch adversarial loss: 0.381761\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329767; batch adversarial loss: 0.438067\n",
      "epoch 17; iter: 200; batch classifier loss: 1.001352; batch adversarial loss: 0.390329\n",
      "epoch 18; iter: 0; batch classifier loss: 0.385035; batch adversarial loss: 0.417471\n",
      "epoch 18; iter: 200; batch classifier loss: 0.330534; batch adversarial loss: 0.459312\n",
      "epoch 19; iter: 0; batch classifier loss: 0.347683; batch adversarial loss: 0.409548\n",
      "epoch 19; iter: 200; batch classifier loss: 0.345029; batch adversarial loss: 0.426813\n",
      "epoch 20; iter: 0; batch classifier loss: 0.383244; batch adversarial loss: 0.505892\n",
      "epoch 20; iter: 200; batch classifier loss: 0.376423; batch adversarial loss: 0.339280\n",
      "epoch 21; iter: 0; batch classifier loss: 0.292474; batch adversarial loss: 0.457886\n",
      "epoch 21; iter: 200; batch classifier loss: 0.503538; batch adversarial loss: 0.358731\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415820; batch adversarial loss: 0.421140\n",
      "epoch 22; iter: 200; batch classifier loss: 0.344884; batch adversarial loss: 0.453399\n",
      "epoch 23; iter: 0; batch classifier loss: 0.374797; batch adversarial loss: 0.390769\n",
      "epoch 23; iter: 200; batch classifier loss: 0.366229; batch adversarial loss: 0.428115\n",
      "epoch 24; iter: 0; batch classifier loss: 0.366417; batch adversarial loss: 0.393212\n",
      "epoch 24; iter: 200; batch classifier loss: 0.350086; batch adversarial loss: 0.282994\n",
      "epoch 25; iter: 0; batch classifier loss: 0.401282; batch adversarial loss: 0.444674\n",
      "epoch 25; iter: 200; batch classifier loss: 0.344859; batch adversarial loss: 0.405446\n",
      "epoch 26; iter: 0; batch classifier loss: 0.306794; batch adversarial loss: 0.428204\n",
      "epoch 26; iter: 200; batch classifier loss: 0.332133; batch adversarial loss: 0.368603\n",
      "epoch 27; iter: 0; batch classifier loss: 0.340628; batch adversarial loss: 0.331798\n",
      "epoch 27; iter: 200; batch classifier loss: 0.335920; batch adversarial loss: 0.413839\n",
      "epoch 28; iter: 0; batch classifier loss: 0.331846; batch adversarial loss: 0.495192\n",
      "epoch 28; iter: 200; batch classifier loss: 0.312976; batch adversarial loss: 0.431698\n",
      "epoch 29; iter: 0; batch classifier loss: 0.330211; batch adversarial loss: 0.478852\n",
      "epoch 29; iter: 200; batch classifier loss: 0.366070; batch adversarial loss: 0.389323\n",
      "epoch 30; iter: 0; batch classifier loss: 0.272318; batch adversarial loss: 0.506236\n",
      "epoch 30; iter: 200; batch classifier loss: 0.359942; batch adversarial loss: 0.391532\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417431; batch adversarial loss: 0.348053\n",
      "epoch 31; iter: 200; batch classifier loss: 0.309806; batch adversarial loss: 0.334428\n",
      "epoch 32; iter: 0; batch classifier loss: 0.294628; batch adversarial loss: 0.409268\n",
      "epoch 32; iter: 200; batch classifier loss: 0.422977; batch adversarial loss: 0.333696\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363094; batch adversarial loss: 0.439503\n",
      "epoch 33; iter: 200; batch classifier loss: 0.376978; batch adversarial loss: 0.433080\n",
      "epoch 34; iter: 0; batch classifier loss: 0.302421; batch adversarial loss: 0.450651\n",
      "epoch 34; iter: 200; batch classifier loss: 0.295630; batch adversarial loss: 0.404945\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434973; batch adversarial loss: 0.483340\n",
      "epoch 35; iter: 200; batch classifier loss: 0.297703; batch adversarial loss: 0.412002\n",
      "epoch 36; iter: 0; batch classifier loss: 0.327820; batch adversarial loss: 0.368912\n",
      "epoch 36; iter: 200; batch classifier loss: 0.424734; batch adversarial loss: 0.343084\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394489; batch adversarial loss: 0.399769\n",
      "epoch 37; iter: 200; batch classifier loss: 0.323842; batch adversarial loss: 0.429179\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447004; batch adversarial loss: 0.403992\n",
      "epoch 38; iter: 200; batch classifier loss: 0.468300; batch adversarial loss: 0.345728\n",
      "epoch 39; iter: 0; batch classifier loss: 0.328757; batch adversarial loss: 0.460917\n",
      "epoch 39; iter: 200; batch classifier loss: 0.457636; batch adversarial loss: 0.352706\n",
      "epoch 40; iter: 0; batch classifier loss: 0.473679; batch adversarial loss: 0.361978\n",
      "epoch 40; iter: 200; batch classifier loss: 0.390059; batch adversarial loss: 0.394022\n",
      "epoch 41; iter: 0; batch classifier loss: 0.356885; batch adversarial loss: 0.358036\n",
      "epoch 41; iter: 200; batch classifier loss: 0.402733; batch adversarial loss: 0.506527\n",
      "epoch 42; iter: 0; batch classifier loss: 0.473812; batch adversarial loss: 0.366392\n",
      "epoch 42; iter: 200; batch classifier loss: 0.448725; batch adversarial loss: 0.403513\n",
      "epoch 43; iter: 0; batch classifier loss: 0.392447; batch adversarial loss: 0.476400\n",
      "epoch 43; iter: 200; batch classifier loss: 0.401733; batch adversarial loss: 0.413578\n",
      "epoch 44; iter: 0; batch classifier loss: 0.344932; batch adversarial loss: 0.304891\n",
      "epoch 44; iter: 200; batch classifier loss: 0.357929; batch adversarial loss: 0.382905\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398075; batch adversarial loss: 0.387408\n",
      "epoch 45; iter: 200; batch classifier loss: 0.598999; batch adversarial loss: 0.458052\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443510; batch adversarial loss: 0.390256\n",
      "epoch 46; iter: 200; batch classifier loss: 0.497279; batch adversarial loss: 0.408039\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505843; batch adversarial loss: 0.348905\n",
      "epoch 47; iter: 200; batch classifier loss: 0.392208; batch adversarial loss: 0.405357\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401336; batch adversarial loss: 0.478656\n",
      "epoch 48; iter: 200; batch classifier loss: 0.535098; batch adversarial loss: 0.429306\n",
      "epoch 49; iter: 0; batch classifier loss: 0.544689; batch adversarial loss: 0.369871\n",
      "epoch 49; iter: 200; batch classifier loss: 0.414410; batch adversarial loss: 0.363560\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.833424  0.572433 -0.004098  0.982503  0.125673  0.073716\n",
      "std   0.016395  0.074911  0.023715  0.160839  0.069346  0.041487\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    "    scope_name='adv',           \n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.1)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate\n",
    "adult_race_metrics = pd.DataFrame(results)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62585541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', 'Default Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fce3f2",
   "metadata": {},
   "source": [
    "## default adversial debiaser, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d433b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 4.419303; batch adversarial loss: 0.659783\n",
      "epoch 0; iter: 200; batch classifier loss: 19.950031; batch adversarial loss: 0.619075\n",
      "epoch 1; iter: 0; batch classifier loss: 8.170157; batch adversarial loss: 0.565668\n",
      "epoch 1; iter: 200; batch classifier loss: 3.687250; batch adversarial loss: 0.663067\n",
      "epoch 2; iter: 0; batch classifier loss: 5.828294; batch adversarial loss: 0.609867\n",
      "epoch 2; iter: 200; batch classifier loss: 3.980613; batch adversarial loss: 0.669920\n",
      "epoch 3; iter: 0; batch classifier loss: 4.614372; batch adversarial loss: 0.641021\n",
      "epoch 3; iter: 200; batch classifier loss: 1.879217; batch adversarial loss: 0.625236\n",
      "epoch 4; iter: 0; batch classifier loss: 2.555663; batch adversarial loss: 0.638144\n",
      "epoch 4; iter: 200; batch classifier loss: 1.196094; batch adversarial loss: 0.597470\n",
      "epoch 5; iter: 0; batch classifier loss: 0.649637; batch adversarial loss: 0.610009\n",
      "epoch 5; iter: 200; batch classifier loss: 0.503398; batch adversarial loss: 0.561846\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565505; batch adversarial loss: 0.701852\n",
      "epoch 6; iter: 200; batch classifier loss: 0.367417; batch adversarial loss: 0.576461\n",
      "epoch 7; iter: 0; batch classifier loss: 0.476597; batch adversarial loss: 0.655141\n",
      "epoch 7; iter: 200; batch classifier loss: 1.494949; batch adversarial loss: 0.640519\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509897; batch adversarial loss: 0.627347\n",
      "epoch 8; iter: 200; batch classifier loss: 0.775990; batch adversarial loss: 0.614242\n",
      "epoch 9; iter: 0; batch classifier loss: 0.791173; batch adversarial loss: 0.614777\n",
      "epoch 9; iter: 200; batch classifier loss: 0.398571; batch adversarial loss: 0.644567\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479358; batch adversarial loss: 0.632867\n",
      "epoch 10; iter: 200; batch classifier loss: 0.378320; batch adversarial loss: 0.618841\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489237; batch adversarial loss: 0.632217\n",
      "epoch 11; iter: 200; batch classifier loss: 0.469132; batch adversarial loss: 0.708108\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448899; batch adversarial loss: 0.603090\n",
      "epoch 12; iter: 200; batch classifier loss: 0.330676; batch adversarial loss: 0.659731\n",
      "epoch 13; iter: 0; batch classifier loss: 0.303513; batch adversarial loss: 0.655508\n",
      "epoch 13; iter: 200; batch classifier loss: 0.344252; batch adversarial loss: 0.687076\n",
      "epoch 14; iter: 0; batch classifier loss: 0.587122; batch adversarial loss: 0.603511\n",
      "epoch 14; iter: 200; batch classifier loss: 0.384014; batch adversarial loss: 0.646793\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359617; batch adversarial loss: 0.594061\n",
      "epoch 15; iter: 200; batch classifier loss: 0.349953; batch adversarial loss: 0.583761\n",
      "epoch 16; iter: 0; batch classifier loss: 0.236057; batch adversarial loss: 0.605958\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352945; batch adversarial loss: 0.643841\n",
      "epoch 17; iter: 0; batch classifier loss: 0.403225; batch adversarial loss: 0.634368\n",
      "epoch 17; iter: 200; batch classifier loss: 0.328406; batch adversarial loss: 0.650830\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332178; batch adversarial loss: 0.627399\n",
      "epoch 18; iter: 200; batch classifier loss: 0.364682; batch adversarial loss: 0.595623\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362718; batch adversarial loss: 0.588695\n",
      "epoch 19; iter: 200; batch classifier loss: 0.331339; batch adversarial loss: 0.629703\n",
      "epoch 20; iter: 0; batch classifier loss: 0.348115; batch adversarial loss: 0.661336\n",
      "epoch 20; iter: 200; batch classifier loss: 0.452877; batch adversarial loss: 0.579616\n",
      "epoch 21; iter: 0; batch classifier loss: 0.275083; batch adversarial loss: 0.678563\n",
      "epoch 21; iter: 200; batch classifier loss: 0.377642; batch adversarial loss: 0.644637\n",
      "epoch 22; iter: 0; batch classifier loss: 0.405905; batch adversarial loss: 0.644751\n",
      "epoch 22; iter: 200; batch classifier loss: 0.324614; batch adversarial loss: 0.594024\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344078; batch adversarial loss: 0.679983\n",
      "epoch 23; iter: 200; batch classifier loss: 0.368202; batch adversarial loss: 0.618930\n",
      "epoch 24; iter: 0; batch classifier loss: 0.375322; batch adversarial loss: 0.624142\n",
      "epoch 24; iter: 200; batch classifier loss: 0.366994; batch adversarial loss: 0.652620\n",
      "epoch 25; iter: 0; batch classifier loss: 0.356650; batch adversarial loss: 0.647820\n",
      "epoch 25; iter: 200; batch classifier loss: 0.377300; batch adversarial loss: 0.611224\n",
      "epoch 26; iter: 0; batch classifier loss: 0.410892; batch adversarial loss: 0.603851\n",
      "epoch 26; iter: 200; batch classifier loss: 0.432214; batch adversarial loss: 0.606504\n",
      "epoch 27; iter: 0; batch classifier loss: 0.675367; batch adversarial loss: 0.622691\n",
      "epoch 27; iter: 200; batch classifier loss: 0.552596; batch adversarial loss: 0.590389\n",
      "epoch 28; iter: 0; batch classifier loss: 0.344464; batch adversarial loss: 0.623470\n",
      "epoch 28; iter: 200; batch classifier loss: 0.437807; batch adversarial loss: 0.561438\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457269; batch adversarial loss: 0.613283\n",
      "epoch 29; iter: 200; batch classifier loss: 0.353321; batch adversarial loss: 0.624111\n",
      "epoch 30; iter: 0; batch classifier loss: 0.338735; batch adversarial loss: 0.588350\n",
      "epoch 30; iter: 200; batch classifier loss: 0.370635; batch adversarial loss: 0.617310\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496298; batch adversarial loss: 0.641898\n",
      "epoch 31; iter: 200; batch classifier loss: 0.373172; batch adversarial loss: 0.575142\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421063; batch adversarial loss: 0.619482\n",
      "epoch 32; iter: 200; batch classifier loss: 0.452890; batch adversarial loss: 0.606822\n",
      "epoch 33; iter: 0; batch classifier loss: 0.338054; batch adversarial loss: 0.645444\n",
      "epoch 33; iter: 200; batch classifier loss: 0.353254; batch adversarial loss: 0.621742\n",
      "epoch 34; iter: 0; batch classifier loss: 0.352917; batch adversarial loss: 0.648422\n",
      "epoch 34; iter: 200; batch classifier loss: 0.378310; batch adversarial loss: 0.694882\n",
      "epoch 35; iter: 0; batch classifier loss: 0.300176; batch adversarial loss: 0.661909\n",
      "epoch 35; iter: 200; batch classifier loss: 0.349846; batch adversarial loss: 0.594278\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389226; batch adversarial loss: 0.633058\n",
      "epoch 36; iter: 200; batch classifier loss: 0.403233; batch adversarial loss: 0.640347\n",
      "epoch 37; iter: 0; batch classifier loss: 0.361590; batch adversarial loss: 0.698115\n",
      "epoch 37; iter: 200; batch classifier loss: 0.304100; batch adversarial loss: 0.690043\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412647; batch adversarial loss: 0.660273\n",
      "epoch 38; iter: 200; batch classifier loss: 0.344252; batch adversarial loss: 0.674942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.608406; batch adversarial loss: 0.687408\n",
      "epoch 39; iter: 200; batch classifier loss: 0.374828; batch adversarial loss: 0.617893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440404; batch adversarial loss: 0.656902\n",
      "epoch 40; iter: 200; batch classifier loss: 0.428629; batch adversarial loss: 0.655051\n",
      "epoch 41; iter: 0; batch classifier loss: 0.337587; batch adversarial loss: 0.594296\n",
      "epoch 41; iter: 200; batch classifier loss: 0.309116; batch adversarial loss: 0.571406\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407205; batch adversarial loss: 0.620916\n",
      "epoch 42; iter: 200; batch classifier loss: 0.334730; batch adversarial loss: 0.655324\n",
      "epoch 43; iter: 0; batch classifier loss: 0.485090; batch adversarial loss: 0.623857\n",
      "epoch 43; iter: 200; batch classifier loss: 0.292634; batch adversarial loss: 0.606073\n",
      "epoch 44; iter: 0; batch classifier loss: 0.316263; batch adversarial loss: 0.652067\n",
      "epoch 44; iter: 200; batch classifier loss: 0.353019; batch adversarial loss: 0.616690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.328930; batch adversarial loss: 0.628534\n",
      "epoch 45; iter: 200; batch classifier loss: 0.385541; batch adversarial loss: 0.587743\n",
      "epoch 46; iter: 0; batch classifier loss: 0.283317; batch adversarial loss: 0.621964\n",
      "epoch 46; iter: 200; batch classifier loss: 0.378341; batch adversarial loss: 0.644402\n",
      "epoch 47; iter: 0; batch classifier loss: 0.333170; batch adversarial loss: 0.659163\n",
      "epoch 47; iter: 200; batch classifier loss: 0.297730; batch adversarial loss: 0.602633\n",
      "epoch 48; iter: 0; batch classifier loss: 0.368710; batch adversarial loss: 0.623029\n",
      "epoch 48; iter: 200; batch classifier loss: 0.375881; batch adversarial loss: 0.603308\n",
      "epoch 49; iter: 0; batch classifier loss: 0.546807; batch adversarial loss: 0.591674\n",
      "epoch 49; iter: 200; batch classifier loss: 0.357656; batch adversarial loss: 0.683381\n",
      "epoch 0; iter: 0; batch classifier loss: 85.091934; batch adversarial loss: 0.791798\n",
      "epoch 0; iter: 200; batch classifier loss: 7.746017; batch adversarial loss: 0.704773\n",
      "epoch 1; iter: 0; batch classifier loss: 5.273861; batch adversarial loss: 0.676096\n",
      "epoch 1; iter: 200; batch classifier loss: 5.568330; batch adversarial loss: 0.653561\n",
      "epoch 2; iter: 0; batch classifier loss: 2.776291; batch adversarial loss: 0.624155\n",
      "epoch 2; iter: 200; batch classifier loss: 3.297092; batch adversarial loss: 0.665183\n",
      "epoch 3; iter: 0; batch classifier loss: 4.060941; batch adversarial loss: 0.585939\n",
      "epoch 3; iter: 200; batch classifier loss: 8.370438; batch adversarial loss: 0.620087\n",
      "epoch 4; iter: 0; batch classifier loss: 0.931800; batch adversarial loss: 0.578617\n",
      "epoch 4; iter: 200; batch classifier loss: 0.475424; batch adversarial loss: 0.630840\n",
      "epoch 5; iter: 0; batch classifier loss: 0.720588; batch adversarial loss: 0.621305\n",
      "epoch 5; iter: 200; batch classifier loss: 2.120459; batch adversarial loss: 0.597196\n",
      "epoch 6; iter: 0; batch classifier loss: 0.750837; batch adversarial loss: 0.600028\n",
      "epoch 6; iter: 200; batch classifier loss: 0.569397; batch adversarial loss: 0.663432\n",
      "epoch 7; iter: 0; batch classifier loss: 0.394334; batch adversarial loss: 0.591076\n",
      "epoch 7; iter: 200; batch classifier loss: 0.501600; batch adversarial loss: 0.629154\n",
      "epoch 8; iter: 0; batch classifier loss: 0.699893; batch adversarial loss: 0.589736\n",
      "epoch 8; iter: 200; batch classifier loss: 0.442480; batch adversarial loss: 0.614439\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434898; batch adversarial loss: 0.636875\n",
      "epoch 9; iter: 200; batch classifier loss: 0.374375; batch adversarial loss: 0.643898\n",
      "epoch 10; iter: 0; batch classifier loss: 0.490055; batch adversarial loss: 0.678210\n",
      "epoch 10; iter: 200; batch classifier loss: 0.507778; batch adversarial loss: 0.623233\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515206; batch adversarial loss: 0.623660\n",
      "epoch 11; iter: 200; batch classifier loss: 0.354920; batch adversarial loss: 0.650941\n",
      "epoch 12; iter: 0; batch classifier loss: 0.394199; batch adversarial loss: 0.651489\n",
      "epoch 12; iter: 200; batch classifier loss: 0.959396; batch adversarial loss: 0.607448\n",
      "epoch 13; iter: 0; batch classifier loss: 0.376887; batch adversarial loss: 0.703040\n",
      "epoch 13; iter: 200; batch classifier loss: 0.347509; batch adversarial loss: 0.660218\n",
      "epoch 14; iter: 0; batch classifier loss: 0.586756; batch adversarial loss: 0.527852\n",
      "epoch 14; iter: 200; batch classifier loss: 0.404002; batch adversarial loss: 0.633524\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311417; batch adversarial loss: 0.616028\n",
      "epoch 15; iter: 200; batch classifier loss: 0.322124; batch adversarial loss: 0.624349\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379985; batch adversarial loss: 0.616819\n",
      "epoch 16; iter: 200; batch classifier loss: 0.493215; batch adversarial loss: 0.582757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398236; batch adversarial loss: 0.670404\n",
      "epoch 17; iter: 200; batch classifier loss: 0.469541; batch adversarial loss: 0.550264\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359762; batch adversarial loss: 0.604220\n",
      "epoch 18; iter: 200; batch classifier loss: 0.306395; batch adversarial loss: 0.568630\n",
      "epoch 19; iter: 0; batch classifier loss: 0.328972; batch adversarial loss: 0.624645\n",
      "epoch 19; iter: 200; batch classifier loss: 0.315317; batch adversarial loss: 0.612505\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347557; batch adversarial loss: 0.616266\n",
      "epoch 20; iter: 200; batch classifier loss: 0.416507; batch adversarial loss: 0.590356\n",
      "epoch 21; iter: 0; batch classifier loss: 0.303070; batch adversarial loss: 0.598043\n",
      "epoch 21; iter: 200; batch classifier loss: 0.301065; batch adversarial loss: 0.567018\n",
      "epoch 22; iter: 0; batch classifier loss: 0.363194; batch adversarial loss: 0.595351\n",
      "epoch 22; iter: 200; batch classifier loss: 0.333286; batch adversarial loss: 0.604455\n",
      "epoch 23; iter: 0; batch classifier loss: 0.546791; batch adversarial loss: 0.601582\n",
      "epoch 23; iter: 200; batch classifier loss: 0.382262; batch adversarial loss: 0.614225\n",
      "epoch 24; iter: 0; batch classifier loss: 0.357536; batch adversarial loss: 0.654834\n",
      "epoch 24; iter: 200; batch classifier loss: 0.393298; batch adversarial loss: 0.641984\n",
      "epoch 25; iter: 0; batch classifier loss: 0.425796; batch adversarial loss: 0.591758\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360871; batch adversarial loss: 0.610109\n",
      "epoch 26; iter: 0; batch classifier loss: 0.394586; batch adversarial loss: 0.596766\n",
      "epoch 26; iter: 200; batch classifier loss: 0.362745; batch adversarial loss: 0.529981\n",
      "epoch 27; iter: 0; batch classifier loss: 0.370077; batch adversarial loss: 0.637663\n",
      "epoch 27; iter: 200; batch classifier loss: 0.347509; batch adversarial loss: 0.602681\n",
      "epoch 28; iter: 0; batch classifier loss: 0.318367; batch adversarial loss: 0.667091\n",
      "epoch 28; iter: 200; batch classifier loss: 0.385883; batch adversarial loss: 0.598856\n",
      "epoch 29; iter: 0; batch classifier loss: 0.293510; batch adversarial loss: 0.675615\n",
      "epoch 29; iter: 200; batch classifier loss: 0.384146; batch adversarial loss: 0.588141\n",
      "epoch 30; iter: 0; batch classifier loss: 0.372782; batch adversarial loss: 0.606264\n",
      "epoch 30; iter: 200; batch classifier loss: 0.298795; batch adversarial loss: 0.592293\n",
      "epoch 31; iter: 0; batch classifier loss: 0.349118; batch adversarial loss: 0.616301\n",
      "epoch 31; iter: 200; batch classifier loss: 0.345762; batch adversarial loss: 0.662530\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439066; batch adversarial loss: 0.601241\n",
      "epoch 32; iter: 200; batch classifier loss: 0.401453; batch adversarial loss: 0.602460\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445719; batch adversarial loss: 0.562716\n",
      "epoch 33; iter: 200; batch classifier loss: 0.392309; batch adversarial loss: 0.679304\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433304; batch adversarial loss: 0.584482\n",
      "epoch 34; iter: 200; batch classifier loss: 0.465309; batch adversarial loss: 0.587083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.329779; batch adversarial loss: 0.700398\n",
      "epoch 35; iter: 200; batch classifier loss: 0.349211; batch adversarial loss: 0.633865\n",
      "epoch 36; iter: 0; batch classifier loss: 0.322442; batch adversarial loss: 0.650249\n",
      "epoch 36; iter: 200; batch classifier loss: 0.316248; batch adversarial loss: 0.610919\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399218; batch adversarial loss: 0.649032\n",
      "epoch 37; iter: 200; batch classifier loss: 0.366155; batch adversarial loss: 0.636033\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446964; batch adversarial loss: 0.627841\n",
      "epoch 38; iter: 200; batch classifier loss: 0.371352; batch adversarial loss: 0.593279\n",
      "epoch 39; iter: 0; batch classifier loss: 0.547084; batch adversarial loss: 0.528234\n",
      "epoch 39; iter: 200; batch classifier loss: 0.311290; batch adversarial loss: 0.665849\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465465; batch adversarial loss: 0.608379\n",
      "epoch 40; iter: 200; batch classifier loss: 0.431962; batch adversarial loss: 0.581096\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463801; batch adversarial loss: 0.627113\n",
      "epoch 41; iter: 200; batch classifier loss: 0.469175; batch adversarial loss: 0.629102\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416280; batch adversarial loss: 0.627827\n",
      "epoch 42; iter: 200; batch classifier loss: 0.456805; batch adversarial loss: 0.679591\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415209; batch adversarial loss: 0.658044\n",
      "epoch 43; iter: 200; batch classifier loss: 0.418119; batch adversarial loss: 0.617955\n",
      "epoch 44; iter: 0; batch classifier loss: 0.559445; batch adversarial loss: 0.654364\n",
      "epoch 44; iter: 200; batch classifier loss: 0.581959; batch adversarial loss: 0.654552\n",
      "epoch 45; iter: 0; batch classifier loss: 0.558691; batch adversarial loss: 0.618558\n",
      "epoch 45; iter: 200; batch classifier loss: 0.321671; batch adversarial loss: 0.647076\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419068; batch adversarial loss: 0.654065\n",
      "epoch 46; iter: 200; batch classifier loss: 0.388110; batch adversarial loss: 0.606057\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350098; batch adversarial loss: 0.685065\n",
      "epoch 47; iter: 200; batch classifier loss: 0.284994; batch adversarial loss: 0.589825\n",
      "epoch 48; iter: 0; batch classifier loss: 0.515468; batch adversarial loss: 0.655788\n",
      "epoch 48; iter: 200; batch classifier loss: 0.451179; batch adversarial loss: 0.614389\n",
      "epoch 49; iter: 0; batch classifier loss: 0.527280; batch adversarial loss: 0.629201\n",
      "epoch 49; iter: 200; batch classifier loss: 0.442271; batch adversarial loss: 0.653169\n",
      "epoch 0; iter: 0; batch classifier loss: 11.718699; batch adversarial loss: 0.625094\n",
      "epoch 0; iter: 200; batch classifier loss: 2.284151; batch adversarial loss: 0.652464\n",
      "epoch 1; iter: 0; batch classifier loss: 2.317600; batch adversarial loss: 0.641639\n",
      "epoch 1; iter: 200; batch classifier loss: 7.727251; batch adversarial loss: 0.669995\n",
      "epoch 2; iter: 0; batch classifier loss: 1.636625; batch adversarial loss: 0.600083\n",
      "epoch 2; iter: 200; batch classifier loss: 2.845588; batch adversarial loss: 0.702716\n",
      "epoch 3; iter: 0; batch classifier loss: 2.433947; batch adversarial loss: 0.636031\n",
      "epoch 3; iter: 200; batch classifier loss: 0.605101; batch adversarial loss: 0.633699\n",
      "epoch 4; iter: 0; batch classifier loss: 0.971957; batch adversarial loss: 0.595356\n",
      "epoch 4; iter: 200; batch classifier loss: 0.631530; batch adversarial loss: 0.550900\n",
      "epoch 5; iter: 0; batch classifier loss: 1.077148; batch adversarial loss: 0.595269\n",
      "epoch 5; iter: 200; batch classifier loss: 2.514203; batch adversarial loss: 0.615005\n",
      "epoch 6; iter: 0; batch classifier loss: 5.998461; batch adversarial loss: 0.586237\n",
      "epoch 6; iter: 200; batch classifier loss: 0.549576; batch adversarial loss: 0.716781\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380614; batch adversarial loss: 0.628840\n",
      "epoch 7; iter: 200; batch classifier loss: 0.361121; batch adversarial loss: 0.617742\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489334; batch adversarial loss: 0.611407\n",
      "epoch 8; iter: 200; batch classifier loss: 0.345567; batch adversarial loss: 0.631740\n",
      "epoch 9; iter: 0; batch classifier loss: 0.377999; batch adversarial loss: 0.619211\n",
      "epoch 9; iter: 200; batch classifier loss: 0.367843; batch adversarial loss: 0.600625\n",
      "epoch 10; iter: 0; batch classifier loss: 0.408356; batch adversarial loss: 0.641728\n",
      "epoch 10; iter: 200; batch classifier loss: 0.453854; batch adversarial loss: 0.621580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459217; batch adversarial loss: 0.647024\n",
      "epoch 11; iter: 200; batch classifier loss: 0.427360; batch adversarial loss: 0.617360\n",
      "epoch 12; iter: 0; batch classifier loss: 0.493267; batch adversarial loss: 0.663534\n",
      "epoch 12; iter: 200; batch classifier loss: 0.636916; batch adversarial loss: 0.603124\n",
      "epoch 13; iter: 0; batch classifier loss: 0.447576; batch adversarial loss: 0.606745\n",
      "epoch 13; iter: 200; batch classifier loss: 0.424817; batch adversarial loss: 0.650773\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508962; batch adversarial loss: 0.638049\n",
      "epoch 14; iter: 200; batch classifier loss: 0.304620; batch adversarial loss: 0.612236\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381984; batch adversarial loss: 0.628597\n",
      "epoch 15; iter: 200; batch classifier loss: 0.275594; batch adversarial loss: 0.669974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.312070; batch adversarial loss: 0.617407\n",
      "epoch 16; iter: 200; batch classifier loss: 0.404769; batch adversarial loss: 0.650983\n",
      "epoch 17; iter: 0; batch classifier loss: 0.432956; batch adversarial loss: 0.666374\n",
      "epoch 17; iter: 200; batch classifier loss: 0.380576; batch adversarial loss: 0.628167\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334520; batch adversarial loss: 0.619718\n",
      "epoch 18; iter: 200; batch classifier loss: 0.463012; batch adversarial loss: 0.582060\n",
      "epoch 19; iter: 0; batch classifier loss: 0.360452; batch adversarial loss: 0.604507\n",
      "epoch 19; iter: 200; batch classifier loss: 0.383947; batch adversarial loss: 0.628023\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510537; batch adversarial loss: 0.646216\n",
      "epoch 20; iter: 200; batch classifier loss: 0.359532; batch adversarial loss: 0.652240\n",
      "epoch 21; iter: 0; batch classifier loss: 0.523090; batch adversarial loss: 0.582468\n",
      "epoch 21; iter: 200; batch classifier loss: 0.389786; batch adversarial loss: 0.657482\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354804; batch adversarial loss: 0.642801\n",
      "epoch 22; iter: 200; batch classifier loss: 0.387970; batch adversarial loss: 0.643853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.317499; batch adversarial loss: 0.698370\n",
      "epoch 23; iter: 200; batch classifier loss: 0.346187; batch adversarial loss: 0.587683\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263909; batch adversarial loss: 0.648691\n",
      "epoch 24; iter: 200; batch classifier loss: 0.344171; batch adversarial loss: 0.595860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.357262; batch adversarial loss: 0.609522\n",
      "epoch 25; iter: 200; batch classifier loss: 0.321307; batch adversarial loss: 0.619651\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343853; batch adversarial loss: 0.638504\n",
      "epoch 26; iter: 200; batch classifier loss: 0.418108; batch adversarial loss: 0.579283\n",
      "epoch 27; iter: 0; batch classifier loss: 0.349304; batch adversarial loss: 0.602175\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328391; batch adversarial loss: 0.647680\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328919; batch adversarial loss: 0.618560\n",
      "epoch 28; iter: 200; batch classifier loss: 0.291290; batch adversarial loss: 0.617436\n",
      "epoch 29; iter: 0; batch classifier loss: 0.449150; batch adversarial loss: 0.577903\n",
      "epoch 29; iter: 200; batch classifier loss: 0.370014; batch adversarial loss: 0.630739\n",
      "epoch 30; iter: 0; batch classifier loss: 0.307333; batch adversarial loss: 0.560998\n",
      "epoch 30; iter: 200; batch classifier loss: 0.373409; batch adversarial loss: 0.635205\n",
      "epoch 31; iter: 0; batch classifier loss: 0.393774; batch adversarial loss: 0.633496\n",
      "epoch 31; iter: 200; batch classifier loss: 0.309208; batch adversarial loss: 0.654319\n",
      "epoch 32; iter: 0; batch classifier loss: 0.233652; batch adversarial loss: 0.633403\n",
      "epoch 32; iter: 200; batch classifier loss: 0.360873; batch adversarial loss: 0.575665\n",
      "epoch 33; iter: 0; batch classifier loss: 0.327342; batch adversarial loss: 0.652796\n",
      "epoch 33; iter: 200; batch classifier loss: 0.286047; batch adversarial loss: 0.586873\n",
      "epoch 34; iter: 0; batch classifier loss: 0.296218; batch adversarial loss: 0.633897\n",
      "epoch 34; iter: 200; batch classifier loss: 0.389184; batch adversarial loss: 0.643375\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376829; batch adversarial loss: 0.601111\n",
      "epoch 35; iter: 200; batch classifier loss: 0.462357; batch adversarial loss: 0.628157\n",
      "epoch 36; iter: 0; batch classifier loss: 0.268291; batch adversarial loss: 0.622755\n",
      "epoch 36; iter: 200; batch classifier loss: 0.335773; batch adversarial loss: 0.609645\n",
      "epoch 37; iter: 0; batch classifier loss: 0.463196; batch adversarial loss: 0.613941\n",
      "epoch 37; iter: 200; batch classifier loss: 0.452475; batch adversarial loss: 0.597067\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402889; batch adversarial loss: 0.630753\n",
      "epoch 38; iter: 200; batch classifier loss: 0.339278; batch adversarial loss: 0.685512\n",
      "epoch 39; iter: 0; batch classifier loss: 0.310974; batch adversarial loss: 0.618318\n",
      "epoch 39; iter: 200; batch classifier loss: 0.248904; batch adversarial loss: 0.622376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465750; batch adversarial loss: 0.600896\n",
      "epoch 40; iter: 200; batch classifier loss: 0.237354; batch adversarial loss: 0.640968\n",
      "epoch 41; iter: 0; batch classifier loss: 0.343253; batch adversarial loss: 0.641493\n",
      "epoch 41; iter: 200; batch classifier loss: 0.354000; batch adversarial loss: 0.592618\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394124; batch adversarial loss: 0.640441\n",
      "epoch 42; iter: 200; batch classifier loss: 0.421734; batch adversarial loss: 0.611563\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381177; batch adversarial loss: 0.650905\n",
      "epoch 43; iter: 200; batch classifier loss: 0.316693; batch adversarial loss: 0.626152\n",
      "epoch 44; iter: 0; batch classifier loss: 0.349567; batch adversarial loss: 0.606113\n",
      "epoch 44; iter: 200; batch classifier loss: 0.324539; batch adversarial loss: 0.623992\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354671; batch adversarial loss: 0.635436\n",
      "epoch 45; iter: 200; batch classifier loss: 0.307451; batch adversarial loss: 0.661318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419028; batch adversarial loss: 0.650244\n",
      "epoch 46; iter: 200; batch classifier loss: 0.469577; batch adversarial loss: 0.638821\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400190; batch adversarial loss: 0.599275\n",
      "epoch 47; iter: 200; batch classifier loss: 0.378738; batch adversarial loss: 0.690179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.346170; batch adversarial loss: 0.641746\n",
      "epoch 48; iter: 200; batch classifier loss: 0.269208; batch adversarial loss: 0.616675\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443095; batch adversarial loss: 0.635433\n",
      "epoch 49; iter: 200; batch classifier loss: 0.347082; batch adversarial loss: 0.642498\n",
      "epoch 0; iter: 0; batch classifier loss: 82.321556; batch adversarial loss: 0.865692\n",
      "epoch 0; iter: 200; batch classifier loss: 10.715055; batch adversarial loss: 0.783261\n",
      "epoch 1; iter: 0; batch classifier loss: 2.570269; batch adversarial loss: 0.697650\n",
      "epoch 1; iter: 200; batch classifier loss: 4.775054; batch adversarial loss: 0.678557\n",
      "epoch 2; iter: 0; batch classifier loss: 2.436499; batch adversarial loss: 0.635615\n",
      "epoch 2; iter: 200; batch classifier loss: 9.256098; batch adversarial loss: 0.676290\n",
      "epoch 3; iter: 0; batch classifier loss: 4.286815; batch adversarial loss: 0.638618\n",
      "epoch 3; iter: 200; batch classifier loss: 5.362323; batch adversarial loss: 0.645777\n",
      "epoch 4; iter: 0; batch classifier loss: 0.396727; batch adversarial loss: 0.638583\n",
      "epoch 4; iter: 200; batch classifier loss: 2.407676; batch adversarial loss: 0.619118\n",
      "epoch 5; iter: 0; batch classifier loss: 0.873261; batch adversarial loss: 0.586635\n",
      "epoch 5; iter: 200; batch classifier loss: 1.143233; batch adversarial loss: 0.595335\n",
      "epoch 6; iter: 0; batch classifier loss: 0.630273; batch adversarial loss: 0.592616\n",
      "epoch 6; iter: 200; batch classifier loss: 0.584453; batch adversarial loss: 0.651855\n",
      "epoch 7; iter: 0; batch classifier loss: 1.384467; batch adversarial loss: 0.594716\n",
      "epoch 7; iter: 200; batch classifier loss: 1.003430; batch adversarial loss: 0.621819\n",
      "epoch 8; iter: 0; batch classifier loss: 1.264411; batch adversarial loss: 0.639236\n",
      "epoch 8; iter: 200; batch classifier loss: 0.349478; batch adversarial loss: 0.580397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.372346; batch adversarial loss: 0.617716\n",
      "epoch 9; iter: 200; batch classifier loss: 0.393761; batch adversarial loss: 0.601167\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308223; batch adversarial loss: 0.637953\n",
      "epoch 10; iter: 200; batch classifier loss: 0.350311; batch adversarial loss: 0.657333\n",
      "epoch 11; iter: 0; batch classifier loss: 0.356790; batch adversarial loss: 0.637033\n",
      "epoch 11; iter: 200; batch classifier loss: 0.545511; batch adversarial loss: 0.650971\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428102; batch adversarial loss: 0.570794\n",
      "epoch 12; iter: 200; batch classifier loss: 0.356158; batch adversarial loss: 0.643342\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578142; batch adversarial loss: 0.601785\n",
      "epoch 13; iter: 200; batch classifier loss: 0.435551; batch adversarial loss: 0.619835\n",
      "epoch 14; iter: 0; batch classifier loss: 0.419223; batch adversarial loss: 0.670133\n",
      "epoch 14; iter: 200; batch classifier loss: 0.392370; batch adversarial loss: 0.629635\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490215; batch adversarial loss: 0.610159\n",
      "epoch 15; iter: 200; batch classifier loss: 0.412899; batch adversarial loss: 0.643048\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470132; batch adversarial loss: 0.596236\n",
      "epoch 16; iter: 200; batch classifier loss: 0.406293; batch adversarial loss: 0.581327\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474671; batch adversarial loss: 0.583899\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381238; batch adversarial loss: 0.636579\n",
      "epoch 18; iter: 0; batch classifier loss: 0.401418; batch adversarial loss: 0.626043\n",
      "epoch 18; iter: 200; batch classifier loss: 0.323887; batch adversarial loss: 0.632330\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443646; batch adversarial loss: 0.614680\n",
      "epoch 19; iter: 200; batch classifier loss: 0.422190; batch adversarial loss: 0.688518\n",
      "epoch 20; iter: 0; batch classifier loss: 0.354147; batch adversarial loss: 0.602151\n",
      "epoch 20; iter: 200; batch classifier loss: 0.311972; batch adversarial loss: 0.614830\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283477; batch adversarial loss: 0.661727\n",
      "epoch 21; iter: 200; batch classifier loss: 0.409421; batch adversarial loss: 0.627603\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348808; batch adversarial loss: 0.601515\n",
      "epoch 22; iter: 200; batch classifier loss: 0.363633; batch adversarial loss: 0.601291\n",
      "epoch 23; iter: 0; batch classifier loss: 0.666448; batch adversarial loss: 0.702813\n",
      "epoch 23; iter: 200; batch classifier loss: 0.333636; batch adversarial loss: 0.615726\n",
      "epoch 24; iter: 0; batch classifier loss: 0.616375; batch adversarial loss: 0.630538\n",
      "epoch 24; iter: 200; batch classifier loss: 0.324349; batch adversarial loss: 0.647418\n",
      "epoch 25; iter: 0; batch classifier loss: 0.350013; batch adversarial loss: 0.611725\n",
      "epoch 25; iter: 200; batch classifier loss: 0.307748; batch adversarial loss: 0.560627\n",
      "epoch 26; iter: 0; batch classifier loss: 0.289024; batch adversarial loss: 0.644656\n",
      "epoch 26; iter: 200; batch classifier loss: 0.375287; batch adversarial loss: 0.612227\n",
      "epoch 27; iter: 0; batch classifier loss: 0.378216; batch adversarial loss: 0.654109\n",
      "epoch 27; iter: 200; batch classifier loss: 0.389595; batch adversarial loss: 0.604602\n",
      "epoch 28; iter: 0; batch classifier loss: 0.296481; batch adversarial loss: 0.604432\n",
      "epoch 28; iter: 200; batch classifier loss: 0.451428; batch adversarial loss: 0.667743\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322061; batch adversarial loss: 0.583374\n",
      "epoch 29; iter: 200; batch classifier loss: 0.281494; batch adversarial loss: 0.683693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.251262; batch adversarial loss: 0.599450\n",
      "epoch 30; iter: 200; batch classifier loss: 0.321402; batch adversarial loss: 0.603242\n",
      "epoch 31; iter: 0; batch classifier loss: 0.323556; batch adversarial loss: 0.630837\n",
      "epoch 31; iter: 200; batch classifier loss: 0.320297; batch adversarial loss: 0.632318\n",
      "epoch 32; iter: 0; batch classifier loss: 0.335065; batch adversarial loss: 0.620364\n",
      "epoch 32; iter: 200; batch classifier loss: 0.357774; batch adversarial loss: 0.653498\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346939; batch adversarial loss: 0.624787\n",
      "epoch 33; iter: 200; batch classifier loss: 0.398329; batch adversarial loss: 0.597346\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331970; batch adversarial loss: 0.610498\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338468; batch adversarial loss: 0.617106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411102; batch adversarial loss: 0.579360\n",
      "epoch 35; iter: 200; batch classifier loss: 0.343267; batch adversarial loss: 0.564291\n",
      "epoch 36; iter: 0; batch classifier loss: 0.291818; batch adversarial loss: 0.658240\n",
      "epoch 36; iter: 200; batch classifier loss: 0.326759; batch adversarial loss: 0.594513\n",
      "epoch 37; iter: 0; batch classifier loss: 0.370409; batch adversarial loss: 0.548202\n",
      "epoch 37; iter: 200; batch classifier loss: 0.350922; batch adversarial loss: 0.627486\n",
      "epoch 38; iter: 0; batch classifier loss: 0.765659; batch adversarial loss: 0.580278\n",
      "epoch 38; iter: 200; batch classifier loss: 0.290845; batch adversarial loss: 0.589027\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427201; batch adversarial loss: 0.630426\n",
      "epoch 39; iter: 200; batch classifier loss: 0.262352; batch adversarial loss: 0.668404\n",
      "epoch 40; iter: 0; batch classifier loss: 0.366057; batch adversarial loss: 0.600960\n",
      "epoch 40; iter: 200; batch classifier loss: 0.425543; batch adversarial loss: 0.632679\n",
      "epoch 41; iter: 0; batch classifier loss: 0.313008; batch adversarial loss: 0.664967\n",
      "epoch 41; iter: 200; batch classifier loss: 0.451898; batch adversarial loss: 0.639692\n",
      "epoch 42; iter: 0; batch classifier loss: 0.281551; batch adversarial loss: 0.611856\n",
      "epoch 42; iter: 200; batch classifier loss: 0.361804; batch adversarial loss: 0.638337\n",
      "epoch 43; iter: 0; batch classifier loss: 0.349958; batch adversarial loss: 0.618601\n",
      "epoch 43; iter: 200; batch classifier loss: 0.284251; batch adversarial loss: 0.667223\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321457; batch adversarial loss: 0.605021\n",
      "epoch 44; iter: 200; batch classifier loss: 0.304390; batch adversarial loss: 0.674862\n",
      "epoch 45; iter: 0; batch classifier loss: 0.245841; batch adversarial loss: 0.618626\n",
      "epoch 45; iter: 200; batch classifier loss: 0.392240; batch adversarial loss: 0.669419\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389232; batch adversarial loss: 0.538548\n",
      "epoch 46; iter: 200; batch classifier loss: 0.281847; batch adversarial loss: 0.608501\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370358; batch adversarial loss: 0.597095\n",
      "epoch 47; iter: 200; batch classifier loss: 0.409304; batch adversarial loss: 0.639538\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370157; batch adversarial loss: 0.646923\n",
      "epoch 48; iter: 200; batch classifier loss: 0.395387; batch adversarial loss: 0.628125\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385286; batch adversarial loss: 0.680290\n",
      "epoch 49; iter: 200; batch classifier loss: 0.301580; batch adversarial loss: 0.662993\n",
      "epoch 0; iter: 0; batch classifier loss: 26.114323; batch adversarial loss: 0.898859\n",
      "epoch 0; iter: 200; batch classifier loss: 7.064419; batch adversarial loss: 0.707128\n",
      "epoch 1; iter: 0; batch classifier loss: 7.676085; batch adversarial loss: 0.726722\n",
      "epoch 1; iter: 200; batch classifier loss: 6.984029; batch adversarial loss: 0.652694\n",
      "epoch 2; iter: 0; batch classifier loss: 4.422680; batch adversarial loss: 0.632265\n",
      "epoch 2; iter: 200; batch classifier loss: 5.864487; batch adversarial loss: 0.636155\n",
      "epoch 3; iter: 0; batch classifier loss: 3.186324; batch adversarial loss: 0.594287\n",
      "epoch 3; iter: 200; batch classifier loss: 0.797121; batch adversarial loss: 0.624987\n",
      "epoch 4; iter: 0; batch classifier loss: 3.520160; batch adversarial loss: 0.604649\n",
      "epoch 4; iter: 200; batch classifier loss: 1.179824; batch adversarial loss: 0.616390\n",
      "epoch 5; iter: 0; batch classifier loss: 1.899132; batch adversarial loss: 0.591989\n",
      "epoch 5; iter: 200; batch classifier loss: 2.134574; batch adversarial loss: 0.620146\n",
      "epoch 6; iter: 0; batch classifier loss: 1.567053; batch adversarial loss: 0.692774\n",
      "epoch 6; iter: 200; batch classifier loss: 0.892700; batch adversarial loss: 0.607259\n",
      "epoch 7; iter: 0; batch classifier loss: 0.728153; batch adversarial loss: 0.658009\n",
      "epoch 7; iter: 200; batch classifier loss: 0.284081; batch adversarial loss: 0.631879\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602309; batch adversarial loss: 0.636939\n",
      "epoch 8; iter: 200; batch classifier loss: 0.955514; batch adversarial loss: 0.638100\n",
      "epoch 9; iter: 0; batch classifier loss: 0.966545; batch adversarial loss: 0.634142\n",
      "epoch 9; iter: 200; batch classifier loss: 0.347847; batch adversarial loss: 0.603922\n",
      "epoch 10; iter: 0; batch classifier loss: 0.645851; batch adversarial loss: 0.608752\n",
      "epoch 10; iter: 200; batch classifier loss: 0.686428; batch adversarial loss: 0.652357\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526184; batch adversarial loss: 0.596625\n",
      "epoch 11; iter: 200; batch classifier loss: 0.489581; batch adversarial loss: 0.617407\n",
      "epoch 12; iter: 0; batch classifier loss: 0.298246; batch adversarial loss: 0.638338\n",
      "epoch 12; iter: 200; batch classifier loss: 0.409039; batch adversarial loss: 0.658387\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384053; batch adversarial loss: 0.633838\n",
      "epoch 13; iter: 200; batch classifier loss: 0.408775; batch adversarial loss: 0.623801\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290235; batch adversarial loss: 0.645178\n",
      "epoch 14; iter: 200; batch classifier loss: 0.343122; batch adversarial loss: 0.613915\n",
      "epoch 15; iter: 0; batch classifier loss: 0.389603; batch adversarial loss: 0.661063\n",
      "epoch 15; iter: 200; batch classifier loss: 0.414437; batch adversarial loss: 0.592905\n",
      "epoch 16; iter: 0; batch classifier loss: 0.345253; batch adversarial loss: 0.743367\n",
      "epoch 16; iter: 200; batch classifier loss: 0.575513; batch adversarial loss: 0.616193\n",
      "epoch 17; iter: 0; batch classifier loss: 0.370122; batch adversarial loss: 0.625203\n",
      "epoch 17; iter: 200; batch classifier loss: 0.431570; batch adversarial loss: 0.639261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309516; batch adversarial loss: 0.575812\n",
      "epoch 18; iter: 200; batch classifier loss: 0.346331; batch adversarial loss: 0.611344\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335173; batch adversarial loss: 0.625062\n",
      "epoch 19; iter: 200; batch classifier loss: 0.321222; batch adversarial loss: 0.675424\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314112; batch adversarial loss: 0.652345\n",
      "epoch 20; iter: 200; batch classifier loss: 0.296522; batch adversarial loss: 0.594269\n",
      "epoch 21; iter: 0; batch classifier loss: 0.357791; batch adversarial loss: 0.591311\n",
      "epoch 21; iter: 200; batch classifier loss: 0.467980; batch adversarial loss: 0.614697\n",
      "epoch 22; iter: 0; batch classifier loss: 0.346589; batch adversarial loss: 0.603807\n",
      "epoch 22; iter: 200; batch classifier loss: 0.263689; batch adversarial loss: 0.681144\n",
      "epoch 23; iter: 0; batch classifier loss: 0.360400; batch adversarial loss: 0.647664\n",
      "epoch 23; iter: 200; batch classifier loss: 0.288921; batch adversarial loss: 0.660463\n",
      "epoch 24; iter: 0; batch classifier loss: 0.269464; batch adversarial loss: 0.655406\n",
      "epoch 24; iter: 200; batch classifier loss: 0.420238; batch adversarial loss: 0.573735\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333469; batch adversarial loss: 0.638839\n",
      "epoch 25; iter: 200; batch classifier loss: 0.267006; batch adversarial loss: 0.576822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.311583; batch adversarial loss: 0.645461\n",
      "epoch 26; iter: 200; batch classifier loss: 0.381971; batch adversarial loss: 0.621892\n",
      "epoch 27; iter: 0; batch classifier loss: 0.395905; batch adversarial loss: 0.630081\n",
      "epoch 27; iter: 200; batch classifier loss: 0.272533; batch adversarial loss: 0.606359\n",
      "epoch 28; iter: 0; batch classifier loss: 0.309880; batch adversarial loss: 0.655288\n",
      "epoch 28; iter: 200; batch classifier loss: 0.366989; batch adversarial loss: 0.595421\n",
      "epoch 29; iter: 0; batch classifier loss: 0.283213; batch adversarial loss: 0.665488\n",
      "epoch 29; iter: 200; batch classifier loss: 0.336510; batch adversarial loss: 0.583263\n",
      "epoch 30; iter: 0; batch classifier loss: 0.310609; batch adversarial loss: 0.632548\n",
      "epoch 30; iter: 200; batch classifier loss: 0.331541; batch adversarial loss: 0.633569\n",
      "epoch 31; iter: 0; batch classifier loss: 0.363898; batch adversarial loss: 0.610564\n",
      "epoch 31; iter: 200; batch classifier loss: 0.231073; batch adversarial loss: 0.602118\n",
      "epoch 32; iter: 0; batch classifier loss: 0.344936; batch adversarial loss: 0.594828\n",
      "epoch 32; iter: 200; batch classifier loss: 0.314613; batch adversarial loss: 0.577042\n",
      "epoch 33; iter: 0; batch classifier loss: 0.356103; batch adversarial loss: 0.546152\n",
      "epoch 33; iter: 200; batch classifier loss: 0.350465; batch adversarial loss: 0.608602\n",
      "epoch 34; iter: 0; batch classifier loss: 0.332339; batch adversarial loss: 0.580298\n",
      "epoch 34; iter: 200; batch classifier loss: 0.299845; batch adversarial loss: 0.597089\n",
      "epoch 35; iter: 0; batch classifier loss: 0.359744; batch adversarial loss: 0.625777\n",
      "epoch 35; iter: 200; batch classifier loss: 0.364853; batch adversarial loss: 0.634885\n",
      "epoch 36; iter: 0; batch classifier loss: 0.277090; batch adversarial loss: 0.658402\n",
      "epoch 36; iter: 200; batch classifier loss: 0.351861; batch adversarial loss: 0.640189\n",
      "epoch 37; iter: 0; batch classifier loss: 0.283099; batch adversarial loss: 0.598148\n",
      "epoch 37; iter: 200; batch classifier loss: 0.279212; batch adversarial loss: 0.617534\n",
      "epoch 38; iter: 0; batch classifier loss: 0.272361; batch adversarial loss: 0.650419\n",
      "epoch 38; iter: 200; batch classifier loss: 0.349240; batch adversarial loss: 0.574918\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410691; batch adversarial loss: 0.669446\n",
      "epoch 39; iter: 200; batch classifier loss: 0.340343; batch adversarial loss: 0.645696\n",
      "epoch 40; iter: 0; batch classifier loss: 0.359848; batch adversarial loss: 0.627310\n",
      "epoch 40; iter: 200; batch classifier loss: 0.315852; batch adversarial loss: 0.614319\n",
      "epoch 41; iter: 0; batch classifier loss: 0.326662; batch adversarial loss: 0.646395\n",
      "epoch 41; iter: 200; batch classifier loss: 0.344222; batch adversarial loss: 0.719182\n",
      "epoch 42; iter: 0; batch classifier loss: 0.658552; batch adversarial loss: 0.656097\n",
      "epoch 42; iter: 200; batch classifier loss: 0.322798; batch adversarial loss: 0.635648\n",
      "epoch 43; iter: 0; batch classifier loss: 0.278547; batch adversarial loss: 0.576295\n",
      "epoch 43; iter: 200; batch classifier loss: 0.390360; batch adversarial loss: 0.570729\n",
      "epoch 44; iter: 0; batch classifier loss: 0.301538; batch adversarial loss: 0.622438\n",
      "epoch 44; iter: 200; batch classifier loss: 0.380197; batch adversarial loss: 0.613721\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368840; batch adversarial loss: 0.638440\n",
      "epoch 45; iter: 200; batch classifier loss: 0.377137; batch adversarial loss: 0.639815\n",
      "epoch 46; iter: 0; batch classifier loss: 0.231066; batch adversarial loss: 0.634293\n",
      "epoch 46; iter: 200; batch classifier loss: 0.495223; batch adversarial loss: 0.585366\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405705; batch adversarial loss: 0.618837\n",
      "epoch 47; iter: 200; batch classifier loss: 0.369484; batch adversarial loss: 0.646157\n",
      "epoch 48; iter: 0; batch classifier loss: 0.330372; batch adversarial loss: 0.613677\n",
      "epoch 48; iter: 200; batch classifier loss: 0.374096; batch adversarial loss: 0.653550\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351870; batch adversarial loss: 0.636231\n",
      "epoch 49; iter: 200; batch classifier loss: 0.319437; batch adversarial loss: 0.638525\n",
      "epoch 0; iter: 0; batch classifier loss: 11.320576; batch adversarial loss: 1.111372\n",
      "epoch 0; iter: 200; batch classifier loss: 9.242892; batch adversarial loss: 0.811136\n",
      "epoch 1; iter: 0; batch classifier loss: 5.860100; batch adversarial loss: 0.735495\n",
      "epoch 1; iter: 200; batch classifier loss: 1.444735; batch adversarial loss: 0.637743\n",
      "epoch 2; iter: 0; batch classifier loss: 3.649712; batch adversarial loss: 0.707355\n",
      "epoch 2; iter: 200; batch classifier loss: 1.816094; batch adversarial loss: 0.650570\n",
      "epoch 3; iter: 0; batch classifier loss: 2.907440; batch adversarial loss: 0.683480\n",
      "epoch 3; iter: 200; batch classifier loss: 3.934467; batch adversarial loss: 0.646695\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569555; batch adversarial loss: 0.589790\n",
      "epoch 4; iter: 200; batch classifier loss: 2.668681; batch adversarial loss: 0.602436\n",
      "epoch 5; iter: 0; batch classifier loss: 0.734173; batch adversarial loss: 0.647322\n",
      "epoch 5; iter: 200; batch classifier loss: 0.395644; batch adversarial loss: 0.598952\n",
      "epoch 6; iter: 0; batch classifier loss: 0.425432; batch adversarial loss: 0.606636\n",
      "epoch 6; iter: 200; batch classifier loss: 1.915916; batch adversarial loss: 0.597363\n",
      "epoch 7; iter: 0; batch classifier loss: 0.926432; batch adversarial loss: 0.635699\n",
      "epoch 7; iter: 200; batch classifier loss: 1.073938; batch adversarial loss: 0.609325\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368040; batch adversarial loss: 0.618751\n",
      "epoch 8; iter: 200; batch classifier loss: 0.348795; batch adversarial loss: 0.660433\n",
      "epoch 9; iter: 0; batch classifier loss: 0.447839; batch adversarial loss: 0.593292\n",
      "epoch 9; iter: 200; batch classifier loss: 0.432798; batch adversarial loss: 0.645604\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335146; batch adversarial loss: 0.672100\n",
      "epoch 10; iter: 200; batch classifier loss: 0.383081; batch adversarial loss: 0.601419\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292873; batch adversarial loss: 0.626445\n",
      "epoch 11; iter: 200; batch classifier loss: 0.397739; batch adversarial loss: 0.568789\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483280; batch adversarial loss: 0.620457\n",
      "epoch 12; iter: 200; batch classifier loss: 0.398121; batch adversarial loss: 0.618895\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506333; batch adversarial loss: 0.619717\n",
      "epoch 13; iter: 200; batch classifier loss: 0.405194; batch adversarial loss: 0.559702\n",
      "epoch 14; iter: 0; batch classifier loss: 0.420399; batch adversarial loss: 0.679768\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416920; batch adversarial loss: 0.617153\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474529; batch adversarial loss: 0.646832\n",
      "epoch 15; iter: 200; batch classifier loss: 0.478551; batch adversarial loss: 0.587438\n",
      "epoch 16; iter: 0; batch classifier loss: 0.425126; batch adversarial loss: 0.623879\n",
      "epoch 16; iter: 200; batch classifier loss: 0.497872; batch adversarial loss: 0.568744\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420650; batch adversarial loss: 0.568234\n",
      "epoch 17; iter: 200; batch classifier loss: 0.411892; batch adversarial loss: 0.618339\n",
      "epoch 18; iter: 0; batch classifier loss: 0.489977; batch adversarial loss: 0.607165\n",
      "epoch 18; iter: 200; batch classifier loss: 0.552107; batch adversarial loss: 0.644443\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369338; batch adversarial loss: 0.580904\n",
      "epoch 19; iter: 200; batch classifier loss: 0.384707; batch adversarial loss: 0.627356\n",
      "epoch 20; iter: 0; batch classifier loss: 0.282463; batch adversarial loss: 0.656915\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368541; batch adversarial loss: 0.609534\n",
      "epoch 21; iter: 0; batch classifier loss: 0.367926; batch adversarial loss: 0.626847\n",
      "epoch 21; iter: 200; batch classifier loss: 0.281839; batch adversarial loss: 0.643010\n",
      "epoch 22; iter: 0; batch classifier loss: 0.673649; batch adversarial loss: 0.570266\n",
      "epoch 22; iter: 200; batch classifier loss: 0.316592; batch adversarial loss: 0.598650\n",
      "epoch 23; iter: 0; batch classifier loss: 0.335895; batch adversarial loss: 0.638153\n",
      "epoch 23; iter: 200; batch classifier loss: 0.460960; batch adversarial loss: 0.630927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.371328; batch adversarial loss: 0.638635\n",
      "epoch 24; iter: 200; batch classifier loss: 0.395893; batch adversarial loss: 0.609212\n",
      "epoch 25; iter: 0; batch classifier loss: 0.293500; batch adversarial loss: 0.690392\n",
      "epoch 25; iter: 200; batch classifier loss: 0.334442; batch adversarial loss: 0.602695\n",
      "epoch 26; iter: 0; batch classifier loss: 0.339212; batch adversarial loss: 0.653626\n",
      "epoch 26; iter: 200; batch classifier loss: 0.276527; batch adversarial loss: 0.543165\n",
      "epoch 27; iter: 0; batch classifier loss: 0.369380; batch adversarial loss: 0.612239\n",
      "epoch 27; iter: 200; batch classifier loss: 0.312622; batch adversarial loss: 0.629717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345047; batch adversarial loss: 0.592523\n",
      "epoch 28; iter: 200; batch classifier loss: 0.310140; batch adversarial loss: 0.630462\n",
      "epoch 29; iter: 0; batch classifier loss: 0.362045; batch adversarial loss: 0.631357\n",
      "epoch 29; iter: 200; batch classifier loss: 0.363380; batch adversarial loss: 0.632513\n",
      "epoch 30; iter: 0; batch classifier loss: 0.395574; batch adversarial loss: 0.605207\n",
      "epoch 30; iter: 200; batch classifier loss: 0.309969; batch adversarial loss: 0.637251\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492785; batch adversarial loss: 0.658088\n",
      "epoch 31; iter: 200; batch classifier loss: 0.266306; batch adversarial loss: 0.598747\n",
      "epoch 32; iter: 0; batch classifier loss: 0.343702; batch adversarial loss: 0.574879\n",
      "epoch 32; iter: 200; batch classifier loss: 0.416636; batch adversarial loss: 0.667030\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442800; batch adversarial loss: 0.654213\n",
      "epoch 33; iter: 200; batch classifier loss: 0.319685; batch adversarial loss: 0.576587\n",
      "epoch 34; iter: 0; batch classifier loss: 0.325154; batch adversarial loss: 0.651613\n",
      "epoch 34; iter: 200; batch classifier loss: 0.389255; batch adversarial loss: 0.595254\n",
      "epoch 35; iter: 0; batch classifier loss: 0.345291; batch adversarial loss: 0.612761\n",
      "epoch 35; iter: 200; batch classifier loss: 0.296266; batch adversarial loss: 0.608445\n",
      "epoch 36; iter: 0; batch classifier loss: 0.288653; batch adversarial loss: 0.636280\n",
      "epoch 36; iter: 200; batch classifier loss: 0.488989; batch adversarial loss: 0.592432\n",
      "epoch 37; iter: 0; batch classifier loss: 0.338943; batch adversarial loss: 0.743156\n",
      "epoch 37; iter: 200; batch classifier loss: 0.261830; batch adversarial loss: 0.609665\n",
      "epoch 38; iter: 0; batch classifier loss: 0.290981; batch adversarial loss: 0.625281\n",
      "epoch 38; iter: 200; batch classifier loss: 0.399194; batch adversarial loss: 0.603874\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392423; batch adversarial loss: 0.583283\n",
      "epoch 39; iter: 200; batch classifier loss: 0.343809; batch adversarial loss: 0.618960\n",
      "epoch 40; iter: 0; batch classifier loss: 0.354762; batch adversarial loss: 0.552275\n",
      "epoch 40; iter: 200; batch classifier loss: 0.328186; batch adversarial loss: 0.632400\n",
      "epoch 41; iter: 0; batch classifier loss: 0.321234; batch adversarial loss: 0.599273\n",
      "epoch 41; iter: 200; batch classifier loss: 0.393810; batch adversarial loss: 0.650040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.430385; batch adversarial loss: 0.649981\n",
      "epoch 42; iter: 200; batch classifier loss: 0.330327; batch adversarial loss: 0.646541\n",
      "epoch 43; iter: 0; batch classifier loss: 0.301938; batch adversarial loss: 0.576743\n",
      "epoch 43; iter: 200; batch classifier loss: 0.302478; batch adversarial loss: 0.633376\n",
      "epoch 44; iter: 0; batch classifier loss: 0.570830; batch adversarial loss: 0.600128\n",
      "epoch 44; iter: 200; batch classifier loss: 0.387241; batch adversarial loss: 0.629816\n",
      "epoch 45; iter: 0; batch classifier loss: 0.310035; batch adversarial loss: 0.674355\n",
      "epoch 45; iter: 200; batch classifier loss: 0.415048; batch adversarial loss: 0.613381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.341855; batch adversarial loss: 0.670650\n",
      "epoch 46; iter: 200; batch classifier loss: 0.395158; batch adversarial loss: 0.561185\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484538; batch adversarial loss: 0.665310\n",
      "epoch 47; iter: 200; batch classifier loss: 0.364671; batch adversarial loss: 0.658759\n",
      "epoch 48; iter: 0; batch classifier loss: 0.293008; batch adversarial loss: 0.658705\n",
      "epoch 48; iter: 200; batch classifier loss: 0.554976; batch adversarial loss: 0.594801\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427017; batch adversarial loss: 0.644092\n",
      "epoch 49; iter: 200; batch classifier loss: 0.446808; batch adversarial loss: 0.607215\n",
      "epoch 0; iter: 0; batch classifier loss: 28.094309; batch adversarial loss: 0.728280\n",
      "epoch 0; iter: 200; batch classifier loss: 29.455738; batch adversarial loss: 0.653440\n",
      "epoch 1; iter: 0; batch classifier loss: 7.677632; batch adversarial loss: 0.639681\n",
      "epoch 1; iter: 200; batch classifier loss: 2.345544; batch adversarial loss: 0.608574\n",
      "epoch 2; iter: 0; batch classifier loss: 3.435966; batch adversarial loss: 0.634651\n",
      "epoch 2; iter: 200; batch classifier loss: 2.789141; batch adversarial loss: 0.640235\n",
      "epoch 3; iter: 0; batch classifier loss: 1.704632; batch adversarial loss: 0.665210\n",
      "epoch 3; iter: 200; batch classifier loss: 4.605793; batch adversarial loss: 0.614881\n",
      "epoch 4; iter: 0; batch classifier loss: 0.632113; batch adversarial loss: 0.657871\n",
      "epoch 4; iter: 200; batch classifier loss: 0.467440; batch adversarial loss: 0.621503\n",
      "epoch 5; iter: 0; batch classifier loss: 0.457569; batch adversarial loss: 0.582451\n",
      "epoch 5; iter: 200; batch classifier loss: 0.620804; batch adversarial loss: 0.689478\n",
      "epoch 6; iter: 0; batch classifier loss: 1.066599; batch adversarial loss: 0.634009\n",
      "epoch 6; iter: 200; batch classifier loss: 0.744429; batch adversarial loss: 0.659706\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493000; batch adversarial loss: 0.640070\n",
      "epoch 7; iter: 200; batch classifier loss: 0.573827; batch adversarial loss: 0.663265\n",
      "epoch 8; iter: 0; batch classifier loss: 0.365197; batch adversarial loss: 0.612404\n",
      "epoch 8; iter: 200; batch classifier loss: 0.503596; batch adversarial loss: 0.646972\n",
      "epoch 9; iter: 0; batch classifier loss: 0.515975; batch adversarial loss: 0.664117\n",
      "epoch 9; iter: 200; batch classifier loss: 0.413288; batch adversarial loss: 0.603322\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388574; batch adversarial loss: 0.626134\n",
      "epoch 10; iter: 200; batch classifier loss: 0.378951; batch adversarial loss: 0.604271\n",
      "epoch 11; iter: 0; batch classifier loss: 0.436853; batch adversarial loss: 0.635067\n",
      "epoch 11; iter: 200; batch classifier loss: 0.367739; batch adversarial loss: 0.579594\n",
      "epoch 12; iter: 0; batch classifier loss: 0.856171; batch adversarial loss: 0.603366\n",
      "epoch 12; iter: 200; batch classifier loss: 0.320750; batch adversarial loss: 0.626188\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349440; batch adversarial loss: 0.605365\n",
      "epoch 13; iter: 200; batch classifier loss: 0.298970; batch adversarial loss: 0.674202\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432349; batch adversarial loss: 0.610210\n",
      "epoch 14; iter: 200; batch classifier loss: 0.336733; batch adversarial loss: 0.615188\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347314; batch adversarial loss: 0.615913\n",
      "epoch 15; iter: 200; batch classifier loss: 0.350805; batch adversarial loss: 0.672183\n",
      "epoch 16; iter: 0; batch classifier loss: 0.359200; batch adversarial loss: 0.607133\n",
      "epoch 16; iter: 200; batch classifier loss: 0.462532; batch adversarial loss: 0.666240\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328677; batch adversarial loss: 0.600657\n",
      "epoch 17; iter: 200; batch classifier loss: 0.386346; batch adversarial loss: 0.598252\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439270; batch adversarial loss: 0.586869\n",
      "epoch 18; iter: 200; batch classifier loss: 0.335199; batch adversarial loss: 0.603083\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313672; batch adversarial loss: 0.633257\n",
      "epoch 19; iter: 200; batch classifier loss: 0.367522; batch adversarial loss: 0.670950\n",
      "epoch 20; iter: 0; batch classifier loss: 0.398264; batch adversarial loss: 0.655965\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368603; batch adversarial loss: 0.638334\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355492; batch adversarial loss: 0.595189\n",
      "epoch 21; iter: 200; batch classifier loss: 0.457344; batch adversarial loss: 0.566901\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348338; batch adversarial loss: 0.568919\n",
      "epoch 22; iter: 200; batch classifier loss: 0.308424; batch adversarial loss: 0.566875\n",
      "epoch 23; iter: 0; batch classifier loss: 0.368003; batch adversarial loss: 0.591084\n",
      "epoch 23; iter: 200; batch classifier loss: 0.378069; batch adversarial loss: 0.645817\n",
      "epoch 24; iter: 0; batch classifier loss: 0.374999; batch adversarial loss: 0.625179\n",
      "epoch 24; iter: 200; batch classifier loss: 0.456354; batch adversarial loss: 0.661746\n",
      "epoch 25; iter: 0; batch classifier loss: 0.363610; batch adversarial loss: 0.581380\n",
      "epoch 25; iter: 200; batch classifier loss: 0.393849; batch adversarial loss: 0.604170\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352483; batch adversarial loss: 0.593226\n",
      "epoch 26; iter: 200; batch classifier loss: 0.353278; batch adversarial loss: 0.660943\n",
      "epoch 27; iter: 0; batch classifier loss: 0.430909; batch adversarial loss: 0.649143\n",
      "epoch 27; iter: 200; batch classifier loss: 0.363957; batch adversarial loss: 0.670294\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265684; batch adversarial loss: 0.552214\n",
      "epoch 28; iter: 200; batch classifier loss: 0.299830; batch adversarial loss: 0.561665\n",
      "epoch 29; iter: 0; batch classifier loss: 0.326424; batch adversarial loss: 0.661963\n",
      "epoch 29; iter: 200; batch classifier loss: 0.505524; batch adversarial loss: 0.593217\n",
      "epoch 30; iter: 0; batch classifier loss: 0.274636; batch adversarial loss: 0.652668\n",
      "epoch 30; iter: 200; batch classifier loss: 0.328779; batch adversarial loss: 0.614445\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443389; batch adversarial loss: 0.631056\n",
      "epoch 31; iter: 200; batch classifier loss: 0.344411; batch adversarial loss: 0.633144\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309173; batch adversarial loss: 0.593295\n",
      "epoch 32; iter: 200; batch classifier loss: 0.527017; batch adversarial loss: 0.662509\n",
      "epoch 33; iter: 0; batch classifier loss: 0.284032; batch adversarial loss: 0.657849\n",
      "epoch 33; iter: 200; batch classifier loss: 0.240777; batch adversarial loss: 0.665821\n",
      "epoch 34; iter: 0; batch classifier loss: 0.357296; batch adversarial loss: 0.534044\n",
      "epoch 34; iter: 200; batch classifier loss: 0.351083; batch adversarial loss: 0.648452\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437816; batch adversarial loss: 0.601255\n",
      "epoch 35; iter: 200; batch classifier loss: 0.372748; batch adversarial loss: 0.623891\n",
      "epoch 36; iter: 0; batch classifier loss: 0.352917; batch adversarial loss: 0.592319\n",
      "epoch 36; iter: 200; batch classifier loss: 0.313183; batch adversarial loss: 0.556044\n",
      "epoch 37; iter: 0; batch classifier loss: 0.243771; batch adversarial loss: 0.649170\n",
      "epoch 37; iter: 200; batch classifier loss: 0.352766; batch adversarial loss: 0.607030\n",
      "epoch 38; iter: 0; batch classifier loss: 0.304859; batch adversarial loss: 0.591781\n",
      "epoch 38; iter: 200; batch classifier loss: 0.405161; batch adversarial loss: 0.616151\n",
      "epoch 39; iter: 0; batch classifier loss: 0.297463; batch adversarial loss: 0.578179\n",
      "epoch 39; iter: 200; batch classifier loss: 0.295127; batch adversarial loss: 0.647766\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351150; batch adversarial loss: 0.615976\n",
      "epoch 40; iter: 200; batch classifier loss: 0.408070; batch adversarial loss: 0.626013\n",
      "epoch 41; iter: 0; batch classifier loss: 0.336114; batch adversarial loss: 0.703719\n",
      "epoch 41; iter: 200; batch classifier loss: 0.456675; batch adversarial loss: 0.635561\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440899; batch adversarial loss: 0.620873\n",
      "epoch 42; iter: 200; batch classifier loss: 0.284238; batch adversarial loss: 0.570647\n",
      "epoch 43; iter: 0; batch classifier loss: 0.348387; batch adversarial loss: 0.627114\n",
      "epoch 43; iter: 200; batch classifier loss: 0.279993; batch adversarial loss: 0.602110\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392287; batch adversarial loss: 0.717254\n",
      "epoch 44; iter: 200; batch classifier loss: 0.442043; batch adversarial loss: 0.586001\n",
      "epoch 45; iter: 0; batch classifier loss: 0.329415; batch adversarial loss: 0.603853\n",
      "epoch 45; iter: 200; batch classifier loss: 0.355897; batch adversarial loss: 0.626895\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331048; batch adversarial loss: 0.661397\n",
      "epoch 46; iter: 200; batch classifier loss: 0.369365; batch adversarial loss: 0.614841\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436940; batch adversarial loss: 0.663450\n",
      "epoch 47; iter: 200; batch classifier loss: 0.396374; batch adversarial loss: 0.670271\n",
      "epoch 48; iter: 0; batch classifier loss: 0.692569; batch adversarial loss: 0.582755\n",
      "epoch 48; iter: 200; batch classifier loss: 0.447957; batch adversarial loss: 0.575066\n",
      "epoch 49; iter: 0; batch classifier loss: 0.244595; batch adversarial loss: 0.671509\n",
      "epoch 49; iter: 200; batch classifier loss: 0.450935; batch adversarial loss: 0.701570\n",
      "epoch 0; iter: 0; batch classifier loss: 24.886629; batch adversarial loss: 0.856607\n",
      "epoch 0; iter: 200; batch classifier loss: 5.962457; batch adversarial loss: 0.710106\n",
      "epoch 1; iter: 0; batch classifier loss: 7.680951; batch adversarial loss: 0.713565\n",
      "epoch 1; iter: 200; batch classifier loss: 5.864575; batch adversarial loss: 0.699148\n",
      "epoch 2; iter: 0; batch classifier loss: 3.133997; batch adversarial loss: 0.675501\n",
      "epoch 2; iter: 200; batch classifier loss: 1.316182; batch adversarial loss: 0.610573\n",
      "epoch 3; iter: 0; batch classifier loss: 1.204373; batch adversarial loss: 0.657741\n",
      "epoch 3; iter: 200; batch classifier loss: 0.754383; batch adversarial loss: 0.648982\n",
      "epoch 4; iter: 0; batch classifier loss: 2.122497; batch adversarial loss: 0.659997\n",
      "epoch 4; iter: 200; batch classifier loss: 2.611930; batch adversarial loss: 0.593763\n",
      "epoch 5; iter: 0; batch classifier loss: 1.345568; batch adversarial loss: 0.602000\n",
      "epoch 5; iter: 200; batch classifier loss: 0.911331; batch adversarial loss: 0.612578\n",
      "epoch 6; iter: 0; batch classifier loss: 0.671816; batch adversarial loss: 0.609513\n",
      "epoch 6; iter: 200; batch classifier loss: 0.471086; batch adversarial loss: 0.647430\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512526; batch adversarial loss: 0.633131\n",
      "epoch 7; iter: 200; batch classifier loss: 0.661325; batch adversarial loss: 0.625805\n",
      "epoch 8; iter: 0; batch classifier loss: 0.657782; batch adversarial loss: 0.664811\n",
      "epoch 8; iter: 200; batch classifier loss: 0.297272; batch adversarial loss: 0.630018\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359959; batch adversarial loss: 0.659347\n",
      "epoch 9; iter: 200; batch classifier loss: 0.456040; batch adversarial loss: 0.642540\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366055; batch adversarial loss: 0.611654\n",
      "epoch 10; iter: 200; batch classifier loss: 0.423719; batch adversarial loss: 0.606352\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464460; batch adversarial loss: 0.633664\n",
      "epoch 11; iter: 200; batch classifier loss: 0.462231; batch adversarial loss: 0.601475\n",
      "epoch 12; iter: 0; batch classifier loss: 0.358217; batch adversarial loss: 0.641124\n",
      "epoch 12; iter: 200; batch classifier loss: 0.353350; batch adversarial loss: 0.661055\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411409; batch adversarial loss: 0.595465\n",
      "epoch 13; iter: 200; batch classifier loss: 0.367273; batch adversarial loss: 0.659533\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313617; batch adversarial loss: 0.590292\n",
      "epoch 14; iter: 200; batch classifier loss: 0.474420; batch adversarial loss: 0.614359\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337482; batch adversarial loss: 0.613058\n",
      "epoch 15; iter: 200; batch classifier loss: 0.386343; batch adversarial loss: 0.623449\n",
      "epoch 16; iter: 0; batch classifier loss: 0.400506; batch adversarial loss: 0.626771\n",
      "epoch 16; iter: 200; batch classifier loss: 0.377863; batch adversarial loss: 0.623984\n",
      "epoch 17; iter: 0; batch classifier loss: 0.498340; batch adversarial loss: 0.625738\n",
      "epoch 17; iter: 200; batch classifier loss: 0.368992; batch adversarial loss: 0.640202\n",
      "epoch 18; iter: 0; batch classifier loss: 0.369128; batch adversarial loss: 0.624799\n",
      "epoch 18; iter: 200; batch classifier loss: 0.263768; batch adversarial loss: 0.629169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376687; batch adversarial loss: 0.619879\n",
      "epoch 19; iter: 200; batch classifier loss: 0.254172; batch adversarial loss: 0.585168\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435174; batch adversarial loss: 0.586312\n",
      "epoch 20; iter: 200; batch classifier loss: 0.249792; batch adversarial loss: 0.664944\n",
      "epoch 21; iter: 0; batch classifier loss: 0.438706; batch adversarial loss: 0.653258\n",
      "epoch 21; iter: 200; batch classifier loss: 0.299473; batch adversarial loss: 0.655882\n",
      "epoch 22; iter: 0; batch classifier loss: 0.376645; batch adversarial loss: 0.567878\n",
      "epoch 22; iter: 200; batch classifier loss: 0.269163; batch adversarial loss: 0.649425\n",
      "epoch 23; iter: 0; batch classifier loss: 0.404075; batch adversarial loss: 0.614892\n",
      "epoch 23; iter: 200; batch classifier loss: 0.383250; batch adversarial loss: 0.633530\n",
      "epoch 24; iter: 0; batch classifier loss: 0.294076; batch adversarial loss: 0.637903\n",
      "epoch 24; iter: 200; batch classifier loss: 0.340241; batch adversarial loss: 0.613197\n",
      "epoch 25; iter: 0; batch classifier loss: 0.343142; batch adversarial loss: 0.614314\n",
      "epoch 25; iter: 200; batch classifier loss: 0.350936; batch adversarial loss: 0.660278\n",
      "epoch 26; iter: 0; batch classifier loss: 0.281908; batch adversarial loss: 0.642026\n",
      "epoch 26; iter: 200; batch classifier loss: 0.353801; batch adversarial loss: 0.583136\n",
      "epoch 27; iter: 0; batch classifier loss: 0.466949; batch adversarial loss: 0.574466\n",
      "epoch 27; iter: 200; batch classifier loss: 0.403904; batch adversarial loss: 0.600344\n",
      "epoch 28; iter: 0; batch classifier loss: 0.326617; batch adversarial loss: 0.617748\n",
      "epoch 28; iter: 200; batch classifier loss: 0.352639; batch adversarial loss: 0.628798\n",
      "epoch 29; iter: 0; batch classifier loss: 0.251388; batch adversarial loss: 0.657629\n",
      "epoch 29; iter: 200; batch classifier loss: 0.312900; batch adversarial loss: 0.652477\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324039; batch adversarial loss: 0.658651\n",
      "epoch 30; iter: 200; batch classifier loss: 0.426531; batch adversarial loss: 0.589493\n",
      "epoch 31; iter: 0; batch classifier loss: 0.323409; batch adversarial loss: 0.630443\n",
      "epoch 31; iter: 200; batch classifier loss: 0.284335; batch adversarial loss: 0.656930\n",
      "epoch 32; iter: 0; batch classifier loss: 0.280812; batch adversarial loss: 0.632483\n",
      "epoch 32; iter: 200; batch classifier loss: 0.318014; batch adversarial loss: 0.655479\n",
      "epoch 33; iter: 0; batch classifier loss: 0.422969; batch adversarial loss: 0.590066\n",
      "epoch 33; iter: 200; batch classifier loss: 0.368170; batch adversarial loss: 0.637485\n",
      "epoch 34; iter: 0; batch classifier loss: 0.258640; batch adversarial loss: 0.654566\n",
      "epoch 34; iter: 200; batch classifier loss: 0.386169; batch adversarial loss: 0.638533\n",
      "epoch 35; iter: 0; batch classifier loss: 0.336214; batch adversarial loss: 0.616777\n",
      "epoch 35; iter: 200; batch classifier loss: 0.374150; batch adversarial loss: 0.580311\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400201; batch adversarial loss: 0.573470\n",
      "epoch 36; iter: 200; batch classifier loss: 0.326486; batch adversarial loss: 0.630579\n",
      "epoch 37; iter: 0; batch classifier loss: 0.341079; batch adversarial loss: 0.603865\n",
      "epoch 37; iter: 200; batch classifier loss: 0.429780; batch adversarial loss: 0.600347\n",
      "epoch 38; iter: 0; batch classifier loss: 0.292143; batch adversarial loss: 0.623812\n",
      "epoch 38; iter: 200; batch classifier loss: 0.304267; batch adversarial loss: 0.601179\n",
      "epoch 39; iter: 0; batch classifier loss: 0.333300; batch adversarial loss: 0.622261\n",
      "epoch 39; iter: 200; batch classifier loss: 0.305840; batch adversarial loss: 0.601179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383016; batch adversarial loss: 0.591242\n",
      "epoch 40; iter: 200; batch classifier loss: 0.281986; batch adversarial loss: 0.624820\n",
      "epoch 41; iter: 0; batch classifier loss: 0.307179; batch adversarial loss: 0.672377\n",
      "epoch 41; iter: 200; batch classifier loss: 0.316019; batch adversarial loss: 0.683607\n",
      "epoch 42; iter: 0; batch classifier loss: 0.366788; batch adversarial loss: 0.664716\n",
      "epoch 42; iter: 200; batch classifier loss: 0.398982; batch adversarial loss: 0.579265\n",
      "epoch 43; iter: 0; batch classifier loss: 0.544357; batch adversarial loss: 0.653331\n",
      "epoch 43; iter: 200; batch classifier loss: 0.285787; batch adversarial loss: 0.674897\n",
      "epoch 44; iter: 0; batch classifier loss: 0.357610; batch adversarial loss: 0.595566\n",
      "epoch 44; iter: 200; batch classifier loss: 0.373773; batch adversarial loss: 0.647202\n",
      "epoch 45; iter: 0; batch classifier loss: 0.281631; batch adversarial loss: 0.650989\n",
      "epoch 45; iter: 200; batch classifier loss: 0.420468; batch adversarial loss: 0.576682\n",
      "epoch 46; iter: 0; batch classifier loss: 0.349312; batch adversarial loss: 0.650812\n",
      "epoch 46; iter: 200; batch classifier loss: 0.285503; batch adversarial loss: 0.644332\n",
      "epoch 47; iter: 0; batch classifier loss: 0.324567; batch adversarial loss: 0.649371\n",
      "epoch 47; iter: 200; batch classifier loss: 0.322803; batch adversarial loss: 0.617918\n",
      "epoch 48; iter: 0; batch classifier loss: 0.352698; batch adversarial loss: 0.640347\n",
      "epoch 48; iter: 200; batch classifier loss: 0.394077; batch adversarial loss: 0.619432\n",
      "epoch 49; iter: 0; batch classifier loss: 0.345173; batch adversarial loss: 0.687405\n",
      "epoch 49; iter: 200; batch classifier loss: 0.333862; batch adversarial loss: 0.625819\n",
      "epoch 0; iter: 0; batch classifier loss: 50.083927; batch adversarial loss: 1.019222\n",
      "epoch 0; iter: 200; batch classifier loss: 4.052598; batch adversarial loss: 0.735092\n",
      "epoch 1; iter: 0; batch classifier loss: 5.554857; batch adversarial loss: 0.705757\n",
      "epoch 1; iter: 200; batch classifier loss: 7.202199; batch adversarial loss: 0.784753\n",
      "epoch 2; iter: 0; batch classifier loss: 0.930328; batch adversarial loss: 0.685173\n",
      "epoch 2; iter: 200; batch classifier loss: 1.043746; batch adversarial loss: 0.671458\n",
      "epoch 3; iter: 0; batch classifier loss: 1.745192; batch adversarial loss: 0.678608\n",
      "epoch 3; iter: 200; batch classifier loss: 1.094673; batch adversarial loss: 0.650807\n",
      "epoch 4; iter: 0; batch classifier loss: 4.325007; batch adversarial loss: 0.585647\n",
      "epoch 4; iter: 200; batch classifier loss: 2.236048; batch adversarial loss: 0.605210\n",
      "epoch 5; iter: 0; batch classifier loss: 3.094284; batch adversarial loss: 0.639735\n",
      "epoch 5; iter: 200; batch classifier loss: 0.485110; batch adversarial loss: 0.710174\n",
      "epoch 6; iter: 0; batch classifier loss: 0.844088; batch adversarial loss: 0.595625\n",
      "epoch 6; iter: 200; batch classifier loss: 0.586419; batch adversarial loss: 0.593243\n",
      "epoch 7; iter: 0; batch classifier loss: 0.674437; batch adversarial loss: 0.638581\n",
      "epoch 7; iter: 200; batch classifier loss: 0.584691; batch adversarial loss: 0.592136\n",
      "epoch 8; iter: 0; batch classifier loss: 0.738117; batch adversarial loss: 0.665111\n",
      "epoch 8; iter: 200; batch classifier loss: 0.377131; batch adversarial loss: 0.689263\n",
      "epoch 9; iter: 0; batch classifier loss: 0.382040; batch adversarial loss: 0.594653\n",
      "epoch 9; iter: 200; batch classifier loss: 0.343923; batch adversarial loss: 0.663179\n",
      "epoch 10; iter: 0; batch classifier loss: 0.396678; batch adversarial loss: 0.588893\n",
      "epoch 10; iter: 200; batch classifier loss: 0.539049; batch adversarial loss: 0.674169\n",
      "epoch 11; iter: 0; batch classifier loss: 0.432409; batch adversarial loss: 0.597036\n",
      "epoch 11; iter: 200; batch classifier loss: 0.372379; batch adversarial loss: 0.650515\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369860; batch adversarial loss: 0.679121\n",
      "epoch 12; iter: 200; batch classifier loss: 0.364870; batch adversarial loss: 0.652140\n",
      "epoch 13; iter: 0; batch classifier loss: 0.471628; batch adversarial loss: 0.569304\n",
      "epoch 13; iter: 200; batch classifier loss: 0.448066; batch adversarial loss: 0.644388\n",
      "epoch 14; iter: 0; batch classifier loss: 0.291932; batch adversarial loss: 0.591411\n",
      "epoch 14; iter: 200; batch classifier loss: 0.384008; batch adversarial loss: 0.641692\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327597; batch adversarial loss: 0.653647\n",
      "epoch 15; iter: 200; batch classifier loss: 0.369414; batch adversarial loss: 0.593057\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404480; batch adversarial loss: 0.631155\n",
      "epoch 16; iter: 200; batch classifier loss: 0.434139; batch adversarial loss: 0.587618\n",
      "epoch 17; iter: 0; batch classifier loss: 0.423958; batch adversarial loss: 0.619169\n",
      "epoch 17; iter: 200; batch classifier loss: 0.421349; batch adversarial loss: 0.588805\n",
      "epoch 18; iter: 0; batch classifier loss: 0.405527; batch adversarial loss: 0.637936\n",
      "epoch 18; iter: 200; batch classifier loss: 0.467140; batch adversarial loss: 0.626238\n",
      "epoch 19; iter: 0; batch classifier loss: 0.398044; batch adversarial loss: 0.591437\n",
      "epoch 19; iter: 200; batch classifier loss: 0.370178; batch adversarial loss: 0.635748\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361180; batch adversarial loss: 0.638583\n",
      "epoch 20; iter: 200; batch classifier loss: 0.411933; batch adversarial loss: 0.606053\n",
      "epoch 21; iter: 0; batch classifier loss: 0.302167; batch adversarial loss: 0.570575\n",
      "epoch 21; iter: 200; batch classifier loss: 0.355665; batch adversarial loss: 0.637686\n",
      "epoch 22; iter: 0; batch classifier loss: 0.229192; batch adversarial loss: 0.595470\n",
      "epoch 22; iter: 200; batch classifier loss: 0.411036; batch adversarial loss: 0.627015\n",
      "epoch 23; iter: 0; batch classifier loss: 0.304126; batch adversarial loss: 0.613063\n",
      "epoch 23; iter: 200; batch classifier loss: 0.342783; batch adversarial loss: 0.564973\n",
      "epoch 24; iter: 0; batch classifier loss: 0.335638; batch adversarial loss: 0.590571\n",
      "epoch 24; iter: 200; batch classifier loss: 0.315646; batch adversarial loss: 0.595022\n",
      "epoch 25; iter: 0; batch classifier loss: 0.331570; batch adversarial loss: 0.589225\n",
      "epoch 25; iter: 200; batch classifier loss: 0.313567; batch adversarial loss: 0.604309\n",
      "epoch 26; iter: 0; batch classifier loss: 0.318871; batch adversarial loss: 0.653191\n",
      "epoch 26; iter: 200; batch classifier loss: 0.293721; batch adversarial loss: 0.595512\n",
      "epoch 27; iter: 0; batch classifier loss: 0.381606; batch adversarial loss: 0.586450\n",
      "epoch 27; iter: 200; batch classifier loss: 0.421020; batch adversarial loss: 0.607965\n",
      "epoch 28; iter: 0; batch classifier loss: 0.394310; batch adversarial loss: 0.609278\n",
      "epoch 28; iter: 200; batch classifier loss: 0.328727; batch adversarial loss: 0.636542\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435171; batch adversarial loss: 0.670987\n",
      "epoch 29; iter: 200; batch classifier loss: 0.285682; batch adversarial loss: 0.622887\n",
      "epoch 30; iter: 0; batch classifier loss: 0.352159; batch adversarial loss: 0.594060\n",
      "epoch 30; iter: 200; batch classifier loss: 0.353231; batch adversarial loss: 0.622474\n",
      "epoch 31; iter: 0; batch classifier loss: 0.376874; batch adversarial loss: 0.622486\n",
      "epoch 31; iter: 200; batch classifier loss: 0.397157; batch adversarial loss: 0.609438\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364498; batch adversarial loss: 0.623122\n",
      "epoch 32; iter: 200; batch classifier loss: 0.387614; batch adversarial loss: 0.653438\n",
      "epoch 33; iter: 0; batch classifier loss: 0.361123; batch adversarial loss: 0.620857\n",
      "epoch 33; iter: 200; batch classifier loss: 0.325308; batch adversarial loss: 0.606360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.317206; batch adversarial loss: 0.638991\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338943; batch adversarial loss: 0.648384\n",
      "epoch 35; iter: 0; batch classifier loss: 0.345680; batch adversarial loss: 0.546623\n",
      "epoch 35; iter: 200; batch classifier loss: 0.282404; batch adversarial loss: 0.684906\n",
      "epoch 36; iter: 0; batch classifier loss: 0.338960; batch adversarial loss: 0.620980\n",
      "epoch 36; iter: 200; batch classifier loss: 0.294699; batch adversarial loss: 0.627365\n",
      "epoch 37; iter: 0; batch classifier loss: 0.264604; batch adversarial loss: 0.713194\n",
      "epoch 37; iter: 200; batch classifier loss: 0.354989; batch adversarial loss: 0.588387\n",
      "epoch 38; iter: 0; batch classifier loss: 0.319136; batch adversarial loss: 0.653578\n",
      "epoch 38; iter: 200; batch classifier loss: 0.312123; batch adversarial loss: 0.699203\n",
      "epoch 39; iter: 0; batch classifier loss: 0.284776; batch adversarial loss: 0.619325\n",
      "epoch 39; iter: 200; batch classifier loss: 0.344329; batch adversarial loss: 0.601132\n",
      "epoch 40; iter: 0; batch classifier loss: 0.353103; batch adversarial loss: 0.668838\n",
      "epoch 40; iter: 200; batch classifier loss: 0.518957; batch adversarial loss: 0.680153\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458323; batch adversarial loss: 0.580412\n",
      "epoch 41; iter: 200; batch classifier loss: 0.315896; batch adversarial loss: 0.613103\n",
      "epoch 42; iter: 0; batch classifier loss: 0.274530; batch adversarial loss: 0.628301\n",
      "epoch 42; iter: 200; batch classifier loss: 0.411153; batch adversarial loss: 0.634135\n",
      "epoch 43; iter: 0; batch classifier loss: 0.356134; batch adversarial loss: 0.594322\n",
      "epoch 43; iter: 200; batch classifier loss: 0.727332; batch adversarial loss: 0.591761\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406086; batch adversarial loss: 0.623093\n",
      "epoch 44; iter: 200; batch classifier loss: 0.395075; batch adversarial loss: 0.621364\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444018; batch adversarial loss: 0.645185\n",
      "epoch 45; iter: 200; batch classifier loss: 0.389283; batch adversarial loss: 0.633519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.296330; batch adversarial loss: 0.636293\n",
      "epoch 46; iter: 200; batch classifier loss: 0.310119; batch adversarial loss: 0.627920\n",
      "epoch 47; iter: 0; batch classifier loss: 0.333358; batch adversarial loss: 0.616968\n",
      "epoch 47; iter: 200; batch classifier loss: 0.299715; batch adversarial loss: 0.674896\n",
      "epoch 48; iter: 0; batch classifier loss: 0.637109; batch adversarial loss: 0.668283\n",
      "epoch 48; iter: 200; batch classifier loss: 0.350950; batch adversarial loss: 0.605257\n",
      "epoch 49; iter: 0; batch classifier loss: 0.328835; batch adversarial loss: 0.624069\n",
      "epoch 49; iter: 200; batch classifier loss: 0.387339; batch adversarial loss: 0.601901\n",
      "epoch 0; iter: 0; batch classifier loss: 98.952705; batch adversarial loss: 0.633276\n",
      "epoch 0; iter: 200; batch classifier loss: 1.586196; batch adversarial loss: 0.658805\n",
      "epoch 1; iter: 0; batch classifier loss: 10.640856; batch adversarial loss: 0.611789\n",
      "epoch 1; iter: 200; batch classifier loss: 5.820269; batch adversarial loss: 0.617692\n",
      "epoch 2; iter: 0; batch classifier loss: 5.398368; batch adversarial loss: 0.665007\n",
      "epoch 2; iter: 200; batch classifier loss: 5.851877; batch adversarial loss: 0.613784\n",
      "epoch 3; iter: 0; batch classifier loss: 3.410471; batch adversarial loss: 0.624333\n",
      "epoch 3; iter: 200; batch classifier loss: 1.111472; batch adversarial loss: 0.632928\n",
      "epoch 4; iter: 0; batch classifier loss: 0.684085; batch adversarial loss: 0.581420\n",
      "epoch 4; iter: 200; batch classifier loss: 0.971324; batch adversarial loss: 0.576195\n",
      "epoch 5; iter: 0; batch classifier loss: 3.480721; batch adversarial loss: 0.590196\n",
      "epoch 5; iter: 200; batch classifier loss: 1.267277; batch adversarial loss: 0.637422\n",
      "epoch 6; iter: 0; batch classifier loss: 2.471673; batch adversarial loss: 0.672417\n",
      "epoch 6; iter: 200; batch classifier loss: 2.054754; batch adversarial loss: 0.648212\n",
      "epoch 7; iter: 0; batch classifier loss: 0.412366; batch adversarial loss: 0.619582\n",
      "epoch 7; iter: 200; batch classifier loss: 1.956873; batch adversarial loss: 0.626592\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500692; batch adversarial loss: 0.618429\n",
      "epoch 8; iter: 200; batch classifier loss: 0.459772; batch adversarial loss: 0.656686\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601234; batch adversarial loss: 0.587507\n",
      "epoch 9; iter: 200; batch classifier loss: 0.463229; batch adversarial loss: 0.622936\n",
      "epoch 10; iter: 0; batch classifier loss: 0.593025; batch adversarial loss: 0.663280\n",
      "epoch 10; iter: 200; batch classifier loss: 0.789135; batch adversarial loss: 0.633996\n",
      "epoch 11; iter: 0; batch classifier loss: 1.823328; batch adversarial loss: 0.625638\n",
      "epoch 11; iter: 200; batch classifier loss: 0.443924; batch adversarial loss: 0.616463\n",
      "epoch 12; iter: 0; batch classifier loss: 0.315046; batch adversarial loss: 0.651357\n",
      "epoch 12; iter: 200; batch classifier loss: 0.456089; batch adversarial loss: 0.580665\n",
      "epoch 13; iter: 0; batch classifier loss: 1.006641; batch adversarial loss: 0.623073\n",
      "epoch 13; iter: 200; batch classifier loss: 0.705687; batch adversarial loss: 0.632007\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313094; batch adversarial loss: 0.593485\n",
      "epoch 14; iter: 200; batch classifier loss: 0.334135; batch adversarial loss: 0.609779\n",
      "epoch 15; iter: 0; batch classifier loss: 1.622040; batch adversarial loss: 0.728331\n",
      "epoch 15; iter: 200; batch classifier loss: 0.268431; batch adversarial loss: 0.615613\n",
      "epoch 16; iter: 0; batch classifier loss: 0.339904; batch adversarial loss: 0.625722\n",
      "epoch 16; iter: 200; batch classifier loss: 0.471540; batch adversarial loss: 0.651863\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345315; batch adversarial loss: 0.607220\n",
      "epoch 17; iter: 200; batch classifier loss: 0.308721; batch adversarial loss: 0.660010\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320044; batch adversarial loss: 0.626983\n",
      "epoch 18; iter: 200; batch classifier loss: 0.299712; batch adversarial loss: 0.624993\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385197; batch adversarial loss: 0.657196\n",
      "epoch 19; iter: 200; batch classifier loss: 0.391910; batch adversarial loss: 0.624087\n",
      "epoch 20; iter: 0; batch classifier loss: 0.367662; batch adversarial loss: 0.616717\n",
      "epoch 20; iter: 200; batch classifier loss: 0.599296; batch adversarial loss: 0.639011\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352061; batch adversarial loss: 0.662422\n",
      "epoch 21; iter: 200; batch classifier loss: 0.302637; batch adversarial loss: 0.630995\n",
      "epoch 22; iter: 0; batch classifier loss: 0.341531; batch adversarial loss: 0.641193\n",
      "epoch 22; iter: 200; batch classifier loss: 0.243282; batch adversarial loss: 0.611173\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333035; batch adversarial loss: 0.578835\n",
      "epoch 23; iter: 200; batch classifier loss: 0.390255; batch adversarial loss: 0.633886\n",
      "epoch 24; iter: 0; batch classifier loss: 0.392226; batch adversarial loss: 0.597860\n",
      "epoch 24; iter: 200; batch classifier loss: 0.412229; batch adversarial loss: 0.611411\n",
      "epoch 25; iter: 0; batch classifier loss: 0.324420; batch adversarial loss: 0.647960\n",
      "epoch 25; iter: 200; batch classifier loss: 0.528141; batch adversarial loss: 0.601329\n",
      "epoch 26; iter: 0; batch classifier loss: 0.353091; batch adversarial loss: 0.643497\n",
      "epoch 26; iter: 200; batch classifier loss: 0.342674; batch adversarial loss: 0.667514\n",
      "epoch 27; iter: 0; batch classifier loss: 0.260820; batch adversarial loss: 0.646328\n",
      "epoch 27; iter: 200; batch classifier loss: 0.419495; batch adversarial loss: 0.588647\n",
      "epoch 28; iter: 0; batch classifier loss: 0.383872; batch adversarial loss: 0.585456\n",
      "epoch 28; iter: 200; batch classifier loss: 0.396899; batch adversarial loss: 0.675005\n",
      "epoch 29; iter: 0; batch classifier loss: 0.327434; batch adversarial loss: 0.694313\n",
      "epoch 29; iter: 200; batch classifier loss: 0.386840; batch adversarial loss: 0.645768\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342075; batch adversarial loss: 0.601592\n",
      "epoch 30; iter: 200; batch classifier loss: 0.333203; batch adversarial loss: 0.684005\n",
      "epoch 31; iter: 0; batch classifier loss: 0.534589; batch adversarial loss: 0.629434\n",
      "epoch 31; iter: 200; batch classifier loss: 0.374663; batch adversarial loss: 0.603206\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256665; batch adversarial loss: 0.659923\n",
      "epoch 32; iter: 200; batch classifier loss: 0.432286; batch adversarial loss: 0.575609\n",
      "epoch 33; iter: 0; batch classifier loss: 0.345276; batch adversarial loss: 0.597148\n",
      "epoch 33; iter: 200; batch classifier loss: 0.283573; batch adversarial loss: 0.652798\n",
      "epoch 34; iter: 0; batch classifier loss: 0.366375; batch adversarial loss: 0.595872\n",
      "epoch 34; iter: 200; batch classifier loss: 0.326287; batch adversarial loss: 0.635189\n",
      "epoch 35; iter: 0; batch classifier loss: 0.358846; batch adversarial loss: 0.624408\n",
      "epoch 35; iter: 200; batch classifier loss: 0.377385; batch adversarial loss: 0.618053\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464220; batch adversarial loss: 0.644990\n",
      "epoch 36; iter: 200; batch classifier loss: 0.329236; batch adversarial loss: 0.620750\n",
      "epoch 37; iter: 0; batch classifier loss: 0.372403; batch adversarial loss: 0.628479\n",
      "epoch 37; iter: 200; batch classifier loss: 0.313173; batch adversarial loss: 0.648771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398970; batch adversarial loss: 0.600356\n",
      "epoch 38; iter: 200; batch classifier loss: 0.334922; batch adversarial loss: 0.572791\n",
      "epoch 39; iter: 0; batch classifier loss: 0.340646; batch adversarial loss: 0.630157\n",
      "epoch 39; iter: 200; batch classifier loss: 0.397713; batch adversarial loss: 0.666815\n",
      "epoch 40; iter: 0; batch classifier loss: 0.491375; batch adversarial loss: 0.609532\n",
      "epoch 40; iter: 200; batch classifier loss: 0.458822; batch adversarial loss: 0.661305\n",
      "epoch 41; iter: 0; batch classifier loss: 0.292941; batch adversarial loss: 0.617272\n",
      "epoch 41; iter: 200; batch classifier loss: 0.344159; batch adversarial loss: 0.659885\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403566; batch adversarial loss: 0.612813\n",
      "epoch 42; iter: 200; batch classifier loss: 0.423403; batch adversarial loss: 0.638948\n",
      "epoch 43; iter: 0; batch classifier loss: 0.254069; batch adversarial loss: 0.626783\n",
      "epoch 43; iter: 200; batch classifier loss: 0.325363; batch adversarial loss: 0.667614\n",
      "epoch 44; iter: 0; batch classifier loss: 0.305869; batch adversarial loss: 0.608287\n",
      "epoch 44; iter: 200; batch classifier loss: 0.352984; batch adversarial loss: 0.625425\n",
      "epoch 45; iter: 0; batch classifier loss: 0.369484; batch adversarial loss: 0.652091\n",
      "epoch 45; iter: 200; batch classifier loss: 0.295825; batch adversarial loss: 0.617575\n",
      "epoch 46; iter: 0; batch classifier loss: 0.249963; batch adversarial loss: 0.638681\n",
      "epoch 46; iter: 200; batch classifier loss: 0.529865; batch adversarial loss: 0.696545\n",
      "epoch 47; iter: 0; batch classifier loss: 0.273754; batch adversarial loss: 0.634132\n",
      "epoch 47; iter: 200; batch classifier loss: 0.386067; batch adversarial loss: 0.609059\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397668; batch adversarial loss: 0.635141\n",
      "epoch 48; iter: 200; batch classifier loss: 0.408294; batch adversarial loss: 0.592224\n",
      "epoch 49; iter: 0; batch classifier loss: 0.374733; batch adversarial loss: 0.587103\n",
      "epoch 49; iter: 200; batch classifier loss: 0.400947; batch adversarial loss: 0.634919\n",
      "epoch 0; iter: 0; batch classifier loss: 2.251531; batch adversarial loss: 0.694663\n",
      "epoch 0; iter: 200; batch classifier loss: 5.316207; batch adversarial loss: 0.634829\n",
      "epoch 1; iter: 0; batch classifier loss: 2.523535; batch adversarial loss: 0.648998\n",
      "epoch 1; iter: 200; batch classifier loss: 2.752030; batch adversarial loss: 0.650876\n",
      "epoch 2; iter: 0; batch classifier loss: 2.034167; batch adversarial loss: 0.551990\n",
      "epoch 2; iter: 200; batch classifier loss: 1.984107; batch adversarial loss: 0.665218\n",
      "epoch 3; iter: 0; batch classifier loss: 1.223551; batch adversarial loss: 0.643947\n",
      "epoch 3; iter: 200; batch classifier loss: 2.169033; batch adversarial loss: 0.643818\n",
      "epoch 4; iter: 0; batch classifier loss: 1.290745; batch adversarial loss: 0.622878\n",
      "epoch 4; iter: 200; batch classifier loss: 0.923337; batch adversarial loss: 0.606537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.412405; batch adversarial loss: 0.614814\n",
      "epoch 5; iter: 200; batch classifier loss: 0.808393; batch adversarial loss: 0.627074\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532062; batch adversarial loss: 0.625208\n",
      "epoch 6; iter: 200; batch classifier loss: 0.464810; batch adversarial loss: 0.627327\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604181; batch adversarial loss: 0.666356\n",
      "epoch 7; iter: 200; batch classifier loss: 0.535368; batch adversarial loss: 0.639673\n",
      "epoch 8; iter: 0; batch classifier loss: 1.408098; batch adversarial loss: 0.634021\n",
      "epoch 8; iter: 200; batch classifier loss: 0.435334; batch adversarial loss: 0.633812\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476060; batch adversarial loss: 0.624369\n",
      "epoch 9; iter: 200; batch classifier loss: 0.487447; batch adversarial loss: 0.580642\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499990; batch adversarial loss: 0.632318\n",
      "epoch 10; iter: 200; batch classifier loss: 0.408369; batch adversarial loss: 0.685740\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412188; batch adversarial loss: 0.658860\n",
      "epoch 11; iter: 200; batch classifier loss: 0.394995; batch adversarial loss: 0.604629\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405363; batch adversarial loss: 0.629303\n",
      "epoch 12; iter: 200; batch classifier loss: 0.307085; batch adversarial loss: 0.685625\n",
      "epoch 13; iter: 0; batch classifier loss: 0.414992; batch adversarial loss: 0.597309\n",
      "epoch 13; iter: 200; batch classifier loss: 0.383122; batch adversarial loss: 0.630509\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356718; batch adversarial loss: 0.610041\n",
      "epoch 14; iter: 200; batch classifier loss: 0.373637; batch adversarial loss: 0.663451\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375496; batch adversarial loss: 0.631502\n",
      "epoch 15; iter: 200; batch classifier loss: 0.354400; batch adversarial loss: 0.641425\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346140; batch adversarial loss: 0.611593\n",
      "epoch 16; iter: 200; batch classifier loss: 0.336478; batch adversarial loss: 0.612101\n",
      "epoch 17; iter: 0; batch classifier loss: 0.531934; batch adversarial loss: 0.620877\n",
      "epoch 17; iter: 200; batch classifier loss: 0.411336; batch adversarial loss: 0.598819\n",
      "epoch 18; iter: 0; batch classifier loss: 0.399636; batch adversarial loss: 0.629373\n",
      "epoch 18; iter: 200; batch classifier loss: 0.405527; batch adversarial loss: 0.637491\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317611; batch adversarial loss: 0.625185\n",
      "epoch 19; iter: 200; batch classifier loss: 0.373985; batch adversarial loss: 0.617769\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454842; batch adversarial loss: 0.617823\n",
      "epoch 20; iter: 200; batch classifier loss: 0.358259; batch adversarial loss: 0.617212\n",
      "epoch 21; iter: 0; batch classifier loss: 0.343869; batch adversarial loss: 0.710780\n",
      "epoch 21; iter: 200; batch classifier loss: 0.281226; batch adversarial loss: 0.671922\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354425; batch adversarial loss: 0.649247\n",
      "epoch 22; iter: 200; batch classifier loss: 0.377130; batch adversarial loss: 0.612902\n",
      "epoch 23; iter: 0; batch classifier loss: 0.265779; batch adversarial loss: 0.648362\n",
      "epoch 23; iter: 200; batch classifier loss: 0.261929; batch adversarial loss: 0.664445\n",
      "epoch 24; iter: 0; batch classifier loss: 0.322336; batch adversarial loss: 0.643373\n",
      "epoch 24; iter: 200; batch classifier loss: 0.605080; batch adversarial loss: 0.604371\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471905; batch adversarial loss: 0.604816\n",
      "epoch 25; iter: 200; batch classifier loss: 0.387928; batch adversarial loss: 0.609516\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297411; batch adversarial loss: 0.610656\n",
      "epoch 26; iter: 200; batch classifier loss: 0.388128; batch adversarial loss: 0.608710\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277280; batch adversarial loss: 0.658167\n",
      "epoch 27; iter: 200; batch classifier loss: 0.300811; batch adversarial loss: 0.623132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.329431; batch adversarial loss: 0.644069\n",
      "epoch 28; iter: 200; batch classifier loss: 0.434673; batch adversarial loss: 0.648451\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411818; batch adversarial loss: 0.591433\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338232; batch adversarial loss: 0.600945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.364425; batch adversarial loss: 0.634611\n",
      "epoch 30; iter: 200; batch classifier loss: 0.384511; batch adversarial loss: 0.603181\n",
      "epoch 31; iter: 0; batch classifier loss: 0.401754; batch adversarial loss: 0.518250\n",
      "epoch 31; iter: 200; batch classifier loss: 0.466158; batch adversarial loss: 0.653629\n",
      "epoch 32; iter: 0; batch classifier loss: 0.301124; batch adversarial loss: 0.634424\n",
      "epoch 32; iter: 200; batch classifier loss: 0.299300; batch adversarial loss: 0.639404\n",
      "epoch 33; iter: 0; batch classifier loss: 0.352471; batch adversarial loss: 0.640415\n",
      "epoch 33; iter: 200; batch classifier loss: 0.228410; batch adversarial loss: 0.630808\n",
      "epoch 34; iter: 0; batch classifier loss: 0.351768; batch adversarial loss: 0.683671\n",
      "epoch 34; iter: 200; batch classifier loss: 0.344034; batch adversarial loss: 0.647461\n",
      "epoch 35; iter: 0; batch classifier loss: 0.334580; batch adversarial loss: 0.644656\n",
      "epoch 35; iter: 200; batch classifier loss: 0.356345; batch adversarial loss: 0.645929\n",
      "epoch 36; iter: 0; batch classifier loss: 0.466669; batch adversarial loss: 0.659904\n",
      "epoch 36; iter: 200; batch classifier loss: 0.396175; batch adversarial loss: 0.635758\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457986; batch adversarial loss: 0.578283\n",
      "epoch 37; iter: 200; batch classifier loss: 0.256626; batch adversarial loss: 0.670884\n",
      "epoch 38; iter: 0; batch classifier loss: 0.371576; batch adversarial loss: 0.663888\n",
      "epoch 38; iter: 200; batch classifier loss: 0.298336; batch adversarial loss: 0.643239\n",
      "epoch 39; iter: 0; batch classifier loss: 0.406411; batch adversarial loss: 0.612247\n",
      "epoch 39; iter: 200; batch classifier loss: 0.295658; batch adversarial loss: 0.611428\n",
      "epoch 40; iter: 0; batch classifier loss: 0.355982; batch adversarial loss: 0.679017\n",
      "epoch 40; iter: 200; batch classifier loss: 0.376226; batch adversarial loss: 0.647991\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478494; batch adversarial loss: 0.630465\n",
      "epoch 41; iter: 200; batch classifier loss: 0.485687; batch adversarial loss: 0.603801\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470743; batch adversarial loss: 0.637771\n",
      "epoch 42; iter: 200; batch classifier loss: 0.220188; batch adversarial loss: 0.633849\n",
      "epoch 43; iter: 0; batch classifier loss: 0.345808; batch adversarial loss: 0.609436\n",
      "epoch 43; iter: 200; batch classifier loss: 0.381190; batch adversarial loss: 0.631551\n",
      "epoch 44; iter: 0; batch classifier loss: 0.342142; batch adversarial loss: 0.632902\n",
      "epoch 44; iter: 200; batch classifier loss: 0.377182; batch adversarial loss: 0.554081\n",
      "epoch 45; iter: 0; batch classifier loss: 0.335033; batch adversarial loss: 0.677632\n",
      "epoch 45; iter: 200; batch classifier loss: 0.294530; batch adversarial loss: 0.590360\n",
      "epoch 46; iter: 0; batch classifier loss: 0.240972; batch adversarial loss: 0.644744\n",
      "epoch 46; iter: 200; batch classifier loss: 0.315073; batch adversarial loss: 0.692819\n",
      "epoch 47; iter: 0; batch classifier loss: 0.296301; batch adversarial loss: 0.648212\n",
      "epoch 47; iter: 200; batch classifier loss: 0.342499; batch adversarial loss: 0.595233\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466349; batch adversarial loss: 0.558551\n",
      "epoch 48; iter: 200; batch classifier loss: 0.413278; batch adversarial loss: 0.596663\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404353; batch adversarial loss: 0.591675\n",
      "epoch 49; iter: 200; batch classifier loss: 0.447498; batch adversarial loss: 0.652399\n",
      "epoch 0; iter: 0; batch classifier loss: 18.334896; batch adversarial loss: 0.769106\n",
      "epoch 0; iter: 200; batch classifier loss: 6.937401; batch adversarial loss: 0.673474\n",
      "epoch 1; iter: 0; batch classifier loss: 16.415350; batch adversarial loss: 0.654129\n",
      "epoch 1; iter: 200; batch classifier loss: 12.028198; batch adversarial loss: 0.611561\n",
      "epoch 2; iter: 0; batch classifier loss: 7.829669; batch adversarial loss: 0.619708\n",
      "epoch 2; iter: 200; batch classifier loss: 3.133100; batch adversarial loss: 0.608059\n",
      "epoch 3; iter: 0; batch classifier loss: 5.164568; batch adversarial loss: 0.636132\n",
      "epoch 3; iter: 200; batch classifier loss: 7.681940; batch adversarial loss: 0.644325\n",
      "epoch 4; iter: 0; batch classifier loss: 1.688870; batch adversarial loss: 0.666971\n",
      "epoch 4; iter: 200; batch classifier loss: 0.609292; batch adversarial loss: 0.665195\n",
      "epoch 5; iter: 0; batch classifier loss: 0.746298; batch adversarial loss: 0.558062\n",
      "epoch 5; iter: 200; batch classifier loss: 1.175158; batch adversarial loss: 0.630745\n",
      "epoch 6; iter: 0; batch classifier loss: 1.341543; batch adversarial loss: 0.603798\n",
      "epoch 6; iter: 200; batch classifier loss: 1.154478; batch adversarial loss: 0.585133\n",
      "epoch 7; iter: 0; batch classifier loss: 1.304274; batch adversarial loss: 0.612504\n",
      "epoch 7; iter: 200; batch classifier loss: 1.191651; batch adversarial loss: 0.600138\n",
      "epoch 8; iter: 0; batch classifier loss: 1.316788; batch adversarial loss: 0.584018\n",
      "epoch 8; iter: 200; batch classifier loss: 0.871261; batch adversarial loss: 0.628146\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578571; batch adversarial loss: 0.634265\n",
      "epoch 9; iter: 200; batch classifier loss: 0.546482; batch adversarial loss: 0.631413\n",
      "epoch 10; iter: 0; batch classifier loss: 0.345564; batch adversarial loss: 0.682962\n",
      "epoch 10; iter: 200; batch classifier loss: 0.354430; batch adversarial loss: 0.673264\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347964; batch adversarial loss: 0.635756\n",
      "epoch 11; iter: 200; batch classifier loss: 0.622616; batch adversarial loss: 0.594778\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506016; batch adversarial loss: 0.663335\n",
      "epoch 12; iter: 200; batch classifier loss: 0.353832; batch adversarial loss: 0.607385\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420475; batch adversarial loss: 0.608314\n",
      "epoch 13; iter: 200; batch classifier loss: 0.445779; batch adversarial loss: 0.616292\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368843; batch adversarial loss: 0.657601\n",
      "epoch 14; iter: 200; batch classifier loss: 0.439005; batch adversarial loss: 0.590477\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477296; batch adversarial loss: 0.667746\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430468; batch adversarial loss: 0.657347\n",
      "epoch 16; iter: 0; batch classifier loss: 0.369275; batch adversarial loss: 0.639419\n",
      "epoch 16; iter: 200; batch classifier loss: 0.373658; batch adversarial loss: 0.638552\n",
      "epoch 17; iter: 0; batch classifier loss: 0.351097; batch adversarial loss: 0.591654\n",
      "epoch 17; iter: 200; batch classifier loss: 0.306507; batch adversarial loss: 0.617588\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519489; batch adversarial loss: 0.618570\n",
      "epoch 18; iter: 200; batch classifier loss: 0.417170; batch adversarial loss: 0.653004\n",
      "epoch 19; iter: 0; batch classifier loss: 0.389708; batch adversarial loss: 0.629184\n",
      "epoch 19; iter: 200; batch classifier loss: 0.388262; batch adversarial loss: 0.661527\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430059; batch adversarial loss: 0.609604\n",
      "epoch 20; iter: 200; batch classifier loss: 0.420666; batch adversarial loss: 0.621092\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424702; batch adversarial loss: 0.651309\n",
      "epoch 21; iter: 200; batch classifier loss: 0.432241; batch adversarial loss: 0.653608\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303995; batch adversarial loss: 0.593168\n",
      "epoch 22; iter: 200; batch classifier loss: 0.453638; batch adversarial loss: 0.574401\n",
      "epoch 23; iter: 0; batch classifier loss: 0.353255; batch adversarial loss: 0.617455\n",
      "epoch 23; iter: 200; batch classifier loss: 0.385098; batch adversarial loss: 0.624295\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253323; batch adversarial loss: 0.643756\n",
      "epoch 24; iter: 200; batch classifier loss: 0.246553; batch adversarial loss: 0.626138\n",
      "epoch 25; iter: 0; batch classifier loss: 0.381715; batch adversarial loss: 0.557131\n",
      "epoch 25; iter: 200; batch classifier loss: 0.417761; batch adversarial loss: 0.621846\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425161; batch adversarial loss: 0.587065\n",
      "epoch 26; iter: 200; batch classifier loss: 0.409180; batch adversarial loss: 0.597670\n",
      "epoch 27; iter: 0; batch classifier loss: 0.280659; batch adversarial loss: 0.628038\n",
      "epoch 27; iter: 200; batch classifier loss: 0.347963; batch adversarial loss: 0.642299\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369831; batch adversarial loss: 0.645747\n",
      "epoch 28; iter: 200; batch classifier loss: 0.357504; batch adversarial loss: 0.604409\n",
      "epoch 29; iter: 0; batch classifier loss: 0.370156; batch adversarial loss: 0.649126\n",
      "epoch 29; iter: 200; batch classifier loss: 0.428040; batch adversarial loss: 0.564659\n",
      "epoch 30; iter: 0; batch classifier loss: 0.402705; batch adversarial loss: 0.613235\n",
      "epoch 30; iter: 200; batch classifier loss: 0.371653; batch adversarial loss: 0.613354\n",
      "epoch 31; iter: 0; batch classifier loss: 0.367395; batch adversarial loss: 0.651279\n",
      "epoch 31; iter: 200; batch classifier loss: 0.325460; batch adversarial loss: 0.617141\n",
      "epoch 32; iter: 0; batch classifier loss: 0.287498; batch adversarial loss: 0.587189\n",
      "epoch 32; iter: 200; batch classifier loss: 0.332375; batch adversarial loss: 0.635552\n",
      "epoch 33; iter: 0; batch classifier loss: 0.365676; batch adversarial loss: 0.599616\n",
      "epoch 33; iter: 200; batch classifier loss: 0.311507; batch adversarial loss: 0.594250\n",
      "epoch 34; iter: 0; batch classifier loss: 0.290116; batch adversarial loss: 0.641286\n",
      "epoch 34; iter: 200; batch classifier loss: 0.257150; batch adversarial loss: 0.592854\n",
      "epoch 35; iter: 0; batch classifier loss: 0.302501; batch adversarial loss: 0.636126\n",
      "epoch 35; iter: 200; batch classifier loss: 0.316595; batch adversarial loss: 0.664071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.331507; batch adversarial loss: 0.584035\n",
      "epoch 36; iter: 200; batch classifier loss: 0.435581; batch adversarial loss: 0.578295\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389355; batch adversarial loss: 0.613128\n",
      "epoch 37; iter: 200; batch classifier loss: 0.250085; batch adversarial loss: 0.642001\n",
      "epoch 38; iter: 0; batch classifier loss: 0.356060; batch adversarial loss: 0.637689\n",
      "epoch 38; iter: 200; batch classifier loss: 0.313608; batch adversarial loss: 0.597610\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382964; batch adversarial loss: 0.566738\n",
      "epoch 39; iter: 200; batch classifier loss: 0.281236; batch adversarial loss: 0.592763\n",
      "epoch 40; iter: 0; batch classifier loss: 0.364856; batch adversarial loss: 0.577509\n",
      "epoch 40; iter: 200; batch classifier loss: 0.387697; batch adversarial loss: 0.651476\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410862; batch adversarial loss: 0.592445\n",
      "epoch 41; iter: 200; batch classifier loss: 0.329689; batch adversarial loss: 0.632515\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406089; batch adversarial loss: 0.624507\n",
      "epoch 42; iter: 200; batch classifier loss: 0.462317; batch adversarial loss: 0.614748\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402722; batch adversarial loss: 0.637896\n",
      "epoch 43; iter: 200; batch classifier loss: 0.402371; batch adversarial loss: 0.594890\n",
      "epoch 44; iter: 0; batch classifier loss: 0.282513; batch adversarial loss: 0.598699\n",
      "epoch 44; iter: 200; batch classifier loss: 0.452314; batch adversarial loss: 0.629042\n",
      "epoch 45; iter: 0; batch classifier loss: 0.345515; batch adversarial loss: 0.614112\n",
      "epoch 45; iter: 200; batch classifier loss: 0.379319; batch adversarial loss: 0.567041\n",
      "epoch 46; iter: 0; batch classifier loss: 0.366263; batch adversarial loss: 0.635370\n",
      "epoch 46; iter: 200; batch classifier loss: 0.367024; batch adversarial loss: 0.661222\n",
      "epoch 47; iter: 0; batch classifier loss: 0.347588; batch adversarial loss: 0.682233\n",
      "epoch 47; iter: 200; batch classifier loss: 0.440085; batch adversarial loss: 0.575726\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452498; batch adversarial loss: 0.664338\n",
      "epoch 48; iter: 200; batch classifier loss: 0.421405; batch adversarial loss: 0.627544\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389466; batch adversarial loss: 0.641681\n",
      "epoch 49; iter: 200; batch classifier loss: 0.390938; batch adversarial loss: 0.558896\n",
      "epoch 0; iter: 0; batch classifier loss: 15.049753; batch adversarial loss: 0.715863\n",
      "epoch 0; iter: 200; batch classifier loss: 17.063019; batch adversarial loss: 0.647225\n",
      "epoch 1; iter: 0; batch classifier loss: 9.050702; batch adversarial loss: 0.651108\n",
      "epoch 1; iter: 200; batch classifier loss: 6.769348; batch adversarial loss: 0.616432\n",
      "epoch 2; iter: 0; batch classifier loss: 4.191592; batch adversarial loss: 0.635775\n",
      "epoch 2; iter: 200; batch classifier loss: 3.883770; batch adversarial loss: 0.611617\n",
      "epoch 3; iter: 0; batch classifier loss: 2.337614; batch adversarial loss: 0.651387\n",
      "epoch 3; iter: 200; batch classifier loss: 3.715961; batch adversarial loss: 0.629256\n",
      "epoch 4; iter: 0; batch classifier loss: 1.637853; batch adversarial loss: 0.597680\n",
      "epoch 4; iter: 200; batch classifier loss: 1.005495; batch adversarial loss: 0.609386\n",
      "epoch 5; iter: 0; batch classifier loss: 0.332483; batch adversarial loss: 0.593052\n",
      "epoch 5; iter: 200; batch classifier loss: 0.478722; batch adversarial loss: 0.614666\n",
      "epoch 6; iter: 0; batch classifier loss: 0.866928; batch adversarial loss: 0.672252\n",
      "epoch 6; iter: 200; batch classifier loss: 0.506654; batch adversarial loss: 0.549369\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480378; batch adversarial loss: 0.631344\n",
      "epoch 7; iter: 200; batch classifier loss: 0.529528; batch adversarial loss: 0.635918\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396896; batch adversarial loss: 0.653241\n",
      "epoch 8; iter: 200; batch classifier loss: 0.308896; batch adversarial loss: 0.608764\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401930; batch adversarial loss: 0.606835\n",
      "epoch 9; iter: 200; batch classifier loss: 0.325056; batch adversarial loss: 0.664180\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343622; batch adversarial loss: 0.614072\n",
      "epoch 10; iter: 200; batch classifier loss: 0.758965; batch adversarial loss: 0.602715\n",
      "epoch 11; iter: 0; batch classifier loss: 0.408289; batch adversarial loss: 0.609746\n",
      "epoch 11; iter: 200; batch classifier loss: 0.323470; batch adversarial loss: 0.655005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360598; batch adversarial loss: 0.534045\n",
      "epoch 12; iter: 200; batch classifier loss: 0.361791; batch adversarial loss: 0.638887\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350989; batch adversarial loss: 0.559653\n",
      "epoch 13; iter: 200; batch classifier loss: 0.340635; batch adversarial loss: 0.588356\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384911; batch adversarial loss: 0.586258\n",
      "epoch 14; iter: 200; batch classifier loss: 0.371966; batch adversarial loss: 0.608961\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370279; batch adversarial loss: 0.581045\n",
      "epoch 15; iter: 200; batch classifier loss: 0.292109; batch adversarial loss: 0.620002\n",
      "epoch 16; iter: 0; batch classifier loss: 0.433949; batch adversarial loss: 0.622291\n",
      "epoch 16; iter: 200; batch classifier loss: 0.703697; batch adversarial loss: 0.631085\n",
      "epoch 17; iter: 0; batch classifier loss: 0.350940; batch adversarial loss: 0.621080\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321605; batch adversarial loss: 0.637472\n",
      "epoch 18; iter: 0; batch classifier loss: 0.394456; batch adversarial loss: 0.657910\n",
      "epoch 18; iter: 200; batch classifier loss: 0.325157; batch adversarial loss: 0.637774\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317471; batch adversarial loss: 0.645481\n",
      "epoch 19; iter: 200; batch classifier loss: 0.448734; batch adversarial loss: 0.647712\n",
      "epoch 20; iter: 0; batch classifier loss: 0.565210; batch adversarial loss: 0.659802\n",
      "epoch 20; iter: 200; batch classifier loss: 0.342182; batch adversarial loss: 0.622241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.362772; batch adversarial loss: 0.667472\n",
      "epoch 21; iter: 200; batch classifier loss: 0.414801; batch adversarial loss: 0.620711\n",
      "epoch 22; iter: 0; batch classifier loss: 0.448362; batch adversarial loss: 0.593071\n",
      "epoch 22; iter: 200; batch classifier loss: 0.367779; batch adversarial loss: 0.652994\n",
      "epoch 23; iter: 0; batch classifier loss: 0.368493; batch adversarial loss: 0.599147\n",
      "epoch 23; iter: 200; batch classifier loss: 0.414483; batch adversarial loss: 0.584566\n",
      "epoch 24; iter: 0; batch classifier loss: 0.313498; batch adversarial loss: 0.599168\n",
      "epoch 24; iter: 200; batch classifier loss: 0.301939; batch adversarial loss: 0.623000\n",
      "epoch 25; iter: 0; batch classifier loss: 0.341522; batch adversarial loss: 0.614793\n",
      "epoch 25; iter: 200; batch classifier loss: 0.334336; batch adversarial loss: 0.663364\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436486; batch adversarial loss: 0.656516\n",
      "epoch 26; iter: 200; batch classifier loss: 0.266446; batch adversarial loss: 0.641653\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411272; batch adversarial loss: 0.692015\n",
      "epoch 27; iter: 200; batch classifier loss: 0.327464; batch adversarial loss: 0.596360\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369307; batch adversarial loss: 0.629678\n",
      "epoch 28; iter: 200; batch classifier loss: 0.201974; batch adversarial loss: 0.670635\n",
      "epoch 29; iter: 0; batch classifier loss: 0.326517; batch adversarial loss: 0.560859\n",
      "epoch 29; iter: 200; batch classifier loss: 0.284851; batch adversarial loss: 0.585539\n",
      "epoch 30; iter: 0; batch classifier loss: 0.335369; batch adversarial loss: 0.642476\n",
      "epoch 30; iter: 200; batch classifier loss: 0.254301; batch adversarial loss: 0.634474\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441359; batch adversarial loss: 0.633506\n",
      "epoch 31; iter: 200; batch classifier loss: 0.368582; batch adversarial loss: 0.574804\n",
      "epoch 32; iter: 0; batch classifier loss: 0.354924; batch adversarial loss: 0.599473\n",
      "epoch 32; iter: 200; batch classifier loss: 0.357310; batch adversarial loss: 0.599243\n",
      "epoch 33; iter: 0; batch classifier loss: 0.315466; batch adversarial loss: 0.624692\n",
      "epoch 33; iter: 200; batch classifier loss: 0.365955; batch adversarial loss: 0.692142\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451506; batch adversarial loss: 0.625984\n",
      "epoch 34; iter: 200; batch classifier loss: 0.367522; batch adversarial loss: 0.698392\n",
      "epoch 35; iter: 0; batch classifier loss: 0.306533; batch adversarial loss: 0.653236\n",
      "epoch 35; iter: 200; batch classifier loss: 0.371988; batch adversarial loss: 0.590523\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478323; batch adversarial loss: 0.606713\n",
      "epoch 36; iter: 200; batch classifier loss: 0.305491; batch adversarial loss: 0.668342\n",
      "epoch 37; iter: 0; batch classifier loss: 0.433624; batch adversarial loss: 0.617971\n",
      "epoch 37; iter: 200; batch classifier loss: 0.302204; batch adversarial loss: 0.580228\n",
      "epoch 38; iter: 0; batch classifier loss: 0.298779; batch adversarial loss: 0.659845\n",
      "epoch 38; iter: 200; batch classifier loss: 0.363935; batch adversarial loss: 0.638018\n",
      "epoch 39; iter: 0; batch classifier loss: 0.365315; batch adversarial loss: 0.598452\n",
      "epoch 39; iter: 200; batch classifier loss: 0.736585; batch adversarial loss: 0.595596\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429599; batch adversarial loss: 0.674670\n",
      "epoch 40; iter: 200; batch classifier loss: 0.371904; batch adversarial loss: 0.633676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432611; batch adversarial loss: 0.623152\n",
      "epoch 41; iter: 200; batch classifier loss: 0.421312; batch adversarial loss: 0.519849\n",
      "epoch 42; iter: 0; batch classifier loss: 0.381647; batch adversarial loss: 0.581921\n",
      "epoch 42; iter: 200; batch classifier loss: 0.295426; batch adversarial loss: 0.617757\n",
      "epoch 43; iter: 0; batch classifier loss: 0.436187; batch adversarial loss: 0.691323\n",
      "epoch 43; iter: 200; batch classifier loss: 0.407880; batch adversarial loss: 0.637832\n",
      "epoch 44; iter: 0; batch classifier loss: 0.448212; batch adversarial loss: 0.713184\n",
      "epoch 44; iter: 200; batch classifier loss: 0.293588; batch adversarial loss: 0.624060\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518477; batch adversarial loss: 0.601220\n",
      "epoch 45; iter: 200; batch classifier loss: 0.371485; batch adversarial loss: 0.657809\n",
      "epoch 46; iter: 0; batch classifier loss: 0.241801; batch adversarial loss: 0.637393\n",
      "epoch 46; iter: 200; batch classifier loss: 0.277627; batch adversarial loss: 0.583301\n",
      "epoch 47; iter: 0; batch classifier loss: 0.329099; batch adversarial loss: 0.631905\n",
      "epoch 47; iter: 200; batch classifier loss: 0.358552; batch adversarial loss: 0.634858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.705611; batch adversarial loss: 0.629591\n",
      "epoch 48; iter: 200; batch classifier loss: 0.366052; batch adversarial loss: 0.671862\n",
      "epoch 49; iter: 0; batch classifier loss: 0.309586; batch adversarial loss: 0.577921\n",
      "epoch 49; iter: 200; batch classifier loss: 0.298127; batch adversarial loss: 0.597066\n",
      "epoch 0; iter: 0; batch classifier loss: 155.212402; batch adversarial loss: 0.702520\n",
      "epoch 0; iter: 200; batch classifier loss: 3.800073; batch adversarial loss: 0.761797\n",
      "epoch 1; iter: 0; batch classifier loss: 4.515304; batch adversarial loss: 0.678380\n",
      "epoch 1; iter: 200; batch classifier loss: 24.588306; batch adversarial loss: 0.655959\n",
      "epoch 2; iter: 0; batch classifier loss: 3.429545; batch adversarial loss: 0.637883\n",
      "epoch 2; iter: 200; batch classifier loss: 1.480745; batch adversarial loss: 0.663182\n",
      "epoch 3; iter: 0; batch classifier loss: 4.153652; batch adversarial loss: 0.637074\n",
      "epoch 3; iter: 200; batch classifier loss: 2.059469; batch adversarial loss: 0.678871\n",
      "epoch 4; iter: 0; batch classifier loss: 1.425947; batch adversarial loss: 0.648849\n",
      "epoch 4; iter: 200; batch classifier loss: 0.716790; batch adversarial loss: 0.633258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421331; batch adversarial loss: 0.578052\n",
      "epoch 5; iter: 200; batch classifier loss: 0.801180; batch adversarial loss: 0.604050\n",
      "epoch 6; iter: 0; batch classifier loss: 0.836376; batch adversarial loss: 0.637877\n",
      "epoch 6; iter: 200; batch classifier loss: 0.437236; batch adversarial loss: 0.604575\n",
      "epoch 7; iter: 0; batch classifier loss: 0.340165; batch adversarial loss: 0.615890\n",
      "epoch 7; iter: 200; batch classifier loss: 0.336639; batch adversarial loss: 0.658273\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400435; batch adversarial loss: 0.670094\n",
      "epoch 8; iter: 200; batch classifier loss: 0.737953; batch adversarial loss: 0.586723\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534396; batch adversarial loss: 0.670931\n",
      "epoch 9; iter: 200; batch classifier loss: 0.475971; batch adversarial loss: 0.584688\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510757; batch adversarial loss: 0.620913\n",
      "epoch 10; iter: 200; batch classifier loss: 0.472699; batch adversarial loss: 0.616393\n",
      "epoch 11; iter: 0; batch classifier loss: 0.710838; batch adversarial loss: 0.636455\n",
      "epoch 11; iter: 200; batch classifier loss: 0.456060; batch adversarial loss: 0.616238\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460236; batch adversarial loss: 0.630281\n",
      "epoch 12; iter: 200; batch classifier loss: 0.347176; batch adversarial loss: 0.604130\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478752; batch adversarial loss: 0.594319\n",
      "epoch 13; iter: 200; batch classifier loss: 0.489394; batch adversarial loss: 0.603282\n",
      "epoch 14; iter: 0; batch classifier loss: 1.447700; batch adversarial loss: 0.676420\n",
      "epoch 14; iter: 200; batch classifier loss: 0.317661; batch adversarial loss: 0.676197\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324953; batch adversarial loss: 0.612625\n",
      "epoch 15; iter: 200; batch classifier loss: 0.368401; batch adversarial loss: 0.598754\n",
      "epoch 16; iter: 0; batch classifier loss: 0.381203; batch adversarial loss: 0.582093\n",
      "epoch 16; iter: 200; batch classifier loss: 0.386015; batch adversarial loss: 0.597167\n",
      "epoch 17; iter: 0; batch classifier loss: 0.414058; batch adversarial loss: 0.659263\n",
      "epoch 17; iter: 200; batch classifier loss: 0.440693; batch adversarial loss: 0.605674\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501594; batch adversarial loss: 0.601177\n",
      "epoch 18; iter: 200; batch classifier loss: 0.428971; batch adversarial loss: 0.657483\n",
      "epoch 19; iter: 0; batch classifier loss: 0.435250; batch adversarial loss: 0.571046\n",
      "epoch 19; iter: 200; batch classifier loss: 0.354292; batch adversarial loss: 0.615890\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436283; batch adversarial loss: 0.568328\n",
      "epoch 20; iter: 200; batch classifier loss: 0.270553; batch adversarial loss: 0.625808\n",
      "epoch 21; iter: 0; batch classifier loss: 0.217154; batch adversarial loss: 0.580960\n",
      "epoch 21; iter: 200; batch classifier loss: 0.274267; batch adversarial loss: 0.643768\n",
      "epoch 22; iter: 0; batch classifier loss: 0.295418; batch adversarial loss: 0.620191\n",
      "epoch 22; iter: 200; batch classifier loss: 0.291076; batch adversarial loss: 0.584051\n",
      "epoch 23; iter: 0; batch classifier loss: 0.295350; batch adversarial loss: 0.628768\n",
      "epoch 23; iter: 200; batch classifier loss: 0.419550; batch adversarial loss: 0.629925\n",
      "epoch 24; iter: 0; batch classifier loss: 0.330229; batch adversarial loss: 0.665004\n",
      "epoch 24; iter: 200; batch classifier loss: 0.362249; batch adversarial loss: 0.643969\n",
      "epoch 25; iter: 0; batch classifier loss: 0.405715; batch adversarial loss: 0.569525\n",
      "epoch 25; iter: 200; batch classifier loss: 0.383058; batch adversarial loss: 0.598328\n",
      "epoch 26; iter: 0; batch classifier loss: 0.299108; batch adversarial loss: 0.659057\n",
      "epoch 26; iter: 200; batch classifier loss: 0.330840; batch adversarial loss: 0.596917\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315476; batch adversarial loss: 0.600545\n",
      "epoch 27; iter: 200; batch classifier loss: 0.269726; batch adversarial loss: 0.616842\n",
      "epoch 28; iter: 0; batch classifier loss: 0.347255; batch adversarial loss: 0.650859\n",
      "epoch 28; iter: 200; batch classifier loss: 0.308246; batch adversarial loss: 0.552063\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320566; batch adversarial loss: 0.646971\n",
      "epoch 29; iter: 200; batch classifier loss: 0.358733; batch adversarial loss: 0.607164\n",
      "epoch 30; iter: 0; batch classifier loss: 0.427394; batch adversarial loss: 0.666605\n",
      "epoch 30; iter: 200; batch classifier loss: 0.275820; batch adversarial loss: 0.643320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545688; batch adversarial loss: 0.595743\n",
      "epoch 31; iter: 200; batch classifier loss: 0.260043; batch adversarial loss: 0.583441\n",
      "epoch 32; iter: 0; batch classifier loss: 0.274396; batch adversarial loss: 0.629587\n",
      "epoch 32; iter: 200; batch classifier loss: 0.376342; batch adversarial loss: 0.608589\n",
      "epoch 33; iter: 0; batch classifier loss: 0.367461; batch adversarial loss: 0.598186\n",
      "epoch 33; iter: 200; batch classifier loss: 0.508034; batch adversarial loss: 0.600266\n",
      "epoch 34; iter: 0; batch classifier loss: 0.286478; batch adversarial loss: 0.595880\n",
      "epoch 34; iter: 200; batch classifier loss: 0.301670; batch adversarial loss: 0.587071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419806; batch adversarial loss: 0.654651\n",
      "epoch 35; iter: 200; batch classifier loss: 0.339922; batch adversarial loss: 0.648863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.457626; batch adversarial loss: 0.593842\n",
      "epoch 36; iter: 200; batch classifier loss: 0.329704; batch adversarial loss: 0.617723\n",
      "epoch 37; iter: 0; batch classifier loss: 0.304544; batch adversarial loss: 0.650773\n",
      "epoch 37; iter: 200; batch classifier loss: 0.367016; batch adversarial loss: 0.613637\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390577; batch adversarial loss: 0.660401\n",
      "epoch 38; iter: 200; batch classifier loss: 0.413302; batch adversarial loss: 0.606660\n",
      "epoch 39; iter: 0; batch classifier loss: 0.280861; batch adversarial loss: 0.639725\n",
      "epoch 39; iter: 200; batch classifier loss: 0.393367; batch adversarial loss: 0.637452\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383243; batch adversarial loss: 0.622442\n",
      "epoch 40; iter: 200; batch classifier loss: 0.342255; batch adversarial loss: 0.596961\n",
      "epoch 41; iter: 0; batch classifier loss: 0.298706; batch adversarial loss: 0.669171\n",
      "epoch 41; iter: 200; batch classifier loss: 0.399798; batch adversarial loss: 0.576336\n",
      "epoch 42; iter: 0; batch classifier loss: 0.274065; batch adversarial loss: 0.631550\n",
      "epoch 42; iter: 200; batch classifier loss: 0.351054; batch adversarial loss: 0.605454\n",
      "epoch 43; iter: 0; batch classifier loss: 0.284415; batch adversarial loss: 0.585382\n",
      "epoch 43; iter: 200; batch classifier loss: 0.348645; batch adversarial loss: 0.591366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395439; batch adversarial loss: 0.563511\n",
      "epoch 44; iter: 200; batch classifier loss: 0.305166; batch adversarial loss: 0.630390\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318878; batch adversarial loss: 0.701746\n",
      "epoch 45; iter: 200; batch classifier loss: 0.287886; batch adversarial loss: 0.624881\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482105; batch adversarial loss: 0.582725\n",
      "epoch 46; iter: 200; batch classifier loss: 0.286942; batch adversarial loss: 0.639740\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350855; batch adversarial loss: 0.683860\n",
      "epoch 47; iter: 200; batch classifier loss: 0.451475; batch adversarial loss: 0.582912\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436686; batch adversarial loss: 0.608121\n",
      "epoch 48; iter: 200; batch classifier loss: 0.347559; batch adversarial loss: 0.638329\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434733; batch adversarial loss: 0.601135\n",
      "epoch 49; iter: 200; batch classifier loss: 0.268672; batch adversarial loss: 0.673183\n",
      "epoch 0; iter: 0; batch classifier loss: 78.090118; batch adversarial loss: 1.276792\n",
      "epoch 0; iter: 200; batch classifier loss: 6.377740; batch adversarial loss: 1.113129\n",
      "epoch 1; iter: 0; batch classifier loss: 16.031603; batch adversarial loss: 0.753972\n",
      "epoch 1; iter: 200; batch classifier loss: 4.452053; batch adversarial loss: 0.704158\n",
      "epoch 2; iter: 0; batch classifier loss: 3.982312; batch adversarial loss: 0.665345\n",
      "epoch 2; iter: 200; batch classifier loss: 2.015262; batch adversarial loss: 0.685182\n",
      "epoch 3; iter: 0; batch classifier loss: 0.620695; batch adversarial loss: 0.684473\n",
      "epoch 3; iter: 200; batch classifier loss: 0.890491; batch adversarial loss: 0.648524\n",
      "epoch 4; iter: 0; batch classifier loss: 1.330523; batch adversarial loss: 0.686002\n",
      "epoch 4; iter: 200; batch classifier loss: 1.869323; batch adversarial loss: 0.612910\n",
      "epoch 5; iter: 0; batch classifier loss: 0.732678; batch adversarial loss: 0.635639\n",
      "epoch 5; iter: 200; batch classifier loss: 0.653263; batch adversarial loss: 0.620856\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388735; batch adversarial loss: 0.665925\n",
      "epoch 6; iter: 200; batch classifier loss: 0.859150; batch adversarial loss: 0.649306\n",
      "epoch 7; iter: 0; batch classifier loss: 0.387620; batch adversarial loss: 0.689758\n",
      "epoch 7; iter: 200; batch classifier loss: 0.488731; batch adversarial loss: 0.641659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.777476; batch adversarial loss: 0.634731\n",
      "epoch 8; iter: 200; batch classifier loss: 0.418266; batch adversarial loss: 0.663983\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519582; batch adversarial loss: 0.612421\n",
      "epoch 9; iter: 200; batch classifier loss: 0.431689; batch adversarial loss: 0.589228\n",
      "epoch 10; iter: 0; batch classifier loss: 0.360129; batch adversarial loss: 0.586300\n",
      "epoch 10; iter: 200; batch classifier loss: 0.405067; batch adversarial loss: 0.644202\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454124; batch adversarial loss: 0.619997\n",
      "epoch 11; iter: 200; batch classifier loss: 0.395387; batch adversarial loss: 0.641724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360625; batch adversarial loss: 0.655879\n",
      "epoch 12; iter: 200; batch classifier loss: 0.358420; batch adversarial loss: 0.604439\n",
      "epoch 13; iter: 0; batch classifier loss: 0.354736; batch adversarial loss: 0.564140\n",
      "epoch 13; iter: 200; batch classifier loss: 0.408097; batch adversarial loss: 0.580939\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344745; batch adversarial loss: 0.633920\n",
      "epoch 14; iter: 200; batch classifier loss: 0.357501; batch adversarial loss: 0.545995\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377171; batch adversarial loss: 0.661487\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392767; batch adversarial loss: 0.626941\n",
      "epoch 16; iter: 0; batch classifier loss: 0.395808; batch adversarial loss: 0.643552\n",
      "epoch 16; iter: 200; batch classifier loss: 0.409249; batch adversarial loss: 0.578717\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364411; batch adversarial loss: 0.597994\n",
      "epoch 17; iter: 200; batch classifier loss: 0.273572; batch adversarial loss: 0.583505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.420014; batch adversarial loss: 0.576359\n",
      "epoch 18; iter: 200; batch classifier loss: 0.379126; batch adversarial loss: 0.594955\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340554; batch adversarial loss: 0.614344\n",
      "epoch 19; iter: 200; batch classifier loss: 0.463495; batch adversarial loss: 0.595917\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461499; batch adversarial loss: 0.594740\n",
      "epoch 20; iter: 200; batch classifier loss: 0.374640; batch adversarial loss: 0.592759\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369110; batch adversarial loss: 0.607983\n",
      "epoch 21; iter: 200; batch classifier loss: 0.360896; batch adversarial loss: 0.603803\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433489; batch adversarial loss: 0.673676\n",
      "epoch 22; iter: 200; batch classifier loss: 0.387046; batch adversarial loss: 0.615218\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308413; batch adversarial loss: 0.620831\n",
      "epoch 23; iter: 200; batch classifier loss: 0.404601; batch adversarial loss: 0.661457\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329504; batch adversarial loss: 0.627343\n",
      "epoch 24; iter: 200; batch classifier loss: 0.320399; batch adversarial loss: 0.602431\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344954; batch adversarial loss: 0.614378\n",
      "epoch 25; iter: 200; batch classifier loss: 0.366221; batch adversarial loss: 0.638920\n",
      "epoch 26; iter: 0; batch classifier loss: 0.307602; batch adversarial loss: 0.644848\n",
      "epoch 26; iter: 200; batch classifier loss: 0.411485; batch adversarial loss: 0.618609\n",
      "epoch 27; iter: 0; batch classifier loss: 0.255740; batch adversarial loss: 0.681878\n",
      "epoch 27; iter: 200; batch classifier loss: 0.344117; batch adversarial loss: 0.649670\n",
      "epoch 28; iter: 0; batch classifier loss: 0.263656; batch adversarial loss: 0.584063\n",
      "epoch 28; iter: 200; batch classifier loss: 0.338293; batch adversarial loss: 0.591249\n",
      "epoch 29; iter: 0; batch classifier loss: 0.344821; batch adversarial loss: 0.594138\n",
      "epoch 29; iter: 200; batch classifier loss: 0.356224; batch adversarial loss: 0.659864\n",
      "epoch 30; iter: 0; batch classifier loss: 0.296407; batch adversarial loss: 0.591162\n",
      "epoch 30; iter: 200; batch classifier loss: 0.417737; batch adversarial loss: 0.600639\n",
      "epoch 31; iter: 0; batch classifier loss: 0.276433; batch adversarial loss: 0.673134\n",
      "epoch 31; iter: 200; batch classifier loss: 0.359780; batch adversarial loss: 0.639793\n",
      "epoch 32; iter: 0; batch classifier loss: 0.339408; batch adversarial loss: 0.600248\n",
      "epoch 32; iter: 200; batch classifier loss: 0.419683; batch adversarial loss: 0.652969\n",
      "epoch 33; iter: 0; batch classifier loss: 0.275587; batch adversarial loss: 0.618899\n",
      "epoch 33; iter: 200; batch classifier loss: 0.446110; batch adversarial loss: 0.572026\n",
      "epoch 34; iter: 0; batch classifier loss: 0.386650; batch adversarial loss: 0.606935\n",
      "epoch 34; iter: 200; batch classifier loss: 0.611475; batch adversarial loss: 0.642342\n",
      "epoch 35; iter: 0; batch classifier loss: 0.348416; batch adversarial loss: 0.637500\n",
      "epoch 35; iter: 200; batch classifier loss: 0.423742; batch adversarial loss: 0.612731\n",
      "epoch 36; iter: 0; batch classifier loss: 0.392089; batch adversarial loss: 0.621859\n",
      "epoch 36; iter: 200; batch classifier loss: 0.340597; batch adversarial loss: 0.640706\n",
      "epoch 37; iter: 0; batch classifier loss: 0.398604; batch adversarial loss: 0.598081\n",
      "epoch 37; iter: 200; batch classifier loss: 0.287455; batch adversarial loss: 0.602167\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286488; batch adversarial loss: 0.641849\n",
      "epoch 38; iter: 200; batch classifier loss: 0.465117; batch adversarial loss: 0.608604\n",
      "epoch 39; iter: 0; batch classifier loss: 0.327137; batch adversarial loss: 0.625975\n",
      "epoch 39; iter: 200; batch classifier loss: 0.295691; batch adversarial loss: 0.654760\n",
      "epoch 40; iter: 0; batch classifier loss: 0.371744; batch adversarial loss: 0.597490\n",
      "epoch 40; iter: 200; batch classifier loss: 0.363171; batch adversarial loss: 0.705858\n",
      "epoch 41; iter: 0; batch classifier loss: 0.344163; batch adversarial loss: 0.662849\n",
      "epoch 41; iter: 200; batch classifier loss: 0.389032; batch adversarial loss: 0.610866\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396397; batch adversarial loss: 0.633695\n",
      "epoch 42; iter: 200; batch classifier loss: 0.236607; batch adversarial loss: 0.635248\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383506; batch adversarial loss: 0.596712\n",
      "epoch 43; iter: 200; batch classifier loss: 0.410765; batch adversarial loss: 0.560259\n",
      "epoch 44; iter: 0; batch classifier loss: 0.293169; batch adversarial loss: 0.618132\n",
      "epoch 44; iter: 200; batch classifier loss: 0.237527; batch adversarial loss: 0.594035\n",
      "epoch 45; iter: 0; batch classifier loss: 0.352280; batch adversarial loss: 0.643185\n",
      "epoch 45; iter: 200; batch classifier loss: 0.330957; batch adversarial loss: 0.634344\n",
      "epoch 46; iter: 0; batch classifier loss: 0.348534; batch adversarial loss: 0.631645\n",
      "epoch 46; iter: 200; batch classifier loss: 0.324109; batch adversarial loss: 0.611079\n",
      "epoch 47; iter: 0; batch classifier loss: 0.430171; batch adversarial loss: 0.575841\n",
      "epoch 47; iter: 200; batch classifier loss: 0.365458; batch adversarial loss: 0.624378\n",
      "epoch 48; iter: 0; batch classifier loss: 0.350772; batch adversarial loss: 0.637527\n",
      "epoch 48; iter: 200; batch classifier loss: 0.319369; batch adversarial loss: 0.635350\n",
      "epoch 49; iter: 0; batch classifier loss: 0.289224; batch adversarial loss: 0.649042\n",
      "epoch 49; iter: 200; batch classifier loss: 0.383212; batch adversarial loss: 0.648149\n",
      "epoch 0; iter: 0; batch classifier loss: 190.670105; batch adversarial loss: 0.687870\n",
      "epoch 0; iter: 200; batch classifier loss: 5.624628; batch adversarial loss: 0.673455\n",
      "epoch 1; iter: 0; batch classifier loss: 8.752779; batch adversarial loss: 0.644240\n",
      "epoch 1; iter: 200; batch classifier loss: 16.697691; batch adversarial loss: 0.632499\n",
      "epoch 2; iter: 0; batch classifier loss: 3.651602; batch adversarial loss: 0.583081\n",
      "epoch 2; iter: 200; batch classifier loss: 0.802957; batch adversarial loss: 0.626449\n",
      "epoch 3; iter: 0; batch classifier loss: 0.964541; batch adversarial loss: 0.597207\n",
      "epoch 3; iter: 200; batch classifier loss: 1.396726; batch adversarial loss: 0.648983\n",
      "epoch 4; iter: 0; batch classifier loss: 1.745529; batch adversarial loss: 0.590982\n",
      "epoch 4; iter: 200; batch classifier loss: 1.563242; batch adversarial loss: 0.590979\n",
      "epoch 5; iter: 0; batch classifier loss: 1.755115; batch adversarial loss: 0.640768\n",
      "epoch 5; iter: 200; batch classifier loss: 0.654727; batch adversarial loss: 0.602842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432304; batch adversarial loss: 0.620384\n",
      "epoch 6; iter: 200; batch classifier loss: 0.738300; batch adversarial loss: 0.643541\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495293; batch adversarial loss: 0.650493\n",
      "epoch 7; iter: 200; batch classifier loss: 0.436102; batch adversarial loss: 0.613014\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515968; batch adversarial loss: 0.625200\n",
      "epoch 8; iter: 200; batch classifier loss: 0.410539; batch adversarial loss: 0.599776\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454896; batch adversarial loss: 0.607064\n",
      "epoch 9; iter: 200; batch classifier loss: 0.372257; batch adversarial loss: 0.617647\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305511; batch adversarial loss: 0.663001\n",
      "epoch 10; iter: 200; batch classifier loss: 0.372942; batch adversarial loss: 0.557451\n",
      "epoch 11; iter: 0; batch classifier loss: 0.300632; batch adversarial loss: 0.620886\n",
      "epoch 11; iter: 200; batch classifier loss: 0.365981; batch adversarial loss: 0.608498\n",
      "epoch 12; iter: 0; batch classifier loss: 0.755120; batch adversarial loss: 0.574879\n",
      "epoch 12; iter: 200; batch classifier loss: 0.335639; batch adversarial loss: 0.595305\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336569; batch adversarial loss: 0.656545\n",
      "epoch 13; iter: 200; batch classifier loss: 0.366429; batch adversarial loss: 0.589413\n",
      "epoch 14; iter: 0; batch classifier loss: 0.460332; batch adversarial loss: 0.649128\n",
      "epoch 14; iter: 200; batch classifier loss: 0.339309; batch adversarial loss: 0.587411\n",
      "epoch 15; iter: 0; batch classifier loss: 0.353260; batch adversarial loss: 0.646426\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392685; batch adversarial loss: 0.638757\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344433; batch adversarial loss: 0.618731\n",
      "epoch 16; iter: 200; batch classifier loss: 0.419568; batch adversarial loss: 0.638157\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349685; batch adversarial loss: 0.576020\n",
      "epoch 17; iter: 200; batch classifier loss: 0.358566; batch adversarial loss: 0.651617\n",
      "epoch 18; iter: 0; batch classifier loss: 0.381075; batch adversarial loss: 0.573780\n",
      "epoch 18; iter: 200; batch classifier loss: 0.492788; batch adversarial loss: 0.671289\n",
      "epoch 19; iter: 0; batch classifier loss: 0.364294; batch adversarial loss: 0.638565\n",
      "epoch 19; iter: 200; batch classifier loss: 0.410995; batch adversarial loss: 0.594262\n",
      "epoch 20; iter: 0; batch classifier loss: 0.394683; batch adversarial loss: 0.576063\n",
      "epoch 20; iter: 200; batch classifier loss: 0.397183; batch adversarial loss: 0.544297\n",
      "epoch 21; iter: 0; batch classifier loss: 0.367221; batch adversarial loss: 0.612968\n",
      "epoch 21; iter: 200; batch classifier loss: 0.351023; batch adversarial loss: 0.649415\n",
      "epoch 22; iter: 0; batch classifier loss: 0.333058; batch adversarial loss: 0.648379\n",
      "epoch 22; iter: 200; batch classifier loss: 0.294332; batch adversarial loss: 0.623620\n",
      "epoch 23; iter: 0; batch classifier loss: 0.416143; batch adversarial loss: 0.585443\n",
      "epoch 23; iter: 200; batch classifier loss: 0.372580; batch adversarial loss: 0.614656\n",
      "epoch 24; iter: 0; batch classifier loss: 0.350436; batch adversarial loss: 0.616560\n",
      "epoch 24; iter: 200; batch classifier loss: 0.281875; batch adversarial loss: 0.654420\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271510; batch adversarial loss: 0.615125\n",
      "epoch 25; iter: 200; batch classifier loss: 0.288902; batch adversarial loss: 0.601452\n",
      "epoch 26; iter: 0; batch classifier loss: 0.336729; batch adversarial loss: 0.516278\n",
      "epoch 26; iter: 200; batch classifier loss: 0.362420; batch adversarial loss: 0.599275\n",
      "epoch 27; iter: 0; batch classifier loss: 0.335108; batch adversarial loss: 0.607128\n",
      "epoch 27; iter: 200; batch classifier loss: 0.422458; batch adversarial loss: 0.610565\n",
      "epoch 28; iter: 0; batch classifier loss: 0.376356; batch adversarial loss: 0.625257\n",
      "epoch 28; iter: 200; batch classifier loss: 0.272150; batch adversarial loss: 0.633587\n",
      "epoch 29; iter: 0; batch classifier loss: 0.312758; batch adversarial loss: 0.611997\n",
      "epoch 29; iter: 200; batch classifier loss: 0.312002; batch adversarial loss: 0.680317\n",
      "epoch 30; iter: 0; batch classifier loss: 0.349262; batch adversarial loss: 0.618078\n",
      "epoch 30; iter: 200; batch classifier loss: 0.339657; batch adversarial loss: 0.608090\n",
      "epoch 31; iter: 0; batch classifier loss: 0.299776; batch adversarial loss: 0.579719\n",
      "epoch 31; iter: 200; batch classifier loss: 0.405331; batch adversarial loss: 0.575019\n",
      "epoch 32; iter: 0; batch classifier loss: 0.301453; batch adversarial loss: 0.565524\n",
      "epoch 32; iter: 200; batch classifier loss: 0.318121; batch adversarial loss: 0.653920\n",
      "epoch 33; iter: 0; batch classifier loss: 0.326354; batch adversarial loss: 0.578352\n",
      "epoch 33; iter: 200; batch classifier loss: 0.352139; batch adversarial loss: 0.606848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.462496; batch adversarial loss: 0.556223\n",
      "epoch 34; iter: 200; batch classifier loss: 0.311660; batch adversarial loss: 0.681698\n",
      "epoch 35; iter: 0; batch classifier loss: 0.370746; batch adversarial loss: 0.637261\n",
      "epoch 35; iter: 200; batch classifier loss: 0.313835; batch adversarial loss: 0.602039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.321329; batch adversarial loss: 0.589441\n",
      "epoch 36; iter: 200; batch classifier loss: 0.396508; batch adversarial loss: 0.672536\n",
      "epoch 37; iter: 0; batch classifier loss: 0.349160; batch adversarial loss: 0.613713\n",
      "epoch 37; iter: 200; batch classifier loss: 0.356749; batch adversarial loss: 0.663517\n",
      "epoch 38; iter: 0; batch classifier loss: 0.245245; batch adversarial loss: 0.626701\n",
      "epoch 38; iter: 200; batch classifier loss: 0.278623; batch adversarial loss: 0.683093\n",
      "epoch 39; iter: 0; batch classifier loss: 0.296385; batch adversarial loss: 0.619693\n",
      "epoch 39; iter: 200; batch classifier loss: 0.322109; batch adversarial loss: 0.633026\n",
      "epoch 40; iter: 0; batch classifier loss: 0.415626; batch adversarial loss: 0.568534\n",
      "epoch 40; iter: 200; batch classifier loss: 0.368482; batch adversarial loss: 0.609360\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377195; batch adversarial loss: 0.662357\n",
      "epoch 41; iter: 200; batch classifier loss: 0.319473; batch adversarial loss: 0.616691\n",
      "epoch 42; iter: 0; batch classifier loss: 0.309893; batch adversarial loss: 0.596013\n",
      "epoch 42; iter: 200; batch classifier loss: 0.276986; batch adversarial loss: 0.608602\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394414; batch adversarial loss: 0.620970\n",
      "epoch 43; iter: 200; batch classifier loss: 0.405461; batch adversarial loss: 0.643952\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405682; batch adversarial loss: 0.620612\n",
      "epoch 44; iter: 200; batch classifier loss: 0.370142; batch adversarial loss: 0.652806\n",
      "epoch 45; iter: 0; batch classifier loss: 0.351284; batch adversarial loss: 0.662981\n",
      "epoch 45; iter: 200; batch classifier loss: 0.370339; batch adversarial loss: 0.587973\n",
      "epoch 46; iter: 0; batch classifier loss: 0.261279; batch adversarial loss: 0.656484\n",
      "epoch 46; iter: 200; batch classifier loss: 0.358976; batch adversarial loss: 0.641583\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425239; batch adversarial loss: 0.610446\n",
      "epoch 47; iter: 200; batch classifier loss: 0.459425; batch adversarial loss: 0.617715\n",
      "epoch 48; iter: 0; batch classifier loss: 0.351232; batch adversarial loss: 0.612630\n",
      "epoch 48; iter: 200; batch classifier loss: 0.406279; batch adversarial loss: 0.600304\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465001; batch adversarial loss: 0.619175\n",
      "epoch 49; iter: 200; batch classifier loss: 0.279779; batch adversarial loss: 0.612420\n",
      "epoch 0; iter: 0; batch classifier loss: 8.114365; batch adversarial loss: 0.708587\n",
      "epoch 0; iter: 200; batch classifier loss: 9.959215; batch adversarial loss: 0.669982\n",
      "epoch 1; iter: 0; batch classifier loss: 6.320290; batch adversarial loss: 0.655346\n",
      "epoch 1; iter: 200; batch classifier loss: 3.728541; batch adversarial loss: 0.650550\n",
      "epoch 2; iter: 0; batch classifier loss: 5.341340; batch adversarial loss: 0.609970\n",
      "epoch 2; iter: 200; batch classifier loss: 2.869095; batch adversarial loss: 0.620328\n",
      "epoch 3; iter: 0; batch classifier loss: 1.282038; batch adversarial loss: 0.627150\n",
      "epoch 3; iter: 200; batch classifier loss: 1.623140; batch adversarial loss: 0.630024\n",
      "epoch 4; iter: 0; batch classifier loss: 1.371557; batch adversarial loss: 0.627847\n",
      "epoch 4; iter: 200; batch classifier loss: 0.878402; batch adversarial loss: 0.635430\n",
      "epoch 5; iter: 0; batch classifier loss: 0.701269; batch adversarial loss: 0.527079\n",
      "epoch 5; iter: 200; batch classifier loss: 0.405974; batch adversarial loss: 0.618230\n",
      "epoch 6; iter: 0; batch classifier loss: 0.435924; batch adversarial loss: 0.622020\n",
      "epoch 6; iter: 200; batch classifier loss: 0.552716; batch adversarial loss: 0.668782\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485344; batch adversarial loss: 0.580897\n",
      "epoch 7; iter: 200; batch classifier loss: 0.337652; batch adversarial loss: 0.648411\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539780; batch adversarial loss: 0.625386\n",
      "epoch 8; iter: 200; batch classifier loss: 0.431240; batch adversarial loss: 0.610049\n",
      "epoch 9; iter: 0; batch classifier loss: 0.439512; batch adversarial loss: 0.625185\n",
      "epoch 9; iter: 200; batch classifier loss: 0.353442; batch adversarial loss: 0.591044\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589608; batch adversarial loss: 0.584073\n",
      "epoch 10; iter: 200; batch classifier loss: 0.423743; batch adversarial loss: 0.652525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329312; batch adversarial loss: 0.602698\n",
      "epoch 11; iter: 200; batch classifier loss: 0.651799; batch adversarial loss: 0.565302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.426504; batch adversarial loss: 0.685297\n",
      "epoch 12; iter: 200; batch classifier loss: 0.375085; batch adversarial loss: 0.642645\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432852; batch adversarial loss: 0.582809\n",
      "epoch 13; iter: 200; batch classifier loss: 0.433048; batch adversarial loss: 0.543958\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477361; batch adversarial loss: 0.618735\n",
      "epoch 14; iter: 200; batch classifier loss: 0.382675; batch adversarial loss: 0.607400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.404207; batch adversarial loss: 0.601613\n",
      "epoch 15; iter: 200; batch classifier loss: 0.388275; batch adversarial loss: 0.615746\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334946; batch adversarial loss: 0.597200\n",
      "epoch 16; iter: 200; batch classifier loss: 0.339435; batch adversarial loss: 0.588111\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420266; batch adversarial loss: 0.641346\n",
      "epoch 17; iter: 200; batch classifier loss: 0.611895; batch adversarial loss: 0.617775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308920; batch adversarial loss: 0.613691\n",
      "epoch 18; iter: 200; batch classifier loss: 0.354782; batch adversarial loss: 0.614461\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340449; batch adversarial loss: 0.691153\n",
      "epoch 19; iter: 200; batch classifier loss: 0.365549; batch adversarial loss: 0.607250\n",
      "epoch 20; iter: 0; batch classifier loss: 0.259922; batch adversarial loss: 0.640503\n",
      "epoch 20; iter: 200; batch classifier loss: 0.320403; batch adversarial loss: 0.601454\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310531; batch adversarial loss: 0.563370\n",
      "epoch 21; iter: 200; batch classifier loss: 0.342475; batch adversarial loss: 0.611716\n",
      "epoch 22; iter: 0; batch classifier loss: 0.260606; batch adversarial loss: 0.607769\n",
      "epoch 22; iter: 200; batch classifier loss: 0.220710; batch adversarial loss: 0.664486\n",
      "epoch 23; iter: 0; batch classifier loss: 0.315319; batch adversarial loss: 0.603238\n",
      "epoch 23; iter: 200; batch classifier loss: 0.376200; batch adversarial loss: 0.598513\n",
      "epoch 24; iter: 0; batch classifier loss: 0.325548; batch adversarial loss: 0.643517\n",
      "epoch 24; iter: 200; batch classifier loss: 0.283295; batch adversarial loss: 0.595708\n",
      "epoch 25; iter: 0; batch classifier loss: 0.294802; batch adversarial loss: 0.608713\n",
      "epoch 25; iter: 200; batch classifier loss: 0.328699; batch adversarial loss: 0.670260\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393253; batch adversarial loss: 0.562876\n",
      "epoch 26; iter: 200; batch classifier loss: 0.283662; batch adversarial loss: 0.621956\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402542; batch adversarial loss: 0.635220\n",
      "epoch 27; iter: 200; batch classifier loss: 0.262287; batch adversarial loss: 0.587674\n",
      "epoch 28; iter: 0; batch classifier loss: 0.392902; batch adversarial loss: 0.608877\n",
      "epoch 28; iter: 200; batch classifier loss: 0.255938; batch adversarial loss: 0.655538\n",
      "epoch 29; iter: 0; batch classifier loss: 0.278892; batch adversarial loss: 0.617275\n",
      "epoch 29; iter: 200; batch classifier loss: 0.323598; batch adversarial loss: 0.617311\n",
      "epoch 30; iter: 0; batch classifier loss: 0.276145; batch adversarial loss: 0.679788\n",
      "epoch 30; iter: 200; batch classifier loss: 0.331241; batch adversarial loss: 0.585774\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414484; batch adversarial loss: 0.574172\n",
      "epoch 31; iter: 200; batch classifier loss: 0.292344; batch adversarial loss: 0.597958\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348378; batch adversarial loss: 0.584302\n",
      "epoch 32; iter: 200; batch classifier loss: 0.302840; batch adversarial loss: 0.619002\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363319; batch adversarial loss: 0.603134\n",
      "epoch 33; iter: 200; batch classifier loss: 0.363952; batch adversarial loss: 0.632227\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363450; batch adversarial loss: 0.627737\n",
      "epoch 34; iter: 200; batch classifier loss: 0.404930; batch adversarial loss: 0.613724\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317626; batch adversarial loss: 0.634559\n",
      "epoch 35; iter: 200; batch classifier loss: 0.320371; batch adversarial loss: 0.656885\n",
      "epoch 36; iter: 0; batch classifier loss: 0.327098; batch adversarial loss: 0.611825\n",
      "epoch 36; iter: 200; batch classifier loss: 0.440502; batch adversarial loss: 0.588180\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226174; batch adversarial loss: 0.605998\n",
      "epoch 37; iter: 200; batch classifier loss: 0.356784; batch adversarial loss: 0.580648\n",
      "epoch 38; iter: 0; batch classifier loss: 0.330924; batch adversarial loss: 0.633402\n",
      "epoch 38; iter: 200; batch classifier loss: 0.320152; batch adversarial loss: 0.617290\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477655; batch adversarial loss: 0.569990\n",
      "epoch 39; iter: 200; batch classifier loss: 0.296368; batch adversarial loss: 0.626299\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361985; batch adversarial loss: 0.702180\n",
      "epoch 40; iter: 200; batch classifier loss: 0.321464; batch adversarial loss: 0.574608\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444112; batch adversarial loss: 0.649428\n",
      "epoch 41; iter: 200; batch classifier loss: 0.314135; batch adversarial loss: 0.610040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.338676; batch adversarial loss: 0.611382\n",
      "epoch 42; iter: 200; batch classifier loss: 0.375886; batch adversarial loss: 0.595555\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444144; batch adversarial loss: 0.571177\n",
      "epoch 43; iter: 200; batch classifier loss: 0.314678; batch adversarial loss: 0.633847\n",
      "epoch 44; iter: 0; batch classifier loss: 0.295329; batch adversarial loss: 0.629850\n",
      "epoch 44; iter: 200; batch classifier loss: 0.391281; batch adversarial loss: 0.590191\n",
      "epoch 45; iter: 0; batch classifier loss: 0.447301; batch adversarial loss: 0.636818\n",
      "epoch 45; iter: 200; batch classifier loss: 0.388525; batch adversarial loss: 0.639414\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324243; batch adversarial loss: 0.584311\n",
      "epoch 46; iter: 200; batch classifier loss: 0.330378; batch adversarial loss: 0.612321\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395520; batch adversarial loss: 0.700839\n",
      "epoch 47; iter: 200; batch classifier loss: 0.222626; batch adversarial loss: 0.637378\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335306; batch adversarial loss: 0.648190\n",
      "epoch 48; iter: 200; batch classifier loss: 0.368154; batch adversarial loss: 0.614933\n",
      "epoch 49; iter: 0; batch classifier loss: 0.342643; batch adversarial loss: 0.653866\n",
      "epoch 49; iter: 200; batch classifier loss: 0.377265; batch adversarial loss: 0.586049\n",
      "epoch 0; iter: 0; batch classifier loss: 4.723608; batch adversarial loss: 0.723920\n",
      "epoch 0; iter: 200; batch classifier loss: 7.755366; batch adversarial loss: 0.694776\n",
      "epoch 1; iter: 0; batch classifier loss: 3.652091; batch adversarial loss: 0.628179\n",
      "epoch 1; iter: 200; batch classifier loss: 4.557713; batch adversarial loss: 0.625788\n",
      "epoch 2; iter: 0; batch classifier loss: 2.903473; batch adversarial loss: 0.650929\n",
      "epoch 2; iter: 200; batch classifier loss: 2.267638; batch adversarial loss: 0.622011\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629940; batch adversarial loss: 0.631377\n",
      "epoch 3; iter: 200; batch classifier loss: 1.371872; batch adversarial loss: 0.665364\n",
      "epoch 4; iter: 0; batch classifier loss: 1.397783; batch adversarial loss: 0.632180\n",
      "epoch 4; iter: 200; batch classifier loss: 1.130720; batch adversarial loss: 0.678621\n",
      "epoch 5; iter: 0; batch classifier loss: 1.060698; batch adversarial loss: 0.625393\n",
      "epoch 5; iter: 200; batch classifier loss: 0.497075; batch adversarial loss: 0.614175\n",
      "epoch 6; iter: 0; batch classifier loss: 0.747472; batch adversarial loss: 0.644927\n",
      "epoch 6; iter: 200; batch classifier loss: 0.967928; batch adversarial loss: 0.550752\n",
      "epoch 7; iter: 0; batch classifier loss: 1.777854; batch adversarial loss: 0.592665\n",
      "epoch 7; iter: 200; batch classifier loss: 0.428032; batch adversarial loss: 0.680767\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598040; batch adversarial loss: 0.669026\n",
      "epoch 8; iter: 200; batch classifier loss: 0.442121; batch adversarial loss: 0.595186\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519500; batch adversarial loss: 0.645461\n",
      "epoch 9; iter: 200; batch classifier loss: 0.445696; batch adversarial loss: 0.663497\n",
      "epoch 10; iter: 0; batch classifier loss: 0.320516; batch adversarial loss: 0.692755\n",
      "epoch 10; iter: 200; batch classifier loss: 0.357094; batch adversarial loss: 0.639057\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454633; batch adversarial loss: 0.592925\n",
      "epoch 11; iter: 200; batch classifier loss: 0.635112; batch adversarial loss: 0.605961\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383754; batch adversarial loss: 0.601666\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391088; batch adversarial loss: 0.587179\n",
      "epoch 13; iter: 0; batch classifier loss: 0.502694; batch adversarial loss: 0.550535\n",
      "epoch 13; iter: 200; batch classifier loss: 0.452842; batch adversarial loss: 0.600170\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403969; batch adversarial loss: 0.649766\n",
      "epoch 14; iter: 200; batch classifier loss: 0.591094; batch adversarial loss: 0.585779\n",
      "epoch 15; iter: 0; batch classifier loss: 0.341891; batch adversarial loss: 0.606435\n",
      "epoch 15; iter: 200; batch classifier loss: 0.326287; batch adversarial loss: 0.695816\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370870; batch adversarial loss: 0.583411\n",
      "epoch 16; iter: 200; batch classifier loss: 0.417273; batch adversarial loss: 0.636188\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390016; batch adversarial loss: 0.691112\n",
      "epoch 17; iter: 200; batch classifier loss: 0.335149; batch adversarial loss: 0.634215\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314205; batch adversarial loss: 0.618875\n",
      "epoch 18; iter: 200; batch classifier loss: 0.405301; batch adversarial loss: 0.577850\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281739; batch adversarial loss: 0.668014\n",
      "epoch 19; iter: 200; batch classifier loss: 0.390009; batch adversarial loss: 0.648846\n",
      "epoch 20; iter: 0; batch classifier loss: 0.270720; batch adversarial loss: 0.590626\n",
      "epoch 20; iter: 200; batch classifier loss: 0.341803; batch adversarial loss: 0.600748\n",
      "epoch 21; iter: 0; batch classifier loss: 0.331224; batch adversarial loss: 0.602468\n",
      "epoch 21; iter: 200; batch classifier loss: 0.603173; batch adversarial loss: 0.625538\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294229; batch adversarial loss: 0.583301\n",
      "epoch 22; iter: 200; batch classifier loss: 0.408160; batch adversarial loss: 0.590870\n",
      "epoch 23; iter: 0; batch classifier loss: 0.358380; batch adversarial loss: 0.544864\n",
      "epoch 23; iter: 200; batch classifier loss: 0.475044; batch adversarial loss: 0.616072\n",
      "epoch 24; iter: 0; batch classifier loss: 0.325069; batch adversarial loss: 0.590857\n",
      "epoch 24; iter: 200; batch classifier loss: 0.379735; batch adversarial loss: 0.623980\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360548; batch adversarial loss: 0.673184\n",
      "epoch 25; iter: 200; batch classifier loss: 0.368989; batch adversarial loss: 0.562916\n",
      "epoch 26; iter: 0; batch classifier loss: 0.370289; batch adversarial loss: 0.640048\n",
      "epoch 26; iter: 200; batch classifier loss: 0.428189; batch adversarial loss: 0.629831\n",
      "epoch 27; iter: 0; batch classifier loss: 0.379463; batch adversarial loss: 0.577478\n",
      "epoch 27; iter: 200; batch classifier loss: 0.392531; batch adversarial loss: 0.592278\n",
      "epoch 28; iter: 0; batch classifier loss: 0.361363; batch adversarial loss: 0.593298\n",
      "epoch 28; iter: 200; batch classifier loss: 0.390963; batch adversarial loss: 0.627481\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324678; batch adversarial loss: 0.626813\n",
      "epoch 29; iter: 200; batch classifier loss: 0.403779; batch adversarial loss: 0.673559\n",
      "epoch 30; iter: 0; batch classifier loss: 0.316490; batch adversarial loss: 0.620727\n",
      "epoch 30; iter: 200; batch classifier loss: 0.434095; batch adversarial loss: 0.595187\n",
      "epoch 31; iter: 0; batch classifier loss: 0.352131; batch adversarial loss: 0.585045\n",
      "epoch 31; iter: 200; batch classifier loss: 0.358890; batch adversarial loss: 0.600958\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279579; batch adversarial loss: 0.673390\n",
      "epoch 32; iter: 200; batch classifier loss: 0.429507; batch adversarial loss: 0.594110\n",
      "epoch 33; iter: 0; batch classifier loss: 0.443120; batch adversarial loss: 0.628592\n",
      "epoch 33; iter: 200; batch classifier loss: 0.345020; batch adversarial loss: 0.695108\n",
      "epoch 34; iter: 0; batch classifier loss: 0.342868; batch adversarial loss: 0.620921\n",
      "epoch 34; iter: 200; batch classifier loss: 0.339502; batch adversarial loss: 0.634696\n",
      "epoch 35; iter: 0; batch classifier loss: 0.361362; batch adversarial loss: 0.636468\n",
      "epoch 35; iter: 200; batch classifier loss: 0.370930; batch adversarial loss: 0.640121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391098; batch adversarial loss: 0.623060\n",
      "epoch 36; iter: 200; batch classifier loss: 0.292660; batch adversarial loss: 0.623469\n",
      "epoch 37; iter: 0; batch classifier loss: 0.733578; batch adversarial loss: 0.593347\n",
      "epoch 37; iter: 200; batch classifier loss: 0.345329; batch adversarial loss: 0.616920\n",
      "epoch 38; iter: 0; batch classifier loss: 0.377371; batch adversarial loss: 0.574163\n",
      "epoch 38; iter: 200; batch classifier loss: 0.387883; batch adversarial loss: 0.568259\n",
      "epoch 39; iter: 0; batch classifier loss: 0.325775; batch adversarial loss: 0.634923\n",
      "epoch 39; iter: 200; batch classifier loss: 0.419442; batch adversarial loss: 0.605583\n",
      "epoch 40; iter: 0; batch classifier loss: 0.402723; batch adversarial loss: 0.632128\n",
      "epoch 40; iter: 200; batch classifier loss: 0.332696; batch adversarial loss: 0.658341\n",
      "epoch 41; iter: 0; batch classifier loss: 0.336003; batch adversarial loss: 0.616313\n",
      "epoch 41; iter: 200; batch classifier loss: 0.365992; batch adversarial loss: 0.633584\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394255; batch adversarial loss: 0.667411\n",
      "epoch 42; iter: 200; batch classifier loss: 0.393690; batch adversarial loss: 0.610649\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382967; batch adversarial loss: 0.672808\n",
      "epoch 43; iter: 200; batch classifier loss: 0.423864; batch adversarial loss: 0.661503\n",
      "epoch 44; iter: 0; batch classifier loss: 0.282518; batch adversarial loss: 0.630718\n",
      "epoch 44; iter: 200; batch classifier loss: 0.316350; batch adversarial loss: 0.617134\n",
      "epoch 45; iter: 0; batch classifier loss: 0.329727; batch adversarial loss: 0.686877\n",
      "epoch 45; iter: 200; batch classifier loss: 0.537196; batch adversarial loss: 0.596708\n",
      "epoch 46; iter: 0; batch classifier loss: 0.390690; batch adversarial loss: 0.603964\n",
      "epoch 46; iter: 200; batch classifier loss: 0.248925; batch adversarial loss: 0.636273\n",
      "epoch 47; iter: 0; batch classifier loss: 0.501006; batch adversarial loss: 0.661237\n",
      "epoch 47; iter: 200; batch classifier loss: 0.567750; batch adversarial loss: 0.594215\n",
      "epoch 48; iter: 0; batch classifier loss: 0.441609; batch adversarial loss: 0.644400\n",
      "epoch 48; iter: 200; batch classifier loss: 0.607554; batch adversarial loss: 0.597279\n",
      "epoch 49; iter: 0; batch classifier loss: 0.652112; batch adversarial loss: 0.613426\n",
      "epoch 49; iter: 200; batch classifier loss: 0.326082; batch adversarial loss: 0.640405\n",
      "epoch 0; iter: 0; batch classifier loss: 87.576538; batch adversarial loss: 0.766235\n",
      "epoch 0; iter: 200; batch classifier loss: 37.945347; batch adversarial loss: 0.668437\n",
      "epoch 1; iter: 0; batch classifier loss: 5.861013; batch adversarial loss: 0.668248\n",
      "epoch 1; iter: 200; batch classifier loss: 7.511866; batch adversarial loss: 0.628218\n",
      "epoch 2; iter: 0; batch classifier loss: 1.322044; batch adversarial loss: 0.614619\n",
      "epoch 2; iter: 200; batch classifier loss: 0.950350; batch adversarial loss: 0.647998\n",
      "epoch 3; iter: 0; batch classifier loss: 4.623241; batch adversarial loss: 0.659162\n",
      "epoch 3; iter: 200; batch classifier loss: 1.350843; batch adversarial loss: 0.616708\n",
      "epoch 4; iter: 0; batch classifier loss: 2.504420; batch adversarial loss: 0.585959\n",
      "epoch 4; iter: 200; batch classifier loss: 2.070375; batch adversarial loss: 0.649058\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580152; batch adversarial loss: 0.622155\n",
      "epoch 5; iter: 200; batch classifier loss: 1.172633; batch adversarial loss: 0.700704\n",
      "epoch 6; iter: 0; batch classifier loss: 0.382233; batch adversarial loss: 0.628773\n",
      "epoch 6; iter: 200; batch classifier loss: 0.969595; batch adversarial loss: 0.612723\n",
      "epoch 7; iter: 0; batch classifier loss: 0.825197; batch adversarial loss: 0.628477\n",
      "epoch 7; iter: 200; batch classifier loss: 0.533430; batch adversarial loss: 0.583370\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573094; batch adversarial loss: 0.662627\n",
      "epoch 8; iter: 200; batch classifier loss: 0.415046; batch adversarial loss: 0.633034\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442697; batch adversarial loss: 0.608616\n",
      "epoch 9; iter: 200; batch classifier loss: 0.496994; batch adversarial loss: 0.637990\n",
      "epoch 10; iter: 0; batch classifier loss: 0.961511; batch adversarial loss: 0.559037\n",
      "epoch 10; iter: 200; batch classifier loss: 0.344227; batch adversarial loss: 0.608293\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362502; batch adversarial loss: 0.564829\n",
      "epoch 11; iter: 200; batch classifier loss: 0.361218; batch adversarial loss: 0.638442\n",
      "epoch 12; iter: 0; batch classifier loss: 0.638921; batch adversarial loss: 0.599287\n",
      "epoch 12; iter: 200; batch classifier loss: 0.533417; batch adversarial loss: 0.583924\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331877; batch adversarial loss: 0.633033\n",
      "epoch 13; iter: 200; batch classifier loss: 0.389528; batch adversarial loss: 0.579118\n",
      "epoch 14; iter: 0; batch classifier loss: 0.401862; batch adversarial loss: 0.629856\n",
      "epoch 14; iter: 200; batch classifier loss: 0.625350; batch adversarial loss: 0.603688\n",
      "epoch 15; iter: 0; batch classifier loss: 0.416222; batch adversarial loss: 0.596249\n",
      "epoch 15; iter: 200; batch classifier loss: 0.413680; batch adversarial loss: 0.623248\n",
      "epoch 16; iter: 0; batch classifier loss: 0.338106; batch adversarial loss: 0.604676\n",
      "epoch 16; iter: 200; batch classifier loss: 0.462057; batch adversarial loss: 0.601952\n",
      "epoch 17; iter: 0; batch classifier loss: 0.716836; batch adversarial loss: 0.641440\n",
      "epoch 17; iter: 200; batch classifier loss: 0.314867; batch adversarial loss: 0.651728\n",
      "epoch 18; iter: 0; batch classifier loss: 0.400826; batch adversarial loss: 0.616036\n",
      "epoch 18; iter: 200; batch classifier loss: 0.390948; batch adversarial loss: 0.577109\n",
      "epoch 19; iter: 0; batch classifier loss: 0.370699; batch adversarial loss: 0.668333\n",
      "epoch 19; iter: 200; batch classifier loss: 0.507396; batch adversarial loss: 0.658767\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406022; batch adversarial loss: 0.642406\n",
      "epoch 20; iter: 200; batch classifier loss: 0.290165; batch adversarial loss: 0.628209\n",
      "epoch 21; iter: 0; batch classifier loss: 0.370017; batch adversarial loss: 0.606782\n",
      "epoch 21; iter: 200; batch classifier loss: 0.433676; batch adversarial loss: 0.613953\n",
      "epoch 22; iter: 0; batch classifier loss: 0.379465; batch adversarial loss: 0.590677\n",
      "epoch 22; iter: 200; batch classifier loss: 0.434010; batch adversarial loss: 0.653146\n",
      "epoch 23; iter: 0; batch classifier loss: 0.391911; batch adversarial loss: 0.532044\n",
      "epoch 23; iter: 200; batch classifier loss: 0.315574; batch adversarial loss: 0.612485\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315333; batch adversarial loss: 0.571789\n",
      "epoch 24; iter: 200; batch classifier loss: 0.392125; batch adversarial loss: 0.619347\n",
      "epoch 25; iter: 0; batch classifier loss: 0.410156; batch adversarial loss: 0.582520\n",
      "epoch 25; iter: 200; batch classifier loss: 0.275318; batch adversarial loss: 0.571775\n",
      "epoch 26; iter: 0; batch classifier loss: 0.365332; batch adversarial loss: 0.588586\n",
      "epoch 26; iter: 200; batch classifier loss: 0.375851; batch adversarial loss: 0.603708\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352543; batch adversarial loss: 0.582334\n",
      "epoch 27; iter: 200; batch classifier loss: 0.391092; batch adversarial loss: 0.557316\n",
      "epoch 28; iter: 0; batch classifier loss: 0.323107; batch adversarial loss: 0.656354\n",
      "epoch 28; iter: 200; batch classifier loss: 0.398362; batch adversarial loss: 0.625554\n",
      "epoch 29; iter: 0; batch classifier loss: 0.274206; batch adversarial loss: 0.565226\n",
      "epoch 29; iter: 200; batch classifier loss: 0.533815; batch adversarial loss: 0.672678\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418726; batch adversarial loss: 0.614400\n",
      "epoch 30; iter: 200; batch classifier loss: 0.385096; batch adversarial loss: 0.666689\n",
      "epoch 31; iter: 0; batch classifier loss: 0.262905; batch adversarial loss: 0.659887\n",
      "epoch 31; iter: 200; batch classifier loss: 0.309426; batch adversarial loss: 0.686027\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348537; batch adversarial loss: 0.651136\n",
      "epoch 32; iter: 200; batch classifier loss: 0.332871; batch adversarial loss: 0.669690\n",
      "epoch 33; iter: 0; batch classifier loss: 0.343339; batch adversarial loss: 0.638051\n",
      "epoch 33; iter: 200; batch classifier loss: 0.249921; batch adversarial loss: 0.697819\n",
      "epoch 34; iter: 0; batch classifier loss: 0.327790; batch adversarial loss: 0.603807\n",
      "epoch 34; iter: 200; batch classifier loss: 0.237416; batch adversarial loss: 0.637331\n",
      "epoch 35; iter: 0; batch classifier loss: 0.344299; batch adversarial loss: 0.650360\n",
      "epoch 35; iter: 200; batch classifier loss: 0.372388; batch adversarial loss: 0.547154\n",
      "epoch 36; iter: 0; batch classifier loss: 0.351277; batch adversarial loss: 0.628968\n",
      "epoch 36; iter: 200; batch classifier loss: 0.403497; batch adversarial loss: 0.685078\n",
      "epoch 37; iter: 0; batch classifier loss: 0.307070; batch adversarial loss: 0.608216\n",
      "epoch 37; iter: 200; batch classifier loss: 0.313918; batch adversarial loss: 0.649449\n",
      "epoch 38; iter: 0; batch classifier loss: 0.296880; batch adversarial loss: 0.586624\n",
      "epoch 38; iter: 200; batch classifier loss: 0.321019; batch adversarial loss: 0.667095\n",
      "epoch 39; iter: 0; batch classifier loss: 0.337063; batch adversarial loss: 0.598509\n",
      "epoch 39; iter: 200; batch classifier loss: 0.399241; batch adversarial loss: 0.614177\n",
      "epoch 40; iter: 0; batch classifier loss: 0.354887; batch adversarial loss: 0.634193\n",
      "epoch 40; iter: 200; batch classifier loss: 0.319272; batch adversarial loss: 0.599459\n",
      "epoch 41; iter: 0; batch classifier loss: 0.298725; batch adversarial loss: 0.620669\n",
      "epoch 41; iter: 200; batch classifier loss: 0.343918; batch adversarial loss: 0.626752\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440139; batch adversarial loss: 0.628611\n",
      "epoch 42; iter: 200; batch classifier loss: 0.348014; batch adversarial loss: 0.668389\n",
      "epoch 43; iter: 0; batch classifier loss: 0.339541; batch adversarial loss: 0.627228\n",
      "epoch 43; iter: 200; batch classifier loss: 0.459809; batch adversarial loss: 0.611618\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439188; batch adversarial loss: 0.567080\n",
      "epoch 44; iter: 200; batch classifier loss: 0.357148; batch adversarial loss: 0.659289\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382501; batch adversarial loss: 0.648872\n",
      "epoch 45; iter: 200; batch classifier loss: 0.368124; batch adversarial loss: 0.609368\n",
      "epoch 46; iter: 0; batch classifier loss: 0.309075; batch adversarial loss: 0.652730\n",
      "epoch 46; iter: 200; batch classifier loss: 0.358048; batch adversarial loss: 0.605281\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478181; batch adversarial loss: 0.617781\n",
      "epoch 47; iter: 200; batch classifier loss: 0.327224; batch adversarial loss: 0.648198\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388482; batch adversarial loss: 0.637549\n",
      "epoch 48; iter: 200; batch classifier loss: 0.367742; batch adversarial loss: 0.666921\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467191; batch adversarial loss: 0.628316\n",
      "epoch 49; iter: 200; batch classifier loss: 0.380522; batch adversarial loss: 0.651465\n",
      "epoch 0; iter: 0; batch classifier loss: 46.670334; batch adversarial loss: 0.892718\n",
      "epoch 0; iter: 200; batch classifier loss: 3.265294; batch adversarial loss: 0.703153\n",
      "epoch 1; iter: 0; batch classifier loss: 4.250326; batch adversarial loss: 0.666047\n",
      "epoch 1; iter: 200; batch classifier loss: 1.390428; batch adversarial loss: 0.690126\n",
      "epoch 2; iter: 0; batch classifier loss: 1.251257; batch adversarial loss: 0.609031\n",
      "epoch 2; iter: 200; batch classifier loss: 1.063838; batch adversarial loss: 0.655352\n",
      "epoch 3; iter: 0; batch classifier loss: 1.520557; batch adversarial loss: 0.654911\n",
      "epoch 3; iter: 200; batch classifier loss: 0.453842; batch adversarial loss: 0.630424\n",
      "epoch 4; iter: 0; batch classifier loss: 0.793464; batch adversarial loss: 0.587664\n",
      "epoch 4; iter: 200; batch classifier loss: 0.631825; batch adversarial loss: 0.641577\n",
      "epoch 5; iter: 0; batch classifier loss: 2.336238; batch adversarial loss: 0.634532\n",
      "epoch 5; iter: 200; batch classifier loss: 0.313129; batch adversarial loss: 0.611729\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559314; batch adversarial loss: 0.642168\n",
      "epoch 6; iter: 200; batch classifier loss: 0.595829; batch adversarial loss: 0.554942\n",
      "epoch 7; iter: 0; batch classifier loss: 0.590889; batch adversarial loss: 0.619384\n",
      "epoch 7; iter: 200; batch classifier loss: 0.457296; batch adversarial loss: 0.637334\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426142; batch adversarial loss: 0.652147\n",
      "epoch 8; iter: 200; batch classifier loss: 0.580976; batch adversarial loss: 0.682564\n",
      "epoch 9; iter: 0; batch classifier loss: 0.350708; batch adversarial loss: 0.683235\n",
      "epoch 9; iter: 200; batch classifier loss: 0.473143; batch adversarial loss: 0.615216\n",
      "epoch 10; iter: 0; batch classifier loss: 0.416986; batch adversarial loss: 0.630841\n",
      "epoch 10; iter: 200; batch classifier loss: 0.452447; batch adversarial loss: 0.599501\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404353; batch adversarial loss: 0.586026\n",
      "epoch 11; iter: 200; batch classifier loss: 0.362600; batch adversarial loss: 0.651584\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381424; batch adversarial loss: 0.625796\n",
      "epoch 12; iter: 200; batch classifier loss: 0.379925; batch adversarial loss: 0.646591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.415490; batch adversarial loss: 0.609270\n",
      "epoch 13; iter: 200; batch classifier loss: 0.380626; batch adversarial loss: 0.579243\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370719; batch adversarial loss: 0.626133\n",
      "epoch 14; iter: 200; batch classifier loss: 0.380945; batch adversarial loss: 0.613202\n",
      "epoch 15; iter: 0; batch classifier loss: 0.341255; batch adversarial loss: 0.595493\n",
      "epoch 15; iter: 200; batch classifier loss: 0.453731; batch adversarial loss: 0.589267\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348049; batch adversarial loss: 0.625448\n",
      "epoch 16; iter: 200; batch classifier loss: 0.330286; batch adversarial loss: 0.735164\n",
      "epoch 17; iter: 0; batch classifier loss: 0.376610; batch adversarial loss: 0.619326\n",
      "epoch 17; iter: 200; batch classifier loss: 0.424501; batch adversarial loss: 0.627939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.385783; batch adversarial loss: 0.656569\n",
      "epoch 18; iter: 200; batch classifier loss: 0.395724; batch adversarial loss: 0.635806\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369130; batch adversarial loss: 0.623140\n",
      "epoch 19; iter: 200; batch classifier loss: 0.305373; batch adversarial loss: 0.633492\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337930; batch adversarial loss: 0.578876\n",
      "epoch 20; iter: 200; batch classifier loss: 0.306998; batch adversarial loss: 0.607360\n",
      "epoch 21; iter: 0; batch classifier loss: 0.445885; batch adversarial loss: 0.606488\n",
      "epoch 21; iter: 200; batch classifier loss: 0.360240; batch adversarial loss: 0.664936\n",
      "epoch 22; iter: 0; batch classifier loss: 0.359312; batch adversarial loss: 0.629120\n",
      "epoch 22; iter: 200; batch classifier loss: 0.327979; batch adversarial loss: 0.639885\n",
      "epoch 23; iter: 0; batch classifier loss: 0.307389; batch adversarial loss: 0.592582\n",
      "epoch 23; iter: 200; batch classifier loss: 0.399826; batch adversarial loss: 0.591909\n",
      "epoch 24; iter: 0; batch classifier loss: 0.282216; batch adversarial loss: 0.616077\n",
      "epoch 24; iter: 200; batch classifier loss: 0.389778; batch adversarial loss: 0.568629\n",
      "epoch 25; iter: 0; batch classifier loss: 0.308774; batch adversarial loss: 0.622379\n",
      "epoch 25; iter: 200; batch classifier loss: 0.328025; batch adversarial loss: 0.601324\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340564; batch adversarial loss: 0.622238\n",
      "epoch 26; iter: 200; batch classifier loss: 0.488269; batch adversarial loss: 0.584301\n",
      "epoch 27; iter: 0; batch classifier loss: 0.374925; batch adversarial loss: 0.612383\n",
      "epoch 27; iter: 200; batch classifier loss: 0.357824; batch adversarial loss: 0.578843\n",
      "epoch 28; iter: 0; batch classifier loss: 0.366278; batch adversarial loss: 0.559028\n",
      "epoch 28; iter: 200; batch classifier loss: 0.308656; batch adversarial loss: 0.658034\n",
      "epoch 29; iter: 0; batch classifier loss: 0.362486; batch adversarial loss: 0.572618\n",
      "epoch 29; iter: 200; batch classifier loss: 0.269242; batch adversarial loss: 0.672755\n",
      "epoch 30; iter: 0; batch classifier loss: 0.383693; batch adversarial loss: 0.627514\n",
      "epoch 30; iter: 200; batch classifier loss: 0.378827; batch adversarial loss: 0.601656\n",
      "epoch 31; iter: 0; batch classifier loss: 0.252317; batch adversarial loss: 0.645912\n",
      "epoch 31; iter: 200; batch classifier loss: 0.356573; batch adversarial loss: 0.612847\n",
      "epoch 32; iter: 0; batch classifier loss: 0.380836; batch adversarial loss: 0.621623\n",
      "epoch 32; iter: 200; batch classifier loss: 0.332220; batch adversarial loss: 0.725022\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409013; batch adversarial loss: 0.659330\n",
      "epoch 33; iter: 200; batch classifier loss: 0.340042; batch adversarial loss: 0.646707\n",
      "epoch 34; iter: 0; batch classifier loss: 0.268154; batch adversarial loss: 0.654912\n",
      "epoch 34; iter: 200; batch classifier loss: 0.577810; batch adversarial loss: 0.587269\n",
      "epoch 35; iter: 0; batch classifier loss: 0.354876; batch adversarial loss: 0.655950\n",
      "epoch 35; iter: 200; batch classifier loss: 0.339970; batch adversarial loss: 0.654591\n",
      "epoch 36; iter: 0; batch classifier loss: 0.419339; batch adversarial loss: 0.595099\n",
      "epoch 36; iter: 200; batch classifier loss: 0.338050; batch adversarial loss: 0.664358\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424889; batch adversarial loss: 0.644618\n",
      "epoch 37; iter: 200; batch classifier loss: 0.349551; batch adversarial loss: 0.597764\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405327; batch adversarial loss: 0.625715\n",
      "epoch 38; iter: 200; batch classifier loss: 0.570947; batch adversarial loss: 0.640109\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455336; batch adversarial loss: 0.652821\n",
      "epoch 39; iter: 200; batch classifier loss: 0.387133; batch adversarial loss: 0.664068\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429004; batch adversarial loss: 0.641874\n",
      "epoch 40; iter: 200; batch classifier loss: 0.354956; batch adversarial loss: 0.580387\n",
      "epoch 41; iter: 0; batch classifier loss: 0.373960; batch adversarial loss: 0.597202\n",
      "epoch 41; iter: 200; batch classifier loss: 0.433705; batch adversarial loss: 0.572421\n",
      "epoch 42; iter: 0; batch classifier loss: 0.357856; batch adversarial loss: 0.626929\n",
      "epoch 42; iter: 200; batch classifier loss: 0.432502; batch adversarial loss: 0.562589\n",
      "epoch 43; iter: 0; batch classifier loss: 0.351053; batch adversarial loss: 0.623420\n",
      "epoch 43; iter: 200; batch classifier loss: 0.416594; batch adversarial loss: 0.577900\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451102; batch adversarial loss: 0.619215\n",
      "epoch 44; iter: 200; batch classifier loss: 0.322143; batch adversarial loss: 0.626779\n",
      "epoch 45; iter: 0; batch classifier loss: 0.526848; batch adversarial loss: 0.658343\n",
      "epoch 45; iter: 200; batch classifier loss: 0.335928; batch adversarial loss: 0.620423\n",
      "epoch 46; iter: 0; batch classifier loss: 0.312172; batch adversarial loss: 0.597730\n",
      "epoch 46; iter: 200; batch classifier loss: 0.332337; batch adversarial loss: 0.647520\n",
      "epoch 47; iter: 0; batch classifier loss: 0.352431; batch adversarial loss: 0.629144\n",
      "epoch 47; iter: 200; batch classifier loss: 0.595960; batch adversarial loss: 0.662813\n",
      "epoch 48; iter: 0; batch classifier loss: 0.333562; batch adversarial loss: 0.612572\n",
      "epoch 48; iter: 200; batch classifier loss: 0.338217; batch adversarial loss: 0.654077\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422938; batch adversarial loss: 0.591726\n",
      "epoch 49; iter: 200; batch classifier loss: 0.426157; batch adversarial loss: 0.647000\n",
      "epoch 0; iter: 0; batch classifier loss: 58.299007; batch adversarial loss: 0.670328\n",
      "epoch 0; iter: 200; batch classifier loss: 8.615425; batch adversarial loss: 0.663217\n",
      "epoch 1; iter: 0; batch classifier loss: 4.629797; batch adversarial loss: 0.676995\n",
      "epoch 1; iter: 200; batch classifier loss: 2.941015; batch adversarial loss: 0.615702\n",
      "epoch 2; iter: 0; batch classifier loss: 3.059931; batch adversarial loss: 0.612645\n",
      "epoch 2; iter: 200; batch classifier loss: 13.741646; batch adversarial loss: 0.630049\n",
      "epoch 3; iter: 0; batch classifier loss: 1.197931; batch adversarial loss: 0.611019\n",
      "epoch 3; iter: 200; batch classifier loss: 2.551228; batch adversarial loss: 0.636944\n",
      "epoch 4; iter: 0; batch classifier loss: 11.745655; batch adversarial loss: 0.601303\n",
      "epoch 4; iter: 200; batch classifier loss: 1.005218; batch adversarial loss: 0.683672\n",
      "epoch 5; iter: 0; batch classifier loss: 8.507772; batch adversarial loss: 0.679395\n",
      "epoch 5; iter: 200; batch classifier loss: 0.565498; batch adversarial loss: 0.603460\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580462; batch adversarial loss: 0.637896\n",
      "epoch 6; iter: 200; batch classifier loss: 0.650239; batch adversarial loss: 0.634402\n",
      "epoch 7; iter: 0; batch classifier loss: 0.576767; batch adversarial loss: 0.623377\n",
      "epoch 7; iter: 200; batch classifier loss: 0.538207; batch adversarial loss: 0.650968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.395001; batch adversarial loss: 0.627687\n",
      "epoch 8; iter: 200; batch classifier loss: 0.621865; batch adversarial loss: 0.659045\n",
      "epoch 9; iter: 0; batch classifier loss: 0.448586; batch adversarial loss: 0.580652\n",
      "epoch 9; iter: 200; batch classifier loss: 1.224120; batch adversarial loss: 0.684365\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443251; batch adversarial loss: 0.621658\n",
      "epoch 10; iter: 200; batch classifier loss: 0.463406; batch adversarial loss: 0.629732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.460999; batch adversarial loss: 0.582774\n",
      "epoch 11; iter: 200; batch classifier loss: 0.410363; batch adversarial loss: 0.614286\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590144; batch adversarial loss: 0.589795\n",
      "epoch 12; iter: 200; batch classifier loss: 0.493453; batch adversarial loss: 0.605898\n",
      "epoch 13; iter: 0; batch classifier loss: 0.379553; batch adversarial loss: 0.574373\n",
      "epoch 13; iter: 200; batch classifier loss: 0.440939; batch adversarial loss: 0.578475\n",
      "epoch 14; iter: 0; batch classifier loss: 0.455545; batch adversarial loss: 0.610399\n",
      "epoch 14; iter: 200; batch classifier loss: 0.692691; batch adversarial loss: 0.600811\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391841; batch adversarial loss: 0.616841\n",
      "epoch 15; iter: 200; batch classifier loss: 0.298929; batch adversarial loss: 0.630142\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314561; batch adversarial loss: 0.569889\n",
      "epoch 16; iter: 200; batch classifier loss: 0.365621; batch adversarial loss: 0.620447\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345647; batch adversarial loss: 0.612864\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381132; batch adversarial loss: 0.610223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.420264; batch adversarial loss: 0.556441\n",
      "epoch 18; iter: 200; batch classifier loss: 0.365798; batch adversarial loss: 0.634877\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264105; batch adversarial loss: 0.643376\n",
      "epoch 19; iter: 200; batch classifier loss: 0.424980; batch adversarial loss: 0.608036\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356307; batch adversarial loss: 0.628116\n",
      "epoch 20; iter: 200; batch classifier loss: 0.343103; batch adversarial loss: 0.654912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312878; batch adversarial loss: 0.675368\n",
      "epoch 21; iter: 200; batch classifier loss: 0.353971; batch adversarial loss: 0.582289\n",
      "epoch 22; iter: 0; batch classifier loss: 0.386545; batch adversarial loss: 0.609201\n",
      "epoch 22; iter: 200; batch classifier loss: 0.257055; batch adversarial loss: 0.595371\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379159; batch adversarial loss: 0.609426\n",
      "epoch 23; iter: 200; batch classifier loss: 0.690362; batch adversarial loss: 0.560505\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370818; batch adversarial loss: 0.615577\n",
      "epoch 24; iter: 200; batch classifier loss: 0.351491; batch adversarial loss: 0.572753\n",
      "epoch 25; iter: 0; batch classifier loss: 0.318953; batch adversarial loss: 0.622712\n",
      "epoch 25; iter: 200; batch classifier loss: 0.383319; batch adversarial loss: 0.624141\n",
      "epoch 26; iter: 0; batch classifier loss: 0.351164; batch adversarial loss: 0.590636\n",
      "epoch 26; iter: 200; batch classifier loss: 0.289093; batch adversarial loss: 0.601734\n",
      "epoch 27; iter: 0; batch classifier loss: 0.374754; batch adversarial loss: 0.588653\n",
      "epoch 27; iter: 200; batch classifier loss: 0.309213; batch adversarial loss: 0.638989\n",
      "epoch 28; iter: 0; batch classifier loss: 0.335152; batch adversarial loss: 0.665767\n",
      "epoch 28; iter: 200; batch classifier loss: 0.364831; batch adversarial loss: 0.621673\n",
      "epoch 29; iter: 0; batch classifier loss: 0.354444; batch adversarial loss: 0.599005\n",
      "epoch 29; iter: 200; batch classifier loss: 0.517545; batch adversarial loss: 0.658010\n",
      "epoch 30; iter: 0; batch classifier loss: 0.269955; batch adversarial loss: 0.659760\n",
      "epoch 30; iter: 200; batch classifier loss: 0.349511; batch adversarial loss: 0.618617\n",
      "epoch 31; iter: 0; batch classifier loss: 0.368492; batch adversarial loss: 0.610255\n",
      "epoch 31; iter: 200; batch classifier loss: 0.377181; batch adversarial loss: 0.577131\n",
      "epoch 32; iter: 0; batch classifier loss: 0.339514; batch adversarial loss: 0.636975\n",
      "epoch 32; iter: 200; batch classifier loss: 0.267761; batch adversarial loss: 0.613918\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358994; batch adversarial loss: 0.527522\n",
      "epoch 33; iter: 200; batch classifier loss: 0.315944; batch adversarial loss: 0.683278\n",
      "epoch 34; iter: 0; batch classifier loss: 0.289257; batch adversarial loss: 0.607612\n",
      "epoch 34; iter: 200; batch classifier loss: 0.379956; batch adversarial loss: 0.649184\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449147; batch adversarial loss: 0.565008\n",
      "epoch 35; iter: 200; batch classifier loss: 0.364459; batch adversarial loss: 0.698008\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480237; batch adversarial loss: 0.625879\n",
      "epoch 36; iter: 200; batch classifier loss: 0.312740; batch adversarial loss: 0.626832\n",
      "epoch 37; iter: 0; batch classifier loss: 0.328034; batch adversarial loss: 0.546657\n",
      "epoch 37; iter: 200; batch classifier loss: 0.366786; batch adversarial loss: 0.602021\n",
      "epoch 38; iter: 0; batch classifier loss: 0.334660; batch adversarial loss: 0.558787\n",
      "epoch 38; iter: 200; batch classifier loss: 0.372507; batch adversarial loss: 0.643898\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423235; batch adversarial loss: 0.632512\n",
      "epoch 39; iter: 200; batch classifier loss: 0.304561; batch adversarial loss: 0.631552\n",
      "epoch 40; iter: 0; batch classifier loss: 0.338230; batch adversarial loss: 0.602840\n",
      "epoch 40; iter: 200; batch classifier loss: 0.394917; batch adversarial loss: 0.688379\n",
      "epoch 41; iter: 0; batch classifier loss: 0.691457; batch adversarial loss: 0.571546\n",
      "epoch 41; iter: 200; batch classifier loss: 0.299754; batch adversarial loss: 0.602220\n",
      "epoch 42; iter: 0; batch classifier loss: 0.366595; batch adversarial loss: 0.654867\n",
      "epoch 42; iter: 200; batch classifier loss: 0.465099; batch adversarial loss: 0.655479\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418006; batch adversarial loss: 0.600113\n",
      "epoch 43; iter: 200; batch classifier loss: 0.274002; batch adversarial loss: 0.607321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412738; batch adversarial loss: 0.531729\n",
      "epoch 44; iter: 200; batch classifier loss: 0.352877; batch adversarial loss: 0.571685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430092; batch adversarial loss: 0.613132\n",
      "epoch 45; iter: 200; batch classifier loss: 0.309458; batch adversarial loss: 0.636713\n",
      "epoch 46; iter: 0; batch classifier loss: 0.344357; batch adversarial loss: 0.622309\n",
      "epoch 46; iter: 200; batch classifier loss: 0.389959; batch adversarial loss: 0.627540\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484855; batch adversarial loss: 0.620539\n",
      "epoch 47; iter: 200; batch classifier loss: 0.240537; batch adversarial loss: 0.671505\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419554; batch adversarial loss: 0.618345\n",
      "epoch 48; iter: 200; batch classifier loss: 0.413132; batch adversarial loss: 0.558853\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426053; batch adversarial loss: 0.593482\n",
      "epoch 49; iter: 200; batch classifier loss: 0.405915; batch adversarial loss: 0.610840\n",
      "epoch 0; iter: 0; batch classifier loss: 102.800652; batch adversarial loss: 0.693195\n",
      "epoch 0; iter: 200; batch classifier loss: 11.744194; batch adversarial loss: 0.664688\n",
      "epoch 1; iter: 0; batch classifier loss: 3.755233; batch adversarial loss: 0.636101\n",
      "epoch 1; iter: 200; batch classifier loss: 4.561151; batch adversarial loss: 0.667565\n",
      "epoch 2; iter: 0; batch classifier loss: 9.662846; batch adversarial loss: 0.639051\n",
      "epoch 2; iter: 200; batch classifier loss: 4.063804; batch adversarial loss: 0.596958\n",
      "epoch 3; iter: 0; batch classifier loss: 2.266232; batch adversarial loss: 0.614165\n",
      "epoch 3; iter: 200; batch classifier loss: 3.485707; batch adversarial loss: 0.645039\n",
      "epoch 4; iter: 0; batch classifier loss: 2.341882; batch adversarial loss: 0.606130\n",
      "epoch 4; iter: 200; batch classifier loss: 2.364844; batch adversarial loss: 0.666293\n",
      "epoch 5; iter: 0; batch classifier loss: 0.969284; batch adversarial loss: 0.621632\n",
      "epoch 5; iter: 200; batch classifier loss: 1.391271; batch adversarial loss: 0.609200\n",
      "epoch 6; iter: 0; batch classifier loss: 1.002796; batch adversarial loss: 0.648671\n",
      "epoch 6; iter: 200; batch classifier loss: 0.842105; batch adversarial loss: 0.651967\n",
      "epoch 7; iter: 0; batch classifier loss: 1.059536; batch adversarial loss: 0.580902\n",
      "epoch 7; iter: 200; batch classifier loss: 0.426087; batch adversarial loss: 0.580842\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559232; batch adversarial loss: 0.654099\n",
      "epoch 8; iter: 200; batch classifier loss: 0.608317; batch adversarial loss: 0.588687\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488681; batch adversarial loss: 0.613935\n",
      "epoch 9; iter: 200; batch classifier loss: 0.384717; batch adversarial loss: 0.621543\n",
      "epoch 10; iter: 0; batch classifier loss: 0.411059; batch adversarial loss: 0.643990\n",
      "epoch 10; iter: 200; batch classifier loss: 0.365751; batch adversarial loss: 0.659167\n",
      "epoch 11; iter: 0; batch classifier loss: 0.307854; batch adversarial loss: 0.610562\n",
      "epoch 11; iter: 200; batch classifier loss: 0.487917; batch adversarial loss: 0.636667\n",
      "epoch 12; iter: 0; batch classifier loss: 0.330646; batch adversarial loss: 0.617636\n",
      "epoch 12; iter: 200; batch classifier loss: 0.470126; batch adversarial loss: 0.583189\n",
      "epoch 13; iter: 0; batch classifier loss: 0.387480; batch adversarial loss: 0.635726\n",
      "epoch 13; iter: 200; batch classifier loss: 0.431906; batch adversarial loss: 0.631984\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395369; batch adversarial loss: 0.639010\n",
      "epoch 14; iter: 200; batch classifier loss: 0.348229; batch adversarial loss: 0.645447\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452012; batch adversarial loss: 0.568537\n",
      "epoch 15; iter: 200; batch classifier loss: 0.728522; batch adversarial loss: 0.648689\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298336; batch adversarial loss: 0.632371\n",
      "epoch 16; iter: 200; batch classifier loss: 0.272163; batch adversarial loss: 0.604494\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332284; batch adversarial loss: 0.659230\n",
      "epoch 17; iter: 200; batch classifier loss: 0.544814; batch adversarial loss: 0.591513\n",
      "epoch 18; iter: 0; batch classifier loss: 0.344364; batch adversarial loss: 0.675080\n",
      "epoch 18; iter: 200; batch classifier loss: 0.411512; batch adversarial loss: 0.636924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.588131; batch adversarial loss: 0.577356\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429134; batch adversarial loss: 0.613533\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437344; batch adversarial loss: 0.613943\n",
      "epoch 20; iter: 200; batch classifier loss: 0.423125; batch adversarial loss: 0.518607\n",
      "epoch 21; iter: 0; batch classifier loss: 0.385822; batch adversarial loss: 0.658908\n",
      "epoch 21; iter: 200; batch classifier loss: 0.288905; batch adversarial loss: 0.640677\n",
      "epoch 22; iter: 0; batch classifier loss: 0.367921; batch adversarial loss: 0.593802\n",
      "epoch 22; iter: 200; batch classifier loss: 0.440051; batch adversarial loss: 0.568988\n",
      "epoch 23; iter: 0; batch classifier loss: 0.307023; batch adversarial loss: 0.642656\n",
      "epoch 23; iter: 200; batch classifier loss: 0.358616; batch adversarial loss: 0.672915\n",
      "epoch 24; iter: 0; batch classifier loss: 0.357132; batch adversarial loss: 0.654496\n",
      "epoch 24; iter: 200; batch classifier loss: 0.329096; batch adversarial loss: 0.620298\n",
      "epoch 25; iter: 0; batch classifier loss: 0.348780; batch adversarial loss: 0.619178\n",
      "epoch 25; iter: 200; batch classifier loss: 0.435010; batch adversarial loss: 0.571242\n",
      "epoch 26; iter: 0; batch classifier loss: 0.355636; batch adversarial loss: 0.595464\n",
      "epoch 26; iter: 200; batch classifier loss: 0.376837; batch adversarial loss: 0.611624\n",
      "epoch 27; iter: 0; batch classifier loss: 0.309800; batch adversarial loss: 0.616762\n",
      "epoch 27; iter: 200; batch classifier loss: 0.353083; batch adversarial loss: 0.567956\n",
      "epoch 28; iter: 0; batch classifier loss: 0.311436; batch adversarial loss: 0.625154\n",
      "epoch 28; iter: 200; batch classifier loss: 0.398752; batch adversarial loss: 0.666418\n",
      "epoch 29; iter: 0; batch classifier loss: 0.321674; batch adversarial loss: 0.634630\n",
      "epoch 29; iter: 200; batch classifier loss: 0.277425; batch adversarial loss: 0.682370\n",
      "epoch 30; iter: 0; batch classifier loss: 0.393853; batch adversarial loss: 0.597084\n",
      "epoch 30; iter: 200; batch classifier loss: 0.313045; batch adversarial loss: 0.673546\n",
      "epoch 31; iter: 0; batch classifier loss: 0.310467; batch adversarial loss: 0.612347\n",
      "epoch 31; iter: 200; batch classifier loss: 0.464859; batch adversarial loss: 0.599160\n",
      "epoch 32; iter: 0; batch classifier loss: 0.457257; batch adversarial loss: 0.601074\n",
      "epoch 32; iter: 200; batch classifier loss: 0.437488; batch adversarial loss: 0.633021\n",
      "epoch 33; iter: 0; batch classifier loss: 0.351563; batch adversarial loss: 0.612061\n",
      "epoch 33; iter: 200; batch classifier loss: 0.459491; batch adversarial loss: 0.671038\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425365; batch adversarial loss: 0.586636\n",
      "epoch 34; iter: 200; batch classifier loss: 0.355781; batch adversarial loss: 0.639700\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402370; batch adversarial loss: 0.632835\n",
      "epoch 35; iter: 200; batch classifier loss: 0.321873; batch adversarial loss: 0.563671\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347366; batch adversarial loss: 0.628330\n",
      "epoch 36; iter: 200; batch classifier loss: 0.362029; batch adversarial loss: 0.629969\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464327; batch adversarial loss: 0.673241\n",
      "epoch 37; iter: 200; batch classifier loss: 0.300772; batch adversarial loss: 0.608056\n",
      "epoch 38; iter: 0; batch classifier loss: 0.337807; batch adversarial loss: 0.601607\n",
      "epoch 38; iter: 200; batch classifier loss: 0.411932; batch adversarial loss: 0.597280\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407792; batch adversarial loss: 0.602127\n",
      "epoch 39; iter: 200; batch classifier loss: 0.339597; batch adversarial loss: 0.631160\n",
      "epoch 40; iter: 0; batch classifier loss: 0.334551; batch adversarial loss: 0.611814\n",
      "epoch 40; iter: 200; batch classifier loss: 0.381593; batch adversarial loss: 0.572926\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406860; batch adversarial loss: 0.633211\n",
      "epoch 41; iter: 200; batch classifier loss: 0.389420; batch adversarial loss: 0.596665\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490569; batch adversarial loss: 0.616232\n",
      "epoch 42; iter: 200; batch classifier loss: 0.285243; batch adversarial loss: 0.613948\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362395; batch adversarial loss: 0.617798\n",
      "epoch 43; iter: 200; batch classifier loss: 0.354629; batch adversarial loss: 0.632814\n",
      "epoch 44; iter: 0; batch classifier loss: 0.355915; batch adversarial loss: 0.672567\n",
      "epoch 44; iter: 200; batch classifier loss: 0.368860; batch adversarial loss: 0.600181\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354040; batch adversarial loss: 0.686126\n",
      "epoch 45; iter: 200; batch classifier loss: 0.400720; batch adversarial loss: 0.648248\n",
      "epoch 46; iter: 0; batch classifier loss: 0.373991; batch adversarial loss: 0.578212\n",
      "epoch 46; iter: 200; batch classifier loss: 0.315501; batch adversarial loss: 0.645313\n",
      "epoch 47; iter: 0; batch classifier loss: 0.309572; batch adversarial loss: 0.647066\n",
      "epoch 47; iter: 200; batch classifier loss: 0.417155; batch adversarial loss: 0.628650\n",
      "epoch 48; iter: 0; batch classifier loss: 0.348843; batch adversarial loss: 0.643551\n",
      "epoch 48; iter: 200; batch classifier loss: 0.341232; batch adversarial loss: 0.670640\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357824; batch adversarial loss: 0.665643\n",
      "epoch 49; iter: 200; batch classifier loss: 0.365998; batch adversarial loss: 0.623631\n",
      "epoch 0; iter: 0; batch classifier loss: 25.874176; batch adversarial loss: 0.758334\n",
      "epoch 0; iter: 200; batch classifier loss: 6.134072; batch adversarial loss: 0.661298\n",
      "epoch 1; iter: 0; batch classifier loss: 13.662582; batch adversarial loss: 0.685670\n",
      "epoch 1; iter: 200; batch classifier loss: 5.117737; batch adversarial loss: 0.650471\n",
      "epoch 2; iter: 0; batch classifier loss: 6.425753; batch adversarial loss: 0.612658\n",
      "epoch 2; iter: 200; batch classifier loss: 5.565818; batch adversarial loss: 0.611109\n",
      "epoch 3; iter: 0; batch classifier loss: 5.568077; batch adversarial loss: 0.629634\n",
      "epoch 3; iter: 200; batch classifier loss: 1.179650; batch adversarial loss: 0.597797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.697488; batch adversarial loss: 0.689826\n",
      "epoch 4; iter: 200; batch classifier loss: 1.399188; batch adversarial loss: 0.675322\n",
      "epoch 5; iter: 0; batch classifier loss: 5.551775; batch adversarial loss: 0.653963\n",
      "epoch 5; iter: 200; batch classifier loss: 0.924362; batch adversarial loss: 0.631734\n",
      "epoch 6; iter: 0; batch classifier loss: 0.846695; batch adversarial loss: 0.607722\n",
      "epoch 6; iter: 200; batch classifier loss: 1.244716; batch adversarial loss: 0.569293\n",
      "epoch 7; iter: 0; batch classifier loss: 0.317019; batch adversarial loss: 0.686545\n",
      "epoch 7; iter: 200; batch classifier loss: 1.509796; batch adversarial loss: 0.604043\n",
      "epoch 8; iter: 0; batch classifier loss: 2.056453; batch adversarial loss: 0.579327\n",
      "epoch 8; iter: 200; batch classifier loss: 0.536034; batch adversarial loss: 0.543601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591552; batch adversarial loss: 0.595544\n",
      "epoch 9; iter: 200; batch classifier loss: 0.375324; batch adversarial loss: 0.644667\n",
      "epoch 10; iter: 0; batch classifier loss: 0.402729; batch adversarial loss: 0.558409\n",
      "epoch 10; iter: 200; batch classifier loss: 0.411831; batch adversarial loss: 0.612061\n",
      "epoch 11; iter: 0; batch classifier loss: 0.405364; batch adversarial loss: 0.592308\n",
      "epoch 11; iter: 200; batch classifier loss: 0.347975; batch adversarial loss: 0.646490\n",
      "epoch 12; iter: 0; batch classifier loss: 0.421787; batch adversarial loss: 0.633989\n",
      "epoch 12; iter: 200; batch classifier loss: 0.441920; batch adversarial loss: 0.623699\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374497; batch adversarial loss: 0.640916\n",
      "epoch 13; iter: 200; batch classifier loss: 0.306227; batch adversarial loss: 0.649974\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510105; batch adversarial loss: 0.680159\n",
      "epoch 14; iter: 200; batch classifier loss: 0.333820; batch adversarial loss: 0.663626\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470896; batch adversarial loss: 0.600102\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353644; batch adversarial loss: 0.566695\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303173; batch adversarial loss: 0.625741\n",
      "epoch 16; iter: 200; batch classifier loss: 0.353844; batch adversarial loss: 0.683558\n",
      "epoch 17; iter: 0; batch classifier loss: 0.401018; batch adversarial loss: 0.559242\n",
      "epoch 17; iter: 200; batch classifier loss: 0.422429; batch adversarial loss: 0.630263\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362865; batch adversarial loss: 0.634551\n",
      "epoch 18; iter: 200; batch classifier loss: 0.411221; batch adversarial loss: 0.636766\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338165; batch adversarial loss: 0.611038\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342075; batch adversarial loss: 0.577130\n",
      "epoch 20; iter: 0; batch classifier loss: 0.366181; batch adversarial loss: 0.632693\n",
      "epoch 20; iter: 200; batch classifier loss: 0.283314; batch adversarial loss: 0.680266\n",
      "epoch 21; iter: 0; batch classifier loss: 0.320986; batch adversarial loss: 0.654761\n",
      "epoch 21; iter: 200; batch classifier loss: 0.323026; batch adversarial loss: 0.582622\n",
      "epoch 22; iter: 0; batch classifier loss: 0.315215; batch adversarial loss: 0.637905\n",
      "epoch 22; iter: 200; batch classifier loss: 0.365171; batch adversarial loss: 0.633021\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497731; batch adversarial loss: 0.619241\n",
      "epoch 23; iter: 200; batch classifier loss: 0.335858; batch adversarial loss: 0.649432\n",
      "epoch 24; iter: 0; batch classifier loss: 0.332958; batch adversarial loss: 0.654814\n",
      "epoch 24; iter: 200; batch classifier loss: 0.320486; batch adversarial loss: 0.621121\n",
      "epoch 25; iter: 0; batch classifier loss: 0.312704; batch adversarial loss: 0.696707\n",
      "epoch 25; iter: 200; batch classifier loss: 0.290039; batch adversarial loss: 0.623769\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298618; batch adversarial loss: 0.638307\n",
      "epoch 26; iter: 200; batch classifier loss: 0.388723; batch adversarial loss: 0.614257\n",
      "epoch 27; iter: 0; batch classifier loss: 0.318085; batch adversarial loss: 0.626358\n",
      "epoch 27; iter: 200; batch classifier loss: 0.368968; batch adversarial loss: 0.648816\n",
      "epoch 28; iter: 0; batch classifier loss: 0.347780; batch adversarial loss: 0.582898\n",
      "epoch 28; iter: 200; batch classifier loss: 0.328639; batch adversarial loss: 0.598178\n",
      "epoch 29; iter: 0; batch classifier loss: 0.410654; batch adversarial loss: 0.595944\n",
      "epoch 29; iter: 200; batch classifier loss: 0.393717; batch adversarial loss: 0.643302\n",
      "epoch 30; iter: 0; batch classifier loss: 0.384918; batch adversarial loss: 0.609272\n",
      "epoch 30; iter: 200; batch classifier loss: 0.384509; batch adversarial loss: 0.658169\n",
      "epoch 31; iter: 0; batch classifier loss: 0.375355; batch adversarial loss: 0.629020\n",
      "epoch 31; iter: 200; batch classifier loss: 0.469296; batch adversarial loss: 0.610731\n",
      "epoch 32; iter: 0; batch classifier loss: 0.347872; batch adversarial loss: 0.633263\n",
      "epoch 32; iter: 200; batch classifier loss: 0.353673; batch adversarial loss: 0.606192\n",
      "epoch 33; iter: 0; batch classifier loss: 0.264618; batch adversarial loss: 0.615409\n",
      "epoch 33; iter: 200; batch classifier loss: 0.367408; batch adversarial loss: 0.616246\n",
      "epoch 34; iter: 0; batch classifier loss: 0.258670; batch adversarial loss: 0.625471\n",
      "epoch 34; iter: 200; batch classifier loss: 0.245127; batch adversarial loss: 0.582168\n",
      "epoch 35; iter: 0; batch classifier loss: 0.304170; batch adversarial loss: 0.634298\n",
      "epoch 35; iter: 200; batch classifier loss: 0.323767; batch adversarial loss: 0.618072\n",
      "epoch 36; iter: 0; batch classifier loss: 0.399596; batch adversarial loss: 0.594575\n",
      "epoch 36; iter: 200; batch classifier loss: 0.488403; batch adversarial loss: 0.651427\n",
      "epoch 37; iter: 0; batch classifier loss: 0.418475; batch adversarial loss: 0.597205\n",
      "epoch 37; iter: 200; batch classifier loss: 0.332200; batch adversarial loss: 0.610909\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381440; batch adversarial loss: 0.623993\n",
      "epoch 38; iter: 200; batch classifier loss: 0.304685; batch adversarial loss: 0.590136\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404534; batch adversarial loss: 0.593013\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349948; batch adversarial loss: 0.599975\n",
      "epoch 40; iter: 0; batch classifier loss: 0.359489; batch adversarial loss: 0.573826\n",
      "epoch 40; iter: 200; batch classifier loss: 0.391362; batch adversarial loss: 0.641377\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424201; batch adversarial loss: 0.612997\n",
      "epoch 41; iter: 200; batch classifier loss: 0.321721; batch adversarial loss: 0.567370\n",
      "epoch 42; iter: 0; batch classifier loss: 0.354335; batch adversarial loss: 0.644590\n",
      "epoch 42; iter: 200; batch classifier loss: 0.293639; batch adversarial loss: 0.608638\n",
      "epoch 43; iter: 0; batch classifier loss: 0.240647; batch adversarial loss: 0.610035\n",
      "epoch 43; iter: 200; batch classifier loss: 0.387765; batch adversarial loss: 0.642362\n",
      "epoch 44; iter: 0; batch classifier loss: 0.311857; batch adversarial loss: 0.549431\n",
      "epoch 44; iter: 200; batch classifier loss: 0.291974; batch adversarial loss: 0.653634\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367381; batch adversarial loss: 0.619187\n",
      "epoch 45; iter: 200; batch classifier loss: 0.248826; batch adversarial loss: 0.645733\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455001; batch adversarial loss: 0.644832\n",
      "epoch 46; iter: 200; batch classifier loss: 0.508312; batch adversarial loss: 0.594315\n",
      "epoch 47; iter: 0; batch classifier loss: 0.280375; batch adversarial loss: 0.661080\n",
      "epoch 47; iter: 200; batch classifier loss: 0.401176; batch adversarial loss: 0.648022\n",
      "epoch 48; iter: 0; batch classifier loss: 0.275192; batch adversarial loss: 0.648415\n",
      "epoch 48; iter: 200; batch classifier loss: 0.365692; batch adversarial loss: 0.613366\n",
      "epoch 49; iter: 0; batch classifier loss: 0.395659; batch adversarial loss: 0.569401\n",
      "epoch 49; iter: 200; batch classifier loss: 0.392240; batch adversarial loss: 0.636258\n",
      "epoch 0; iter: 0; batch classifier loss: 45.376850; batch adversarial loss: 0.686097\n",
      "epoch 0; iter: 200; batch classifier loss: 27.997219; batch adversarial loss: 0.663321\n",
      "epoch 1; iter: 0; batch classifier loss: 3.185307; batch adversarial loss: 0.645466\n",
      "epoch 1; iter: 200; batch classifier loss: 11.683170; batch adversarial loss: 0.597229\n",
      "epoch 2; iter: 0; batch classifier loss: 1.630321; batch adversarial loss: 0.684683\n",
      "epoch 2; iter: 200; batch classifier loss: 3.726024; batch adversarial loss: 0.674963\n",
      "epoch 3; iter: 0; batch classifier loss: 1.422285; batch adversarial loss: 0.664242\n",
      "epoch 3; iter: 200; batch classifier loss: 1.821781; batch adversarial loss: 0.676102\n",
      "epoch 4; iter: 0; batch classifier loss: 1.974040; batch adversarial loss: 0.575984\n",
      "epoch 4; iter: 200; batch classifier loss: 1.009912; batch adversarial loss: 0.643302\n",
      "epoch 5; iter: 0; batch classifier loss: 1.165116; batch adversarial loss: 0.599043\n",
      "epoch 5; iter: 200; batch classifier loss: 1.705703; batch adversarial loss: 0.593069\n",
      "epoch 6; iter: 0; batch classifier loss: 0.838163; batch adversarial loss: 0.615407\n",
      "epoch 6; iter: 200; batch classifier loss: 0.409737; batch adversarial loss: 0.676138\n",
      "epoch 7; iter: 0; batch classifier loss: 0.697540; batch adversarial loss: 0.629778\n",
      "epoch 7; iter: 200; batch classifier loss: 0.741697; batch adversarial loss: 0.593186\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478394; batch adversarial loss: 0.600246\n",
      "epoch 8; iter: 200; batch classifier loss: 0.690585; batch adversarial loss: 0.666421\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519696; batch adversarial loss: 0.601958\n",
      "epoch 9; iter: 200; batch classifier loss: 0.382836; batch adversarial loss: 0.594210\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388790; batch adversarial loss: 0.613326\n",
      "epoch 10; iter: 200; batch classifier loss: 0.782780; batch adversarial loss: 0.623373\n",
      "epoch 11; iter: 0; batch classifier loss: 0.707296; batch adversarial loss: 0.637608\n",
      "epoch 11; iter: 200; batch classifier loss: 0.430683; batch adversarial loss: 0.572277\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427793; batch adversarial loss: 0.628128\n",
      "epoch 12; iter: 200; batch classifier loss: 0.409303; batch adversarial loss: 0.625098\n",
      "epoch 13; iter: 0; batch classifier loss: 0.624978; batch adversarial loss: 0.641153\n",
      "epoch 13; iter: 200; batch classifier loss: 1.089132; batch adversarial loss: 0.613750\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389486; batch adversarial loss: 0.649346\n",
      "epoch 14; iter: 200; batch classifier loss: 0.359748; batch adversarial loss: 0.653766\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406447; batch adversarial loss: 0.599929\n",
      "epoch 15; iter: 200; batch classifier loss: 0.268847; batch adversarial loss: 0.626398\n",
      "epoch 16; iter: 0; batch classifier loss: 0.424629; batch adversarial loss: 0.679200\n",
      "epoch 16; iter: 200; batch classifier loss: 0.423400; batch adversarial loss: 0.595286\n",
      "epoch 17; iter: 0; batch classifier loss: 0.358690; batch adversarial loss: 0.609835\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339632; batch adversarial loss: 0.635053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.403030; batch adversarial loss: 0.609557\n",
      "epoch 18; iter: 200; batch classifier loss: 0.319214; batch adversarial loss: 0.643066\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374664; batch adversarial loss: 0.597052\n",
      "epoch 19; iter: 200; batch classifier loss: 0.392788; batch adversarial loss: 0.606435\n",
      "epoch 20; iter: 0; batch classifier loss: 0.339484; batch adversarial loss: 0.644317\n",
      "epoch 20; iter: 200; batch classifier loss: 0.350036; batch adversarial loss: 0.642988\n",
      "epoch 21; iter: 0; batch classifier loss: 0.576915; batch adversarial loss: 0.627523\n",
      "epoch 21; iter: 200; batch classifier loss: 0.367564; batch adversarial loss: 0.618767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.302728; batch adversarial loss: 0.684509\n",
      "epoch 22; iter: 200; batch classifier loss: 0.385369; batch adversarial loss: 0.629209\n",
      "epoch 23; iter: 0; batch classifier loss: 0.247760; batch adversarial loss: 0.643673\n",
      "epoch 23; iter: 200; batch classifier loss: 0.345863; batch adversarial loss: 0.637340\n",
      "epoch 24; iter: 0; batch classifier loss: 0.409535; batch adversarial loss: 0.626154\n",
      "epoch 24; iter: 200; batch classifier loss: 0.412859; batch adversarial loss: 0.563553\n",
      "epoch 25; iter: 0; batch classifier loss: 0.415188; batch adversarial loss: 0.591827\n",
      "epoch 25; iter: 200; batch classifier loss: 0.290288; batch adversarial loss: 0.575616\n",
      "epoch 26; iter: 0; batch classifier loss: 0.375976; batch adversarial loss: 0.661735\n",
      "epoch 26; iter: 200; batch classifier loss: 0.426826; batch adversarial loss: 0.680371\n",
      "epoch 27; iter: 0; batch classifier loss: 0.341533; batch adversarial loss: 0.611072\n",
      "epoch 27; iter: 200; batch classifier loss: 0.324959; batch adversarial loss: 0.628474\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342181; batch adversarial loss: 0.628833\n",
      "epoch 28; iter: 200; batch classifier loss: 0.423220; batch adversarial loss: 0.597752\n",
      "epoch 29; iter: 0; batch classifier loss: 0.301820; batch adversarial loss: 0.600952\n",
      "epoch 29; iter: 200; batch classifier loss: 0.380666; batch adversarial loss: 0.631260\n",
      "epoch 30; iter: 0; batch classifier loss: 0.369383; batch adversarial loss: 0.595161\n",
      "epoch 30; iter: 200; batch classifier loss: 0.343722; batch adversarial loss: 0.605953\n",
      "epoch 31; iter: 0; batch classifier loss: 0.306692; batch adversarial loss: 0.634718\n",
      "epoch 31; iter: 200; batch classifier loss: 0.411867; batch adversarial loss: 0.574322\n",
      "epoch 32; iter: 0; batch classifier loss: 0.267490; batch adversarial loss: 0.581308\n",
      "epoch 32; iter: 200; batch classifier loss: 0.319578; batch adversarial loss: 0.637794\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272270; batch adversarial loss: 0.576810\n",
      "epoch 33; iter: 200; batch classifier loss: 0.359507; batch adversarial loss: 0.575098\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431546; batch adversarial loss: 0.586132\n",
      "epoch 34; iter: 200; batch classifier loss: 0.298807; batch adversarial loss: 0.687177\n",
      "epoch 35; iter: 0; batch classifier loss: 0.325311; batch adversarial loss: 0.606024\n",
      "epoch 35; iter: 200; batch classifier loss: 0.302468; batch adversarial loss: 0.644068\n",
      "epoch 36; iter: 0; batch classifier loss: 0.283337; batch adversarial loss: 0.632967\n",
      "epoch 36; iter: 200; batch classifier loss: 0.317518; batch adversarial loss: 0.607925\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288530; batch adversarial loss: 0.639410\n",
      "epoch 37; iter: 200; batch classifier loss: 0.416793; batch adversarial loss: 0.644079\n",
      "epoch 38; iter: 0; batch classifier loss: 0.362691; batch adversarial loss: 0.649221\n",
      "epoch 38; iter: 200; batch classifier loss: 0.323001; batch adversarial loss: 0.596258\n",
      "epoch 39; iter: 0; batch classifier loss: 0.390802; batch adversarial loss: 0.607385\n",
      "epoch 39; iter: 200; batch classifier loss: 0.418511; batch adversarial loss: 0.564022\n",
      "epoch 40; iter: 0; batch classifier loss: 0.378267; batch adversarial loss: 0.625113\n",
      "epoch 40; iter: 200; batch classifier loss: 0.405958; batch adversarial loss: 0.592416\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385276; batch adversarial loss: 0.659333\n",
      "epoch 41; iter: 200; batch classifier loss: 0.381984; batch adversarial loss: 0.566671\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408250; batch adversarial loss: 0.672904\n",
      "epoch 42; iter: 200; batch classifier loss: 0.399491; batch adversarial loss: 0.634066\n",
      "epoch 43; iter: 0; batch classifier loss: 0.341782; batch adversarial loss: 0.656849\n",
      "epoch 43; iter: 200; batch classifier loss: 0.301744; batch adversarial loss: 0.710913\n",
      "epoch 44; iter: 0; batch classifier loss: 0.332904; batch adversarial loss: 0.624967\n",
      "epoch 44; iter: 200; batch classifier loss: 0.311004; batch adversarial loss: 0.562087\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385014; batch adversarial loss: 0.577273\n",
      "epoch 45; iter: 200; batch classifier loss: 0.444054; batch adversarial loss: 0.641353\n",
      "epoch 46; iter: 0; batch classifier loss: 0.305090; batch adversarial loss: 0.661728\n",
      "epoch 46; iter: 200; batch classifier loss: 0.309453; batch adversarial loss: 0.678408\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386671; batch adversarial loss: 0.614361\n",
      "epoch 47; iter: 200; batch classifier loss: 0.331434; batch adversarial loss: 0.608414\n",
      "epoch 48; iter: 0; batch classifier loss: 0.258234; batch adversarial loss: 0.670845\n",
      "epoch 48; iter: 200; batch classifier loss: 0.421658; batch adversarial loss: 0.604638\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433103; batch adversarial loss: 0.600814\n",
      "epoch 49; iter: 200; batch classifier loss: 0.348424; batch adversarial loss: 0.620809\n",
      "epoch 0; iter: 0; batch classifier loss: 23.226107; batch adversarial loss: 0.692931\n",
      "epoch 0; iter: 200; batch classifier loss: 18.246889; batch adversarial loss: 0.641542\n",
      "epoch 1; iter: 0; batch classifier loss: 11.956262; batch adversarial loss: 0.628019\n",
      "epoch 1; iter: 200; batch classifier loss: 9.009877; batch adversarial loss: 0.597423\n",
      "epoch 2; iter: 0; batch classifier loss: 1.662817; batch adversarial loss: 0.622691\n",
      "epoch 2; iter: 200; batch classifier loss: 1.363865; batch adversarial loss: 0.650052\n",
      "epoch 3; iter: 0; batch classifier loss: 1.298658; batch adversarial loss: 0.641503\n",
      "epoch 3; iter: 200; batch classifier loss: 2.625163; batch adversarial loss: 0.666487\n",
      "epoch 4; iter: 0; batch classifier loss: 2.741417; batch adversarial loss: 0.630871\n",
      "epoch 4; iter: 200; batch classifier loss: 1.743494; batch adversarial loss: 0.654163\n",
      "epoch 5; iter: 0; batch classifier loss: 0.461108; batch adversarial loss: 0.632144\n",
      "epoch 5; iter: 200; batch classifier loss: 0.990931; batch adversarial loss: 0.547560\n",
      "epoch 6; iter: 0; batch classifier loss: 1.046480; batch adversarial loss: 0.624925\n",
      "epoch 6; iter: 200; batch classifier loss: 1.241318; batch adversarial loss: 0.596542\n",
      "epoch 7; iter: 0; batch classifier loss: 1.198625; batch adversarial loss: 0.669684\n",
      "epoch 7; iter: 200; batch classifier loss: 0.393388; batch adversarial loss: 0.655541\n",
      "epoch 8; iter: 0; batch classifier loss: 0.609977; batch adversarial loss: 0.637506\n",
      "epoch 8; iter: 200; batch classifier loss: 0.579945; batch adversarial loss: 0.632416\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371586; batch adversarial loss: 0.608323\n",
      "epoch 9; iter: 200; batch classifier loss: 0.761510; batch adversarial loss: 0.605658\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445005; batch adversarial loss: 0.627432\n",
      "epoch 10; iter: 200; batch classifier loss: 1.739907; batch adversarial loss: 0.671042\n",
      "epoch 11; iter: 0; batch classifier loss: 0.733131; batch adversarial loss: 0.646702\n",
      "epoch 11; iter: 200; batch classifier loss: 0.376509; batch adversarial loss: 0.633415\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455181; batch adversarial loss: 0.567282\n",
      "epoch 12; iter: 200; batch classifier loss: 0.431622; batch adversarial loss: 0.561839\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382244; batch adversarial loss: 0.630403\n",
      "epoch 13; iter: 200; batch classifier loss: 0.342062; batch adversarial loss: 0.608769\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349375; batch adversarial loss: 0.625147\n",
      "epoch 14; iter: 200; batch classifier loss: 0.428190; batch adversarial loss: 0.544244\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349718; batch adversarial loss: 0.642995\n",
      "epoch 15; iter: 200; batch classifier loss: 0.304945; batch adversarial loss: 0.639767\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430177; batch adversarial loss: 0.601824\n",
      "epoch 16; iter: 200; batch classifier loss: 0.301010; batch adversarial loss: 0.680491\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392430; batch adversarial loss: 0.613829\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346270; batch adversarial loss: 0.657966\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310043; batch adversarial loss: 0.662671\n",
      "epoch 18; iter: 200; batch classifier loss: 0.407535; batch adversarial loss: 0.644587\n",
      "epoch 19; iter: 0; batch classifier loss: 0.312699; batch adversarial loss: 0.661008\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429425; batch adversarial loss: 0.676163\n",
      "epoch 20; iter: 0; batch classifier loss: 0.344751; batch adversarial loss: 0.590437\n",
      "epoch 20; iter: 200; batch classifier loss: 0.375060; batch adversarial loss: 0.601000\n",
      "epoch 21; iter: 0; batch classifier loss: 0.271202; batch adversarial loss: 0.642018\n",
      "epoch 21; iter: 200; batch classifier loss: 0.406254; batch adversarial loss: 0.600722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.460109; batch adversarial loss: 0.609367\n",
      "epoch 22; iter: 200; batch classifier loss: 0.371454; batch adversarial loss: 0.609283\n",
      "epoch 23; iter: 0; batch classifier loss: 0.373771; batch adversarial loss: 0.676625\n",
      "epoch 23; iter: 200; batch classifier loss: 0.257834; batch adversarial loss: 0.670263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387771; batch adversarial loss: 0.688419\n",
      "epoch 24; iter: 200; batch classifier loss: 0.394613; batch adversarial loss: 0.625274\n",
      "epoch 25; iter: 0; batch classifier loss: 0.300742; batch adversarial loss: 0.632758\n",
      "epoch 25; iter: 200; batch classifier loss: 0.358688; batch adversarial loss: 0.601340\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445102; batch adversarial loss: 0.579782\n",
      "epoch 26; iter: 200; batch classifier loss: 0.333862; batch adversarial loss: 0.583062\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390956; batch adversarial loss: 0.606319\n",
      "epoch 27; iter: 200; batch classifier loss: 0.367738; batch adversarial loss: 0.605140\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345794; batch adversarial loss: 0.631698\n",
      "epoch 28; iter: 200; batch classifier loss: 0.311774; batch adversarial loss: 0.594013\n",
      "epoch 29; iter: 0; batch classifier loss: 0.343322; batch adversarial loss: 0.662590\n",
      "epoch 29; iter: 200; batch classifier loss: 0.427633; batch adversarial loss: 0.643931\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378210; batch adversarial loss: 0.617772\n",
      "epoch 30; iter: 200; batch classifier loss: 0.380951; batch adversarial loss: 0.645554\n",
      "epoch 31; iter: 0; batch classifier loss: 0.345485; batch adversarial loss: 0.570867\n",
      "epoch 31; iter: 200; batch classifier loss: 0.383540; batch adversarial loss: 0.646694\n",
      "epoch 32; iter: 0; batch classifier loss: 0.382627; batch adversarial loss: 0.659203\n",
      "epoch 32; iter: 200; batch classifier loss: 0.432900; batch adversarial loss: 0.619071\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440683; batch adversarial loss: 0.607629\n",
      "epoch 33; iter: 200; batch classifier loss: 0.448349; batch adversarial loss: 0.593199\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331425; batch adversarial loss: 0.610122\n",
      "epoch 34; iter: 200; batch classifier loss: 0.371321; batch adversarial loss: 0.600129\n",
      "epoch 35; iter: 0; batch classifier loss: 0.365974; batch adversarial loss: 0.656772\n",
      "epoch 35; iter: 200; batch classifier loss: 0.201585; batch adversarial loss: 0.675430\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414865; batch adversarial loss: 0.642099\n",
      "epoch 36; iter: 200; batch classifier loss: 0.432856; batch adversarial loss: 0.576999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.298075; batch adversarial loss: 0.551502\n",
      "epoch 37; iter: 200; batch classifier loss: 0.405341; batch adversarial loss: 0.563064\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399822; batch adversarial loss: 0.640792\n",
      "epoch 38; iter: 200; batch classifier loss: 0.353816; batch adversarial loss: 0.617894\n",
      "epoch 39; iter: 0; batch classifier loss: 0.328241; batch adversarial loss: 0.659209\n",
      "epoch 39; iter: 200; batch classifier loss: 0.292284; batch adversarial loss: 0.581974\n",
      "epoch 40; iter: 0; batch classifier loss: 0.292815; batch adversarial loss: 0.622799\n",
      "epoch 40; iter: 200; batch classifier loss: 0.342973; batch adversarial loss: 0.567233\n",
      "epoch 41; iter: 0; batch classifier loss: 0.345018; batch adversarial loss: 0.603142\n",
      "epoch 41; iter: 200; batch classifier loss: 0.401782; batch adversarial loss: 0.656276\n",
      "epoch 42; iter: 0; batch classifier loss: 0.396170; batch adversarial loss: 0.655032\n",
      "epoch 42; iter: 200; batch classifier loss: 0.418768; batch adversarial loss: 0.582638\n",
      "epoch 43; iter: 0; batch classifier loss: 0.300745; batch adversarial loss: 0.608241\n",
      "epoch 43; iter: 200; batch classifier loss: 0.237592; batch adversarial loss: 0.642425\n",
      "epoch 44; iter: 0; batch classifier loss: 0.363226; batch adversarial loss: 0.605953\n",
      "epoch 44; iter: 200; batch classifier loss: 0.300685; batch adversarial loss: 0.638592\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414298; batch adversarial loss: 0.620306\n",
      "epoch 45; iter: 200; batch classifier loss: 0.266503; batch adversarial loss: 0.613903\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397909; batch adversarial loss: 0.594552\n",
      "epoch 46; iter: 200; batch classifier loss: 0.409213; batch adversarial loss: 0.630077\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441486; batch adversarial loss: 0.585581\n",
      "epoch 47; iter: 200; batch classifier loss: 0.405239; batch adversarial loss: 0.614057\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411529; batch adversarial loss: 0.597893\n",
      "epoch 48; iter: 200; batch classifier loss: 0.275496; batch adversarial loss: 0.580319\n",
      "epoch 49; iter: 0; batch classifier loss: 0.353567; batch adversarial loss: 0.638011\n",
      "epoch 49; iter: 200; batch classifier loss: 0.313503; batch adversarial loss: 0.626998\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.833424  0.572433 -0.004098  0.982503  0.125673  0.073716\n",
      "std   0.016395  0.074911  0.023715  0.160839  0.069346  0.041487\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'sex'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','sex')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    "    scope_name='adv',           \n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.1)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate\n",
    "adult_sex_metrics = pd.DataFrame(results)\n",
    "adult_sex_metrics_agg = adult_sex_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae1c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', 'Default Adversial Debiasing Adult: Baseline - Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a28cb",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6be3258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 92.339256; batch adversarial loss: 0.735219\n",
      "epoch 0; iter: 200; batch classifier loss: 14.735712; batch adversarial loss: 0.894313\n",
      "epoch 0; iter: 400; batch classifier loss: 6.197246; batch adversarial loss: 0.660421\n",
      "epoch 0; iter: 600; batch classifier loss: 13.188496; batch adversarial loss: 0.630917\n",
      "epoch 1; iter: 0; batch classifier loss: 5.373996; batch adversarial loss: 0.632252\n",
      "epoch 1; iter: 200; batch classifier loss: 5.085405; batch adversarial loss: 0.466742\n",
      "epoch 1; iter: 400; batch classifier loss: 1.341484; batch adversarial loss: 0.488913\n",
      "epoch 1; iter: 600; batch classifier loss: 1.261639; batch adversarial loss: 0.438722\n",
      "epoch 2; iter: 0; batch classifier loss: 1.537276; batch adversarial loss: 0.463051\n",
      "epoch 2; iter: 200; batch classifier loss: 0.649286; batch adversarial loss: 0.500669\n",
      "epoch 2; iter: 400; batch classifier loss: 1.263907; batch adversarial loss: 0.444304\n",
      "epoch 2; iter: 600; batch classifier loss: 1.434459; batch adversarial loss: 0.431647\n",
      "epoch 3; iter: 0; batch classifier loss: 0.469871; batch adversarial loss: 0.466903\n",
      "epoch 3; iter: 200; batch classifier loss: 1.029219; batch adversarial loss: 0.363829\n",
      "epoch 3; iter: 400; batch classifier loss: 0.775784; batch adversarial loss: 0.441266\n",
      "epoch 3; iter: 600; batch classifier loss: 0.622979; batch adversarial loss: 0.318579\n",
      "epoch 4; iter: 0; batch classifier loss: 0.294614; batch adversarial loss: 0.435049\n",
      "epoch 4; iter: 200; batch classifier loss: 0.854261; batch adversarial loss: 0.361760\n",
      "epoch 4; iter: 400; batch classifier loss: 1.045867; batch adversarial loss: 0.430636\n",
      "epoch 4; iter: 600; batch classifier loss: 0.318365; batch adversarial loss: 0.397040\n",
      "epoch 5; iter: 0; batch classifier loss: 0.664425; batch adversarial loss: 0.259727\n",
      "epoch 5; iter: 200; batch classifier loss: 0.346525; batch adversarial loss: 0.413269\n",
      "epoch 5; iter: 400; batch classifier loss: 0.901309; batch adversarial loss: 0.400122\n",
      "epoch 5; iter: 600; batch classifier loss: 0.402273; batch adversarial loss: 0.386839\n",
      "epoch 6; iter: 0; batch classifier loss: 0.390379; batch adversarial loss: 0.341222\n",
      "epoch 6; iter: 200; batch classifier loss: 0.432936; batch adversarial loss: 0.398698\n",
      "epoch 6; iter: 400; batch classifier loss: 0.269183; batch adversarial loss: 0.443458\n",
      "epoch 6; iter: 600; batch classifier loss: 0.340837; batch adversarial loss: 0.403498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.473663; batch adversarial loss: 0.347883\n",
      "epoch 7; iter: 200; batch classifier loss: 0.772889; batch adversarial loss: 0.381542\n",
      "epoch 7; iter: 400; batch classifier loss: 0.205311; batch adversarial loss: 0.444635\n",
      "epoch 7; iter: 600; batch classifier loss: 0.335324; batch adversarial loss: 0.335503\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483689; batch adversarial loss: 0.430676\n",
      "epoch 8; iter: 200; batch classifier loss: 0.372961; batch adversarial loss: 0.512288\n",
      "epoch 8; iter: 400; batch classifier loss: 0.391523; batch adversarial loss: 0.369988\n",
      "epoch 8; iter: 600; batch classifier loss: 0.243443; batch adversarial loss: 0.568901\n",
      "epoch 9; iter: 0; batch classifier loss: 0.300340; batch adversarial loss: 0.614329\n",
      "epoch 9; iter: 200; batch classifier loss: 0.986652; batch adversarial loss: 0.493284\n",
      "epoch 9; iter: 400; batch classifier loss: 0.381976; batch adversarial loss: 0.564861\n",
      "epoch 9; iter: 600; batch classifier loss: 0.316031; batch adversarial loss: 0.406675\n",
      "epoch 0; iter: 0; batch classifier loss: 17.948479; batch adversarial loss: 0.707448\n",
      "epoch 0; iter: 200; batch classifier loss: 12.600789; batch adversarial loss: 0.675745\n",
      "epoch 0; iter: 400; batch classifier loss: 6.535391; batch adversarial loss: 0.575876\n",
      "epoch 0; iter: 600; batch classifier loss: 30.067152; batch adversarial loss: 0.523290\n",
      "epoch 1; iter: 0; batch classifier loss: 2.498865; batch adversarial loss: 0.527709\n",
      "epoch 1; iter: 200; batch classifier loss: 21.280066; batch adversarial loss: 0.478077\n",
      "epoch 1; iter: 400; batch classifier loss: 1.057730; batch adversarial loss: 0.517310\n",
      "epoch 1; iter: 600; batch classifier loss: 3.399520; batch adversarial loss: 0.468050\n",
      "epoch 2; iter: 0; batch classifier loss: 1.266680; batch adversarial loss: 0.457597\n",
      "epoch 2; iter: 200; batch classifier loss: 1.448057; batch adversarial loss: 0.400889\n",
      "epoch 2; iter: 400; batch classifier loss: 1.193941; batch adversarial loss: 0.435224\n",
      "epoch 2; iter: 600; batch classifier loss: 0.704676; batch adversarial loss: 0.563554\n",
      "epoch 3; iter: 0; batch classifier loss: 0.771151; batch adversarial loss: 0.360031\n",
      "epoch 3; iter: 200; batch classifier loss: 0.695287; batch adversarial loss: 0.401541\n",
      "epoch 3; iter: 400; batch classifier loss: 2.014579; batch adversarial loss: 0.507202\n",
      "epoch 3; iter: 600; batch classifier loss: 1.145529; batch adversarial loss: 0.458498\n",
      "epoch 4; iter: 0; batch classifier loss: 1.062243; batch adversarial loss: 0.343192\n",
      "epoch 4; iter: 200; batch classifier loss: 0.756660; batch adversarial loss: 0.479305\n",
      "epoch 4; iter: 400; batch classifier loss: 0.400803; batch adversarial loss: 0.500623\n",
      "epoch 4; iter: 600; batch classifier loss: 1.020695; batch adversarial loss: 0.507637\n",
      "epoch 5; iter: 0; batch classifier loss: 0.467446; batch adversarial loss: 0.270642\n",
      "epoch 5; iter: 200; batch classifier loss: 0.290657; batch adversarial loss: 0.302836\n",
      "epoch 5; iter: 400; batch classifier loss: 0.428969; batch adversarial loss: 0.404440\n",
      "epoch 5; iter: 600; batch classifier loss: 0.283144; batch adversarial loss: 0.481803\n",
      "epoch 6; iter: 0; batch classifier loss: 0.396062; batch adversarial loss: 0.373632\n",
      "epoch 6; iter: 200; batch classifier loss: 0.300046; batch adversarial loss: 0.451310\n",
      "epoch 6; iter: 400; batch classifier loss: 0.258143; batch adversarial loss: 0.297795\n",
      "epoch 6; iter: 600; batch classifier loss: 0.402109; batch adversarial loss: 0.367099\n",
      "epoch 7; iter: 0; batch classifier loss: 0.391504; batch adversarial loss: 0.328985\n",
      "epoch 7; iter: 200; batch classifier loss: 0.389261; batch adversarial loss: 0.477185\n",
      "epoch 7; iter: 400; batch classifier loss: 0.440224; batch adversarial loss: 0.352854\n",
      "epoch 7; iter: 600; batch classifier loss: 0.602758; batch adversarial loss: 0.452692\n",
      "epoch 8; iter: 0; batch classifier loss: 0.332039; batch adversarial loss: 0.481445\n",
      "epoch 8; iter: 200; batch classifier loss: 0.358509; batch adversarial loss: 0.353032\n",
      "epoch 8; iter: 400; batch classifier loss: 0.353830; batch adversarial loss: 0.381098\n",
      "epoch 8; iter: 600; batch classifier loss: 0.474924; batch adversarial loss: 0.271407\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440272; batch adversarial loss: 0.402369\n",
      "epoch 9; iter: 200; batch classifier loss: 0.324955; batch adversarial loss: 0.481919\n",
      "epoch 9; iter: 400; batch classifier loss: 0.372338; batch adversarial loss: 0.444837\n",
      "epoch 9; iter: 600; batch classifier loss: 0.382463; batch adversarial loss: 0.396194\n",
      "epoch 0; iter: 0; batch classifier loss: 28.473568; batch adversarial loss: 0.657719\n",
      "epoch 0; iter: 200; batch classifier loss: 4.030164; batch adversarial loss: 0.575620\n",
      "epoch 0; iter: 400; batch classifier loss: 4.418633; batch adversarial loss: 0.638138\n",
      "epoch 0; iter: 600; batch classifier loss: 0.493169; batch adversarial loss: 0.501579\n",
      "epoch 1; iter: 0; batch classifier loss: 1.106848; batch adversarial loss: 0.491313\n",
      "epoch 1; iter: 200; batch classifier loss: 1.548266; batch adversarial loss: 0.486983\n",
      "epoch 1; iter: 400; batch classifier loss: 4.117544; batch adversarial loss: 0.476896\n",
      "epoch 1; iter: 600; batch classifier loss: 2.839305; batch adversarial loss: 0.489484\n",
      "epoch 2; iter: 0; batch classifier loss: 0.814691; batch adversarial loss: 0.494218\n",
      "epoch 2; iter: 200; batch classifier loss: 0.453578; batch adversarial loss: 0.391056\n",
      "epoch 2; iter: 400; batch classifier loss: 1.154553; batch adversarial loss: 0.464795\n",
      "epoch 2; iter: 600; batch classifier loss: 0.695570; batch adversarial loss: 0.402730\n",
      "epoch 3; iter: 0; batch classifier loss: 1.272038; batch adversarial loss: 0.571039\n",
      "epoch 3; iter: 200; batch classifier loss: 0.503779; batch adversarial loss: 0.459326\n",
      "epoch 3; iter: 400; batch classifier loss: 0.459223; batch adversarial loss: 0.452734\n",
      "epoch 3; iter: 600; batch classifier loss: 0.855843; batch adversarial loss: 0.457728\n",
      "epoch 4; iter: 0; batch classifier loss: 0.343330; batch adversarial loss: 0.552366\n",
      "epoch 4; iter: 200; batch classifier loss: 0.319609; batch adversarial loss: 0.419821\n",
      "epoch 4; iter: 400; batch classifier loss: 0.275729; batch adversarial loss: 0.318798\n",
      "epoch 4; iter: 600; batch classifier loss: 0.424155; batch adversarial loss: 0.497665\n",
      "epoch 5; iter: 0; batch classifier loss: 0.436694; batch adversarial loss: 0.412349\n",
      "epoch 5; iter: 200; batch classifier loss: 0.332918; batch adversarial loss: 0.252933\n",
      "epoch 5; iter: 400; batch classifier loss: 0.574703; batch adversarial loss: 0.303246\n",
      "epoch 5; iter: 600; batch classifier loss: 0.417364; batch adversarial loss: 0.426527\n",
      "epoch 6; iter: 0; batch classifier loss: 1.082034; batch adversarial loss: 0.407890\n",
      "epoch 6; iter: 200; batch classifier loss: 0.468354; batch adversarial loss: 0.365059\n",
      "epoch 6; iter: 400; batch classifier loss: 0.309454; batch adversarial loss: 0.398385\n",
      "epoch 6; iter: 600; batch classifier loss: 0.447874; batch adversarial loss: 0.287455\n",
      "epoch 7; iter: 0; batch classifier loss: 0.280634; batch adversarial loss: 0.479064\n",
      "epoch 7; iter: 200; batch classifier loss: 0.391222; batch adversarial loss: 0.401542\n",
      "epoch 7; iter: 400; batch classifier loss: 0.365253; batch adversarial loss: 0.514278\n",
      "epoch 7; iter: 600; batch classifier loss: 0.334147; batch adversarial loss: 0.378450\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417952; batch adversarial loss: 0.377475\n",
      "epoch 8; iter: 200; batch classifier loss: 0.421874; batch adversarial loss: 0.327427\n",
      "epoch 8; iter: 400; batch classifier loss: 0.365379; batch adversarial loss: 0.344068\n",
      "epoch 8; iter: 600; batch classifier loss: 0.400298; batch adversarial loss: 0.444098\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299628; batch adversarial loss: 0.357215\n",
      "epoch 9; iter: 200; batch classifier loss: 0.369589; batch adversarial loss: 0.317144\n",
      "epoch 9; iter: 400; batch classifier loss: 0.444234; batch adversarial loss: 0.342807\n",
      "epoch 9; iter: 600; batch classifier loss: 0.435705; batch adversarial loss: 0.490946\n",
      "epoch 0; iter: 0; batch classifier loss: 11.230033; batch adversarial loss: 0.719924\n",
      "epoch 0; iter: 200; batch classifier loss: 9.240929; batch adversarial loss: 0.624972\n",
      "epoch 0; iter: 400; batch classifier loss: 6.070868; batch adversarial loss: 0.574773\n",
      "epoch 0; iter: 600; batch classifier loss: 1.530769; batch adversarial loss: 0.510702\n",
      "epoch 1; iter: 0; batch classifier loss: 14.186654; batch adversarial loss: 0.527737\n",
      "epoch 1; iter: 200; batch classifier loss: 1.776651; batch adversarial loss: 0.437100\n",
      "epoch 1; iter: 400; batch classifier loss: 0.786816; batch adversarial loss: 0.509367\n",
      "epoch 1; iter: 600; batch classifier loss: 1.795190; batch adversarial loss: 0.466870\n",
      "epoch 2; iter: 0; batch classifier loss: 0.661403; batch adversarial loss: 0.436749\n",
      "epoch 2; iter: 200; batch classifier loss: 0.998603; batch adversarial loss: 0.485457\n",
      "epoch 2; iter: 400; batch classifier loss: 2.751581; batch adversarial loss: 0.371397\n",
      "epoch 2; iter: 600; batch classifier loss: 0.407348; batch adversarial loss: 0.547723\n",
      "epoch 3; iter: 0; batch classifier loss: 1.645278; batch adversarial loss: 0.279794\n",
      "epoch 3; iter: 200; batch classifier loss: 1.441863; batch adversarial loss: 0.387303\n",
      "epoch 3; iter: 400; batch classifier loss: 0.560226; batch adversarial loss: 0.396998\n",
      "epoch 3; iter: 600; batch classifier loss: 0.283491; batch adversarial loss: 0.431381\n",
      "epoch 4; iter: 0; batch classifier loss: 0.292968; batch adversarial loss: 0.268509\n",
      "epoch 4; iter: 200; batch classifier loss: 1.247224; batch adversarial loss: 0.417681\n",
      "epoch 4; iter: 400; batch classifier loss: 0.842506; batch adversarial loss: 0.440416\n",
      "epoch 4; iter: 600; batch classifier loss: 1.458425; batch adversarial loss: 0.470210\n",
      "epoch 5; iter: 0; batch classifier loss: 0.331741; batch adversarial loss: 0.417016\n",
      "epoch 5; iter: 200; batch classifier loss: 3.398002; batch adversarial loss: 0.564636\n",
      "epoch 5; iter: 400; batch classifier loss: 0.336299; batch adversarial loss: 0.328658\n",
      "epoch 5; iter: 600; batch classifier loss: 0.354767; batch adversarial loss: 0.502493\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376913; batch adversarial loss: 0.349572\n",
      "epoch 6; iter: 200; batch classifier loss: 0.222787; batch adversarial loss: 0.405285\n",
      "epoch 6; iter: 400; batch classifier loss: 0.284993; batch adversarial loss: 0.666821\n",
      "epoch 6; iter: 600; batch classifier loss: 0.464999; batch adversarial loss: 0.457234\n",
      "epoch 7; iter: 0; batch classifier loss: 0.312823; batch adversarial loss: 0.342748\n",
      "epoch 7; iter: 200; batch classifier loss: 0.320251; batch adversarial loss: 0.416992\n",
      "epoch 7; iter: 400; batch classifier loss: 0.606347; batch adversarial loss: 0.295314\n",
      "epoch 7; iter: 600; batch classifier loss: 0.353405; batch adversarial loss: 0.325306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368627; batch adversarial loss: 0.384350\n",
      "epoch 8; iter: 200; batch classifier loss: 0.391267; batch adversarial loss: 0.336933\n",
      "epoch 8; iter: 400; batch classifier loss: 0.414110; batch adversarial loss: 0.385824\n",
      "epoch 8; iter: 600; batch classifier loss: 0.364586; batch adversarial loss: 0.479415\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401380; batch adversarial loss: 0.423510\n",
      "epoch 9; iter: 200; batch classifier loss: 0.316380; batch adversarial loss: 0.487490\n",
      "epoch 9; iter: 400; batch classifier loss: 0.368296; batch adversarial loss: 0.326323\n",
      "epoch 9; iter: 600; batch classifier loss: 0.518303; batch adversarial loss: 0.316336\n",
      "epoch 0; iter: 0; batch classifier loss: 66.436493; batch adversarial loss: 0.646700\n",
      "epoch 0; iter: 200; batch classifier loss: 2.833020; batch adversarial loss: 0.585191\n",
      "epoch 0; iter: 400; batch classifier loss: 16.071445; batch adversarial loss: 0.568835\n",
      "epoch 0; iter: 600; batch classifier loss: 11.636360; batch adversarial loss: 0.520503\n",
      "epoch 1; iter: 0; batch classifier loss: 2.487020; batch adversarial loss: 0.493163\n",
      "epoch 1; iter: 200; batch classifier loss: 2.672794; batch adversarial loss: 0.585849\n",
      "epoch 1; iter: 400; batch classifier loss: 3.256470; batch adversarial loss: 0.415941\n",
      "epoch 1; iter: 600; batch classifier loss: 0.403428; batch adversarial loss: 0.433885\n",
      "epoch 2; iter: 0; batch classifier loss: 2.232022; batch adversarial loss: 0.497418\n",
      "epoch 2; iter: 200; batch classifier loss: 0.839769; batch adversarial loss: 0.457033\n",
      "epoch 2; iter: 400; batch classifier loss: 0.644882; batch adversarial loss: 0.477496\n",
      "epoch 2; iter: 600; batch classifier loss: 2.543816; batch adversarial loss: 0.405361\n",
      "epoch 3; iter: 0; batch classifier loss: 2.124920; batch adversarial loss: 0.509701\n",
      "epoch 3; iter: 200; batch classifier loss: 0.438059; batch adversarial loss: 0.364385\n",
      "epoch 3; iter: 400; batch classifier loss: 0.804900; batch adversarial loss: 0.424821\n",
      "epoch 3; iter: 600; batch classifier loss: 0.302845; batch adversarial loss: 0.530447\n",
      "epoch 4; iter: 0; batch classifier loss: 0.839172; batch adversarial loss: 0.266477\n",
      "epoch 4; iter: 200; batch classifier loss: 0.926700; batch adversarial loss: 0.400914\n",
      "epoch 4; iter: 400; batch classifier loss: 0.675960; batch adversarial loss: 0.354936\n",
      "epoch 4; iter: 600; batch classifier loss: 0.590822; batch adversarial loss: 0.462582\n",
      "epoch 5; iter: 0; batch classifier loss: 0.430507; batch adversarial loss: 0.490971\n",
      "epoch 5; iter: 200; batch classifier loss: 0.539452; batch adversarial loss: 0.326670\n",
      "epoch 5; iter: 400; batch classifier loss: 0.495645; batch adversarial loss: 0.474248\n",
      "epoch 5; iter: 600; batch classifier loss: 0.336627; batch adversarial loss: 0.436256\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348098; batch adversarial loss: 0.379717\n",
      "epoch 6; iter: 200; batch classifier loss: 0.293011; batch adversarial loss: 0.512365\n",
      "epoch 6; iter: 400; batch classifier loss: 0.529854; batch adversarial loss: 0.347954\n",
      "epoch 6; iter: 600; batch classifier loss: 0.449225; batch adversarial loss: 0.356926\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337578; batch adversarial loss: 0.347755\n",
      "epoch 7; iter: 200; batch classifier loss: 0.310205; batch adversarial loss: 0.449310\n",
      "epoch 7; iter: 400; batch classifier loss: 0.314958; batch adversarial loss: 0.356776\n",
      "epoch 7; iter: 600; batch classifier loss: 0.409187; batch adversarial loss: 0.540948\n",
      "epoch 8; iter: 0; batch classifier loss: 0.262117; batch adversarial loss: 0.458329\n",
      "epoch 8; iter: 200; batch classifier loss: 0.500523; batch adversarial loss: 0.324640\n",
      "epoch 8; iter: 400; batch classifier loss: 0.375515; batch adversarial loss: 0.463432\n",
      "epoch 8; iter: 600; batch classifier loss: 0.360350; batch adversarial loss: 0.410629\n",
      "epoch 9; iter: 0; batch classifier loss: 0.174288; batch adversarial loss: 0.593776\n",
      "epoch 9; iter: 200; batch classifier loss: 0.522505; batch adversarial loss: 0.444536\n",
      "epoch 9; iter: 400; batch classifier loss: 0.401273; batch adversarial loss: 0.491381\n",
      "epoch 9; iter: 600; batch classifier loss: 0.919068; batch adversarial loss: 0.373461\n",
      "epoch 0; iter: 0; batch classifier loss: 106.785980; batch adversarial loss: 0.693097\n",
      "epoch 0; iter: 200; batch classifier loss: 13.702869; batch adversarial loss: 0.654759\n",
      "epoch 0; iter: 400; batch classifier loss: 8.842070; batch adversarial loss: 0.594111\n",
      "epoch 0; iter: 600; batch classifier loss: 9.106302; batch adversarial loss: 0.510875\n",
      "epoch 1; iter: 0; batch classifier loss: 11.162437; batch adversarial loss: 0.532033\n",
      "epoch 1; iter: 200; batch classifier loss: 15.517706; batch adversarial loss: 0.464185\n",
      "epoch 1; iter: 400; batch classifier loss: 0.483758; batch adversarial loss: 0.494904\n",
      "epoch 1; iter: 600; batch classifier loss: 4.563818; batch adversarial loss: 0.429655\n",
      "epoch 2; iter: 0; batch classifier loss: 0.671693; batch adversarial loss: 0.549688\n",
      "epoch 2; iter: 200; batch classifier loss: 0.612476; batch adversarial loss: 0.432006\n",
      "epoch 2; iter: 400; batch classifier loss: 0.427931; batch adversarial loss: 0.360447\n",
      "epoch 2; iter: 600; batch classifier loss: 0.294397; batch adversarial loss: 0.467433\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632145; batch adversarial loss: 0.479186\n",
      "epoch 3; iter: 200; batch classifier loss: 20.615557; batch adversarial loss: 0.379167\n",
      "epoch 3; iter: 400; batch classifier loss: 1.223773; batch adversarial loss: 0.312192\n",
      "epoch 3; iter: 600; batch classifier loss: 1.471999; batch adversarial loss: 0.287861\n",
      "epoch 4; iter: 0; batch classifier loss: 1.298876; batch adversarial loss: 0.460092\n",
      "epoch 4; iter: 200; batch classifier loss: 0.523129; batch adversarial loss: 0.506124\n",
      "epoch 4; iter: 400; batch classifier loss: 0.496982; batch adversarial loss: 0.430232\n",
      "epoch 4; iter: 600; batch classifier loss: 0.541724; batch adversarial loss: 0.477591\n",
      "epoch 5; iter: 0; batch classifier loss: 0.388046; batch adversarial loss: 0.393283\n",
      "epoch 5; iter: 200; batch classifier loss: 1.033470; batch adversarial loss: 0.498395\n",
      "epoch 5; iter: 400; batch classifier loss: 0.376221; batch adversarial loss: 0.403653\n",
      "epoch 5; iter: 600; batch classifier loss: 0.517378; batch adversarial loss: 0.292896\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319987; batch adversarial loss: 0.513570\n",
      "epoch 6; iter: 200; batch classifier loss: 0.840079; batch adversarial loss: 0.560435\n",
      "epoch 6; iter: 400; batch classifier loss: 0.335686; batch adversarial loss: 0.397727\n",
      "epoch 6; iter: 600; batch classifier loss: 0.383133; batch adversarial loss: 0.564639\n",
      "epoch 7; iter: 0; batch classifier loss: 1.378581; batch adversarial loss: 0.354672\n",
      "epoch 7; iter: 200; batch classifier loss: 0.560004; batch adversarial loss: 0.476466\n",
      "epoch 7; iter: 400; batch classifier loss: 0.386554; batch adversarial loss: 0.480801\n",
      "epoch 7; iter: 600; batch classifier loss: 0.367195; batch adversarial loss: 0.517198\n",
      "epoch 8; iter: 0; batch classifier loss: 0.303954; batch adversarial loss: 0.411528\n",
      "epoch 8; iter: 200; batch classifier loss: 0.424747; batch adversarial loss: 0.371606\n",
      "epoch 8; iter: 400; batch classifier loss: 0.504796; batch adversarial loss: 0.271411\n",
      "epoch 8; iter: 600; batch classifier loss: 0.154672; batch adversarial loss: 0.430212\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347591; batch adversarial loss: 0.429342\n",
      "epoch 9; iter: 200; batch classifier loss: 0.618187; batch adversarial loss: 0.506837\n",
      "epoch 9; iter: 400; batch classifier loss: 0.244528; batch adversarial loss: 0.392178\n",
      "epoch 9; iter: 600; batch classifier loss: 0.473062; batch adversarial loss: 0.260128\n",
      "epoch 0; iter: 0; batch classifier loss: 28.764538; batch adversarial loss: 1.087798\n",
      "epoch 0; iter: 200; batch classifier loss: 10.142818; batch adversarial loss: 1.132488\n",
      "epoch 0; iter: 400; batch classifier loss: 21.737961; batch adversarial loss: 0.838431\n",
      "epoch 0; iter: 600; batch classifier loss: 7.225829; batch adversarial loss: 0.700619\n",
      "epoch 1; iter: 0; batch classifier loss: 7.581656; batch adversarial loss: 0.678603\n",
      "epoch 1; iter: 200; batch classifier loss: 5.077226; batch adversarial loss: 0.496904\n",
      "epoch 1; iter: 400; batch classifier loss: 0.774828; batch adversarial loss: 0.522348\n",
      "epoch 1; iter: 600; batch classifier loss: 1.227136; batch adversarial loss: 0.522206\n",
      "epoch 2; iter: 0; batch classifier loss: 1.989012; batch adversarial loss: 0.538575\n",
      "epoch 2; iter: 200; batch classifier loss: 2.270001; batch adversarial loss: 0.465249\n",
      "epoch 2; iter: 400; batch classifier loss: 3.259533; batch adversarial loss: 0.374145\n",
      "epoch 2; iter: 600; batch classifier loss: 0.380928; batch adversarial loss: 0.503699\n",
      "epoch 3; iter: 0; batch classifier loss: 2.708985; batch adversarial loss: 0.471524\n",
      "epoch 3; iter: 200; batch classifier loss: 2.495302; batch adversarial loss: 0.424920\n",
      "epoch 3; iter: 400; batch classifier loss: 3.362376; batch adversarial loss: 0.567568\n",
      "epoch 3; iter: 600; batch classifier loss: 0.449827; batch adversarial loss: 0.417577\n",
      "epoch 4; iter: 0; batch classifier loss: 0.415215; batch adversarial loss: 0.312059\n",
      "epoch 4; iter: 200; batch classifier loss: 0.512807; batch adversarial loss: 0.324013\n",
      "epoch 4; iter: 400; batch classifier loss: 0.441421; batch adversarial loss: 0.334317\n",
      "epoch 4; iter: 600; batch classifier loss: 0.732695; batch adversarial loss: 0.386405\n",
      "epoch 5; iter: 0; batch classifier loss: 0.441597; batch adversarial loss: 0.394598\n",
      "epoch 5; iter: 200; batch classifier loss: 0.493290; batch adversarial loss: 0.403586\n",
      "epoch 5; iter: 400; batch classifier loss: 0.595885; batch adversarial loss: 0.348103\n",
      "epoch 5; iter: 600; batch classifier loss: 0.548496; batch adversarial loss: 0.478350\n",
      "epoch 6; iter: 0; batch classifier loss: 0.421207; batch adversarial loss: 0.482418\n",
      "epoch 6; iter: 200; batch classifier loss: 0.747575; batch adversarial loss: 0.365154\n",
      "epoch 6; iter: 400; batch classifier loss: 0.374065; batch adversarial loss: 0.381130\n",
      "epoch 6; iter: 600; batch classifier loss: 0.346874; batch adversarial loss: 0.343667\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571090; batch adversarial loss: 0.418701\n",
      "epoch 7; iter: 200; batch classifier loss: 0.403853; batch adversarial loss: 0.516879\n",
      "epoch 7; iter: 400; batch classifier loss: 0.330724; batch adversarial loss: 0.426413\n",
      "epoch 7; iter: 600; batch classifier loss: 0.283096; batch adversarial loss: 0.373104\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449956; batch adversarial loss: 0.402250\n",
      "epoch 8; iter: 200; batch classifier loss: 0.343928; batch adversarial loss: 0.438738\n",
      "epoch 8; iter: 400; batch classifier loss: 0.458970; batch adversarial loss: 0.370469\n",
      "epoch 8; iter: 600; batch classifier loss: 0.445690; batch adversarial loss: 0.424406\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445165; batch adversarial loss: 0.429378\n",
      "epoch 9; iter: 200; batch classifier loss: 0.371945; batch adversarial loss: 0.345232\n",
      "epoch 9; iter: 400; batch classifier loss: 0.399903; batch adversarial loss: 0.410691\n",
      "epoch 9; iter: 600; batch classifier loss: 0.283236; batch adversarial loss: 0.299635\n",
      "epoch 0; iter: 0; batch classifier loss: 150.636124; batch adversarial loss: 0.693818\n",
      "epoch 0; iter: 200; batch classifier loss: 4.244778; batch adversarial loss: 0.643762\n",
      "epoch 0; iter: 400; batch classifier loss: 17.586462; batch adversarial loss: 0.579032\n",
      "epoch 0; iter: 600; batch classifier loss: 10.077217; batch adversarial loss: 0.518711\n",
      "epoch 1; iter: 0; batch classifier loss: 10.221554; batch adversarial loss: 0.517115\n",
      "epoch 1; iter: 200; batch classifier loss: 0.611007; batch adversarial loss: 0.502326\n",
      "epoch 1; iter: 400; batch classifier loss: 2.055084; batch adversarial loss: 0.573132\n",
      "epoch 1; iter: 600; batch classifier loss: 3.856995; batch adversarial loss: 0.438704\n",
      "epoch 2; iter: 0; batch classifier loss: 0.816979; batch adversarial loss: 0.436662\n",
      "epoch 2; iter: 200; batch classifier loss: 4.323806; batch adversarial loss: 0.372748\n",
      "epoch 2; iter: 400; batch classifier loss: 1.537542; batch adversarial loss: 0.359538\n",
      "epoch 2; iter: 600; batch classifier loss: 3.883065; batch adversarial loss: 0.327116\n",
      "epoch 3; iter: 0; batch classifier loss: 1.597039; batch adversarial loss: 0.333257\n",
      "epoch 3; iter: 200; batch classifier loss: 0.310790; batch adversarial loss: 0.449295\n",
      "epoch 3; iter: 400; batch classifier loss: 0.620059; batch adversarial loss: 0.406290\n",
      "epoch 3; iter: 600; batch classifier loss: 0.613882; batch adversarial loss: 0.347500\n",
      "epoch 4; iter: 0; batch classifier loss: 1.177663; batch adversarial loss: 0.408342\n",
      "epoch 4; iter: 200; batch classifier loss: 1.284000; batch adversarial loss: 0.336836\n",
      "epoch 4; iter: 400; batch classifier loss: 0.680662; batch adversarial loss: 0.329923\n",
      "epoch 4; iter: 600; batch classifier loss: 1.325933; batch adversarial loss: 0.326249\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595688; batch adversarial loss: 0.248898\n",
      "epoch 5; iter: 200; batch classifier loss: 0.770427; batch adversarial loss: 0.395949\n",
      "epoch 5; iter: 400; batch classifier loss: 0.692642; batch adversarial loss: 0.444964\n",
      "epoch 5; iter: 600; batch classifier loss: 0.492003; batch adversarial loss: 0.358355\n",
      "epoch 6; iter: 0; batch classifier loss: 0.757107; batch adversarial loss: 0.363510\n",
      "epoch 6; iter: 200; batch classifier loss: 0.388095; batch adversarial loss: 0.444061\n",
      "epoch 6; iter: 400; batch classifier loss: 0.358915; batch adversarial loss: 0.333210\n",
      "epoch 6; iter: 600; batch classifier loss: 0.319247; batch adversarial loss: 0.454009\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469616; batch adversarial loss: 0.569962\n",
      "epoch 7; iter: 200; batch classifier loss: 0.345086; batch adversarial loss: 0.522508\n",
      "epoch 7; iter: 400; batch classifier loss: 0.505375; batch adversarial loss: 0.537764\n",
      "epoch 7; iter: 600; batch classifier loss: 0.456842; batch adversarial loss: 0.348085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.385890; batch adversarial loss: 0.397185\n",
      "epoch 8; iter: 200; batch classifier loss: 0.483091; batch adversarial loss: 0.400251\n",
      "epoch 8; iter: 400; batch classifier loss: 0.329815; batch adversarial loss: 0.294573\n",
      "epoch 8; iter: 600; batch classifier loss: 0.348021; batch adversarial loss: 0.334303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371353; batch adversarial loss: 0.427684\n",
      "epoch 9; iter: 200; batch classifier loss: 0.373045; batch adversarial loss: 0.395837\n",
      "epoch 9; iter: 400; batch classifier loss: 0.539436; batch adversarial loss: 0.489234\n",
      "epoch 9; iter: 600; batch classifier loss: 0.528242; batch adversarial loss: 0.324412\n",
      "epoch 0; iter: 0; batch classifier loss: 18.166954; batch adversarial loss: 0.575271\n",
      "epoch 0; iter: 200; batch classifier loss: 71.054222; batch adversarial loss: 0.557079\n",
      "epoch 0; iter: 400; batch classifier loss: 2.270827; batch adversarial loss: 0.556113\n",
      "epoch 0; iter: 600; batch classifier loss: 2.451213; batch adversarial loss: 0.525249\n",
      "epoch 1; iter: 0; batch classifier loss: 4.076214; batch adversarial loss: 0.504546\n",
      "epoch 1; iter: 200; batch classifier loss: 2.569110; batch adversarial loss: 0.422914\n",
      "epoch 1; iter: 400; batch classifier loss: 2.766913; batch adversarial loss: 0.476941\n",
      "epoch 1; iter: 600; batch classifier loss: 1.016659; batch adversarial loss: 0.395851\n",
      "epoch 2; iter: 0; batch classifier loss: 6.595314; batch adversarial loss: 0.487626\n",
      "epoch 2; iter: 200; batch classifier loss: 5.319680; batch adversarial loss: 0.459779\n",
      "epoch 2; iter: 400; batch classifier loss: 0.386405; batch adversarial loss: 0.489127\n",
      "epoch 2; iter: 600; batch classifier loss: 1.711604; batch adversarial loss: 0.434952\n",
      "epoch 3; iter: 0; batch classifier loss: 1.034740; batch adversarial loss: 0.450866\n",
      "epoch 3; iter: 200; batch classifier loss: 0.394892; batch adversarial loss: 0.360703\n",
      "epoch 3; iter: 400; batch classifier loss: 1.813024; batch adversarial loss: 0.456013\n",
      "epoch 3; iter: 600; batch classifier loss: 0.320462; batch adversarial loss: 0.465834\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422338; batch adversarial loss: 0.383297\n",
      "epoch 4; iter: 200; batch classifier loss: 0.476070; batch adversarial loss: 0.401401\n",
      "epoch 4; iter: 400; batch classifier loss: 0.263962; batch adversarial loss: 0.485340\n",
      "epoch 4; iter: 600; batch classifier loss: 0.438826; batch adversarial loss: 0.335620\n",
      "epoch 5; iter: 0; batch classifier loss: 0.618366; batch adversarial loss: 0.413303\n",
      "epoch 5; iter: 200; batch classifier loss: 0.307562; batch adversarial loss: 0.442814\n",
      "epoch 5; iter: 400; batch classifier loss: 5.826274; batch adversarial loss: 0.397108\n",
      "epoch 5; iter: 600; batch classifier loss: 0.345728; batch adversarial loss: 0.239772\n",
      "epoch 6; iter: 0; batch classifier loss: 0.439065; batch adversarial loss: 0.519393\n",
      "epoch 6; iter: 200; batch classifier loss: 0.452263; batch adversarial loss: 0.377963\n",
      "epoch 6; iter: 400; batch classifier loss: 0.425672; batch adversarial loss: 0.320041\n",
      "epoch 6; iter: 600; batch classifier loss: 0.391935; batch adversarial loss: 0.490888\n",
      "epoch 7; iter: 0; batch classifier loss: 0.357063; batch adversarial loss: 0.423330\n",
      "epoch 7; iter: 200; batch classifier loss: 0.239265; batch adversarial loss: 0.403105\n",
      "epoch 7; iter: 400; batch classifier loss: 0.464634; batch adversarial loss: 0.327975\n",
      "epoch 7; iter: 600; batch classifier loss: 0.313578; batch adversarial loss: 0.502614\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325289; batch adversarial loss: 0.395140\n",
      "epoch 8; iter: 200; batch classifier loss: 0.451276; batch adversarial loss: 0.398668\n",
      "epoch 8; iter: 400; batch classifier loss: 0.614264; batch adversarial loss: 0.326185\n",
      "epoch 8; iter: 600; batch classifier loss: 0.365116; batch adversarial loss: 0.395427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404756; batch adversarial loss: 0.216427\n",
      "epoch 9; iter: 200; batch classifier loss: 0.316918; batch adversarial loss: 0.550469\n",
      "epoch 9; iter: 400; batch classifier loss: 0.335292; batch adversarial loss: 0.461358\n",
      "epoch 9; iter: 600; batch classifier loss: 0.289921; batch adversarial loss: 0.351087\n",
      "epoch 0; iter: 0; batch classifier loss: 9.090505; batch adversarial loss: 0.660548\n",
      "epoch 0; iter: 200; batch classifier loss: 5.693145; batch adversarial loss: 0.628210\n",
      "epoch 0; iter: 400; batch classifier loss: 2.609819; batch adversarial loss: 0.550290\n",
      "epoch 0; iter: 600; batch classifier loss: 6.600290; batch adversarial loss: 0.518902\n",
      "epoch 1; iter: 0; batch classifier loss: 2.316133; batch adversarial loss: 0.420832\n",
      "epoch 1; iter: 200; batch classifier loss: 3.851698; batch adversarial loss: 0.510155\n",
      "epoch 1; iter: 400; batch classifier loss: 5.951048; batch adversarial loss: 0.461219\n",
      "epoch 1; iter: 600; batch classifier loss: 1.051053; batch adversarial loss: 0.382271\n",
      "epoch 2; iter: 0; batch classifier loss: 4.435722; batch adversarial loss: 0.445889\n",
      "epoch 2; iter: 200; batch classifier loss: 3.730855; batch adversarial loss: 0.392990\n",
      "epoch 2; iter: 400; batch classifier loss: 0.431922; batch adversarial loss: 0.424226\n",
      "epoch 2; iter: 600; batch classifier loss: 3.034163; batch adversarial loss: 0.515351\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384621; batch adversarial loss: 0.525767\n",
      "epoch 3; iter: 200; batch classifier loss: 1.325181; batch adversarial loss: 0.350036\n",
      "epoch 3; iter: 400; batch classifier loss: 10.670952; batch adversarial loss: 0.412176\n",
      "epoch 3; iter: 600; batch classifier loss: 0.297104; batch adversarial loss: 0.356596\n",
      "epoch 4; iter: 0; batch classifier loss: 0.364653; batch adversarial loss: 0.441614\n",
      "epoch 4; iter: 200; batch classifier loss: 1.991259; batch adversarial loss: 0.415308\n",
      "epoch 4; iter: 400; batch classifier loss: 0.351246; batch adversarial loss: 0.315398\n",
      "epoch 4; iter: 600; batch classifier loss: 0.311247; batch adversarial loss: 0.411439\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420910; batch adversarial loss: 0.314686\n",
      "epoch 5; iter: 200; batch classifier loss: 0.766598; batch adversarial loss: 0.298452\n",
      "epoch 5; iter: 400; batch classifier loss: 0.443663; batch adversarial loss: 0.371303\n",
      "epoch 5; iter: 600; batch classifier loss: 0.307614; batch adversarial loss: 0.334063\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296925; batch adversarial loss: 0.443465\n",
      "epoch 6; iter: 200; batch classifier loss: 0.500350; batch adversarial loss: 0.423559\n",
      "epoch 6; iter: 400; batch classifier loss: 0.582011; batch adversarial loss: 0.511786\n",
      "epoch 6; iter: 600; batch classifier loss: 0.450335; batch adversarial loss: 0.495868\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351415; batch adversarial loss: 0.375493\n",
      "epoch 7; iter: 200; batch classifier loss: 0.312693; batch adversarial loss: 0.502884\n",
      "epoch 7; iter: 400; batch classifier loss: 0.376061; batch adversarial loss: 0.366886\n",
      "epoch 7; iter: 600; batch classifier loss: 0.323815; batch adversarial loss: 0.355326\n",
      "epoch 8; iter: 0; batch classifier loss: 0.477889; batch adversarial loss: 0.347326\n",
      "epoch 8; iter: 200; batch classifier loss: 0.542524; batch adversarial loss: 0.423197\n",
      "epoch 8; iter: 400; batch classifier loss: 0.648645; batch adversarial loss: 0.304295\n",
      "epoch 8; iter: 600; batch classifier loss: 0.468082; batch adversarial loss: 0.436967\n",
      "epoch 9; iter: 0; batch classifier loss: 0.362726; batch adversarial loss: 0.488407\n",
      "epoch 9; iter: 200; batch classifier loss: 0.498827; batch adversarial loss: 0.350691\n",
      "epoch 9; iter: 400; batch classifier loss: 0.251301; batch adversarial loss: 0.356742\n",
      "epoch 9; iter: 600; batch classifier loss: 0.425741; batch adversarial loss: 0.378345\n",
      "epoch 0; iter: 0; batch classifier loss: 8.094266; batch adversarial loss: 0.702719\n",
      "epoch 0; iter: 200; batch classifier loss: 7.893721; batch adversarial loss: 0.647207\n",
      "epoch 0; iter: 400; batch classifier loss: 5.328605; batch adversarial loss: 0.568512\n",
      "epoch 0; iter: 600; batch classifier loss: 8.658068; batch adversarial loss: 0.450198\n",
      "epoch 1; iter: 0; batch classifier loss: 2.398937; batch adversarial loss: 0.523348\n",
      "epoch 1; iter: 200; batch classifier loss: 4.180680; batch adversarial loss: 0.492566\n",
      "epoch 1; iter: 400; batch classifier loss: 1.573077; batch adversarial loss: 0.511802\n",
      "epoch 1; iter: 600; batch classifier loss: 0.706504; batch adversarial loss: 0.533692\n",
      "epoch 2; iter: 0; batch classifier loss: 2.129511; batch adversarial loss: 0.407045\n",
      "epoch 2; iter: 200; batch classifier loss: 2.654328; batch adversarial loss: 0.429946\n",
      "epoch 2; iter: 400; batch classifier loss: 2.085606; batch adversarial loss: 0.486258\n",
      "epoch 2; iter: 600; batch classifier loss: 1.126564; batch adversarial loss: 0.452487\n",
      "epoch 3; iter: 0; batch classifier loss: 1.950008; batch adversarial loss: 0.294463\n",
      "epoch 3; iter: 200; batch classifier loss: 0.604872; batch adversarial loss: 0.398332\n",
      "epoch 3; iter: 400; batch classifier loss: 1.154289; batch adversarial loss: 0.389910\n",
      "epoch 3; iter: 600; batch classifier loss: 0.609719; batch adversarial loss: 0.326316\n",
      "epoch 4; iter: 0; batch classifier loss: 0.915542; batch adversarial loss: 0.389445\n",
      "epoch 4; iter: 200; batch classifier loss: 0.342101; batch adversarial loss: 0.445132\n",
      "epoch 4; iter: 400; batch classifier loss: 0.347104; batch adversarial loss: 0.373941\n",
      "epoch 4; iter: 600; batch classifier loss: 0.590735; batch adversarial loss: 0.356728\n",
      "epoch 5; iter: 0; batch classifier loss: 1.202881; batch adversarial loss: 0.380575\n",
      "epoch 5; iter: 200; batch classifier loss: 0.339218; batch adversarial loss: 0.472157\n",
      "epoch 5; iter: 400; batch classifier loss: 0.460956; batch adversarial loss: 0.383145\n",
      "epoch 5; iter: 600; batch classifier loss: 0.417143; batch adversarial loss: 0.316125\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581736; batch adversarial loss: 0.554876\n",
      "epoch 6; iter: 200; batch classifier loss: 0.270064; batch adversarial loss: 0.265335\n",
      "epoch 6; iter: 400; batch classifier loss: 0.639155; batch adversarial loss: 0.344075\n",
      "epoch 6; iter: 600; batch classifier loss: 0.552285; batch adversarial loss: 0.298139\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517208; batch adversarial loss: 0.418320\n",
      "epoch 7; iter: 200; batch classifier loss: 0.335750; batch adversarial loss: 0.448643\n",
      "epoch 7; iter: 400; batch classifier loss: 0.415414; batch adversarial loss: 0.452456\n",
      "epoch 7; iter: 600; batch classifier loss: 0.324306; batch adversarial loss: 0.298045\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490464; batch adversarial loss: 0.414697\n",
      "epoch 8; iter: 200; batch classifier loss: 0.381282; batch adversarial loss: 0.288031\n",
      "epoch 8; iter: 400; batch classifier loss: 0.428051; batch adversarial loss: 0.377024\n",
      "epoch 8; iter: 600; batch classifier loss: 0.319941; batch adversarial loss: 0.329152\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409345; batch adversarial loss: 0.329499\n",
      "epoch 9; iter: 200; batch classifier loss: 0.457389; batch adversarial loss: 0.376053\n",
      "epoch 9; iter: 400; batch classifier loss: 0.425027; batch adversarial loss: 0.400475\n",
      "epoch 9; iter: 600; batch classifier loss: 0.293026; batch adversarial loss: 0.378165\n",
      "epoch 0; iter: 0; batch classifier loss: 48.315041; batch adversarial loss: 0.569441\n",
      "epoch 0; iter: 200; batch classifier loss: 6.968608; batch adversarial loss: 0.617509\n",
      "epoch 0; iter: 400; batch classifier loss: 3.835813; batch adversarial loss: 0.553433\n",
      "epoch 0; iter: 600; batch classifier loss: 3.313323; batch adversarial loss: 0.479991\n",
      "epoch 1; iter: 0; batch classifier loss: 5.196115; batch adversarial loss: 0.536060\n",
      "epoch 1; iter: 200; batch classifier loss: 0.973757; batch adversarial loss: 0.448816\n",
      "epoch 1; iter: 400; batch classifier loss: 3.885769; batch adversarial loss: 0.549503\n",
      "epoch 1; iter: 600; batch classifier loss: 2.245598; batch adversarial loss: 0.269347\n",
      "epoch 2; iter: 0; batch classifier loss: 2.331038; batch adversarial loss: 0.495556\n",
      "epoch 2; iter: 200; batch classifier loss: 3.942478; batch adversarial loss: 0.463988\n",
      "epoch 2; iter: 400; batch classifier loss: 1.895424; batch adversarial loss: 0.439341\n",
      "epoch 2; iter: 600; batch classifier loss: 14.811688; batch adversarial loss: 0.373439\n",
      "epoch 3; iter: 0; batch classifier loss: 0.874703; batch adversarial loss: 0.430441\n",
      "epoch 3; iter: 200; batch classifier loss: 0.336883; batch adversarial loss: 0.455494\n",
      "epoch 3; iter: 400; batch classifier loss: 1.878353; batch adversarial loss: 0.472160\n",
      "epoch 3; iter: 600; batch classifier loss: 0.665440; batch adversarial loss: 0.569709\n",
      "epoch 4; iter: 0; batch classifier loss: 0.385380; batch adversarial loss: 0.489212\n",
      "epoch 4; iter: 200; batch classifier loss: 0.685182; batch adversarial loss: 0.448647\n",
      "epoch 4; iter: 400; batch classifier loss: 0.829880; batch adversarial loss: 0.424514\n",
      "epoch 4; iter: 600; batch classifier loss: 0.290611; batch adversarial loss: 0.501297\n",
      "epoch 5; iter: 0; batch classifier loss: 0.345947; batch adversarial loss: 0.522192\n",
      "epoch 5; iter: 200; batch classifier loss: 0.803560; batch adversarial loss: 0.353735\n",
      "epoch 5; iter: 400; batch classifier loss: 5.046939; batch adversarial loss: 0.354190\n",
      "epoch 5; iter: 600; batch classifier loss: 0.418845; batch adversarial loss: 0.463601\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473075; batch adversarial loss: 0.381585\n",
      "epoch 6; iter: 200; batch classifier loss: 0.263485; batch adversarial loss: 0.290346\n",
      "epoch 6; iter: 400; batch classifier loss: 0.691366; batch adversarial loss: 0.484397\n",
      "epoch 6; iter: 600; batch classifier loss: 0.511580; batch adversarial loss: 0.462317\n",
      "epoch 7; iter: 0; batch classifier loss: 0.398442; batch adversarial loss: 0.446402\n",
      "epoch 7; iter: 200; batch classifier loss: 0.393461; batch adversarial loss: 0.470573\n",
      "epoch 7; iter: 400; batch classifier loss: 0.303903; batch adversarial loss: 0.454771\n",
      "epoch 7; iter: 600; batch classifier loss: 0.325473; batch adversarial loss: 0.342521\n",
      "epoch 8; iter: 0; batch classifier loss: 0.405765; batch adversarial loss: 0.460531\n",
      "epoch 8; iter: 200; batch classifier loss: 0.329718; batch adversarial loss: 0.508250\n",
      "epoch 8; iter: 400; batch classifier loss: 0.476718; batch adversarial loss: 0.371347\n",
      "epoch 8; iter: 600; batch classifier loss: 0.390239; batch adversarial loss: 0.532186\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291592; batch adversarial loss: 0.431678\n",
      "epoch 9; iter: 200; batch classifier loss: 0.288303; batch adversarial loss: 0.319379\n",
      "epoch 9; iter: 400; batch classifier loss: 0.348407; batch adversarial loss: 0.505072\n",
      "epoch 9; iter: 600; batch classifier loss: 0.297851; batch adversarial loss: 0.452527\n",
      "epoch 0; iter: 0; batch classifier loss: 14.842825; batch adversarial loss: 0.929084\n",
      "epoch 0; iter: 200; batch classifier loss: 10.467039; batch adversarial loss: 0.665860\n",
      "epoch 0; iter: 400; batch classifier loss: 16.790886; batch adversarial loss: 0.686974\n",
      "epoch 0; iter: 600; batch classifier loss: 2.128906; batch adversarial loss: 0.560103\n",
      "epoch 1; iter: 0; batch classifier loss: 24.184761; batch adversarial loss: 0.535051\n",
      "epoch 1; iter: 200; batch classifier loss: 1.325814; batch adversarial loss: 0.514816\n",
      "epoch 1; iter: 400; batch classifier loss: 0.332140; batch adversarial loss: 0.480961\n",
      "epoch 1; iter: 600; batch classifier loss: 1.275513; batch adversarial loss: 0.546508\n",
      "epoch 2; iter: 0; batch classifier loss: 3.553078; batch adversarial loss: 0.507616\n",
      "epoch 2; iter: 200; batch classifier loss: 1.289300; batch adversarial loss: 0.548821\n",
      "epoch 2; iter: 400; batch classifier loss: 2.201145; batch adversarial loss: 0.462231\n",
      "epoch 2; iter: 600; batch classifier loss: 0.356693; batch adversarial loss: 0.401738\n",
      "epoch 3; iter: 0; batch classifier loss: 0.928052; batch adversarial loss: 0.495345\n",
      "epoch 3; iter: 200; batch classifier loss: 2.248162; batch adversarial loss: 0.432319\n",
      "epoch 3; iter: 400; batch classifier loss: 3.425650; batch adversarial loss: 0.346134\n",
      "epoch 3; iter: 600; batch classifier loss: 0.385142; batch adversarial loss: 0.429040\n",
      "epoch 4; iter: 0; batch classifier loss: 0.287490; batch adversarial loss: 0.482472\n",
      "epoch 4; iter: 200; batch classifier loss: 0.414726; batch adversarial loss: 0.492566\n",
      "epoch 4; iter: 400; batch classifier loss: 0.596100; batch adversarial loss: 0.449143\n",
      "epoch 4; iter: 600; batch classifier loss: 0.991945; batch adversarial loss: 0.445556\n",
      "epoch 5; iter: 0; batch classifier loss: 0.397789; batch adversarial loss: 0.408699\n",
      "epoch 5; iter: 200; batch classifier loss: 0.566865; batch adversarial loss: 0.320349\n",
      "epoch 5; iter: 400; batch classifier loss: 0.281461; batch adversarial loss: 0.317669\n",
      "epoch 5; iter: 600; batch classifier loss: 0.397936; batch adversarial loss: 0.281655\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496864; batch adversarial loss: 0.369959\n",
      "epoch 6; iter: 200; batch classifier loss: 0.470797; batch adversarial loss: 0.481811\n",
      "epoch 6; iter: 400; batch classifier loss: 0.375625; batch adversarial loss: 0.416244\n",
      "epoch 6; iter: 600; batch classifier loss: 0.490890; batch adversarial loss: 0.381805\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315338; batch adversarial loss: 0.403152\n",
      "epoch 7; iter: 200; batch classifier loss: 0.393847; batch adversarial loss: 0.513607\n",
      "epoch 7; iter: 400; batch classifier loss: 0.248405; batch adversarial loss: 0.378857\n",
      "epoch 7; iter: 600; batch classifier loss: 0.381186; batch adversarial loss: 0.477579\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507162; batch adversarial loss: 0.381842\n",
      "epoch 8; iter: 200; batch classifier loss: 0.318310; batch adversarial loss: 0.391273\n",
      "epoch 8; iter: 400; batch classifier loss: 0.432485; batch adversarial loss: 0.434388\n",
      "epoch 8; iter: 600; batch classifier loss: 0.328361; batch adversarial loss: 0.376023\n",
      "epoch 9; iter: 0; batch classifier loss: 0.422654; batch adversarial loss: 0.348773\n",
      "epoch 9; iter: 200; batch classifier loss: 0.466899; batch adversarial loss: 0.401927\n",
      "epoch 9; iter: 400; batch classifier loss: 0.361920; batch adversarial loss: 0.545702\n",
      "epoch 9; iter: 600; batch classifier loss: 0.357091; batch adversarial loss: 0.394962\n",
      "epoch 0; iter: 0; batch classifier loss: 15.595427; batch adversarial loss: 0.697298\n",
      "epoch 0; iter: 200; batch classifier loss: 9.075184; batch adversarial loss: 0.485114\n",
      "epoch 0; iter: 400; batch classifier loss: 7.698755; batch adversarial loss: 0.570730\n",
      "epoch 0; iter: 600; batch classifier loss: 8.354664; batch adversarial loss: 0.420314\n",
      "epoch 1; iter: 0; batch classifier loss: 4.552189; batch adversarial loss: 0.519646\n",
      "epoch 1; iter: 200; batch classifier loss: 2.273609; batch adversarial loss: 0.530731\n",
      "epoch 1; iter: 400; batch classifier loss: 1.543402; batch adversarial loss: 0.399411\n",
      "epoch 1; iter: 600; batch classifier loss: 7.898484; batch adversarial loss: 0.374684\n",
      "epoch 2; iter: 0; batch classifier loss: 3.302304; batch adversarial loss: 0.466835\n",
      "epoch 2; iter: 200; batch classifier loss: 0.284168; batch adversarial loss: 0.450923\n",
      "epoch 2; iter: 400; batch classifier loss: 1.362991; batch adversarial loss: 0.529156\n",
      "epoch 2; iter: 600; batch classifier loss: 2.171002; batch adversarial loss: 0.378619\n",
      "epoch 3; iter: 0; batch classifier loss: 0.882574; batch adversarial loss: 0.503672\n",
      "epoch 3; iter: 200; batch classifier loss: 0.482735; batch adversarial loss: 0.512834\n",
      "epoch 3; iter: 400; batch classifier loss: 0.415606; batch adversarial loss: 0.462173\n",
      "epoch 3; iter: 600; batch classifier loss: 0.356094; batch adversarial loss: 0.379703\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619869; batch adversarial loss: 0.454265\n",
      "epoch 4; iter: 200; batch classifier loss: 0.244295; batch adversarial loss: 0.371090\n",
      "epoch 4; iter: 400; batch classifier loss: 1.030910; batch adversarial loss: 0.446390\n",
      "epoch 4; iter: 600; batch classifier loss: 0.495892; batch adversarial loss: 0.357779\n",
      "epoch 5; iter: 0; batch classifier loss: 0.397196; batch adversarial loss: 0.332404\n",
      "epoch 5; iter: 200; batch classifier loss: 0.287015; batch adversarial loss: 0.472565\n",
      "epoch 5; iter: 400; batch classifier loss: 0.446745; batch adversarial loss: 0.509335\n",
      "epoch 5; iter: 600; batch classifier loss: 0.431621; batch adversarial loss: 0.331994\n",
      "epoch 6; iter: 0; batch classifier loss: 2.001019; batch adversarial loss: 0.506335\n",
      "epoch 6; iter: 200; batch classifier loss: 0.474115; batch adversarial loss: 0.455814\n",
      "epoch 6; iter: 400; batch classifier loss: 0.540141; batch adversarial loss: 0.350214\n",
      "epoch 6; iter: 600; batch classifier loss: 0.404539; batch adversarial loss: 0.384277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.384447; batch adversarial loss: 0.358592\n",
      "epoch 7; iter: 200; batch classifier loss: 0.382632; batch adversarial loss: 0.383802\n",
      "epoch 7; iter: 400; batch classifier loss: 0.705200; batch adversarial loss: 0.585541\n",
      "epoch 7; iter: 600; batch classifier loss: 0.311174; batch adversarial loss: 0.358764\n",
      "epoch 8; iter: 0; batch classifier loss: 0.427755; batch adversarial loss: 0.622959\n",
      "epoch 8; iter: 200; batch classifier loss: 0.429470; batch adversarial loss: 0.384649\n",
      "epoch 8; iter: 400; batch classifier loss: 0.384839; batch adversarial loss: 0.377352\n",
      "epoch 8; iter: 600; batch classifier loss: 0.296748; batch adversarial loss: 0.348394\n",
      "epoch 9; iter: 0; batch classifier loss: 0.428769; batch adversarial loss: 0.582470\n",
      "epoch 9; iter: 200; batch classifier loss: 0.429290; batch adversarial loss: 0.401879\n",
      "epoch 9; iter: 400; batch classifier loss: 0.358383; batch adversarial loss: 0.258772\n",
      "epoch 9; iter: 600; batch classifier loss: 0.270649; batch adversarial loss: 0.326662\n",
      "epoch 0; iter: 0; batch classifier loss: 9.981939; batch adversarial loss: 0.788824\n",
      "epoch 0; iter: 200; batch classifier loss: 2.792667; batch adversarial loss: 1.051004\n",
      "epoch 0; iter: 400; batch classifier loss: 3.810356; batch adversarial loss: 0.806582\n",
      "epoch 0; iter: 600; batch classifier loss: 11.858706; batch adversarial loss: 0.617881\n",
      "epoch 1; iter: 0; batch classifier loss: 9.611537; batch adversarial loss: 0.629876\n",
      "epoch 1; iter: 200; batch classifier loss: 10.340292; batch adversarial loss: 0.501003\n",
      "epoch 1; iter: 400; batch classifier loss: 0.998782; batch adversarial loss: 0.459545\n",
      "epoch 1; iter: 600; batch classifier loss: 1.410836; batch adversarial loss: 0.490591\n",
      "epoch 2; iter: 0; batch classifier loss: 0.490874; batch adversarial loss: 0.581568\n",
      "epoch 2; iter: 200; batch classifier loss: 1.188785; batch adversarial loss: 0.441556\n",
      "epoch 2; iter: 400; batch classifier loss: 2.357245; batch adversarial loss: 0.437707\n",
      "epoch 2; iter: 600; batch classifier loss: 0.883346; batch adversarial loss: 0.359630\n",
      "epoch 3; iter: 0; batch classifier loss: 0.998636; batch adversarial loss: 0.548760\n",
      "epoch 3; iter: 200; batch classifier loss: 0.882822; batch adversarial loss: 0.536846\n",
      "epoch 3; iter: 400; batch classifier loss: 0.754618; batch adversarial loss: 0.450879\n",
      "epoch 3; iter: 600; batch classifier loss: 1.329227; batch adversarial loss: 0.373689\n",
      "epoch 4; iter: 0; batch classifier loss: 1.393107; batch adversarial loss: 0.439907\n",
      "epoch 4; iter: 200; batch classifier loss: 0.779312; batch adversarial loss: 0.486293\n",
      "epoch 4; iter: 400; batch classifier loss: 0.355447; batch adversarial loss: 0.399704\n",
      "epoch 4; iter: 600; batch classifier loss: 0.385096; batch adversarial loss: 0.389306\n",
      "epoch 5; iter: 0; batch classifier loss: 0.330453; batch adversarial loss: 0.301028\n",
      "epoch 5; iter: 200; batch classifier loss: 0.575315; batch adversarial loss: 0.368630\n",
      "epoch 5; iter: 400; batch classifier loss: 0.435712; batch adversarial loss: 0.475445\n",
      "epoch 5; iter: 600; batch classifier loss: 0.652348; batch adversarial loss: 0.374679\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589420; batch adversarial loss: 0.444984\n",
      "epoch 6; iter: 200; batch classifier loss: 0.447230; batch adversarial loss: 0.420076\n",
      "epoch 6; iter: 400; batch classifier loss: 0.392125; batch adversarial loss: 0.392224\n",
      "epoch 6; iter: 600; batch classifier loss: 0.433579; batch adversarial loss: 0.316380\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533712; batch adversarial loss: 0.428995\n",
      "epoch 7; iter: 200; batch classifier loss: 0.417371; batch adversarial loss: 0.355747\n",
      "epoch 7; iter: 400; batch classifier loss: 0.414549; batch adversarial loss: 0.374244\n",
      "epoch 7; iter: 600; batch classifier loss: 0.400202; batch adversarial loss: 0.551004\n",
      "epoch 8; iter: 0; batch classifier loss: 0.312043; batch adversarial loss: 0.545053\n",
      "epoch 8; iter: 200; batch classifier loss: 0.390191; batch adversarial loss: 0.317118\n",
      "epoch 8; iter: 400; batch classifier loss: 0.551812; batch adversarial loss: 0.500632\n",
      "epoch 8; iter: 600; batch classifier loss: 0.185540; batch adversarial loss: 0.449372\n",
      "epoch 9; iter: 0; batch classifier loss: 0.408826; batch adversarial loss: 0.507742\n",
      "epoch 9; iter: 200; batch classifier loss: 0.407751; batch adversarial loss: 0.429852\n",
      "epoch 9; iter: 400; batch classifier loss: 0.272999; batch adversarial loss: 0.500080\n",
      "epoch 9; iter: 600; batch classifier loss: 0.234595; batch adversarial loss: 0.498521\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 120.260147; batch adversarial loss: 1.251242\n",
      "epoch 0; iter: 200; batch classifier loss: 5.561444; batch adversarial loss: 0.703644\n",
      "epoch 0; iter: 400; batch classifier loss: 1.467160; batch adversarial loss: 0.593706\n",
      "epoch 0; iter: 600; batch classifier loss: 60.417713; batch adversarial loss: 0.587032\n",
      "epoch 1; iter: 0; batch classifier loss: 6.499242; batch adversarial loss: 0.630116\n",
      "epoch 1; iter: 200; batch classifier loss: 0.403991; batch adversarial loss: 0.593258\n",
      "epoch 1; iter: 400; batch classifier loss: 1.407570; batch adversarial loss: 0.504657\n",
      "epoch 1; iter: 600; batch classifier loss: 0.422078; batch adversarial loss: 0.457270\n",
      "epoch 2; iter: 0; batch classifier loss: 4.848332; batch adversarial loss: 0.484872\n",
      "epoch 2; iter: 200; batch classifier loss: 2.316538; batch adversarial loss: 0.517260\n",
      "epoch 2; iter: 400; batch classifier loss: 2.762341; batch adversarial loss: 0.439954\n",
      "epoch 2; iter: 600; batch classifier loss: 1.381950; batch adversarial loss: 0.488745\n",
      "epoch 3; iter: 0; batch classifier loss: 0.778774; batch adversarial loss: 0.450000\n",
      "epoch 3; iter: 200; batch classifier loss: 1.022300; batch adversarial loss: 0.483743\n",
      "epoch 3; iter: 400; batch classifier loss: 1.471624; batch adversarial loss: 0.298164\n",
      "epoch 3; iter: 600; batch classifier loss: 0.434878; batch adversarial loss: 0.439221\n",
      "epoch 4; iter: 0; batch classifier loss: 0.398548; batch adversarial loss: 0.295658\n",
      "epoch 4; iter: 200; batch classifier loss: 0.718252; batch adversarial loss: 0.429456\n",
      "epoch 4; iter: 400; batch classifier loss: 0.249502; batch adversarial loss: 0.311638\n",
      "epoch 4; iter: 600; batch classifier loss: 0.655630; batch adversarial loss: 0.332102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.430644; batch adversarial loss: 0.365181\n",
      "epoch 5; iter: 200; batch classifier loss: 0.746355; batch adversarial loss: 0.326238\n",
      "epoch 5; iter: 400; batch classifier loss: 0.532229; batch adversarial loss: 0.476269\n",
      "epoch 5; iter: 600; batch classifier loss: 0.575163; batch adversarial loss: 0.330076\n",
      "epoch 6; iter: 0; batch classifier loss: 0.630331; batch adversarial loss: 0.418497\n",
      "epoch 6; iter: 200; batch classifier loss: 0.354764; batch adversarial loss: 0.313492\n",
      "epoch 6; iter: 400; batch classifier loss: 0.424241; batch adversarial loss: 0.374697\n",
      "epoch 6; iter: 600; batch classifier loss: 0.394350; batch adversarial loss: 0.402114\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410342; batch adversarial loss: 0.419353\n",
      "epoch 7; iter: 200; batch classifier loss: 0.272976; batch adversarial loss: 0.216081\n",
      "epoch 7; iter: 400; batch classifier loss: 0.439879; batch adversarial loss: 0.521495\n",
      "epoch 7; iter: 600; batch classifier loss: 0.373725; batch adversarial loss: 0.425997\n",
      "epoch 8; iter: 0; batch classifier loss: 0.424302; batch adversarial loss: 0.316861\n",
      "epoch 8; iter: 200; batch classifier loss: 0.402756; batch adversarial loss: 0.441028\n",
      "epoch 8; iter: 400; batch classifier loss: 0.495661; batch adversarial loss: 0.484207\n",
      "epoch 8; iter: 600; batch classifier loss: 0.265515; batch adversarial loss: 0.377146\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443252; batch adversarial loss: 0.397494\n",
      "epoch 9; iter: 200; batch classifier loss: 0.789220; batch adversarial loss: 0.211618\n",
      "epoch 9; iter: 400; batch classifier loss: 0.275422; batch adversarial loss: 0.322352\n",
      "epoch 9; iter: 600; batch classifier loss: 0.504499; batch adversarial loss: 0.380236\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325107; batch adversarial loss: 0.456989\n",
      "epoch 10; iter: 200; batch classifier loss: 0.343004; batch adversarial loss: 0.397858\n",
      "epoch 10; iter: 400; batch classifier loss: 0.355364; batch adversarial loss: 0.451783\n",
      "epoch 10; iter: 600; batch classifier loss: 0.364496; batch adversarial loss: 0.331524\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348300; batch adversarial loss: 0.457232\n",
      "epoch 11; iter: 200; batch classifier loss: 0.299701; batch adversarial loss: 0.332851\n",
      "epoch 11; iter: 400; batch classifier loss: 0.471167; batch adversarial loss: 0.504359\n",
      "epoch 11; iter: 600; batch classifier loss: 0.414232; batch adversarial loss: 0.530542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.436466; batch adversarial loss: 0.448834\n",
      "epoch 12; iter: 200; batch classifier loss: 0.330693; batch adversarial loss: 0.374917\n",
      "epoch 12; iter: 400; batch classifier loss: 0.346879; batch adversarial loss: 0.518959\n",
      "epoch 12; iter: 600; batch classifier loss: 0.412846; batch adversarial loss: 0.344197\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487451; batch adversarial loss: 0.509256\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353447; batch adversarial loss: 0.294284\n",
      "epoch 13; iter: 400; batch classifier loss: 0.320663; batch adversarial loss: 0.483321\n",
      "epoch 13; iter: 600; batch classifier loss: 0.341217; batch adversarial loss: 0.324785\n",
      "epoch 14; iter: 0; batch classifier loss: 0.422045; batch adversarial loss: 0.521451\n",
      "epoch 14; iter: 200; batch classifier loss: 0.277181; batch adversarial loss: 0.375477\n",
      "epoch 14; iter: 400; batch classifier loss: 0.313263; batch adversarial loss: 0.488846\n",
      "epoch 14; iter: 600; batch classifier loss: 0.350584; batch adversarial loss: 0.436724\n",
      "epoch 15; iter: 0; batch classifier loss: 0.305651; batch adversarial loss: 0.296207\n",
      "epoch 15; iter: 200; batch classifier loss: 0.267522; batch adversarial loss: 0.264530\n",
      "epoch 15; iter: 400; batch classifier loss: 0.386350; batch adversarial loss: 0.431273\n",
      "epoch 15; iter: 600; batch classifier loss: 0.270999; batch adversarial loss: 0.474647\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408540; batch adversarial loss: 0.398678\n",
      "epoch 16; iter: 200; batch classifier loss: 0.416832; batch adversarial loss: 0.377001\n",
      "epoch 16; iter: 400; batch classifier loss: 0.351251; batch adversarial loss: 0.417824\n",
      "epoch 16; iter: 600; batch classifier loss: 0.388725; batch adversarial loss: 0.435370\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383736; batch adversarial loss: 0.349277\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381675; batch adversarial loss: 0.424679\n",
      "epoch 17; iter: 400; batch classifier loss: 0.312231; batch adversarial loss: 0.492433\n",
      "epoch 17; iter: 600; batch classifier loss: 0.366757; batch adversarial loss: 0.454927\n",
      "epoch 18; iter: 0; batch classifier loss: 0.353267; batch adversarial loss: 0.508925\n",
      "epoch 18; iter: 200; batch classifier loss: 0.360350; batch adversarial loss: 0.531704\n",
      "epoch 18; iter: 400; batch classifier loss: 0.374445; batch adversarial loss: 0.440295\n",
      "epoch 18; iter: 600; batch classifier loss: 0.584967; batch adversarial loss: 0.347553\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437677; batch adversarial loss: 0.297709\n",
      "epoch 19; iter: 200; batch classifier loss: 0.486433; batch adversarial loss: 0.551064\n",
      "epoch 19; iter: 400; batch classifier loss: 0.364298; batch adversarial loss: 0.297001\n",
      "epoch 19; iter: 600; batch classifier loss: 0.353667; batch adversarial loss: 0.436357\n",
      "epoch 0; iter: 0; batch classifier loss: 15.516051; batch adversarial loss: 0.691471\n",
      "epoch 0; iter: 200; batch classifier loss: 4.091122; batch adversarial loss: 0.821311\n",
      "epoch 0; iter: 400; batch classifier loss: 7.876857; batch adversarial loss: 0.577906\n",
      "epoch 0; iter: 600; batch classifier loss: 6.742151; batch adversarial loss: 0.542404\n",
      "epoch 1; iter: 0; batch classifier loss: 1.172708; batch adversarial loss: 0.613890\n",
      "epoch 1; iter: 200; batch classifier loss: 6.773322; batch adversarial loss: 0.480921\n",
      "epoch 1; iter: 400; batch classifier loss: 3.090696; batch adversarial loss: 0.459132\n",
      "epoch 1; iter: 600; batch classifier loss: 2.980355; batch adversarial loss: 0.449478\n",
      "epoch 2; iter: 0; batch classifier loss: 0.423434; batch adversarial loss: 0.466908\n",
      "epoch 2; iter: 200; batch classifier loss: 0.481529; batch adversarial loss: 0.395192\n",
      "epoch 2; iter: 400; batch classifier loss: 4.853923; batch adversarial loss: 0.393496\n",
      "epoch 2; iter: 600; batch classifier loss: 0.826108; batch adversarial loss: 0.400001\n",
      "epoch 3; iter: 0; batch classifier loss: 1.192941; batch adversarial loss: 0.453940\n",
      "epoch 3; iter: 200; batch classifier loss: 1.480911; batch adversarial loss: 0.397260\n",
      "epoch 3; iter: 400; batch classifier loss: 0.975303; batch adversarial loss: 0.425597\n",
      "epoch 3; iter: 600; batch classifier loss: 1.473103; batch adversarial loss: 0.371329\n",
      "epoch 4; iter: 0; batch classifier loss: 0.458264; batch adversarial loss: 0.467938\n",
      "epoch 4; iter: 200; batch classifier loss: 0.988220; batch adversarial loss: 0.453547\n",
      "epoch 4; iter: 400; batch classifier loss: 0.351205; batch adversarial loss: 0.418961\n",
      "epoch 4; iter: 600; batch classifier loss: 0.430189; batch adversarial loss: 0.445497\n",
      "epoch 5; iter: 0; batch classifier loss: 1.177025; batch adversarial loss: 0.518761\n",
      "epoch 5; iter: 200; batch classifier loss: 0.364243; batch adversarial loss: 0.479611\n",
      "epoch 5; iter: 400; batch classifier loss: 0.335798; batch adversarial loss: 0.344764\n",
      "epoch 5; iter: 600; batch classifier loss: 0.644923; batch adversarial loss: 0.309361\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307750; batch adversarial loss: 0.390814\n",
      "epoch 6; iter: 200; batch classifier loss: 0.483633; batch adversarial loss: 0.289575\n",
      "epoch 6; iter: 400; batch classifier loss: 0.459686; batch adversarial loss: 0.411246\n",
      "epoch 6; iter: 600; batch classifier loss: 0.431106; batch adversarial loss: 0.290762\n",
      "epoch 7; iter: 0; batch classifier loss: 0.444502; batch adversarial loss: 0.517597\n",
      "epoch 7; iter: 200; batch classifier loss: 0.502392; batch adversarial loss: 0.429878\n",
      "epoch 7; iter: 400; batch classifier loss: 0.478207; batch adversarial loss: 0.396248\n",
      "epoch 7; iter: 600; batch classifier loss: 0.328928; batch adversarial loss: 0.444744\n",
      "epoch 8; iter: 0; batch classifier loss: 0.416748; batch adversarial loss: 0.471895\n",
      "epoch 8; iter: 200; batch classifier loss: 0.337853; batch adversarial loss: 0.476141\n",
      "epoch 8; iter: 400; batch classifier loss: 0.890536; batch adversarial loss: 0.404578\n",
      "epoch 8; iter: 600; batch classifier loss: 0.475076; batch adversarial loss: 0.314457\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369834; batch adversarial loss: 0.495240\n",
      "epoch 9; iter: 200; batch classifier loss: 0.321449; batch adversarial loss: 0.594667\n",
      "epoch 9; iter: 400; batch classifier loss: 0.401279; batch adversarial loss: 0.518222\n",
      "epoch 9; iter: 600; batch classifier loss: 0.288090; batch adversarial loss: 0.369793\n",
      "epoch 10; iter: 0; batch classifier loss: 0.421994; batch adversarial loss: 0.383466\n",
      "epoch 10; iter: 200; batch classifier loss: 0.276102; batch adversarial loss: 0.430578\n",
      "epoch 10; iter: 400; batch classifier loss: 0.356711; batch adversarial loss: 0.383129\n",
      "epoch 10; iter: 600; batch classifier loss: 0.282538; batch adversarial loss: 0.475057\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441005; batch adversarial loss: 0.506184\n",
      "epoch 11; iter: 200; batch classifier loss: 0.364220; batch adversarial loss: 0.403193\n",
      "epoch 11; iter: 400; batch classifier loss: 0.303065; batch adversarial loss: 0.452589\n",
      "epoch 11; iter: 600; batch classifier loss: 0.305394; batch adversarial loss: 0.426077\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333326; batch adversarial loss: 0.471399\n",
      "epoch 12; iter: 200; batch classifier loss: 0.393488; batch adversarial loss: 0.403532\n",
      "epoch 12; iter: 400; batch classifier loss: 0.322274; batch adversarial loss: 0.382173\n",
      "epoch 12; iter: 600; batch classifier loss: 0.276694; batch adversarial loss: 0.398860\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418116; batch adversarial loss: 0.414493\n",
      "epoch 13; iter: 200; batch classifier loss: 0.412311; batch adversarial loss: 0.466109\n",
      "epoch 13; iter: 400; batch classifier loss: 0.388250; batch adversarial loss: 0.539410\n",
      "epoch 13; iter: 600; batch classifier loss: 0.247225; batch adversarial loss: 0.438489\n",
      "epoch 14; iter: 0; batch classifier loss: 0.436661; batch adversarial loss: 0.365358\n",
      "epoch 14; iter: 200; batch classifier loss: 0.271128; batch adversarial loss: 0.207930\n",
      "epoch 14; iter: 400; batch classifier loss: 0.336748; batch adversarial loss: 0.317423\n",
      "epoch 14; iter: 600; batch classifier loss: 0.289575; batch adversarial loss: 0.354009\n",
      "epoch 15; iter: 0; batch classifier loss: 0.452095; batch adversarial loss: 0.433828\n",
      "epoch 15; iter: 200; batch classifier loss: 0.335182; batch adversarial loss: 0.456897\n",
      "epoch 15; iter: 400; batch classifier loss: 0.548731; batch adversarial loss: 0.315238\n",
      "epoch 15; iter: 600; batch classifier loss: 0.347669; batch adversarial loss: 0.470894\n",
      "epoch 16; iter: 0; batch classifier loss: 0.254298; batch adversarial loss: 0.447178\n",
      "epoch 16; iter: 200; batch classifier loss: 0.372783; batch adversarial loss: 0.482060\n",
      "epoch 16; iter: 400; batch classifier loss: 0.365973; batch adversarial loss: 0.375089\n",
      "epoch 16; iter: 600; batch classifier loss: 0.251719; batch adversarial loss: 0.496006\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420546; batch adversarial loss: 0.507070\n",
      "epoch 17; iter: 200; batch classifier loss: 0.408287; batch adversarial loss: 0.514570\n",
      "epoch 17; iter: 400; batch classifier loss: 0.382425; batch adversarial loss: 0.379303\n",
      "epoch 17; iter: 600; batch classifier loss: 0.300592; batch adversarial loss: 0.288108\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345041; batch adversarial loss: 0.524082\n",
      "epoch 18; iter: 200; batch classifier loss: 0.323067; batch adversarial loss: 0.411091\n",
      "epoch 18; iter: 400; batch classifier loss: 0.386505; batch adversarial loss: 0.500832\n",
      "epoch 18; iter: 600; batch classifier loss: 0.349929; batch adversarial loss: 0.354925\n",
      "epoch 19; iter: 0; batch classifier loss: 0.241570; batch adversarial loss: 0.378282\n",
      "epoch 19; iter: 200; batch classifier loss: 0.354522; batch adversarial loss: 0.459033\n",
      "epoch 19; iter: 400; batch classifier loss: 0.304253; batch adversarial loss: 0.432477\n",
      "epoch 19; iter: 600; batch classifier loss: 0.291610; batch adversarial loss: 0.323799\n",
      "epoch 0; iter: 0; batch classifier loss: 10.512398; batch adversarial loss: 0.759405\n",
      "epoch 0; iter: 200; batch classifier loss: 2.962734; batch adversarial loss: 0.599303\n",
      "epoch 0; iter: 400; batch classifier loss: 4.872730; batch adversarial loss: 0.582534\n",
      "epoch 0; iter: 600; batch classifier loss: 1.658965; batch adversarial loss: 0.530305\n",
      "epoch 1; iter: 0; batch classifier loss: 13.981639; batch adversarial loss: 0.525445\n",
      "epoch 1; iter: 200; batch classifier loss: 3.469634; batch adversarial loss: 0.483059\n",
      "epoch 1; iter: 400; batch classifier loss: 0.353536; batch adversarial loss: 0.466797\n",
      "epoch 1; iter: 600; batch classifier loss: 1.413001; batch adversarial loss: 0.418173\n",
      "epoch 2; iter: 0; batch classifier loss: 5.892416; batch adversarial loss: 0.491215\n",
      "epoch 2; iter: 200; batch classifier loss: 1.474467; batch adversarial loss: 0.464638\n",
      "epoch 2; iter: 400; batch classifier loss: 0.571888; batch adversarial loss: 0.358074\n",
      "epoch 2; iter: 600; batch classifier loss: 0.660948; batch adversarial loss: 0.385616\n",
      "epoch 3; iter: 0; batch classifier loss: 0.332038; batch adversarial loss: 0.351014\n",
      "epoch 3; iter: 200; batch classifier loss: 1.037424; batch adversarial loss: 0.438742\n",
      "epoch 3; iter: 400; batch classifier loss: 0.522928; batch adversarial loss: 0.447810\n",
      "epoch 3; iter: 600; batch classifier loss: 1.250412; batch adversarial loss: 0.386241\n",
      "epoch 4; iter: 0; batch classifier loss: 0.411709; batch adversarial loss: 0.341495\n",
      "epoch 4; iter: 200; batch classifier loss: 1.057266; batch adversarial loss: 0.385116\n",
      "epoch 4; iter: 400; batch classifier loss: 0.558893; batch adversarial loss: 0.384976\n",
      "epoch 4; iter: 600; batch classifier loss: 0.506414; batch adversarial loss: 0.381624\n",
      "epoch 5; iter: 0; batch classifier loss: 0.315622; batch adversarial loss: 0.431490\n",
      "epoch 5; iter: 200; batch classifier loss: 1.008986; batch adversarial loss: 0.453220\n",
      "epoch 5; iter: 400; batch classifier loss: 0.562773; batch adversarial loss: 0.441617\n",
      "epoch 5; iter: 600; batch classifier loss: 0.485760; batch adversarial loss: 0.517654\n",
      "epoch 6; iter: 0; batch classifier loss: 0.353182; batch adversarial loss: 0.500600\n",
      "epoch 6; iter: 200; batch classifier loss: 0.528057; batch adversarial loss: 0.383340\n",
      "epoch 6; iter: 400; batch classifier loss: 0.284506; batch adversarial loss: 0.472030\n",
      "epoch 6; iter: 600; batch classifier loss: 0.496864; batch adversarial loss: 0.321115\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458193; batch adversarial loss: 0.442283\n",
      "epoch 7; iter: 200; batch classifier loss: 0.361331; batch adversarial loss: 0.375710\n",
      "epoch 7; iter: 400; batch classifier loss: 0.324136; batch adversarial loss: 0.367087\n",
      "epoch 7; iter: 600; batch classifier loss: 0.226388; batch adversarial loss: 0.620099\n",
      "epoch 8; iter: 0; batch classifier loss: 0.311190; batch adversarial loss: 0.556605\n",
      "epoch 8; iter: 200; batch classifier loss: 0.709743; batch adversarial loss: 0.349132\n",
      "epoch 8; iter: 400; batch classifier loss: 0.459677; batch adversarial loss: 0.402677\n",
      "epoch 8; iter: 600; batch classifier loss: 0.318710; batch adversarial loss: 0.539205\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353125; batch adversarial loss: 0.450231\n",
      "epoch 9; iter: 200; batch classifier loss: 0.400546; batch adversarial loss: 0.316027\n",
      "epoch 9; iter: 400; batch classifier loss: 0.387710; batch adversarial loss: 0.476704\n",
      "epoch 9; iter: 600; batch classifier loss: 0.323727; batch adversarial loss: 0.382773\n",
      "epoch 10; iter: 0; batch classifier loss: 0.313071; batch adversarial loss: 0.317834\n",
      "epoch 10; iter: 200; batch classifier loss: 0.319676; batch adversarial loss: 0.347530\n",
      "epoch 10; iter: 400; batch classifier loss: 0.356808; batch adversarial loss: 0.345638\n",
      "epoch 10; iter: 600; batch classifier loss: 0.338868; batch adversarial loss: 0.551970\n",
      "epoch 11; iter: 0; batch classifier loss: 0.228265; batch adversarial loss: 0.488810\n",
      "epoch 11; iter: 200; batch classifier loss: 0.339698; batch adversarial loss: 0.579199\n",
      "epoch 11; iter: 400; batch classifier loss: 0.430797; batch adversarial loss: 0.466505\n",
      "epoch 11; iter: 600; batch classifier loss: 0.347170; batch adversarial loss: 0.344130\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327478; batch adversarial loss: 0.404735\n",
      "epoch 12; iter: 200; batch classifier loss: 0.383211; batch adversarial loss: 0.534902\n",
      "epoch 12; iter: 400; batch classifier loss: 0.472916; batch adversarial loss: 0.322509\n",
      "epoch 12; iter: 600; batch classifier loss: 0.321449; batch adversarial loss: 0.293410\n",
      "epoch 13; iter: 0; batch classifier loss: 0.227590; batch adversarial loss: 0.505099\n",
      "epoch 13; iter: 200; batch classifier loss: 0.327938; batch adversarial loss: 0.423432\n",
      "epoch 13; iter: 400; batch classifier loss: 0.392501; batch adversarial loss: 0.611076\n",
      "epoch 13; iter: 600; batch classifier loss: 0.351009; batch adversarial loss: 0.355163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.327926; batch adversarial loss: 0.393944\n",
      "epoch 14; iter: 200; batch classifier loss: 0.323157; batch adversarial loss: 0.404879\n",
      "epoch 14; iter: 400; batch classifier loss: 0.411360; batch adversarial loss: 0.341689\n",
      "epoch 14; iter: 600; batch classifier loss: 0.343948; batch adversarial loss: 0.476851\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406463; batch adversarial loss: 0.437667\n",
      "epoch 15; iter: 200; batch classifier loss: 0.432840; batch adversarial loss: 0.319738\n",
      "epoch 15; iter: 400; batch classifier loss: 0.383867; batch adversarial loss: 0.428363\n",
      "epoch 15; iter: 600; batch classifier loss: 0.424738; batch adversarial loss: 0.517111\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292195; batch adversarial loss: 0.477398\n",
      "epoch 16; iter: 200; batch classifier loss: 0.283449; batch adversarial loss: 0.408623\n",
      "epoch 16; iter: 400; batch classifier loss: 0.270434; batch adversarial loss: 0.557171\n",
      "epoch 16; iter: 600; batch classifier loss: 0.300556; batch adversarial loss: 0.408087\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347577; batch adversarial loss: 0.368576\n",
      "epoch 17; iter: 200; batch classifier loss: 0.384706; batch adversarial loss: 0.432931\n",
      "epoch 17; iter: 400; batch classifier loss: 0.246715; batch adversarial loss: 0.371960\n",
      "epoch 17; iter: 600; batch classifier loss: 0.333105; batch adversarial loss: 0.519158\n",
      "epoch 18; iter: 0; batch classifier loss: 0.291273; batch adversarial loss: 0.383074\n",
      "epoch 18; iter: 200; batch classifier loss: 0.715609; batch adversarial loss: 0.447977\n",
      "epoch 18; iter: 400; batch classifier loss: 0.315541; batch adversarial loss: 0.421640\n",
      "epoch 18; iter: 600; batch classifier loss: 0.379569; batch adversarial loss: 0.345573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369324; batch adversarial loss: 0.317083\n",
      "epoch 19; iter: 200; batch classifier loss: 0.418321; batch adversarial loss: 0.236404\n",
      "epoch 19; iter: 400; batch classifier loss: 0.276462; batch adversarial loss: 0.433335\n",
      "epoch 19; iter: 600; batch classifier loss: 0.666164; batch adversarial loss: 0.522798\n",
      "epoch 0; iter: 0; batch classifier loss: 280.176147; batch adversarial loss: 0.681827\n",
      "epoch 0; iter: 200; batch classifier loss: 37.457603; batch adversarial loss: 0.623420\n",
      "epoch 0; iter: 400; batch classifier loss: 2.542151; batch adversarial loss: 0.518345\n",
      "epoch 0; iter: 600; batch classifier loss: 10.484532; batch adversarial loss: 0.559433\n",
      "epoch 1; iter: 0; batch classifier loss: 0.869103; batch adversarial loss: 0.499482\n",
      "epoch 1; iter: 200; batch classifier loss: 1.422756; batch adversarial loss: 0.527657\n",
      "epoch 1; iter: 400; batch classifier loss: 7.338516; batch adversarial loss: 0.435895\n",
      "epoch 1; iter: 600; batch classifier loss: 1.212489; batch adversarial loss: 0.461304\n",
      "epoch 2; iter: 0; batch classifier loss: 1.798460; batch adversarial loss: 0.367156\n",
      "epoch 2; iter: 200; batch classifier loss: 1.549862; batch adversarial loss: 0.430757\n",
      "epoch 2; iter: 400; batch classifier loss: 6.421791; batch adversarial loss: 0.377319\n",
      "epoch 2; iter: 600; batch classifier loss: 1.991794; batch adversarial loss: 0.458493\n",
      "epoch 3; iter: 0; batch classifier loss: 1.845507; batch adversarial loss: 0.440308\n",
      "epoch 3; iter: 200; batch classifier loss: 0.414011; batch adversarial loss: 0.497369\n",
      "epoch 3; iter: 400; batch classifier loss: 0.904915; batch adversarial loss: 0.407699\n",
      "epoch 3; iter: 600; batch classifier loss: 1.317304; batch adversarial loss: 0.323240\n",
      "epoch 4; iter: 0; batch classifier loss: 0.666622; batch adversarial loss: 0.371493\n",
      "epoch 4; iter: 200; batch classifier loss: 0.595972; batch adversarial loss: 0.432431\n",
      "epoch 4; iter: 400; batch classifier loss: 0.370816; batch adversarial loss: 0.480946\n",
      "epoch 4; iter: 600; batch classifier loss: 0.759329; batch adversarial loss: 0.415816\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392074; batch adversarial loss: 0.373466\n",
      "epoch 5; iter: 200; batch classifier loss: 0.266454; batch adversarial loss: 0.485706\n",
      "epoch 5; iter: 400; batch classifier loss: 0.270826; batch adversarial loss: 0.523020\n",
      "epoch 5; iter: 600; batch classifier loss: 0.208989; batch adversarial loss: 0.420855\n",
      "epoch 6; iter: 0; batch classifier loss: 0.948213; batch adversarial loss: 0.384784\n",
      "epoch 6; iter: 200; batch classifier loss: 0.490292; batch adversarial loss: 0.404855\n",
      "epoch 6; iter: 400; batch classifier loss: 0.336869; batch adversarial loss: 0.317471\n",
      "epoch 6; iter: 600; batch classifier loss: 0.251055; batch adversarial loss: 0.432767\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458694; batch adversarial loss: 0.532931\n",
      "epoch 7; iter: 200; batch classifier loss: 0.309516; batch adversarial loss: 0.294231\n",
      "epoch 7; iter: 400; batch classifier loss: 0.449024; batch adversarial loss: 0.412204\n",
      "epoch 7; iter: 600; batch classifier loss: 0.455969; batch adversarial loss: 0.509106\n",
      "epoch 8; iter: 0; batch classifier loss: 0.444196; batch adversarial loss: 0.573090\n",
      "epoch 8; iter: 200; batch classifier loss: 0.365702; batch adversarial loss: 0.500639\n",
      "epoch 8; iter: 400; batch classifier loss: 0.374167; batch adversarial loss: 0.242769\n",
      "epoch 8; iter: 600; batch classifier loss: 0.452654; batch adversarial loss: 0.382641\n",
      "epoch 9; iter: 0; batch classifier loss: 0.429286; batch adversarial loss: 0.476449\n",
      "epoch 9; iter: 200; batch classifier loss: 0.226955; batch adversarial loss: 0.533913\n",
      "epoch 9; iter: 400; batch classifier loss: 0.428637; batch adversarial loss: 0.573987\n",
      "epoch 9; iter: 600; batch classifier loss: 0.361173; batch adversarial loss: 0.407359\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370495; batch adversarial loss: 0.264115\n",
      "epoch 10; iter: 200; batch classifier loss: 0.243014; batch adversarial loss: 0.464326\n",
      "epoch 10; iter: 400; batch classifier loss: 0.397190; batch adversarial loss: 0.490276\n",
      "epoch 10; iter: 600; batch classifier loss: 0.281343; batch adversarial loss: 0.407435\n",
      "epoch 11; iter: 0; batch classifier loss: 0.340234; batch adversarial loss: 0.399473\n",
      "epoch 11; iter: 200; batch classifier loss: 0.297710; batch adversarial loss: 0.493462\n",
      "epoch 11; iter: 400; batch classifier loss: 0.357021; batch adversarial loss: 0.457381\n",
      "epoch 11; iter: 600; batch classifier loss: 0.365804; batch adversarial loss: 0.456718\n",
      "epoch 12; iter: 0; batch classifier loss: 0.316070; batch adversarial loss: 0.424824\n",
      "epoch 12; iter: 200; batch classifier loss: 0.339975; batch adversarial loss: 0.243562\n",
      "epoch 12; iter: 400; batch classifier loss: 0.399469; batch adversarial loss: 0.328901\n",
      "epoch 12; iter: 600; batch classifier loss: 0.349872; batch adversarial loss: 0.435306\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432109; batch adversarial loss: 0.618971\n",
      "epoch 13; iter: 200; batch classifier loss: 0.347857; batch adversarial loss: 0.478475\n",
      "epoch 13; iter: 400; batch classifier loss: 0.333175; batch adversarial loss: 0.401842\n",
      "epoch 13; iter: 600; batch classifier loss: 0.308425; batch adversarial loss: 0.369740\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402094; batch adversarial loss: 0.345292\n",
      "epoch 14; iter: 200; batch classifier loss: 0.520072; batch adversarial loss: 0.277416\n",
      "epoch 14; iter: 400; batch classifier loss: 0.353235; batch adversarial loss: 0.482824\n",
      "epoch 14; iter: 600; batch classifier loss: 0.348155; batch adversarial loss: 0.425598\n",
      "epoch 15; iter: 0; batch classifier loss: 0.277440; batch adversarial loss: 0.522845\n",
      "epoch 15; iter: 200; batch classifier loss: 0.355207; batch adversarial loss: 0.475209\n",
      "epoch 15; iter: 400; batch classifier loss: 0.388471; batch adversarial loss: 0.433635\n",
      "epoch 15; iter: 600; batch classifier loss: 0.323976; batch adversarial loss: 0.391251\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367650; batch adversarial loss: 0.318472\n",
      "epoch 16; iter: 200; batch classifier loss: 0.288662; batch adversarial loss: 0.433802\n",
      "epoch 16; iter: 400; batch classifier loss: 0.402476; batch adversarial loss: 0.486659\n",
      "epoch 16; iter: 600; batch classifier loss: 0.411505; batch adversarial loss: 0.471480\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382477; batch adversarial loss: 0.533353\n",
      "epoch 17; iter: 200; batch classifier loss: 0.309025; batch adversarial loss: 0.361725\n",
      "epoch 17; iter: 400; batch classifier loss: 0.362701; batch adversarial loss: 0.541586\n",
      "epoch 17; iter: 600; batch classifier loss: 0.418174; batch adversarial loss: 0.428223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.363045; batch adversarial loss: 0.383495\n",
      "epoch 18; iter: 200; batch classifier loss: 0.458031; batch adversarial loss: 0.289451\n",
      "epoch 18; iter: 400; batch classifier loss: 0.270223; batch adversarial loss: 0.406531\n",
      "epoch 18; iter: 600; batch classifier loss: 0.332165; batch adversarial loss: 0.519710\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340632; batch adversarial loss: 0.397058\n",
      "epoch 19; iter: 200; batch classifier loss: 0.542607; batch adversarial loss: 0.348004\n",
      "epoch 19; iter: 400; batch classifier loss: 0.315906; batch adversarial loss: 0.453926\n",
      "epoch 19; iter: 600; batch classifier loss: 0.314617; batch adversarial loss: 0.315759\n",
      "epoch 0; iter: 0; batch classifier loss: 30.999468; batch adversarial loss: 0.728756\n",
      "epoch 0; iter: 200; batch classifier loss: 10.129713; batch adversarial loss: 0.628172\n",
      "epoch 0; iter: 400; batch classifier loss: 4.095343; batch adversarial loss: 0.539183\n",
      "epoch 0; iter: 600; batch classifier loss: 11.258793; batch adversarial loss: 0.557444\n",
      "epoch 1; iter: 0; batch classifier loss: 14.041982; batch adversarial loss: 0.554268\n",
      "epoch 1; iter: 200; batch classifier loss: 3.962116; batch adversarial loss: 0.470827\n",
      "epoch 1; iter: 400; batch classifier loss: 7.503453; batch adversarial loss: 0.546347\n",
      "epoch 1; iter: 600; batch classifier loss: 3.471341; batch adversarial loss: 0.370818\n",
      "epoch 2; iter: 0; batch classifier loss: 0.862102; batch adversarial loss: 0.447387\n",
      "epoch 2; iter: 200; batch classifier loss: 1.960876; batch adversarial loss: 0.464857\n",
      "epoch 2; iter: 400; batch classifier loss: 0.390967; batch adversarial loss: 0.495686\n",
      "epoch 2; iter: 600; batch classifier loss: 0.410182; batch adversarial loss: 0.601756\n",
      "epoch 3; iter: 0; batch classifier loss: 2.768495; batch adversarial loss: 0.441649\n",
      "epoch 3; iter: 200; batch classifier loss: 0.420771; batch adversarial loss: 0.376313\n",
      "epoch 3; iter: 400; batch classifier loss: 1.033845; batch adversarial loss: 0.437615\n",
      "epoch 3; iter: 600; batch classifier loss: 1.378454; batch adversarial loss: 0.451250\n",
      "epoch 4; iter: 0; batch classifier loss: 0.988613; batch adversarial loss: 0.367965\n",
      "epoch 4; iter: 200; batch classifier loss: 0.405946; batch adversarial loss: 0.506191\n",
      "epoch 4; iter: 400; batch classifier loss: 1.093967; batch adversarial loss: 0.446160\n",
      "epoch 4; iter: 600; batch classifier loss: 0.777475; batch adversarial loss: 0.421677\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572222; batch adversarial loss: 0.475112\n",
      "epoch 5; iter: 200; batch classifier loss: 0.493764; batch adversarial loss: 0.399737\n",
      "epoch 5; iter: 400; batch classifier loss: 0.347802; batch adversarial loss: 0.575820\n",
      "epoch 5; iter: 600; batch classifier loss: 0.464501; batch adversarial loss: 0.564048\n",
      "epoch 6; iter: 0; batch classifier loss: 0.744316; batch adversarial loss: 0.495156\n",
      "epoch 6; iter: 200; batch classifier loss: 0.305924; batch adversarial loss: 0.466769\n",
      "epoch 6; iter: 400; batch classifier loss: 0.378657; batch adversarial loss: 0.499966\n",
      "epoch 6; iter: 600; batch classifier loss: 0.548453; batch adversarial loss: 0.405450\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372297; batch adversarial loss: 0.546527\n",
      "epoch 7; iter: 200; batch classifier loss: 0.415482; batch adversarial loss: 0.304990\n",
      "epoch 7; iter: 400; batch classifier loss: 0.305687; batch adversarial loss: 0.404722\n",
      "epoch 7; iter: 600; batch classifier loss: 0.728727; batch adversarial loss: 0.396487\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564995; batch adversarial loss: 0.492629\n",
      "epoch 8; iter: 200; batch classifier loss: 0.497444; batch adversarial loss: 0.552521\n",
      "epoch 8; iter: 400; batch classifier loss: 0.467671; batch adversarial loss: 0.409292\n",
      "epoch 8; iter: 600; batch classifier loss: 0.586905; batch adversarial loss: 0.373972\n",
      "epoch 9; iter: 0; batch classifier loss: 0.252428; batch adversarial loss: 0.623459\n",
      "epoch 9; iter: 200; batch classifier loss: 0.378742; batch adversarial loss: 0.424832\n",
      "epoch 9; iter: 400; batch classifier loss: 0.381307; batch adversarial loss: 0.329252\n",
      "epoch 9; iter: 600; batch classifier loss: 0.248139; batch adversarial loss: 0.451945\n",
      "epoch 10; iter: 0; batch classifier loss: 0.373154; batch adversarial loss: 0.478352\n",
      "epoch 10; iter: 200; batch classifier loss: 0.939867; batch adversarial loss: 0.314277\n",
      "epoch 10; iter: 400; batch classifier loss: 0.399928; batch adversarial loss: 0.420388\n",
      "epoch 10; iter: 600; batch classifier loss: 0.342738; batch adversarial loss: 0.433157\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522473; batch adversarial loss: 0.619500\n",
      "epoch 11; iter: 200; batch classifier loss: 0.430345; batch adversarial loss: 0.405408\n",
      "epoch 11; iter: 400; batch classifier loss: 0.285910; batch adversarial loss: 0.570838\n",
      "epoch 11; iter: 600; batch classifier loss: 0.339900; batch adversarial loss: 0.404983\n",
      "epoch 12; iter: 0; batch classifier loss: 0.291820; batch adversarial loss: 0.344455\n",
      "epoch 12; iter: 200; batch classifier loss: 0.301512; batch adversarial loss: 0.350922\n",
      "epoch 12; iter: 400; batch classifier loss: 0.424808; batch adversarial loss: 0.335887\n",
      "epoch 12; iter: 600; batch classifier loss: 0.334364; batch adversarial loss: 0.383219\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324809; batch adversarial loss: 0.478739\n",
      "epoch 13; iter: 200; batch classifier loss: 0.338323; batch adversarial loss: 0.371377\n",
      "epoch 13; iter: 400; batch classifier loss: 0.394398; batch adversarial loss: 0.428484\n",
      "epoch 13; iter: 600; batch classifier loss: 0.290563; batch adversarial loss: 0.429664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394618; batch adversarial loss: 0.396404\n",
      "epoch 14; iter: 200; batch classifier loss: 0.340502; batch adversarial loss: 0.458388\n",
      "epoch 14; iter: 400; batch classifier loss: 0.366794; batch adversarial loss: 0.467625\n",
      "epoch 14; iter: 600; batch classifier loss: 0.403995; batch adversarial loss: 0.496754\n",
      "epoch 15; iter: 0; batch classifier loss: 0.248803; batch adversarial loss: 0.464381\n",
      "epoch 15; iter: 200; batch classifier loss: 0.326284; batch adversarial loss: 0.428604\n",
      "epoch 15; iter: 400; batch classifier loss: 0.346799; batch adversarial loss: 0.236175\n",
      "epoch 15; iter: 600; batch classifier loss: 0.295861; batch adversarial loss: 0.441853\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314953; batch adversarial loss: 0.508927\n",
      "epoch 16; iter: 200; batch classifier loss: 0.241727; batch adversarial loss: 0.578279\n",
      "epoch 16; iter: 400; batch classifier loss: 0.386639; batch adversarial loss: 0.430448\n",
      "epoch 16; iter: 600; batch classifier loss: 0.509827; batch adversarial loss: 0.440806\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424931; batch adversarial loss: 0.377083\n",
      "epoch 17; iter: 200; batch classifier loss: 0.317217; batch adversarial loss: 0.571470\n",
      "epoch 17; iter: 400; batch classifier loss: 0.398318; batch adversarial loss: 0.488182\n",
      "epoch 17; iter: 600; batch classifier loss: 0.347229; batch adversarial loss: 0.434281\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285465; batch adversarial loss: 0.371714\n",
      "epoch 18; iter: 200; batch classifier loss: 0.367623; batch adversarial loss: 0.454725\n",
      "epoch 18; iter: 400; batch classifier loss: 0.455778; batch adversarial loss: 0.317426\n",
      "epoch 18; iter: 600; batch classifier loss: 0.345390; batch adversarial loss: 0.424698\n",
      "epoch 19; iter: 0; batch classifier loss: 0.291212; batch adversarial loss: 0.429039\n",
      "epoch 19; iter: 200; batch classifier loss: 0.361621; batch adversarial loss: 0.458398\n",
      "epoch 19; iter: 400; batch classifier loss: 0.307522; batch adversarial loss: 0.448452\n",
      "epoch 19; iter: 600; batch classifier loss: 0.352998; batch adversarial loss: 0.346379\n",
      "epoch 0; iter: 0; batch classifier loss: 22.838078; batch adversarial loss: 0.688192\n",
      "epoch 0; iter: 200; batch classifier loss: 27.318830; batch adversarial loss: 0.602854\n",
      "epoch 0; iter: 400; batch classifier loss: 2.856195; batch adversarial loss: 0.510921\n",
      "epoch 0; iter: 600; batch classifier loss: 9.469766; batch adversarial loss: 0.514610\n",
      "epoch 1; iter: 0; batch classifier loss: 11.177057; batch adversarial loss: 0.536740\n",
      "epoch 1; iter: 200; batch classifier loss: 3.996980; batch adversarial loss: 0.471014\n",
      "epoch 1; iter: 400; batch classifier loss: 0.368417; batch adversarial loss: 0.403364\n",
      "epoch 1; iter: 600; batch classifier loss: 1.001421; batch adversarial loss: 0.537942\n",
      "epoch 2; iter: 0; batch classifier loss: 0.635650; batch adversarial loss: 0.403899\n",
      "epoch 2; iter: 200; batch classifier loss: 5.265380; batch adversarial loss: 0.364786\n",
      "epoch 2; iter: 400; batch classifier loss: 0.754674; batch adversarial loss: 0.445914\n",
      "epoch 2; iter: 600; batch classifier loss: 1.526052; batch adversarial loss: 0.368559\n",
      "epoch 3; iter: 0; batch classifier loss: 0.280277; batch adversarial loss: 0.418974\n",
      "epoch 3; iter: 200; batch classifier loss: 2.198983; batch adversarial loss: 0.546857\n",
      "epoch 3; iter: 400; batch classifier loss: 0.280382; batch adversarial loss: 0.480181\n",
      "epoch 3; iter: 600; batch classifier loss: 0.291202; batch adversarial loss: 0.348833\n",
      "epoch 4; iter: 0; batch classifier loss: 1.467564; batch adversarial loss: 0.339515\n",
      "epoch 4; iter: 200; batch classifier loss: 0.850765; batch adversarial loss: 0.369959\n",
      "epoch 4; iter: 400; batch classifier loss: 0.406810; batch adversarial loss: 0.421827\n",
      "epoch 4; iter: 600; batch classifier loss: 0.824104; batch adversarial loss: 0.397611\n",
      "epoch 5; iter: 0; batch classifier loss: 0.358479; batch adversarial loss: 0.503936\n",
      "epoch 5; iter: 200; batch classifier loss: 0.552252; batch adversarial loss: 0.327491\n",
      "epoch 5; iter: 400; batch classifier loss: 0.735632; batch adversarial loss: 0.470864\n",
      "epoch 5; iter: 600; batch classifier loss: 0.410367; batch adversarial loss: 0.575683\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512251; batch adversarial loss: 0.328907\n",
      "epoch 6; iter: 200; batch classifier loss: 0.372805; batch adversarial loss: 0.402617\n",
      "epoch 6; iter: 400; batch classifier loss: 0.393300; batch adversarial loss: 0.430877\n",
      "epoch 6; iter: 600; batch classifier loss: 0.381734; batch adversarial loss: 0.367974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.274421; batch adversarial loss: 0.396493\n",
      "epoch 7; iter: 200; batch classifier loss: 0.357132; batch adversarial loss: 0.429571\n",
      "epoch 7; iter: 400; batch classifier loss: 0.436518; batch adversarial loss: 0.370380\n",
      "epoch 7; iter: 600; batch classifier loss: 0.386773; batch adversarial loss: 0.423866\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321145; batch adversarial loss: 0.445914\n",
      "epoch 8; iter: 200; batch classifier loss: 0.437106; batch adversarial loss: 0.484952\n",
      "epoch 8; iter: 400; batch classifier loss: 0.479730; batch adversarial loss: 0.328304\n",
      "epoch 8; iter: 600; batch classifier loss: 0.321475; batch adversarial loss: 0.465734\n",
      "epoch 9; iter: 0; batch classifier loss: 0.411251; batch adversarial loss: 0.293175\n",
      "epoch 9; iter: 200; batch classifier loss: 0.322059; batch adversarial loss: 0.404571\n",
      "epoch 9; iter: 400; batch classifier loss: 0.545417; batch adversarial loss: 0.372411\n",
      "epoch 9; iter: 600; batch classifier loss: 0.288861; batch adversarial loss: 0.434240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.281050; batch adversarial loss: 0.500127\n",
      "epoch 10; iter: 200; batch classifier loss: 0.357750; batch adversarial loss: 0.344748\n",
      "epoch 10; iter: 400; batch classifier loss: 0.211032; batch adversarial loss: 0.367735\n",
      "epoch 10; iter: 600; batch classifier loss: 0.205618; batch adversarial loss: 0.399359\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527516; batch adversarial loss: 0.296670\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383082; batch adversarial loss: 0.409749\n",
      "epoch 11; iter: 400; batch classifier loss: 0.407954; batch adversarial loss: 0.519567\n",
      "epoch 11; iter: 600; batch classifier loss: 0.363947; batch adversarial loss: 0.322509\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327862; batch adversarial loss: 0.292144\n",
      "epoch 12; iter: 200; batch classifier loss: 0.339211; batch adversarial loss: 0.435796\n",
      "epoch 12; iter: 400; batch classifier loss: 0.262991; batch adversarial loss: 0.276771\n",
      "epoch 12; iter: 600; batch classifier loss: 0.269140; batch adversarial loss: 0.385854\n",
      "epoch 13; iter: 0; batch classifier loss: 0.362718; batch adversarial loss: 0.439375\n",
      "epoch 13; iter: 200; batch classifier loss: 0.286686; batch adversarial loss: 0.393630\n",
      "epoch 13; iter: 400; batch classifier loss: 0.264095; batch adversarial loss: 0.597951\n",
      "epoch 13; iter: 600; batch classifier loss: 0.413642; batch adversarial loss: 0.242484\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409767; batch adversarial loss: 0.394991\n",
      "epoch 14; iter: 200; batch classifier loss: 0.336290; batch adversarial loss: 0.483830\n",
      "epoch 14; iter: 400; batch classifier loss: 0.362188; batch adversarial loss: 0.344162\n",
      "epoch 14; iter: 600; batch classifier loss: 0.305906; batch adversarial loss: 0.317421\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375003; batch adversarial loss: 0.287125\n",
      "epoch 15; iter: 200; batch classifier loss: 0.375188; batch adversarial loss: 0.512134\n",
      "epoch 15; iter: 400; batch classifier loss: 0.351192; batch adversarial loss: 0.407826\n",
      "epoch 15; iter: 600; batch classifier loss: 0.381737; batch adversarial loss: 0.274313\n",
      "epoch 16; iter: 0; batch classifier loss: 0.410369; batch adversarial loss: 0.412217\n",
      "epoch 16; iter: 200; batch classifier loss: 0.366795; batch adversarial loss: 0.426256\n",
      "epoch 16; iter: 400; batch classifier loss: 0.292174; batch adversarial loss: 0.435491\n",
      "epoch 16; iter: 600; batch classifier loss: 0.562785; batch adversarial loss: 0.449852\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294075; batch adversarial loss: 0.378013\n",
      "epoch 17; iter: 200; batch classifier loss: 0.378327; batch adversarial loss: 0.372530\n",
      "epoch 17; iter: 400; batch classifier loss: 0.500238; batch adversarial loss: 0.323975\n",
      "epoch 17; iter: 600; batch classifier loss: 0.338474; batch adversarial loss: 0.420347\n",
      "epoch 18; iter: 0; batch classifier loss: 0.357774; batch adversarial loss: 0.369228\n",
      "epoch 18; iter: 200; batch classifier loss: 0.276782; batch adversarial loss: 0.487352\n",
      "epoch 18; iter: 400; batch classifier loss: 0.416767; batch adversarial loss: 0.367803\n",
      "epoch 18; iter: 600; batch classifier loss: 0.283170; batch adversarial loss: 0.454626\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424158; batch adversarial loss: 0.400709\n",
      "epoch 19; iter: 200; batch classifier loss: 0.508613; batch adversarial loss: 0.397170\n",
      "epoch 19; iter: 400; batch classifier loss: 0.422440; batch adversarial loss: 0.346424\n",
      "epoch 19; iter: 600; batch classifier loss: 0.366044; batch adversarial loss: 0.296118\n",
      "epoch 0; iter: 0; batch classifier loss: 313.238556; batch adversarial loss: 0.686676\n",
      "epoch 0; iter: 200; batch classifier loss: 25.230328; batch adversarial loss: 0.643095\n",
      "epoch 0; iter: 400; batch classifier loss: 5.629603; batch adversarial loss: 0.548300\n",
      "epoch 0; iter: 600; batch classifier loss: 24.203697; batch adversarial loss: 0.514351\n",
      "epoch 1; iter: 0; batch classifier loss: 4.178288; batch adversarial loss: 0.554531\n",
      "epoch 1; iter: 200; batch classifier loss: 12.482777; batch adversarial loss: 0.476097\n",
      "epoch 1; iter: 400; batch classifier loss: 8.789104; batch adversarial loss: 0.410139\n",
      "epoch 1; iter: 600; batch classifier loss: 3.539118; batch adversarial loss: 0.506830\n",
      "epoch 2; iter: 0; batch classifier loss: 5.163744; batch adversarial loss: 0.461688\n",
      "epoch 2; iter: 200; batch classifier loss: 0.812634; batch adversarial loss: 0.358310\n",
      "epoch 2; iter: 400; batch classifier loss: 0.829360; batch adversarial loss: 0.427703\n",
      "epoch 2; iter: 600; batch classifier loss: 0.942211; batch adversarial loss: 0.392755\n",
      "epoch 3; iter: 0; batch classifier loss: 0.666612; batch adversarial loss: 0.519062\n",
      "epoch 3; iter: 200; batch classifier loss: 0.585046; batch adversarial loss: 0.317980\n",
      "epoch 3; iter: 400; batch classifier loss: 0.848701; batch adversarial loss: 0.405561\n",
      "epoch 3; iter: 600; batch classifier loss: 1.189486; batch adversarial loss: 0.416753\n",
      "epoch 4; iter: 0; batch classifier loss: 0.486775; batch adversarial loss: 0.393951\n",
      "epoch 4; iter: 200; batch classifier loss: 1.544819; batch adversarial loss: 0.378902\n",
      "epoch 4; iter: 400; batch classifier loss: 0.696700; batch adversarial loss: 0.385479\n",
      "epoch 4; iter: 600; batch classifier loss: 0.375630; batch adversarial loss: 0.448890\n",
      "epoch 5; iter: 0; batch classifier loss: 0.690450; batch adversarial loss: 0.391355\n",
      "epoch 5; iter: 200; batch classifier loss: 0.672217; batch adversarial loss: 0.384100\n",
      "epoch 5; iter: 400; batch classifier loss: 0.283871; batch adversarial loss: 0.356649\n",
      "epoch 5; iter: 600; batch classifier loss: 0.662949; batch adversarial loss: 0.323870\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639449; batch adversarial loss: 0.291496\n",
      "epoch 6; iter: 200; batch classifier loss: 0.478754; batch adversarial loss: 0.316717\n",
      "epoch 6; iter: 400; batch classifier loss: 0.484159; batch adversarial loss: 0.455733\n",
      "epoch 6; iter: 600; batch classifier loss: 0.890387; batch adversarial loss: 0.397730\n",
      "epoch 7; iter: 0; batch classifier loss: 0.326257; batch adversarial loss: 0.426568\n",
      "epoch 7; iter: 200; batch classifier loss: 0.745253; batch adversarial loss: 0.373722\n",
      "epoch 7; iter: 400; batch classifier loss: 2.264915; batch adversarial loss: 0.416732\n",
      "epoch 7; iter: 600; batch classifier loss: 0.481805; batch adversarial loss: 0.670114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.386336; batch adversarial loss: 0.350032\n",
      "epoch 8; iter: 200; batch classifier loss: 0.456665; batch adversarial loss: 0.426003\n",
      "epoch 8; iter: 400; batch classifier loss: 0.411257; batch adversarial loss: 0.426584\n",
      "epoch 8; iter: 600; batch classifier loss: 0.399694; batch adversarial loss: 0.367227\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486448; batch adversarial loss: 0.325000\n",
      "epoch 9; iter: 200; batch classifier loss: 0.529387; batch adversarial loss: 0.521526\n",
      "epoch 9; iter: 400; batch classifier loss: 0.395269; batch adversarial loss: 0.348040\n",
      "epoch 9; iter: 600; batch classifier loss: 0.460428; batch adversarial loss: 0.424324\n",
      "epoch 10; iter: 0; batch classifier loss: 0.381484; batch adversarial loss: 0.433777\n",
      "epoch 10; iter: 200; batch classifier loss: 0.345175; batch adversarial loss: 0.450615\n",
      "epoch 10; iter: 400; batch classifier loss: 0.801867; batch adversarial loss: 0.393175\n",
      "epoch 10; iter: 600; batch classifier loss: 0.446308; batch adversarial loss: 0.538257\n",
      "epoch 11; iter: 0; batch classifier loss: 0.325819; batch adversarial loss: 0.413103\n",
      "epoch 11; iter: 200; batch classifier loss: 0.229759; batch adversarial loss: 0.473263\n",
      "epoch 11; iter: 400; batch classifier loss: 0.407183; batch adversarial loss: 0.387353\n",
      "epoch 11; iter: 600; batch classifier loss: 0.428749; batch adversarial loss: 0.428159\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377839; batch adversarial loss: 0.323358\n",
      "epoch 12; iter: 200; batch classifier loss: 0.242625; batch adversarial loss: 0.419486\n",
      "epoch 12; iter: 400; batch classifier loss: 0.315026; batch adversarial loss: 0.398649\n",
      "epoch 12; iter: 600; batch classifier loss: 0.305257; batch adversarial loss: 0.509496\n",
      "epoch 13; iter: 0; batch classifier loss: 0.464413; batch adversarial loss: 0.407547\n",
      "epoch 13; iter: 200; batch classifier loss: 0.342400; batch adversarial loss: 0.478638\n",
      "epoch 13; iter: 400; batch classifier loss: 0.322068; batch adversarial loss: 0.576841\n",
      "epoch 13; iter: 600; batch classifier loss: 0.419474; batch adversarial loss: 0.553930\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343439; batch adversarial loss: 0.376333\n",
      "epoch 14; iter: 200; batch classifier loss: 0.308649; batch adversarial loss: 0.392664\n",
      "epoch 14; iter: 400; batch classifier loss: 0.303495; batch adversarial loss: 0.491423\n",
      "epoch 14; iter: 600; batch classifier loss: 0.265822; batch adversarial loss: 0.506409\n",
      "epoch 15; iter: 0; batch classifier loss: 0.303350; batch adversarial loss: 0.396449\n",
      "epoch 15; iter: 200; batch classifier loss: 0.359027; batch adversarial loss: 0.599572\n",
      "epoch 15; iter: 400; batch classifier loss: 0.308732; batch adversarial loss: 0.372454\n",
      "epoch 15; iter: 600; batch classifier loss: 0.242369; batch adversarial loss: 0.398541\n",
      "epoch 16; iter: 0; batch classifier loss: 0.141247; batch adversarial loss: 0.429780\n",
      "epoch 16; iter: 200; batch classifier loss: 0.336342; batch adversarial loss: 0.432106\n",
      "epoch 16; iter: 400; batch classifier loss: 0.359623; batch adversarial loss: 0.395110\n",
      "epoch 16; iter: 600; batch classifier loss: 0.430307; batch adversarial loss: 0.409128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290169; batch adversarial loss: 0.487716\n",
      "epoch 17; iter: 200; batch classifier loss: 0.538279; batch adversarial loss: 0.515674\n",
      "epoch 17; iter: 400; batch classifier loss: 0.347868; batch adversarial loss: 0.516307\n",
      "epoch 17; iter: 600; batch classifier loss: 0.489162; batch adversarial loss: 0.445692\n",
      "epoch 18; iter: 0; batch classifier loss: 0.312063; batch adversarial loss: 0.292911\n",
      "epoch 18; iter: 200; batch classifier loss: 0.200268; batch adversarial loss: 0.367433\n",
      "epoch 18; iter: 400; batch classifier loss: 0.311334; batch adversarial loss: 0.406707\n",
      "epoch 18; iter: 600; batch classifier loss: 0.359634; batch adversarial loss: 0.465558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.259832; batch adversarial loss: 0.363997\n",
      "epoch 19; iter: 200; batch classifier loss: 0.362828; batch adversarial loss: 0.366853\n",
      "epoch 19; iter: 400; batch classifier loss: 0.360669; batch adversarial loss: 0.483494\n",
      "epoch 19; iter: 600; batch classifier loss: 0.404924; batch adversarial loss: 0.463510\n",
      "epoch 0; iter: 0; batch classifier loss: 17.188553; batch adversarial loss: 0.667058\n",
      "epoch 0; iter: 200; batch classifier loss: 10.202269; batch adversarial loss: 0.553839\n",
      "epoch 0; iter: 400; batch classifier loss: 44.841827; batch adversarial loss: 0.597147\n",
      "epoch 0; iter: 600; batch classifier loss: 6.814643; batch adversarial loss: 0.493027\n",
      "epoch 1; iter: 0; batch classifier loss: 5.453693; batch adversarial loss: 0.488179\n",
      "epoch 1; iter: 200; batch classifier loss: 20.114531; batch adversarial loss: 0.443561\n",
      "epoch 1; iter: 400; batch classifier loss: 9.756977; batch adversarial loss: 0.443207\n",
      "epoch 1; iter: 600; batch classifier loss: 0.863919; batch adversarial loss: 0.441036\n",
      "epoch 2; iter: 0; batch classifier loss: 2.593782; batch adversarial loss: 0.556138\n",
      "epoch 2; iter: 200; batch classifier loss: 1.353316; batch adversarial loss: 0.493508\n",
      "epoch 2; iter: 400; batch classifier loss: 0.792858; batch adversarial loss: 0.431702\n",
      "epoch 2; iter: 600; batch classifier loss: 1.976353; batch adversarial loss: 0.409871\n",
      "epoch 3; iter: 0; batch classifier loss: 1.073805; batch adversarial loss: 0.525313\n",
      "epoch 3; iter: 200; batch classifier loss: 10.848994; batch adversarial loss: 0.543149\n",
      "epoch 3; iter: 400; batch classifier loss: 0.339068; batch adversarial loss: 0.437065\n",
      "epoch 3; iter: 600; batch classifier loss: 0.894223; batch adversarial loss: 0.373207\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559093; batch adversarial loss: 0.438729\n",
      "epoch 4; iter: 200; batch classifier loss: 0.878107; batch adversarial loss: 0.349103\n",
      "epoch 4; iter: 400; batch classifier loss: 0.360203; batch adversarial loss: 0.536588\n",
      "epoch 4; iter: 600; batch classifier loss: 0.509721; batch adversarial loss: 0.510258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568737; batch adversarial loss: 0.508387\n",
      "epoch 5; iter: 200; batch classifier loss: 0.361362; batch adversarial loss: 0.529525\n",
      "epoch 5; iter: 400; batch classifier loss: 0.374208; batch adversarial loss: 0.334368\n",
      "epoch 5; iter: 600; batch classifier loss: 0.683144; batch adversarial loss: 0.351672\n",
      "epoch 6; iter: 0; batch classifier loss: 0.870427; batch adversarial loss: 0.430677\n",
      "epoch 6; iter: 200; batch classifier loss: 0.521986; batch adversarial loss: 0.445306\n",
      "epoch 6; iter: 400; batch classifier loss: 0.578261; batch adversarial loss: 0.356652\n",
      "epoch 6; iter: 600; batch classifier loss: 0.724930; batch adversarial loss: 0.330767\n",
      "epoch 7; iter: 0; batch classifier loss: 0.307899; batch adversarial loss: 0.425845\n",
      "epoch 7; iter: 200; batch classifier loss: 0.812181; batch adversarial loss: 0.330258\n",
      "epoch 7; iter: 400; batch classifier loss: 0.435539; batch adversarial loss: 0.428480\n",
      "epoch 7; iter: 600; batch classifier loss: 0.289163; batch adversarial loss: 0.355183\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302298; batch adversarial loss: 0.419072\n",
      "epoch 8; iter: 200; batch classifier loss: 0.448326; batch adversarial loss: 0.433170\n",
      "epoch 8; iter: 400; batch classifier loss: 0.520409; batch adversarial loss: 0.433962\n",
      "epoch 8; iter: 600; batch classifier loss: 0.360890; batch adversarial loss: 0.558206\n",
      "epoch 9; iter: 0; batch classifier loss: 0.463357; batch adversarial loss: 0.478992\n",
      "epoch 9; iter: 200; batch classifier loss: 0.425620; batch adversarial loss: 0.459515\n",
      "epoch 9; iter: 400; batch classifier loss: 0.277358; batch adversarial loss: 0.325566\n",
      "epoch 9; iter: 600; batch classifier loss: 0.313991; batch adversarial loss: 0.438974\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366533; batch adversarial loss: 0.540866\n",
      "epoch 10; iter: 200; batch classifier loss: 0.406117; batch adversarial loss: 0.380371\n",
      "epoch 10; iter: 400; batch classifier loss: 0.379856; batch adversarial loss: 0.447995\n",
      "epoch 10; iter: 600; batch classifier loss: 0.275463; batch adversarial loss: 0.457431\n",
      "epoch 11; iter: 0; batch classifier loss: 0.397818; batch adversarial loss: 0.395200\n",
      "epoch 11; iter: 200; batch classifier loss: 0.361355; batch adversarial loss: 0.328374\n",
      "epoch 11; iter: 400; batch classifier loss: 0.313570; batch adversarial loss: 0.444246\n",
      "epoch 11; iter: 600; batch classifier loss: 0.390644; batch adversarial loss: 0.541828\n",
      "epoch 12; iter: 0; batch classifier loss: 0.344839; batch adversarial loss: 0.487132\n",
      "epoch 12; iter: 200; batch classifier loss: 0.346455; batch adversarial loss: 0.425095\n",
      "epoch 12; iter: 400; batch classifier loss: 0.381071; batch adversarial loss: 0.500505\n",
      "epoch 12; iter: 600; batch classifier loss: 0.445297; batch adversarial loss: 0.393922\n",
      "epoch 13; iter: 0; batch classifier loss: 0.289301; batch adversarial loss: 0.525444\n",
      "epoch 13; iter: 200; batch classifier loss: 0.362270; batch adversarial loss: 0.291741\n",
      "epoch 13; iter: 400; batch classifier loss: 0.412652; batch adversarial loss: 0.254935\n",
      "epoch 13; iter: 600; batch classifier loss: 0.373353; batch adversarial loss: 0.399285\n",
      "epoch 14; iter: 0; batch classifier loss: 0.400669; batch adversarial loss: 0.422423\n",
      "epoch 14; iter: 200; batch classifier loss: 0.322301; batch adversarial loss: 0.392374\n",
      "epoch 14; iter: 400; batch classifier loss: 0.455092; batch adversarial loss: 0.369308\n",
      "epoch 14; iter: 600; batch classifier loss: 0.422423; batch adversarial loss: 0.338113\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322536; batch adversarial loss: 0.516167\n",
      "epoch 15; iter: 200; batch classifier loss: 0.402744; batch adversarial loss: 0.538008\n",
      "epoch 15; iter: 400; batch classifier loss: 0.419546; batch adversarial loss: 0.424450\n",
      "epoch 15; iter: 600; batch classifier loss: 0.283029; batch adversarial loss: 0.489172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380845; batch adversarial loss: 0.425624\n",
      "epoch 16; iter: 200; batch classifier loss: 0.291831; batch adversarial loss: 0.472170\n",
      "epoch 16; iter: 400; batch classifier loss: 0.345308; batch adversarial loss: 0.452975\n",
      "epoch 16; iter: 600; batch classifier loss: 0.424272; batch adversarial loss: 0.464414\n",
      "epoch 17; iter: 0; batch classifier loss: 0.408547; batch adversarial loss: 0.400611\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381683; batch adversarial loss: 0.456199\n",
      "epoch 17; iter: 400; batch classifier loss: 0.324740; batch adversarial loss: 0.320659\n",
      "epoch 17; iter: 600; batch classifier loss: 0.384729; batch adversarial loss: 0.411704\n",
      "epoch 18; iter: 0; batch classifier loss: 0.324150; batch adversarial loss: 0.560997\n",
      "epoch 18; iter: 200; batch classifier loss: 0.298858; batch adversarial loss: 0.461868\n",
      "epoch 18; iter: 400; batch classifier loss: 0.316106; batch adversarial loss: 0.326149\n",
      "epoch 18; iter: 600; batch classifier loss: 0.289449; batch adversarial loss: 0.292343\n",
      "epoch 19; iter: 0; batch classifier loss: 0.391801; batch adversarial loss: 0.419386\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342633; batch adversarial loss: 0.489265\n",
      "epoch 19; iter: 400; batch classifier loss: 0.404675; batch adversarial loss: 0.402405\n",
      "epoch 19; iter: 600; batch classifier loss: 0.269598; batch adversarial loss: 0.513077\n",
      "epoch 0; iter: 0; batch classifier loss: 25.753183; batch adversarial loss: 0.491345\n",
      "epoch 0; iter: 200; batch classifier loss: 8.122432; batch adversarial loss: 0.614788\n",
      "epoch 0; iter: 400; batch classifier loss: 6.285056; batch adversarial loss: 0.550622\n",
      "epoch 0; iter: 600; batch classifier loss: 7.903285; batch adversarial loss: 0.509980\n",
      "epoch 1; iter: 0; batch classifier loss: 4.083477; batch adversarial loss: 0.461569\n",
      "epoch 1; iter: 200; batch classifier loss: 6.480097; batch adversarial loss: 0.417648\n",
      "epoch 1; iter: 400; batch classifier loss: 2.467296; batch adversarial loss: 0.592546\n",
      "epoch 1; iter: 600; batch classifier loss: 0.495590; batch adversarial loss: 0.475841\n",
      "epoch 2; iter: 0; batch classifier loss: 10.225704; batch adversarial loss: 0.428361\n",
      "epoch 2; iter: 200; batch classifier loss: 1.664024; batch adversarial loss: 0.385123\n",
      "epoch 2; iter: 400; batch classifier loss: 1.289437; batch adversarial loss: 0.363693\n",
      "epoch 2; iter: 600; batch classifier loss: 1.078845; batch adversarial loss: 0.570161\n",
      "epoch 3; iter: 0; batch classifier loss: 7.300568; batch adversarial loss: 0.403941\n",
      "epoch 3; iter: 200; batch classifier loss: 0.717657; batch adversarial loss: 0.398452\n",
      "epoch 3; iter: 400; batch classifier loss: 0.409897; batch adversarial loss: 0.420340\n",
      "epoch 3; iter: 600; batch classifier loss: 0.474404; batch adversarial loss: 0.407313\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390506; batch adversarial loss: 0.394191\n",
      "epoch 4; iter: 200; batch classifier loss: 0.863620; batch adversarial loss: 0.383787\n",
      "epoch 4; iter: 400; batch classifier loss: 0.465105; batch adversarial loss: 0.529086\n",
      "epoch 4; iter: 600; batch classifier loss: 0.247740; batch adversarial loss: 0.384219\n",
      "epoch 5; iter: 0; batch classifier loss: 0.788375; batch adversarial loss: 0.464341\n",
      "epoch 5; iter: 200; batch classifier loss: 0.436525; batch adversarial loss: 0.404877\n",
      "epoch 5; iter: 400; batch classifier loss: 13.508568; batch adversarial loss: 0.475536\n",
      "epoch 5; iter: 600; batch classifier loss: 0.417292; batch adversarial loss: 0.468886\n",
      "epoch 6; iter: 0; batch classifier loss: 0.240859; batch adversarial loss: 0.377537\n",
      "epoch 6; iter: 200; batch classifier loss: 0.713883; batch adversarial loss: 0.299544\n",
      "epoch 6; iter: 400; batch classifier loss: 0.415093; batch adversarial loss: 0.466322\n",
      "epoch 6; iter: 600; batch classifier loss: 0.406188; batch adversarial loss: 0.246392\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362127; batch adversarial loss: 0.360230\n",
      "epoch 7; iter: 200; batch classifier loss: 0.508466; batch adversarial loss: 0.404865\n",
      "epoch 7; iter: 400; batch classifier loss: 0.373681; batch adversarial loss: 0.405982\n",
      "epoch 7; iter: 600; batch classifier loss: 0.449641; batch adversarial loss: 0.428330\n",
      "epoch 8; iter: 0; batch classifier loss: 0.344228; batch adversarial loss: 0.571552\n",
      "epoch 8; iter: 200; batch classifier loss: 0.329700; batch adversarial loss: 0.343565\n",
      "epoch 8; iter: 400; batch classifier loss: 0.403624; batch adversarial loss: 0.453030\n",
      "epoch 8; iter: 600; batch classifier loss: 0.369768; batch adversarial loss: 0.504849\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508217; batch adversarial loss: 0.446656\n",
      "epoch 9; iter: 200; batch classifier loss: 0.917338; batch adversarial loss: 0.348233\n",
      "epoch 9; iter: 400; batch classifier loss: 0.266647; batch adversarial loss: 0.399520\n",
      "epoch 9; iter: 600; batch classifier loss: 0.253806; batch adversarial loss: 0.349700\n",
      "epoch 10; iter: 0; batch classifier loss: 0.336025; batch adversarial loss: 0.390627\n",
      "epoch 10; iter: 200; batch classifier loss: 0.370022; batch adversarial loss: 0.398090\n",
      "epoch 10; iter: 400; batch classifier loss: 0.230774; batch adversarial loss: 0.542148\n",
      "epoch 10; iter: 600; batch classifier loss: 0.470367; batch adversarial loss: 0.452129\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368633; batch adversarial loss: 0.402403\n",
      "epoch 11; iter: 200; batch classifier loss: 0.274672; batch adversarial loss: 0.406669\n",
      "epoch 11; iter: 400; batch classifier loss: 0.548612; batch adversarial loss: 0.525538\n",
      "epoch 11; iter: 600; batch classifier loss: 0.360513; batch adversarial loss: 0.418213\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383766; batch adversarial loss: 0.525715\n",
      "epoch 12; iter: 200; batch classifier loss: 0.295819; batch adversarial loss: 0.377069\n",
      "epoch 12; iter: 400; batch classifier loss: 0.321224; batch adversarial loss: 0.399026\n",
      "epoch 12; iter: 600; batch classifier loss: 0.330676; batch adversarial loss: 0.428164\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432425; batch adversarial loss: 0.496735\n",
      "epoch 13; iter: 200; batch classifier loss: 0.487218; batch adversarial loss: 0.385070\n",
      "epoch 13; iter: 400; batch classifier loss: 0.297587; batch adversarial loss: 0.295506\n",
      "epoch 13; iter: 600; batch classifier loss: 0.732620; batch adversarial loss: 0.504921\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306298; batch adversarial loss: 0.347068\n",
      "epoch 14; iter: 200; batch classifier loss: 0.404622; batch adversarial loss: 0.407076\n",
      "epoch 14; iter: 400; batch classifier loss: 0.246722; batch adversarial loss: 0.369450\n",
      "epoch 14; iter: 600; batch classifier loss: 0.272219; batch adversarial loss: 0.482337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322545; batch adversarial loss: 0.404282\n",
      "epoch 15; iter: 200; batch classifier loss: 0.308937; batch adversarial loss: 0.347022\n",
      "epoch 15; iter: 400; batch classifier loss: 0.380335; batch adversarial loss: 0.354404\n",
      "epoch 15; iter: 600; batch classifier loss: 0.380095; batch adversarial loss: 0.391430\n",
      "epoch 16; iter: 0; batch classifier loss: 0.381658; batch adversarial loss: 0.481905\n",
      "epoch 16; iter: 200; batch classifier loss: 0.318362; batch adversarial loss: 0.457612\n",
      "epoch 16; iter: 400; batch classifier loss: 0.328749; batch adversarial loss: 0.292262\n",
      "epoch 16; iter: 600; batch classifier loss: 0.466126; batch adversarial loss: 0.477468\n",
      "epoch 17; iter: 0; batch classifier loss: 0.399368; batch adversarial loss: 0.291628\n",
      "epoch 17; iter: 200; batch classifier loss: 0.390381; batch adversarial loss: 0.379014\n",
      "epoch 17; iter: 400; batch classifier loss: 0.279425; batch adversarial loss: 0.416018\n",
      "epoch 17; iter: 600; batch classifier loss: 0.314326; batch adversarial loss: 0.345073\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334579; batch adversarial loss: 0.514317\n",
      "epoch 18; iter: 200; batch classifier loss: 0.334474; batch adversarial loss: 0.348662\n",
      "epoch 18; iter: 400; batch classifier loss: 0.210670; batch adversarial loss: 0.399385\n",
      "epoch 18; iter: 600; batch classifier loss: 0.328986; batch adversarial loss: 0.526646\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305368; batch adversarial loss: 0.489966\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385684; batch adversarial loss: 0.458026\n",
      "epoch 19; iter: 400; batch classifier loss: 0.629983; batch adversarial loss: 0.436520\n",
      "epoch 19; iter: 600; batch classifier loss: 0.456579; batch adversarial loss: 0.509194\n",
      "epoch 0; iter: 0; batch classifier loss: 100.921448; batch adversarial loss: 0.693131\n",
      "epoch 0; iter: 200; batch classifier loss: 3.214864; batch adversarial loss: 0.588406\n",
      "epoch 0; iter: 400; batch classifier loss: 10.801960; batch adversarial loss: 0.452084\n",
      "epoch 0; iter: 600; batch classifier loss: 19.990887; batch adversarial loss: 0.486359\n",
      "epoch 1; iter: 0; batch classifier loss: 10.077044; batch adversarial loss: 0.495875\n",
      "epoch 1; iter: 200; batch classifier loss: 8.992620; batch adversarial loss: 0.596684\n",
      "epoch 1; iter: 400; batch classifier loss: 18.399395; batch adversarial loss: 0.492743\n",
      "epoch 1; iter: 600; batch classifier loss: 1.739111; batch adversarial loss: 0.339189\n",
      "epoch 2; iter: 0; batch classifier loss: 2.525011; batch adversarial loss: 0.376950\n",
      "epoch 2; iter: 200; batch classifier loss: 2.673690; batch adversarial loss: 0.376557\n",
      "epoch 2; iter: 400; batch classifier loss: 4.298794; batch adversarial loss: 0.558781\n",
      "epoch 2; iter: 600; batch classifier loss: 0.463839; batch adversarial loss: 0.395327\n",
      "epoch 3; iter: 0; batch classifier loss: 0.685249; batch adversarial loss: 0.467661\n",
      "epoch 3; iter: 200; batch classifier loss: 3.047671; batch adversarial loss: 0.305075\n",
      "epoch 3; iter: 400; batch classifier loss: 0.497818; batch adversarial loss: 0.333364\n",
      "epoch 3; iter: 600; batch classifier loss: 1.949367; batch adversarial loss: 0.444225\n",
      "epoch 4; iter: 0; batch classifier loss: 0.619461; batch adversarial loss: 0.336941\n",
      "epoch 4; iter: 200; batch classifier loss: 0.393806; batch adversarial loss: 0.431483\n",
      "epoch 4; iter: 400; batch classifier loss: 0.208662; batch adversarial loss: 0.467033\n",
      "epoch 4; iter: 600; batch classifier loss: 0.305634; batch adversarial loss: 0.532474\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516630; batch adversarial loss: 0.270557\n",
      "epoch 5; iter: 200; batch classifier loss: 0.465452; batch adversarial loss: 0.528613\n",
      "epoch 5; iter: 400; batch classifier loss: 0.362643; batch adversarial loss: 0.293707\n",
      "epoch 5; iter: 600; batch classifier loss: 0.258824; batch adversarial loss: 0.490276\n",
      "epoch 6; iter: 0; batch classifier loss: 0.879742; batch adversarial loss: 0.248991\n",
      "epoch 6; iter: 200; batch classifier loss: 0.388042; batch adversarial loss: 0.539695\n",
      "epoch 6; iter: 400; batch classifier loss: 0.280997; batch adversarial loss: 0.380112\n",
      "epoch 6; iter: 600; batch classifier loss: 0.396392; batch adversarial loss: 0.369540\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380193; batch adversarial loss: 0.483226\n",
      "epoch 7; iter: 200; batch classifier loss: 0.392211; batch adversarial loss: 0.483279\n",
      "epoch 7; iter: 400; batch classifier loss: 0.351423; batch adversarial loss: 0.379175\n",
      "epoch 7; iter: 600; batch classifier loss: 0.440541; batch adversarial loss: 0.427585\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324677; batch adversarial loss: 0.533496\n",
      "epoch 8; iter: 200; batch classifier loss: 0.292314; batch adversarial loss: 0.551952\n",
      "epoch 8; iter: 400; batch classifier loss: 0.408142; batch adversarial loss: 0.392878\n",
      "epoch 8; iter: 600; batch classifier loss: 0.379123; batch adversarial loss: 0.370461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334592; batch adversarial loss: 0.562294\n",
      "epoch 9; iter: 200; batch classifier loss: 0.500460; batch adversarial loss: 0.397865\n",
      "epoch 9; iter: 400; batch classifier loss: 0.463894; batch adversarial loss: 0.351104\n",
      "epoch 9; iter: 600; batch classifier loss: 0.315347; batch adversarial loss: 0.397566\n",
      "epoch 10; iter: 0; batch classifier loss: 0.265269; batch adversarial loss: 0.411316\n",
      "epoch 10; iter: 200; batch classifier loss: 0.332383; batch adversarial loss: 0.430544\n",
      "epoch 10; iter: 400; batch classifier loss: 0.338814; batch adversarial loss: 0.315721\n",
      "epoch 10; iter: 600; batch classifier loss: 0.201894; batch adversarial loss: 0.385124\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419855; batch adversarial loss: 0.467392\n",
      "epoch 11; iter: 200; batch classifier loss: 0.311871; batch adversarial loss: 0.431523\n",
      "epoch 11; iter: 400; batch classifier loss: 0.505131; batch adversarial loss: 0.243277\n",
      "epoch 11; iter: 600; batch classifier loss: 0.280342; batch adversarial loss: 0.387790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397239; batch adversarial loss: 0.406108\n",
      "epoch 12; iter: 200; batch classifier loss: 0.410163; batch adversarial loss: 0.449219\n",
      "epoch 12; iter: 400; batch classifier loss: 0.289027; batch adversarial loss: 0.290328\n",
      "epoch 12; iter: 600; batch classifier loss: 0.569646; batch adversarial loss: 0.549112\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522950; batch adversarial loss: 0.409927\n",
      "epoch 13; iter: 200; batch classifier loss: 0.245158; batch adversarial loss: 0.437489\n",
      "epoch 13; iter: 400; batch classifier loss: 0.312217; batch adversarial loss: 0.351460\n",
      "epoch 13; iter: 600; batch classifier loss: 0.389404; batch adversarial loss: 0.430348\n",
      "epoch 14; iter: 0; batch classifier loss: 0.262653; batch adversarial loss: 0.473832\n",
      "epoch 14; iter: 200; batch classifier loss: 0.398487; batch adversarial loss: 0.433027\n",
      "epoch 14; iter: 400; batch classifier loss: 0.302486; batch adversarial loss: 0.416786\n",
      "epoch 14; iter: 600; batch classifier loss: 0.260423; batch adversarial loss: 0.425818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.414140; batch adversarial loss: 0.420982\n",
      "epoch 15; iter: 200; batch classifier loss: 0.173026; batch adversarial loss: 0.465399\n",
      "epoch 15; iter: 400; batch classifier loss: 0.326482; batch adversarial loss: 0.430178\n",
      "epoch 15; iter: 600; batch classifier loss: 0.381286; batch adversarial loss: 0.540869\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408622; batch adversarial loss: 0.340791\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357520; batch adversarial loss: 0.404878\n",
      "epoch 16; iter: 400; batch classifier loss: 0.429336; batch adversarial loss: 0.398803\n",
      "epoch 16; iter: 600; batch classifier loss: 0.367648; batch adversarial loss: 0.431721\n",
      "epoch 17; iter: 0; batch classifier loss: 0.413099; batch adversarial loss: 0.466469\n",
      "epoch 17; iter: 200; batch classifier loss: 0.309777; batch adversarial loss: 0.377662\n",
      "epoch 17; iter: 400; batch classifier loss: 0.385702; batch adversarial loss: 0.401677\n",
      "epoch 17; iter: 600; batch classifier loss: 0.401587; batch adversarial loss: 0.437859\n",
      "epoch 18; iter: 0; batch classifier loss: 0.240474; batch adversarial loss: 0.354349\n",
      "epoch 18; iter: 200; batch classifier loss: 0.414178; batch adversarial loss: 0.269447\n",
      "epoch 18; iter: 400; batch classifier loss: 0.405770; batch adversarial loss: 0.345400\n",
      "epoch 18; iter: 600; batch classifier loss: 0.360304; batch adversarial loss: 0.394157\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310389; batch adversarial loss: 0.406119\n",
      "epoch 19; iter: 200; batch classifier loss: 0.394783; batch adversarial loss: 0.464921\n",
      "epoch 19; iter: 400; batch classifier loss: 0.241820; batch adversarial loss: 0.382536\n",
      "epoch 19; iter: 600; batch classifier loss: 0.278443; batch adversarial loss: 0.343364\n",
      "epoch 0; iter: 0; batch classifier loss: 37.606556; batch adversarial loss: 0.580983\n",
      "epoch 0; iter: 200; batch classifier loss: 12.959103; batch adversarial loss: 0.546488\n",
      "epoch 0; iter: 400; batch classifier loss: 4.463470; batch adversarial loss: 0.542936\n",
      "epoch 0; iter: 600; batch classifier loss: 5.151679; batch adversarial loss: 0.531200\n",
      "epoch 1; iter: 0; batch classifier loss: 9.259171; batch adversarial loss: 0.535878\n",
      "epoch 1; iter: 200; batch classifier loss: 1.236575; batch adversarial loss: 0.489785\n",
      "epoch 1; iter: 400; batch classifier loss: 7.432834; batch adversarial loss: 0.485999\n",
      "epoch 1; iter: 600; batch classifier loss: 0.772524; batch adversarial loss: 0.479581\n",
      "epoch 2; iter: 0; batch classifier loss: 2.420862; batch adversarial loss: 0.450714\n",
      "epoch 2; iter: 200; batch classifier loss: 2.540545; batch adversarial loss: 0.445511\n",
      "epoch 2; iter: 400; batch classifier loss: 7.035312; batch adversarial loss: 0.371881\n",
      "epoch 2; iter: 600; batch classifier loss: 0.541698; batch adversarial loss: 0.350055\n",
      "epoch 3; iter: 0; batch classifier loss: 0.812338; batch adversarial loss: 0.387310\n",
      "epoch 3; iter: 200; batch classifier loss: 0.892160; batch adversarial loss: 0.438546\n",
      "epoch 3; iter: 400; batch classifier loss: 1.194885; batch adversarial loss: 0.279461\n",
      "epoch 3; iter: 600; batch classifier loss: 0.622936; batch adversarial loss: 0.425170\n",
      "epoch 4; iter: 0; batch classifier loss: 1.117147; batch adversarial loss: 0.338745\n",
      "epoch 4; iter: 200; batch classifier loss: 1.371994; batch adversarial loss: 0.305648\n",
      "epoch 4; iter: 400; batch classifier loss: 0.788315; batch adversarial loss: 0.534878\n",
      "epoch 4; iter: 600; batch classifier loss: 0.836319; batch adversarial loss: 0.736646\n",
      "epoch 5; iter: 0; batch classifier loss: 0.431633; batch adversarial loss: 0.473237\n",
      "epoch 5; iter: 200; batch classifier loss: 0.261074; batch adversarial loss: 0.417480\n",
      "epoch 5; iter: 400; batch classifier loss: 2.035339; batch adversarial loss: 0.349620\n",
      "epoch 5; iter: 600; batch classifier loss: 0.256931; batch adversarial loss: 0.449484\n",
      "epoch 6; iter: 0; batch classifier loss: 0.465691; batch adversarial loss: 0.321426\n",
      "epoch 6; iter: 200; batch classifier loss: 0.362415; batch adversarial loss: 0.298494\n",
      "epoch 6; iter: 400; batch classifier loss: 0.325860; batch adversarial loss: 0.378069\n",
      "epoch 6; iter: 600; batch classifier loss: 0.692344; batch adversarial loss: 0.363250\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547256; batch adversarial loss: 0.269706\n",
      "epoch 7; iter: 200; batch classifier loss: 0.549335; batch adversarial loss: 0.350512\n",
      "epoch 7; iter: 400; batch classifier loss: 0.291611; batch adversarial loss: 0.403811\n",
      "epoch 7; iter: 600; batch classifier loss: 0.370582; batch adversarial loss: 0.490573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.382686; batch adversarial loss: 0.352496\n",
      "epoch 8; iter: 200; batch classifier loss: 0.440114; batch adversarial loss: 0.423250\n",
      "epoch 8; iter: 400; batch classifier loss: 0.307472; batch adversarial loss: 0.291102\n",
      "epoch 8; iter: 600; batch classifier loss: 0.292785; batch adversarial loss: 0.374476\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335410; batch adversarial loss: 0.305512\n",
      "epoch 9; iter: 200; batch classifier loss: 0.455550; batch adversarial loss: 0.374668\n",
      "epoch 9; iter: 400; batch classifier loss: 0.312028; batch adversarial loss: 0.531259\n",
      "epoch 9; iter: 600; batch classifier loss: 0.323429; batch adversarial loss: 0.536284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.352715; batch adversarial loss: 0.507117\n",
      "epoch 10; iter: 200; batch classifier loss: 0.312879; batch adversarial loss: 0.617806\n",
      "epoch 10; iter: 400; batch classifier loss: 0.804484; batch adversarial loss: 0.523451\n",
      "epoch 10; iter: 600; batch classifier loss: 0.244109; batch adversarial loss: 0.402638\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323646; batch adversarial loss: 0.293573\n",
      "epoch 11; iter: 200; batch classifier loss: 0.273818; batch adversarial loss: 0.436232\n",
      "epoch 11; iter: 400; batch classifier loss: 0.428409; batch adversarial loss: 0.504094\n",
      "epoch 11; iter: 600; batch classifier loss: 0.318753; batch adversarial loss: 0.374875\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253409; batch adversarial loss: 0.291486\n",
      "epoch 12; iter: 200; batch classifier loss: 0.291903; batch adversarial loss: 0.429196\n",
      "epoch 12; iter: 400; batch classifier loss: 0.300752; batch adversarial loss: 0.347085\n",
      "epoch 12; iter: 600; batch classifier loss: 0.342053; batch adversarial loss: 0.348723\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383241; batch adversarial loss: 0.448212\n",
      "epoch 13; iter: 200; batch classifier loss: 0.340995; batch adversarial loss: 0.548947\n",
      "epoch 13; iter: 400; batch classifier loss: 0.258275; batch adversarial loss: 0.408514\n",
      "epoch 13; iter: 600; batch classifier loss: 0.396225; batch adversarial loss: 0.444159\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487601; batch adversarial loss: 0.438249\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416811; batch adversarial loss: 0.469394\n",
      "epoch 14; iter: 400; batch classifier loss: 0.296365; batch adversarial loss: 0.377327\n",
      "epoch 14; iter: 600; batch classifier loss: 0.392923; batch adversarial loss: 0.401209\n",
      "epoch 15; iter: 0; batch classifier loss: 0.230880; batch adversarial loss: 0.438752\n",
      "epoch 15; iter: 200; batch classifier loss: 0.384945; batch adversarial loss: 0.411374\n",
      "epoch 15; iter: 400; batch classifier loss: 0.214186; batch adversarial loss: 0.441049\n",
      "epoch 15; iter: 600; batch classifier loss: 0.362855; batch adversarial loss: 0.529252\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414635; batch adversarial loss: 0.450898\n",
      "epoch 16; iter: 200; batch classifier loss: 0.285514; batch adversarial loss: 0.347685\n",
      "epoch 16; iter: 400; batch classifier loss: 0.277532; batch adversarial loss: 0.425893\n",
      "epoch 16; iter: 600; batch classifier loss: 0.269119; batch adversarial loss: 0.316074\n",
      "epoch 17; iter: 0; batch classifier loss: 0.291819; batch adversarial loss: 0.433428\n",
      "epoch 17; iter: 200; batch classifier loss: 0.300953; batch adversarial loss: 0.290089\n",
      "epoch 17; iter: 400; batch classifier loss: 0.242397; batch adversarial loss: 0.575337\n",
      "epoch 17; iter: 600; batch classifier loss: 0.239524; batch adversarial loss: 0.374849\n",
      "epoch 18; iter: 0; batch classifier loss: 0.297338; batch adversarial loss: 0.429923\n",
      "epoch 18; iter: 200; batch classifier loss: 0.451027; batch adversarial loss: 0.400734\n",
      "epoch 18; iter: 400; batch classifier loss: 0.279632; batch adversarial loss: 0.419692\n",
      "epoch 18; iter: 600; batch classifier loss: 0.282739; batch adversarial loss: 0.469059\n",
      "epoch 19; iter: 0; batch classifier loss: 0.330748; batch adversarial loss: 0.370723\n",
      "epoch 19; iter: 200; batch classifier loss: 0.383802; batch adversarial loss: 0.265557\n",
      "epoch 19; iter: 400; batch classifier loss: 0.369939; batch adversarial loss: 0.374122\n",
      "epoch 19; iter: 600; batch classifier loss: 0.381398; batch adversarial loss: 0.449629\n",
      "epoch 0; iter: 0; batch classifier loss: 40.589844; batch adversarial loss: 0.756954\n",
      "epoch 0; iter: 200; batch classifier loss: 3.505904; batch adversarial loss: 0.614273\n",
      "epoch 0; iter: 400; batch classifier loss: 19.168983; batch adversarial loss: 0.559474\n",
      "epoch 0; iter: 600; batch classifier loss: 9.986921; batch adversarial loss: 0.463577\n",
      "epoch 1; iter: 0; batch classifier loss: 2.643359; batch adversarial loss: 0.520137\n",
      "epoch 1; iter: 200; batch classifier loss: 1.511429; batch adversarial loss: 0.461545\n",
      "epoch 1; iter: 400; batch classifier loss: 1.979487; batch adversarial loss: 0.468371\n",
      "epoch 1; iter: 600; batch classifier loss: 0.366262; batch adversarial loss: 0.498574\n",
      "epoch 2; iter: 0; batch classifier loss: 0.764280; batch adversarial loss: 0.507162\n",
      "epoch 2; iter: 200; batch classifier loss: 3.864572; batch adversarial loss: 0.558500\n",
      "epoch 2; iter: 400; batch classifier loss: 0.672946; batch adversarial loss: 0.350261\n",
      "epoch 2; iter: 600; batch classifier loss: 0.349181; batch adversarial loss: 0.382212\n",
      "epoch 3; iter: 0; batch classifier loss: 0.608108; batch adversarial loss: 0.488476\n",
      "epoch 3; iter: 200; batch classifier loss: 0.931969; batch adversarial loss: 0.339188\n",
      "epoch 3; iter: 400; batch classifier loss: 0.527006; batch adversarial loss: 0.336563\n",
      "epoch 3; iter: 600; batch classifier loss: 0.923895; batch adversarial loss: 0.512462\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579912; batch adversarial loss: 0.447291\n",
      "epoch 4; iter: 200; batch classifier loss: 0.561249; batch adversarial loss: 0.404685\n",
      "epoch 4; iter: 400; batch classifier loss: 0.400367; batch adversarial loss: 0.531644\n",
      "epoch 4; iter: 600; batch classifier loss: 0.795759; batch adversarial loss: 0.378517\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582818; batch adversarial loss: 0.460056\n",
      "epoch 5; iter: 200; batch classifier loss: 0.366013; batch adversarial loss: 0.361015\n",
      "epoch 5; iter: 400; batch classifier loss: 0.458660; batch adversarial loss: 0.625013\n",
      "epoch 5; iter: 600; batch classifier loss: 0.739807; batch adversarial loss: 0.505194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.339477; batch adversarial loss: 0.416920\n",
      "epoch 6; iter: 200; batch classifier loss: 0.300666; batch adversarial loss: 0.386653\n",
      "epoch 6; iter: 400; batch classifier loss: 0.509139; batch adversarial loss: 0.438099\n",
      "epoch 6; iter: 600; batch classifier loss: 0.369548; batch adversarial loss: 0.387426\n",
      "epoch 7; iter: 0; batch classifier loss: 0.329449; batch adversarial loss: 0.349924\n",
      "epoch 7; iter: 200; batch classifier loss: 0.526928; batch adversarial loss: 0.325102\n",
      "epoch 7; iter: 400; batch classifier loss: 0.269528; batch adversarial loss: 0.473771\n",
      "epoch 7; iter: 600; batch classifier loss: 0.430664; batch adversarial loss: 0.252868\n",
      "epoch 8; iter: 0; batch classifier loss: 0.279342; batch adversarial loss: 0.460951\n",
      "epoch 8; iter: 200; batch classifier loss: 0.327857; batch adversarial loss: 0.285247\n",
      "epoch 8; iter: 400; batch classifier loss: 0.469213; batch adversarial loss: 0.382828\n",
      "epoch 8; iter: 600; batch classifier loss: 0.291856; batch adversarial loss: 0.485022\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364112; batch adversarial loss: 0.272411\n",
      "epoch 9; iter: 200; batch classifier loss: 0.300434; batch adversarial loss: 0.433277\n",
      "epoch 9; iter: 400; batch classifier loss: 0.289892; batch adversarial loss: 0.579879\n",
      "epoch 9; iter: 600; batch classifier loss: 0.342503; batch adversarial loss: 0.316706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.323298; batch adversarial loss: 0.399098\n",
      "epoch 10; iter: 200; batch classifier loss: 0.278629; batch adversarial loss: 0.536714\n",
      "epoch 10; iter: 400; batch classifier loss: 0.310558; batch adversarial loss: 0.413098\n",
      "epoch 10; iter: 600; batch classifier loss: 0.320639; batch adversarial loss: 0.675235\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472768; batch adversarial loss: 0.384193\n",
      "epoch 11; iter: 200; batch classifier loss: 0.156090; batch adversarial loss: 0.479401\n",
      "epoch 11; iter: 400; batch classifier loss: 0.360018; batch adversarial loss: 0.361805\n",
      "epoch 11; iter: 600; batch classifier loss: 0.340359; batch adversarial loss: 0.380703\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463210; batch adversarial loss: 0.454770\n",
      "epoch 12; iter: 200; batch classifier loss: 0.376115; batch adversarial loss: 0.530568\n",
      "epoch 12; iter: 400; batch classifier loss: 0.462002; batch adversarial loss: 0.473515\n",
      "epoch 12; iter: 600; batch classifier loss: 0.491639; batch adversarial loss: 0.354127\n",
      "epoch 13; iter: 0; batch classifier loss: 0.375026; batch adversarial loss: 0.383631\n",
      "epoch 13; iter: 200; batch classifier loss: 0.302121; batch adversarial loss: 0.371355\n",
      "epoch 13; iter: 400; batch classifier loss: 0.354941; batch adversarial loss: 0.407262\n",
      "epoch 13; iter: 600; batch classifier loss: 0.351547; batch adversarial loss: 0.408540\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344717; batch adversarial loss: 0.298996\n",
      "epoch 14; iter: 200; batch classifier loss: 0.296663; batch adversarial loss: 0.431161\n",
      "epoch 14; iter: 400; batch classifier loss: 0.286497; batch adversarial loss: 0.406095\n",
      "epoch 14; iter: 600; batch classifier loss: 0.404062; batch adversarial loss: 0.346814\n",
      "epoch 15; iter: 0; batch classifier loss: 0.339380; batch adversarial loss: 0.660556\n",
      "epoch 15; iter: 200; batch classifier loss: 0.271898; batch adversarial loss: 0.515078\n",
      "epoch 15; iter: 400; batch classifier loss: 0.320312; batch adversarial loss: 0.379442\n",
      "epoch 15; iter: 600; batch classifier loss: 0.241305; batch adversarial loss: 0.370291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506963; batch adversarial loss: 0.288550\n",
      "epoch 16; iter: 200; batch classifier loss: 0.272750; batch adversarial loss: 0.434343\n",
      "epoch 16; iter: 400; batch classifier loss: 0.496251; batch adversarial loss: 0.429339\n",
      "epoch 16; iter: 600; batch classifier loss: 0.327454; batch adversarial loss: 0.475339\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346824; batch adversarial loss: 0.435968\n",
      "epoch 17; iter: 200; batch classifier loss: 0.453384; batch adversarial loss: 0.289476\n",
      "epoch 17; iter: 400; batch classifier loss: 0.327484; batch adversarial loss: 0.482569\n",
      "epoch 17; iter: 600; batch classifier loss: 0.243421; batch adversarial loss: 0.476070\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258461; batch adversarial loss: 0.398530\n",
      "epoch 18; iter: 200; batch classifier loss: 0.271577; batch adversarial loss: 0.479357\n",
      "epoch 18; iter: 400; batch classifier loss: 0.429236; batch adversarial loss: 0.264002\n",
      "epoch 18; iter: 600; batch classifier loss: 0.342104; batch adversarial loss: 0.480075\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305453; batch adversarial loss: 0.460230\n",
      "epoch 19; iter: 200; batch classifier loss: 0.494201; batch adversarial loss: 0.416604\n",
      "epoch 19; iter: 400; batch classifier loss: 0.455642; batch adversarial loss: 0.370511\n",
      "epoch 19; iter: 600; batch classifier loss: 0.334385; batch adversarial loss: 0.321578\n",
      "epoch 0; iter: 0; batch classifier loss: 5.270189; batch adversarial loss: 0.610778\n",
      "epoch 0; iter: 200; batch classifier loss: 1.920233; batch adversarial loss: 0.583218\n",
      "epoch 0; iter: 400; batch classifier loss: 3.429392; batch adversarial loss: 0.518907\n",
      "epoch 0; iter: 600; batch classifier loss: 1.038355; batch adversarial loss: 0.472813\n",
      "epoch 1; iter: 0; batch classifier loss: 5.250728; batch adversarial loss: 0.545301\n",
      "epoch 1; iter: 200; batch classifier loss: 16.737471; batch adversarial loss: 0.465925\n",
      "epoch 1; iter: 400; batch classifier loss: 5.466173; batch adversarial loss: 0.555319\n",
      "epoch 1; iter: 600; batch classifier loss: 4.556816; batch adversarial loss: 0.608751\n",
      "epoch 2; iter: 0; batch classifier loss: 0.784572; batch adversarial loss: 0.514787\n",
      "epoch 2; iter: 200; batch classifier loss: 4.376026; batch adversarial loss: 0.408078\n",
      "epoch 2; iter: 400; batch classifier loss: 0.766249; batch adversarial loss: 0.363965\n",
      "epoch 2; iter: 600; batch classifier loss: 0.371434; batch adversarial loss: 0.418867\n",
      "epoch 3; iter: 0; batch classifier loss: 1.447465; batch adversarial loss: 0.418149\n",
      "epoch 3; iter: 200; batch classifier loss: 0.883895; batch adversarial loss: 0.283015\n",
      "epoch 3; iter: 400; batch classifier loss: 1.159541; batch adversarial loss: 0.451756\n",
      "epoch 3; iter: 600; batch classifier loss: 0.789377; batch adversarial loss: 0.420436\n",
      "epoch 4; iter: 0; batch classifier loss: 1.551702; batch adversarial loss: 0.517768\n",
      "epoch 4; iter: 200; batch classifier loss: 1.228724; batch adversarial loss: 0.437417\n",
      "epoch 4; iter: 400; batch classifier loss: 0.978875; batch adversarial loss: 0.412682\n",
      "epoch 4; iter: 600; batch classifier loss: 0.340743; batch adversarial loss: 0.368208\n",
      "epoch 5; iter: 0; batch classifier loss: 0.314292; batch adversarial loss: 0.335189\n",
      "epoch 5; iter: 200; batch classifier loss: 0.311106; batch adversarial loss: 0.475429\n",
      "epoch 5; iter: 400; batch classifier loss: 0.365141; batch adversarial loss: 0.484947\n",
      "epoch 5; iter: 600; batch classifier loss: 0.476575; batch adversarial loss: 0.379059\n",
      "epoch 6; iter: 0; batch classifier loss: 0.481237; batch adversarial loss: 0.428480\n",
      "epoch 6; iter: 200; batch classifier loss: 0.412627; batch adversarial loss: 0.427011\n",
      "epoch 6; iter: 400; batch classifier loss: 0.323894; batch adversarial loss: 0.426744\n",
      "epoch 6; iter: 600; batch classifier loss: 0.345882; batch adversarial loss: 0.557763\n",
      "epoch 7; iter: 0; batch classifier loss: 0.366306; batch adversarial loss: 0.375562\n",
      "epoch 7; iter: 200; batch classifier loss: 0.270981; batch adversarial loss: 0.614682\n",
      "epoch 7; iter: 400; batch classifier loss: 0.353389; batch adversarial loss: 0.346744\n",
      "epoch 7; iter: 600; batch classifier loss: 0.428184; batch adversarial loss: 0.407383\n",
      "epoch 8; iter: 0; batch classifier loss: 0.375239; batch adversarial loss: 0.374400\n",
      "epoch 8; iter: 200; batch classifier loss: 0.383002; batch adversarial loss: 0.324081\n",
      "epoch 8; iter: 400; batch classifier loss: 0.629534; batch adversarial loss: 0.508631\n",
      "epoch 8; iter: 600; batch classifier loss: 0.378560; batch adversarial loss: 0.346870\n",
      "epoch 9; iter: 0; batch classifier loss: 0.309539; batch adversarial loss: 0.344006\n",
      "epoch 9; iter: 200; batch classifier loss: 0.593694; batch adversarial loss: 0.347190\n",
      "epoch 9; iter: 400; batch classifier loss: 0.389232; batch adversarial loss: 0.214084\n",
      "epoch 9; iter: 600; batch classifier loss: 0.345398; batch adversarial loss: 0.349306\n",
      "epoch 10; iter: 0; batch classifier loss: 0.306754; batch adversarial loss: 0.349638\n",
      "epoch 10; iter: 200; batch classifier loss: 0.495076; batch adversarial loss: 0.498178\n",
      "epoch 10; iter: 400; batch classifier loss: 0.390858; batch adversarial loss: 0.328203\n",
      "epoch 10; iter: 600; batch classifier loss: 0.388017; batch adversarial loss: 0.399435\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366490; batch adversarial loss: 0.467430\n",
      "epoch 11; iter: 200; batch classifier loss: 0.403594; batch adversarial loss: 0.318338\n",
      "epoch 11; iter: 400; batch classifier loss: 0.284633; batch adversarial loss: 0.504131\n",
      "epoch 11; iter: 600; batch classifier loss: 0.340215; batch adversarial loss: 0.426683\n",
      "epoch 12; iter: 0; batch classifier loss: 0.330540; batch adversarial loss: 0.399024\n",
      "epoch 12; iter: 200; batch classifier loss: 0.377263; batch adversarial loss: 0.348540\n",
      "epoch 12; iter: 400; batch classifier loss: 0.314863; batch adversarial loss: 0.360901\n",
      "epoch 12; iter: 600; batch classifier loss: 0.355746; batch adversarial loss: 0.346827\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472384; batch adversarial loss: 0.352036\n",
      "epoch 13; iter: 200; batch classifier loss: 0.231128; batch adversarial loss: 0.397387\n",
      "epoch 13; iter: 400; batch classifier loss: 0.330036; batch adversarial loss: 0.405915\n",
      "epoch 13; iter: 600; batch classifier loss: 0.423633; batch adversarial loss: 0.348719\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351367; batch adversarial loss: 0.511543\n",
      "epoch 14; iter: 200; batch classifier loss: 0.264345; batch adversarial loss: 0.452368\n",
      "epoch 14; iter: 400; batch classifier loss: 0.243535; batch adversarial loss: 0.484709\n",
      "epoch 14; iter: 600; batch classifier loss: 0.423601; batch adversarial loss: 0.384337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260621; batch adversarial loss: 0.347826\n",
      "epoch 15; iter: 200; batch classifier loss: 0.253385; batch adversarial loss: 0.554154\n",
      "epoch 15; iter: 400; batch classifier loss: 0.302169; batch adversarial loss: 0.407346\n",
      "epoch 15; iter: 600; batch classifier loss: 0.346702; batch adversarial loss: 0.401377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354531; batch adversarial loss: 0.433735\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342080; batch adversarial loss: 0.403698\n",
      "epoch 16; iter: 400; batch classifier loss: 0.354840; batch adversarial loss: 0.433541\n",
      "epoch 16; iter: 600; batch classifier loss: 0.344866; batch adversarial loss: 0.369749\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338712; batch adversarial loss: 0.321753\n",
      "epoch 17; iter: 200; batch classifier loss: 0.297437; batch adversarial loss: 0.506109\n",
      "epoch 17; iter: 400; batch classifier loss: 0.333249; batch adversarial loss: 0.332555\n",
      "epoch 17; iter: 600; batch classifier loss: 0.370851; batch adversarial loss: 0.297872\n",
      "epoch 18; iter: 0; batch classifier loss: 0.397919; batch adversarial loss: 0.290500\n",
      "epoch 18; iter: 200; batch classifier loss: 0.412099; batch adversarial loss: 0.378370\n",
      "epoch 18; iter: 400; batch classifier loss: 0.524216; batch adversarial loss: 0.378463\n",
      "epoch 18; iter: 600; batch classifier loss: 0.390685; batch adversarial loss: 0.401023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331047; batch adversarial loss: 0.459115\n",
      "epoch 19; iter: 200; batch classifier loss: 0.281368; batch adversarial loss: 0.433996\n",
      "epoch 19; iter: 400; batch classifier loss: 0.289369; batch adversarial loss: 0.426986\n",
      "epoch 19; iter: 600; batch classifier loss: 0.195421; batch adversarial loss: 0.402268\n",
      "epoch 0; iter: 0; batch classifier loss: 35.120708; batch adversarial loss: 1.084552\n",
      "epoch 0; iter: 200; batch classifier loss: 0.324019; batch adversarial loss: 0.707506\n",
      "epoch 0; iter: 400; batch classifier loss: 1.373427; batch adversarial loss: 0.671018\n",
      "epoch 0; iter: 600; batch classifier loss: 2.933812; batch adversarial loss: 0.573933\n",
      "epoch 1; iter: 0; batch classifier loss: 1.798467; batch adversarial loss: 0.629741\n",
      "epoch 1; iter: 200; batch classifier loss: 3.018828; batch adversarial loss: 0.530096\n",
      "epoch 1; iter: 400; batch classifier loss: 5.340290; batch adversarial loss: 0.582551\n",
      "epoch 1; iter: 600; batch classifier loss: 1.356249; batch adversarial loss: 0.587198\n",
      "epoch 2; iter: 0; batch classifier loss: 0.548266; batch adversarial loss: 0.429860\n",
      "epoch 2; iter: 200; batch classifier loss: 0.469494; batch adversarial loss: 0.484296\n",
      "epoch 2; iter: 400; batch classifier loss: 0.681303; batch adversarial loss: 0.547738\n",
      "epoch 2; iter: 600; batch classifier loss: 1.962132; batch adversarial loss: 0.417753\n",
      "epoch 3; iter: 0; batch classifier loss: 0.378322; batch adversarial loss: 0.453623\n",
      "epoch 3; iter: 200; batch classifier loss: 1.237499; batch adversarial loss: 0.444553\n",
      "epoch 3; iter: 400; batch classifier loss: 1.391196; batch adversarial loss: 0.497812\n",
      "epoch 3; iter: 600; batch classifier loss: 1.037545; batch adversarial loss: 0.385772\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382596; batch adversarial loss: 0.539847\n",
      "epoch 4; iter: 200; batch classifier loss: 4.399871; batch adversarial loss: 0.342297\n",
      "epoch 4; iter: 400; batch classifier loss: 1.028049; batch adversarial loss: 0.361298\n",
      "epoch 4; iter: 600; batch classifier loss: 0.350362; batch adversarial loss: 0.504333\n",
      "epoch 5; iter: 0; batch classifier loss: 0.509344; batch adversarial loss: 0.384988\n",
      "epoch 5; iter: 200; batch classifier loss: 0.379891; batch adversarial loss: 0.484958\n",
      "epoch 5; iter: 400; batch classifier loss: 0.326839; batch adversarial loss: 0.325308\n",
      "epoch 5; iter: 600; batch classifier loss: 0.371829; batch adversarial loss: 0.398332\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358377; batch adversarial loss: 0.560970\n",
      "epoch 6; iter: 200; batch classifier loss: 0.350504; batch adversarial loss: 0.379576\n",
      "epoch 6; iter: 400; batch classifier loss: 0.350365; batch adversarial loss: 0.578303\n",
      "epoch 6; iter: 600; batch classifier loss: 0.392538; batch adversarial loss: 0.543644\n",
      "epoch 7; iter: 0; batch classifier loss: 0.929792; batch adversarial loss: 0.345952\n",
      "epoch 7; iter: 200; batch classifier loss: 0.332147; batch adversarial loss: 0.363610\n",
      "epoch 7; iter: 400; batch classifier loss: 0.329965; batch adversarial loss: 0.551007\n",
      "epoch 7; iter: 600; batch classifier loss: 0.399162; batch adversarial loss: 0.451951\n",
      "epoch 8; iter: 0; batch classifier loss: 0.339144; batch adversarial loss: 0.337744\n",
      "epoch 8; iter: 200; batch classifier loss: 0.427992; batch adversarial loss: 0.290967\n",
      "epoch 8; iter: 400; batch classifier loss: 0.323218; batch adversarial loss: 0.462769\n",
      "epoch 8; iter: 600; batch classifier loss: 0.496371; batch adversarial loss: 0.525265\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455984; batch adversarial loss: 0.431616\n",
      "epoch 9; iter: 200; batch classifier loss: 0.409600; batch adversarial loss: 0.344968\n",
      "epoch 9; iter: 400; batch classifier loss: 0.272703; batch adversarial loss: 0.339092\n",
      "epoch 9; iter: 600; batch classifier loss: 0.436453; batch adversarial loss: 0.430965\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494752; batch adversarial loss: 0.397274\n",
      "epoch 10; iter: 200; batch classifier loss: 0.325984; batch adversarial loss: 0.375357\n",
      "epoch 10; iter: 400; batch classifier loss: 0.360539; batch adversarial loss: 0.439799\n",
      "epoch 10; iter: 600; batch classifier loss: 0.382892; batch adversarial loss: 0.367366\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366725; batch adversarial loss: 0.304913\n",
      "epoch 11; iter: 200; batch classifier loss: 0.301312; batch adversarial loss: 0.452354\n",
      "epoch 11; iter: 400; batch classifier loss: 0.539147; batch adversarial loss: 0.458779\n",
      "epoch 11; iter: 600; batch classifier loss: 0.346601; batch adversarial loss: 0.387930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275339; batch adversarial loss: 0.421155\n",
      "epoch 12; iter: 200; batch classifier loss: 0.413372; batch adversarial loss: 0.398830\n",
      "epoch 12; iter: 400; batch classifier loss: 0.301570; batch adversarial loss: 0.364699\n",
      "epoch 12; iter: 600; batch classifier loss: 0.462346; batch adversarial loss: 0.355435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.367008; batch adversarial loss: 0.317546\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326756; batch adversarial loss: 0.405279\n",
      "epoch 13; iter: 400; batch classifier loss: 0.406528; batch adversarial loss: 0.423639\n",
      "epoch 13; iter: 600; batch classifier loss: 0.232716; batch adversarial loss: 0.489041\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333052; batch adversarial loss: 0.427928\n",
      "epoch 14; iter: 200; batch classifier loss: 0.398236; batch adversarial loss: 0.427003\n",
      "epoch 14; iter: 400; batch classifier loss: 0.384152; batch adversarial loss: 0.424290\n",
      "epoch 14; iter: 600; batch classifier loss: 0.248893; batch adversarial loss: 0.328769\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268167; batch adversarial loss: 0.401897\n",
      "epoch 15; iter: 200; batch classifier loss: 0.277219; batch adversarial loss: 0.585195\n",
      "epoch 15; iter: 400; batch classifier loss: 0.373611; batch adversarial loss: 0.514257\n",
      "epoch 15; iter: 600; batch classifier loss: 0.352042; batch adversarial loss: 0.331823\n",
      "epoch 16; iter: 0; batch classifier loss: 0.374114; batch adversarial loss: 0.501988\n",
      "epoch 16; iter: 200; batch classifier loss: 0.307792; batch adversarial loss: 0.464539\n",
      "epoch 16; iter: 400; batch classifier loss: 0.320818; batch adversarial loss: 0.427881\n",
      "epoch 16; iter: 600; batch classifier loss: 0.430363; batch adversarial loss: 0.344617\n",
      "epoch 17; iter: 0; batch classifier loss: 0.431996; batch adversarial loss: 0.373430\n",
      "epoch 17; iter: 200; batch classifier loss: 0.291966; batch adversarial loss: 0.379889\n",
      "epoch 17; iter: 400; batch classifier loss: 0.321140; batch adversarial loss: 0.428578\n",
      "epoch 17; iter: 600; batch classifier loss: 0.318227; batch adversarial loss: 0.412274\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366179; batch adversarial loss: 0.457851\n",
      "epoch 18; iter: 200; batch classifier loss: 0.369026; batch adversarial loss: 0.411704\n",
      "epoch 18; iter: 400; batch classifier loss: 0.656994; batch adversarial loss: 0.460638\n",
      "epoch 18; iter: 600; batch classifier loss: 0.302912; batch adversarial loss: 0.313352\n",
      "epoch 19; iter: 0; batch classifier loss: 0.659646; batch adversarial loss: 0.375396\n",
      "epoch 19; iter: 200; batch classifier loss: 0.315551; batch adversarial loss: 0.350785\n",
      "epoch 19; iter: 400; batch classifier loss: 0.274469; batch adversarial loss: 0.459448\n",
      "epoch 19; iter: 600; batch classifier loss: 0.339999; batch adversarial loss: 0.316275\n",
      "epoch 0; iter: 0; batch classifier loss: 50.542480; batch adversarial loss: 0.683116\n",
      "epoch 0; iter: 200; batch classifier loss: 10.499828; batch adversarial loss: 0.564982\n",
      "epoch 0; iter: 400; batch classifier loss: 56.650410; batch adversarial loss: 0.476351\n",
      "epoch 0; iter: 600; batch classifier loss: 4.962116; batch adversarial loss: 0.479231\n",
      "epoch 1; iter: 0; batch classifier loss: 5.341869; batch adversarial loss: 0.539348\n",
      "epoch 1; iter: 200; batch classifier loss: 4.954160; batch adversarial loss: 0.559579\n",
      "epoch 1; iter: 400; batch classifier loss: 2.499277; batch adversarial loss: 0.477160\n",
      "epoch 1; iter: 600; batch classifier loss: 4.052480; batch adversarial loss: 0.495827\n",
      "epoch 2; iter: 0; batch classifier loss: 3.289845; batch adversarial loss: 0.519906\n",
      "epoch 2; iter: 200; batch classifier loss: 1.002364; batch adversarial loss: 0.370419\n",
      "epoch 2; iter: 400; batch classifier loss: 1.237707; batch adversarial loss: 0.505277\n",
      "epoch 2; iter: 600; batch classifier loss: 0.447002; batch adversarial loss: 0.460557\n",
      "epoch 3; iter: 0; batch classifier loss: 2.331654; batch adversarial loss: 0.399239\n",
      "epoch 3; iter: 200; batch classifier loss: 0.445638; batch adversarial loss: 0.426442\n",
      "epoch 3; iter: 400; batch classifier loss: 0.501082; batch adversarial loss: 0.346991\n",
      "epoch 3; iter: 600; batch classifier loss: 0.764447; batch adversarial loss: 0.346977\n",
      "epoch 4; iter: 0; batch classifier loss: 0.699397; batch adversarial loss: 0.404797\n",
      "epoch 4; iter: 200; batch classifier loss: 0.294616; batch adversarial loss: 0.412529\n",
      "epoch 4; iter: 400; batch classifier loss: 0.245846; batch adversarial loss: 0.408670\n",
      "epoch 4; iter: 600; batch classifier loss: 1.035164; batch adversarial loss: 0.473426\n",
      "epoch 5; iter: 0; batch classifier loss: 1.099266; batch adversarial loss: 0.465087\n",
      "epoch 5; iter: 200; batch classifier loss: 0.818046; batch adversarial loss: 0.407501\n",
      "epoch 5; iter: 400; batch classifier loss: 0.835939; batch adversarial loss: 0.328580\n",
      "epoch 5; iter: 600; batch classifier loss: 0.463714; batch adversarial loss: 0.383495\n",
      "epoch 6; iter: 0; batch classifier loss: 0.446505; batch adversarial loss: 0.427888\n",
      "epoch 6; iter: 200; batch classifier loss: 0.392179; batch adversarial loss: 0.446615\n",
      "epoch 6; iter: 400; batch classifier loss: 0.787040; batch adversarial loss: 0.319543\n",
      "epoch 6; iter: 600; batch classifier loss: 0.329523; batch adversarial loss: 0.372408\n",
      "epoch 7; iter: 0; batch classifier loss: 0.320386; batch adversarial loss: 0.403208\n",
      "epoch 7; iter: 200; batch classifier loss: 0.436937; batch adversarial loss: 0.464807\n",
      "epoch 7; iter: 400; batch classifier loss: 0.411091; batch adversarial loss: 0.486851\n",
      "epoch 7; iter: 600; batch classifier loss: 0.296500; batch adversarial loss: 0.354046\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453669; batch adversarial loss: 0.403653\n",
      "epoch 8; iter: 200; batch classifier loss: 0.432195; batch adversarial loss: 0.378177\n",
      "epoch 8; iter: 400; batch classifier loss: 0.407089; batch adversarial loss: 0.412036\n",
      "epoch 8; iter: 600; batch classifier loss: 0.342595; batch adversarial loss: 0.315389\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342894; batch adversarial loss: 0.383021\n",
      "epoch 9; iter: 200; batch classifier loss: 0.435826; batch adversarial loss: 0.379979\n",
      "epoch 9; iter: 400; batch classifier loss: 0.461496; batch adversarial loss: 0.387628\n",
      "epoch 9; iter: 600; batch classifier loss: 0.199382; batch adversarial loss: 0.438634\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461396; batch adversarial loss: 0.369992\n",
      "epoch 10; iter: 200; batch classifier loss: 0.384492; batch adversarial loss: 0.400551\n",
      "epoch 10; iter: 400; batch classifier loss: 0.490574; batch adversarial loss: 0.396318\n",
      "epoch 10; iter: 600; batch classifier loss: 0.237120; batch adversarial loss: 0.716016\n",
      "epoch 11; iter: 0; batch classifier loss: 0.385637; batch adversarial loss: 0.367267\n",
      "epoch 11; iter: 200; batch classifier loss: 0.433337; batch adversarial loss: 0.397012\n",
      "epoch 11; iter: 400; batch classifier loss: 0.489492; batch adversarial loss: 0.519845\n",
      "epoch 11; iter: 600; batch classifier loss: 0.528560; batch adversarial loss: 0.391782\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396855; batch adversarial loss: 0.369549\n",
      "epoch 12; iter: 200; batch classifier loss: 0.338179; batch adversarial loss: 0.320924\n",
      "epoch 12; iter: 400; batch classifier loss: 0.359700; batch adversarial loss: 0.458337\n",
      "epoch 12; iter: 600; batch classifier loss: 0.309786; batch adversarial loss: 0.261226\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272706; batch adversarial loss: 0.572727\n",
      "epoch 13; iter: 200; batch classifier loss: 0.330138; batch adversarial loss: 0.409676\n",
      "epoch 13; iter: 400; batch classifier loss: 0.335317; batch adversarial loss: 0.526716\n",
      "epoch 13; iter: 600; batch classifier loss: 0.287846; batch adversarial loss: 0.526914\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480155; batch adversarial loss: 0.320525\n",
      "epoch 14; iter: 200; batch classifier loss: 0.395893; batch adversarial loss: 0.426101\n",
      "epoch 14; iter: 400; batch classifier loss: 0.321853; batch adversarial loss: 0.425248\n",
      "epoch 14; iter: 600; batch classifier loss: 0.306336; batch adversarial loss: 0.388491\n",
      "epoch 15; iter: 0; batch classifier loss: 0.300088; batch adversarial loss: 0.476872\n",
      "epoch 15; iter: 200; batch classifier loss: 0.246641; batch adversarial loss: 0.376341\n",
      "epoch 15; iter: 400; batch classifier loss: 0.392306; batch adversarial loss: 0.239929\n",
      "epoch 15; iter: 600; batch classifier loss: 0.334978; batch adversarial loss: 0.404967\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292512; batch adversarial loss: 0.435690\n",
      "epoch 16; iter: 200; batch classifier loss: 0.515941; batch adversarial loss: 0.432188\n",
      "epoch 16; iter: 400; batch classifier loss: 0.402965; batch adversarial loss: 0.333021\n",
      "epoch 16; iter: 600; batch classifier loss: 0.418577; batch adversarial loss: 0.538177\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368785; batch adversarial loss: 0.343277\n",
      "epoch 17; iter: 200; batch classifier loss: 0.313314; batch adversarial loss: 0.425038\n",
      "epoch 17; iter: 400; batch classifier loss: 0.400479; batch adversarial loss: 0.344369\n",
      "epoch 17; iter: 600; batch classifier loss: 0.182073; batch adversarial loss: 0.322876\n",
      "epoch 18; iter: 0; batch classifier loss: 0.299058; batch adversarial loss: 0.525944\n",
      "epoch 18; iter: 200; batch classifier loss: 0.359803; batch adversarial loss: 0.407456\n",
      "epoch 18; iter: 400; batch classifier loss: 0.340850; batch adversarial loss: 0.359849\n",
      "epoch 18; iter: 600; batch classifier loss: 0.257375; batch adversarial loss: 0.317811\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382416; batch adversarial loss: 0.448757\n",
      "epoch 19; iter: 200; batch classifier loss: 0.414745; batch adversarial loss: 0.377187\n",
      "epoch 19; iter: 400; batch classifier loss: 0.442664; batch adversarial loss: 0.350779\n",
      "epoch 19; iter: 600; batch classifier loss: 0.448262; batch adversarial loss: 0.431184\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 58.402748; batch adversarial loss: 0.698745\n",
      "epoch 0; iter: 200; batch classifier loss: 11.518730; batch adversarial loss: 0.648545\n",
      "epoch 0; iter: 400; batch classifier loss: 1.238547; batch adversarial loss: 0.571378\n",
      "epoch 0; iter: 600; batch classifier loss: 6.026841; batch adversarial loss: 0.540802\n",
      "epoch 1; iter: 0; batch classifier loss: 4.531978; batch adversarial loss: 0.479418\n",
      "epoch 1; iter: 200; batch classifier loss: 8.659819; batch adversarial loss: 0.594504\n",
      "epoch 1; iter: 400; batch classifier loss: 4.404228; batch adversarial loss: 0.518848\n",
      "epoch 1; iter: 600; batch classifier loss: 1.478726; batch adversarial loss: 0.380611\n",
      "epoch 2; iter: 0; batch classifier loss: 2.559673; batch adversarial loss: 0.459644\n",
      "epoch 2; iter: 200; batch classifier loss: 1.279149; batch adversarial loss: 0.496341\n",
      "epoch 2; iter: 400; batch classifier loss: 1.520021; batch adversarial loss: 0.328757\n",
      "epoch 2; iter: 600; batch classifier loss: 2.920469; batch adversarial loss: 0.401545\n",
      "epoch 3; iter: 0; batch classifier loss: 0.314669; batch adversarial loss: 0.458541\n",
      "epoch 3; iter: 200; batch classifier loss: 3.066255; batch adversarial loss: 0.497483\n",
      "epoch 3; iter: 400; batch classifier loss: 0.485273; batch adversarial loss: 0.438475\n",
      "epoch 3; iter: 600; batch classifier loss: 0.484435; batch adversarial loss: 0.409550\n",
      "epoch 4; iter: 0; batch classifier loss: 1.162198; batch adversarial loss: 0.410138\n",
      "epoch 4; iter: 200; batch classifier loss: 0.457312; batch adversarial loss: 0.434007\n",
      "epoch 4; iter: 400; batch classifier loss: 5.029953; batch adversarial loss: 0.385891\n",
      "epoch 4; iter: 600; batch classifier loss: 0.864760; batch adversarial loss: 0.428224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387911; batch adversarial loss: 0.439287\n",
      "epoch 5; iter: 200; batch classifier loss: 0.394177; batch adversarial loss: 0.610205\n",
      "epoch 5; iter: 400; batch classifier loss: 0.580385; batch adversarial loss: 0.343619\n",
      "epoch 5; iter: 600; batch classifier loss: 0.634990; batch adversarial loss: 0.505727\n",
      "epoch 6; iter: 0; batch classifier loss: 0.474081; batch adversarial loss: 0.540049\n",
      "epoch 6; iter: 200; batch classifier loss: 0.505706; batch adversarial loss: 0.416442\n",
      "epoch 6; iter: 400; batch classifier loss: 0.386528; batch adversarial loss: 0.513378\n",
      "epoch 6; iter: 600; batch classifier loss: 0.238564; batch adversarial loss: 0.424576\n",
      "epoch 7; iter: 0; batch classifier loss: 0.279263; batch adversarial loss: 0.429085\n",
      "epoch 7; iter: 200; batch classifier loss: 0.538802; batch adversarial loss: 0.276988\n",
      "epoch 7; iter: 400; batch classifier loss: 0.361611; batch adversarial loss: 0.394385\n",
      "epoch 7; iter: 600; batch classifier loss: 0.348474; batch adversarial loss: 0.432110\n",
      "epoch 8; iter: 0; batch classifier loss: 0.672240; batch adversarial loss: 0.345596\n",
      "epoch 8; iter: 200; batch classifier loss: 0.646216; batch adversarial loss: 0.390376\n",
      "epoch 8; iter: 400; batch classifier loss: 0.434505; batch adversarial loss: 0.294836\n",
      "epoch 8; iter: 600; batch classifier loss: 1.208316; batch adversarial loss: 0.482853\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435886; batch adversarial loss: 0.320716\n",
      "epoch 9; iter: 200; batch classifier loss: 0.347881; batch adversarial loss: 0.459161\n",
      "epoch 9; iter: 400; batch classifier loss: 0.599069; batch adversarial loss: 0.441805\n",
      "epoch 9; iter: 600; batch classifier loss: 0.558804; batch adversarial loss: 0.303580\n",
      "epoch 10; iter: 0; batch classifier loss: 0.681967; batch adversarial loss: 0.333903\n",
      "epoch 10; iter: 200; batch classifier loss: 0.177314; batch adversarial loss: 0.430400\n",
      "epoch 10; iter: 400; batch classifier loss: 0.398474; batch adversarial loss: 0.552244\n",
      "epoch 10; iter: 600; batch classifier loss: 0.390211; batch adversarial loss: 0.269400\n",
      "epoch 11; iter: 0; batch classifier loss: 0.401839; batch adversarial loss: 0.361655\n",
      "epoch 11; iter: 200; batch classifier loss: 0.335207; batch adversarial loss: 0.493048\n",
      "epoch 11; iter: 400; batch classifier loss: 0.333013; batch adversarial loss: 0.410621\n",
      "epoch 11; iter: 600; batch classifier loss: 0.557874; batch adversarial loss: 0.236107\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373860; batch adversarial loss: 0.462362\n",
      "epoch 12; iter: 200; batch classifier loss: 0.387895; batch adversarial loss: 0.596022\n",
      "epoch 12; iter: 400; batch classifier loss: 0.344433; batch adversarial loss: 0.418403\n",
      "epoch 12; iter: 600; batch classifier loss: 0.327367; batch adversarial loss: 0.465821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282876; batch adversarial loss: 0.543998\n",
      "epoch 13; iter: 200; batch classifier loss: 0.293560; batch adversarial loss: 0.482374\n",
      "epoch 13; iter: 400; batch classifier loss: 0.378015; batch adversarial loss: 0.414111\n",
      "epoch 13; iter: 600; batch classifier loss: 0.324205; batch adversarial loss: 0.318061\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266076; batch adversarial loss: 0.526235\n",
      "epoch 14; iter: 200; batch classifier loss: 0.554649; batch adversarial loss: 0.343620\n",
      "epoch 14; iter: 400; batch classifier loss: 0.320366; batch adversarial loss: 0.274243\n",
      "epoch 14; iter: 600; batch classifier loss: 0.329995; batch adversarial loss: 0.442641\n",
      "epoch 15; iter: 0; batch classifier loss: 0.262021; batch adversarial loss: 0.320644\n",
      "epoch 15; iter: 200; batch classifier loss: 0.438574; batch adversarial loss: 0.391336\n",
      "epoch 15; iter: 400; batch classifier loss: 0.347091; batch adversarial loss: 0.397092\n",
      "epoch 15; iter: 600; batch classifier loss: 0.335267; batch adversarial loss: 0.400221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327792; batch adversarial loss: 0.486258\n",
      "epoch 16; iter: 200; batch classifier loss: 0.430955; batch adversarial loss: 0.318532\n",
      "epoch 16; iter: 400; batch classifier loss: 0.325132; batch adversarial loss: 0.398632\n",
      "epoch 16; iter: 600; batch classifier loss: 0.489707; batch adversarial loss: 0.530374\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480442; batch adversarial loss: 0.350194\n",
      "epoch 17; iter: 200; batch classifier loss: 0.335199; batch adversarial loss: 0.496920\n",
      "epoch 17; iter: 400; batch classifier loss: 0.338329; batch adversarial loss: 0.368294\n",
      "epoch 17; iter: 600; batch classifier loss: 0.344929; batch adversarial loss: 0.314379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367367; batch adversarial loss: 0.425926\n",
      "epoch 18; iter: 200; batch classifier loss: 0.367876; batch adversarial loss: 0.303114\n",
      "epoch 18; iter: 400; batch classifier loss: 0.394303; batch adversarial loss: 0.406827\n",
      "epoch 18; iter: 600; batch classifier loss: 0.324078; batch adversarial loss: 0.292938\n",
      "epoch 19; iter: 0; batch classifier loss: 0.386829; batch adversarial loss: 0.289819\n",
      "epoch 19; iter: 200; batch classifier loss: 0.320269; batch adversarial loss: 0.424112\n",
      "epoch 19; iter: 400; batch classifier loss: 0.284339; batch adversarial loss: 0.327384\n",
      "epoch 19; iter: 600; batch classifier loss: 0.387446; batch adversarial loss: 0.463473\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279579; batch adversarial loss: 0.462995\n",
      "epoch 20; iter: 200; batch classifier loss: 0.269697; batch adversarial loss: 0.489339\n",
      "epoch 20; iter: 400; batch classifier loss: 0.320292; batch adversarial loss: 0.425378\n",
      "epoch 20; iter: 600; batch classifier loss: 0.288703; batch adversarial loss: 0.518852\n",
      "epoch 21; iter: 0; batch classifier loss: 0.406758; batch adversarial loss: 0.366884\n",
      "epoch 21; iter: 200; batch classifier loss: 0.351324; batch adversarial loss: 0.399864\n",
      "epoch 21; iter: 400; batch classifier loss: 0.375731; batch adversarial loss: 0.518861\n",
      "epoch 21; iter: 600; batch classifier loss: 0.371686; batch adversarial loss: 0.327135\n",
      "epoch 22; iter: 0; batch classifier loss: 0.334711; batch adversarial loss: 0.647873\n",
      "epoch 22; iter: 200; batch classifier loss: 0.305714; batch adversarial loss: 0.432735\n",
      "epoch 22; iter: 400; batch classifier loss: 0.263170; batch adversarial loss: 0.367020\n",
      "epoch 22; iter: 600; batch classifier loss: 0.365550; batch adversarial loss: 0.551475\n",
      "epoch 23; iter: 0; batch classifier loss: 0.346002; batch adversarial loss: 0.288502\n",
      "epoch 23; iter: 200; batch classifier loss: 0.321657; batch adversarial loss: 0.625627\n",
      "epoch 23; iter: 400; batch classifier loss: 0.236846; batch adversarial loss: 0.375715\n",
      "epoch 23; iter: 600; batch classifier loss: 0.326289; batch adversarial loss: 0.357689\n",
      "epoch 24; iter: 0; batch classifier loss: 0.270075; batch adversarial loss: 0.455935\n",
      "epoch 24; iter: 200; batch classifier loss: 0.648169; batch adversarial loss: 0.436682\n",
      "epoch 24; iter: 400; batch classifier loss: 0.316028; batch adversarial loss: 0.354343\n",
      "epoch 24; iter: 600; batch classifier loss: 0.389767; batch adversarial loss: 0.408461\n",
      "epoch 25; iter: 0; batch classifier loss: 0.355838; batch adversarial loss: 0.563181\n",
      "epoch 25; iter: 200; batch classifier loss: 0.338099; batch adversarial loss: 0.326374\n",
      "epoch 25; iter: 400; batch classifier loss: 0.320139; batch adversarial loss: 0.513990\n",
      "epoch 25; iter: 600; batch classifier loss: 0.255217; batch adversarial loss: 0.389647\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363656; batch adversarial loss: 0.449483\n",
      "epoch 26; iter: 200; batch classifier loss: 0.770692; batch adversarial loss: 0.468506\n",
      "epoch 26; iter: 400; batch classifier loss: 0.377254; batch adversarial loss: 0.308511\n",
      "epoch 26; iter: 600; batch classifier loss: 0.252731; batch adversarial loss: 0.492503\n",
      "epoch 27; iter: 0; batch classifier loss: 0.344757; batch adversarial loss: 0.342166\n",
      "epoch 27; iter: 200; batch classifier loss: 0.443352; batch adversarial loss: 0.442045\n",
      "epoch 27; iter: 400; batch classifier loss: 0.339947; batch adversarial loss: 0.409758\n",
      "epoch 27; iter: 600; batch classifier loss: 0.257597; batch adversarial loss: 0.425469\n",
      "epoch 28; iter: 0; batch classifier loss: 0.290128; batch adversarial loss: 0.255945\n",
      "epoch 28; iter: 200; batch classifier loss: 0.280402; batch adversarial loss: 0.323276\n",
      "epoch 28; iter: 400; batch classifier loss: 0.448990; batch adversarial loss: 0.321906\n",
      "epoch 28; iter: 600; batch classifier loss: 0.292327; batch adversarial loss: 0.445251\n",
      "epoch 29; iter: 0; batch classifier loss: 0.264565; batch adversarial loss: 0.453679\n",
      "epoch 29; iter: 200; batch classifier loss: 0.465245; batch adversarial loss: 0.428948\n",
      "epoch 29; iter: 400; batch classifier loss: 0.461717; batch adversarial loss: 0.438347\n",
      "epoch 29; iter: 600; batch classifier loss: 0.246576; batch adversarial loss: 0.300857\n",
      "epoch 30; iter: 0; batch classifier loss: 0.345537; batch adversarial loss: 0.565940\n",
      "epoch 30; iter: 200; batch classifier loss: 0.422887; batch adversarial loss: 0.421228\n",
      "epoch 30; iter: 400; batch classifier loss: 0.214851; batch adversarial loss: 0.302589\n",
      "epoch 30; iter: 600; batch classifier loss: 0.470365; batch adversarial loss: 0.396836\n",
      "epoch 31; iter: 0; batch classifier loss: 0.180990; batch adversarial loss: 0.431397\n",
      "epoch 31; iter: 200; batch classifier loss: 0.550825; batch adversarial loss: 0.488250\n",
      "epoch 31; iter: 400; batch classifier loss: 0.484601; batch adversarial loss: 0.318241\n",
      "epoch 31; iter: 600; batch classifier loss: 0.352493; batch adversarial loss: 0.469397\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279341; batch adversarial loss: 0.354187\n",
      "epoch 32; iter: 200; batch classifier loss: 0.401870; batch adversarial loss: 0.404310\n",
      "epoch 32; iter: 400; batch classifier loss: 0.325523; batch adversarial loss: 0.293459\n",
      "epoch 32; iter: 600; batch classifier loss: 0.396902; batch adversarial loss: 0.353991\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358481; batch adversarial loss: 0.374932\n",
      "epoch 33; iter: 200; batch classifier loss: 0.278267; batch adversarial loss: 0.600871\n",
      "epoch 33; iter: 400; batch classifier loss: 0.922479; batch adversarial loss: 0.315928\n",
      "epoch 33; iter: 600; batch classifier loss: 0.325126; batch adversarial loss: 0.561878\n",
      "epoch 34; iter: 0; batch classifier loss: 0.378008; batch adversarial loss: 0.436958\n",
      "epoch 34; iter: 200; batch classifier loss: 0.365615; batch adversarial loss: 0.327538\n",
      "epoch 34; iter: 400; batch classifier loss: 0.403025; batch adversarial loss: 0.417528\n",
      "epoch 34; iter: 600; batch classifier loss: 0.422758; batch adversarial loss: 0.431458\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400832; batch adversarial loss: 0.443356\n",
      "epoch 35; iter: 200; batch classifier loss: 0.242284; batch adversarial loss: 0.492796\n",
      "epoch 35; iter: 400; batch classifier loss: 0.369969; batch adversarial loss: 0.344384\n",
      "epoch 35; iter: 600; batch classifier loss: 0.334017; batch adversarial loss: 0.318668\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391190; batch adversarial loss: 0.382827\n",
      "epoch 36; iter: 200; batch classifier loss: 0.417431; batch adversarial loss: 0.360779\n",
      "epoch 36; iter: 400; batch classifier loss: 0.345069; batch adversarial loss: 0.429792\n",
      "epoch 36; iter: 600; batch classifier loss: 0.303057; batch adversarial loss: 0.406622\n",
      "epoch 37; iter: 0; batch classifier loss: 0.516220; batch adversarial loss: 0.397388\n",
      "epoch 37; iter: 200; batch classifier loss: 0.238036; batch adversarial loss: 0.621556\n",
      "epoch 37; iter: 400; batch classifier loss: 0.329123; batch adversarial loss: 0.379488\n",
      "epoch 37; iter: 600; batch classifier loss: 0.385203; batch adversarial loss: 0.288409\n",
      "epoch 38; iter: 0; batch classifier loss: 0.380243; batch adversarial loss: 0.456965\n",
      "epoch 38; iter: 200; batch classifier loss: 0.380292; batch adversarial loss: 0.342346\n",
      "epoch 38; iter: 400; batch classifier loss: 0.303069; batch adversarial loss: 0.533051\n",
      "epoch 38; iter: 600; batch classifier loss: 0.473219; batch adversarial loss: 0.344623\n",
      "epoch 39; iter: 0; batch classifier loss: 0.277156; batch adversarial loss: 0.358961\n",
      "epoch 39; iter: 200; batch classifier loss: 0.254839; batch adversarial loss: 0.398544\n",
      "epoch 39; iter: 400; batch classifier loss: 0.318198; batch adversarial loss: 0.347912\n",
      "epoch 39; iter: 600; batch classifier loss: 0.331379; batch adversarial loss: 0.353575\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361325; batch adversarial loss: 0.320546\n",
      "epoch 40; iter: 200; batch classifier loss: 0.220152; batch adversarial loss: 0.353219\n",
      "epoch 40; iter: 400; batch classifier loss: 0.259236; batch adversarial loss: 0.287843\n",
      "epoch 40; iter: 600; batch classifier loss: 0.766254; batch adversarial loss: 0.321502\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454248; batch adversarial loss: 0.543869\n",
      "epoch 41; iter: 200; batch classifier loss: 0.244828; batch adversarial loss: 0.358305\n",
      "epoch 41; iter: 400; batch classifier loss: 0.349441; batch adversarial loss: 0.486811\n",
      "epoch 41; iter: 600; batch classifier loss: 0.726048; batch adversarial loss: 0.288202\n",
      "epoch 42; iter: 0; batch classifier loss: 0.370351; batch adversarial loss: 0.314023\n",
      "epoch 42; iter: 200; batch classifier loss: 0.413836; batch adversarial loss: 0.488001\n",
      "epoch 42; iter: 400; batch classifier loss: 0.339016; batch adversarial loss: 0.361122\n",
      "epoch 42; iter: 600; batch classifier loss: 0.748939; batch adversarial loss: 0.459370\n",
      "epoch 43; iter: 0; batch classifier loss: 0.566569; batch adversarial loss: 0.330004\n",
      "epoch 43; iter: 200; batch classifier loss: 0.325721; batch adversarial loss: 0.404654\n",
      "epoch 43; iter: 400; batch classifier loss: 0.350751; batch adversarial loss: 0.363822\n",
      "epoch 43; iter: 600; batch classifier loss: 0.477172; batch adversarial loss: 0.432648\n",
      "epoch 44; iter: 0; batch classifier loss: 0.295102; batch adversarial loss: 0.322161\n",
      "epoch 44; iter: 200; batch classifier loss: 0.580882; batch adversarial loss: 0.377093\n",
      "epoch 44; iter: 400; batch classifier loss: 0.335997; batch adversarial loss: 0.345754\n",
      "epoch 44; iter: 600; batch classifier loss: 0.525442; batch adversarial loss: 0.479894\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318135; batch adversarial loss: 0.372341\n",
      "epoch 45; iter: 200; batch classifier loss: 0.421203; batch adversarial loss: 0.478694\n",
      "epoch 45; iter: 400; batch classifier loss: 0.431763; batch adversarial loss: 0.435201\n",
      "epoch 45; iter: 600; batch classifier loss: 0.238816; batch adversarial loss: 0.314643\n",
      "epoch 46; iter: 0; batch classifier loss: 0.339023; batch adversarial loss: 0.345229\n",
      "epoch 46; iter: 200; batch classifier loss: 0.227374; batch adversarial loss: 0.398471\n",
      "epoch 46; iter: 400; batch classifier loss: 0.340873; batch adversarial loss: 0.290809\n",
      "epoch 46; iter: 600; batch classifier loss: 0.282742; batch adversarial loss: 0.379998\n",
      "epoch 47; iter: 0; batch classifier loss: 0.545265; batch adversarial loss: 0.325040\n",
      "epoch 47; iter: 200; batch classifier loss: 0.335847; batch adversarial loss: 0.374522\n",
      "epoch 47; iter: 400; batch classifier loss: 0.437516; batch adversarial loss: 0.288873\n",
      "epoch 47; iter: 600; batch classifier loss: 0.506558; batch adversarial loss: 0.494650\n",
      "epoch 48; iter: 0; batch classifier loss: 0.505541; batch adversarial loss: 0.373957\n",
      "epoch 48; iter: 200; batch classifier loss: 0.396304; batch adversarial loss: 0.349466\n",
      "epoch 48; iter: 400; batch classifier loss: 0.263024; batch adversarial loss: 0.532882\n",
      "epoch 48; iter: 600; batch classifier loss: 0.443484; batch adversarial loss: 0.498787\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452655; batch adversarial loss: 0.332260\n",
      "epoch 49; iter: 200; batch classifier loss: 0.373510; batch adversarial loss: 0.432764\n",
      "epoch 49; iter: 400; batch classifier loss: 0.336098; batch adversarial loss: 0.581646\n",
      "epoch 49; iter: 600; batch classifier loss: 0.363331; batch adversarial loss: 0.411677\n",
      "epoch 0; iter: 0; batch classifier loss: 140.648773; batch adversarial loss: 1.032190\n",
      "epoch 0; iter: 200; batch classifier loss: 19.252090; batch adversarial loss: 0.811957\n",
      "epoch 0; iter: 400; batch classifier loss: 5.633777; batch adversarial loss: 0.635852\n",
      "epoch 0; iter: 600; batch classifier loss: 0.898970; batch adversarial loss: 0.547716\n",
      "epoch 1; iter: 0; batch classifier loss: 4.486480; batch adversarial loss: 0.540682\n",
      "epoch 1; iter: 200; batch classifier loss: 1.300957; batch adversarial loss: 0.521649\n",
      "epoch 1; iter: 400; batch classifier loss: 1.287579; batch adversarial loss: 0.530585\n",
      "epoch 1; iter: 600; batch classifier loss: 6.509093; batch adversarial loss: 0.491834\n",
      "epoch 2; iter: 0; batch classifier loss: 0.900090; batch adversarial loss: 0.477548\n",
      "epoch 2; iter: 200; batch classifier loss: 2.965105; batch adversarial loss: 0.502099\n",
      "epoch 2; iter: 400; batch classifier loss: 0.576277; batch adversarial loss: 0.447310\n",
      "epoch 2; iter: 600; batch classifier loss: 2.582295; batch adversarial loss: 0.394107\n",
      "epoch 3; iter: 0; batch classifier loss: 0.816956; batch adversarial loss: 0.463659\n",
      "epoch 3; iter: 200; batch classifier loss: 0.700653; batch adversarial loss: 0.457260\n",
      "epoch 3; iter: 400; batch classifier loss: 1.191003; batch adversarial loss: 0.335921\n",
      "epoch 3; iter: 600; batch classifier loss: 14.986633; batch adversarial loss: 0.362123\n",
      "epoch 4; iter: 0; batch classifier loss: 12.311607; batch adversarial loss: 0.436685\n",
      "epoch 4; iter: 200; batch classifier loss: 0.415484; batch adversarial loss: 0.433320\n",
      "epoch 4; iter: 400; batch classifier loss: 0.781075; batch adversarial loss: 0.431509\n",
      "epoch 4; iter: 600; batch classifier loss: 0.357168; batch adversarial loss: 0.400027\n",
      "epoch 5; iter: 0; batch classifier loss: 0.551087; batch adversarial loss: 0.454061\n",
      "epoch 5; iter: 200; batch classifier loss: 0.362916; batch adversarial loss: 0.321003\n",
      "epoch 5; iter: 400; batch classifier loss: 0.283412; batch adversarial loss: 0.431449\n",
      "epoch 5; iter: 600; batch classifier loss: 0.418372; batch adversarial loss: 0.314470\n",
      "epoch 6; iter: 0; batch classifier loss: 0.616292; batch adversarial loss: 0.370533\n",
      "epoch 6; iter: 200; batch classifier loss: 0.343174; batch adversarial loss: 0.532241\n",
      "epoch 6; iter: 400; batch classifier loss: 0.290645; batch adversarial loss: 0.405886\n",
      "epoch 6; iter: 600; batch classifier loss: 0.994407; batch adversarial loss: 0.321588\n",
      "epoch 7; iter: 0; batch classifier loss: 1.346433; batch adversarial loss: 0.543620\n",
      "epoch 7; iter: 200; batch classifier loss: 0.848992; batch adversarial loss: 0.350515\n",
      "epoch 7; iter: 400; batch classifier loss: 0.417649; batch adversarial loss: 0.393761\n",
      "epoch 7; iter: 600; batch classifier loss: 0.344979; batch adversarial loss: 0.471157\n",
      "epoch 8; iter: 0; batch classifier loss: 0.469897; batch adversarial loss: 0.511867\n",
      "epoch 8; iter: 200; batch classifier loss: 0.481779; batch adversarial loss: 0.491745\n",
      "epoch 8; iter: 400; batch classifier loss: 0.430711; batch adversarial loss: 0.321870\n",
      "epoch 8; iter: 600; batch classifier loss: 0.398595; batch adversarial loss: 0.425705\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416059; batch adversarial loss: 0.353591\n",
      "epoch 9; iter: 200; batch classifier loss: 0.442008; batch adversarial loss: 0.345321\n",
      "epoch 9; iter: 400; batch classifier loss: 0.420276; batch adversarial loss: 0.277069\n",
      "epoch 9; iter: 600; batch classifier loss: 0.490788; batch adversarial loss: 0.426919\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440477; batch adversarial loss: 0.434917\n",
      "epoch 10; iter: 200; batch classifier loss: 0.346404; batch adversarial loss: 0.524666\n",
      "epoch 10; iter: 400; batch classifier loss: 0.388641; batch adversarial loss: 0.348875\n",
      "epoch 10; iter: 600; batch classifier loss: 0.274155; batch adversarial loss: 0.413237\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359269; batch adversarial loss: 0.411009\n",
      "epoch 11; iter: 200; batch classifier loss: 0.374152; batch adversarial loss: 0.465029\n",
      "epoch 11; iter: 400; batch classifier loss: 0.442529; batch adversarial loss: 0.282379\n",
      "epoch 11; iter: 600; batch classifier loss: 0.480879; batch adversarial loss: 0.342120\n",
      "epoch 12; iter: 0; batch classifier loss: 0.274815; batch adversarial loss: 0.407510\n",
      "epoch 12; iter: 200; batch classifier loss: 0.410882; batch adversarial loss: 0.454570\n",
      "epoch 12; iter: 400; batch classifier loss: 0.278294; batch adversarial loss: 0.369404\n",
      "epoch 12; iter: 600; batch classifier loss: 0.208318; batch adversarial loss: 0.463412\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297053; batch adversarial loss: 0.447790\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326169; batch adversarial loss: 0.325482\n",
      "epoch 13; iter: 400; batch classifier loss: 0.276936; batch adversarial loss: 0.385343\n",
      "epoch 13; iter: 600; batch classifier loss: 0.402869; batch adversarial loss: 0.399483\n",
      "epoch 14; iter: 0; batch classifier loss: 0.278526; batch adversarial loss: 0.298522\n",
      "epoch 14; iter: 200; batch classifier loss: 0.380384; batch adversarial loss: 0.316788\n",
      "epoch 14; iter: 400; batch classifier loss: 0.425741; batch adversarial loss: 0.461236\n",
      "epoch 14; iter: 600; batch classifier loss: 0.338149; batch adversarial loss: 0.373321\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323190; batch adversarial loss: 0.482511\n",
      "epoch 15; iter: 200; batch classifier loss: 0.331418; batch adversarial loss: 0.449551\n",
      "epoch 15; iter: 400; batch classifier loss: 0.396769; batch adversarial loss: 0.323545\n",
      "epoch 15; iter: 600; batch classifier loss: 0.336879; batch adversarial loss: 0.457361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372524; batch adversarial loss: 0.269794\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399430; batch adversarial loss: 0.558117\n",
      "epoch 16; iter: 400; batch classifier loss: 0.503610; batch adversarial loss: 0.492184\n",
      "epoch 16; iter: 600; batch classifier loss: 0.405315; batch adversarial loss: 0.407457\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349075; batch adversarial loss: 0.324995\n",
      "epoch 17; iter: 200; batch classifier loss: 0.313447; batch adversarial loss: 0.462442\n",
      "epoch 17; iter: 400; batch classifier loss: 0.555526; batch adversarial loss: 0.502771\n",
      "epoch 17; iter: 600; batch classifier loss: 0.419892; batch adversarial loss: 0.347301\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349664; batch adversarial loss: 0.347061\n",
      "epoch 18; iter: 200; batch classifier loss: 0.331516; batch adversarial loss: 0.503699\n",
      "epoch 18; iter: 400; batch classifier loss: 0.245970; batch adversarial loss: 0.420223\n",
      "epoch 18; iter: 600; batch classifier loss: 0.338155; batch adversarial loss: 0.395499\n",
      "epoch 19; iter: 0; batch classifier loss: 0.336900; batch adversarial loss: 0.409616\n",
      "epoch 19; iter: 200; batch classifier loss: 0.381141; batch adversarial loss: 0.343216\n",
      "epoch 19; iter: 400; batch classifier loss: 0.395071; batch adversarial loss: 0.429340\n",
      "epoch 19; iter: 600; batch classifier loss: 0.341946; batch adversarial loss: 0.511704\n",
      "epoch 20; iter: 0; batch classifier loss: 0.411459; batch adversarial loss: 0.346794\n",
      "epoch 20; iter: 200; batch classifier loss: 0.377034; batch adversarial loss: 0.354785\n",
      "epoch 20; iter: 400; batch classifier loss: 0.341761; batch adversarial loss: 0.361055\n",
      "epoch 20; iter: 600; batch classifier loss: 0.487090; batch adversarial loss: 0.432236\n",
      "epoch 21; iter: 0; batch classifier loss: 0.330608; batch adversarial loss: 0.397126\n",
      "epoch 21; iter: 200; batch classifier loss: 0.369754; batch adversarial loss: 0.379354\n",
      "epoch 21; iter: 400; batch classifier loss: 0.426495; batch adversarial loss: 0.465804\n",
      "epoch 21; iter: 600; batch classifier loss: 0.322868; batch adversarial loss: 0.318709\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350558; batch adversarial loss: 0.345249\n",
      "epoch 22; iter: 200; batch classifier loss: 0.404653; batch adversarial loss: 0.451879\n",
      "epoch 22; iter: 400; batch classifier loss: 0.361040; batch adversarial loss: 0.411021\n",
      "epoch 22; iter: 600; batch classifier loss: 0.493882; batch adversarial loss: 0.326366\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588235; batch adversarial loss: 0.357648\n",
      "epoch 23; iter: 200; batch classifier loss: 0.316488; batch adversarial loss: 0.350315\n",
      "epoch 23; iter: 400; batch classifier loss: 0.327819; batch adversarial loss: 0.461088\n",
      "epoch 23; iter: 600; batch classifier loss: 0.384527; batch adversarial loss: 0.412281\n",
      "epoch 24; iter: 0; batch classifier loss: 0.358026; batch adversarial loss: 0.505054\n",
      "epoch 24; iter: 200; batch classifier loss: 0.262174; batch adversarial loss: 0.496599\n",
      "epoch 24; iter: 400; batch classifier loss: 0.372515; batch adversarial loss: 0.652007\n",
      "epoch 24; iter: 600; batch classifier loss: 0.468027; batch adversarial loss: 0.396799\n",
      "epoch 25; iter: 0; batch classifier loss: 0.251240; batch adversarial loss: 0.398469\n",
      "epoch 25; iter: 200; batch classifier loss: 0.447831; batch adversarial loss: 0.536893\n",
      "epoch 25; iter: 400; batch classifier loss: 0.329107; batch adversarial loss: 0.407553\n",
      "epoch 25; iter: 600; batch classifier loss: 0.508378; batch adversarial loss: 0.344807\n",
      "epoch 26; iter: 0; batch classifier loss: 0.314291; batch adversarial loss: 0.424816\n",
      "epoch 26; iter: 200; batch classifier loss: 0.457364; batch adversarial loss: 0.579738\n",
      "epoch 26; iter: 400; batch classifier loss: 0.322088; batch adversarial loss: 0.451202\n",
      "epoch 26; iter: 600; batch classifier loss: 0.362154; batch adversarial loss: 0.456149\n",
      "epoch 27; iter: 0; batch classifier loss: 0.456728; batch adversarial loss: 0.541846\n",
      "epoch 27; iter: 200; batch classifier loss: 0.348609; batch adversarial loss: 0.299344\n",
      "epoch 27; iter: 400; batch classifier loss: 0.419076; batch adversarial loss: 0.287860\n",
      "epoch 27; iter: 600; batch classifier loss: 0.362634; batch adversarial loss: 0.484571\n",
      "epoch 28; iter: 0; batch classifier loss: 0.325861; batch adversarial loss: 0.345125\n",
      "epoch 28; iter: 200; batch classifier loss: 0.455010; batch adversarial loss: 0.409728\n",
      "epoch 28; iter: 400; batch classifier loss: 0.288001; batch adversarial loss: 0.470701\n",
      "epoch 28; iter: 600; batch classifier loss: 0.456083; batch adversarial loss: 0.486747\n",
      "epoch 29; iter: 0; batch classifier loss: 0.505556; batch adversarial loss: 0.459414\n",
      "epoch 29; iter: 200; batch classifier loss: 0.354536; batch adversarial loss: 0.433687\n",
      "epoch 29; iter: 400; batch classifier loss: 0.432429; batch adversarial loss: 0.394772\n",
      "epoch 29; iter: 600; batch classifier loss: 0.474488; batch adversarial loss: 0.408622\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444165; batch adversarial loss: 0.400064\n",
      "epoch 30; iter: 200; batch classifier loss: 0.483344; batch adversarial loss: 0.353499\n",
      "epoch 30; iter: 400; batch classifier loss: 0.433430; batch adversarial loss: 0.322931\n",
      "epoch 30; iter: 600; batch classifier loss: 0.400891; batch adversarial loss: 0.411690\n",
      "epoch 31; iter: 0; batch classifier loss: 0.565921; batch adversarial loss: 0.395499\n",
      "epoch 31; iter: 200; batch classifier loss: 0.311192; batch adversarial loss: 0.407480\n",
      "epoch 31; iter: 400; batch classifier loss: 0.249565; batch adversarial loss: 0.422305\n",
      "epoch 31; iter: 600; batch classifier loss: 0.329378; batch adversarial loss: 0.365830\n",
      "epoch 32; iter: 0; batch classifier loss: 0.567599; batch adversarial loss: 0.347553\n",
      "epoch 32; iter: 200; batch classifier loss: 0.294330; batch adversarial loss: 0.381192\n",
      "epoch 32; iter: 400; batch classifier loss: 0.451428; batch adversarial loss: 0.378797\n",
      "epoch 32; iter: 600; batch classifier loss: 0.184293; batch adversarial loss: 0.452946\n",
      "epoch 33; iter: 0; batch classifier loss: 0.523949; batch adversarial loss: 0.383674\n",
      "epoch 33; iter: 200; batch classifier loss: 0.376540; batch adversarial loss: 0.263517\n",
      "epoch 33; iter: 400; batch classifier loss: 0.549860; batch adversarial loss: 0.496870\n",
      "epoch 33; iter: 600; batch classifier loss: 0.416470; batch adversarial loss: 0.401316\n",
      "epoch 34; iter: 0; batch classifier loss: 0.358997; batch adversarial loss: 0.516428\n",
      "epoch 34; iter: 200; batch classifier loss: 0.269530; batch adversarial loss: 0.360335\n",
      "epoch 34; iter: 400; batch classifier loss: 0.498422; batch adversarial loss: 0.398260\n",
      "epoch 34; iter: 600; batch classifier loss: 0.615778; batch adversarial loss: 0.311383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341685; batch adversarial loss: 0.354640\n",
      "epoch 35; iter: 200; batch classifier loss: 0.443811; batch adversarial loss: 0.400580\n",
      "epoch 35; iter: 400; batch classifier loss: 0.300164; batch adversarial loss: 0.371914\n",
      "epoch 35; iter: 600; batch classifier loss: 0.344495; batch adversarial loss: 0.402679\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492036; batch adversarial loss: 0.511428\n",
      "epoch 36; iter: 200; batch classifier loss: 0.453729; batch adversarial loss: 0.463144\n",
      "epoch 36; iter: 400; batch classifier loss: 0.363482; batch adversarial loss: 0.341634\n",
      "epoch 36; iter: 600; batch classifier loss: 0.392147; batch adversarial loss: 0.434069\n",
      "epoch 37; iter: 0; batch classifier loss: 0.293478; batch adversarial loss: 0.399356\n",
      "epoch 37; iter: 200; batch classifier loss: 0.739160; batch adversarial loss: 0.293002\n",
      "epoch 37; iter: 400; batch classifier loss: 0.350163; batch adversarial loss: 0.482044\n",
      "epoch 37; iter: 600; batch classifier loss: 0.411366; batch adversarial loss: 0.399106\n",
      "epoch 38; iter: 0; batch classifier loss: 0.362368; batch adversarial loss: 0.371348\n",
      "epoch 38; iter: 200; batch classifier loss: 0.508653; batch adversarial loss: 0.428155\n",
      "epoch 38; iter: 400; batch classifier loss: 0.282436; batch adversarial loss: 0.463089\n",
      "epoch 38; iter: 600; batch classifier loss: 0.480585; batch adversarial loss: 0.341550\n",
      "epoch 39; iter: 0; batch classifier loss: 0.313043; batch adversarial loss: 0.362297\n",
      "epoch 39; iter: 200; batch classifier loss: 0.476977; batch adversarial loss: 0.182686\n",
      "epoch 39; iter: 400; batch classifier loss: 0.316260; batch adversarial loss: 0.300994\n",
      "epoch 39; iter: 600; batch classifier loss: 0.341183; batch adversarial loss: 0.319507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.526539; batch adversarial loss: 0.344778\n",
      "epoch 40; iter: 200; batch classifier loss: 0.358854; batch adversarial loss: 0.377438\n",
      "epoch 40; iter: 400; batch classifier loss: 0.502411; batch adversarial loss: 0.408700\n",
      "epoch 40; iter: 600; batch classifier loss: 0.638031; batch adversarial loss: 0.449314\n",
      "epoch 41; iter: 0; batch classifier loss: 0.289966; batch adversarial loss: 0.550080\n",
      "epoch 41; iter: 200; batch classifier loss: 0.403241; batch adversarial loss: 0.581177\n",
      "epoch 41; iter: 400; batch classifier loss: 0.754794; batch adversarial loss: 0.379726\n",
      "epoch 41; iter: 600; batch classifier loss: 0.452849; batch adversarial loss: 0.437216\n",
      "epoch 42; iter: 0; batch classifier loss: 0.504095; batch adversarial loss: 0.450809\n",
      "epoch 42; iter: 200; batch classifier loss: 0.423858; batch adversarial loss: 0.386928\n",
      "epoch 42; iter: 400; batch classifier loss: 0.388650; batch adversarial loss: 0.344647\n",
      "epoch 42; iter: 600; batch classifier loss: 0.373038; batch adversarial loss: 0.401784\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454083; batch adversarial loss: 0.315592\n",
      "epoch 43; iter: 200; batch classifier loss: 0.364583; batch adversarial loss: 0.289163\n",
      "epoch 43; iter: 400; batch classifier loss: 0.527896; batch adversarial loss: 0.460741\n",
      "epoch 43; iter: 600; batch classifier loss: 0.475506; batch adversarial loss: 0.343551\n",
      "epoch 44; iter: 0; batch classifier loss: 0.345309; batch adversarial loss: 0.384863\n",
      "epoch 44; iter: 200; batch classifier loss: 0.526493; batch adversarial loss: 0.543850\n",
      "epoch 44; iter: 400; batch classifier loss: 0.320191; batch adversarial loss: 0.426755\n",
      "epoch 44; iter: 600; batch classifier loss: 0.406229; batch adversarial loss: 0.433281\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376731; batch adversarial loss: 0.407631\n",
      "epoch 45; iter: 200; batch classifier loss: 0.409458; batch adversarial loss: 0.352757\n",
      "epoch 45; iter: 400; batch classifier loss: 0.512457; batch adversarial loss: 0.464764\n",
      "epoch 45; iter: 600; batch classifier loss: 0.374693; batch adversarial loss: 0.405515\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407355; batch adversarial loss: 0.504714\n",
      "epoch 46; iter: 200; batch classifier loss: 0.427399; batch adversarial loss: 0.296715\n",
      "epoch 46; iter: 400; batch classifier loss: 0.408788; batch adversarial loss: 0.461567\n",
      "epoch 46; iter: 600; batch classifier loss: 0.313044; batch adversarial loss: 0.383884\n",
      "epoch 47; iter: 0; batch classifier loss: 0.355226; batch adversarial loss: 0.516523\n",
      "epoch 47; iter: 200; batch classifier loss: 0.325394; batch adversarial loss: 0.291859\n",
      "epoch 47; iter: 400; batch classifier loss: 0.470410; batch adversarial loss: 0.372441\n",
      "epoch 47; iter: 600; batch classifier loss: 0.653007; batch adversarial loss: 0.406355\n",
      "epoch 48; iter: 0; batch classifier loss: 0.501251; batch adversarial loss: 0.351016\n",
      "epoch 48; iter: 200; batch classifier loss: 0.452279; batch adversarial loss: 0.405184\n",
      "epoch 48; iter: 400; batch classifier loss: 0.383687; batch adversarial loss: 0.346126\n",
      "epoch 48; iter: 600; batch classifier loss: 0.258046; batch adversarial loss: 0.482228\n",
      "epoch 49; iter: 0; batch classifier loss: 0.330061; batch adversarial loss: 0.402365\n",
      "epoch 49; iter: 200; batch classifier loss: 0.665666; batch adversarial loss: 0.379778\n",
      "epoch 49; iter: 400; batch classifier loss: 0.403466; batch adversarial loss: 0.459901\n",
      "epoch 49; iter: 600; batch classifier loss: 0.424408; batch adversarial loss: 0.407823\n",
      "epoch 0; iter: 0; batch classifier loss: 25.623575; batch adversarial loss: 0.595830\n",
      "epoch 0; iter: 200; batch classifier loss: 3.380630; batch adversarial loss: 0.590595\n",
      "epoch 0; iter: 400; batch classifier loss: 3.174987; batch adversarial loss: 0.520890\n",
      "epoch 0; iter: 600; batch classifier loss: 0.715639; batch adversarial loss: 0.517181\n",
      "epoch 1; iter: 0; batch classifier loss: 6.103698; batch adversarial loss: 0.504203\n",
      "epoch 1; iter: 200; batch classifier loss: 2.104395; batch adversarial loss: 0.471624\n",
      "epoch 1; iter: 400; batch classifier loss: 5.601260; batch adversarial loss: 0.431278\n",
      "epoch 1; iter: 600; batch classifier loss: 2.992956; batch adversarial loss: 0.393004\n",
      "epoch 2; iter: 0; batch classifier loss: 0.836517; batch adversarial loss: 0.435894\n",
      "epoch 2; iter: 200; batch classifier loss: 0.911585; batch adversarial loss: 0.322710\n",
      "epoch 2; iter: 400; batch classifier loss: 0.898279; batch adversarial loss: 0.356248\n",
      "epoch 2; iter: 600; batch classifier loss: 0.602462; batch adversarial loss: 0.443943\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575564; batch adversarial loss: 0.448541\n",
      "epoch 3; iter: 200; batch classifier loss: 0.677955; batch adversarial loss: 0.394881\n",
      "epoch 3; iter: 400; batch classifier loss: 0.466827; batch adversarial loss: 0.429387\n",
      "epoch 3; iter: 600; batch classifier loss: 0.421742; batch adversarial loss: 0.405608\n",
      "epoch 4; iter: 0; batch classifier loss: 0.748830; batch adversarial loss: 0.355585\n",
      "epoch 4; iter: 200; batch classifier loss: 0.744934; batch adversarial loss: 0.400401\n",
      "epoch 4; iter: 400; batch classifier loss: 0.395187; batch adversarial loss: 0.320973\n",
      "epoch 4; iter: 600; batch classifier loss: 1.225315; batch adversarial loss: 0.554796\n",
      "epoch 5; iter: 0; batch classifier loss: 0.444476; batch adversarial loss: 0.412611\n",
      "epoch 5; iter: 200; batch classifier loss: 0.788281; batch adversarial loss: 0.452599\n",
      "epoch 5; iter: 400; batch classifier loss: 0.387803; batch adversarial loss: 0.335742\n",
      "epoch 5; iter: 600; batch classifier loss: 0.443955; batch adversarial loss: 0.437413\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388866; batch adversarial loss: 0.401834\n",
      "epoch 6; iter: 200; batch classifier loss: 0.311159; batch adversarial loss: 0.424409\n",
      "epoch 6; iter: 400; batch classifier loss: 0.444349; batch adversarial loss: 0.605476\n",
      "epoch 6; iter: 600; batch classifier loss: 0.436416; batch adversarial loss: 0.373551\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516248; batch adversarial loss: 0.447423\n",
      "epoch 7; iter: 200; batch classifier loss: 0.398592; batch adversarial loss: 0.459108\n",
      "epoch 7; iter: 400; batch classifier loss: 0.377544; batch adversarial loss: 0.441705\n",
      "epoch 7; iter: 600; batch classifier loss: 0.496454; batch adversarial loss: 0.380647\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507287; batch adversarial loss: 0.457502\n",
      "epoch 8; iter: 200; batch classifier loss: 0.343795; batch adversarial loss: 0.295742\n",
      "epoch 8; iter: 400; batch classifier loss: 0.422618; batch adversarial loss: 0.395648\n",
      "epoch 8; iter: 600; batch classifier loss: 0.466883; batch adversarial loss: 0.352242\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335000; batch adversarial loss: 0.337198\n",
      "epoch 9; iter: 200; batch classifier loss: 0.327460; batch adversarial loss: 0.528616\n",
      "epoch 9; iter: 400; batch classifier loss: 0.430404; batch adversarial loss: 0.378243\n",
      "epoch 9; iter: 600; batch classifier loss: 0.475096; batch adversarial loss: 0.507853\n",
      "epoch 10; iter: 0; batch classifier loss: 0.380316; batch adversarial loss: 0.344569\n",
      "epoch 10; iter: 200; batch classifier loss: 0.333397; batch adversarial loss: 0.425588\n",
      "epoch 10; iter: 400; batch classifier loss: 0.384093; batch adversarial loss: 0.398837\n",
      "epoch 10; iter: 600; batch classifier loss: 0.331438; batch adversarial loss: 0.319106\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320186; batch adversarial loss: 0.388421\n",
      "epoch 11; iter: 200; batch classifier loss: 0.344366; batch adversarial loss: 0.430152\n",
      "epoch 11; iter: 400; batch classifier loss: 0.626416; batch adversarial loss: 0.399288\n",
      "epoch 11; iter: 600; batch classifier loss: 0.300186; batch adversarial loss: 0.395941\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348687; batch adversarial loss: 0.435177\n",
      "epoch 12; iter: 200; batch classifier loss: 0.492922; batch adversarial loss: 0.460489\n",
      "epoch 12; iter: 400; batch classifier loss: 0.477650; batch adversarial loss: 0.646702\n",
      "epoch 12; iter: 600; batch classifier loss: 0.374275; batch adversarial loss: 0.424548\n",
      "epoch 13; iter: 0; batch classifier loss: 0.333031; batch adversarial loss: 0.317837\n",
      "epoch 13; iter: 200; batch classifier loss: 0.327200; batch adversarial loss: 0.512867\n",
      "epoch 13; iter: 400; batch classifier loss: 0.374810; batch adversarial loss: 0.452393\n",
      "epoch 13; iter: 600; batch classifier loss: 0.367346; batch adversarial loss: 0.435565\n",
      "epoch 14; iter: 0; batch classifier loss: 0.388718; batch adversarial loss: 0.317265\n",
      "epoch 14; iter: 200; batch classifier loss: 0.259674; batch adversarial loss: 0.590092\n",
      "epoch 14; iter: 400; batch classifier loss: 0.383665; batch adversarial loss: 0.448028\n",
      "epoch 14; iter: 600; batch classifier loss: 0.449397; batch adversarial loss: 0.438452\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297857; batch adversarial loss: 0.379831\n",
      "epoch 15; iter: 200; batch classifier loss: 0.245591; batch adversarial loss: 0.407557\n",
      "epoch 15; iter: 400; batch classifier loss: 0.330522; batch adversarial loss: 0.349339\n",
      "epoch 15; iter: 600; batch classifier loss: 0.333883; batch adversarial loss: 0.396954\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364294; batch adversarial loss: 0.401542\n",
      "epoch 16; iter: 200; batch classifier loss: 0.284959; batch adversarial loss: 0.485361\n",
      "epoch 16; iter: 400; batch classifier loss: 0.402722; batch adversarial loss: 0.399021\n",
      "epoch 16; iter: 600; batch classifier loss: 0.446989; batch adversarial loss: 0.404313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.297795; batch adversarial loss: 0.426950\n",
      "epoch 17; iter: 200; batch classifier loss: 0.457879; batch adversarial loss: 0.462190\n",
      "epoch 17; iter: 400; batch classifier loss: 0.425272; batch adversarial loss: 0.387237\n",
      "epoch 17; iter: 600; batch classifier loss: 0.369869; batch adversarial loss: 0.391400\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361561; batch adversarial loss: 0.397441\n",
      "epoch 18; iter: 200; batch classifier loss: 0.423023; batch adversarial loss: 0.368361\n",
      "epoch 18; iter: 400; batch classifier loss: 0.405672; batch adversarial loss: 0.411837\n",
      "epoch 18; iter: 600; batch classifier loss: 0.423529; batch adversarial loss: 0.459008\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472074; batch adversarial loss: 0.433263\n",
      "epoch 19; iter: 200; batch classifier loss: 0.404543; batch adversarial loss: 0.398004\n",
      "epoch 19; iter: 400; batch classifier loss: 0.338063; batch adversarial loss: 0.404769\n",
      "epoch 19; iter: 600; batch classifier loss: 0.444755; batch adversarial loss: 0.507007\n",
      "epoch 20; iter: 0; batch classifier loss: 0.308818; batch adversarial loss: 0.322834\n",
      "epoch 20; iter: 200; batch classifier loss: 0.608370; batch adversarial loss: 0.552091\n",
      "epoch 20; iter: 400; batch classifier loss: 0.401269; batch adversarial loss: 0.396476\n",
      "epoch 20; iter: 600; batch classifier loss: 0.222572; batch adversarial loss: 0.327535\n",
      "epoch 21; iter: 0; batch classifier loss: 0.393513; batch adversarial loss: 0.478424\n",
      "epoch 21; iter: 200; batch classifier loss: 0.447332; batch adversarial loss: 0.301698\n",
      "epoch 21; iter: 400; batch classifier loss: 0.293327; batch adversarial loss: 0.482181\n",
      "epoch 21; iter: 600; batch classifier loss: 0.373096; batch adversarial loss: 0.518056\n",
      "epoch 22; iter: 0; batch classifier loss: 0.326501; batch adversarial loss: 0.446472\n",
      "epoch 22; iter: 200; batch classifier loss: 0.339126; batch adversarial loss: 0.261804\n",
      "epoch 22; iter: 400; batch classifier loss: 0.349459; batch adversarial loss: 0.427239\n",
      "epoch 22; iter: 600; batch classifier loss: 0.384489; batch adversarial loss: 0.540609\n",
      "epoch 23; iter: 0; batch classifier loss: 0.255214; batch adversarial loss: 0.552790\n",
      "epoch 23; iter: 200; batch classifier loss: 0.358490; batch adversarial loss: 0.425427\n",
      "epoch 23; iter: 400; batch classifier loss: 0.227418; batch adversarial loss: 0.368972\n",
      "epoch 23; iter: 600; batch classifier loss: 0.346745; batch adversarial loss: 0.438785\n",
      "epoch 24; iter: 0; batch classifier loss: 0.399884; batch adversarial loss: 0.451083\n",
      "epoch 24; iter: 200; batch classifier loss: 0.351353; batch adversarial loss: 0.403932\n",
      "epoch 24; iter: 400; batch classifier loss: 0.330846; batch adversarial loss: 0.260501\n",
      "epoch 24; iter: 600; batch classifier loss: 0.309560; batch adversarial loss: 0.465366\n",
      "epoch 25; iter: 0; batch classifier loss: 0.295393; batch adversarial loss: 0.236564\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360958; batch adversarial loss: 0.496062\n",
      "epoch 25; iter: 400; batch classifier loss: 0.447677; batch adversarial loss: 0.395056\n",
      "epoch 25; iter: 600; batch classifier loss: 0.371368; batch adversarial loss: 0.458163\n",
      "epoch 26; iter: 0; batch classifier loss: 0.431085; batch adversarial loss: 0.414720\n",
      "epoch 26; iter: 200; batch classifier loss: 0.544519; batch adversarial loss: 0.466361\n",
      "epoch 26; iter: 400; batch classifier loss: 0.494832; batch adversarial loss: 0.388028\n",
      "epoch 26; iter: 600; batch classifier loss: 0.401796; batch adversarial loss: 0.373065\n",
      "epoch 27; iter: 0; batch classifier loss: 0.225490; batch adversarial loss: 0.322277\n",
      "epoch 27; iter: 200; batch classifier loss: 0.363804; batch adversarial loss: 0.460214\n",
      "epoch 27; iter: 400; batch classifier loss: 0.643322; batch adversarial loss: 0.469142\n",
      "epoch 27; iter: 600; batch classifier loss: 0.481566; batch adversarial loss: 0.471859\n",
      "epoch 28; iter: 0; batch classifier loss: 0.469218; batch adversarial loss: 0.475296\n",
      "epoch 28; iter: 200; batch classifier loss: 0.334726; batch adversarial loss: 0.529062\n",
      "epoch 28; iter: 400; batch classifier loss: 0.237536; batch adversarial loss: 0.404001\n",
      "epoch 28; iter: 600; batch classifier loss: 0.276645; batch adversarial loss: 0.468820\n",
      "epoch 29; iter: 0; batch classifier loss: 0.501629; batch adversarial loss: 0.412108\n",
      "epoch 29; iter: 200; batch classifier loss: 0.295187; batch adversarial loss: 0.326808\n",
      "epoch 29; iter: 400; batch classifier loss: 0.478289; batch adversarial loss: 0.524971\n",
      "epoch 29; iter: 600; batch classifier loss: 0.407837; batch adversarial loss: 0.482193\n",
      "epoch 30; iter: 0; batch classifier loss: 0.537693; batch adversarial loss: 0.564830\n",
      "epoch 30; iter: 200; batch classifier loss: 0.313988; batch adversarial loss: 0.507972\n",
      "epoch 30; iter: 400; batch classifier loss: 0.300442; batch adversarial loss: 0.360428\n",
      "epoch 30; iter: 600; batch classifier loss: 0.298199; batch adversarial loss: 0.420852\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436845; batch adversarial loss: 0.506138\n",
      "epoch 31; iter: 200; batch classifier loss: 0.359933; batch adversarial loss: 0.500756\n",
      "epoch 31; iter: 400; batch classifier loss: 0.334659; batch adversarial loss: 0.368238\n",
      "epoch 31; iter: 600; batch classifier loss: 0.464778; batch adversarial loss: 0.383886\n",
      "epoch 32; iter: 0; batch classifier loss: 0.402371; batch adversarial loss: 0.553621\n",
      "epoch 32; iter: 200; batch classifier loss: 0.374124; batch adversarial loss: 0.394593\n",
      "epoch 32; iter: 400; batch classifier loss: 0.510091; batch adversarial loss: 0.384518\n",
      "epoch 32; iter: 600; batch classifier loss: 0.652124; batch adversarial loss: 0.306912\n",
      "epoch 33; iter: 0; batch classifier loss: 0.644961; batch adversarial loss: 0.461131\n",
      "epoch 33; iter: 200; batch classifier loss: 0.284742; batch adversarial loss: 0.344307\n",
      "epoch 33; iter: 400; batch classifier loss: 0.383934; batch adversarial loss: 0.504926\n",
      "epoch 33; iter: 600; batch classifier loss: 0.310056; batch adversarial loss: 0.330715\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401130; batch adversarial loss: 0.439327\n",
      "epoch 34; iter: 200; batch classifier loss: 0.349124; batch adversarial loss: 0.429679\n",
      "epoch 34; iter: 400; batch classifier loss: 0.434103; batch adversarial loss: 0.381136\n",
      "epoch 34; iter: 600; batch classifier loss: 0.174502; batch adversarial loss: 0.530885\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437271; batch adversarial loss: 0.439842\n",
      "epoch 35; iter: 200; batch classifier loss: 0.385172; batch adversarial loss: 0.455980\n",
      "epoch 35; iter: 400; batch classifier loss: 0.396069; batch adversarial loss: 0.524931\n",
      "epoch 35; iter: 600; batch classifier loss: 0.532052; batch adversarial loss: 0.429218\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415691; batch adversarial loss: 0.432124\n",
      "epoch 36; iter: 200; batch classifier loss: 0.335571; batch adversarial loss: 0.450620\n",
      "epoch 36; iter: 400; batch classifier loss: 0.444499; batch adversarial loss: 0.379917\n",
      "epoch 36; iter: 600; batch classifier loss: 0.317275; batch adversarial loss: 0.401679\n",
      "epoch 37; iter: 0; batch classifier loss: 0.315402; batch adversarial loss: 0.473645\n",
      "epoch 37; iter: 200; batch classifier loss: 0.435854; batch adversarial loss: 0.401953\n",
      "epoch 37; iter: 400; batch classifier loss: 0.369963; batch adversarial loss: 0.401913\n",
      "epoch 37; iter: 600; batch classifier loss: 0.352684; batch adversarial loss: 0.400368\n",
      "epoch 38; iter: 0; batch classifier loss: 0.501675; batch adversarial loss: 0.581985\n",
      "epoch 38; iter: 200; batch classifier loss: 0.448591; batch adversarial loss: 0.518100\n",
      "epoch 38; iter: 400; batch classifier loss: 0.422074; batch adversarial loss: 0.481311\n",
      "epoch 38; iter: 600; batch classifier loss: 0.375039; batch adversarial loss: 0.404837\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377886; batch adversarial loss: 0.478201\n",
      "epoch 39; iter: 200; batch classifier loss: 0.495873; batch adversarial loss: 0.436401\n",
      "epoch 39; iter: 400; batch classifier loss: 0.479666; batch adversarial loss: 0.231573\n",
      "epoch 39; iter: 600; batch classifier loss: 0.532145; batch adversarial loss: 0.380132\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367329; batch adversarial loss: 0.483068\n",
      "epoch 40; iter: 200; batch classifier loss: 0.473774; batch adversarial loss: 0.271131\n",
      "epoch 40; iter: 400; batch classifier loss: 0.434824; batch adversarial loss: 0.366961\n",
      "epoch 40; iter: 600; batch classifier loss: 0.306925; batch adversarial loss: 0.394959\n",
      "epoch 41; iter: 0; batch classifier loss: 0.500457; batch adversarial loss: 0.339606\n",
      "epoch 41; iter: 200; batch classifier loss: 0.486084; batch adversarial loss: 0.482375\n",
      "epoch 41; iter: 400; batch classifier loss: 0.270576; batch adversarial loss: 0.526619\n",
      "epoch 41; iter: 600; batch classifier loss: 0.304433; batch adversarial loss: 0.407103\n",
      "epoch 42; iter: 0; batch classifier loss: 0.331925; batch adversarial loss: 0.374572\n",
      "epoch 42; iter: 200; batch classifier loss: 0.498737; batch adversarial loss: 0.477681\n",
      "epoch 42; iter: 400; batch classifier loss: 0.511413; batch adversarial loss: 0.485165\n",
      "epoch 42; iter: 600; batch classifier loss: 0.458669; batch adversarial loss: 0.398631\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426386; batch adversarial loss: 0.402693\n",
      "epoch 43; iter: 200; batch classifier loss: 0.490220; batch adversarial loss: 0.452685\n",
      "epoch 43; iter: 400; batch classifier loss: 0.294589; batch adversarial loss: 0.331431\n",
      "epoch 43; iter: 600; batch classifier loss: 0.177741; batch adversarial loss: 0.531093\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474582; batch adversarial loss: 0.454786\n",
      "epoch 44; iter: 200; batch classifier loss: 0.324096; batch adversarial loss: 0.457015\n",
      "epoch 44; iter: 400; batch classifier loss: 0.302201; batch adversarial loss: 0.527770\n",
      "epoch 44; iter: 600; batch classifier loss: 0.401782; batch adversarial loss: 0.397513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.537070; batch adversarial loss: 0.449521\n",
      "epoch 45; iter: 200; batch classifier loss: 0.313825; batch adversarial loss: 0.762804\n",
      "epoch 45; iter: 400; batch classifier loss: 0.590880; batch adversarial loss: 0.346784\n",
      "epoch 45; iter: 600; batch classifier loss: 0.252671; batch adversarial loss: 0.533168\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356156; batch adversarial loss: 0.434043\n",
      "epoch 46; iter: 200; batch classifier loss: 0.425708; batch adversarial loss: 0.402383\n",
      "epoch 46; iter: 400; batch classifier loss: 0.378909; batch adversarial loss: 0.510090\n",
      "epoch 46; iter: 600; batch classifier loss: 0.320641; batch adversarial loss: 0.376314\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393883; batch adversarial loss: 0.427235\n",
      "epoch 47; iter: 200; batch classifier loss: 0.320557; batch adversarial loss: 0.477791\n",
      "epoch 47; iter: 400; batch classifier loss: 0.355218; batch adversarial loss: 0.356131\n",
      "epoch 47; iter: 600; batch classifier loss: 0.442799; batch adversarial loss: 0.449142\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379280; batch adversarial loss: 0.404076\n",
      "epoch 48; iter: 200; batch classifier loss: 0.244365; batch adversarial loss: 0.437701\n",
      "epoch 48; iter: 400; batch classifier loss: 0.356220; batch adversarial loss: 0.416190\n",
      "epoch 48; iter: 600; batch classifier loss: 0.487170; batch adversarial loss: 0.315360\n",
      "epoch 49; iter: 0; batch classifier loss: 0.354688; batch adversarial loss: 0.352430\n",
      "epoch 49; iter: 200; batch classifier loss: 0.594922; batch adversarial loss: 0.427826\n",
      "epoch 49; iter: 400; batch classifier loss: 0.459056; batch adversarial loss: 0.354344\n",
      "epoch 49; iter: 600; batch classifier loss: 0.440602; batch adversarial loss: 0.311581\n",
      "epoch 0; iter: 0; batch classifier loss: 18.916830; batch adversarial loss: 1.563075\n",
      "epoch 0; iter: 200; batch classifier loss: 3.341803; batch adversarial loss: 1.060519\n",
      "epoch 0; iter: 400; batch classifier loss: 8.132544; batch adversarial loss: 0.896858\n",
      "epoch 0; iter: 600; batch classifier loss: 2.367644; batch adversarial loss: 0.727214\n",
      "epoch 1; iter: 0; batch classifier loss: 1.099574; batch adversarial loss: 0.743995\n",
      "epoch 1; iter: 200; batch classifier loss: 4.441913; batch adversarial loss: 0.588525\n",
      "epoch 1; iter: 400; batch classifier loss: 0.596927; batch adversarial loss: 0.539648\n",
      "epoch 1; iter: 600; batch classifier loss: 2.569403; batch adversarial loss: 0.423896\n",
      "epoch 2; iter: 0; batch classifier loss: 6.696951; batch adversarial loss: 0.433369\n",
      "epoch 2; iter: 200; batch classifier loss: 4.661471; batch adversarial loss: 0.420714\n",
      "epoch 2; iter: 400; batch classifier loss: 2.209981; batch adversarial loss: 0.479328\n",
      "epoch 2; iter: 600; batch classifier loss: 6.763453; batch adversarial loss: 0.385099\n",
      "epoch 3; iter: 0; batch classifier loss: 1.938400; batch adversarial loss: 0.398915\n",
      "epoch 3; iter: 200; batch classifier loss: 1.975144; batch adversarial loss: 0.355091\n",
      "epoch 3; iter: 400; batch classifier loss: 1.284048; batch adversarial loss: 0.405344\n",
      "epoch 3; iter: 600; batch classifier loss: 1.785889; batch adversarial loss: 0.388929\n",
      "epoch 4; iter: 0; batch classifier loss: 0.530881; batch adversarial loss: 0.408722\n",
      "epoch 4; iter: 200; batch classifier loss: 0.909990; batch adversarial loss: 0.472756\n",
      "epoch 4; iter: 400; batch classifier loss: 0.826294; batch adversarial loss: 0.421453\n",
      "epoch 4; iter: 600; batch classifier loss: 1.247769; batch adversarial loss: 0.469889\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421845; batch adversarial loss: 0.428929\n",
      "epoch 5; iter: 200; batch classifier loss: 0.578330; batch adversarial loss: 0.519313\n",
      "epoch 5; iter: 400; batch classifier loss: 0.401053; batch adversarial loss: 0.442858\n",
      "epoch 5; iter: 600; batch classifier loss: 0.738185; batch adversarial loss: 0.459223\n",
      "epoch 6; iter: 0; batch classifier loss: 0.412231; batch adversarial loss: 0.450465\n",
      "epoch 6; iter: 200; batch classifier loss: 0.421044; batch adversarial loss: 0.385326\n",
      "epoch 6; iter: 400; batch classifier loss: 0.429638; batch adversarial loss: 0.337397\n",
      "epoch 6; iter: 600; batch classifier loss: 0.557816; batch adversarial loss: 0.474065\n",
      "epoch 7; iter: 0; batch classifier loss: 0.415243; batch adversarial loss: 0.491585\n",
      "epoch 7; iter: 200; batch classifier loss: 0.354836; batch adversarial loss: 0.380908\n",
      "epoch 7; iter: 400; batch classifier loss: 0.756922; batch adversarial loss: 0.486807\n",
      "epoch 7; iter: 600; batch classifier loss: 0.339459; batch adversarial loss: 0.443107\n",
      "epoch 8; iter: 0; batch classifier loss: 0.296624; batch adversarial loss: 0.501944\n",
      "epoch 8; iter: 200; batch classifier loss: 0.605469; batch adversarial loss: 0.406573\n",
      "epoch 8; iter: 400; batch classifier loss: 0.401006; batch adversarial loss: 0.400153\n",
      "epoch 8; iter: 600; batch classifier loss: 0.316807; batch adversarial loss: 0.432087\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516345; batch adversarial loss: 0.495316\n",
      "epoch 9; iter: 200; batch classifier loss: 0.300412; batch adversarial loss: 0.485604\n",
      "epoch 9; iter: 400; batch classifier loss: 0.404024; batch adversarial loss: 0.341085\n",
      "epoch 9; iter: 600; batch classifier loss: 0.284893; batch adversarial loss: 0.284600\n",
      "epoch 10; iter: 0; batch classifier loss: 0.285029; batch adversarial loss: 0.335924\n",
      "epoch 10; iter: 200; batch classifier loss: 0.379501; batch adversarial loss: 0.450656\n",
      "epoch 10; iter: 400; batch classifier loss: 0.410170; batch adversarial loss: 0.356716\n",
      "epoch 10; iter: 600; batch classifier loss: 0.333127; batch adversarial loss: 0.417940\n",
      "epoch 11; iter: 0; batch classifier loss: 0.405435; batch adversarial loss: 0.396313\n",
      "epoch 11; iter: 200; batch classifier loss: 0.284511; batch adversarial loss: 0.293355\n",
      "epoch 11; iter: 400; batch classifier loss: 0.395245; batch adversarial loss: 0.421131\n",
      "epoch 11; iter: 600; batch classifier loss: 0.420153; batch adversarial loss: 0.478471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353010; batch adversarial loss: 0.400251\n",
      "epoch 12; iter: 200; batch classifier loss: 0.380777; batch adversarial loss: 0.436240\n",
      "epoch 12; iter: 400; batch classifier loss: 0.364205; batch adversarial loss: 0.427948\n",
      "epoch 12; iter: 600; batch classifier loss: 0.330288; batch adversarial loss: 0.335482\n",
      "epoch 13; iter: 0; batch classifier loss: 0.236393; batch adversarial loss: 0.361791\n",
      "epoch 13; iter: 200; batch classifier loss: 0.327808; batch adversarial loss: 0.629072\n",
      "epoch 13; iter: 400; batch classifier loss: 0.359773; batch adversarial loss: 0.288809\n",
      "epoch 13; iter: 600; batch classifier loss: 0.538520; batch adversarial loss: 0.491199\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294536; batch adversarial loss: 0.490650\n",
      "epoch 14; iter: 200; batch classifier loss: 0.299713; batch adversarial loss: 0.339978\n",
      "epoch 14; iter: 400; batch classifier loss: 0.284986; batch adversarial loss: 0.289186\n",
      "epoch 14; iter: 600; batch classifier loss: 0.236250; batch adversarial loss: 0.338146\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386616; batch adversarial loss: 0.356923\n",
      "epoch 15; iter: 200; batch classifier loss: 0.449284; batch adversarial loss: 0.452767\n",
      "epoch 15; iter: 400; batch classifier loss: 0.432876; batch adversarial loss: 0.521178\n",
      "epoch 15; iter: 600; batch classifier loss: 0.374388; batch adversarial loss: 0.379534\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287200; batch adversarial loss: 0.369497\n",
      "epoch 16; iter: 200; batch classifier loss: 0.393564; batch adversarial loss: 0.359623\n",
      "epoch 16; iter: 400; batch classifier loss: 0.253430; batch adversarial loss: 0.371456\n",
      "epoch 16; iter: 600; batch classifier loss: 0.305239; batch adversarial loss: 0.328720\n",
      "epoch 17; iter: 0; batch classifier loss: 0.431248; batch adversarial loss: 0.400048\n",
      "epoch 17; iter: 200; batch classifier loss: 0.328826; batch adversarial loss: 0.424405\n",
      "epoch 17; iter: 400; batch classifier loss: 0.377098; batch adversarial loss: 0.444420\n",
      "epoch 17; iter: 600; batch classifier loss: 0.279531; batch adversarial loss: 0.262316\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235333; batch adversarial loss: 0.531870\n",
      "epoch 18; iter: 200; batch classifier loss: 0.293835; batch adversarial loss: 0.599144\n",
      "epoch 18; iter: 400; batch classifier loss: 0.333981; batch adversarial loss: 0.317007\n",
      "epoch 18; iter: 600; batch classifier loss: 0.365035; batch adversarial loss: 0.325036\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261401; batch adversarial loss: 0.442953\n",
      "epoch 19; iter: 200; batch classifier loss: 0.228899; batch adversarial loss: 0.598276\n",
      "epoch 19; iter: 400; batch classifier loss: 0.347110; batch adversarial loss: 0.368710\n",
      "epoch 19; iter: 600; batch classifier loss: 0.310566; batch adversarial loss: 0.462388\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285352; batch adversarial loss: 0.465024\n",
      "epoch 20; iter: 200; batch classifier loss: 0.318123; batch adversarial loss: 0.400649\n",
      "epoch 20; iter: 400; batch classifier loss: 0.392809; batch adversarial loss: 0.385744\n",
      "epoch 20; iter: 600; batch classifier loss: 0.323467; batch adversarial loss: 0.242883\n",
      "epoch 21; iter: 0; batch classifier loss: 0.333627; batch adversarial loss: 0.520026\n",
      "epoch 21; iter: 200; batch classifier loss: 0.231431; batch adversarial loss: 0.399876\n",
      "epoch 21; iter: 400; batch classifier loss: 0.349417; batch adversarial loss: 0.343821\n",
      "epoch 21; iter: 600; batch classifier loss: 0.303039; batch adversarial loss: 0.304371\n",
      "epoch 22; iter: 0; batch classifier loss: 0.368003; batch adversarial loss: 0.368341\n",
      "epoch 22; iter: 200; batch classifier loss: 0.203112; batch adversarial loss: 0.516464\n",
      "epoch 22; iter: 400; batch classifier loss: 0.382625; batch adversarial loss: 0.342844\n",
      "epoch 22; iter: 600; batch classifier loss: 0.356373; batch adversarial loss: 0.486941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.357971; batch adversarial loss: 0.322382\n",
      "epoch 23; iter: 200; batch classifier loss: 0.345223; batch adversarial loss: 0.431049\n",
      "epoch 23; iter: 400; batch classifier loss: 0.345349; batch adversarial loss: 0.451608\n",
      "epoch 23; iter: 600; batch classifier loss: 0.255658; batch adversarial loss: 0.428756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.377957; batch adversarial loss: 0.470089\n",
      "epoch 24; iter: 200; batch classifier loss: 0.344490; batch adversarial loss: 0.546045\n",
      "epoch 24; iter: 400; batch classifier loss: 0.370858; batch adversarial loss: 0.400521\n",
      "epoch 24; iter: 600; batch classifier loss: 0.366095; batch adversarial loss: 0.432967\n",
      "epoch 25; iter: 0; batch classifier loss: 0.300159; batch adversarial loss: 0.294352\n",
      "epoch 25; iter: 200; batch classifier loss: 0.488822; batch adversarial loss: 0.508961\n",
      "epoch 25; iter: 400; batch classifier loss: 0.321037; batch adversarial loss: 0.459847\n",
      "epoch 25; iter: 600; batch classifier loss: 0.422291; batch adversarial loss: 0.343154\n",
      "epoch 26; iter: 0; batch classifier loss: 0.180867; batch adversarial loss: 0.378701\n",
      "epoch 26; iter: 200; batch classifier loss: 0.367506; batch adversarial loss: 0.492693\n",
      "epoch 26; iter: 400; batch classifier loss: 0.400903; batch adversarial loss: 0.341283\n",
      "epoch 26; iter: 600; batch classifier loss: 0.325674; batch adversarial loss: 0.534918\n",
      "epoch 27; iter: 0; batch classifier loss: 0.354418; batch adversarial loss: 0.318315\n",
      "epoch 27; iter: 200; batch classifier loss: 0.444013; batch adversarial loss: 0.416524\n",
      "epoch 27; iter: 400; batch classifier loss: 0.409538; batch adversarial loss: 0.317502\n",
      "epoch 27; iter: 600; batch classifier loss: 0.267555; batch adversarial loss: 0.432335\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416055; batch adversarial loss: 0.464894\n",
      "epoch 28; iter: 200; batch classifier loss: 0.387634; batch adversarial loss: 0.538805\n",
      "epoch 28; iter: 400; batch classifier loss: 0.329269; batch adversarial loss: 0.477647\n",
      "epoch 28; iter: 600; batch classifier loss: 0.396622; batch adversarial loss: 0.434057\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303271; batch adversarial loss: 0.396140\n",
      "epoch 29; iter: 200; batch classifier loss: 0.325321; batch adversarial loss: 0.374954\n",
      "epoch 29; iter: 400; batch classifier loss: 0.518477; batch adversarial loss: 0.426215\n",
      "epoch 29; iter: 600; batch classifier loss: 0.315661; batch adversarial loss: 0.421293\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329296; batch adversarial loss: 0.535044\n",
      "epoch 30; iter: 200; batch classifier loss: 0.435186; batch adversarial loss: 0.238036\n",
      "epoch 30; iter: 400; batch classifier loss: 0.418121; batch adversarial loss: 0.412947\n",
      "epoch 30; iter: 600; batch classifier loss: 0.356866; batch adversarial loss: 0.467023\n",
      "epoch 31; iter: 0; batch classifier loss: 0.541446; batch adversarial loss: 0.429338\n",
      "epoch 31; iter: 200; batch classifier loss: 0.323384; batch adversarial loss: 0.404441\n",
      "epoch 31; iter: 400; batch classifier loss: 0.391085; batch adversarial loss: 0.324060\n",
      "epoch 31; iter: 600; batch classifier loss: 0.324362; batch adversarial loss: 0.544679\n",
      "epoch 32; iter: 0; batch classifier loss: 0.275710; batch adversarial loss: 0.448996\n",
      "epoch 32; iter: 200; batch classifier loss: 0.428321; batch adversarial loss: 0.516476\n",
      "epoch 32; iter: 400; batch classifier loss: 0.263973; batch adversarial loss: 0.374016\n",
      "epoch 32; iter: 600; batch classifier loss: 0.412637; batch adversarial loss: 0.584261\n",
      "epoch 33; iter: 0; batch classifier loss: 0.384112; batch adversarial loss: 0.523295\n",
      "epoch 33; iter: 200; batch classifier loss: 0.313003; batch adversarial loss: 0.347311\n",
      "epoch 33; iter: 400; batch classifier loss: 0.252977; batch adversarial loss: 0.318244\n",
      "epoch 33; iter: 600; batch classifier loss: 0.279333; batch adversarial loss: 0.399217\n",
      "epoch 34; iter: 0; batch classifier loss: 0.333406; batch adversarial loss: 0.387674\n",
      "epoch 34; iter: 200; batch classifier loss: 0.340548; batch adversarial loss: 0.538471\n",
      "epoch 34; iter: 400; batch classifier loss: 0.338870; batch adversarial loss: 0.378222\n",
      "epoch 34; iter: 600; batch classifier loss: 0.319576; batch adversarial loss: 0.326568\n",
      "epoch 35; iter: 0; batch classifier loss: 0.276781; batch adversarial loss: 0.419631\n",
      "epoch 35; iter: 200; batch classifier loss: 0.325119; batch adversarial loss: 0.483277\n",
      "epoch 35; iter: 400; batch classifier loss: 0.407310; batch adversarial loss: 0.319533\n",
      "epoch 35; iter: 600; batch classifier loss: 0.414313; batch adversarial loss: 0.448987\n",
      "epoch 36; iter: 0; batch classifier loss: 0.319631; batch adversarial loss: 0.459576\n",
      "epoch 36; iter: 200; batch classifier loss: 0.377209; batch adversarial loss: 0.431132\n",
      "epoch 36; iter: 400; batch classifier loss: 0.291964; batch adversarial loss: 0.375198\n",
      "epoch 36; iter: 600; batch classifier loss: 0.298773; batch adversarial loss: 0.435490\n",
      "epoch 37; iter: 0; batch classifier loss: 0.318449; batch adversarial loss: 0.502458\n",
      "epoch 37; iter: 200; batch classifier loss: 0.300130; batch adversarial loss: 0.454773\n",
      "epoch 37; iter: 400; batch classifier loss: 0.463654; batch adversarial loss: 0.467118\n",
      "epoch 37; iter: 600; batch classifier loss: 0.185591; batch adversarial loss: 0.425638\n",
      "epoch 38; iter: 0; batch classifier loss: 0.311990; batch adversarial loss: 0.372285\n",
      "epoch 38; iter: 200; batch classifier loss: 0.323336; batch adversarial loss: 0.510714\n",
      "epoch 38; iter: 400; batch classifier loss: 0.347828; batch adversarial loss: 0.434989\n",
      "epoch 38; iter: 600; batch classifier loss: 0.261289; batch adversarial loss: 0.394871\n",
      "epoch 39; iter: 0; batch classifier loss: 0.464165; batch adversarial loss: 0.380280\n",
      "epoch 39; iter: 200; batch classifier loss: 0.332504; batch adversarial loss: 0.476507\n",
      "epoch 39; iter: 400; batch classifier loss: 0.295846; batch adversarial loss: 0.397433\n",
      "epoch 39; iter: 600; batch classifier loss: 0.280007; batch adversarial loss: 0.461838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.346729; batch adversarial loss: 0.320743\n",
      "epoch 40; iter: 200; batch classifier loss: 0.350586; batch adversarial loss: 0.440093\n",
      "epoch 40; iter: 400; batch classifier loss: 0.562232; batch adversarial loss: 0.293725\n",
      "epoch 40; iter: 600; batch classifier loss: 0.426165; batch adversarial loss: 0.504941\n",
      "epoch 41; iter: 0; batch classifier loss: 0.291502; batch adversarial loss: 0.433684\n",
      "epoch 41; iter: 200; batch classifier loss: 0.307089; batch adversarial loss: 0.407834\n",
      "epoch 41; iter: 400; batch classifier loss: 0.438369; batch adversarial loss: 0.510823\n",
      "epoch 41; iter: 600; batch classifier loss: 0.310524; batch adversarial loss: 0.489416\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482591; batch adversarial loss: 0.346911\n",
      "epoch 42; iter: 200; batch classifier loss: 0.355659; batch adversarial loss: 0.414345\n",
      "epoch 42; iter: 400; batch classifier loss: 0.450242; batch adversarial loss: 0.427398\n",
      "epoch 42; iter: 600; batch classifier loss: 0.332119; batch adversarial loss: 0.341311\n",
      "epoch 43; iter: 0; batch classifier loss: 0.354957; batch adversarial loss: 0.321510\n",
      "epoch 43; iter: 200; batch classifier loss: 0.308201; batch adversarial loss: 0.433653\n",
      "epoch 43; iter: 400; batch classifier loss: 0.318520; batch adversarial loss: 0.452176\n",
      "epoch 43; iter: 600; batch classifier loss: 0.418930; batch adversarial loss: 0.425732\n",
      "epoch 44; iter: 0; batch classifier loss: 0.339134; batch adversarial loss: 0.484754\n",
      "epoch 44; iter: 200; batch classifier loss: 0.307167; batch adversarial loss: 0.322600\n",
      "epoch 44; iter: 400; batch classifier loss: 0.346148; batch adversarial loss: 0.428178\n",
      "epoch 44; iter: 600; batch classifier loss: 0.382170; batch adversarial loss: 0.452243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.269280; batch adversarial loss: 0.512393\n",
      "epoch 45; iter: 200; batch classifier loss: 0.395970; batch adversarial loss: 0.264156\n",
      "epoch 45; iter: 400; batch classifier loss: 0.229082; batch adversarial loss: 0.377239\n",
      "epoch 45; iter: 600; batch classifier loss: 0.388725; batch adversarial loss: 0.325471\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443980; batch adversarial loss: 0.543728\n",
      "epoch 46; iter: 200; batch classifier loss: 0.264190; batch adversarial loss: 0.483480\n",
      "epoch 46; iter: 400; batch classifier loss: 0.453969; batch adversarial loss: 0.374793\n",
      "epoch 46; iter: 600; batch classifier loss: 0.373712; batch adversarial loss: 0.565029\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375827; batch adversarial loss: 0.410168\n",
      "epoch 47; iter: 200; batch classifier loss: 0.456704; batch adversarial loss: 0.508724\n",
      "epoch 47; iter: 400; batch classifier loss: 0.263281; batch adversarial loss: 0.401008\n",
      "epoch 47; iter: 600; batch classifier loss: 0.269903; batch adversarial loss: 0.479054\n",
      "epoch 48; iter: 0; batch classifier loss: 0.564055; batch adversarial loss: 0.374985\n",
      "epoch 48; iter: 200; batch classifier loss: 0.365285; batch adversarial loss: 0.437844\n",
      "epoch 48; iter: 400; batch classifier loss: 0.239395; batch adversarial loss: 0.290231\n",
      "epoch 48; iter: 600; batch classifier loss: 0.354299; batch adversarial loss: 0.406528\n",
      "epoch 49; iter: 0; batch classifier loss: 0.536288; batch adversarial loss: 0.541814\n",
      "epoch 49; iter: 200; batch classifier loss: 0.374225; batch adversarial loss: 0.551190\n",
      "epoch 49; iter: 400; batch classifier loss: 0.489397; batch adversarial loss: 0.395935\n",
      "epoch 49; iter: 600; batch classifier loss: 0.435763; batch adversarial loss: 0.570849\n",
      "epoch 0; iter: 0; batch classifier loss: 8.342455; batch adversarial loss: 0.675229\n",
      "epoch 0; iter: 200; batch classifier loss: 1.191948; batch adversarial loss: 0.573500\n",
      "epoch 0; iter: 400; batch classifier loss: 3.744394; batch adversarial loss: 0.574434\n",
      "epoch 0; iter: 600; batch classifier loss: 2.635636; batch adversarial loss: 0.435261\n",
      "epoch 1; iter: 0; batch classifier loss: 0.778320; batch adversarial loss: 0.504740\n",
      "epoch 1; iter: 200; batch classifier loss: 0.653642; batch adversarial loss: 0.446303\n",
      "epoch 1; iter: 400; batch classifier loss: 0.596269; batch adversarial loss: 0.522597\n",
      "epoch 1; iter: 600; batch classifier loss: 1.988503; batch adversarial loss: 0.408392\n",
      "epoch 2; iter: 0; batch classifier loss: 1.809595; batch adversarial loss: 0.364630\n",
      "epoch 2; iter: 200; batch classifier loss: 0.754521; batch adversarial loss: 0.520276\n",
      "epoch 2; iter: 400; batch classifier loss: 2.592092; batch adversarial loss: 0.480604\n",
      "epoch 2; iter: 600; batch classifier loss: 0.759513; batch adversarial loss: 0.427101\n",
      "epoch 3; iter: 0; batch classifier loss: 2.564898; batch adversarial loss: 0.327446\n",
      "epoch 3; iter: 200; batch classifier loss: 1.258813; batch adversarial loss: 0.340314\n",
      "epoch 3; iter: 400; batch classifier loss: 0.599396; batch adversarial loss: 0.410248\n",
      "epoch 3; iter: 600; batch classifier loss: 1.316692; batch adversarial loss: 0.411882\n",
      "epoch 4; iter: 0; batch classifier loss: 0.916466; batch adversarial loss: 0.412813\n",
      "epoch 4; iter: 200; batch classifier loss: 0.658867; batch adversarial loss: 0.369280\n",
      "epoch 4; iter: 400; batch classifier loss: 1.531891; batch adversarial loss: 0.366720\n",
      "epoch 4; iter: 600; batch classifier loss: 0.829929; batch adversarial loss: 0.442406\n",
      "epoch 5; iter: 0; batch classifier loss: 0.980192; batch adversarial loss: 0.541969\n",
      "epoch 5; iter: 200; batch classifier loss: 0.337195; batch adversarial loss: 0.407098\n",
      "epoch 5; iter: 400; batch classifier loss: 0.270432; batch adversarial loss: 0.403665\n",
      "epoch 5; iter: 600; batch classifier loss: 0.356722; batch adversarial loss: 0.376078\n",
      "epoch 6; iter: 0; batch classifier loss: 0.702987; batch adversarial loss: 0.347452\n",
      "epoch 6; iter: 200; batch classifier loss: 0.393970; batch adversarial loss: 0.435759\n",
      "epoch 6; iter: 400; batch classifier loss: 0.398398; batch adversarial loss: 0.475184\n",
      "epoch 6; iter: 600; batch classifier loss: 0.456805; batch adversarial loss: 0.381040\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441352; batch adversarial loss: 0.451407\n",
      "epoch 7; iter: 200; batch classifier loss: 0.382508; batch adversarial loss: 0.398346\n",
      "epoch 7; iter: 400; batch classifier loss: 0.573962; batch adversarial loss: 0.274326\n",
      "epoch 7; iter: 600; batch classifier loss: 0.259880; batch adversarial loss: 0.355658\n",
      "epoch 8; iter: 0; batch classifier loss: 0.275129; batch adversarial loss: 0.509686\n",
      "epoch 8; iter: 200; batch classifier loss: 0.504832; batch adversarial loss: 0.383270\n",
      "epoch 8; iter: 400; batch classifier loss: 0.423124; batch adversarial loss: 0.367781\n",
      "epoch 8; iter: 600; batch classifier loss: 0.308600; batch adversarial loss: 0.420701\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556005; batch adversarial loss: 0.367746\n",
      "epoch 9; iter: 200; batch classifier loss: 0.402939; batch adversarial loss: 0.295400\n",
      "epoch 9; iter: 400; batch classifier loss: 0.305256; batch adversarial loss: 0.294601\n",
      "epoch 9; iter: 600; batch classifier loss: 0.445462; batch adversarial loss: 0.396433\n",
      "epoch 10; iter: 0; batch classifier loss: 0.354891; batch adversarial loss: 0.463033\n",
      "epoch 10; iter: 200; batch classifier loss: 0.492402; batch adversarial loss: 0.271258\n",
      "epoch 10; iter: 400; batch classifier loss: 0.278537; batch adversarial loss: 0.382839\n",
      "epoch 10; iter: 600; batch classifier loss: 0.432671; batch adversarial loss: 0.321628\n",
      "epoch 11; iter: 0; batch classifier loss: 0.303007; batch adversarial loss: 0.370444\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449253; batch adversarial loss: 0.429017\n",
      "epoch 11; iter: 400; batch classifier loss: 0.228193; batch adversarial loss: 0.404873\n",
      "epoch 11; iter: 600; batch classifier loss: 0.319710; batch adversarial loss: 0.455472\n",
      "epoch 12; iter: 0; batch classifier loss: 0.291387; batch adversarial loss: 0.345982\n",
      "epoch 12; iter: 200; batch classifier loss: 0.310350; batch adversarial loss: 0.428702\n",
      "epoch 12; iter: 400; batch classifier loss: 0.326803; batch adversarial loss: 0.455891\n",
      "epoch 12; iter: 600; batch classifier loss: 0.444739; batch adversarial loss: 0.267016\n",
      "epoch 13; iter: 0; batch classifier loss: 0.427348; batch adversarial loss: 0.375441\n",
      "epoch 13; iter: 200; batch classifier loss: 0.297694; batch adversarial loss: 0.462642\n",
      "epoch 13; iter: 400; batch classifier loss: 0.370704; batch adversarial loss: 0.331788\n",
      "epoch 13; iter: 600; batch classifier loss: 0.335651; batch adversarial loss: 0.314463\n",
      "epoch 14; iter: 0; batch classifier loss: 0.375969; batch adversarial loss: 0.347991\n",
      "epoch 14; iter: 200; batch classifier loss: 0.321238; batch adversarial loss: 0.479091\n",
      "epoch 14; iter: 400; batch classifier loss: 0.344761; batch adversarial loss: 0.620675\n",
      "epoch 14; iter: 600; batch classifier loss: 0.310918; batch adversarial loss: 0.518588\n",
      "epoch 15; iter: 0; batch classifier loss: 0.461195; batch adversarial loss: 0.425296\n",
      "epoch 15; iter: 200; batch classifier loss: 0.273700; batch adversarial loss: 0.509505\n",
      "epoch 15; iter: 400; batch classifier loss: 0.615928; batch adversarial loss: 0.403417\n",
      "epoch 15; iter: 600; batch classifier loss: 0.281899; batch adversarial loss: 0.401087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418406; batch adversarial loss: 0.350536\n",
      "epoch 16; iter: 200; batch classifier loss: 0.234653; batch adversarial loss: 0.429920\n",
      "epoch 16; iter: 400; batch classifier loss: 0.384305; batch adversarial loss: 0.325595\n",
      "epoch 16; iter: 600; batch classifier loss: 0.320893; batch adversarial loss: 0.408247\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364181; batch adversarial loss: 0.458160\n",
      "epoch 17; iter: 200; batch classifier loss: 0.403882; batch adversarial loss: 0.442523\n",
      "epoch 17; iter: 400; batch classifier loss: 0.312065; batch adversarial loss: 0.351614\n",
      "epoch 17; iter: 600; batch classifier loss: 0.289910; batch adversarial loss: 0.506002\n",
      "epoch 18; iter: 0; batch classifier loss: 0.351288; batch adversarial loss: 0.393989\n",
      "epoch 18; iter: 200; batch classifier loss: 0.270163; batch adversarial loss: 0.445827\n",
      "epoch 18; iter: 400; batch classifier loss: 0.430951; batch adversarial loss: 0.492209\n",
      "epoch 18; iter: 600; batch classifier loss: 0.335535; batch adversarial loss: 0.425005\n",
      "epoch 19; iter: 0; batch classifier loss: 0.279109; batch adversarial loss: 0.315401\n",
      "epoch 19; iter: 200; batch classifier loss: 0.276312; batch adversarial loss: 0.370446\n",
      "epoch 19; iter: 400; batch classifier loss: 0.520602; batch adversarial loss: 0.325036\n",
      "epoch 19; iter: 600; batch classifier loss: 0.352058; batch adversarial loss: 0.601763\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378146; batch adversarial loss: 0.292343\n",
      "epoch 20; iter: 200; batch classifier loss: 0.274641; batch adversarial loss: 0.373688\n",
      "epoch 20; iter: 400; batch classifier loss: 0.333285; batch adversarial loss: 0.436540\n",
      "epoch 20; iter: 600; batch classifier loss: 0.342273; batch adversarial loss: 0.377226\n",
      "epoch 21; iter: 0; batch classifier loss: 0.621873; batch adversarial loss: 0.405333\n",
      "epoch 21; iter: 200; batch classifier loss: 0.422927; batch adversarial loss: 0.597903\n",
      "epoch 21; iter: 400; batch classifier loss: 0.369172; batch adversarial loss: 0.234939\n",
      "epoch 21; iter: 600; batch classifier loss: 0.413334; batch adversarial loss: 0.462770\n",
      "epoch 22; iter: 0; batch classifier loss: 0.258273; batch adversarial loss: 0.463455\n",
      "epoch 22; iter: 200; batch classifier loss: 0.240119; batch adversarial loss: 0.299669\n",
      "epoch 22; iter: 400; batch classifier loss: 0.209619; batch adversarial loss: 0.356949\n",
      "epoch 22; iter: 600; batch classifier loss: 0.307157; batch adversarial loss: 0.482103\n",
      "epoch 23; iter: 0; batch classifier loss: 0.356720; batch adversarial loss: 0.392465\n",
      "epoch 23; iter: 200; batch classifier loss: 0.419121; batch adversarial loss: 0.413584\n",
      "epoch 23; iter: 400; batch classifier loss: 0.287269; batch adversarial loss: 0.432760\n",
      "epoch 23; iter: 600; batch classifier loss: 0.378204; batch adversarial loss: 0.348751\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338976; batch adversarial loss: 0.446597\n",
      "epoch 24; iter: 200; batch classifier loss: 0.426620; batch adversarial loss: 0.345893\n",
      "epoch 24; iter: 400; batch classifier loss: 0.389714; batch adversarial loss: 0.421715\n",
      "epoch 24; iter: 600; batch classifier loss: 0.273066; batch adversarial loss: 0.536106\n",
      "epoch 25; iter: 0; batch classifier loss: 0.358559; batch adversarial loss: 0.435044\n",
      "epoch 25; iter: 200; batch classifier loss: 0.358369; batch adversarial loss: 0.397995\n",
      "epoch 25; iter: 400; batch classifier loss: 0.334582; batch adversarial loss: 0.296748\n",
      "epoch 25; iter: 600; batch classifier loss: 0.542024; batch adversarial loss: 0.397351\n",
      "epoch 26; iter: 0; batch classifier loss: 0.261641; batch adversarial loss: 0.441611\n",
      "epoch 26; iter: 200; batch classifier loss: 0.333310; batch adversarial loss: 0.413753\n",
      "epoch 26; iter: 400; batch classifier loss: 0.504178; batch adversarial loss: 0.318033\n",
      "epoch 26; iter: 600; batch classifier loss: 0.298223; batch adversarial loss: 0.323842\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484108; batch adversarial loss: 0.461054\n",
      "epoch 27; iter: 200; batch classifier loss: 0.359486; batch adversarial loss: 0.289533\n",
      "epoch 27; iter: 400; batch classifier loss: 0.510510; batch adversarial loss: 0.298503\n",
      "epoch 27; iter: 600; batch classifier loss: 0.358522; batch adversarial loss: 0.505404\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441787; batch adversarial loss: 0.467101\n",
      "epoch 28; iter: 200; batch classifier loss: 0.504072; batch adversarial loss: 0.341076\n",
      "epoch 28; iter: 400; batch classifier loss: 0.255575; batch adversarial loss: 0.479888\n",
      "epoch 28; iter: 600; batch classifier loss: 0.425627; batch adversarial loss: 0.453836\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263509; batch adversarial loss: 0.352401\n",
      "epoch 29; iter: 200; batch classifier loss: 0.271713; batch adversarial loss: 0.405843\n",
      "epoch 29; iter: 400; batch classifier loss: 0.288540; batch adversarial loss: 0.381559\n",
      "epoch 29; iter: 600; batch classifier loss: 0.528500; batch adversarial loss: 0.406505\n",
      "epoch 30; iter: 0; batch classifier loss: 0.393651; batch adversarial loss: 0.347727\n",
      "epoch 30; iter: 200; batch classifier loss: 0.218059; batch adversarial loss: 0.345229\n",
      "epoch 30; iter: 400; batch classifier loss: 0.281537; batch adversarial loss: 0.394601\n",
      "epoch 30; iter: 600; batch classifier loss: 0.387646; batch adversarial loss: 0.394740\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499849; batch adversarial loss: 0.326574\n",
      "epoch 31; iter: 200; batch classifier loss: 0.312403; batch adversarial loss: 0.402364\n",
      "epoch 31; iter: 400; batch classifier loss: 0.302431; batch adversarial loss: 0.480682\n",
      "epoch 31; iter: 600; batch classifier loss: 0.367248; batch adversarial loss: 0.430240\n",
      "epoch 32; iter: 0; batch classifier loss: 0.336136; batch adversarial loss: 0.478630\n",
      "epoch 32; iter: 200; batch classifier loss: 0.336218; batch adversarial loss: 0.415681\n",
      "epoch 32; iter: 400; batch classifier loss: 0.335811; batch adversarial loss: 0.479142\n",
      "epoch 32; iter: 600; batch classifier loss: 0.426246; batch adversarial loss: 0.404190\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412528; batch adversarial loss: 0.412686\n",
      "epoch 33; iter: 200; batch classifier loss: 0.432349; batch adversarial loss: 0.380360\n",
      "epoch 33; iter: 400; batch classifier loss: 0.369636; batch adversarial loss: 0.292844\n",
      "epoch 33; iter: 600; batch classifier loss: 0.582022; batch adversarial loss: 0.315771\n",
      "epoch 34; iter: 0; batch classifier loss: 0.295140; batch adversarial loss: 0.480558\n",
      "epoch 34; iter: 200; batch classifier loss: 0.322255; batch adversarial loss: 0.559325\n",
      "epoch 34; iter: 400; batch classifier loss: 0.413681; batch adversarial loss: 0.484026\n",
      "epoch 34; iter: 600; batch classifier loss: 0.267865; batch adversarial loss: 0.332237\n",
      "epoch 35; iter: 0; batch classifier loss: 0.343125; batch adversarial loss: 0.397095\n",
      "epoch 35; iter: 200; batch classifier loss: 0.299552; batch adversarial loss: 0.403163\n",
      "epoch 35; iter: 400; batch classifier loss: 0.439442; batch adversarial loss: 0.356424\n",
      "epoch 35; iter: 600; batch classifier loss: 0.186540; batch adversarial loss: 0.514671\n",
      "epoch 36; iter: 0; batch classifier loss: 0.241312; batch adversarial loss: 0.360958\n",
      "epoch 36; iter: 200; batch classifier loss: 0.513207; batch adversarial loss: 0.447114\n",
      "epoch 36; iter: 400; batch classifier loss: 0.367261; batch adversarial loss: 0.378000\n",
      "epoch 36; iter: 600; batch classifier loss: 0.375775; batch adversarial loss: 0.550312\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288211; batch adversarial loss: 0.392368\n",
      "epoch 37; iter: 200; batch classifier loss: 0.430514; batch adversarial loss: 0.346740\n",
      "epoch 37; iter: 400; batch classifier loss: 0.357960; batch adversarial loss: 0.394471\n",
      "epoch 37; iter: 600; batch classifier loss: 0.346212; batch adversarial loss: 0.409971\n",
      "epoch 38; iter: 0; batch classifier loss: 0.377170; batch adversarial loss: 0.450426\n",
      "epoch 38; iter: 200; batch classifier loss: 0.470324; batch adversarial loss: 0.444321\n",
      "epoch 38; iter: 400; batch classifier loss: 0.280368; batch adversarial loss: 0.346672\n",
      "epoch 38; iter: 600; batch classifier loss: 0.249986; batch adversarial loss: 0.344992\n",
      "epoch 39; iter: 0; batch classifier loss: 0.339425; batch adversarial loss: 0.466062\n",
      "epoch 39; iter: 200; batch classifier loss: 0.327911; batch adversarial loss: 0.314124\n",
      "epoch 39; iter: 400; batch classifier loss: 0.507977; batch adversarial loss: 0.402775\n",
      "epoch 39; iter: 600; batch classifier loss: 0.293119; batch adversarial loss: 0.612321\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404706; batch adversarial loss: 0.402311\n",
      "epoch 40; iter: 200; batch classifier loss: 0.343280; batch adversarial loss: 0.372340\n",
      "epoch 40; iter: 400; batch classifier loss: 0.441411; batch adversarial loss: 0.453966\n",
      "epoch 40; iter: 600; batch classifier loss: 0.362933; batch adversarial loss: 0.342213\n",
      "epoch 41; iter: 0; batch classifier loss: 0.267864; batch adversarial loss: 0.385052\n",
      "epoch 41; iter: 200; batch classifier loss: 0.368374; batch adversarial loss: 0.543044\n",
      "epoch 41; iter: 400; batch classifier loss: 0.333324; batch adversarial loss: 0.511206\n",
      "epoch 41; iter: 600; batch classifier loss: 0.530594; batch adversarial loss: 0.286227\n",
      "epoch 42; iter: 0; batch classifier loss: 0.375005; batch adversarial loss: 0.618896\n",
      "epoch 42; iter: 200; batch classifier loss: 0.450222; batch adversarial loss: 0.364858\n",
      "epoch 42; iter: 400; batch classifier loss: 0.366699; batch adversarial loss: 0.479347\n",
      "epoch 42; iter: 600; batch classifier loss: 0.475069; batch adversarial loss: 0.344014\n",
      "epoch 43; iter: 0; batch classifier loss: 0.263889; batch adversarial loss: 0.428070\n",
      "epoch 43; iter: 200; batch classifier loss: 0.443909; batch adversarial loss: 0.355115\n",
      "epoch 43; iter: 400; batch classifier loss: 0.352209; batch adversarial loss: 0.502571\n",
      "epoch 43; iter: 600; batch classifier loss: 0.453448; batch adversarial loss: 0.551089\n",
      "epoch 44; iter: 0; batch classifier loss: 0.350139; batch adversarial loss: 0.422393\n",
      "epoch 44; iter: 200; batch classifier loss: 0.376100; batch adversarial loss: 0.441502\n",
      "epoch 44; iter: 400; batch classifier loss: 0.312461; batch adversarial loss: 0.400186\n",
      "epoch 44; iter: 600; batch classifier loss: 0.327183; batch adversarial loss: 0.495070\n",
      "epoch 45; iter: 0; batch classifier loss: 0.342498; batch adversarial loss: 0.450929\n",
      "epoch 45; iter: 200; batch classifier loss: 0.344345; batch adversarial loss: 0.458951\n",
      "epoch 45; iter: 400; batch classifier loss: 0.351366; batch adversarial loss: 0.370922\n",
      "epoch 45; iter: 600; batch classifier loss: 0.444069; batch adversarial loss: 0.519972\n",
      "epoch 46; iter: 0; batch classifier loss: 0.300542; batch adversarial loss: 0.466332\n",
      "epoch 46; iter: 200; batch classifier loss: 0.316027; batch adversarial loss: 0.470138\n",
      "epoch 46; iter: 400; batch classifier loss: 0.309625; batch adversarial loss: 0.458308\n",
      "epoch 46; iter: 600; batch classifier loss: 0.326153; batch adversarial loss: 0.292452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.309349; batch adversarial loss: 0.539894\n",
      "epoch 47; iter: 200; batch classifier loss: 0.329140; batch adversarial loss: 0.291898\n",
      "epoch 47; iter: 400; batch classifier loss: 0.562454; batch adversarial loss: 0.353098\n",
      "epoch 47; iter: 600; batch classifier loss: 0.381971; batch adversarial loss: 0.403613\n",
      "epoch 48; iter: 0; batch classifier loss: 0.321629; batch adversarial loss: 0.378138\n",
      "epoch 48; iter: 200; batch classifier loss: 0.367198; batch adversarial loss: 0.393305\n",
      "epoch 48; iter: 400; batch classifier loss: 0.370435; batch adversarial loss: 0.452282\n",
      "epoch 48; iter: 600; batch classifier loss: 0.480933; batch adversarial loss: 0.560526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.324053; batch adversarial loss: 0.369092\n",
      "epoch 49; iter: 200; batch classifier loss: 0.393840; batch adversarial loss: 0.394269\n",
      "epoch 49; iter: 400; batch classifier loss: 0.265970; batch adversarial loss: 0.378779\n",
      "epoch 49; iter: 600; batch classifier loss: 0.236494; batch adversarial loss: 0.290850\n",
      "epoch 0; iter: 0; batch classifier loss: 18.673702; batch adversarial loss: 0.531875\n",
      "epoch 0; iter: 200; batch classifier loss: 10.257843; batch adversarial loss: 0.586848\n",
      "epoch 0; iter: 400; batch classifier loss: 11.499475; batch adversarial loss: 0.559356\n",
      "epoch 0; iter: 600; batch classifier loss: 2.267182; batch adversarial loss: 0.408722\n",
      "epoch 1; iter: 0; batch classifier loss: 0.878514; batch adversarial loss: 0.496149\n",
      "epoch 1; iter: 200; batch classifier loss: 1.938116; batch adversarial loss: 0.451147\n",
      "epoch 1; iter: 400; batch classifier loss: 8.143386; batch adversarial loss: 0.490024\n",
      "epoch 1; iter: 600; batch classifier loss: 6.411748; batch adversarial loss: 0.344377\n",
      "epoch 2; iter: 0; batch classifier loss: 7.355890; batch adversarial loss: 0.425750\n",
      "epoch 2; iter: 200; batch classifier loss: 2.231538; batch adversarial loss: 0.471838\n",
      "epoch 2; iter: 400; batch classifier loss: 2.373551; batch adversarial loss: 0.409981\n",
      "epoch 2; iter: 600; batch classifier loss: 1.777207; batch adversarial loss: 0.344686\n",
      "epoch 3; iter: 0; batch classifier loss: 0.826824; batch adversarial loss: 0.412758\n",
      "epoch 3; iter: 200; batch classifier loss: 2.180309; batch adversarial loss: 0.327596\n",
      "epoch 3; iter: 400; batch classifier loss: 1.635245; batch adversarial loss: 0.422859\n",
      "epoch 3; iter: 600; batch classifier loss: 0.878383; batch adversarial loss: 0.408289\n",
      "epoch 4; iter: 0; batch classifier loss: 0.456441; batch adversarial loss: 0.360619\n",
      "epoch 4; iter: 200; batch classifier loss: 0.577517; batch adversarial loss: 0.384090\n",
      "epoch 4; iter: 400; batch classifier loss: 0.912643; batch adversarial loss: 0.325785\n",
      "epoch 4; iter: 600; batch classifier loss: 0.445959; batch adversarial loss: 0.330154\n",
      "epoch 5; iter: 0; batch classifier loss: 0.382501; batch adversarial loss: 0.297684\n",
      "epoch 5; iter: 200; batch classifier loss: 0.718809; batch adversarial loss: 0.509763\n",
      "epoch 5; iter: 400; batch classifier loss: 0.838053; batch adversarial loss: 0.293593\n",
      "epoch 5; iter: 600; batch classifier loss: 0.521657; batch adversarial loss: 0.401605\n",
      "epoch 6; iter: 0; batch classifier loss: 0.701306; batch adversarial loss: 0.322005\n",
      "epoch 6; iter: 200; batch classifier loss: 0.316026; batch adversarial loss: 0.598544\n",
      "epoch 6; iter: 400; batch classifier loss: 0.356127; batch adversarial loss: 0.554704\n",
      "epoch 6; iter: 600; batch classifier loss: 0.234378; batch adversarial loss: 0.456788\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360903; batch adversarial loss: 0.335383\n",
      "epoch 7; iter: 200; batch classifier loss: 0.375799; batch adversarial loss: 0.454781\n",
      "epoch 7; iter: 400; batch classifier loss: 0.536014; batch adversarial loss: 0.524977\n",
      "epoch 7; iter: 600; batch classifier loss: 0.215101; batch adversarial loss: 0.529629\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532458; batch adversarial loss: 0.316470\n",
      "epoch 8; iter: 200; batch classifier loss: 0.367380; batch adversarial loss: 0.389792\n",
      "epoch 8; iter: 400; batch classifier loss: 0.346047; batch adversarial loss: 0.260207\n",
      "epoch 8; iter: 600; batch classifier loss: 0.241924; batch adversarial loss: 0.554360\n",
      "epoch 9; iter: 0; batch classifier loss: 0.210129; batch adversarial loss: 0.353472\n",
      "epoch 9; iter: 200; batch classifier loss: 0.447223; batch adversarial loss: 0.346510\n",
      "epoch 9; iter: 400; batch classifier loss: 0.310720; batch adversarial loss: 0.431527\n",
      "epoch 9; iter: 600; batch classifier loss: 0.383462; batch adversarial loss: 0.458316\n",
      "epoch 10; iter: 0; batch classifier loss: 0.330000; batch adversarial loss: 0.404968\n",
      "epoch 10; iter: 200; batch classifier loss: 0.406418; batch adversarial loss: 0.237988\n",
      "epoch 10; iter: 400; batch classifier loss: 0.316406; batch adversarial loss: 0.355823\n",
      "epoch 10; iter: 600; batch classifier loss: 0.336570; batch adversarial loss: 0.447681\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329161; batch adversarial loss: 0.446998\n",
      "epoch 11; iter: 200; batch classifier loss: 0.584213; batch adversarial loss: 0.345600\n",
      "epoch 11; iter: 400; batch classifier loss: 0.309728; batch adversarial loss: 0.497533\n",
      "epoch 11; iter: 600; batch classifier loss: 0.355781; batch adversarial loss: 0.458566\n",
      "epoch 12; iter: 0; batch classifier loss: 0.241422; batch adversarial loss: 0.407013\n",
      "epoch 12; iter: 200; batch classifier loss: 0.364461; batch adversarial loss: 0.311628\n",
      "epoch 12; iter: 400; batch classifier loss: 0.336302; batch adversarial loss: 0.478707\n",
      "epoch 12; iter: 600; batch classifier loss: 0.391019; batch adversarial loss: 0.375886\n",
      "epoch 13; iter: 0; batch classifier loss: 0.352090; batch adversarial loss: 0.392542\n",
      "epoch 13; iter: 200; batch classifier loss: 0.406569; batch adversarial loss: 0.544688\n",
      "epoch 13; iter: 400; batch classifier loss: 0.381631; batch adversarial loss: 0.403751\n",
      "epoch 13; iter: 600; batch classifier loss: 0.419882; batch adversarial loss: 0.343125\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384600; batch adversarial loss: 0.531821\n",
      "epoch 14; iter: 200; batch classifier loss: 0.409592; batch adversarial loss: 0.458880\n",
      "epoch 14; iter: 400; batch classifier loss: 0.456244; batch adversarial loss: 0.427126\n",
      "epoch 14; iter: 600; batch classifier loss: 0.319066; batch adversarial loss: 0.350974\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440703; batch adversarial loss: 0.487690\n",
      "epoch 15; iter: 200; batch classifier loss: 0.301839; batch adversarial loss: 0.377224\n",
      "epoch 15; iter: 400; batch classifier loss: 0.438369; batch adversarial loss: 0.388395\n",
      "epoch 15; iter: 600; batch classifier loss: 0.356328; batch adversarial loss: 0.485657\n",
      "epoch 16; iter: 0; batch classifier loss: 0.351435; batch adversarial loss: 0.297445\n",
      "epoch 16; iter: 200; batch classifier loss: 0.426741; batch adversarial loss: 0.353833\n",
      "epoch 16; iter: 400; batch classifier loss: 0.273803; batch adversarial loss: 0.372448\n",
      "epoch 16; iter: 600; batch classifier loss: 0.385047; batch adversarial loss: 0.506497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.376224; batch adversarial loss: 0.592777\n",
      "epoch 17; iter: 200; batch classifier loss: 0.312997; batch adversarial loss: 0.299129\n",
      "epoch 17; iter: 400; batch classifier loss: 0.274958; batch adversarial loss: 0.438977\n",
      "epoch 17; iter: 600; batch classifier loss: 0.389817; batch adversarial loss: 0.459393\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238334; batch adversarial loss: 0.368646\n",
      "epoch 18; iter: 200; batch classifier loss: 0.435974; batch adversarial loss: 0.298571\n",
      "epoch 18; iter: 400; batch classifier loss: 0.342678; batch adversarial loss: 0.372623\n",
      "epoch 18; iter: 600; batch classifier loss: 0.293978; batch adversarial loss: 0.507314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.323118; batch adversarial loss: 0.460918\n",
      "epoch 19; iter: 200; batch classifier loss: 0.335549; batch adversarial loss: 0.373989\n",
      "epoch 19; iter: 400; batch classifier loss: 0.295458; batch adversarial loss: 0.485095\n",
      "epoch 19; iter: 600; batch classifier loss: 0.547329; batch adversarial loss: 0.397149\n",
      "epoch 20; iter: 0; batch classifier loss: 0.252223; batch adversarial loss: 0.438360\n",
      "epoch 20; iter: 200; batch classifier loss: 0.255020; batch adversarial loss: 0.463130\n",
      "epoch 20; iter: 400; batch classifier loss: 0.327819; batch adversarial loss: 0.367832\n",
      "epoch 20; iter: 600; batch classifier loss: 0.334440; batch adversarial loss: 0.399400\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493167; batch adversarial loss: 0.352493\n",
      "epoch 21; iter: 200; batch classifier loss: 0.542249; batch adversarial loss: 0.310367\n",
      "epoch 21; iter: 400; batch classifier loss: 0.299204; batch adversarial loss: 0.398671\n",
      "epoch 21; iter: 600; batch classifier loss: 0.284855; batch adversarial loss: 0.341799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271930; batch adversarial loss: 0.401004\n",
      "epoch 22; iter: 200; batch classifier loss: 0.374318; batch adversarial loss: 0.418748\n",
      "epoch 22; iter: 400; batch classifier loss: 0.405273; batch adversarial loss: 0.423141\n",
      "epoch 22; iter: 600; batch classifier loss: 0.340999; batch adversarial loss: 0.565385\n",
      "epoch 23; iter: 0; batch classifier loss: 0.391283; batch adversarial loss: 0.384890\n",
      "epoch 23; iter: 200; batch classifier loss: 0.242762; batch adversarial loss: 0.456999\n",
      "epoch 23; iter: 400; batch classifier loss: 0.351839; batch adversarial loss: 0.476335\n",
      "epoch 23; iter: 600; batch classifier loss: 0.363088; batch adversarial loss: 0.342431\n",
      "epoch 24; iter: 0; batch classifier loss: 0.337031; batch adversarial loss: 0.594285\n",
      "epoch 24; iter: 200; batch classifier loss: 0.381602; batch adversarial loss: 0.397637\n",
      "epoch 24; iter: 400; batch classifier loss: 0.364893; batch adversarial loss: 0.509394\n",
      "epoch 24; iter: 600; batch classifier loss: 0.379675; batch adversarial loss: 0.486184\n",
      "epoch 25; iter: 0; batch classifier loss: 0.385072; batch adversarial loss: 0.534482\n",
      "epoch 25; iter: 200; batch classifier loss: 0.263542; batch adversarial loss: 0.347590\n",
      "epoch 25; iter: 400; batch classifier loss: 0.335561; batch adversarial loss: 0.403447\n",
      "epoch 25; iter: 600; batch classifier loss: 0.200267; batch adversarial loss: 0.471424\n",
      "epoch 26; iter: 0; batch classifier loss: 0.327319; batch adversarial loss: 0.371067\n",
      "epoch 26; iter: 200; batch classifier loss: 0.319124; batch adversarial loss: 0.323659\n",
      "epoch 26; iter: 400; batch classifier loss: 0.311727; batch adversarial loss: 0.429541\n",
      "epoch 26; iter: 600; batch classifier loss: 0.263958; batch adversarial loss: 0.321126\n",
      "epoch 27; iter: 0; batch classifier loss: 0.369826; batch adversarial loss: 0.288834\n",
      "epoch 27; iter: 200; batch classifier loss: 0.452008; batch adversarial loss: 0.297452\n",
      "epoch 27; iter: 400; batch classifier loss: 0.407547; batch adversarial loss: 0.377680\n",
      "epoch 27; iter: 600; batch classifier loss: 0.540592; batch adversarial loss: 0.462833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.339757; batch adversarial loss: 0.431149\n",
      "epoch 28; iter: 200; batch classifier loss: 0.280437; batch adversarial loss: 0.544296\n",
      "epoch 28; iter: 400; batch classifier loss: 0.353922; batch adversarial loss: 0.317510\n",
      "epoch 28; iter: 600; batch classifier loss: 0.360751; batch adversarial loss: 0.466018\n",
      "epoch 29; iter: 0; batch classifier loss: 0.370146; batch adversarial loss: 0.478317\n",
      "epoch 29; iter: 200; batch classifier loss: 0.311801; batch adversarial loss: 0.431112\n",
      "epoch 29; iter: 400; batch classifier loss: 0.459071; batch adversarial loss: 0.511068\n",
      "epoch 29; iter: 600; batch classifier loss: 0.419283; batch adversarial loss: 0.406424\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323834; batch adversarial loss: 0.336178\n",
      "epoch 30; iter: 200; batch classifier loss: 0.245258; batch adversarial loss: 0.375645\n",
      "epoch 30; iter: 400; batch classifier loss: 0.391400; batch adversarial loss: 0.487363\n",
      "epoch 30; iter: 600; batch classifier loss: 0.496769; batch adversarial loss: 0.376948\n",
      "epoch 31; iter: 0; batch classifier loss: 0.465025; batch adversarial loss: 0.396713\n",
      "epoch 31; iter: 200; batch classifier loss: 0.439694; batch adversarial loss: 0.379142\n",
      "epoch 31; iter: 400; batch classifier loss: 0.296996; batch adversarial loss: 0.581584\n",
      "epoch 31; iter: 600; batch classifier loss: 0.323206; batch adversarial loss: 0.357242\n",
      "epoch 32; iter: 0; batch classifier loss: 0.368749; batch adversarial loss: 0.534389\n",
      "epoch 32; iter: 200; batch classifier loss: 0.247702; batch adversarial loss: 0.370051\n",
      "epoch 32; iter: 400; batch classifier loss: 0.474414; batch adversarial loss: 0.318322\n",
      "epoch 32; iter: 600; batch classifier loss: 0.221691; batch adversarial loss: 0.429603\n",
      "epoch 33; iter: 0; batch classifier loss: 0.387857; batch adversarial loss: 0.531005\n",
      "epoch 33; iter: 200; batch classifier loss: 0.393459; batch adversarial loss: 0.460507\n",
      "epoch 33; iter: 400; batch classifier loss: 0.780178; batch adversarial loss: 0.486900\n",
      "epoch 33; iter: 600; batch classifier loss: 0.225620; batch adversarial loss: 0.237005\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363170; batch adversarial loss: 0.314842\n",
      "epoch 34; iter: 200; batch classifier loss: 0.371262; batch adversarial loss: 0.590797\n",
      "epoch 34; iter: 400; batch classifier loss: 0.409233; batch adversarial loss: 0.330795\n",
      "epoch 34; iter: 600; batch classifier loss: 0.389696; batch adversarial loss: 0.229949\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438161; batch adversarial loss: 0.425750\n",
      "epoch 35; iter: 200; batch classifier loss: 0.264741; batch adversarial loss: 0.241406\n",
      "epoch 35; iter: 400; batch classifier loss: 0.398016; batch adversarial loss: 0.538004\n",
      "epoch 35; iter: 600; batch classifier loss: 0.353650; batch adversarial loss: 0.317636\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373036; batch adversarial loss: 0.378625\n",
      "epoch 36; iter: 200; batch classifier loss: 0.352437; batch adversarial loss: 0.379025\n",
      "epoch 36; iter: 400; batch classifier loss: 0.417652; batch adversarial loss: 0.416013\n",
      "epoch 36; iter: 600; batch classifier loss: 0.352317; batch adversarial loss: 0.411028\n",
      "epoch 37; iter: 0; batch classifier loss: 0.350567; batch adversarial loss: 0.371909\n",
      "epoch 37; iter: 200; batch classifier loss: 0.310212; batch adversarial loss: 0.450280\n",
      "epoch 37; iter: 400; batch classifier loss: 0.383930; batch adversarial loss: 0.344668\n",
      "epoch 37; iter: 600; batch classifier loss: 0.390391; batch adversarial loss: 0.520559\n",
      "epoch 38; iter: 0; batch classifier loss: 0.320010; batch adversarial loss: 0.373718\n",
      "epoch 38; iter: 200; batch classifier loss: 0.390449; batch adversarial loss: 0.432355\n",
      "epoch 38; iter: 400; batch classifier loss: 0.981931; batch adversarial loss: 0.401595\n",
      "epoch 38; iter: 600; batch classifier loss: 0.382300; batch adversarial loss: 0.406740\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401222; batch adversarial loss: 0.377448\n",
      "epoch 39; iter: 200; batch classifier loss: 0.389372; batch adversarial loss: 0.601040\n",
      "epoch 39; iter: 400; batch classifier loss: 0.469973; batch adversarial loss: 0.374157\n",
      "epoch 39; iter: 600; batch classifier loss: 0.493126; batch adversarial loss: 0.539781\n",
      "epoch 40; iter: 0; batch classifier loss: 0.570325; batch adversarial loss: 0.319512\n",
      "epoch 40; iter: 200; batch classifier loss: 0.257311; batch adversarial loss: 0.345205\n",
      "epoch 40; iter: 400; batch classifier loss: 0.226112; batch adversarial loss: 0.401065\n",
      "epoch 40; iter: 600; batch classifier loss: 0.673476; batch adversarial loss: 0.624386\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325380; batch adversarial loss: 0.383355\n",
      "epoch 41; iter: 200; batch classifier loss: 0.295760; batch adversarial loss: 0.459589\n",
      "epoch 41; iter: 400; batch classifier loss: 0.417541; batch adversarial loss: 0.430966\n",
      "epoch 41; iter: 600; batch classifier loss: 0.330302; batch adversarial loss: 0.235565\n",
      "epoch 42; iter: 0; batch classifier loss: 0.246521; batch adversarial loss: 0.458207\n",
      "epoch 42; iter: 200; batch classifier loss: 0.494384; batch adversarial loss: 0.381792\n",
      "epoch 42; iter: 400; batch classifier loss: 0.380117; batch adversarial loss: 0.461913\n",
      "epoch 42; iter: 600; batch classifier loss: 0.303147; batch adversarial loss: 0.371229\n",
      "epoch 43; iter: 0; batch classifier loss: 0.437810; batch adversarial loss: 0.322139\n",
      "epoch 43; iter: 200; batch classifier loss: 0.271293; batch adversarial loss: 0.533660\n",
      "epoch 43; iter: 400; batch classifier loss: 0.376316; batch adversarial loss: 0.343621\n",
      "epoch 43; iter: 600; batch classifier loss: 0.350681; batch adversarial loss: 0.320827\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388895; batch adversarial loss: 0.399249\n",
      "epoch 44; iter: 200; batch classifier loss: 0.348758; batch adversarial loss: 0.345652\n",
      "epoch 44; iter: 400; batch classifier loss: 0.339504; batch adversarial loss: 0.459442\n",
      "epoch 44; iter: 600; batch classifier loss: 0.246525; batch adversarial loss: 0.453334\n",
      "epoch 45; iter: 0; batch classifier loss: 0.355681; batch adversarial loss: 0.427881\n",
      "epoch 45; iter: 200; batch classifier loss: 0.307247; batch adversarial loss: 0.347291\n",
      "epoch 45; iter: 400; batch classifier loss: 0.344966; batch adversarial loss: 0.397344\n",
      "epoch 45; iter: 600; batch classifier loss: 0.326818; batch adversarial loss: 0.315539\n",
      "epoch 46; iter: 0; batch classifier loss: 0.294886; batch adversarial loss: 0.290590\n",
      "epoch 46; iter: 200; batch classifier loss: 0.369636; batch adversarial loss: 0.406831\n",
      "epoch 46; iter: 400; batch classifier loss: 0.426238; batch adversarial loss: 0.408752\n",
      "epoch 46; iter: 600; batch classifier loss: 0.414357; batch adversarial loss: 0.375552\n",
      "epoch 47; iter: 0; batch classifier loss: 0.310587; batch adversarial loss: 0.317850\n",
      "epoch 47; iter: 200; batch classifier loss: 0.393872; batch adversarial loss: 0.395766\n",
      "epoch 47; iter: 400; batch classifier loss: 0.379815; batch adversarial loss: 0.348239\n",
      "epoch 47; iter: 600; batch classifier loss: 0.233639; batch adversarial loss: 0.597346\n",
      "epoch 48; iter: 0; batch classifier loss: 0.281953; batch adversarial loss: 0.351510\n",
      "epoch 48; iter: 200; batch classifier loss: 0.207768; batch adversarial loss: 0.376172\n",
      "epoch 48; iter: 400; batch classifier loss: 0.432995; batch adversarial loss: 0.516067\n",
      "epoch 48; iter: 600; batch classifier loss: 0.356566; batch adversarial loss: 0.452567\n",
      "epoch 49; iter: 0; batch classifier loss: 0.413812; batch adversarial loss: 0.456012\n",
      "epoch 49; iter: 200; batch classifier loss: 0.298890; batch adversarial loss: 0.438439\n",
      "epoch 49; iter: 400; batch classifier loss: 0.204063; batch adversarial loss: 0.238812\n",
      "epoch 49; iter: 600; batch classifier loss: 0.370429; batch adversarial loss: 0.533205\n",
      "epoch 0; iter: 0; batch classifier loss: 66.445000; batch adversarial loss: 0.720781\n",
      "epoch 0; iter: 200; batch classifier loss: 9.417215; batch adversarial loss: 0.623689\n",
      "epoch 0; iter: 400; batch classifier loss: 6.528601; batch adversarial loss: 0.585497\n",
      "epoch 0; iter: 600; batch classifier loss: 13.346518; batch adversarial loss: 0.506276\n",
      "epoch 1; iter: 0; batch classifier loss: 1.381542; batch adversarial loss: 0.549789\n",
      "epoch 1; iter: 200; batch classifier loss: 6.118143; batch adversarial loss: 0.459961\n",
      "epoch 1; iter: 400; batch classifier loss: 3.702797; batch adversarial loss: 0.463928\n",
      "epoch 1; iter: 600; batch classifier loss: 2.119534; batch adversarial loss: 0.507763\n",
      "epoch 2; iter: 0; batch classifier loss: 2.484083; batch adversarial loss: 0.495095\n",
      "epoch 2; iter: 200; batch classifier loss: 7.308289; batch adversarial loss: 0.416815\n",
      "epoch 2; iter: 400; batch classifier loss: 3.207550; batch adversarial loss: 0.376682\n",
      "epoch 2; iter: 600; batch classifier loss: 3.936500; batch adversarial loss: 0.388072\n",
      "epoch 3; iter: 0; batch classifier loss: 2.327824; batch adversarial loss: 0.495923\n",
      "epoch 3; iter: 200; batch classifier loss: 3.742079; batch adversarial loss: 0.458446\n",
      "epoch 3; iter: 400; batch classifier loss: 0.596237; batch adversarial loss: 0.447109\n",
      "epoch 3; iter: 600; batch classifier loss: 0.699169; batch adversarial loss: 0.419215\n",
      "epoch 4; iter: 0; batch classifier loss: 3.989275; batch adversarial loss: 0.314374\n",
      "epoch 4; iter: 200; batch classifier loss: 1.186237; batch adversarial loss: 0.496615\n",
      "epoch 4; iter: 400; batch classifier loss: 0.661516; batch adversarial loss: 0.383461\n",
      "epoch 4; iter: 600; batch classifier loss: 0.944671; batch adversarial loss: 0.408953\n",
      "epoch 5; iter: 0; batch classifier loss: 0.291775; batch adversarial loss: 0.378916\n",
      "epoch 5; iter: 200; batch classifier loss: 0.894853; batch adversarial loss: 0.430440\n",
      "epoch 5; iter: 400; batch classifier loss: 0.439040; batch adversarial loss: 0.466218\n",
      "epoch 5; iter: 600; batch classifier loss: 1.155891; batch adversarial loss: 0.240747\n",
      "epoch 6; iter: 0; batch classifier loss: 0.718616; batch adversarial loss: 0.371594\n",
      "epoch 6; iter: 200; batch classifier loss: 0.238111; batch adversarial loss: 0.445913\n",
      "epoch 6; iter: 400; batch classifier loss: 0.404083; batch adversarial loss: 0.397522\n",
      "epoch 6; iter: 600; batch classifier loss: 0.367991; batch adversarial loss: 0.423116\n",
      "epoch 7; iter: 0; batch classifier loss: 0.259807; batch adversarial loss: 0.476004\n",
      "epoch 7; iter: 200; batch classifier loss: 0.302748; batch adversarial loss: 0.400797\n",
      "epoch 7; iter: 400; batch classifier loss: 0.381676; batch adversarial loss: 0.423437\n",
      "epoch 7; iter: 600; batch classifier loss: 0.431204; batch adversarial loss: 0.398615\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399498; batch adversarial loss: 0.433264\n",
      "epoch 8; iter: 200; batch classifier loss: 0.591060; batch adversarial loss: 0.458943\n",
      "epoch 8; iter: 400; batch classifier loss: 0.330294; batch adversarial loss: 0.341604\n",
      "epoch 8; iter: 600; batch classifier loss: 0.248698; batch adversarial loss: 0.289768\n",
      "epoch 9; iter: 0; batch classifier loss: 0.291630; batch adversarial loss: 0.320200\n",
      "epoch 9; iter: 200; batch classifier loss: 0.284219; batch adversarial loss: 0.428842\n",
      "epoch 9; iter: 400; batch classifier loss: 0.370216; batch adversarial loss: 0.472531\n",
      "epoch 9; iter: 600; batch classifier loss: 0.568682; batch adversarial loss: 0.352081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.447937; batch adversarial loss: 0.462031\n",
      "epoch 10; iter: 200; batch classifier loss: 0.212626; batch adversarial loss: 0.387734\n",
      "epoch 10; iter: 400; batch classifier loss: 0.324792; batch adversarial loss: 0.483589\n",
      "epoch 10; iter: 600; batch classifier loss: 0.374139; batch adversarial loss: 0.398421\n",
      "epoch 11; iter: 0; batch classifier loss: 0.399763; batch adversarial loss: 0.323398\n",
      "epoch 11; iter: 200; batch classifier loss: 0.362294; batch adversarial loss: 0.462300\n",
      "epoch 11; iter: 400; batch classifier loss: 0.402899; batch adversarial loss: 0.421112\n",
      "epoch 11; iter: 600; batch classifier loss: 0.371120; batch adversarial loss: 0.481758\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304472; batch adversarial loss: 0.351644\n",
      "epoch 12; iter: 200; batch classifier loss: 0.368348; batch adversarial loss: 0.379442\n",
      "epoch 12; iter: 400; batch classifier loss: 0.314371; batch adversarial loss: 0.404310\n",
      "epoch 12; iter: 600; batch classifier loss: 0.329189; batch adversarial loss: 0.437430\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249864; batch adversarial loss: 0.346674\n",
      "epoch 13; iter: 200; batch classifier loss: 0.289629; batch adversarial loss: 0.544581\n",
      "epoch 13; iter: 400; batch classifier loss: 0.375386; batch adversarial loss: 0.370628\n",
      "epoch 13; iter: 600; batch classifier loss: 0.335229; batch adversarial loss: 0.489833\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406914; batch adversarial loss: 0.503161\n",
      "epoch 14; iter: 200; batch classifier loss: 0.348075; batch adversarial loss: 0.293349\n",
      "epoch 14; iter: 400; batch classifier loss: 0.236377; batch adversarial loss: 0.442896\n",
      "epoch 14; iter: 600; batch classifier loss: 0.366206; batch adversarial loss: 0.465511\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324183; batch adversarial loss: 0.438675\n",
      "epoch 15; iter: 200; batch classifier loss: 0.346723; batch adversarial loss: 0.388455\n",
      "epoch 15; iter: 400; batch classifier loss: 0.396416; batch adversarial loss: 0.286619\n",
      "epoch 15; iter: 600; batch classifier loss: 0.340805; batch adversarial loss: 0.400168\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306436; batch adversarial loss: 0.441450\n",
      "epoch 16; iter: 200; batch classifier loss: 0.251933; batch adversarial loss: 0.431177\n",
      "epoch 16; iter: 400; batch classifier loss: 0.250306; batch adversarial loss: 0.394443\n",
      "epoch 16; iter: 600; batch classifier loss: 0.303351; batch adversarial loss: 0.315006\n",
      "epoch 17; iter: 0; batch classifier loss: 0.415660; batch adversarial loss: 0.520827\n",
      "epoch 17; iter: 200; batch classifier loss: 0.324098; batch adversarial loss: 0.322674\n",
      "epoch 17; iter: 400; batch classifier loss: 0.323023; batch adversarial loss: 0.434633\n",
      "epoch 17; iter: 600; batch classifier loss: 0.409990; batch adversarial loss: 0.384467\n",
      "epoch 18; iter: 0; batch classifier loss: 0.291852; batch adversarial loss: 0.627922\n",
      "epoch 18; iter: 200; batch classifier loss: 0.266504; batch adversarial loss: 0.427886\n",
      "epoch 18; iter: 400; batch classifier loss: 0.439056; batch adversarial loss: 0.419761\n",
      "epoch 18; iter: 600; batch classifier loss: 0.432263; batch adversarial loss: 0.376664\n",
      "epoch 19; iter: 0; batch classifier loss: 0.507844; batch adversarial loss: 0.346349\n",
      "epoch 19; iter: 200; batch classifier loss: 0.482307; batch adversarial loss: 0.384332\n",
      "epoch 19; iter: 400; batch classifier loss: 0.409431; batch adversarial loss: 0.351769\n",
      "epoch 19; iter: 600; batch classifier loss: 0.332925; batch adversarial loss: 0.458695\n",
      "epoch 20; iter: 0; batch classifier loss: 0.282948; batch adversarial loss: 0.421093\n",
      "epoch 20; iter: 200; batch classifier loss: 0.443822; batch adversarial loss: 0.400268\n",
      "epoch 20; iter: 400; batch classifier loss: 0.309802; batch adversarial loss: 0.405201\n",
      "epoch 20; iter: 600; batch classifier loss: 0.390077; batch adversarial loss: 0.326138\n",
      "epoch 21; iter: 0; batch classifier loss: 0.304554; batch adversarial loss: 0.471001\n",
      "epoch 21; iter: 200; batch classifier loss: 0.327798; batch adversarial loss: 0.347835\n",
      "epoch 21; iter: 400; batch classifier loss: 0.485897; batch adversarial loss: 0.429342\n",
      "epoch 21; iter: 600; batch classifier loss: 0.367228; batch adversarial loss: 0.392907\n",
      "epoch 22; iter: 0; batch classifier loss: 0.240316; batch adversarial loss: 0.346391\n",
      "epoch 22; iter: 200; batch classifier loss: 0.453710; batch adversarial loss: 0.311027\n",
      "epoch 22; iter: 400; batch classifier loss: 0.309371; batch adversarial loss: 0.326622\n",
      "epoch 22; iter: 600; batch classifier loss: 0.381406; batch adversarial loss: 0.289147\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445036; batch adversarial loss: 0.432341\n",
      "epoch 23; iter: 200; batch classifier loss: 0.465445; batch adversarial loss: 0.405593\n",
      "epoch 23; iter: 400; batch classifier loss: 0.296217; batch adversarial loss: 0.389701\n",
      "epoch 23; iter: 600; batch classifier loss: 0.406412; batch adversarial loss: 0.376013\n",
      "epoch 24; iter: 0; batch classifier loss: 0.252264; batch adversarial loss: 0.424320\n",
      "epoch 24; iter: 200; batch classifier loss: 0.329664; batch adversarial loss: 0.445724\n",
      "epoch 24; iter: 400; batch classifier loss: 0.432977; batch adversarial loss: 0.497876\n",
      "epoch 24; iter: 600; batch classifier loss: 0.536050; batch adversarial loss: 0.394120\n",
      "epoch 25; iter: 0; batch classifier loss: 0.461224; batch adversarial loss: 0.398337\n",
      "epoch 25; iter: 200; batch classifier loss: 0.280220; batch adversarial loss: 0.344872\n",
      "epoch 25; iter: 400; batch classifier loss: 0.349241; batch adversarial loss: 0.441915\n",
      "epoch 25; iter: 600; batch classifier loss: 0.422080; batch adversarial loss: 0.394542\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271750; batch adversarial loss: 0.364619\n",
      "epoch 26; iter: 200; batch classifier loss: 0.362390; batch adversarial loss: 0.399555\n",
      "epoch 26; iter: 400; batch classifier loss: 0.339243; batch adversarial loss: 0.325752\n",
      "epoch 26; iter: 600; batch classifier loss: 0.259171; batch adversarial loss: 0.508084\n",
      "epoch 27; iter: 0; batch classifier loss: 0.467068; batch adversarial loss: 0.401708\n",
      "epoch 27; iter: 200; batch classifier loss: 0.559410; batch adversarial loss: 0.443959\n",
      "epoch 27; iter: 400; batch classifier loss: 0.423358; batch adversarial loss: 0.462215\n",
      "epoch 27; iter: 600; batch classifier loss: 0.485811; batch adversarial loss: 0.545814\n",
      "epoch 28; iter: 0; batch classifier loss: 0.379807; batch adversarial loss: 0.355317\n",
      "epoch 28; iter: 200; batch classifier loss: 0.436785; batch adversarial loss: 0.348634\n",
      "epoch 28; iter: 400; batch classifier loss: 0.298989; batch adversarial loss: 0.412297\n",
      "epoch 28; iter: 600; batch classifier loss: 0.492964; batch adversarial loss: 0.394922\n",
      "epoch 29; iter: 0; batch classifier loss: 0.351473; batch adversarial loss: 0.560325\n",
      "epoch 29; iter: 200; batch classifier loss: 0.370056; batch adversarial loss: 0.433217\n",
      "epoch 29; iter: 400; batch classifier loss: 0.404485; batch adversarial loss: 0.393443\n",
      "epoch 29; iter: 600; batch classifier loss: 0.437267; batch adversarial loss: 0.398968\n",
      "epoch 30; iter: 0; batch classifier loss: 0.455669; batch adversarial loss: 0.381976\n",
      "epoch 30; iter: 200; batch classifier loss: 0.380605; batch adversarial loss: 0.265544\n",
      "epoch 30; iter: 400; batch classifier loss: 0.286912; batch adversarial loss: 0.432350\n",
      "epoch 30; iter: 600; batch classifier loss: 0.441802; batch adversarial loss: 0.265178\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398198; batch adversarial loss: 0.316751\n",
      "epoch 31; iter: 200; batch classifier loss: 0.294411; batch adversarial loss: 0.351149\n",
      "epoch 31; iter: 400; batch classifier loss: 0.438595; batch adversarial loss: 0.320631\n",
      "epoch 31; iter: 600; batch classifier loss: 0.364069; batch adversarial loss: 0.264502\n",
      "epoch 32; iter: 0; batch classifier loss: 0.370657; batch adversarial loss: 0.292089\n",
      "epoch 32; iter: 200; batch classifier loss: 0.418428; batch adversarial loss: 0.453666\n",
      "epoch 32; iter: 400; batch classifier loss: 0.439884; batch adversarial loss: 0.347126\n",
      "epoch 32; iter: 600; batch classifier loss: 0.371515; batch adversarial loss: 0.314442\n",
      "epoch 33; iter: 0; batch classifier loss: 0.373424; batch adversarial loss: 0.455018\n",
      "epoch 33; iter: 200; batch classifier loss: 0.545355; batch adversarial loss: 0.336378\n",
      "epoch 33; iter: 400; batch classifier loss: 0.420067; batch adversarial loss: 0.371013\n",
      "epoch 33; iter: 600; batch classifier loss: 0.468072; batch adversarial loss: 0.348500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367268; batch adversarial loss: 0.546138\n",
      "epoch 34; iter: 200; batch classifier loss: 0.258806; batch adversarial loss: 0.403484\n",
      "epoch 34; iter: 400; batch classifier loss: 0.355341; batch adversarial loss: 0.375671\n",
      "epoch 34; iter: 600; batch classifier loss: 0.265175; batch adversarial loss: 0.347998\n",
      "epoch 35; iter: 0; batch classifier loss: 0.229340; batch adversarial loss: 0.403598\n",
      "epoch 35; iter: 200; batch classifier loss: 0.259880; batch adversarial loss: 0.402054\n",
      "epoch 35; iter: 400; batch classifier loss: 0.406819; batch adversarial loss: 0.260764\n",
      "epoch 35; iter: 600; batch classifier loss: 0.253416; batch adversarial loss: 0.406997\n",
      "epoch 36; iter: 0; batch classifier loss: 0.192730; batch adversarial loss: 0.346369\n",
      "epoch 36; iter: 200; batch classifier loss: 0.303629; batch adversarial loss: 0.236396\n",
      "epoch 36; iter: 400; batch classifier loss: 0.447779; batch adversarial loss: 0.441360\n",
      "epoch 36; iter: 600; batch classifier loss: 0.280914; batch adversarial loss: 0.244224\n",
      "epoch 37; iter: 0; batch classifier loss: 0.348521; batch adversarial loss: 0.370808\n",
      "epoch 37; iter: 200; batch classifier loss: 0.223474; batch adversarial loss: 0.289462\n",
      "epoch 37; iter: 400; batch classifier loss: 0.355259; batch adversarial loss: 0.462612\n",
      "epoch 37; iter: 600; batch classifier loss: 0.275000; batch adversarial loss: 0.426201\n",
      "epoch 38; iter: 0; batch classifier loss: 0.533915; batch adversarial loss: 0.480757\n",
      "epoch 38; iter: 200; batch classifier loss: 0.387834; batch adversarial loss: 0.366003\n",
      "epoch 38; iter: 400; batch classifier loss: 0.464374; batch adversarial loss: 0.328818\n",
      "epoch 38; iter: 600; batch classifier loss: 0.417145; batch adversarial loss: 0.568835\n",
      "epoch 39; iter: 0; batch classifier loss: 0.197693; batch adversarial loss: 0.374686\n",
      "epoch 39; iter: 200; batch classifier loss: 0.371393; batch adversarial loss: 0.457629\n",
      "epoch 39; iter: 400; batch classifier loss: 1.075713; batch adversarial loss: 0.492864\n",
      "epoch 39; iter: 600; batch classifier loss: 0.308666; batch adversarial loss: 0.682967\n",
      "epoch 40; iter: 0; batch classifier loss: 0.366955; batch adversarial loss: 0.268472\n",
      "epoch 40; iter: 200; batch classifier loss: 0.332045; batch adversarial loss: 0.428822\n",
      "epoch 40; iter: 400; batch classifier loss: 0.258787; batch adversarial loss: 0.553121\n",
      "epoch 40; iter: 600; batch classifier loss: 0.372600; batch adversarial loss: 0.398162\n",
      "epoch 41; iter: 0; batch classifier loss: 0.347686; batch adversarial loss: 0.374357\n",
      "epoch 41; iter: 200; batch classifier loss: 0.364360; batch adversarial loss: 0.575167\n",
      "epoch 41; iter: 400; batch classifier loss: 0.303682; batch adversarial loss: 0.413437\n",
      "epoch 41; iter: 600; batch classifier loss: 0.311894; batch adversarial loss: 0.344895\n",
      "epoch 42; iter: 0; batch classifier loss: 0.356126; batch adversarial loss: 0.390990\n",
      "epoch 42; iter: 200; batch classifier loss: 0.317840; batch adversarial loss: 0.462868\n",
      "epoch 42; iter: 400; batch classifier loss: 0.385208; batch adversarial loss: 0.343464\n",
      "epoch 42; iter: 600; batch classifier loss: 0.545182; batch adversarial loss: 0.425516\n",
      "epoch 43; iter: 0; batch classifier loss: 0.363233; batch adversarial loss: 0.291650\n",
      "epoch 43; iter: 200; batch classifier loss: 0.790876; batch adversarial loss: 0.264026\n",
      "epoch 43; iter: 400; batch classifier loss: 0.322000; batch adversarial loss: 0.267250\n",
      "epoch 43; iter: 600; batch classifier loss: 0.426547; batch adversarial loss: 0.347033\n",
      "epoch 44; iter: 0; batch classifier loss: 0.334246; batch adversarial loss: 0.598474\n",
      "epoch 44; iter: 200; batch classifier loss: 0.253099; batch adversarial loss: 0.453579\n",
      "epoch 44; iter: 400; batch classifier loss: 0.541085; batch adversarial loss: 0.268048\n",
      "epoch 44; iter: 600; batch classifier loss: 0.255657; batch adversarial loss: 0.213610\n",
      "epoch 45; iter: 0; batch classifier loss: 0.345931; batch adversarial loss: 0.489272\n",
      "epoch 45; iter: 200; batch classifier loss: 0.353362; batch adversarial loss: 0.347003\n",
      "epoch 45; iter: 400; batch classifier loss: 0.298023; batch adversarial loss: 0.452503\n",
      "epoch 45; iter: 600; batch classifier loss: 0.364167; batch adversarial loss: 0.473459\n",
      "epoch 46; iter: 0; batch classifier loss: 0.344861; batch adversarial loss: 0.395940\n",
      "epoch 46; iter: 200; batch classifier loss: 0.336976; batch adversarial loss: 0.388796\n",
      "epoch 46; iter: 400; batch classifier loss: 0.412558; batch adversarial loss: 0.429345\n",
      "epoch 46; iter: 600; batch classifier loss: 0.407310; batch adversarial loss: 0.319477\n",
      "epoch 47; iter: 0; batch classifier loss: 0.173680; batch adversarial loss: 0.287230\n",
      "epoch 47; iter: 200; batch classifier loss: 0.318401; batch adversarial loss: 0.553814\n",
      "epoch 47; iter: 400; batch classifier loss: 0.298249; batch adversarial loss: 0.492233\n",
      "epoch 47; iter: 600; batch classifier loss: 0.497052; batch adversarial loss: 0.372523\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428627; batch adversarial loss: 0.320448\n",
      "epoch 48; iter: 200; batch classifier loss: 0.186621; batch adversarial loss: 0.244688\n",
      "epoch 48; iter: 400; batch classifier loss: 0.409143; batch adversarial loss: 0.323268\n",
      "epoch 48; iter: 600; batch classifier loss: 0.243031; batch adversarial loss: 0.403780\n",
      "epoch 49; iter: 0; batch classifier loss: 0.316972; batch adversarial loss: 0.373929\n",
      "epoch 49; iter: 200; batch classifier loss: 0.445212; batch adversarial loss: 0.425782\n",
      "epoch 49; iter: 400; batch classifier loss: 0.187569; batch adversarial loss: 0.425532\n",
      "epoch 49; iter: 600; batch classifier loss: 0.378068; batch adversarial loss: 0.485476\n",
      "epoch 0; iter: 0; batch classifier loss: 5.411836; batch adversarial loss: 0.672852\n",
      "epoch 0; iter: 200; batch classifier loss: 5.258913; batch adversarial loss: 0.608538\n",
      "epoch 0; iter: 400; batch classifier loss: 16.797968; batch adversarial loss: 0.516498\n",
      "epoch 0; iter: 600; batch classifier loss: 4.236367; batch adversarial loss: 0.470860\n",
      "epoch 1; iter: 0; batch classifier loss: 4.245665; batch adversarial loss: 0.520458\n",
      "epoch 1; iter: 200; batch classifier loss: 4.676762; batch adversarial loss: 0.467611\n",
      "epoch 1; iter: 400; batch classifier loss: 2.554045; batch adversarial loss: 0.473599\n",
      "epoch 1; iter: 600; batch classifier loss: 3.245477; batch adversarial loss: 0.452874\n",
      "epoch 2; iter: 0; batch classifier loss: 0.372993; batch adversarial loss: 0.465029\n",
      "epoch 2; iter: 200; batch classifier loss: 0.649396; batch adversarial loss: 0.474515\n",
      "epoch 2; iter: 400; batch classifier loss: 1.820800; batch adversarial loss: 0.481928\n",
      "epoch 2; iter: 600; batch classifier loss: 0.698588; batch adversarial loss: 0.459367\n",
      "epoch 3; iter: 0; batch classifier loss: 1.258737; batch adversarial loss: 0.332609\n",
      "epoch 3; iter: 200; batch classifier loss: 0.951176; batch adversarial loss: 0.473436\n",
      "epoch 3; iter: 400; batch classifier loss: 0.401318; batch adversarial loss: 0.383356\n",
      "epoch 3; iter: 600; batch classifier loss: 17.483957; batch adversarial loss: 0.347220\n",
      "epoch 4; iter: 0; batch classifier loss: 0.632414; batch adversarial loss: 0.562816\n",
      "epoch 4; iter: 200; batch classifier loss: 1.149764; batch adversarial loss: 0.515679\n",
      "epoch 4; iter: 400; batch classifier loss: 0.766708; batch adversarial loss: 0.467977\n",
      "epoch 4; iter: 600; batch classifier loss: 3.263491; batch adversarial loss: 0.493141\n",
      "epoch 5; iter: 0; batch classifier loss: 0.339289; batch adversarial loss: 0.429244\n",
      "epoch 5; iter: 200; batch classifier loss: 0.481264; batch adversarial loss: 0.406160\n",
      "epoch 5; iter: 400; batch classifier loss: 0.253352; batch adversarial loss: 0.526267\n",
      "epoch 5; iter: 600; batch classifier loss: 0.428024; batch adversarial loss: 0.503469\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473043; batch adversarial loss: 0.400121\n",
      "epoch 6; iter: 200; batch classifier loss: 0.530789; batch adversarial loss: 0.343988\n",
      "epoch 6; iter: 400; batch classifier loss: 0.402512; batch adversarial loss: 0.431428\n",
      "epoch 6; iter: 600; batch classifier loss: 0.281031; batch adversarial loss: 0.398033\n",
      "epoch 7; iter: 0; batch classifier loss: 0.383540; batch adversarial loss: 0.429029\n",
      "epoch 7; iter: 200; batch classifier loss: 0.509840; batch adversarial loss: 0.375472\n",
      "epoch 7; iter: 400; batch classifier loss: 0.298858; batch adversarial loss: 0.288185\n",
      "epoch 7; iter: 600; batch classifier loss: 0.390906; batch adversarial loss: 0.404522\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505874; batch adversarial loss: 0.397738\n",
      "epoch 8; iter: 200; batch classifier loss: 0.378160; batch adversarial loss: 0.506613\n",
      "epoch 8; iter: 400; batch classifier loss: 0.392769; batch adversarial loss: 0.494533\n",
      "epoch 8; iter: 600; batch classifier loss: 0.553638; batch adversarial loss: 0.322164\n",
      "epoch 9; iter: 0; batch classifier loss: 0.618973; batch adversarial loss: 0.481158\n",
      "epoch 9; iter: 200; batch classifier loss: 0.229170; batch adversarial loss: 0.378543\n",
      "epoch 9; iter: 400; batch classifier loss: 0.279848; batch adversarial loss: 0.347825\n",
      "epoch 9; iter: 600; batch classifier loss: 0.296389; batch adversarial loss: 0.285060\n",
      "epoch 10; iter: 0; batch classifier loss: 0.410898; batch adversarial loss: 0.509987\n",
      "epoch 10; iter: 200; batch classifier loss: 0.335097; batch adversarial loss: 0.346330\n",
      "epoch 10; iter: 400; batch classifier loss: 0.404979; batch adversarial loss: 0.364790\n",
      "epoch 10; iter: 600; batch classifier loss: 0.235838; batch adversarial loss: 0.381529\n",
      "epoch 11; iter: 0; batch classifier loss: 0.349585; batch adversarial loss: 0.326988\n",
      "epoch 11; iter: 200; batch classifier loss: 0.366507; batch adversarial loss: 0.402691\n",
      "epoch 11; iter: 400; batch classifier loss: 0.394154; batch adversarial loss: 0.508738\n",
      "epoch 11; iter: 600; batch classifier loss: 0.353955; batch adversarial loss: 0.420444\n",
      "epoch 12; iter: 0; batch classifier loss: 0.331714; batch adversarial loss: 0.349308\n",
      "epoch 12; iter: 200; batch classifier loss: 0.357030; batch adversarial loss: 0.387177\n",
      "epoch 12; iter: 400; batch classifier loss: 0.348800; batch adversarial loss: 0.598027\n",
      "epoch 12; iter: 600; batch classifier loss: 0.425960; batch adversarial loss: 0.453103\n",
      "epoch 13; iter: 0; batch classifier loss: 0.326316; batch adversarial loss: 0.428156\n",
      "epoch 13; iter: 200; batch classifier loss: 0.288141; batch adversarial loss: 0.391692\n",
      "epoch 13; iter: 400; batch classifier loss: 0.437733; batch adversarial loss: 0.369542\n",
      "epoch 13; iter: 600; batch classifier loss: 0.239108; batch adversarial loss: 0.317143\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274693; batch adversarial loss: 0.393430\n",
      "epoch 14; iter: 200; batch classifier loss: 0.502617; batch adversarial loss: 0.354076\n",
      "epoch 14; iter: 400; batch classifier loss: 0.266823; batch adversarial loss: 0.402566\n",
      "epoch 14; iter: 600; batch classifier loss: 0.363909; batch adversarial loss: 0.607080\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505182; batch adversarial loss: 0.293055\n",
      "epoch 15; iter: 200; batch classifier loss: 0.372508; batch adversarial loss: 0.318800\n",
      "epoch 15; iter: 400; batch classifier loss: 0.289388; batch adversarial loss: 0.523958\n",
      "epoch 15; iter: 600; batch classifier loss: 0.319181; batch adversarial loss: 0.567178\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299371; batch adversarial loss: 0.349500\n",
      "epoch 16; iter: 200; batch classifier loss: 0.288669; batch adversarial loss: 0.319984\n",
      "epoch 16; iter: 400; batch classifier loss: 0.357466; batch adversarial loss: 0.488628\n",
      "epoch 16; iter: 600; batch classifier loss: 0.404400; batch adversarial loss: 0.426229\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409013; batch adversarial loss: 0.454770\n",
      "epoch 17; iter: 200; batch classifier loss: 0.410141; batch adversarial loss: 0.270016\n",
      "epoch 17; iter: 400; batch classifier loss: 0.298354; batch adversarial loss: 0.478741\n",
      "epoch 17; iter: 600; batch classifier loss: 0.398823; batch adversarial loss: 0.318470\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465026; batch adversarial loss: 0.371957\n",
      "epoch 18; iter: 200; batch classifier loss: 0.447344; batch adversarial loss: 0.467266\n",
      "epoch 18; iter: 400; batch classifier loss: 0.368520; batch adversarial loss: 0.338356\n",
      "epoch 18; iter: 600; batch classifier loss: 0.424281; batch adversarial loss: 0.488200\n",
      "epoch 19; iter: 0; batch classifier loss: 0.383669; batch adversarial loss: 0.505820\n",
      "epoch 19; iter: 200; batch classifier loss: 0.367834; batch adversarial loss: 0.451188\n",
      "epoch 19; iter: 400; batch classifier loss: 0.747946; batch adversarial loss: 0.466023\n",
      "epoch 19; iter: 600; batch classifier loss: 0.489143; batch adversarial loss: 0.402088\n",
      "epoch 20; iter: 0; batch classifier loss: 0.370419; batch adversarial loss: 0.569957\n",
      "epoch 20; iter: 200; batch classifier loss: 0.719884; batch adversarial loss: 0.340024\n",
      "epoch 20; iter: 400; batch classifier loss: 0.320516; batch adversarial loss: 0.487201\n",
      "epoch 20; iter: 600; batch classifier loss: 0.368539; batch adversarial loss: 0.315507\n",
      "epoch 21; iter: 0; batch classifier loss: 0.428275; batch adversarial loss: 0.389711\n",
      "epoch 21; iter: 200; batch classifier loss: 0.410198; batch adversarial loss: 0.401284\n",
      "epoch 21; iter: 400; batch classifier loss: 0.408035; batch adversarial loss: 0.403206\n",
      "epoch 21; iter: 600; batch classifier loss: 0.300068; batch adversarial loss: 0.289863\n",
      "epoch 22; iter: 0; batch classifier loss: 0.297505; batch adversarial loss: 0.401767\n",
      "epoch 22; iter: 200; batch classifier loss: 0.313521; batch adversarial loss: 0.432312\n",
      "epoch 22; iter: 400; batch classifier loss: 0.392352; batch adversarial loss: 0.342746\n",
      "epoch 22; iter: 600; batch classifier loss: 0.288644; batch adversarial loss: 0.343991\n",
      "epoch 23; iter: 0; batch classifier loss: 0.267503; batch adversarial loss: 0.736897\n",
      "epoch 23; iter: 200; batch classifier loss: 0.370949; batch adversarial loss: 0.382707\n",
      "epoch 23; iter: 400; batch classifier loss: 0.402875; batch adversarial loss: 0.513108\n",
      "epoch 23; iter: 600; batch classifier loss: 0.481672; batch adversarial loss: 0.352185\n",
      "epoch 24; iter: 0; batch classifier loss: 0.476125; batch adversarial loss: 0.460349\n",
      "epoch 24; iter: 200; batch classifier loss: 0.445340; batch adversarial loss: 0.433863\n",
      "epoch 24; iter: 400; batch classifier loss: 0.347158; batch adversarial loss: 0.512666\n",
      "epoch 24; iter: 600; batch classifier loss: 0.260091; batch adversarial loss: 0.383369\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484684; batch adversarial loss: 0.406751\n",
      "epoch 25; iter: 200; batch classifier loss: 0.304730; batch adversarial loss: 0.354289\n",
      "epoch 25; iter: 400; batch classifier loss: 0.299188; batch adversarial loss: 0.503034\n",
      "epoch 25; iter: 600; batch classifier loss: 0.325266; batch adversarial loss: 0.368118\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340190; batch adversarial loss: 0.403159\n",
      "epoch 26; iter: 200; batch classifier loss: 0.419784; batch adversarial loss: 0.454985\n",
      "epoch 26; iter: 400; batch classifier loss: 0.323262; batch adversarial loss: 0.429201\n",
      "epoch 26; iter: 600; batch classifier loss: 0.232766; batch adversarial loss: 0.291471\n",
      "epoch 27; iter: 0; batch classifier loss: 0.439492; batch adversarial loss: 0.461929\n",
      "epoch 27; iter: 200; batch classifier loss: 0.353118; batch adversarial loss: 0.466489\n",
      "epoch 27; iter: 400; batch classifier loss: 0.422073; batch adversarial loss: 0.346684\n",
      "epoch 27; iter: 600; batch classifier loss: 0.504263; batch adversarial loss: 0.528923\n",
      "epoch 28; iter: 0; batch classifier loss: 0.363817; batch adversarial loss: 0.668452\n",
      "epoch 28; iter: 200; batch classifier loss: 0.289858; batch adversarial loss: 0.423527\n",
      "epoch 28; iter: 400; batch classifier loss: 0.298666; batch adversarial loss: 0.564021\n",
      "epoch 28; iter: 600; batch classifier loss: 0.248653; batch adversarial loss: 0.406851\n",
      "epoch 29; iter: 0; batch classifier loss: 0.332757; batch adversarial loss: 0.443170\n",
      "epoch 29; iter: 200; batch classifier loss: 0.373904; batch adversarial loss: 0.407243\n",
      "epoch 29; iter: 400; batch classifier loss: 0.431014; batch adversarial loss: 0.646338\n",
      "epoch 29; iter: 600; batch classifier loss: 0.244171; batch adversarial loss: 0.231472\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365200; batch adversarial loss: 0.403681\n",
      "epoch 30; iter: 200; batch classifier loss: 0.332163; batch adversarial loss: 0.485073\n",
      "epoch 30; iter: 400; batch classifier loss: 0.502440; batch adversarial loss: 0.404265\n",
      "epoch 30; iter: 600; batch classifier loss: 0.327104; batch adversarial loss: 0.513949\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320113; batch adversarial loss: 0.369984\n",
      "epoch 31; iter: 200; batch classifier loss: 0.506031; batch adversarial loss: 0.508471\n",
      "epoch 31; iter: 400; batch classifier loss: 0.332435; batch adversarial loss: 0.405610\n",
      "epoch 31; iter: 600; batch classifier loss: 0.324255; batch adversarial loss: 0.357048\n",
      "epoch 32; iter: 0; batch classifier loss: 0.367141; batch adversarial loss: 0.344056\n",
      "epoch 32; iter: 200; batch classifier loss: 0.379958; batch adversarial loss: 0.463571\n",
      "epoch 32; iter: 400; batch classifier loss: 0.413196; batch adversarial loss: 0.340965\n",
      "epoch 32; iter: 600; batch classifier loss: 0.340421; batch adversarial loss: 0.301162\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458110; batch adversarial loss: 0.580741\n",
      "epoch 33; iter: 200; batch classifier loss: 0.438729; batch adversarial loss: 0.366423\n",
      "epoch 33; iter: 400; batch classifier loss: 0.286671; batch adversarial loss: 0.425462\n",
      "epoch 33; iter: 600; batch classifier loss: 0.496195; batch adversarial loss: 0.465996\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310962; batch adversarial loss: 0.646168\n",
      "epoch 34; iter: 200; batch classifier loss: 0.424577; batch adversarial loss: 0.330015\n",
      "epoch 34; iter: 400; batch classifier loss: 0.274002; batch adversarial loss: 0.457484\n",
      "epoch 34; iter: 600; batch classifier loss: 0.384054; batch adversarial loss: 0.286346\n",
      "epoch 35; iter: 0; batch classifier loss: 0.342147; batch adversarial loss: 0.612996\n",
      "epoch 35; iter: 200; batch classifier loss: 0.479912; batch adversarial loss: 0.371598\n",
      "epoch 35; iter: 400; batch classifier loss: 0.352939; batch adversarial loss: 0.398750\n",
      "epoch 35; iter: 600; batch classifier loss: 0.343939; batch adversarial loss: 0.259961\n",
      "epoch 36; iter: 0; batch classifier loss: 0.215041; batch adversarial loss: 0.496331\n",
      "epoch 36; iter: 200; batch classifier loss: 0.394460; batch adversarial loss: 0.294572\n",
      "epoch 36; iter: 400; batch classifier loss: 0.354182; batch adversarial loss: 0.462059\n",
      "epoch 36; iter: 600; batch classifier loss: 0.389388; batch adversarial loss: 0.342904\n",
      "epoch 37; iter: 0; batch classifier loss: 0.433752; batch adversarial loss: 0.301197\n",
      "epoch 37; iter: 200; batch classifier loss: 0.277292; batch adversarial loss: 0.317736\n",
      "epoch 37; iter: 400; batch classifier loss: 0.408920; batch adversarial loss: 0.356694\n",
      "epoch 37; iter: 600; batch classifier loss: 0.312792; batch adversarial loss: 0.455766\n",
      "epoch 38; iter: 0; batch classifier loss: 0.416959; batch adversarial loss: 0.379610\n",
      "epoch 38; iter: 200; batch classifier loss: 0.295089; batch adversarial loss: 0.407613\n",
      "epoch 38; iter: 400; batch classifier loss: 0.319816; batch adversarial loss: 0.433360\n",
      "epoch 38; iter: 600; batch classifier loss: 0.375705; batch adversarial loss: 0.498961\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431878; batch adversarial loss: 0.325727\n",
      "epoch 39; iter: 200; batch classifier loss: 0.303720; batch adversarial loss: 0.451561\n",
      "epoch 39; iter: 400; batch classifier loss: 0.232408; batch adversarial loss: 0.457898\n",
      "epoch 39; iter: 600; batch classifier loss: 0.282310; batch adversarial loss: 0.345830\n",
      "epoch 40; iter: 0; batch classifier loss: 0.293842; batch adversarial loss: 0.560613\n",
      "epoch 40; iter: 200; batch classifier loss: 0.582234; batch adversarial loss: 0.512813\n",
      "epoch 40; iter: 400; batch classifier loss: 0.266829; batch adversarial loss: 0.486345\n",
      "epoch 40; iter: 600; batch classifier loss: 0.231341; batch adversarial loss: 0.362361\n",
      "epoch 41; iter: 0; batch classifier loss: 0.297499; batch adversarial loss: 0.615610\n",
      "epoch 41; iter: 200; batch classifier loss: 0.318296; batch adversarial loss: 0.378214\n",
      "epoch 41; iter: 400; batch classifier loss: 0.350882; batch adversarial loss: 0.265033\n",
      "epoch 41; iter: 600; batch classifier loss: 0.357582; batch adversarial loss: 0.364578\n",
      "epoch 42; iter: 0; batch classifier loss: 0.530279; batch adversarial loss: 0.319419\n",
      "epoch 42; iter: 200; batch classifier loss: 0.345950; batch adversarial loss: 0.361813\n",
      "epoch 42; iter: 400; batch classifier loss: 0.218552; batch adversarial loss: 0.348113\n",
      "epoch 42; iter: 600; batch classifier loss: 0.471796; batch adversarial loss: 0.424609\n",
      "epoch 43; iter: 0; batch classifier loss: 0.292699; batch adversarial loss: 0.354810\n",
      "epoch 43; iter: 200; batch classifier loss: 0.354528; batch adversarial loss: 0.454772\n",
      "epoch 43; iter: 400; batch classifier loss: 0.322587; batch adversarial loss: 0.260984\n",
      "epoch 43; iter: 600; batch classifier loss: 0.508060; batch adversarial loss: 0.374334\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403463; batch adversarial loss: 0.324864\n",
      "epoch 44; iter: 200; batch classifier loss: 0.347959; batch adversarial loss: 0.316936\n",
      "epoch 44; iter: 400; batch classifier loss: 0.438052; batch adversarial loss: 0.421387\n",
      "epoch 44; iter: 600; batch classifier loss: 0.648558; batch adversarial loss: 0.347107\n",
      "epoch 45; iter: 0; batch classifier loss: 0.329601; batch adversarial loss: 0.532429\n",
      "epoch 45; iter: 200; batch classifier loss: 0.318535; batch adversarial loss: 0.377498\n",
      "epoch 45; iter: 400; batch classifier loss: 0.427507; batch adversarial loss: 0.295857\n",
      "epoch 45; iter: 600; batch classifier loss: 0.277778; batch adversarial loss: 0.347749\n",
      "epoch 46; iter: 0; batch classifier loss: 0.295620; batch adversarial loss: 0.407881\n",
      "epoch 46; iter: 200; batch classifier loss: 0.354445; batch adversarial loss: 0.462606\n",
      "epoch 46; iter: 400; batch classifier loss: 0.254392; batch adversarial loss: 0.458328\n",
      "epoch 46; iter: 600; batch classifier loss: 0.287444; batch adversarial loss: 0.527577\n",
      "epoch 47; iter: 0; batch classifier loss: 0.275358; batch adversarial loss: 0.507555\n",
      "epoch 47; iter: 200; batch classifier loss: 0.379910; batch adversarial loss: 0.460122\n",
      "epoch 47; iter: 400; batch classifier loss: 0.403194; batch adversarial loss: 0.415620\n",
      "epoch 47; iter: 600; batch classifier loss: 0.343589; batch adversarial loss: 0.401334\n",
      "epoch 48; iter: 0; batch classifier loss: 0.238375; batch adversarial loss: 0.458123\n",
      "epoch 48; iter: 200; batch classifier loss: 0.292601; batch adversarial loss: 0.458381\n",
      "epoch 48; iter: 400; batch classifier loss: 0.244736; batch adversarial loss: 0.422581\n",
      "epoch 48; iter: 600; batch classifier loss: 0.255047; batch adversarial loss: 0.342904\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480049; batch adversarial loss: 0.460725\n",
      "epoch 49; iter: 200; batch classifier loss: 0.327510; batch adversarial loss: 0.260143\n",
      "epoch 49; iter: 400; batch classifier loss: 0.230606; batch adversarial loss: 0.339260\n",
      "epoch 49; iter: 600; batch classifier loss: 0.386196; batch adversarial loss: 0.348493\n",
      "epoch 0; iter: 0; batch classifier loss: 14.568682; batch adversarial loss: 0.454137\n",
      "epoch 0; iter: 200; batch classifier loss: 3.847045; batch adversarial loss: 0.556493\n",
      "epoch 0; iter: 400; batch classifier loss: 1.358195; batch adversarial loss: 0.591072\n",
      "epoch 0; iter: 600; batch classifier loss: 1.896001; batch adversarial loss: 0.487073\n",
      "epoch 1; iter: 0; batch classifier loss: 5.899689; batch adversarial loss: 0.471305\n",
      "epoch 1; iter: 200; batch classifier loss: 3.349444; batch adversarial loss: 0.455632\n",
      "epoch 1; iter: 400; batch classifier loss: 0.843092; batch adversarial loss: 0.503134\n",
      "epoch 1; iter: 600; batch classifier loss: 10.283652; batch adversarial loss: 0.479480\n",
      "epoch 2; iter: 0; batch classifier loss: 1.893355; batch adversarial loss: 0.388579\n",
      "epoch 2; iter: 200; batch classifier loss: 4.515656; batch adversarial loss: 0.391296\n",
      "epoch 2; iter: 400; batch classifier loss: 3.474210; batch adversarial loss: 0.488998\n",
      "epoch 2; iter: 600; batch classifier loss: 3.390539; batch adversarial loss: 0.473821\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541886; batch adversarial loss: 0.457107\n",
      "epoch 3; iter: 200; batch classifier loss: 0.633793; batch adversarial loss: 0.630845\n",
      "epoch 3; iter: 400; batch classifier loss: 0.765093; batch adversarial loss: 0.311313\n",
      "epoch 3; iter: 600; batch classifier loss: 0.546225; batch adversarial loss: 0.563452\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546699; batch adversarial loss: 0.576660\n",
      "epoch 4; iter: 200; batch classifier loss: 0.793877; batch adversarial loss: 0.301341\n",
      "epoch 4; iter: 400; batch classifier loss: 8.284582; batch adversarial loss: 0.437201\n",
      "epoch 4; iter: 600; batch classifier loss: 0.486073; batch adversarial loss: 0.418187\n",
      "epoch 5; iter: 0; batch classifier loss: 0.756277; batch adversarial loss: 0.437574\n",
      "epoch 5; iter: 200; batch classifier loss: 0.273481; batch adversarial loss: 0.549974\n",
      "epoch 5; iter: 400; batch classifier loss: 0.404624; batch adversarial loss: 0.397315\n",
      "epoch 5; iter: 600; batch classifier loss: 5.414940; batch adversarial loss: 0.350928\n",
      "epoch 6; iter: 0; batch classifier loss: 1.038462; batch adversarial loss: 0.268740\n",
      "epoch 6; iter: 200; batch classifier loss: 0.469001; batch adversarial loss: 0.443542\n",
      "epoch 6; iter: 400; batch classifier loss: 0.322203; batch adversarial loss: 0.325576\n",
      "epoch 6; iter: 600; batch classifier loss: 0.426777; batch adversarial loss: 0.286376\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561673; batch adversarial loss: 0.449779\n",
      "epoch 7; iter: 200; batch classifier loss: 0.541574; batch adversarial loss: 0.439658\n",
      "epoch 7; iter: 400; batch classifier loss: 0.426048; batch adversarial loss: 0.323825\n",
      "epoch 7; iter: 600; batch classifier loss: 0.352494; batch adversarial loss: 0.346496\n",
      "epoch 8; iter: 0; batch classifier loss: 0.260491; batch adversarial loss: 0.621872\n",
      "epoch 8; iter: 200; batch classifier loss: 0.476790; batch adversarial loss: 0.428194\n",
      "epoch 8; iter: 400; batch classifier loss: 0.378479; batch adversarial loss: 0.452845\n",
      "epoch 8; iter: 600; batch classifier loss: 0.415856; batch adversarial loss: 0.546627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.317227; batch adversarial loss: 0.370597\n",
      "epoch 9; iter: 200; batch classifier loss: 0.341218; batch adversarial loss: 0.291919\n",
      "epoch 9; iter: 400; batch classifier loss: 0.498699; batch adversarial loss: 0.413666\n",
      "epoch 9; iter: 600; batch classifier loss: 0.436405; batch adversarial loss: 0.420007\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321619; batch adversarial loss: 0.405049\n",
      "epoch 10; iter: 200; batch classifier loss: 0.421236; batch adversarial loss: 0.319843\n",
      "epoch 10; iter: 400; batch classifier loss: 0.487732; batch adversarial loss: 0.478537\n",
      "epoch 10; iter: 600; batch classifier loss: 0.333960; batch adversarial loss: 0.320486\n",
      "epoch 11; iter: 0; batch classifier loss: 0.286112; batch adversarial loss: 0.317330\n",
      "epoch 11; iter: 200; batch classifier loss: 0.367042; batch adversarial loss: 0.423102\n",
      "epoch 11; iter: 400; batch classifier loss: 0.424352; batch adversarial loss: 0.477964\n",
      "epoch 11; iter: 600; batch classifier loss: 0.317640; batch adversarial loss: 0.402873\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329333; batch adversarial loss: 0.404585\n",
      "epoch 12; iter: 200; batch classifier loss: 0.387239; batch adversarial loss: 0.447313\n",
      "epoch 12; iter: 400; batch classifier loss: 0.351192; batch adversarial loss: 0.449312\n",
      "epoch 12; iter: 600; batch classifier loss: 0.261258; batch adversarial loss: 0.386050\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521444; batch adversarial loss: 0.403624\n",
      "epoch 13; iter: 200; batch classifier loss: 0.265801; batch adversarial loss: 0.506778\n",
      "epoch 13; iter: 400; batch classifier loss: 0.225860; batch adversarial loss: 0.460802\n",
      "epoch 13; iter: 600; batch classifier loss: 0.279689; batch adversarial loss: 0.423443\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358250; batch adversarial loss: 0.410036\n",
      "epoch 14; iter: 200; batch classifier loss: 0.380440; batch adversarial loss: 0.374489\n",
      "epoch 14; iter: 400; batch classifier loss: 0.285386; batch adversarial loss: 0.373618\n",
      "epoch 14; iter: 600; batch classifier loss: 0.239381; batch adversarial loss: 0.596802\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370962; batch adversarial loss: 0.292337\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341884; batch adversarial loss: 0.449773\n",
      "epoch 15; iter: 400; batch classifier loss: 0.457789; batch adversarial loss: 0.403058\n",
      "epoch 15; iter: 600; batch classifier loss: 0.314288; batch adversarial loss: 0.559922\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301664; batch adversarial loss: 0.316162\n",
      "epoch 16; iter: 200; batch classifier loss: 0.289592; batch adversarial loss: 0.399249\n",
      "epoch 16; iter: 400; batch classifier loss: 0.424051; batch adversarial loss: 0.346803\n",
      "epoch 16; iter: 600; batch classifier loss: 0.263570; batch adversarial loss: 0.582560\n",
      "epoch 17; iter: 0; batch classifier loss: 0.406215; batch adversarial loss: 0.461866\n",
      "epoch 17; iter: 200; batch classifier loss: 0.396136; batch adversarial loss: 0.291897\n",
      "epoch 17; iter: 400; batch classifier loss: 0.303722; batch adversarial loss: 0.351812\n",
      "epoch 17; iter: 600; batch classifier loss: 0.344411; batch adversarial loss: 0.289152\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300259; batch adversarial loss: 0.515726\n",
      "epoch 18; iter: 200; batch classifier loss: 0.316508; batch adversarial loss: 0.314135\n",
      "epoch 18; iter: 400; batch classifier loss: 0.264343; batch adversarial loss: 0.395698\n",
      "epoch 18; iter: 600; batch classifier loss: 0.478547; batch adversarial loss: 0.476231\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261856; batch adversarial loss: 0.377403\n",
      "epoch 19; iter: 200; batch classifier loss: 0.273633; batch adversarial loss: 0.449827\n",
      "epoch 19; iter: 400; batch classifier loss: 0.284929; batch adversarial loss: 0.383858\n",
      "epoch 19; iter: 600; batch classifier loss: 0.357184; batch adversarial loss: 0.373216\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406540; batch adversarial loss: 0.350503\n",
      "epoch 20; iter: 200; batch classifier loss: 0.398436; batch adversarial loss: 0.455215\n",
      "epoch 20; iter: 400; batch classifier loss: 0.274346; batch adversarial loss: 0.354095\n",
      "epoch 20; iter: 600; batch classifier loss: 0.357312; batch adversarial loss: 0.455121\n",
      "epoch 21; iter: 0; batch classifier loss: 0.421241; batch adversarial loss: 0.414570\n",
      "epoch 21; iter: 200; batch classifier loss: 0.314230; batch adversarial loss: 0.316291\n",
      "epoch 21; iter: 400; batch classifier loss: 0.284366; batch adversarial loss: 0.348603\n",
      "epoch 21; iter: 600; batch classifier loss: 0.437098; batch adversarial loss: 0.423571\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331975; batch adversarial loss: 0.432390\n",
      "epoch 22; iter: 200; batch classifier loss: 0.304346; batch adversarial loss: 0.494571\n",
      "epoch 22; iter: 400; batch classifier loss: 0.288886; batch adversarial loss: 0.378454\n",
      "epoch 22; iter: 600; batch classifier loss: 0.335868; batch adversarial loss: 0.455025\n",
      "epoch 23; iter: 0; batch classifier loss: 0.395085; batch adversarial loss: 0.350151\n",
      "epoch 23; iter: 200; batch classifier loss: 0.393993; batch adversarial loss: 0.351578\n",
      "epoch 23; iter: 400; batch classifier loss: 0.501713; batch adversarial loss: 0.346686\n",
      "epoch 23; iter: 600; batch classifier loss: 0.509131; batch adversarial loss: 0.427626\n",
      "epoch 24; iter: 0; batch classifier loss: 0.289832; batch adversarial loss: 0.399383\n",
      "epoch 24; iter: 200; batch classifier loss: 0.468262; batch adversarial loss: 0.380562\n",
      "epoch 24; iter: 400; batch classifier loss: 0.218678; batch adversarial loss: 0.381569\n",
      "epoch 24; iter: 600; batch classifier loss: 0.471513; batch adversarial loss: 0.493640\n",
      "epoch 25; iter: 0; batch classifier loss: 0.266653; batch adversarial loss: 0.583436\n",
      "epoch 25; iter: 200; batch classifier loss: 0.473342; batch adversarial loss: 0.377927\n",
      "epoch 25; iter: 400; batch classifier loss: 0.410699; batch adversarial loss: 0.377866\n",
      "epoch 25; iter: 600; batch classifier loss: 0.230985; batch adversarial loss: 0.424816\n",
      "epoch 26; iter: 0; batch classifier loss: 0.392304; batch adversarial loss: 0.399586\n",
      "epoch 26; iter: 200; batch classifier loss: 0.475531; batch adversarial loss: 0.442193\n",
      "epoch 26; iter: 400; batch classifier loss: 0.519940; batch adversarial loss: 0.318098\n",
      "epoch 26; iter: 600; batch classifier loss: 0.435494; batch adversarial loss: 0.425777\n",
      "epoch 27; iter: 0; batch classifier loss: 0.591454; batch adversarial loss: 0.399054\n",
      "epoch 27; iter: 200; batch classifier loss: 0.367856; batch adversarial loss: 0.492004\n",
      "epoch 27; iter: 400; batch classifier loss: 0.406269; batch adversarial loss: 0.403156\n",
      "epoch 27; iter: 600; batch classifier loss: 0.440974; batch adversarial loss: 0.434868\n",
      "epoch 28; iter: 0; batch classifier loss: 0.330310; batch adversarial loss: 0.375072\n",
      "epoch 28; iter: 200; batch classifier loss: 0.262419; batch adversarial loss: 0.438091\n",
      "epoch 28; iter: 400; batch classifier loss: 0.386438; batch adversarial loss: 0.449543\n",
      "epoch 28; iter: 600; batch classifier loss: 0.335679; batch adversarial loss: 0.364969\n",
      "epoch 29; iter: 0; batch classifier loss: 0.336111; batch adversarial loss: 0.470644\n",
      "epoch 29; iter: 200; batch classifier loss: 0.355521; batch adversarial loss: 0.532413\n",
      "epoch 29; iter: 400; batch classifier loss: 0.402380; batch adversarial loss: 0.403789\n",
      "epoch 29; iter: 600; batch classifier loss: 0.400678; batch adversarial loss: 0.368933\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446505; batch adversarial loss: 0.506306\n",
      "epoch 30; iter: 200; batch classifier loss: 0.246689; batch adversarial loss: 0.321900\n",
      "epoch 30; iter: 400; batch classifier loss: 0.380073; batch adversarial loss: 0.339671\n",
      "epoch 30; iter: 600; batch classifier loss: 0.218550; batch adversarial loss: 0.454987\n",
      "epoch 31; iter: 0; batch classifier loss: 0.551673; batch adversarial loss: 0.342450\n",
      "epoch 31; iter: 200; batch classifier loss: 0.459850; batch adversarial loss: 0.479373\n",
      "epoch 31; iter: 400; batch classifier loss: 0.615182; batch adversarial loss: 0.353606\n",
      "epoch 31; iter: 600; batch classifier loss: 0.252387; batch adversarial loss: 0.240011\n",
      "epoch 32; iter: 0; batch classifier loss: 0.458142; batch adversarial loss: 0.474318\n",
      "epoch 32; iter: 200; batch classifier loss: 0.313663; batch adversarial loss: 0.427231\n",
      "epoch 32; iter: 400; batch classifier loss: 0.386081; batch adversarial loss: 0.396828\n",
      "epoch 32; iter: 600; batch classifier loss: 0.251036; batch adversarial loss: 0.511135\n",
      "epoch 33; iter: 0; batch classifier loss: 0.260088; batch adversarial loss: 0.403208\n",
      "epoch 33; iter: 200; batch classifier loss: 0.429056; batch adversarial loss: 0.514237\n",
      "epoch 33; iter: 400; batch classifier loss: 0.377525; batch adversarial loss: 0.571800\n",
      "epoch 33; iter: 600; batch classifier loss: 0.378354; batch adversarial loss: 0.344005\n",
      "epoch 34; iter: 0; batch classifier loss: 0.364777; batch adversarial loss: 0.595470\n",
      "epoch 34; iter: 200; batch classifier loss: 0.298221; batch adversarial loss: 0.429713\n",
      "epoch 34; iter: 400; batch classifier loss: 0.417376; batch adversarial loss: 0.483757\n",
      "epoch 34; iter: 600; batch classifier loss: 0.298762; batch adversarial loss: 0.379570\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407809; batch adversarial loss: 0.451997\n",
      "epoch 35; iter: 200; batch classifier loss: 0.313638; batch adversarial loss: 0.397518\n",
      "epoch 35; iter: 400; batch classifier loss: 0.283766; batch adversarial loss: 0.509016\n",
      "epoch 35; iter: 600; batch classifier loss: 0.306965; batch adversarial loss: 0.438598\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479930; batch adversarial loss: 0.428983\n",
      "epoch 36; iter: 200; batch classifier loss: 0.353477; batch adversarial loss: 0.501001\n",
      "epoch 36; iter: 400; batch classifier loss: 0.477486; batch adversarial loss: 0.399231\n",
      "epoch 36; iter: 600; batch classifier loss: 0.442726; batch adversarial loss: 0.442771\n",
      "epoch 37; iter: 0; batch classifier loss: 0.319870; batch adversarial loss: 0.368312\n",
      "epoch 37; iter: 200; batch classifier loss: 0.301009; batch adversarial loss: 0.476602\n",
      "epoch 37; iter: 400; batch classifier loss: 0.393368; batch adversarial loss: 0.346272\n",
      "epoch 37; iter: 600; batch classifier loss: 0.190632; batch adversarial loss: 0.303783\n",
      "epoch 38; iter: 0; batch classifier loss: 0.363153; batch adversarial loss: 0.320118\n",
      "epoch 38; iter: 200; batch classifier loss: 0.415504; batch adversarial loss: 0.473081\n",
      "epoch 38; iter: 400; batch classifier loss: 0.752421; batch adversarial loss: 0.358719\n",
      "epoch 38; iter: 600; batch classifier loss: 0.365526; batch adversarial loss: 0.419892\n",
      "epoch 39; iter: 0; batch classifier loss: 0.419801; batch adversarial loss: 0.429483\n",
      "epoch 39; iter: 200; batch classifier loss: 0.375940; batch adversarial loss: 0.548574\n",
      "epoch 39; iter: 400; batch classifier loss: 0.380783; batch adversarial loss: 0.368806\n",
      "epoch 39; iter: 600; batch classifier loss: 0.371189; batch adversarial loss: 0.353930\n",
      "epoch 40; iter: 0; batch classifier loss: 0.373195; batch adversarial loss: 0.379394\n",
      "epoch 40; iter: 200; batch classifier loss: 0.243387; batch adversarial loss: 0.429737\n",
      "epoch 40; iter: 400; batch classifier loss: 0.519537; batch adversarial loss: 0.293436\n",
      "epoch 40; iter: 600; batch classifier loss: 0.432891; batch adversarial loss: 0.352739\n",
      "epoch 41; iter: 0; batch classifier loss: 0.267240; batch adversarial loss: 0.502684\n",
      "epoch 41; iter: 200; batch classifier loss: 0.372307; batch adversarial loss: 0.519439\n",
      "epoch 41; iter: 400; batch classifier loss: 0.302991; batch adversarial loss: 0.406470\n",
      "epoch 41; iter: 600; batch classifier loss: 0.340260; batch adversarial loss: 0.375618\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400558; batch adversarial loss: 0.457939\n",
      "epoch 42; iter: 200; batch classifier loss: 0.201844; batch adversarial loss: 0.349303\n",
      "epoch 42; iter: 400; batch classifier loss: 0.322333; batch adversarial loss: 0.401747\n",
      "epoch 42; iter: 600; batch classifier loss: 0.275550; batch adversarial loss: 0.318702\n",
      "epoch 43; iter: 0; batch classifier loss: 0.358006; batch adversarial loss: 0.430378\n",
      "epoch 43; iter: 200; batch classifier loss: 0.411863; batch adversarial loss: 0.466838\n",
      "epoch 43; iter: 400; batch classifier loss: 0.348469; batch adversarial loss: 0.372742\n",
      "epoch 43; iter: 600; batch classifier loss: 0.535189; batch adversarial loss: 0.502939\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481098; batch adversarial loss: 0.322957\n",
      "epoch 44; iter: 200; batch classifier loss: 0.349579; batch adversarial loss: 0.507656\n",
      "epoch 44; iter: 400; batch classifier loss: 0.422402; batch adversarial loss: 0.374470\n",
      "epoch 44; iter: 600; batch classifier loss: 0.490310; batch adversarial loss: 0.539730\n",
      "epoch 45; iter: 0; batch classifier loss: 0.285610; batch adversarial loss: 0.212882\n",
      "epoch 45; iter: 200; batch classifier loss: 0.424378; batch adversarial loss: 0.430064\n",
      "epoch 45; iter: 400; batch classifier loss: 0.282367; batch adversarial loss: 0.432440\n",
      "epoch 45; iter: 600; batch classifier loss: 0.340315; batch adversarial loss: 0.411895\n",
      "epoch 46; iter: 0; batch classifier loss: 0.224034; batch adversarial loss: 0.319522\n",
      "epoch 46; iter: 200; batch classifier loss: 0.486262; batch adversarial loss: 0.331189\n",
      "epoch 46; iter: 400; batch classifier loss: 0.381196; batch adversarial loss: 0.331012\n",
      "epoch 46; iter: 600; batch classifier loss: 0.360556; batch adversarial loss: 0.414122\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366373; batch adversarial loss: 0.528952\n",
      "epoch 47; iter: 200; batch classifier loss: 0.473164; batch adversarial loss: 0.342750\n",
      "epoch 47; iter: 400; batch classifier loss: 0.416445; batch adversarial loss: 0.345951\n",
      "epoch 47; iter: 600; batch classifier loss: 0.789476; batch adversarial loss: 0.404303\n",
      "epoch 48; iter: 0; batch classifier loss: 0.542302; batch adversarial loss: 0.347854\n",
      "epoch 48; iter: 200; batch classifier loss: 0.199404; batch adversarial loss: 0.390740\n",
      "epoch 48; iter: 400; batch classifier loss: 0.361047; batch adversarial loss: 0.371199\n",
      "epoch 48; iter: 600; batch classifier loss: 0.461998; batch adversarial loss: 0.349110\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392350; batch adversarial loss: 0.364878\n",
      "epoch 49; iter: 200; batch classifier loss: 0.525197; batch adversarial loss: 0.572468\n",
      "epoch 49; iter: 400; batch classifier loss: 0.259051; batch adversarial loss: 0.487221\n",
      "epoch 49; iter: 600; batch classifier loss: 0.540911; batch adversarial loss: 0.297718\n",
      "epoch 0; iter: 0; batch classifier loss: 38.686516; batch adversarial loss: 0.598196\n",
      "epoch 0; iter: 200; batch classifier loss: 7.209325; batch adversarial loss: 0.668603\n",
      "epoch 0; iter: 400; batch classifier loss: 9.555973; batch adversarial loss: 0.591162\n",
      "epoch 0; iter: 600; batch classifier loss: 3.337026; batch adversarial loss: 0.529737\n",
      "epoch 1; iter: 0; batch classifier loss: 3.499589; batch adversarial loss: 0.482317\n",
      "epoch 1; iter: 200; batch classifier loss: 17.448357; batch adversarial loss: 0.467851\n",
      "epoch 1; iter: 400; batch classifier loss: 6.168417; batch adversarial loss: 0.369820\n",
      "epoch 1; iter: 600; batch classifier loss: 3.205626; batch adversarial loss: 0.428021\n",
      "epoch 2; iter: 0; batch classifier loss: 3.197281; batch adversarial loss: 0.512867\n",
      "epoch 2; iter: 200; batch classifier loss: 1.770660; batch adversarial loss: 0.408151\n",
      "epoch 2; iter: 400; batch classifier loss: 4.922130; batch adversarial loss: 0.474468\n",
      "epoch 2; iter: 600; batch classifier loss: 1.199887; batch adversarial loss: 0.397943\n",
      "epoch 3; iter: 0; batch classifier loss: 0.450056; batch adversarial loss: 0.462249\n",
      "epoch 3; iter: 200; batch classifier loss: 0.641505; batch adversarial loss: 0.473041\n",
      "epoch 3; iter: 400; batch classifier loss: 0.809058; batch adversarial loss: 0.369480\n",
      "epoch 3; iter: 600; batch classifier loss: 0.388323; batch adversarial loss: 0.376636\n",
      "epoch 4; iter: 0; batch classifier loss: 0.345077; batch adversarial loss: 0.508815\n",
      "epoch 4; iter: 200; batch classifier loss: 0.602342; batch adversarial loss: 0.454175\n",
      "epoch 4; iter: 400; batch classifier loss: 1.062409; batch adversarial loss: 0.374520\n",
      "epoch 4; iter: 600; batch classifier loss: 0.398507; batch adversarial loss: 0.420223\n",
      "epoch 5; iter: 0; batch classifier loss: 0.391768; batch adversarial loss: 0.321386\n",
      "epoch 5; iter: 200; batch classifier loss: 0.325166; batch adversarial loss: 0.349022\n",
      "epoch 5; iter: 400; batch classifier loss: 0.326520; batch adversarial loss: 0.426109\n",
      "epoch 5; iter: 600; batch classifier loss: 0.535468; batch adversarial loss: 0.355894\n",
      "epoch 6; iter: 0; batch classifier loss: 0.493084; batch adversarial loss: 0.383660\n",
      "epoch 6; iter: 200; batch classifier loss: 0.493157; batch adversarial loss: 0.569160\n",
      "epoch 6; iter: 400; batch classifier loss: 0.516169; batch adversarial loss: 0.338766\n",
      "epoch 6; iter: 600; batch classifier loss: 0.362928; batch adversarial loss: 0.314916\n",
      "epoch 7; iter: 0; batch classifier loss: 0.487062; batch adversarial loss: 0.436851\n",
      "epoch 7; iter: 200; batch classifier loss: 0.645320; batch adversarial loss: 0.382755\n",
      "epoch 7; iter: 400; batch classifier loss: 0.288960; batch adversarial loss: 0.364478\n",
      "epoch 7; iter: 600; batch classifier loss: 0.522371; batch adversarial loss: 0.491852\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449702; batch adversarial loss: 0.569261\n",
      "epoch 8; iter: 200; batch classifier loss: 0.477358; batch adversarial loss: 0.460420\n",
      "epoch 8; iter: 400; batch classifier loss: 0.304132; batch adversarial loss: 0.458758\n",
      "epoch 8; iter: 600; batch classifier loss: 0.332539; batch adversarial loss: 0.423660\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320200; batch adversarial loss: 0.610354\n",
      "epoch 9; iter: 200; batch classifier loss: 0.642474; batch adversarial loss: 0.317205\n",
      "epoch 9; iter: 400; batch classifier loss: 0.405869; batch adversarial loss: 0.446085\n",
      "epoch 9; iter: 600; batch classifier loss: 0.326782; batch adversarial loss: 0.467814\n",
      "epoch 10; iter: 0; batch classifier loss: 0.448616; batch adversarial loss: 0.331584\n",
      "epoch 10; iter: 200; batch classifier loss: 0.334418; batch adversarial loss: 0.401616\n",
      "epoch 10; iter: 400; batch classifier loss: 0.346861; batch adversarial loss: 0.465738\n",
      "epoch 10; iter: 600; batch classifier loss: 0.389792; batch adversarial loss: 0.405658\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309643; batch adversarial loss: 0.351525\n",
      "epoch 11; iter: 200; batch classifier loss: 0.283256; batch adversarial loss: 0.506424\n",
      "epoch 11; iter: 400; batch classifier loss: 0.297522; batch adversarial loss: 0.472544\n",
      "epoch 11; iter: 600; batch classifier loss: 0.356297; batch adversarial loss: 0.557417\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407638; batch adversarial loss: 0.492985\n",
      "epoch 12; iter: 200; batch classifier loss: 0.312058; batch adversarial loss: 0.501053\n",
      "epoch 12; iter: 400; batch classifier loss: 0.334949; batch adversarial loss: 0.431144\n",
      "epoch 12; iter: 600; batch classifier loss: 0.328505; batch adversarial loss: 0.546082\n",
      "epoch 13; iter: 0; batch classifier loss: 0.332934; batch adversarial loss: 0.484416\n",
      "epoch 13; iter: 200; batch classifier loss: 0.299240; batch adversarial loss: 0.478546\n",
      "epoch 13; iter: 400; batch classifier loss: 0.296318; batch adversarial loss: 0.506594\n",
      "epoch 13; iter: 600; batch classifier loss: 0.402526; batch adversarial loss: 0.382352\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307461; batch adversarial loss: 0.434963\n",
      "epoch 14; iter: 200; batch classifier loss: 0.265776; batch adversarial loss: 0.478536\n",
      "epoch 14; iter: 400; batch classifier loss: 0.307921; batch adversarial loss: 0.487732\n",
      "epoch 14; iter: 600; batch classifier loss: 0.335315; batch adversarial loss: 0.377221\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274118; batch adversarial loss: 0.354799\n",
      "epoch 15; iter: 200; batch classifier loss: 0.297082; batch adversarial loss: 0.345168\n",
      "epoch 15; iter: 400; batch classifier loss: 0.333772; batch adversarial loss: 0.292155\n",
      "epoch 15; iter: 600; batch classifier loss: 0.211519; batch adversarial loss: 0.401868\n",
      "epoch 16; iter: 0; batch classifier loss: 0.309210; batch adversarial loss: 0.321196\n",
      "epoch 16; iter: 200; batch classifier loss: 0.390404; batch adversarial loss: 0.467891\n",
      "epoch 16; iter: 400; batch classifier loss: 0.301392; batch adversarial loss: 0.326111\n",
      "epoch 16; iter: 600; batch classifier loss: 0.259084; batch adversarial loss: 0.489234\n",
      "epoch 17; iter: 0; batch classifier loss: 0.407637; batch adversarial loss: 0.315037\n",
      "epoch 17; iter: 200; batch classifier loss: 0.435912; batch adversarial loss: 0.462696\n",
      "epoch 17; iter: 400; batch classifier loss: 0.321178; batch adversarial loss: 0.642495\n",
      "epoch 17; iter: 600; batch classifier loss: 0.636898; batch adversarial loss: 0.409624\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268056; batch adversarial loss: 0.403494\n",
      "epoch 18; iter: 200; batch classifier loss: 0.392508; batch adversarial loss: 0.432961\n",
      "epoch 18; iter: 400; batch classifier loss: 0.331468; batch adversarial loss: 0.344205\n",
      "epoch 18; iter: 600; batch classifier loss: 0.344953; batch adversarial loss: 0.314511\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309555; batch adversarial loss: 0.487296\n",
      "epoch 19; iter: 200; batch classifier loss: 0.361864; batch adversarial loss: 0.347909\n",
      "epoch 19; iter: 400; batch classifier loss: 0.392506; batch adversarial loss: 0.410273\n",
      "epoch 19; iter: 600; batch classifier loss: 0.371185; batch adversarial loss: 0.451282\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269320; batch adversarial loss: 0.343405\n",
      "epoch 20; iter: 200; batch classifier loss: 0.299381; batch adversarial loss: 0.405309\n",
      "epoch 20; iter: 400; batch classifier loss: 0.472524; batch adversarial loss: 0.396738\n",
      "epoch 20; iter: 600; batch classifier loss: 0.299125; batch adversarial loss: 0.404226\n",
      "epoch 21; iter: 0; batch classifier loss: 0.317015; batch adversarial loss: 0.512863\n",
      "epoch 21; iter: 200; batch classifier loss: 0.323572; batch adversarial loss: 0.365825\n",
      "epoch 21; iter: 400; batch classifier loss: 0.453257; batch adversarial loss: 0.530885\n",
      "epoch 21; iter: 600; batch classifier loss: 0.459652; batch adversarial loss: 0.569353\n",
      "epoch 22; iter: 0; batch classifier loss: 0.392045; batch adversarial loss: 0.420215\n",
      "epoch 22; iter: 200; batch classifier loss: 0.246753; batch adversarial loss: 0.479906\n",
      "epoch 22; iter: 400; batch classifier loss: 0.346537; batch adversarial loss: 0.515391\n",
      "epoch 22; iter: 600; batch classifier loss: 0.352038; batch adversarial loss: 0.342957\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514185; batch adversarial loss: 0.391183\n",
      "epoch 23; iter: 200; batch classifier loss: 0.368817; batch adversarial loss: 0.289303\n",
      "epoch 23; iter: 400; batch classifier loss: 0.369474; batch adversarial loss: 0.315437\n",
      "epoch 23; iter: 600; batch classifier loss: 0.242026; batch adversarial loss: 0.509205\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426248; batch adversarial loss: 0.340214\n",
      "epoch 24; iter: 200; batch classifier loss: 0.434782; batch adversarial loss: 0.344299\n",
      "epoch 24; iter: 400; batch classifier loss: 0.310331; batch adversarial loss: 0.393968\n",
      "epoch 24; iter: 600; batch classifier loss: 0.282168; batch adversarial loss: 0.563617\n",
      "epoch 25; iter: 0; batch classifier loss: 0.336159; batch adversarial loss: 0.499446\n",
      "epoch 25; iter: 200; batch classifier loss: 0.382540; batch adversarial loss: 0.517836\n",
      "epoch 25; iter: 400; batch classifier loss: 0.471441; batch adversarial loss: 0.341952\n",
      "epoch 25; iter: 600; batch classifier loss: 0.358166; batch adversarial loss: 0.396743\n",
      "epoch 26; iter: 0; batch classifier loss: 0.433612; batch adversarial loss: 0.510294\n",
      "epoch 26; iter: 200; batch classifier loss: 0.447721; batch adversarial loss: 0.292931\n",
      "epoch 26; iter: 400; batch classifier loss: 0.398910; batch adversarial loss: 0.399403\n",
      "epoch 26; iter: 600; batch classifier loss: 0.236538; batch adversarial loss: 0.497283\n",
      "epoch 27; iter: 0; batch classifier loss: 0.416915; batch adversarial loss: 0.261736\n",
      "epoch 27; iter: 200; batch classifier loss: 0.341790; batch adversarial loss: 0.489196\n",
      "epoch 27; iter: 400; batch classifier loss: 0.277206; batch adversarial loss: 0.402309\n",
      "epoch 27; iter: 600; batch classifier loss: 0.367752; batch adversarial loss: 0.496379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.376972; batch adversarial loss: 0.326332\n",
      "epoch 28; iter: 200; batch classifier loss: 0.248682; batch adversarial loss: 0.369106\n",
      "epoch 28; iter: 400; batch classifier loss: 0.321519; batch adversarial loss: 0.317998\n",
      "epoch 28; iter: 600; batch classifier loss: 0.394163; batch adversarial loss: 0.550264\n",
      "epoch 29; iter: 0; batch classifier loss: 0.154229; batch adversarial loss: 0.400747\n",
      "epoch 29; iter: 200; batch classifier loss: 0.303627; batch adversarial loss: 0.290057\n",
      "epoch 29; iter: 400; batch classifier loss: 0.661680; batch adversarial loss: 0.401326\n",
      "epoch 29; iter: 600; batch classifier loss: 0.297627; batch adversarial loss: 0.417953\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390431; batch adversarial loss: 0.425177\n",
      "epoch 30; iter: 200; batch classifier loss: 0.312155; batch adversarial loss: 0.610353\n",
      "epoch 30; iter: 400; batch classifier loss: 0.331419; batch adversarial loss: 0.427860\n",
      "epoch 30; iter: 600; batch classifier loss: 0.417756; batch adversarial loss: 0.387911\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334368; batch adversarial loss: 0.566919\n",
      "epoch 31; iter: 200; batch classifier loss: 0.306661; batch adversarial loss: 0.441462\n",
      "epoch 31; iter: 400; batch classifier loss: 0.402745; batch adversarial loss: 0.512624\n",
      "epoch 31; iter: 600; batch classifier loss: 0.318523; batch adversarial loss: 0.321339\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418775; batch adversarial loss: 0.370301\n",
      "epoch 32; iter: 200; batch classifier loss: 0.439608; batch adversarial loss: 0.408158\n",
      "epoch 32; iter: 400; batch classifier loss: 0.520176; batch adversarial loss: 0.374147\n",
      "epoch 32; iter: 600; batch classifier loss: 0.348315; batch adversarial loss: 0.428360\n",
      "epoch 33; iter: 0; batch classifier loss: 0.387486; batch adversarial loss: 0.502129\n",
      "epoch 33; iter: 200; batch classifier loss: 0.296871; batch adversarial loss: 0.374339\n",
      "epoch 33; iter: 400; batch classifier loss: 0.291742; batch adversarial loss: 0.464556\n",
      "epoch 33; iter: 600; batch classifier loss: 0.345717; batch adversarial loss: 0.493643\n",
      "epoch 34; iter: 0; batch classifier loss: 0.396168; batch adversarial loss: 0.344203\n",
      "epoch 34; iter: 200; batch classifier loss: 0.266521; batch adversarial loss: 0.478340\n",
      "epoch 34; iter: 400; batch classifier loss: 0.340391; batch adversarial loss: 0.544792\n",
      "epoch 34; iter: 600; batch classifier loss: 0.571292; batch adversarial loss: 0.403897\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405886; batch adversarial loss: 0.492580\n",
      "epoch 35; iter: 200; batch classifier loss: 0.415127; batch adversarial loss: 0.557968\n",
      "epoch 35; iter: 400; batch classifier loss: 0.463901; batch adversarial loss: 0.371489\n",
      "epoch 35; iter: 600; batch classifier loss: 0.386623; batch adversarial loss: 0.424721\n",
      "epoch 36; iter: 0; batch classifier loss: 0.331953; batch adversarial loss: 0.493497\n",
      "epoch 36; iter: 200; batch classifier loss: 0.478241; batch adversarial loss: 0.412430\n",
      "epoch 36; iter: 400; batch classifier loss: 0.362164; batch adversarial loss: 0.551445\n",
      "epoch 36; iter: 600; batch classifier loss: 0.327005; batch adversarial loss: 0.438440\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392849; batch adversarial loss: 0.289719\n",
      "epoch 37; iter: 200; batch classifier loss: 0.555391; batch adversarial loss: 0.316781\n",
      "epoch 37; iter: 400; batch classifier loss: 0.392527; batch adversarial loss: 0.707636\n",
      "epoch 37; iter: 600; batch classifier loss: 0.399747; batch adversarial loss: 0.265501\n",
      "epoch 38; iter: 0; batch classifier loss: 0.232097; batch adversarial loss: 0.451888\n",
      "epoch 38; iter: 200; batch classifier loss: 0.389477; batch adversarial loss: 0.478368\n",
      "epoch 38; iter: 400; batch classifier loss: 0.383315; batch adversarial loss: 0.488986\n",
      "epoch 38; iter: 600; batch classifier loss: 0.411670; batch adversarial loss: 0.437192\n",
      "epoch 39; iter: 0; batch classifier loss: 0.342323; batch adversarial loss: 0.453378\n",
      "epoch 39; iter: 200; batch classifier loss: 0.388103; batch adversarial loss: 0.370935\n",
      "epoch 39; iter: 400; batch classifier loss: 0.433127; batch adversarial loss: 0.489692\n",
      "epoch 39; iter: 600; batch classifier loss: 0.716673; batch adversarial loss: 0.414761\n",
      "epoch 40; iter: 0; batch classifier loss: 0.506318; batch adversarial loss: 0.463224\n",
      "epoch 40; iter: 200; batch classifier loss: 0.574537; batch adversarial loss: 0.641536\n",
      "epoch 40; iter: 400; batch classifier loss: 0.444733; batch adversarial loss: 0.427231\n",
      "epoch 40; iter: 600; batch classifier loss: 0.334050; batch adversarial loss: 0.378141\n",
      "epoch 41; iter: 0; batch classifier loss: 0.332396; batch adversarial loss: 0.437300\n",
      "epoch 41; iter: 200; batch classifier loss: 0.521227; batch adversarial loss: 0.296017\n",
      "epoch 41; iter: 400; batch classifier loss: 0.352140; batch adversarial loss: 0.293739\n",
      "epoch 41; iter: 600; batch classifier loss: 0.495531; batch adversarial loss: 0.488683\n",
      "epoch 42; iter: 0; batch classifier loss: 0.312745; batch adversarial loss: 0.401468\n",
      "epoch 42; iter: 200; batch classifier loss: 0.269032; batch adversarial loss: 0.436309\n",
      "epoch 42; iter: 400; batch classifier loss: 0.421101; batch adversarial loss: 0.302382\n",
      "epoch 42; iter: 600; batch classifier loss: 0.406088; batch adversarial loss: 0.467682\n",
      "epoch 43; iter: 0; batch classifier loss: 0.503869; batch adversarial loss: 0.349028\n",
      "epoch 43; iter: 200; batch classifier loss: 0.278672; batch adversarial loss: 0.452534\n",
      "epoch 43; iter: 400; batch classifier loss: 0.288420; batch adversarial loss: 0.489481\n",
      "epoch 43; iter: 600; batch classifier loss: 0.462378; batch adversarial loss: 0.427697\n",
      "epoch 44; iter: 0; batch classifier loss: 0.289184; batch adversarial loss: 0.364495\n",
      "epoch 44; iter: 200; batch classifier loss: 0.433664; batch adversarial loss: 0.426099\n",
      "epoch 44; iter: 400; batch classifier loss: 0.406530; batch adversarial loss: 0.394570\n",
      "epoch 44; iter: 600; batch classifier loss: 0.509992; batch adversarial loss: 0.270380\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389772; batch adversarial loss: 0.405204\n",
      "epoch 45; iter: 200; batch classifier loss: 0.392781; batch adversarial loss: 0.386224\n",
      "epoch 45; iter: 400; batch classifier loss: 0.219418; batch adversarial loss: 0.454686\n",
      "epoch 45; iter: 600; batch classifier loss: 0.351785; batch adversarial loss: 0.346940\n",
      "epoch 46; iter: 0; batch classifier loss: 0.376417; batch adversarial loss: 0.324816\n",
      "epoch 46; iter: 200; batch classifier loss: 0.371057; batch adversarial loss: 0.318827\n",
      "epoch 46; iter: 400; batch classifier loss: 0.406569; batch adversarial loss: 0.402930\n",
      "epoch 46; iter: 600; batch classifier loss: 0.618764; batch adversarial loss: 0.397104\n",
      "epoch 47; iter: 0; batch classifier loss: 0.364542; batch adversarial loss: 0.491339\n",
      "epoch 47; iter: 200; batch classifier loss: 0.254872; batch adversarial loss: 0.296270\n",
      "epoch 47; iter: 400; batch classifier loss: 0.527696; batch adversarial loss: 0.480177\n",
      "epoch 47; iter: 600; batch classifier loss: 0.400468; batch adversarial loss: 0.404388\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468949; batch adversarial loss: 0.431860\n",
      "epoch 48; iter: 200; batch classifier loss: 0.450399; batch adversarial loss: 0.331961\n",
      "epoch 48; iter: 400; batch classifier loss: 0.256267; batch adversarial loss: 0.324542\n",
      "epoch 48; iter: 600; batch classifier loss: 0.326898; batch adversarial loss: 0.514403\n",
      "epoch 49; iter: 0; batch classifier loss: 0.405515; batch adversarial loss: 0.351925\n",
      "epoch 49; iter: 200; batch classifier loss: 0.425409; batch adversarial loss: 0.417678\n",
      "epoch 49; iter: 400; batch classifier loss: 0.381116; batch adversarial loss: 0.423583\n",
      "epoch 49; iter: 600; batch classifier loss: 0.460976; batch adversarial loss: 0.405097\n",
      "epoch 0; iter: 0; batch classifier loss: 44.215561; batch adversarial loss: 0.693126\n",
      "epoch 0; iter: 200; batch classifier loss: 13.183348; batch adversarial loss: 0.598508\n",
      "epoch 0; iter: 400; batch classifier loss: 0.586445; batch adversarial loss: 0.570555\n",
      "epoch 0; iter: 600; batch classifier loss: 4.180935; batch adversarial loss: 0.594411\n",
      "epoch 1; iter: 0; batch classifier loss: 3.094619; batch adversarial loss: 0.500511\n",
      "epoch 1; iter: 200; batch classifier loss: 1.641127; batch adversarial loss: 0.404799\n",
      "epoch 1; iter: 400; batch classifier loss: 4.198565; batch adversarial loss: 0.399800\n",
      "epoch 1; iter: 600; batch classifier loss: 0.710213; batch adversarial loss: 0.423439\n",
      "epoch 2; iter: 0; batch classifier loss: 58.867649; batch adversarial loss: 0.408364\n",
      "epoch 2; iter: 200; batch classifier loss: 0.310083; batch adversarial loss: 0.484335\n",
      "epoch 2; iter: 400; batch classifier loss: 1.678763; batch adversarial loss: 0.398433\n",
      "epoch 2; iter: 600; batch classifier loss: 0.897352; batch adversarial loss: 0.442232\n",
      "epoch 3; iter: 0; batch classifier loss: 2.723204; batch adversarial loss: 0.470248\n",
      "epoch 3; iter: 200; batch classifier loss: 0.628760; batch adversarial loss: 0.420038\n",
      "epoch 3; iter: 400; batch classifier loss: 1.120130; batch adversarial loss: 0.584778\n",
      "epoch 3; iter: 600; batch classifier loss: 0.660159; batch adversarial loss: 0.436897\n",
      "epoch 4; iter: 0; batch classifier loss: 2.694299; batch adversarial loss: 0.351888\n",
      "epoch 4; iter: 200; batch classifier loss: 0.412021; batch adversarial loss: 0.462601\n",
      "epoch 4; iter: 400; batch classifier loss: 0.418268; batch adversarial loss: 0.425323\n",
      "epoch 4; iter: 600; batch classifier loss: 1.506133; batch adversarial loss: 0.416691\n",
      "epoch 5; iter: 0; batch classifier loss: 0.462159; batch adversarial loss: 0.365586\n",
      "epoch 5; iter: 200; batch classifier loss: 0.544424; batch adversarial loss: 0.517050\n",
      "epoch 5; iter: 400; batch classifier loss: 0.436613; batch adversarial loss: 0.257783\n",
      "epoch 5; iter: 600; batch classifier loss: 0.466851; batch adversarial loss: 0.314573\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326364; batch adversarial loss: 0.511389\n",
      "epoch 6; iter: 200; batch classifier loss: 0.537108; batch adversarial loss: 0.474986\n",
      "epoch 6; iter: 400; batch classifier loss: 0.489929; batch adversarial loss: 0.415329\n",
      "epoch 6; iter: 600; batch classifier loss: 0.269725; batch adversarial loss: 0.486370\n",
      "epoch 7; iter: 0; batch classifier loss: 0.367518; batch adversarial loss: 0.460500\n",
      "epoch 7; iter: 200; batch classifier loss: 0.270164; batch adversarial loss: 0.447782\n",
      "epoch 7; iter: 400; batch classifier loss: 0.398268; batch adversarial loss: 0.405089\n",
      "epoch 7; iter: 600; batch classifier loss: 0.368348; batch adversarial loss: 0.483788\n",
      "epoch 8; iter: 0; batch classifier loss: 0.288905; batch adversarial loss: 0.335304\n",
      "epoch 8; iter: 200; batch classifier loss: 0.328125; batch adversarial loss: 0.546526\n",
      "epoch 8; iter: 400; batch classifier loss: 0.291129; batch adversarial loss: 0.539991\n",
      "epoch 8; iter: 600; batch classifier loss: 0.386487; batch adversarial loss: 0.622150\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434691; batch adversarial loss: 0.317108\n",
      "epoch 9; iter: 200; batch classifier loss: 0.408787; batch adversarial loss: 0.345088\n",
      "epoch 9; iter: 400; batch classifier loss: 0.341684; batch adversarial loss: 0.453577\n",
      "epoch 9; iter: 600; batch classifier loss: 0.406348; batch adversarial loss: 0.472203\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398051; batch adversarial loss: 0.332387\n",
      "epoch 10; iter: 200; batch classifier loss: 0.462579; batch adversarial loss: 0.462810\n",
      "epoch 10; iter: 400; batch classifier loss: 0.407773; batch adversarial loss: 0.311700\n",
      "epoch 10; iter: 600; batch classifier loss: 0.414173; batch adversarial loss: 0.356676\n",
      "epoch 11; iter: 0; batch classifier loss: 0.386208; batch adversarial loss: 0.478647\n",
      "epoch 11; iter: 200; batch classifier loss: 0.368681; batch adversarial loss: 0.511518\n",
      "epoch 11; iter: 400; batch classifier loss: 0.357008; batch adversarial loss: 0.395667\n",
      "epoch 11; iter: 600; batch classifier loss: 0.250456; batch adversarial loss: 0.453533\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345934; batch adversarial loss: 0.551935\n",
      "epoch 12; iter: 200; batch classifier loss: 0.485671; batch adversarial loss: 0.374989\n",
      "epoch 12; iter: 400; batch classifier loss: 0.506382; batch adversarial loss: 0.358839\n",
      "epoch 12; iter: 600; batch classifier loss: 0.296901; batch adversarial loss: 0.600085\n",
      "epoch 13; iter: 0; batch classifier loss: 0.355746; batch adversarial loss: 0.290646\n",
      "epoch 13; iter: 200; batch classifier loss: 0.343638; batch adversarial loss: 0.459859\n",
      "epoch 13; iter: 400; batch classifier loss: 0.337415; batch adversarial loss: 0.367911\n",
      "epoch 13; iter: 600; batch classifier loss: 0.500779; batch adversarial loss: 0.363961\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368859; batch adversarial loss: 0.398855\n",
      "epoch 14; iter: 200; batch classifier loss: 0.365444; batch adversarial loss: 0.442811\n",
      "epoch 14; iter: 400; batch classifier loss: 0.333577; batch adversarial loss: 0.480870\n",
      "epoch 14; iter: 600; batch classifier loss: 0.215087; batch adversarial loss: 0.458786\n",
      "epoch 15; iter: 0; batch classifier loss: 0.303776; batch adversarial loss: 0.388352\n",
      "epoch 15; iter: 200; batch classifier loss: 0.220066; batch adversarial loss: 0.456303\n",
      "epoch 15; iter: 400; batch classifier loss: 0.332421; batch adversarial loss: 0.273323\n",
      "epoch 15; iter: 600; batch classifier loss: 0.231294; batch adversarial loss: 0.532413\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297543; batch adversarial loss: 0.472863\n",
      "epoch 16; iter: 200; batch classifier loss: 0.379964; batch adversarial loss: 0.510858\n",
      "epoch 16; iter: 400; batch classifier loss: 0.352419; batch adversarial loss: 0.328155\n",
      "epoch 16; iter: 600; batch classifier loss: 0.360789; batch adversarial loss: 0.317546\n",
      "epoch 17; iter: 0; batch classifier loss: 0.381080; batch adversarial loss: 0.337141\n",
      "epoch 17; iter: 200; batch classifier loss: 0.275818; batch adversarial loss: 0.431771\n",
      "epoch 17; iter: 400; batch classifier loss: 0.310265; batch adversarial loss: 0.477043\n",
      "epoch 17; iter: 600; batch classifier loss: 0.305309; batch adversarial loss: 0.521440\n",
      "epoch 18; iter: 0; batch classifier loss: 0.219683; batch adversarial loss: 0.503602\n",
      "epoch 18; iter: 200; batch classifier loss: 0.346268; batch adversarial loss: 0.443396\n",
      "epoch 18; iter: 400; batch classifier loss: 0.417895; batch adversarial loss: 0.445211\n",
      "epoch 18; iter: 600; batch classifier loss: 0.350011; batch adversarial loss: 0.320523\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325029; batch adversarial loss: 0.430126\n",
      "epoch 19; iter: 200; batch classifier loss: 0.292439; batch adversarial loss: 0.352224\n",
      "epoch 19; iter: 400; batch classifier loss: 0.341122; batch adversarial loss: 0.375494\n",
      "epoch 19; iter: 600; batch classifier loss: 0.268196; batch adversarial loss: 0.476819\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426772; batch adversarial loss: 0.412956\n",
      "epoch 20; iter: 200; batch classifier loss: 0.383093; batch adversarial loss: 0.238923\n",
      "epoch 20; iter: 400; batch classifier loss: 0.267304; batch adversarial loss: 0.349474\n",
      "epoch 20; iter: 600; batch classifier loss: 0.248436; batch adversarial loss: 0.471529\n",
      "epoch 21; iter: 0; batch classifier loss: 0.299265; batch adversarial loss: 0.497517\n",
      "epoch 21; iter: 200; batch classifier loss: 0.278421; batch adversarial loss: 0.371642\n",
      "epoch 21; iter: 400; batch classifier loss: 0.300583; batch adversarial loss: 0.352691\n",
      "epoch 21; iter: 600; batch classifier loss: 0.384645; batch adversarial loss: 0.324962\n",
      "epoch 22; iter: 0; batch classifier loss: 0.369097; batch adversarial loss: 0.408530\n",
      "epoch 22; iter: 200; batch classifier loss: 0.329679; batch adversarial loss: 0.418598\n",
      "epoch 22; iter: 400; batch classifier loss: 0.425060; batch adversarial loss: 0.480437\n",
      "epoch 22; iter: 600; batch classifier loss: 0.413522; batch adversarial loss: 0.499557\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322430; batch adversarial loss: 0.289095\n",
      "epoch 23; iter: 200; batch classifier loss: 0.357176; batch adversarial loss: 0.343877\n",
      "epoch 23; iter: 400; batch classifier loss: 0.300862; batch adversarial loss: 0.442496\n",
      "epoch 23; iter: 600; batch classifier loss: 0.221143; batch adversarial loss: 0.438581\n",
      "epoch 24; iter: 0; batch classifier loss: 0.460567; batch adversarial loss: 0.401633\n",
      "epoch 24; iter: 200; batch classifier loss: 0.361956; batch adversarial loss: 0.316232\n",
      "epoch 24; iter: 400; batch classifier loss: 0.375406; batch adversarial loss: 0.232887\n",
      "epoch 24; iter: 600; batch classifier loss: 0.415937; batch adversarial loss: 0.393331\n",
      "epoch 25; iter: 0; batch classifier loss: 0.340285; batch adversarial loss: 0.316892\n",
      "epoch 25; iter: 200; batch classifier loss: 0.235550; batch adversarial loss: 0.321162\n",
      "epoch 25; iter: 400; batch classifier loss: 0.271618; batch adversarial loss: 0.441782\n",
      "epoch 25; iter: 600; batch classifier loss: 0.389104; batch adversarial loss: 0.378034\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319073; batch adversarial loss: 0.357257\n",
      "epoch 26; iter: 200; batch classifier loss: 0.274953; batch adversarial loss: 0.466952\n",
      "epoch 26; iter: 400; batch classifier loss: 0.376351; batch adversarial loss: 0.265799\n",
      "epoch 26; iter: 600; batch classifier loss: 0.443400; batch adversarial loss: 0.375860\n",
      "epoch 27; iter: 0; batch classifier loss: 0.824417; batch adversarial loss: 0.500136\n",
      "epoch 27; iter: 200; batch classifier loss: 0.242360; batch adversarial loss: 0.346659\n",
      "epoch 27; iter: 400; batch classifier loss: 0.272295; batch adversarial loss: 0.607704\n",
      "epoch 27; iter: 600; batch classifier loss: 0.349133; batch adversarial loss: 0.569922\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459434; batch adversarial loss: 0.477989\n",
      "epoch 28; iter: 200; batch classifier loss: 0.259546; batch adversarial loss: 0.366290\n",
      "epoch 28; iter: 400; batch classifier loss: 0.353435; batch adversarial loss: 0.352385\n",
      "epoch 28; iter: 600; batch classifier loss: 0.300734; batch adversarial loss: 0.493453\n",
      "epoch 29; iter: 0; batch classifier loss: 0.331016; batch adversarial loss: 0.296979\n",
      "epoch 29; iter: 200; batch classifier loss: 0.480541; batch adversarial loss: 0.413102\n",
      "epoch 29; iter: 400; batch classifier loss: 0.341395; batch adversarial loss: 0.421835\n",
      "epoch 29; iter: 600; batch classifier loss: 0.338541; batch adversarial loss: 0.375267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.328756; batch adversarial loss: 0.441122\n",
      "epoch 30; iter: 200; batch classifier loss: 0.211258; batch adversarial loss: 0.370302\n",
      "epoch 30; iter: 400; batch classifier loss: 0.246502; batch adversarial loss: 0.546271\n",
      "epoch 30; iter: 600; batch classifier loss: 0.337318; batch adversarial loss: 0.371926\n",
      "epoch 31; iter: 0; batch classifier loss: 0.273247; batch adversarial loss: 0.376245\n",
      "epoch 31; iter: 200; batch classifier loss: 0.294525; batch adversarial loss: 0.374180\n",
      "epoch 31; iter: 400; batch classifier loss: 0.338051; batch adversarial loss: 0.382584\n",
      "epoch 31; iter: 600; batch classifier loss: 0.422822; batch adversarial loss: 0.617021\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230932; batch adversarial loss: 0.397440\n",
      "epoch 32; iter: 200; batch classifier loss: 0.405957; batch adversarial loss: 0.429727\n",
      "epoch 32; iter: 400; batch classifier loss: 0.313263; batch adversarial loss: 0.382615\n",
      "epoch 32; iter: 600; batch classifier loss: 0.339838; batch adversarial loss: 0.401869\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346415; batch adversarial loss: 0.372439\n",
      "epoch 33; iter: 200; batch classifier loss: 0.458016; batch adversarial loss: 0.302532\n",
      "epoch 33; iter: 400; batch classifier loss: 0.388374; batch adversarial loss: 0.372905\n",
      "epoch 33; iter: 600; batch classifier loss: 0.348803; batch adversarial loss: 0.482483\n",
      "epoch 34; iter: 0; batch classifier loss: 0.332511; batch adversarial loss: 0.269108\n",
      "epoch 34; iter: 200; batch classifier loss: 0.269360; batch adversarial loss: 0.426181\n",
      "epoch 34; iter: 400; batch classifier loss: 0.497813; batch adversarial loss: 0.501514\n",
      "epoch 34; iter: 600; batch classifier loss: 0.288343; batch adversarial loss: 0.344734\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406576; batch adversarial loss: 0.365150\n",
      "epoch 35; iter: 200; batch classifier loss: 0.645689; batch adversarial loss: 0.574354\n",
      "epoch 35; iter: 400; batch classifier loss: 0.275039; batch adversarial loss: 0.532829\n",
      "epoch 35; iter: 600; batch classifier loss: 0.399638; batch adversarial loss: 0.543168\n",
      "epoch 36; iter: 0; batch classifier loss: 0.329513; batch adversarial loss: 0.323370\n",
      "epoch 36; iter: 200; batch classifier loss: 0.597874; batch adversarial loss: 0.430631\n",
      "epoch 36; iter: 400; batch classifier loss: 0.390477; batch adversarial loss: 0.501464\n",
      "epoch 36; iter: 600; batch classifier loss: 0.431323; batch adversarial loss: 0.404332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.216450; batch adversarial loss: 0.396155\n",
      "epoch 37; iter: 200; batch classifier loss: 0.319818; batch adversarial loss: 0.353616\n",
      "epoch 37; iter: 400; batch classifier loss: 0.354597; batch adversarial loss: 0.461322\n",
      "epoch 37; iter: 600; batch classifier loss: 0.356986; batch adversarial loss: 0.325918\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480605; batch adversarial loss: 0.424433\n",
      "epoch 38; iter: 200; batch classifier loss: 0.401570; batch adversarial loss: 0.325284\n",
      "epoch 38; iter: 400; batch classifier loss: 0.304039; batch adversarial loss: 0.354560\n",
      "epoch 38; iter: 600; batch classifier loss: 0.319898; batch adversarial loss: 0.292724\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322708; batch adversarial loss: 0.404304\n",
      "epoch 39; iter: 200; batch classifier loss: 0.300741; batch adversarial loss: 0.347153\n",
      "epoch 39; iter: 400; batch classifier loss: 0.378462; batch adversarial loss: 0.415408\n",
      "epoch 39; iter: 600; batch classifier loss: 0.316562; batch adversarial loss: 0.453141\n",
      "epoch 40; iter: 0; batch classifier loss: 0.362721; batch adversarial loss: 0.409559\n",
      "epoch 40; iter: 200; batch classifier loss: 0.273852; batch adversarial loss: 0.371617\n",
      "epoch 40; iter: 400; batch classifier loss: 0.329288; batch adversarial loss: 0.372239\n",
      "epoch 40; iter: 600; batch classifier loss: 0.342778; batch adversarial loss: 0.495205\n",
      "epoch 41; iter: 0; batch classifier loss: 0.273716; batch adversarial loss: 0.395037\n",
      "epoch 41; iter: 200; batch classifier loss: 0.385293; batch adversarial loss: 0.345035\n",
      "epoch 41; iter: 400; batch classifier loss: 0.352875; batch adversarial loss: 0.337497\n",
      "epoch 41; iter: 600; batch classifier loss: 0.279037; batch adversarial loss: 0.412617\n",
      "epoch 42; iter: 0; batch classifier loss: 0.291771; batch adversarial loss: 0.455105\n",
      "epoch 42; iter: 200; batch classifier loss: 0.341803; batch adversarial loss: 0.443976\n",
      "epoch 42; iter: 400; batch classifier loss: 0.246649; batch adversarial loss: 0.382396\n",
      "epoch 42; iter: 600; batch classifier loss: 0.413284; batch adversarial loss: 0.436796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.523931; batch adversarial loss: 0.324702\n",
      "epoch 43; iter: 200; batch classifier loss: 0.324187; batch adversarial loss: 0.496249\n",
      "epoch 43; iter: 400; batch classifier loss: 0.445209; batch adversarial loss: 0.434773\n",
      "epoch 43; iter: 600; batch classifier loss: 0.430152; batch adversarial loss: 0.536529\n",
      "epoch 44; iter: 0; batch classifier loss: 0.359130; batch adversarial loss: 0.344165\n",
      "epoch 44; iter: 200; batch classifier loss: 0.301059; batch adversarial loss: 0.350437\n",
      "epoch 44; iter: 400; batch classifier loss: 0.331352; batch adversarial loss: 0.426654\n",
      "epoch 44; iter: 600; batch classifier loss: 0.470685; batch adversarial loss: 0.381616\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393097; batch adversarial loss: 0.380271\n",
      "epoch 45; iter: 200; batch classifier loss: 0.384366; batch adversarial loss: 0.602224\n",
      "epoch 45; iter: 400; batch classifier loss: 0.481644; batch adversarial loss: 0.493252\n",
      "epoch 45; iter: 600; batch classifier loss: 0.332717; batch adversarial loss: 0.443325\n",
      "epoch 46; iter: 0; batch classifier loss: 0.384858; batch adversarial loss: 0.425549\n",
      "epoch 46; iter: 200; batch classifier loss: 0.371657; batch adversarial loss: 0.385168\n",
      "epoch 46; iter: 400; batch classifier loss: 0.324231; batch adversarial loss: 0.492526\n",
      "epoch 46; iter: 600; batch classifier loss: 0.394546; batch adversarial loss: 0.405312\n",
      "epoch 47; iter: 0; batch classifier loss: 0.306540; batch adversarial loss: 0.497639\n",
      "epoch 47; iter: 200; batch classifier loss: 0.541624; batch adversarial loss: 0.403875\n",
      "epoch 47; iter: 400; batch classifier loss: 0.416015; batch adversarial loss: 0.457128\n",
      "epoch 47; iter: 600; batch classifier loss: 0.375999; batch adversarial loss: 0.348121\n",
      "epoch 48; iter: 0; batch classifier loss: 0.314329; batch adversarial loss: 0.373126\n",
      "epoch 48; iter: 200; batch classifier loss: 0.356598; batch adversarial loss: 0.356370\n",
      "epoch 48; iter: 400; batch classifier loss: 0.337388; batch adversarial loss: 0.464607\n",
      "epoch 48; iter: 600; batch classifier loss: 0.294839; batch adversarial loss: 0.475776\n",
      "epoch 49; iter: 0; batch classifier loss: 0.343185; batch adversarial loss: 0.628548\n",
      "epoch 49; iter: 200; batch classifier loss: 0.317026; batch adversarial loss: 0.346458\n",
      "epoch 49; iter: 400; batch classifier loss: 0.352237; batch adversarial loss: 0.491731\n",
      "epoch 49; iter: 600; batch classifier loss: 1.025240; batch adversarial loss: 0.398348\n",
      "epoch 0; iter: 0; batch classifier loss: 71.804474; batch adversarial loss: 0.648032\n",
      "epoch 0; iter: 200; batch classifier loss: 36.538612; batch adversarial loss: 0.536463\n",
      "epoch 0; iter: 400; batch classifier loss: 3.744716; batch adversarial loss: 0.519201\n",
      "epoch 0; iter: 600; batch classifier loss: 9.474258; batch adversarial loss: 0.464235\n",
      "epoch 1; iter: 0; batch classifier loss: 8.295503; batch adversarial loss: 0.458356\n",
      "epoch 1; iter: 200; batch classifier loss: 2.595026; batch adversarial loss: 0.458135\n",
      "epoch 1; iter: 400; batch classifier loss: 11.903950; batch adversarial loss: 0.472637\n",
      "epoch 1; iter: 600; batch classifier loss: 1.302520; batch adversarial loss: 0.430851\n",
      "epoch 2; iter: 0; batch classifier loss: 4.187476; batch adversarial loss: 0.464924\n",
      "epoch 2; iter: 200; batch classifier loss: 0.696853; batch adversarial loss: 0.493230\n",
      "epoch 2; iter: 400; batch classifier loss: 1.738570; batch adversarial loss: 0.400577\n",
      "epoch 2; iter: 600; batch classifier loss: 1.590201; batch adversarial loss: 0.486052\n",
      "epoch 3; iter: 0; batch classifier loss: 4.527933; batch adversarial loss: 0.338254\n",
      "epoch 3; iter: 200; batch classifier loss: 0.573279; batch adversarial loss: 0.344507\n",
      "epoch 3; iter: 400; batch classifier loss: 0.475192; batch adversarial loss: 0.413146\n",
      "epoch 3; iter: 600; batch classifier loss: 0.421763; batch adversarial loss: 0.395515\n",
      "epoch 4; iter: 0; batch classifier loss: 0.356576; batch adversarial loss: 0.438447\n",
      "epoch 4; iter: 200; batch classifier loss: 2.648962; batch adversarial loss: 0.464084\n",
      "epoch 4; iter: 400; batch classifier loss: 0.368491; batch adversarial loss: 0.339475\n",
      "epoch 4; iter: 600; batch classifier loss: 0.383735; batch adversarial loss: 0.457255\n",
      "epoch 5; iter: 0; batch classifier loss: 0.986156; batch adversarial loss: 0.537913\n",
      "epoch 5; iter: 200; batch classifier loss: 0.350028; batch adversarial loss: 0.512548\n",
      "epoch 5; iter: 400; batch classifier loss: 0.398831; batch adversarial loss: 0.490675\n",
      "epoch 5; iter: 600; batch classifier loss: 0.425635; batch adversarial loss: 0.266192\n",
      "epoch 6; iter: 0; batch classifier loss: 0.374036; batch adversarial loss: 0.477478\n",
      "epoch 6; iter: 200; batch classifier loss: 0.673985; batch adversarial loss: 0.471748\n",
      "epoch 6; iter: 400; batch classifier loss: 0.283333; batch adversarial loss: 0.396679\n",
      "epoch 6; iter: 600; batch classifier loss: 0.448352; batch adversarial loss: 0.402118\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462774; batch adversarial loss: 0.291123\n",
      "epoch 7; iter: 200; batch classifier loss: 0.390904; batch adversarial loss: 0.593292\n",
      "epoch 7; iter: 400; batch classifier loss: 0.410360; batch adversarial loss: 0.484563\n",
      "epoch 7; iter: 600; batch classifier loss: 0.350235; batch adversarial loss: 0.491180\n",
      "epoch 8; iter: 0; batch classifier loss: 0.392623; batch adversarial loss: 0.348849\n",
      "epoch 8; iter: 200; batch classifier loss: 0.425324; batch adversarial loss: 0.431558\n",
      "epoch 8; iter: 400; batch classifier loss: 0.385122; batch adversarial loss: 0.388501\n",
      "epoch 8; iter: 600; batch classifier loss: 0.329917; batch adversarial loss: 0.396588\n",
      "epoch 9; iter: 0; batch classifier loss: 0.309900; batch adversarial loss: 0.430811\n",
      "epoch 9; iter: 200; batch classifier loss: 0.268103; batch adversarial loss: 0.401630\n",
      "epoch 9; iter: 400; batch classifier loss: 0.330365; batch adversarial loss: 0.478442\n",
      "epoch 9; iter: 600; batch classifier loss: 0.313275; batch adversarial loss: 0.459909\n",
      "epoch 10; iter: 0; batch classifier loss: 0.329938; batch adversarial loss: 0.443986\n",
      "epoch 10; iter: 200; batch classifier loss: 0.381770; batch adversarial loss: 0.488777\n",
      "epoch 10; iter: 400; batch classifier loss: 0.489395; batch adversarial loss: 0.535020\n",
      "epoch 10; iter: 600; batch classifier loss: 0.491642; batch adversarial loss: 0.351660\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412093; batch adversarial loss: 0.350350\n",
      "epoch 11; iter: 200; batch classifier loss: 0.507060; batch adversarial loss: 0.296944\n",
      "epoch 11; iter: 400; batch classifier loss: 0.416500; batch adversarial loss: 0.398234\n",
      "epoch 11; iter: 600; batch classifier loss: 0.281798; batch adversarial loss: 0.482862\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418013; batch adversarial loss: 0.294866\n",
      "epoch 12; iter: 200; batch classifier loss: 0.505390; batch adversarial loss: 0.327320\n",
      "epoch 12; iter: 400; batch classifier loss: 0.332898; batch adversarial loss: 0.307311\n",
      "epoch 12; iter: 600; batch classifier loss: 0.422745; batch adversarial loss: 0.500059\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361415; batch adversarial loss: 0.563684\n",
      "epoch 13; iter: 200; batch classifier loss: 0.298876; batch adversarial loss: 0.406315\n",
      "epoch 13; iter: 400; batch classifier loss: 0.232079; batch adversarial loss: 0.412598\n",
      "epoch 13; iter: 600; batch classifier loss: 0.305562; batch adversarial loss: 0.482610\n",
      "epoch 14; iter: 0; batch classifier loss: 0.357319; batch adversarial loss: 0.401630\n",
      "epoch 14; iter: 200; batch classifier loss: 0.321718; batch adversarial loss: 0.378128\n",
      "epoch 14; iter: 400; batch classifier loss: 0.256775; batch adversarial loss: 0.375938\n",
      "epoch 14; iter: 600; batch classifier loss: 0.465762; batch adversarial loss: 0.436057\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314140; batch adversarial loss: 0.347053\n",
      "epoch 15; iter: 200; batch classifier loss: 0.324557; batch adversarial loss: 0.488099\n",
      "epoch 15; iter: 400; batch classifier loss: 0.337704; batch adversarial loss: 0.306319\n",
      "epoch 15; iter: 600; batch classifier loss: 0.196607; batch adversarial loss: 0.474113\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448846; batch adversarial loss: 0.430582\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383508; batch adversarial loss: 0.457212\n",
      "epoch 16; iter: 400; batch classifier loss: 0.318361; batch adversarial loss: 0.478070\n",
      "epoch 16; iter: 600; batch classifier loss: 0.206896; batch adversarial loss: 0.507287\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357422; batch adversarial loss: 0.375350\n",
      "epoch 17; iter: 200; batch classifier loss: 0.268267; batch adversarial loss: 0.342181\n",
      "epoch 17; iter: 400; batch classifier loss: 0.327406; batch adversarial loss: 0.317643\n",
      "epoch 17; iter: 600; batch classifier loss: 0.366634; batch adversarial loss: 0.461748\n",
      "epoch 18; iter: 0; batch classifier loss: 0.272985; batch adversarial loss: 0.345700\n",
      "epoch 18; iter: 200; batch classifier loss: 0.345530; batch adversarial loss: 0.430275\n",
      "epoch 18; iter: 400; batch classifier loss: 0.401933; batch adversarial loss: 0.348241\n",
      "epoch 18; iter: 600; batch classifier loss: 0.331383; batch adversarial loss: 0.383406\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474708; batch adversarial loss: 0.393497\n",
      "epoch 19; iter: 200; batch classifier loss: 0.252058; batch adversarial loss: 0.474838\n",
      "epoch 19; iter: 400; batch classifier loss: 0.339981; batch adversarial loss: 0.450392\n",
      "epoch 19; iter: 600; batch classifier loss: 0.312975; batch adversarial loss: 0.539630\n",
      "epoch 20; iter: 0; batch classifier loss: 0.312775; batch adversarial loss: 0.314846\n",
      "epoch 20; iter: 200; batch classifier loss: 0.271495; batch adversarial loss: 0.410082\n",
      "epoch 20; iter: 400; batch classifier loss: 0.661934; batch adversarial loss: 0.417247\n",
      "epoch 20; iter: 600; batch classifier loss: 0.319792; batch adversarial loss: 0.361892\n",
      "epoch 21; iter: 0; batch classifier loss: 0.334396; batch adversarial loss: 0.300138\n",
      "epoch 21; iter: 200; batch classifier loss: 0.306013; batch adversarial loss: 0.424898\n",
      "epoch 21; iter: 400; batch classifier loss: 0.316175; batch adversarial loss: 0.441665\n",
      "epoch 21; iter: 600; batch classifier loss: 0.298599; batch adversarial loss: 0.474970\n",
      "epoch 22; iter: 0; batch classifier loss: 0.250438; batch adversarial loss: 0.428211\n",
      "epoch 22; iter: 200; batch classifier loss: 0.328489; batch adversarial loss: 0.334153\n",
      "epoch 22; iter: 400; batch classifier loss: 0.287009; batch adversarial loss: 0.426011\n",
      "epoch 22; iter: 600; batch classifier loss: 0.330361; batch adversarial loss: 0.446856\n",
      "epoch 23; iter: 0; batch classifier loss: 0.348985; batch adversarial loss: 0.396596\n",
      "epoch 23; iter: 200; batch classifier loss: 0.354075; batch adversarial loss: 0.410721\n",
      "epoch 23; iter: 400; batch classifier loss: 0.420123; batch adversarial loss: 0.406336\n",
      "epoch 23; iter: 600; batch classifier loss: 0.410076; batch adversarial loss: 0.362366\n",
      "epoch 24; iter: 0; batch classifier loss: 0.267711; batch adversarial loss: 0.427161\n",
      "epoch 24; iter: 200; batch classifier loss: 0.270166; batch adversarial loss: 0.490462\n",
      "epoch 24; iter: 400; batch classifier loss: 0.395165; batch adversarial loss: 0.333032\n",
      "epoch 24; iter: 600; batch classifier loss: 0.222365; batch adversarial loss: 0.486603\n",
      "epoch 25; iter: 0; batch classifier loss: 0.575478; batch adversarial loss: 0.302909\n",
      "epoch 25; iter: 200; batch classifier loss: 0.226256; batch adversarial loss: 0.456578\n",
      "epoch 25; iter: 400; batch classifier loss: 0.353413; batch adversarial loss: 0.348446\n",
      "epoch 25; iter: 600; batch classifier loss: 0.307543; batch adversarial loss: 0.478233\n",
      "epoch 26; iter: 0; batch classifier loss: 0.331203; batch adversarial loss: 0.453031\n",
      "epoch 26; iter: 200; batch classifier loss: 0.371947; batch adversarial loss: 0.377295\n",
      "epoch 26; iter: 400; batch classifier loss: 0.364787; batch adversarial loss: 0.348783\n",
      "epoch 26; iter: 600; batch classifier loss: 0.369966; batch adversarial loss: 0.293186\n",
      "epoch 27; iter: 0; batch classifier loss: 0.264662; batch adversarial loss: 0.522853\n",
      "epoch 27; iter: 200; batch classifier loss: 0.352747; batch adversarial loss: 0.433653\n",
      "epoch 27; iter: 400; batch classifier loss: 0.358006; batch adversarial loss: 0.385789\n",
      "epoch 27; iter: 600; batch classifier loss: 0.351566; batch adversarial loss: 0.408639\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375446; batch adversarial loss: 0.345481\n",
      "epoch 28; iter: 200; batch classifier loss: 0.412582; batch adversarial loss: 0.343500\n",
      "epoch 28; iter: 400; batch classifier loss: 0.314836; batch adversarial loss: 0.348629\n",
      "epoch 28; iter: 600; batch classifier loss: 0.307928; batch adversarial loss: 0.351675\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386081; batch adversarial loss: 0.341615\n",
      "epoch 29; iter: 200; batch classifier loss: 0.339011; batch adversarial loss: 0.452642\n",
      "epoch 29; iter: 400; batch classifier loss: 0.350259; batch adversarial loss: 0.356770\n",
      "epoch 29; iter: 600; batch classifier loss: 0.349518; batch adversarial loss: 0.351769\n",
      "epoch 30; iter: 0; batch classifier loss: 0.388768; batch adversarial loss: 0.404089\n",
      "epoch 30; iter: 200; batch classifier loss: 0.437150; batch adversarial loss: 0.291287\n",
      "epoch 30; iter: 400; batch classifier loss: 0.397664; batch adversarial loss: 0.590504\n",
      "epoch 30; iter: 600; batch classifier loss: 0.355906; batch adversarial loss: 0.355980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.362222; batch adversarial loss: 0.345883\n",
      "epoch 31; iter: 200; batch classifier loss: 0.361395; batch adversarial loss: 0.526849\n",
      "epoch 31; iter: 400; batch classifier loss: 0.303498; batch adversarial loss: 0.366161\n",
      "epoch 31; iter: 600; batch classifier loss: 0.422921; batch adversarial loss: 0.379156\n",
      "epoch 32; iter: 0; batch classifier loss: 0.402739; batch adversarial loss: 0.486999\n",
      "epoch 32; iter: 200; batch classifier loss: 0.388330; batch adversarial loss: 0.399050\n",
      "epoch 32; iter: 400; batch classifier loss: 0.266611; batch adversarial loss: 0.544860\n",
      "epoch 32; iter: 600; batch classifier loss: 0.482145; batch adversarial loss: 0.354622\n",
      "epoch 33; iter: 0; batch classifier loss: 0.453446; batch adversarial loss: 0.490837\n",
      "epoch 33; iter: 200; batch classifier loss: 0.317736; batch adversarial loss: 0.399027\n",
      "epoch 33; iter: 400; batch classifier loss: 0.347633; batch adversarial loss: 0.412618\n",
      "epoch 33; iter: 600; batch classifier loss: 0.274825; batch adversarial loss: 0.293679\n",
      "epoch 34; iter: 0; batch classifier loss: 0.497966; batch adversarial loss: 0.292609\n",
      "epoch 34; iter: 200; batch classifier loss: 0.405675; batch adversarial loss: 0.455640\n",
      "epoch 34; iter: 400; batch classifier loss: 0.359758; batch adversarial loss: 0.384212\n",
      "epoch 34; iter: 600; batch classifier loss: 0.647843; batch adversarial loss: 0.424145\n",
      "epoch 35; iter: 0; batch classifier loss: 0.386408; batch adversarial loss: 0.488398\n",
      "epoch 35; iter: 200; batch classifier loss: 0.371888; batch adversarial loss: 0.518946\n",
      "epoch 35; iter: 400; batch classifier loss: 0.353344; batch adversarial loss: 0.414795\n",
      "epoch 35; iter: 600; batch classifier loss: 0.414329; batch adversarial loss: 0.285362\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401242; batch adversarial loss: 0.437468\n",
      "epoch 36; iter: 200; batch classifier loss: 0.303580; batch adversarial loss: 0.369066\n",
      "epoch 36; iter: 400; batch classifier loss: 0.457144; batch adversarial loss: 0.428320\n",
      "epoch 36; iter: 600; batch classifier loss: 0.414420; batch adversarial loss: 0.521249\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407148; batch adversarial loss: 0.327673\n",
      "epoch 37; iter: 200; batch classifier loss: 0.459476; batch adversarial loss: 0.427804\n",
      "epoch 37; iter: 400; batch classifier loss: 0.273899; batch adversarial loss: 0.443832\n",
      "epoch 37; iter: 600; batch classifier loss: 0.173455; batch adversarial loss: 0.374435\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457649; batch adversarial loss: 0.431920\n",
      "epoch 38; iter: 200; batch classifier loss: 0.333265; batch adversarial loss: 0.331214\n",
      "epoch 38; iter: 400; batch classifier loss: 0.379734; batch adversarial loss: 0.541036\n",
      "epoch 38; iter: 600; batch classifier loss: 0.252085; batch adversarial loss: 0.432340\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467773; batch adversarial loss: 0.539212\n",
      "epoch 39; iter: 200; batch classifier loss: 0.436069; batch adversarial loss: 0.433689\n",
      "epoch 39; iter: 400; batch classifier loss: 0.286344; batch adversarial loss: 0.457626\n",
      "epoch 39; iter: 600; batch classifier loss: 0.273195; batch adversarial loss: 0.409641\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407247; batch adversarial loss: 0.425802\n",
      "epoch 40; iter: 200; batch classifier loss: 0.354547; batch adversarial loss: 0.344987\n",
      "epoch 40; iter: 400; batch classifier loss: 0.463220; batch adversarial loss: 0.404322\n",
      "epoch 40; iter: 600; batch classifier loss: 0.212571; batch adversarial loss: 0.348753\n",
      "epoch 41; iter: 0; batch classifier loss: 0.536821; batch adversarial loss: 0.327497\n",
      "epoch 41; iter: 200; batch classifier loss: 0.338884; batch adversarial loss: 0.461004\n",
      "epoch 41; iter: 400; batch classifier loss: 0.271390; batch adversarial loss: 0.410101\n",
      "epoch 41; iter: 600; batch classifier loss: 0.683063; batch adversarial loss: 0.484454\n",
      "epoch 42; iter: 0; batch classifier loss: 0.447044; batch adversarial loss: 0.343607\n",
      "epoch 42; iter: 200; batch classifier loss: 0.360504; batch adversarial loss: 0.536313\n",
      "epoch 42; iter: 400; batch classifier loss: 0.560224; batch adversarial loss: 0.440983\n",
      "epoch 42; iter: 600; batch classifier loss: 0.372110; batch adversarial loss: 0.288173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.269930; batch adversarial loss: 0.482225\n",
      "epoch 43; iter: 200; batch classifier loss: 0.458473; batch adversarial loss: 0.413711\n",
      "epoch 43; iter: 400; batch classifier loss: 0.480102; batch adversarial loss: 0.504195\n",
      "epoch 43; iter: 600; batch classifier loss: 0.372219; batch adversarial loss: 0.296293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.617141; batch adversarial loss: 0.295501\n",
      "epoch 44; iter: 200; batch classifier loss: 0.229324; batch adversarial loss: 0.497440\n",
      "epoch 44; iter: 400; batch classifier loss: 0.547981; batch adversarial loss: 0.265085\n",
      "epoch 44; iter: 600; batch classifier loss: 0.272020; batch adversarial loss: 0.370732\n",
      "epoch 45; iter: 0; batch classifier loss: 0.298224; batch adversarial loss: 0.521397\n",
      "epoch 45; iter: 200; batch classifier loss: 0.243159; batch adversarial loss: 0.440758\n",
      "epoch 45; iter: 400; batch classifier loss: 0.351956; batch adversarial loss: 0.346520\n",
      "epoch 45; iter: 600; batch classifier loss: 0.342634; batch adversarial loss: 0.379803\n",
      "epoch 46; iter: 0; batch classifier loss: 0.539010; batch adversarial loss: 0.440231\n",
      "epoch 46; iter: 200; batch classifier loss: 0.400683; batch adversarial loss: 0.233562\n",
      "epoch 46; iter: 400; batch classifier loss: 0.274588; batch adversarial loss: 0.219262\n",
      "epoch 46; iter: 600; batch classifier loss: 0.338869; batch adversarial loss: 0.264679\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425130; batch adversarial loss: 0.343942\n",
      "epoch 47; iter: 200; batch classifier loss: 0.428863; batch adversarial loss: 0.285925\n",
      "epoch 47; iter: 400; batch classifier loss: 0.348576; batch adversarial loss: 0.544605\n",
      "epoch 47; iter: 600; batch classifier loss: 0.327574; batch adversarial loss: 0.459900\n",
      "epoch 48; iter: 0; batch classifier loss: 0.325805; batch adversarial loss: 0.491272\n",
      "epoch 48; iter: 200; batch classifier loss: 0.202295; batch adversarial loss: 0.319129\n",
      "epoch 48; iter: 400; batch classifier loss: 0.408642; batch adversarial loss: 0.237366\n",
      "epoch 48; iter: 600; batch classifier loss: 0.210083; batch adversarial loss: 0.327538\n",
      "epoch 49; iter: 0; batch classifier loss: 0.271451; batch adversarial loss: 0.516922\n",
      "epoch 49; iter: 200; batch classifier loss: 0.406977; batch adversarial loss: 0.626284\n",
      "epoch 49; iter: 400; batch classifier loss: 0.301809; batch adversarial loss: 0.351688\n",
      "epoch 49; iter: 600; batch classifier loss: 0.312453; batch adversarial loss: 0.430504\n",
      "epoch 0; iter: 0; batch classifier loss: 3.598715; batch adversarial loss: 0.684189\n",
      "epoch 0; iter: 200; batch classifier loss: 5.750854; batch adversarial loss: 0.619674\n",
      "epoch 0; iter: 400; batch classifier loss: 0.787070; batch adversarial loss: 0.587975\n",
      "epoch 0; iter: 600; batch classifier loss: 0.755643; batch adversarial loss: 0.553779\n",
      "epoch 1; iter: 0; batch classifier loss: 3.530707; batch adversarial loss: 0.502857\n",
      "epoch 1; iter: 200; batch classifier loss: 2.734494; batch adversarial loss: 0.479481\n",
      "epoch 1; iter: 400; batch classifier loss: 0.895595; batch adversarial loss: 0.554162\n",
      "epoch 1; iter: 600; batch classifier loss: 1.454630; batch adversarial loss: 0.418537\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625015; batch adversarial loss: 0.439929\n",
      "epoch 2; iter: 200; batch classifier loss: 0.365488; batch adversarial loss: 0.370539\n",
      "epoch 2; iter: 400; batch classifier loss: 1.380477; batch adversarial loss: 0.393277\n",
      "epoch 2; iter: 600; batch classifier loss: 1.088184; batch adversarial loss: 0.417851\n",
      "epoch 3; iter: 0; batch classifier loss: 2.226690; batch adversarial loss: 0.359649\n",
      "epoch 3; iter: 200; batch classifier loss: 1.591003; batch adversarial loss: 0.376158\n",
      "epoch 3; iter: 400; batch classifier loss: 0.491093; batch adversarial loss: 0.384281\n",
      "epoch 3; iter: 600; batch classifier loss: 1.171484; batch adversarial loss: 0.444467\n",
      "epoch 4; iter: 0; batch classifier loss: 4.315969; batch adversarial loss: 0.496151\n",
      "epoch 4; iter: 200; batch classifier loss: 0.672724; batch adversarial loss: 0.330283\n",
      "epoch 4; iter: 400; batch classifier loss: 0.450089; batch adversarial loss: 0.491832\n",
      "epoch 4; iter: 600; batch classifier loss: 0.658469; batch adversarial loss: 0.420147\n",
      "epoch 5; iter: 0; batch classifier loss: 0.457197; batch adversarial loss: 0.582896\n",
      "epoch 5; iter: 200; batch classifier loss: 0.783804; batch adversarial loss: 0.517697\n",
      "epoch 5; iter: 400; batch classifier loss: 0.505856; batch adversarial loss: 0.331412\n",
      "epoch 5; iter: 600; batch classifier loss: 0.632008; batch adversarial loss: 0.405917\n",
      "epoch 6; iter: 0; batch classifier loss: 0.461616; batch adversarial loss: 0.529911\n",
      "epoch 6; iter: 200; batch classifier loss: 0.288119; batch adversarial loss: 0.380113\n",
      "epoch 6; iter: 400; batch classifier loss: 0.365686; batch adversarial loss: 0.541268\n",
      "epoch 6; iter: 600; batch classifier loss: 0.411195; batch adversarial loss: 0.334044\n",
      "epoch 7; iter: 0; batch classifier loss: 0.406454; batch adversarial loss: 0.525148\n",
      "epoch 7; iter: 200; batch classifier loss: 0.357928; batch adversarial loss: 0.465469\n",
      "epoch 7; iter: 400; batch classifier loss: 0.423261; batch adversarial loss: 0.449275\n",
      "epoch 7; iter: 600; batch classifier loss: 0.370879; batch adversarial loss: 0.453771\n",
      "epoch 8; iter: 0; batch classifier loss: 0.373334; batch adversarial loss: 0.412046\n",
      "epoch 8; iter: 200; batch classifier loss: 0.372636; batch adversarial loss: 0.480614\n",
      "epoch 8; iter: 400; batch classifier loss: 0.482641; batch adversarial loss: 0.441201\n",
      "epoch 8; iter: 600; batch classifier loss: 0.228777; batch adversarial loss: 0.467145\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383098; batch adversarial loss: 0.488226\n",
      "epoch 9; iter: 200; batch classifier loss: 0.516698; batch adversarial loss: 0.330508\n",
      "epoch 9; iter: 400; batch classifier loss: 0.393569; batch adversarial loss: 0.298827\n",
      "epoch 9; iter: 600; batch classifier loss: 0.453442; batch adversarial loss: 0.508541\n",
      "epoch 10; iter: 0; batch classifier loss: 0.245697; batch adversarial loss: 0.438002\n",
      "epoch 10; iter: 200; batch classifier loss: 0.460121; batch adversarial loss: 0.378136\n",
      "epoch 10; iter: 400; batch classifier loss: 0.319144; batch adversarial loss: 0.340871\n",
      "epoch 10; iter: 600; batch classifier loss: 0.349767; batch adversarial loss: 0.339208\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319356; batch adversarial loss: 0.581267\n",
      "epoch 11; iter: 200; batch classifier loss: 0.280087; batch adversarial loss: 0.549476\n",
      "epoch 11; iter: 400; batch classifier loss: 0.268905; batch adversarial loss: 0.410709\n",
      "epoch 11; iter: 600; batch classifier loss: 0.312682; batch adversarial loss: 0.370919\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381653; batch adversarial loss: 0.454239\n",
      "epoch 12; iter: 200; batch classifier loss: 0.288079; batch adversarial loss: 0.505248\n",
      "epoch 12; iter: 400; batch classifier loss: 0.382672; batch adversarial loss: 0.499001\n",
      "epoch 12; iter: 600; batch classifier loss: 0.391663; batch adversarial loss: 0.396067\n",
      "epoch 13; iter: 0; batch classifier loss: 0.406571; batch adversarial loss: 0.362354\n",
      "epoch 13; iter: 200; batch classifier loss: 0.449363; batch adversarial loss: 0.375773\n",
      "epoch 13; iter: 400; batch classifier loss: 0.356463; batch adversarial loss: 0.473215\n",
      "epoch 13; iter: 600; batch classifier loss: 0.283697; batch adversarial loss: 0.409778\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284759; batch adversarial loss: 0.375188\n",
      "epoch 14; iter: 200; batch classifier loss: 0.374352; batch adversarial loss: 0.506660\n",
      "epoch 14; iter: 400; batch classifier loss: 0.252186; batch adversarial loss: 0.313262\n",
      "epoch 14; iter: 600; batch classifier loss: 0.357952; batch adversarial loss: 0.463120\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415280; batch adversarial loss: 0.598483\n",
      "epoch 15; iter: 200; batch classifier loss: 0.362786; batch adversarial loss: 0.449170\n",
      "epoch 15; iter: 400; batch classifier loss: 0.358600; batch adversarial loss: 0.462897\n",
      "epoch 15; iter: 600; batch classifier loss: 0.385163; batch adversarial loss: 0.477667\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362866; batch adversarial loss: 0.478625\n",
      "epoch 16; iter: 200; batch classifier loss: 0.311926; batch adversarial loss: 0.376812\n",
      "epoch 16; iter: 400; batch classifier loss: 0.497128; batch adversarial loss: 0.419019\n",
      "epoch 16; iter: 600; batch classifier loss: 0.426712; batch adversarial loss: 0.377065\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278997; batch adversarial loss: 0.469021\n",
      "epoch 17; iter: 200; batch classifier loss: 0.394683; batch adversarial loss: 0.344430\n",
      "epoch 17; iter: 400; batch classifier loss: 0.357927; batch adversarial loss: 0.372314\n",
      "epoch 17; iter: 600; batch classifier loss: 0.252544; batch adversarial loss: 0.320530\n",
      "epoch 18; iter: 0; batch classifier loss: 0.321294; batch adversarial loss: 0.502319\n",
      "epoch 18; iter: 200; batch classifier loss: 0.343418; batch adversarial loss: 0.338654\n",
      "epoch 18; iter: 400; batch classifier loss: 0.273476; batch adversarial loss: 0.623981\n",
      "epoch 18; iter: 600; batch classifier loss: 0.357394; batch adversarial loss: 0.287247\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444760; batch adversarial loss: 0.428508\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346399; batch adversarial loss: 0.375045\n",
      "epoch 19; iter: 400; batch classifier loss: 0.323896; batch adversarial loss: 0.403323\n",
      "epoch 19; iter: 600; batch classifier loss: 0.296303; batch adversarial loss: 0.316504\n",
      "epoch 20; iter: 0; batch classifier loss: 0.315762; batch adversarial loss: 0.268614\n",
      "epoch 20; iter: 200; batch classifier loss: 0.327129; batch adversarial loss: 0.325498\n",
      "epoch 20; iter: 400; batch classifier loss: 0.262669; batch adversarial loss: 0.429033\n",
      "epoch 20; iter: 600; batch classifier loss: 0.417339; batch adversarial loss: 0.349716\n",
      "epoch 21; iter: 0; batch classifier loss: 0.213199; batch adversarial loss: 0.429092\n",
      "epoch 21; iter: 200; batch classifier loss: 0.291385; batch adversarial loss: 0.398024\n",
      "epoch 21; iter: 400; batch classifier loss: 0.347499; batch adversarial loss: 0.460346\n",
      "epoch 21; iter: 600; batch classifier loss: 0.406301; batch adversarial loss: 0.518330\n",
      "epoch 22; iter: 0; batch classifier loss: 0.280281; batch adversarial loss: 0.541880\n",
      "epoch 22; iter: 200; batch classifier loss: 0.454139; batch adversarial loss: 0.437666\n",
      "epoch 22; iter: 400; batch classifier loss: 0.417586; batch adversarial loss: 0.370223\n",
      "epoch 22; iter: 600; batch classifier loss: 0.401193; batch adversarial loss: 0.259204\n",
      "epoch 23; iter: 0; batch classifier loss: 0.377207; batch adversarial loss: 0.485867\n",
      "epoch 23; iter: 200; batch classifier loss: 0.424437; batch adversarial loss: 0.403349\n",
      "epoch 23; iter: 400; batch classifier loss: 0.307537; batch adversarial loss: 0.575005\n",
      "epoch 23; iter: 600; batch classifier loss: 0.271888; batch adversarial loss: 0.534828\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361492; batch adversarial loss: 0.290037\n",
      "epoch 24; iter: 200; batch classifier loss: 0.300261; batch adversarial loss: 0.433483\n",
      "epoch 24; iter: 400; batch classifier loss: 0.291464; batch adversarial loss: 0.512564\n",
      "epoch 24; iter: 600; batch classifier loss: 0.346857; batch adversarial loss: 0.532921\n",
      "epoch 25; iter: 0; batch classifier loss: 0.272229; batch adversarial loss: 0.355313\n",
      "epoch 25; iter: 200; batch classifier loss: 0.583089; batch adversarial loss: 0.513441\n",
      "epoch 25; iter: 400; batch classifier loss: 0.273744; batch adversarial loss: 0.451980\n",
      "epoch 25; iter: 600; batch classifier loss: 0.449390; batch adversarial loss: 0.544388\n",
      "epoch 26; iter: 0; batch classifier loss: 0.407877; batch adversarial loss: 0.543436\n",
      "epoch 26; iter: 200; batch classifier loss: 0.361473; batch adversarial loss: 0.487178\n",
      "epoch 26; iter: 400; batch classifier loss: 0.335124; batch adversarial loss: 0.396824\n",
      "epoch 26; iter: 600; batch classifier loss: 0.398953; batch adversarial loss: 0.333290\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352382; batch adversarial loss: 0.349289\n",
      "epoch 27; iter: 200; batch classifier loss: 0.409689; batch adversarial loss: 0.389214\n",
      "epoch 27; iter: 400; batch classifier loss: 0.483386; batch adversarial loss: 0.402330\n",
      "epoch 27; iter: 600; batch classifier loss: 0.354248; batch adversarial loss: 0.430483\n",
      "epoch 28; iter: 0; batch classifier loss: 0.670367; batch adversarial loss: 0.323170\n",
      "epoch 28; iter: 200; batch classifier loss: 0.303313; batch adversarial loss: 0.327959\n",
      "epoch 28; iter: 400; batch classifier loss: 0.902148; batch adversarial loss: 0.345439\n",
      "epoch 28; iter: 600; batch classifier loss: 0.312915; batch adversarial loss: 0.432645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.270279; batch adversarial loss: 0.344233\n",
      "epoch 29; iter: 200; batch classifier loss: 0.392583; batch adversarial loss: 0.579845\n",
      "epoch 29; iter: 400; batch classifier loss: 0.350412; batch adversarial loss: 0.298527\n",
      "epoch 29; iter: 600; batch classifier loss: 0.239785; batch adversarial loss: 0.430591\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397130; batch adversarial loss: 0.456379\n",
      "epoch 30; iter: 200; batch classifier loss: 0.349409; batch adversarial loss: 0.428486\n",
      "epoch 30; iter: 400; batch classifier loss: 0.350249; batch adversarial loss: 0.377549\n",
      "epoch 30; iter: 600; batch classifier loss: 0.231218; batch adversarial loss: 0.408630\n",
      "epoch 31; iter: 0; batch classifier loss: 0.644189; batch adversarial loss: 0.427176\n",
      "epoch 31; iter: 200; batch classifier loss: 0.375372; batch adversarial loss: 0.291607\n",
      "epoch 31; iter: 400; batch classifier loss: 0.398265; batch adversarial loss: 0.385364\n",
      "epoch 31; iter: 600; batch classifier loss: 0.310395; batch adversarial loss: 0.528895\n",
      "epoch 32; iter: 0; batch classifier loss: 0.341860; batch adversarial loss: 0.397811\n",
      "epoch 32; iter: 200; batch classifier loss: 0.423131; batch adversarial loss: 0.432814\n",
      "epoch 32; iter: 400; batch classifier loss: 0.387907; batch adversarial loss: 0.408206\n",
      "epoch 32; iter: 600; batch classifier loss: 0.581207; batch adversarial loss: 0.427605\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355474; batch adversarial loss: 0.293336\n",
      "epoch 33; iter: 200; batch classifier loss: 0.432306; batch adversarial loss: 0.330464\n",
      "epoch 33; iter: 400; batch classifier loss: 0.366513; batch adversarial loss: 0.498526\n",
      "epoch 33; iter: 600; batch classifier loss: 0.327135; batch adversarial loss: 0.570096\n",
      "epoch 34; iter: 0; batch classifier loss: 0.501617; batch adversarial loss: 0.342393\n",
      "epoch 34; iter: 200; batch classifier loss: 0.519115; batch adversarial loss: 0.490345\n",
      "epoch 34; iter: 400; batch classifier loss: 0.271381; batch adversarial loss: 0.350533\n",
      "epoch 34; iter: 600; batch classifier loss: 0.383830; batch adversarial loss: 0.379700\n",
      "epoch 35; iter: 0; batch classifier loss: 0.256623; batch adversarial loss: 0.446167\n",
      "epoch 35; iter: 200; batch classifier loss: 0.492685; batch adversarial loss: 0.349986\n",
      "epoch 35; iter: 400; batch classifier loss: 0.280629; batch adversarial loss: 0.507598\n",
      "epoch 35; iter: 600; batch classifier loss: 0.439055; batch adversarial loss: 0.375330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.308149; batch adversarial loss: 0.319533\n",
      "epoch 36; iter: 200; batch classifier loss: 0.404606; batch adversarial loss: 0.453970\n",
      "epoch 36; iter: 400; batch classifier loss: 0.299516; batch adversarial loss: 0.547498\n",
      "epoch 36; iter: 600; batch classifier loss: 0.644836; batch adversarial loss: 0.320534\n",
      "epoch 37; iter: 0; batch classifier loss: 0.466359; batch adversarial loss: 0.401522\n",
      "epoch 37; iter: 200; batch classifier loss: 0.398125; batch adversarial loss: 0.320186\n",
      "epoch 37; iter: 400; batch classifier loss: 0.325396; batch adversarial loss: 0.370780\n",
      "epoch 37; iter: 600; batch classifier loss: 0.213659; batch adversarial loss: 0.509550\n",
      "epoch 38; iter: 0; batch classifier loss: 0.535298; batch adversarial loss: 0.271348\n",
      "epoch 38; iter: 200; batch classifier loss: 0.306828; batch adversarial loss: 0.372595\n",
      "epoch 38; iter: 400; batch classifier loss: 0.492204; batch adversarial loss: 0.413372\n",
      "epoch 38; iter: 600; batch classifier loss: 0.381590; batch adversarial loss: 0.326331\n",
      "epoch 39; iter: 0; batch classifier loss: 0.469949; batch adversarial loss: 0.513297\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349062; batch adversarial loss: 0.426070\n",
      "epoch 39; iter: 400; batch classifier loss: 0.276201; batch adversarial loss: 0.391541\n",
      "epoch 39; iter: 600; batch classifier loss: 0.329010; batch adversarial loss: 0.452809\n",
      "epoch 40; iter: 0; batch classifier loss: 0.379770; batch adversarial loss: 0.292486\n",
      "epoch 40; iter: 200; batch classifier loss: 0.472255; batch adversarial loss: 0.399586\n",
      "epoch 40; iter: 400; batch classifier loss: 0.451073; batch adversarial loss: 0.398913\n",
      "epoch 40; iter: 600; batch classifier loss: 0.400098; batch adversarial loss: 0.402245\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413341; batch adversarial loss: 0.320642\n",
      "epoch 41; iter: 200; batch classifier loss: 0.489462; batch adversarial loss: 0.270085\n",
      "epoch 41; iter: 400; batch classifier loss: 0.291077; batch adversarial loss: 0.379962\n",
      "epoch 41; iter: 600; batch classifier loss: 0.230479; batch adversarial loss: 0.408413\n",
      "epoch 42; iter: 0; batch classifier loss: 0.317936; batch adversarial loss: 0.518664\n",
      "epoch 42; iter: 200; batch classifier loss: 0.355417; batch adversarial loss: 0.353373\n",
      "epoch 42; iter: 400; batch classifier loss: 0.326191; batch adversarial loss: 0.488131\n",
      "epoch 42; iter: 600; batch classifier loss: 0.335073; batch adversarial loss: 0.435698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.276040; batch adversarial loss: 0.380697\n",
      "epoch 43; iter: 200; batch classifier loss: 0.354427; batch adversarial loss: 0.428731\n",
      "epoch 43; iter: 400; batch classifier loss: 0.367128; batch adversarial loss: 0.496466\n",
      "epoch 43; iter: 600; batch classifier loss: 0.448912; batch adversarial loss: 0.457225\n",
      "epoch 44; iter: 0; batch classifier loss: 0.341278; batch adversarial loss: 0.323451\n",
      "epoch 44; iter: 200; batch classifier loss: 0.451586; batch adversarial loss: 0.433973\n",
      "epoch 44; iter: 400; batch classifier loss: 0.381217; batch adversarial loss: 0.345893\n",
      "epoch 44; iter: 600; batch classifier loss: 0.442718; batch adversarial loss: 0.290474\n",
      "epoch 45; iter: 0; batch classifier loss: 0.357000; batch adversarial loss: 0.268070\n",
      "epoch 45; iter: 200; batch classifier loss: 0.264972; batch adversarial loss: 0.544757\n",
      "epoch 45; iter: 400; batch classifier loss: 0.486321; batch adversarial loss: 0.376324\n",
      "epoch 45; iter: 600; batch classifier loss: 0.441422; batch adversarial loss: 0.318080\n",
      "epoch 46; iter: 0; batch classifier loss: 0.542471; batch adversarial loss: 0.324252\n",
      "epoch 46; iter: 200; batch classifier loss: 0.271625; batch adversarial loss: 0.514593\n",
      "epoch 46; iter: 400; batch classifier loss: 0.382507; batch adversarial loss: 0.348617\n",
      "epoch 46; iter: 600; batch classifier loss: 0.556825; batch adversarial loss: 0.401726\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340003; batch adversarial loss: 0.293370\n",
      "epoch 47; iter: 200; batch classifier loss: 0.377108; batch adversarial loss: 0.582337\n",
      "epoch 47; iter: 400; batch classifier loss: 0.331082; batch adversarial loss: 0.436079\n",
      "epoch 47; iter: 600; batch classifier loss: 0.553077; batch adversarial loss: 0.430853\n",
      "epoch 48; iter: 0; batch classifier loss: 0.183063; batch adversarial loss: 0.622716\n",
      "epoch 48; iter: 200; batch classifier loss: 0.422136; batch adversarial loss: 0.374514\n",
      "epoch 48; iter: 400; batch classifier loss: 0.349039; batch adversarial loss: 0.402709\n",
      "epoch 48; iter: 600; batch classifier loss: 0.462760; batch adversarial loss: 0.297546\n",
      "epoch 49; iter: 0; batch classifier loss: 0.511572; batch adversarial loss: 0.513426\n",
      "epoch 49; iter: 200; batch classifier loss: 0.331435; batch adversarial loss: 0.352852\n",
      "epoch 49; iter: 400; batch classifier loss: 0.310591; batch adversarial loss: 0.429836\n",
      "epoch 49; iter: 600; batch classifier loss: 0.838224; batch adversarial loss: 0.402276\n",
      "epoch 0; iter: 0; batch classifier loss: 16.081779; batch adversarial loss: 0.622111\n",
      "epoch 0; iter: 200; batch classifier loss: 1.436608; batch adversarial loss: 0.588563\n",
      "epoch 0; iter: 400; batch classifier loss: 18.233490; batch adversarial loss: 0.567993\n",
      "epoch 0; iter: 600; batch classifier loss: 4.176379; batch adversarial loss: 0.579094\n",
      "epoch 1; iter: 0; batch classifier loss: 2.989972; batch adversarial loss: 0.509776\n",
      "epoch 1; iter: 200; batch classifier loss: 9.107773; batch adversarial loss: 0.445412\n",
      "epoch 1; iter: 400; batch classifier loss: 5.040848; batch adversarial loss: 0.358993\n",
      "epoch 1; iter: 600; batch classifier loss: 4.296038; batch adversarial loss: 0.442888\n",
      "epoch 2; iter: 0; batch classifier loss: 3.127381; batch adversarial loss: 0.416431\n",
      "epoch 2; iter: 200; batch classifier loss: 1.797801; batch adversarial loss: 0.499909\n",
      "epoch 2; iter: 400; batch classifier loss: 2.874729; batch adversarial loss: 0.414614\n",
      "epoch 2; iter: 600; batch classifier loss: 2.014639; batch adversarial loss: 0.498793\n",
      "epoch 3; iter: 0; batch classifier loss: 1.020213; batch adversarial loss: 0.502638\n",
      "epoch 3; iter: 200; batch classifier loss: 0.623272; batch adversarial loss: 0.345812\n",
      "epoch 3; iter: 400; batch classifier loss: 0.464969; batch adversarial loss: 0.432025\n",
      "epoch 3; iter: 600; batch classifier loss: 0.574315; batch adversarial loss: 0.373156\n",
      "epoch 4; iter: 0; batch classifier loss: 0.274475; batch adversarial loss: 0.415012\n",
      "epoch 4; iter: 200; batch classifier loss: 0.598686; batch adversarial loss: 0.273474\n",
      "epoch 4; iter: 400; batch classifier loss: 0.456050; batch adversarial loss: 0.402964\n",
      "epoch 4; iter: 600; batch classifier loss: 0.369510; batch adversarial loss: 0.408152\n",
      "epoch 5; iter: 0; batch classifier loss: 0.510517; batch adversarial loss: 0.471336\n",
      "epoch 5; iter: 200; batch classifier loss: 0.283745; batch adversarial loss: 0.476384\n",
      "epoch 5; iter: 400; batch classifier loss: 0.426556; batch adversarial loss: 0.406617\n",
      "epoch 5; iter: 600; batch classifier loss: 0.450040; batch adversarial loss: 0.569418\n",
      "epoch 6; iter: 0; batch classifier loss: 0.424063; batch adversarial loss: 0.507543\n",
      "epoch 6; iter: 200; batch classifier loss: 2.408745; batch adversarial loss: 0.427173\n",
      "epoch 6; iter: 400; batch classifier loss: 0.255617; batch adversarial loss: 0.433983\n",
      "epoch 6; iter: 600; batch classifier loss: 0.398969; batch adversarial loss: 0.504340\n",
      "epoch 7; iter: 0; batch classifier loss: 0.430791; batch adversarial loss: 0.457851\n",
      "epoch 7; iter: 200; batch classifier loss: 0.406205; batch adversarial loss: 0.308811\n",
      "epoch 7; iter: 400; batch classifier loss: 0.430992; batch adversarial loss: 0.423278\n",
      "epoch 7; iter: 600; batch classifier loss: 0.550542; batch adversarial loss: 0.403245\n",
      "epoch 8; iter: 0; batch classifier loss: 0.354634; batch adversarial loss: 0.455102\n",
      "epoch 8; iter: 200; batch classifier loss: 0.830792; batch adversarial loss: 0.320619\n",
      "epoch 8; iter: 400; batch classifier loss: 0.255955; batch adversarial loss: 0.381403\n",
      "epoch 8; iter: 600; batch classifier loss: 0.394566; batch adversarial loss: 0.556363\n",
      "epoch 9; iter: 0; batch classifier loss: 0.279747; batch adversarial loss: 0.420667\n",
      "epoch 9; iter: 200; batch classifier loss: 0.457308; batch adversarial loss: 0.376296\n",
      "epoch 9; iter: 400; batch classifier loss: 0.310297; batch adversarial loss: 0.375554\n",
      "epoch 9; iter: 600; batch classifier loss: 0.529479; batch adversarial loss: 0.242325\n",
      "epoch 10; iter: 0; batch classifier loss: 0.327142; batch adversarial loss: 0.621691\n",
      "epoch 10; iter: 200; batch classifier loss: 0.313492; batch adversarial loss: 0.509224\n",
      "epoch 10; iter: 400; batch classifier loss: 0.338015; batch adversarial loss: 0.521972\n",
      "epoch 10; iter: 600; batch classifier loss: 0.337127; batch adversarial loss: 0.437657\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362133; batch adversarial loss: 0.558268\n",
      "epoch 11; iter: 200; batch classifier loss: 0.404450; batch adversarial loss: 0.489874\n",
      "epoch 11; iter: 400; batch classifier loss: 0.249285; batch adversarial loss: 0.289467\n",
      "epoch 11; iter: 600; batch classifier loss: 0.353847; batch adversarial loss: 0.449900\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300118; batch adversarial loss: 0.417747\n",
      "epoch 12; iter: 200; batch classifier loss: 0.297100; batch adversarial loss: 0.433269\n",
      "epoch 12; iter: 400; batch classifier loss: 0.288934; batch adversarial loss: 0.399642\n",
      "epoch 12; iter: 600; batch classifier loss: 0.307253; batch adversarial loss: 0.427346\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341555; batch adversarial loss: 0.370401\n",
      "epoch 13; iter: 200; batch classifier loss: 0.264200; batch adversarial loss: 0.463105\n",
      "epoch 13; iter: 400; batch classifier loss: 0.346072; batch adversarial loss: 0.330417\n",
      "epoch 13; iter: 600; batch classifier loss: 0.434116; batch adversarial loss: 0.503100\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245475; batch adversarial loss: 0.348260\n",
      "epoch 14; iter: 200; batch classifier loss: 0.310512; batch adversarial loss: 0.438472\n",
      "epoch 14; iter: 400; batch classifier loss: 0.254875; batch adversarial loss: 0.461059\n",
      "epoch 14; iter: 600; batch classifier loss: 0.399852; batch adversarial loss: 0.355022\n",
      "epoch 15; iter: 0; batch classifier loss: 0.383205; batch adversarial loss: 0.426740\n",
      "epoch 15; iter: 200; batch classifier loss: 0.418680; batch adversarial loss: 0.370476\n",
      "epoch 15; iter: 400; batch classifier loss: 0.348014; batch adversarial loss: 0.261868\n",
      "epoch 15; iter: 600; batch classifier loss: 0.335550; batch adversarial loss: 0.393093\n",
      "epoch 16; iter: 0; batch classifier loss: 0.395558; batch adversarial loss: 0.294695\n",
      "epoch 16; iter: 200; batch classifier loss: 0.366683; batch adversarial loss: 0.434628\n",
      "epoch 16; iter: 400; batch classifier loss: 0.275974; batch adversarial loss: 0.407884\n",
      "epoch 16; iter: 600; batch classifier loss: 0.658767; batch adversarial loss: 0.458527\n",
      "epoch 17; iter: 0; batch classifier loss: 0.306696; batch adversarial loss: 0.359787\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345830; batch adversarial loss: 0.327823\n",
      "epoch 17; iter: 400; batch classifier loss: 0.292807; batch adversarial loss: 0.428011\n",
      "epoch 17; iter: 600; batch classifier loss: 0.333941; batch adversarial loss: 0.402821\n",
      "epoch 18; iter: 0; batch classifier loss: 0.270339; batch adversarial loss: 0.415072\n",
      "epoch 18; iter: 200; batch classifier loss: 0.377710; batch adversarial loss: 0.376096\n",
      "epoch 18; iter: 400; batch classifier loss: 0.347440; batch adversarial loss: 0.516294\n",
      "epoch 18; iter: 600; batch classifier loss: 0.429095; batch adversarial loss: 0.358048\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350327; batch adversarial loss: 0.319529\n",
      "epoch 19; iter: 200; batch classifier loss: 0.285638; batch adversarial loss: 0.353833\n",
      "epoch 19; iter: 400; batch classifier loss: 0.553244; batch adversarial loss: 0.449247\n",
      "epoch 19; iter: 600; batch classifier loss: 0.366046; batch adversarial loss: 0.437424\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436307; batch adversarial loss: 0.430230\n",
      "epoch 20; iter: 200; batch classifier loss: 0.388715; batch adversarial loss: 0.355060\n",
      "epoch 20; iter: 400; batch classifier loss: 0.228318; batch adversarial loss: 0.431717\n",
      "epoch 20; iter: 600; batch classifier loss: 0.417016; batch adversarial loss: 0.340894\n",
      "epoch 21; iter: 0; batch classifier loss: 0.370908; batch adversarial loss: 0.502449\n",
      "epoch 21; iter: 200; batch classifier loss: 0.390215; batch adversarial loss: 0.355293\n",
      "epoch 21; iter: 400; batch classifier loss: 0.286015; batch adversarial loss: 0.370261\n",
      "epoch 21; iter: 600; batch classifier loss: 0.321242; batch adversarial loss: 0.401761\n",
      "epoch 22; iter: 0; batch classifier loss: 0.473792; batch adversarial loss: 0.216179\n",
      "epoch 22; iter: 200; batch classifier loss: 0.428811; batch adversarial loss: 0.434101\n",
      "epoch 22; iter: 400; batch classifier loss: 0.325012; batch adversarial loss: 0.466203\n",
      "epoch 22; iter: 600; batch classifier loss: 0.345920; batch adversarial loss: 0.476374\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438686; batch adversarial loss: 0.428513\n",
      "epoch 23; iter: 200; batch classifier loss: 0.436722; batch adversarial loss: 0.404152\n",
      "epoch 23; iter: 400; batch classifier loss: 0.257458; batch adversarial loss: 0.316491\n",
      "epoch 23; iter: 600; batch classifier loss: 0.402499; batch adversarial loss: 0.413563\n",
      "epoch 24; iter: 0; batch classifier loss: 0.415501; batch adversarial loss: 0.517967\n",
      "epoch 24; iter: 200; batch classifier loss: 0.375514; batch adversarial loss: 0.264305\n",
      "epoch 24; iter: 400; batch classifier loss: 0.440889; batch adversarial loss: 0.377153\n",
      "epoch 24; iter: 600; batch classifier loss: 0.558614; batch adversarial loss: 0.549198\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483363; batch adversarial loss: 0.457681\n",
      "epoch 25; iter: 200; batch classifier loss: 0.330675; batch adversarial loss: 0.564419\n",
      "epoch 25; iter: 400; batch classifier loss: 0.446745; batch adversarial loss: 0.428258\n",
      "epoch 25; iter: 600; batch classifier loss: 0.477027; batch adversarial loss: 0.351707\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426411; batch adversarial loss: 0.458768\n",
      "epoch 26; iter: 200; batch classifier loss: 0.375662; batch adversarial loss: 0.405003\n",
      "epoch 26; iter: 400; batch classifier loss: 0.567406; batch adversarial loss: 0.460721\n",
      "epoch 26; iter: 600; batch classifier loss: 0.233129; batch adversarial loss: 0.404824\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278307; batch adversarial loss: 0.434196\n",
      "epoch 27; iter: 200; batch classifier loss: 0.266209; batch adversarial loss: 0.513364\n",
      "epoch 27; iter: 400; batch classifier loss: 0.368103; batch adversarial loss: 0.429571\n",
      "epoch 27; iter: 600; batch classifier loss: 0.216484; batch adversarial loss: 0.398391\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368977; batch adversarial loss: 0.407006\n",
      "epoch 28; iter: 200; batch classifier loss: 0.510950; batch adversarial loss: 0.293768\n",
      "epoch 28; iter: 400; batch classifier loss: 0.896847; batch adversarial loss: 0.320084\n",
      "epoch 28; iter: 600; batch classifier loss: 0.447141; batch adversarial loss: 0.507375\n",
      "epoch 29; iter: 0; batch classifier loss: 0.413711; batch adversarial loss: 0.404698\n",
      "epoch 29; iter: 200; batch classifier loss: 0.265380; batch adversarial loss: 0.454882\n",
      "epoch 29; iter: 400; batch classifier loss: 0.293998; batch adversarial loss: 0.542608\n",
      "epoch 29; iter: 600; batch classifier loss: 0.575399; batch adversarial loss: 0.525515\n",
      "epoch 30; iter: 0; batch classifier loss: 0.403927; batch adversarial loss: 0.447730\n",
      "epoch 30; iter: 200; batch classifier loss: 0.547715; batch adversarial loss: 0.342922\n",
      "epoch 30; iter: 400; batch classifier loss: 0.344120; batch adversarial loss: 0.424748\n",
      "epoch 30; iter: 600; batch classifier loss: 0.390726; batch adversarial loss: 0.407600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480294; batch adversarial loss: 0.428923\n",
      "epoch 31; iter: 200; batch classifier loss: 0.307677; batch adversarial loss: 0.645134\n",
      "epoch 31; iter: 400; batch classifier loss: 0.395849; batch adversarial loss: 0.496383\n",
      "epoch 31; iter: 600; batch classifier loss: 0.317045; batch adversarial loss: 0.432560\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361473; batch adversarial loss: 0.467691\n",
      "epoch 32; iter: 200; batch classifier loss: 0.657816; batch adversarial loss: 0.456003\n",
      "epoch 32; iter: 400; batch classifier loss: 0.365945; batch adversarial loss: 0.319215\n",
      "epoch 32; iter: 600; batch classifier loss: 0.457005; batch adversarial loss: 0.341002\n",
      "epoch 33; iter: 0; batch classifier loss: 0.519962; batch adversarial loss: 0.345604\n",
      "epoch 33; iter: 200; batch classifier loss: 0.396301; batch adversarial loss: 0.551104\n",
      "epoch 33; iter: 400; batch classifier loss: 0.340667; batch adversarial loss: 0.319789\n",
      "epoch 33; iter: 600; batch classifier loss: 0.482266; batch adversarial loss: 0.466943\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438180; batch adversarial loss: 0.344812\n",
      "epoch 34; iter: 200; batch classifier loss: 0.369164; batch adversarial loss: 0.402126\n",
      "epoch 34; iter: 400; batch classifier loss: 0.301637; batch adversarial loss: 0.257168\n",
      "epoch 34; iter: 600; batch classifier loss: 0.387883; batch adversarial loss: 0.378805\n",
      "epoch 35; iter: 0; batch classifier loss: 0.313579; batch adversarial loss: 0.433523\n",
      "epoch 35; iter: 200; batch classifier loss: 0.431084; batch adversarial loss: 0.422179\n",
      "epoch 35; iter: 400; batch classifier loss: 0.299833; batch adversarial loss: 0.426756\n",
      "epoch 35; iter: 600; batch classifier loss: 0.472293; batch adversarial loss: 0.372993\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353472; batch adversarial loss: 0.464424\n",
      "epoch 36; iter: 200; batch classifier loss: 0.359668; batch adversarial loss: 0.438548\n",
      "epoch 36; iter: 400; batch classifier loss: 0.344236; batch adversarial loss: 0.291557\n",
      "epoch 36; iter: 600; batch classifier loss: 0.228334; batch adversarial loss: 0.408306\n",
      "epoch 37; iter: 0; batch classifier loss: 0.227748; batch adversarial loss: 0.421329\n",
      "epoch 37; iter: 200; batch classifier loss: 0.382997; batch adversarial loss: 0.374303\n",
      "epoch 37; iter: 400; batch classifier loss: 0.304421; batch adversarial loss: 0.486261\n",
      "epoch 37; iter: 600; batch classifier loss: 0.443413; batch adversarial loss: 0.375466\n",
      "epoch 38; iter: 0; batch classifier loss: 0.348180; batch adversarial loss: 0.430245\n",
      "epoch 38; iter: 200; batch classifier loss: 0.407547; batch adversarial loss: 0.399305\n",
      "epoch 38; iter: 400; batch classifier loss: 0.286394; batch adversarial loss: 0.451041\n",
      "epoch 38; iter: 600; batch classifier loss: 0.529655; batch adversarial loss: 0.493351\n",
      "epoch 39; iter: 0; batch classifier loss: 0.503830; batch adversarial loss: 0.374640\n",
      "epoch 39; iter: 200; batch classifier loss: 0.479694; batch adversarial loss: 0.427994\n",
      "epoch 39; iter: 400; batch classifier loss: 0.416131; batch adversarial loss: 0.354104\n",
      "epoch 39; iter: 600; batch classifier loss: 0.298236; batch adversarial loss: 0.552842\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460860; batch adversarial loss: 0.414010\n",
      "epoch 40; iter: 200; batch classifier loss: 0.421145; batch adversarial loss: 0.408159\n",
      "epoch 40; iter: 400; batch classifier loss: 0.407722; batch adversarial loss: 0.262926\n",
      "epoch 40; iter: 600; batch classifier loss: 0.412161; batch adversarial loss: 0.299882\n",
      "epoch 41; iter: 0; batch classifier loss: 0.217033; batch adversarial loss: 0.409460\n",
      "epoch 41; iter: 200; batch classifier loss: 0.513536; batch adversarial loss: 0.375940\n",
      "epoch 41; iter: 400; batch classifier loss: 0.311302; batch adversarial loss: 0.534751\n",
      "epoch 41; iter: 600; batch classifier loss: 0.256427; batch adversarial loss: 0.570051\n",
      "epoch 42; iter: 0; batch classifier loss: 0.295567; batch adversarial loss: 0.430340\n",
      "epoch 42; iter: 200; batch classifier loss: 0.499209; batch adversarial loss: 0.265080\n",
      "epoch 42; iter: 400; batch classifier loss: 0.462201; batch adversarial loss: 0.399051\n",
      "epoch 42; iter: 600; batch classifier loss: 0.399008; batch adversarial loss: 0.481686\n",
      "epoch 43; iter: 0; batch classifier loss: 0.260093; batch adversarial loss: 0.350666\n",
      "epoch 43; iter: 200; batch classifier loss: 0.390346; batch adversarial loss: 0.297692\n",
      "epoch 43; iter: 400; batch classifier loss: 0.484684; batch adversarial loss: 0.463807\n",
      "epoch 43; iter: 600; batch classifier loss: 0.555879; batch adversarial loss: 0.457058\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395398; batch adversarial loss: 0.282513\n",
      "epoch 44; iter: 200; batch classifier loss: 0.380189; batch adversarial loss: 0.479285\n",
      "epoch 44; iter: 400; batch classifier loss: 0.347357; batch adversarial loss: 0.319231\n",
      "epoch 44; iter: 600; batch classifier loss: 0.444646; batch adversarial loss: 0.428708\n",
      "epoch 45; iter: 0; batch classifier loss: 0.277525; batch adversarial loss: 0.261697\n",
      "epoch 45; iter: 200; batch classifier loss: 0.329343; batch adversarial loss: 0.524910\n",
      "epoch 45; iter: 400; batch classifier loss: 0.383741; batch adversarial loss: 0.451382\n",
      "epoch 45; iter: 600; batch classifier loss: 0.421720; batch adversarial loss: 0.343969\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468347; batch adversarial loss: 0.489327\n",
      "epoch 46; iter: 200; batch classifier loss: 0.288644; batch adversarial loss: 0.475946\n",
      "epoch 46; iter: 400; batch classifier loss: 0.513529; batch adversarial loss: 0.508548\n",
      "epoch 46; iter: 600; batch classifier loss: 0.377667; batch adversarial loss: 0.517632\n",
      "epoch 47; iter: 0; batch classifier loss: 0.595621; batch adversarial loss: 0.477631\n",
      "epoch 47; iter: 200; batch classifier loss: 0.562345; batch adversarial loss: 0.523828\n",
      "epoch 47; iter: 400; batch classifier loss: 0.648028; batch adversarial loss: 0.398637\n",
      "epoch 47; iter: 600; batch classifier loss: 0.158244; batch adversarial loss: 0.314949\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419441; batch adversarial loss: 0.263234\n",
      "epoch 48; iter: 200; batch classifier loss: 0.452572; batch adversarial loss: 0.517969\n",
      "epoch 48; iter: 400; batch classifier loss: 0.297526; batch adversarial loss: 0.418835\n",
      "epoch 48; iter: 600; batch classifier loss: 0.525136; batch adversarial loss: 0.540057\n",
      "epoch 49; iter: 0; batch classifier loss: 0.314666; batch adversarial loss: 0.381885\n",
      "epoch 49; iter: 200; batch classifier loss: 0.248735; batch adversarial loss: 0.401133\n",
      "epoch 49; iter: 400; batch classifier loss: 0.707006; batch adversarial loss: 0.283065\n",
      "epoch 49; iter: 600; batch classifier loss: 0.372441; batch adversarial loss: 0.455094\n",
      "epoch 0; iter: 0; batch classifier loss: 20.429941; batch adversarial loss: 0.505869\n",
      "epoch 0; iter: 200; batch classifier loss: 9.521785; batch adversarial loss: 0.592778\n",
      "epoch 0; iter: 400; batch classifier loss: 16.603987; batch adversarial loss: 0.550277\n",
      "epoch 0; iter: 600; batch classifier loss: 0.703255; batch adversarial loss: 0.458451\n",
      "epoch 1; iter: 0; batch classifier loss: 1.971698; batch adversarial loss: 0.566655\n",
      "epoch 1; iter: 200; batch classifier loss: 0.503330; batch adversarial loss: 0.429738\n",
      "epoch 1; iter: 400; batch classifier loss: 4.503382; batch adversarial loss: 0.375684\n",
      "epoch 1; iter: 600; batch classifier loss: 3.827595; batch adversarial loss: 0.518987\n",
      "epoch 2; iter: 0; batch classifier loss: 2.992850; batch adversarial loss: 0.503370\n",
      "epoch 2; iter: 200; batch classifier loss: 3.641423; batch adversarial loss: 0.443226\n",
      "epoch 2; iter: 400; batch classifier loss: 1.312178; batch adversarial loss: 0.473313\n",
      "epoch 2; iter: 600; batch classifier loss: 4.631202; batch adversarial loss: 0.345712\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384908; batch adversarial loss: 0.293887\n",
      "epoch 3; iter: 200; batch classifier loss: 3.325306; batch adversarial loss: 0.566098\n",
      "epoch 3; iter: 400; batch classifier loss: 0.651510; batch adversarial loss: 0.337296\n",
      "epoch 3; iter: 600; batch classifier loss: 2.069803; batch adversarial loss: 0.512401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.836317; batch adversarial loss: 0.329327\n",
      "epoch 4; iter: 200; batch classifier loss: 0.274200; batch adversarial loss: 0.543348\n",
      "epoch 4; iter: 400; batch classifier loss: 0.384495; batch adversarial loss: 0.258393\n",
      "epoch 4; iter: 600; batch classifier loss: 0.775654; batch adversarial loss: 0.280416\n",
      "epoch 5; iter: 0; batch classifier loss: 0.412338; batch adversarial loss: 0.429279\n",
      "epoch 5; iter: 200; batch classifier loss: 0.706181; batch adversarial loss: 0.350883\n",
      "epoch 5; iter: 400; batch classifier loss: 0.560680; batch adversarial loss: 0.486535\n",
      "epoch 5; iter: 600; batch classifier loss: 0.398350; batch adversarial loss: 0.521552\n",
      "epoch 6; iter: 0; batch classifier loss: 0.437337; batch adversarial loss: 0.381449\n",
      "epoch 6; iter: 200; batch classifier loss: 0.330301; batch adversarial loss: 0.348096\n",
      "epoch 6; iter: 400; batch classifier loss: 0.375709; batch adversarial loss: 0.380640\n",
      "epoch 6; iter: 600; batch classifier loss: 0.377900; batch adversarial loss: 0.371258\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401082; batch adversarial loss: 0.381097\n",
      "epoch 7; iter: 200; batch classifier loss: 0.300117; batch adversarial loss: 0.425304\n",
      "epoch 7; iter: 400; batch classifier loss: 0.494304; batch adversarial loss: 0.410359\n",
      "epoch 7; iter: 600; batch classifier loss: 0.384835; batch adversarial loss: 0.423102\n",
      "epoch 8; iter: 0; batch classifier loss: 0.460870; batch adversarial loss: 0.350637\n",
      "epoch 8; iter: 200; batch classifier loss: 0.422820; batch adversarial loss: 0.411539\n",
      "epoch 8; iter: 400; batch classifier loss: 0.275081; batch adversarial loss: 0.266668\n",
      "epoch 8; iter: 600; batch classifier loss: 0.272475; batch adversarial loss: 0.422005\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443023; batch adversarial loss: 0.270304\n",
      "epoch 9; iter: 200; batch classifier loss: 0.351364; batch adversarial loss: 0.351669\n",
      "epoch 9; iter: 400; batch classifier loss: 0.465448; batch adversarial loss: 0.560601\n",
      "epoch 9; iter: 600; batch classifier loss: 0.473419; batch adversarial loss: 0.296590\n",
      "epoch 10; iter: 0; batch classifier loss: 0.323205; batch adversarial loss: 0.434367\n",
      "epoch 10; iter: 200; batch classifier loss: 0.371280; batch adversarial loss: 0.433812\n",
      "epoch 10; iter: 400; batch classifier loss: 0.323213; batch adversarial loss: 0.376317\n",
      "epoch 10; iter: 600; batch classifier loss: 0.249768; batch adversarial loss: 0.375262\n",
      "epoch 11; iter: 0; batch classifier loss: 0.335939; batch adversarial loss: 0.383643\n",
      "epoch 11; iter: 200; batch classifier loss: 0.396287; batch adversarial loss: 0.431775\n",
      "epoch 11; iter: 400; batch classifier loss: 0.358626; batch adversarial loss: 0.432118\n",
      "epoch 11; iter: 600; batch classifier loss: 0.380358; batch adversarial loss: 0.348774\n",
      "epoch 12; iter: 0; batch classifier loss: 0.450157; batch adversarial loss: 0.537806\n",
      "epoch 12; iter: 200; batch classifier loss: 0.306939; batch adversarial loss: 0.342385\n",
      "epoch 12; iter: 400; batch classifier loss: 0.404165; batch adversarial loss: 0.425695\n",
      "epoch 12; iter: 600; batch classifier loss: 0.430686; batch adversarial loss: 0.339821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348871; batch adversarial loss: 0.454457\n",
      "epoch 13; iter: 200; batch classifier loss: 0.494373; batch adversarial loss: 0.464600\n",
      "epoch 13; iter: 400; batch classifier loss: 0.298545; batch adversarial loss: 0.449993\n",
      "epoch 13; iter: 600; batch classifier loss: 0.322553; batch adversarial loss: 0.487891\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376819; batch adversarial loss: 0.270601\n",
      "epoch 14; iter: 200; batch classifier loss: 0.328277; batch adversarial loss: 0.399358\n",
      "epoch 14; iter: 400; batch classifier loss: 0.335102; batch adversarial loss: 0.428254\n",
      "epoch 14; iter: 600; batch classifier loss: 0.292080; batch adversarial loss: 0.360567\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381920; batch adversarial loss: 0.383639\n",
      "epoch 15; iter: 200; batch classifier loss: 0.436347; batch adversarial loss: 0.540633\n",
      "epoch 15; iter: 400; batch classifier loss: 0.342966; batch adversarial loss: 0.425800\n",
      "epoch 15; iter: 600; batch classifier loss: 0.359756; batch adversarial loss: 0.468045\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537840; batch adversarial loss: 0.437211\n",
      "epoch 16; iter: 200; batch classifier loss: 0.442206; batch adversarial loss: 0.400690\n",
      "epoch 16; iter: 400; batch classifier loss: 0.534395; batch adversarial loss: 0.320484\n",
      "epoch 16; iter: 600; batch classifier loss: 0.354740; batch adversarial loss: 0.379766\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420529; batch adversarial loss: 0.494179\n",
      "epoch 17; iter: 200; batch classifier loss: 0.312330; batch adversarial loss: 0.265565\n",
      "epoch 17; iter: 400; batch classifier loss: 0.232580; batch adversarial loss: 0.432921\n",
      "epoch 17; iter: 600; batch classifier loss: 0.422647; batch adversarial loss: 0.368282\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314588; batch adversarial loss: 0.367625\n",
      "epoch 18; iter: 200; batch classifier loss: 0.305133; batch adversarial loss: 0.367531\n",
      "epoch 18; iter: 400; batch classifier loss: 0.477154; batch adversarial loss: 0.370599\n",
      "epoch 18; iter: 600; batch classifier loss: 0.392971; batch adversarial loss: 0.407346\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441445; batch adversarial loss: 0.318423\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350163; batch adversarial loss: 0.476332\n",
      "epoch 19; iter: 400; batch classifier loss: 0.404475; batch adversarial loss: 0.549538\n",
      "epoch 19; iter: 600; batch classifier loss: 0.381852; batch adversarial loss: 0.480371\n",
      "epoch 20; iter: 0; batch classifier loss: 0.404678; batch adversarial loss: 0.306143\n",
      "epoch 20; iter: 200; batch classifier loss: 0.315787; batch adversarial loss: 0.456778\n",
      "epoch 20; iter: 400; batch classifier loss: 0.342064; batch adversarial loss: 0.370518\n",
      "epoch 20; iter: 600; batch classifier loss: 0.357206; batch adversarial loss: 0.343998\n",
      "epoch 21; iter: 0; batch classifier loss: 0.292612; batch adversarial loss: 0.313958\n",
      "epoch 21; iter: 200; batch classifier loss: 0.360089; batch adversarial loss: 0.354185\n",
      "epoch 21; iter: 400; batch classifier loss: 0.478642; batch adversarial loss: 0.439440\n",
      "epoch 21; iter: 600; batch classifier loss: 0.373959; batch adversarial loss: 0.495633\n",
      "epoch 22; iter: 0; batch classifier loss: 0.453340; batch adversarial loss: 0.379308\n",
      "epoch 22; iter: 200; batch classifier loss: 0.423158; batch adversarial loss: 0.337380\n",
      "epoch 22; iter: 400; batch classifier loss: 0.517040; batch adversarial loss: 0.372761\n",
      "epoch 22; iter: 600; batch classifier loss: 0.394829; batch adversarial loss: 0.498293\n",
      "epoch 23; iter: 0; batch classifier loss: 0.291382; batch adversarial loss: 0.327717\n",
      "epoch 23; iter: 200; batch classifier loss: 0.285221; batch adversarial loss: 0.263732\n",
      "epoch 23; iter: 400; batch classifier loss: 0.348550; batch adversarial loss: 0.676878\n",
      "epoch 23; iter: 600; batch classifier loss: 0.394046; batch adversarial loss: 0.373343\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510166; batch adversarial loss: 0.439913\n",
      "epoch 24; iter: 200; batch classifier loss: 0.346640; batch adversarial loss: 0.465351\n",
      "epoch 24; iter: 400; batch classifier loss: 0.372442; batch adversarial loss: 0.406080\n",
      "epoch 24; iter: 600; batch classifier loss: 0.336487; batch adversarial loss: 0.336759\n",
      "epoch 25; iter: 0; batch classifier loss: 0.316722; batch adversarial loss: 0.474805\n",
      "epoch 25; iter: 200; batch classifier loss: 0.343400; batch adversarial loss: 0.425732\n",
      "epoch 25; iter: 400; batch classifier loss: 0.693142; batch adversarial loss: 0.316607\n",
      "epoch 25; iter: 600; batch classifier loss: 0.216159; batch adversarial loss: 0.383763\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465812; batch adversarial loss: 0.393195\n",
      "epoch 26; iter: 200; batch classifier loss: 0.346170; batch adversarial loss: 0.386267\n",
      "epoch 26; iter: 400; batch classifier loss: 0.293736; batch adversarial loss: 0.318969\n",
      "epoch 26; iter: 600; batch classifier loss: 0.348725; batch adversarial loss: 0.533883\n",
      "epoch 27; iter: 0; batch classifier loss: 0.224424; batch adversarial loss: 0.353559\n",
      "epoch 27; iter: 200; batch classifier loss: 0.298873; batch adversarial loss: 0.381427\n",
      "epoch 27; iter: 400; batch classifier loss: 0.390016; batch adversarial loss: 0.293661\n",
      "epoch 27; iter: 600; batch classifier loss: 0.464606; batch adversarial loss: 0.325350\n",
      "epoch 28; iter: 0; batch classifier loss: 0.252787; batch adversarial loss: 0.484387\n",
      "epoch 28; iter: 200; batch classifier loss: 0.409763; batch adversarial loss: 0.477295\n",
      "epoch 28; iter: 400; batch classifier loss: 0.386325; batch adversarial loss: 0.384502\n",
      "epoch 28; iter: 600; batch classifier loss: 0.407441; batch adversarial loss: 0.448911\n",
      "epoch 29; iter: 0; batch classifier loss: 0.357598; batch adversarial loss: 0.348539\n",
      "epoch 29; iter: 200; batch classifier loss: 0.346217; batch adversarial loss: 0.348410\n",
      "epoch 29; iter: 400; batch classifier loss: 0.580977; batch adversarial loss: 0.379345\n",
      "epoch 29; iter: 600; batch classifier loss: 0.324181; batch adversarial loss: 0.387630\n",
      "epoch 30; iter: 0; batch classifier loss: 0.383562; batch adversarial loss: 0.356356\n",
      "epoch 30; iter: 200; batch classifier loss: 0.253705; batch adversarial loss: 0.485759\n",
      "epoch 30; iter: 400; batch classifier loss: 0.515203; batch adversarial loss: 0.532436\n",
      "epoch 30; iter: 600; batch classifier loss: 0.398521; batch adversarial loss: 0.376695\n",
      "epoch 31; iter: 0; batch classifier loss: 0.356677; batch adversarial loss: 0.373205\n",
      "epoch 31; iter: 200; batch classifier loss: 0.435643; batch adversarial loss: 0.607190\n",
      "epoch 31; iter: 400; batch classifier loss: 0.347645; batch adversarial loss: 0.265831\n",
      "epoch 31; iter: 600; batch classifier loss: 0.560666; batch adversarial loss: 0.393216\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430159; batch adversarial loss: 0.343960\n",
      "epoch 32; iter: 200; batch classifier loss: 0.304856; batch adversarial loss: 0.423878\n",
      "epoch 32; iter: 400; batch classifier loss: 0.343341; batch adversarial loss: 0.428458\n",
      "epoch 32; iter: 600; batch classifier loss: 0.381540; batch adversarial loss: 0.395886\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355475; batch adversarial loss: 0.476027\n",
      "epoch 33; iter: 200; batch classifier loss: 0.586242; batch adversarial loss: 0.505792\n",
      "epoch 33; iter: 400; batch classifier loss: 0.260798; batch adversarial loss: 0.346152\n",
      "epoch 33; iter: 600; batch classifier loss: 0.269817; batch adversarial loss: 0.409975\n",
      "epoch 34; iter: 0; batch classifier loss: 0.257789; batch adversarial loss: 0.340829\n",
      "epoch 34; iter: 200; batch classifier loss: 0.312786; batch adversarial loss: 0.497517\n",
      "epoch 34; iter: 400; batch classifier loss: 0.402843; batch adversarial loss: 0.319262\n",
      "epoch 34; iter: 600; batch classifier loss: 0.312204; batch adversarial loss: 0.560373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.399849; batch adversarial loss: 0.264822\n",
      "epoch 35; iter: 200; batch classifier loss: 0.379888; batch adversarial loss: 0.423155\n",
      "epoch 35; iter: 400; batch classifier loss: 0.436818; batch adversarial loss: 0.514418\n",
      "epoch 35; iter: 600; batch classifier loss: 0.395185; batch adversarial loss: 0.513156\n",
      "epoch 36; iter: 0; batch classifier loss: 0.422337; batch adversarial loss: 0.492088\n",
      "epoch 36; iter: 200; batch classifier loss: 0.239786; batch adversarial loss: 0.370794\n",
      "epoch 36; iter: 400; batch classifier loss: 0.292299; batch adversarial loss: 0.427459\n",
      "epoch 36; iter: 600; batch classifier loss: 0.380026; batch adversarial loss: 0.380491\n",
      "epoch 37; iter: 0; batch classifier loss: 0.337831; batch adversarial loss: 0.508932\n",
      "epoch 37; iter: 200; batch classifier loss: 0.482907; batch adversarial loss: 0.380595\n",
      "epoch 37; iter: 400; batch classifier loss: 0.334078; batch adversarial loss: 0.324914\n",
      "epoch 37; iter: 600; batch classifier loss: 0.577067; batch adversarial loss: 0.413483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404127; batch adversarial loss: 0.454895\n",
      "epoch 38; iter: 200; batch classifier loss: 0.389726; batch adversarial loss: 0.321869\n",
      "epoch 38; iter: 400; batch classifier loss: 0.288602; batch adversarial loss: 0.451105\n",
      "epoch 38; iter: 600; batch classifier loss: 0.297655; batch adversarial loss: 0.344827\n",
      "epoch 39; iter: 0; batch classifier loss: 0.282383; batch adversarial loss: 0.638451\n",
      "epoch 39; iter: 200; batch classifier loss: 0.361757; batch adversarial loss: 0.358686\n",
      "epoch 39; iter: 400; batch classifier loss: 0.557271; batch adversarial loss: 0.390284\n",
      "epoch 39; iter: 600; batch classifier loss: 0.350530; batch adversarial loss: 0.343643\n",
      "epoch 40; iter: 0; batch classifier loss: 0.388835; batch adversarial loss: 0.353024\n",
      "epoch 40; iter: 200; batch classifier loss: 0.260790; batch adversarial loss: 0.582887\n",
      "epoch 40; iter: 400; batch classifier loss: 0.512006; batch adversarial loss: 0.352874\n",
      "epoch 40; iter: 600; batch classifier loss: 0.319929; batch adversarial loss: 0.460802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464089; batch adversarial loss: 0.430672\n",
      "epoch 41; iter: 200; batch classifier loss: 0.475259; batch adversarial loss: 0.442539\n",
      "epoch 41; iter: 400; batch classifier loss: 0.332814; batch adversarial loss: 0.458299\n",
      "epoch 41; iter: 600; batch classifier loss: 0.368864; batch adversarial loss: 0.498223\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406096; batch adversarial loss: 0.347891\n",
      "epoch 42; iter: 200; batch classifier loss: 0.387470; batch adversarial loss: 0.458498\n",
      "epoch 42; iter: 400; batch classifier loss: 0.440155; batch adversarial loss: 0.272181\n",
      "epoch 42; iter: 600; batch classifier loss: 0.445794; batch adversarial loss: 0.484450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.312711; batch adversarial loss: 0.504397\n",
      "epoch 43; iter: 200; batch classifier loss: 0.298424; batch adversarial loss: 0.500612\n",
      "epoch 43; iter: 400; batch classifier loss: 0.430820; batch adversarial loss: 0.329954\n",
      "epoch 43; iter: 600; batch classifier loss: 0.376399; batch adversarial loss: 0.264184\n",
      "epoch 44; iter: 0; batch classifier loss: 0.185843; batch adversarial loss: 0.447705\n",
      "epoch 44; iter: 200; batch classifier loss: 0.326939; batch adversarial loss: 0.543067\n",
      "epoch 44; iter: 400; batch classifier loss: 0.374817; batch adversarial loss: 0.374040\n",
      "epoch 44; iter: 600; batch classifier loss: 0.261364; batch adversarial loss: 0.397716\n",
      "epoch 45; iter: 0; batch classifier loss: 0.332609; batch adversarial loss: 0.345019\n",
      "epoch 45; iter: 200; batch classifier loss: 0.393093; batch adversarial loss: 0.346562\n",
      "epoch 45; iter: 400; batch classifier loss: 0.378878; batch adversarial loss: 0.455990\n",
      "epoch 45; iter: 600; batch classifier loss: 0.421356; batch adversarial loss: 0.416133\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444283; batch adversarial loss: 0.405651\n",
      "epoch 46; iter: 200; batch classifier loss: 0.487822; batch adversarial loss: 0.438993\n",
      "epoch 46; iter: 400; batch classifier loss: 0.449960; batch adversarial loss: 0.512975\n",
      "epoch 46; iter: 600; batch classifier loss: 0.515048; batch adversarial loss: 0.418850\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350790; batch adversarial loss: 0.341203\n",
      "epoch 47; iter: 200; batch classifier loss: 0.293210; batch adversarial loss: 0.503705\n",
      "epoch 47; iter: 400; batch classifier loss: 0.682169; batch adversarial loss: 0.535878\n",
      "epoch 47; iter: 600; batch classifier loss: 0.382680; batch adversarial loss: 0.322231\n",
      "epoch 48; iter: 0; batch classifier loss: 0.350332; batch adversarial loss: 0.383822\n",
      "epoch 48; iter: 200; batch classifier loss: 0.322935; batch adversarial loss: 0.371861\n",
      "epoch 48; iter: 400; batch classifier loss: 0.316604; batch adversarial loss: 0.336646\n",
      "epoch 48; iter: 600; batch classifier loss: 0.544158; batch adversarial loss: 0.471910\n",
      "epoch 49; iter: 0; batch classifier loss: 0.537847; batch adversarial loss: 0.443362\n",
      "epoch 49; iter: 200; batch classifier loss: 0.319533; batch adversarial loss: 0.411622\n",
      "epoch 49; iter: 400; batch classifier loss: 0.568778; batch adversarial loss: 0.400758\n",
      "epoch 49; iter: 600; batch classifier loss: 0.296893; batch adversarial loss: 0.385154\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 65.994766; batch adversarial loss: 0.553393\n",
      "epoch 0; iter: 200; batch classifier loss: 9.399185; batch adversarial loss: 0.586793\n",
      "epoch 1; iter: 0; batch classifier loss: 3.945864; batch adversarial loss: 0.564935\n",
      "epoch 1; iter: 200; batch classifier loss: 4.006601; batch adversarial loss: 0.568110\n",
      "epoch 2; iter: 0; batch classifier loss: 6.572489; batch adversarial loss: 0.443211\n",
      "epoch 2; iter: 200; batch classifier loss: 6.274938; batch adversarial loss: 0.494053\n",
      "epoch 3; iter: 0; batch classifier loss: 4.065726; batch adversarial loss: 0.487477\n",
      "epoch 3; iter: 200; batch classifier loss: 3.433251; batch adversarial loss: 0.506957\n",
      "epoch 4; iter: 0; batch classifier loss: 1.794913; batch adversarial loss: 0.470606\n",
      "epoch 4; iter: 200; batch classifier loss: 0.421355; batch adversarial loss: 0.412983\n",
      "epoch 5; iter: 0; batch classifier loss: 0.452606; batch adversarial loss: 0.503505\n",
      "epoch 5; iter: 200; batch classifier loss: 1.338260; batch adversarial loss: 0.454979\n",
      "epoch 6; iter: 0; batch classifier loss: 0.340977; batch adversarial loss: 0.467995\n",
      "epoch 6; iter: 200; batch classifier loss: 0.779021; batch adversarial loss: 0.399848\n",
      "epoch 7; iter: 0; batch classifier loss: 1.009172; batch adversarial loss: 0.356829\n",
      "epoch 7; iter: 200; batch classifier loss: 0.599793; batch adversarial loss: 0.423591\n",
      "epoch 8; iter: 0; batch classifier loss: 0.743870; batch adversarial loss: 0.390524\n",
      "epoch 8; iter: 200; batch classifier loss: 0.594192; batch adversarial loss: 0.411699\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409305; batch adversarial loss: 0.432403\n",
      "epoch 9; iter: 200; batch classifier loss: 0.442931; batch adversarial loss: 0.423608\n",
      "epoch 0; iter: 0; batch classifier loss: 73.325691; batch adversarial loss: 0.663824\n",
      "epoch 0; iter: 200; batch classifier loss: 6.896685; batch adversarial loss: 0.575920\n",
      "epoch 1; iter: 0; batch classifier loss: 1.394907; batch adversarial loss: 0.540229\n",
      "epoch 1; iter: 200; batch classifier loss: 8.526309; batch adversarial loss: 0.561923\n",
      "epoch 2; iter: 0; batch classifier loss: 5.485352; batch adversarial loss: 0.497268\n",
      "epoch 2; iter: 200; batch classifier loss: 0.625091; batch adversarial loss: 0.450131\n",
      "epoch 3; iter: 0; batch classifier loss: 4.262315; batch adversarial loss: 0.492516\n",
      "epoch 3; iter: 200; batch classifier loss: 0.934310; batch adversarial loss: 0.486740\n",
      "epoch 4; iter: 0; batch classifier loss: 1.198657; batch adversarial loss: 0.421351\n",
      "epoch 4; iter: 200; batch classifier loss: 1.245195; batch adversarial loss: 0.351103\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574909; batch adversarial loss: 0.447693\n",
      "epoch 5; iter: 200; batch classifier loss: 0.625637; batch adversarial loss: 0.435834\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559642; batch adversarial loss: 0.435540\n",
      "epoch 6; iter: 200; batch classifier loss: 0.630011; batch adversarial loss: 0.413472\n",
      "epoch 7; iter: 0; batch classifier loss: 0.810434; batch adversarial loss: 0.368444\n",
      "epoch 7; iter: 200; batch classifier loss: 0.798607; batch adversarial loss: 0.412558\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316558; batch adversarial loss: 0.404033\n",
      "epoch 8; iter: 200; batch classifier loss: 0.400435; batch adversarial loss: 0.346690\n",
      "epoch 9; iter: 0; batch classifier loss: 0.702208; batch adversarial loss: 0.357515\n",
      "epoch 9; iter: 200; batch classifier loss: 0.940357; batch adversarial loss: 0.367561\n",
      "epoch 0; iter: 0; batch classifier loss: 7.607571; batch adversarial loss: 1.046687\n",
      "epoch 0; iter: 200; batch classifier loss: 16.623877; batch adversarial loss: 1.131066\n",
      "epoch 1; iter: 0; batch classifier loss: 4.092916; batch adversarial loss: 0.825282\n",
      "epoch 1; iter: 200; batch classifier loss: 3.299756; batch adversarial loss: 0.555089\n",
      "epoch 2; iter: 0; batch classifier loss: 3.625358; batch adversarial loss: 0.636524\n",
      "epoch 2; iter: 200; batch classifier loss: 1.247488; batch adversarial loss: 0.513121\n",
      "epoch 3; iter: 0; batch classifier loss: 2.989921; batch adversarial loss: 0.520096\n",
      "epoch 3; iter: 200; batch classifier loss: 0.761415; batch adversarial loss: 0.492670\n",
      "epoch 4; iter: 0; batch classifier loss: 0.696760; batch adversarial loss: 0.476333\n",
      "epoch 4; iter: 200; batch classifier loss: 1.036159; batch adversarial loss: 0.461428\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563933; batch adversarial loss: 0.471046\n",
      "epoch 5; iter: 200; batch classifier loss: 0.937463; batch adversarial loss: 0.462333\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289029; batch adversarial loss: 0.449488\n",
      "epoch 6; iter: 200; batch classifier loss: 0.596027; batch adversarial loss: 0.416754\n",
      "epoch 7; iter: 0; batch classifier loss: 0.627909; batch adversarial loss: 0.417469\n",
      "epoch 7; iter: 200; batch classifier loss: 0.547624; batch adversarial loss: 0.398612\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633584; batch adversarial loss: 0.416468\n",
      "epoch 8; iter: 200; batch classifier loss: 0.394807; batch adversarial loss: 0.385601\n",
      "epoch 9; iter: 0; batch classifier loss: 0.457131; batch adversarial loss: 0.442591\n",
      "epoch 9; iter: 200; batch classifier loss: 0.463826; batch adversarial loss: 0.400875\n",
      "epoch 0; iter: 0; batch classifier loss: 14.765051; batch adversarial loss: 0.729332\n",
      "epoch 0; iter: 200; batch classifier loss: 6.035885; batch adversarial loss: 0.625299\n",
      "epoch 1; iter: 0; batch classifier loss: 5.790584; batch adversarial loss: 0.576298\n",
      "epoch 1; iter: 200; batch classifier loss: 5.954498; batch adversarial loss: 0.524512\n",
      "epoch 2; iter: 0; batch classifier loss: 7.680091; batch adversarial loss: 0.543458\n",
      "epoch 2; iter: 200; batch classifier loss: 3.798535; batch adversarial loss: 0.496282\n",
      "epoch 3; iter: 0; batch classifier loss: 1.219730; batch adversarial loss: 0.462098\n",
      "epoch 3; iter: 200; batch classifier loss: 1.798635; batch adversarial loss: 0.438375\n",
      "epoch 4; iter: 0; batch classifier loss: 1.413121; batch adversarial loss: 0.393492\n",
      "epoch 4; iter: 200; batch classifier loss: 0.963391; batch adversarial loss: 0.466328\n",
      "epoch 5; iter: 0; batch classifier loss: 0.713382; batch adversarial loss: 0.382846\n",
      "epoch 5; iter: 200; batch classifier loss: 0.523771; batch adversarial loss: 0.412713\n",
      "epoch 6; iter: 0; batch classifier loss: 0.410067; batch adversarial loss: 0.355882\n",
      "epoch 6; iter: 200; batch classifier loss: 0.481537; batch adversarial loss: 0.455223\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338566; batch adversarial loss: 0.398151\n",
      "epoch 7; iter: 200; batch classifier loss: 0.309153; batch adversarial loss: 0.394074\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403616; batch adversarial loss: 0.384095\n",
      "epoch 8; iter: 200; batch classifier loss: 0.261029; batch adversarial loss: 0.530246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486188; batch adversarial loss: 0.390034\n",
      "epoch 9; iter: 200; batch classifier loss: 0.361012; batch adversarial loss: 0.310841\n",
      "epoch 0; iter: 0; batch classifier loss: 8.826897; batch adversarial loss: 0.634734\n",
      "epoch 0; iter: 200; batch classifier loss: 3.629661; batch adversarial loss: 0.602828\n",
      "epoch 1; iter: 0; batch classifier loss: 7.378013; batch adversarial loss: 0.618109\n",
      "epoch 1; iter: 200; batch classifier loss: 2.067228; batch adversarial loss: 0.565591\n",
      "epoch 2; iter: 0; batch classifier loss: 3.571498; batch adversarial loss: 0.491931\n",
      "epoch 2; iter: 200; batch classifier loss: 3.221861; batch adversarial loss: 0.439475\n",
      "epoch 3; iter: 0; batch classifier loss: 1.400002; batch adversarial loss: 0.504921\n",
      "epoch 3; iter: 200; batch classifier loss: 1.280258; batch adversarial loss: 0.400089\n",
      "epoch 4; iter: 0; batch classifier loss: 1.019198; batch adversarial loss: 0.454558\n",
      "epoch 4; iter: 200; batch classifier loss: 0.833570; batch adversarial loss: 0.406434\n",
      "epoch 5; iter: 0; batch classifier loss: 1.268967; batch adversarial loss: 0.431155\n",
      "epoch 5; iter: 200; batch classifier loss: 0.925036; batch adversarial loss: 0.420637\n",
      "epoch 6; iter: 0; batch classifier loss: 0.916038; batch adversarial loss: 0.518288\n",
      "epoch 6; iter: 200; batch classifier loss: 0.376534; batch adversarial loss: 0.435055\n",
      "epoch 7; iter: 0; batch classifier loss: 0.399517; batch adversarial loss: 0.411593\n",
      "epoch 7; iter: 200; batch classifier loss: 0.413537; batch adversarial loss: 0.404271\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404009; batch adversarial loss: 0.391663\n",
      "epoch 8; iter: 200; batch classifier loss: 0.482917; batch adversarial loss: 0.434124\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420647; batch adversarial loss: 0.449420\n",
      "epoch 9; iter: 200; batch classifier loss: 0.364672; batch adversarial loss: 0.398189\n",
      "epoch 0; iter: 0; batch classifier loss: 17.629822; batch adversarial loss: 0.527022\n",
      "epoch 0; iter: 200; batch classifier loss: 3.029066; batch adversarial loss: 0.416178\n",
      "epoch 1; iter: 0; batch classifier loss: 7.774739; batch adversarial loss: 0.568394\n",
      "epoch 1; iter: 200; batch classifier loss: 13.748922; batch adversarial loss: 0.436162\n",
      "epoch 2; iter: 0; batch classifier loss: 6.754182; batch adversarial loss: 0.485810\n",
      "epoch 2; iter: 200; batch classifier loss: 0.799656; batch adversarial loss: 0.475693\n",
      "epoch 3; iter: 0; batch classifier loss: 1.450382; batch adversarial loss: 0.507447\n",
      "epoch 3; iter: 200; batch classifier loss: 9.352787; batch adversarial loss: 0.504704\n",
      "epoch 4; iter: 0; batch classifier loss: 5.256883; batch adversarial loss: 0.443658\n",
      "epoch 4; iter: 200; batch classifier loss: 0.940646; batch adversarial loss: 0.497215\n",
      "epoch 5; iter: 0; batch classifier loss: 0.733730; batch adversarial loss: 0.477947\n",
      "epoch 5; iter: 200; batch classifier loss: 3.704957; batch adversarial loss: 0.412752\n",
      "epoch 6; iter: 0; batch classifier loss: 1.711725; batch adversarial loss: 0.374800\n",
      "epoch 6; iter: 200; batch classifier loss: 0.426835; batch adversarial loss: 0.449921\n",
      "epoch 7; iter: 0; batch classifier loss: 1.054850; batch adversarial loss: 0.466313\n",
      "epoch 7; iter: 200; batch classifier loss: 0.393852; batch adversarial loss: 0.373952\n",
      "epoch 8; iter: 0; batch classifier loss: 0.442831; batch adversarial loss: 0.388252\n",
      "epoch 8; iter: 200; batch classifier loss: 0.529633; batch adversarial loss: 0.411299\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323912; batch adversarial loss: 0.363772\n",
      "epoch 9; iter: 200; batch classifier loss: 0.444693; batch adversarial loss: 0.493843\n",
      "epoch 0; iter: 0; batch classifier loss: 18.248211; batch adversarial loss: 1.805661\n",
      "epoch 0; iter: 200; batch classifier loss: 11.801673; batch adversarial loss: 1.289017\n",
      "epoch 1; iter: 0; batch classifier loss: 7.067408; batch adversarial loss: 1.052710\n",
      "epoch 1; iter: 200; batch classifier loss: 4.908159; batch adversarial loss: 0.722567\n",
      "epoch 2; iter: 0; batch classifier loss: 4.517840; batch adversarial loss: 0.604983\n",
      "epoch 2; iter: 200; batch classifier loss: 3.163388; batch adversarial loss: 0.696007\n",
      "epoch 3; iter: 0; batch classifier loss: 4.484011; batch adversarial loss: 0.604680\n",
      "epoch 3; iter: 200; batch classifier loss: 2.073844; batch adversarial loss: 0.521600\n",
      "epoch 4; iter: 0; batch classifier loss: 2.580900; batch adversarial loss: 0.503252\n",
      "epoch 4; iter: 200; batch classifier loss: 0.551595; batch adversarial loss: 0.487810\n",
      "epoch 5; iter: 0; batch classifier loss: 1.081590; batch adversarial loss: 0.440281\n",
      "epoch 5; iter: 200; batch classifier loss: 2.062801; batch adversarial loss: 0.404479\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473338; batch adversarial loss: 0.431143\n",
      "epoch 6; iter: 200; batch classifier loss: 0.420961; batch adversarial loss: 0.408999\n",
      "epoch 7; iter: 0; batch classifier loss: 0.677585; batch adversarial loss: 0.431582\n",
      "epoch 7; iter: 200; batch classifier loss: 0.373059; batch adversarial loss: 0.436339\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497828; batch adversarial loss: 0.430918\n",
      "epoch 8; iter: 200; batch classifier loss: 0.384470; batch adversarial loss: 0.416287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.358938; batch adversarial loss: 0.427103\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426920; batch adversarial loss: 0.458708\n",
      "epoch 0; iter: 0; batch classifier loss: 65.974937; batch adversarial loss: 0.723401\n",
      "epoch 0; iter: 200; batch classifier loss: 5.016345; batch adversarial loss: 0.664277\n",
      "epoch 1; iter: 0; batch classifier loss: 6.661811; batch adversarial loss: 0.600066\n",
      "epoch 1; iter: 200; batch classifier loss: 5.209915; batch adversarial loss: 0.534174\n",
      "epoch 2; iter: 0; batch classifier loss: 2.255886; batch adversarial loss: 0.455251\n",
      "epoch 2; iter: 200; batch classifier loss: 2.489635; batch adversarial loss: 0.464089\n",
      "epoch 3; iter: 0; batch classifier loss: 2.310575; batch adversarial loss: 0.476774\n",
      "epoch 3; iter: 200; batch classifier loss: 0.988366; batch adversarial loss: 0.530950\n",
      "epoch 4; iter: 0; batch classifier loss: 0.892775; batch adversarial loss: 0.456578\n",
      "epoch 4; iter: 200; batch classifier loss: 0.861790; batch adversarial loss: 0.462319\n",
      "epoch 5; iter: 0; batch classifier loss: 2.285242; batch adversarial loss: 0.420538\n",
      "epoch 5; iter: 200; batch classifier loss: 5.901122; batch adversarial loss: 0.508491\n",
      "epoch 6; iter: 0; batch classifier loss: 2.879712; batch adversarial loss: 0.413944\n",
      "epoch 6; iter: 200; batch classifier loss: 0.759790; batch adversarial loss: 0.413229\n",
      "epoch 7; iter: 0; batch classifier loss: 0.797363; batch adversarial loss: 0.398029\n",
      "epoch 7; iter: 200; batch classifier loss: 0.230725; batch adversarial loss: 0.347048\n",
      "epoch 8; iter: 0; batch classifier loss: 0.761351; batch adversarial loss: 0.475819\n",
      "epoch 8; iter: 200; batch classifier loss: 0.404808; batch adversarial loss: 0.513759\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386616; batch adversarial loss: 0.469262\n",
      "epoch 9; iter: 200; batch classifier loss: 1.125078; batch adversarial loss: 0.358922\n",
      "epoch 0; iter: 0; batch classifier loss: 40.840889; batch adversarial loss: 0.825485\n",
      "epoch 0; iter: 200; batch classifier loss: 9.312447; batch adversarial loss: 0.661217\n",
      "epoch 1; iter: 0; batch classifier loss: 4.785441; batch adversarial loss: 0.636204\n",
      "epoch 1; iter: 200; batch classifier loss: 3.965725; batch adversarial loss: 0.572772\n",
      "epoch 2; iter: 0; batch classifier loss: 5.647179; batch adversarial loss: 0.527885\n",
      "epoch 2; iter: 200; batch classifier loss: 1.913872; batch adversarial loss: 0.502390\n",
      "epoch 3; iter: 0; batch classifier loss: 1.052825; batch adversarial loss: 0.485895\n",
      "epoch 3; iter: 200; batch classifier loss: 1.172310; batch adversarial loss: 0.463468\n",
      "epoch 4; iter: 0; batch classifier loss: 0.920886; batch adversarial loss: 0.429416\n",
      "epoch 4; iter: 200; batch classifier loss: 1.146725; batch adversarial loss: 0.443097\n",
      "epoch 5; iter: 0; batch classifier loss: 0.820374; batch adversarial loss: 0.460866\n",
      "epoch 5; iter: 200; batch classifier loss: 1.737975; batch adversarial loss: 0.476535\n",
      "epoch 6; iter: 0; batch classifier loss: 1.384625; batch adversarial loss: 0.369781\n",
      "epoch 6; iter: 200; batch classifier loss: 0.326433; batch adversarial loss: 0.391001\n",
      "epoch 7; iter: 0; batch classifier loss: 1.443241; batch adversarial loss: 0.403864\n",
      "epoch 7; iter: 200; batch classifier loss: 0.566110; batch adversarial loss: 0.267626\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360666; batch adversarial loss: 0.467666\n",
      "epoch 8; iter: 200; batch classifier loss: 0.439708; batch adversarial loss: 0.448078\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455291; batch adversarial loss: 0.519837\n",
      "epoch 9; iter: 200; batch classifier loss: 0.355673; batch adversarial loss: 0.350188\n",
      "epoch 0; iter: 0; batch classifier loss: 10.097998; batch adversarial loss: 0.515455\n",
      "epoch 0; iter: 200; batch classifier loss: 5.092900; batch adversarial loss: 0.639176\n",
      "epoch 1; iter: 0; batch classifier loss: 13.341194; batch adversarial loss: 0.553360\n",
      "epoch 1; iter: 200; batch classifier loss: 2.624786; batch adversarial loss: 0.535904\n",
      "epoch 2; iter: 0; batch classifier loss: 3.820154; batch adversarial loss: 0.486648\n",
      "epoch 2; iter: 200; batch classifier loss: 5.573781; batch adversarial loss: 0.491933\n",
      "epoch 3; iter: 0; batch classifier loss: 20.269194; batch adversarial loss: 0.521618\n",
      "epoch 3; iter: 200; batch classifier loss: 2.017498; batch adversarial loss: 0.463031\n",
      "epoch 4; iter: 0; batch classifier loss: 0.705246; batch adversarial loss: 0.387183\n",
      "epoch 4; iter: 200; batch classifier loss: 2.752063; batch adversarial loss: 0.404283\n",
      "epoch 5; iter: 0; batch classifier loss: 0.930364; batch adversarial loss: 0.395918\n",
      "epoch 5; iter: 200; batch classifier loss: 0.965562; batch adversarial loss: 0.476345\n",
      "epoch 6; iter: 0; batch classifier loss: 0.470329; batch adversarial loss: 0.420985\n",
      "epoch 6; iter: 200; batch classifier loss: 0.401982; batch adversarial loss: 0.465085\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380476; batch adversarial loss: 0.390889\n",
      "epoch 7; iter: 200; batch classifier loss: 0.381582; batch adversarial loss: 0.479276\n",
      "epoch 8; iter: 0; batch classifier loss: 0.423615; batch adversarial loss: 0.403347\n",
      "epoch 8; iter: 200; batch classifier loss: 0.464236; batch adversarial loss: 0.343961\n",
      "epoch 9; iter: 0; batch classifier loss: 0.433602; batch adversarial loss: 0.342859\n",
      "epoch 9; iter: 200; batch classifier loss: 0.453018; batch adversarial loss: 0.386077\n",
      "epoch 0; iter: 0; batch classifier loss: 27.168121; batch adversarial loss: 0.657614\n",
      "epoch 0; iter: 200; batch classifier loss: 6.767858; batch adversarial loss: 0.561602\n",
      "epoch 1; iter: 0; batch classifier loss: 7.992548; batch adversarial loss: 0.522530\n",
      "epoch 1; iter: 200; batch classifier loss: 1.296112; batch adversarial loss: 0.529723\n",
      "epoch 2; iter: 0; batch classifier loss: 2.081666; batch adversarial loss: 0.514992\n",
      "epoch 2; iter: 200; batch classifier loss: 2.511986; batch adversarial loss: 0.445840\n",
      "epoch 3; iter: 0; batch classifier loss: 0.713923; batch adversarial loss: 0.428231\n",
      "epoch 3; iter: 200; batch classifier loss: 0.765380; batch adversarial loss: 0.503081\n",
      "epoch 4; iter: 0; batch classifier loss: 2.245518; batch adversarial loss: 0.462973\n",
      "epoch 4; iter: 200; batch classifier loss: 0.958582; batch adversarial loss: 0.517581\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616673; batch adversarial loss: 0.342202\n",
      "epoch 5; iter: 200; batch classifier loss: 0.728053; batch adversarial loss: 0.373241\n",
      "epoch 6; iter: 0; batch classifier loss: 0.838724; batch adversarial loss: 0.366953\n",
      "epoch 6; iter: 200; batch classifier loss: 0.600093; batch adversarial loss: 0.456883\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559170; batch adversarial loss: 0.440308\n",
      "epoch 7; iter: 200; batch classifier loss: 0.360496; batch adversarial loss: 0.420275\n",
      "epoch 8; iter: 0; batch classifier loss: 0.677417; batch adversarial loss: 0.458132\n",
      "epoch 8; iter: 200; batch classifier loss: 0.536991; batch adversarial loss: 0.445660\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337031; batch adversarial loss: 0.536395\n",
      "epoch 9; iter: 200; batch classifier loss: 0.265601; batch adversarial loss: 0.433262\n",
      "epoch 0; iter: 0; batch classifier loss: 418.115662; batch adversarial loss: 0.693148\n",
      "epoch 0; iter: 200; batch classifier loss: 13.737103; batch adversarial loss: 0.691736\n",
      "epoch 1; iter: 0; batch classifier loss: 9.589972; batch adversarial loss: 0.622485\n",
      "epoch 1; iter: 200; batch classifier loss: 6.494008; batch adversarial loss: 0.629240\n",
      "epoch 2; iter: 0; batch classifier loss: 5.896327; batch adversarial loss: 0.590018\n",
      "epoch 2; iter: 200; batch classifier loss: 2.277548; batch adversarial loss: 0.505642\n",
      "epoch 3; iter: 0; batch classifier loss: 20.551924; batch adversarial loss: 0.511893\n",
      "epoch 3; iter: 200; batch classifier loss: 3.602189; batch adversarial loss: 0.458726\n",
      "epoch 4; iter: 0; batch classifier loss: 1.690504; batch adversarial loss: 0.437975\n",
      "epoch 4; iter: 200; batch classifier loss: 1.608671; batch adversarial loss: 0.428115\n",
      "epoch 5; iter: 0; batch classifier loss: 1.598239; batch adversarial loss: 0.472869\n",
      "epoch 5; iter: 200; batch classifier loss: 0.494129; batch adversarial loss: 0.496713\n",
      "epoch 6; iter: 0; batch classifier loss: 0.707204; batch adversarial loss: 0.438083\n",
      "epoch 6; iter: 200; batch classifier loss: 2.674397; batch adversarial loss: 0.455579\n",
      "epoch 7; iter: 0; batch classifier loss: 0.992120; batch adversarial loss: 0.411781\n",
      "epoch 7; iter: 200; batch classifier loss: 0.371378; batch adversarial loss: 0.443337\n",
      "epoch 8; iter: 0; batch classifier loss: 0.785102; batch adversarial loss: 0.451505\n",
      "epoch 8; iter: 200; batch classifier loss: 0.964901; batch adversarial loss: 0.422531\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320883; batch adversarial loss: 0.411823\n",
      "epoch 9; iter: 200; batch classifier loss: 0.681467; batch adversarial loss: 0.457499\n",
      "epoch 0; iter: 0; batch classifier loss: 6.104123; batch adversarial loss: 0.694131\n",
      "epoch 0; iter: 200; batch classifier loss: 2.294017; batch adversarial loss: 0.611168\n",
      "epoch 1; iter: 0; batch classifier loss: 6.404629; batch adversarial loss: 0.553458\n",
      "epoch 1; iter: 200; batch classifier loss: 7.616035; batch adversarial loss: 0.549566\n",
      "epoch 2; iter: 0; batch classifier loss: 7.531919; batch adversarial loss: 0.537159\n",
      "epoch 2; iter: 200; batch classifier loss: 4.634574; batch adversarial loss: 0.468970\n",
      "epoch 3; iter: 0; batch classifier loss: 1.887518; batch adversarial loss: 0.439176\n",
      "epoch 3; iter: 200; batch classifier loss: 1.389030; batch adversarial loss: 0.440029\n",
      "epoch 4; iter: 0; batch classifier loss: 1.436420; batch adversarial loss: 0.402671\n",
      "epoch 4; iter: 200; batch classifier loss: 1.098763; batch adversarial loss: 0.389460\n",
      "epoch 5; iter: 0; batch classifier loss: 0.820324; batch adversarial loss: 0.504252\n",
      "epoch 5; iter: 200; batch classifier loss: 0.879343; batch adversarial loss: 0.350449\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607517; batch adversarial loss: 0.468535\n",
      "epoch 6; iter: 200; batch classifier loss: 0.522563; batch adversarial loss: 0.497021\n",
      "epoch 7; iter: 0; batch classifier loss: 0.762784; batch adversarial loss: 0.418056\n",
      "epoch 7; iter: 200; batch classifier loss: 0.594109; batch adversarial loss: 0.481065\n",
      "epoch 8; iter: 0; batch classifier loss: 0.439605; batch adversarial loss: 0.414961\n",
      "epoch 8; iter: 200; batch classifier loss: 0.731329; batch adversarial loss: 0.416618\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418140; batch adversarial loss: 0.470333\n",
      "epoch 9; iter: 200; batch classifier loss: 0.466771; batch adversarial loss: 0.331963\n",
      "epoch 0; iter: 0; batch classifier loss: 11.236151; batch adversarial loss: 0.697642\n",
      "epoch 0; iter: 200; batch classifier loss: 5.292137; batch adversarial loss: 0.613770\n",
      "epoch 1; iter: 0; batch classifier loss: 5.724241; batch adversarial loss: 0.583414\n",
      "epoch 1; iter: 200; batch classifier loss: 9.168440; batch adversarial loss: 0.574297\n",
      "epoch 2; iter: 0; batch classifier loss: 2.844088; batch adversarial loss: 0.549295\n",
      "epoch 2; iter: 200; batch classifier loss: 9.632612; batch adversarial loss: 0.455572\n",
      "epoch 3; iter: 0; batch classifier loss: 0.858458; batch adversarial loss: 0.548838\n",
      "epoch 3; iter: 200; batch classifier loss: 7.549752; batch adversarial loss: 0.395566\n",
      "epoch 4; iter: 0; batch classifier loss: 1.488797; batch adversarial loss: 0.438480\n",
      "epoch 4; iter: 200; batch classifier loss: 0.597002; batch adversarial loss: 0.485820\n",
      "epoch 5; iter: 0; batch classifier loss: 1.728173; batch adversarial loss: 0.421349\n",
      "epoch 5; iter: 200; batch classifier loss: 0.426723; batch adversarial loss: 0.516755\n",
      "epoch 6; iter: 0; batch classifier loss: 0.348968; batch adversarial loss: 0.535397\n",
      "epoch 6; iter: 200; batch classifier loss: 0.457259; batch adversarial loss: 0.400941\n",
      "epoch 7; iter: 0; batch classifier loss: 0.540380; batch adversarial loss: 0.451404\n",
      "epoch 7; iter: 200; batch classifier loss: 0.904534; batch adversarial loss: 0.439297\n",
      "epoch 8; iter: 0; batch classifier loss: 0.877229; batch adversarial loss: 0.445410\n",
      "epoch 8; iter: 200; batch classifier loss: 0.378140; batch adversarial loss: 0.426272\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418045; batch adversarial loss: 0.408204\n",
      "epoch 9; iter: 200; batch classifier loss: 0.472187; batch adversarial loss: 0.535624\n",
      "epoch 0; iter: 0; batch classifier loss: 252.709747; batch adversarial loss: 0.691089\n",
      "epoch 0; iter: 200; batch classifier loss: 11.803235; batch adversarial loss: 0.611882\n",
      "epoch 1; iter: 0; batch classifier loss: 3.192975; batch adversarial loss: 0.570291\n",
      "epoch 1; iter: 200; batch classifier loss: 2.849885; batch adversarial loss: 0.528792\n",
      "epoch 2; iter: 0; batch classifier loss: 4.041474; batch adversarial loss: 0.514634\n",
      "epoch 2; iter: 200; batch classifier loss: 0.699528; batch adversarial loss: 0.480739\n",
      "epoch 3; iter: 0; batch classifier loss: 6.567974; batch adversarial loss: 0.482577\n",
      "epoch 3; iter: 200; batch classifier loss: 2.073699; batch adversarial loss: 0.450986\n",
      "epoch 4; iter: 0; batch classifier loss: 1.651576; batch adversarial loss: 0.459235\n",
      "epoch 4; iter: 200; batch classifier loss: 3.117503; batch adversarial loss: 0.443022\n",
      "epoch 5; iter: 0; batch classifier loss: 3.546478; batch adversarial loss: 0.461400\n",
      "epoch 5; iter: 200; batch classifier loss: 0.414424; batch adversarial loss: 0.357065\n",
      "epoch 6; iter: 0; batch classifier loss: 0.643897; batch adversarial loss: 0.421290\n",
      "epoch 6; iter: 200; batch classifier loss: 0.475395; batch adversarial loss: 0.400912\n",
      "epoch 7; iter: 0; batch classifier loss: 0.746093; batch adversarial loss: 0.409765\n",
      "epoch 7; iter: 200; batch classifier loss: 0.700833; batch adversarial loss: 0.532230\n",
      "epoch 8; iter: 0; batch classifier loss: 0.641600; batch adversarial loss: 0.378740\n",
      "epoch 8; iter: 200; batch classifier loss: 0.606381; batch adversarial loss: 0.352886\n",
      "epoch 9; iter: 0; batch classifier loss: 0.717953; batch adversarial loss: 0.410791\n",
      "epoch 9; iter: 200; batch classifier loss: 0.382050; batch adversarial loss: 0.444804\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 7.815549; batch adversarial loss: 0.678846\n",
      "epoch 0; iter: 200; batch classifier loss: 4.991156; batch adversarial loss: 0.635943\n",
      "epoch 1; iter: 0; batch classifier loss: 7.240269; batch adversarial loss: 0.546825\n",
      "epoch 1; iter: 200; batch classifier loss: 5.170500; batch adversarial loss: 0.526909\n",
      "epoch 2; iter: 0; batch classifier loss: 2.182665; batch adversarial loss: 0.545993\n",
      "epoch 2; iter: 200; batch classifier loss: 2.374322; batch adversarial loss: 0.495198\n",
      "epoch 3; iter: 0; batch classifier loss: 2.035366; batch adversarial loss: 0.468869\n",
      "epoch 3; iter: 200; batch classifier loss: 2.377595; batch adversarial loss: 0.476955\n",
      "epoch 4; iter: 0; batch classifier loss: 0.722328; batch adversarial loss: 0.489579\n",
      "epoch 4; iter: 200; batch classifier loss: 0.326453; batch adversarial loss: 0.419176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.720345; batch adversarial loss: 0.450534\n",
      "epoch 5; iter: 200; batch classifier loss: 0.688282; batch adversarial loss: 0.535081\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364930; batch adversarial loss: 0.438472\n",
      "epoch 6; iter: 200; batch classifier loss: 1.798024; batch adversarial loss: 0.436006\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510140; batch adversarial loss: 0.464735\n",
      "epoch 7; iter: 200; batch classifier loss: 0.386908; batch adversarial loss: 0.430259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421349; batch adversarial loss: 0.474110\n",
      "epoch 8; iter: 200; batch classifier loss: 0.358288; batch adversarial loss: 0.402122\n",
      "epoch 9; iter: 0; batch classifier loss: 0.422289; batch adversarial loss: 0.519355\n",
      "epoch 9; iter: 200; batch classifier loss: 0.637289; batch adversarial loss: 0.461748\n",
      "epoch 10; iter: 0; batch classifier loss: 0.353640; batch adversarial loss: 0.382238\n",
      "epoch 10; iter: 200; batch classifier loss: 0.346411; batch adversarial loss: 0.398547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308025; batch adversarial loss: 0.432567\n",
      "epoch 11; iter: 200; batch classifier loss: 0.439678; batch adversarial loss: 0.455894\n",
      "epoch 12; iter: 0; batch classifier loss: 0.693295; batch adversarial loss: 0.365640\n",
      "epoch 12; iter: 200; batch classifier loss: 0.496720; batch adversarial loss: 0.354094\n",
      "epoch 13; iter: 0; batch classifier loss: 0.435180; batch adversarial loss: 0.467625\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352483; batch adversarial loss: 0.390873\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342279; batch adversarial loss: 0.442690\n",
      "epoch 14; iter: 200; batch classifier loss: 0.283976; batch adversarial loss: 0.414556\n",
      "epoch 15; iter: 0; batch classifier loss: 0.810817; batch adversarial loss: 0.415426\n",
      "epoch 15; iter: 200; batch classifier loss: 0.480562; batch adversarial loss: 0.522440\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362560; batch adversarial loss: 0.437051\n",
      "epoch 16; iter: 200; batch classifier loss: 0.362449; batch adversarial loss: 0.393170\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348342; batch adversarial loss: 0.416247\n",
      "epoch 17; iter: 200; batch classifier loss: 0.451696; batch adversarial loss: 0.535069\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300265; batch adversarial loss: 0.429620\n",
      "epoch 18; iter: 200; batch classifier loss: 0.368601; batch adversarial loss: 0.309362\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378556; batch adversarial loss: 0.435787\n",
      "epoch 19; iter: 200; batch classifier loss: 0.425587; batch adversarial loss: 0.520689\n",
      "epoch 0; iter: 0; batch classifier loss: 18.793549; batch adversarial loss: 0.629593\n",
      "epoch 0; iter: 200; batch classifier loss: 4.324569; batch adversarial loss: 0.631028\n",
      "epoch 1; iter: 0; batch classifier loss: 8.576763; batch adversarial loss: 0.587242\n",
      "epoch 1; iter: 200; batch classifier loss: 8.081535; batch adversarial loss: 0.559793\n",
      "epoch 2; iter: 0; batch classifier loss: 7.369259; batch adversarial loss: 0.414698\n",
      "epoch 2; iter: 200; batch classifier loss: 1.150685; batch adversarial loss: 0.459842\n",
      "epoch 3; iter: 0; batch classifier loss: 1.748049; batch adversarial loss: 0.450992\n",
      "epoch 3; iter: 200; batch classifier loss: 1.551820; batch adversarial loss: 0.356973\n",
      "epoch 4; iter: 0; batch classifier loss: 2.016084; batch adversarial loss: 0.396496\n",
      "epoch 4; iter: 200; batch classifier loss: 1.777743; batch adversarial loss: 0.459326\n",
      "epoch 5; iter: 0; batch classifier loss: 1.259814; batch adversarial loss: 0.368791\n",
      "epoch 5; iter: 200; batch classifier loss: 0.288913; batch adversarial loss: 0.479956\n",
      "epoch 6; iter: 0; batch classifier loss: 0.448796; batch adversarial loss: 0.348481\n",
      "epoch 6; iter: 200; batch classifier loss: 0.511939; batch adversarial loss: 0.431959\n",
      "epoch 7; iter: 0; batch classifier loss: 0.710601; batch adversarial loss: 0.509645\n",
      "epoch 7; iter: 200; batch classifier loss: 0.470926; batch adversarial loss: 0.388651\n",
      "epoch 8; iter: 0; batch classifier loss: 1.028413; batch adversarial loss: 0.350677\n",
      "epoch 8; iter: 200; batch classifier loss: 0.549255; batch adversarial loss: 0.433047\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601697; batch adversarial loss: 0.458389\n",
      "epoch 9; iter: 200; batch classifier loss: 0.520915; batch adversarial loss: 0.484019\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484953; batch adversarial loss: 0.431384\n",
      "epoch 10; iter: 200; batch classifier loss: 0.338270; batch adversarial loss: 0.502430\n",
      "epoch 11; iter: 0; batch classifier loss: 0.395563; batch adversarial loss: 0.482447\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449282; batch adversarial loss: 0.401297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379947; batch adversarial loss: 0.531842\n",
      "epoch 12; iter: 200; batch classifier loss: 0.757107; batch adversarial loss: 0.475759\n",
      "epoch 13; iter: 0; batch classifier loss: 0.426231; batch adversarial loss: 0.518542\n",
      "epoch 13; iter: 200; batch classifier loss: 0.621656; batch adversarial loss: 0.412723\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344785; batch adversarial loss: 0.380540\n",
      "epoch 14; iter: 200; batch classifier loss: 0.340523; batch adversarial loss: 0.373880\n",
      "epoch 15; iter: 0; batch classifier loss: 0.290415; batch adversarial loss: 0.499422\n",
      "epoch 15; iter: 200; batch classifier loss: 0.349899; batch adversarial loss: 0.418383\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371266; batch adversarial loss: 0.431201\n",
      "epoch 16; iter: 200; batch classifier loss: 0.372041; batch adversarial loss: 0.401537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345500; batch adversarial loss: 0.404160\n",
      "epoch 17; iter: 200; batch classifier loss: 0.330881; batch adversarial loss: 0.457503\n",
      "epoch 18; iter: 0; batch classifier loss: 0.425023; batch adversarial loss: 0.463851\n",
      "epoch 18; iter: 200; batch classifier loss: 0.313547; batch adversarial loss: 0.445933\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313429; batch adversarial loss: 0.416493\n",
      "epoch 19; iter: 200; batch classifier loss: 0.348727; batch adversarial loss: 0.391438\n",
      "epoch 0; iter: 0; batch classifier loss: 22.542295; batch adversarial loss: 0.603569\n",
      "epoch 0; iter: 200; batch classifier loss: 6.176008; batch adversarial loss: 0.612568\n",
      "epoch 1; iter: 0; batch classifier loss: 8.897175; batch adversarial loss: 0.551916\n",
      "epoch 1; iter: 200; batch classifier loss: 6.862838; batch adversarial loss: 0.545109\n",
      "epoch 2; iter: 0; batch classifier loss: 6.169211; batch adversarial loss: 0.405864\n",
      "epoch 2; iter: 200; batch classifier loss: 1.399448; batch adversarial loss: 0.463880\n",
      "epoch 3; iter: 0; batch classifier loss: 2.152237; batch adversarial loss: 0.381398\n",
      "epoch 3; iter: 200; batch classifier loss: 1.827482; batch adversarial loss: 0.376484\n",
      "epoch 4; iter: 0; batch classifier loss: 1.954796; batch adversarial loss: 0.414723\n",
      "epoch 4; iter: 200; batch classifier loss: 3.803893; batch adversarial loss: 0.429884\n",
      "epoch 5; iter: 0; batch classifier loss: 0.974290; batch adversarial loss: 0.361264\n",
      "epoch 5; iter: 200; batch classifier loss: 1.100318; batch adversarial loss: 0.366630\n",
      "epoch 6; iter: 0; batch classifier loss: 1.575764; batch adversarial loss: 0.414495\n",
      "epoch 6; iter: 200; batch classifier loss: 0.530284; batch adversarial loss: 0.470920\n",
      "epoch 7; iter: 0; batch classifier loss: 0.546940; batch adversarial loss: 0.396272\n",
      "epoch 7; iter: 200; batch classifier loss: 0.624078; batch adversarial loss: 0.407332\n",
      "epoch 8; iter: 0; batch classifier loss: 0.645369; batch adversarial loss: 0.379995\n",
      "epoch 8; iter: 200; batch classifier loss: 0.301712; batch adversarial loss: 0.411644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332911; batch adversarial loss: 0.423288\n",
      "epoch 9; iter: 200; batch classifier loss: 0.331487; batch adversarial loss: 0.433953\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434609; batch adversarial loss: 0.409776\n",
      "epoch 10; iter: 200; batch classifier loss: 0.336252; batch adversarial loss: 0.575415\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574993; batch adversarial loss: 0.336645\n",
      "epoch 11; iter: 200; batch classifier loss: 0.573852; batch adversarial loss: 0.475271\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478512; batch adversarial loss: 0.457087\n",
      "epoch 12; iter: 200; batch classifier loss: 0.338331; batch adversarial loss: 0.484841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380799; batch adversarial loss: 0.378893\n",
      "epoch 13; iter: 200; batch classifier loss: 0.872675; batch adversarial loss: 0.456233\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389859; batch adversarial loss: 0.396243\n",
      "epoch 14; iter: 200; batch classifier loss: 0.365679; batch adversarial loss: 0.391909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432295; batch adversarial loss: 0.413995\n",
      "epoch 15; iter: 200; batch classifier loss: 0.416099; batch adversarial loss: 0.450577\n",
      "epoch 16; iter: 0; batch classifier loss: 0.479290; batch adversarial loss: 0.389897\n",
      "epoch 16; iter: 200; batch classifier loss: 0.336670; batch adversarial loss: 0.383958\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353386; batch adversarial loss: 0.478925\n",
      "epoch 17; iter: 200; batch classifier loss: 0.293363; batch adversarial loss: 0.346846\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302086; batch adversarial loss: 0.442478\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399895; batch adversarial loss: 0.373551\n",
      "epoch 19; iter: 0; batch classifier loss: 0.318576; batch adversarial loss: 0.402814\n",
      "epoch 19; iter: 200; batch classifier loss: 0.319083; batch adversarial loss: 0.452748\n",
      "epoch 0; iter: 0; batch classifier loss: 18.319378; batch adversarial loss: 0.678908\n",
      "epoch 0; iter: 200; batch classifier loss: 33.188000; batch adversarial loss: 0.609546\n",
      "epoch 1; iter: 0; batch classifier loss: 7.732013; batch adversarial loss: 0.580743\n",
      "epoch 1; iter: 200; batch classifier loss: 3.195050; batch adversarial loss: 0.553515\n",
      "epoch 2; iter: 0; batch classifier loss: 0.750732; batch adversarial loss: 0.548813\n",
      "epoch 2; iter: 200; batch classifier loss: 1.363093; batch adversarial loss: 0.488471\n",
      "epoch 3; iter: 0; batch classifier loss: 3.534253; batch adversarial loss: 0.485813\n",
      "epoch 3; iter: 200; batch classifier loss: 2.280111; batch adversarial loss: 0.485301\n",
      "epoch 4; iter: 0; batch classifier loss: 1.279851; batch adversarial loss: 0.468008\n",
      "epoch 4; iter: 200; batch classifier loss: 7.902401; batch adversarial loss: 0.407560\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593336; batch adversarial loss: 0.450543\n",
      "epoch 5; iter: 200; batch classifier loss: 0.817786; batch adversarial loss: 0.460851\n",
      "epoch 6; iter: 0; batch classifier loss: 0.727337; batch adversarial loss: 0.380919\n",
      "epoch 6; iter: 200; batch classifier loss: 0.325729; batch adversarial loss: 0.373285\n",
      "epoch 7; iter: 0; batch classifier loss: 0.690149; batch adversarial loss: 0.460976\n",
      "epoch 7; iter: 200; batch classifier loss: 0.403892; batch adversarial loss: 0.454216\n",
      "epoch 8; iter: 0; batch classifier loss: 0.443062; batch adversarial loss: 0.595835\n",
      "epoch 8; iter: 200; batch classifier loss: 0.331374; batch adversarial loss: 0.376228\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390273; batch adversarial loss: 0.388733\n",
      "epoch 9; iter: 200; batch classifier loss: 1.013335; batch adversarial loss: 0.330700\n",
      "epoch 10; iter: 0; batch classifier loss: 0.402446; batch adversarial loss: 0.367360\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420775; batch adversarial loss: 0.419216\n",
      "epoch 11; iter: 0; batch classifier loss: 0.421704; batch adversarial loss: 0.441543\n",
      "epoch 11; iter: 200; batch classifier loss: 0.427921; batch adversarial loss: 0.426929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553059; batch adversarial loss: 0.512694\n",
      "epoch 12; iter: 200; batch classifier loss: 0.401563; batch adversarial loss: 0.442923\n",
      "epoch 13; iter: 0; batch classifier loss: 0.352696; batch adversarial loss: 0.402701\n",
      "epoch 13; iter: 200; batch classifier loss: 0.344476; batch adversarial loss: 0.521405\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298597; batch adversarial loss: 0.472503\n",
      "epoch 14; iter: 200; batch classifier loss: 0.365644; batch adversarial loss: 0.441818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386731; batch adversarial loss: 0.387242\n",
      "epoch 15; iter: 200; batch classifier loss: 0.286509; batch adversarial loss: 0.428800\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380610; batch adversarial loss: 0.397877\n",
      "epoch 16; iter: 200; batch classifier loss: 0.372456; batch adversarial loss: 0.431379\n",
      "epoch 17; iter: 0; batch classifier loss: 0.341673; batch adversarial loss: 0.561286\n",
      "epoch 17; iter: 200; batch classifier loss: 0.406220; batch adversarial loss: 0.418280\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266883; batch adversarial loss: 0.316439\n",
      "epoch 18; iter: 200; batch classifier loss: 0.301611; batch adversarial loss: 0.356179\n",
      "epoch 19; iter: 0; batch classifier loss: 0.351148; batch adversarial loss: 0.451001\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346497; batch adversarial loss: 0.388752\n",
      "epoch 0; iter: 0; batch classifier loss: 13.222586; batch adversarial loss: 1.238887\n",
      "epoch 0; iter: 200; batch classifier loss: 7.386594; batch adversarial loss: 0.646497\n",
      "epoch 1; iter: 0; batch classifier loss: 3.784731; batch adversarial loss: 0.887034\n",
      "epoch 1; iter: 200; batch classifier loss: 5.133112; batch adversarial loss: 0.580748\n",
      "epoch 2; iter: 0; batch classifier loss: 3.812489; batch adversarial loss: 0.621912\n",
      "epoch 2; iter: 200; batch classifier loss: 1.718055; batch adversarial loss: 0.540919\n",
      "epoch 3; iter: 0; batch classifier loss: 1.724510; batch adversarial loss: 0.504706\n",
      "epoch 3; iter: 200; batch classifier loss: 2.249419; batch adversarial loss: 0.526617\n",
      "epoch 4; iter: 0; batch classifier loss: 7.878703; batch adversarial loss: 0.514268\n",
      "epoch 4; iter: 200; batch classifier loss: 0.582887; batch adversarial loss: 0.463773\n",
      "epoch 5; iter: 0; batch classifier loss: 0.818433; batch adversarial loss: 0.383931\n",
      "epoch 5; iter: 200; batch classifier loss: 1.315047; batch adversarial loss: 0.455802\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579229; batch adversarial loss: 0.410418\n",
      "epoch 6; iter: 200; batch classifier loss: 0.843949; batch adversarial loss: 0.396307\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568177; batch adversarial loss: 0.454589\n",
      "epoch 7; iter: 200; batch classifier loss: 0.540778; batch adversarial loss: 0.414528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.659568; batch adversarial loss: 0.427548\n",
      "epoch 8; iter: 200; batch classifier loss: 0.453766; batch adversarial loss: 0.369558\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578880; batch adversarial loss: 0.484392\n",
      "epoch 9; iter: 200; batch classifier loss: 0.597653; batch adversarial loss: 0.517145\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305270; batch adversarial loss: 0.467107\n",
      "epoch 10; iter: 200; batch classifier loss: 0.400372; batch adversarial loss: 0.384811\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567789; batch adversarial loss: 0.419797\n",
      "epoch 11; iter: 200; batch classifier loss: 0.420413; batch adversarial loss: 0.464712\n",
      "epoch 12; iter: 0; batch classifier loss: 0.301379; batch adversarial loss: 0.456927\n",
      "epoch 12; iter: 200; batch classifier loss: 0.423885; batch adversarial loss: 0.408625\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484164; batch adversarial loss: 0.528440\n",
      "epoch 13; iter: 200; batch classifier loss: 0.436658; batch adversarial loss: 0.391371\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506941; batch adversarial loss: 0.428982\n",
      "epoch 14; iter: 200; batch classifier loss: 0.385840; batch adversarial loss: 0.381925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538725; batch adversarial loss: 0.487776\n",
      "epoch 15; iter: 200; batch classifier loss: 0.355633; batch adversarial loss: 0.452893\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379033; batch adversarial loss: 0.487565\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380639; batch adversarial loss: 0.456235\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367479; batch adversarial loss: 0.556628\n",
      "epoch 17; iter: 200; batch classifier loss: 0.447418; batch adversarial loss: 0.472256\n",
      "epoch 18; iter: 0; batch classifier loss: 0.388397; batch adversarial loss: 0.383017\n",
      "epoch 18; iter: 200; batch classifier loss: 0.335510; batch adversarial loss: 0.329487\n",
      "epoch 19; iter: 0; batch classifier loss: 0.405205; batch adversarial loss: 0.483060\n",
      "epoch 19; iter: 200; batch classifier loss: 0.406712; batch adversarial loss: 0.438878\n",
      "epoch 0; iter: 0; batch classifier loss: 11.927237; batch adversarial loss: 0.816701\n",
      "epoch 0; iter: 200; batch classifier loss: 5.577290; batch adversarial loss: 0.634509\n",
      "epoch 1; iter: 0; batch classifier loss: 3.384220; batch adversarial loss: 0.598792\n",
      "epoch 1; iter: 200; batch classifier loss: 4.550662; batch adversarial loss: 0.540098\n",
      "epoch 2; iter: 0; batch classifier loss: 7.203709; batch adversarial loss: 0.525055\n",
      "epoch 2; iter: 200; batch classifier loss: 1.366568; batch adversarial loss: 0.512296\n",
      "epoch 3; iter: 0; batch classifier loss: 0.780625; batch adversarial loss: 0.493448\n",
      "epoch 3; iter: 200; batch classifier loss: 2.534186; batch adversarial loss: 0.427790\n",
      "epoch 4; iter: 0; batch classifier loss: 1.596751; batch adversarial loss: 0.450584\n",
      "epoch 4; iter: 200; batch classifier loss: 0.861399; batch adversarial loss: 0.403751\n",
      "epoch 5; iter: 0; batch classifier loss: 1.986436; batch adversarial loss: 0.414124\n",
      "epoch 5; iter: 200; batch classifier loss: 0.514786; batch adversarial loss: 0.422485\n",
      "epoch 6; iter: 0; batch classifier loss: 0.426707; batch adversarial loss: 0.415315\n",
      "epoch 6; iter: 200; batch classifier loss: 0.309847; batch adversarial loss: 0.335543\n",
      "epoch 7; iter: 0; batch classifier loss: 0.464744; batch adversarial loss: 0.390110\n",
      "epoch 7; iter: 200; batch classifier loss: 0.517144; batch adversarial loss: 0.431986\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504647; batch adversarial loss: 0.415623\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452632; batch adversarial loss: 0.366930\n",
      "epoch 9; iter: 0; batch classifier loss: 0.498806; batch adversarial loss: 0.422221\n",
      "epoch 9; iter: 200; batch classifier loss: 0.350142; batch adversarial loss: 0.378102\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367535; batch adversarial loss: 0.415702\n",
      "epoch 10; iter: 200; batch classifier loss: 0.602686; batch adversarial loss: 0.401030\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404585; batch adversarial loss: 0.440628\n",
      "epoch 11; iter: 200; batch classifier loss: 0.361104; batch adversarial loss: 0.382191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304727; batch adversarial loss: 0.459448\n",
      "epoch 12; iter: 200; batch classifier loss: 0.378879; batch adversarial loss: 0.382727\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477149; batch adversarial loss: 0.373493\n",
      "epoch 13; iter: 200; batch classifier loss: 0.459263; batch adversarial loss: 0.370019\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517253; batch adversarial loss: 0.351838\n",
      "epoch 14; iter: 200; batch classifier loss: 0.384391; batch adversarial loss: 0.479708\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390133; batch adversarial loss: 0.384474\n",
      "epoch 15; iter: 200; batch classifier loss: 0.420895; batch adversarial loss: 0.327863\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347959; batch adversarial loss: 0.494586\n",
      "epoch 16; iter: 200; batch classifier loss: 0.381095; batch adversarial loss: 0.381467\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345490; batch adversarial loss: 0.284896\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341113; batch adversarial loss: 0.427672\n",
      "epoch 18; iter: 0; batch classifier loss: 0.406785; batch adversarial loss: 0.377860\n",
      "epoch 18; iter: 200; batch classifier loss: 0.316551; batch adversarial loss: 0.435153\n",
      "epoch 19; iter: 0; batch classifier loss: 0.339980; batch adversarial loss: 0.403057\n",
      "epoch 19; iter: 200; batch classifier loss: 0.302878; batch adversarial loss: 0.371248\n",
      "epoch 0; iter: 0; batch classifier loss: 22.701862; batch adversarial loss: 0.929486\n",
      "epoch 0; iter: 200; batch classifier loss: 9.559292; batch adversarial loss: 0.652759\n",
      "epoch 1; iter: 0; batch classifier loss: 7.118333; batch adversarial loss: 0.647776\n",
      "epoch 1; iter: 200; batch classifier loss: 5.217632; batch adversarial loss: 0.543589\n",
      "epoch 2; iter: 0; batch classifier loss: 3.723247; batch adversarial loss: 0.549172\n",
      "epoch 2; iter: 200; batch classifier loss: 8.805166; batch adversarial loss: 0.514138\n",
      "epoch 3; iter: 0; batch classifier loss: 2.540089; batch adversarial loss: 0.474997\n",
      "epoch 3; iter: 200; batch classifier loss: 10.257328; batch adversarial loss: 0.445892\n",
      "epoch 4; iter: 0; batch classifier loss: 0.989454; batch adversarial loss: 0.453493\n",
      "epoch 4; iter: 200; batch classifier loss: 1.277793; batch adversarial loss: 0.408229\n",
      "epoch 5; iter: 0; batch classifier loss: 1.327808; batch adversarial loss: 0.378705\n",
      "epoch 5; iter: 200; batch classifier loss: 1.790637; batch adversarial loss: 0.436490\n",
      "epoch 6; iter: 0; batch classifier loss: 0.422228; batch adversarial loss: 0.450283\n",
      "epoch 6; iter: 200; batch classifier loss: 0.893858; batch adversarial loss: 0.463134\n",
      "epoch 7; iter: 0; batch classifier loss: 1.603992; batch adversarial loss: 0.391184\n",
      "epoch 7; iter: 200; batch classifier loss: 0.461096; batch adversarial loss: 0.457886\n",
      "epoch 8; iter: 0; batch classifier loss: 0.347436; batch adversarial loss: 0.442751\n",
      "epoch 8; iter: 200; batch classifier loss: 4.019087; batch adversarial loss: 0.359962\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383889; batch adversarial loss: 0.431510\n",
      "epoch 9; iter: 200; batch classifier loss: 0.427831; batch adversarial loss: 0.497512\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503235; batch adversarial loss: 0.401910\n",
      "epoch 10; iter: 200; batch classifier loss: 0.368950; batch adversarial loss: 0.448310\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412908; batch adversarial loss: 0.291861\n",
      "epoch 11; iter: 200; batch classifier loss: 0.437659; batch adversarial loss: 0.458053\n",
      "epoch 12; iter: 0; batch classifier loss: 0.473131; batch adversarial loss: 0.430478\n",
      "epoch 12; iter: 200; batch classifier loss: 0.360495; batch adversarial loss: 0.451617\n",
      "epoch 13; iter: 0; batch classifier loss: 0.314704; batch adversarial loss: 0.301080\n",
      "epoch 13; iter: 200; batch classifier loss: 0.361620; batch adversarial loss: 0.464457\n",
      "epoch 14; iter: 0; batch classifier loss: 0.388228; batch adversarial loss: 0.307746\n",
      "epoch 14; iter: 200; batch classifier loss: 0.469034; batch adversarial loss: 0.483030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446402; batch adversarial loss: 0.352035\n",
      "epoch 15; iter: 200; batch classifier loss: 0.302245; batch adversarial loss: 0.447718\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413358; batch adversarial loss: 0.452219\n",
      "epoch 16; iter: 200; batch classifier loss: 0.393233; batch adversarial loss: 0.437620\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337055; batch adversarial loss: 0.395472\n",
      "epoch 17; iter: 200; batch classifier loss: 0.350144; batch adversarial loss: 0.460924\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323332; batch adversarial loss: 0.477568\n",
      "epoch 18; iter: 200; batch classifier loss: 0.344353; batch adversarial loss: 0.453375\n",
      "epoch 19; iter: 0; batch classifier loss: 0.318726; batch adversarial loss: 0.474184\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347515; batch adversarial loss: 0.275655\n",
      "epoch 0; iter: 0; batch classifier loss: 18.821293; batch adversarial loss: 0.733390\n",
      "epoch 0; iter: 200; batch classifier loss: 2.999920; batch adversarial loss: 0.724900\n",
      "epoch 1; iter: 0; batch classifier loss: 1.433273; batch adversarial loss: 0.599414\n",
      "epoch 1; iter: 200; batch classifier loss: 6.695065; batch adversarial loss: 0.593339\n",
      "epoch 2; iter: 0; batch classifier loss: 9.474318; batch adversarial loss: 0.543699\n",
      "epoch 2; iter: 200; batch classifier loss: 1.827415; batch adversarial loss: 0.544276\n",
      "epoch 3; iter: 0; batch classifier loss: 5.444902; batch adversarial loss: 0.509838\n",
      "epoch 3; iter: 200; batch classifier loss: 0.790099; batch adversarial loss: 0.539968\n",
      "epoch 4; iter: 0; batch classifier loss: 1.115734; batch adversarial loss: 0.456109\n",
      "epoch 4; iter: 200; batch classifier loss: 0.480671; batch adversarial loss: 0.484957\n",
      "epoch 5; iter: 0; batch classifier loss: 6.774117; batch adversarial loss: 0.448555\n",
      "epoch 5; iter: 200; batch classifier loss: 1.494853; batch adversarial loss: 0.484578\n",
      "epoch 6; iter: 0; batch classifier loss: 1.761218; batch adversarial loss: 0.461043\n",
      "epoch 6; iter: 200; batch classifier loss: 0.750491; batch adversarial loss: 0.454589\n",
      "epoch 7; iter: 0; batch classifier loss: 0.684197; batch adversarial loss: 0.452467\n",
      "epoch 7; iter: 200; batch classifier loss: 0.757821; batch adversarial loss: 0.434605\n",
      "epoch 8; iter: 0; batch classifier loss: 0.725569; batch adversarial loss: 0.407201\n",
      "epoch 8; iter: 200; batch classifier loss: 0.364725; batch adversarial loss: 0.377000\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561086; batch adversarial loss: 0.443911\n",
      "epoch 9; iter: 200; batch classifier loss: 0.398050; batch adversarial loss: 0.418243\n",
      "epoch 10; iter: 0; batch classifier loss: 0.404475; batch adversarial loss: 0.374714\n",
      "epoch 10; iter: 200; batch classifier loss: 0.692543; batch adversarial loss: 0.488793\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370080; batch adversarial loss: 0.384696\n",
      "epoch 11; iter: 200; batch classifier loss: 0.300568; batch adversarial loss: 0.419933\n",
      "epoch 12; iter: 0; batch classifier loss: 0.394784; batch adversarial loss: 0.532559\n",
      "epoch 12; iter: 200; batch classifier loss: 0.362030; batch adversarial loss: 0.427596\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349302; batch adversarial loss: 0.415083\n",
      "epoch 13; iter: 200; batch classifier loss: 0.336315; batch adversarial loss: 0.413584\n",
      "epoch 14; iter: 0; batch classifier loss: 0.324591; batch adversarial loss: 0.401759\n",
      "epoch 14; iter: 200; batch classifier loss: 0.436398; batch adversarial loss: 0.481475\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376710; batch adversarial loss: 0.456899\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333307; batch adversarial loss: 0.418811\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387754; batch adversarial loss: 0.425523\n",
      "epoch 16; iter: 200; batch classifier loss: 0.319334; batch adversarial loss: 0.463275\n",
      "epoch 17; iter: 0; batch classifier loss: 0.303658; batch adversarial loss: 0.378658\n",
      "epoch 17; iter: 200; batch classifier loss: 0.330199; batch adversarial loss: 0.478238\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338165; batch adversarial loss: 0.409816\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382554; batch adversarial loss: 0.305098\n",
      "epoch 19; iter: 0; batch classifier loss: 0.386749; batch adversarial loss: 0.444445\n",
      "epoch 19; iter: 200; batch classifier loss: 0.310527; batch adversarial loss: 0.347141\n",
      "epoch 0; iter: 0; batch classifier loss: 306.239624; batch adversarial loss: 0.693184\n",
      "epoch 0; iter: 200; batch classifier loss: 5.838819; batch adversarial loss: 1.022721\n",
      "epoch 1; iter: 0; batch classifier loss: 22.751137; batch adversarial loss: 0.629289\n",
      "epoch 1; iter: 200; batch classifier loss: 5.218064; batch adversarial loss: 0.593737\n",
      "epoch 2; iter: 0; batch classifier loss: 1.628396; batch adversarial loss: 0.585686\n",
      "epoch 2; iter: 200; batch classifier loss: 5.067360; batch adversarial loss: 0.580127\n",
      "epoch 3; iter: 0; batch classifier loss: 3.135962; batch adversarial loss: 0.580432\n",
      "epoch 3; iter: 200; batch classifier loss: 0.890205; batch adversarial loss: 0.539568\n",
      "epoch 4; iter: 0; batch classifier loss: 2.009212; batch adversarial loss: 0.484225\n",
      "epoch 4; iter: 200; batch classifier loss: 4.250264; batch adversarial loss: 0.471624\n",
      "epoch 5; iter: 0; batch classifier loss: 1.045231; batch adversarial loss: 0.455030\n",
      "epoch 5; iter: 200; batch classifier loss: 1.029642; batch adversarial loss: 0.460651\n",
      "epoch 6; iter: 0; batch classifier loss: 0.467704; batch adversarial loss: 0.431419\n",
      "epoch 6; iter: 200; batch classifier loss: 0.369782; batch adversarial loss: 0.454435\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360334; batch adversarial loss: 0.401146\n",
      "epoch 7; iter: 200; batch classifier loss: 0.629477; batch adversarial loss: 0.465661\n",
      "epoch 8; iter: 0; batch classifier loss: 0.657147; batch adversarial loss: 0.453152\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452367; batch adversarial loss: 0.412099\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532911; batch adversarial loss: 0.415730\n",
      "epoch 9; iter: 200; batch classifier loss: 0.428894; batch adversarial loss: 0.370137\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419619; batch adversarial loss: 0.420553\n",
      "epoch 10; iter: 200; batch classifier loss: 0.349044; batch adversarial loss: 0.477033\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413310; batch adversarial loss: 0.453602\n",
      "epoch 11; iter: 200; batch classifier loss: 0.532346; batch adversarial loss: 0.379585\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504791; batch adversarial loss: 0.408474\n",
      "epoch 12; iter: 200; batch classifier loss: 0.396029; batch adversarial loss: 0.479041\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518966; batch adversarial loss: 0.358280\n",
      "epoch 13; iter: 200; batch classifier loss: 0.325638; batch adversarial loss: 0.413502\n",
      "epoch 14; iter: 0; batch classifier loss: 0.323410; batch adversarial loss: 0.409290\n",
      "epoch 14; iter: 200; batch classifier loss: 0.330226; batch adversarial loss: 0.408812\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326659; batch adversarial loss: 0.410085\n",
      "epoch 15; iter: 200; batch classifier loss: 0.388303; batch adversarial loss: 0.374069\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372472; batch adversarial loss: 0.378291\n",
      "epoch 16; iter: 200; batch classifier loss: 0.382253; batch adversarial loss: 0.439166\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390340; batch adversarial loss: 0.303068\n",
      "epoch 17; iter: 200; batch classifier loss: 0.405014; batch adversarial loss: 0.436185\n",
      "epoch 18; iter: 0; batch classifier loss: 0.411054; batch adversarial loss: 0.426674\n",
      "epoch 18; iter: 200; batch classifier loss: 0.396008; batch adversarial loss: 0.452318\n",
      "epoch 19; iter: 0; batch classifier loss: 0.399970; batch adversarial loss: 0.470765\n",
      "epoch 19; iter: 200; batch classifier loss: 0.382471; batch adversarial loss: 0.485604\n",
      "epoch 0; iter: 0; batch classifier loss: 27.159374; batch adversarial loss: 1.015696\n",
      "epoch 0; iter: 200; batch classifier loss: 8.612185; batch adversarial loss: 0.669763\n",
      "epoch 1; iter: 0; batch classifier loss: 5.447478; batch adversarial loss: 0.655044\n",
      "epoch 1; iter: 200; batch classifier loss: 6.097984; batch adversarial loss: 0.590929\n",
      "epoch 2; iter: 0; batch classifier loss: 1.021200; batch adversarial loss: 0.549984\n",
      "epoch 2; iter: 200; batch classifier loss: 2.090389; batch adversarial loss: 0.509877\n",
      "epoch 3; iter: 0; batch classifier loss: 2.405765; batch adversarial loss: 0.518417\n",
      "epoch 3; iter: 200; batch classifier loss: 2.111164; batch adversarial loss: 0.468599\n",
      "epoch 4; iter: 0; batch classifier loss: 1.887314; batch adversarial loss: 0.494664\n",
      "epoch 4; iter: 200; batch classifier loss: 0.487045; batch adversarial loss: 0.443255\n",
      "epoch 5; iter: 0; batch classifier loss: 1.300636; batch adversarial loss: 0.440846\n",
      "epoch 5; iter: 200; batch classifier loss: 1.505580; batch adversarial loss: 0.374509\n",
      "epoch 6; iter: 0; batch classifier loss: 0.478586; batch adversarial loss: 0.395325\n",
      "epoch 6; iter: 200; batch classifier loss: 1.134927; batch adversarial loss: 0.384931\n",
      "epoch 7; iter: 0; batch classifier loss: 0.692827; batch adversarial loss: 0.360404\n",
      "epoch 7; iter: 200; batch classifier loss: 1.086375; batch adversarial loss: 0.386362\n",
      "epoch 8; iter: 0; batch classifier loss: 0.828555; batch adversarial loss: 0.375255\n",
      "epoch 8; iter: 200; batch classifier loss: 0.287136; batch adversarial loss: 0.326082\n",
      "epoch 9; iter: 0; batch classifier loss: 0.302463; batch adversarial loss: 0.359222\n",
      "epoch 9; iter: 200; batch classifier loss: 0.382809; batch adversarial loss: 0.399636\n",
      "epoch 10; iter: 0; batch classifier loss: 0.322637; batch adversarial loss: 0.343821\n",
      "epoch 10; iter: 200; batch classifier loss: 0.367884; batch adversarial loss: 0.309252\n",
      "epoch 11; iter: 0; batch classifier loss: 0.386747; batch adversarial loss: 0.388481\n",
      "epoch 11; iter: 200; batch classifier loss: 0.294725; batch adversarial loss: 0.345849\n",
      "epoch 12; iter: 0; batch classifier loss: 0.387523; batch adversarial loss: 0.423384\n",
      "epoch 12; iter: 200; batch classifier loss: 0.381077; batch adversarial loss: 0.526570\n",
      "epoch 13; iter: 0; batch classifier loss: 0.692935; batch adversarial loss: 0.481354\n",
      "epoch 13; iter: 200; batch classifier loss: 0.384748; batch adversarial loss: 0.425813\n",
      "epoch 14; iter: 0; batch classifier loss: 0.392402; batch adversarial loss: 0.342677\n",
      "epoch 14; iter: 200; batch classifier loss: 0.311376; batch adversarial loss: 0.428291\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324132; batch adversarial loss: 0.457328\n",
      "epoch 15; iter: 200; batch classifier loss: 0.379185; batch adversarial loss: 0.383271\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385833; batch adversarial loss: 0.435015\n",
      "epoch 16; iter: 200; batch classifier loss: 0.247529; batch adversarial loss: 0.317290\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349018; batch adversarial loss: 0.444229\n",
      "epoch 17; iter: 200; batch classifier loss: 0.340782; batch adversarial loss: 0.474477\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246160; batch adversarial loss: 0.482660\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341139; batch adversarial loss: 0.448573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382782; batch adversarial loss: 0.384149\n",
      "epoch 19; iter: 200; batch classifier loss: 0.333885; batch adversarial loss: 0.352363\n",
      "epoch 0; iter: 0; batch classifier loss: 5.955457; batch adversarial loss: 1.052589\n",
      "epoch 0; iter: 200; batch classifier loss: 5.652708; batch adversarial loss: 0.689449\n",
      "epoch 1; iter: 0; batch classifier loss: 9.281521; batch adversarial loss: 0.609124\n",
      "epoch 1; iter: 200; batch classifier loss: 6.409248; batch adversarial loss: 0.694984\n",
      "epoch 2; iter: 0; batch classifier loss: 6.318573; batch adversarial loss: 0.644237\n",
      "epoch 2; iter: 200; batch classifier loss: 3.800286; batch adversarial loss: 0.569795\n",
      "epoch 3; iter: 0; batch classifier loss: 1.494526; batch adversarial loss: 0.585971\n",
      "epoch 3; iter: 200; batch classifier loss: 1.052328; batch adversarial loss: 0.525355\n",
      "epoch 4; iter: 0; batch classifier loss: 0.765071; batch adversarial loss: 0.508516\n",
      "epoch 4; iter: 200; batch classifier loss: 2.873973; batch adversarial loss: 0.478939\n",
      "epoch 5; iter: 0; batch classifier loss: 0.666615; batch adversarial loss: 0.454083\n",
      "epoch 5; iter: 200; batch classifier loss: 1.226460; batch adversarial loss: 0.400142\n",
      "epoch 6; iter: 0; batch classifier loss: 1.354728; batch adversarial loss: 0.418208\n",
      "epoch 6; iter: 200; batch classifier loss: 2.169359; batch adversarial loss: 0.419647\n",
      "epoch 7; iter: 0; batch classifier loss: 0.633642; batch adversarial loss: 0.410378\n",
      "epoch 7; iter: 200; batch classifier loss: 0.867556; batch adversarial loss: 0.425964\n",
      "epoch 8; iter: 0; batch classifier loss: 0.398806; batch adversarial loss: 0.464731\n",
      "epoch 8; iter: 200; batch classifier loss: 0.526324; batch adversarial loss: 0.402777\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420435; batch adversarial loss: 0.414837\n",
      "epoch 9; iter: 200; batch classifier loss: 0.331640; batch adversarial loss: 0.340337\n",
      "epoch 10; iter: 0; batch classifier loss: 0.613471; batch adversarial loss: 0.425953\n",
      "epoch 10; iter: 200; batch classifier loss: 0.370233; batch adversarial loss: 0.359518\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329213; batch adversarial loss: 0.447492\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449895; batch adversarial loss: 0.334573\n",
      "epoch 12; iter: 0; batch classifier loss: 0.388980; batch adversarial loss: 0.386333\n",
      "epoch 12; iter: 200; batch classifier loss: 0.467441; batch adversarial loss: 0.428205\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383705; batch adversarial loss: 0.576882\n",
      "epoch 13; iter: 200; batch classifier loss: 0.435094; batch adversarial loss: 0.392883\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486377; batch adversarial loss: 0.471327\n",
      "epoch 14; iter: 200; batch classifier loss: 0.335634; batch adversarial loss: 0.356703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476903; batch adversarial loss: 0.392205\n",
      "epoch 15; iter: 200; batch classifier loss: 0.396295; batch adversarial loss: 0.397653\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515521; batch adversarial loss: 0.493874\n",
      "epoch 16; iter: 200; batch classifier loss: 0.320091; batch adversarial loss: 0.467557\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310553; batch adversarial loss: 0.401058\n",
      "epoch 17; iter: 200; batch classifier loss: 0.416782; batch adversarial loss: 0.386746\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467567; batch adversarial loss: 0.352080\n",
      "epoch 18; iter: 200; batch classifier loss: 0.393595; batch adversarial loss: 0.506490\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382772; batch adversarial loss: 0.406550\n",
      "epoch 19; iter: 200; batch classifier loss: 0.349875; batch adversarial loss: 0.416090\n",
      "epoch 0; iter: 0; batch classifier loss: 7.630648; batch adversarial loss: 0.499001\n",
      "epoch 0; iter: 200; batch classifier loss: 9.192138; batch adversarial loss: 0.572264\n",
      "epoch 1; iter: 0; batch classifier loss: 10.446883; batch adversarial loss: 0.586234\n",
      "epoch 1; iter: 200; batch classifier loss: 2.533183; batch adversarial loss: 0.529371\n",
      "epoch 2; iter: 0; batch classifier loss: 3.265732; batch adversarial loss: 0.520319\n",
      "epoch 2; iter: 200; batch classifier loss: 1.050546; batch adversarial loss: 0.493985\n",
      "epoch 3; iter: 0; batch classifier loss: 1.927277; batch adversarial loss: 0.452381\n",
      "epoch 3; iter: 200; batch classifier loss: 1.670881; batch adversarial loss: 0.454614\n",
      "epoch 4; iter: 0; batch classifier loss: 2.283737; batch adversarial loss: 0.598719\n",
      "epoch 4; iter: 200; batch classifier loss: 0.544690; batch adversarial loss: 0.416245\n",
      "epoch 5; iter: 0; batch classifier loss: 1.532358; batch adversarial loss: 0.387977\n",
      "epoch 5; iter: 200; batch classifier loss: 0.682624; batch adversarial loss: 0.406571\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451904; batch adversarial loss: 0.458086\n",
      "epoch 6; iter: 200; batch classifier loss: 0.480148; batch adversarial loss: 0.489711\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521296; batch adversarial loss: 0.522130\n",
      "epoch 7; iter: 200; batch classifier loss: 0.445510; batch adversarial loss: 0.424358\n",
      "epoch 8; iter: 0; batch classifier loss: 0.439231; batch adversarial loss: 0.454787\n",
      "epoch 8; iter: 200; batch classifier loss: 0.300248; batch adversarial loss: 0.428800\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534477; batch adversarial loss: 0.334781\n",
      "epoch 9; iter: 200; batch classifier loss: 0.424466; batch adversarial loss: 0.453934\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505626; batch adversarial loss: 0.410684\n",
      "epoch 10; iter: 200; batch classifier loss: 0.398926; batch adversarial loss: 0.431681\n",
      "epoch 11; iter: 0; batch classifier loss: 0.397583; batch adversarial loss: 0.421764\n",
      "epoch 11; iter: 200; batch classifier loss: 0.451797; batch adversarial loss: 0.395037\n",
      "epoch 12; iter: 0; batch classifier loss: 0.431611; batch adversarial loss: 0.459621\n",
      "epoch 12; iter: 200; batch classifier loss: 0.381294; batch adversarial loss: 0.488720\n",
      "epoch 13; iter: 0; batch classifier loss: 0.607575; batch adversarial loss: 0.404640\n",
      "epoch 13; iter: 200; batch classifier loss: 0.455199; batch adversarial loss: 0.402127\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296644; batch adversarial loss: 0.399125\n",
      "epoch 14; iter: 200; batch classifier loss: 0.307076; batch adversarial loss: 0.415170\n",
      "epoch 15; iter: 0; batch classifier loss: 0.389462; batch adversarial loss: 0.392891\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333014; batch adversarial loss: 0.369682\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382829; batch adversarial loss: 0.389335\n",
      "epoch 16; iter: 200; batch classifier loss: 0.360354; batch adversarial loss: 0.408893\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366761; batch adversarial loss: 0.460488\n",
      "epoch 17; iter: 200; batch classifier loss: 0.422816; batch adversarial loss: 0.415331\n",
      "epoch 18; iter: 0; batch classifier loss: 0.413825; batch adversarial loss: 0.415350\n",
      "epoch 18; iter: 200; batch classifier loss: 0.386379; batch adversarial loss: 0.449149\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476583; batch adversarial loss: 0.387843\n",
      "epoch 19; iter: 200; batch classifier loss: 0.321522; batch adversarial loss: 0.301117\n",
      "epoch 0; iter: 0; batch classifier loss: 30.725374; batch adversarial loss: 0.690904\n",
      "epoch 0; iter: 200; batch classifier loss: 3.843793; batch adversarial loss: 0.595371\n",
      "epoch 1; iter: 0; batch classifier loss: 3.380110; batch adversarial loss: 0.554118\n",
      "epoch 1; iter: 200; batch classifier loss: 2.875885; batch adversarial loss: 0.560754\n",
      "epoch 2; iter: 0; batch classifier loss: 1.059667; batch adversarial loss: 0.472685\n",
      "epoch 2; iter: 200; batch classifier loss: 1.876046; batch adversarial loss: 0.496235\n",
      "epoch 3; iter: 0; batch classifier loss: 1.991922; batch adversarial loss: 0.415056\n",
      "epoch 3; iter: 200; batch classifier loss: 1.095140; batch adversarial loss: 0.476405\n",
      "epoch 4; iter: 0; batch classifier loss: 1.812271; batch adversarial loss: 0.443705\n",
      "epoch 4; iter: 200; batch classifier loss: 0.682264; batch adversarial loss: 0.421187\n",
      "epoch 5; iter: 0; batch classifier loss: 1.009575; batch adversarial loss: 0.439996\n",
      "epoch 5; iter: 200; batch classifier loss: 0.790399; batch adversarial loss: 0.414751\n",
      "epoch 6; iter: 0; batch classifier loss: 0.621984; batch adversarial loss: 0.455102\n",
      "epoch 6; iter: 200; batch classifier loss: 0.851132; batch adversarial loss: 0.381862\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334488; batch adversarial loss: 0.455989\n",
      "epoch 7; iter: 200; batch classifier loss: 0.408976; batch adversarial loss: 0.431787\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322457; batch adversarial loss: 0.384521\n",
      "epoch 8; iter: 200; batch classifier loss: 0.369843; batch adversarial loss: 0.350342\n",
      "epoch 9; iter: 0; batch classifier loss: 0.322057; batch adversarial loss: 0.378493\n",
      "epoch 9; iter: 200; batch classifier loss: 0.308077; batch adversarial loss: 0.424675\n",
      "epoch 10; iter: 0; batch classifier loss: 0.429964; batch adversarial loss: 0.369137\n",
      "epoch 10; iter: 200; batch classifier loss: 0.303059; batch adversarial loss: 0.481691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321097; batch adversarial loss: 0.439295\n",
      "epoch 11; iter: 200; batch classifier loss: 0.640338; batch adversarial loss: 0.393997\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365045; batch adversarial loss: 0.366736\n",
      "epoch 12; iter: 200; batch classifier loss: 0.326905; batch adversarial loss: 0.372131\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291245; batch adversarial loss: 0.382505\n",
      "epoch 13; iter: 200; batch classifier loss: 0.412036; batch adversarial loss: 0.389153\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351481; batch adversarial loss: 0.448913\n",
      "epoch 14; iter: 200; batch classifier loss: 0.295227; batch adversarial loss: 0.424912\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364919; batch adversarial loss: 0.406521\n",
      "epoch 15; iter: 200; batch classifier loss: 0.321644; batch adversarial loss: 0.440863\n",
      "epoch 16; iter: 0; batch classifier loss: 0.607653; batch adversarial loss: 0.363626\n",
      "epoch 16; iter: 200; batch classifier loss: 0.365580; batch adversarial loss: 0.429465\n",
      "epoch 17; iter: 0; batch classifier loss: 0.380549; batch adversarial loss: 0.362139\n",
      "epoch 17; iter: 200; batch classifier loss: 0.353320; batch adversarial loss: 0.398374\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328398; batch adversarial loss: 0.398965\n",
      "epoch 18; iter: 200; batch classifier loss: 0.339577; batch adversarial loss: 0.375482\n",
      "epoch 19; iter: 0; batch classifier loss: 0.357993; batch adversarial loss: 0.426264\n",
      "epoch 19; iter: 200; batch classifier loss: 0.329311; batch adversarial loss: 0.455916\n",
      "epoch 0; iter: 0; batch classifier loss: 103.741508; batch adversarial loss: 0.718082\n",
      "epoch 0; iter: 200; batch classifier loss: 14.303297; batch adversarial loss: 0.622860\n",
      "epoch 1; iter: 0; batch classifier loss: 7.385858; batch adversarial loss: 0.573118\n",
      "epoch 1; iter: 200; batch classifier loss: 3.178040; batch adversarial loss: 0.535985\n",
      "epoch 2; iter: 0; batch classifier loss: 6.561966; batch adversarial loss: 0.557605\n",
      "epoch 2; iter: 200; batch classifier loss: 2.933253; batch adversarial loss: 0.475100\n",
      "epoch 3; iter: 0; batch classifier loss: 2.189057; batch adversarial loss: 0.450650\n",
      "epoch 3; iter: 200; batch classifier loss: 2.340115; batch adversarial loss: 0.482814\n",
      "epoch 4; iter: 0; batch classifier loss: 0.994003; batch adversarial loss: 0.399928\n",
      "epoch 4; iter: 200; batch classifier loss: 0.659889; batch adversarial loss: 0.488557\n",
      "epoch 5; iter: 0; batch classifier loss: 1.754779; batch adversarial loss: 0.408133\n",
      "epoch 5; iter: 200; batch classifier loss: 1.127215; batch adversarial loss: 0.409289\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376170; batch adversarial loss: 0.397780\n",
      "epoch 6; iter: 200; batch classifier loss: 0.824628; batch adversarial loss: 0.364844\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380364; batch adversarial loss: 0.387572\n",
      "epoch 7; iter: 200; batch classifier loss: 0.908943; batch adversarial loss: 0.388476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.709685; batch adversarial loss: 0.424408\n",
      "epoch 8; iter: 200; batch classifier loss: 0.274685; batch adversarial loss: 0.464793\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389902; batch adversarial loss: 0.449387\n",
      "epoch 9; iter: 200; batch classifier loss: 0.340060; batch adversarial loss: 0.413488\n",
      "epoch 10; iter: 0; batch classifier loss: 0.431802; batch adversarial loss: 0.481306\n",
      "epoch 10; iter: 200; batch classifier loss: 0.869505; batch adversarial loss: 0.386510\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366587; batch adversarial loss: 0.401821\n",
      "epoch 11; iter: 200; batch classifier loss: 0.407595; batch adversarial loss: 0.449857\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359413; batch adversarial loss: 0.575000\n",
      "epoch 12; iter: 200; batch classifier loss: 0.384752; batch adversarial loss: 0.470375\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382557; batch adversarial loss: 0.419403\n",
      "epoch 13; iter: 200; batch classifier loss: 0.376668; batch adversarial loss: 0.428502\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384748; batch adversarial loss: 0.461711\n",
      "epoch 14; iter: 200; batch classifier loss: 0.346745; batch adversarial loss: 0.456390\n",
      "epoch 15; iter: 0; batch classifier loss: 0.282025; batch adversarial loss: 0.465763\n",
      "epoch 15; iter: 200; batch classifier loss: 0.344480; batch adversarial loss: 0.446320\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337035; batch adversarial loss: 0.420078\n",
      "epoch 16; iter: 200; batch classifier loss: 0.358505; batch adversarial loss: 0.423382\n",
      "epoch 17; iter: 0; batch classifier loss: 0.385471; batch adversarial loss: 0.477445\n",
      "epoch 17; iter: 200; batch classifier loss: 0.295339; batch adversarial loss: 0.331744\n",
      "epoch 18; iter: 0; batch classifier loss: 0.315839; batch adversarial loss: 0.401917\n",
      "epoch 18; iter: 200; batch classifier loss: 0.410878; batch adversarial loss: 0.363450\n",
      "epoch 19; iter: 0; batch classifier loss: 0.346266; batch adversarial loss: 0.472618\n",
      "epoch 19; iter: 200; batch classifier loss: 0.287971; batch adversarial loss: 0.421859\n",
      "epoch 0; iter: 0; batch classifier loss: 13.919130; batch adversarial loss: 0.834904\n",
      "epoch 0; iter: 200; batch classifier loss: 10.235450; batch adversarial loss: 0.657327\n",
      "epoch 1; iter: 0; batch classifier loss: 12.364959; batch adversarial loss: 0.638041\n",
      "epoch 1; iter: 200; batch classifier loss: 5.189568; batch adversarial loss: 0.569770\n",
      "epoch 2; iter: 0; batch classifier loss: 2.811332; batch adversarial loss: 0.585901\n",
      "epoch 2; iter: 200; batch classifier loss: 2.413074; batch adversarial loss: 0.522332\n",
      "epoch 3; iter: 0; batch classifier loss: 1.036725; batch adversarial loss: 0.529372\n",
      "epoch 3; iter: 200; batch classifier loss: 4.407568; batch adversarial loss: 0.455820\n",
      "epoch 4; iter: 0; batch classifier loss: 3.881239; batch adversarial loss: 0.446391\n",
      "epoch 4; iter: 200; batch classifier loss: 1.010698; batch adversarial loss: 0.424164\n",
      "epoch 5; iter: 0; batch classifier loss: 0.379538; batch adversarial loss: 0.403977\n",
      "epoch 5; iter: 200; batch classifier loss: 0.956832; batch adversarial loss: 0.443907\n",
      "epoch 6; iter: 0; batch classifier loss: 1.103907; batch adversarial loss: 0.384274\n",
      "epoch 6; iter: 200; batch classifier loss: 1.187253; batch adversarial loss: 0.408133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345596; batch adversarial loss: 0.457753\n",
      "epoch 7; iter: 200; batch classifier loss: 0.876786; batch adversarial loss: 0.393798\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613423; batch adversarial loss: 0.519813\n",
      "epoch 8; iter: 200; batch classifier loss: 0.664622; batch adversarial loss: 0.424740\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531506; batch adversarial loss: 0.489348\n",
      "epoch 9; iter: 200; batch classifier loss: 0.454473; batch adversarial loss: 0.395169\n",
      "epoch 10; iter: 0; batch classifier loss: 0.379775; batch adversarial loss: 0.319537\n",
      "epoch 10; iter: 200; batch classifier loss: 0.411544; batch adversarial loss: 0.361487\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361220; batch adversarial loss: 0.355940\n",
      "epoch 11; iter: 200; batch classifier loss: 0.260581; batch adversarial loss: 0.395638\n",
      "epoch 12; iter: 0; batch classifier loss: 0.291757; batch adversarial loss: 0.370973\n",
      "epoch 12; iter: 200; batch classifier loss: 0.367648; batch adversarial loss: 0.460149\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526093; batch adversarial loss: 0.373783\n",
      "epoch 13; iter: 200; batch classifier loss: 1.031165; batch adversarial loss: 0.397393\n",
      "epoch 14; iter: 0; batch classifier loss: 0.420455; batch adversarial loss: 0.438947\n",
      "epoch 14; iter: 200; batch classifier loss: 0.505282; batch adversarial loss: 0.446206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.653645; batch adversarial loss: 0.413373\n",
      "epoch 15; iter: 200; batch classifier loss: 0.351271; batch adversarial loss: 0.433603\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307423; batch adversarial loss: 0.437563\n",
      "epoch 16; iter: 200; batch classifier loss: 0.364511; batch adversarial loss: 0.417791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390345; batch adversarial loss: 0.438412\n",
      "epoch 17; iter: 200; batch classifier loss: 0.309487; batch adversarial loss: 0.477283\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316127; batch adversarial loss: 0.404172\n",
      "epoch 18; iter: 200; batch classifier loss: 0.461267; batch adversarial loss: 0.364369\n",
      "epoch 19; iter: 0; batch classifier loss: 0.336451; batch adversarial loss: 0.377940\n",
      "epoch 19; iter: 200; batch classifier loss: 0.341330; batch adversarial loss: 0.388391\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 9.251080; batch adversarial loss: 0.688906\n",
      "epoch 0; iter: 200; batch classifier loss: 8.945469; batch adversarial loss: 0.602933\n",
      "epoch 1; iter: 0; batch classifier loss: 4.601886; batch adversarial loss: 0.595583\n",
      "epoch 1; iter: 200; batch classifier loss: 4.528042; batch adversarial loss: 0.526059\n",
      "epoch 2; iter: 0; batch classifier loss: 5.354399; batch adversarial loss: 0.486510\n",
      "epoch 2; iter: 200; batch classifier loss: 1.001574; batch adversarial loss: 0.509767\n",
      "epoch 3; iter: 0; batch classifier loss: 1.889830; batch adversarial loss: 0.487052\n",
      "epoch 3; iter: 200; batch classifier loss: 2.926879; batch adversarial loss: 0.388949\n",
      "epoch 4; iter: 0; batch classifier loss: 1.538717; batch adversarial loss: 0.496292\n",
      "epoch 4; iter: 200; batch classifier loss: 9.611337; batch adversarial loss: 0.380329\n",
      "epoch 5; iter: 0; batch classifier loss: 0.530159; batch adversarial loss: 0.380219\n",
      "epoch 5; iter: 200; batch classifier loss: 1.702066; batch adversarial loss: 0.366869\n",
      "epoch 6; iter: 0; batch classifier loss: 0.640806; batch adversarial loss: 0.441768\n",
      "epoch 6; iter: 200; batch classifier loss: 1.021805; batch adversarial loss: 0.446508\n",
      "epoch 7; iter: 0; batch classifier loss: 1.617267; batch adversarial loss: 0.373639\n",
      "epoch 7; iter: 200; batch classifier loss: 0.800167; batch adversarial loss: 0.406573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556291; batch adversarial loss: 0.432290\n",
      "epoch 8; iter: 200; batch classifier loss: 0.458606; batch adversarial loss: 0.304424\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525287; batch adversarial loss: 0.449626\n",
      "epoch 9; iter: 200; batch classifier loss: 0.350673; batch adversarial loss: 0.427993\n",
      "epoch 10; iter: 0; batch classifier loss: 0.925858; batch adversarial loss: 0.335812\n",
      "epoch 10; iter: 200; batch classifier loss: 0.668142; batch adversarial loss: 0.422600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.337413; batch adversarial loss: 0.399933\n",
      "epoch 11; iter: 200; batch classifier loss: 0.327565; batch adversarial loss: 0.428157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365616; batch adversarial loss: 0.349452\n",
      "epoch 12; iter: 200; batch classifier loss: 0.446741; batch adversarial loss: 0.421826\n",
      "epoch 13; iter: 0; batch classifier loss: 0.440557; batch adversarial loss: 0.460398\n",
      "epoch 13; iter: 200; batch classifier loss: 0.344313; batch adversarial loss: 0.362275\n",
      "epoch 14; iter: 0; batch classifier loss: 0.404757; batch adversarial loss: 0.383270\n",
      "epoch 14; iter: 200; batch classifier loss: 0.697469; batch adversarial loss: 0.409107\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406184; batch adversarial loss: 0.375611\n",
      "epoch 15; iter: 200; batch classifier loss: 0.317673; batch adversarial loss: 0.377447\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323172; batch adversarial loss: 0.472286\n",
      "epoch 16; iter: 200; batch classifier loss: 0.269812; batch adversarial loss: 0.378216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.370868; batch adversarial loss: 0.375042\n",
      "epoch 17; iter: 200; batch classifier loss: 0.347464; batch adversarial loss: 0.446235\n",
      "epoch 18; iter: 0; batch classifier loss: 0.372872; batch adversarial loss: 0.422026\n",
      "epoch 18; iter: 200; batch classifier loss: 0.352077; batch adversarial loss: 0.501099\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424416; batch adversarial loss: 0.423903\n",
      "epoch 19; iter: 200; batch classifier loss: 0.414692; batch adversarial loss: 0.437611\n",
      "epoch 20; iter: 0; batch classifier loss: 0.354500; batch adversarial loss: 0.500727\n",
      "epoch 20; iter: 200; batch classifier loss: 0.387605; batch adversarial loss: 0.339213\n",
      "epoch 21; iter: 0; batch classifier loss: 0.351795; batch adversarial loss: 0.407297\n",
      "epoch 21; iter: 200; batch classifier loss: 0.375219; batch adversarial loss: 0.462720\n",
      "epoch 22; iter: 0; batch classifier loss: 0.311285; batch adversarial loss: 0.445040\n",
      "epoch 22; iter: 200; batch classifier loss: 0.429362; batch adversarial loss: 0.408773\n",
      "epoch 23; iter: 0; batch classifier loss: 0.300921; batch adversarial loss: 0.403702\n",
      "epoch 23; iter: 200; batch classifier loss: 0.364978; batch adversarial loss: 0.375015\n",
      "epoch 24; iter: 0; batch classifier loss: 0.277175; batch adversarial loss: 0.332386\n",
      "epoch 24; iter: 200; batch classifier loss: 0.354176; batch adversarial loss: 0.304432\n",
      "epoch 25; iter: 0; batch classifier loss: 0.376848; batch adversarial loss: 0.404800\n",
      "epoch 25; iter: 200; batch classifier loss: 0.389206; batch adversarial loss: 0.404510\n",
      "epoch 26; iter: 0; batch classifier loss: 0.301908; batch adversarial loss: 0.542745\n",
      "epoch 26; iter: 200; batch classifier loss: 0.344278; batch adversarial loss: 0.419936\n",
      "epoch 27; iter: 0; batch classifier loss: 0.348962; batch adversarial loss: 0.473835\n",
      "epoch 27; iter: 200; batch classifier loss: 0.384503; batch adversarial loss: 0.473293\n",
      "epoch 28; iter: 0; batch classifier loss: 0.350684; batch adversarial loss: 0.279928\n",
      "epoch 28; iter: 200; batch classifier loss: 0.384736; batch adversarial loss: 0.339886\n",
      "epoch 29; iter: 0; batch classifier loss: 0.356411; batch adversarial loss: 0.289604\n",
      "epoch 29; iter: 200; batch classifier loss: 0.434746; batch adversarial loss: 0.407673\n",
      "epoch 30; iter: 0; batch classifier loss: 0.375981; batch adversarial loss: 0.430528\n",
      "epoch 30; iter: 200; batch classifier loss: 0.388242; batch adversarial loss: 0.421303\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328184; batch adversarial loss: 0.496233\n",
      "epoch 31; iter: 200; batch classifier loss: 0.302573; batch adversarial loss: 0.417003\n",
      "epoch 32; iter: 0; batch classifier loss: 0.368545; batch adversarial loss: 0.322583\n",
      "epoch 32; iter: 200; batch classifier loss: 0.368831; batch adversarial loss: 0.386062\n",
      "epoch 33; iter: 0; batch classifier loss: 0.258147; batch adversarial loss: 0.408389\n",
      "epoch 33; iter: 200; batch classifier loss: 0.345695; batch adversarial loss: 0.399789\n",
      "epoch 34; iter: 0; batch classifier loss: 0.495375; batch adversarial loss: 0.434000\n",
      "epoch 34; iter: 200; batch classifier loss: 0.396123; batch adversarial loss: 0.326453\n",
      "epoch 35; iter: 0; batch classifier loss: 0.375314; batch adversarial loss: 0.331181\n",
      "epoch 35; iter: 200; batch classifier loss: 0.262619; batch adversarial loss: 0.407410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.210143; batch adversarial loss: 0.438352\n",
      "epoch 36; iter: 200; batch classifier loss: 0.248635; batch adversarial loss: 0.481127\n",
      "epoch 37; iter: 0; batch classifier loss: 0.324289; batch adversarial loss: 0.425595\n",
      "epoch 37; iter: 200; batch classifier loss: 0.312080; batch adversarial loss: 0.469574\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382672; batch adversarial loss: 0.448371\n",
      "epoch 38; iter: 200; batch classifier loss: 0.331076; batch adversarial loss: 0.420359\n",
      "epoch 39; iter: 0; batch classifier loss: 0.343299; batch adversarial loss: 0.501637\n",
      "epoch 39; iter: 200; batch classifier loss: 0.267561; batch adversarial loss: 0.418488\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398699; batch adversarial loss: 0.481844\n",
      "epoch 40; iter: 200; batch classifier loss: 0.369835; batch adversarial loss: 0.388595\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499342; batch adversarial loss: 0.369392\n",
      "epoch 41; iter: 200; batch classifier loss: 0.345164; batch adversarial loss: 0.320228\n",
      "epoch 42; iter: 0; batch classifier loss: 0.478994; batch adversarial loss: 0.468000\n",
      "epoch 42; iter: 200; batch classifier loss: 0.337671; batch adversarial loss: 0.335598\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384062; batch adversarial loss: 0.351294\n",
      "epoch 43; iter: 200; batch classifier loss: 0.383078; batch adversarial loss: 0.370736\n",
      "epoch 44; iter: 0; batch classifier loss: 0.350402; batch adversarial loss: 0.486445\n",
      "epoch 44; iter: 200; batch classifier loss: 0.319272; batch adversarial loss: 0.469924\n",
      "epoch 45; iter: 0; batch classifier loss: 0.283227; batch adversarial loss: 0.392530\n",
      "epoch 45; iter: 200; batch classifier loss: 0.378668; batch adversarial loss: 0.321142\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398549; batch adversarial loss: 0.358687\n",
      "epoch 46; iter: 200; batch classifier loss: 0.452569; batch adversarial loss: 0.451146\n",
      "epoch 47; iter: 0; batch classifier loss: 0.324515; batch adversarial loss: 0.415849\n",
      "epoch 47; iter: 200; batch classifier loss: 0.288834; batch adversarial loss: 0.397594\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447085; batch adversarial loss: 0.331476\n",
      "epoch 48; iter: 200; batch classifier loss: 0.346787; batch adversarial loss: 0.384855\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357879; batch adversarial loss: 0.310164\n",
      "epoch 49; iter: 200; batch classifier loss: 0.368406; batch adversarial loss: 0.479960\n",
      "epoch 0; iter: 0; batch classifier loss: 12.152868; batch adversarial loss: 0.821153\n",
      "epoch 0; iter: 200; batch classifier loss: 5.418952; batch adversarial loss: 0.947501\n",
      "epoch 1; iter: 0; batch classifier loss: 9.640305; batch adversarial loss: 0.842329\n",
      "epoch 1; iter: 200; batch classifier loss: 3.926023; batch adversarial loss: 0.716225\n",
      "epoch 2; iter: 0; batch classifier loss: 1.797426; batch adversarial loss: 0.541841\n",
      "epoch 2; iter: 200; batch classifier loss: 0.676555; batch adversarial loss: 0.499766\n",
      "epoch 3; iter: 0; batch classifier loss: 1.133730; batch adversarial loss: 0.499315\n",
      "epoch 3; iter: 200; batch classifier loss: 1.950207; batch adversarial loss: 0.510984\n",
      "epoch 4; iter: 0; batch classifier loss: 1.741326; batch adversarial loss: 0.504043\n",
      "epoch 4; iter: 200; batch classifier loss: 0.616840; batch adversarial loss: 0.447934\n",
      "epoch 5; iter: 0; batch classifier loss: 1.032099; batch adversarial loss: 0.475913\n",
      "epoch 5; iter: 200; batch classifier loss: 0.591918; batch adversarial loss: 0.394740\n",
      "epoch 6; iter: 0; batch classifier loss: 0.737800; batch adversarial loss: 0.441505\n",
      "epoch 6; iter: 200; batch classifier loss: 0.600008; batch adversarial loss: 0.449079\n",
      "epoch 7; iter: 0; batch classifier loss: 0.672823; batch adversarial loss: 0.421988\n",
      "epoch 7; iter: 200; batch classifier loss: 0.585490; batch adversarial loss: 0.472939\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399697; batch adversarial loss: 0.549912\n",
      "epoch 8; iter: 200; batch classifier loss: 0.419980; batch adversarial loss: 0.470495\n",
      "epoch 9; iter: 0; batch classifier loss: 0.356272; batch adversarial loss: 0.381217\n",
      "epoch 9; iter: 200; batch classifier loss: 0.700861; batch adversarial loss: 0.369587\n",
      "epoch 10; iter: 0; batch classifier loss: 0.322079; batch adversarial loss: 0.436446\n",
      "epoch 10; iter: 200; batch classifier loss: 0.424958; batch adversarial loss: 0.422792\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368626; batch adversarial loss: 0.432309\n",
      "epoch 11; iter: 200; batch classifier loss: 0.348664; batch adversarial loss: 0.419348\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346138; batch adversarial loss: 0.415005\n",
      "epoch 12; iter: 200; batch classifier loss: 0.374968; batch adversarial loss: 0.281964\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389916; batch adversarial loss: 0.512558\n",
      "epoch 13; iter: 200; batch classifier loss: 0.433821; batch adversarial loss: 0.423691\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274355; batch adversarial loss: 0.355780\n",
      "epoch 14; iter: 200; batch classifier loss: 0.411054; batch adversarial loss: 0.438994\n",
      "epoch 15; iter: 0; batch classifier loss: 0.353189; batch adversarial loss: 0.293625\n",
      "epoch 15; iter: 200; batch classifier loss: 0.420877; batch adversarial loss: 0.513782\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304875; batch adversarial loss: 0.422808\n",
      "epoch 16; iter: 200; batch classifier loss: 0.308628; batch adversarial loss: 0.304959\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349548; batch adversarial loss: 0.376110\n",
      "epoch 17; iter: 200; batch classifier loss: 0.411841; batch adversarial loss: 0.460027\n",
      "epoch 18; iter: 0; batch classifier loss: 0.759025; batch adversarial loss: 0.419242\n",
      "epoch 18; iter: 200; batch classifier loss: 0.331013; batch adversarial loss: 0.400710\n",
      "epoch 19; iter: 0; batch classifier loss: 0.401056; batch adversarial loss: 0.335763\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385215; batch adversarial loss: 0.398474\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492722; batch adversarial loss: 0.419934\n",
      "epoch 20; iter: 200; batch classifier loss: 0.369806; batch adversarial loss: 0.378788\n",
      "epoch 21; iter: 0; batch classifier loss: 0.341841; batch adversarial loss: 0.360486\n",
      "epoch 21; iter: 200; batch classifier loss: 0.313688; batch adversarial loss: 0.369883\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339159; batch adversarial loss: 0.432011\n",
      "epoch 22; iter: 200; batch classifier loss: 0.319483; batch adversarial loss: 0.402185\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280154; batch adversarial loss: 0.411629\n",
      "epoch 23; iter: 200; batch classifier loss: 0.380628; batch adversarial loss: 0.550916\n",
      "epoch 24; iter: 0; batch classifier loss: 0.359839; batch adversarial loss: 0.354457\n",
      "epoch 24; iter: 200; batch classifier loss: 0.455429; batch adversarial loss: 0.332521\n",
      "epoch 25; iter: 0; batch classifier loss: 0.357740; batch adversarial loss: 0.349811\n",
      "epoch 25; iter: 200; batch classifier loss: 0.415452; batch adversarial loss: 0.485331\n",
      "epoch 26; iter: 0; batch classifier loss: 0.410433; batch adversarial loss: 0.504722\n",
      "epoch 26; iter: 200; batch classifier loss: 0.274570; batch adversarial loss: 0.457743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.365487; batch adversarial loss: 0.406068\n",
      "epoch 27; iter: 200; batch classifier loss: 0.369155; batch adversarial loss: 0.463424\n",
      "epoch 28; iter: 0; batch classifier loss: 0.331839; batch adversarial loss: 0.378424\n",
      "epoch 28; iter: 200; batch classifier loss: 0.348030; batch adversarial loss: 0.354828\n",
      "epoch 29; iter: 0; batch classifier loss: 0.302189; batch adversarial loss: 0.363091\n",
      "epoch 29; iter: 200; batch classifier loss: 0.545519; batch adversarial loss: 0.440573\n",
      "epoch 30; iter: 0; batch classifier loss: 0.290173; batch adversarial loss: 0.332424\n",
      "epoch 30; iter: 200; batch classifier loss: 0.367026; batch adversarial loss: 0.398324\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315364; batch adversarial loss: 0.446182\n",
      "epoch 31; iter: 200; batch classifier loss: 0.386681; batch adversarial loss: 0.439367\n",
      "epoch 32; iter: 0; batch classifier loss: 0.304230; batch adversarial loss: 0.324336\n",
      "epoch 32; iter: 200; batch classifier loss: 0.334336; batch adversarial loss: 0.446009\n",
      "epoch 33; iter: 0; batch classifier loss: 0.334962; batch adversarial loss: 0.411263\n",
      "epoch 33; iter: 200; batch classifier loss: 0.337565; batch adversarial loss: 0.416185\n",
      "epoch 34; iter: 0; batch classifier loss: 0.347898; batch adversarial loss: 0.417441\n",
      "epoch 34; iter: 200; batch classifier loss: 0.301949; batch adversarial loss: 0.347793\n",
      "epoch 35; iter: 0; batch classifier loss: 0.305090; batch adversarial loss: 0.404580\n",
      "epoch 35; iter: 200; batch classifier loss: 0.311536; batch adversarial loss: 0.455860\n",
      "epoch 36; iter: 0; batch classifier loss: 0.319738; batch adversarial loss: 0.391660\n",
      "epoch 36; iter: 200; batch classifier loss: 0.310785; batch adversarial loss: 0.452957\n",
      "epoch 37; iter: 0; batch classifier loss: 0.295689; batch adversarial loss: 0.399375\n",
      "epoch 37; iter: 200; batch classifier loss: 0.385025; batch adversarial loss: 0.444658\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284982; batch adversarial loss: 0.428396\n",
      "epoch 38; iter: 200; batch classifier loss: 0.290887; batch adversarial loss: 0.433185\n",
      "epoch 39; iter: 0; batch classifier loss: 0.325074; batch adversarial loss: 0.379057\n",
      "epoch 39; iter: 200; batch classifier loss: 0.500183; batch adversarial loss: 0.388803\n",
      "epoch 40; iter: 0; batch classifier loss: 0.384287; batch adversarial loss: 0.429385\n",
      "epoch 40; iter: 200; batch classifier loss: 0.305411; batch adversarial loss: 0.338720\n",
      "epoch 41; iter: 0; batch classifier loss: 0.451691; batch adversarial loss: 0.426187\n",
      "epoch 41; iter: 200; batch classifier loss: 0.333110; batch adversarial loss: 0.377287\n",
      "epoch 42; iter: 0; batch classifier loss: 0.316263; batch adversarial loss: 0.508140\n",
      "epoch 42; iter: 200; batch classifier loss: 0.291043; batch adversarial loss: 0.405916\n",
      "epoch 43; iter: 0; batch classifier loss: 0.296972; batch adversarial loss: 0.322663\n",
      "epoch 43; iter: 200; batch classifier loss: 0.367012; batch adversarial loss: 0.457242\n",
      "epoch 44; iter: 0; batch classifier loss: 0.303308; batch adversarial loss: 0.385057\n",
      "epoch 44; iter: 200; batch classifier loss: 0.325705; batch adversarial loss: 0.444428\n",
      "epoch 45; iter: 0; batch classifier loss: 0.330729; batch adversarial loss: 0.453069\n",
      "epoch 45; iter: 200; batch classifier loss: 0.417988; batch adversarial loss: 0.364791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.328542; batch adversarial loss: 0.406479\n",
      "epoch 46; iter: 200; batch classifier loss: 0.370995; batch adversarial loss: 0.427139\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367666; batch adversarial loss: 0.391236\n",
      "epoch 47; iter: 200; batch classifier loss: 0.344457; batch adversarial loss: 0.330048\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427111; batch adversarial loss: 0.436606\n",
      "epoch 48; iter: 200; batch classifier loss: 0.508247; batch adversarial loss: 0.343248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438285; batch adversarial loss: 0.375946\n",
      "epoch 49; iter: 200; batch classifier loss: 0.320280; batch adversarial loss: 0.349308\n",
      "epoch 0; iter: 0; batch classifier loss: 138.631454; batch adversarial loss: 0.540473\n",
      "epoch 0; iter: 200; batch classifier loss: 12.086317; batch adversarial loss: 0.489690\n",
      "epoch 1; iter: 0; batch classifier loss: 22.938992; batch adversarial loss: 0.561881\n",
      "epoch 1; iter: 200; batch classifier loss: 4.485231; batch adversarial loss: 0.536535\n",
      "epoch 2; iter: 0; batch classifier loss: 3.845124; batch adversarial loss: 0.485653\n",
      "epoch 2; iter: 200; batch classifier loss: 6.791612; batch adversarial loss: 0.462680\n",
      "epoch 3; iter: 0; batch classifier loss: 1.402873; batch adversarial loss: 0.417389\n",
      "epoch 3; iter: 200; batch classifier loss: 2.166325; batch adversarial loss: 0.509635\n",
      "epoch 4; iter: 0; batch classifier loss: 1.156952; batch adversarial loss: 0.460117\n",
      "epoch 4; iter: 200; batch classifier loss: 1.498654; batch adversarial loss: 0.378711\n",
      "epoch 5; iter: 0; batch classifier loss: 1.380684; batch adversarial loss: 0.400011\n",
      "epoch 5; iter: 200; batch classifier loss: 0.916110; batch adversarial loss: 0.410132\n",
      "epoch 6; iter: 0; batch classifier loss: 0.459431; batch adversarial loss: 0.392781\n",
      "epoch 6; iter: 200; batch classifier loss: 0.404125; batch adversarial loss: 0.385429\n",
      "epoch 7; iter: 0; batch classifier loss: 0.404174; batch adversarial loss: 0.359943\n",
      "epoch 7; iter: 200; batch classifier loss: 0.355218; batch adversarial loss: 0.518185\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370449; batch adversarial loss: 0.426419\n",
      "epoch 8; iter: 200; batch classifier loss: 0.412259; batch adversarial loss: 0.390595\n",
      "epoch 9; iter: 0; batch classifier loss: 0.441448; batch adversarial loss: 0.341221\n",
      "epoch 9; iter: 200; batch classifier loss: 0.332788; batch adversarial loss: 0.395983\n",
      "epoch 10; iter: 0; batch classifier loss: 0.331306; batch adversarial loss: 0.531379\n",
      "epoch 10; iter: 200; batch classifier loss: 0.377770; batch adversarial loss: 0.454823\n",
      "epoch 11; iter: 0; batch classifier loss: 0.649169; batch adversarial loss: 0.519969\n",
      "epoch 11; iter: 200; batch classifier loss: 0.349852; batch adversarial loss: 0.462040\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379232; batch adversarial loss: 0.269406\n",
      "epoch 12; iter: 200; batch classifier loss: 0.478751; batch adversarial loss: 0.336890\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407186; batch adversarial loss: 0.394502\n",
      "epoch 13; iter: 200; batch classifier loss: 0.520370; batch adversarial loss: 0.415843\n",
      "epoch 14; iter: 0; batch classifier loss: 0.404243; batch adversarial loss: 0.538991\n",
      "epoch 14; iter: 200; batch classifier loss: 0.347889; batch adversarial loss: 0.395829\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374292; batch adversarial loss: 0.534264\n",
      "epoch 15; iter: 200; batch classifier loss: 0.424694; batch adversarial loss: 0.284075\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323226; batch adversarial loss: 0.427692\n",
      "epoch 16; iter: 200; batch classifier loss: 0.381521; batch adversarial loss: 0.379526\n",
      "epoch 17; iter: 0; batch classifier loss: 0.362827; batch adversarial loss: 0.407118\n",
      "epoch 17; iter: 200; batch classifier loss: 0.451424; batch adversarial loss: 0.356535\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398952; batch adversarial loss: 0.363363\n",
      "epoch 18; iter: 200; batch classifier loss: 0.265242; batch adversarial loss: 0.453429\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309845; batch adversarial loss: 0.450839\n",
      "epoch 19; iter: 200; batch classifier loss: 0.329908; batch adversarial loss: 0.508569\n",
      "epoch 20; iter: 0; batch classifier loss: 0.269680; batch adversarial loss: 0.349715\n",
      "epoch 20; iter: 200; batch classifier loss: 0.272580; batch adversarial loss: 0.447482\n",
      "epoch 21; iter: 0; batch classifier loss: 0.328561; batch adversarial loss: 0.418325\n",
      "epoch 21; iter: 200; batch classifier loss: 0.313236; batch adversarial loss: 0.374859\n",
      "epoch 22; iter: 0; batch classifier loss: 0.400940; batch adversarial loss: 0.389572\n",
      "epoch 22; iter: 200; batch classifier loss: 0.290292; batch adversarial loss: 0.424149\n",
      "epoch 23; iter: 0; batch classifier loss: 0.376540; batch adversarial loss: 0.447181\n",
      "epoch 23; iter: 200; batch classifier loss: 0.466384; batch adversarial loss: 0.418760\n",
      "epoch 24; iter: 0; batch classifier loss: 0.337611; batch adversarial loss: 0.399992\n",
      "epoch 24; iter: 200; batch classifier loss: 0.322579; batch adversarial loss: 0.395328\n",
      "epoch 25; iter: 0; batch classifier loss: 0.380184; batch adversarial loss: 0.378882\n",
      "epoch 25; iter: 200; batch classifier loss: 0.386878; batch adversarial loss: 0.418272\n",
      "epoch 26; iter: 0; batch classifier loss: 0.328189; batch adversarial loss: 0.376775\n",
      "epoch 26; iter: 200; batch classifier loss: 0.249937; batch adversarial loss: 0.313785\n",
      "epoch 27; iter: 0; batch classifier loss: 0.281255; batch adversarial loss: 0.469155\n",
      "epoch 27; iter: 200; batch classifier loss: 0.311309; batch adversarial loss: 0.391155\n",
      "epoch 28; iter: 0; batch classifier loss: 0.316896; batch adversarial loss: 0.388006\n",
      "epoch 28; iter: 200; batch classifier loss: 0.315197; batch adversarial loss: 0.376043\n",
      "epoch 29; iter: 0; batch classifier loss: 0.350831; batch adversarial loss: 0.397110\n",
      "epoch 29; iter: 200; batch classifier loss: 0.299401; batch adversarial loss: 0.420182\n",
      "epoch 30; iter: 0; batch classifier loss: 0.384205; batch adversarial loss: 0.477321\n",
      "epoch 30; iter: 200; batch classifier loss: 0.432431; batch adversarial loss: 0.453106\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387245; batch adversarial loss: 0.406883\n",
      "epoch 31; iter: 200; batch classifier loss: 0.255683; batch adversarial loss: 0.478434\n",
      "epoch 32; iter: 0; batch classifier loss: 0.321834; batch adversarial loss: 0.366074\n",
      "epoch 32; iter: 200; batch classifier loss: 0.390320; batch adversarial loss: 0.467060\n",
      "epoch 33; iter: 0; batch classifier loss: 0.373698; batch adversarial loss: 0.350218\n",
      "epoch 33; iter: 200; batch classifier loss: 0.339587; batch adversarial loss: 0.337532\n",
      "epoch 34; iter: 0; batch classifier loss: 0.327544; batch adversarial loss: 0.407159\n",
      "epoch 34; iter: 200; batch classifier loss: 0.361089; batch adversarial loss: 0.445089\n",
      "epoch 35; iter: 0; batch classifier loss: 0.271678; batch adversarial loss: 0.403428\n",
      "epoch 35; iter: 200; batch classifier loss: 0.365524; batch adversarial loss: 0.410114\n",
      "epoch 36; iter: 0; batch classifier loss: 0.317105; batch adversarial loss: 0.557213\n",
      "epoch 36; iter: 200; batch classifier loss: 0.444427; batch adversarial loss: 0.431266\n",
      "epoch 37; iter: 0; batch classifier loss: 0.371513; batch adversarial loss: 0.461497\n",
      "epoch 37; iter: 200; batch classifier loss: 0.349421; batch adversarial loss: 0.455341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.329852; batch adversarial loss: 0.427938\n",
      "epoch 38; iter: 200; batch classifier loss: 0.298403; batch adversarial loss: 0.455294\n",
      "epoch 39; iter: 0; batch classifier loss: 0.251855; batch adversarial loss: 0.422204\n",
      "epoch 39; iter: 200; batch classifier loss: 0.319517; batch adversarial loss: 0.362838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.315440; batch adversarial loss: 0.388637\n",
      "epoch 40; iter: 200; batch classifier loss: 0.315815; batch adversarial loss: 0.374883\n",
      "epoch 41; iter: 0; batch classifier loss: 0.342665; batch adversarial loss: 0.400400\n",
      "epoch 41; iter: 200; batch classifier loss: 0.372407; batch adversarial loss: 0.537242\n",
      "epoch 42; iter: 0; batch classifier loss: 0.264299; batch adversarial loss: 0.385574\n",
      "epoch 42; iter: 200; batch classifier loss: 0.420444; batch adversarial loss: 0.398499\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365179; batch adversarial loss: 0.400766\n",
      "epoch 43; iter: 200; batch classifier loss: 0.372322; batch adversarial loss: 0.405003\n",
      "epoch 44; iter: 0; batch classifier loss: 0.391269; batch adversarial loss: 0.344678\n",
      "epoch 44; iter: 200; batch classifier loss: 0.395434; batch adversarial loss: 0.412059\n",
      "epoch 45; iter: 0; batch classifier loss: 0.375546; batch adversarial loss: 0.421279\n",
      "epoch 45; iter: 200; batch classifier loss: 0.367022; batch adversarial loss: 0.337124\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389183; batch adversarial loss: 0.426670\n",
      "epoch 46; iter: 200; batch classifier loss: 0.379888; batch adversarial loss: 0.299014\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340750; batch adversarial loss: 0.439107\n",
      "epoch 47; iter: 200; batch classifier loss: 0.403801; batch adversarial loss: 0.372862\n",
      "epoch 48; iter: 0; batch classifier loss: 0.275828; batch adversarial loss: 0.400210\n",
      "epoch 48; iter: 200; batch classifier loss: 0.369935; batch adversarial loss: 0.457021\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429714; batch adversarial loss: 0.364094\n",
      "epoch 49; iter: 200; batch classifier loss: 0.315486; batch adversarial loss: 0.402358\n",
      "epoch 0; iter: 0; batch classifier loss: 48.051872; batch adversarial loss: 0.602855\n",
      "epoch 0; iter: 200; batch classifier loss: 10.030241; batch adversarial loss: 0.556460\n",
      "epoch 1; iter: 0; batch classifier loss: 2.968187; batch adversarial loss: 0.578331\n",
      "epoch 1; iter: 200; batch classifier loss: 2.663247; batch adversarial loss: 0.521926\n",
      "epoch 2; iter: 0; batch classifier loss: 3.550648; batch adversarial loss: 0.543900\n",
      "epoch 2; iter: 200; batch classifier loss: 1.271755; batch adversarial loss: 0.506954\n",
      "epoch 3; iter: 0; batch classifier loss: 3.019660; batch adversarial loss: 0.504572\n",
      "epoch 3; iter: 200; batch classifier loss: 1.502060; batch adversarial loss: 0.444866\n",
      "epoch 4; iter: 0; batch classifier loss: 5.320570; batch adversarial loss: 0.465681\n",
      "epoch 4; iter: 200; batch classifier loss: 1.953653; batch adversarial loss: 0.445944\n",
      "epoch 5; iter: 0; batch classifier loss: 0.939729; batch adversarial loss: 0.437864\n",
      "epoch 5; iter: 200; batch classifier loss: 0.523318; batch adversarial loss: 0.445024\n",
      "epoch 6; iter: 0; batch classifier loss: 0.433672; batch adversarial loss: 0.464632\n",
      "epoch 6; iter: 200; batch classifier loss: 0.439056; batch adversarial loss: 0.418505\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521764; batch adversarial loss: 0.374935\n",
      "epoch 7; iter: 200; batch classifier loss: 0.683190; batch adversarial loss: 0.480977\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342508; batch adversarial loss: 0.396476\n",
      "epoch 8; iter: 200; batch classifier loss: 0.464208; batch adversarial loss: 0.338569\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440246; batch adversarial loss: 0.412325\n",
      "epoch 9; iter: 200; batch classifier loss: 0.604522; batch adversarial loss: 0.435643\n",
      "epoch 10; iter: 0; batch classifier loss: 0.415505; batch adversarial loss: 0.360958\n",
      "epoch 10; iter: 200; batch classifier loss: 0.445229; batch adversarial loss: 0.395875\n",
      "epoch 11; iter: 0; batch classifier loss: 0.318369; batch adversarial loss: 0.361953\n",
      "epoch 11; iter: 200; batch classifier loss: 0.401029; batch adversarial loss: 0.372547\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485303; batch adversarial loss: 0.511568\n",
      "epoch 12; iter: 200; batch classifier loss: 0.403420; batch adversarial loss: 0.400241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346864; batch adversarial loss: 0.471908\n",
      "epoch 13; iter: 200; batch classifier loss: 0.438022; batch adversarial loss: 0.382259\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336371; batch adversarial loss: 0.414628\n",
      "epoch 14; iter: 200; batch classifier loss: 0.286210; batch adversarial loss: 0.384919\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344321; batch adversarial loss: 0.402205\n",
      "epoch 15; iter: 200; batch classifier loss: 0.308800; batch adversarial loss: 0.492654\n",
      "epoch 16; iter: 0; batch classifier loss: 0.365065; batch adversarial loss: 0.369604\n",
      "epoch 16; iter: 200; batch classifier loss: 0.320042; batch adversarial loss: 0.431744\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327600; batch adversarial loss: 0.373835\n",
      "epoch 17; iter: 200; batch classifier loss: 0.359552; batch adversarial loss: 0.408546\n",
      "epoch 18; iter: 0; batch classifier loss: 0.392652; batch adversarial loss: 0.305514\n",
      "epoch 18; iter: 200; batch classifier loss: 0.320850; batch adversarial loss: 0.442629\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354361; batch adversarial loss: 0.410924\n",
      "epoch 19; iter: 200; batch classifier loss: 0.369619; batch adversarial loss: 0.393939\n",
      "epoch 20; iter: 0; batch classifier loss: 0.364487; batch adversarial loss: 0.310307\n",
      "epoch 20; iter: 200; batch classifier loss: 0.323057; batch adversarial loss: 0.459548\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323508; batch adversarial loss: 0.368722\n",
      "epoch 21; iter: 200; batch classifier loss: 0.332618; batch adversarial loss: 0.362817\n",
      "epoch 22; iter: 0; batch classifier loss: 0.317818; batch adversarial loss: 0.391774\n",
      "epoch 22; iter: 200; batch classifier loss: 0.397951; batch adversarial loss: 0.440219\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311300; batch adversarial loss: 0.527361\n",
      "epoch 23; iter: 200; batch classifier loss: 0.325573; batch adversarial loss: 0.370578\n",
      "epoch 24; iter: 0; batch classifier loss: 0.357773; batch adversarial loss: 0.423602\n",
      "epoch 24; iter: 200; batch classifier loss: 0.296557; batch adversarial loss: 0.385050\n",
      "epoch 25; iter: 0; batch classifier loss: 0.309250; batch adversarial loss: 0.431229\n",
      "epoch 25; iter: 200; batch classifier loss: 0.356882; batch adversarial loss: 0.367991\n",
      "epoch 26; iter: 0; batch classifier loss: 0.345262; batch adversarial loss: 0.415536\n",
      "epoch 26; iter: 200; batch classifier loss: 0.315158; batch adversarial loss: 0.343944\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414863; batch adversarial loss: 0.544128\n",
      "epoch 27; iter: 200; batch classifier loss: 0.272608; batch adversarial loss: 0.472487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.333887; batch adversarial loss: 0.338511\n",
      "epoch 28; iter: 200; batch classifier loss: 0.315972; batch adversarial loss: 0.402132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.352818; batch adversarial loss: 0.559011\n",
      "epoch 29; iter: 200; batch classifier loss: 0.252445; batch adversarial loss: 0.492991\n",
      "epoch 30; iter: 0; batch classifier loss: 0.359608; batch adversarial loss: 0.414010\n",
      "epoch 30; iter: 200; batch classifier loss: 0.343659; batch adversarial loss: 0.428131\n",
      "epoch 31; iter: 0; batch classifier loss: 0.349820; batch adversarial loss: 0.399053\n",
      "epoch 31; iter: 200; batch classifier loss: 0.316419; batch adversarial loss: 0.464385\n",
      "epoch 32; iter: 0; batch classifier loss: 0.293735; batch adversarial loss: 0.330557\n",
      "epoch 32; iter: 200; batch classifier loss: 0.343087; batch adversarial loss: 0.478845\n",
      "epoch 33; iter: 0; batch classifier loss: 0.352337; batch adversarial loss: 0.419355\n",
      "epoch 33; iter: 200; batch classifier loss: 0.282734; batch adversarial loss: 0.462419\n",
      "epoch 34; iter: 0; batch classifier loss: 0.347139; batch adversarial loss: 0.348615\n",
      "epoch 34; iter: 200; batch classifier loss: 0.354057; batch adversarial loss: 0.592299\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341565; batch adversarial loss: 0.368984\n",
      "epoch 35; iter: 200; batch classifier loss: 0.280196; batch adversarial loss: 0.438105\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272612; batch adversarial loss: 0.449400\n",
      "epoch 36; iter: 200; batch classifier loss: 0.295794; batch adversarial loss: 0.389246\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408091; batch adversarial loss: 0.452487\n",
      "epoch 37; iter: 200; batch classifier loss: 0.289214; batch adversarial loss: 0.477181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.331023; batch adversarial loss: 0.430123\n",
      "epoch 38; iter: 200; batch classifier loss: 0.273654; batch adversarial loss: 0.396291\n",
      "epoch 39; iter: 0; batch classifier loss: 0.251459; batch adversarial loss: 0.479489\n",
      "epoch 39; iter: 200; batch classifier loss: 0.497462; batch adversarial loss: 0.417160\n",
      "epoch 40; iter: 0; batch classifier loss: 0.291178; batch adversarial loss: 0.306783\n",
      "epoch 40; iter: 200; batch classifier loss: 0.287740; batch adversarial loss: 0.441935\n",
      "epoch 41; iter: 0; batch classifier loss: 0.326792; batch adversarial loss: 0.415938\n",
      "epoch 41; iter: 200; batch classifier loss: 0.396130; batch adversarial loss: 0.349256\n",
      "epoch 42; iter: 0; batch classifier loss: 0.348282; batch adversarial loss: 0.374286\n",
      "epoch 42; iter: 200; batch classifier loss: 0.276920; batch adversarial loss: 0.423872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.302798; batch adversarial loss: 0.377535\n",
      "epoch 43; iter: 200; batch classifier loss: 0.292775; batch adversarial loss: 0.360062\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405188; batch adversarial loss: 0.434601\n",
      "epoch 44; iter: 200; batch classifier loss: 0.410162; batch adversarial loss: 0.510000\n",
      "epoch 45; iter: 0; batch classifier loss: 0.360392; batch adversarial loss: 0.524647\n",
      "epoch 45; iter: 200; batch classifier loss: 0.349227; batch adversarial loss: 0.407306\n",
      "epoch 46; iter: 0; batch classifier loss: 0.269098; batch adversarial loss: 0.492207\n",
      "epoch 46; iter: 200; batch classifier loss: 0.284939; batch adversarial loss: 0.284637\n",
      "epoch 47; iter: 0; batch classifier loss: 0.336102; batch adversarial loss: 0.521349\n",
      "epoch 47; iter: 200; batch classifier loss: 0.335097; batch adversarial loss: 0.418273\n",
      "epoch 48; iter: 0; batch classifier loss: 0.458465; batch adversarial loss: 0.445228\n",
      "epoch 48; iter: 200; batch classifier loss: 0.258835; batch adversarial loss: 0.431842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351479; batch adversarial loss: 0.423988\n",
      "epoch 49; iter: 200; batch classifier loss: 0.300360; batch adversarial loss: 0.396842\n",
      "epoch 0; iter: 0; batch classifier loss: 56.409004; batch adversarial loss: 0.698690\n",
      "epoch 0; iter: 200; batch classifier loss: 10.939781; batch adversarial loss: 0.634421\n",
      "epoch 1; iter: 0; batch classifier loss: 2.863980; batch adversarial loss: 0.573368\n",
      "epoch 1; iter: 200; batch classifier loss: 18.141821; batch adversarial loss: 0.454108\n",
      "epoch 2; iter: 0; batch classifier loss: 2.231464; batch adversarial loss: 0.515378\n",
      "epoch 2; iter: 200; batch classifier loss: 4.018705; batch adversarial loss: 0.450757\n",
      "epoch 3; iter: 0; batch classifier loss: 1.326940; batch adversarial loss: 0.440971\n",
      "epoch 3; iter: 200; batch classifier loss: 4.133145; batch adversarial loss: 0.375794\n",
      "epoch 4; iter: 0; batch classifier loss: 3.478636; batch adversarial loss: 0.397535\n",
      "epoch 4; iter: 200; batch classifier loss: 0.704065; batch adversarial loss: 0.397750\n",
      "epoch 5; iter: 0; batch classifier loss: 0.855335; batch adversarial loss: 0.443456\n",
      "epoch 5; iter: 200; batch classifier loss: 0.718867; batch adversarial loss: 0.418687\n",
      "epoch 6; iter: 0; batch classifier loss: 0.365386; batch adversarial loss: 0.480040\n",
      "epoch 6; iter: 200; batch classifier loss: 0.574086; batch adversarial loss: 0.490886\n",
      "epoch 7; iter: 0; batch classifier loss: 0.738275; batch adversarial loss: 0.489925\n",
      "epoch 7; iter: 200; batch classifier loss: 0.273445; batch adversarial loss: 0.480224\n",
      "epoch 8; iter: 0; batch classifier loss: 0.343993; batch adversarial loss: 0.435365\n",
      "epoch 8; iter: 200; batch classifier loss: 0.622745; batch adversarial loss: 0.507468\n",
      "epoch 9; iter: 0; batch classifier loss: 2.963789; batch adversarial loss: 0.418223\n",
      "epoch 9; iter: 200; batch classifier loss: 0.534054; batch adversarial loss: 0.385568\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513574; batch adversarial loss: 0.328344\n",
      "epoch 10; iter: 200; batch classifier loss: 0.592964; batch adversarial loss: 0.517064\n",
      "epoch 11; iter: 0; batch classifier loss: 0.477814; batch adversarial loss: 0.437598\n",
      "epoch 11; iter: 200; batch classifier loss: 0.438730; batch adversarial loss: 0.531398\n",
      "epoch 12; iter: 0; batch classifier loss: 0.414531; batch adversarial loss: 0.389577\n",
      "epoch 12; iter: 200; batch classifier loss: 0.413903; batch adversarial loss: 0.414879\n",
      "epoch 13; iter: 0; batch classifier loss: 0.425337; batch adversarial loss: 0.405856\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404977; batch adversarial loss: 0.348422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.433206; batch adversarial loss: 0.424117\n",
      "epoch 14; iter: 200; batch classifier loss: 0.377949; batch adversarial loss: 0.406674\n",
      "epoch 15; iter: 0; batch classifier loss: 0.896661; batch adversarial loss: 0.399498\n",
      "epoch 15; iter: 200; batch classifier loss: 0.326206; batch adversarial loss: 0.443494\n",
      "epoch 16; iter: 0; batch classifier loss: 0.436774; batch adversarial loss: 0.497184\n",
      "epoch 16; iter: 200; batch classifier loss: 0.426108; batch adversarial loss: 0.392762\n",
      "epoch 17; iter: 0; batch classifier loss: 0.308660; batch adversarial loss: 0.453478\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381828; batch adversarial loss: 0.464410\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391912; batch adversarial loss: 0.304197\n",
      "epoch 18; iter: 200; batch classifier loss: 0.302649; batch adversarial loss: 0.381256\n",
      "epoch 19; iter: 0; batch classifier loss: 0.594468; batch adversarial loss: 0.364091\n",
      "epoch 19; iter: 200; batch classifier loss: 0.330265; batch adversarial loss: 0.402495\n",
      "epoch 20; iter: 0; batch classifier loss: 0.397833; batch adversarial loss: 0.379089\n",
      "epoch 20; iter: 200; batch classifier loss: 0.358615; batch adversarial loss: 0.399286\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355688; batch adversarial loss: 0.460226\n",
      "epoch 21; iter: 200; batch classifier loss: 0.345418; batch adversarial loss: 0.495046\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458804; batch adversarial loss: 0.445738\n",
      "epoch 22; iter: 200; batch classifier loss: 0.378607; batch adversarial loss: 0.372795\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311844; batch adversarial loss: 0.422507\n",
      "epoch 23; iter: 200; batch classifier loss: 0.415465; batch adversarial loss: 0.405458\n",
      "epoch 24; iter: 0; batch classifier loss: 0.336096; batch adversarial loss: 0.452493\n",
      "epoch 24; iter: 200; batch classifier loss: 0.338111; batch adversarial loss: 0.444176\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326995; batch adversarial loss: 0.467073\n",
      "epoch 25; iter: 200; batch classifier loss: 0.386669; batch adversarial loss: 0.431967\n",
      "epoch 26; iter: 0; batch classifier loss: 0.441880; batch adversarial loss: 0.416911\n",
      "epoch 26; iter: 200; batch classifier loss: 0.365470; batch adversarial loss: 0.341191\n",
      "epoch 27; iter: 0; batch classifier loss: 0.351898; batch adversarial loss: 0.456997\n",
      "epoch 27; iter: 200; batch classifier loss: 0.454592; batch adversarial loss: 0.439184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.365903; batch adversarial loss: 0.388732\n",
      "epoch 28; iter: 200; batch classifier loss: 0.359201; batch adversarial loss: 0.383258\n",
      "epoch 29; iter: 0; batch classifier loss: 0.306759; batch adversarial loss: 0.378682\n",
      "epoch 29; iter: 200; batch classifier loss: 0.312733; batch adversarial loss: 0.385623\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320859; batch adversarial loss: 0.459634\n",
      "epoch 30; iter: 200; batch classifier loss: 0.274239; batch adversarial loss: 0.411255\n",
      "epoch 31; iter: 0; batch classifier loss: 0.329285; batch adversarial loss: 0.410387\n",
      "epoch 31; iter: 200; batch classifier loss: 0.348169; batch adversarial loss: 0.387386\n",
      "epoch 32; iter: 0; batch classifier loss: 0.311158; batch adversarial loss: 0.426730\n",
      "epoch 32; iter: 200; batch classifier loss: 0.328232; batch adversarial loss: 0.459820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.376419; batch adversarial loss: 0.330139\n",
      "epoch 33; iter: 200; batch classifier loss: 0.312350; batch adversarial loss: 0.385104\n",
      "epoch 34; iter: 0; batch classifier loss: 0.373571; batch adversarial loss: 0.375710\n",
      "epoch 34; iter: 200; batch classifier loss: 0.373455; batch adversarial loss: 0.481322\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440275; batch adversarial loss: 0.454839\n",
      "epoch 35; iter: 200; batch classifier loss: 0.369140; batch adversarial loss: 0.403882\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468469; batch adversarial loss: 0.373579\n",
      "epoch 36; iter: 200; batch classifier loss: 0.358483; batch adversarial loss: 0.419701\n",
      "epoch 37; iter: 0; batch classifier loss: 0.311037; batch adversarial loss: 0.426633\n",
      "epoch 37; iter: 200; batch classifier loss: 0.363193; batch adversarial loss: 0.417593\n",
      "epoch 38; iter: 0; batch classifier loss: 0.246550; batch adversarial loss: 0.477479\n",
      "epoch 38; iter: 200; batch classifier loss: 0.367152; batch adversarial loss: 0.453222\n",
      "epoch 39; iter: 0; batch classifier loss: 0.356769; batch adversarial loss: 0.436201\n",
      "epoch 39; iter: 200; batch classifier loss: 0.383856; batch adversarial loss: 0.455027\n",
      "epoch 40; iter: 0; batch classifier loss: 0.237356; batch adversarial loss: 0.507868\n",
      "epoch 40; iter: 200; batch classifier loss: 0.315199; batch adversarial loss: 0.487193\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385449; batch adversarial loss: 0.331567\n",
      "epoch 41; iter: 200; batch classifier loss: 0.334715; batch adversarial loss: 0.378863\n",
      "epoch 42; iter: 0; batch classifier loss: 0.263332; batch adversarial loss: 0.424131\n",
      "epoch 42; iter: 200; batch classifier loss: 0.469506; batch adversarial loss: 0.420548\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408924; batch adversarial loss: 0.422085\n",
      "epoch 43; iter: 200; batch classifier loss: 0.327537; batch adversarial loss: 0.520869\n",
      "epoch 44; iter: 0; batch classifier loss: 0.275228; batch adversarial loss: 0.390012\n",
      "epoch 44; iter: 200; batch classifier loss: 0.343288; batch adversarial loss: 0.392482\n",
      "epoch 45; iter: 0; batch classifier loss: 0.394764; batch adversarial loss: 0.353633\n",
      "epoch 45; iter: 200; batch classifier loss: 0.326162; batch adversarial loss: 0.400807\n",
      "epoch 46; iter: 0; batch classifier loss: 0.256318; batch adversarial loss: 0.345843\n",
      "epoch 46; iter: 200; batch classifier loss: 0.371368; batch adversarial loss: 0.396375\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357568; batch adversarial loss: 0.403399\n",
      "epoch 47; iter: 200; batch classifier loss: 0.458566; batch adversarial loss: 0.426244\n",
      "epoch 48; iter: 0; batch classifier loss: 0.322121; batch adversarial loss: 0.477381\n",
      "epoch 48; iter: 200; batch classifier loss: 0.333640; batch adversarial loss: 0.321717\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383983; batch adversarial loss: 0.405926\n",
      "epoch 49; iter: 200; batch classifier loss: 0.328744; batch adversarial loss: 0.460877\n",
      "epoch 0; iter: 0; batch classifier loss: 72.622414; batch adversarial loss: 0.697828\n",
      "epoch 0; iter: 200; batch classifier loss: 6.416059; batch adversarial loss: 0.693716\n",
      "epoch 1; iter: 0; batch classifier loss: 8.819743; batch adversarial loss: 0.592544\n",
      "epoch 1; iter: 200; batch classifier loss: 1.465170; batch adversarial loss: 0.562308\n",
      "epoch 2; iter: 0; batch classifier loss: 3.412235; batch adversarial loss: 0.543480\n",
      "epoch 2; iter: 200; batch classifier loss: 3.280559; batch adversarial loss: 0.511686\n",
      "epoch 3; iter: 0; batch classifier loss: 0.808696; batch adversarial loss: 0.431311\n",
      "epoch 3; iter: 200; batch classifier loss: 0.606639; batch adversarial loss: 0.481624\n",
      "epoch 4; iter: 0; batch classifier loss: 0.987021; batch adversarial loss: 0.414622\n",
      "epoch 4; iter: 200; batch classifier loss: 0.472354; batch adversarial loss: 0.457427\n",
      "epoch 5; iter: 0; batch classifier loss: 0.710963; batch adversarial loss: 0.409132\n",
      "epoch 5; iter: 200; batch classifier loss: 0.545703; batch adversarial loss: 0.430399\n",
      "epoch 6; iter: 0; batch classifier loss: 0.691436; batch adversarial loss: 0.494581\n",
      "epoch 6; iter: 200; batch classifier loss: 1.038087; batch adversarial loss: 0.394895\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411709; batch adversarial loss: 0.405103\n",
      "epoch 7; iter: 200; batch classifier loss: 0.459163; batch adversarial loss: 0.366192\n",
      "epoch 8; iter: 0; batch classifier loss: 0.393313; batch adversarial loss: 0.383293\n",
      "epoch 8; iter: 200; batch classifier loss: 0.320749; batch adversarial loss: 0.369930\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407459; batch adversarial loss: 0.385383\n",
      "epoch 9; iter: 200; batch classifier loss: 0.500924; batch adversarial loss: 0.320952\n",
      "epoch 10; iter: 0; batch classifier loss: 0.360540; batch adversarial loss: 0.432955\n",
      "epoch 10; iter: 200; batch classifier loss: 0.489081; batch adversarial loss: 0.327345\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459959; batch adversarial loss: 0.418782\n",
      "epoch 11; iter: 200; batch classifier loss: 0.373197; batch adversarial loss: 0.410594\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306544; batch adversarial loss: 0.409656\n",
      "epoch 12; iter: 200; batch classifier loss: 0.285480; batch adversarial loss: 0.443539\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489096; batch adversarial loss: 0.389192\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326861; batch adversarial loss: 0.369208\n",
      "epoch 14; iter: 0; batch classifier loss: 0.414499; batch adversarial loss: 0.462193\n",
      "epoch 14; iter: 200; batch classifier loss: 0.297451; batch adversarial loss: 0.386507\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326107; batch adversarial loss: 0.485703\n",
      "epoch 15; iter: 200; batch classifier loss: 0.439162; batch adversarial loss: 0.460618\n",
      "epoch 16; iter: 0; batch classifier loss: 0.401877; batch adversarial loss: 0.348816\n",
      "epoch 16; iter: 200; batch classifier loss: 0.408606; batch adversarial loss: 0.372040\n",
      "epoch 17; iter: 0; batch classifier loss: 0.386522; batch adversarial loss: 0.328717\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343963; batch adversarial loss: 0.424665\n",
      "epoch 18; iter: 0; batch classifier loss: 0.357624; batch adversarial loss: 0.354922\n",
      "epoch 18; iter: 200; batch classifier loss: 0.279205; batch adversarial loss: 0.423441\n",
      "epoch 19; iter: 0; batch classifier loss: 0.401681; batch adversarial loss: 0.475512\n",
      "epoch 19; iter: 200; batch classifier loss: 0.262482; batch adversarial loss: 0.445602\n",
      "epoch 20; iter: 0; batch classifier loss: 0.369232; batch adversarial loss: 0.383994\n",
      "epoch 20; iter: 200; batch classifier loss: 0.325056; batch adversarial loss: 0.437270\n",
      "epoch 21; iter: 0; batch classifier loss: 0.339783; batch adversarial loss: 0.319789\n",
      "epoch 21; iter: 200; batch classifier loss: 0.387165; batch adversarial loss: 0.318673\n",
      "epoch 22; iter: 0; batch classifier loss: 0.316612; batch adversarial loss: 0.423523\n",
      "epoch 22; iter: 200; batch classifier loss: 0.314555; batch adversarial loss: 0.348704\n",
      "epoch 23; iter: 0; batch classifier loss: 0.389387; batch adversarial loss: 0.422497\n",
      "epoch 23; iter: 200; batch classifier loss: 0.391782; batch adversarial loss: 0.419463\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340491; batch adversarial loss: 0.414240\n",
      "epoch 24; iter: 200; batch classifier loss: 0.300025; batch adversarial loss: 0.470778\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278534; batch adversarial loss: 0.440286\n",
      "epoch 25; iter: 200; batch classifier loss: 0.323105; batch adversarial loss: 0.444371\n",
      "epoch 26; iter: 0; batch classifier loss: 0.344569; batch adversarial loss: 0.436262\n",
      "epoch 26; iter: 200; batch classifier loss: 0.358659; batch adversarial loss: 0.320767\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449609; batch adversarial loss: 0.335660\n",
      "epoch 27; iter: 200; batch classifier loss: 0.314085; batch adversarial loss: 0.368120\n",
      "epoch 28; iter: 0; batch classifier loss: 0.280627; batch adversarial loss: 0.481176\n",
      "epoch 28; iter: 200; batch classifier loss: 0.347599; batch adversarial loss: 0.477120\n",
      "epoch 29; iter: 0; batch classifier loss: 0.354330; batch adversarial loss: 0.441821\n",
      "epoch 29; iter: 200; batch classifier loss: 0.327295; batch adversarial loss: 0.472976\n",
      "epoch 30; iter: 0; batch classifier loss: 0.287845; batch adversarial loss: 0.333675\n",
      "epoch 30; iter: 200; batch classifier loss: 0.281347; batch adversarial loss: 0.407141\n",
      "epoch 31; iter: 0; batch classifier loss: 0.309055; batch adversarial loss: 0.400615\n",
      "epoch 31; iter: 200; batch classifier loss: 0.360111; batch adversarial loss: 0.384140\n",
      "epoch 32; iter: 0; batch classifier loss: 0.314333; batch adversarial loss: 0.454761\n",
      "epoch 32; iter: 200; batch classifier loss: 0.352821; batch adversarial loss: 0.372744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347925; batch adversarial loss: 0.394849\n",
      "epoch 33; iter: 200; batch classifier loss: 0.319589; batch adversarial loss: 0.437566\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306247; batch adversarial loss: 0.482606\n",
      "epoch 34; iter: 200; batch classifier loss: 0.290890; batch adversarial loss: 0.394768\n",
      "epoch 35; iter: 0; batch classifier loss: 0.269648; batch adversarial loss: 0.383301\n",
      "epoch 35; iter: 200; batch classifier loss: 0.376839; batch adversarial loss: 0.415305\n",
      "epoch 36; iter: 0; batch classifier loss: 0.344989; batch adversarial loss: 0.421017\n",
      "epoch 36; iter: 200; batch classifier loss: 0.376558; batch adversarial loss: 0.433952\n",
      "epoch 37; iter: 0; batch classifier loss: 0.379210; batch adversarial loss: 0.592756\n",
      "epoch 37; iter: 200; batch classifier loss: 0.323826; batch adversarial loss: 0.471454\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381732; batch adversarial loss: 0.400245\n",
      "epoch 38; iter: 200; batch classifier loss: 0.365470; batch adversarial loss: 0.493221\n",
      "epoch 39; iter: 0; batch classifier loss: 0.337690; batch adversarial loss: 0.374572\n",
      "epoch 39; iter: 200; batch classifier loss: 0.388899; batch adversarial loss: 0.406945\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404997; batch adversarial loss: 0.356753\n",
      "epoch 40; iter: 200; batch classifier loss: 0.324848; batch adversarial loss: 0.460029\n",
      "epoch 41; iter: 0; batch classifier loss: 0.299518; batch adversarial loss: 0.491721\n",
      "epoch 41; iter: 200; batch classifier loss: 0.324305; batch adversarial loss: 0.399824\n",
      "epoch 42; iter: 0; batch classifier loss: 0.313703; batch adversarial loss: 0.373862\n",
      "epoch 42; iter: 200; batch classifier loss: 0.310648; batch adversarial loss: 0.481235\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390103; batch adversarial loss: 0.345399\n",
      "epoch 43; iter: 200; batch classifier loss: 0.380488; batch adversarial loss: 0.338571\n",
      "epoch 44; iter: 0; batch classifier loss: 0.314815; batch adversarial loss: 0.441165\n",
      "epoch 44; iter: 200; batch classifier loss: 0.385722; batch adversarial loss: 0.547223\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426301; batch adversarial loss: 0.374726\n",
      "epoch 45; iter: 200; batch classifier loss: 0.385192; batch adversarial loss: 0.431219\n",
      "epoch 46; iter: 0; batch classifier loss: 0.366341; batch adversarial loss: 0.499840\n",
      "epoch 46; iter: 200; batch classifier loss: 0.369150; batch adversarial loss: 0.316545\n",
      "epoch 47; iter: 0; batch classifier loss: 0.220145; batch adversarial loss: 0.406997\n",
      "epoch 47; iter: 200; batch classifier loss: 0.377678; batch adversarial loss: 0.364502\n",
      "epoch 48; iter: 0; batch classifier loss: 0.274908; batch adversarial loss: 0.368355\n",
      "epoch 48; iter: 200; batch classifier loss: 0.464484; batch adversarial loss: 0.425328\n",
      "epoch 49; iter: 0; batch classifier loss: 0.270852; batch adversarial loss: 0.435036\n",
      "epoch 49; iter: 200; batch classifier loss: 0.405633; batch adversarial loss: 0.289117\n",
      "epoch 0; iter: 0; batch classifier loss: 10.634013; batch adversarial loss: 1.390679\n",
      "epoch 0; iter: 200; batch classifier loss: 9.643174; batch adversarial loss: 1.160500\n",
      "epoch 1; iter: 0; batch classifier loss: 7.819230; batch adversarial loss: 0.654215\n",
      "epoch 1; iter: 200; batch classifier loss: 8.105783; batch adversarial loss: 0.573810\n",
      "epoch 2; iter: 0; batch classifier loss: 4.613986; batch adversarial loss: 0.705424\n",
      "epoch 2; iter: 200; batch classifier loss: 3.625908; batch adversarial loss: 0.612700\n",
      "epoch 3; iter: 0; batch classifier loss: 3.890383; batch adversarial loss: 0.548957\n",
      "epoch 3; iter: 200; batch classifier loss: 2.399366; batch adversarial loss: 0.463755\n",
      "epoch 4; iter: 0; batch classifier loss: 1.160655; batch adversarial loss: 0.429188\n",
      "epoch 4; iter: 200; batch classifier loss: 1.443368; batch adversarial loss: 0.469811\n",
      "epoch 5; iter: 0; batch classifier loss: 1.042370; batch adversarial loss: 0.436043\n",
      "epoch 5; iter: 200; batch classifier loss: 0.910562; batch adversarial loss: 0.442919\n",
      "epoch 6; iter: 0; batch classifier loss: 1.175207; batch adversarial loss: 0.416818\n",
      "epoch 6; iter: 200; batch classifier loss: 0.950627; batch adversarial loss: 0.433744\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528062; batch adversarial loss: 0.410875\n",
      "epoch 7; iter: 200; batch classifier loss: 0.914773; batch adversarial loss: 0.462758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.676747; batch adversarial loss: 0.391198\n",
      "epoch 8; iter: 200; batch classifier loss: 0.650853; batch adversarial loss: 0.464907\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312023; batch adversarial loss: 0.359443\n",
      "epoch 9; iter: 200; batch classifier loss: 0.396481; batch adversarial loss: 0.474134\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520167; batch adversarial loss: 0.467891\n",
      "epoch 10; iter: 200; batch classifier loss: 0.392208; batch adversarial loss: 0.419743\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372949; batch adversarial loss: 0.342049\n",
      "epoch 11; iter: 200; batch classifier loss: 0.357882; batch adversarial loss: 0.428623\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396762; batch adversarial loss: 0.414793\n",
      "epoch 12; iter: 200; batch classifier loss: 0.345522; batch adversarial loss: 0.456286\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476086; batch adversarial loss: 0.376604\n",
      "epoch 13; iter: 200; batch classifier loss: 0.335108; batch adversarial loss: 0.385388\n",
      "epoch 14; iter: 0; batch classifier loss: 0.365507; batch adversarial loss: 0.357183\n",
      "epoch 14; iter: 200; batch classifier loss: 0.540051; batch adversarial loss: 0.497451\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494433; batch adversarial loss: 0.482283\n",
      "epoch 15; iter: 200; batch classifier loss: 0.644448; batch adversarial loss: 0.419144\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454545; batch adversarial loss: 0.374722\n",
      "epoch 16; iter: 200; batch classifier loss: 0.402948; batch adversarial loss: 0.392692\n",
      "epoch 17; iter: 0; batch classifier loss: 0.385544; batch adversarial loss: 0.434951\n",
      "epoch 17; iter: 200; batch classifier loss: 0.464057; batch adversarial loss: 0.428646\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308972; batch adversarial loss: 0.438558\n",
      "epoch 18; iter: 200; batch classifier loss: 0.401165; batch adversarial loss: 0.497826\n",
      "epoch 19; iter: 0; batch classifier loss: 0.336338; batch adversarial loss: 0.345392\n",
      "epoch 19; iter: 200; batch classifier loss: 0.400471; batch adversarial loss: 0.466654\n",
      "epoch 20; iter: 0; batch classifier loss: 0.483831; batch adversarial loss: 0.475286\n",
      "epoch 20; iter: 200; batch classifier loss: 0.684053; batch adversarial loss: 0.463952\n",
      "epoch 21; iter: 0; batch classifier loss: 0.385942; batch adversarial loss: 0.429915\n",
      "epoch 21; iter: 200; batch classifier loss: 0.300674; batch adversarial loss: 0.382001\n",
      "epoch 22; iter: 0; batch classifier loss: 0.371163; batch adversarial loss: 0.368059\n",
      "epoch 22; iter: 200; batch classifier loss: 0.338239; batch adversarial loss: 0.517349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.352203; batch adversarial loss: 0.416222\n",
      "epoch 23; iter: 200; batch classifier loss: 0.375107; batch adversarial loss: 0.391914\n",
      "epoch 24; iter: 0; batch classifier loss: 0.381796; batch adversarial loss: 0.262436\n",
      "epoch 24; iter: 200; batch classifier loss: 0.347176; batch adversarial loss: 0.400980\n",
      "epoch 25; iter: 0; batch classifier loss: 0.377032; batch adversarial loss: 0.416847\n",
      "epoch 25; iter: 200; batch classifier loss: 0.285538; batch adversarial loss: 0.499732\n",
      "epoch 26; iter: 0; batch classifier loss: 0.384959; batch adversarial loss: 0.383836\n",
      "epoch 26; iter: 200; batch classifier loss: 0.301663; batch adversarial loss: 0.448764\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315581; batch adversarial loss: 0.413824\n",
      "epoch 27; iter: 200; batch classifier loss: 0.282626; batch adversarial loss: 0.338057\n",
      "epoch 28; iter: 0; batch classifier loss: 0.391355; batch adversarial loss: 0.264070\n",
      "epoch 28; iter: 200; batch classifier loss: 0.429957; batch adversarial loss: 0.429110\n",
      "epoch 29; iter: 0; batch classifier loss: 0.311311; batch adversarial loss: 0.389842\n",
      "epoch 29; iter: 200; batch classifier loss: 0.388035; batch adversarial loss: 0.412477\n",
      "epoch 30; iter: 0; batch classifier loss: 0.336969; batch adversarial loss: 0.275516\n",
      "epoch 30; iter: 200; batch classifier loss: 0.327425; batch adversarial loss: 0.468000\n",
      "epoch 31; iter: 0; batch classifier loss: 0.403782; batch adversarial loss: 0.473630\n",
      "epoch 31; iter: 200; batch classifier loss: 0.597505; batch adversarial loss: 0.413764\n",
      "epoch 32; iter: 0; batch classifier loss: 0.275659; batch adversarial loss: 0.427813\n",
      "epoch 32; iter: 200; batch classifier loss: 0.295229; batch adversarial loss: 0.341160\n",
      "epoch 33; iter: 0; batch classifier loss: 0.350342; batch adversarial loss: 0.426033\n",
      "epoch 33; iter: 200; batch classifier loss: 0.404825; batch adversarial loss: 0.321554\n",
      "epoch 34; iter: 0; batch classifier loss: 0.309576; batch adversarial loss: 0.371422\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338466; batch adversarial loss: 0.313122\n",
      "epoch 35; iter: 0; batch classifier loss: 0.388320; batch adversarial loss: 0.362575\n",
      "epoch 35; iter: 200; batch classifier loss: 0.305093; batch adversarial loss: 0.384105\n",
      "epoch 36; iter: 0; batch classifier loss: 0.297696; batch adversarial loss: 0.512398\n",
      "epoch 36; iter: 200; batch classifier loss: 0.396073; batch adversarial loss: 0.496324\n",
      "epoch 37; iter: 0; batch classifier loss: 0.311258; batch adversarial loss: 0.456765\n",
      "epoch 37; iter: 200; batch classifier loss: 0.384113; batch adversarial loss: 0.351626\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286607; batch adversarial loss: 0.381090\n",
      "epoch 38; iter: 200; batch classifier loss: 0.296454; batch adversarial loss: 0.426365\n",
      "epoch 39; iter: 0; batch classifier loss: 0.361744; batch adversarial loss: 0.456665\n",
      "epoch 39; iter: 200; batch classifier loss: 0.337129; batch adversarial loss: 0.426370\n",
      "epoch 40; iter: 0; batch classifier loss: 0.336946; batch adversarial loss: 0.349305\n",
      "epoch 40; iter: 200; batch classifier loss: 0.273977; batch adversarial loss: 0.430027\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388618; batch adversarial loss: 0.428394\n",
      "epoch 41; iter: 200; batch classifier loss: 0.401323; batch adversarial loss: 0.375052\n",
      "epoch 42; iter: 0; batch classifier loss: 0.359605; batch adversarial loss: 0.390782\n",
      "epoch 42; iter: 200; batch classifier loss: 0.357691; batch adversarial loss: 0.357756\n",
      "epoch 43; iter: 0; batch classifier loss: 0.551258; batch adversarial loss: 0.416085\n",
      "epoch 43; iter: 200; batch classifier loss: 0.353844; batch adversarial loss: 0.373679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321842; batch adversarial loss: 0.403209\n",
      "epoch 44; iter: 200; batch classifier loss: 0.318108; batch adversarial loss: 0.468295\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364964; batch adversarial loss: 0.516803\n",
      "epoch 45; iter: 200; batch classifier loss: 0.279543; batch adversarial loss: 0.424373\n",
      "epoch 46; iter: 0; batch classifier loss: 0.369214; batch adversarial loss: 0.489362\n",
      "epoch 46; iter: 200; batch classifier loss: 0.325228; batch adversarial loss: 0.462004\n",
      "epoch 47; iter: 0; batch classifier loss: 0.354918; batch adversarial loss: 0.435335\n",
      "epoch 47; iter: 200; batch classifier loss: 0.363586; batch adversarial loss: 0.294198\n",
      "epoch 48; iter: 0; batch classifier loss: 0.363366; batch adversarial loss: 0.421461\n",
      "epoch 48; iter: 200; batch classifier loss: 0.269295; batch adversarial loss: 0.460311\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433637; batch adversarial loss: 0.444068\n",
      "epoch 49; iter: 200; batch classifier loss: 0.290947; batch adversarial loss: 0.346684\n",
      "epoch 0; iter: 0; batch classifier loss: 14.532895; batch adversarial loss: 0.664111\n",
      "epoch 0; iter: 200; batch classifier loss: 7.507792; batch adversarial loss: 0.561224\n",
      "epoch 1; iter: 0; batch classifier loss: 5.945837; batch adversarial loss: 0.527299\n",
      "epoch 1; iter: 200; batch classifier loss: 7.185260; batch adversarial loss: 0.546070\n",
      "epoch 2; iter: 0; batch classifier loss: 2.983517; batch adversarial loss: 0.474400\n",
      "epoch 2; iter: 200; batch classifier loss: 0.973138; batch adversarial loss: 0.418432\n",
      "epoch 3; iter: 0; batch classifier loss: 3.702502; batch adversarial loss: 0.379805\n",
      "epoch 3; iter: 200; batch classifier loss: 1.226130; batch adversarial loss: 0.420926\n",
      "epoch 4; iter: 0; batch classifier loss: 1.041460; batch adversarial loss: 0.455246\n",
      "epoch 4; iter: 200; batch classifier loss: 0.801948; batch adversarial loss: 0.476521\n",
      "epoch 5; iter: 0; batch classifier loss: 2.314555; batch adversarial loss: 0.385942\n",
      "epoch 5; iter: 200; batch classifier loss: 0.785754; batch adversarial loss: 0.515714\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330318; batch adversarial loss: 0.441162\n",
      "epoch 6; iter: 200; batch classifier loss: 0.365742; batch adversarial loss: 0.396388\n",
      "epoch 7; iter: 0; batch classifier loss: 0.370265; batch adversarial loss: 0.384786\n",
      "epoch 7; iter: 200; batch classifier loss: 0.389985; batch adversarial loss: 0.400618\n",
      "epoch 8; iter: 0; batch classifier loss: 0.638844; batch adversarial loss: 0.458961\n",
      "epoch 8; iter: 200; batch classifier loss: 0.458953; batch adversarial loss: 0.447234\n",
      "epoch 9; iter: 0; batch classifier loss: 0.429367; batch adversarial loss: 0.328405\n",
      "epoch 9; iter: 200; batch classifier loss: 0.393517; batch adversarial loss: 0.361643\n",
      "epoch 10; iter: 0; batch classifier loss: 0.377405; batch adversarial loss: 0.381682\n",
      "epoch 10; iter: 200; batch classifier loss: 0.351671; batch adversarial loss: 0.442224\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420065; batch adversarial loss: 0.377886\n",
      "epoch 11; iter: 200; batch classifier loss: 0.507919; batch adversarial loss: 0.457252\n",
      "epoch 12; iter: 0; batch classifier loss: 0.944187; batch adversarial loss: 0.449394\n",
      "epoch 12; iter: 200; batch classifier loss: 0.402934; batch adversarial loss: 0.421843\n",
      "epoch 13; iter: 0; batch classifier loss: 0.354706; batch adversarial loss: 0.361246\n",
      "epoch 13; iter: 200; batch classifier loss: 0.327201; batch adversarial loss: 0.471273\n",
      "epoch 14; iter: 0; batch classifier loss: 0.327669; batch adversarial loss: 0.322660\n",
      "epoch 14; iter: 200; batch classifier loss: 0.361880; batch adversarial loss: 0.369965\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409409; batch adversarial loss: 0.444322\n",
      "epoch 15; iter: 200; batch classifier loss: 0.317390; batch adversarial loss: 0.380861\n",
      "epoch 16; iter: 0; batch classifier loss: 0.433464; batch adversarial loss: 0.298445\n",
      "epoch 16; iter: 200; batch classifier loss: 0.308060; batch adversarial loss: 0.407704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.423752; batch adversarial loss: 0.446946\n",
      "epoch 17; iter: 200; batch classifier loss: 0.492321; batch adversarial loss: 0.413344\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335613; batch adversarial loss: 0.403996\n",
      "epoch 18; iter: 200; batch classifier loss: 0.303190; batch adversarial loss: 0.342398\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430979; batch adversarial loss: 0.338526\n",
      "epoch 19; iter: 200; batch classifier loss: 0.296324; batch adversarial loss: 0.333496\n",
      "epoch 20; iter: 0; batch classifier loss: 0.250601; batch adversarial loss: 0.404041\n",
      "epoch 20; iter: 200; batch classifier loss: 0.464207; batch adversarial loss: 0.428904\n",
      "epoch 21; iter: 0; batch classifier loss: 0.357795; batch adversarial loss: 0.448148\n",
      "epoch 21; iter: 200; batch classifier loss: 0.297751; batch adversarial loss: 0.430130\n",
      "epoch 22; iter: 0; batch classifier loss: 0.414306; batch adversarial loss: 0.439230\n",
      "epoch 22; iter: 200; batch classifier loss: 0.335356; batch adversarial loss: 0.348295\n",
      "epoch 23; iter: 0; batch classifier loss: 0.364886; batch adversarial loss: 0.468778\n",
      "epoch 23; iter: 200; batch classifier loss: 0.309021; batch adversarial loss: 0.431854\n",
      "epoch 24; iter: 0; batch classifier loss: 0.348031; batch adversarial loss: 0.407371\n",
      "epoch 24; iter: 200; batch classifier loss: 0.437576; batch adversarial loss: 0.298433\n",
      "epoch 25; iter: 0; batch classifier loss: 0.328078; batch adversarial loss: 0.399472\n",
      "epoch 25; iter: 200; batch classifier loss: 0.380422; batch adversarial loss: 0.422248\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387204; batch adversarial loss: 0.515304\n",
      "epoch 26; iter: 200; batch classifier loss: 0.310112; batch adversarial loss: 0.497974\n",
      "epoch 27; iter: 0; batch classifier loss: 0.265354; batch adversarial loss: 0.525800\n",
      "epoch 27; iter: 200; batch classifier loss: 0.279617; batch adversarial loss: 0.476086\n",
      "epoch 28; iter: 0; batch classifier loss: 0.294355; batch adversarial loss: 0.542922\n",
      "epoch 28; iter: 200; batch classifier loss: 0.447184; batch adversarial loss: 0.516326\n",
      "epoch 29; iter: 0; batch classifier loss: 0.256629; batch adversarial loss: 0.403400\n",
      "epoch 29; iter: 200; batch classifier loss: 0.291131; batch adversarial loss: 0.416615\n",
      "epoch 30; iter: 0; batch classifier loss: 0.297077; batch adversarial loss: 0.493604\n",
      "epoch 30; iter: 200; batch classifier loss: 0.304956; batch adversarial loss: 0.429947\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328308; batch adversarial loss: 0.392567\n",
      "epoch 31; iter: 200; batch classifier loss: 0.345430; batch adversarial loss: 0.428283\n",
      "epoch 32; iter: 0; batch classifier loss: 0.308698; batch adversarial loss: 0.393455\n",
      "epoch 32; iter: 200; batch classifier loss: 0.394004; batch adversarial loss: 0.424755\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347719; batch adversarial loss: 0.425352\n",
      "epoch 33; iter: 200; batch classifier loss: 0.341684; batch adversarial loss: 0.376329\n",
      "epoch 34; iter: 0; batch classifier loss: 0.322967; batch adversarial loss: 0.341568\n",
      "epoch 34; iter: 200; batch classifier loss: 0.367224; batch adversarial loss: 0.372146\n",
      "epoch 35; iter: 0; batch classifier loss: 0.339108; batch adversarial loss: 0.454864\n",
      "epoch 35; iter: 200; batch classifier loss: 0.534338; batch adversarial loss: 0.370160\n",
      "epoch 36; iter: 0; batch classifier loss: 0.289311; batch adversarial loss: 0.465995\n",
      "epoch 36; iter: 200; batch classifier loss: 0.437174; batch adversarial loss: 0.569142\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485261; batch adversarial loss: 0.377640\n",
      "epoch 37; iter: 200; batch classifier loss: 0.372585; batch adversarial loss: 0.334471\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423762; batch adversarial loss: 0.389403\n",
      "epoch 38; iter: 200; batch classifier loss: 0.307242; batch adversarial loss: 0.387790\n",
      "epoch 39; iter: 0; batch classifier loss: 0.294983; batch adversarial loss: 0.437638\n",
      "epoch 39; iter: 200; batch classifier loss: 0.318473; batch adversarial loss: 0.376672\n",
      "epoch 40; iter: 0; batch classifier loss: 0.315558; batch adversarial loss: 0.535369\n",
      "epoch 40; iter: 200; batch classifier loss: 0.398317; batch adversarial loss: 0.459032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.370193; batch adversarial loss: 0.360703\n",
      "epoch 41; iter: 200; batch classifier loss: 0.278480; batch adversarial loss: 0.409315\n",
      "epoch 42; iter: 0; batch classifier loss: 0.972238; batch adversarial loss: 0.461730\n",
      "epoch 42; iter: 200; batch classifier loss: 0.367652; batch adversarial loss: 0.534759\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471273; batch adversarial loss: 0.378012\n",
      "epoch 43; iter: 200; batch classifier loss: 0.415000; batch adversarial loss: 0.410684\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396108; batch adversarial loss: 0.364419\n",
      "epoch 44; iter: 200; batch classifier loss: 0.324596; batch adversarial loss: 0.388347\n",
      "epoch 45; iter: 0; batch classifier loss: 0.429946; batch adversarial loss: 0.425283\n",
      "epoch 45; iter: 200; batch classifier loss: 0.385777; batch adversarial loss: 0.419295\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437453; batch adversarial loss: 0.419523\n",
      "epoch 46; iter: 200; batch classifier loss: 0.237836; batch adversarial loss: 0.510867\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383109; batch adversarial loss: 0.373708\n",
      "epoch 47; iter: 200; batch classifier loss: 0.329142; batch adversarial loss: 0.444117\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387954; batch adversarial loss: 0.438738\n",
      "epoch 48; iter: 200; batch classifier loss: 0.323885; batch adversarial loss: 0.403250\n",
      "epoch 49; iter: 0; batch classifier loss: 0.266819; batch adversarial loss: 0.468573\n",
      "epoch 49; iter: 200; batch classifier loss: 0.352397; batch adversarial loss: 0.283927\n",
      "epoch 0; iter: 0; batch classifier loss: 14.484293; batch adversarial loss: 0.888059\n",
      "epoch 0; iter: 200; batch classifier loss: 12.930403; batch adversarial loss: 0.662637\n",
      "epoch 1; iter: 0; batch classifier loss: 5.961664; batch adversarial loss: 0.614786\n",
      "epoch 1; iter: 200; batch classifier loss: 3.931326; batch adversarial loss: 0.519753\n",
      "epoch 2; iter: 0; batch classifier loss: 3.329124; batch adversarial loss: 0.533344\n",
      "epoch 2; iter: 200; batch classifier loss: 2.400372; batch adversarial loss: 0.464732\n",
      "epoch 3; iter: 0; batch classifier loss: 0.804631; batch adversarial loss: 0.507145\n",
      "epoch 3; iter: 200; batch classifier loss: 2.245032; batch adversarial loss: 0.488965\n",
      "epoch 4; iter: 0; batch classifier loss: 0.981564; batch adversarial loss: 0.412938\n",
      "epoch 4; iter: 200; batch classifier loss: 6.925901; batch adversarial loss: 0.360923\n",
      "epoch 5; iter: 0; batch classifier loss: 0.634727; batch adversarial loss: 0.390543\n",
      "epoch 5; iter: 200; batch classifier loss: 0.474042; batch adversarial loss: 0.482196\n",
      "epoch 6; iter: 0; batch classifier loss: 0.355303; batch adversarial loss: 0.365596\n",
      "epoch 6; iter: 200; batch classifier loss: 0.324120; batch adversarial loss: 0.392481\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534702; batch adversarial loss: 0.427779\n",
      "epoch 7; iter: 200; batch classifier loss: 0.352963; batch adversarial loss: 0.407920\n",
      "epoch 8; iter: 0; batch classifier loss: 0.445463; batch adversarial loss: 0.309034\n",
      "epoch 8; iter: 200; batch classifier loss: 0.447041; batch adversarial loss: 0.406169\n",
      "epoch 9; iter: 0; batch classifier loss: 0.439365; batch adversarial loss: 0.412682\n",
      "epoch 9; iter: 200; batch classifier loss: 0.465279; batch adversarial loss: 0.300087\n",
      "epoch 10; iter: 0; batch classifier loss: 0.382434; batch adversarial loss: 0.419640\n",
      "epoch 10; iter: 200; batch classifier loss: 0.383454; batch adversarial loss: 0.413405\n",
      "epoch 11; iter: 0; batch classifier loss: 0.734291; batch adversarial loss: 0.388533\n",
      "epoch 11; iter: 200; batch classifier loss: 0.464263; batch adversarial loss: 0.386916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.409202; batch adversarial loss: 0.388416\n",
      "epoch 12; iter: 200; batch classifier loss: 0.456502; batch adversarial loss: 0.473259\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350996; batch adversarial loss: 0.525256\n",
      "epoch 13; iter: 200; batch classifier loss: 0.380899; batch adversarial loss: 0.338240\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481492; batch adversarial loss: 0.507666\n",
      "epoch 14; iter: 200; batch classifier loss: 0.358855; batch adversarial loss: 0.394749\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391955; batch adversarial loss: 0.512184\n",
      "epoch 15; iter: 200; batch classifier loss: 0.417312; batch adversarial loss: 0.455609\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372284; batch adversarial loss: 0.371497\n",
      "epoch 16; iter: 200; batch classifier loss: 0.297521; batch adversarial loss: 0.488492\n",
      "epoch 17; iter: 0; batch classifier loss: 0.422326; batch adversarial loss: 0.341460\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364671; batch adversarial loss: 0.434207\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523385; batch adversarial loss: 0.326320\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326470; batch adversarial loss: 0.454174\n",
      "epoch 19; iter: 0; batch classifier loss: 0.600268; batch adversarial loss: 0.390631\n",
      "epoch 19; iter: 200; batch classifier loss: 0.311152; batch adversarial loss: 0.418305\n",
      "epoch 20; iter: 0; batch classifier loss: 0.380839; batch adversarial loss: 0.446801\n",
      "epoch 20; iter: 200; batch classifier loss: 0.325602; batch adversarial loss: 0.478934\n",
      "epoch 21; iter: 0; batch classifier loss: 0.342585; batch adversarial loss: 0.402099\n",
      "epoch 21; iter: 200; batch classifier loss: 0.357453; batch adversarial loss: 0.436711\n",
      "epoch 22; iter: 0; batch classifier loss: 0.376304; batch adversarial loss: 0.444602\n",
      "epoch 22; iter: 200; batch classifier loss: 0.362932; batch adversarial loss: 0.381853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.388328; batch adversarial loss: 0.360566\n",
      "epoch 23; iter: 200; batch classifier loss: 0.316345; batch adversarial loss: 0.479662\n",
      "epoch 24; iter: 0; batch classifier loss: 0.374625; batch adversarial loss: 0.440288\n",
      "epoch 24; iter: 200; batch classifier loss: 0.334522; batch adversarial loss: 0.488473\n",
      "epoch 25; iter: 0; batch classifier loss: 0.348008; batch adversarial loss: 0.401734\n",
      "epoch 25; iter: 200; batch classifier loss: 0.350159; batch adversarial loss: 0.434594\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406918; batch adversarial loss: 0.423055\n",
      "epoch 26; iter: 200; batch classifier loss: 0.440712; batch adversarial loss: 0.488490\n",
      "epoch 27; iter: 0; batch classifier loss: 0.304965; batch adversarial loss: 0.459950\n",
      "epoch 27; iter: 200; batch classifier loss: 0.345020; batch adversarial loss: 0.396167\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453623; batch adversarial loss: 0.423572\n",
      "epoch 28; iter: 200; batch classifier loss: 0.425325; batch adversarial loss: 0.435116\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394627; batch adversarial loss: 0.346387\n",
      "epoch 29; iter: 200; batch classifier loss: 0.342120; batch adversarial loss: 0.367054\n",
      "epoch 30; iter: 0; batch classifier loss: 0.343070; batch adversarial loss: 0.354036\n",
      "epoch 30; iter: 200; batch classifier loss: 0.386214; batch adversarial loss: 0.319550\n",
      "epoch 31; iter: 0; batch classifier loss: 0.286671; batch adversarial loss: 0.393646\n",
      "epoch 31; iter: 200; batch classifier loss: 0.296277; batch adversarial loss: 0.419437\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361506; batch adversarial loss: 0.409657\n",
      "epoch 32; iter: 200; batch classifier loss: 0.398328; batch adversarial loss: 0.399985\n",
      "epoch 33; iter: 0; batch classifier loss: 0.332595; batch adversarial loss: 0.350205\n",
      "epoch 33; iter: 200; batch classifier loss: 0.417451; batch adversarial loss: 0.379539\n",
      "epoch 34; iter: 0; batch classifier loss: 0.377016; batch adversarial loss: 0.459778\n",
      "epoch 34; iter: 200; batch classifier loss: 0.293052; batch adversarial loss: 0.440086\n",
      "epoch 35; iter: 0; batch classifier loss: 0.339564; batch adversarial loss: 0.444444\n",
      "epoch 35; iter: 200; batch classifier loss: 0.347098; batch adversarial loss: 0.439877\n",
      "epoch 36; iter: 0; batch classifier loss: 0.317216; batch adversarial loss: 0.512485\n",
      "epoch 36; iter: 200; batch classifier loss: 0.310540; batch adversarial loss: 0.462155\n",
      "epoch 37; iter: 0; batch classifier loss: 0.350498; batch adversarial loss: 0.417981\n",
      "epoch 37; iter: 200; batch classifier loss: 0.375604; batch adversarial loss: 0.429222\n",
      "epoch 38; iter: 0; batch classifier loss: 0.369723; batch adversarial loss: 0.435576\n",
      "epoch 38; iter: 200; batch classifier loss: 0.310189; batch adversarial loss: 0.388253\n",
      "epoch 39; iter: 0; batch classifier loss: 0.335286; batch adversarial loss: 0.427246\n",
      "epoch 39; iter: 200; batch classifier loss: 0.388348; batch adversarial loss: 0.437588\n",
      "epoch 40; iter: 0; batch classifier loss: 0.374490; batch adversarial loss: 0.472204\n",
      "epoch 40; iter: 200; batch classifier loss: 0.271290; batch adversarial loss: 0.429050\n",
      "epoch 41; iter: 0; batch classifier loss: 0.311891; batch adversarial loss: 0.332479\n",
      "epoch 41; iter: 200; batch classifier loss: 0.351123; batch adversarial loss: 0.456675\n",
      "epoch 42; iter: 0; batch classifier loss: 0.336257; batch adversarial loss: 0.353836\n",
      "epoch 42; iter: 200; batch classifier loss: 0.288656; batch adversarial loss: 0.351042\n",
      "epoch 43; iter: 0; batch classifier loss: 0.459677; batch adversarial loss: 0.426234\n",
      "epoch 43; iter: 200; batch classifier loss: 0.382747; batch adversarial loss: 0.416493\n",
      "epoch 44; iter: 0; batch classifier loss: 0.283672; batch adversarial loss: 0.411911\n",
      "epoch 44; iter: 200; batch classifier loss: 0.285644; batch adversarial loss: 0.366275\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419432; batch adversarial loss: 0.465851\n",
      "epoch 45; iter: 200; batch classifier loss: 0.397817; batch adversarial loss: 0.431915\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389757; batch adversarial loss: 0.371451\n",
      "epoch 46; iter: 200; batch classifier loss: 0.393460; batch adversarial loss: 0.404206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340890; batch adversarial loss: 0.369381\n",
      "epoch 47; iter: 200; batch classifier loss: 0.354469; batch adversarial loss: 0.349459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.332967; batch adversarial loss: 0.364885\n",
      "epoch 48; iter: 200; batch classifier loss: 0.374202; batch adversarial loss: 0.434096\n",
      "epoch 49; iter: 0; batch classifier loss: 0.602018; batch adversarial loss: 0.410629\n",
      "epoch 49; iter: 200; batch classifier loss: 0.326882; batch adversarial loss: 0.380826\n",
      "epoch 0; iter: 0; batch classifier loss: 273.433105; batch adversarial loss: 0.685798\n",
      "epoch 0; iter: 200; batch classifier loss: 6.430485; batch adversarial loss: 0.595523\n",
      "epoch 1; iter: 0; batch classifier loss: 3.762621; batch adversarial loss: 0.571135\n",
      "epoch 1; iter: 200; batch classifier loss: 3.545974; batch adversarial loss: 0.521852\n",
      "epoch 2; iter: 0; batch classifier loss: 1.563399; batch adversarial loss: 0.477496\n",
      "epoch 2; iter: 200; batch classifier loss: 7.670728; batch adversarial loss: 0.460386\n",
      "epoch 3; iter: 0; batch classifier loss: 3.199557; batch adversarial loss: 0.465310\n",
      "epoch 3; iter: 200; batch classifier loss: 0.774363; batch adversarial loss: 0.416547\n",
      "epoch 4; iter: 0; batch classifier loss: 4.705227; batch adversarial loss: 0.426895\n",
      "epoch 4; iter: 200; batch classifier loss: 3.696603; batch adversarial loss: 0.384903\n",
      "epoch 5; iter: 0; batch classifier loss: 2.056386; batch adversarial loss: 0.430023\n",
      "epoch 5; iter: 200; batch classifier loss: 0.663914; batch adversarial loss: 0.461429\n",
      "epoch 6; iter: 0; batch classifier loss: 1.591106; batch adversarial loss: 0.386382\n",
      "epoch 6; iter: 200; batch classifier loss: 0.421027; batch adversarial loss: 0.379313\n",
      "epoch 7; iter: 0; batch classifier loss: 1.933888; batch adversarial loss: 0.377093\n",
      "epoch 7; iter: 200; batch classifier loss: 0.377045; batch adversarial loss: 0.395250\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590038; batch adversarial loss: 0.434270\n",
      "epoch 8; iter: 200; batch classifier loss: 0.368747; batch adversarial loss: 0.344097\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465077; batch adversarial loss: 0.419083\n",
      "epoch 9; iter: 200; batch classifier loss: 0.486599; batch adversarial loss: 0.362649\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526928; batch adversarial loss: 0.567885\n",
      "epoch 10; iter: 200; batch classifier loss: 0.473178; batch adversarial loss: 0.464486\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465566; batch adversarial loss: 0.490597\n",
      "epoch 11; iter: 200; batch classifier loss: 0.446757; batch adversarial loss: 0.369952\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430505; batch adversarial loss: 0.403954\n",
      "epoch 12; iter: 200; batch classifier loss: 0.493746; batch adversarial loss: 0.340980\n",
      "epoch 13; iter: 0; batch classifier loss: 0.459397; batch adversarial loss: 0.440419\n",
      "epoch 13; iter: 200; batch classifier loss: 0.480660; batch adversarial loss: 0.598478\n",
      "epoch 14; iter: 0; batch classifier loss: 0.440360; batch adversarial loss: 0.392895\n",
      "epoch 14; iter: 200; batch classifier loss: 0.377845; batch adversarial loss: 0.354143\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364178; batch adversarial loss: 0.491038\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380725; batch adversarial loss: 0.286449\n",
      "epoch 16; iter: 0; batch classifier loss: 0.295289; batch adversarial loss: 0.500659\n",
      "epoch 16; iter: 200; batch classifier loss: 0.398193; batch adversarial loss: 0.415133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.270940; batch adversarial loss: 0.397022\n",
      "epoch 17; iter: 200; batch classifier loss: 0.327512; batch adversarial loss: 0.511439\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499663; batch adversarial loss: 0.391945\n",
      "epoch 18; iter: 200; batch classifier loss: 0.332972; batch adversarial loss: 0.393413\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298301; batch adversarial loss: 0.480968\n",
      "epoch 19; iter: 200; batch classifier loss: 0.477360; batch adversarial loss: 0.540853\n",
      "epoch 20; iter: 0; batch classifier loss: 0.329754; batch adversarial loss: 0.415532\n",
      "epoch 20; iter: 200; batch classifier loss: 0.314621; batch adversarial loss: 0.346079\n",
      "epoch 21; iter: 0; batch classifier loss: 0.380359; batch adversarial loss: 0.469782\n",
      "epoch 21; iter: 200; batch classifier loss: 0.421294; batch adversarial loss: 0.365458\n",
      "epoch 22; iter: 0; batch classifier loss: 0.332842; batch adversarial loss: 0.536844\n",
      "epoch 22; iter: 200; batch classifier loss: 0.343693; batch adversarial loss: 0.447994\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396275; batch adversarial loss: 0.516742\n",
      "epoch 23; iter: 200; batch classifier loss: 0.381622; batch adversarial loss: 0.342780\n",
      "epoch 24; iter: 0; batch classifier loss: 0.378450; batch adversarial loss: 0.415500\n",
      "epoch 24; iter: 200; batch classifier loss: 0.301675; batch adversarial loss: 0.374957\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553671; batch adversarial loss: 0.253254\n",
      "epoch 25; iter: 200; batch classifier loss: 0.432707; batch adversarial loss: 0.394625\n",
      "epoch 26; iter: 0; batch classifier loss: 0.291983; batch adversarial loss: 0.409804\n",
      "epoch 26; iter: 200; batch classifier loss: 0.345013; batch adversarial loss: 0.484918\n",
      "epoch 27; iter: 0; batch classifier loss: 0.378686; batch adversarial loss: 0.464591\n",
      "epoch 27; iter: 200; batch classifier loss: 0.316864; batch adversarial loss: 0.387193\n",
      "epoch 28; iter: 0; batch classifier loss: 0.298456; batch adversarial loss: 0.427405\n",
      "epoch 28; iter: 200; batch classifier loss: 0.353125; batch adversarial loss: 0.327189\n",
      "epoch 29; iter: 0; batch classifier loss: 0.350901; batch adversarial loss: 0.338209\n",
      "epoch 29; iter: 200; batch classifier loss: 0.347695; batch adversarial loss: 0.407603\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320991; batch adversarial loss: 0.502655\n",
      "epoch 30; iter: 200; batch classifier loss: 0.384982; batch adversarial loss: 0.505165\n",
      "epoch 31; iter: 0; batch classifier loss: 0.367857; batch adversarial loss: 0.468483\n",
      "epoch 31; iter: 200; batch classifier loss: 0.324328; batch adversarial loss: 0.411168\n",
      "epoch 32; iter: 0; batch classifier loss: 0.333195; batch adversarial loss: 0.443339\n",
      "epoch 32; iter: 200; batch classifier loss: 0.281717; batch adversarial loss: 0.363003\n",
      "epoch 33; iter: 0; batch classifier loss: 0.352417; batch adversarial loss: 0.515843\n",
      "epoch 33; iter: 200; batch classifier loss: 0.264060; batch adversarial loss: 0.422353\n",
      "epoch 34; iter: 0; batch classifier loss: 0.327124; batch adversarial loss: 0.360696\n",
      "epoch 34; iter: 200; batch classifier loss: 0.271492; batch adversarial loss: 0.424719\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317298; batch adversarial loss: 0.364703\n",
      "epoch 35; iter: 200; batch classifier loss: 0.332979; batch adversarial loss: 0.496766\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404756; batch adversarial loss: 0.432939\n",
      "epoch 36; iter: 200; batch classifier loss: 0.306266; batch adversarial loss: 0.346663\n",
      "epoch 37; iter: 0; batch classifier loss: 0.646679; batch adversarial loss: 0.430184\n",
      "epoch 37; iter: 200; batch classifier loss: 0.409648; batch adversarial loss: 0.440520\n",
      "epoch 38; iter: 0; batch classifier loss: 0.326819; batch adversarial loss: 0.417750\n",
      "epoch 38; iter: 200; batch classifier loss: 0.231422; batch adversarial loss: 0.440885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428067; batch adversarial loss: 0.467976\n",
      "epoch 39; iter: 200; batch classifier loss: 0.313982; batch adversarial loss: 0.406862\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351117; batch adversarial loss: 0.370395\n",
      "epoch 40; iter: 200; batch classifier loss: 0.315192; batch adversarial loss: 0.464835\n",
      "epoch 41; iter: 0; batch classifier loss: 0.285273; batch adversarial loss: 0.479746\n",
      "epoch 41; iter: 200; batch classifier loss: 0.359529; batch adversarial loss: 0.379182\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409309; batch adversarial loss: 0.314522\n",
      "epoch 42; iter: 200; batch classifier loss: 0.705552; batch adversarial loss: 0.379250\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421225; batch adversarial loss: 0.329305\n",
      "epoch 43; iter: 200; batch classifier loss: 0.409642; batch adversarial loss: 0.433351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.324699; batch adversarial loss: 0.385527\n",
      "epoch 44; iter: 200; batch classifier loss: 0.359377; batch adversarial loss: 0.362412\n",
      "epoch 45; iter: 0; batch classifier loss: 0.462564; batch adversarial loss: 0.511363\n",
      "epoch 45; iter: 200; batch classifier loss: 0.297858; batch adversarial loss: 0.450190\n",
      "epoch 46; iter: 0; batch classifier loss: 0.328557; batch adversarial loss: 0.406579\n",
      "epoch 46; iter: 200; batch classifier loss: 0.399211; batch adversarial loss: 0.340043\n",
      "epoch 47; iter: 0; batch classifier loss: 0.390356; batch adversarial loss: 0.456136\n",
      "epoch 47; iter: 200; batch classifier loss: 0.445788; batch adversarial loss: 0.398449\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335285; batch adversarial loss: 0.370135\n",
      "epoch 48; iter: 200; batch classifier loss: 0.565162; batch adversarial loss: 0.474854\n",
      "epoch 49; iter: 0; batch classifier loss: 0.313048; batch adversarial loss: 0.403704\n",
      "epoch 49; iter: 200; batch classifier loss: 0.449662; batch adversarial loss: 0.402362\n",
      "epoch 0; iter: 0; batch classifier loss: 46.285248; batch adversarial loss: 0.582159\n",
      "epoch 0; iter: 200; batch classifier loss: 5.396123; batch adversarial loss: 0.553404\n",
      "epoch 1; iter: 0; batch classifier loss: 8.096531; batch adversarial loss: 0.528912\n",
      "epoch 1; iter: 200; batch classifier loss: 3.557545; batch adversarial loss: 0.598040\n",
      "epoch 2; iter: 0; batch classifier loss: 2.969264; batch adversarial loss: 0.457325\n",
      "epoch 2; iter: 200; batch classifier loss: 0.783448; batch adversarial loss: 0.504385\n",
      "epoch 3; iter: 0; batch classifier loss: 0.633683; batch adversarial loss: 0.441480\n",
      "epoch 3; iter: 200; batch classifier loss: 1.248454; batch adversarial loss: 0.510823\n",
      "epoch 4; iter: 0; batch classifier loss: 1.555748; batch adversarial loss: 0.467670\n",
      "epoch 4; iter: 200; batch classifier loss: 0.977747; batch adversarial loss: 0.379931\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599898; batch adversarial loss: 0.424685\n",
      "epoch 5; iter: 200; batch classifier loss: 0.618992; batch adversarial loss: 0.455898\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330022; batch adversarial loss: 0.440973\n",
      "epoch 6; iter: 200; batch classifier loss: 0.398196; batch adversarial loss: 0.522538\n",
      "epoch 7; iter: 0; batch classifier loss: 2.606685; batch adversarial loss: 0.422819\n",
      "epoch 7; iter: 200; batch classifier loss: 0.387729; batch adversarial loss: 0.494981\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485350; batch adversarial loss: 0.367737\n",
      "epoch 8; iter: 200; batch classifier loss: 0.366885; batch adversarial loss: 0.402441\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437914; batch adversarial loss: 0.333338\n",
      "epoch 9; iter: 200; batch classifier loss: 0.292237; batch adversarial loss: 0.472758\n",
      "epoch 10; iter: 0; batch classifier loss: 0.394110; batch adversarial loss: 0.445530\n",
      "epoch 10; iter: 200; batch classifier loss: 0.358166; batch adversarial loss: 0.392969\n",
      "epoch 11; iter: 0; batch classifier loss: 0.401809; batch adversarial loss: 0.435092\n",
      "epoch 11; iter: 200; batch classifier loss: 0.368171; batch adversarial loss: 0.449515\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385789; batch adversarial loss: 0.363882\n",
      "epoch 12; iter: 200; batch classifier loss: 0.373172; batch adversarial loss: 0.349160\n",
      "epoch 13; iter: 0; batch classifier loss: 0.343621; batch adversarial loss: 0.457586\n",
      "epoch 13; iter: 200; batch classifier loss: 0.381490; batch adversarial loss: 0.372955\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356401; batch adversarial loss: 0.339258\n",
      "epoch 14; iter: 200; batch classifier loss: 0.336078; batch adversarial loss: 0.408703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343045; batch adversarial loss: 0.476507\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353132; batch adversarial loss: 0.456816\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297197; batch adversarial loss: 0.385807\n",
      "epoch 16; iter: 200; batch classifier loss: 0.333717; batch adversarial loss: 0.415696\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371134; batch adversarial loss: 0.414193\n",
      "epoch 17; iter: 200; batch classifier loss: 0.330530; batch adversarial loss: 0.365277\n",
      "epoch 18; iter: 0; batch classifier loss: 0.353814; batch adversarial loss: 0.372401\n",
      "epoch 18; iter: 200; batch classifier loss: 0.478692; batch adversarial loss: 0.432486\n",
      "epoch 19; iter: 0; batch classifier loss: 0.357643; batch adversarial loss: 0.427263\n",
      "epoch 19; iter: 200; batch classifier loss: 0.631122; batch adversarial loss: 0.344824\n",
      "epoch 20; iter: 0; batch classifier loss: 0.278161; batch adversarial loss: 0.375391\n",
      "epoch 20; iter: 200; batch classifier loss: 0.295704; batch adversarial loss: 0.446225\n",
      "epoch 21; iter: 0; batch classifier loss: 0.345335; batch adversarial loss: 0.444969\n",
      "epoch 21; iter: 200; batch classifier loss: 0.421573; batch adversarial loss: 0.411251\n",
      "epoch 22; iter: 0; batch classifier loss: 0.321590; batch adversarial loss: 0.449615\n",
      "epoch 22; iter: 200; batch classifier loss: 0.325371; batch adversarial loss: 0.381032\n",
      "epoch 23; iter: 0; batch classifier loss: 0.336056; batch adversarial loss: 0.334705\n",
      "epoch 23; iter: 200; batch classifier loss: 0.332220; batch adversarial loss: 0.468368\n",
      "epoch 24; iter: 0; batch classifier loss: 0.372283; batch adversarial loss: 0.411899\n",
      "epoch 24; iter: 200; batch classifier loss: 0.309879; batch adversarial loss: 0.467212\n",
      "epoch 25; iter: 0; batch classifier loss: 0.351074; batch adversarial loss: 0.346847\n",
      "epoch 25; iter: 200; batch classifier loss: 0.383915; batch adversarial loss: 0.267557\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329420; batch adversarial loss: 0.399679\n",
      "epoch 26; iter: 200; batch classifier loss: 0.395000; batch adversarial loss: 0.488511\n",
      "epoch 27; iter: 0; batch classifier loss: 0.308179; batch adversarial loss: 0.440304\n",
      "epoch 27; iter: 200; batch classifier loss: 0.327502; batch adversarial loss: 0.492969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215722; batch adversarial loss: 0.438767\n",
      "epoch 28; iter: 200; batch classifier loss: 0.375250; batch adversarial loss: 0.407329\n",
      "epoch 29; iter: 0; batch classifier loss: 0.373805; batch adversarial loss: 0.444793\n",
      "epoch 29; iter: 200; batch classifier loss: 0.363603; batch adversarial loss: 0.474360\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390936; batch adversarial loss: 0.358909\n",
      "epoch 30; iter: 200; batch classifier loss: 0.519420; batch adversarial loss: 0.455006\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268286; batch adversarial loss: 0.343989\n",
      "epoch 31; iter: 200; batch classifier loss: 0.477526; batch adversarial loss: 0.382541\n",
      "epoch 32; iter: 0; batch classifier loss: 0.379317; batch adversarial loss: 0.361394\n",
      "epoch 32; iter: 200; batch classifier loss: 0.308036; batch adversarial loss: 0.345444\n",
      "epoch 33; iter: 0; batch classifier loss: 0.439987; batch adversarial loss: 0.414748\n",
      "epoch 33; iter: 200; batch classifier loss: 0.323258; batch adversarial loss: 0.504808\n",
      "epoch 34; iter: 0; batch classifier loss: 0.396739; batch adversarial loss: 0.446078\n",
      "epoch 34; iter: 200; batch classifier loss: 0.388702; batch adversarial loss: 0.381716\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341894; batch adversarial loss: 0.427566\n",
      "epoch 35; iter: 200; batch classifier loss: 0.378134; batch adversarial loss: 0.372065\n",
      "epoch 36; iter: 0; batch classifier loss: 0.317181; batch adversarial loss: 0.413597\n",
      "epoch 36; iter: 200; batch classifier loss: 0.340229; batch adversarial loss: 0.439822\n",
      "epoch 37; iter: 0; batch classifier loss: 0.353557; batch adversarial loss: 0.538977\n",
      "epoch 37; iter: 200; batch classifier loss: 0.413867; batch adversarial loss: 0.463794\n",
      "epoch 38; iter: 0; batch classifier loss: 0.364789; batch adversarial loss: 0.412468\n",
      "epoch 38; iter: 200; batch classifier loss: 0.361645; batch adversarial loss: 0.363907\n",
      "epoch 39; iter: 0; batch classifier loss: 0.354195; batch adversarial loss: 0.430615\n",
      "epoch 39; iter: 200; batch classifier loss: 0.387219; batch adversarial loss: 0.437984\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444638; batch adversarial loss: 0.367878\n",
      "epoch 40; iter: 200; batch classifier loss: 0.325081; batch adversarial loss: 0.550658\n",
      "epoch 41; iter: 0; batch classifier loss: 0.339633; batch adversarial loss: 0.457355\n",
      "epoch 41; iter: 200; batch classifier loss: 0.331527; batch adversarial loss: 0.443646\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393162; batch adversarial loss: 0.361326\n",
      "epoch 42; iter: 200; batch classifier loss: 0.395117; batch adversarial loss: 0.488192\n",
      "epoch 43; iter: 0; batch classifier loss: 0.369472; batch adversarial loss: 0.378353\n",
      "epoch 43; iter: 200; batch classifier loss: 0.310093; batch adversarial loss: 0.446248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.360785; batch adversarial loss: 0.345440\n",
      "epoch 44; iter: 200; batch classifier loss: 0.263622; batch adversarial loss: 0.459340\n",
      "epoch 45; iter: 0; batch classifier loss: 0.309388; batch adversarial loss: 0.516626\n",
      "epoch 45; iter: 200; batch classifier loss: 0.261928; batch adversarial loss: 0.350033\n",
      "epoch 46; iter: 0; batch classifier loss: 0.343995; batch adversarial loss: 0.438358\n",
      "epoch 46; iter: 200; batch classifier loss: 0.382343; batch adversarial loss: 0.430627\n",
      "epoch 47; iter: 0; batch classifier loss: 0.306192; batch adversarial loss: 0.358605\n",
      "epoch 47; iter: 200; batch classifier loss: 0.286562; batch adversarial loss: 0.390671\n",
      "epoch 48; iter: 0; batch classifier loss: 0.298473; batch adversarial loss: 0.349510\n",
      "epoch 48; iter: 200; batch classifier loss: 0.411114; batch adversarial loss: 0.389828\n",
      "epoch 49; iter: 0; batch classifier loss: 0.293134; batch adversarial loss: 0.372432\n",
      "epoch 49; iter: 200; batch classifier loss: 0.309762; batch adversarial loss: 0.394176\n",
      "epoch 0; iter: 0; batch classifier loss: 129.100403; batch adversarial loss: 0.534266\n",
      "epoch 0; iter: 200; batch classifier loss: 8.455615; batch adversarial loss: 0.624714\n",
      "epoch 1; iter: 0; batch classifier loss: 5.172001; batch adversarial loss: 0.541516\n",
      "epoch 1; iter: 200; batch classifier loss: 7.946412; batch adversarial loss: 0.521741\n",
      "epoch 2; iter: 0; batch classifier loss: 8.839887; batch adversarial loss: 0.533089\n",
      "epoch 2; iter: 200; batch classifier loss: 0.645940; batch adversarial loss: 0.489078\n",
      "epoch 3; iter: 0; batch classifier loss: 0.467474; batch adversarial loss: 0.510329\n",
      "epoch 3; iter: 200; batch classifier loss: 1.830233; batch adversarial loss: 0.411003\n",
      "epoch 4; iter: 0; batch classifier loss: 1.685794; batch adversarial loss: 0.431504\n",
      "epoch 4; iter: 200; batch classifier loss: 0.727904; batch adversarial loss: 0.480418\n",
      "epoch 5; iter: 0; batch classifier loss: 0.998749; batch adversarial loss: 0.457759\n",
      "epoch 5; iter: 200; batch classifier loss: 1.100278; batch adversarial loss: 0.413573\n",
      "epoch 6; iter: 0; batch classifier loss: 0.407075; batch adversarial loss: 0.379898\n",
      "epoch 6; iter: 200; batch classifier loss: 0.998094; batch adversarial loss: 0.460393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.852762; batch adversarial loss: 0.537688\n",
      "epoch 7; iter: 200; batch classifier loss: 0.834956; batch adversarial loss: 0.407348\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468058; batch adversarial loss: 0.432391\n",
      "epoch 8; iter: 200; batch classifier loss: 0.547821; batch adversarial loss: 0.406825\n",
      "epoch 9; iter: 0; batch classifier loss: 0.935619; batch adversarial loss: 0.358886\n",
      "epoch 9; iter: 200; batch classifier loss: 0.346555; batch adversarial loss: 0.392102\n",
      "epoch 10; iter: 0; batch classifier loss: 0.545552; batch adversarial loss: 0.344369\n",
      "epoch 10; iter: 200; batch classifier loss: 0.476673; batch adversarial loss: 0.404640\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542098; batch adversarial loss: 0.449674\n",
      "epoch 11; iter: 200; batch classifier loss: 0.340716; batch adversarial loss: 0.439548\n",
      "epoch 12; iter: 0; batch classifier loss: 0.666047; batch adversarial loss: 0.349309\n",
      "epoch 12; iter: 200; batch classifier loss: 0.374728; batch adversarial loss: 0.350054\n",
      "epoch 13; iter: 0; batch classifier loss: 0.692069; batch adversarial loss: 0.451873\n",
      "epoch 13; iter: 200; batch classifier loss: 0.443423; batch adversarial loss: 0.444741\n",
      "epoch 14; iter: 0; batch classifier loss: 0.317968; batch adversarial loss: 0.469199\n",
      "epoch 14; iter: 200; batch classifier loss: 0.421627; batch adversarial loss: 0.422608\n",
      "epoch 15; iter: 0; batch classifier loss: 0.764631; batch adversarial loss: 0.362305\n",
      "epoch 15; iter: 200; batch classifier loss: 0.480282; batch adversarial loss: 0.383183\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314836; batch adversarial loss: 0.444121\n",
      "epoch 16; iter: 200; batch classifier loss: 0.359493; batch adversarial loss: 0.423350\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336037; batch adversarial loss: 0.491689\n",
      "epoch 17; iter: 200; batch classifier loss: 0.336835; batch adversarial loss: 0.416792\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387695; batch adversarial loss: 0.408136\n",
      "epoch 18; iter: 200; batch classifier loss: 0.309563; batch adversarial loss: 0.361642\n",
      "epoch 19; iter: 0; batch classifier loss: 0.595035; batch adversarial loss: 0.376706\n",
      "epoch 19; iter: 200; batch classifier loss: 0.321745; batch adversarial loss: 0.474659\n",
      "epoch 20; iter: 0; batch classifier loss: 0.379251; batch adversarial loss: 0.355697\n",
      "epoch 20; iter: 200; batch classifier loss: 0.358661; batch adversarial loss: 0.495008\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392210; batch adversarial loss: 0.583402\n",
      "epoch 21; iter: 200; batch classifier loss: 0.405005; batch adversarial loss: 0.494634\n",
      "epoch 22; iter: 0; batch classifier loss: 0.312451; batch adversarial loss: 0.488850\n",
      "epoch 22; iter: 200; batch classifier loss: 0.272485; batch adversarial loss: 0.437317\n",
      "epoch 23; iter: 0; batch classifier loss: 0.269366; batch adversarial loss: 0.519667\n",
      "epoch 23; iter: 200; batch classifier loss: 0.353197; batch adversarial loss: 0.402087\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280970; batch adversarial loss: 0.488053\n",
      "epoch 24; iter: 200; batch classifier loss: 0.347284; batch adversarial loss: 0.414306\n",
      "epoch 25; iter: 0; batch classifier loss: 0.347771; batch adversarial loss: 0.436641\n",
      "epoch 25; iter: 200; batch classifier loss: 0.362737; batch adversarial loss: 0.477855\n",
      "epoch 26; iter: 0; batch classifier loss: 0.379522; batch adversarial loss: 0.363844\n",
      "epoch 26; iter: 200; batch classifier loss: 0.278533; batch adversarial loss: 0.335495\n",
      "epoch 27; iter: 0; batch classifier loss: 0.416297; batch adversarial loss: 0.385149\n",
      "epoch 27; iter: 200; batch classifier loss: 0.335420; batch adversarial loss: 0.419792\n",
      "epoch 28; iter: 0; batch classifier loss: 0.370755; batch adversarial loss: 0.360228\n",
      "epoch 28; iter: 200; batch classifier loss: 0.212701; batch adversarial loss: 0.449332\n",
      "epoch 29; iter: 0; batch classifier loss: 0.289823; batch adversarial loss: 0.418204\n",
      "epoch 29; iter: 200; batch classifier loss: 0.306608; batch adversarial loss: 0.496318\n",
      "epoch 30; iter: 0; batch classifier loss: 0.284863; batch adversarial loss: 0.416767\n",
      "epoch 30; iter: 200; batch classifier loss: 0.377685; batch adversarial loss: 0.551252\n",
      "epoch 31; iter: 0; batch classifier loss: 0.388419; batch adversarial loss: 0.371815\n",
      "epoch 31; iter: 200; batch classifier loss: 0.348880; batch adversarial loss: 0.365070\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364129; batch adversarial loss: 0.423712\n",
      "epoch 32; iter: 200; batch classifier loss: 0.328736; batch adversarial loss: 0.421141\n",
      "epoch 33; iter: 0; batch classifier loss: 0.448059; batch adversarial loss: 0.487172\n",
      "epoch 33; iter: 200; batch classifier loss: 0.339245; batch adversarial loss: 0.470080\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367838; batch adversarial loss: 0.349326\n",
      "epoch 34; iter: 200; batch classifier loss: 0.344642; batch adversarial loss: 0.369106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393320; batch adversarial loss: 0.341235\n",
      "epoch 35; iter: 200; batch classifier loss: 0.302964; batch adversarial loss: 0.502161\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357404; batch adversarial loss: 0.430858\n",
      "epoch 36; iter: 200; batch classifier loss: 0.297884; batch adversarial loss: 0.490953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.382990; batch adversarial loss: 0.363656\n",
      "epoch 37; iter: 200; batch classifier loss: 0.346936; batch adversarial loss: 0.414318\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373532; batch adversarial loss: 0.454853\n",
      "epoch 38; iter: 200; batch classifier loss: 0.355772; batch adversarial loss: 0.557129\n",
      "epoch 39; iter: 0; batch classifier loss: 0.272650; batch adversarial loss: 0.460085\n",
      "epoch 39; iter: 200; batch classifier loss: 0.306413; batch adversarial loss: 0.432318\n",
      "epoch 40; iter: 0; batch classifier loss: 0.340496; batch adversarial loss: 0.440164\n",
      "epoch 40; iter: 200; batch classifier loss: 0.456179; batch adversarial loss: 0.433399\n",
      "epoch 41; iter: 0; batch classifier loss: 0.364228; batch adversarial loss: 0.453775\n",
      "epoch 41; iter: 200; batch classifier loss: 0.447834; batch adversarial loss: 0.462097\n",
      "epoch 42; iter: 0; batch classifier loss: 0.387954; batch adversarial loss: 0.280769\n",
      "epoch 42; iter: 200; batch classifier loss: 0.429000; batch adversarial loss: 0.455279\n",
      "epoch 43; iter: 0; batch classifier loss: 0.314807; batch adversarial loss: 0.345604\n",
      "epoch 43; iter: 200; batch classifier loss: 0.342615; batch adversarial loss: 0.433040\n",
      "epoch 44; iter: 0; batch classifier loss: 0.331491; batch adversarial loss: 0.352653\n",
      "epoch 44; iter: 200; batch classifier loss: 0.300272; batch adversarial loss: 0.450809\n",
      "epoch 45; iter: 0; batch classifier loss: 0.369545; batch adversarial loss: 0.436732\n",
      "epoch 45; iter: 200; batch classifier loss: 0.460157; batch adversarial loss: 0.392922\n",
      "epoch 46; iter: 0; batch classifier loss: 0.288490; batch adversarial loss: 0.446608\n",
      "epoch 46; iter: 200; batch classifier loss: 0.217297; batch adversarial loss: 0.370580\n",
      "epoch 47; iter: 0; batch classifier loss: 0.432015; batch adversarial loss: 0.440341\n",
      "epoch 47; iter: 200; batch classifier loss: 0.237588; batch adversarial loss: 0.472326\n",
      "epoch 48; iter: 0; batch classifier loss: 0.333844; batch adversarial loss: 0.349500\n",
      "epoch 48; iter: 200; batch classifier loss: 0.370661; batch adversarial loss: 0.374793\n",
      "epoch 49; iter: 0; batch classifier loss: 0.336745; batch adversarial loss: 0.404459\n",
      "epoch 49; iter: 200; batch classifier loss: 0.308611; batch adversarial loss: 0.439092\n",
      "epoch 0; iter: 0; batch classifier loss: 46.911285; batch adversarial loss: 0.689619\n",
      "epoch 0; iter: 200; batch classifier loss: 8.683473; batch adversarial loss: 0.589553\n",
      "epoch 1; iter: 0; batch classifier loss: 6.453394; batch adversarial loss: 0.562686\n",
      "epoch 1; iter: 200; batch classifier loss: 6.750029; batch adversarial loss: 0.562826\n",
      "epoch 2; iter: 0; batch classifier loss: 7.913613; batch adversarial loss: 0.531954\n",
      "epoch 2; iter: 200; batch classifier loss: 1.198683; batch adversarial loss: 0.537402\n",
      "epoch 3; iter: 0; batch classifier loss: 4.135372; batch adversarial loss: 0.464292\n",
      "epoch 3; iter: 200; batch classifier loss: 3.600729; batch adversarial loss: 0.399000\n",
      "epoch 4; iter: 0; batch classifier loss: 4.815862; batch adversarial loss: 0.425181\n",
      "epoch 4; iter: 200; batch classifier loss: 1.826682; batch adversarial loss: 0.395900\n",
      "epoch 5; iter: 0; batch classifier loss: 1.345955; batch adversarial loss: 0.508369\n",
      "epoch 5; iter: 200; batch classifier loss: 0.763314; batch adversarial loss: 0.400882\n",
      "epoch 6; iter: 0; batch classifier loss: 0.434455; batch adversarial loss: 0.343333\n",
      "epoch 6; iter: 200; batch classifier loss: 0.805602; batch adversarial loss: 0.418552\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380569; batch adversarial loss: 0.378717\n",
      "epoch 7; iter: 200; batch classifier loss: 0.489967; batch adversarial loss: 0.424292\n",
      "epoch 8; iter: 0; batch classifier loss: 1.606171; batch adversarial loss: 0.452678\n",
      "epoch 8; iter: 200; batch classifier loss: 0.301604; batch adversarial loss: 0.401607\n",
      "epoch 9; iter: 0; batch classifier loss: 0.444108; batch adversarial loss: 0.469370\n",
      "epoch 9; iter: 200; batch classifier loss: 0.340941; batch adversarial loss: 0.531056\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426817; batch adversarial loss: 0.489550\n",
      "epoch 10; iter: 200; batch classifier loss: 0.336848; batch adversarial loss: 0.392501\n",
      "epoch 11; iter: 0; batch classifier loss: 0.314050; batch adversarial loss: 0.519329\n",
      "epoch 11; iter: 200; batch classifier loss: 0.487686; batch adversarial loss: 0.350057\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412903; batch adversarial loss: 0.475976\n",
      "epoch 12; iter: 200; batch classifier loss: 0.686054; batch adversarial loss: 0.479594\n",
      "epoch 13; iter: 0; batch classifier loss: 0.426442; batch adversarial loss: 0.391888\n",
      "epoch 13; iter: 200; batch classifier loss: 0.434889; batch adversarial loss: 0.345150\n",
      "epoch 14; iter: 0; batch classifier loss: 0.460401; batch adversarial loss: 0.361542\n",
      "epoch 14; iter: 200; batch classifier loss: 0.347746; batch adversarial loss: 0.346437\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298130; batch adversarial loss: 0.361324\n",
      "epoch 15; iter: 200; batch classifier loss: 0.368023; batch adversarial loss: 0.442299\n",
      "epoch 16; iter: 0; batch classifier loss: 0.444248; batch adversarial loss: 0.404042\n",
      "epoch 16; iter: 200; batch classifier loss: 0.347186; batch adversarial loss: 0.476351\n",
      "epoch 17; iter: 0; batch classifier loss: 0.343696; batch adversarial loss: 0.432442\n",
      "epoch 17; iter: 200; batch classifier loss: 0.325386; batch adversarial loss: 0.437862\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359319; batch adversarial loss: 0.390729\n",
      "epoch 18; iter: 200; batch classifier loss: 0.397809; batch adversarial loss: 0.386567\n",
      "epoch 19; iter: 0; batch classifier loss: 0.326300; batch adversarial loss: 0.371882\n",
      "epoch 19; iter: 200; batch classifier loss: 0.453231; batch adversarial loss: 0.466884\n",
      "epoch 20; iter: 0; batch classifier loss: 0.375680; batch adversarial loss: 0.392039\n",
      "epoch 20; iter: 200; batch classifier loss: 0.279579; batch adversarial loss: 0.578422\n",
      "epoch 21; iter: 0; batch classifier loss: 0.472714; batch adversarial loss: 0.465336\n",
      "epoch 21; iter: 200; batch classifier loss: 0.434003; batch adversarial loss: 0.368282\n",
      "epoch 22; iter: 0; batch classifier loss: 0.389323; batch adversarial loss: 0.373929\n",
      "epoch 22; iter: 200; batch classifier loss: 0.353140; batch adversarial loss: 0.387513\n",
      "epoch 23; iter: 0; batch classifier loss: 0.341611; batch adversarial loss: 0.455703\n",
      "epoch 23; iter: 200; batch classifier loss: 0.356841; batch adversarial loss: 0.373094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387952; batch adversarial loss: 0.495428\n",
      "epoch 24; iter: 200; batch classifier loss: 0.283969; batch adversarial loss: 0.447384\n",
      "epoch 25; iter: 0; batch classifier loss: 0.356602; batch adversarial loss: 0.367915\n",
      "epoch 25; iter: 200; batch classifier loss: 0.406668; batch adversarial loss: 0.356795\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303558; batch adversarial loss: 0.413854\n",
      "epoch 26; iter: 200; batch classifier loss: 0.288794; batch adversarial loss: 0.515177\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327203; batch adversarial loss: 0.469849\n",
      "epoch 27; iter: 200; batch classifier loss: 0.419196; batch adversarial loss: 0.500558\n",
      "epoch 28; iter: 0; batch classifier loss: 0.332606; batch adversarial loss: 0.432104\n",
      "epoch 28; iter: 200; batch classifier loss: 0.390193; batch adversarial loss: 0.313854\n",
      "epoch 29; iter: 0; batch classifier loss: 0.339084; batch adversarial loss: 0.441692\n",
      "epoch 29; iter: 200; batch classifier loss: 0.400111; batch adversarial loss: 0.378192\n",
      "epoch 30; iter: 0; batch classifier loss: 0.307078; batch adversarial loss: 0.407029\n",
      "epoch 30; iter: 200; batch classifier loss: 0.325197; batch adversarial loss: 0.416071\n",
      "epoch 31; iter: 0; batch classifier loss: 0.296827; batch adversarial loss: 0.385023\n",
      "epoch 31; iter: 200; batch classifier loss: 0.276744; batch adversarial loss: 0.455074\n",
      "epoch 32; iter: 0; batch classifier loss: 0.331321; batch adversarial loss: 0.524449\n",
      "epoch 32; iter: 200; batch classifier loss: 0.351767; batch adversarial loss: 0.379316\n",
      "epoch 33; iter: 0; batch classifier loss: 0.342797; batch adversarial loss: 0.474643\n",
      "epoch 33; iter: 200; batch classifier loss: 0.286576; batch adversarial loss: 0.412306\n",
      "epoch 34; iter: 0; batch classifier loss: 0.424822; batch adversarial loss: 0.449181\n",
      "epoch 34; iter: 200; batch classifier loss: 0.453280; batch adversarial loss: 0.265272\n",
      "epoch 35; iter: 0; batch classifier loss: 0.352032; batch adversarial loss: 0.421255\n",
      "epoch 35; iter: 200; batch classifier loss: 0.495938; batch adversarial loss: 0.492298\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360332; batch adversarial loss: 0.303679\n",
      "epoch 36; iter: 200; batch classifier loss: 0.309679; batch adversarial loss: 0.340151\n",
      "epoch 37; iter: 0; batch classifier loss: 0.653467; batch adversarial loss: 0.444601\n",
      "epoch 37; iter: 200; batch classifier loss: 0.317549; batch adversarial loss: 0.412973\n",
      "epoch 38; iter: 0; batch classifier loss: 0.264845; batch adversarial loss: 0.445852\n",
      "epoch 38; iter: 200; batch classifier loss: 0.317463; batch adversarial loss: 0.461869\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413204; batch adversarial loss: 0.380057\n",
      "epoch 39; iter: 200; batch classifier loss: 0.402230; batch adversarial loss: 0.501571\n",
      "epoch 40; iter: 0; batch classifier loss: 0.324030; batch adversarial loss: 0.390000\n",
      "epoch 40; iter: 200; batch classifier loss: 0.453731; batch adversarial loss: 0.400521\n",
      "epoch 41; iter: 0; batch classifier loss: 0.301198; batch adversarial loss: 0.422403\n",
      "epoch 41; iter: 200; batch classifier loss: 0.296511; batch adversarial loss: 0.480793\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374292; batch adversarial loss: 0.347806\n",
      "epoch 42; iter: 200; batch classifier loss: 0.430194; batch adversarial loss: 0.397836\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381593; batch adversarial loss: 0.403516\n",
      "epoch 43; iter: 200; batch classifier loss: 0.377202; batch adversarial loss: 0.432324\n",
      "epoch 44; iter: 0; batch classifier loss: 0.387830; batch adversarial loss: 0.442092\n",
      "epoch 44; iter: 200; batch classifier loss: 0.322061; batch adversarial loss: 0.342075\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442871; batch adversarial loss: 0.410247\n",
      "epoch 45; iter: 200; batch classifier loss: 0.343851; batch adversarial loss: 0.366756\n",
      "epoch 46; iter: 0; batch classifier loss: 0.386574; batch adversarial loss: 0.435745\n",
      "epoch 46; iter: 200; batch classifier loss: 0.372271; batch adversarial loss: 0.361129\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386608; batch adversarial loss: 0.350353\n",
      "epoch 47; iter: 200; batch classifier loss: 0.318335; batch adversarial loss: 0.509187\n",
      "epoch 48; iter: 0; batch classifier loss: 0.311171; batch adversarial loss: 0.469901\n",
      "epoch 48; iter: 200; batch classifier loss: 0.351542; batch adversarial loss: 0.321699\n",
      "epoch 49; iter: 0; batch classifier loss: 0.318873; batch adversarial loss: 0.404991\n",
      "epoch 49; iter: 200; batch classifier loss: 0.334214; batch adversarial loss: 0.497389\n",
      "epoch 0; iter: 0; batch classifier loss: 113.185318; batch adversarial loss: 0.474353\n",
      "epoch 0; iter: 200; batch classifier loss: 6.737143; batch adversarial loss: 0.559771\n",
      "epoch 1; iter: 0; batch classifier loss: 8.663401; batch adversarial loss: 0.539584\n",
      "epoch 1; iter: 200; batch classifier loss: 8.900081; batch adversarial loss: 0.485473\n",
      "epoch 2; iter: 0; batch classifier loss: 11.251276; batch adversarial loss: 0.479804\n",
      "epoch 2; iter: 200; batch classifier loss: 3.291709; batch adversarial loss: 0.476529\n",
      "epoch 3; iter: 0; batch classifier loss: 4.051485; batch adversarial loss: 0.448734\n",
      "epoch 3; iter: 200; batch classifier loss: 2.347576; batch adversarial loss: 0.428235\n",
      "epoch 4; iter: 0; batch classifier loss: 2.687544; batch adversarial loss: 0.448023\n",
      "epoch 4; iter: 200; batch classifier loss: 1.675633; batch adversarial loss: 0.350759\n",
      "epoch 5; iter: 0; batch classifier loss: 1.534933; batch adversarial loss: 0.518834\n",
      "epoch 5; iter: 200; batch classifier loss: 1.179714; batch adversarial loss: 0.354403\n",
      "epoch 6; iter: 0; batch classifier loss: 0.773587; batch adversarial loss: 0.427951\n",
      "epoch 6; iter: 200; batch classifier loss: 0.612644; batch adversarial loss: 0.401222\n",
      "epoch 7; iter: 0; batch classifier loss: 0.706996; batch adversarial loss: 0.468462\n",
      "epoch 7; iter: 200; batch classifier loss: 0.564768; batch adversarial loss: 0.520824\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562019; batch adversarial loss: 0.561350\n",
      "epoch 8; iter: 200; batch classifier loss: 1.222278; batch adversarial loss: 0.442557\n",
      "epoch 9; iter: 0; batch classifier loss: 0.736161; batch adversarial loss: 0.345402\n",
      "epoch 9; iter: 200; batch classifier loss: 0.507248; batch adversarial loss: 0.490811\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520987; batch adversarial loss: 0.477976\n",
      "epoch 10; iter: 200; batch classifier loss: 0.429200; batch adversarial loss: 0.354533\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495140; batch adversarial loss: 0.380536\n",
      "epoch 11; iter: 200; batch classifier loss: 0.564798; batch adversarial loss: 0.514399\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598798; batch adversarial loss: 0.454535\n",
      "epoch 12; iter: 200; batch classifier loss: 0.400345; batch adversarial loss: 0.506368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.377387; batch adversarial loss: 0.431435\n",
      "epoch 13; iter: 200; batch classifier loss: 0.360355; batch adversarial loss: 0.357286\n",
      "epoch 14; iter: 0; batch classifier loss: 0.385489; batch adversarial loss: 0.332952\n",
      "epoch 14; iter: 200; batch classifier loss: 0.340240; batch adversarial loss: 0.431003\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436192; batch adversarial loss: 0.442681\n",
      "epoch 15; iter: 200; batch classifier loss: 0.358976; batch adversarial loss: 0.325113\n",
      "epoch 16; iter: 0; batch classifier loss: 0.807371; batch adversarial loss: 0.484960\n",
      "epoch 16; iter: 200; batch classifier loss: 0.381746; batch adversarial loss: 0.405045\n",
      "epoch 17; iter: 0; batch classifier loss: 0.342300; batch adversarial loss: 0.482448\n",
      "epoch 17; iter: 200; batch classifier loss: 0.529018; batch adversarial loss: 0.335935\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308076; batch adversarial loss: 0.425941\n",
      "epoch 18; iter: 200; batch classifier loss: 0.306530; batch adversarial loss: 0.380312\n",
      "epoch 19; iter: 0; batch classifier loss: 0.361506; batch adversarial loss: 0.468420\n",
      "epoch 19; iter: 200; batch classifier loss: 0.397686; batch adversarial loss: 0.343656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.352909; batch adversarial loss: 0.459245\n",
      "epoch 20; iter: 200; batch classifier loss: 0.376645; batch adversarial loss: 0.412021\n",
      "epoch 21; iter: 0; batch classifier loss: 0.405662; batch adversarial loss: 0.469174\n",
      "epoch 21; iter: 200; batch classifier loss: 0.319170; batch adversarial loss: 0.492603\n",
      "epoch 22; iter: 0; batch classifier loss: 0.336170; batch adversarial loss: 0.382146\n",
      "epoch 22; iter: 200; batch classifier loss: 0.344084; batch adversarial loss: 0.332614\n",
      "epoch 23; iter: 0; batch classifier loss: 0.307563; batch adversarial loss: 0.478969\n",
      "epoch 23; iter: 200; batch classifier loss: 0.272241; batch adversarial loss: 0.444620\n",
      "epoch 24; iter: 0; batch classifier loss: 0.419662; batch adversarial loss: 0.388693\n",
      "epoch 24; iter: 200; batch classifier loss: 0.320606; batch adversarial loss: 0.421526\n",
      "epoch 25; iter: 0; batch classifier loss: 0.366295; batch adversarial loss: 0.252956\n",
      "epoch 25; iter: 200; batch classifier loss: 0.398697; batch adversarial loss: 0.564645\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366880; batch adversarial loss: 0.392484\n",
      "epoch 26; iter: 200; batch classifier loss: 0.307410; batch adversarial loss: 0.530924\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405069; batch adversarial loss: 0.432003\n",
      "epoch 27; iter: 200; batch classifier loss: 0.288619; batch adversarial loss: 0.397321\n",
      "epoch 28; iter: 0; batch classifier loss: 0.307121; batch adversarial loss: 0.358720\n",
      "epoch 28; iter: 200; batch classifier loss: 0.472259; batch adversarial loss: 0.362087\n",
      "epoch 29; iter: 0; batch classifier loss: 0.321644; batch adversarial loss: 0.419066\n",
      "epoch 29; iter: 200; batch classifier loss: 0.246249; batch adversarial loss: 0.456267\n",
      "epoch 30; iter: 0; batch classifier loss: 0.411990; batch adversarial loss: 0.428581\n",
      "epoch 30; iter: 200; batch classifier loss: 0.268224; batch adversarial loss: 0.365042\n",
      "epoch 31; iter: 0; batch classifier loss: 0.222643; batch adversarial loss: 0.439270\n",
      "epoch 31; iter: 200; batch classifier loss: 0.368570; batch adversarial loss: 0.398301\n",
      "epoch 32; iter: 0; batch classifier loss: 0.278299; batch adversarial loss: 0.417370\n",
      "epoch 32; iter: 200; batch classifier loss: 0.425744; batch adversarial loss: 0.437416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.337148; batch adversarial loss: 0.442786\n",
      "epoch 33; iter: 200; batch classifier loss: 0.424505; batch adversarial loss: 0.484360\n",
      "epoch 34; iter: 0; batch classifier loss: 0.311301; batch adversarial loss: 0.505524\n",
      "epoch 34; iter: 200; batch classifier loss: 0.352406; batch adversarial loss: 0.435352\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395557; batch adversarial loss: 0.444207\n",
      "epoch 35; iter: 200; batch classifier loss: 0.448714; batch adversarial loss: 0.428310\n",
      "epoch 36; iter: 0; batch classifier loss: 0.549227; batch adversarial loss: 0.483674\n",
      "epoch 36; iter: 200; batch classifier loss: 0.329902; batch adversarial loss: 0.323986\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343648; batch adversarial loss: 0.332982\n",
      "epoch 37; iter: 200; batch classifier loss: 0.348869; batch adversarial loss: 0.403177\n",
      "epoch 38; iter: 0; batch classifier loss: 0.298426; batch adversarial loss: 0.347236\n",
      "epoch 38; iter: 200; batch classifier loss: 0.286277; batch adversarial loss: 0.325569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.291578; batch adversarial loss: 0.308943\n",
      "epoch 39; iter: 200; batch classifier loss: 0.393550; batch adversarial loss: 0.506970\n",
      "epoch 40; iter: 0; batch classifier loss: 0.376294; batch adversarial loss: 0.399367\n",
      "epoch 40; iter: 200; batch classifier loss: 0.334026; batch adversarial loss: 0.387008\n",
      "epoch 41; iter: 0; batch classifier loss: 0.354570; batch adversarial loss: 0.390237\n",
      "epoch 41; iter: 200; batch classifier loss: 0.275352; batch adversarial loss: 0.426964\n",
      "epoch 42; iter: 0; batch classifier loss: 0.347800; batch adversarial loss: 0.471186\n",
      "epoch 42; iter: 200; batch classifier loss: 0.342925; batch adversarial loss: 0.447335\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409031; batch adversarial loss: 0.392816\n",
      "epoch 43; iter: 200; batch classifier loss: 0.309112; batch adversarial loss: 0.356820\n",
      "epoch 44; iter: 0; batch classifier loss: 0.344439; batch adversarial loss: 0.388686\n",
      "epoch 44; iter: 200; batch classifier loss: 0.337480; batch adversarial loss: 0.466864\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336512; batch adversarial loss: 0.387551\n",
      "epoch 45; iter: 200; batch classifier loss: 0.416221; batch adversarial loss: 0.453794\n",
      "epoch 46; iter: 0; batch classifier loss: 0.355808; batch adversarial loss: 0.475939\n",
      "epoch 46; iter: 200; batch classifier loss: 0.432868; batch adversarial loss: 0.380428\n",
      "epoch 47; iter: 0; batch classifier loss: 0.289807; batch adversarial loss: 0.465568\n",
      "epoch 47; iter: 200; batch classifier loss: 0.271080; batch adversarial loss: 0.408492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455280; batch adversarial loss: 0.445365\n",
      "epoch 48; iter: 200; batch classifier loss: 0.429800; batch adversarial loss: 0.421831\n",
      "epoch 49; iter: 0; batch classifier loss: 0.290970; batch adversarial loss: 0.392494\n",
      "epoch 49; iter: 200; batch classifier loss: 0.435917; batch adversarial loss: 0.417965\n",
      "epoch 0; iter: 0; batch classifier loss: 25.752686; batch adversarial loss: 1.074330\n",
      "epoch 0; iter: 200; batch classifier loss: 39.699200; batch adversarial loss: 0.690182\n",
      "epoch 1; iter: 0; batch classifier loss: 3.880200; batch adversarial loss: 0.686306\n",
      "epoch 1; iter: 200; batch classifier loss: 2.911032; batch adversarial loss: 0.544352\n",
      "epoch 2; iter: 0; batch classifier loss: 1.648349; batch adversarial loss: 0.553348\n",
      "epoch 2; iter: 200; batch classifier loss: 1.467589; batch adversarial loss: 0.496799\n",
      "epoch 3; iter: 0; batch classifier loss: 3.477161; batch adversarial loss: 0.519143\n",
      "epoch 3; iter: 200; batch classifier loss: 1.619089; batch adversarial loss: 0.552957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.525892; batch adversarial loss: 0.468146\n",
      "epoch 4; iter: 200; batch classifier loss: 0.447287; batch adversarial loss: 0.449176\n",
      "epoch 5; iter: 0; batch classifier loss: 1.982596; batch adversarial loss: 0.405295\n",
      "epoch 5; iter: 200; batch classifier loss: 4.776310; batch adversarial loss: 0.364629\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597088; batch adversarial loss: 0.455022\n",
      "epoch 6; iter: 200; batch classifier loss: 1.083103; batch adversarial loss: 0.403230\n",
      "epoch 7; iter: 0; batch classifier loss: 2.192394; batch adversarial loss: 0.385800\n",
      "epoch 7; iter: 200; batch classifier loss: 0.656722; batch adversarial loss: 0.458177\n",
      "epoch 8; iter: 0; batch classifier loss: 0.445158; batch adversarial loss: 0.442681\n",
      "epoch 8; iter: 200; batch classifier loss: 0.314094; batch adversarial loss: 0.352749\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480644; batch adversarial loss: 0.507240\n",
      "epoch 9; iter: 200; batch classifier loss: 0.352123; batch adversarial loss: 0.452086\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370956; batch adversarial loss: 0.370582\n",
      "epoch 10; iter: 200; batch classifier loss: 0.330984; batch adversarial loss: 0.479510\n",
      "epoch 11; iter: 0; batch classifier loss: 0.700783; batch adversarial loss: 0.293423\n",
      "epoch 11; iter: 200; batch classifier loss: 0.354651; batch adversarial loss: 0.451490\n",
      "epoch 12; iter: 0; batch classifier loss: 0.235143; batch adversarial loss: 0.407794\n",
      "epoch 12; iter: 200; batch classifier loss: 0.364378; batch adversarial loss: 0.508632\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264299; batch adversarial loss: 0.392080\n",
      "epoch 13; iter: 200; batch classifier loss: 0.348696; batch adversarial loss: 0.450763\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369085; batch adversarial loss: 0.412436\n",
      "epoch 14; iter: 200; batch classifier loss: 0.370279; batch adversarial loss: 0.402494\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480649; batch adversarial loss: 0.507644\n",
      "epoch 15; iter: 200; batch classifier loss: 0.356746; batch adversarial loss: 0.422414\n",
      "epoch 16; iter: 0; batch classifier loss: 0.342380; batch adversarial loss: 0.475331\n",
      "epoch 16; iter: 200; batch classifier loss: 0.329594; batch adversarial loss: 0.364469\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467153; batch adversarial loss: 0.375234\n",
      "epoch 17; iter: 200; batch classifier loss: 0.248972; batch adversarial loss: 0.441827\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306703; batch adversarial loss: 0.444252\n",
      "epoch 18; iter: 200; batch classifier loss: 0.323534; batch adversarial loss: 0.353681\n",
      "epoch 19; iter: 0; batch classifier loss: 0.373916; batch adversarial loss: 0.474648\n",
      "epoch 19; iter: 200; batch classifier loss: 0.414448; batch adversarial loss: 0.374955\n",
      "epoch 20; iter: 0; batch classifier loss: 0.318243; batch adversarial loss: 0.400572\n",
      "epoch 20; iter: 200; batch classifier loss: 0.436243; batch adversarial loss: 0.481348\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355724; batch adversarial loss: 0.352452\n",
      "epoch 21; iter: 200; batch classifier loss: 0.305423; batch adversarial loss: 0.401496\n",
      "epoch 22; iter: 0; batch classifier loss: 0.387418; batch adversarial loss: 0.346021\n",
      "epoch 22; iter: 200; batch classifier loss: 0.299596; batch adversarial loss: 0.441844\n",
      "epoch 23; iter: 0; batch classifier loss: 0.391949; batch adversarial loss: 0.342593\n",
      "epoch 23; iter: 200; batch classifier loss: 0.280327; batch adversarial loss: 0.367289\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329729; batch adversarial loss: 0.418698\n",
      "epoch 24; iter: 200; batch classifier loss: 0.417786; batch adversarial loss: 0.417270\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311348; batch adversarial loss: 0.437115\n",
      "epoch 25; iter: 200; batch classifier loss: 0.395142; batch adversarial loss: 0.451067\n",
      "epoch 26; iter: 0; batch classifier loss: 0.342530; batch adversarial loss: 0.383343\n",
      "epoch 26; iter: 200; batch classifier loss: 0.340224; batch adversarial loss: 0.446386\n",
      "epoch 27; iter: 0; batch classifier loss: 0.346594; batch adversarial loss: 0.401888\n",
      "epoch 27; iter: 200; batch classifier loss: 0.368482; batch adversarial loss: 0.374885\n",
      "epoch 28; iter: 0; batch classifier loss: 0.249384; batch adversarial loss: 0.462999\n",
      "epoch 28; iter: 200; batch classifier loss: 0.364816; batch adversarial loss: 0.439914\n",
      "epoch 29; iter: 0; batch classifier loss: 0.334815; batch adversarial loss: 0.492846\n",
      "epoch 29; iter: 200; batch classifier loss: 0.341837; batch adversarial loss: 0.484287\n",
      "epoch 30; iter: 0; batch classifier loss: 0.346859; batch adversarial loss: 0.393524\n",
      "epoch 30; iter: 200; batch classifier loss: 0.339202; batch adversarial loss: 0.435987\n",
      "epoch 31; iter: 0; batch classifier loss: 0.338499; batch adversarial loss: 0.412004\n",
      "epoch 31; iter: 200; batch classifier loss: 0.482053; batch adversarial loss: 0.414013\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474603; batch adversarial loss: 0.251993\n",
      "epoch 32; iter: 200; batch classifier loss: 0.351784; batch adversarial loss: 0.405850\n",
      "epoch 33; iter: 0; batch classifier loss: 0.369260; batch adversarial loss: 0.499706\n",
      "epoch 33; iter: 200; batch classifier loss: 0.337910; batch adversarial loss: 0.398647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.413976; batch adversarial loss: 0.411545\n",
      "epoch 34; iter: 200; batch classifier loss: 0.364953; batch adversarial loss: 0.353277\n",
      "epoch 35; iter: 0; batch classifier loss: 0.356382; batch adversarial loss: 0.422386\n",
      "epoch 35; iter: 200; batch classifier loss: 0.352413; batch adversarial loss: 0.391487\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357636; batch adversarial loss: 0.335761\n",
      "epoch 36; iter: 200; batch classifier loss: 0.364246; batch adversarial loss: 0.292624\n",
      "epoch 37; iter: 0; batch classifier loss: 0.327228; batch adversarial loss: 0.424049\n",
      "epoch 37; iter: 200; batch classifier loss: 0.251209; batch adversarial loss: 0.475504\n",
      "epoch 38; iter: 0; batch classifier loss: 0.396022; batch adversarial loss: 0.412354\n",
      "epoch 38; iter: 200; batch classifier loss: 0.287192; batch adversarial loss: 0.404519\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401522; batch adversarial loss: 0.448467\n",
      "epoch 39; iter: 200; batch classifier loss: 0.320672; batch adversarial loss: 0.482150\n",
      "epoch 40; iter: 0; batch classifier loss: 0.318869; batch adversarial loss: 0.375698\n",
      "epoch 40; iter: 200; batch classifier loss: 0.315614; batch adversarial loss: 0.468162\n",
      "epoch 41; iter: 0; batch classifier loss: 0.470503; batch adversarial loss: 0.346070\n",
      "epoch 41; iter: 200; batch classifier loss: 0.322160; batch adversarial loss: 0.397546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.366357; batch adversarial loss: 0.367360\n",
      "epoch 42; iter: 200; batch classifier loss: 0.447563; batch adversarial loss: 0.436139\n",
      "epoch 43; iter: 0; batch classifier loss: 0.342038; batch adversarial loss: 0.450011\n",
      "epoch 43; iter: 200; batch classifier loss: 0.514353; batch adversarial loss: 0.395772\n",
      "epoch 44; iter: 0; batch classifier loss: 0.479143; batch adversarial loss: 0.489799\n",
      "epoch 44; iter: 200; batch classifier loss: 0.478889; batch adversarial loss: 0.435142\n",
      "epoch 45; iter: 0; batch classifier loss: 0.539061; batch adversarial loss: 0.345977\n",
      "epoch 45; iter: 200; batch classifier loss: 0.515534; batch adversarial loss: 0.483080\n",
      "epoch 46; iter: 0; batch classifier loss: 0.517832; batch adversarial loss: 0.393952\n",
      "epoch 46; iter: 200; batch classifier loss: 0.418232; batch adversarial loss: 0.377484\n",
      "epoch 47; iter: 0; batch classifier loss: 0.536502; batch adversarial loss: 0.353275\n",
      "epoch 47; iter: 200; batch classifier loss: 0.419045; batch adversarial loss: 0.431098\n",
      "epoch 48; iter: 0; batch classifier loss: 0.491201; batch adversarial loss: 0.408924\n",
      "epoch 48; iter: 200; batch classifier loss: 0.471182; batch adversarial loss: 0.431021\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503646; batch adversarial loss: 0.388087\n",
      "epoch 49; iter: 200; batch classifier loss: 0.457837; batch adversarial loss: 0.394877\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 20.859621; batch adversarial loss: 0.846921\n",
      "epoch 0; iter: 200; batch classifier loss: 6.824196; batch adversarial loss: 0.794855\n",
      "epoch 0; iter: 400; batch classifier loss: 6.132789; batch adversarial loss: 0.566763\n",
      "epoch 0; iter: 600; batch classifier loss: 4.191037; batch adversarial loss: 0.567613\n",
      "epoch 1; iter: 0; batch classifier loss: 5.099241; batch adversarial loss: 0.571631\n",
      "epoch 1; iter: 200; batch classifier loss: 5.988645; batch adversarial loss: 0.519707\n",
      "epoch 1; iter: 400; batch classifier loss: 0.591411; batch adversarial loss: 0.577630\n",
      "epoch 1; iter: 600; batch classifier loss: 4.813804; batch adversarial loss: 0.446554\n",
      "epoch 2; iter: 0; batch classifier loss: 2.417523; batch adversarial loss: 0.454585\n",
      "epoch 2; iter: 200; batch classifier loss: 3.856664; batch adversarial loss: 0.377329\n",
      "epoch 2; iter: 400; batch classifier loss: 1.495085; batch adversarial loss: 0.380527\n",
      "epoch 2; iter: 600; batch classifier loss: 0.953596; batch adversarial loss: 0.452706\n",
      "epoch 3; iter: 0; batch classifier loss: 0.997512; batch adversarial loss: 0.379346\n",
      "epoch 3; iter: 200; batch classifier loss: 1.537646; batch adversarial loss: 0.587225\n",
      "epoch 3; iter: 400; batch classifier loss: 17.608088; batch adversarial loss: 0.366575\n",
      "epoch 3; iter: 600; batch classifier loss: 2.002440; batch adversarial loss: 0.491155\n",
      "epoch 4; iter: 0; batch classifier loss: 0.792598; batch adversarial loss: 0.420527\n",
      "epoch 4; iter: 200; batch classifier loss: 0.538207; batch adversarial loss: 0.382020\n",
      "epoch 4; iter: 400; batch classifier loss: 0.294341; batch adversarial loss: 0.371937\n",
      "epoch 4; iter: 600; batch classifier loss: 0.454358; batch adversarial loss: 0.325536\n",
      "epoch 5; iter: 0; batch classifier loss: 0.692476; batch adversarial loss: 0.397562\n",
      "epoch 5; iter: 200; batch classifier loss: 0.652260; batch adversarial loss: 0.385154\n",
      "epoch 5; iter: 400; batch classifier loss: 1.167348; batch adversarial loss: 0.442226\n",
      "epoch 5; iter: 600; batch classifier loss: 0.342517; batch adversarial loss: 0.311343\n",
      "epoch 6; iter: 0; batch classifier loss: 0.295912; batch adversarial loss: 0.353161\n",
      "epoch 6; iter: 200; batch classifier loss: 0.400640; batch adversarial loss: 0.420875\n",
      "epoch 6; iter: 400; batch classifier loss: 0.349432; batch adversarial loss: 0.455556\n",
      "epoch 6; iter: 600; batch classifier loss: 0.264323; batch adversarial loss: 0.411926\n",
      "epoch 7; iter: 0; batch classifier loss: 0.429121; batch adversarial loss: 0.461619\n",
      "epoch 7; iter: 200; batch classifier loss: 0.914708; batch adversarial loss: 0.374509\n",
      "epoch 7; iter: 400; batch classifier loss: 0.499947; batch adversarial loss: 0.573049\n",
      "epoch 7; iter: 600; batch classifier loss: 0.376653; batch adversarial loss: 0.395055\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455276; batch adversarial loss: 0.501783\n",
      "epoch 8; iter: 200; batch classifier loss: 0.244171; batch adversarial loss: 0.511875\n",
      "epoch 8; iter: 400; batch classifier loss: 0.618276; batch adversarial loss: 0.417965\n",
      "epoch 8; iter: 600; batch classifier loss: 0.294942; batch adversarial loss: 0.242427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449742; batch adversarial loss: 0.509345\n",
      "epoch 9; iter: 200; batch classifier loss: 0.330066; batch adversarial loss: 0.447548\n",
      "epoch 9; iter: 400; batch classifier loss: 0.366047; batch adversarial loss: 0.478816\n",
      "epoch 9; iter: 600; batch classifier loss: 0.375425; batch adversarial loss: 0.337930\n",
      "epoch 0; iter: 0; batch classifier loss: 7.882623; batch adversarial loss: 0.696159\n",
      "epoch 0; iter: 200; batch classifier loss: 9.159620; batch adversarial loss: 0.616657\n",
      "epoch 0; iter: 400; batch classifier loss: 4.933167; batch adversarial loss: 0.583864\n",
      "epoch 0; iter: 600; batch classifier loss: 3.640873; batch adversarial loss: 0.544406\n",
      "epoch 1; iter: 0; batch classifier loss: 8.781051; batch adversarial loss: 0.507267\n",
      "epoch 1; iter: 200; batch classifier loss: 5.742959; batch adversarial loss: 0.439811\n",
      "epoch 1; iter: 400; batch classifier loss: 2.912950; batch adversarial loss: 0.391995\n",
      "epoch 1; iter: 600; batch classifier loss: 4.372898; batch adversarial loss: 0.371704\n",
      "epoch 2; iter: 0; batch classifier loss: 0.964315; batch adversarial loss: 0.406134\n",
      "epoch 2; iter: 200; batch classifier loss: 0.937004; batch adversarial loss: 0.450873\n",
      "epoch 2; iter: 400; batch classifier loss: 1.927039; batch adversarial loss: 0.367759\n",
      "epoch 2; iter: 600; batch classifier loss: 1.414313; batch adversarial loss: 0.346885\n",
      "epoch 3; iter: 0; batch classifier loss: 1.583763; batch adversarial loss: 0.370652\n",
      "epoch 3; iter: 200; batch classifier loss: 0.483656; batch adversarial loss: 0.401449\n",
      "epoch 3; iter: 400; batch classifier loss: 0.372215; batch adversarial loss: 0.383144\n",
      "epoch 3; iter: 600; batch classifier loss: 1.162206; batch adversarial loss: 0.322613\n",
      "epoch 4; iter: 0; batch classifier loss: 0.366473; batch adversarial loss: 0.552002\n",
      "epoch 4; iter: 200; batch classifier loss: 0.381852; batch adversarial loss: 0.356550\n",
      "epoch 4; iter: 400; batch classifier loss: 0.658555; batch adversarial loss: 0.435192\n",
      "epoch 4; iter: 600; batch classifier loss: 0.523403; batch adversarial loss: 0.495395\n",
      "epoch 5; iter: 0; batch classifier loss: 0.293844; batch adversarial loss: 0.446135\n",
      "epoch 5; iter: 200; batch classifier loss: 0.377756; batch adversarial loss: 0.645913\n",
      "epoch 5; iter: 400; batch classifier loss: 0.573435; batch adversarial loss: 0.500197\n",
      "epoch 5; iter: 600; batch classifier loss: 0.315604; batch adversarial loss: 0.367274\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359878; batch adversarial loss: 0.440473\n",
      "epoch 6; iter: 200; batch classifier loss: 0.392399; batch adversarial loss: 0.298784\n",
      "epoch 6; iter: 400; batch classifier loss: 0.355681; batch adversarial loss: 0.344039\n",
      "epoch 6; iter: 600; batch classifier loss: 0.431150; batch adversarial loss: 0.494197\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338407; batch adversarial loss: 0.519907\n",
      "epoch 7; iter: 200; batch classifier loss: 0.494353; batch adversarial loss: 0.403943\n",
      "epoch 7; iter: 400; batch classifier loss: 0.400943; batch adversarial loss: 0.501231\n",
      "epoch 7; iter: 600; batch classifier loss: 0.348939; batch adversarial loss: 0.518867\n",
      "epoch 8; iter: 0; batch classifier loss: 0.483048; batch adversarial loss: 0.428832\n",
      "epoch 8; iter: 200; batch classifier loss: 0.488419; batch adversarial loss: 0.293701\n",
      "epoch 8; iter: 400; batch classifier loss: 0.391482; batch adversarial loss: 0.435892\n",
      "epoch 8; iter: 600; batch classifier loss: 0.446005; batch adversarial loss: 0.426285\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509974; batch adversarial loss: 0.504662\n",
      "epoch 9; iter: 200; batch classifier loss: 0.395779; batch adversarial loss: 0.371235\n",
      "epoch 9; iter: 400; batch classifier loss: 0.306691; batch adversarial loss: 0.458124\n",
      "epoch 9; iter: 600; batch classifier loss: 0.305426; batch adversarial loss: 0.393299\n",
      "epoch 0; iter: 0; batch classifier loss: 98.874908; batch adversarial loss: 0.647684\n",
      "epoch 0; iter: 200; batch classifier loss: 1.974668; batch adversarial loss: 0.622182\n",
      "epoch 0; iter: 400; batch classifier loss: 7.581588; batch adversarial loss: 0.586754\n",
      "epoch 0; iter: 600; batch classifier loss: 8.338694; batch adversarial loss: 0.500006\n",
      "epoch 1; iter: 0; batch classifier loss: 0.714595; batch adversarial loss: 0.562648\n",
      "epoch 1; iter: 200; batch classifier loss: 1.599487; batch adversarial loss: 0.529406\n",
      "epoch 1; iter: 400; batch classifier loss: 2.407796; batch adversarial loss: 0.458923\n",
      "epoch 1; iter: 600; batch classifier loss: 0.411950; batch adversarial loss: 0.383811\n",
      "epoch 2; iter: 0; batch classifier loss: 1.238354; batch adversarial loss: 0.478943\n",
      "epoch 2; iter: 200; batch classifier loss: 1.088989; batch adversarial loss: 0.416666\n",
      "epoch 2; iter: 400; batch classifier loss: 1.516333; batch adversarial loss: 0.520506\n",
      "epoch 2; iter: 600; batch classifier loss: 0.346805; batch adversarial loss: 0.544254\n",
      "epoch 3; iter: 0; batch classifier loss: 2.174644; batch adversarial loss: 0.320172\n",
      "epoch 3; iter: 200; batch classifier loss: 3.020161; batch adversarial loss: 0.336122\n",
      "epoch 3; iter: 400; batch classifier loss: 1.413835; batch adversarial loss: 0.414005\n",
      "epoch 3; iter: 600; batch classifier loss: 1.137399; batch adversarial loss: 0.455234\n",
      "epoch 4; iter: 0; batch classifier loss: 0.950381; batch adversarial loss: 0.353451\n",
      "epoch 4; iter: 200; batch classifier loss: 0.541231; batch adversarial loss: 0.329837\n",
      "epoch 4; iter: 400; batch classifier loss: 0.727763; batch adversarial loss: 0.352385\n",
      "epoch 4; iter: 600; batch classifier loss: 0.561694; batch adversarial loss: 0.351694\n",
      "epoch 5; iter: 0; batch classifier loss: 0.722528; batch adversarial loss: 0.423679\n",
      "epoch 5; iter: 200; batch classifier loss: 0.740390; batch adversarial loss: 0.369554\n",
      "epoch 5; iter: 400; batch classifier loss: 0.384628; batch adversarial loss: 0.485120\n",
      "epoch 5; iter: 600; batch classifier loss: 0.401873; batch adversarial loss: 0.375759\n",
      "epoch 6; iter: 0; batch classifier loss: 0.373196; batch adversarial loss: 0.337343\n",
      "epoch 6; iter: 200; batch classifier loss: 0.656340; batch adversarial loss: 0.370057\n",
      "epoch 6; iter: 400; batch classifier loss: 0.531312; batch adversarial loss: 0.429054\n",
      "epoch 6; iter: 600; batch classifier loss: 0.611181; batch adversarial loss: 0.388364\n",
      "epoch 7; iter: 0; batch classifier loss: 0.429137; batch adversarial loss: 0.377812\n",
      "epoch 7; iter: 200; batch classifier loss: 0.340042; batch adversarial loss: 0.437531\n",
      "epoch 7; iter: 400; batch classifier loss: 0.378374; batch adversarial loss: 0.336862\n",
      "epoch 7; iter: 600; batch classifier loss: 0.371993; batch adversarial loss: 0.501742\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490950; batch adversarial loss: 0.510622\n",
      "epoch 8; iter: 200; batch classifier loss: 0.499705; batch adversarial loss: 0.434722\n",
      "epoch 8; iter: 400; batch classifier loss: 0.537711; batch adversarial loss: 0.380361\n",
      "epoch 8; iter: 600; batch classifier loss: 0.408545; batch adversarial loss: 0.435781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.351003; batch adversarial loss: 0.321858\n",
      "epoch 9; iter: 200; batch classifier loss: 0.523070; batch adversarial loss: 0.405831\n",
      "epoch 9; iter: 400; batch classifier loss: 0.322151; batch adversarial loss: 0.345704\n",
      "epoch 9; iter: 600; batch classifier loss: 0.493831; batch adversarial loss: 0.452736\n",
      "epoch 0; iter: 0; batch classifier loss: 51.365211; batch adversarial loss: 1.028772\n",
      "epoch 0; iter: 200; batch classifier loss: 5.538356; batch adversarial loss: 0.718191\n",
      "epoch 0; iter: 400; batch classifier loss: 9.305122; batch adversarial loss: 0.587815\n",
      "epoch 0; iter: 600; batch classifier loss: 6.164348; batch adversarial loss: 0.600477\n",
      "epoch 1; iter: 0; batch classifier loss: 2.486294; batch adversarial loss: 0.552040\n",
      "epoch 1; iter: 200; batch classifier loss: 3.310472; batch adversarial loss: 0.486890\n",
      "epoch 1; iter: 400; batch classifier loss: 7.211226; batch adversarial loss: 0.448841\n",
      "epoch 1; iter: 600; batch classifier loss: 1.263195; batch adversarial loss: 0.485371\n",
      "epoch 2; iter: 0; batch classifier loss: 9.171803; batch adversarial loss: 0.446478\n",
      "epoch 2; iter: 200; batch classifier loss: 1.333442; batch adversarial loss: 0.423155\n",
      "epoch 2; iter: 400; batch classifier loss: 0.544285; batch adversarial loss: 0.426002\n",
      "epoch 2; iter: 600; batch classifier loss: 1.083353; batch adversarial loss: 0.377984\n",
      "epoch 3; iter: 0; batch classifier loss: 1.579444; batch adversarial loss: 0.300817\n",
      "epoch 3; iter: 200; batch classifier loss: 1.938850; batch adversarial loss: 0.504677\n",
      "epoch 3; iter: 400; batch classifier loss: 0.394184; batch adversarial loss: 0.464204\n",
      "epoch 3; iter: 600; batch classifier loss: 1.435696; batch adversarial loss: 0.368228\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407815; batch adversarial loss: 0.420948\n",
      "epoch 4; iter: 200; batch classifier loss: 1.923743; batch adversarial loss: 0.403534\n",
      "epoch 4; iter: 400; batch classifier loss: 1.553827; batch adversarial loss: 0.399167\n",
      "epoch 4; iter: 600; batch classifier loss: 0.480764; batch adversarial loss: 0.417039\n",
      "epoch 5; iter: 0; batch classifier loss: 1.739313; batch adversarial loss: 0.402959\n",
      "epoch 5; iter: 200; batch classifier loss: 0.599008; batch adversarial loss: 0.348729\n",
      "epoch 5; iter: 400; batch classifier loss: 0.779914; batch adversarial loss: 0.487051\n",
      "epoch 5; iter: 600; batch classifier loss: 0.550342; batch adversarial loss: 0.518110\n",
      "epoch 6; iter: 0; batch classifier loss: 0.469273; batch adversarial loss: 0.421919\n",
      "epoch 6; iter: 200; batch classifier loss: 0.564885; batch adversarial loss: 0.391038\n",
      "epoch 6; iter: 400; batch classifier loss: 0.421029; batch adversarial loss: 0.428130\n",
      "epoch 6; iter: 600; batch classifier loss: 0.840172; batch adversarial loss: 0.427272\n",
      "epoch 7; iter: 0; batch classifier loss: 0.445935; batch adversarial loss: 0.430430\n",
      "epoch 7; iter: 200; batch classifier loss: 0.338659; batch adversarial loss: 0.216438\n",
      "epoch 7; iter: 400; batch classifier loss: 0.279200; batch adversarial loss: 0.457515\n",
      "epoch 7; iter: 600; batch classifier loss: 0.441613; batch adversarial loss: 0.409972\n",
      "epoch 8; iter: 0; batch classifier loss: 0.454636; batch adversarial loss: 0.321966\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401350; batch adversarial loss: 0.316039\n",
      "epoch 8; iter: 400; batch classifier loss: 0.320737; batch adversarial loss: 0.401892\n",
      "epoch 8; iter: 600; batch classifier loss: 0.283520; batch adversarial loss: 0.428670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.279716; batch adversarial loss: 0.454234\n",
      "epoch 9; iter: 200; batch classifier loss: 0.493443; batch adversarial loss: 0.471084\n",
      "epoch 9; iter: 400; batch classifier loss: 0.404586; batch adversarial loss: 0.387771\n",
      "epoch 9; iter: 600; batch classifier loss: 0.298575; batch adversarial loss: 0.373280\n",
      "epoch 0; iter: 0; batch classifier loss: 22.699068; batch adversarial loss: 0.705097\n",
      "epoch 0; iter: 200; batch classifier loss: 7.485623; batch adversarial loss: 0.642394\n",
      "epoch 0; iter: 400; batch classifier loss: 0.597540; batch adversarial loss: 0.577408\n",
      "epoch 0; iter: 600; batch classifier loss: 6.706540; batch adversarial loss: 0.525437\n",
      "epoch 1; iter: 0; batch classifier loss: 6.337803; batch adversarial loss: 0.531178\n",
      "epoch 1; iter: 200; batch classifier loss: 2.802037; batch adversarial loss: 0.458006\n",
      "epoch 1; iter: 400; batch classifier loss: 5.092824; batch adversarial loss: 0.486327\n",
      "epoch 1; iter: 600; batch classifier loss: 2.665999; batch adversarial loss: 0.465428\n",
      "epoch 2; iter: 0; batch classifier loss: 10.511765; batch adversarial loss: 0.495488\n",
      "epoch 2; iter: 200; batch classifier loss: 0.636118; batch adversarial loss: 0.427811\n",
      "epoch 2; iter: 400; batch classifier loss: 0.393410; batch adversarial loss: 0.548454\n",
      "epoch 2; iter: 600; batch classifier loss: 0.476231; batch adversarial loss: 0.415013\n",
      "epoch 3; iter: 0; batch classifier loss: 0.465632; batch adversarial loss: 0.377059\n",
      "epoch 3; iter: 200; batch classifier loss: 2.297836; batch adversarial loss: 0.398142\n",
      "epoch 3; iter: 400; batch classifier loss: 0.565149; batch adversarial loss: 0.357629\n",
      "epoch 3; iter: 600; batch classifier loss: 1.072458; batch adversarial loss: 0.402487\n",
      "epoch 4; iter: 0; batch classifier loss: 1.144042; batch adversarial loss: 0.344608\n",
      "epoch 4; iter: 200; batch classifier loss: 0.765502; batch adversarial loss: 0.400183\n",
      "epoch 4; iter: 400; batch classifier loss: 1.356417; batch adversarial loss: 0.344268\n",
      "epoch 4; iter: 600; batch classifier loss: 0.312052; batch adversarial loss: 0.376249\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572876; batch adversarial loss: 0.508577\n",
      "epoch 5; iter: 200; batch classifier loss: 0.468000; batch adversarial loss: 0.290731\n",
      "epoch 5; iter: 400; batch classifier loss: 0.839893; batch adversarial loss: 0.359510\n",
      "epoch 5; iter: 600; batch classifier loss: 0.315183; batch adversarial loss: 0.478624\n",
      "epoch 6; iter: 0; batch classifier loss: 0.331273; batch adversarial loss: 0.440102\n",
      "epoch 6; iter: 200; batch classifier loss: 0.406477; batch adversarial loss: 0.513915\n",
      "epoch 6; iter: 400; batch classifier loss: 0.400578; batch adversarial loss: 0.369708\n",
      "epoch 6; iter: 600; batch classifier loss: 0.513002; batch adversarial loss: 0.420230\n",
      "epoch 7; iter: 0; batch classifier loss: 0.521503; batch adversarial loss: 0.462653\n",
      "epoch 7; iter: 200; batch classifier loss: 0.349325; batch adversarial loss: 0.359523\n",
      "epoch 7; iter: 400; batch classifier loss: 0.363759; batch adversarial loss: 0.378793\n",
      "epoch 7; iter: 600; batch classifier loss: 0.337500; batch adversarial loss: 0.349223\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360994; batch adversarial loss: 0.481831\n",
      "epoch 8; iter: 200; batch classifier loss: 0.384511; batch adversarial loss: 0.368764\n",
      "epoch 8; iter: 400; batch classifier loss: 0.328106; batch adversarial loss: 0.374861\n",
      "epoch 8; iter: 600; batch classifier loss: 0.581345; batch adversarial loss: 0.353317\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560006; batch adversarial loss: 0.494279\n",
      "epoch 9; iter: 200; batch classifier loss: 0.622170; batch adversarial loss: 0.369429\n",
      "epoch 9; iter: 400; batch classifier loss: 0.257477; batch adversarial loss: 0.324811\n",
      "epoch 9; iter: 600; batch classifier loss: 0.267005; batch adversarial loss: 0.727230\n",
      "epoch 0; iter: 0; batch classifier loss: 31.840118; batch adversarial loss: 0.678399\n",
      "epoch 0; iter: 200; batch classifier loss: 18.621161; batch adversarial loss: 0.598186\n",
      "epoch 0; iter: 400; batch classifier loss: 14.720052; batch adversarial loss: 0.513650\n",
      "epoch 0; iter: 600; batch classifier loss: 9.246252; batch adversarial loss: 0.497127\n",
      "epoch 1; iter: 0; batch classifier loss: 2.575768; batch adversarial loss: 0.482642\n",
      "epoch 1; iter: 200; batch classifier loss: 4.526133; batch adversarial loss: 0.495036\n",
      "epoch 1; iter: 400; batch classifier loss: 0.938110; batch adversarial loss: 0.422537\n",
      "epoch 1; iter: 600; batch classifier loss: 0.433216; batch adversarial loss: 0.399280\n",
      "epoch 2; iter: 0; batch classifier loss: 2.285258; batch adversarial loss: 0.416477\n",
      "epoch 2; iter: 200; batch classifier loss: 1.574796; batch adversarial loss: 0.398513\n",
      "epoch 2; iter: 400; batch classifier loss: 2.914924; batch adversarial loss: 0.424684\n",
      "epoch 2; iter: 600; batch classifier loss: 0.568617; batch adversarial loss: 0.454487\n",
      "epoch 3; iter: 0; batch classifier loss: 0.401557; batch adversarial loss: 0.318142\n",
      "epoch 3; iter: 200; batch classifier loss: 0.502172; batch adversarial loss: 0.418592\n",
      "epoch 3; iter: 400; batch classifier loss: 1.244457; batch adversarial loss: 0.465828\n",
      "epoch 3; iter: 600; batch classifier loss: 1.429193; batch adversarial loss: 0.452608\n",
      "epoch 4; iter: 0; batch classifier loss: 0.711988; batch adversarial loss: 0.343187\n",
      "epoch 4; iter: 200; batch classifier loss: 0.385974; batch adversarial loss: 0.463245\n",
      "epoch 4; iter: 400; batch classifier loss: 1.566223; batch adversarial loss: 0.419361\n",
      "epoch 4; iter: 600; batch classifier loss: 0.720426; batch adversarial loss: 0.397219\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573694; batch adversarial loss: 0.483468\n",
      "epoch 5; iter: 200; batch classifier loss: 0.247442; batch adversarial loss: 0.388507\n",
      "epoch 5; iter: 400; batch classifier loss: 0.226821; batch adversarial loss: 0.536402\n",
      "epoch 5; iter: 600; batch classifier loss: 1.205246; batch adversarial loss: 0.391951\n",
      "epoch 6; iter: 0; batch classifier loss: 0.678266; batch adversarial loss: 0.363997\n",
      "epoch 6; iter: 200; batch classifier loss: 0.708892; batch adversarial loss: 0.389796\n",
      "epoch 6; iter: 400; batch classifier loss: 0.438217; batch adversarial loss: 0.525179\n",
      "epoch 6; iter: 600; batch classifier loss: 0.480955; batch adversarial loss: 0.312096\n",
      "epoch 7; iter: 0; batch classifier loss: 0.316368; batch adversarial loss: 0.395236\n",
      "epoch 7; iter: 200; batch classifier loss: 0.376204; batch adversarial loss: 0.329219\n",
      "epoch 7; iter: 400; batch classifier loss: 0.384353; batch adversarial loss: 0.378970\n",
      "epoch 7; iter: 600; batch classifier loss: 0.312106; batch adversarial loss: 0.454500\n",
      "epoch 8; iter: 0; batch classifier loss: 0.459069; batch adversarial loss: 0.381931\n",
      "epoch 8; iter: 200; batch classifier loss: 0.268728; batch adversarial loss: 0.347547\n",
      "epoch 8; iter: 400; batch classifier loss: 0.427980; batch adversarial loss: 0.409233\n",
      "epoch 8; iter: 600; batch classifier loss: 0.290546; batch adversarial loss: 0.455252\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401107; batch adversarial loss: 0.390523\n",
      "epoch 9; iter: 200; batch classifier loss: 0.231321; batch adversarial loss: 0.382303\n",
      "epoch 9; iter: 400; batch classifier loss: 0.295055; batch adversarial loss: 0.264703\n",
      "epoch 9; iter: 600; batch classifier loss: 0.355570; batch adversarial loss: 0.346423\n",
      "epoch 0; iter: 0; batch classifier loss: 36.080681; batch adversarial loss: 0.767838\n",
      "epoch 0; iter: 200; batch classifier loss: 2.360266; batch adversarial loss: 0.683220\n",
      "epoch 0; iter: 400; batch classifier loss: 5.233315; batch adversarial loss: 0.589885\n",
      "epoch 0; iter: 600; batch classifier loss: 10.955558; batch adversarial loss: 0.565454\n",
      "epoch 1; iter: 0; batch classifier loss: 8.328724; batch adversarial loss: 0.544205\n",
      "epoch 1; iter: 200; batch classifier loss: 7.681917; batch adversarial loss: 0.467044\n",
      "epoch 1; iter: 400; batch classifier loss: 13.142967; batch adversarial loss: 0.517190\n",
      "epoch 1; iter: 600; batch classifier loss: 4.108399; batch adversarial loss: 0.443832\n",
      "epoch 2; iter: 0; batch classifier loss: 5.011684; batch adversarial loss: 0.468212\n",
      "epoch 2; iter: 200; batch classifier loss: 2.455024; batch adversarial loss: 0.409994\n",
      "epoch 2; iter: 400; batch classifier loss: 1.545007; batch adversarial loss: 0.325935\n",
      "epoch 2; iter: 600; batch classifier loss: 0.343959; batch adversarial loss: 0.449648\n",
      "epoch 3; iter: 0; batch classifier loss: 1.821960; batch adversarial loss: 0.486951\n",
      "epoch 3; iter: 200; batch classifier loss: 0.758618; batch adversarial loss: 0.419720\n",
      "epoch 3; iter: 400; batch classifier loss: 0.534318; batch adversarial loss: 0.503970\n",
      "epoch 3; iter: 600; batch classifier loss: 0.453727; batch adversarial loss: 0.513507\n",
      "epoch 4; iter: 0; batch classifier loss: 0.802546; batch adversarial loss: 0.362573\n",
      "epoch 4; iter: 200; batch classifier loss: 0.376823; batch adversarial loss: 0.341812\n",
      "epoch 4; iter: 400; batch classifier loss: 0.462639; batch adversarial loss: 0.401872\n",
      "epoch 4; iter: 600; batch classifier loss: 1.043403; batch adversarial loss: 0.433142\n",
      "epoch 5; iter: 0; batch classifier loss: 0.417756; batch adversarial loss: 0.501146\n",
      "epoch 5; iter: 200; batch classifier loss: 0.725711; batch adversarial loss: 0.295949\n",
      "epoch 5; iter: 400; batch classifier loss: 0.455441; batch adversarial loss: 0.438097\n",
      "epoch 5; iter: 600; batch classifier loss: 0.490090; batch adversarial loss: 0.438873\n",
      "epoch 6; iter: 0; batch classifier loss: 0.866453; batch adversarial loss: 0.472181\n",
      "epoch 6; iter: 200; batch classifier loss: 0.442212; batch adversarial loss: 0.242531\n",
      "epoch 6; iter: 400; batch classifier loss: 2.926617; batch adversarial loss: 0.491905\n",
      "epoch 6; iter: 600; batch classifier loss: 0.489327; batch adversarial loss: 0.358194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.215514; batch adversarial loss: 0.407459\n",
      "epoch 7; iter: 200; batch classifier loss: 0.516867; batch adversarial loss: 0.395621\n",
      "epoch 7; iter: 400; batch classifier loss: 0.645493; batch adversarial loss: 0.356223\n",
      "epoch 7; iter: 600; batch classifier loss: 0.327042; batch adversarial loss: 0.468070\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286295; batch adversarial loss: 0.507422\n",
      "epoch 8; iter: 200; batch classifier loss: 0.445404; batch adversarial loss: 0.464637\n",
      "epoch 8; iter: 400; batch classifier loss: 0.336803; batch adversarial loss: 0.467512\n",
      "epoch 8; iter: 600; batch classifier loss: 0.348447; batch adversarial loss: 0.381414\n",
      "epoch 9; iter: 0; batch classifier loss: 0.482848; batch adversarial loss: 0.404438\n",
      "epoch 9; iter: 200; batch classifier loss: 0.472539; batch adversarial loss: 0.431762\n",
      "epoch 9; iter: 400; batch classifier loss: 0.478918; batch adversarial loss: 0.375407\n",
      "epoch 9; iter: 600; batch classifier loss: 0.439854; batch adversarial loss: 0.422259\n",
      "epoch 0; iter: 0; batch classifier loss: 8.198101; batch adversarial loss: 0.741213\n",
      "epoch 0; iter: 200; batch classifier loss: 7.962484; batch adversarial loss: 0.746402\n",
      "epoch 0; iter: 400; batch classifier loss: 0.886312; batch adversarial loss: 0.586736\n",
      "epoch 0; iter: 600; batch classifier loss: 3.876736; batch adversarial loss: 0.598642\n",
      "epoch 1; iter: 0; batch classifier loss: 9.415492; batch adversarial loss: 0.552019\n",
      "epoch 1; iter: 200; batch classifier loss: 2.381934; batch adversarial loss: 0.520624\n",
      "epoch 1; iter: 400; batch classifier loss: 5.004869; batch adversarial loss: 0.466153\n",
      "epoch 1; iter: 600; batch classifier loss: 1.203644; batch adversarial loss: 0.520522\n",
      "epoch 2; iter: 0; batch classifier loss: 1.604150; batch adversarial loss: 0.442165\n",
      "epoch 2; iter: 200; batch classifier loss: 2.077294; batch adversarial loss: 0.430889\n",
      "epoch 2; iter: 400; batch classifier loss: 1.409565; batch adversarial loss: 0.544750\n",
      "epoch 2; iter: 600; batch classifier loss: 2.182024; batch adversarial loss: 0.394506\n",
      "epoch 3; iter: 0; batch classifier loss: 0.933778; batch adversarial loss: 0.365661\n",
      "epoch 3; iter: 200; batch classifier loss: 0.606136; batch adversarial loss: 0.429313\n",
      "epoch 3; iter: 400; batch classifier loss: 0.408235; batch adversarial loss: 0.407184\n",
      "epoch 3; iter: 600; batch classifier loss: 0.468601; batch adversarial loss: 0.389304\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386997; batch adversarial loss: 0.449904\n",
      "epoch 4; iter: 200; batch classifier loss: 0.303567; batch adversarial loss: 0.329593\n",
      "epoch 4; iter: 400; batch classifier loss: 0.404406; batch adversarial loss: 0.293870\n",
      "epoch 4; iter: 600; batch classifier loss: 0.523608; batch adversarial loss: 0.472798\n",
      "epoch 5; iter: 0; batch classifier loss: 7.536199; batch adversarial loss: 0.355859\n",
      "epoch 5; iter: 200; batch classifier loss: 0.529095; batch adversarial loss: 0.387632\n",
      "epoch 5; iter: 400; batch classifier loss: 0.402279; batch adversarial loss: 0.473905\n",
      "epoch 5; iter: 600; batch classifier loss: 0.283414; batch adversarial loss: 0.464698\n",
      "epoch 6; iter: 0; batch classifier loss: 0.433964; batch adversarial loss: 0.350722\n",
      "epoch 6; iter: 200; batch classifier loss: 0.352408; batch adversarial loss: 0.315159\n",
      "epoch 6; iter: 400; batch classifier loss: 0.313493; batch adversarial loss: 0.453543\n",
      "epoch 6; iter: 600; batch classifier loss: 0.449227; batch adversarial loss: 0.359587\n",
      "epoch 7; iter: 0; batch classifier loss: 0.593704; batch adversarial loss: 0.404121\n",
      "epoch 7; iter: 200; batch classifier loss: 0.449903; batch adversarial loss: 0.369158\n",
      "epoch 7; iter: 400; batch classifier loss: 0.417395; batch adversarial loss: 0.254889\n",
      "epoch 7; iter: 600; batch classifier loss: 0.352057; batch adversarial loss: 0.316560\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322364; batch adversarial loss: 0.448106\n",
      "epoch 8; iter: 200; batch classifier loss: 0.275058; batch adversarial loss: 0.477583\n",
      "epoch 8; iter: 400; batch classifier loss: 0.347739; batch adversarial loss: 0.319196\n",
      "epoch 8; iter: 600; batch classifier loss: 0.438869; batch adversarial loss: 0.498737\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304889; batch adversarial loss: 0.396628\n",
      "epoch 9; iter: 200; batch classifier loss: 0.454748; batch adversarial loss: 0.372619\n",
      "epoch 9; iter: 400; batch classifier loss: 0.405071; batch adversarial loss: 0.572793\n",
      "epoch 9; iter: 600; batch classifier loss: 0.329611; batch adversarial loss: 0.313479\n",
      "epoch 0; iter: 0; batch classifier loss: 50.603092; batch adversarial loss: 0.674213\n",
      "epoch 0; iter: 200; batch classifier loss: 10.255850; batch adversarial loss: 0.635677\n",
      "epoch 0; iter: 400; batch classifier loss: 2.302819; batch adversarial loss: 0.647407\n",
      "epoch 0; iter: 600; batch classifier loss: 5.695759; batch adversarial loss: 0.639074\n",
      "epoch 1; iter: 0; batch classifier loss: 11.221859; batch adversarial loss: 0.478263\n",
      "epoch 1; iter: 200; batch classifier loss: 7.162688; batch adversarial loss: 0.443682\n",
      "epoch 1; iter: 400; batch classifier loss: 1.576021; batch adversarial loss: 0.447287\n",
      "epoch 1; iter: 600; batch classifier loss: 3.919822; batch adversarial loss: 0.548912\n",
      "epoch 2; iter: 0; batch classifier loss: 7.878170; batch adversarial loss: 0.394681\n",
      "epoch 2; iter: 200; batch classifier loss: 1.479080; batch adversarial loss: 0.592437\n",
      "epoch 2; iter: 400; batch classifier loss: 4.711283; batch adversarial loss: 0.450285\n",
      "epoch 2; iter: 600; batch classifier loss: 1.474359; batch adversarial loss: 0.551162\n",
      "epoch 3; iter: 0; batch classifier loss: 1.391440; batch adversarial loss: 0.439438\n",
      "epoch 3; iter: 200; batch classifier loss: 0.401225; batch adversarial loss: 0.404921\n",
      "epoch 3; iter: 400; batch classifier loss: 0.417309; batch adversarial loss: 0.406730\n",
      "epoch 3; iter: 600; batch classifier loss: 0.658007; batch adversarial loss: 0.470334\n",
      "epoch 4; iter: 0; batch classifier loss: 0.611010; batch adversarial loss: 0.507010\n",
      "epoch 4; iter: 200; batch classifier loss: 0.319790; batch adversarial loss: 0.486633\n",
      "epoch 4; iter: 400; batch classifier loss: 1.290435; batch adversarial loss: 0.544968\n",
      "epoch 4; iter: 600; batch classifier loss: 0.840215; batch adversarial loss: 0.361918\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589155; batch adversarial loss: 0.362204\n",
      "epoch 5; iter: 200; batch classifier loss: 0.280901; batch adversarial loss: 0.489034\n",
      "epoch 5; iter: 400; batch classifier loss: 0.446352; batch adversarial loss: 0.510831\n",
      "epoch 5; iter: 600; batch classifier loss: 0.392569; batch adversarial loss: 0.394380\n",
      "epoch 6; iter: 0; batch classifier loss: 0.325314; batch adversarial loss: 0.411202\n",
      "epoch 6; iter: 200; batch classifier loss: 0.471983; batch adversarial loss: 0.548145\n",
      "epoch 6; iter: 400; batch classifier loss: 0.611958; batch adversarial loss: 0.350346\n",
      "epoch 6; iter: 600; batch classifier loss: 0.185535; batch adversarial loss: 0.461108\n",
      "epoch 7; iter: 0; batch classifier loss: 0.319534; batch adversarial loss: 0.438277\n",
      "epoch 7; iter: 200; batch classifier loss: 0.398283; batch adversarial loss: 0.406988\n",
      "epoch 7; iter: 400; batch classifier loss: 0.454671; batch adversarial loss: 0.247669\n",
      "epoch 7; iter: 600; batch classifier loss: 0.272672; batch adversarial loss: 0.449942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.336749; batch adversarial loss: 0.431162\n",
      "epoch 8; iter: 200; batch classifier loss: 0.282608; batch adversarial loss: 0.424572\n",
      "epoch 8; iter: 400; batch classifier loss: 0.373709; batch adversarial loss: 0.287261\n",
      "epoch 8; iter: 600; batch classifier loss: 0.468489; batch adversarial loss: 0.399463\n",
      "epoch 9; iter: 0; batch classifier loss: 0.328238; batch adversarial loss: 0.475729\n",
      "epoch 9; iter: 200; batch classifier loss: 0.343910; batch adversarial loss: 0.480574\n",
      "epoch 9; iter: 400; batch classifier loss: 0.628585; batch adversarial loss: 0.444522\n",
      "epoch 9; iter: 600; batch classifier loss: 0.274808; batch adversarial loss: 0.407187\n",
      "epoch 0; iter: 0; batch classifier loss: 23.746605; batch adversarial loss: 0.763132\n",
      "epoch 0; iter: 200; batch classifier loss: 8.113899; batch adversarial loss: 0.627357\n",
      "epoch 0; iter: 400; batch classifier loss: 0.526173; batch adversarial loss: 0.560741\n",
      "epoch 0; iter: 600; batch classifier loss: 6.430442; batch adversarial loss: 0.529462\n",
      "epoch 1; iter: 0; batch classifier loss: 7.768638; batch adversarial loss: 0.490066\n",
      "epoch 1; iter: 200; batch classifier loss: 2.883507; batch adversarial loss: 0.419777\n",
      "epoch 1; iter: 400; batch classifier loss: 2.828063; batch adversarial loss: 0.520549\n",
      "epoch 1; iter: 600; batch classifier loss: 2.495342; batch adversarial loss: 0.429581\n",
      "epoch 2; iter: 0; batch classifier loss: 6.484357; batch adversarial loss: 0.368089\n",
      "epoch 2; iter: 200; batch classifier loss: 1.727325; batch adversarial loss: 0.352125\n",
      "epoch 2; iter: 400; batch classifier loss: 3.201850; batch adversarial loss: 0.409486\n",
      "epoch 2; iter: 600; batch classifier loss: 2.869564; batch adversarial loss: 0.452142\n",
      "epoch 3; iter: 0; batch classifier loss: 0.263038; batch adversarial loss: 0.471189\n",
      "epoch 3; iter: 200; batch classifier loss: 0.680821; batch adversarial loss: 0.488517\n",
      "epoch 3; iter: 400; batch classifier loss: 4.067485; batch adversarial loss: 0.393025\n",
      "epoch 3; iter: 600; batch classifier loss: 0.339609; batch adversarial loss: 0.456194\n",
      "epoch 4; iter: 0; batch classifier loss: 1.539541; batch adversarial loss: 0.471458\n",
      "epoch 4; iter: 200; batch classifier loss: 1.298344; batch adversarial loss: 0.470021\n",
      "epoch 4; iter: 400; batch classifier loss: 0.372917; batch adversarial loss: 0.502327\n",
      "epoch 4; iter: 600; batch classifier loss: 1.038800; batch adversarial loss: 0.314025\n",
      "epoch 5; iter: 0; batch classifier loss: 0.348703; batch adversarial loss: 0.436427\n",
      "epoch 5; iter: 200; batch classifier loss: 0.363998; batch adversarial loss: 0.360588\n",
      "epoch 5; iter: 400; batch classifier loss: 0.263291; batch adversarial loss: 0.313117\n",
      "epoch 5; iter: 600; batch classifier loss: 0.281153; batch adversarial loss: 0.395196\n",
      "epoch 6; iter: 0; batch classifier loss: 0.319539; batch adversarial loss: 0.331414\n",
      "epoch 6; iter: 200; batch classifier loss: 0.442433; batch adversarial loss: 0.376441\n",
      "epoch 6; iter: 400; batch classifier loss: 0.592035; batch adversarial loss: 0.482767\n",
      "epoch 6; iter: 600; batch classifier loss: 0.366477; batch adversarial loss: 0.293534\n",
      "epoch 7; iter: 0; batch classifier loss: 0.378881; batch adversarial loss: 0.369797\n",
      "epoch 7; iter: 200; batch classifier loss: 0.502865; batch adversarial loss: 0.436842\n",
      "epoch 7; iter: 400; batch classifier loss: 0.392541; batch adversarial loss: 0.463255\n",
      "epoch 7; iter: 600; batch classifier loss: 0.404481; batch adversarial loss: 0.303277\n",
      "epoch 8; iter: 0; batch classifier loss: 0.496409; batch adversarial loss: 0.380065\n",
      "epoch 8; iter: 200; batch classifier loss: 0.297995; batch adversarial loss: 0.566073\n",
      "epoch 8; iter: 400; batch classifier loss: 0.493170; batch adversarial loss: 0.454648\n",
      "epoch 8; iter: 600; batch classifier loss: 0.452567; batch adversarial loss: 0.287475\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438056; batch adversarial loss: 0.432641\n",
      "epoch 9; iter: 200; batch classifier loss: 0.395534; batch adversarial loss: 0.447344\n",
      "epoch 9; iter: 400; batch classifier loss: 0.269824; batch adversarial loss: 0.407817\n",
      "epoch 9; iter: 600; batch classifier loss: 0.408090; batch adversarial loss: 0.248041\n",
      "epoch 0; iter: 0; batch classifier loss: 95.003433; batch adversarial loss: 0.705504\n",
      "epoch 0; iter: 200; batch classifier loss: 9.603483; batch adversarial loss: 0.624680\n",
      "epoch 0; iter: 400; batch classifier loss: 6.851254; batch adversarial loss: 0.559972\n",
      "epoch 0; iter: 600; batch classifier loss: 10.142748; batch adversarial loss: 0.534286\n",
      "epoch 1; iter: 0; batch classifier loss: 9.203518; batch adversarial loss: 0.613757\n",
      "epoch 1; iter: 200; batch classifier loss: 6.629988; batch adversarial loss: 0.492170\n",
      "epoch 1; iter: 400; batch classifier loss: 4.723842; batch adversarial loss: 0.517031\n",
      "epoch 1; iter: 600; batch classifier loss: 3.083728; batch adversarial loss: 0.437223\n",
      "epoch 2; iter: 0; batch classifier loss: 10.248995; batch adversarial loss: 0.494228\n",
      "epoch 2; iter: 200; batch classifier loss: 1.218923; batch adversarial loss: 0.461846\n",
      "epoch 2; iter: 400; batch classifier loss: 4.176079; batch adversarial loss: 0.435500\n",
      "epoch 2; iter: 600; batch classifier loss: 0.760075; batch adversarial loss: 0.479195\n",
      "epoch 3; iter: 0; batch classifier loss: 2.418980; batch adversarial loss: 0.379411\n",
      "epoch 3; iter: 200; batch classifier loss: 1.131873; batch adversarial loss: 0.560111\n",
      "epoch 3; iter: 400; batch classifier loss: 0.316940; batch adversarial loss: 0.361465\n",
      "epoch 3; iter: 600; batch classifier loss: 1.746278; batch adversarial loss: 0.469579\n",
      "epoch 4; iter: 0; batch classifier loss: 3.643329; batch adversarial loss: 0.435034\n",
      "epoch 4; iter: 200; batch classifier loss: 0.842380; batch adversarial loss: 0.478942\n",
      "epoch 4; iter: 400; batch classifier loss: 0.475543; batch adversarial loss: 0.392368\n",
      "epoch 4; iter: 600; batch classifier loss: 1.286115; batch adversarial loss: 0.424940\n",
      "epoch 5; iter: 0; batch classifier loss: 0.435791; batch adversarial loss: 0.371741\n",
      "epoch 5; iter: 200; batch classifier loss: 0.727239; batch adversarial loss: 0.514248\n",
      "epoch 5; iter: 400; batch classifier loss: 0.331463; batch adversarial loss: 0.490396\n",
      "epoch 5; iter: 600; batch classifier loss: 0.693746; batch adversarial loss: 0.489105\n",
      "epoch 6; iter: 0; batch classifier loss: 0.286900; batch adversarial loss: 0.388851\n",
      "epoch 6; iter: 200; batch classifier loss: 0.493518; batch adversarial loss: 0.366057\n",
      "epoch 6; iter: 400; batch classifier loss: 0.341492; batch adversarial loss: 0.438361\n",
      "epoch 6; iter: 600; batch classifier loss: 0.367063; batch adversarial loss: 0.243034\n",
      "epoch 7; iter: 0; batch classifier loss: 0.357787; batch adversarial loss: 0.464726\n",
      "epoch 7; iter: 200; batch classifier loss: 0.350592; batch adversarial loss: 0.427953\n",
      "epoch 7; iter: 400; batch classifier loss: 0.226182; batch adversarial loss: 0.322906\n",
      "epoch 7; iter: 600; batch classifier loss: 0.281555; batch adversarial loss: 0.489492\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544314; batch adversarial loss: 0.332240\n",
      "epoch 8; iter: 200; batch classifier loss: 0.561647; batch adversarial loss: 0.403608\n",
      "epoch 8; iter: 400; batch classifier loss: 0.448979; batch adversarial loss: 0.354848\n",
      "epoch 8; iter: 600; batch classifier loss: 0.350643; batch adversarial loss: 0.514120\n",
      "epoch 9; iter: 0; batch classifier loss: 0.447370; batch adversarial loss: 0.460398\n",
      "epoch 9; iter: 200; batch classifier loss: 0.356059; batch adversarial loss: 0.460062\n",
      "epoch 9; iter: 400; batch classifier loss: 0.588757; batch adversarial loss: 0.449512\n",
      "epoch 9; iter: 600; batch classifier loss: 0.405991; batch adversarial loss: 0.619094\n",
      "epoch 0; iter: 0; batch classifier loss: 259.355896; batch adversarial loss: 0.868364\n",
      "epoch 0; iter: 200; batch classifier loss: 16.960539; batch adversarial loss: 0.643592\n",
      "epoch 0; iter: 400; batch classifier loss: 1.360463; batch adversarial loss: 0.577939\n",
      "epoch 0; iter: 600; batch classifier loss: 4.751752; batch adversarial loss: 0.538768\n",
      "epoch 1; iter: 0; batch classifier loss: 3.526644; batch adversarial loss: 0.602897\n",
      "epoch 1; iter: 200; batch classifier loss: 15.071342; batch adversarial loss: 0.547694\n",
      "epoch 1; iter: 400; batch classifier loss: 12.244007; batch adversarial loss: 0.430721\n",
      "epoch 1; iter: 600; batch classifier loss: 4.488422; batch adversarial loss: 0.401667\n",
      "epoch 2; iter: 0; batch classifier loss: 1.974733; batch adversarial loss: 0.464884\n",
      "epoch 2; iter: 200; batch classifier loss: 3.255675; batch adversarial loss: 0.491368\n",
      "epoch 2; iter: 400; batch classifier loss: 1.262794; batch adversarial loss: 0.489103\n",
      "epoch 2; iter: 600; batch classifier loss: 0.378580; batch adversarial loss: 0.351248\n",
      "epoch 3; iter: 0; batch classifier loss: 2.785844; batch adversarial loss: 0.510245\n",
      "epoch 3; iter: 200; batch classifier loss: 0.360201; batch adversarial loss: 0.483657\n",
      "epoch 3; iter: 400; batch classifier loss: 2.587736; batch adversarial loss: 0.523178\n",
      "epoch 3; iter: 600; batch classifier loss: 0.339816; batch adversarial loss: 0.290667\n",
      "epoch 4; iter: 0; batch classifier loss: 2.162668; batch adversarial loss: 0.338147\n",
      "epoch 4; iter: 200; batch classifier loss: 0.407451; batch adversarial loss: 0.406596\n",
      "epoch 4; iter: 400; batch classifier loss: 1.977282; batch adversarial loss: 0.355661\n",
      "epoch 4; iter: 600; batch classifier loss: 0.430239; batch adversarial loss: 0.456838\n",
      "epoch 5; iter: 0; batch classifier loss: 0.408227; batch adversarial loss: 0.387244\n",
      "epoch 5; iter: 200; batch classifier loss: 0.707138; batch adversarial loss: 0.509409\n",
      "epoch 5; iter: 400; batch classifier loss: 1.337271; batch adversarial loss: 0.479930\n",
      "epoch 5; iter: 600; batch classifier loss: 0.580130; batch adversarial loss: 0.410826\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357607; batch adversarial loss: 0.402483\n",
      "epoch 6; iter: 200; batch classifier loss: 0.601014; batch adversarial loss: 0.383486\n",
      "epoch 6; iter: 400; batch classifier loss: 0.574560; batch adversarial loss: 0.335358\n",
      "epoch 6; iter: 600; batch classifier loss: 0.349410; batch adversarial loss: 0.465953\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508849; batch adversarial loss: 0.393789\n",
      "epoch 7; iter: 200; batch classifier loss: 0.624503; batch adversarial loss: 0.382434\n",
      "epoch 7; iter: 400; batch classifier loss: 0.298351; batch adversarial loss: 0.406458\n",
      "epoch 7; iter: 600; batch classifier loss: 0.553999; batch adversarial loss: 0.469604\n",
      "epoch 8; iter: 0; batch classifier loss: 0.424129; batch adversarial loss: 0.485863\n",
      "epoch 8; iter: 200; batch classifier loss: 0.345815; batch adversarial loss: 0.467300\n",
      "epoch 8; iter: 400; batch classifier loss: 0.430916; batch adversarial loss: 0.328730\n",
      "epoch 8; iter: 600; batch classifier loss: 0.345555; batch adversarial loss: 0.238767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284319; batch adversarial loss: 0.440682\n",
      "epoch 9; iter: 200; batch classifier loss: 0.374452; batch adversarial loss: 0.377880\n",
      "epoch 9; iter: 400; batch classifier loss: 0.384635; batch adversarial loss: 0.422143\n",
      "epoch 9; iter: 600; batch classifier loss: 0.245266; batch adversarial loss: 0.405162\n",
      "epoch 0; iter: 0; batch classifier loss: 22.847759; batch adversarial loss: 1.003074\n",
      "epoch 0; iter: 200; batch classifier loss: 2.534142; batch adversarial loss: 0.731419\n",
      "epoch 0; iter: 400; batch classifier loss: 1.582247; batch adversarial loss: 0.607969\n",
      "epoch 0; iter: 600; batch classifier loss: 3.785773; batch adversarial loss: 0.548365\n",
      "epoch 1; iter: 0; batch classifier loss: 3.124760; batch adversarial loss: 0.542032\n",
      "epoch 1; iter: 200; batch classifier loss: 15.418417; batch adversarial loss: 0.536916\n",
      "epoch 1; iter: 400; batch classifier loss: 1.394419; batch adversarial loss: 0.465739\n",
      "epoch 1; iter: 600; batch classifier loss: 3.464216; batch adversarial loss: 0.478158\n",
      "epoch 2; iter: 0; batch classifier loss: 0.674789; batch adversarial loss: 0.458484\n",
      "epoch 2; iter: 200; batch classifier loss: 1.178401; batch adversarial loss: 0.393795\n",
      "epoch 2; iter: 400; batch classifier loss: 1.727706; batch adversarial loss: 0.413810\n",
      "epoch 2; iter: 600; batch classifier loss: 1.414795; batch adversarial loss: 0.350437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.860520; batch adversarial loss: 0.463367\n",
      "epoch 3; iter: 200; batch classifier loss: 0.323664; batch adversarial loss: 0.563447\n",
      "epoch 3; iter: 400; batch classifier loss: 0.303411; batch adversarial loss: 0.524749\n",
      "epoch 3; iter: 600; batch classifier loss: 0.409421; batch adversarial loss: 0.427423\n",
      "epoch 4; iter: 0; batch classifier loss: 1.815516; batch adversarial loss: 0.429418\n",
      "epoch 4; iter: 200; batch classifier loss: 0.507972; batch adversarial loss: 0.360420\n",
      "epoch 4; iter: 400; batch classifier loss: 0.455952; batch adversarial loss: 0.436897\n",
      "epoch 4; iter: 600; batch classifier loss: 0.438983; batch adversarial loss: 0.455645\n",
      "epoch 5; iter: 0; batch classifier loss: 0.342912; batch adversarial loss: 0.342731\n",
      "epoch 5; iter: 200; batch classifier loss: 0.363096; batch adversarial loss: 0.444515\n",
      "epoch 5; iter: 400; batch classifier loss: 0.333619; batch adversarial loss: 0.401548\n",
      "epoch 5; iter: 600; batch classifier loss: 0.334860; batch adversarial loss: 0.561186\n",
      "epoch 6; iter: 0; batch classifier loss: 0.429681; batch adversarial loss: 0.295517\n",
      "epoch 6; iter: 200; batch classifier loss: 0.476699; batch adversarial loss: 0.277939\n",
      "epoch 6; iter: 400; batch classifier loss: 0.503263; batch adversarial loss: 0.347281\n",
      "epoch 6; iter: 600; batch classifier loss: 0.521025; batch adversarial loss: 0.398508\n",
      "epoch 7; iter: 0; batch classifier loss: 0.419965; batch adversarial loss: 0.462088\n",
      "epoch 7; iter: 200; batch classifier loss: 0.338281; batch adversarial loss: 0.461807\n",
      "epoch 7; iter: 400; batch classifier loss: 0.402328; batch adversarial loss: 0.336370\n",
      "epoch 7; iter: 600; batch classifier loss: 0.382835; batch adversarial loss: 0.398502\n",
      "epoch 8; iter: 0; batch classifier loss: 0.941293; batch adversarial loss: 0.465172\n",
      "epoch 8; iter: 200; batch classifier loss: 0.490489; batch adversarial loss: 0.477989\n",
      "epoch 8; iter: 400; batch classifier loss: 0.378222; batch adversarial loss: 0.520046\n",
      "epoch 8; iter: 600; batch classifier loss: 0.355188; batch adversarial loss: 0.534760\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465425; batch adversarial loss: 0.399448\n",
      "epoch 9; iter: 200; batch classifier loss: 0.493333; batch adversarial loss: 0.411946\n",
      "epoch 9; iter: 400; batch classifier loss: 0.389481; batch adversarial loss: 0.344038\n",
      "epoch 9; iter: 600; batch classifier loss: 0.364410; batch adversarial loss: 0.571100\n",
      "epoch 0; iter: 0; batch classifier loss: 21.485310; batch adversarial loss: 0.793892\n",
      "epoch 0; iter: 200; batch classifier loss: 4.726140; batch adversarial loss: 1.043390\n",
      "epoch 0; iter: 400; batch classifier loss: 42.635143; batch adversarial loss: 0.605214\n",
      "epoch 0; iter: 600; batch classifier loss: 3.267077; batch adversarial loss: 0.586095\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565321; batch adversarial loss: 0.585426\n",
      "epoch 1; iter: 200; batch classifier loss: 1.750679; batch adversarial loss: 0.532401\n",
      "epoch 1; iter: 400; batch classifier loss: 7.935288; batch adversarial loss: 0.458495\n",
      "epoch 1; iter: 600; batch classifier loss: 4.971489; batch adversarial loss: 0.491230\n",
      "epoch 2; iter: 0; batch classifier loss: 5.782242; batch adversarial loss: 0.468973\n",
      "epoch 2; iter: 200; batch classifier loss: 4.438514; batch adversarial loss: 0.444928\n",
      "epoch 2; iter: 400; batch classifier loss: 0.579506; batch adversarial loss: 0.524022\n",
      "epoch 2; iter: 600; batch classifier loss: 0.856465; batch adversarial loss: 0.504972\n",
      "epoch 3; iter: 0; batch classifier loss: 1.267735; batch adversarial loss: 0.504280\n",
      "epoch 3; iter: 200; batch classifier loss: 0.811458; batch adversarial loss: 0.442671\n",
      "epoch 3; iter: 400; batch classifier loss: 2.195868; batch adversarial loss: 0.418186\n",
      "epoch 3; iter: 600; batch classifier loss: 2.469844; batch adversarial loss: 0.372899\n",
      "epoch 4; iter: 0; batch classifier loss: 2.867615; batch adversarial loss: 0.478876\n",
      "epoch 4; iter: 200; batch classifier loss: 0.435105; batch adversarial loss: 0.363748\n",
      "epoch 4; iter: 400; batch classifier loss: 0.345977; batch adversarial loss: 0.350570\n",
      "epoch 4; iter: 600; batch classifier loss: 0.742059; batch adversarial loss: 0.469176\n",
      "epoch 5; iter: 0; batch classifier loss: 1.019470; batch adversarial loss: 0.414940\n",
      "epoch 5; iter: 200; batch classifier loss: 0.612389; batch adversarial loss: 0.401647\n",
      "epoch 5; iter: 400; batch classifier loss: 0.575178; batch adversarial loss: 0.372008\n",
      "epoch 5; iter: 600; batch classifier loss: 0.609146; batch adversarial loss: 0.414874\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514839; batch adversarial loss: 0.485311\n",
      "epoch 6; iter: 200; batch classifier loss: 0.402279; batch adversarial loss: 0.548196\n",
      "epoch 6; iter: 400; batch classifier loss: 0.399441; batch adversarial loss: 0.414116\n",
      "epoch 6; iter: 600; batch classifier loss: 0.374582; batch adversarial loss: 0.415680\n",
      "epoch 7; iter: 0; batch classifier loss: 0.361951; batch adversarial loss: 0.334383\n",
      "epoch 7; iter: 200; batch classifier loss: 0.422091; batch adversarial loss: 0.424879\n",
      "epoch 7; iter: 400; batch classifier loss: 0.480241; batch adversarial loss: 0.472632\n",
      "epoch 7; iter: 600; batch classifier loss: 0.428704; batch adversarial loss: 0.614997\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377876; batch adversarial loss: 0.312455\n",
      "epoch 8; iter: 200; batch classifier loss: 0.394725; batch adversarial loss: 0.461777\n",
      "epoch 8; iter: 400; batch classifier loss: 0.391545; batch adversarial loss: 0.336520\n",
      "epoch 8; iter: 600; batch classifier loss: 0.368179; batch adversarial loss: 0.428184\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530162; batch adversarial loss: 0.366641\n",
      "epoch 9; iter: 200; batch classifier loss: 0.427161; batch adversarial loss: 0.376560\n",
      "epoch 9; iter: 400; batch classifier loss: 0.344285; batch adversarial loss: 0.471412\n",
      "epoch 9; iter: 600; batch classifier loss: 0.285632; batch adversarial loss: 0.353698\n",
      "epoch 0; iter: 0; batch classifier loss: 95.144897; batch adversarial loss: 0.511587\n",
      "epoch 0; iter: 200; batch classifier loss: 8.530787; batch adversarial loss: 0.574772\n",
      "epoch 0; iter: 400; batch classifier loss: 77.085144; batch adversarial loss: 0.511160\n",
      "epoch 0; iter: 600; batch classifier loss: 2.142626; batch adversarial loss: 0.517091\n",
      "epoch 1; iter: 0; batch classifier loss: 5.309342; batch adversarial loss: 0.555598\n",
      "epoch 1; iter: 200; batch classifier loss: 1.631515; batch adversarial loss: 0.477929\n",
      "epoch 1; iter: 400; batch classifier loss: 0.639202; batch adversarial loss: 0.476182\n",
      "epoch 1; iter: 600; batch classifier loss: 2.835747; batch adversarial loss: 0.455034\n",
      "epoch 2; iter: 0; batch classifier loss: 6.148407; batch adversarial loss: 0.350795\n",
      "epoch 2; iter: 200; batch classifier loss: 1.234989; batch adversarial loss: 0.457288\n",
      "epoch 2; iter: 400; batch classifier loss: 1.223618; batch adversarial loss: 0.358094\n",
      "epoch 2; iter: 600; batch classifier loss: 1.218745; batch adversarial loss: 0.552175\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326528; batch adversarial loss: 0.424903\n",
      "epoch 3; iter: 200; batch classifier loss: 0.363199; batch adversarial loss: 0.464215\n",
      "epoch 3; iter: 400; batch classifier loss: 0.728887; batch adversarial loss: 0.405744\n",
      "epoch 3; iter: 600; batch classifier loss: 0.860338; batch adversarial loss: 0.311865\n",
      "epoch 4; iter: 0; batch classifier loss: 0.367852; batch adversarial loss: 0.396366\n",
      "epoch 4; iter: 200; batch classifier loss: 0.321324; batch adversarial loss: 0.467075\n",
      "epoch 4; iter: 400; batch classifier loss: 0.724800; batch adversarial loss: 0.490172\n",
      "epoch 4; iter: 600; batch classifier loss: 1.461521; batch adversarial loss: 0.412425\n",
      "epoch 5; iter: 0; batch classifier loss: 0.501628; batch adversarial loss: 0.427863\n",
      "epoch 5; iter: 200; batch classifier loss: 0.348208; batch adversarial loss: 0.445759\n",
      "epoch 5; iter: 400; batch classifier loss: 0.428242; batch adversarial loss: 0.297251\n",
      "epoch 5; iter: 600; batch classifier loss: 0.760489; batch adversarial loss: 0.486833\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376242; batch adversarial loss: 0.511573\n",
      "epoch 6; iter: 200; batch classifier loss: 0.590031; batch adversarial loss: 0.405582\n",
      "epoch 6; iter: 400; batch classifier loss: 0.380753; batch adversarial loss: 0.452512\n",
      "epoch 6; iter: 600; batch classifier loss: 0.256653; batch adversarial loss: 0.382457\n",
      "epoch 7; iter: 0; batch classifier loss: 0.374513; batch adversarial loss: 0.414990\n",
      "epoch 7; iter: 200; batch classifier loss: 0.448846; batch adversarial loss: 0.573587\n",
      "epoch 7; iter: 400; batch classifier loss: 0.290216; batch adversarial loss: 0.452753\n",
      "epoch 7; iter: 600; batch classifier loss: 0.438469; batch adversarial loss: 0.297284\n",
      "epoch 8; iter: 0; batch classifier loss: 0.415692; batch adversarial loss: 0.295504\n",
      "epoch 8; iter: 200; batch classifier loss: 0.276351; batch adversarial loss: 0.321749\n",
      "epoch 8; iter: 400; batch classifier loss: 0.300107; batch adversarial loss: 0.359425\n",
      "epoch 8; iter: 600; batch classifier loss: 0.337663; batch adversarial loss: 0.355831\n",
      "epoch 9; iter: 0; batch classifier loss: 0.403175; batch adversarial loss: 0.350139\n",
      "epoch 9; iter: 200; batch classifier loss: 0.404819; batch adversarial loss: 0.430090\n",
      "epoch 9; iter: 400; batch classifier loss: 0.469785; batch adversarial loss: 0.342838\n",
      "epoch 9; iter: 600; batch classifier loss: 0.476391; batch adversarial loss: 0.328618\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 4.091536; batch adversarial loss: 0.745416\n",
      "epoch 0; iter: 200; batch classifier loss: 2.332649; batch adversarial loss: 0.689216\n",
      "epoch 0; iter: 400; batch classifier loss: 7.801348; batch adversarial loss: 0.539831\n",
      "epoch 0; iter: 600; batch classifier loss: 39.102238; batch adversarial loss: 0.526182\n",
      "epoch 1; iter: 0; batch classifier loss: 0.424038; batch adversarial loss: 0.523535\n",
      "epoch 1; iter: 200; batch classifier loss: 5.544218; batch adversarial loss: 0.499753\n",
      "epoch 1; iter: 400; batch classifier loss: 1.433987; batch adversarial loss: 0.453113\n",
      "epoch 1; iter: 600; batch classifier loss: 1.029181; batch adversarial loss: 0.442872\n",
      "epoch 2; iter: 0; batch classifier loss: 8.461253; batch adversarial loss: 0.454896\n",
      "epoch 2; iter: 200; batch classifier loss: 4.968942; batch adversarial loss: 0.452328\n",
      "epoch 2; iter: 400; batch classifier loss: 2.757406; batch adversarial loss: 0.453043\n",
      "epoch 2; iter: 600; batch classifier loss: 1.318703; batch adversarial loss: 0.382038\n",
      "epoch 3; iter: 0; batch classifier loss: 1.277507; batch adversarial loss: 0.406217\n",
      "epoch 3; iter: 200; batch classifier loss: 0.435921; batch adversarial loss: 0.491889\n",
      "epoch 3; iter: 400; batch classifier loss: 0.468580; batch adversarial loss: 0.345927\n",
      "epoch 3; iter: 600; batch classifier loss: 1.142900; batch adversarial loss: 0.430949\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537891; batch adversarial loss: 0.462123\n",
      "epoch 4; iter: 200; batch classifier loss: 0.338862; batch adversarial loss: 0.369361\n",
      "epoch 4; iter: 400; batch classifier loss: 1.113682; batch adversarial loss: 0.438990\n",
      "epoch 4; iter: 600; batch classifier loss: 0.343805; batch adversarial loss: 0.352230\n",
      "epoch 5; iter: 0; batch classifier loss: 0.513085; batch adversarial loss: 0.302836\n",
      "epoch 5; iter: 200; batch classifier loss: 1.016168; batch adversarial loss: 0.532297\n",
      "epoch 5; iter: 400; batch classifier loss: 0.519801; batch adversarial loss: 0.399172\n",
      "epoch 5; iter: 600; batch classifier loss: 0.357905; batch adversarial loss: 0.425440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388198; batch adversarial loss: 0.341829\n",
      "epoch 6; iter: 200; batch classifier loss: 0.488252; batch adversarial loss: 0.385281\n",
      "epoch 6; iter: 400; batch classifier loss: 0.475160; batch adversarial loss: 0.429516\n",
      "epoch 6; iter: 600; batch classifier loss: 0.401766; batch adversarial loss: 0.251189\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310763; batch adversarial loss: 0.392467\n",
      "epoch 7; iter: 200; batch classifier loss: 0.450335; batch adversarial loss: 0.346090\n",
      "epoch 7; iter: 400; batch classifier loss: 0.463996; batch adversarial loss: 0.416915\n",
      "epoch 7; iter: 600; batch classifier loss: 0.414433; batch adversarial loss: 0.516634\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455409; batch adversarial loss: 0.295046\n",
      "epoch 8; iter: 200; batch classifier loss: 0.331327; batch adversarial loss: 0.289801\n",
      "epoch 8; iter: 400; batch classifier loss: 0.371579; batch adversarial loss: 0.270551\n",
      "epoch 8; iter: 600; batch classifier loss: 0.467399; batch adversarial loss: 0.374880\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466128; batch adversarial loss: 0.381241\n",
      "epoch 9; iter: 200; batch classifier loss: 0.423798; batch adversarial loss: 0.446285\n",
      "epoch 9; iter: 400; batch classifier loss: 0.273655; batch adversarial loss: 0.441346\n",
      "epoch 9; iter: 600; batch classifier loss: 0.429725; batch adversarial loss: 0.422428\n",
      "epoch 10; iter: 0; batch classifier loss: 0.389753; batch adversarial loss: 0.376014\n",
      "epoch 10; iter: 200; batch classifier loss: 0.380013; batch adversarial loss: 0.507336\n",
      "epoch 10; iter: 400; batch classifier loss: 0.376169; batch adversarial loss: 0.428619\n",
      "epoch 10; iter: 600; batch classifier loss: 0.413959; batch adversarial loss: 0.574457\n",
      "epoch 11; iter: 0; batch classifier loss: 0.306866; batch adversarial loss: 0.514051\n",
      "epoch 11; iter: 200; batch classifier loss: 0.378050; batch adversarial loss: 0.448659\n",
      "epoch 11; iter: 400; batch classifier loss: 0.328714; batch adversarial loss: 0.530026\n",
      "epoch 11; iter: 600; batch classifier loss: 0.370941; batch adversarial loss: 0.352675\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334655; batch adversarial loss: 0.357536\n",
      "epoch 12; iter: 200; batch classifier loss: 0.313316; batch adversarial loss: 0.274477\n",
      "epoch 12; iter: 400; batch classifier loss: 0.337683; batch adversarial loss: 0.436885\n",
      "epoch 12; iter: 600; batch classifier loss: 0.311300; batch adversarial loss: 0.452922\n",
      "epoch 13; iter: 0; batch classifier loss: 0.299122; batch adversarial loss: 0.488279\n",
      "epoch 13; iter: 200; batch classifier loss: 0.253182; batch adversarial loss: 0.448393\n",
      "epoch 13; iter: 400; batch classifier loss: 0.194698; batch adversarial loss: 0.480502\n",
      "epoch 13; iter: 600; batch classifier loss: 0.281223; batch adversarial loss: 0.315095\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333354; batch adversarial loss: 0.458452\n",
      "epoch 14; iter: 200; batch classifier loss: 0.422275; batch adversarial loss: 0.554787\n",
      "epoch 14; iter: 400; batch classifier loss: 0.414331; batch adversarial loss: 0.534492\n",
      "epoch 14; iter: 600; batch classifier loss: 0.272436; batch adversarial loss: 0.343142\n",
      "epoch 15; iter: 0; batch classifier loss: 0.365414; batch adversarial loss: 0.459427\n",
      "epoch 15; iter: 200; batch classifier loss: 0.349676; batch adversarial loss: 0.296692\n",
      "epoch 15; iter: 400; batch classifier loss: 0.473385; batch adversarial loss: 0.595102\n",
      "epoch 15; iter: 600; batch classifier loss: 0.365419; batch adversarial loss: 0.351776\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363636; batch adversarial loss: 0.425575\n",
      "epoch 16; iter: 200; batch classifier loss: 0.434730; batch adversarial loss: 0.434754\n",
      "epoch 16; iter: 400; batch classifier loss: 0.736804; batch adversarial loss: 0.324492\n",
      "epoch 16; iter: 600; batch classifier loss: 0.422622; batch adversarial loss: 0.480669\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374055; batch adversarial loss: 0.335849\n",
      "epoch 17; iter: 200; batch classifier loss: 0.400157; batch adversarial loss: 0.403295\n",
      "epoch 17; iter: 400; batch classifier loss: 0.374545; batch adversarial loss: 0.460882\n",
      "epoch 17; iter: 600; batch classifier loss: 0.235324; batch adversarial loss: 0.431617\n",
      "epoch 18; iter: 0; batch classifier loss: 0.235464; batch adversarial loss: 0.474077\n",
      "epoch 18; iter: 200; batch classifier loss: 0.388764; batch adversarial loss: 0.317739\n",
      "epoch 18; iter: 400; batch classifier loss: 0.308069; batch adversarial loss: 0.460685\n",
      "epoch 18; iter: 600; batch classifier loss: 0.347063; batch adversarial loss: 0.466540\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278934; batch adversarial loss: 0.351535\n",
      "epoch 19; iter: 200; batch classifier loss: 0.377372; batch adversarial loss: 0.376016\n",
      "epoch 19; iter: 400; batch classifier loss: 0.361577; batch adversarial loss: 0.537788\n",
      "epoch 19; iter: 600; batch classifier loss: 0.395860; batch adversarial loss: 0.407647\n",
      "epoch 0; iter: 0; batch classifier loss: 22.044209; batch adversarial loss: 0.685393\n",
      "epoch 0; iter: 200; batch classifier loss: 6.304039; batch adversarial loss: 0.635817\n",
      "epoch 0; iter: 400; batch classifier loss: 11.764576; batch adversarial loss: 0.537662\n",
      "epoch 0; iter: 600; batch classifier loss: 0.597678; batch adversarial loss: 0.463380\n",
      "epoch 1; iter: 0; batch classifier loss: 1.948949; batch adversarial loss: 0.509510\n",
      "epoch 1; iter: 200; batch classifier loss: 1.996711; batch adversarial loss: 0.563315\n",
      "epoch 1; iter: 400; batch classifier loss: 2.285882; batch adversarial loss: 0.505542\n",
      "epoch 1; iter: 600; batch classifier loss: 2.161081; batch adversarial loss: 0.505826\n",
      "epoch 2; iter: 0; batch classifier loss: 1.708071; batch adversarial loss: 0.467147\n",
      "epoch 2; iter: 200; batch classifier loss: 1.563420; batch adversarial loss: 0.447176\n",
      "epoch 2; iter: 400; batch classifier loss: 0.395574; batch adversarial loss: 0.376744\n",
      "epoch 2; iter: 600; batch classifier loss: 0.579662; batch adversarial loss: 0.447626\n",
      "epoch 3; iter: 0; batch classifier loss: 0.681746; batch adversarial loss: 0.413595\n",
      "epoch 3; iter: 200; batch classifier loss: 1.078197; batch adversarial loss: 0.449843\n",
      "epoch 3; iter: 400; batch classifier loss: 1.401327; batch adversarial loss: 0.299342\n",
      "epoch 3; iter: 600; batch classifier loss: 1.500109; batch adversarial loss: 0.394229\n",
      "epoch 4; iter: 0; batch classifier loss: 0.174939; batch adversarial loss: 0.585071\n",
      "epoch 4; iter: 200; batch classifier loss: 0.544460; batch adversarial loss: 0.519145\n",
      "epoch 4; iter: 400; batch classifier loss: 0.268624; batch adversarial loss: 0.466496\n",
      "epoch 4; iter: 600; batch classifier loss: 0.346891; batch adversarial loss: 0.428156\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651631; batch adversarial loss: 0.362873\n",
      "epoch 5; iter: 200; batch classifier loss: 0.645519; batch adversarial loss: 0.485675\n",
      "epoch 5; iter: 400; batch classifier loss: 0.489607; batch adversarial loss: 0.451916\n",
      "epoch 5; iter: 600; batch classifier loss: 0.461709; batch adversarial loss: 0.414040\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401319; batch adversarial loss: 0.515910\n",
      "epoch 6; iter: 200; batch classifier loss: 0.568161; batch adversarial loss: 0.505032\n",
      "epoch 6; iter: 400; batch classifier loss: 0.617577; batch adversarial loss: 0.466621\n",
      "epoch 6; iter: 600; batch classifier loss: 0.321205; batch adversarial loss: 0.428811\n",
      "epoch 7; iter: 0; batch classifier loss: 0.356733; batch adversarial loss: 0.571938\n",
      "epoch 7; iter: 200; batch classifier loss: 0.340695; batch adversarial loss: 0.348897\n",
      "epoch 7; iter: 400; batch classifier loss: 0.396177; batch adversarial loss: 0.323594\n",
      "epoch 7; iter: 600; batch classifier loss: 0.527246; batch adversarial loss: 0.424726\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403732; batch adversarial loss: 0.565770\n",
      "epoch 8; iter: 200; batch classifier loss: 0.364998; batch adversarial loss: 0.342237\n",
      "epoch 8; iter: 400; batch classifier loss: 0.389817; batch adversarial loss: 0.405434\n",
      "epoch 8; iter: 600; batch classifier loss: 0.302730; batch adversarial loss: 0.407466\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254902; batch adversarial loss: 0.540525\n",
      "epoch 9; iter: 200; batch classifier loss: 0.293706; batch adversarial loss: 0.427920\n",
      "epoch 9; iter: 400; batch classifier loss: 0.365531; batch adversarial loss: 0.467651\n",
      "epoch 9; iter: 600; batch classifier loss: 0.304020; batch adversarial loss: 0.329938\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341065; batch adversarial loss: 0.424571\n",
      "epoch 10; iter: 200; batch classifier loss: 0.261365; batch adversarial loss: 0.452460\n",
      "epoch 10; iter: 400; batch classifier loss: 0.347626; batch adversarial loss: 0.342493\n",
      "epoch 10; iter: 600; batch classifier loss: 0.304432; batch adversarial loss: 0.295288\n",
      "epoch 11; iter: 0; batch classifier loss: 0.644025; batch adversarial loss: 0.631163\n",
      "epoch 11; iter: 200; batch classifier loss: 0.419013; batch adversarial loss: 0.437500\n",
      "epoch 11; iter: 400; batch classifier loss: 0.348016; batch adversarial loss: 0.324376\n",
      "epoch 11; iter: 600; batch classifier loss: 0.320881; batch adversarial loss: 0.321281\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553920; batch adversarial loss: 0.491819\n",
      "epoch 12; iter: 200; batch classifier loss: 0.383329; batch adversarial loss: 0.507865\n",
      "epoch 12; iter: 400; batch classifier loss: 0.365320; batch adversarial loss: 0.452843\n",
      "epoch 12; iter: 600; batch classifier loss: 0.539033; batch adversarial loss: 0.430516\n",
      "epoch 13; iter: 0; batch classifier loss: 0.669318; batch adversarial loss: 0.297401\n",
      "epoch 13; iter: 200; batch classifier loss: 0.245746; batch adversarial loss: 0.291239\n",
      "epoch 13; iter: 400; batch classifier loss: 0.387962; batch adversarial loss: 0.391371\n",
      "epoch 13; iter: 600; batch classifier loss: 0.223496; batch adversarial loss: 0.320475\n",
      "epoch 14; iter: 0; batch classifier loss: 0.346509; batch adversarial loss: 0.622896\n",
      "epoch 14; iter: 200; batch classifier loss: 0.323022; batch adversarial loss: 0.314611\n",
      "epoch 14; iter: 400; batch classifier loss: 0.417887; batch adversarial loss: 0.398805\n",
      "epoch 14; iter: 600; batch classifier loss: 0.322150; batch adversarial loss: 0.543458\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406355; batch adversarial loss: 0.463309\n",
      "epoch 15; iter: 200; batch classifier loss: 0.282559; batch adversarial loss: 0.449309\n",
      "epoch 15; iter: 400; batch classifier loss: 0.307231; batch adversarial loss: 0.456588\n",
      "epoch 15; iter: 600; batch classifier loss: 0.215104; batch adversarial loss: 0.371152\n",
      "epoch 16; iter: 0; batch classifier loss: 0.295373; batch adversarial loss: 0.520260\n",
      "epoch 16; iter: 200; batch classifier loss: 0.300137; batch adversarial loss: 0.433840\n",
      "epoch 16; iter: 400; batch classifier loss: 0.215262; batch adversarial loss: 0.424094\n",
      "epoch 16; iter: 600; batch classifier loss: 0.263912; batch adversarial loss: 0.479238\n",
      "epoch 17; iter: 0; batch classifier loss: 0.393331; batch adversarial loss: 0.290415\n",
      "epoch 17; iter: 200; batch classifier loss: 0.400642; batch adversarial loss: 0.374981\n",
      "epoch 17; iter: 400; batch classifier loss: 0.397669; batch adversarial loss: 0.461125\n",
      "epoch 17; iter: 600; batch classifier loss: 0.353742; batch adversarial loss: 0.482458\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334836; batch adversarial loss: 0.518525\n",
      "epoch 18; iter: 200; batch classifier loss: 0.493057; batch adversarial loss: 0.403092\n",
      "epoch 18; iter: 400; batch classifier loss: 0.252895; batch adversarial loss: 0.358332\n",
      "epoch 18; iter: 600; batch classifier loss: 0.280549; batch adversarial loss: 0.450808\n",
      "epoch 19; iter: 0; batch classifier loss: 0.345908; batch adversarial loss: 0.518015\n",
      "epoch 19; iter: 200; batch classifier loss: 0.249211; batch adversarial loss: 0.418659\n",
      "epoch 19; iter: 400; batch classifier loss: 0.294267; batch adversarial loss: 0.374664\n",
      "epoch 19; iter: 600; batch classifier loss: 0.356850; batch adversarial loss: 0.514582\n",
      "epoch 0; iter: 0; batch classifier loss: 20.442020; batch adversarial loss: 0.940286\n",
      "epoch 0; iter: 200; batch classifier loss: 1.053533; batch adversarial loss: 0.680183\n",
      "epoch 0; iter: 400; batch classifier loss: 5.434847; batch adversarial loss: 0.605699\n",
      "epoch 0; iter: 600; batch classifier loss: 5.557957; batch adversarial loss: 0.572674\n",
      "epoch 1; iter: 0; batch classifier loss: 5.017610; batch adversarial loss: 0.567330\n",
      "epoch 1; iter: 200; batch classifier loss: 0.918071; batch adversarial loss: 0.534332\n",
      "epoch 1; iter: 400; batch classifier loss: 0.891027; batch adversarial loss: 0.439600\n",
      "epoch 1; iter: 600; batch classifier loss: 2.671726; batch adversarial loss: 0.396159\n",
      "epoch 2; iter: 0; batch classifier loss: 1.115286; batch adversarial loss: 0.515950\n",
      "epoch 2; iter: 200; batch classifier loss: 2.356466; batch adversarial loss: 0.370911\n",
      "epoch 2; iter: 400; batch classifier loss: 2.093608; batch adversarial loss: 0.454732\n",
      "epoch 2; iter: 600; batch classifier loss: 0.355280; batch adversarial loss: 0.410846\n",
      "epoch 3; iter: 0; batch classifier loss: 1.074035; batch adversarial loss: 0.526204\n",
      "epoch 3; iter: 200; batch classifier loss: 0.485651; batch adversarial loss: 0.323427\n",
      "epoch 3; iter: 400; batch classifier loss: 0.418038; batch adversarial loss: 0.423680\n",
      "epoch 3; iter: 600; batch classifier loss: 0.345802; batch adversarial loss: 0.379121\n",
      "epoch 4; iter: 0; batch classifier loss: 0.907420; batch adversarial loss: 0.471274\n",
      "epoch 4; iter: 200; batch classifier loss: 0.594209; batch adversarial loss: 0.499848\n",
      "epoch 4; iter: 400; batch classifier loss: 0.833520; batch adversarial loss: 0.303965\n",
      "epoch 4; iter: 600; batch classifier loss: 0.416697; batch adversarial loss: 0.419777\n",
      "epoch 5; iter: 0; batch classifier loss: 0.399830; batch adversarial loss: 0.443112\n",
      "epoch 5; iter: 200; batch classifier loss: 0.566488; batch adversarial loss: 0.487522\n",
      "epoch 5; iter: 400; batch classifier loss: 1.467964; batch adversarial loss: 0.501595\n",
      "epoch 5; iter: 600; batch classifier loss: 0.463256; batch adversarial loss: 0.391282\n",
      "epoch 6; iter: 0; batch classifier loss: 0.328532; batch adversarial loss: 0.653516\n",
      "epoch 6; iter: 200; batch classifier loss: 0.383021; batch adversarial loss: 0.428066\n",
      "epoch 6; iter: 400; batch classifier loss: 0.407689; batch adversarial loss: 0.522070\n",
      "epoch 6; iter: 600; batch classifier loss: 0.401939; batch adversarial loss: 0.442173\n",
      "epoch 7; iter: 0; batch classifier loss: 0.438753; batch adversarial loss: 0.397263\n",
      "epoch 7; iter: 200; batch classifier loss: 0.396923; batch adversarial loss: 0.414493\n",
      "epoch 7; iter: 400; batch classifier loss: 0.380046; batch adversarial loss: 0.474610\n",
      "epoch 7; iter: 600; batch classifier loss: 0.424237; batch adversarial loss: 0.321090\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595947; batch adversarial loss: 0.320790\n",
      "epoch 8; iter: 200; batch classifier loss: 0.385689; batch adversarial loss: 0.326048\n",
      "epoch 8; iter: 400; batch classifier loss: 0.386959; batch adversarial loss: 0.350480\n",
      "epoch 8; iter: 600; batch classifier loss: 0.639970; batch adversarial loss: 0.356966\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373666; batch adversarial loss: 0.321432\n",
      "epoch 9; iter: 200; batch classifier loss: 0.407030; batch adversarial loss: 0.533944\n",
      "epoch 9; iter: 400; batch classifier loss: 0.247414; batch adversarial loss: 0.484467\n",
      "epoch 9; iter: 600; batch classifier loss: 0.358919; batch adversarial loss: 0.440496\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368510; batch adversarial loss: 0.538299\n",
      "epoch 10; iter: 200; batch classifier loss: 0.282734; batch adversarial loss: 0.349019\n",
      "epoch 10; iter: 400; batch classifier loss: 0.342947; batch adversarial loss: 0.437881\n",
      "epoch 10; iter: 600; batch classifier loss: 0.458438; batch adversarial loss: 0.433032\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398651; batch adversarial loss: 0.313817\n",
      "epoch 11; iter: 200; batch classifier loss: 0.363475; batch adversarial loss: 0.402298\n",
      "epoch 11; iter: 400; batch classifier loss: 0.301243; batch adversarial loss: 0.463142\n",
      "epoch 11; iter: 600; batch classifier loss: 0.368918; batch adversarial loss: 0.537420\n",
      "epoch 12; iter: 0; batch classifier loss: 0.354353; batch adversarial loss: 0.460775\n",
      "epoch 12; iter: 200; batch classifier loss: 0.321116; batch adversarial loss: 0.285925\n",
      "epoch 12; iter: 400; batch classifier loss: 0.497032; batch adversarial loss: 0.408388\n",
      "epoch 12; iter: 600; batch classifier loss: 0.272191; batch adversarial loss: 0.438867\n",
      "epoch 13; iter: 0; batch classifier loss: 0.234182; batch adversarial loss: 0.319963\n",
      "epoch 13; iter: 200; batch classifier loss: 0.394856; batch adversarial loss: 0.470355\n",
      "epoch 13; iter: 400; batch classifier loss: 0.319476; batch adversarial loss: 0.423117\n",
      "epoch 13; iter: 600; batch classifier loss: 0.285720; batch adversarial loss: 0.677789\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279413; batch adversarial loss: 0.332198\n",
      "epoch 14; iter: 200; batch classifier loss: 0.370397; batch adversarial loss: 0.482499\n",
      "epoch 14; iter: 400; batch classifier loss: 0.358141; batch adversarial loss: 0.345507\n",
      "epoch 14; iter: 600; batch classifier loss: 0.616675; batch adversarial loss: 0.393393\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323861; batch adversarial loss: 0.416439\n",
      "epoch 15; iter: 200; batch classifier loss: 0.460370; batch adversarial loss: 0.425358\n",
      "epoch 15; iter: 400; batch classifier loss: 0.200438; batch adversarial loss: 0.397807\n",
      "epoch 15; iter: 600; batch classifier loss: 0.324585; batch adversarial loss: 0.426657\n",
      "epoch 16; iter: 0; batch classifier loss: 0.329809; batch adversarial loss: 0.406218\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380266; batch adversarial loss: 0.550017\n",
      "epoch 16; iter: 400; batch classifier loss: 0.348262; batch adversarial loss: 0.433794\n",
      "epoch 16; iter: 600; batch classifier loss: 0.434229; batch adversarial loss: 0.375622\n",
      "epoch 17; iter: 0; batch classifier loss: 0.378687; batch adversarial loss: 0.502520\n",
      "epoch 17; iter: 200; batch classifier loss: 0.275460; batch adversarial loss: 0.478499\n",
      "epoch 17; iter: 400; batch classifier loss: 0.280925; batch adversarial loss: 0.349347\n",
      "epoch 17; iter: 600; batch classifier loss: 0.258095; batch adversarial loss: 0.385468\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309327; batch adversarial loss: 0.487492\n",
      "epoch 18; iter: 200; batch classifier loss: 0.474212; batch adversarial loss: 0.354527\n",
      "epoch 18; iter: 400; batch classifier loss: 0.381857; batch adversarial loss: 0.376304\n",
      "epoch 18; iter: 600; batch classifier loss: 0.223078; batch adversarial loss: 0.347896\n",
      "epoch 19; iter: 0; batch classifier loss: 0.359430; batch adversarial loss: 0.408490\n",
      "epoch 19; iter: 200; batch classifier loss: 0.294044; batch adversarial loss: 0.532019\n",
      "epoch 19; iter: 400; batch classifier loss: 0.208338; batch adversarial loss: 0.460071\n",
      "epoch 19; iter: 600; batch classifier loss: 0.267018; batch adversarial loss: 0.376771\n",
      "epoch 0; iter: 0; batch classifier loss: 287.615814; batch adversarial loss: 0.658893\n",
      "epoch 0; iter: 200; batch classifier loss: 10.656117; batch adversarial loss: 0.609711\n",
      "epoch 0; iter: 400; batch classifier loss: 5.049233; batch adversarial loss: 0.525106\n",
      "epoch 0; iter: 600; batch classifier loss: 7.513694; batch adversarial loss: 0.524863\n",
      "epoch 1; iter: 0; batch classifier loss: 22.438066; batch adversarial loss: 0.518851\n",
      "epoch 1; iter: 200; batch classifier loss: 5.835937; batch adversarial loss: 0.445481\n",
      "epoch 1; iter: 400; batch classifier loss: 4.873582; batch adversarial loss: 0.466816\n",
      "epoch 1; iter: 600; batch classifier loss: 5.765690; batch adversarial loss: 0.428841\n",
      "epoch 2; iter: 0; batch classifier loss: 9.414854; batch adversarial loss: 0.535309\n",
      "epoch 2; iter: 200; batch classifier loss: 1.759941; batch adversarial loss: 0.390859\n",
      "epoch 2; iter: 400; batch classifier loss: 0.472301; batch adversarial loss: 0.473920\n",
      "epoch 2; iter: 600; batch classifier loss: 0.581596; batch adversarial loss: 0.461908\n",
      "epoch 3; iter: 0; batch classifier loss: 3.678624; batch adversarial loss: 0.479729\n",
      "epoch 3; iter: 200; batch classifier loss: 1.572466; batch adversarial loss: 0.382466\n",
      "epoch 3; iter: 400; batch classifier loss: 2.264765; batch adversarial loss: 0.357058\n",
      "epoch 3; iter: 600; batch classifier loss: 0.420988; batch adversarial loss: 0.602761\n",
      "epoch 4; iter: 0; batch classifier loss: 1.079053; batch adversarial loss: 0.327250\n",
      "epoch 4; iter: 200; batch classifier loss: 1.077132; batch adversarial loss: 0.530949\n",
      "epoch 4; iter: 400; batch classifier loss: 0.487397; batch adversarial loss: 0.514285\n",
      "epoch 4; iter: 600; batch classifier loss: 0.235143; batch adversarial loss: 0.317647\n",
      "epoch 5; iter: 0; batch classifier loss: 0.251045; batch adversarial loss: 0.582624\n",
      "epoch 5; iter: 200; batch classifier loss: 0.469290; batch adversarial loss: 0.511274\n",
      "epoch 5; iter: 400; batch classifier loss: 1.254046; batch adversarial loss: 0.474062\n",
      "epoch 5; iter: 600; batch classifier loss: 0.575414; batch adversarial loss: 0.509308\n",
      "epoch 6; iter: 0; batch classifier loss: 0.413168; batch adversarial loss: 0.445424\n",
      "epoch 6; iter: 200; batch classifier loss: 0.257289; batch adversarial loss: 0.402099\n",
      "epoch 6; iter: 400; batch classifier loss: 0.755836; batch adversarial loss: 0.341194\n",
      "epoch 6; iter: 600; batch classifier loss: 0.293057; batch adversarial loss: 0.444918\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379777; batch adversarial loss: 0.376012\n",
      "epoch 7; iter: 200; batch classifier loss: 0.534857; batch adversarial loss: 0.421583\n",
      "epoch 7; iter: 400; batch classifier loss: 0.321283; batch adversarial loss: 0.532346\n",
      "epoch 7; iter: 600; batch classifier loss: 0.428330; batch adversarial loss: 0.296993\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330886; batch adversarial loss: 0.322112\n",
      "epoch 8; iter: 200; batch classifier loss: 0.530902; batch adversarial loss: 0.299463\n",
      "epoch 8; iter: 400; batch classifier loss: 0.377176; batch adversarial loss: 0.471503\n",
      "epoch 8; iter: 600; batch classifier loss: 0.514308; batch adversarial loss: 0.305882\n",
      "epoch 9; iter: 0; batch classifier loss: 0.372457; batch adversarial loss: 0.268186\n",
      "epoch 9; iter: 200; batch classifier loss: 0.349424; batch adversarial loss: 0.237966\n",
      "epoch 9; iter: 400; batch classifier loss: 0.426695; batch adversarial loss: 0.545989\n",
      "epoch 9; iter: 600; batch classifier loss: 0.283837; batch adversarial loss: 0.399189\n",
      "epoch 10; iter: 0; batch classifier loss: 0.295950; batch adversarial loss: 0.430744\n",
      "epoch 10; iter: 200; batch classifier loss: 0.299439; batch adversarial loss: 0.459960\n",
      "epoch 10; iter: 400; batch classifier loss: 0.290412; batch adversarial loss: 0.433502\n",
      "epoch 10; iter: 600; batch classifier loss: 0.447079; batch adversarial loss: 0.399184\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368308; batch adversarial loss: 0.315474\n",
      "epoch 11; iter: 200; batch classifier loss: 0.346815; batch adversarial loss: 0.341260\n",
      "epoch 11; iter: 400; batch classifier loss: 0.362825; batch adversarial loss: 0.431010\n",
      "epoch 11; iter: 600; batch classifier loss: 0.276356; batch adversarial loss: 0.534712\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376072; batch adversarial loss: 0.552185\n",
      "epoch 12; iter: 200; batch classifier loss: 0.299685; batch adversarial loss: 0.402194\n",
      "epoch 12; iter: 400; batch classifier loss: 0.394049; batch adversarial loss: 0.428362\n",
      "epoch 12; iter: 600; batch classifier loss: 0.399008; batch adversarial loss: 0.367133\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412472; batch adversarial loss: 0.456905\n",
      "epoch 13; iter: 200; batch classifier loss: 0.316969; batch adversarial loss: 0.320817\n",
      "epoch 13; iter: 400; batch classifier loss: 0.451375; batch adversarial loss: 0.687791\n",
      "epoch 13; iter: 600; batch classifier loss: 0.405125; batch adversarial loss: 0.490937\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330261; batch adversarial loss: 0.317995\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352417; batch adversarial loss: 0.532752\n",
      "epoch 14; iter: 400; batch classifier loss: 0.335841; batch adversarial loss: 0.427021\n",
      "epoch 14; iter: 600; batch classifier loss: 0.446052; batch adversarial loss: 0.494639\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304751; batch adversarial loss: 0.338594\n",
      "epoch 15; iter: 200; batch classifier loss: 0.356806; batch adversarial loss: 0.401888\n",
      "epoch 15; iter: 400; batch classifier loss: 0.321540; batch adversarial loss: 0.396319\n",
      "epoch 15; iter: 600; batch classifier loss: 0.485381; batch adversarial loss: 0.520534\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346463; batch adversarial loss: 0.340809\n",
      "epoch 16; iter: 200; batch classifier loss: 0.408432; batch adversarial loss: 0.327307\n",
      "epoch 16; iter: 400; batch classifier loss: 0.238722; batch adversarial loss: 0.539337\n",
      "epoch 16; iter: 600; batch classifier loss: 0.260016; batch adversarial loss: 0.302115\n",
      "epoch 17; iter: 0; batch classifier loss: 0.387775; batch adversarial loss: 0.570444\n",
      "epoch 17; iter: 200; batch classifier loss: 0.525696; batch adversarial loss: 0.314340\n",
      "epoch 17; iter: 400; batch classifier loss: 0.381754; batch adversarial loss: 0.369750\n",
      "epoch 17; iter: 600; batch classifier loss: 0.316836; batch adversarial loss: 0.666299\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455358; batch adversarial loss: 0.377186\n",
      "epoch 18; iter: 200; batch classifier loss: 0.355431; batch adversarial loss: 0.380102\n",
      "epoch 18; iter: 400; batch classifier loss: 0.471345; batch adversarial loss: 0.342731\n",
      "epoch 18; iter: 600; batch classifier loss: 0.297840; batch adversarial loss: 0.490721\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343518; batch adversarial loss: 0.512554\n",
      "epoch 19; iter: 200; batch classifier loss: 0.333128; batch adversarial loss: 0.411781\n",
      "epoch 19; iter: 400; batch classifier loss: 0.359664; batch adversarial loss: 0.349139\n",
      "epoch 19; iter: 600; batch classifier loss: 0.405612; batch adversarial loss: 0.540888\n",
      "epoch 0; iter: 0; batch classifier loss: 15.592587; batch adversarial loss: 0.953244\n",
      "epoch 0; iter: 200; batch classifier loss: 7.874094; batch adversarial loss: 0.743980\n",
      "epoch 0; iter: 400; batch classifier loss: 12.978200; batch adversarial loss: 0.637033\n",
      "epoch 0; iter: 600; batch classifier loss: 2.567922; batch adversarial loss: 0.573859\n",
      "epoch 1; iter: 0; batch classifier loss: 7.562151; batch adversarial loss: 0.558582\n",
      "epoch 1; iter: 200; batch classifier loss: 1.207324; batch adversarial loss: 0.485442\n",
      "epoch 1; iter: 400; batch classifier loss: 2.188694; batch adversarial loss: 0.494304\n",
      "epoch 1; iter: 600; batch classifier loss: 2.412257; batch adversarial loss: 0.430455\n",
      "epoch 2; iter: 0; batch classifier loss: 5.110620; batch adversarial loss: 0.420584\n",
      "epoch 2; iter: 200; batch classifier loss: 2.125879; batch adversarial loss: 0.531150\n",
      "epoch 2; iter: 400; batch classifier loss: 3.653874; batch adversarial loss: 0.493360\n",
      "epoch 2; iter: 600; batch classifier loss: 0.382957; batch adversarial loss: 0.396470\n",
      "epoch 3; iter: 0; batch classifier loss: 1.211435; batch adversarial loss: 0.393612\n",
      "epoch 3; iter: 200; batch classifier loss: 0.477191; batch adversarial loss: 0.460554\n",
      "epoch 3; iter: 400; batch classifier loss: 3.593476; batch adversarial loss: 0.354960\n",
      "epoch 3; iter: 600; batch classifier loss: 1.042395; batch adversarial loss: 0.327444\n",
      "epoch 4; iter: 0; batch classifier loss: 0.553160; batch adversarial loss: 0.427645\n",
      "epoch 4; iter: 200; batch classifier loss: 1.943731; batch adversarial loss: 0.357263\n",
      "epoch 4; iter: 400; batch classifier loss: 0.389970; batch adversarial loss: 0.538024\n",
      "epoch 4; iter: 600; batch classifier loss: 1.108475; batch adversarial loss: 0.360985\n",
      "epoch 5; iter: 0; batch classifier loss: 0.867293; batch adversarial loss: 0.393147\n",
      "epoch 5; iter: 200; batch classifier loss: 0.345381; batch adversarial loss: 0.506129\n",
      "epoch 5; iter: 400; batch classifier loss: 0.352885; batch adversarial loss: 0.439119\n",
      "epoch 5; iter: 600; batch classifier loss: 0.399897; batch adversarial loss: 0.469796\n",
      "epoch 6; iter: 0; batch classifier loss: 0.338246; batch adversarial loss: 0.427221\n",
      "epoch 6; iter: 200; batch classifier loss: 0.493932; batch adversarial loss: 0.355799\n",
      "epoch 6; iter: 400; batch classifier loss: 0.292871; batch adversarial loss: 0.384895\n",
      "epoch 6; iter: 600; batch classifier loss: 0.521530; batch adversarial loss: 0.262695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505871; batch adversarial loss: 0.502651\n",
      "epoch 7; iter: 200; batch classifier loss: 0.361289; batch adversarial loss: 0.512307\n",
      "epoch 7; iter: 400; batch classifier loss: 0.378287; batch adversarial loss: 0.346795\n",
      "epoch 7; iter: 600; batch classifier loss: 0.429942; batch adversarial loss: 0.282728\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537598; batch adversarial loss: 0.409806\n",
      "epoch 8; iter: 200; batch classifier loss: 0.414964; batch adversarial loss: 0.326874\n",
      "epoch 8; iter: 400; batch classifier loss: 0.356626; batch adversarial loss: 0.439806\n",
      "epoch 8; iter: 600; batch classifier loss: 0.355762; batch adversarial loss: 0.347749\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465759; batch adversarial loss: 0.485583\n",
      "epoch 9; iter: 200; batch classifier loss: 0.376335; batch adversarial loss: 0.497150\n",
      "epoch 9; iter: 400; batch classifier loss: 0.468363; batch adversarial loss: 0.290580\n",
      "epoch 9; iter: 600; batch classifier loss: 0.401154; batch adversarial loss: 0.374248\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370293; batch adversarial loss: 0.321002\n",
      "epoch 10; iter: 200; batch classifier loss: 0.379052; batch adversarial loss: 0.368013\n",
      "epoch 10; iter: 400; batch classifier loss: 0.385510; batch adversarial loss: 0.469868\n",
      "epoch 10; iter: 600; batch classifier loss: 0.418145; batch adversarial loss: 0.547176\n",
      "epoch 11; iter: 0; batch classifier loss: 0.300837; batch adversarial loss: 0.359194\n",
      "epoch 11; iter: 200; batch classifier loss: 0.313379; batch adversarial loss: 0.452379\n",
      "epoch 11; iter: 400; batch classifier loss: 0.508134; batch adversarial loss: 0.455753\n",
      "epoch 11; iter: 600; batch classifier loss: 0.286965; batch adversarial loss: 0.556313\n",
      "epoch 12; iter: 0; batch classifier loss: 0.371029; batch adversarial loss: 0.459422\n",
      "epoch 12; iter: 200; batch classifier loss: 0.409309; batch adversarial loss: 0.449373\n",
      "epoch 12; iter: 400; batch classifier loss: 0.464871; batch adversarial loss: 0.270727\n",
      "epoch 12; iter: 600; batch classifier loss: 0.312433; batch adversarial loss: 0.531804\n",
      "epoch 13; iter: 0; batch classifier loss: 0.345341; batch adversarial loss: 0.281882\n",
      "epoch 13; iter: 200; batch classifier loss: 0.320085; batch adversarial loss: 0.337262\n",
      "epoch 13; iter: 400; batch classifier loss: 0.387576; batch adversarial loss: 0.410797\n",
      "epoch 13; iter: 600; batch classifier loss: 0.430912; batch adversarial loss: 0.493404\n",
      "epoch 14; iter: 0; batch classifier loss: 0.383879; batch adversarial loss: 0.266761\n",
      "epoch 14; iter: 200; batch classifier loss: 0.372021; batch adversarial loss: 0.302581\n",
      "epoch 14; iter: 400; batch classifier loss: 0.369073; batch adversarial loss: 0.242926\n",
      "epoch 14; iter: 600; batch classifier loss: 0.301513; batch adversarial loss: 0.434876\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286262; batch adversarial loss: 0.447772\n",
      "epoch 15; iter: 200; batch classifier loss: 0.265244; batch adversarial loss: 0.290749\n",
      "epoch 15; iter: 400; batch classifier loss: 0.434205; batch adversarial loss: 0.461533\n",
      "epoch 15; iter: 600; batch classifier loss: 0.251690; batch adversarial loss: 0.309592\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370887; batch adversarial loss: 0.349243\n",
      "epoch 16; iter: 200; batch classifier loss: 0.384054; batch adversarial loss: 0.379681\n",
      "epoch 16; iter: 400; batch classifier loss: 0.292391; batch adversarial loss: 0.465806\n",
      "epoch 16; iter: 600; batch classifier loss: 0.295336; batch adversarial loss: 0.405951\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286423; batch adversarial loss: 0.568437\n",
      "epoch 17; iter: 200; batch classifier loss: 0.298324; batch adversarial loss: 0.481941\n",
      "epoch 17; iter: 400; batch classifier loss: 0.307441; batch adversarial loss: 0.358669\n",
      "epoch 17; iter: 600; batch classifier loss: 0.359405; batch adversarial loss: 0.390278\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339785; batch adversarial loss: 0.384045\n",
      "epoch 18; iter: 200; batch classifier loss: 0.295369; batch adversarial loss: 0.400360\n",
      "epoch 18; iter: 400; batch classifier loss: 0.329149; batch adversarial loss: 0.431718\n",
      "epoch 18; iter: 600; batch classifier loss: 0.399649; batch adversarial loss: 0.464291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.381770; batch adversarial loss: 0.488177\n",
      "epoch 19; iter: 200; batch classifier loss: 0.361807; batch adversarial loss: 0.499948\n",
      "epoch 19; iter: 400; batch classifier loss: 0.460233; batch adversarial loss: 0.433241\n",
      "epoch 19; iter: 600; batch classifier loss: 0.326057; batch adversarial loss: 0.543974\n",
      "epoch 0; iter: 0; batch classifier loss: 5.161302; batch adversarial loss: 0.423030\n",
      "epoch 0; iter: 200; batch classifier loss: 8.303802; batch adversarial loss: 0.559599\n",
      "epoch 0; iter: 400; batch classifier loss: 3.326258; batch adversarial loss: 0.562907\n",
      "epoch 0; iter: 600; batch classifier loss: 6.347516; batch adversarial loss: 0.525195\n",
      "epoch 1; iter: 0; batch classifier loss: 6.973871; batch adversarial loss: 0.383262\n",
      "epoch 1; iter: 200; batch classifier loss: 7.349471; batch adversarial loss: 0.431134\n",
      "epoch 1; iter: 400; batch classifier loss: 1.887614; batch adversarial loss: 0.481728\n",
      "epoch 1; iter: 600; batch classifier loss: 19.376368; batch adversarial loss: 0.461037\n",
      "epoch 2; iter: 0; batch classifier loss: 19.130766; batch adversarial loss: 0.440380\n",
      "epoch 2; iter: 200; batch classifier loss: 2.157739; batch adversarial loss: 0.333652\n",
      "epoch 2; iter: 400; batch classifier loss: 2.210367; batch adversarial loss: 0.333552\n",
      "epoch 2; iter: 600; batch classifier loss: 1.730744; batch adversarial loss: 0.351509\n",
      "epoch 3; iter: 0; batch classifier loss: 0.343997; batch adversarial loss: 0.559882\n",
      "epoch 3; iter: 200; batch classifier loss: 7.065533; batch adversarial loss: 0.392582\n",
      "epoch 3; iter: 400; batch classifier loss: 1.202201; batch adversarial loss: 0.447672\n",
      "epoch 3; iter: 600; batch classifier loss: 0.347349; batch adversarial loss: 0.420387\n",
      "epoch 4; iter: 0; batch classifier loss: 0.886431; batch adversarial loss: 0.391146\n",
      "epoch 4; iter: 200; batch classifier loss: 1.150092; batch adversarial loss: 0.312216\n",
      "epoch 4; iter: 400; batch classifier loss: 0.764579; batch adversarial loss: 0.465008\n",
      "epoch 4; iter: 600; batch classifier loss: 0.634799; batch adversarial loss: 0.482395\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418629; batch adversarial loss: 0.475690\n",
      "epoch 5; iter: 200; batch classifier loss: 0.709610; batch adversarial loss: 0.306093\n",
      "epoch 5; iter: 400; batch classifier loss: 0.444751; batch adversarial loss: 0.335724\n",
      "epoch 5; iter: 600; batch classifier loss: 0.282669; batch adversarial loss: 0.452166\n",
      "epoch 6; iter: 0; batch classifier loss: 0.374840; batch adversarial loss: 0.348971\n",
      "epoch 6; iter: 200; batch classifier loss: 0.422786; batch adversarial loss: 0.395498\n",
      "epoch 6; iter: 400; batch classifier loss: 0.482267; batch adversarial loss: 0.453801\n",
      "epoch 6; iter: 600; batch classifier loss: 1.492197; batch adversarial loss: 0.483681\n",
      "epoch 7; iter: 0; batch classifier loss: 0.752230; batch adversarial loss: 0.327520\n",
      "epoch 7; iter: 200; batch classifier loss: 0.542927; batch adversarial loss: 0.377518\n",
      "epoch 7; iter: 400; batch classifier loss: 0.378367; batch adversarial loss: 0.481032\n",
      "epoch 7; iter: 600; batch classifier loss: 0.298308; batch adversarial loss: 0.425721\n",
      "epoch 8; iter: 0; batch classifier loss: 0.420325; batch adversarial loss: 0.522180\n",
      "epoch 8; iter: 200; batch classifier loss: 0.425166; batch adversarial loss: 0.453777\n",
      "epoch 8; iter: 400; batch classifier loss: 0.428887; batch adversarial loss: 0.459234\n",
      "epoch 8; iter: 600; batch classifier loss: 0.510187; batch adversarial loss: 0.400596\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432451; batch adversarial loss: 0.379806\n",
      "epoch 9; iter: 200; batch classifier loss: 0.294688; batch adversarial loss: 0.329086\n",
      "epoch 9; iter: 400; batch classifier loss: 0.261403; batch adversarial loss: 0.354383\n",
      "epoch 9; iter: 600; batch classifier loss: 0.346742; batch adversarial loss: 0.433165\n",
      "epoch 10; iter: 0; batch classifier loss: 0.344306; batch adversarial loss: 0.568913\n",
      "epoch 10; iter: 200; batch classifier loss: 0.364328; batch adversarial loss: 0.289187\n",
      "epoch 10; iter: 400; batch classifier loss: 0.368207; batch adversarial loss: 0.507098\n",
      "epoch 10; iter: 600; batch classifier loss: 0.318058; batch adversarial loss: 0.425574\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426196; batch adversarial loss: 0.344395\n",
      "epoch 11; iter: 200; batch classifier loss: 0.353871; batch adversarial loss: 0.435693\n",
      "epoch 11; iter: 400; batch classifier loss: 0.342242; batch adversarial loss: 0.366009\n",
      "epoch 11; iter: 600; batch classifier loss: 0.399569; batch adversarial loss: 0.409601\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361227; batch adversarial loss: 0.485669\n",
      "epoch 12; iter: 200; batch classifier loss: 0.293142; batch adversarial loss: 0.439078\n",
      "epoch 12; iter: 400; batch classifier loss: 0.356205; batch adversarial loss: 0.265890\n",
      "epoch 12; iter: 600; batch classifier loss: 0.403281; batch adversarial loss: 0.424742\n",
      "epoch 13; iter: 0; batch classifier loss: 0.379798; batch adversarial loss: 0.581602\n",
      "epoch 13; iter: 200; batch classifier loss: 0.388220; batch adversarial loss: 0.284905\n",
      "epoch 13; iter: 400; batch classifier loss: 0.383323; batch adversarial loss: 0.265103\n",
      "epoch 13; iter: 600; batch classifier loss: 0.286519; batch adversarial loss: 0.453453\n",
      "epoch 14; iter: 0; batch classifier loss: 0.293554; batch adversarial loss: 0.489569\n",
      "epoch 14; iter: 200; batch classifier loss: 0.398646; batch adversarial loss: 0.530359\n",
      "epoch 14; iter: 400; batch classifier loss: 0.354916; batch adversarial loss: 0.501781\n",
      "epoch 14; iter: 600; batch classifier loss: 0.459981; batch adversarial loss: 0.317116\n",
      "epoch 15; iter: 0; batch classifier loss: 0.430660; batch adversarial loss: 0.327954\n",
      "epoch 15; iter: 200; batch classifier loss: 0.212069; batch adversarial loss: 0.383001\n",
      "epoch 15; iter: 400; batch classifier loss: 0.421523; batch adversarial loss: 0.353015\n",
      "epoch 15; iter: 600; batch classifier loss: 0.502615; batch adversarial loss: 0.457288\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408111; batch adversarial loss: 0.401805\n",
      "epoch 16; iter: 200; batch classifier loss: 0.338323; batch adversarial loss: 0.481639\n",
      "epoch 16; iter: 400; batch classifier loss: 0.384841; batch adversarial loss: 0.374263\n",
      "epoch 16; iter: 600; batch classifier loss: 0.317816; batch adversarial loss: 0.599197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.457701; batch adversarial loss: 0.480897\n",
      "epoch 17; iter: 200; batch classifier loss: 0.372944; batch adversarial loss: 0.455457\n",
      "epoch 17; iter: 400; batch classifier loss: 0.206777; batch adversarial loss: 0.454424\n",
      "epoch 17; iter: 600; batch classifier loss: 0.420763; batch adversarial loss: 0.423363\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284452; batch adversarial loss: 0.267055\n",
      "epoch 18; iter: 200; batch classifier loss: 0.354208; batch adversarial loss: 0.443705\n",
      "epoch 18; iter: 400; batch classifier loss: 0.369349; batch adversarial loss: 0.404929\n",
      "epoch 18; iter: 600; batch classifier loss: 0.342913; batch adversarial loss: 0.380050\n",
      "epoch 19; iter: 0; batch classifier loss: 0.263703; batch adversarial loss: 0.422810\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376765; batch adversarial loss: 0.259321\n",
      "epoch 19; iter: 400; batch classifier loss: 0.349749; batch adversarial loss: 0.546385\n",
      "epoch 19; iter: 600; batch classifier loss: 0.212332; batch adversarial loss: 0.564397\n",
      "epoch 0; iter: 0; batch classifier loss: 8.575719; batch adversarial loss: 0.665160\n",
      "epoch 0; iter: 200; batch classifier loss: 36.779221; batch adversarial loss: 0.598064\n",
      "epoch 0; iter: 400; batch classifier loss: 6.022038; batch adversarial loss: 0.561425\n",
      "epoch 0; iter: 600; batch classifier loss: 2.876889; batch adversarial loss: 0.479947\n",
      "epoch 1; iter: 0; batch classifier loss: 1.327103; batch adversarial loss: 0.463533\n",
      "epoch 1; iter: 200; batch classifier loss: 0.713398; batch adversarial loss: 0.461838\n",
      "epoch 1; iter: 400; batch classifier loss: 2.229908; batch adversarial loss: 0.405036\n",
      "epoch 1; iter: 600; batch classifier loss: 1.099453; batch adversarial loss: 0.483949\n",
      "epoch 2; iter: 0; batch classifier loss: 2.929051; batch adversarial loss: 0.377364\n",
      "epoch 2; iter: 200; batch classifier loss: 1.416595; batch adversarial loss: 0.536586\n",
      "epoch 2; iter: 400; batch classifier loss: 2.239899; batch adversarial loss: 0.482505\n",
      "epoch 2; iter: 600; batch classifier loss: 0.741396; batch adversarial loss: 0.403923\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582204; batch adversarial loss: 0.439639\n",
      "epoch 3; iter: 200; batch classifier loss: 0.991849; batch adversarial loss: 0.392756\n",
      "epoch 3; iter: 400; batch classifier loss: 1.557527; batch adversarial loss: 0.477685\n",
      "epoch 3; iter: 600; batch classifier loss: 2.121561; batch adversarial loss: 0.527171\n",
      "epoch 4; iter: 0; batch classifier loss: 0.262952; batch adversarial loss: 0.463747\n",
      "epoch 4; iter: 200; batch classifier loss: 0.353794; batch adversarial loss: 0.419690\n",
      "epoch 4; iter: 400; batch classifier loss: 0.570483; batch adversarial loss: 0.528182\n",
      "epoch 4; iter: 600; batch classifier loss: 1.033365; batch adversarial loss: 0.455055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515928; batch adversarial loss: 0.414947\n",
      "epoch 5; iter: 200; batch classifier loss: 0.244319; batch adversarial loss: 0.352990\n",
      "epoch 5; iter: 400; batch classifier loss: 0.916480; batch adversarial loss: 0.381264\n",
      "epoch 5; iter: 600; batch classifier loss: 1.370069; batch adversarial loss: 0.411100\n",
      "epoch 6; iter: 0; batch classifier loss: 0.774469; batch adversarial loss: 0.447791\n",
      "epoch 6; iter: 200; batch classifier loss: 0.430077; batch adversarial loss: 0.412106\n",
      "epoch 6; iter: 400; batch classifier loss: 0.485295; batch adversarial loss: 0.514022\n",
      "epoch 6; iter: 600; batch classifier loss: 0.421263; batch adversarial loss: 0.408653\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530208; batch adversarial loss: 0.497070\n",
      "epoch 7; iter: 200; batch classifier loss: 0.428073; batch adversarial loss: 0.399144\n",
      "epoch 7; iter: 400; batch classifier loss: 0.342460; batch adversarial loss: 0.443343\n",
      "epoch 7; iter: 600; batch classifier loss: 0.442919; batch adversarial loss: 0.376230\n",
      "epoch 8; iter: 0; batch classifier loss: 0.429241; batch adversarial loss: 0.268589\n",
      "epoch 8; iter: 200; batch classifier loss: 0.407075; batch adversarial loss: 0.358140\n",
      "epoch 8; iter: 400; batch classifier loss: 0.406292; batch adversarial loss: 0.479868\n",
      "epoch 8; iter: 600; batch classifier loss: 0.392051; batch adversarial loss: 0.300481\n",
      "epoch 9; iter: 0; batch classifier loss: 0.218300; batch adversarial loss: 0.425170\n",
      "epoch 9; iter: 200; batch classifier loss: 0.376555; batch adversarial loss: 0.558851\n",
      "epoch 9; iter: 400; batch classifier loss: 0.363164; batch adversarial loss: 0.298191\n",
      "epoch 9; iter: 600; batch classifier loss: 0.378487; batch adversarial loss: 0.424296\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398028; batch adversarial loss: 0.400431\n",
      "epoch 10; iter: 200; batch classifier loss: 0.270335; batch adversarial loss: 0.403261\n",
      "epoch 10; iter: 400; batch classifier loss: 0.335279; batch adversarial loss: 0.399181\n",
      "epoch 10; iter: 600; batch classifier loss: 0.485485; batch adversarial loss: 0.562509\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292699; batch adversarial loss: 0.432525\n",
      "epoch 11; iter: 200; batch classifier loss: 0.417416; batch adversarial loss: 0.455863\n",
      "epoch 11; iter: 400; batch classifier loss: 0.273194; batch adversarial loss: 0.472590\n",
      "epoch 11; iter: 600; batch classifier loss: 0.390835; batch adversarial loss: 0.405656\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448687; batch adversarial loss: 0.435950\n",
      "epoch 12; iter: 200; batch classifier loss: 0.439272; batch adversarial loss: 0.395996\n",
      "epoch 12; iter: 400; batch classifier loss: 0.215676; batch adversarial loss: 0.468249\n",
      "epoch 12; iter: 600; batch classifier loss: 0.346055; batch adversarial loss: 0.470283\n",
      "epoch 13; iter: 0; batch classifier loss: 0.283238; batch adversarial loss: 0.321764\n",
      "epoch 13; iter: 200; batch classifier loss: 0.355005; batch adversarial loss: 0.430489\n",
      "epoch 13; iter: 400; batch classifier loss: 0.337054; batch adversarial loss: 0.461068\n",
      "epoch 13; iter: 600; batch classifier loss: 0.398460; batch adversarial loss: 0.374522\n",
      "epoch 14; iter: 0; batch classifier loss: 0.374056; batch adversarial loss: 0.271877\n",
      "epoch 14; iter: 200; batch classifier loss: 0.486167; batch adversarial loss: 0.435975\n",
      "epoch 14; iter: 400; batch classifier loss: 0.293547; batch adversarial loss: 0.564882\n",
      "epoch 14; iter: 600; batch classifier loss: 0.380016; batch adversarial loss: 0.455952\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343341; batch adversarial loss: 0.316655\n",
      "epoch 15; iter: 200; batch classifier loss: 0.330234; batch adversarial loss: 0.399090\n",
      "epoch 15; iter: 400; batch classifier loss: 0.334198; batch adversarial loss: 0.425945\n",
      "epoch 15; iter: 600; batch classifier loss: 0.364946; batch adversarial loss: 0.414289\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331330; batch adversarial loss: 0.294592\n",
      "epoch 16; iter: 200; batch classifier loss: 0.348894; batch adversarial loss: 0.502165\n",
      "epoch 16; iter: 400; batch classifier loss: 0.387989; batch adversarial loss: 0.488904\n",
      "epoch 16; iter: 600; batch classifier loss: 0.373469; batch adversarial loss: 0.477489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.279116; batch adversarial loss: 0.476248\n",
      "epoch 17; iter: 200; batch classifier loss: 0.290645; batch adversarial loss: 0.502823\n",
      "epoch 17; iter: 400; batch classifier loss: 0.450606; batch adversarial loss: 0.542856\n",
      "epoch 17; iter: 600; batch classifier loss: 0.336851; batch adversarial loss: 0.465313\n",
      "epoch 18; iter: 0; batch classifier loss: 0.374098; batch adversarial loss: 0.237482\n",
      "epoch 18; iter: 200; batch classifier loss: 0.404596; batch adversarial loss: 0.242399\n",
      "epoch 18; iter: 400; batch classifier loss: 0.286251; batch adversarial loss: 0.506222\n",
      "epoch 18; iter: 600; batch classifier loss: 0.267345; batch adversarial loss: 0.348045\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447500; batch adversarial loss: 0.369811\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376711; batch adversarial loss: 0.360043\n",
      "epoch 19; iter: 400; batch classifier loss: 0.413624; batch adversarial loss: 0.271516\n",
      "epoch 19; iter: 600; batch classifier loss: 0.334261; batch adversarial loss: 0.263429\n",
      "epoch 0; iter: 0; batch classifier loss: 116.657822; batch adversarial loss: 0.697372\n",
      "epoch 0; iter: 200; batch classifier loss: 14.332502; batch adversarial loss: 0.615551\n",
      "epoch 0; iter: 400; batch classifier loss: 9.641166; batch adversarial loss: 0.554569\n",
      "epoch 0; iter: 600; batch classifier loss: 5.327491; batch adversarial loss: 0.478490\n",
      "epoch 1; iter: 0; batch classifier loss: 5.609297; batch adversarial loss: 0.491196\n",
      "epoch 1; iter: 200; batch classifier loss: 2.038316; batch adversarial loss: 0.526097\n",
      "epoch 1; iter: 400; batch classifier loss: 2.565252; batch adversarial loss: 0.511955\n",
      "epoch 1; iter: 600; batch classifier loss: 7.354242; batch adversarial loss: 0.458867\n",
      "epoch 2; iter: 0; batch classifier loss: 0.802491; batch adversarial loss: 0.389718\n",
      "epoch 2; iter: 200; batch classifier loss: 0.916066; batch adversarial loss: 0.500115\n",
      "epoch 2; iter: 400; batch classifier loss: 1.063965; batch adversarial loss: 0.322339\n",
      "epoch 2; iter: 600; batch classifier loss: 0.462840; batch adversarial loss: 0.406740\n",
      "epoch 3; iter: 0; batch classifier loss: 0.536790; batch adversarial loss: 0.500637\n",
      "epoch 3; iter: 200; batch classifier loss: 0.336816; batch adversarial loss: 0.523302\n",
      "epoch 3; iter: 400; batch classifier loss: 1.923136; batch adversarial loss: 0.478008\n",
      "epoch 3; iter: 600; batch classifier loss: 0.437931; batch adversarial loss: 0.520777\n",
      "epoch 4; iter: 0; batch classifier loss: 3.150260; batch adversarial loss: 0.397840\n",
      "epoch 4; iter: 200; batch classifier loss: 1.094421; batch adversarial loss: 0.296844\n",
      "epoch 4; iter: 400; batch classifier loss: 1.170056; batch adversarial loss: 0.453776\n",
      "epoch 4; iter: 600; batch classifier loss: 0.452613; batch adversarial loss: 0.450956\n",
      "epoch 5; iter: 0; batch classifier loss: 1.403554; batch adversarial loss: 0.462956\n",
      "epoch 5; iter: 200; batch classifier loss: 0.430622; batch adversarial loss: 0.297720\n",
      "epoch 5; iter: 400; batch classifier loss: 4.438211; batch adversarial loss: 0.376631\n",
      "epoch 5; iter: 600; batch classifier loss: 0.443598; batch adversarial loss: 0.375626\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641328; batch adversarial loss: 0.344421\n",
      "epoch 6; iter: 200; batch classifier loss: 0.364206; batch adversarial loss: 0.407037\n",
      "epoch 6; iter: 400; batch classifier loss: 0.261381; batch adversarial loss: 0.457278\n",
      "epoch 6; iter: 600; batch classifier loss: 0.430916; batch adversarial loss: 0.434764\n",
      "epoch 7; iter: 0; batch classifier loss: 0.282484; batch adversarial loss: 0.324812\n",
      "epoch 7; iter: 200; batch classifier loss: 0.461375; batch adversarial loss: 0.322059\n",
      "epoch 7; iter: 400; batch classifier loss: 0.249523; batch adversarial loss: 0.346643\n",
      "epoch 7; iter: 600; batch classifier loss: 0.326672; batch adversarial loss: 0.382330\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438783; batch adversarial loss: 0.441056\n",
      "epoch 8; iter: 200; batch classifier loss: 0.372240; batch adversarial loss: 0.305541\n",
      "epoch 8; iter: 400; batch classifier loss: 0.351181; batch adversarial loss: 0.319591\n",
      "epoch 8; iter: 600; batch classifier loss: 1.281877; batch adversarial loss: 0.328634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398341; batch adversarial loss: 0.495924\n",
      "epoch 9; iter: 200; batch classifier loss: 0.339919; batch adversarial loss: 0.325650\n",
      "epoch 9; iter: 400; batch classifier loss: 0.246767; batch adversarial loss: 0.479991\n",
      "epoch 9; iter: 600; batch classifier loss: 0.434850; batch adversarial loss: 0.405963\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273361; batch adversarial loss: 0.481180\n",
      "epoch 10; iter: 200; batch classifier loss: 0.512558; batch adversarial loss: 0.485728\n",
      "epoch 10; iter: 400; batch classifier loss: 0.450811; batch adversarial loss: 0.443234\n",
      "epoch 10; iter: 600; batch classifier loss: 0.286866; batch adversarial loss: 0.319916\n",
      "epoch 11; iter: 0; batch classifier loss: 0.271038; batch adversarial loss: 0.414976\n",
      "epoch 11; iter: 200; batch classifier loss: 0.317520; batch adversarial loss: 0.289850\n",
      "epoch 11; iter: 400; batch classifier loss: 0.394687; batch adversarial loss: 0.424223\n",
      "epoch 11; iter: 600; batch classifier loss: 0.298266; batch adversarial loss: 0.328682\n",
      "epoch 12; iter: 0; batch classifier loss: 0.275276; batch adversarial loss: 0.454322\n",
      "epoch 12; iter: 200; batch classifier loss: 0.425133; batch adversarial loss: 0.575061\n",
      "epoch 12; iter: 400; batch classifier loss: 0.356490; batch adversarial loss: 0.445464\n",
      "epoch 12; iter: 600; batch classifier loss: 0.376616; batch adversarial loss: 0.373714\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273146; batch adversarial loss: 0.292415\n",
      "epoch 13; iter: 200; batch classifier loss: 0.398974; batch adversarial loss: 0.597421\n",
      "epoch 13; iter: 400; batch classifier loss: 0.355694; batch adversarial loss: 0.474563\n",
      "epoch 13; iter: 600; batch classifier loss: 0.414778; batch adversarial loss: 0.255705\n",
      "epoch 14; iter: 0; batch classifier loss: 0.248606; batch adversarial loss: 0.511433\n",
      "epoch 14; iter: 200; batch classifier loss: 0.478387; batch adversarial loss: 0.547281\n",
      "epoch 14; iter: 400; batch classifier loss: 0.348989; batch adversarial loss: 0.445108\n",
      "epoch 14; iter: 600; batch classifier loss: 0.360475; batch adversarial loss: 0.340167\n",
      "epoch 15; iter: 0; batch classifier loss: 0.300507; batch adversarial loss: 0.375898\n",
      "epoch 15; iter: 200; batch classifier loss: 0.438417; batch adversarial loss: 0.311637\n",
      "epoch 15; iter: 400; batch classifier loss: 0.341579; batch adversarial loss: 0.345835\n",
      "epoch 15; iter: 600; batch classifier loss: 0.247274; batch adversarial loss: 0.319053\n",
      "epoch 16; iter: 0; batch classifier loss: 0.300562; batch adversarial loss: 0.421887\n",
      "epoch 16; iter: 200; batch classifier loss: 0.346262; batch adversarial loss: 0.380611\n",
      "epoch 16; iter: 400; batch classifier loss: 0.388033; batch adversarial loss: 0.460535\n",
      "epoch 16; iter: 600; batch classifier loss: 0.477401; batch adversarial loss: 0.375025\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275466; batch adversarial loss: 0.410518\n",
      "epoch 17; iter: 200; batch classifier loss: 0.355143; batch adversarial loss: 0.309426\n",
      "epoch 17; iter: 400; batch classifier loss: 0.442739; batch adversarial loss: 0.408115\n",
      "epoch 17; iter: 600; batch classifier loss: 0.358111; batch adversarial loss: 0.398453\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326479; batch adversarial loss: 0.361967\n",
      "epoch 18; iter: 200; batch classifier loss: 0.352996; batch adversarial loss: 0.313631\n",
      "epoch 18; iter: 400; batch classifier loss: 0.390178; batch adversarial loss: 0.488157\n",
      "epoch 18; iter: 600; batch classifier loss: 0.374755; batch adversarial loss: 0.468816\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425840; batch adversarial loss: 0.383376\n",
      "epoch 19; iter: 200; batch classifier loss: 0.323797; batch adversarial loss: 0.474402\n",
      "epoch 19; iter: 400; batch classifier loss: 0.416699; batch adversarial loss: 0.368873\n",
      "epoch 19; iter: 600; batch classifier loss: 0.868056; batch adversarial loss: 0.451659\n",
      "epoch 0; iter: 0; batch classifier loss: 10.122727; batch adversarial loss: 0.688549\n",
      "epoch 0; iter: 200; batch classifier loss: 3.246843; batch adversarial loss: 0.627101\n",
      "epoch 0; iter: 400; batch classifier loss: 6.132742; batch adversarial loss: 0.508941\n",
      "epoch 0; iter: 600; batch classifier loss: 6.331821; batch adversarial loss: 0.579878\n",
      "epoch 1; iter: 0; batch classifier loss: 8.030094; batch adversarial loss: 0.488894\n",
      "epoch 1; iter: 200; batch classifier loss: 1.894801; batch adversarial loss: 0.441049\n",
      "epoch 1; iter: 400; batch classifier loss: 2.991247; batch adversarial loss: 0.489441\n",
      "epoch 1; iter: 600; batch classifier loss: 1.851454; batch adversarial loss: 0.414658\n",
      "epoch 2; iter: 0; batch classifier loss: 19.241179; batch adversarial loss: 0.428284\n",
      "epoch 2; iter: 200; batch classifier loss: 2.460685; batch adversarial loss: 0.512923\n",
      "epoch 2; iter: 400; batch classifier loss: 1.661627; batch adversarial loss: 0.370709\n",
      "epoch 2; iter: 600; batch classifier loss: 3.444477; batch adversarial loss: 0.517235\n",
      "epoch 3; iter: 0; batch classifier loss: 0.957830; batch adversarial loss: 0.473257\n",
      "epoch 3; iter: 200; batch classifier loss: 0.267437; batch adversarial loss: 0.357423\n",
      "epoch 3; iter: 400; batch classifier loss: 0.448631; batch adversarial loss: 0.439192\n",
      "epoch 3; iter: 600; batch classifier loss: 0.327901; batch adversarial loss: 0.362830\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498023; batch adversarial loss: 0.350696\n",
      "epoch 4; iter: 200; batch classifier loss: 0.370264; batch adversarial loss: 0.375878\n",
      "epoch 4; iter: 400; batch classifier loss: 0.312563; batch adversarial loss: 0.502381\n",
      "epoch 4; iter: 600; batch classifier loss: 0.503235; batch adversarial loss: 0.429057\n",
      "epoch 5; iter: 0; batch classifier loss: 1.506544; batch adversarial loss: 0.472374\n",
      "epoch 5; iter: 200; batch classifier loss: 0.333528; batch adversarial loss: 0.421770\n",
      "epoch 5; iter: 400; batch classifier loss: 0.590934; batch adversarial loss: 0.354902\n",
      "epoch 5; iter: 600; batch classifier loss: 0.733594; batch adversarial loss: 0.315470\n",
      "epoch 6; iter: 0; batch classifier loss: 0.475830; batch adversarial loss: 0.501953\n",
      "epoch 6; iter: 200; batch classifier loss: 0.313675; batch adversarial loss: 0.393590\n",
      "epoch 6; iter: 400; batch classifier loss: 0.299384; batch adversarial loss: 0.318573\n",
      "epoch 6; iter: 600; batch classifier loss: 0.413123; batch adversarial loss: 0.439697\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273267; batch adversarial loss: 0.463654\n",
      "epoch 7; iter: 200; batch classifier loss: 0.384244; batch adversarial loss: 0.329312\n",
      "epoch 7; iter: 400; batch classifier loss: 0.502723; batch adversarial loss: 0.489328\n",
      "epoch 7; iter: 600; batch classifier loss: 0.464398; batch adversarial loss: 0.462413\n",
      "epoch 8; iter: 0; batch classifier loss: 2.034502; batch adversarial loss: 0.349197\n",
      "epoch 8; iter: 200; batch classifier loss: 0.292118; batch adversarial loss: 0.350087\n",
      "epoch 8; iter: 400; batch classifier loss: 0.381986; batch adversarial loss: 0.463379\n",
      "epoch 8; iter: 600; batch classifier loss: 0.458680; batch adversarial loss: 0.543210\n",
      "epoch 9; iter: 0; batch classifier loss: 0.295173; batch adversarial loss: 0.401601\n",
      "epoch 9; iter: 200; batch classifier loss: 0.302462; batch adversarial loss: 0.496308\n",
      "epoch 9; iter: 400; batch classifier loss: 0.350073; batch adversarial loss: 0.403380\n",
      "epoch 9; iter: 600; batch classifier loss: 0.373229; batch adversarial loss: 0.455072\n",
      "epoch 10; iter: 0; batch classifier loss: 0.448459; batch adversarial loss: 0.455531\n",
      "epoch 10; iter: 200; batch classifier loss: 0.348021; batch adversarial loss: 0.461459\n",
      "epoch 10; iter: 400; batch classifier loss: 0.274393; batch adversarial loss: 0.407601\n",
      "epoch 10; iter: 600; batch classifier loss: 0.307249; batch adversarial loss: 0.477131\n",
      "epoch 11; iter: 0; batch classifier loss: 0.219968; batch adversarial loss: 0.391848\n",
      "epoch 11; iter: 200; batch classifier loss: 0.377141; batch adversarial loss: 0.492150\n",
      "epoch 11; iter: 400; batch classifier loss: 0.408053; batch adversarial loss: 0.299099\n",
      "epoch 11; iter: 600; batch classifier loss: 0.386708; batch adversarial loss: 0.366785\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312078; batch adversarial loss: 0.509371\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432795; batch adversarial loss: 0.484361\n",
      "epoch 12; iter: 400; batch classifier loss: 0.475700; batch adversarial loss: 0.232681\n",
      "epoch 12; iter: 600; batch classifier loss: 0.409617; batch adversarial loss: 0.561540\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418537; batch adversarial loss: 0.404473\n",
      "epoch 13; iter: 200; batch classifier loss: 0.295791; batch adversarial loss: 0.341344\n",
      "epoch 13; iter: 400; batch classifier loss: 0.370491; batch adversarial loss: 0.378583\n",
      "epoch 13; iter: 600; batch classifier loss: 0.189287; batch adversarial loss: 0.480563\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371198; batch adversarial loss: 0.433152\n",
      "epoch 14; iter: 200; batch classifier loss: 0.223630; batch adversarial loss: 0.464858\n",
      "epoch 14; iter: 400; batch classifier loss: 0.228382; batch adversarial loss: 0.429687\n",
      "epoch 14; iter: 600; batch classifier loss: 0.224943; batch adversarial loss: 0.343030\n",
      "epoch 15; iter: 0; batch classifier loss: 0.384552; batch adversarial loss: 0.403519\n",
      "epoch 15; iter: 200; batch classifier loss: 0.300259; batch adversarial loss: 0.340874\n",
      "epoch 15; iter: 400; batch classifier loss: 0.269574; batch adversarial loss: 0.319013\n",
      "epoch 15; iter: 600; batch classifier loss: 0.376828; batch adversarial loss: 0.450515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.240391; batch adversarial loss: 0.368278\n",
      "epoch 16; iter: 200; batch classifier loss: 0.309460; batch adversarial loss: 0.371310\n",
      "epoch 16; iter: 400; batch classifier loss: 0.279595; batch adversarial loss: 0.316454\n",
      "epoch 16; iter: 600; batch classifier loss: 0.337597; batch adversarial loss: 0.399718\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377982; batch adversarial loss: 0.338967\n",
      "epoch 17; iter: 200; batch classifier loss: 0.370295; batch adversarial loss: 0.239417\n",
      "epoch 17; iter: 400; batch classifier loss: 0.484151; batch adversarial loss: 0.478086\n",
      "epoch 17; iter: 600; batch classifier loss: 0.515224; batch adversarial loss: 0.438417\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295064; batch adversarial loss: 0.438985\n",
      "epoch 18; iter: 200; batch classifier loss: 0.432487; batch adversarial loss: 0.378698\n",
      "epoch 18; iter: 400; batch classifier loss: 0.354971; batch adversarial loss: 0.621583\n",
      "epoch 18; iter: 600; batch classifier loss: 0.264327; batch adversarial loss: 0.377806\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338071; batch adversarial loss: 0.424267\n",
      "epoch 19; iter: 200; batch classifier loss: 0.363562; batch adversarial loss: 0.450723\n",
      "epoch 19; iter: 400; batch classifier loss: 0.311495; batch adversarial loss: 0.380232\n",
      "epoch 19; iter: 600; batch classifier loss: 0.351022; batch adversarial loss: 0.289081\n",
      "epoch 0; iter: 0; batch classifier loss: 5.735363; batch adversarial loss: 0.913175\n",
      "epoch 0; iter: 200; batch classifier loss: 8.301664; batch adversarial loss: 0.749537\n",
      "epoch 0; iter: 400; batch classifier loss: 5.644310; batch adversarial loss: 0.665980\n",
      "epoch 0; iter: 600; batch classifier loss: 7.601401; batch adversarial loss: 0.556884\n",
      "epoch 1; iter: 0; batch classifier loss: 3.197577; batch adversarial loss: 0.601667\n",
      "epoch 1; iter: 200; batch classifier loss: 4.674396; batch adversarial loss: 0.530826\n",
      "epoch 1; iter: 400; batch classifier loss: 0.868067; batch adversarial loss: 0.558591\n",
      "epoch 1; iter: 600; batch classifier loss: 1.402437; batch adversarial loss: 0.422740\n",
      "epoch 2; iter: 0; batch classifier loss: 2.686068; batch adversarial loss: 0.545210\n",
      "epoch 2; iter: 200; batch classifier loss: 0.374204; batch adversarial loss: 0.478245\n",
      "epoch 2; iter: 400; batch classifier loss: 1.366293; batch adversarial loss: 0.391550\n",
      "epoch 2; iter: 600; batch classifier loss: 6.512376; batch adversarial loss: 0.445558\n",
      "epoch 3; iter: 0; batch classifier loss: 0.546030; batch adversarial loss: 0.413510\n",
      "epoch 3; iter: 200; batch classifier loss: 1.050418; batch adversarial loss: 0.466608\n",
      "epoch 3; iter: 400; batch classifier loss: 0.423127; batch adversarial loss: 0.464229\n",
      "epoch 3; iter: 600; batch classifier loss: 0.576799; batch adversarial loss: 0.488223\n",
      "epoch 4; iter: 0; batch classifier loss: 0.760216; batch adversarial loss: 0.430063\n",
      "epoch 4; iter: 200; batch classifier loss: 0.586112; batch adversarial loss: 0.306974\n",
      "epoch 4; iter: 400; batch classifier loss: 0.907628; batch adversarial loss: 0.378489\n",
      "epoch 4; iter: 600; batch classifier loss: 0.648460; batch adversarial loss: 0.350620\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521764; batch adversarial loss: 0.360046\n",
      "epoch 5; iter: 200; batch classifier loss: 0.537827; batch adversarial loss: 0.300153\n",
      "epoch 5; iter: 400; batch classifier loss: 0.545585; batch adversarial loss: 0.388092\n",
      "epoch 5; iter: 600; batch classifier loss: 0.359120; batch adversarial loss: 0.397431\n",
      "epoch 6; iter: 0; batch classifier loss: 0.392813; batch adversarial loss: 0.349877\n",
      "epoch 6; iter: 200; batch classifier loss: 0.329923; batch adversarial loss: 0.395581\n",
      "epoch 6; iter: 400; batch classifier loss: 0.450429; batch adversarial loss: 0.587611\n",
      "epoch 6; iter: 600; batch classifier loss: 0.375394; batch adversarial loss: 0.404412\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376063; batch adversarial loss: 0.355075\n",
      "epoch 7; iter: 200; batch classifier loss: 0.352086; batch adversarial loss: 0.547467\n",
      "epoch 7; iter: 400; batch classifier loss: 0.355060; batch adversarial loss: 0.371112\n",
      "epoch 7; iter: 600; batch classifier loss: 0.481104; batch adversarial loss: 0.535991\n",
      "epoch 8; iter: 0; batch classifier loss: 0.415549; batch adversarial loss: 0.360454\n",
      "epoch 8; iter: 200; batch classifier loss: 0.310241; batch adversarial loss: 0.503199\n",
      "epoch 8; iter: 400; batch classifier loss: 0.492213; batch adversarial loss: 0.547131\n",
      "epoch 8; iter: 600; batch classifier loss: 0.374635; batch adversarial loss: 0.498695\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414030; batch adversarial loss: 0.352366\n",
      "epoch 9; iter: 200; batch classifier loss: 0.358692; batch adversarial loss: 0.418911\n",
      "epoch 9; iter: 400; batch classifier loss: 0.303242; batch adversarial loss: 0.438150\n",
      "epoch 9; iter: 600; batch classifier loss: 0.286040; batch adversarial loss: 0.439811\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338133; batch adversarial loss: 0.485013\n",
      "epoch 10; iter: 200; batch classifier loss: 0.532918; batch adversarial loss: 0.347918\n",
      "epoch 10; iter: 400; batch classifier loss: 0.240620; batch adversarial loss: 0.509986\n",
      "epoch 10; iter: 600; batch classifier loss: 0.415938; batch adversarial loss: 0.345669\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361313; batch adversarial loss: 0.322865\n",
      "epoch 11; iter: 200; batch classifier loss: 0.355994; batch adversarial loss: 0.431329\n",
      "epoch 11; iter: 400; batch classifier loss: 0.432361; batch adversarial loss: 0.320612\n",
      "epoch 11; iter: 600; batch classifier loss: 0.420710; batch adversarial loss: 0.351823\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359700; batch adversarial loss: 0.404051\n",
      "epoch 12; iter: 200; batch classifier loss: 0.230625; batch adversarial loss: 0.682769\n",
      "epoch 12; iter: 400; batch classifier loss: 0.340824; batch adversarial loss: 0.457348\n",
      "epoch 12; iter: 600; batch classifier loss: 0.341851; batch adversarial loss: 0.492624\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430774; batch adversarial loss: 0.409339\n",
      "epoch 13; iter: 200; batch classifier loss: 0.261744; batch adversarial loss: 0.440339\n",
      "epoch 13; iter: 400; batch classifier loss: 0.361195; batch adversarial loss: 0.399626\n",
      "epoch 13; iter: 600; batch classifier loss: 0.310455; batch adversarial loss: 0.458621\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384046; batch adversarial loss: 0.372292\n",
      "epoch 14; iter: 200; batch classifier loss: 0.243947; batch adversarial loss: 0.378002\n",
      "epoch 14; iter: 400; batch classifier loss: 0.520427; batch adversarial loss: 0.430281\n",
      "epoch 14; iter: 600; batch classifier loss: 0.276471; batch adversarial loss: 0.454897\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465709; batch adversarial loss: 0.323592\n",
      "epoch 15; iter: 200; batch classifier loss: 0.396934; batch adversarial loss: 0.353378\n",
      "epoch 15; iter: 400; batch classifier loss: 0.365310; batch adversarial loss: 0.498397\n",
      "epoch 15; iter: 600; batch classifier loss: 0.297819; batch adversarial loss: 0.320826\n",
      "epoch 16; iter: 0; batch classifier loss: 0.386435; batch adversarial loss: 0.478948\n",
      "epoch 16; iter: 200; batch classifier loss: 0.296057; batch adversarial loss: 0.402498\n",
      "epoch 16; iter: 400; batch classifier loss: 0.344581; batch adversarial loss: 0.433827\n",
      "epoch 16; iter: 600; batch classifier loss: 0.439880; batch adversarial loss: 0.370888\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340700; batch adversarial loss: 0.398961\n",
      "epoch 17; iter: 200; batch classifier loss: 0.281357; batch adversarial loss: 0.623150\n",
      "epoch 17; iter: 400; batch classifier loss: 0.263627; batch adversarial loss: 0.509282\n",
      "epoch 17; iter: 600; batch classifier loss: 0.521046; batch adversarial loss: 0.379089\n",
      "epoch 18; iter: 0; batch classifier loss: 0.484445; batch adversarial loss: 0.420427\n",
      "epoch 18; iter: 200; batch classifier loss: 0.380737; batch adversarial loss: 0.345167\n",
      "epoch 18; iter: 400; batch classifier loss: 0.291186; batch adversarial loss: 0.403182\n",
      "epoch 18; iter: 600; batch classifier loss: 0.390113; batch adversarial loss: 0.390323\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374932; batch adversarial loss: 0.376766\n",
      "epoch 19; iter: 200; batch classifier loss: 0.427501; batch adversarial loss: 0.401134\n",
      "epoch 19; iter: 400; batch classifier loss: 0.328195; batch adversarial loss: 0.481993\n",
      "epoch 19; iter: 600; batch classifier loss: 0.323362; batch adversarial loss: 0.356202\n",
      "epoch 0; iter: 0; batch classifier loss: 8.738820; batch adversarial loss: 0.943076\n",
      "epoch 0; iter: 200; batch classifier loss: 4.571536; batch adversarial loss: 0.861950\n",
      "epoch 0; iter: 400; batch classifier loss: 5.779772; batch adversarial loss: 0.691606\n",
      "epoch 0; iter: 600; batch classifier loss: 9.969595; batch adversarial loss: 0.576048\n",
      "epoch 1; iter: 0; batch classifier loss: 2.892112; batch adversarial loss: 0.568756\n",
      "epoch 1; iter: 200; batch classifier loss: 6.238189; batch adversarial loss: 0.496031\n",
      "epoch 1; iter: 400; batch classifier loss: 11.481222; batch adversarial loss: 0.549111\n",
      "epoch 1; iter: 600; batch classifier loss: 3.086584; batch adversarial loss: 0.485179\n",
      "epoch 2; iter: 0; batch classifier loss: 1.597733; batch adversarial loss: 0.431552\n",
      "epoch 2; iter: 200; batch classifier loss: 2.400890; batch adversarial loss: 0.376744\n",
      "epoch 2; iter: 400; batch classifier loss: 3.056455; batch adversarial loss: 0.389707\n",
      "epoch 2; iter: 600; batch classifier loss: 3.148151; batch adversarial loss: 0.456013\n",
      "epoch 3; iter: 0; batch classifier loss: 32.051331; batch adversarial loss: 0.425062\n",
      "epoch 3; iter: 200; batch classifier loss: 0.788897; batch adversarial loss: 0.304088\n",
      "epoch 3; iter: 400; batch classifier loss: 0.426291; batch adversarial loss: 0.389969\n",
      "epoch 3; iter: 600; batch classifier loss: 3.546196; batch adversarial loss: 0.282259\n",
      "epoch 4; iter: 0; batch classifier loss: 1.933474; batch adversarial loss: 0.321197\n",
      "epoch 4; iter: 200; batch classifier loss: 0.486405; batch adversarial loss: 0.471699\n",
      "epoch 4; iter: 400; batch classifier loss: 0.728091; batch adversarial loss: 0.410280\n",
      "epoch 4; iter: 600; batch classifier loss: 0.271830; batch adversarial loss: 0.398175\n",
      "epoch 5; iter: 0; batch classifier loss: 2.184681; batch adversarial loss: 0.463064\n",
      "epoch 5; iter: 200; batch classifier loss: 0.701917; batch adversarial loss: 0.292942\n",
      "epoch 5; iter: 400; batch classifier loss: 0.456457; batch adversarial loss: 0.363031\n",
      "epoch 5; iter: 600; batch classifier loss: 0.575801; batch adversarial loss: 0.342626\n",
      "epoch 6; iter: 0; batch classifier loss: 1.220150; batch adversarial loss: 0.349779\n",
      "epoch 6; iter: 200; batch classifier loss: 1.130758; batch adversarial loss: 0.316640\n",
      "epoch 6; iter: 400; batch classifier loss: 0.757865; batch adversarial loss: 0.595582\n",
      "epoch 6; iter: 600; batch classifier loss: 0.709575; batch adversarial loss: 0.434737\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469901; batch adversarial loss: 0.433882\n",
      "epoch 7; iter: 200; batch classifier loss: 0.308362; batch adversarial loss: 0.498653\n",
      "epoch 7; iter: 400; batch classifier loss: 0.277059; batch adversarial loss: 0.477684\n",
      "epoch 7; iter: 600; batch classifier loss: 0.371596; batch adversarial loss: 0.550699\n",
      "epoch 8; iter: 0; batch classifier loss: 0.420651; batch adversarial loss: 0.359188\n",
      "epoch 8; iter: 200; batch classifier loss: 0.529159; batch adversarial loss: 0.383228\n",
      "epoch 8; iter: 400; batch classifier loss: 0.388196; batch adversarial loss: 0.375379\n",
      "epoch 8; iter: 600; batch classifier loss: 0.459918; batch adversarial loss: 0.358710\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345334; batch adversarial loss: 0.418673\n",
      "epoch 9; iter: 200; batch classifier loss: 0.210015; batch adversarial loss: 0.442963\n",
      "epoch 9; iter: 400; batch classifier loss: 0.393488; batch adversarial loss: 0.490066\n",
      "epoch 9; iter: 600; batch classifier loss: 0.367635; batch adversarial loss: 0.369714\n",
      "epoch 10; iter: 0; batch classifier loss: 0.322051; batch adversarial loss: 0.434724\n",
      "epoch 10; iter: 200; batch classifier loss: 0.298941; batch adversarial loss: 0.549596\n",
      "epoch 10; iter: 400; batch classifier loss: 0.286044; batch adversarial loss: 0.349337\n",
      "epoch 10; iter: 600; batch classifier loss: 0.351490; batch adversarial loss: 0.340243\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499577; batch adversarial loss: 0.313545\n",
      "epoch 11; iter: 200; batch classifier loss: 0.406762; batch adversarial loss: 0.370150\n",
      "epoch 11; iter: 400; batch classifier loss: 0.402166; batch adversarial loss: 0.537109\n",
      "epoch 11; iter: 600; batch classifier loss: 0.285902; batch adversarial loss: 0.431908\n",
      "epoch 12; iter: 0; batch classifier loss: 0.309519; batch adversarial loss: 0.388246\n",
      "epoch 12; iter: 200; batch classifier loss: 0.318530; batch adversarial loss: 0.271148\n",
      "epoch 12; iter: 400; batch classifier loss: 0.368901; batch adversarial loss: 0.402117\n",
      "epoch 12; iter: 600; batch classifier loss: 0.340910; batch adversarial loss: 0.463067\n",
      "epoch 13; iter: 0; batch classifier loss: 0.387215; batch adversarial loss: 0.405964\n",
      "epoch 13; iter: 200; batch classifier loss: 0.354573; batch adversarial loss: 0.540410\n",
      "epoch 13; iter: 400; batch classifier loss: 0.443916; batch adversarial loss: 0.405042\n",
      "epoch 13; iter: 600; batch classifier loss: 0.351956; batch adversarial loss: 0.543906\n",
      "epoch 14; iter: 0; batch classifier loss: 0.687451; batch adversarial loss: 0.367089\n",
      "epoch 14; iter: 200; batch classifier loss: 0.320767; batch adversarial loss: 0.375997\n",
      "epoch 14; iter: 400; batch classifier loss: 0.359016; batch adversarial loss: 0.461396\n",
      "epoch 14; iter: 600; batch classifier loss: 0.293569; batch adversarial loss: 0.491724\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327765; batch adversarial loss: 0.443424\n",
      "epoch 15; iter: 200; batch classifier loss: 0.365845; batch adversarial loss: 0.438890\n",
      "epoch 15; iter: 400; batch classifier loss: 0.303465; batch adversarial loss: 0.383717\n",
      "epoch 15; iter: 600; batch classifier loss: 0.335228; batch adversarial loss: 0.485333\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334117; batch adversarial loss: 0.479440\n",
      "epoch 16; iter: 200; batch classifier loss: 0.296394; batch adversarial loss: 0.490931\n",
      "epoch 16; iter: 400; batch classifier loss: 0.353802; batch adversarial loss: 0.408130\n",
      "epoch 16; iter: 600; batch classifier loss: 0.251613; batch adversarial loss: 0.479438\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296661; batch adversarial loss: 0.440645\n",
      "epoch 17; iter: 200; batch classifier loss: 0.393032; batch adversarial loss: 0.400721\n",
      "epoch 17; iter: 400; batch classifier loss: 0.380440; batch adversarial loss: 0.395498\n",
      "epoch 17; iter: 600; batch classifier loss: 0.383185; batch adversarial loss: 0.506399\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366598; batch adversarial loss: 0.412695\n",
      "epoch 18; iter: 200; batch classifier loss: 0.265748; batch adversarial loss: 0.400333\n",
      "epoch 18; iter: 400; batch classifier loss: 0.259489; batch adversarial loss: 0.452293\n",
      "epoch 18; iter: 600; batch classifier loss: 0.339564; batch adversarial loss: 0.447547\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322685; batch adversarial loss: 0.435211\n",
      "epoch 19; iter: 200; batch classifier loss: 0.474364; batch adversarial loss: 0.299002\n",
      "epoch 19; iter: 400; batch classifier loss: 0.339801; batch adversarial loss: 0.433762\n",
      "epoch 19; iter: 600; batch classifier loss: 0.521771; batch adversarial loss: 0.485884\n",
      "epoch 0; iter: 0; batch classifier loss: 66.201637; batch adversarial loss: 0.571862\n",
      "epoch 0; iter: 200; batch classifier loss: 19.916653; batch adversarial loss: 0.588263\n",
      "epoch 0; iter: 400; batch classifier loss: 4.134830; batch adversarial loss: 0.553574\n",
      "epoch 0; iter: 600; batch classifier loss: 2.745438; batch adversarial loss: 0.545214\n",
      "epoch 1; iter: 0; batch classifier loss: 12.295647; batch adversarial loss: 0.500931\n",
      "epoch 1; iter: 200; batch classifier loss: 9.564798; batch adversarial loss: 0.457342\n",
      "epoch 1; iter: 400; batch classifier loss: 8.791198; batch adversarial loss: 0.518839\n",
      "epoch 1; iter: 600; batch classifier loss: 0.414039; batch adversarial loss: 0.511493\n",
      "epoch 2; iter: 0; batch classifier loss: 0.303836; batch adversarial loss: 0.517440\n",
      "epoch 2; iter: 200; batch classifier loss: 0.311012; batch adversarial loss: 0.521429\n",
      "epoch 2; iter: 400; batch classifier loss: 1.036688; batch adversarial loss: 0.459397\n",
      "epoch 2; iter: 600; batch classifier loss: 1.177830; batch adversarial loss: 0.468270\n",
      "epoch 3; iter: 0; batch classifier loss: 1.418572; batch adversarial loss: 0.480441\n",
      "epoch 3; iter: 200; batch classifier loss: 1.690668; batch adversarial loss: 0.429468\n",
      "epoch 3; iter: 400; batch classifier loss: 1.794356; batch adversarial loss: 0.358328\n",
      "epoch 3; iter: 600; batch classifier loss: 0.382423; batch adversarial loss: 0.405053\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597546; batch adversarial loss: 0.367953\n",
      "epoch 4; iter: 200; batch classifier loss: 0.381187; batch adversarial loss: 0.456107\n",
      "epoch 4; iter: 400; batch classifier loss: 1.336056; batch adversarial loss: 0.405104\n",
      "epoch 4; iter: 600; batch classifier loss: 0.803765; batch adversarial loss: 0.341356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.382654; batch adversarial loss: 0.398930\n",
      "epoch 5; iter: 200; batch classifier loss: 0.375035; batch adversarial loss: 0.399405\n",
      "epoch 5; iter: 400; batch classifier loss: 0.382819; batch adversarial loss: 0.272390\n",
      "epoch 5; iter: 600; batch classifier loss: 0.767683; batch adversarial loss: 0.351106\n",
      "epoch 6; iter: 0; batch classifier loss: 0.221303; batch adversarial loss: 0.560330\n",
      "epoch 6; iter: 200; batch classifier loss: 0.666613; batch adversarial loss: 0.462072\n",
      "epoch 6; iter: 400; batch classifier loss: 0.527071; batch adversarial loss: 0.447191\n",
      "epoch 6; iter: 600; batch classifier loss: 0.351137; batch adversarial loss: 0.400435\n",
      "epoch 7; iter: 0; batch classifier loss: 0.810803; batch adversarial loss: 0.322945\n",
      "epoch 7; iter: 200; batch classifier loss: 0.630741; batch adversarial loss: 0.400864\n",
      "epoch 7; iter: 400; batch classifier loss: 0.556420; batch adversarial loss: 0.394727\n",
      "epoch 7; iter: 600; batch classifier loss: 0.303812; batch adversarial loss: 0.607953\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478905; batch adversarial loss: 0.461554\n",
      "epoch 8; iter: 200; batch classifier loss: 0.517129; batch adversarial loss: 0.518382\n",
      "epoch 8; iter: 400; batch classifier loss: 0.472605; batch adversarial loss: 0.533227\n",
      "epoch 8; iter: 600; batch classifier loss: 0.367996; batch adversarial loss: 0.454212\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284413; batch adversarial loss: 0.351052\n",
      "epoch 9; iter: 200; batch classifier loss: 0.338173; batch adversarial loss: 0.319665\n",
      "epoch 9; iter: 400; batch classifier loss: 0.307424; batch adversarial loss: 0.374023\n",
      "epoch 9; iter: 600; batch classifier loss: 0.393191; batch adversarial loss: 0.428975\n",
      "epoch 10; iter: 0; batch classifier loss: 0.401534; batch adversarial loss: 0.431348\n",
      "epoch 10; iter: 200; batch classifier loss: 0.410800; batch adversarial loss: 0.396494\n",
      "epoch 10; iter: 400; batch classifier loss: 0.482396; batch adversarial loss: 0.260065\n",
      "epoch 10; iter: 600; batch classifier loss: 0.303526; batch adversarial loss: 0.349568\n",
      "epoch 11; iter: 0; batch classifier loss: 0.297557; batch adversarial loss: 0.406325\n",
      "epoch 11; iter: 200; batch classifier loss: 0.350426; batch adversarial loss: 0.431959\n",
      "epoch 11; iter: 400; batch classifier loss: 0.261538; batch adversarial loss: 0.295751\n",
      "epoch 11; iter: 600; batch classifier loss: 0.508497; batch adversarial loss: 0.426422\n",
      "epoch 12; iter: 0; batch classifier loss: 0.338593; batch adversarial loss: 0.488529\n",
      "epoch 12; iter: 200; batch classifier loss: 0.452254; batch adversarial loss: 0.352295\n",
      "epoch 12; iter: 400; batch classifier loss: 0.280622; batch adversarial loss: 0.352895\n",
      "epoch 12; iter: 600; batch classifier loss: 0.315990; batch adversarial loss: 0.407578\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361660; batch adversarial loss: 0.350463\n",
      "epoch 13; iter: 200; batch classifier loss: 0.440818; batch adversarial loss: 0.500495\n",
      "epoch 13; iter: 400; batch classifier loss: 0.480761; batch adversarial loss: 0.423250\n",
      "epoch 13; iter: 600; batch classifier loss: 0.455209; batch adversarial loss: 0.373198\n",
      "epoch 14; iter: 0; batch classifier loss: 0.420667; batch adversarial loss: 0.368724\n",
      "epoch 14; iter: 200; batch classifier loss: 0.292957; batch adversarial loss: 0.454100\n",
      "epoch 14; iter: 400; batch classifier loss: 0.266243; batch adversarial loss: 0.453526\n",
      "epoch 14; iter: 600; batch classifier loss: 0.372457; batch adversarial loss: 0.347739\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316270; batch adversarial loss: 0.457994\n",
      "epoch 15; iter: 200; batch classifier loss: 0.299208; batch adversarial loss: 0.443271\n",
      "epoch 15; iter: 400; batch classifier loss: 0.303253; batch adversarial loss: 0.346280\n",
      "epoch 15; iter: 600; batch classifier loss: 0.370932; batch adversarial loss: 0.437876\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307280; batch adversarial loss: 0.352195\n",
      "epoch 16; iter: 200; batch classifier loss: 0.263182; batch adversarial loss: 0.405951\n",
      "epoch 16; iter: 400; batch classifier loss: 0.518801; batch adversarial loss: 0.375941\n",
      "epoch 16; iter: 600; batch classifier loss: 0.292765; batch adversarial loss: 0.438735\n",
      "epoch 17; iter: 0; batch classifier loss: 0.407664; batch adversarial loss: 0.342640\n",
      "epoch 17; iter: 200; batch classifier loss: 0.351886; batch adversarial loss: 0.405900\n",
      "epoch 17; iter: 400; batch classifier loss: 0.337709; batch adversarial loss: 0.515984\n",
      "epoch 17; iter: 600; batch classifier loss: 0.427964; batch adversarial loss: 0.382595\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454609; batch adversarial loss: 0.373569\n",
      "epoch 18; iter: 200; batch classifier loss: 0.302694; batch adversarial loss: 0.491434\n",
      "epoch 18; iter: 400; batch classifier loss: 0.345697; batch adversarial loss: 0.377156\n",
      "epoch 18; iter: 600; batch classifier loss: 0.554776; batch adversarial loss: 0.321831\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334785; batch adversarial loss: 0.617103\n",
      "epoch 19; iter: 200; batch classifier loss: 0.335258; batch adversarial loss: 0.289492\n",
      "epoch 19; iter: 400; batch classifier loss: 0.373463; batch adversarial loss: 0.538394\n",
      "epoch 19; iter: 600; batch classifier loss: 0.212422; batch adversarial loss: 0.311238\n",
      "epoch 0; iter: 0; batch classifier loss: 42.495071; batch adversarial loss: 1.042209\n",
      "epoch 0; iter: 200; batch classifier loss: 11.222194; batch adversarial loss: 0.637721\n",
      "epoch 0; iter: 400; batch classifier loss: 17.599405; batch adversarial loss: 0.602874\n",
      "epoch 0; iter: 600; batch classifier loss: 4.190364; batch adversarial loss: 0.530280\n",
      "epoch 1; iter: 0; batch classifier loss: 6.597062; batch adversarial loss: 0.534608\n",
      "epoch 1; iter: 200; batch classifier loss: 8.327969; batch adversarial loss: 0.497993\n",
      "epoch 1; iter: 400; batch classifier loss: 4.275238; batch adversarial loss: 0.446098\n",
      "epoch 1; iter: 600; batch classifier loss: 2.260485; batch adversarial loss: 0.403599\n",
      "epoch 2; iter: 0; batch classifier loss: 3.209775; batch adversarial loss: 0.455949\n",
      "epoch 2; iter: 200; batch classifier loss: 0.905065; batch adversarial loss: 0.455284\n",
      "epoch 2; iter: 400; batch classifier loss: 0.260815; batch adversarial loss: 0.428406\n",
      "epoch 2; iter: 600; batch classifier loss: 1.164842; batch adversarial loss: 0.411181\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548486; batch adversarial loss: 0.505803\n",
      "epoch 3; iter: 200; batch classifier loss: 1.232816; batch adversarial loss: 0.506536\n",
      "epoch 3; iter: 400; batch classifier loss: 1.215184; batch adversarial loss: 0.453057\n",
      "epoch 3; iter: 600; batch classifier loss: 1.822729; batch adversarial loss: 0.430819\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542330; batch adversarial loss: 0.446614\n",
      "epoch 4; iter: 200; batch classifier loss: 0.857785; batch adversarial loss: 0.426712\n",
      "epoch 4; iter: 400; batch classifier loss: 1.414002; batch adversarial loss: 0.486338\n",
      "epoch 4; iter: 600; batch classifier loss: 0.321385; batch adversarial loss: 0.410877\n",
      "epoch 5; iter: 0; batch classifier loss: 0.372641; batch adversarial loss: 0.297073\n",
      "epoch 5; iter: 200; batch classifier loss: 0.346810; batch adversarial loss: 0.356435\n",
      "epoch 5; iter: 400; batch classifier loss: 0.506594; batch adversarial loss: 0.375004\n",
      "epoch 5; iter: 600; batch classifier loss: 0.316103; batch adversarial loss: 0.341576\n",
      "epoch 6; iter: 0; batch classifier loss: 0.297495; batch adversarial loss: 0.312324\n",
      "epoch 6; iter: 200; batch classifier loss: 0.289606; batch adversarial loss: 0.415128\n",
      "epoch 6; iter: 400; batch classifier loss: 0.465753; batch adversarial loss: 0.378819\n",
      "epoch 6; iter: 600; batch classifier loss: 0.310331; batch adversarial loss: 0.473910\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380833; batch adversarial loss: 0.342053\n",
      "epoch 7; iter: 200; batch classifier loss: 0.306316; batch adversarial loss: 0.338700\n",
      "epoch 7; iter: 400; batch classifier loss: 0.373745; batch adversarial loss: 0.477140\n",
      "epoch 7; iter: 600; batch classifier loss: 0.464134; batch adversarial loss: 0.398181\n",
      "epoch 8; iter: 0; batch classifier loss: 0.447882; batch adversarial loss: 0.329819\n",
      "epoch 8; iter: 200; batch classifier loss: 0.461118; batch adversarial loss: 0.397300\n",
      "epoch 8; iter: 400; batch classifier loss: 0.447350; batch adversarial loss: 0.399430\n",
      "epoch 8; iter: 600; batch classifier loss: 0.438297; batch adversarial loss: 0.492285\n",
      "epoch 9; iter: 0; batch classifier loss: 0.741753; batch adversarial loss: 0.375349\n",
      "epoch 9; iter: 200; batch classifier loss: 0.449028; batch adversarial loss: 0.356146\n",
      "epoch 9; iter: 400; batch classifier loss: 0.292556; batch adversarial loss: 0.473552\n",
      "epoch 9; iter: 600; batch classifier loss: 0.259628; batch adversarial loss: 0.469904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.319170; batch adversarial loss: 0.498748\n",
      "epoch 10; iter: 200; batch classifier loss: 0.339394; batch adversarial loss: 0.404709\n",
      "epoch 10; iter: 400; batch classifier loss: 0.394060; batch adversarial loss: 0.284827\n",
      "epoch 10; iter: 600; batch classifier loss: 0.296786; batch adversarial loss: 0.525565\n",
      "epoch 11; iter: 0; batch classifier loss: 0.358710; batch adversarial loss: 0.452102\n",
      "epoch 11; iter: 200; batch classifier loss: 0.308765; batch adversarial loss: 0.466310\n",
      "epoch 11; iter: 400; batch classifier loss: 0.366208; batch adversarial loss: 0.500280\n",
      "epoch 11; iter: 600; batch classifier loss: 0.468925; batch adversarial loss: 0.482632\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313442; batch adversarial loss: 0.333398\n",
      "epoch 12; iter: 200; batch classifier loss: 0.494275; batch adversarial loss: 0.542513\n",
      "epoch 12; iter: 400; batch classifier loss: 0.369267; batch adversarial loss: 0.412442\n",
      "epoch 12; iter: 600; batch classifier loss: 0.344962; batch adversarial loss: 0.404387\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390074; batch adversarial loss: 0.295603\n",
      "epoch 13; iter: 200; batch classifier loss: 0.293065; batch adversarial loss: 0.423126\n",
      "epoch 13; iter: 400; batch classifier loss: 0.298302; batch adversarial loss: 0.487132\n",
      "epoch 13; iter: 600; batch classifier loss: 0.314356; batch adversarial loss: 0.489866\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397474; batch adversarial loss: 0.462103\n",
      "epoch 14; iter: 200; batch classifier loss: 0.234449; batch adversarial loss: 0.396684\n",
      "epoch 14; iter: 400; batch classifier loss: 0.322781; batch adversarial loss: 0.316188\n",
      "epoch 14; iter: 600; batch classifier loss: 0.365869; batch adversarial loss: 0.454573\n",
      "epoch 15; iter: 0; batch classifier loss: 0.342509; batch adversarial loss: 0.341755\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366872; batch adversarial loss: 0.366776\n",
      "epoch 15; iter: 400; batch classifier loss: 0.293595; batch adversarial loss: 0.406596\n",
      "epoch 15; iter: 600; batch classifier loss: 0.257453; batch adversarial loss: 0.230714\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355539; batch adversarial loss: 0.512082\n",
      "epoch 16; iter: 200; batch classifier loss: 0.277977; batch adversarial loss: 0.424022\n",
      "epoch 16; iter: 400; batch classifier loss: 0.428004; batch adversarial loss: 0.349616\n",
      "epoch 16; iter: 600; batch classifier loss: 0.311586; batch adversarial loss: 0.343488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.282038; batch adversarial loss: 0.549748\n",
      "epoch 17; iter: 200; batch classifier loss: 0.388870; batch adversarial loss: 0.371073\n",
      "epoch 17; iter: 400; batch classifier loss: 0.341501; batch adversarial loss: 0.369752\n",
      "epoch 17; iter: 600; batch classifier loss: 0.508042; batch adversarial loss: 0.457390\n",
      "epoch 18; iter: 0; batch classifier loss: 0.231582; batch adversarial loss: 0.344572\n",
      "epoch 18; iter: 200; batch classifier loss: 0.288135; batch adversarial loss: 0.441157\n",
      "epoch 18; iter: 400; batch classifier loss: 0.333366; batch adversarial loss: 0.559560\n",
      "epoch 18; iter: 600; batch classifier loss: 0.301902; batch adversarial loss: 0.470390\n",
      "epoch 19; iter: 0; batch classifier loss: 0.233386; batch adversarial loss: 0.424268\n",
      "epoch 19; iter: 200; batch classifier loss: 0.414217; batch adversarial loss: 0.374705\n",
      "epoch 19; iter: 400; batch classifier loss: 0.267707; batch adversarial loss: 0.534630\n",
      "epoch 19; iter: 600; batch classifier loss: 0.340504; batch adversarial loss: 0.483834\n",
      "epoch 0; iter: 0; batch classifier loss: 19.807137; batch adversarial loss: 0.674862\n",
      "epoch 0; iter: 200; batch classifier loss: 8.228233; batch adversarial loss: 0.643147\n",
      "epoch 0; iter: 400; batch classifier loss: 1.979069; batch adversarial loss: 0.605528\n",
      "epoch 0; iter: 600; batch classifier loss: 13.032291; batch adversarial loss: 0.545593\n",
      "epoch 1; iter: 0; batch classifier loss: 3.938317; batch adversarial loss: 0.544575\n",
      "epoch 1; iter: 200; batch classifier loss: 4.864861; batch adversarial loss: 0.420806\n",
      "epoch 1; iter: 400; batch classifier loss: 1.048697; batch adversarial loss: 0.490710\n",
      "epoch 1; iter: 600; batch classifier loss: 4.617448; batch adversarial loss: 0.522717\n",
      "epoch 2; iter: 0; batch classifier loss: 3.342254; batch adversarial loss: 0.432621\n",
      "epoch 2; iter: 200; batch classifier loss: 2.335333; batch adversarial loss: 0.379364\n",
      "epoch 2; iter: 400; batch classifier loss: 11.435668; batch adversarial loss: 0.438178\n",
      "epoch 2; iter: 600; batch classifier loss: 4.366572; batch adversarial loss: 0.395385\n",
      "epoch 3; iter: 0; batch classifier loss: 1.841488; batch adversarial loss: 0.363805\n",
      "epoch 3; iter: 200; batch classifier loss: 0.552550; batch adversarial loss: 0.441670\n",
      "epoch 3; iter: 400; batch classifier loss: 0.690243; batch adversarial loss: 0.374065\n",
      "epoch 3; iter: 600; batch classifier loss: 2.311430; batch adversarial loss: 0.414533\n",
      "epoch 4; iter: 0; batch classifier loss: 0.253853; batch adversarial loss: 0.505334\n",
      "epoch 4; iter: 200; batch classifier loss: 0.620094; batch adversarial loss: 0.392058\n",
      "epoch 4; iter: 400; batch classifier loss: 1.868086; batch adversarial loss: 0.300383\n",
      "epoch 4; iter: 600; batch classifier loss: 0.450869; batch adversarial loss: 0.450518\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377769; batch adversarial loss: 0.463577\n",
      "epoch 5; iter: 200; batch classifier loss: 0.398373; batch adversarial loss: 0.329321\n",
      "epoch 5; iter: 400; batch classifier loss: 0.521976; batch adversarial loss: 0.352779\n",
      "epoch 5; iter: 600; batch classifier loss: 0.372786; batch adversarial loss: 0.299885\n",
      "epoch 6; iter: 0; batch classifier loss: 5.496265; batch adversarial loss: 0.376715\n",
      "epoch 6; iter: 200; batch classifier loss: 0.341220; batch adversarial loss: 0.407319\n",
      "epoch 6; iter: 400; batch classifier loss: 0.284011; batch adversarial loss: 0.485216\n",
      "epoch 6; iter: 600; batch classifier loss: 0.341995; batch adversarial loss: 0.407546\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332788; batch adversarial loss: 0.345305\n",
      "epoch 7; iter: 200; batch classifier loss: 0.491184; batch adversarial loss: 0.403488\n",
      "epoch 7; iter: 400; batch classifier loss: 0.455215; batch adversarial loss: 0.456761\n",
      "epoch 7; iter: 600; batch classifier loss: 0.346055; batch adversarial loss: 0.347486\n",
      "epoch 8; iter: 0; batch classifier loss: 0.424910; batch adversarial loss: 0.396309\n",
      "epoch 8; iter: 200; batch classifier loss: 0.308920; batch adversarial loss: 0.410000\n",
      "epoch 8; iter: 400; batch classifier loss: 0.324344; batch adversarial loss: 0.411014\n",
      "epoch 8; iter: 600; batch classifier loss: 0.284858; batch adversarial loss: 0.456830\n",
      "epoch 9; iter: 0; batch classifier loss: 0.482481; batch adversarial loss: 0.377307\n",
      "epoch 9; iter: 200; batch classifier loss: 0.415031; batch adversarial loss: 0.432744\n",
      "epoch 9; iter: 400; batch classifier loss: 0.341368; batch adversarial loss: 0.432750\n",
      "epoch 9; iter: 600; batch classifier loss: 0.403630; batch adversarial loss: 0.400677\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346209; batch adversarial loss: 0.430498\n",
      "epoch 10; iter: 200; batch classifier loss: 0.503585; batch adversarial loss: 0.493497\n",
      "epoch 10; iter: 400; batch classifier loss: 0.358369; batch adversarial loss: 0.417536\n",
      "epoch 10; iter: 600; batch classifier loss: 0.369223; batch adversarial loss: 0.427599\n",
      "epoch 11; iter: 0; batch classifier loss: 0.385856; batch adversarial loss: 0.377987\n",
      "epoch 11; iter: 200; batch classifier loss: 0.421712; batch adversarial loss: 0.426578\n",
      "epoch 11; iter: 400; batch classifier loss: 0.435691; batch adversarial loss: 0.393193\n",
      "epoch 11; iter: 600; batch classifier loss: 0.326140; batch adversarial loss: 0.407278\n",
      "epoch 12; iter: 0; batch classifier loss: 0.353777; batch adversarial loss: 0.374575\n",
      "epoch 12; iter: 200; batch classifier loss: 0.412429; batch adversarial loss: 0.417991\n",
      "epoch 12; iter: 400; batch classifier loss: 0.278408; batch adversarial loss: 0.422164\n",
      "epoch 12; iter: 600; batch classifier loss: 0.285276; batch adversarial loss: 0.314266\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260506; batch adversarial loss: 0.509842\n",
      "epoch 13; iter: 200; batch classifier loss: 0.317033; batch adversarial loss: 0.439467\n",
      "epoch 13; iter: 400; batch classifier loss: 0.431878; batch adversarial loss: 0.346650\n",
      "epoch 13; iter: 600; batch classifier loss: 0.315297; batch adversarial loss: 0.353773\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292453; batch adversarial loss: 0.389666\n",
      "epoch 14; iter: 200; batch classifier loss: 0.492614; batch adversarial loss: 0.341854\n",
      "epoch 14; iter: 400; batch classifier loss: 0.274464; batch adversarial loss: 0.489212\n",
      "epoch 14; iter: 600; batch classifier loss: 0.313319; batch adversarial loss: 0.367152\n",
      "epoch 15; iter: 0; batch classifier loss: 0.246191; batch adversarial loss: 0.542745\n",
      "epoch 15; iter: 200; batch classifier loss: 0.282545; batch adversarial loss: 0.355100\n",
      "epoch 15; iter: 400; batch classifier loss: 0.218110; batch adversarial loss: 0.538625\n",
      "epoch 15; iter: 600; batch classifier loss: 0.364635; batch adversarial loss: 0.291936\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387290; batch adversarial loss: 0.485005\n",
      "epoch 16; iter: 200; batch classifier loss: 0.351852; batch adversarial loss: 0.394437\n",
      "epoch 16; iter: 400; batch classifier loss: 0.395323; batch adversarial loss: 0.378328\n",
      "epoch 16; iter: 600; batch classifier loss: 0.265923; batch adversarial loss: 0.329099\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336841; batch adversarial loss: 0.427377\n",
      "epoch 17; iter: 200; batch classifier loss: 0.270682; batch adversarial loss: 0.315873\n",
      "epoch 17; iter: 400; batch classifier loss: 0.340085; batch adversarial loss: 0.315863\n",
      "epoch 17; iter: 600; batch classifier loss: 0.387551; batch adversarial loss: 0.476661\n",
      "epoch 18; iter: 0; batch classifier loss: 0.261063; batch adversarial loss: 0.322204\n",
      "epoch 18; iter: 200; batch classifier loss: 0.450643; batch adversarial loss: 0.437710\n",
      "epoch 18; iter: 400; batch classifier loss: 0.305661; batch adversarial loss: 0.476145\n",
      "epoch 18; iter: 600; batch classifier loss: 0.438207; batch adversarial loss: 0.542591\n",
      "epoch 19; iter: 0; batch classifier loss: 0.300583; batch adversarial loss: 0.325246\n",
      "epoch 19; iter: 200; batch classifier loss: 0.196413; batch adversarial loss: 0.486330\n",
      "epoch 19; iter: 400; batch classifier loss: 0.286791; batch adversarial loss: 0.436284\n",
      "epoch 19; iter: 600; batch classifier loss: 1.075597; batch adversarial loss: 0.346567\n",
      "epoch 0; iter: 0; batch classifier loss: 19.396303; batch adversarial loss: 0.697901\n",
      "epoch 0; iter: 200; batch classifier loss: 4.800218; batch adversarial loss: 0.626579\n",
      "epoch 0; iter: 400; batch classifier loss: 3.271341; batch adversarial loss: 0.542493\n",
      "epoch 0; iter: 600; batch classifier loss: 0.926436; batch adversarial loss: 0.535764\n",
      "epoch 1; iter: 0; batch classifier loss: 0.944644; batch adversarial loss: 0.566123\n",
      "epoch 1; iter: 200; batch classifier loss: 3.746250; batch adversarial loss: 0.541335\n",
      "epoch 1; iter: 400; batch classifier loss: 1.311618; batch adversarial loss: 0.511533\n",
      "epoch 1; iter: 600; batch classifier loss: 4.493523; batch adversarial loss: 0.423965\n",
      "epoch 2; iter: 0; batch classifier loss: 1.538246; batch adversarial loss: 0.434371\n",
      "epoch 2; iter: 200; batch classifier loss: 4.100563; batch adversarial loss: 0.576232\n",
      "epoch 2; iter: 400; batch classifier loss: 0.788327; batch adversarial loss: 0.557442\n",
      "epoch 2; iter: 600; batch classifier loss: 0.229456; batch adversarial loss: 0.420044\n",
      "epoch 3; iter: 0; batch classifier loss: 0.395235; batch adversarial loss: 0.396309\n",
      "epoch 3; iter: 200; batch classifier loss: 0.701610; batch adversarial loss: 0.379929\n",
      "epoch 3; iter: 400; batch classifier loss: 0.744651; batch adversarial loss: 0.514267\n",
      "epoch 3; iter: 600; batch classifier loss: 0.527062; batch adversarial loss: 0.542209\n",
      "epoch 4; iter: 0; batch classifier loss: 0.484556; batch adversarial loss: 0.491521\n",
      "epoch 4; iter: 200; batch classifier loss: 0.932338; batch adversarial loss: 0.426209\n",
      "epoch 4; iter: 400; batch classifier loss: 0.427900; batch adversarial loss: 0.407947\n",
      "epoch 4; iter: 600; batch classifier loss: 0.368357; batch adversarial loss: 0.525148\n",
      "epoch 5; iter: 0; batch classifier loss: 0.690649; batch adversarial loss: 0.368583\n",
      "epoch 5; iter: 200; batch classifier loss: 0.863235; batch adversarial loss: 0.417444\n",
      "epoch 5; iter: 400; batch classifier loss: 0.443545; batch adversarial loss: 0.389537\n",
      "epoch 5; iter: 600; batch classifier loss: 0.405852; batch adversarial loss: 0.263326\n",
      "epoch 6; iter: 0; batch classifier loss: 0.512394; batch adversarial loss: 0.425717\n",
      "epoch 6; iter: 200; batch classifier loss: 0.482826; batch adversarial loss: 0.412199\n",
      "epoch 6; iter: 400; batch classifier loss: 0.499125; batch adversarial loss: 0.489495\n",
      "epoch 6; iter: 600; batch classifier loss: 0.439239; batch adversarial loss: 0.408886\n",
      "epoch 7; iter: 0; batch classifier loss: 0.475098; batch adversarial loss: 0.400669\n",
      "epoch 7; iter: 200; batch classifier loss: 0.444963; batch adversarial loss: 0.392233\n",
      "epoch 7; iter: 400; batch classifier loss: 0.358068; batch adversarial loss: 0.358035\n",
      "epoch 7; iter: 600; batch classifier loss: 0.379315; batch adversarial loss: 0.425979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.905034; batch adversarial loss: 0.320779\n",
      "epoch 8; iter: 200; batch classifier loss: 0.360624; batch adversarial loss: 0.449734\n",
      "epoch 8; iter: 400; batch classifier loss: 0.368173; batch adversarial loss: 0.396638\n",
      "epoch 8; iter: 600; batch classifier loss: 0.407562; batch adversarial loss: 0.503744\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335032; batch adversarial loss: 0.370247\n",
      "epoch 9; iter: 200; batch classifier loss: 0.568096; batch adversarial loss: 0.382241\n",
      "epoch 9; iter: 400; batch classifier loss: 0.384216; batch adversarial loss: 0.272904\n",
      "epoch 9; iter: 600; batch classifier loss: 0.426503; batch adversarial loss: 0.378775\n",
      "epoch 10; iter: 0; batch classifier loss: 0.277902; batch adversarial loss: 0.446894\n",
      "epoch 10; iter: 200; batch classifier loss: 0.305724; batch adversarial loss: 0.413915\n",
      "epoch 10; iter: 400; batch classifier loss: 0.334128; batch adversarial loss: 0.311804\n",
      "epoch 10; iter: 600; batch classifier loss: 0.235372; batch adversarial loss: 0.428095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.266497; batch adversarial loss: 0.507257\n",
      "epoch 11; iter: 200; batch classifier loss: 0.376610; batch adversarial loss: 0.533591\n",
      "epoch 11; iter: 400; batch classifier loss: 0.251486; batch adversarial loss: 0.425464\n",
      "epoch 11; iter: 600; batch classifier loss: 0.291274; batch adversarial loss: 0.389201\n",
      "epoch 12; iter: 0; batch classifier loss: 0.333661; batch adversarial loss: 0.317200\n",
      "epoch 12; iter: 200; batch classifier loss: 0.370906; batch adversarial loss: 0.456918\n",
      "epoch 12; iter: 400; batch classifier loss: 0.443555; batch adversarial loss: 0.439274\n",
      "epoch 12; iter: 600; batch classifier loss: 0.352731; batch adversarial loss: 0.399791\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307213; batch adversarial loss: 0.481538\n",
      "epoch 13; iter: 200; batch classifier loss: 0.235197; batch adversarial loss: 0.504102\n",
      "epoch 13; iter: 400; batch classifier loss: 0.273923; batch adversarial loss: 0.267609\n",
      "epoch 13; iter: 600; batch classifier loss: 0.283339; batch adversarial loss: 0.402838\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298219; batch adversarial loss: 0.576371\n",
      "epoch 14; iter: 200; batch classifier loss: 0.356699; batch adversarial loss: 0.469440\n",
      "epoch 14; iter: 400; batch classifier loss: 0.325093; batch adversarial loss: 0.484569\n",
      "epoch 14; iter: 600; batch classifier loss: 0.416075; batch adversarial loss: 0.393890\n",
      "epoch 15; iter: 0; batch classifier loss: 0.240272; batch adversarial loss: 0.354490\n",
      "epoch 15; iter: 200; batch classifier loss: 0.305599; batch adversarial loss: 0.478577\n",
      "epoch 15; iter: 400; batch classifier loss: 0.437229; batch adversarial loss: 0.346384\n",
      "epoch 15; iter: 600; batch classifier loss: 0.277512; batch adversarial loss: 0.344280\n",
      "epoch 16; iter: 0; batch classifier loss: 0.313465; batch adversarial loss: 0.296305\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304649; batch adversarial loss: 0.324473\n",
      "epoch 16; iter: 400; batch classifier loss: 0.355228; batch adversarial loss: 0.357195\n",
      "epoch 16; iter: 600; batch classifier loss: 0.318494; batch adversarial loss: 0.403967\n",
      "epoch 17; iter: 0; batch classifier loss: 0.450592; batch adversarial loss: 0.369226\n",
      "epoch 17; iter: 200; batch classifier loss: 0.331371; batch adversarial loss: 0.457528\n",
      "epoch 17; iter: 400; batch classifier loss: 0.370929; batch adversarial loss: 0.341769\n",
      "epoch 17; iter: 600; batch classifier loss: 0.322893; batch adversarial loss: 0.508726\n",
      "epoch 18; iter: 0; batch classifier loss: 0.228319; batch adversarial loss: 0.457082\n",
      "epoch 18; iter: 200; batch classifier loss: 0.374002; batch adversarial loss: 0.480748\n",
      "epoch 18; iter: 400; batch classifier loss: 0.394825; batch adversarial loss: 0.346772\n",
      "epoch 18; iter: 600; batch classifier loss: 0.374178; batch adversarial loss: 0.371036\n",
      "epoch 19; iter: 0; batch classifier loss: 0.380697; batch adversarial loss: 0.438059\n",
      "epoch 19; iter: 200; batch classifier loss: 0.260154; batch adversarial loss: 0.396877\n",
      "epoch 19; iter: 400; batch classifier loss: 0.359795; batch adversarial loss: 0.403805\n",
      "epoch 19; iter: 600; batch classifier loss: 0.536220; batch adversarial loss: 0.293973\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 26.817530; batch adversarial loss: 0.693648\n",
      "epoch 0; iter: 200; batch classifier loss: 33.415306; batch adversarial loss: 0.582551\n",
      "epoch 0; iter: 400; batch classifier loss: 5.760433; batch adversarial loss: 0.584442\n",
      "epoch 0; iter: 600; batch classifier loss: 5.764765; batch adversarial loss: 0.529492\n",
      "epoch 1; iter: 0; batch classifier loss: 7.401922; batch adversarial loss: 0.483536\n",
      "epoch 1; iter: 200; batch classifier loss: 2.042605; batch adversarial loss: 0.464931\n",
      "epoch 1; iter: 400; batch classifier loss: 1.079982; batch adversarial loss: 0.509652\n",
      "epoch 1; iter: 600; batch classifier loss: 0.548608; batch adversarial loss: 0.447132\n",
      "epoch 2; iter: 0; batch classifier loss: 1.066973; batch adversarial loss: 0.434173\n",
      "epoch 2; iter: 200; batch classifier loss: 11.446692; batch adversarial loss: 0.323536\n",
      "epoch 2; iter: 400; batch classifier loss: 1.336215; batch adversarial loss: 0.532356\n",
      "epoch 2; iter: 600; batch classifier loss: 0.777009; batch adversarial loss: 0.388529\n",
      "epoch 3; iter: 0; batch classifier loss: 0.668111; batch adversarial loss: 0.468628\n",
      "epoch 3; iter: 200; batch classifier loss: 6.136064; batch adversarial loss: 0.420840\n",
      "epoch 3; iter: 400; batch classifier loss: 0.807580; batch adversarial loss: 0.489198\n",
      "epoch 3; iter: 600; batch classifier loss: 0.844307; batch adversarial loss: 0.398149\n",
      "epoch 4; iter: 0; batch classifier loss: 0.454336; batch adversarial loss: 0.423894\n",
      "epoch 4; iter: 200; batch classifier loss: 0.581184; batch adversarial loss: 0.564858\n",
      "epoch 4; iter: 400; batch classifier loss: 0.344751; batch adversarial loss: 0.449323\n",
      "epoch 4; iter: 600; batch classifier loss: 0.259843; batch adversarial loss: 0.412941\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420808; batch adversarial loss: 0.315371\n",
      "epoch 5; iter: 200; batch classifier loss: 0.472867; batch adversarial loss: 0.407495\n",
      "epoch 5; iter: 400; batch classifier loss: 0.232562; batch adversarial loss: 0.399404\n",
      "epoch 5; iter: 600; batch classifier loss: 0.442697; batch adversarial loss: 0.329105\n",
      "epoch 6; iter: 0; batch classifier loss: 0.390848; batch adversarial loss: 0.480329\n",
      "epoch 6; iter: 200; batch classifier loss: 0.475269; batch adversarial loss: 0.430435\n",
      "epoch 6; iter: 400; batch classifier loss: 0.379693; batch adversarial loss: 0.357213\n",
      "epoch 6; iter: 600; batch classifier loss: 0.259232; batch adversarial loss: 0.406232\n",
      "epoch 7; iter: 0; batch classifier loss: 0.431892; batch adversarial loss: 0.623311\n",
      "epoch 7; iter: 200; batch classifier loss: 0.461089; batch adversarial loss: 0.514833\n",
      "epoch 7; iter: 400; batch classifier loss: 0.291263; batch adversarial loss: 0.642908\n",
      "epoch 7; iter: 600; batch classifier loss: 0.557293; batch adversarial loss: 0.347770\n",
      "epoch 8; iter: 0; batch classifier loss: 0.382911; batch adversarial loss: 0.420690\n",
      "epoch 8; iter: 200; batch classifier loss: 0.426759; batch adversarial loss: 0.435935\n",
      "epoch 8; iter: 400; batch classifier loss: 0.436508; batch adversarial loss: 0.346125\n",
      "epoch 8; iter: 600; batch classifier loss: 0.279638; batch adversarial loss: 0.408810\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440023; batch adversarial loss: 0.526291\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386523; batch adversarial loss: 0.509740\n",
      "epoch 9; iter: 400; batch classifier loss: 0.291959; batch adversarial loss: 0.501744\n",
      "epoch 9; iter: 600; batch classifier loss: 0.253025; batch adversarial loss: 0.424555\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400281; batch adversarial loss: 0.342293\n",
      "epoch 10; iter: 200; batch classifier loss: 0.347638; batch adversarial loss: 0.343210\n",
      "epoch 10; iter: 400; batch classifier loss: 0.309587; batch adversarial loss: 0.349671\n",
      "epoch 10; iter: 600; batch classifier loss: 0.291559; batch adversarial loss: 0.658580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.312481; batch adversarial loss: 0.489364\n",
      "epoch 11; iter: 200; batch classifier loss: 0.733692; batch adversarial loss: 0.396821\n",
      "epoch 11; iter: 400; batch classifier loss: 0.360555; batch adversarial loss: 0.297083\n",
      "epoch 11; iter: 600; batch classifier loss: 0.223895; batch adversarial loss: 0.424777\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360709; batch adversarial loss: 0.473470\n",
      "epoch 12; iter: 200; batch classifier loss: 0.328875; batch adversarial loss: 0.288293\n",
      "epoch 12; iter: 400; batch classifier loss: 0.305553; batch adversarial loss: 0.458031\n",
      "epoch 12; iter: 600; batch classifier loss: 0.352143; batch adversarial loss: 0.377106\n",
      "epoch 13; iter: 0; batch classifier loss: 0.388761; batch adversarial loss: 0.358136\n",
      "epoch 13; iter: 200; batch classifier loss: 0.258447; batch adversarial loss: 0.437625\n",
      "epoch 13; iter: 400; batch classifier loss: 0.339946; batch adversarial loss: 0.348008\n",
      "epoch 13; iter: 600; batch classifier loss: 0.198765; batch adversarial loss: 0.235178\n",
      "epoch 14; iter: 0; batch classifier loss: 0.447871; batch adversarial loss: 0.409024\n",
      "epoch 14; iter: 200; batch classifier loss: 0.252012; batch adversarial loss: 0.456454\n",
      "epoch 14; iter: 400; batch classifier loss: 0.504221; batch adversarial loss: 0.287977\n",
      "epoch 14; iter: 600; batch classifier loss: 0.444979; batch adversarial loss: 0.515391\n",
      "epoch 15; iter: 0; batch classifier loss: 0.412619; batch adversarial loss: 0.326972\n",
      "epoch 15; iter: 200; batch classifier loss: 0.410817; batch adversarial loss: 0.511573\n",
      "epoch 15; iter: 400; batch classifier loss: 0.518491; batch adversarial loss: 0.434885\n",
      "epoch 15; iter: 600; batch classifier loss: 0.355319; batch adversarial loss: 0.458434\n",
      "epoch 16; iter: 0; batch classifier loss: 0.369859; batch adversarial loss: 0.319449\n",
      "epoch 16; iter: 200; batch classifier loss: 0.460556; batch adversarial loss: 0.372862\n",
      "epoch 16; iter: 400; batch classifier loss: 0.502491; batch adversarial loss: 0.406308\n",
      "epoch 16; iter: 600; batch classifier loss: 0.472450; batch adversarial loss: 0.458608\n",
      "epoch 17; iter: 0; batch classifier loss: 0.518334; batch adversarial loss: 0.457965\n",
      "epoch 17; iter: 200; batch classifier loss: 0.657340; batch adversarial loss: 0.405691\n",
      "epoch 17; iter: 400; batch classifier loss: 0.509057; batch adversarial loss: 0.396364\n",
      "epoch 17; iter: 600; batch classifier loss: 0.431801; batch adversarial loss: 0.459798\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310458; batch adversarial loss: 0.609261\n",
      "epoch 18; iter: 200; batch classifier loss: 0.546010; batch adversarial loss: 0.409161\n",
      "epoch 18; iter: 400; batch classifier loss: 0.461456; batch adversarial loss: 0.430559\n",
      "epoch 18; iter: 600; batch classifier loss: 0.554861; batch adversarial loss: 0.387409\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305153; batch adversarial loss: 0.533435\n",
      "epoch 19; iter: 200; batch classifier loss: 0.439950; batch adversarial loss: 0.401369\n",
      "epoch 19; iter: 400; batch classifier loss: 0.444791; batch adversarial loss: 0.358226\n",
      "epoch 19; iter: 600; batch classifier loss: 0.371949; batch adversarial loss: 0.392527\n",
      "epoch 20; iter: 0; batch classifier loss: 0.573181; batch adversarial loss: 0.321607\n",
      "epoch 20; iter: 200; batch classifier loss: 0.432022; batch adversarial loss: 0.345144\n",
      "epoch 20; iter: 400; batch classifier loss: 0.440072; batch adversarial loss: 0.471997\n",
      "epoch 20; iter: 600; batch classifier loss: 0.495512; batch adversarial loss: 0.532613\n",
      "epoch 21; iter: 0; batch classifier loss: 0.667114; batch adversarial loss: 0.424392\n",
      "epoch 21; iter: 200; batch classifier loss: 0.401301; batch adversarial loss: 0.378985\n",
      "epoch 21; iter: 400; batch classifier loss: 0.457789; batch adversarial loss: 0.349588\n",
      "epoch 21; iter: 600; batch classifier loss: 0.263644; batch adversarial loss: 0.386392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.434625; batch adversarial loss: 0.458689\n",
      "epoch 22; iter: 200; batch classifier loss: 0.509336; batch adversarial loss: 0.457276\n",
      "epoch 22; iter: 400; batch classifier loss: 0.524805; batch adversarial loss: 0.443582\n",
      "epoch 22; iter: 600; batch classifier loss: 0.520667; batch adversarial loss: 0.454397\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439762; batch adversarial loss: 0.483350\n",
      "epoch 23; iter: 200; batch classifier loss: 0.457976; batch adversarial loss: 0.464493\n",
      "epoch 23; iter: 400; batch classifier loss: 0.388877; batch adversarial loss: 0.517376\n",
      "epoch 23; iter: 600; batch classifier loss: 0.401356; batch adversarial loss: 0.372782\n",
      "epoch 24; iter: 0; batch classifier loss: 0.388882; batch adversarial loss: 0.327955\n",
      "epoch 24; iter: 200; batch classifier loss: 0.539086; batch adversarial loss: 0.327971\n",
      "epoch 24; iter: 400; batch classifier loss: 0.376635; batch adversarial loss: 0.348002\n",
      "epoch 24; iter: 600; batch classifier loss: 0.538795; batch adversarial loss: 0.299422\n",
      "epoch 25; iter: 0; batch classifier loss: 0.595537; batch adversarial loss: 0.346611\n",
      "epoch 25; iter: 200; batch classifier loss: 0.531392; batch adversarial loss: 0.325280\n",
      "epoch 25; iter: 400; batch classifier loss: 0.332424; batch adversarial loss: 0.398860\n",
      "epoch 25; iter: 600; batch classifier loss: 0.453722; batch adversarial loss: 0.345083\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435565; batch adversarial loss: 0.371703\n",
      "epoch 26; iter: 200; batch classifier loss: 0.398795; batch adversarial loss: 0.522762\n",
      "epoch 26; iter: 400; batch classifier loss: 0.399179; batch adversarial loss: 0.375750\n",
      "epoch 26; iter: 600; batch classifier loss: 0.417114; batch adversarial loss: 0.384321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482401; batch adversarial loss: 0.513368\n",
      "epoch 27; iter: 200; batch classifier loss: 0.588594; batch adversarial loss: 0.328362\n",
      "epoch 27; iter: 400; batch classifier loss: 0.576046; batch adversarial loss: 0.343461\n",
      "epoch 27; iter: 600; batch classifier loss: 0.349753; batch adversarial loss: 0.317762\n",
      "epoch 28; iter: 0; batch classifier loss: 0.384690; batch adversarial loss: 0.376208\n",
      "epoch 28; iter: 200; batch classifier loss: 0.407010; batch adversarial loss: 0.476357\n",
      "epoch 28; iter: 400; batch classifier loss: 0.582973; batch adversarial loss: 0.479939\n",
      "epoch 28; iter: 600; batch classifier loss: 0.648280; batch adversarial loss: 0.321653\n",
      "epoch 29; iter: 0; batch classifier loss: 0.327131; batch adversarial loss: 0.400724\n",
      "epoch 29; iter: 200; batch classifier loss: 0.671794; batch adversarial loss: 0.640774\n",
      "epoch 29; iter: 400; batch classifier loss: 0.553212; batch adversarial loss: 0.345292\n",
      "epoch 29; iter: 600; batch classifier loss: 0.514230; batch adversarial loss: 0.472586\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439293; batch adversarial loss: 0.396501\n",
      "epoch 30; iter: 200; batch classifier loss: 0.489959; batch adversarial loss: 0.482408\n",
      "epoch 30; iter: 400; batch classifier loss: 0.526296; batch adversarial loss: 0.416676\n",
      "epoch 30; iter: 600; batch classifier loss: 0.304577; batch adversarial loss: 0.463753\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484988; batch adversarial loss: 0.453111\n",
      "epoch 31; iter: 200; batch classifier loss: 0.421739; batch adversarial loss: 0.215126\n",
      "epoch 31; iter: 400; batch classifier loss: 0.434612; batch adversarial loss: 0.376904\n",
      "epoch 31; iter: 600; batch classifier loss: 0.656196; batch adversarial loss: 0.375515\n",
      "epoch 32; iter: 0; batch classifier loss: 0.668404; batch adversarial loss: 0.404246\n",
      "epoch 32; iter: 200; batch classifier loss: 0.523160; batch adversarial loss: 0.369156\n",
      "epoch 32; iter: 400; batch classifier loss: 0.413809; batch adversarial loss: 0.489000\n",
      "epoch 32; iter: 600; batch classifier loss: 0.808526; batch adversarial loss: 0.235006\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415611; batch adversarial loss: 0.458508\n",
      "epoch 33; iter: 200; batch classifier loss: 0.605104; batch adversarial loss: 0.299783\n",
      "epoch 33; iter: 400; batch classifier loss: 0.340212; batch adversarial loss: 0.400332\n",
      "epoch 33; iter: 600; batch classifier loss: 0.666916; batch adversarial loss: 0.436302\n",
      "epoch 34; iter: 0; batch classifier loss: 0.565679; batch adversarial loss: 0.456780\n",
      "epoch 34; iter: 200; batch classifier loss: 0.675573; batch adversarial loss: 0.384955\n",
      "epoch 34; iter: 400; batch classifier loss: 0.524019; batch adversarial loss: 0.436941\n",
      "epoch 34; iter: 600; batch classifier loss: 0.753922; batch adversarial loss: 0.214859\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470348; batch adversarial loss: 0.369553\n",
      "epoch 35; iter: 200; batch classifier loss: 0.656837; batch adversarial loss: 0.428888\n",
      "epoch 35; iter: 400; batch classifier loss: 0.477824; batch adversarial loss: 0.372921\n",
      "epoch 35; iter: 600; batch classifier loss: 0.537671; batch adversarial loss: 0.395495\n",
      "epoch 36; iter: 0; batch classifier loss: 0.659606; batch adversarial loss: 0.453571\n",
      "epoch 36; iter: 200; batch classifier loss: 0.523920; batch adversarial loss: 0.340034\n",
      "epoch 36; iter: 400; batch classifier loss: 0.358295; batch adversarial loss: 0.571700\n",
      "epoch 36; iter: 600; batch classifier loss: 0.712605; batch adversarial loss: 0.400284\n",
      "epoch 37; iter: 0; batch classifier loss: 0.456824; batch adversarial loss: 0.426626\n",
      "epoch 37; iter: 200; batch classifier loss: 0.604933; batch adversarial loss: 0.297556\n",
      "epoch 37; iter: 400; batch classifier loss: 0.451706; batch adversarial loss: 0.548544\n",
      "epoch 37; iter: 600; batch classifier loss: 0.492808; batch adversarial loss: 0.505389\n",
      "epoch 38; iter: 0; batch classifier loss: 0.552823; batch adversarial loss: 0.500222\n",
      "epoch 38; iter: 200; batch classifier loss: 0.644410; batch adversarial loss: 0.452426\n",
      "epoch 38; iter: 400; batch classifier loss: 0.503084; batch adversarial loss: 0.350862\n",
      "epoch 38; iter: 600; batch classifier loss: 0.335359; batch adversarial loss: 0.400216\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315767; batch adversarial loss: 0.512417\n",
      "epoch 39; iter: 200; batch classifier loss: 0.759719; batch adversarial loss: 0.348515\n",
      "epoch 39; iter: 400; batch classifier loss: 0.535087; batch adversarial loss: 0.545146\n",
      "epoch 39; iter: 600; batch classifier loss: 0.306058; batch adversarial loss: 0.316499\n",
      "epoch 40; iter: 0; batch classifier loss: 0.726273; batch adversarial loss: 0.423779\n",
      "epoch 40; iter: 200; batch classifier loss: 0.204210; batch adversarial loss: 0.595491\n",
      "epoch 40; iter: 400; batch classifier loss: 0.440285; batch adversarial loss: 0.346254\n",
      "epoch 40; iter: 600; batch classifier loss: 0.477750; batch adversarial loss: 0.343033\n",
      "epoch 41; iter: 0; batch classifier loss: 0.632623; batch adversarial loss: 0.236934\n",
      "epoch 41; iter: 200; batch classifier loss: 0.837786; batch adversarial loss: 0.408299\n",
      "epoch 41; iter: 400; batch classifier loss: 0.594174; batch adversarial loss: 0.374645\n",
      "epoch 41; iter: 600; batch classifier loss: 0.436058; batch adversarial loss: 0.549715\n",
      "epoch 42; iter: 0; batch classifier loss: 0.556495; batch adversarial loss: 0.425424\n",
      "epoch 42; iter: 200; batch classifier loss: 0.606508; batch adversarial loss: 0.451452\n",
      "epoch 42; iter: 400; batch classifier loss: 0.543846; batch adversarial loss: 0.352634\n",
      "epoch 42; iter: 600; batch classifier loss: 0.360900; batch adversarial loss: 0.497434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.575726; batch adversarial loss: 0.424256\n",
      "epoch 43; iter: 200; batch classifier loss: 0.437943; batch adversarial loss: 0.325558\n",
      "epoch 43; iter: 400; batch classifier loss: 0.426691; batch adversarial loss: 0.480800\n",
      "epoch 43; iter: 600; batch classifier loss: 0.321388; batch adversarial loss: 0.528436\n",
      "epoch 44; iter: 0; batch classifier loss: 0.790201; batch adversarial loss: 0.263803\n",
      "epoch 44; iter: 200; batch classifier loss: 0.768177; batch adversarial loss: 0.534449\n",
      "epoch 44; iter: 400; batch classifier loss: 0.696576; batch adversarial loss: 0.511192\n",
      "epoch 44; iter: 600; batch classifier loss: 0.429001; batch adversarial loss: 0.315386\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405096; batch adversarial loss: 0.407884\n",
      "epoch 45; iter: 200; batch classifier loss: 0.654710; batch adversarial loss: 0.469959\n",
      "epoch 45; iter: 400; batch classifier loss: 0.573169; batch adversarial loss: 0.408591\n",
      "epoch 45; iter: 600; batch classifier loss: 0.329743; batch adversarial loss: 0.350569\n",
      "epoch 46; iter: 0; batch classifier loss: 0.641519; batch adversarial loss: 0.345862\n",
      "epoch 46; iter: 200; batch classifier loss: 0.459720; batch adversarial loss: 0.508329\n",
      "epoch 46; iter: 400; batch classifier loss: 0.496787; batch adversarial loss: 0.450130\n",
      "epoch 46; iter: 600; batch classifier loss: 0.478205; batch adversarial loss: 0.289072\n",
      "epoch 47; iter: 0; batch classifier loss: 0.722435; batch adversarial loss: 0.345665\n",
      "epoch 47; iter: 200; batch classifier loss: 0.694011; batch adversarial loss: 0.462047\n",
      "epoch 47; iter: 400; batch classifier loss: 0.448985; batch adversarial loss: 0.345618\n",
      "epoch 47; iter: 600; batch classifier loss: 0.588004; batch adversarial loss: 0.379372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.643290; batch adversarial loss: 0.436942\n",
      "epoch 48; iter: 200; batch classifier loss: 0.633329; batch adversarial loss: 0.368153\n",
      "epoch 48; iter: 400; batch classifier loss: 0.538767; batch adversarial loss: 0.399791\n",
      "epoch 48; iter: 600; batch classifier loss: 0.463387; batch adversarial loss: 0.342529\n",
      "epoch 49; iter: 0; batch classifier loss: 0.580336; batch adversarial loss: 0.455339\n",
      "epoch 49; iter: 200; batch classifier loss: 0.259823; batch adversarial loss: 0.473681\n",
      "epoch 49; iter: 400; batch classifier loss: 0.895810; batch adversarial loss: 0.367687\n",
      "epoch 49; iter: 600; batch classifier loss: 0.630662; batch adversarial loss: 0.544773\n",
      "epoch 0; iter: 0; batch classifier loss: 5.724742; batch adversarial loss: 1.048304\n",
      "epoch 0; iter: 200; batch classifier loss: 5.664647; batch adversarial loss: 0.930056\n",
      "epoch 0; iter: 400; batch classifier loss: 3.151639; batch adversarial loss: 0.664185\n",
      "epoch 0; iter: 600; batch classifier loss: 15.098186; batch adversarial loss: 0.566624\n",
      "epoch 1; iter: 0; batch classifier loss: 2.089386; batch adversarial loss: 0.538849\n",
      "epoch 1; iter: 200; batch classifier loss: 5.675953; batch adversarial loss: 0.507259\n",
      "epoch 1; iter: 400; batch classifier loss: 0.951700; batch adversarial loss: 0.464664\n",
      "epoch 1; iter: 600; batch classifier loss: 2.841094; batch adversarial loss: 0.430127\n",
      "epoch 2; iter: 0; batch classifier loss: 3.749399; batch adversarial loss: 0.579462\n",
      "epoch 2; iter: 200; batch classifier loss: 3.575888; batch adversarial loss: 0.497734\n",
      "epoch 2; iter: 400; batch classifier loss: 1.004791; batch adversarial loss: 0.435780\n",
      "epoch 2; iter: 600; batch classifier loss: 7.114219; batch adversarial loss: 0.426715\n",
      "epoch 3; iter: 0; batch classifier loss: 1.209719; batch adversarial loss: 0.416874\n",
      "epoch 3; iter: 200; batch classifier loss: 0.260299; batch adversarial loss: 0.408674\n",
      "epoch 3; iter: 400; batch classifier loss: 0.489760; batch adversarial loss: 0.502264\n",
      "epoch 3; iter: 600; batch classifier loss: 0.378191; batch adversarial loss: 0.390124\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399795; batch adversarial loss: 0.403469\n",
      "epoch 4; iter: 200; batch classifier loss: 0.382974; batch adversarial loss: 0.429513\n",
      "epoch 4; iter: 400; batch classifier loss: 1.622024; batch adversarial loss: 0.525634\n",
      "epoch 4; iter: 600; batch classifier loss: 0.872495; batch adversarial loss: 0.399682\n",
      "epoch 5; iter: 0; batch classifier loss: 1.536544; batch adversarial loss: 0.457545\n",
      "epoch 5; iter: 200; batch classifier loss: 1.524882; batch adversarial loss: 0.377787\n",
      "epoch 5; iter: 400; batch classifier loss: 0.418839; batch adversarial loss: 0.400256\n",
      "epoch 5; iter: 600; batch classifier loss: 0.692526; batch adversarial loss: 0.459861\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480447; batch adversarial loss: 0.320763\n",
      "epoch 6; iter: 200; batch classifier loss: 0.355934; batch adversarial loss: 0.428406\n",
      "epoch 6; iter: 400; batch classifier loss: 0.890223; batch adversarial loss: 0.291710\n",
      "epoch 6; iter: 600; batch classifier loss: 0.740102; batch adversarial loss: 0.356868\n",
      "epoch 7; iter: 0; batch classifier loss: 0.618296; batch adversarial loss: 0.426156\n",
      "epoch 7; iter: 200; batch classifier loss: 0.601798; batch adversarial loss: 0.323567\n",
      "epoch 7; iter: 400; batch classifier loss: 0.427125; batch adversarial loss: 0.532061\n",
      "epoch 7; iter: 600; batch classifier loss: 0.373449; batch adversarial loss: 0.341557\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432203; batch adversarial loss: 0.319171\n",
      "epoch 8; iter: 200; batch classifier loss: 0.233181; batch adversarial loss: 0.381613\n",
      "epoch 8; iter: 400; batch classifier loss: 0.228135; batch adversarial loss: 0.475180\n",
      "epoch 8; iter: 600; batch classifier loss: 0.402473; batch adversarial loss: 0.404414\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381169; batch adversarial loss: 0.451649\n",
      "epoch 9; iter: 200; batch classifier loss: 0.445113; batch adversarial loss: 0.471876\n",
      "epoch 9; iter: 400; batch classifier loss: 0.267292; batch adversarial loss: 0.470478\n",
      "epoch 9; iter: 600; batch classifier loss: 0.336840; batch adversarial loss: 0.544395\n",
      "epoch 10; iter: 0; batch classifier loss: 0.465510; batch adversarial loss: 0.427116\n",
      "epoch 10; iter: 200; batch classifier loss: 0.353529; batch adversarial loss: 0.451473\n",
      "epoch 10; iter: 400; batch classifier loss: 0.422295; batch adversarial loss: 0.291615\n",
      "epoch 10; iter: 600; batch classifier loss: 0.367704; batch adversarial loss: 0.234864\n",
      "epoch 11; iter: 0; batch classifier loss: 0.296217; batch adversarial loss: 0.515994\n",
      "epoch 11; iter: 200; batch classifier loss: 0.348692; batch adversarial loss: 0.401296\n",
      "epoch 11; iter: 400; batch classifier loss: 0.673074; batch adversarial loss: 0.411579\n",
      "epoch 11; iter: 600; batch classifier loss: 0.278419; batch adversarial loss: 0.431020\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359910; batch adversarial loss: 0.474897\n",
      "epoch 12; iter: 200; batch classifier loss: 0.348929; batch adversarial loss: 0.464504\n",
      "epoch 12; iter: 400; batch classifier loss: 0.267246; batch adversarial loss: 0.566569\n",
      "epoch 12; iter: 600; batch classifier loss: 0.413010; batch adversarial loss: 0.611287\n",
      "epoch 13; iter: 0; batch classifier loss: 0.345378; batch adversarial loss: 0.511394\n",
      "epoch 13; iter: 200; batch classifier loss: 0.273109; batch adversarial loss: 0.477016\n",
      "epoch 13; iter: 400; batch classifier loss: 0.301977; batch adversarial loss: 0.490030\n",
      "epoch 13; iter: 600; batch classifier loss: 0.405378; batch adversarial loss: 0.401091\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343044; batch adversarial loss: 0.592047\n",
      "epoch 14; iter: 200; batch classifier loss: 0.495815; batch adversarial loss: 0.454826\n",
      "epoch 14; iter: 400; batch classifier loss: 0.529445; batch adversarial loss: 0.400383\n",
      "epoch 14; iter: 600; batch classifier loss: 0.329896; batch adversarial loss: 0.348934\n",
      "epoch 15; iter: 0; batch classifier loss: 0.482282; batch adversarial loss: 0.447247\n",
      "epoch 15; iter: 200; batch classifier loss: 0.545380; batch adversarial loss: 0.424218\n",
      "epoch 15; iter: 400; batch classifier loss: 0.433286; batch adversarial loss: 0.568282\n",
      "epoch 15; iter: 600; batch classifier loss: 0.319400; batch adversarial loss: 0.339322\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334412; batch adversarial loss: 0.236472\n",
      "epoch 16; iter: 200; batch classifier loss: 0.303475; batch adversarial loss: 0.402379\n",
      "epoch 16; iter: 400; batch classifier loss: 0.284152; batch adversarial loss: 0.369037\n",
      "epoch 16; iter: 600; batch classifier loss: 0.481512; batch adversarial loss: 0.367769\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372952; batch adversarial loss: 0.418456\n",
      "epoch 17; iter: 200; batch classifier loss: 0.303466; batch adversarial loss: 0.614262\n",
      "epoch 17; iter: 400; batch classifier loss: 0.334937; batch adversarial loss: 0.351099\n",
      "epoch 17; iter: 600; batch classifier loss: 0.291976; batch adversarial loss: 0.493540\n",
      "epoch 18; iter: 0; batch classifier loss: 0.388756; batch adversarial loss: 0.431180\n",
      "epoch 18; iter: 200; batch classifier loss: 0.384481; batch adversarial loss: 0.409981\n",
      "epoch 18; iter: 400; batch classifier loss: 0.394538; batch adversarial loss: 0.545314\n",
      "epoch 18; iter: 600; batch classifier loss: 0.517805; batch adversarial loss: 0.546436\n",
      "epoch 19; iter: 0; batch classifier loss: 0.257518; batch adversarial loss: 0.478134\n",
      "epoch 19; iter: 200; batch classifier loss: 0.405225; batch adversarial loss: 0.489562\n",
      "epoch 19; iter: 400; batch classifier loss: 0.329729; batch adversarial loss: 0.348607\n",
      "epoch 19; iter: 600; batch classifier loss: 0.364381; batch adversarial loss: 0.371530\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325989; batch adversarial loss: 0.427526\n",
      "epoch 20; iter: 200; batch classifier loss: 0.333225; batch adversarial loss: 0.398107\n",
      "epoch 20; iter: 400; batch classifier loss: 0.257359; batch adversarial loss: 0.398622\n",
      "epoch 20; iter: 600; batch classifier loss: 0.313356; batch adversarial loss: 0.430349\n",
      "epoch 21; iter: 0; batch classifier loss: 0.382731; batch adversarial loss: 0.480015\n",
      "epoch 21; iter: 200; batch classifier loss: 0.374518; batch adversarial loss: 0.346277\n",
      "epoch 21; iter: 400; batch classifier loss: 0.298175; batch adversarial loss: 0.496942\n",
      "epoch 21; iter: 600; batch classifier loss: 0.338769; batch adversarial loss: 0.318922\n",
      "epoch 22; iter: 0; batch classifier loss: 0.272458; batch adversarial loss: 0.442484\n",
      "epoch 22; iter: 200; batch classifier loss: 0.342860; batch adversarial loss: 0.404485\n",
      "epoch 22; iter: 400; batch classifier loss: 0.386614; batch adversarial loss: 0.457066\n",
      "epoch 22; iter: 600; batch classifier loss: 0.293024; batch adversarial loss: 0.398190\n",
      "epoch 23; iter: 0; batch classifier loss: 0.315546; batch adversarial loss: 0.317691\n",
      "epoch 23; iter: 200; batch classifier loss: 0.311333; batch adversarial loss: 0.466393\n",
      "epoch 23; iter: 400; batch classifier loss: 0.503280; batch adversarial loss: 0.344286\n",
      "epoch 23; iter: 600; batch classifier loss: 0.427164; batch adversarial loss: 0.374748\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462132; batch adversarial loss: 0.403831\n",
      "epoch 24; iter: 200; batch classifier loss: 0.439075; batch adversarial loss: 0.356623\n",
      "epoch 24; iter: 400; batch classifier loss: 0.431287; batch adversarial loss: 0.296133\n",
      "epoch 24; iter: 600; batch classifier loss: 0.388496; batch adversarial loss: 0.237903\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339860; batch adversarial loss: 0.511176\n",
      "epoch 25; iter: 200; batch classifier loss: 0.378708; batch adversarial loss: 0.403045\n",
      "epoch 25; iter: 400; batch classifier loss: 0.357572; batch adversarial loss: 0.507058\n",
      "epoch 25; iter: 600; batch classifier loss: 0.331509; batch adversarial loss: 0.717509\n",
      "epoch 26; iter: 0; batch classifier loss: 0.336521; batch adversarial loss: 0.406875\n",
      "epoch 26; iter: 200; batch classifier loss: 0.279666; batch adversarial loss: 0.374469\n",
      "epoch 26; iter: 400; batch classifier loss: 0.471081; batch adversarial loss: 0.379003\n",
      "epoch 26; iter: 600; batch classifier loss: 0.372478; batch adversarial loss: 0.479283\n",
      "epoch 27; iter: 0; batch classifier loss: 0.546431; batch adversarial loss: 0.489631\n",
      "epoch 27; iter: 200; batch classifier loss: 0.319420; batch adversarial loss: 0.564029\n",
      "epoch 27; iter: 400; batch classifier loss: 0.387568; batch adversarial loss: 0.382688\n",
      "epoch 27; iter: 600; batch classifier loss: 0.325539; batch adversarial loss: 0.528540\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368459; batch adversarial loss: 0.266007\n",
      "epoch 28; iter: 200; batch classifier loss: 0.371315; batch adversarial loss: 0.393017\n",
      "epoch 28; iter: 400; batch classifier loss: 0.509623; batch adversarial loss: 0.276867\n",
      "epoch 28; iter: 600; batch classifier loss: 0.369137; batch adversarial loss: 0.542052\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522552; batch adversarial loss: 0.399174\n",
      "epoch 29; iter: 200; batch classifier loss: 0.359470; batch adversarial loss: 0.316762\n",
      "epoch 29; iter: 400; batch classifier loss: 0.340786; batch adversarial loss: 0.534843\n",
      "epoch 29; iter: 600; batch classifier loss: 0.388985; batch adversarial loss: 0.342128\n",
      "epoch 30; iter: 0; batch classifier loss: 0.490243; batch adversarial loss: 0.453375\n",
      "epoch 30; iter: 200; batch classifier loss: 0.301979; batch adversarial loss: 0.448959\n",
      "epoch 30; iter: 400; batch classifier loss: 0.494513; batch adversarial loss: 0.429566\n",
      "epoch 30; iter: 600; batch classifier loss: 0.347667; batch adversarial loss: 0.488121\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475491; batch adversarial loss: 0.341715\n",
      "epoch 31; iter: 200; batch classifier loss: 0.244375; batch adversarial loss: 0.406505\n",
      "epoch 31; iter: 400; batch classifier loss: 0.391301; batch adversarial loss: 0.517963\n",
      "epoch 31; iter: 600; batch classifier loss: 0.472455; batch adversarial loss: 0.459408\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499692; batch adversarial loss: 0.405341\n",
      "epoch 32; iter: 200; batch classifier loss: 0.349848; batch adversarial loss: 0.513131\n",
      "epoch 32; iter: 400; batch classifier loss: 0.475759; batch adversarial loss: 0.422427\n",
      "epoch 32; iter: 600; batch classifier loss: 0.347316; batch adversarial loss: 0.260297\n",
      "epoch 33; iter: 0; batch classifier loss: 0.349325; batch adversarial loss: 0.321120\n",
      "epoch 33; iter: 200; batch classifier loss: 0.249895; batch adversarial loss: 0.380266\n",
      "epoch 33; iter: 400; batch classifier loss: 0.336432; batch adversarial loss: 0.493232\n",
      "epoch 33; iter: 600; batch classifier loss: 0.501716; batch adversarial loss: 0.426788\n",
      "epoch 34; iter: 0; batch classifier loss: 0.413598; batch adversarial loss: 0.327407\n",
      "epoch 34; iter: 200; batch classifier loss: 0.271297; batch adversarial loss: 0.434109\n",
      "epoch 34; iter: 400; batch classifier loss: 0.427770; batch adversarial loss: 0.640504\n",
      "epoch 34; iter: 600; batch classifier loss: 0.224406; batch adversarial loss: 0.532864\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410137; batch adversarial loss: 0.483244\n",
      "epoch 35; iter: 200; batch classifier loss: 0.524732; batch adversarial loss: 0.442851\n",
      "epoch 35; iter: 400; batch classifier loss: 0.502695; batch adversarial loss: 0.412834\n",
      "epoch 35; iter: 600; batch classifier loss: 0.276108; batch adversarial loss: 0.415836\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391971; batch adversarial loss: 0.268193\n",
      "epoch 36; iter: 200; batch classifier loss: 0.436837; batch adversarial loss: 0.436089\n",
      "epoch 36; iter: 400; batch classifier loss: 0.521026; batch adversarial loss: 0.573004\n",
      "epoch 36; iter: 600; batch classifier loss: 0.626029; batch adversarial loss: 0.320036\n",
      "epoch 37; iter: 0; batch classifier loss: 0.342227; batch adversarial loss: 0.380540\n",
      "epoch 37; iter: 200; batch classifier loss: 0.536351; batch adversarial loss: 0.425869\n",
      "epoch 37; iter: 400; batch classifier loss: 0.494562; batch adversarial loss: 0.407036\n",
      "epoch 37; iter: 600; batch classifier loss: 0.254619; batch adversarial loss: 0.475715\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261863; batch adversarial loss: 0.367908\n",
      "epoch 38; iter: 200; batch classifier loss: 0.434169; batch adversarial loss: 0.355265\n",
      "epoch 38; iter: 400; batch classifier loss: 0.349111; batch adversarial loss: 0.592603\n",
      "epoch 38; iter: 600; batch classifier loss: 0.278520; batch adversarial loss: 0.403574\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490821; batch adversarial loss: 0.420469\n",
      "epoch 39; iter: 200; batch classifier loss: 0.419246; batch adversarial loss: 0.510232\n",
      "epoch 39; iter: 400; batch classifier loss: 0.249351; batch adversarial loss: 0.486686\n",
      "epoch 39; iter: 600; batch classifier loss: 0.469254; batch adversarial loss: 0.399327\n",
      "epoch 40; iter: 0; batch classifier loss: 0.448237; batch adversarial loss: 0.466723\n",
      "epoch 40; iter: 200; batch classifier loss: 0.447889; batch adversarial loss: 0.463032\n",
      "epoch 40; iter: 400; batch classifier loss: 0.323523; batch adversarial loss: 0.503921\n",
      "epoch 40; iter: 600; batch classifier loss: 0.380874; batch adversarial loss: 0.454969\n",
      "epoch 41; iter: 0; batch classifier loss: 0.517162; batch adversarial loss: 0.456769\n",
      "epoch 41; iter: 200; batch classifier loss: 0.371996; batch adversarial loss: 0.407285\n",
      "epoch 41; iter: 400; batch classifier loss: 0.516409; batch adversarial loss: 0.430182\n",
      "epoch 41; iter: 600; batch classifier loss: 0.318611; batch adversarial loss: 0.504580\n",
      "epoch 42; iter: 0; batch classifier loss: 0.458348; batch adversarial loss: 0.359172\n",
      "epoch 42; iter: 200; batch classifier loss: 0.404615; batch adversarial loss: 0.422471\n",
      "epoch 42; iter: 400; batch classifier loss: 0.453216; batch adversarial loss: 0.431820\n",
      "epoch 42; iter: 600; batch classifier loss: 0.398181; batch adversarial loss: 0.417430\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394091; batch adversarial loss: 0.455811\n",
      "epoch 43; iter: 200; batch classifier loss: 0.417637; batch adversarial loss: 0.426709\n",
      "epoch 43; iter: 400; batch classifier loss: 0.326575; batch adversarial loss: 0.402112\n",
      "epoch 43; iter: 600; batch classifier loss: 0.275018; batch adversarial loss: 0.440591\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490733; batch adversarial loss: 0.435247\n",
      "epoch 44; iter: 200; batch classifier loss: 0.466052; batch adversarial loss: 0.422721\n",
      "epoch 44; iter: 400; batch classifier loss: 0.282320; batch adversarial loss: 0.375044\n",
      "epoch 44; iter: 600; batch classifier loss: 0.398301; batch adversarial loss: 0.572385\n",
      "epoch 45; iter: 0; batch classifier loss: 0.343235; batch adversarial loss: 0.421351\n",
      "epoch 45; iter: 200; batch classifier loss: 0.563865; batch adversarial loss: 0.392456\n",
      "epoch 45; iter: 400; batch classifier loss: 0.397383; batch adversarial loss: 0.397064\n",
      "epoch 45; iter: 600; batch classifier loss: 0.466112; batch adversarial loss: 0.260595\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378997; batch adversarial loss: 0.597377\n",
      "epoch 46; iter: 200; batch classifier loss: 0.570394; batch adversarial loss: 0.350266\n",
      "epoch 46; iter: 400; batch classifier loss: 0.245492; batch adversarial loss: 0.417404\n",
      "epoch 46; iter: 600; batch classifier loss: 0.487189; batch adversarial loss: 0.370973\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405458; batch adversarial loss: 0.488647\n",
      "epoch 47; iter: 200; batch classifier loss: 0.569277; batch adversarial loss: 0.508870\n",
      "epoch 47; iter: 400; batch classifier loss: 0.422328; batch adversarial loss: 0.374116\n",
      "epoch 47; iter: 600; batch classifier loss: 0.491117; batch adversarial loss: 0.370992\n",
      "epoch 48; iter: 0; batch classifier loss: 0.547480; batch adversarial loss: 0.266619\n",
      "epoch 48; iter: 200; batch classifier loss: 0.412358; batch adversarial loss: 0.295311\n",
      "epoch 48; iter: 400; batch classifier loss: 0.445772; batch adversarial loss: 0.267530\n",
      "epoch 48; iter: 600; batch classifier loss: 0.239288; batch adversarial loss: 0.371012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.402523; batch adversarial loss: 0.376664\n",
      "epoch 49; iter: 200; batch classifier loss: 0.384131; batch adversarial loss: 0.514984\n",
      "epoch 49; iter: 400; batch classifier loss: 0.379293; batch adversarial loss: 0.544943\n",
      "epoch 49; iter: 600; batch classifier loss: 0.249133; batch adversarial loss: 0.306007\n",
      "epoch 0; iter: 0; batch classifier loss: 4.417654; batch adversarial loss: 0.647656\n",
      "epoch 0; iter: 200; batch classifier loss: 2.323628; batch adversarial loss: 0.648173\n",
      "epoch 0; iter: 400; batch classifier loss: 18.011543; batch adversarial loss: 0.590737\n",
      "epoch 0; iter: 600; batch classifier loss: 7.805714; batch adversarial loss: 0.493223\n",
      "epoch 1; iter: 0; batch classifier loss: 5.372080; batch adversarial loss: 0.531084\n",
      "epoch 1; iter: 200; batch classifier loss: 4.983977; batch adversarial loss: 0.504417\n",
      "epoch 1; iter: 400; batch classifier loss: 1.221628; batch adversarial loss: 0.477219\n",
      "epoch 1; iter: 600; batch classifier loss: 0.964952; batch adversarial loss: 0.579195\n",
      "epoch 2; iter: 0; batch classifier loss: 0.858514; batch adversarial loss: 0.539731\n",
      "epoch 2; iter: 200; batch classifier loss: 0.462781; batch adversarial loss: 0.620712\n",
      "epoch 2; iter: 400; batch classifier loss: 0.588346; batch adversarial loss: 0.326322\n",
      "epoch 2; iter: 600; batch classifier loss: 0.382206; batch adversarial loss: 0.445099\n",
      "epoch 3; iter: 0; batch classifier loss: 1.227094; batch adversarial loss: 0.432095\n",
      "epoch 3; iter: 200; batch classifier loss: 0.341881; batch adversarial loss: 0.570393\n",
      "epoch 3; iter: 400; batch classifier loss: 0.264398; batch adversarial loss: 0.570220\n",
      "epoch 3; iter: 600; batch classifier loss: 1.326744; batch adversarial loss: 0.450386\n",
      "epoch 4; iter: 0; batch classifier loss: 0.493985; batch adversarial loss: 0.599186\n",
      "epoch 4; iter: 200; batch classifier loss: 0.357661; batch adversarial loss: 0.350561\n",
      "epoch 4; iter: 400; batch classifier loss: 0.292194; batch adversarial loss: 0.361130\n",
      "epoch 4; iter: 600; batch classifier loss: 0.614626; batch adversarial loss: 0.329761\n",
      "epoch 5; iter: 0; batch classifier loss: 0.913216; batch adversarial loss: 0.418843\n",
      "epoch 5; iter: 200; batch classifier loss: 0.493306; batch adversarial loss: 0.386004\n",
      "epoch 5; iter: 400; batch classifier loss: 0.790324; batch adversarial loss: 0.499854\n",
      "epoch 5; iter: 600; batch classifier loss: 0.545378; batch adversarial loss: 0.410853\n",
      "epoch 6; iter: 0; batch classifier loss: 0.967926; batch adversarial loss: 0.413842\n",
      "epoch 6; iter: 200; batch classifier loss: 0.329455; batch adversarial loss: 0.613790\n",
      "epoch 6; iter: 400; batch classifier loss: 0.423877; batch adversarial loss: 0.319394\n",
      "epoch 6; iter: 600; batch classifier loss: 0.582192; batch adversarial loss: 0.400503\n",
      "epoch 7; iter: 0; batch classifier loss: 0.282461; batch adversarial loss: 0.382193\n",
      "epoch 7; iter: 200; batch classifier loss: 0.453250; batch adversarial loss: 0.350244\n",
      "epoch 7; iter: 400; batch classifier loss: 0.243554; batch adversarial loss: 0.420941\n",
      "epoch 7; iter: 600; batch classifier loss: 0.332088; batch adversarial loss: 0.598851\n",
      "epoch 8; iter: 0; batch classifier loss: 0.496052; batch adversarial loss: 0.472048\n",
      "epoch 8; iter: 200; batch classifier loss: 0.416103; batch adversarial loss: 0.358448\n",
      "epoch 8; iter: 400; batch classifier loss: 0.298076; batch adversarial loss: 0.426807\n",
      "epoch 8; iter: 600; batch classifier loss: 0.467931; batch adversarial loss: 0.427677\n",
      "epoch 9; iter: 0; batch classifier loss: 0.339819; batch adversarial loss: 0.457122\n",
      "epoch 9; iter: 200; batch classifier loss: 0.423447; batch adversarial loss: 0.508325\n",
      "epoch 9; iter: 400; batch classifier loss: 0.288108; batch adversarial loss: 0.378004\n",
      "epoch 9; iter: 600; batch classifier loss: 0.455854; batch adversarial loss: 0.427820\n",
      "epoch 10; iter: 0; batch classifier loss: 0.385592; batch adversarial loss: 0.259679\n",
      "epoch 10; iter: 200; batch classifier loss: 0.313528; batch adversarial loss: 0.562090\n",
      "epoch 10; iter: 400; batch classifier loss: 0.330451; batch adversarial loss: 0.545474\n",
      "epoch 10; iter: 600; batch classifier loss: 0.336898; batch adversarial loss: 0.594931\n",
      "epoch 11; iter: 0; batch classifier loss: 0.296353; batch adversarial loss: 0.349744\n",
      "epoch 11; iter: 200; batch classifier loss: 0.393173; batch adversarial loss: 0.428008\n",
      "epoch 11; iter: 400; batch classifier loss: 0.439081; batch adversarial loss: 0.435750\n",
      "epoch 11; iter: 600; batch classifier loss: 0.413286; batch adversarial loss: 0.492774\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285300; batch adversarial loss: 0.368920\n",
      "epoch 12; iter: 200; batch classifier loss: 0.403059; batch adversarial loss: 0.320622\n",
      "epoch 12; iter: 400; batch classifier loss: 0.287020; batch adversarial loss: 0.415289\n",
      "epoch 12; iter: 600; batch classifier loss: 0.479569; batch adversarial loss: 0.527900\n",
      "epoch 13; iter: 0; batch classifier loss: 0.309449; batch adversarial loss: 0.490247\n",
      "epoch 13; iter: 200; batch classifier loss: 0.374710; batch adversarial loss: 0.488119\n",
      "epoch 13; iter: 400; batch classifier loss: 0.398184; batch adversarial loss: 0.457218\n",
      "epoch 13; iter: 600; batch classifier loss: 0.284431; batch adversarial loss: 0.513318\n",
      "epoch 14; iter: 0; batch classifier loss: 0.236791; batch adversarial loss: 0.289938\n",
      "epoch 14; iter: 200; batch classifier loss: 0.350293; batch adversarial loss: 0.346160\n",
      "epoch 14; iter: 400; batch classifier loss: 0.392441; batch adversarial loss: 0.509656\n",
      "epoch 14; iter: 600; batch classifier loss: 0.389499; batch adversarial loss: 0.348608\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289352; batch adversarial loss: 0.402241\n",
      "epoch 15; iter: 200; batch classifier loss: 0.317055; batch adversarial loss: 0.367042\n",
      "epoch 15; iter: 400; batch classifier loss: 0.336112; batch adversarial loss: 0.287084\n",
      "epoch 15; iter: 600; batch classifier loss: 0.398119; batch adversarial loss: 0.325343\n",
      "epoch 16; iter: 0; batch classifier loss: 0.407008; batch adversarial loss: 0.453683\n",
      "epoch 16; iter: 200; batch classifier loss: 0.270237; batch adversarial loss: 0.417563\n",
      "epoch 16; iter: 400; batch classifier loss: 0.384864; batch adversarial loss: 0.459571\n",
      "epoch 16; iter: 600; batch classifier loss: 0.324860; batch adversarial loss: 0.461785\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435659; batch adversarial loss: 0.511086\n",
      "epoch 17; iter: 200; batch classifier loss: 0.415835; batch adversarial loss: 0.591430\n",
      "epoch 17; iter: 400; batch classifier loss: 0.378092; batch adversarial loss: 0.356566\n",
      "epoch 17; iter: 600; batch classifier loss: 0.309781; batch adversarial loss: 0.420478\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387083; batch adversarial loss: 0.323463\n",
      "epoch 18; iter: 200; batch classifier loss: 0.447561; batch adversarial loss: 0.353954\n",
      "epoch 18; iter: 400; batch classifier loss: 0.348647; batch adversarial loss: 0.318197\n",
      "epoch 18; iter: 600; batch classifier loss: 0.271236; batch adversarial loss: 0.422773\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335681; batch adversarial loss: 0.369650\n",
      "epoch 19; iter: 200; batch classifier loss: 0.225647; batch adversarial loss: 0.320379\n",
      "epoch 19; iter: 400; batch classifier loss: 0.288700; batch adversarial loss: 0.458849\n",
      "epoch 19; iter: 600; batch classifier loss: 0.337322; batch adversarial loss: 0.499343\n",
      "epoch 20; iter: 0; batch classifier loss: 0.482023; batch adversarial loss: 0.431252\n",
      "epoch 20; iter: 200; batch classifier loss: 0.419668; batch adversarial loss: 0.451343\n",
      "epoch 20; iter: 400; batch classifier loss: 0.333063; batch adversarial loss: 0.344103\n",
      "epoch 20; iter: 600; batch classifier loss: 0.348441; batch adversarial loss: 0.414736\n",
      "epoch 21; iter: 0; batch classifier loss: 0.254486; batch adversarial loss: 0.343333\n",
      "epoch 21; iter: 200; batch classifier loss: 0.532155; batch adversarial loss: 0.462736\n",
      "epoch 21; iter: 400; batch classifier loss: 0.338937; batch adversarial loss: 0.407895\n",
      "epoch 21; iter: 600; batch classifier loss: 0.292493; batch adversarial loss: 0.628532\n",
      "epoch 22; iter: 0; batch classifier loss: 0.319073; batch adversarial loss: 0.265467\n",
      "epoch 22; iter: 200; batch classifier loss: 0.446384; batch adversarial loss: 0.532526\n",
      "epoch 22; iter: 400; batch classifier loss: 0.332542; batch adversarial loss: 0.428876\n",
      "epoch 22; iter: 600; batch classifier loss: 0.418400; batch adversarial loss: 0.429702\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285727; batch adversarial loss: 0.423293\n",
      "epoch 23; iter: 200; batch classifier loss: 0.410304; batch adversarial loss: 0.486178\n",
      "epoch 23; iter: 400; batch classifier loss: 0.279304; batch adversarial loss: 0.459132\n",
      "epoch 23; iter: 600; batch classifier loss: 0.322848; batch adversarial loss: 0.518150\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331174; batch adversarial loss: 0.405005\n",
      "epoch 24; iter: 200; batch classifier loss: 0.308474; batch adversarial loss: 0.447188\n",
      "epoch 24; iter: 400; batch classifier loss: 0.278014; batch adversarial loss: 0.342829\n",
      "epoch 24; iter: 600; batch classifier loss: 0.435079; batch adversarial loss: 0.408431\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433555; batch adversarial loss: 0.351190\n",
      "epoch 25; iter: 200; batch classifier loss: 0.232030; batch adversarial loss: 0.290521\n",
      "epoch 25; iter: 400; batch classifier loss: 0.317478; batch adversarial loss: 0.460881\n",
      "epoch 25; iter: 600; batch classifier loss: 0.329707; batch adversarial loss: 0.322085\n",
      "epoch 26; iter: 0; batch classifier loss: 0.376448; batch adversarial loss: 0.404041\n",
      "epoch 26; iter: 200; batch classifier loss: 0.345186; batch adversarial loss: 0.489785\n",
      "epoch 26; iter: 400; batch classifier loss: 0.451024; batch adversarial loss: 0.427459\n",
      "epoch 26; iter: 600; batch classifier loss: 0.302324; batch adversarial loss: 0.425856\n",
      "epoch 27; iter: 0; batch classifier loss: 0.380774; batch adversarial loss: 0.477302\n",
      "epoch 27; iter: 200; batch classifier loss: 0.282257; batch adversarial loss: 0.355135\n",
      "epoch 27; iter: 400; batch classifier loss: 0.394597; batch adversarial loss: 0.474192\n",
      "epoch 27; iter: 600; batch classifier loss: 0.294712; batch adversarial loss: 0.421030\n",
      "epoch 28; iter: 0; batch classifier loss: 0.292785; batch adversarial loss: 0.415018\n",
      "epoch 28; iter: 200; batch classifier loss: 0.488156; batch adversarial loss: 0.317521\n",
      "epoch 28; iter: 400; batch classifier loss: 0.471116; batch adversarial loss: 0.415252\n",
      "epoch 28; iter: 600; batch classifier loss: 0.499708; batch adversarial loss: 0.351203\n",
      "epoch 29; iter: 0; batch classifier loss: 0.285547; batch adversarial loss: 0.378909\n",
      "epoch 29; iter: 200; batch classifier loss: 0.460108; batch adversarial loss: 0.359397\n",
      "epoch 29; iter: 400; batch classifier loss: 0.428195; batch adversarial loss: 0.307404\n",
      "epoch 29; iter: 600; batch classifier loss: 0.422165; batch adversarial loss: 0.437032\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431370; batch adversarial loss: 0.431693\n",
      "epoch 30; iter: 200; batch classifier loss: 0.567459; batch adversarial loss: 0.487013\n",
      "epoch 30; iter: 400; batch classifier loss: 0.385725; batch adversarial loss: 0.413373\n",
      "epoch 30; iter: 600; batch classifier loss: 0.368868; batch adversarial loss: 0.405885\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440118; batch adversarial loss: 0.340218\n",
      "epoch 31; iter: 200; batch classifier loss: 0.460772; batch adversarial loss: 0.356019\n",
      "epoch 31; iter: 400; batch classifier loss: 0.339445; batch adversarial loss: 0.432823\n",
      "epoch 31; iter: 600; batch classifier loss: 0.364382; batch adversarial loss: 0.431727\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421830; batch adversarial loss: 0.320358\n",
      "epoch 32; iter: 200; batch classifier loss: 0.406247; batch adversarial loss: 0.506455\n",
      "epoch 32; iter: 400; batch classifier loss: 0.298539; batch adversarial loss: 0.397553\n",
      "epoch 32; iter: 600; batch classifier loss: 0.297913; batch adversarial loss: 0.241768\n",
      "epoch 33; iter: 0; batch classifier loss: 0.286715; batch adversarial loss: 0.342919\n",
      "epoch 33; iter: 200; batch classifier loss: 0.206917; batch adversarial loss: 0.614819\n",
      "epoch 33; iter: 400; batch classifier loss: 0.366797; batch adversarial loss: 0.377548\n",
      "epoch 33; iter: 600; batch classifier loss: 0.344627; batch adversarial loss: 0.398966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.292755; batch adversarial loss: 0.556694\n",
      "epoch 34; iter: 200; batch classifier loss: 0.492294; batch adversarial loss: 0.343393\n",
      "epoch 34; iter: 400; batch classifier loss: 0.221736; batch adversarial loss: 0.549873\n",
      "epoch 34; iter: 600; batch classifier loss: 0.276166; batch adversarial loss: 0.323315\n",
      "epoch 35; iter: 0; batch classifier loss: 0.310376; batch adversarial loss: 0.492670\n",
      "epoch 35; iter: 200; batch classifier loss: 0.468207; batch adversarial loss: 0.340172\n",
      "epoch 35; iter: 400; batch classifier loss: 0.384073; batch adversarial loss: 0.370813\n",
      "epoch 35; iter: 600; batch classifier loss: 0.313151; batch adversarial loss: 0.299659\n",
      "epoch 36; iter: 0; batch classifier loss: 0.516673; batch adversarial loss: 0.400171\n",
      "epoch 36; iter: 200; batch classifier loss: 0.275532; batch adversarial loss: 0.617176\n",
      "epoch 36; iter: 400; batch classifier loss: 0.280150; batch adversarial loss: 0.481173\n",
      "epoch 36; iter: 600; batch classifier loss: 0.367202; batch adversarial loss: 0.478460\n",
      "epoch 37; iter: 0; batch classifier loss: 0.390130; batch adversarial loss: 0.488804\n",
      "epoch 37; iter: 200; batch classifier loss: 0.272209; batch adversarial loss: 0.460411\n",
      "epoch 37; iter: 400; batch classifier loss: 0.465614; batch adversarial loss: 0.438664\n",
      "epoch 37; iter: 600; batch classifier loss: 0.444196; batch adversarial loss: 0.551605\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440611; batch adversarial loss: 0.436634\n",
      "epoch 38; iter: 200; batch classifier loss: 0.334628; batch adversarial loss: 0.508012\n",
      "epoch 38; iter: 400; batch classifier loss: 0.333552; batch adversarial loss: 0.370588\n",
      "epoch 38; iter: 600; batch classifier loss: 0.379972; batch adversarial loss: 0.467547\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386801; batch adversarial loss: 0.318664\n",
      "epoch 39; iter: 200; batch classifier loss: 1.100845; batch adversarial loss: 0.423003\n",
      "epoch 39; iter: 400; batch classifier loss: 0.483733; batch adversarial loss: 0.381048\n",
      "epoch 39; iter: 600; batch classifier loss: 0.312255; batch adversarial loss: 0.409067\n",
      "epoch 40; iter: 0; batch classifier loss: 0.334893; batch adversarial loss: 0.541358\n",
      "epoch 40; iter: 200; batch classifier loss: 0.223549; batch adversarial loss: 0.343735\n",
      "epoch 40; iter: 400; batch classifier loss: 0.535011; batch adversarial loss: 0.538647\n",
      "epoch 40; iter: 600; batch classifier loss: 0.288763; batch adversarial loss: 0.421821\n",
      "epoch 41; iter: 0; batch classifier loss: 0.439105; batch adversarial loss: 0.317625\n",
      "epoch 41; iter: 200; batch classifier loss: 0.370836; batch adversarial loss: 0.538654\n",
      "epoch 41; iter: 400; batch classifier loss: 0.332415; batch adversarial loss: 0.339940\n",
      "epoch 41; iter: 600; batch classifier loss: 0.356145; batch adversarial loss: 0.325094\n",
      "epoch 42; iter: 0; batch classifier loss: 0.316187; batch adversarial loss: 0.391589\n",
      "epoch 42; iter: 200; batch classifier loss: 0.461773; batch adversarial loss: 0.346231\n",
      "epoch 42; iter: 400; batch classifier loss: 0.290982; batch adversarial loss: 0.317665\n",
      "epoch 42; iter: 600; batch classifier loss: 0.271586; batch adversarial loss: 0.525590\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469676; batch adversarial loss: 0.292954\n",
      "epoch 43; iter: 200; batch classifier loss: 0.579445; batch adversarial loss: 0.362557\n",
      "epoch 43; iter: 400; batch classifier loss: 0.390775; batch adversarial loss: 0.521610\n",
      "epoch 43; iter: 600; batch classifier loss: 0.320837; batch adversarial loss: 0.370267\n",
      "epoch 44; iter: 0; batch classifier loss: 0.502889; batch adversarial loss: 0.526914\n",
      "epoch 44; iter: 200; batch classifier loss: 0.567740; batch adversarial loss: 0.466258\n",
      "epoch 44; iter: 400; batch classifier loss: 0.288544; batch adversarial loss: 0.375024\n",
      "epoch 44; iter: 600; batch classifier loss: 0.282219; batch adversarial loss: 0.672860\n",
      "epoch 45; iter: 0; batch classifier loss: 0.316034; batch adversarial loss: 0.377844\n",
      "epoch 45; iter: 200; batch classifier loss: 0.583199; batch adversarial loss: 0.277739\n",
      "epoch 45; iter: 400; batch classifier loss: 0.279944; batch adversarial loss: 0.562265\n",
      "epoch 45; iter: 600; batch classifier loss: 0.322919; batch adversarial loss: 0.480914\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392820; batch adversarial loss: 0.435934\n",
      "epoch 46; iter: 200; batch classifier loss: 0.188257; batch adversarial loss: 0.358829\n",
      "epoch 46; iter: 400; batch classifier loss: 0.306634; batch adversarial loss: 0.529387\n",
      "epoch 46; iter: 600; batch classifier loss: 0.257618; batch adversarial loss: 0.497301\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465143; batch adversarial loss: 0.401507\n",
      "epoch 47; iter: 200; batch classifier loss: 0.323707; batch adversarial loss: 0.455130\n",
      "epoch 47; iter: 400; batch classifier loss: 0.394174; batch adversarial loss: 0.316270\n",
      "epoch 47; iter: 600; batch classifier loss: 0.542235; batch adversarial loss: 0.466919\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400544; batch adversarial loss: 0.370085\n",
      "epoch 48; iter: 200; batch classifier loss: 0.254107; batch adversarial loss: 0.438145\n",
      "epoch 48; iter: 400; batch classifier loss: 0.384356; batch adversarial loss: 0.528621\n",
      "epoch 48; iter: 600; batch classifier loss: 0.338406; batch adversarial loss: 0.406350\n",
      "epoch 49; iter: 0; batch classifier loss: 0.323585; batch adversarial loss: 0.466075\n",
      "epoch 49; iter: 200; batch classifier loss: 0.300032; batch adversarial loss: 0.287194\n",
      "epoch 49; iter: 400; batch classifier loss: 0.405694; batch adversarial loss: 0.455169\n",
      "epoch 49; iter: 600; batch classifier loss: 0.958421; batch adversarial loss: 0.396923\n",
      "epoch 0; iter: 0; batch classifier loss: 6.531811; batch adversarial loss: 0.708488\n",
      "epoch 0; iter: 200; batch classifier loss: 5.256260; batch adversarial loss: 0.825947\n",
      "epoch 0; iter: 400; batch classifier loss: 12.883080; batch adversarial loss: 0.622219\n",
      "epoch 0; iter: 600; batch classifier loss: 1.226393; batch adversarial loss: 0.551008\n",
      "epoch 1; iter: 0; batch classifier loss: 1.650958; batch adversarial loss: 0.551868\n",
      "epoch 1; iter: 200; batch classifier loss: 0.971578; batch adversarial loss: 0.501068\n",
      "epoch 1; iter: 400; batch classifier loss: 9.096502; batch adversarial loss: 0.529613\n",
      "epoch 1; iter: 600; batch classifier loss: 1.835569; batch adversarial loss: 0.428407\n",
      "epoch 2; iter: 0; batch classifier loss: 0.729734; batch adversarial loss: 0.458403\n",
      "epoch 2; iter: 200; batch classifier loss: 2.641208; batch adversarial loss: 0.450233\n",
      "epoch 2; iter: 400; batch classifier loss: 0.944747; batch adversarial loss: 0.428314\n",
      "epoch 2; iter: 600; batch classifier loss: 0.908294; batch adversarial loss: 0.474271\n",
      "epoch 3; iter: 0; batch classifier loss: 0.412554; batch adversarial loss: 0.400783\n",
      "epoch 3; iter: 200; batch classifier loss: 0.584225; batch adversarial loss: 0.409693\n",
      "epoch 3; iter: 400; batch classifier loss: 0.795061; batch adversarial loss: 0.494000\n",
      "epoch 3; iter: 600; batch classifier loss: 1.091709; batch adversarial loss: 0.506499\n",
      "epoch 4; iter: 0; batch classifier loss: 0.485841; batch adversarial loss: 0.333779\n",
      "epoch 4; iter: 200; batch classifier loss: 0.429749; batch adversarial loss: 0.380872\n",
      "epoch 4; iter: 400; batch classifier loss: 0.430516; batch adversarial loss: 0.398617\n",
      "epoch 4; iter: 600; batch classifier loss: 0.435472; batch adversarial loss: 0.387266\n",
      "epoch 5; iter: 0; batch classifier loss: 0.518343; batch adversarial loss: 0.407981\n",
      "epoch 5; iter: 200; batch classifier loss: 0.369008; batch adversarial loss: 0.336541\n",
      "epoch 5; iter: 400; batch classifier loss: 0.534981; batch adversarial loss: 0.345032\n",
      "epoch 5; iter: 600; batch classifier loss: 0.486639; batch adversarial loss: 0.444686\n",
      "epoch 6; iter: 0; batch classifier loss: 0.351521; batch adversarial loss: 0.396842\n",
      "epoch 6; iter: 200; batch classifier loss: 0.326765; batch adversarial loss: 0.499712\n",
      "epoch 6; iter: 400; batch classifier loss: 0.411568; batch adversarial loss: 0.362973\n",
      "epoch 6; iter: 600; batch classifier loss: 0.472919; batch adversarial loss: 0.502352\n",
      "epoch 7; iter: 0; batch classifier loss: 0.667278; batch adversarial loss: 0.418883\n",
      "epoch 7; iter: 200; batch classifier loss: 0.438919; batch adversarial loss: 0.583275\n",
      "epoch 7; iter: 400; batch classifier loss: 0.421092; batch adversarial loss: 0.448032\n",
      "epoch 7; iter: 600; batch classifier loss: 0.354393; batch adversarial loss: 0.495192\n",
      "epoch 8; iter: 0; batch classifier loss: 0.320974; batch adversarial loss: 0.342658\n",
      "epoch 8; iter: 200; batch classifier loss: 0.357759; batch adversarial loss: 0.255742\n",
      "epoch 8; iter: 400; batch classifier loss: 0.434340; batch adversarial loss: 0.433825\n",
      "epoch 8; iter: 600; batch classifier loss: 0.325253; batch adversarial loss: 0.327905\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421546; batch adversarial loss: 0.392103\n",
      "epoch 9; iter: 200; batch classifier loss: 0.367358; batch adversarial loss: 0.513026\n",
      "epoch 9; iter: 400; batch classifier loss: 0.523118; batch adversarial loss: 0.373190\n",
      "epoch 9; iter: 600; batch classifier loss: 0.304555; batch adversarial loss: 0.407667\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464122; batch adversarial loss: 0.341307\n",
      "epoch 10; iter: 200; batch classifier loss: 0.381447; batch adversarial loss: 0.394541\n",
      "epoch 10; iter: 400; batch classifier loss: 0.267954; batch adversarial loss: 0.498022\n",
      "epoch 10; iter: 600; batch classifier loss: 0.513946; batch adversarial loss: 0.214907\n",
      "epoch 11; iter: 0; batch classifier loss: 0.223815; batch adversarial loss: 0.329080\n",
      "epoch 11; iter: 200; batch classifier loss: 0.491141; batch adversarial loss: 0.344912\n",
      "epoch 11; iter: 400; batch classifier loss: 0.437461; batch adversarial loss: 0.299796\n",
      "epoch 11; iter: 600; batch classifier loss: 0.407258; batch adversarial loss: 0.342714\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383476; batch adversarial loss: 0.460546\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432733; batch adversarial loss: 0.429471\n",
      "epoch 12; iter: 400; batch classifier loss: 0.360630; batch adversarial loss: 0.322653\n",
      "epoch 12; iter: 600; batch classifier loss: 0.313023; batch adversarial loss: 0.484987\n",
      "epoch 13; iter: 0; batch classifier loss: 0.237028; batch adversarial loss: 0.409245\n",
      "epoch 13; iter: 200; batch classifier loss: 0.370938; batch adversarial loss: 0.544068\n",
      "epoch 13; iter: 400; batch classifier loss: 0.451073; batch adversarial loss: 0.374835\n",
      "epoch 13; iter: 600; batch classifier loss: 0.275300; batch adversarial loss: 0.406374\n",
      "epoch 14; iter: 0; batch classifier loss: 0.414028; batch adversarial loss: 0.394252\n",
      "epoch 14; iter: 200; batch classifier loss: 0.411174; batch adversarial loss: 0.416607\n",
      "epoch 14; iter: 400; batch classifier loss: 0.270366; batch adversarial loss: 0.350653\n",
      "epoch 14; iter: 600; batch classifier loss: 0.334674; batch adversarial loss: 0.570769\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276337; batch adversarial loss: 0.484406\n",
      "epoch 15; iter: 200; batch classifier loss: 0.473343; batch adversarial loss: 0.464909\n",
      "epoch 15; iter: 400; batch classifier loss: 0.356201; batch adversarial loss: 0.379751\n",
      "epoch 15; iter: 600; batch classifier loss: 0.346208; batch adversarial loss: 0.518466\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376825; batch adversarial loss: 0.343221\n",
      "epoch 16; iter: 200; batch classifier loss: 0.268310; batch adversarial loss: 0.455907\n",
      "epoch 16; iter: 400; batch classifier loss: 0.424010; batch adversarial loss: 0.289704\n",
      "epoch 16; iter: 600; batch classifier loss: 0.392212; batch adversarial loss: 0.308964\n",
      "epoch 17; iter: 0; batch classifier loss: 0.282319; batch adversarial loss: 0.352204\n",
      "epoch 17; iter: 200; batch classifier loss: 0.404256; batch adversarial loss: 0.465563\n",
      "epoch 17; iter: 400; batch classifier loss: 0.290187; batch adversarial loss: 0.379678\n",
      "epoch 17; iter: 600; batch classifier loss: 0.300566; batch adversarial loss: 0.511830\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334515; batch adversarial loss: 0.384465\n",
      "epoch 18; iter: 200; batch classifier loss: 0.394633; batch adversarial loss: 0.431209\n",
      "epoch 18; iter: 400; batch classifier loss: 0.376345; batch adversarial loss: 0.428585\n",
      "epoch 18; iter: 600; batch classifier loss: 0.408878; batch adversarial loss: 0.349238\n",
      "epoch 19; iter: 0; batch classifier loss: 0.349501; batch adversarial loss: 0.386832\n",
      "epoch 19; iter: 200; batch classifier loss: 0.357072; batch adversarial loss: 0.344320\n",
      "epoch 19; iter: 400; batch classifier loss: 0.383171; batch adversarial loss: 0.357657\n",
      "epoch 19; iter: 600; batch classifier loss: 0.403749; batch adversarial loss: 0.403023\n",
      "epoch 20; iter: 0; batch classifier loss: 0.276216; batch adversarial loss: 0.595930\n",
      "epoch 20; iter: 200; batch classifier loss: 0.342144; batch adversarial loss: 0.400465\n",
      "epoch 20; iter: 400; batch classifier loss: 0.367958; batch adversarial loss: 0.313825\n",
      "epoch 20; iter: 600; batch classifier loss: 0.236809; batch adversarial loss: 0.531175\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388521; batch adversarial loss: 0.317638\n",
      "epoch 21; iter: 200; batch classifier loss: 0.409340; batch adversarial loss: 0.266955\n",
      "epoch 21; iter: 400; batch classifier loss: 0.272883; batch adversarial loss: 0.340460\n",
      "epoch 21; iter: 600; batch classifier loss: 0.369143; batch adversarial loss: 0.506867\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331604; batch adversarial loss: 0.263189\n",
      "epoch 22; iter: 200; batch classifier loss: 0.330614; batch adversarial loss: 0.368315\n",
      "epoch 22; iter: 400; batch classifier loss: 0.307280; batch adversarial loss: 0.371346\n",
      "epoch 22; iter: 600; batch classifier loss: 0.396776; batch adversarial loss: 0.393985\n",
      "epoch 23; iter: 0; batch classifier loss: 0.365124; batch adversarial loss: 0.460018\n",
      "epoch 23; iter: 200; batch classifier loss: 0.292528; batch adversarial loss: 0.502427\n",
      "epoch 23; iter: 400; batch classifier loss: 0.421875; batch adversarial loss: 0.455210\n",
      "epoch 23; iter: 600; batch classifier loss: 0.352542; batch adversarial loss: 0.442582\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451252; batch adversarial loss: 0.426157\n",
      "epoch 24; iter: 200; batch classifier loss: 0.491044; batch adversarial loss: 0.403493\n",
      "epoch 24; iter: 400; batch classifier loss: 0.413862; batch adversarial loss: 0.456512\n",
      "epoch 24; iter: 600; batch classifier loss: 0.332879; batch adversarial loss: 0.588717\n",
      "epoch 25; iter: 0; batch classifier loss: 0.412409; batch adversarial loss: 0.410316\n",
      "epoch 25; iter: 200; batch classifier loss: 0.364929; batch adversarial loss: 0.487706\n",
      "epoch 25; iter: 400; batch classifier loss: 0.494110; batch adversarial loss: 0.316847\n",
      "epoch 25; iter: 600; batch classifier loss: 0.433247; batch adversarial loss: 0.354125\n",
      "epoch 26; iter: 0; batch classifier loss: 0.524881; batch adversarial loss: 0.529056\n",
      "epoch 26; iter: 200; batch classifier loss: 0.239213; batch adversarial loss: 0.349867\n",
      "epoch 26; iter: 400; batch classifier loss: 0.545512; batch adversarial loss: 0.432680\n",
      "epoch 26; iter: 600; batch classifier loss: 0.276191; batch adversarial loss: 0.375683\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463175; batch adversarial loss: 0.315832\n",
      "epoch 27; iter: 200; batch classifier loss: 0.391233; batch adversarial loss: 0.408332\n",
      "epoch 27; iter: 400; batch classifier loss: 0.554909; batch adversarial loss: 0.428532\n",
      "epoch 27; iter: 600; batch classifier loss: 0.525021; batch adversarial loss: 0.494885\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425410; batch adversarial loss: 0.361546\n",
      "epoch 28; iter: 200; batch classifier loss: 0.350183; batch adversarial loss: 0.573527\n",
      "epoch 28; iter: 400; batch classifier loss: 0.399273; batch adversarial loss: 0.488394\n",
      "epoch 28; iter: 600; batch classifier loss: 0.493007; batch adversarial loss: 0.312510\n",
      "epoch 29; iter: 0; batch classifier loss: 0.515270; batch adversarial loss: 0.456977\n",
      "epoch 29; iter: 200; batch classifier loss: 0.370786; batch adversarial loss: 0.431363\n",
      "epoch 29; iter: 400; batch classifier loss: 0.232567; batch adversarial loss: 0.523270\n",
      "epoch 29; iter: 600; batch classifier loss: 0.248776; batch adversarial loss: 0.438523\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378939; batch adversarial loss: 0.401501\n",
      "epoch 30; iter: 200; batch classifier loss: 0.437683; batch adversarial loss: 0.540678\n",
      "epoch 30; iter: 400; batch classifier loss: 0.324454; batch adversarial loss: 0.510951\n",
      "epoch 30; iter: 600; batch classifier loss: 0.311886; batch adversarial loss: 0.466322\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437378; batch adversarial loss: 0.532960\n",
      "epoch 31; iter: 200; batch classifier loss: 0.554536; batch adversarial loss: 0.415993\n",
      "epoch 31; iter: 400; batch classifier loss: 0.279935; batch adversarial loss: 0.246469\n",
      "epoch 31; iter: 600; batch classifier loss: 0.321993; batch adversarial loss: 0.378272\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459972; batch adversarial loss: 0.525756\n",
      "epoch 32; iter: 200; batch classifier loss: 0.552558; batch adversarial loss: 0.490409\n",
      "epoch 32; iter: 400; batch classifier loss: 0.225591; batch adversarial loss: 0.442259\n",
      "epoch 32; iter: 600; batch classifier loss: 0.454522; batch adversarial loss: 0.374895\n",
      "epoch 33; iter: 0; batch classifier loss: 0.332319; batch adversarial loss: 0.347644\n",
      "epoch 33; iter: 200; batch classifier loss: 0.459087; batch adversarial loss: 0.358073\n",
      "epoch 33; iter: 400; batch classifier loss: 0.319822; batch adversarial loss: 0.383701\n",
      "epoch 33; iter: 600; batch classifier loss: 0.387801; batch adversarial loss: 0.374100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.346875; batch adversarial loss: 0.416077\n",
      "epoch 34; iter: 200; batch classifier loss: 0.343718; batch adversarial loss: 0.392655\n",
      "epoch 34; iter: 400; batch classifier loss: 0.545158; batch adversarial loss: 0.267550\n",
      "epoch 34; iter: 600; batch classifier loss: 0.498829; batch adversarial loss: 0.516781\n",
      "epoch 35; iter: 0; batch classifier loss: 0.492916; batch adversarial loss: 0.370943\n",
      "epoch 35; iter: 200; batch classifier loss: 0.472816; batch adversarial loss: 0.380767\n",
      "epoch 35; iter: 400; batch classifier loss: 0.552795; batch adversarial loss: 0.361203\n",
      "epoch 35; iter: 600; batch classifier loss: 0.508591; batch adversarial loss: 0.482990\n",
      "epoch 36; iter: 0; batch classifier loss: 0.392503; batch adversarial loss: 0.291355\n",
      "epoch 36; iter: 200; batch classifier loss: 0.450667; batch adversarial loss: 0.575425\n",
      "epoch 36; iter: 400; batch classifier loss: 0.319161; batch adversarial loss: 0.320869\n",
      "epoch 36; iter: 600; batch classifier loss: 0.495688; batch adversarial loss: 0.504578\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593335; batch adversarial loss: 0.386579\n",
      "epoch 37; iter: 200; batch classifier loss: 0.266916; batch adversarial loss: 0.495924\n",
      "epoch 37; iter: 400; batch classifier loss: 0.387461; batch adversarial loss: 0.414648\n",
      "epoch 37; iter: 600; batch classifier loss: 0.372457; batch adversarial loss: 0.436059\n",
      "epoch 38; iter: 0; batch classifier loss: 0.315669; batch adversarial loss: 0.322828\n",
      "epoch 38; iter: 200; batch classifier loss: 0.385554; batch adversarial loss: 0.528364\n",
      "epoch 38; iter: 400; batch classifier loss: 0.393735; batch adversarial loss: 0.455972\n",
      "epoch 38; iter: 600; batch classifier loss: 0.501278; batch adversarial loss: 0.431996\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377502; batch adversarial loss: 0.344762\n",
      "epoch 39; iter: 200; batch classifier loss: 0.517685; batch adversarial loss: 0.672147\n",
      "epoch 39; iter: 400; batch classifier loss: 0.533688; batch adversarial loss: 0.457987\n",
      "epoch 39; iter: 600; batch classifier loss: 0.427017; batch adversarial loss: 0.431718\n",
      "epoch 40; iter: 0; batch classifier loss: 0.645117; batch adversarial loss: 0.458999\n",
      "epoch 40; iter: 200; batch classifier loss: 0.645455; batch adversarial loss: 0.373925\n",
      "epoch 40; iter: 400; batch classifier loss: 0.410155; batch adversarial loss: 0.517378\n",
      "epoch 40; iter: 600; batch classifier loss: 0.441873; batch adversarial loss: 0.294743\n",
      "epoch 41; iter: 0; batch classifier loss: 0.558143; batch adversarial loss: 0.539076\n",
      "epoch 41; iter: 200; batch classifier loss: 0.277208; batch adversarial loss: 0.486987\n",
      "epoch 41; iter: 400; batch classifier loss: 0.305920; batch adversarial loss: 0.294027\n",
      "epoch 41; iter: 600; batch classifier loss: 0.357794; batch adversarial loss: 0.406098\n",
      "epoch 42; iter: 0; batch classifier loss: 0.444105; batch adversarial loss: 0.438582\n",
      "epoch 42; iter: 200; batch classifier loss: 0.443578; batch adversarial loss: 0.370982\n",
      "epoch 42; iter: 400; batch classifier loss: 0.474567; batch adversarial loss: 0.370212\n",
      "epoch 42; iter: 600; batch classifier loss: 0.330621; batch adversarial loss: 0.400316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.465343; batch adversarial loss: 0.479548\n",
      "epoch 43; iter: 200; batch classifier loss: 0.515482; batch adversarial loss: 0.259802\n",
      "epoch 43; iter: 400; batch classifier loss: 0.567226; batch adversarial loss: 0.396492\n",
      "epoch 43; iter: 600; batch classifier loss: 0.384387; batch adversarial loss: 0.383406\n",
      "epoch 44; iter: 0; batch classifier loss: 0.471208; batch adversarial loss: 0.551986\n",
      "epoch 44; iter: 200; batch classifier loss: 0.713248; batch adversarial loss: 0.428638\n",
      "epoch 44; iter: 400; batch classifier loss: 0.493432; batch adversarial loss: 0.396827\n",
      "epoch 44; iter: 600; batch classifier loss: 0.457339; batch adversarial loss: 0.510928\n",
      "epoch 45; iter: 0; batch classifier loss: 0.647137; batch adversarial loss: 0.316395\n",
      "epoch 45; iter: 200; batch classifier loss: 0.442987; batch adversarial loss: 0.322496\n",
      "epoch 45; iter: 400; batch classifier loss: 0.427666; batch adversarial loss: 0.372972\n",
      "epoch 45; iter: 600; batch classifier loss: 0.282345; batch adversarial loss: 0.290523\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428331; batch adversarial loss: 0.501788\n",
      "epoch 46; iter: 200; batch classifier loss: 0.414693; batch adversarial loss: 0.533245\n",
      "epoch 46; iter: 400; batch classifier loss: 0.441417; batch adversarial loss: 0.443730\n",
      "epoch 46; iter: 600; batch classifier loss: 0.333867; batch adversarial loss: 0.534881\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401358; batch adversarial loss: 0.379691\n",
      "epoch 47; iter: 200; batch classifier loss: 0.387097; batch adversarial loss: 0.290097\n",
      "epoch 47; iter: 400; batch classifier loss: 0.463679; batch adversarial loss: 0.569703\n",
      "epoch 47; iter: 600; batch classifier loss: 0.638763; batch adversarial loss: 0.458141\n",
      "epoch 48; iter: 0; batch classifier loss: 0.519628; batch adversarial loss: 0.411705\n",
      "epoch 48; iter: 200; batch classifier loss: 0.484736; batch adversarial loss: 0.436369\n",
      "epoch 48; iter: 400; batch classifier loss: 0.542347; batch adversarial loss: 0.373705\n",
      "epoch 48; iter: 600; batch classifier loss: 0.427541; batch adversarial loss: 0.404112\n",
      "epoch 49; iter: 0; batch classifier loss: 0.251275; batch adversarial loss: 0.427541\n",
      "epoch 49; iter: 200; batch classifier loss: 0.596538; batch adversarial loss: 0.407389\n",
      "epoch 49; iter: 400; batch classifier loss: 0.432758; batch adversarial loss: 0.315472\n",
      "epoch 49; iter: 600; batch classifier loss: 0.425317; batch adversarial loss: 0.410823\n",
      "epoch 0; iter: 0; batch classifier loss: 100.955414; batch adversarial loss: 0.683019\n",
      "epoch 0; iter: 200; batch classifier loss: 4.309176; batch adversarial loss: 0.636318\n",
      "epoch 0; iter: 400; batch classifier loss: 10.782326; batch adversarial loss: 0.501765\n",
      "epoch 0; iter: 600; batch classifier loss: 3.094460; batch adversarial loss: 0.481220\n",
      "epoch 1; iter: 0; batch classifier loss: 11.696264; batch adversarial loss: 0.490248\n",
      "epoch 1; iter: 200; batch classifier loss: 5.485625; batch adversarial loss: 0.481361\n",
      "epoch 1; iter: 400; batch classifier loss: 4.238629; batch adversarial loss: 0.449403\n",
      "epoch 1; iter: 600; batch classifier loss: 2.431019; batch adversarial loss: 0.372285\n",
      "epoch 2; iter: 0; batch classifier loss: 3.199254; batch adversarial loss: 0.408716\n",
      "epoch 2; iter: 200; batch classifier loss: 2.002095; batch adversarial loss: 0.576805\n",
      "epoch 2; iter: 400; batch classifier loss: 4.260922; batch adversarial loss: 0.400033\n",
      "epoch 2; iter: 600; batch classifier loss: 2.045290; batch adversarial loss: 0.480517\n",
      "epoch 3; iter: 0; batch classifier loss: 2.456969; batch adversarial loss: 0.433224\n",
      "epoch 3; iter: 200; batch classifier loss: 0.443669; batch adversarial loss: 0.355303\n",
      "epoch 3; iter: 400; batch classifier loss: 2.540258; batch adversarial loss: 0.376454\n",
      "epoch 3; iter: 600; batch classifier loss: 0.515769; batch adversarial loss: 0.486810\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405672; batch adversarial loss: 0.278744\n",
      "epoch 4; iter: 200; batch classifier loss: 0.457391; batch adversarial loss: 0.412082\n",
      "epoch 4; iter: 400; batch classifier loss: 1.043667; batch adversarial loss: 0.464729\n",
      "epoch 4; iter: 600; batch classifier loss: 0.867184; batch adversarial loss: 0.361458\n",
      "epoch 5; iter: 0; batch classifier loss: 0.370844; batch adversarial loss: 0.415766\n",
      "epoch 5; iter: 200; batch classifier loss: 0.410562; batch adversarial loss: 0.414829\n",
      "epoch 5; iter: 400; batch classifier loss: 0.455548; batch adversarial loss: 0.366978\n",
      "epoch 5; iter: 600; batch classifier loss: 0.371782; batch adversarial loss: 0.421807\n",
      "epoch 6; iter: 0; batch classifier loss: 0.247322; batch adversarial loss: 0.269894\n",
      "epoch 6; iter: 200; batch classifier loss: 0.376969; batch adversarial loss: 0.447959\n",
      "epoch 6; iter: 400; batch classifier loss: 0.318338; batch adversarial loss: 0.309125\n",
      "epoch 6; iter: 600; batch classifier loss: 0.316274; batch adversarial loss: 0.370290\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392286; batch adversarial loss: 0.444038\n",
      "epoch 7; iter: 200; batch classifier loss: 0.358966; batch adversarial loss: 0.361693\n",
      "epoch 7; iter: 400; batch classifier loss: 0.383008; batch adversarial loss: 0.426771\n",
      "epoch 7; iter: 600; batch classifier loss: 0.641924; batch adversarial loss: 0.452182\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501951; batch adversarial loss: 0.620441\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401835; batch adversarial loss: 0.376341\n",
      "epoch 8; iter: 400; batch classifier loss: 0.419848; batch adversarial loss: 0.651329\n",
      "epoch 8; iter: 600; batch classifier loss: 0.214885; batch adversarial loss: 0.485429\n",
      "epoch 9; iter: 0; batch classifier loss: 0.394363; batch adversarial loss: 0.397722\n",
      "epoch 9; iter: 200; batch classifier loss: 0.436069; batch adversarial loss: 0.431939\n",
      "epoch 9; iter: 400; batch classifier loss: 0.503918; batch adversarial loss: 0.356416\n",
      "epoch 9; iter: 600; batch classifier loss: 0.429882; batch adversarial loss: 0.537515\n",
      "epoch 10; iter: 0; batch classifier loss: 0.373826; batch adversarial loss: 0.452814\n",
      "epoch 10; iter: 200; batch classifier loss: 0.320615; batch adversarial loss: 0.346035\n",
      "epoch 10; iter: 400; batch classifier loss: 0.268007; batch adversarial loss: 0.378472\n",
      "epoch 10; iter: 600; batch classifier loss: 0.386318; batch adversarial loss: 0.442764\n",
      "epoch 11; iter: 0; batch classifier loss: 0.650220; batch adversarial loss: 0.320096\n",
      "epoch 11; iter: 200; batch classifier loss: 0.587788; batch adversarial loss: 0.407299\n",
      "epoch 11; iter: 400; batch classifier loss: 0.271390; batch adversarial loss: 0.461299\n",
      "epoch 11; iter: 600; batch classifier loss: 0.374183; batch adversarial loss: 0.343569\n",
      "epoch 12; iter: 0; batch classifier loss: 0.358404; batch adversarial loss: 0.368958\n",
      "epoch 12; iter: 200; batch classifier loss: 0.297984; batch adversarial loss: 0.510421\n",
      "epoch 12; iter: 400; batch classifier loss: 0.433102; batch adversarial loss: 0.400290\n",
      "epoch 12; iter: 600; batch classifier loss: 0.240809; batch adversarial loss: 0.435451\n",
      "epoch 13; iter: 0; batch classifier loss: 0.277331; batch adversarial loss: 0.353683\n",
      "epoch 13; iter: 200; batch classifier loss: 0.364926; batch adversarial loss: 0.319169\n",
      "epoch 13; iter: 400; batch classifier loss: 0.446747; batch adversarial loss: 0.343804\n",
      "epoch 13; iter: 600; batch classifier loss: 0.265023; batch adversarial loss: 0.429152\n",
      "epoch 14; iter: 0; batch classifier loss: 0.443822; batch adversarial loss: 0.456402\n",
      "epoch 14; iter: 200; batch classifier loss: 0.318630; batch adversarial loss: 0.268146\n",
      "epoch 14; iter: 400; batch classifier loss: 0.349690; batch adversarial loss: 0.345698\n",
      "epoch 14; iter: 600; batch classifier loss: 0.455382; batch adversarial loss: 0.373375\n",
      "epoch 15; iter: 0; batch classifier loss: 0.286657; batch adversarial loss: 0.350585\n",
      "epoch 15; iter: 200; batch classifier loss: 0.402901; batch adversarial loss: 0.399837\n",
      "epoch 15; iter: 400; batch classifier loss: 0.413887; batch adversarial loss: 0.356057\n",
      "epoch 15; iter: 600; batch classifier loss: 0.368538; batch adversarial loss: 0.346816\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299860; batch adversarial loss: 0.381601\n",
      "epoch 16; iter: 200; batch classifier loss: 0.518038; batch adversarial loss: 0.506506\n",
      "epoch 16; iter: 400; batch classifier loss: 0.306795; batch adversarial loss: 0.424136\n",
      "epoch 16; iter: 600; batch classifier loss: 0.354851; batch adversarial loss: 0.378365\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404406; batch adversarial loss: 0.325467\n",
      "epoch 17; iter: 200; batch classifier loss: 0.540247; batch adversarial loss: 0.455375\n",
      "epoch 17; iter: 400; batch classifier loss: 0.378088; batch adversarial loss: 0.430798\n",
      "epoch 17; iter: 600; batch classifier loss: 0.399406; batch adversarial loss: 0.481457\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359607; batch adversarial loss: 0.301898\n",
      "epoch 18; iter: 200; batch classifier loss: 0.420008; batch adversarial loss: 0.425126\n",
      "epoch 18; iter: 400; batch classifier loss: 0.259924; batch adversarial loss: 0.608549\n",
      "epoch 18; iter: 600; batch classifier loss: 0.514822; batch adversarial loss: 0.317512\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451058; batch adversarial loss: 0.344880\n",
      "epoch 19; iter: 200; batch classifier loss: 0.290911; batch adversarial loss: 0.408186\n",
      "epoch 19; iter: 400; batch classifier loss: 0.322189; batch adversarial loss: 0.442376\n",
      "epoch 19; iter: 600; batch classifier loss: 0.330270; batch adversarial loss: 0.547453\n",
      "epoch 20; iter: 0; batch classifier loss: 0.395487; batch adversarial loss: 0.374958\n",
      "epoch 20; iter: 200; batch classifier loss: 0.338929; batch adversarial loss: 0.461246\n",
      "epoch 20; iter: 400; batch classifier loss: 0.373714; batch adversarial loss: 0.541263\n",
      "epoch 20; iter: 600; batch classifier loss: 0.382274; batch adversarial loss: 0.484339\n",
      "epoch 21; iter: 0; batch classifier loss: 0.488856; batch adversarial loss: 0.431306\n",
      "epoch 21; iter: 200; batch classifier loss: 0.331893; batch adversarial loss: 0.352406\n",
      "epoch 21; iter: 400; batch classifier loss: 0.403460; batch adversarial loss: 0.460497\n",
      "epoch 21; iter: 600; batch classifier loss: 0.347007; batch adversarial loss: 0.496747\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431359; batch adversarial loss: 0.543313\n",
      "epoch 22; iter: 200; batch classifier loss: 0.336753; batch adversarial loss: 0.344263\n",
      "epoch 22; iter: 400; batch classifier loss: 0.317884; batch adversarial loss: 0.265837\n",
      "epoch 22; iter: 600; batch classifier loss: 0.495413; batch adversarial loss: 0.345057\n",
      "epoch 23; iter: 0; batch classifier loss: 0.211423; batch adversarial loss: 0.398631\n",
      "epoch 23; iter: 200; batch classifier loss: 0.684496; batch adversarial loss: 0.373414\n",
      "epoch 23; iter: 400; batch classifier loss: 0.322435; batch adversarial loss: 0.516782\n",
      "epoch 23; iter: 600; batch classifier loss: 0.483782; batch adversarial loss: 0.401292\n",
      "epoch 24; iter: 0; batch classifier loss: 0.386114; batch adversarial loss: 0.427761\n",
      "epoch 24; iter: 200; batch classifier loss: 0.355922; batch adversarial loss: 0.463840\n",
      "epoch 24; iter: 400; batch classifier loss: 0.322239; batch adversarial loss: 0.426710\n",
      "epoch 24; iter: 600; batch classifier loss: 0.187265; batch adversarial loss: 0.374498\n",
      "epoch 25; iter: 0; batch classifier loss: 0.273821; batch adversarial loss: 0.377808\n",
      "epoch 25; iter: 200; batch classifier loss: 0.459766; batch adversarial loss: 0.352145\n",
      "epoch 25; iter: 400; batch classifier loss: 0.341167; batch adversarial loss: 0.398368\n",
      "epoch 25; iter: 600; batch classifier loss: 0.370012; batch adversarial loss: 0.438899\n",
      "epoch 26; iter: 0; batch classifier loss: 0.266592; batch adversarial loss: 0.385697\n",
      "epoch 26; iter: 200; batch classifier loss: 0.328412; batch adversarial loss: 0.553715\n",
      "epoch 26; iter: 400; batch classifier loss: 0.276350; batch adversarial loss: 0.440642\n",
      "epoch 26; iter: 600; batch classifier loss: 0.361399; batch adversarial loss: 0.466861\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402360; batch adversarial loss: 0.391398\n",
      "epoch 27; iter: 200; batch classifier loss: 0.356453; batch adversarial loss: 0.403615\n",
      "epoch 27; iter: 400; batch classifier loss: 0.270010; batch adversarial loss: 0.411923\n",
      "epoch 27; iter: 600; batch classifier loss: 0.443644; batch adversarial loss: 0.434710\n",
      "epoch 28; iter: 0; batch classifier loss: 0.526150; batch adversarial loss: 0.347830\n",
      "epoch 28; iter: 200; batch classifier loss: 0.424400; batch adversarial loss: 0.436025\n",
      "epoch 28; iter: 400; batch classifier loss: 0.274317; batch adversarial loss: 0.427804\n",
      "epoch 28; iter: 600; batch classifier loss: 0.362658; batch adversarial loss: 0.634398\n",
      "epoch 29; iter: 0; batch classifier loss: 0.327958; batch adversarial loss: 0.357891\n",
      "epoch 29; iter: 200; batch classifier loss: 0.292412; batch adversarial loss: 0.323834\n",
      "epoch 29; iter: 400; batch classifier loss: 0.350681; batch adversarial loss: 0.383073\n",
      "epoch 29; iter: 600; batch classifier loss: 0.366017; batch adversarial loss: 0.321358\n",
      "epoch 30; iter: 0; batch classifier loss: 0.609477; batch adversarial loss: 0.317467\n",
      "epoch 30; iter: 200; batch classifier loss: 0.264897; batch adversarial loss: 0.518171\n",
      "epoch 30; iter: 400; batch classifier loss: 0.336661; batch adversarial loss: 0.542779\n",
      "epoch 30; iter: 600; batch classifier loss: 0.495475; batch adversarial loss: 0.382281\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436653; batch adversarial loss: 0.343037\n",
      "epoch 31; iter: 200; batch classifier loss: 0.248597; batch adversarial loss: 0.439888\n",
      "epoch 31; iter: 400; batch classifier loss: 0.348123; batch adversarial loss: 0.515505\n",
      "epoch 31; iter: 600; batch classifier loss: 0.239548; batch adversarial loss: 0.383601\n",
      "epoch 32; iter: 0; batch classifier loss: 0.370093; batch adversarial loss: 0.458816\n",
      "epoch 32; iter: 200; batch classifier loss: 0.316469; batch adversarial loss: 0.483523\n",
      "epoch 32; iter: 400; batch classifier loss: 0.373738; batch adversarial loss: 0.317486\n",
      "epoch 32; iter: 600; batch classifier loss: 0.401467; batch adversarial loss: 0.488501\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249781; batch adversarial loss: 0.352062\n",
      "epoch 33; iter: 200; batch classifier loss: 0.323711; batch adversarial loss: 0.597147\n",
      "epoch 33; iter: 400; batch classifier loss: 0.350820; batch adversarial loss: 0.465152\n",
      "epoch 33; iter: 600; batch classifier loss: 0.707828; batch adversarial loss: 0.375701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456824; batch adversarial loss: 0.398783\n",
      "epoch 34; iter: 200; batch classifier loss: 0.399794; batch adversarial loss: 0.453977\n",
      "epoch 34; iter: 400; batch classifier loss: 0.489041; batch adversarial loss: 0.334215\n",
      "epoch 34; iter: 600; batch classifier loss: 0.351373; batch adversarial loss: 0.266928\n",
      "epoch 35; iter: 0; batch classifier loss: 0.288084; batch adversarial loss: 0.401081\n",
      "epoch 35; iter: 200; batch classifier loss: 0.515190; batch adversarial loss: 0.374537\n",
      "epoch 35; iter: 400; batch classifier loss: 0.469079; batch adversarial loss: 0.349144\n",
      "epoch 35; iter: 600; batch classifier loss: 0.236952; batch adversarial loss: 0.428038\n",
      "epoch 36; iter: 0; batch classifier loss: 0.300956; batch adversarial loss: 0.348708\n",
      "epoch 36; iter: 200; batch classifier loss: 0.170825; batch adversarial loss: 0.535886\n",
      "epoch 36; iter: 400; batch classifier loss: 0.430475; batch adversarial loss: 0.550721\n",
      "epoch 36; iter: 600; batch classifier loss: 0.294440; batch adversarial loss: 0.402818\n",
      "epoch 37; iter: 0; batch classifier loss: 0.353559; batch adversarial loss: 0.412841\n",
      "epoch 37; iter: 200; batch classifier loss: 0.317426; batch adversarial loss: 0.297001\n",
      "epoch 37; iter: 400; batch classifier loss: 0.423192; batch adversarial loss: 0.377039\n",
      "epoch 37; iter: 600; batch classifier loss: 0.322792; batch adversarial loss: 0.463399\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429822; batch adversarial loss: 0.240292\n",
      "epoch 38; iter: 200; batch classifier loss: 0.376365; batch adversarial loss: 0.568262\n",
      "epoch 38; iter: 400; batch classifier loss: 0.434551; batch adversarial loss: 0.521976\n",
      "epoch 38; iter: 600; batch classifier loss: 0.351830; batch adversarial loss: 0.401595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.402903; batch adversarial loss: 0.495224\n",
      "epoch 39; iter: 200; batch classifier loss: 0.826620; batch adversarial loss: 0.379638\n",
      "epoch 39; iter: 400; batch classifier loss: 0.448271; batch adversarial loss: 0.463104\n",
      "epoch 39; iter: 600; batch classifier loss: 0.320795; batch adversarial loss: 0.486179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421140; batch adversarial loss: 0.485728\n",
      "epoch 40; iter: 200; batch classifier loss: 0.371516; batch adversarial loss: 0.407157\n",
      "epoch 40; iter: 400; batch classifier loss: 0.448706; batch adversarial loss: 0.488311\n",
      "epoch 40; iter: 600; batch classifier loss: 0.512357; batch adversarial loss: 0.321555\n",
      "epoch 41; iter: 0; batch classifier loss: 0.313078; batch adversarial loss: 0.497963\n",
      "epoch 41; iter: 200; batch classifier loss: 0.316674; batch adversarial loss: 0.291146\n",
      "epoch 41; iter: 400; batch classifier loss: 0.315705; batch adversarial loss: 0.427526\n",
      "epoch 41; iter: 600; batch classifier loss: 0.332678; batch adversarial loss: 0.346992\n",
      "epoch 42; iter: 0; batch classifier loss: 0.369773; batch adversarial loss: 0.377722\n",
      "epoch 42; iter: 200; batch classifier loss: 0.320725; batch adversarial loss: 0.520117\n",
      "epoch 42; iter: 400; batch classifier loss: 0.435907; batch adversarial loss: 0.438910\n",
      "epoch 42; iter: 600; batch classifier loss: 0.345666; batch adversarial loss: 0.458731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.366258; batch adversarial loss: 0.459845\n",
      "epoch 43; iter: 200; batch classifier loss: 0.280675; batch adversarial loss: 0.410406\n",
      "epoch 43; iter: 400; batch classifier loss: 0.268125; batch adversarial loss: 0.372496\n",
      "epoch 43; iter: 600; batch classifier loss: 0.411284; batch adversarial loss: 0.429475\n",
      "epoch 44; iter: 0; batch classifier loss: 0.353225; batch adversarial loss: 0.575681\n",
      "epoch 44; iter: 200; batch classifier loss: 0.357199; batch adversarial loss: 0.386016\n",
      "epoch 44; iter: 400; batch classifier loss: 0.363297; batch adversarial loss: 0.431120\n",
      "epoch 44; iter: 600; batch classifier loss: 0.377212; batch adversarial loss: 0.433975\n",
      "epoch 45; iter: 0; batch classifier loss: 0.297522; batch adversarial loss: 0.470710\n",
      "epoch 45; iter: 200; batch classifier loss: 0.212885; batch adversarial loss: 0.459399\n",
      "epoch 45; iter: 400; batch classifier loss: 0.397250; batch adversarial loss: 0.402864\n",
      "epoch 45; iter: 600; batch classifier loss: 0.403758; batch adversarial loss: 0.406331\n",
      "epoch 46; iter: 0; batch classifier loss: 0.463801; batch adversarial loss: 0.433962\n",
      "epoch 46; iter: 200; batch classifier loss: 0.430662; batch adversarial loss: 0.464284\n",
      "epoch 46; iter: 400; batch classifier loss: 0.297435; batch adversarial loss: 0.376902\n",
      "epoch 46; iter: 600; batch classifier loss: 0.319358; batch adversarial loss: 0.540922\n",
      "epoch 47; iter: 0; batch classifier loss: 0.322101; batch adversarial loss: 0.377686\n",
      "epoch 47; iter: 200; batch classifier loss: 0.241598; batch adversarial loss: 0.374563\n",
      "epoch 47; iter: 400; batch classifier loss: 0.263263; batch adversarial loss: 0.484200\n",
      "epoch 47; iter: 600; batch classifier loss: 0.345085; batch adversarial loss: 0.428832\n",
      "epoch 48; iter: 0; batch classifier loss: 0.204260; batch adversarial loss: 0.435245\n",
      "epoch 48; iter: 200; batch classifier loss: 0.158805; batch adversarial loss: 0.488573\n",
      "epoch 48; iter: 400; batch classifier loss: 0.240220; batch adversarial loss: 0.318603\n",
      "epoch 48; iter: 600; batch classifier loss: 0.327944; batch adversarial loss: 0.322167\n",
      "epoch 49; iter: 0; batch classifier loss: 0.273116; batch adversarial loss: 0.244599\n",
      "epoch 49; iter: 200; batch classifier loss: 0.672619; batch adversarial loss: 0.461290\n",
      "epoch 49; iter: 400; batch classifier loss: 0.416588; batch adversarial loss: 0.541230\n",
      "epoch 49; iter: 600; batch classifier loss: 0.420770; batch adversarial loss: 0.461185\n",
      "epoch 0; iter: 0; batch classifier loss: 45.043167; batch adversarial loss: 0.797824\n",
      "epoch 0; iter: 200; batch classifier loss: 7.093585; batch adversarial loss: 0.777126\n",
      "epoch 0; iter: 400; batch classifier loss: 8.578800; batch adversarial loss: 0.671353\n",
      "epoch 0; iter: 600; batch classifier loss: 4.422313; batch adversarial loss: 0.632782\n",
      "epoch 1; iter: 0; batch classifier loss: 4.022154; batch adversarial loss: 0.549952\n",
      "epoch 1; iter: 200; batch classifier loss: 2.627096; batch adversarial loss: 0.541720\n",
      "epoch 1; iter: 400; batch classifier loss: 1.172300; batch adversarial loss: 0.493472\n",
      "epoch 1; iter: 600; batch classifier loss: 10.884768; batch adversarial loss: 0.466199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.997229; batch adversarial loss: 0.456384\n",
      "epoch 2; iter: 200; batch classifier loss: 7.436820; batch adversarial loss: 0.450866\n",
      "epoch 2; iter: 400; batch classifier loss: 2.733520; batch adversarial loss: 0.463995\n",
      "epoch 2; iter: 600; batch classifier loss: 0.632081; batch adversarial loss: 0.524193\n",
      "epoch 3; iter: 0; batch classifier loss: 2.003001; batch adversarial loss: 0.326071\n",
      "epoch 3; iter: 200; batch classifier loss: 1.262562; batch adversarial loss: 0.392458\n",
      "epoch 3; iter: 400; batch classifier loss: 2.196115; batch adversarial loss: 0.412979\n",
      "epoch 3; iter: 600; batch classifier loss: 0.864900; batch adversarial loss: 0.307705\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518223; batch adversarial loss: 0.249352\n",
      "epoch 4; iter: 200; batch classifier loss: 3.447137; batch adversarial loss: 0.424057\n",
      "epoch 4; iter: 400; batch classifier loss: 1.718337; batch adversarial loss: 0.285708\n",
      "epoch 4; iter: 600; batch classifier loss: 0.525595; batch adversarial loss: 0.373011\n",
      "epoch 5; iter: 0; batch classifier loss: 0.337453; batch adversarial loss: 0.603729\n",
      "epoch 5; iter: 200; batch classifier loss: 0.571561; batch adversarial loss: 0.401988\n",
      "epoch 5; iter: 400; batch classifier loss: 0.471347; batch adversarial loss: 0.402139\n",
      "epoch 5; iter: 600; batch classifier loss: 0.555156; batch adversarial loss: 0.470988\n",
      "epoch 6; iter: 0; batch classifier loss: 0.368764; batch adversarial loss: 0.474030\n",
      "epoch 6; iter: 200; batch classifier loss: 0.381049; batch adversarial loss: 0.455580\n",
      "epoch 6; iter: 400; batch classifier loss: 0.450165; batch adversarial loss: 0.515949\n",
      "epoch 6; iter: 600; batch classifier loss: 0.307891; batch adversarial loss: 0.357816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.378070; batch adversarial loss: 0.435426\n",
      "epoch 7; iter: 200; batch classifier loss: 0.394463; batch adversarial loss: 0.487203\n",
      "epoch 7; iter: 400; batch classifier loss: 0.414868; batch adversarial loss: 0.407962\n",
      "epoch 7; iter: 600; batch classifier loss: 0.450599; batch adversarial loss: 0.542415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478764; batch adversarial loss: 0.313853\n",
      "epoch 8; iter: 200; batch classifier loss: 0.444822; batch adversarial loss: 0.348929\n",
      "epoch 8; iter: 400; batch classifier loss: 0.448897; batch adversarial loss: 0.380831\n",
      "epoch 8; iter: 600; batch classifier loss: 0.247837; batch adversarial loss: 0.464811\n",
      "epoch 9; iter: 0; batch classifier loss: 0.459174; batch adversarial loss: 0.436641\n",
      "epoch 9; iter: 200; batch classifier loss: 0.353377; batch adversarial loss: 0.288710\n",
      "epoch 9; iter: 400; batch classifier loss: 0.374723; batch adversarial loss: 0.458708\n",
      "epoch 9; iter: 600; batch classifier loss: 0.348880; batch adversarial loss: 0.311495\n",
      "epoch 10; iter: 0; batch classifier loss: 0.567524; batch adversarial loss: 0.460472\n",
      "epoch 10; iter: 200; batch classifier loss: 0.337824; batch adversarial loss: 0.340288\n",
      "epoch 10; iter: 400; batch classifier loss: 0.441659; batch adversarial loss: 0.291072\n",
      "epoch 10; iter: 600; batch classifier loss: 0.319528; batch adversarial loss: 0.420285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.351077; batch adversarial loss: 0.374773\n",
      "epoch 11; iter: 200; batch classifier loss: 0.354558; batch adversarial loss: 0.369371\n",
      "epoch 11; iter: 400; batch classifier loss: 0.319333; batch adversarial loss: 0.331170\n",
      "epoch 11; iter: 600; batch classifier loss: 0.333570; batch adversarial loss: 0.399065\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361480; batch adversarial loss: 0.509939\n",
      "epoch 12; iter: 200; batch classifier loss: 0.249188; batch adversarial loss: 0.463668\n",
      "epoch 12; iter: 400; batch classifier loss: 0.349051; batch adversarial loss: 0.363571\n",
      "epoch 12; iter: 600; batch classifier loss: 0.310203; batch adversarial loss: 0.374145\n",
      "epoch 13; iter: 0; batch classifier loss: 0.363492; batch adversarial loss: 0.469231\n",
      "epoch 13; iter: 200; batch classifier loss: 0.350852; batch adversarial loss: 0.351020\n",
      "epoch 13; iter: 400; batch classifier loss: 0.362568; batch adversarial loss: 0.453059\n",
      "epoch 13; iter: 600; batch classifier loss: 0.234799; batch adversarial loss: 0.347464\n",
      "epoch 14; iter: 0; batch classifier loss: 0.441428; batch adversarial loss: 0.452265\n",
      "epoch 14; iter: 200; batch classifier loss: 0.331149; batch adversarial loss: 0.381221\n",
      "epoch 14; iter: 400; batch classifier loss: 0.305889; batch adversarial loss: 0.452650\n",
      "epoch 14; iter: 600; batch classifier loss: 0.416291; batch adversarial loss: 0.357295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373342; batch adversarial loss: 0.486272\n",
      "epoch 15; iter: 200; batch classifier loss: 0.345679; batch adversarial loss: 0.405103\n",
      "epoch 15; iter: 400; batch classifier loss: 0.334650; batch adversarial loss: 0.369821\n",
      "epoch 15; iter: 600; batch classifier loss: 0.264520; batch adversarial loss: 0.431109\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402833; batch adversarial loss: 0.319596\n",
      "epoch 16; iter: 200; batch classifier loss: 0.351293; batch adversarial loss: 0.437648\n",
      "epoch 16; iter: 400; batch classifier loss: 0.234103; batch adversarial loss: 0.453317\n",
      "epoch 16; iter: 600; batch classifier loss: 0.424633; batch adversarial loss: 0.385321\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285662; batch adversarial loss: 0.293578\n",
      "epoch 17; iter: 200; batch classifier loss: 0.420707; batch adversarial loss: 0.375818\n",
      "epoch 17; iter: 400; batch classifier loss: 0.343265; batch adversarial loss: 0.490121\n",
      "epoch 17; iter: 600; batch classifier loss: 0.453465; batch adversarial loss: 0.555232\n",
      "epoch 18; iter: 0; batch classifier loss: 0.383467; batch adversarial loss: 0.382360\n",
      "epoch 18; iter: 200; batch classifier loss: 0.400688; batch adversarial loss: 0.329916\n",
      "epoch 18; iter: 400; batch classifier loss: 0.292846; batch adversarial loss: 0.422962\n",
      "epoch 18; iter: 600; batch classifier loss: 0.327915; batch adversarial loss: 0.440509\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350836; batch adversarial loss: 0.443963\n",
      "epoch 19; iter: 200; batch classifier loss: 0.298638; batch adversarial loss: 0.494340\n",
      "epoch 19; iter: 400; batch classifier loss: 0.370861; batch adversarial loss: 0.621542\n",
      "epoch 19; iter: 600; batch classifier loss: 0.299734; batch adversarial loss: 0.377841\n",
      "epoch 20; iter: 0; batch classifier loss: 0.394335; batch adversarial loss: 0.349754\n",
      "epoch 20; iter: 200; batch classifier loss: 0.407554; batch adversarial loss: 0.406619\n",
      "epoch 20; iter: 400; batch classifier loss: 0.448917; batch adversarial loss: 0.389058\n",
      "epoch 20; iter: 600; batch classifier loss: 0.303589; batch adversarial loss: 0.536738\n",
      "epoch 21; iter: 0; batch classifier loss: 0.324514; batch adversarial loss: 0.380661\n",
      "epoch 21; iter: 200; batch classifier loss: 0.717111; batch adversarial loss: 0.410231\n",
      "epoch 21; iter: 400; batch classifier loss: 0.414828; batch adversarial loss: 0.386410\n",
      "epoch 21; iter: 600; batch classifier loss: 0.354320; batch adversarial loss: 0.343278\n",
      "epoch 22; iter: 0; batch classifier loss: 0.406592; batch adversarial loss: 0.439693\n",
      "epoch 22; iter: 200; batch classifier loss: 0.329913; batch adversarial loss: 0.327346\n",
      "epoch 22; iter: 400; batch classifier loss: 0.245502; batch adversarial loss: 0.564663\n",
      "epoch 22; iter: 600; batch classifier loss: 0.462121; batch adversarial loss: 0.399010\n",
      "epoch 23; iter: 0; batch classifier loss: 0.240237; batch adversarial loss: 0.411308\n",
      "epoch 23; iter: 200; batch classifier loss: 0.297179; batch adversarial loss: 0.469605\n",
      "epoch 23; iter: 400; batch classifier loss: 0.377153; batch adversarial loss: 0.477565\n",
      "epoch 23; iter: 600; batch classifier loss: 0.485570; batch adversarial loss: 0.408605\n",
      "epoch 24; iter: 0; batch classifier loss: 0.393937; batch adversarial loss: 0.379013\n",
      "epoch 24; iter: 200; batch classifier loss: 0.278498; batch adversarial loss: 0.408771\n",
      "epoch 24; iter: 400; batch classifier loss: 0.389648; batch adversarial loss: 0.375984\n",
      "epoch 24; iter: 600; batch classifier loss: 0.272067; batch adversarial loss: 0.517254\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333512; batch adversarial loss: 0.378853\n",
      "epoch 25; iter: 200; batch classifier loss: 0.380684; batch adversarial loss: 0.330803\n",
      "epoch 25; iter: 400; batch classifier loss: 0.291649; batch adversarial loss: 0.425580\n",
      "epoch 25; iter: 600; batch classifier loss: 0.348944; batch adversarial loss: 0.340484\n",
      "epoch 26; iter: 0; batch classifier loss: 0.339064; batch adversarial loss: 0.434131\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336490; batch adversarial loss: 0.529308\n",
      "epoch 26; iter: 400; batch classifier loss: 0.325214; batch adversarial loss: 0.524272\n",
      "epoch 26; iter: 600; batch classifier loss: 0.570745; batch adversarial loss: 0.489569\n",
      "epoch 27; iter: 0; batch classifier loss: 0.334837; batch adversarial loss: 0.455083\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310429; batch adversarial loss: 0.434098\n",
      "epoch 27; iter: 400; batch classifier loss: 0.255663; batch adversarial loss: 0.398618\n",
      "epoch 27; iter: 600; batch classifier loss: 0.335351; batch adversarial loss: 0.458627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.439135; batch adversarial loss: 0.372499\n",
      "epoch 28; iter: 200; batch classifier loss: 0.181414; batch adversarial loss: 0.503173\n",
      "epoch 28; iter: 400; batch classifier loss: 0.259875; batch adversarial loss: 0.507249\n",
      "epoch 28; iter: 600; batch classifier loss: 0.308398; batch adversarial loss: 0.476581\n",
      "epoch 29; iter: 0; batch classifier loss: 0.296606; batch adversarial loss: 0.568279\n",
      "epoch 29; iter: 200; batch classifier loss: 0.433227; batch adversarial loss: 0.452397\n",
      "epoch 29; iter: 400; batch classifier loss: 0.275780; batch adversarial loss: 0.349645\n",
      "epoch 29; iter: 600; batch classifier loss: 0.319928; batch adversarial loss: 0.554886\n",
      "epoch 30; iter: 0; batch classifier loss: 0.606801; batch adversarial loss: 0.409970\n",
      "epoch 30; iter: 200; batch classifier loss: 0.418585; batch adversarial loss: 0.431663\n",
      "epoch 30; iter: 400; batch classifier loss: 0.395508; batch adversarial loss: 0.510863\n",
      "epoch 30; iter: 600; batch classifier loss: 0.401451; batch adversarial loss: 0.517612\n",
      "epoch 31; iter: 0; batch classifier loss: 0.287015; batch adversarial loss: 0.354635\n",
      "epoch 31; iter: 200; batch classifier loss: 0.339459; batch adversarial loss: 0.425280\n",
      "epoch 31; iter: 400; batch classifier loss: 0.316988; batch adversarial loss: 0.485196\n",
      "epoch 31; iter: 600; batch classifier loss: 0.335740; batch adversarial loss: 0.474081\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309692; batch adversarial loss: 0.424261\n",
      "epoch 32; iter: 200; batch classifier loss: 0.449196; batch adversarial loss: 0.395402\n",
      "epoch 32; iter: 400; batch classifier loss: 0.435683; batch adversarial loss: 0.294643\n",
      "epoch 32; iter: 600; batch classifier loss: 0.394351; batch adversarial loss: 0.403022\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518535; batch adversarial loss: 0.404793\n",
      "epoch 33; iter: 200; batch classifier loss: 0.405453; batch adversarial loss: 0.452594\n",
      "epoch 33; iter: 400; batch classifier loss: 0.376775; batch adversarial loss: 0.473313\n",
      "epoch 33; iter: 600; batch classifier loss: 0.310794; batch adversarial loss: 0.470200\n",
      "epoch 34; iter: 0; batch classifier loss: 0.268423; batch adversarial loss: 0.299355\n",
      "epoch 34; iter: 200; batch classifier loss: 0.496026; batch adversarial loss: 0.398697\n",
      "epoch 34; iter: 400; batch classifier loss: 0.349778; batch adversarial loss: 0.543482\n",
      "epoch 34; iter: 600; batch classifier loss: 0.537436; batch adversarial loss: 0.368321\n",
      "epoch 35; iter: 0; batch classifier loss: 0.211821; batch adversarial loss: 0.387629\n",
      "epoch 35; iter: 200; batch classifier loss: 0.228344; batch adversarial loss: 0.549314\n",
      "epoch 35; iter: 400; batch classifier loss: 0.238556; batch adversarial loss: 0.376044\n",
      "epoch 35; iter: 600; batch classifier loss: 0.431407; batch adversarial loss: 0.381099\n",
      "epoch 36; iter: 0; batch classifier loss: 0.398769; batch adversarial loss: 0.450062\n",
      "epoch 36; iter: 200; batch classifier loss: 0.367944; batch adversarial loss: 0.309006\n",
      "epoch 36; iter: 400; batch classifier loss: 0.331402; batch adversarial loss: 0.430834\n",
      "epoch 36; iter: 600; batch classifier loss: 0.458712; batch adversarial loss: 0.468631\n",
      "epoch 37; iter: 0; batch classifier loss: 0.258831; batch adversarial loss: 0.553008\n",
      "epoch 37; iter: 200; batch classifier loss: 0.372155; batch adversarial loss: 0.401449\n",
      "epoch 37; iter: 400; batch classifier loss: 0.364711; batch adversarial loss: 0.503759\n",
      "epoch 37; iter: 600; batch classifier loss: 0.401939; batch adversarial loss: 0.316404\n",
      "epoch 38; iter: 0; batch classifier loss: 0.631582; batch adversarial loss: 0.370419\n",
      "epoch 38; iter: 200; batch classifier loss: 0.367290; batch adversarial loss: 0.298248\n",
      "epoch 38; iter: 400; batch classifier loss: 0.349955; batch adversarial loss: 0.327807\n",
      "epoch 38; iter: 600; batch classifier loss: 0.617908; batch adversarial loss: 0.548700\n",
      "epoch 39; iter: 0; batch classifier loss: 0.302719; batch adversarial loss: 0.349228\n",
      "epoch 39; iter: 200; batch classifier loss: 0.414500; batch adversarial loss: 0.424836\n",
      "epoch 39; iter: 400; batch classifier loss: 0.481312; batch adversarial loss: 0.568797\n",
      "epoch 39; iter: 600; batch classifier loss: 0.450067; batch adversarial loss: 0.345574\n",
      "epoch 40; iter: 0; batch classifier loss: 0.547754; batch adversarial loss: 0.436083\n",
      "epoch 40; iter: 200; batch classifier loss: 0.312808; batch adversarial loss: 0.371768\n",
      "epoch 40; iter: 400; batch classifier loss: 0.552802; batch adversarial loss: 0.476321\n",
      "epoch 40; iter: 600; batch classifier loss: 0.349829; batch adversarial loss: 0.377745\n",
      "epoch 41; iter: 0; batch classifier loss: 0.364553; batch adversarial loss: 0.423865\n",
      "epoch 41; iter: 200; batch classifier loss: 0.322349; batch adversarial loss: 0.490375\n",
      "epoch 41; iter: 400; batch classifier loss: 0.370756; batch adversarial loss: 0.427741\n",
      "epoch 41; iter: 600; batch classifier loss: 0.578633; batch adversarial loss: 0.546804\n",
      "epoch 42; iter: 0; batch classifier loss: 0.486617; batch adversarial loss: 0.383818\n",
      "epoch 42; iter: 200; batch classifier loss: 0.255900; batch adversarial loss: 0.483369\n",
      "epoch 42; iter: 400; batch classifier loss: 0.279675; batch adversarial loss: 0.454865\n",
      "epoch 42; iter: 600; batch classifier loss: 0.483757; batch adversarial loss: 0.348364\n",
      "epoch 43; iter: 0; batch classifier loss: 0.410283; batch adversarial loss: 0.294918\n",
      "epoch 43; iter: 200; batch classifier loss: 0.406658; batch adversarial loss: 0.479595\n",
      "epoch 43; iter: 400; batch classifier loss: 0.288784; batch adversarial loss: 0.289588\n",
      "epoch 43; iter: 600; batch classifier loss: 0.404426; batch adversarial loss: 0.466092\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410209; batch adversarial loss: 0.351490\n",
      "epoch 44; iter: 200; batch classifier loss: 0.419423; batch adversarial loss: 0.473646\n",
      "epoch 44; iter: 400; batch classifier loss: 0.500267; batch adversarial loss: 0.248973\n",
      "epoch 44; iter: 600; batch classifier loss: 0.453047; batch adversarial loss: 0.462543\n",
      "epoch 45; iter: 0; batch classifier loss: 0.456219; batch adversarial loss: 0.508285\n",
      "epoch 45; iter: 200; batch classifier loss: 0.391722; batch adversarial loss: 0.447338\n",
      "epoch 45; iter: 400; batch classifier loss: 0.581778; batch adversarial loss: 0.488270\n",
      "epoch 45; iter: 600; batch classifier loss: 0.449049; batch adversarial loss: 0.372816\n",
      "epoch 46; iter: 0; batch classifier loss: 0.379790; batch adversarial loss: 0.432471\n",
      "epoch 46; iter: 200; batch classifier loss: 0.376079; batch adversarial loss: 0.437666\n",
      "epoch 46; iter: 400; batch classifier loss: 0.280400; batch adversarial loss: 0.488887\n",
      "epoch 46; iter: 600; batch classifier loss: 0.337765; batch adversarial loss: 0.343885\n",
      "epoch 47; iter: 0; batch classifier loss: 0.412842; batch adversarial loss: 0.440135\n",
      "epoch 47; iter: 200; batch classifier loss: 0.297203; batch adversarial loss: 0.344945\n",
      "epoch 47; iter: 400; batch classifier loss: 0.459307; batch adversarial loss: 0.396331\n",
      "epoch 47; iter: 600; batch classifier loss: 0.444523; batch adversarial loss: 0.398773\n",
      "epoch 48; iter: 0; batch classifier loss: 0.588556; batch adversarial loss: 0.204565\n",
      "epoch 48; iter: 200; batch classifier loss: 0.473906; batch adversarial loss: 0.384699\n",
      "epoch 48; iter: 400; batch classifier loss: 0.451936; batch adversarial loss: 0.289643\n",
      "epoch 48; iter: 600; batch classifier loss: 0.445990; batch adversarial loss: 0.448451\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434283; batch adversarial loss: 0.493254\n",
      "epoch 49; iter: 200; batch classifier loss: 0.431638; batch adversarial loss: 0.318398\n",
      "epoch 49; iter: 400; batch classifier loss: 0.252415; batch adversarial loss: 0.539749\n",
      "epoch 49; iter: 600; batch classifier loss: 0.519982; batch adversarial loss: 0.373983\n",
      "epoch 0; iter: 0; batch classifier loss: 24.179214; batch adversarial loss: 0.642679\n",
      "epoch 0; iter: 200; batch classifier loss: 3.732449; batch adversarial loss: 0.506177\n",
      "epoch 0; iter: 400; batch classifier loss: 7.133795; batch adversarial loss: 0.591476\n",
      "epoch 0; iter: 600; batch classifier loss: 4.913042; batch adversarial loss: 0.534797\n",
      "epoch 1; iter: 0; batch classifier loss: 2.507319; batch adversarial loss: 0.533748\n",
      "epoch 1; iter: 200; batch classifier loss: 2.785743; batch adversarial loss: 0.497083\n",
      "epoch 1; iter: 400; batch classifier loss: 1.507014; batch adversarial loss: 0.541196\n",
      "epoch 1; iter: 600; batch classifier loss: 1.215282; batch adversarial loss: 0.485661\n",
      "epoch 2; iter: 0; batch classifier loss: 3.284218; batch adversarial loss: 0.435483\n",
      "epoch 2; iter: 200; batch classifier loss: 2.339652; batch adversarial loss: 0.457124\n",
      "epoch 2; iter: 400; batch classifier loss: 2.320781; batch adversarial loss: 0.470729\n",
      "epoch 2; iter: 600; batch classifier loss: 0.404566; batch adversarial loss: 0.441814\n",
      "epoch 3; iter: 0; batch classifier loss: 1.194377; batch adversarial loss: 0.364108\n",
      "epoch 3; iter: 200; batch classifier loss: 0.325427; batch adversarial loss: 0.368207\n",
      "epoch 3; iter: 400; batch classifier loss: 0.716322; batch adversarial loss: 0.338285\n",
      "epoch 3; iter: 600; batch classifier loss: 0.498870; batch adversarial loss: 0.378858\n",
      "epoch 4; iter: 0; batch classifier loss: 0.396498; batch adversarial loss: 0.507245\n",
      "epoch 4; iter: 200; batch classifier loss: 0.417534; batch adversarial loss: 0.507833\n",
      "epoch 4; iter: 400; batch classifier loss: 0.558621; batch adversarial loss: 0.402448\n",
      "epoch 4; iter: 600; batch classifier loss: 0.438904; batch adversarial loss: 0.433293\n",
      "epoch 5; iter: 0; batch classifier loss: 0.433574; batch adversarial loss: 0.433495\n",
      "epoch 5; iter: 200; batch classifier loss: 0.503116; batch adversarial loss: 0.253450\n",
      "epoch 5; iter: 400; batch classifier loss: 0.398061; batch adversarial loss: 0.534454\n",
      "epoch 5; iter: 600; batch classifier loss: 0.437964; batch adversarial loss: 0.439674\n",
      "epoch 6; iter: 0; batch classifier loss: 2.207492; batch adversarial loss: 0.473201\n",
      "epoch 6; iter: 200; batch classifier loss: 0.356375; batch adversarial loss: 0.539133\n",
      "epoch 6; iter: 400; batch classifier loss: 0.329917; batch adversarial loss: 0.425972\n",
      "epoch 6; iter: 600; batch classifier loss: 0.262717; batch adversarial loss: 0.383187\n",
      "epoch 7; iter: 0; batch classifier loss: 0.390613; batch adversarial loss: 0.351334\n",
      "epoch 7; iter: 200; batch classifier loss: 0.421007; batch adversarial loss: 0.400292\n",
      "epoch 7; iter: 400; batch classifier loss: 0.417635; batch adversarial loss: 0.348182\n",
      "epoch 7; iter: 600; batch classifier loss: 0.336166; batch adversarial loss: 0.354098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.264401; batch adversarial loss: 0.327905\n",
      "epoch 8; iter: 200; batch classifier loss: 0.423043; batch adversarial loss: 0.533977\n",
      "epoch 8; iter: 400; batch classifier loss: 0.430388; batch adversarial loss: 0.429661\n",
      "epoch 8; iter: 600; batch classifier loss: 0.359322; batch adversarial loss: 0.366580\n",
      "epoch 9; iter: 0; batch classifier loss: 0.374179; batch adversarial loss: 0.261672\n",
      "epoch 9; iter: 200; batch classifier loss: 0.323430; batch adversarial loss: 0.318444\n",
      "epoch 9; iter: 400; batch classifier loss: 0.311594; batch adversarial loss: 0.678035\n",
      "epoch 9; iter: 600; batch classifier loss: 0.329786; batch adversarial loss: 0.344602\n",
      "epoch 10; iter: 0; batch classifier loss: 0.332326; batch adversarial loss: 0.448683\n",
      "epoch 10; iter: 200; batch classifier loss: 0.260646; batch adversarial loss: 0.500798\n",
      "epoch 10; iter: 400; batch classifier loss: 0.385053; batch adversarial loss: 0.454776\n",
      "epoch 10; iter: 600; batch classifier loss: 0.401131; batch adversarial loss: 0.378048\n",
      "epoch 11; iter: 0; batch classifier loss: 0.288339; batch adversarial loss: 0.514090\n",
      "epoch 11; iter: 200; batch classifier loss: 0.297231; batch adversarial loss: 0.525845\n",
      "epoch 11; iter: 400; batch classifier loss: 0.298808; batch adversarial loss: 0.441348\n",
      "epoch 11; iter: 600; batch classifier loss: 0.433266; batch adversarial loss: 0.323351\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233176; batch adversarial loss: 0.398962\n",
      "epoch 12; iter: 200; batch classifier loss: 0.455359; batch adversarial loss: 0.285579\n",
      "epoch 12; iter: 400; batch classifier loss: 0.285074; batch adversarial loss: 0.673049\n",
      "epoch 12; iter: 600; batch classifier loss: 0.280857; batch adversarial loss: 0.397984\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331956; batch adversarial loss: 0.399046\n",
      "epoch 13; iter: 200; batch classifier loss: 0.312701; batch adversarial loss: 0.404865\n",
      "epoch 13; iter: 400; batch classifier loss: 0.422529; batch adversarial loss: 0.400561\n",
      "epoch 13; iter: 600; batch classifier loss: 0.315009; batch adversarial loss: 0.386477\n",
      "epoch 14; iter: 0; batch classifier loss: 0.355597; batch adversarial loss: 0.508224\n",
      "epoch 14; iter: 200; batch classifier loss: 0.293032; batch adversarial loss: 0.237046\n",
      "epoch 14; iter: 400; batch classifier loss: 0.331871; batch adversarial loss: 0.601928\n",
      "epoch 14; iter: 600; batch classifier loss: 0.324506; batch adversarial loss: 0.486502\n",
      "epoch 15; iter: 0; batch classifier loss: 0.217834; batch adversarial loss: 0.421005\n",
      "epoch 15; iter: 200; batch classifier loss: 0.400924; batch adversarial loss: 0.449943\n",
      "epoch 15; iter: 400; batch classifier loss: 0.335026; batch adversarial loss: 0.379435\n",
      "epoch 15; iter: 600; batch classifier loss: 0.313025; batch adversarial loss: 0.314204\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355748; batch adversarial loss: 0.426251\n",
      "epoch 16; iter: 200; batch classifier loss: 0.331908; batch adversarial loss: 0.375804\n",
      "epoch 16; iter: 400; batch classifier loss: 0.248502; batch adversarial loss: 0.375221\n",
      "epoch 16; iter: 600; batch classifier loss: 0.350156; batch adversarial loss: 0.350117\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331888; batch adversarial loss: 0.316990\n",
      "epoch 17; iter: 200; batch classifier loss: 0.245193; batch adversarial loss: 0.456132\n",
      "epoch 17; iter: 400; batch classifier loss: 0.324934; batch adversarial loss: 0.455952\n",
      "epoch 17; iter: 600; batch classifier loss: 0.320243; batch adversarial loss: 0.348380\n",
      "epoch 18; iter: 0; batch classifier loss: 0.266368; batch adversarial loss: 0.452991\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336962; batch adversarial loss: 0.426275\n",
      "epoch 18; iter: 400; batch classifier loss: 0.323830; batch adversarial loss: 0.459575\n",
      "epoch 18; iter: 600; batch classifier loss: 0.342477; batch adversarial loss: 0.488904\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287969; batch adversarial loss: 0.452044\n",
      "epoch 19; iter: 200; batch classifier loss: 0.291804; batch adversarial loss: 0.320841\n",
      "epoch 19; iter: 400; batch classifier loss: 0.323835; batch adversarial loss: 0.330416\n",
      "epoch 19; iter: 600; batch classifier loss: 0.300028; batch adversarial loss: 0.471166\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338709; batch adversarial loss: 0.362905\n",
      "epoch 20; iter: 200; batch classifier loss: 0.478836; batch adversarial loss: 0.400253\n",
      "epoch 20; iter: 400; batch classifier loss: 0.339541; batch adversarial loss: 0.472194\n",
      "epoch 20; iter: 600; batch classifier loss: 0.354386; batch adversarial loss: 0.506054\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469656; batch adversarial loss: 0.353194\n",
      "epoch 21; iter: 200; batch classifier loss: 0.372248; batch adversarial loss: 0.507230\n",
      "epoch 21; iter: 400; batch classifier loss: 0.327960; batch adversarial loss: 0.426133\n",
      "epoch 21; iter: 600; batch classifier loss: 0.227136; batch adversarial loss: 0.526563\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502917; batch adversarial loss: 0.454662\n",
      "epoch 22; iter: 200; batch classifier loss: 0.438829; batch adversarial loss: 0.343024\n",
      "epoch 22; iter: 400; batch classifier loss: 0.324878; batch adversarial loss: 0.474702\n",
      "epoch 22; iter: 600; batch classifier loss: 0.315269; batch adversarial loss: 0.436704\n",
      "epoch 23; iter: 0; batch classifier loss: 0.385892; batch adversarial loss: 0.561009\n",
      "epoch 23; iter: 200; batch classifier loss: 0.393862; batch adversarial loss: 0.456296\n",
      "epoch 23; iter: 400; batch classifier loss: 0.362230; batch adversarial loss: 0.593657\n",
      "epoch 23; iter: 600; batch classifier loss: 0.429943; batch adversarial loss: 0.403974\n",
      "epoch 24; iter: 0; batch classifier loss: 0.386581; batch adversarial loss: 0.322952\n",
      "epoch 24; iter: 200; batch classifier loss: 0.292582; batch adversarial loss: 0.430341\n",
      "epoch 24; iter: 400; batch classifier loss: 0.213410; batch adversarial loss: 0.379604\n",
      "epoch 24; iter: 600; batch classifier loss: 0.387296; batch adversarial loss: 0.376123\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306923; batch adversarial loss: 0.587949\n",
      "epoch 25; iter: 200; batch classifier loss: 0.271227; batch adversarial loss: 0.516874\n",
      "epoch 25; iter: 400; batch classifier loss: 0.369234; batch adversarial loss: 0.373212\n",
      "epoch 25; iter: 600; batch classifier loss: 0.369862; batch adversarial loss: 0.461121\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239379; batch adversarial loss: 0.424442\n",
      "epoch 26; iter: 200; batch classifier loss: 0.290750; batch adversarial loss: 0.386739\n",
      "epoch 26; iter: 400; batch classifier loss: 0.381910; batch adversarial loss: 0.452230\n",
      "epoch 26; iter: 600; batch classifier loss: 0.460618; batch adversarial loss: 0.404992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.386812; batch adversarial loss: 0.294276\n",
      "epoch 27; iter: 200; batch classifier loss: 0.418061; batch adversarial loss: 0.520396\n",
      "epoch 27; iter: 400; batch classifier loss: 0.387135; batch adversarial loss: 0.400873\n",
      "epoch 27; iter: 600; batch classifier loss: 0.315409; batch adversarial loss: 0.533291\n",
      "epoch 28; iter: 0; batch classifier loss: 0.288718; batch adversarial loss: 0.410375\n",
      "epoch 28; iter: 200; batch classifier loss: 0.548015; batch adversarial loss: 0.302774\n",
      "epoch 28; iter: 400; batch classifier loss: 0.311286; batch adversarial loss: 0.350716\n",
      "epoch 28; iter: 600; batch classifier loss: 0.259286; batch adversarial loss: 0.379595\n",
      "epoch 29; iter: 0; batch classifier loss: 0.204739; batch adversarial loss: 0.378747\n",
      "epoch 29; iter: 200; batch classifier loss: 0.252805; batch adversarial loss: 0.440746\n",
      "epoch 29; iter: 400; batch classifier loss: 0.375576; batch adversarial loss: 0.491680\n",
      "epoch 29; iter: 600; batch classifier loss: 0.519942; batch adversarial loss: 0.372949\n",
      "epoch 30; iter: 0; batch classifier loss: 0.301532; batch adversarial loss: 0.409515\n",
      "epoch 30; iter: 200; batch classifier loss: 0.237927; batch adversarial loss: 0.428286\n",
      "epoch 30; iter: 400; batch classifier loss: 0.325468; batch adversarial loss: 0.407894\n",
      "epoch 30; iter: 600; batch classifier loss: 0.351308; batch adversarial loss: 0.232570\n",
      "epoch 31; iter: 0; batch classifier loss: 0.240379; batch adversarial loss: 0.438742\n",
      "epoch 31; iter: 200; batch classifier loss: 0.870114; batch adversarial loss: 0.464537\n",
      "epoch 31; iter: 400; batch classifier loss: 0.331108; batch adversarial loss: 0.464413\n",
      "epoch 31; iter: 600; batch classifier loss: 0.324106; batch adversarial loss: 0.369109\n",
      "epoch 32; iter: 0; batch classifier loss: 0.337258; batch adversarial loss: 0.354006\n",
      "epoch 32; iter: 200; batch classifier loss: 0.229179; batch adversarial loss: 0.328797\n",
      "epoch 32; iter: 400; batch classifier loss: 0.348318; batch adversarial loss: 0.510666\n",
      "epoch 32; iter: 600; batch classifier loss: 0.286296; batch adversarial loss: 0.370135\n",
      "epoch 33; iter: 0; batch classifier loss: 0.449469; batch adversarial loss: 0.438574\n",
      "epoch 33; iter: 200; batch classifier loss: 0.427239; batch adversarial loss: 0.380170\n",
      "epoch 33; iter: 400; batch classifier loss: 0.454030; batch adversarial loss: 0.413792\n",
      "epoch 33; iter: 600; batch classifier loss: 0.355867; batch adversarial loss: 0.296977\n",
      "epoch 34; iter: 0; batch classifier loss: 1.084441; batch adversarial loss: 0.384994\n",
      "epoch 34; iter: 200; batch classifier loss: 0.364821; batch adversarial loss: 0.460510\n",
      "epoch 34; iter: 400; batch classifier loss: 0.356775; batch adversarial loss: 0.292717\n",
      "epoch 34; iter: 600; batch classifier loss: 0.292832; batch adversarial loss: 0.344961\n",
      "epoch 35; iter: 0; batch classifier loss: 0.602623; batch adversarial loss: 0.409362\n",
      "epoch 35; iter: 200; batch classifier loss: 0.263022; batch adversarial loss: 0.395922\n",
      "epoch 35; iter: 400; batch classifier loss: 0.484488; batch adversarial loss: 0.293142\n",
      "epoch 35; iter: 600; batch classifier loss: 0.414409; batch adversarial loss: 0.380125\n",
      "epoch 36; iter: 0; batch classifier loss: 0.351689; batch adversarial loss: 0.403016\n",
      "epoch 36; iter: 200; batch classifier loss: 0.279099; batch adversarial loss: 0.356934\n",
      "epoch 36; iter: 400; batch classifier loss: 0.297433; batch adversarial loss: 0.348177\n",
      "epoch 36; iter: 600; batch classifier loss: 0.318500; batch adversarial loss: 0.412984\n",
      "epoch 37; iter: 0; batch classifier loss: 0.537119; batch adversarial loss: 0.429952\n",
      "epoch 37; iter: 200; batch classifier loss: 0.360170; batch adversarial loss: 0.453720\n",
      "epoch 37; iter: 400; batch classifier loss: 0.289736; batch adversarial loss: 0.298825\n",
      "epoch 37; iter: 600; batch classifier loss: 0.335962; batch adversarial loss: 0.405960\n",
      "epoch 38; iter: 0; batch classifier loss: 0.384675; batch adversarial loss: 0.352352\n",
      "epoch 38; iter: 200; batch classifier loss: 0.314934; batch adversarial loss: 0.377833\n",
      "epoch 38; iter: 400; batch classifier loss: 0.576311; batch adversarial loss: 0.483146\n",
      "epoch 38; iter: 600; batch classifier loss: 0.294523; batch adversarial loss: 0.354702\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430435; batch adversarial loss: 0.264939\n",
      "epoch 39; iter: 200; batch classifier loss: 0.230994; batch adversarial loss: 0.345232\n",
      "epoch 39; iter: 400; batch classifier loss: 0.411054; batch adversarial loss: 0.431406\n",
      "epoch 39; iter: 600; batch classifier loss: 0.338676; batch adversarial loss: 0.295701\n",
      "epoch 40; iter: 0; batch classifier loss: 0.603316; batch adversarial loss: 0.486790\n",
      "epoch 40; iter: 200; batch classifier loss: 0.350868; batch adversarial loss: 0.312322\n",
      "epoch 40; iter: 400; batch classifier loss: 0.433355; batch adversarial loss: 0.317295\n",
      "epoch 40; iter: 600; batch classifier loss: 0.352558; batch adversarial loss: 0.366594\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416695; batch adversarial loss: 0.372903\n",
      "epoch 41; iter: 200; batch classifier loss: 0.375175; batch adversarial loss: 0.506310\n",
      "epoch 41; iter: 400; batch classifier loss: 0.407696; batch adversarial loss: 0.475605\n",
      "epoch 41; iter: 600; batch classifier loss: 0.260013; batch adversarial loss: 0.456991\n",
      "epoch 42; iter: 0; batch classifier loss: 0.333066; batch adversarial loss: 0.476575\n",
      "epoch 42; iter: 200; batch classifier loss: 0.438213; batch adversarial loss: 0.460544\n",
      "epoch 42; iter: 400; batch classifier loss: 0.510206; batch adversarial loss: 0.369574\n",
      "epoch 42; iter: 600; batch classifier loss: 0.397127; batch adversarial loss: 0.522613\n",
      "epoch 43; iter: 0; batch classifier loss: 0.552460; batch adversarial loss: 0.431123\n",
      "epoch 43; iter: 200; batch classifier loss: 0.532789; batch adversarial loss: 0.287382\n",
      "epoch 43; iter: 400; batch classifier loss: 0.476398; batch adversarial loss: 0.260228\n",
      "epoch 43; iter: 600; batch classifier loss: 0.345430; batch adversarial loss: 0.485352\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410530; batch adversarial loss: 0.344430\n",
      "epoch 44; iter: 200; batch classifier loss: 0.312063; batch adversarial loss: 0.375011\n",
      "epoch 44; iter: 400; batch classifier loss: 0.340366; batch adversarial loss: 0.484626\n",
      "epoch 44; iter: 600; batch classifier loss: 0.355290; batch adversarial loss: 0.442890\n",
      "epoch 45; iter: 0; batch classifier loss: 0.241463; batch adversarial loss: 0.410923\n",
      "epoch 45; iter: 200; batch classifier loss: 0.359301; batch adversarial loss: 0.442722\n",
      "epoch 45; iter: 400; batch classifier loss: 0.260442; batch adversarial loss: 0.384968\n",
      "epoch 45; iter: 600; batch classifier loss: 0.443307; batch adversarial loss: 0.485121\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317517; batch adversarial loss: 0.400367\n",
      "epoch 46; iter: 200; batch classifier loss: 0.283562; batch adversarial loss: 0.453704\n",
      "epoch 46; iter: 400; batch classifier loss: 0.520899; batch adversarial loss: 0.351949\n",
      "epoch 46; iter: 600; batch classifier loss: 0.335523; batch adversarial loss: 0.375881\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422372; batch adversarial loss: 0.490717\n",
      "epoch 47; iter: 200; batch classifier loss: 0.260996; batch adversarial loss: 0.729041\n",
      "epoch 47; iter: 400; batch classifier loss: 0.416178; batch adversarial loss: 0.292405\n",
      "epoch 47; iter: 600; batch classifier loss: 0.463563; batch adversarial loss: 0.349684\n",
      "epoch 48; iter: 0; batch classifier loss: 0.765380; batch adversarial loss: 0.371702\n",
      "epoch 48; iter: 200; batch classifier loss: 0.448113; batch adversarial loss: 0.519727\n",
      "epoch 48; iter: 400; batch classifier loss: 0.414979; batch adversarial loss: 0.397509\n",
      "epoch 48; iter: 600; batch classifier loss: 0.354286; batch adversarial loss: 0.411747\n",
      "epoch 49; iter: 0; batch classifier loss: 0.336430; batch adversarial loss: 0.344954\n",
      "epoch 49; iter: 200; batch classifier loss: 0.519164; batch adversarial loss: 0.381144\n",
      "epoch 49; iter: 400; batch classifier loss: 0.283855; batch adversarial loss: 0.288564\n",
      "epoch 49; iter: 600; batch classifier loss: 0.537420; batch adversarial loss: 0.455061\n",
      "epoch 0; iter: 0; batch classifier loss: 1.398766; batch adversarial loss: 0.573808\n",
      "epoch 0; iter: 200; batch classifier loss: 10.277969; batch adversarial loss: 0.619152\n",
      "epoch 0; iter: 400; batch classifier loss: 4.479694; batch adversarial loss: 0.555624\n",
      "epoch 0; iter: 600; batch classifier loss: 2.806374; batch adversarial loss: 0.536514\n",
      "epoch 1; iter: 0; batch classifier loss: 3.567643; batch adversarial loss: 0.560851\n",
      "epoch 1; iter: 200; batch classifier loss: 9.393713; batch adversarial loss: 0.489885\n",
      "epoch 1; iter: 400; batch classifier loss: 0.371597; batch adversarial loss: 0.486077\n",
      "epoch 1; iter: 600; batch classifier loss: 0.260308; batch adversarial loss: 0.439707\n",
      "epoch 2; iter: 0; batch classifier loss: 2.783464; batch adversarial loss: 0.418754\n",
      "epoch 2; iter: 200; batch classifier loss: 1.075860; batch adversarial loss: 0.373416\n",
      "epoch 2; iter: 400; batch classifier loss: 7.353756; batch adversarial loss: 0.371537\n",
      "epoch 2; iter: 600; batch classifier loss: 4.592112; batch adversarial loss: 0.518772\n",
      "epoch 3; iter: 0; batch classifier loss: 0.461034; batch adversarial loss: 0.403536\n",
      "epoch 3; iter: 200; batch classifier loss: 3.279764; batch adversarial loss: 0.356943\n",
      "epoch 3; iter: 400; batch classifier loss: 1.220701; batch adversarial loss: 0.447330\n",
      "epoch 3; iter: 600; batch classifier loss: 0.354764; batch adversarial loss: 0.409002\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382656; batch adversarial loss: 0.452421\n",
      "epoch 4; iter: 200; batch classifier loss: 0.434929; batch adversarial loss: 0.433637\n",
      "epoch 4; iter: 400; batch classifier loss: 0.556405; batch adversarial loss: 0.334934\n",
      "epoch 4; iter: 600; batch classifier loss: 0.945020; batch adversarial loss: 0.229747\n",
      "epoch 5; iter: 0; batch classifier loss: 0.404358; batch adversarial loss: 0.418864\n",
      "epoch 5; iter: 200; batch classifier loss: 0.411009; batch adversarial loss: 0.314608\n",
      "epoch 5; iter: 400; batch classifier loss: 0.218431; batch adversarial loss: 0.432604\n",
      "epoch 5; iter: 600; batch classifier loss: 0.262029; batch adversarial loss: 0.456908\n",
      "epoch 6; iter: 0; batch classifier loss: 0.324599; batch adversarial loss: 0.423423\n",
      "epoch 6; iter: 200; batch classifier loss: 0.370449; batch adversarial loss: 0.452962\n",
      "epoch 6; iter: 400; batch classifier loss: 0.355642; batch adversarial loss: 0.451033\n",
      "epoch 6; iter: 600; batch classifier loss: 0.459287; batch adversarial loss: 0.411194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.313429; batch adversarial loss: 0.296292\n",
      "epoch 7; iter: 200; batch classifier loss: 0.376835; batch adversarial loss: 0.521023\n",
      "epoch 7; iter: 400; batch classifier loss: 0.381857; batch adversarial loss: 0.507252\n",
      "epoch 7; iter: 600; batch classifier loss: 0.456031; batch adversarial loss: 0.487514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.234437; batch adversarial loss: 0.345781\n",
      "epoch 8; iter: 200; batch classifier loss: 0.343951; batch adversarial loss: 0.410793\n",
      "epoch 8; iter: 400; batch classifier loss: 0.343555; batch adversarial loss: 0.437258\n",
      "epoch 8; iter: 600; batch classifier loss: 0.452129; batch adversarial loss: 0.430722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.439816; batch adversarial loss: 0.384211\n",
      "epoch 9; iter: 200; batch classifier loss: 0.479958; batch adversarial loss: 0.290962\n",
      "epoch 9; iter: 400; batch classifier loss: 0.335267; batch adversarial loss: 0.494543\n",
      "epoch 9; iter: 600; batch classifier loss: 0.450285; batch adversarial loss: 0.339603\n",
      "epoch 10; iter: 0; batch classifier loss: 0.249794; batch adversarial loss: 0.405348\n",
      "epoch 10; iter: 200; batch classifier loss: 0.248181; batch adversarial loss: 0.357052\n",
      "epoch 10; iter: 400; batch classifier loss: 0.283473; batch adversarial loss: 0.486555\n",
      "epoch 10; iter: 600; batch classifier loss: 0.379034; batch adversarial loss: 0.405666\n",
      "epoch 11; iter: 0; batch classifier loss: 0.401044; batch adversarial loss: 0.422793\n",
      "epoch 11; iter: 200; batch classifier loss: 0.459733; batch adversarial loss: 0.434460\n",
      "epoch 11; iter: 400; batch classifier loss: 0.337108; batch adversarial loss: 0.362517\n",
      "epoch 11; iter: 600; batch classifier loss: 0.278953; batch adversarial loss: 0.350467\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285727; batch adversarial loss: 0.411577\n",
      "epoch 12; iter: 200; batch classifier loss: 0.261662; batch adversarial loss: 0.556389\n",
      "epoch 12; iter: 400; batch classifier loss: 0.414336; batch adversarial loss: 0.409488\n",
      "epoch 12; iter: 600; batch classifier loss: 0.381930; batch adversarial loss: 0.490320\n",
      "epoch 13; iter: 0; batch classifier loss: 0.315580; batch adversarial loss: 0.373503\n",
      "epoch 13; iter: 200; batch classifier loss: 0.322588; batch adversarial loss: 0.430934\n",
      "epoch 13; iter: 400; batch classifier loss: 0.404645; batch adversarial loss: 0.302057\n",
      "epoch 13; iter: 600; batch classifier loss: 0.270777; batch adversarial loss: 0.424520\n",
      "epoch 14; iter: 0; batch classifier loss: 0.298832; batch adversarial loss: 0.398165\n",
      "epoch 14; iter: 200; batch classifier loss: 0.349544; batch adversarial loss: 0.372100\n",
      "epoch 14; iter: 400; batch classifier loss: 0.275941; batch adversarial loss: 0.366969\n",
      "epoch 14; iter: 600; batch classifier loss: 0.300155; batch adversarial loss: 0.355905\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344949; batch adversarial loss: 0.382371\n",
      "epoch 15; iter: 200; batch classifier loss: 0.397186; batch adversarial loss: 0.447204\n",
      "epoch 15; iter: 400; batch classifier loss: 0.319750; batch adversarial loss: 0.376767\n",
      "epoch 15; iter: 600; batch classifier loss: 0.352533; batch adversarial loss: 0.453932\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347922; batch adversarial loss: 0.447857\n",
      "epoch 16; iter: 200; batch classifier loss: 0.427666; batch adversarial loss: 0.562954\n",
      "epoch 16; iter: 400; batch classifier loss: 0.398979; batch adversarial loss: 0.407319\n",
      "epoch 16; iter: 600; batch classifier loss: 0.405270; batch adversarial loss: 0.377984\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330505; batch adversarial loss: 0.334381\n",
      "epoch 17; iter: 200; batch classifier loss: 0.560782; batch adversarial loss: 0.400963\n",
      "epoch 17; iter: 400; batch classifier loss: 0.354318; batch adversarial loss: 0.523666\n",
      "epoch 17; iter: 600; batch classifier loss: 0.448409; batch adversarial loss: 0.385032\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264667; batch adversarial loss: 0.374013\n",
      "epoch 18; iter: 200; batch classifier loss: 0.236925; batch adversarial loss: 0.407399\n",
      "epoch 18; iter: 400; batch classifier loss: 0.393943; batch adversarial loss: 0.367875\n",
      "epoch 18; iter: 600; batch classifier loss: 0.306185; batch adversarial loss: 0.265150\n",
      "epoch 19; iter: 0; batch classifier loss: 0.402893; batch adversarial loss: 0.454403\n",
      "epoch 19; iter: 200; batch classifier loss: 0.298717; batch adversarial loss: 0.494435\n",
      "epoch 19; iter: 400; batch classifier loss: 0.384667; batch adversarial loss: 0.291416\n",
      "epoch 19; iter: 600; batch classifier loss: 0.453403; batch adversarial loss: 0.289847\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428557; batch adversarial loss: 0.498408\n",
      "epoch 20; iter: 200; batch classifier loss: 0.315097; batch adversarial loss: 0.263178\n",
      "epoch 20; iter: 400; batch classifier loss: 0.542722; batch adversarial loss: 0.417539\n",
      "epoch 20; iter: 600; batch classifier loss: 0.374719; batch adversarial loss: 0.573227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285924; batch adversarial loss: 0.399899\n",
      "epoch 21; iter: 200; batch classifier loss: 0.388718; batch adversarial loss: 0.473046\n",
      "epoch 21; iter: 400; batch classifier loss: 0.327717; batch adversarial loss: 0.325373\n",
      "epoch 21; iter: 600; batch classifier loss: 0.295009; batch adversarial loss: 0.315202\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372373; batch adversarial loss: 0.397363\n",
      "epoch 22; iter: 200; batch classifier loss: 0.317723; batch adversarial loss: 0.405070\n",
      "epoch 22; iter: 400; batch classifier loss: 0.300620; batch adversarial loss: 0.364771\n",
      "epoch 22; iter: 600; batch classifier loss: 0.270610; batch adversarial loss: 0.429235\n",
      "epoch 23; iter: 0; batch classifier loss: 0.421211; batch adversarial loss: 0.357605\n",
      "epoch 23; iter: 200; batch classifier loss: 0.347685; batch adversarial loss: 0.438108\n",
      "epoch 23; iter: 400; batch classifier loss: 0.316322; batch adversarial loss: 0.457943\n",
      "epoch 23; iter: 600; batch classifier loss: 0.282148; batch adversarial loss: 0.352104\n",
      "epoch 24; iter: 0; batch classifier loss: 0.280502; batch adversarial loss: 0.313590\n",
      "epoch 24; iter: 200; batch classifier loss: 0.415226; batch adversarial loss: 0.466692\n",
      "epoch 24; iter: 400; batch classifier loss: 0.355743; batch adversarial loss: 0.588130\n",
      "epoch 24; iter: 600; batch classifier loss: 0.361174; batch adversarial loss: 0.408093\n",
      "epoch 25; iter: 0; batch classifier loss: 0.400656; batch adversarial loss: 0.287166\n",
      "epoch 25; iter: 200; batch classifier loss: 0.382064; batch adversarial loss: 0.379763\n",
      "epoch 25; iter: 400; batch classifier loss: 0.598350; batch adversarial loss: 0.468246\n",
      "epoch 25; iter: 600; batch classifier loss: 0.925344; batch adversarial loss: 0.426644\n",
      "epoch 26; iter: 0; batch classifier loss: 0.702343; batch adversarial loss: 0.330817\n",
      "epoch 26; iter: 200; batch classifier loss: 0.380134; batch adversarial loss: 0.371039\n",
      "epoch 26; iter: 400; batch classifier loss: 0.418968; batch adversarial loss: 0.408343\n",
      "epoch 26; iter: 600; batch classifier loss: 0.367295; batch adversarial loss: 0.372645\n",
      "epoch 27; iter: 0; batch classifier loss: 0.328907; batch adversarial loss: 0.471765\n",
      "epoch 27; iter: 200; batch classifier loss: 0.405634; batch adversarial loss: 0.449179\n",
      "epoch 27; iter: 400; batch classifier loss: 0.277503; batch adversarial loss: 0.509616\n",
      "epoch 27; iter: 600; batch classifier loss: 0.352682; batch adversarial loss: 0.420257\n",
      "epoch 28; iter: 0; batch classifier loss: 0.358035; batch adversarial loss: 0.341549\n",
      "epoch 28; iter: 200; batch classifier loss: 0.361748; batch adversarial loss: 0.371884\n",
      "epoch 28; iter: 400; batch classifier loss: 0.369027; batch adversarial loss: 0.382109\n",
      "epoch 28; iter: 600; batch classifier loss: 0.288929; batch adversarial loss: 0.378755\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411951; batch adversarial loss: 0.238399\n",
      "epoch 29; iter: 200; batch classifier loss: 0.349870; batch adversarial loss: 0.295382\n",
      "epoch 29; iter: 400; batch classifier loss: 0.551852; batch adversarial loss: 0.402566\n",
      "epoch 29; iter: 600; batch classifier loss: 0.439638; batch adversarial loss: 0.479585\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324736; batch adversarial loss: 0.401359\n",
      "epoch 30; iter: 200; batch classifier loss: 0.438363; batch adversarial loss: 0.434033\n",
      "epoch 30; iter: 400; batch classifier loss: 0.415692; batch adversarial loss: 0.294143\n",
      "epoch 30; iter: 600; batch classifier loss: 0.501552; batch adversarial loss: 0.428366\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320679; batch adversarial loss: 0.355828\n",
      "epoch 31; iter: 200; batch classifier loss: 0.410067; batch adversarial loss: 0.448035\n",
      "epoch 31; iter: 400; batch classifier loss: 0.281192; batch adversarial loss: 0.337829\n",
      "epoch 31; iter: 600; batch classifier loss: 0.372713; batch adversarial loss: 0.383080\n",
      "epoch 32; iter: 0; batch classifier loss: 0.286014; batch adversarial loss: 0.457557\n",
      "epoch 32; iter: 200; batch classifier loss: 0.579020; batch adversarial loss: 0.515998\n",
      "epoch 32; iter: 400; batch classifier loss: 0.372258; batch adversarial loss: 0.427336\n",
      "epoch 32; iter: 600; batch classifier loss: 0.344005; batch adversarial loss: 0.345049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.411679; batch adversarial loss: 0.464326\n",
      "epoch 33; iter: 200; batch classifier loss: 0.317247; batch adversarial loss: 0.517208\n",
      "epoch 33; iter: 400; batch classifier loss: 0.260352; batch adversarial loss: 0.411837\n",
      "epoch 33; iter: 600; batch classifier loss: 0.330968; batch adversarial loss: 0.405564\n",
      "epoch 34; iter: 0; batch classifier loss: 0.288827; batch adversarial loss: 0.344563\n",
      "epoch 34; iter: 200; batch classifier loss: 0.409048; batch adversarial loss: 0.476938\n",
      "epoch 34; iter: 400; batch classifier loss: 0.365854; batch adversarial loss: 0.442161\n",
      "epoch 34; iter: 600; batch classifier loss: 0.215393; batch adversarial loss: 0.426743\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254101; batch adversarial loss: 0.422688\n",
      "epoch 35; iter: 200; batch classifier loss: 0.319831; batch adversarial loss: 0.449584\n",
      "epoch 35; iter: 400; batch classifier loss: 0.418198; batch adversarial loss: 0.462386\n",
      "epoch 35; iter: 600; batch classifier loss: 0.310817; batch adversarial loss: 0.483271\n",
      "epoch 36; iter: 0; batch classifier loss: 0.377737; batch adversarial loss: 0.392104\n",
      "epoch 36; iter: 200; batch classifier loss: 0.356304; batch adversarial loss: 0.400133\n",
      "epoch 36; iter: 400; batch classifier loss: 0.270731; batch adversarial loss: 0.325451\n",
      "epoch 36; iter: 600; batch classifier loss: 0.228353; batch adversarial loss: 0.446873\n",
      "epoch 37; iter: 0; batch classifier loss: 0.279204; batch adversarial loss: 0.411702\n",
      "epoch 37; iter: 200; batch classifier loss: 0.337686; batch adversarial loss: 0.415133\n",
      "epoch 37; iter: 400; batch classifier loss: 0.362112; batch adversarial loss: 0.381843\n",
      "epoch 37; iter: 600; batch classifier loss: 0.323718; batch adversarial loss: 0.555169\n",
      "epoch 38; iter: 0; batch classifier loss: 0.378294; batch adversarial loss: 0.561940\n",
      "epoch 38; iter: 200; batch classifier loss: 0.283344; batch adversarial loss: 0.379613\n",
      "epoch 38; iter: 400; batch classifier loss: 0.470989; batch adversarial loss: 0.493729\n",
      "epoch 38; iter: 600; batch classifier loss: 0.552641; batch adversarial loss: 0.371167\n",
      "epoch 39; iter: 0; batch classifier loss: 0.330997; batch adversarial loss: 0.314682\n",
      "epoch 39; iter: 200; batch classifier loss: 0.300920; batch adversarial loss: 0.503757\n",
      "epoch 39; iter: 400; batch classifier loss: 0.344128; batch adversarial loss: 0.461636\n",
      "epoch 39; iter: 600; batch classifier loss: 0.269377; batch adversarial loss: 0.453923\n",
      "epoch 40; iter: 0; batch classifier loss: 0.369606; batch adversarial loss: 0.402070\n",
      "epoch 40; iter: 200; batch classifier loss: 0.456532; batch adversarial loss: 0.408973\n",
      "epoch 40; iter: 400; batch classifier loss: 0.301595; batch adversarial loss: 0.450343\n",
      "epoch 40; iter: 600; batch classifier loss: 0.396639; batch adversarial loss: 0.414566\n",
      "epoch 41; iter: 0; batch classifier loss: 0.274145; batch adversarial loss: 0.426330\n",
      "epoch 41; iter: 200; batch classifier loss: 0.174060; batch adversarial loss: 0.323562\n",
      "epoch 41; iter: 400; batch classifier loss: 0.398425; batch adversarial loss: 0.390145\n",
      "epoch 41; iter: 600; batch classifier loss: 0.276796; batch adversarial loss: 0.344997\n",
      "epoch 42; iter: 0; batch classifier loss: 0.308141; batch adversarial loss: 0.565921\n",
      "epoch 42; iter: 200; batch classifier loss: 0.240707; batch adversarial loss: 0.364876\n",
      "epoch 42; iter: 400; batch classifier loss: 0.476604; batch adversarial loss: 0.493348\n",
      "epoch 42; iter: 600; batch classifier loss: 0.369129; batch adversarial loss: 0.508851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.388865; batch adversarial loss: 0.378863\n",
      "epoch 43; iter: 200; batch classifier loss: 0.279740; batch adversarial loss: 0.446341\n",
      "epoch 43; iter: 400; batch classifier loss: 0.337691; batch adversarial loss: 0.423117\n",
      "epoch 43; iter: 600; batch classifier loss: 0.423945; batch adversarial loss: 0.423617\n",
      "epoch 44; iter: 0; batch classifier loss: 0.206089; batch adversarial loss: 0.440651\n",
      "epoch 44; iter: 200; batch classifier loss: 0.200197; batch adversarial loss: 0.319645\n",
      "epoch 44; iter: 400; batch classifier loss: 0.374191; batch adversarial loss: 0.504485\n",
      "epoch 44; iter: 600; batch classifier loss: 0.370941; batch adversarial loss: 0.523692\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432876; batch adversarial loss: 0.398683\n",
      "epoch 45; iter: 200; batch classifier loss: 0.387942; batch adversarial loss: 0.409808\n",
      "epoch 45; iter: 400; batch classifier loss: 0.366669; batch adversarial loss: 0.482765\n",
      "epoch 45; iter: 600; batch classifier loss: 0.277469; batch adversarial loss: 0.541335\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410153; batch adversarial loss: 0.269077\n",
      "epoch 46; iter: 200; batch classifier loss: 0.344768; batch adversarial loss: 0.383921\n",
      "epoch 46; iter: 400; batch classifier loss: 0.426072; batch adversarial loss: 0.434002\n",
      "epoch 46; iter: 600; batch classifier loss: 0.364285; batch adversarial loss: 0.442213\n",
      "epoch 47; iter: 0; batch classifier loss: 0.423788; batch adversarial loss: 0.408997\n",
      "epoch 47; iter: 200; batch classifier loss: 0.336183; batch adversarial loss: 0.435862\n",
      "epoch 47; iter: 400; batch classifier loss: 0.334223; batch adversarial loss: 0.478375\n",
      "epoch 47; iter: 600; batch classifier loss: 0.378285; batch adversarial loss: 0.543483\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426566; batch adversarial loss: 0.291250\n",
      "epoch 48; iter: 200; batch classifier loss: 0.412113; batch adversarial loss: 0.455002\n",
      "epoch 48; iter: 400; batch classifier loss: 0.267402; batch adversarial loss: 0.341748\n",
      "epoch 48; iter: 600; batch classifier loss: 0.414296; batch adversarial loss: 0.398591\n",
      "epoch 49; iter: 0; batch classifier loss: 0.608707; batch adversarial loss: 0.441883\n",
      "epoch 49; iter: 200; batch classifier loss: 0.233112; batch adversarial loss: 0.527745\n",
      "epoch 49; iter: 400; batch classifier loss: 0.300544; batch adversarial loss: 0.294227\n",
      "epoch 49; iter: 600; batch classifier loss: 0.403876; batch adversarial loss: 0.462744\n",
      "epoch 0; iter: 0; batch classifier loss: 17.139977; batch adversarial loss: 0.714878\n",
      "epoch 0; iter: 200; batch classifier loss: 6.081339; batch adversarial loss: 1.108505\n",
      "epoch 0; iter: 400; batch classifier loss: 4.254208; batch adversarial loss: 0.636792\n",
      "epoch 0; iter: 600; batch classifier loss: 1.841522; batch adversarial loss: 0.582182\n",
      "epoch 1; iter: 0; batch classifier loss: 3.439071; batch adversarial loss: 0.602937\n",
      "epoch 1; iter: 200; batch classifier loss: 5.046729; batch adversarial loss: 0.649761\n",
      "epoch 1; iter: 400; batch classifier loss: 3.303979; batch adversarial loss: 0.499933\n",
      "epoch 1; iter: 600; batch classifier loss: 1.232081; batch adversarial loss: 0.443718\n",
      "epoch 2; iter: 0; batch classifier loss: 0.700116; batch adversarial loss: 0.492723\n",
      "epoch 2; iter: 200; batch classifier loss: 1.321646; batch adversarial loss: 0.378635\n",
      "epoch 2; iter: 400; batch classifier loss: 0.736172; batch adversarial loss: 0.474739\n",
      "epoch 2; iter: 600; batch classifier loss: 0.343588; batch adversarial loss: 0.437471\n",
      "epoch 3; iter: 0; batch classifier loss: 3.024178; batch adversarial loss: 0.526902\n",
      "epoch 3; iter: 200; batch classifier loss: 0.950545; batch adversarial loss: 0.402966\n",
      "epoch 3; iter: 400; batch classifier loss: 0.733028; batch adversarial loss: 0.459578\n",
      "epoch 3; iter: 600; batch classifier loss: 0.473909; batch adversarial loss: 0.390321\n",
      "epoch 4; iter: 0; batch classifier loss: 1.817354; batch adversarial loss: 0.453959\n",
      "epoch 4; iter: 200; batch classifier loss: 0.861092; batch adversarial loss: 0.367408\n",
      "epoch 4; iter: 400; batch classifier loss: 0.627229; batch adversarial loss: 0.342097\n",
      "epoch 4; iter: 600; batch classifier loss: 1.193769; batch adversarial loss: 0.399086\n",
      "epoch 5; iter: 0; batch classifier loss: 0.338665; batch adversarial loss: 0.425980\n",
      "epoch 5; iter: 200; batch classifier loss: 1.185159; batch adversarial loss: 0.472319\n",
      "epoch 5; iter: 400; batch classifier loss: 0.330183; batch adversarial loss: 0.348416\n",
      "epoch 5; iter: 600; batch classifier loss: 0.496437; batch adversarial loss: 0.531555\n",
      "epoch 6; iter: 0; batch classifier loss: 0.415959; batch adversarial loss: 0.501366\n",
      "epoch 6; iter: 200; batch classifier loss: 0.362754; batch adversarial loss: 0.368670\n",
      "epoch 6; iter: 400; batch classifier loss: 0.434364; batch adversarial loss: 0.379116\n",
      "epoch 6; iter: 600; batch classifier loss: 0.569015; batch adversarial loss: 0.403379\n",
      "epoch 7; iter: 0; batch classifier loss: 0.221017; batch adversarial loss: 0.411540\n",
      "epoch 7; iter: 200; batch classifier loss: 0.371154; batch adversarial loss: 0.517112\n",
      "epoch 7; iter: 400; batch classifier loss: 0.445188; batch adversarial loss: 0.474999\n",
      "epoch 7; iter: 600; batch classifier loss: 1.204454; batch adversarial loss: 0.425455\n",
      "epoch 8; iter: 0; batch classifier loss: 0.323258; batch adversarial loss: 0.293083\n",
      "epoch 8; iter: 200; batch classifier loss: 0.451167; batch adversarial loss: 0.375130\n",
      "epoch 8; iter: 400; batch classifier loss: 0.301255; batch adversarial loss: 0.400586\n",
      "epoch 8; iter: 600; batch classifier loss: 0.348732; batch adversarial loss: 0.355618\n",
      "epoch 9; iter: 0; batch classifier loss: 0.365302; batch adversarial loss: 0.322913\n",
      "epoch 9; iter: 200; batch classifier loss: 0.297313; batch adversarial loss: 0.468706\n",
      "epoch 9; iter: 400; batch classifier loss: 0.301251; batch adversarial loss: 0.450594\n",
      "epoch 9; iter: 600; batch classifier loss: 0.319399; batch adversarial loss: 0.512940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487994; batch adversarial loss: 0.429052\n",
      "epoch 10; iter: 200; batch classifier loss: 0.340183; batch adversarial loss: 0.234890\n",
      "epoch 10; iter: 400; batch classifier loss: 0.427951; batch adversarial loss: 0.534560\n",
      "epoch 10; iter: 600; batch classifier loss: 0.422382; batch adversarial loss: 0.360131\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345439; batch adversarial loss: 0.491667\n",
      "epoch 11; iter: 200; batch classifier loss: 0.457137; batch adversarial loss: 0.312665\n",
      "epoch 11; iter: 400; batch classifier loss: 0.421958; batch adversarial loss: 0.294069\n",
      "epoch 11; iter: 600; batch classifier loss: 0.339668; batch adversarial loss: 0.293876\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396680; batch adversarial loss: 0.430931\n",
      "epoch 12; iter: 200; batch classifier loss: 0.339763; batch adversarial loss: 0.352326\n",
      "epoch 12; iter: 400; batch classifier loss: 0.302576; batch adversarial loss: 0.352225\n",
      "epoch 12; iter: 600; batch classifier loss: 0.316322; batch adversarial loss: 0.428356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485054; batch adversarial loss: 0.461418\n",
      "epoch 13; iter: 200; batch classifier loss: 0.294314; batch adversarial loss: 0.524941\n",
      "epoch 13; iter: 400; batch classifier loss: 0.320161; batch adversarial loss: 0.461339\n",
      "epoch 13; iter: 600; batch classifier loss: 0.426328; batch adversarial loss: 0.403225\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330921; batch adversarial loss: 0.386538\n",
      "epoch 14; iter: 200; batch classifier loss: 0.363345; batch adversarial loss: 0.364352\n",
      "epoch 14; iter: 400; batch classifier loss: 0.328736; batch adversarial loss: 0.293989\n",
      "epoch 14; iter: 600; batch classifier loss: 0.259625; batch adversarial loss: 0.418375\n",
      "epoch 15; iter: 0; batch classifier loss: 0.762159; batch adversarial loss: 0.294172\n",
      "epoch 15; iter: 200; batch classifier loss: 0.299778; batch adversarial loss: 0.407355\n",
      "epoch 15; iter: 400; batch classifier loss: 0.330005; batch adversarial loss: 0.294443\n",
      "epoch 15; iter: 600; batch classifier loss: 0.257091; batch adversarial loss: 0.398462\n",
      "epoch 16; iter: 0; batch classifier loss: 0.374107; batch adversarial loss: 0.486775\n",
      "epoch 16; iter: 200; batch classifier loss: 0.235522; batch adversarial loss: 0.501492\n",
      "epoch 16; iter: 400; batch classifier loss: 0.300869; batch adversarial loss: 0.372763\n",
      "epoch 16; iter: 600; batch classifier loss: 0.350946; batch adversarial loss: 0.322187\n",
      "epoch 17; iter: 0; batch classifier loss: 0.241301; batch adversarial loss: 0.566408\n",
      "epoch 17; iter: 200; batch classifier loss: 0.354321; batch adversarial loss: 0.384218\n",
      "epoch 17; iter: 400; batch classifier loss: 0.303879; batch adversarial loss: 0.371372\n",
      "epoch 17; iter: 600; batch classifier loss: 0.351863; batch adversarial loss: 0.434082\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300147; batch adversarial loss: 0.418885\n",
      "epoch 18; iter: 200; batch classifier loss: 0.439280; batch adversarial loss: 0.537665\n",
      "epoch 18; iter: 400; batch classifier loss: 0.376928; batch adversarial loss: 0.280973\n",
      "epoch 18; iter: 600; batch classifier loss: 0.392420; batch adversarial loss: 0.435090\n",
      "epoch 19; iter: 0; batch classifier loss: 0.339945; batch adversarial loss: 0.366316\n",
      "epoch 19; iter: 200; batch classifier loss: 0.294584; batch adversarial loss: 0.347663\n",
      "epoch 19; iter: 400; batch classifier loss: 0.439349; batch adversarial loss: 0.392508\n",
      "epoch 19; iter: 600; batch classifier loss: 0.265201; batch adversarial loss: 0.444320\n",
      "epoch 20; iter: 0; batch classifier loss: 0.501360; batch adversarial loss: 0.443543\n",
      "epoch 20; iter: 200; batch classifier loss: 0.346436; batch adversarial loss: 0.403713\n",
      "epoch 20; iter: 400; batch classifier loss: 0.314360; batch adversarial loss: 0.433311\n",
      "epoch 20; iter: 600; batch classifier loss: 0.307031; batch adversarial loss: 0.495491\n",
      "epoch 21; iter: 0; batch classifier loss: 0.276113; batch adversarial loss: 0.709521\n",
      "epoch 21; iter: 200; batch classifier loss: 0.352422; batch adversarial loss: 0.453244\n",
      "epoch 21; iter: 400; batch classifier loss: 0.279781; batch adversarial loss: 0.330147\n",
      "epoch 21; iter: 600; batch classifier loss: 0.457245; batch adversarial loss: 0.366392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433452; batch adversarial loss: 0.286656\n",
      "epoch 22; iter: 200; batch classifier loss: 0.381702; batch adversarial loss: 0.402876\n",
      "epoch 22; iter: 400; batch classifier loss: 0.373050; batch adversarial loss: 0.439469\n",
      "epoch 22; iter: 600; batch classifier loss: 0.427472; batch adversarial loss: 0.296276\n",
      "epoch 23; iter: 0; batch classifier loss: 0.252599; batch adversarial loss: 0.364162\n",
      "epoch 23; iter: 200; batch classifier loss: 0.392976; batch adversarial loss: 0.424939\n",
      "epoch 23; iter: 400; batch classifier loss: 0.402846; batch adversarial loss: 0.315562\n",
      "epoch 23; iter: 600; batch classifier loss: 0.395083; batch adversarial loss: 0.438413\n",
      "epoch 24; iter: 0; batch classifier loss: 0.298951; batch adversarial loss: 0.412432\n",
      "epoch 24; iter: 200; batch classifier loss: 0.338654; batch adversarial loss: 0.319853\n",
      "epoch 24; iter: 400; batch classifier loss: 0.336057; batch adversarial loss: 0.463819\n",
      "epoch 24; iter: 600; batch classifier loss: 0.382723; batch adversarial loss: 0.349767\n",
      "epoch 25; iter: 0; batch classifier loss: 0.367999; batch adversarial loss: 0.351273\n",
      "epoch 25; iter: 200; batch classifier loss: 0.351757; batch adversarial loss: 0.401501\n",
      "epoch 25; iter: 400; batch classifier loss: 0.344598; batch adversarial loss: 0.315069\n",
      "epoch 25; iter: 600; batch classifier loss: 0.263529; batch adversarial loss: 0.371792\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473702; batch adversarial loss: 0.429011\n",
      "epoch 26; iter: 200; batch classifier loss: 0.315078; batch adversarial loss: 0.379343\n",
      "epoch 26; iter: 400; batch classifier loss: 0.373925; batch adversarial loss: 0.413073\n",
      "epoch 26; iter: 600; batch classifier loss: 0.476957; batch adversarial loss: 0.236956\n",
      "epoch 27; iter: 0; batch classifier loss: 0.260558; batch adversarial loss: 0.267982\n",
      "epoch 27; iter: 200; batch classifier loss: 0.347150; batch adversarial loss: 0.511495\n",
      "epoch 27; iter: 400; batch classifier loss: 0.387068; batch adversarial loss: 0.322642\n",
      "epoch 27; iter: 600; batch classifier loss: 0.265667; batch adversarial loss: 0.422598\n",
      "epoch 28; iter: 0; batch classifier loss: 0.356240; batch adversarial loss: 0.569247\n",
      "epoch 28; iter: 200; batch classifier loss: 0.466410; batch adversarial loss: 0.343934\n",
      "epoch 28; iter: 400; batch classifier loss: 0.480448; batch adversarial loss: 0.431544\n",
      "epoch 28; iter: 600; batch classifier loss: 0.296928; batch adversarial loss: 0.378161\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397305; batch adversarial loss: 0.269953\n",
      "epoch 29; iter: 200; batch classifier loss: 0.402593; batch adversarial loss: 0.550170\n",
      "epoch 29; iter: 400; batch classifier loss: 0.422627; batch adversarial loss: 0.411874\n",
      "epoch 29; iter: 600; batch classifier loss: 0.436929; batch adversarial loss: 0.375957\n",
      "epoch 30; iter: 0; batch classifier loss: 0.364867; batch adversarial loss: 0.370125\n",
      "epoch 30; iter: 200; batch classifier loss: 0.542348; batch adversarial loss: 0.360224\n",
      "epoch 30; iter: 400; batch classifier loss: 0.398447; batch adversarial loss: 0.414921\n",
      "epoch 30; iter: 600; batch classifier loss: 0.509232; batch adversarial loss: 0.375612\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455764; batch adversarial loss: 0.420289\n",
      "epoch 31; iter: 200; batch classifier loss: 0.401720; batch adversarial loss: 0.377975\n",
      "epoch 31; iter: 400; batch classifier loss: 0.258909; batch adversarial loss: 0.463352\n",
      "epoch 31; iter: 600; batch classifier loss: 0.318684; batch adversarial loss: 0.480098\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320065; batch adversarial loss: 0.414407\n",
      "epoch 32; iter: 200; batch classifier loss: 0.474405; batch adversarial loss: 0.405851\n",
      "epoch 32; iter: 400; batch classifier loss: 0.388644; batch adversarial loss: 0.427580\n",
      "epoch 32; iter: 600; batch classifier loss: 0.307437; batch adversarial loss: 0.512868\n",
      "epoch 33; iter: 0; batch classifier loss: 0.276459; batch adversarial loss: 0.376858\n",
      "epoch 33; iter: 200; batch classifier loss: 0.462468; batch adversarial loss: 0.460877\n",
      "epoch 33; iter: 400; batch classifier loss: 0.349495; batch adversarial loss: 0.486951\n",
      "epoch 33; iter: 600; batch classifier loss: 0.407914; batch adversarial loss: 0.400909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.312435; batch adversarial loss: 0.399372\n",
      "epoch 34; iter: 200; batch classifier loss: 0.454125; batch adversarial loss: 0.570246\n",
      "epoch 34; iter: 400; batch classifier loss: 0.283426; batch adversarial loss: 0.400963\n",
      "epoch 34; iter: 600; batch classifier loss: 0.326859; batch adversarial loss: 0.324358\n",
      "epoch 35; iter: 0; batch classifier loss: 0.250130; batch adversarial loss: 0.346147\n",
      "epoch 35; iter: 200; batch classifier loss: 0.302207; batch adversarial loss: 0.344853\n",
      "epoch 35; iter: 400; batch classifier loss: 0.308213; batch adversarial loss: 0.423780\n",
      "epoch 35; iter: 600; batch classifier loss: 0.460001; batch adversarial loss: 0.375148\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353199; batch adversarial loss: 0.572600\n",
      "epoch 36; iter: 200; batch classifier loss: 0.467234; batch adversarial loss: 0.450642\n",
      "epoch 36; iter: 400; batch classifier loss: 0.397971; batch adversarial loss: 0.295097\n",
      "epoch 36; iter: 600; batch classifier loss: 0.289783; batch adversarial loss: 0.505282\n",
      "epoch 37; iter: 0; batch classifier loss: 0.258992; batch adversarial loss: 0.434507\n",
      "epoch 37; iter: 200; batch classifier loss: 0.277488; batch adversarial loss: 0.397885\n",
      "epoch 37; iter: 400; batch classifier loss: 0.249298; batch adversarial loss: 0.439627\n",
      "epoch 37; iter: 600; batch classifier loss: 0.245219; batch adversarial loss: 0.519375\n",
      "epoch 38; iter: 0; batch classifier loss: 0.405920; batch adversarial loss: 0.469760\n",
      "epoch 38; iter: 200; batch classifier loss: 0.362772; batch adversarial loss: 0.435326\n",
      "epoch 38; iter: 400; batch classifier loss: 0.272740; batch adversarial loss: 0.268164\n",
      "epoch 38; iter: 600; batch classifier loss: 0.386211; batch adversarial loss: 0.456440\n",
      "epoch 39; iter: 0; batch classifier loss: 0.271567; batch adversarial loss: 0.291533\n",
      "epoch 39; iter: 200; batch classifier loss: 0.227565; batch adversarial loss: 0.463685\n",
      "epoch 39; iter: 400; batch classifier loss: 0.243406; batch adversarial loss: 0.404756\n",
      "epoch 39; iter: 600; batch classifier loss: 0.341066; batch adversarial loss: 0.423324\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390848; batch adversarial loss: 0.553139\n",
      "epoch 40; iter: 200; batch classifier loss: 0.261593; batch adversarial loss: 0.416952\n",
      "epoch 40; iter: 400; batch classifier loss: 0.368983; batch adversarial loss: 0.326895\n",
      "epoch 40; iter: 600; batch classifier loss: 0.475712; batch adversarial loss: 0.461023\n",
      "epoch 41; iter: 0; batch classifier loss: 0.301418; batch adversarial loss: 0.467497\n",
      "epoch 41; iter: 200; batch classifier loss: 0.437033; batch adversarial loss: 0.451729\n",
      "epoch 41; iter: 400; batch classifier loss: 0.479784; batch adversarial loss: 0.430701\n",
      "epoch 41; iter: 600; batch classifier loss: 0.424699; batch adversarial loss: 0.514114\n",
      "epoch 42; iter: 0; batch classifier loss: 0.272387; batch adversarial loss: 0.345741\n",
      "epoch 42; iter: 200; batch classifier loss: 0.426381; batch adversarial loss: 0.423563\n",
      "epoch 42; iter: 400; batch classifier loss: 0.316673; batch adversarial loss: 0.370811\n",
      "epoch 42; iter: 600; batch classifier loss: 0.411140; batch adversarial loss: 0.483812\n",
      "epoch 43; iter: 0; batch classifier loss: 0.351366; batch adversarial loss: 0.375593\n",
      "epoch 43; iter: 200; batch classifier loss: 0.311440; batch adversarial loss: 0.461032\n",
      "epoch 43; iter: 400; batch classifier loss: 0.264315; batch adversarial loss: 0.420116\n",
      "epoch 43; iter: 600; batch classifier loss: 0.518497; batch adversarial loss: 0.463057\n",
      "epoch 44; iter: 0; batch classifier loss: 0.214063; batch adversarial loss: 0.434731\n",
      "epoch 44; iter: 200; batch classifier loss: 0.484684; batch adversarial loss: 0.319183\n",
      "epoch 44; iter: 400; batch classifier loss: 0.394500; batch adversarial loss: 0.613837\n",
      "epoch 44; iter: 600; batch classifier loss: 0.300982; batch adversarial loss: 0.377437\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476699; batch adversarial loss: 0.406184\n",
      "epoch 45; iter: 200; batch classifier loss: 0.412908; batch adversarial loss: 0.490583\n",
      "epoch 45; iter: 400; batch classifier loss: 0.474240; batch adversarial loss: 0.519372\n",
      "epoch 45; iter: 600; batch classifier loss: 0.238617; batch adversarial loss: 0.571631\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441581; batch adversarial loss: 0.486590\n",
      "epoch 46; iter: 200; batch classifier loss: 0.249948; batch adversarial loss: 0.539018\n",
      "epoch 46; iter: 400; batch classifier loss: 0.267421; batch adversarial loss: 0.436176\n",
      "epoch 46; iter: 600; batch classifier loss: 0.382361; batch adversarial loss: 0.499701\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398568; batch adversarial loss: 0.516487\n",
      "epoch 47; iter: 200; batch classifier loss: 0.549511; batch adversarial loss: 0.428827\n",
      "epoch 47; iter: 400; batch classifier loss: 0.495499; batch adversarial loss: 0.452492\n",
      "epoch 47; iter: 600; batch classifier loss: 0.374071; batch adversarial loss: 0.274741\n",
      "epoch 48; iter: 0; batch classifier loss: 0.323233; batch adversarial loss: 0.451617\n",
      "epoch 48; iter: 200; batch classifier loss: 0.356503; batch adversarial loss: 0.433245\n",
      "epoch 48; iter: 400; batch classifier loss: 0.383627; batch adversarial loss: 0.326086\n",
      "epoch 48; iter: 600; batch classifier loss: 0.502405; batch adversarial loss: 0.411752\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400663; batch adversarial loss: 0.319903\n",
      "epoch 49; iter: 200; batch classifier loss: 0.458870; batch adversarial loss: 0.427201\n",
      "epoch 49; iter: 400; batch classifier loss: 0.478181; batch adversarial loss: 0.542586\n",
      "epoch 49; iter: 600; batch classifier loss: 0.337381; batch adversarial loss: 0.320328\n",
      "epoch 0; iter: 0; batch classifier loss: 7.560465; batch adversarial loss: 0.666568\n",
      "epoch 0; iter: 200; batch classifier loss: 5.009445; batch adversarial loss: 0.608244\n",
      "epoch 0; iter: 400; batch classifier loss: 5.093370; batch adversarial loss: 0.595383\n",
      "epoch 0; iter: 600; batch classifier loss: 2.474478; batch adversarial loss: 0.503575\n",
      "epoch 1; iter: 0; batch classifier loss: 6.211792; batch adversarial loss: 0.483345\n",
      "epoch 1; iter: 200; batch classifier loss: 2.247880; batch adversarial loss: 0.438971\n",
      "epoch 1; iter: 400; batch classifier loss: 0.521136; batch adversarial loss: 0.454295\n",
      "epoch 1; iter: 600; batch classifier loss: 2.714310; batch adversarial loss: 0.383095\n",
      "epoch 2; iter: 0; batch classifier loss: 0.905908; batch adversarial loss: 0.415512\n",
      "epoch 2; iter: 200; batch classifier loss: 1.380243; batch adversarial loss: 0.431298\n",
      "epoch 2; iter: 400; batch classifier loss: 0.486540; batch adversarial loss: 0.473940\n",
      "epoch 2; iter: 600; batch classifier loss: 1.878046; batch adversarial loss: 0.354827\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677076; batch adversarial loss: 0.326446\n",
      "epoch 3; iter: 200; batch classifier loss: 0.768954; batch adversarial loss: 0.381456\n",
      "epoch 3; iter: 400; batch classifier loss: 1.839225; batch adversarial loss: 0.374494\n",
      "epoch 3; iter: 600; batch classifier loss: 0.407336; batch adversarial loss: 0.361373\n",
      "epoch 4; iter: 0; batch classifier loss: 0.323826; batch adversarial loss: 0.551337\n",
      "epoch 4; iter: 200; batch classifier loss: 0.454288; batch adversarial loss: 0.451587\n",
      "epoch 4; iter: 400; batch classifier loss: 1.183927; batch adversarial loss: 0.402718\n",
      "epoch 4; iter: 600; batch classifier loss: 0.654206; batch adversarial loss: 0.354036\n",
      "epoch 5; iter: 0; batch classifier loss: 0.424248; batch adversarial loss: 0.349615\n",
      "epoch 5; iter: 200; batch classifier loss: 0.264066; batch adversarial loss: 0.400481\n",
      "epoch 5; iter: 400; batch classifier loss: 0.349048; batch adversarial loss: 0.409878\n",
      "epoch 5; iter: 600; batch classifier loss: 0.473509; batch adversarial loss: 0.456946\n",
      "epoch 6; iter: 0; batch classifier loss: 0.445345; batch adversarial loss: 0.412942\n",
      "epoch 6; iter: 200; batch classifier loss: 0.384066; batch adversarial loss: 0.451331\n",
      "epoch 6; iter: 400; batch classifier loss: 0.762089; batch adversarial loss: 0.625056\n",
      "epoch 6; iter: 600; batch classifier loss: 0.415666; batch adversarial loss: 0.427184\n",
      "epoch 7; iter: 0; batch classifier loss: 0.413100; batch adversarial loss: 0.380394\n",
      "epoch 7; iter: 200; batch classifier loss: 0.262031; batch adversarial loss: 0.433709\n",
      "epoch 7; iter: 400; batch classifier loss: 0.338390; batch adversarial loss: 0.428655\n",
      "epoch 7; iter: 600; batch classifier loss: 0.409166; batch adversarial loss: 0.403921\n",
      "epoch 8; iter: 0; batch classifier loss: 0.221594; batch adversarial loss: 0.565063\n",
      "epoch 8; iter: 200; batch classifier loss: 0.308550; batch adversarial loss: 0.450910\n",
      "epoch 8; iter: 400; batch classifier loss: 0.287281; batch adversarial loss: 0.403130\n",
      "epoch 8; iter: 600; batch classifier loss: 0.446820; batch adversarial loss: 0.378304\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474045; batch adversarial loss: 0.324194\n",
      "epoch 9; iter: 200; batch classifier loss: 0.326185; batch adversarial loss: 0.482673\n",
      "epoch 9; iter: 400; batch classifier loss: 0.256252; batch adversarial loss: 0.495216\n",
      "epoch 9; iter: 600; batch classifier loss: 0.303340; batch adversarial loss: 0.351056\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386319; batch adversarial loss: 0.467369\n",
      "epoch 10; iter: 200; batch classifier loss: 0.260867; batch adversarial loss: 0.392228\n",
      "epoch 10; iter: 400; batch classifier loss: 0.364243; batch adversarial loss: 0.341790\n",
      "epoch 10; iter: 600; batch classifier loss: 0.194916; batch adversarial loss: 0.375232\n",
      "epoch 11; iter: 0; batch classifier loss: 0.445333; batch adversarial loss: 0.315538\n",
      "epoch 11; iter: 200; batch classifier loss: 0.387591; batch adversarial loss: 0.344036\n",
      "epoch 11; iter: 400; batch classifier loss: 0.328731; batch adversarial loss: 0.425773\n",
      "epoch 11; iter: 600; batch classifier loss: 0.388669; batch adversarial loss: 0.461562\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356028; batch adversarial loss: 0.403913\n",
      "epoch 12; iter: 200; batch classifier loss: 0.518575; batch adversarial loss: 0.262868\n",
      "epoch 12; iter: 400; batch classifier loss: 0.328573; batch adversarial loss: 0.317447\n",
      "epoch 12; iter: 600; batch classifier loss: 0.272329; batch adversarial loss: 0.379101\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328978; batch adversarial loss: 0.514515\n",
      "epoch 13; iter: 200; batch classifier loss: 0.339593; batch adversarial loss: 0.351247\n",
      "epoch 13; iter: 400; batch classifier loss: 0.238844; batch adversarial loss: 0.404166\n",
      "epoch 13; iter: 600; batch classifier loss: 0.382976; batch adversarial loss: 0.379445\n",
      "epoch 14; iter: 0; batch classifier loss: 0.307281; batch adversarial loss: 0.349324\n",
      "epoch 14; iter: 200; batch classifier loss: 0.310055; batch adversarial loss: 0.412178\n",
      "epoch 14; iter: 400; batch classifier loss: 0.356869; batch adversarial loss: 0.454108\n",
      "epoch 14; iter: 600; batch classifier loss: 0.355654; batch adversarial loss: 0.373175\n",
      "epoch 15; iter: 0; batch classifier loss: 0.367382; batch adversarial loss: 0.478261\n",
      "epoch 15; iter: 200; batch classifier loss: 0.412183; batch adversarial loss: 0.465756\n",
      "epoch 15; iter: 400; batch classifier loss: 0.334483; batch adversarial loss: 0.433358\n",
      "epoch 15; iter: 600; batch classifier loss: 0.333786; batch adversarial loss: 0.514121\n",
      "epoch 16; iter: 0; batch classifier loss: 0.313217; batch adversarial loss: 0.524093\n",
      "epoch 16; iter: 200; batch classifier loss: 0.362473; batch adversarial loss: 0.428875\n",
      "epoch 16; iter: 400; batch classifier loss: 0.240530; batch adversarial loss: 0.349451\n",
      "epoch 16; iter: 600; batch classifier loss: 0.315776; batch adversarial loss: 0.354345\n",
      "epoch 17; iter: 0; batch classifier loss: 0.351050; batch adversarial loss: 0.449459\n",
      "epoch 17; iter: 200; batch classifier loss: 0.262244; batch adversarial loss: 0.241453\n",
      "epoch 17; iter: 400; batch classifier loss: 0.342015; batch adversarial loss: 0.399948\n",
      "epoch 17; iter: 600; batch classifier loss: 0.414338; batch adversarial loss: 0.394845\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306688; batch adversarial loss: 0.477046\n",
      "epoch 18; iter: 200; batch classifier loss: 0.290986; batch adversarial loss: 0.372093\n",
      "epoch 18; iter: 400; batch classifier loss: 0.380650; batch adversarial loss: 0.465165\n",
      "epoch 18; iter: 600; batch classifier loss: 0.443803; batch adversarial loss: 0.465254\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307174; batch adversarial loss: 0.414036\n",
      "epoch 19; iter: 200; batch classifier loss: 0.303304; batch adversarial loss: 0.713130\n",
      "epoch 19; iter: 400; batch classifier loss: 0.283678; batch adversarial loss: 0.456954\n",
      "epoch 19; iter: 600; batch classifier loss: 0.614730; batch adversarial loss: 0.262878\n",
      "epoch 20; iter: 0; batch classifier loss: 0.320113; batch adversarial loss: 0.480761\n",
      "epoch 20; iter: 200; batch classifier loss: 0.306729; batch adversarial loss: 0.423722\n",
      "epoch 20; iter: 400; batch classifier loss: 0.381540; batch adversarial loss: 0.469583\n",
      "epoch 20; iter: 600; batch classifier loss: 0.319956; batch adversarial loss: 0.495102\n",
      "epoch 21; iter: 0; batch classifier loss: 0.361383; batch adversarial loss: 0.407263\n",
      "epoch 21; iter: 200; batch classifier loss: 0.249128; batch adversarial loss: 0.318605\n",
      "epoch 21; iter: 400; batch classifier loss: 0.183164; batch adversarial loss: 0.682316\n",
      "epoch 21; iter: 600; batch classifier loss: 0.477725; batch adversarial loss: 0.417120\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372374; batch adversarial loss: 0.374585\n",
      "epoch 22; iter: 200; batch classifier loss: 0.470104; batch adversarial loss: 0.370798\n",
      "epoch 22; iter: 400; batch classifier loss: 0.383067; batch adversarial loss: 0.388344\n",
      "epoch 22; iter: 600; batch classifier loss: 0.334332; batch adversarial loss: 0.487779\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238021; batch adversarial loss: 0.460217\n",
      "epoch 23; iter: 200; batch classifier loss: 0.326117; batch adversarial loss: 0.492605\n",
      "epoch 23; iter: 400; batch classifier loss: 0.318781; batch adversarial loss: 0.235032\n",
      "epoch 23; iter: 600; batch classifier loss: 0.265259; batch adversarial loss: 0.537056\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511947; batch adversarial loss: 0.524918\n",
      "epoch 24; iter: 200; batch classifier loss: 0.360690; batch adversarial loss: 0.402245\n",
      "epoch 24; iter: 400; batch classifier loss: 0.344718; batch adversarial loss: 0.342597\n",
      "epoch 24; iter: 600; batch classifier loss: 0.448777; batch adversarial loss: 0.640839\n",
      "epoch 25; iter: 0; batch classifier loss: 0.384121; batch adversarial loss: 0.494225\n",
      "epoch 25; iter: 200; batch classifier loss: 0.418326; batch adversarial loss: 0.336156\n",
      "epoch 25; iter: 400; batch classifier loss: 0.299368; batch adversarial loss: 0.479547\n",
      "epoch 25; iter: 600; batch classifier loss: 0.385305; batch adversarial loss: 0.435869\n",
      "epoch 26; iter: 0; batch classifier loss: 0.405776; batch adversarial loss: 0.425055\n",
      "epoch 26; iter: 200; batch classifier loss: 0.371922; batch adversarial loss: 0.413585\n",
      "epoch 26; iter: 400; batch classifier loss: 0.288286; batch adversarial loss: 0.451678\n",
      "epoch 26; iter: 600; batch classifier loss: 0.350378; batch adversarial loss: 0.493048\n",
      "epoch 27; iter: 0; batch classifier loss: 0.370567; batch adversarial loss: 0.629597\n",
      "epoch 27; iter: 200; batch classifier loss: 0.335264; batch adversarial loss: 0.588525\n",
      "epoch 27; iter: 400; batch classifier loss: 0.368715; batch adversarial loss: 0.400227\n",
      "epoch 27; iter: 600; batch classifier loss: 0.316859; batch adversarial loss: 0.455626\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369935; batch adversarial loss: 0.318127\n",
      "epoch 28; iter: 200; batch classifier loss: 0.356908; batch adversarial loss: 0.408958\n",
      "epoch 28; iter: 400; batch classifier loss: 0.383703; batch adversarial loss: 0.353238\n",
      "epoch 28; iter: 600; batch classifier loss: 0.405423; batch adversarial loss: 0.302185\n",
      "epoch 29; iter: 0; batch classifier loss: 0.381157; batch adversarial loss: 0.428129\n",
      "epoch 29; iter: 200; batch classifier loss: 0.333133; batch adversarial loss: 0.376256\n",
      "epoch 29; iter: 400; batch classifier loss: 0.413194; batch adversarial loss: 0.353177\n",
      "epoch 29; iter: 600; batch classifier loss: 0.362301; batch adversarial loss: 0.413502\n",
      "epoch 30; iter: 0; batch classifier loss: 0.333224; batch adversarial loss: 0.291451\n",
      "epoch 30; iter: 200; batch classifier loss: 0.338068; batch adversarial loss: 0.470975\n",
      "epoch 30; iter: 400; batch classifier loss: 0.457688; batch adversarial loss: 0.444642\n",
      "epoch 30; iter: 600; batch classifier loss: 0.197074; batch adversarial loss: 0.487279\n",
      "epoch 31; iter: 0; batch classifier loss: 0.344752; batch adversarial loss: 0.494148\n",
      "epoch 31; iter: 200; batch classifier loss: 0.417316; batch adversarial loss: 0.508463\n",
      "epoch 31; iter: 400; batch classifier loss: 0.418077; batch adversarial loss: 0.425102\n",
      "epoch 31; iter: 600; batch classifier loss: 0.293835; batch adversarial loss: 0.438618\n",
      "epoch 32; iter: 0; batch classifier loss: 0.249067; batch adversarial loss: 0.315318\n",
      "epoch 32; iter: 200; batch classifier loss: 0.271687; batch adversarial loss: 0.563562\n",
      "epoch 32; iter: 400; batch classifier loss: 0.449723; batch adversarial loss: 0.438483\n",
      "epoch 32; iter: 600; batch classifier loss: 0.411520; batch adversarial loss: 0.352491\n",
      "epoch 33; iter: 0; batch classifier loss: 0.362867; batch adversarial loss: 0.430878\n",
      "epoch 33; iter: 200; batch classifier loss: 0.357159; batch adversarial loss: 0.483135\n",
      "epoch 33; iter: 400; batch classifier loss: 0.486321; batch adversarial loss: 0.427118\n",
      "epoch 33; iter: 600; batch classifier loss: 0.388033; batch adversarial loss: 0.538302\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422108; batch adversarial loss: 0.488616\n",
      "epoch 34; iter: 200; batch classifier loss: 0.300354; batch adversarial loss: 0.487473\n",
      "epoch 34; iter: 400; batch classifier loss: 0.275760; batch adversarial loss: 0.666500\n",
      "epoch 34; iter: 600; batch classifier loss: 0.548491; batch adversarial loss: 0.406867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.255523; batch adversarial loss: 0.379972\n",
      "epoch 35; iter: 200; batch classifier loss: 0.438786; batch adversarial loss: 0.300601\n",
      "epoch 35; iter: 400; batch classifier loss: 0.181364; batch adversarial loss: 0.454906\n",
      "epoch 35; iter: 600; batch classifier loss: 0.500127; batch adversarial loss: 0.383660\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347875; batch adversarial loss: 0.423356\n",
      "epoch 36; iter: 200; batch classifier loss: 0.293749; batch adversarial loss: 0.371199\n",
      "epoch 36; iter: 400; batch classifier loss: 0.315008; batch adversarial loss: 0.434872\n",
      "epoch 36; iter: 600; batch classifier loss: 0.258100; batch adversarial loss: 0.345508\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495055; batch adversarial loss: 0.372142\n",
      "epoch 37; iter: 200; batch classifier loss: 0.356716; batch adversarial loss: 0.324184\n",
      "epoch 37; iter: 400; batch classifier loss: 0.414270; batch adversarial loss: 0.414995\n",
      "epoch 37; iter: 600; batch classifier loss: 0.355933; batch adversarial loss: 0.616586\n",
      "epoch 38; iter: 0; batch classifier loss: 0.287804; batch adversarial loss: 0.296131\n",
      "epoch 38; iter: 200; batch classifier loss: 0.365327; batch adversarial loss: 0.317025\n",
      "epoch 38; iter: 400; batch classifier loss: 0.410239; batch adversarial loss: 0.369612\n",
      "epoch 38; iter: 600; batch classifier loss: 0.543862; batch adversarial loss: 0.514197\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425303; batch adversarial loss: 0.460561\n",
      "epoch 39; iter: 200; batch classifier loss: 0.327126; batch adversarial loss: 0.503767\n",
      "epoch 39; iter: 400; batch classifier loss: 0.638908; batch adversarial loss: 0.345503\n",
      "epoch 39; iter: 600; batch classifier loss: 0.369918; batch adversarial loss: 0.593136\n",
      "epoch 40; iter: 0; batch classifier loss: 0.331567; batch adversarial loss: 0.532807\n",
      "epoch 40; iter: 200; batch classifier loss: 0.383325; batch adversarial loss: 0.494122\n",
      "epoch 40; iter: 400; batch classifier loss: 0.356931; batch adversarial loss: 0.581272\n",
      "epoch 40; iter: 600; batch classifier loss: 0.285876; batch adversarial loss: 0.431412\n",
      "epoch 41; iter: 0; batch classifier loss: 0.307969; batch adversarial loss: 0.392832\n",
      "epoch 41; iter: 200; batch classifier loss: 0.228375; batch adversarial loss: 0.448500\n",
      "epoch 41; iter: 400; batch classifier loss: 0.529751; batch adversarial loss: 0.465919\n",
      "epoch 41; iter: 600; batch classifier loss: 0.325444; batch adversarial loss: 0.484384\n",
      "epoch 42; iter: 0; batch classifier loss: 0.232473; batch adversarial loss: 0.379505\n",
      "epoch 42; iter: 200; batch classifier loss: 0.365924; batch adversarial loss: 0.341777\n",
      "epoch 42; iter: 400; batch classifier loss: 0.201655; batch adversarial loss: 0.372102\n",
      "epoch 42; iter: 600; batch classifier loss: 0.310043; batch adversarial loss: 0.465829\n",
      "epoch 43; iter: 0; batch classifier loss: 0.364564; batch adversarial loss: 0.435592\n",
      "epoch 43; iter: 200; batch classifier loss: 0.357390; batch adversarial loss: 0.518381\n",
      "epoch 43; iter: 400; batch classifier loss: 0.518250; batch adversarial loss: 0.409438\n",
      "epoch 43; iter: 600; batch classifier loss: 0.357817; batch adversarial loss: 0.404684\n",
      "epoch 44; iter: 0; batch classifier loss: 0.250605; batch adversarial loss: 0.425230\n",
      "epoch 44; iter: 200; batch classifier loss: 0.380471; batch adversarial loss: 0.536520\n",
      "epoch 44; iter: 400; batch classifier loss: 0.303389; batch adversarial loss: 0.351917\n",
      "epoch 44; iter: 600; batch classifier loss: 0.302082; batch adversarial loss: 0.397299\n",
      "epoch 45; iter: 0; batch classifier loss: 0.611499; batch adversarial loss: 0.413183\n",
      "epoch 45; iter: 200; batch classifier loss: 0.479736; batch adversarial loss: 0.377042\n",
      "epoch 45; iter: 400; batch classifier loss: 0.367367; batch adversarial loss: 0.427297\n",
      "epoch 45; iter: 600; batch classifier loss: 0.589856; batch adversarial loss: 0.432543\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402439; batch adversarial loss: 0.431847\n",
      "epoch 46; iter: 200; batch classifier loss: 0.417749; batch adversarial loss: 0.511322\n",
      "epoch 46; iter: 400; batch classifier loss: 0.311530; batch adversarial loss: 0.508092\n",
      "epoch 46; iter: 600; batch classifier loss: 0.377001; batch adversarial loss: 0.565606\n",
      "epoch 47; iter: 0; batch classifier loss: 0.335162; batch adversarial loss: 0.394746\n",
      "epoch 47; iter: 200; batch classifier loss: 0.470025; batch adversarial loss: 0.535862\n",
      "epoch 47; iter: 400; batch classifier loss: 0.530698; batch adversarial loss: 0.457753\n",
      "epoch 47; iter: 600; batch classifier loss: 0.361367; batch adversarial loss: 0.519146\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464657; batch adversarial loss: 0.474883\n",
      "epoch 48; iter: 200; batch classifier loss: 0.230970; batch adversarial loss: 0.342119\n",
      "epoch 48; iter: 400; batch classifier loss: 0.220085; batch adversarial loss: 0.510701\n",
      "epoch 48; iter: 600; batch classifier loss: 0.341593; batch adversarial loss: 0.351656\n",
      "epoch 49; iter: 0; batch classifier loss: 0.544826; batch adversarial loss: 0.421565\n",
      "epoch 49; iter: 200; batch classifier loss: 0.229205; batch adversarial loss: 0.397377\n",
      "epoch 49; iter: 400; batch classifier loss: 0.415513; batch adversarial loss: 0.460262\n",
      "epoch 49; iter: 600; batch classifier loss: 0.330869; batch adversarial loss: 0.325229\n",
      "epoch 0; iter: 0; batch classifier loss: 19.106993; batch adversarial loss: 1.068791\n",
      "epoch 0; iter: 200; batch classifier loss: 23.371002; batch adversarial loss: 0.794975\n",
      "epoch 0; iter: 400; batch classifier loss: 4.110752; batch adversarial loss: 0.620267\n",
      "epoch 0; iter: 600; batch classifier loss: 9.195071; batch adversarial loss: 0.544552\n",
      "epoch 1; iter: 0; batch classifier loss: 15.423362; batch adversarial loss: 0.570551\n",
      "epoch 1; iter: 200; batch classifier loss: 1.619472; batch adversarial loss: 0.530933\n",
      "epoch 1; iter: 400; batch classifier loss: 4.065571; batch adversarial loss: 0.489110\n",
      "epoch 1; iter: 600; batch classifier loss: 2.165277; batch adversarial loss: 0.442711\n",
      "epoch 2; iter: 0; batch classifier loss: 0.268039; batch adversarial loss: 0.427414\n",
      "epoch 2; iter: 200; batch classifier loss: 3.839258; batch adversarial loss: 0.486572\n",
      "epoch 2; iter: 400; batch classifier loss: 0.409106; batch adversarial loss: 0.487055\n",
      "epoch 2; iter: 600; batch classifier loss: 3.862937; batch adversarial loss: 0.446510\n",
      "epoch 3; iter: 0; batch classifier loss: 0.415427; batch adversarial loss: 0.474906\n",
      "epoch 3; iter: 200; batch classifier loss: 0.255366; batch adversarial loss: 0.341259\n",
      "epoch 3; iter: 400; batch classifier loss: 1.231311; batch adversarial loss: 0.418750\n",
      "epoch 3; iter: 600; batch classifier loss: 0.364773; batch adversarial loss: 0.508456\n",
      "epoch 4; iter: 0; batch classifier loss: 0.412563; batch adversarial loss: 0.376391\n",
      "epoch 4; iter: 200; batch classifier loss: 0.593156; batch adversarial loss: 0.410352\n",
      "epoch 4; iter: 400; batch classifier loss: 0.821998; batch adversarial loss: 0.493491\n",
      "epoch 4; iter: 600; batch classifier loss: 0.424182; batch adversarial loss: 0.397658\n",
      "epoch 5; iter: 0; batch classifier loss: 0.425993; batch adversarial loss: 0.386284\n",
      "epoch 5; iter: 200; batch classifier loss: 0.468015; batch adversarial loss: 0.249469\n",
      "epoch 5; iter: 400; batch classifier loss: 0.491590; batch adversarial loss: 0.373912\n",
      "epoch 5; iter: 600; batch classifier loss: 0.578315; batch adversarial loss: 0.381144\n",
      "epoch 6; iter: 0; batch classifier loss: 0.427076; batch adversarial loss: 0.394191\n",
      "epoch 6; iter: 200; batch classifier loss: 0.455853; batch adversarial loss: 0.513525\n",
      "epoch 6; iter: 400; batch classifier loss: 0.428101; batch adversarial loss: 0.421259\n",
      "epoch 6; iter: 600; batch classifier loss: 0.397718; batch adversarial loss: 0.315292\n",
      "epoch 7; iter: 0; batch classifier loss: 0.433655; batch adversarial loss: 0.299825\n",
      "epoch 7; iter: 200; batch classifier loss: 0.368307; batch adversarial loss: 0.308372\n",
      "epoch 7; iter: 400; batch classifier loss: 0.329464; batch adversarial loss: 0.447917\n",
      "epoch 7; iter: 600; batch classifier loss: 0.393900; batch adversarial loss: 0.437929\n",
      "epoch 8; iter: 0; batch classifier loss: 0.350331; batch adversarial loss: 0.303184\n",
      "epoch 8; iter: 200; batch classifier loss: 0.499080; batch adversarial loss: 0.561854\n",
      "epoch 8; iter: 400; batch classifier loss: 0.359272; batch adversarial loss: 0.370625\n",
      "epoch 8; iter: 600; batch classifier loss: 0.494251; batch adversarial loss: 0.348080\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511143; batch adversarial loss: 0.321708\n",
      "epoch 9; iter: 200; batch classifier loss: 0.255326; batch adversarial loss: 0.380426\n",
      "epoch 9; iter: 400; batch classifier loss: 0.378127; batch adversarial loss: 0.474724\n",
      "epoch 9; iter: 600; batch classifier loss: 0.390284; batch adversarial loss: 0.379883\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292075; batch adversarial loss: 0.435359\n",
      "epoch 10; iter: 200; batch classifier loss: 0.339868; batch adversarial loss: 0.406378\n",
      "epoch 10; iter: 400; batch classifier loss: 0.340451; batch adversarial loss: 0.482836\n",
      "epoch 10; iter: 600; batch classifier loss: 0.407814; batch adversarial loss: 0.324425\n",
      "epoch 11; iter: 0; batch classifier loss: 0.306013; batch adversarial loss: 0.335976\n",
      "epoch 11; iter: 200; batch classifier loss: 0.373630; batch adversarial loss: 0.487220\n",
      "epoch 11; iter: 400; batch classifier loss: 0.391976; batch adversarial loss: 0.515987\n",
      "epoch 11; iter: 600; batch classifier loss: 0.332924; batch adversarial loss: 0.454720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.436099; batch adversarial loss: 0.308874\n",
      "epoch 12; iter: 200; batch classifier loss: 0.399301; batch adversarial loss: 0.239537\n",
      "epoch 12; iter: 400; batch classifier loss: 0.216653; batch adversarial loss: 0.368097\n",
      "epoch 12; iter: 600; batch classifier loss: 0.297665; batch adversarial loss: 0.403531\n",
      "epoch 13; iter: 0; batch classifier loss: 0.245334; batch adversarial loss: 0.293720\n",
      "epoch 13; iter: 200; batch classifier loss: 0.323059; batch adversarial loss: 0.409159\n",
      "epoch 13; iter: 400; batch classifier loss: 0.301350; batch adversarial loss: 0.370593\n",
      "epoch 13; iter: 600; batch classifier loss: 0.294455; batch adversarial loss: 0.527586\n",
      "epoch 14; iter: 0; batch classifier loss: 0.329735; batch adversarial loss: 0.455283\n",
      "epoch 14; iter: 200; batch classifier loss: 0.484120; batch adversarial loss: 0.457365\n",
      "epoch 14; iter: 400; batch classifier loss: 0.390255; batch adversarial loss: 0.429100\n",
      "epoch 14; iter: 600; batch classifier loss: 0.311234; batch adversarial loss: 0.400115\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424687; batch adversarial loss: 0.374033\n",
      "epoch 15; iter: 200; batch classifier loss: 0.951952; batch adversarial loss: 0.430249\n",
      "epoch 15; iter: 400; batch classifier loss: 0.429321; batch adversarial loss: 0.322819\n",
      "epoch 15; iter: 600; batch classifier loss: 0.345938; batch adversarial loss: 0.368665\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460674; batch adversarial loss: 0.356604\n",
      "epoch 16; iter: 200; batch classifier loss: 0.374296; batch adversarial loss: 0.289136\n",
      "epoch 16; iter: 400; batch classifier loss: 0.188507; batch adversarial loss: 0.294314\n",
      "epoch 16; iter: 600; batch classifier loss: 0.359349; batch adversarial loss: 0.397569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.388762; batch adversarial loss: 0.349781\n",
      "epoch 17; iter: 200; batch classifier loss: 0.474633; batch adversarial loss: 0.704253\n",
      "epoch 17; iter: 400; batch classifier loss: 0.366219; batch adversarial loss: 0.456396\n",
      "epoch 17; iter: 600; batch classifier loss: 0.391448; batch adversarial loss: 0.494560\n",
      "epoch 18; iter: 0; batch classifier loss: 0.592205; batch adversarial loss: 0.431346\n",
      "epoch 18; iter: 200; batch classifier loss: 0.499842; batch adversarial loss: 0.379937\n",
      "epoch 18; iter: 400; batch classifier loss: 0.605880; batch adversarial loss: 0.388459\n",
      "epoch 18; iter: 600; batch classifier loss: 0.371592; batch adversarial loss: 0.345660\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335239; batch adversarial loss: 0.377487\n",
      "epoch 19; iter: 200; batch classifier loss: 0.481747; batch adversarial loss: 0.401849\n",
      "epoch 19; iter: 400; batch classifier loss: 0.539543; batch adversarial loss: 0.378630\n",
      "epoch 19; iter: 600; batch classifier loss: 0.456353; batch adversarial loss: 0.426263\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368942; batch adversarial loss: 0.409692\n",
      "epoch 20; iter: 200; batch classifier loss: 0.473989; batch adversarial loss: 0.406023\n",
      "epoch 20; iter: 400; batch classifier loss: 0.317719; batch adversarial loss: 0.385012\n",
      "epoch 20; iter: 600; batch classifier loss: 0.413564; batch adversarial loss: 0.451771\n",
      "epoch 21; iter: 0; batch classifier loss: 0.348427; batch adversarial loss: 0.453494\n",
      "epoch 21; iter: 200; batch classifier loss: 0.376156; batch adversarial loss: 0.352479\n",
      "epoch 21; iter: 400; batch classifier loss: 0.493341; batch adversarial loss: 0.297932\n",
      "epoch 21; iter: 600; batch classifier loss: 0.580020; batch adversarial loss: 0.380308\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440208; batch adversarial loss: 0.404187\n",
      "epoch 22; iter: 200; batch classifier loss: 0.648027; batch adversarial loss: 0.294538\n",
      "epoch 22; iter: 400; batch classifier loss: 0.581363; batch adversarial loss: 0.453040\n",
      "epoch 22; iter: 600; batch classifier loss: 0.462708; batch adversarial loss: 0.507288\n",
      "epoch 23; iter: 0; batch classifier loss: 0.406741; batch adversarial loss: 0.399882\n",
      "epoch 23; iter: 200; batch classifier loss: 0.438888; batch adversarial loss: 0.489899\n",
      "epoch 23; iter: 400; batch classifier loss: 0.439436; batch adversarial loss: 0.381425\n",
      "epoch 23; iter: 600; batch classifier loss: 0.585790; batch adversarial loss: 0.465882\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501912; batch adversarial loss: 0.493673\n",
      "epoch 24; iter: 200; batch classifier loss: 0.371931; batch adversarial loss: 0.345385\n",
      "epoch 24; iter: 400; batch classifier loss: 0.478462; batch adversarial loss: 0.315314\n",
      "epoch 24; iter: 600; batch classifier loss: 0.468971; batch adversarial loss: 0.483234\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520611; batch adversarial loss: 0.401264\n",
      "epoch 25; iter: 200; batch classifier loss: 0.641471; batch adversarial loss: 0.327134\n",
      "epoch 25; iter: 400; batch classifier loss: 0.517687; batch adversarial loss: 0.493569\n",
      "epoch 25; iter: 600; batch classifier loss: 0.387353; batch adversarial loss: 0.353823\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378234; batch adversarial loss: 0.345983\n",
      "epoch 26; iter: 200; batch classifier loss: 0.545179; batch adversarial loss: 0.458603\n",
      "epoch 26; iter: 400; batch classifier loss: 0.492740; batch adversarial loss: 0.474870\n",
      "epoch 26; iter: 600; batch classifier loss: 0.394501; batch adversarial loss: 0.308354\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392596; batch adversarial loss: 0.432710\n",
      "epoch 27; iter: 200; batch classifier loss: 0.478699; batch adversarial loss: 0.317125\n",
      "epoch 27; iter: 400; batch classifier loss: 0.595539; batch adversarial loss: 0.328267\n",
      "epoch 27; iter: 600; batch classifier loss: 0.701442; batch adversarial loss: 0.346556\n",
      "epoch 28; iter: 0; batch classifier loss: 0.387712; batch adversarial loss: 0.456059\n",
      "epoch 28; iter: 200; batch classifier loss: 0.467310; batch adversarial loss: 0.237575\n",
      "epoch 28; iter: 400; batch classifier loss: 0.547643; batch adversarial loss: 0.438098\n",
      "epoch 28; iter: 600; batch classifier loss: 0.723292; batch adversarial loss: 0.399928\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521076; batch adversarial loss: 0.317743\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338749; batch adversarial loss: 0.373369\n",
      "epoch 29; iter: 400; batch classifier loss: 0.578978; batch adversarial loss: 0.400948\n",
      "epoch 29; iter: 600; batch classifier loss: 0.522731; batch adversarial loss: 0.373955\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431730; batch adversarial loss: 0.454493\n",
      "epoch 30; iter: 200; batch classifier loss: 0.421866; batch adversarial loss: 0.371334\n",
      "epoch 30; iter: 400; batch classifier loss: 0.386903; batch adversarial loss: 0.454646\n",
      "epoch 30; iter: 600; batch classifier loss: 0.495460; batch adversarial loss: 0.436556\n",
      "epoch 31; iter: 0; batch classifier loss: 0.488121; batch adversarial loss: 0.462817\n",
      "epoch 31; iter: 200; batch classifier loss: 0.522048; batch adversarial loss: 0.371534\n",
      "epoch 31; iter: 400; batch classifier loss: 0.781761; batch adversarial loss: 0.454806\n",
      "epoch 31; iter: 600; batch classifier loss: 0.475230; batch adversarial loss: 0.377903\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428667; batch adversarial loss: 0.418890\n",
      "epoch 32; iter: 200; batch classifier loss: 0.677739; batch adversarial loss: 0.377837\n",
      "epoch 32; iter: 400; batch classifier loss: 0.495802; batch adversarial loss: 0.314847\n",
      "epoch 32; iter: 600; batch classifier loss: 0.598113; batch adversarial loss: 0.376855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.544020; batch adversarial loss: 0.498340\n",
      "epoch 33; iter: 200; batch classifier loss: 0.450736; batch adversarial loss: 0.390977\n",
      "epoch 33; iter: 400; batch classifier loss: 0.616421; batch adversarial loss: 0.482424\n",
      "epoch 33; iter: 600; batch classifier loss: 0.448632; batch adversarial loss: 0.499999\n",
      "epoch 34; iter: 0; batch classifier loss: 0.471509; batch adversarial loss: 0.400217\n",
      "epoch 34; iter: 200; batch classifier loss: 0.531927; batch adversarial loss: 0.494070\n",
      "epoch 34; iter: 400; batch classifier loss: 0.590535; batch adversarial loss: 0.465228\n",
      "epoch 34; iter: 600; batch classifier loss: 0.391200; batch adversarial loss: 0.430326\n",
      "epoch 35; iter: 0; batch classifier loss: 0.367181; batch adversarial loss: 0.531566\n",
      "epoch 35; iter: 200; batch classifier loss: 0.481890; batch adversarial loss: 0.328577\n",
      "epoch 35; iter: 400; batch classifier loss: 0.703107; batch adversarial loss: 0.424853\n",
      "epoch 35; iter: 600; batch classifier loss: 0.400621; batch adversarial loss: 0.465548\n",
      "epoch 36; iter: 0; batch classifier loss: 0.250527; batch adversarial loss: 0.343531\n",
      "epoch 36; iter: 200; batch classifier loss: 0.343376; batch adversarial loss: 0.398475\n",
      "epoch 36; iter: 400; batch classifier loss: 0.468827; batch adversarial loss: 0.327267\n",
      "epoch 36; iter: 600; batch classifier loss: 0.732526; batch adversarial loss: 0.403434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450769; batch adversarial loss: 0.508461\n",
      "epoch 37; iter: 200; batch classifier loss: 0.360490; batch adversarial loss: 0.382935\n",
      "epoch 37; iter: 400; batch classifier loss: 0.539337; batch adversarial loss: 0.401641\n",
      "epoch 37; iter: 600; batch classifier loss: 0.629356; batch adversarial loss: 0.486896\n",
      "epoch 38; iter: 0; batch classifier loss: 0.462779; batch adversarial loss: 0.549561\n",
      "epoch 38; iter: 200; batch classifier loss: 0.602157; batch adversarial loss: 0.311705\n",
      "epoch 38; iter: 400; batch classifier loss: 0.603963; batch adversarial loss: 0.379299\n",
      "epoch 38; iter: 600; batch classifier loss: 0.709485; batch adversarial loss: 0.400356\n",
      "epoch 39; iter: 0; batch classifier loss: 0.325378; batch adversarial loss: 0.563161\n",
      "epoch 39; iter: 200; batch classifier loss: 0.430134; batch adversarial loss: 0.428686\n",
      "epoch 39; iter: 400; batch classifier loss: 0.708803; batch adversarial loss: 0.471118\n",
      "epoch 39; iter: 600; batch classifier loss: 0.394439; batch adversarial loss: 0.323997\n",
      "epoch 40; iter: 0; batch classifier loss: 0.648014; batch adversarial loss: 0.317448\n",
      "epoch 40; iter: 200; batch classifier loss: 0.647958; batch adversarial loss: 0.373434\n",
      "epoch 40; iter: 400; batch classifier loss: 0.590099; batch adversarial loss: 0.395332\n",
      "epoch 40; iter: 600; batch classifier loss: 0.529963; batch adversarial loss: 0.432002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.526328; batch adversarial loss: 0.347120\n",
      "epoch 41; iter: 200; batch classifier loss: 0.472516; batch adversarial loss: 0.398280\n",
      "epoch 41; iter: 400; batch classifier loss: 0.576718; batch adversarial loss: 0.504442\n",
      "epoch 41; iter: 600; batch classifier loss: 0.431805; batch adversarial loss: 0.427062\n",
      "epoch 42; iter: 0; batch classifier loss: 0.463620; batch adversarial loss: 0.429624\n",
      "epoch 42; iter: 200; batch classifier loss: 0.548705; batch adversarial loss: 0.313279\n",
      "epoch 42; iter: 400; batch classifier loss: 0.464879; batch adversarial loss: 0.562070\n",
      "epoch 42; iter: 600; batch classifier loss: 0.386423; batch adversarial loss: 0.537568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.683237; batch adversarial loss: 0.465155\n",
      "epoch 43; iter: 200; batch classifier loss: 0.574167; batch adversarial loss: 0.372918\n",
      "epoch 43; iter: 400; batch classifier loss: 0.252363; batch adversarial loss: 0.356698\n",
      "epoch 43; iter: 600; batch classifier loss: 0.477335; batch adversarial loss: 0.455207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323569; batch adversarial loss: 0.458444\n",
      "epoch 44; iter: 200; batch classifier loss: 0.649911; batch adversarial loss: 0.348240\n",
      "epoch 44; iter: 400; batch classifier loss: 0.616474; batch adversarial loss: 0.459451\n",
      "epoch 44; iter: 600; batch classifier loss: 0.394195; batch adversarial loss: 0.400947\n",
      "epoch 45; iter: 0; batch classifier loss: 0.387671; batch adversarial loss: 0.291107\n",
      "epoch 45; iter: 200; batch classifier loss: 0.612639; batch adversarial loss: 0.318435\n",
      "epoch 45; iter: 400; batch classifier loss: 0.554774; batch adversarial loss: 0.563396\n",
      "epoch 45; iter: 600; batch classifier loss: 0.502595; batch adversarial loss: 0.343933\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371602; batch adversarial loss: 0.378445\n",
      "epoch 46; iter: 200; batch classifier loss: 0.369386; batch adversarial loss: 0.387079\n",
      "epoch 46; iter: 400; batch classifier loss: 0.717179; batch adversarial loss: 0.361329\n",
      "epoch 46; iter: 600; batch classifier loss: 0.492756; batch adversarial loss: 0.497006\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511773; batch adversarial loss: 0.626882\n",
      "epoch 47; iter: 200; batch classifier loss: 0.681855; batch adversarial loss: 0.442447\n",
      "epoch 47; iter: 400; batch classifier loss: 0.426062; batch adversarial loss: 0.427987\n",
      "epoch 47; iter: 600; batch classifier loss: 0.609525; batch adversarial loss: 0.407714\n",
      "epoch 48; iter: 0; batch classifier loss: 0.704626; batch adversarial loss: 0.559308\n",
      "epoch 48; iter: 200; batch classifier loss: 0.609896; batch adversarial loss: 0.602930\n",
      "epoch 48; iter: 400; batch classifier loss: 0.472935; batch adversarial loss: 0.378286\n",
      "epoch 48; iter: 600; batch classifier loss: 0.730889; batch adversarial loss: 0.455092\n",
      "epoch 49; iter: 0; batch classifier loss: 0.692163; batch adversarial loss: 0.433221\n",
      "epoch 49; iter: 200; batch classifier loss: 0.425935; batch adversarial loss: 0.411466\n",
      "epoch 49; iter: 400; batch classifier loss: 0.628938; batch adversarial loss: 0.343252\n",
      "epoch 49; iter: 600; batch classifier loss: 0.626485; batch adversarial loss: 0.488028\n",
      "epoch 0; iter: 0; batch classifier loss: 12.079535; batch adversarial loss: 1.219019\n",
      "epoch 0; iter: 200; batch classifier loss: 7.800732; batch adversarial loss: 0.701008\n",
      "epoch 0; iter: 400; batch classifier loss: 0.818433; batch adversarial loss: 0.610149\n",
      "epoch 0; iter: 600; batch classifier loss: 2.593601; batch adversarial loss: 0.568330\n",
      "epoch 1; iter: 0; batch classifier loss: 4.566827; batch adversarial loss: 0.540048\n",
      "epoch 1; iter: 200; batch classifier loss: 3.336228; batch adversarial loss: 0.599367\n",
      "epoch 1; iter: 400; batch classifier loss: 1.175824; batch adversarial loss: 0.437875\n",
      "epoch 1; iter: 600; batch classifier loss: 1.742774; batch adversarial loss: 0.532603\n",
      "epoch 2; iter: 0; batch classifier loss: 2.394814; batch adversarial loss: 0.503737\n",
      "epoch 2; iter: 200; batch classifier loss: 0.697859; batch adversarial loss: 0.412567\n",
      "epoch 2; iter: 400; batch classifier loss: 2.211118; batch adversarial loss: 0.416521\n",
      "epoch 2; iter: 600; batch classifier loss: 0.642032; batch adversarial loss: 0.429775\n",
      "epoch 3; iter: 0; batch classifier loss: 0.908356; batch adversarial loss: 0.391425\n",
      "epoch 3; iter: 200; batch classifier loss: 7.408078; batch adversarial loss: 0.570949\n",
      "epoch 3; iter: 400; batch classifier loss: 1.471322; batch adversarial loss: 0.371255\n",
      "epoch 3; iter: 600; batch classifier loss: 0.364481; batch adversarial loss: 0.461855\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555669; batch adversarial loss: 0.411047\n",
      "epoch 4; iter: 200; batch classifier loss: 1.905517; batch adversarial loss: 0.506697\n",
      "epoch 4; iter: 400; batch classifier loss: 0.836340; batch adversarial loss: 0.483014\n",
      "epoch 4; iter: 600; batch classifier loss: 0.591146; batch adversarial loss: 0.437734\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567830; batch adversarial loss: 0.383329\n",
      "epoch 5; iter: 200; batch classifier loss: 0.523495; batch adversarial loss: 0.516887\n",
      "epoch 5; iter: 400; batch classifier loss: 0.602831; batch adversarial loss: 0.268814\n",
      "epoch 5; iter: 600; batch classifier loss: 1.288527; batch adversarial loss: 0.402346\n",
      "epoch 6; iter: 0; batch classifier loss: 0.869878; batch adversarial loss: 0.381652\n",
      "epoch 6; iter: 200; batch classifier loss: 0.382757; batch adversarial loss: 0.497234\n",
      "epoch 6; iter: 400; batch classifier loss: 0.539696; batch adversarial loss: 0.429254\n",
      "epoch 6; iter: 600; batch classifier loss: 0.289287; batch adversarial loss: 0.397739\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480866; batch adversarial loss: 0.432653\n",
      "epoch 7; iter: 200; batch classifier loss: 0.488431; batch adversarial loss: 0.261036\n",
      "epoch 7; iter: 400; batch classifier loss: 0.239408; batch adversarial loss: 0.563489\n",
      "epoch 7; iter: 600; batch classifier loss: 0.691876; batch adversarial loss: 0.351209\n",
      "epoch 8; iter: 0; batch classifier loss: 0.422326; batch adversarial loss: 0.300964\n",
      "epoch 8; iter: 200; batch classifier loss: 0.302138; batch adversarial loss: 0.379204\n",
      "epoch 8; iter: 400; batch classifier loss: 0.474910; batch adversarial loss: 0.457931\n",
      "epoch 8; iter: 600; batch classifier loss: 0.475534; batch adversarial loss: 0.516181\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359453; batch adversarial loss: 0.362898\n",
      "epoch 9; iter: 200; batch classifier loss: 0.340602; batch adversarial loss: 0.515153\n",
      "epoch 9; iter: 400; batch classifier loss: 0.376727; batch adversarial loss: 0.407080\n",
      "epoch 9; iter: 600; batch classifier loss: 0.413793; batch adversarial loss: 0.398008\n",
      "epoch 10; iter: 0; batch classifier loss: 0.179080; batch adversarial loss: 0.409709\n",
      "epoch 10; iter: 200; batch classifier loss: 0.342852; batch adversarial loss: 0.400209\n",
      "epoch 10; iter: 400; batch classifier loss: 0.355543; batch adversarial loss: 0.541789\n",
      "epoch 10; iter: 600; batch classifier loss: 0.271181; batch adversarial loss: 0.458073\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331019; batch adversarial loss: 0.411626\n",
      "epoch 11; iter: 200; batch classifier loss: 0.344518; batch adversarial loss: 0.459173\n",
      "epoch 11; iter: 400; batch classifier loss: 0.426253; batch adversarial loss: 0.457831\n",
      "epoch 11; iter: 600; batch classifier loss: 0.291034; batch adversarial loss: 0.454586\n",
      "epoch 12; iter: 0; batch classifier loss: 0.236037; batch adversarial loss: 0.358687\n",
      "epoch 12; iter: 200; batch classifier loss: 0.356723; batch adversarial loss: 0.425105\n",
      "epoch 12; iter: 400; batch classifier loss: 0.312901; batch adversarial loss: 0.457023\n",
      "epoch 12; iter: 600; batch classifier loss: 0.421580; batch adversarial loss: 0.349823\n",
      "epoch 13; iter: 0; batch classifier loss: 0.366798; batch adversarial loss: 0.525244\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326971; batch adversarial loss: 0.379810\n",
      "epoch 13; iter: 400; batch classifier loss: 0.387633; batch adversarial loss: 0.415628\n",
      "epoch 13; iter: 600; batch classifier loss: 0.309266; batch adversarial loss: 0.451187\n",
      "epoch 14; iter: 0; batch classifier loss: 0.377946; batch adversarial loss: 0.352063\n",
      "epoch 14; iter: 200; batch classifier loss: 0.260836; batch adversarial loss: 0.344060\n",
      "epoch 14; iter: 400; batch classifier loss: 0.347704; batch adversarial loss: 0.385351\n",
      "epoch 14; iter: 600; batch classifier loss: 0.543671; batch adversarial loss: 0.400669\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362535; batch adversarial loss: 0.465657\n",
      "epoch 15; iter: 200; batch classifier loss: 0.338515; batch adversarial loss: 0.431071\n",
      "epoch 15; iter: 400; batch classifier loss: 0.313940; batch adversarial loss: 0.380599\n",
      "epoch 15; iter: 600; batch classifier loss: 0.420079; batch adversarial loss: 0.457998\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347680; batch adversarial loss: 0.423301\n",
      "epoch 16; iter: 200; batch classifier loss: 0.309823; batch adversarial loss: 0.481172\n",
      "epoch 16; iter: 400; batch classifier loss: 0.409710; batch adversarial loss: 0.375125\n",
      "epoch 16; iter: 600; batch classifier loss: 0.406076; batch adversarial loss: 0.401079\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392248; batch adversarial loss: 0.478285\n",
      "epoch 17; iter: 200; batch classifier loss: 0.344353; batch adversarial loss: 0.272866\n",
      "epoch 17; iter: 400; batch classifier loss: 0.381777; batch adversarial loss: 0.520674\n",
      "epoch 17; iter: 600; batch classifier loss: 0.534761; batch adversarial loss: 0.410214\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342714; batch adversarial loss: 0.443791\n",
      "epoch 18; iter: 200; batch classifier loss: 0.328291; batch adversarial loss: 0.423690\n",
      "epoch 18; iter: 400; batch classifier loss: 0.319554; batch adversarial loss: 0.477479\n",
      "epoch 18; iter: 600; batch classifier loss: 0.393396; batch adversarial loss: 0.404905\n",
      "epoch 19; iter: 0; batch classifier loss: 0.289261; batch adversarial loss: 0.332068\n",
      "epoch 19; iter: 200; batch classifier loss: 0.373753; batch adversarial loss: 0.521333\n",
      "epoch 19; iter: 400; batch classifier loss: 0.364951; batch adversarial loss: 0.512035\n",
      "epoch 19; iter: 600; batch classifier loss: 0.339129; batch adversarial loss: 0.402697\n",
      "epoch 20; iter: 0; batch classifier loss: 0.409312; batch adversarial loss: 0.411964\n",
      "epoch 20; iter: 200; batch classifier loss: 0.298880; batch adversarial loss: 0.376494\n",
      "epoch 20; iter: 400; batch classifier loss: 0.289960; batch adversarial loss: 0.437909\n",
      "epoch 20; iter: 600; batch classifier loss: 0.313000; batch adversarial loss: 0.466922\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256377; batch adversarial loss: 0.510110\n",
      "epoch 21; iter: 200; batch classifier loss: 0.508686; batch adversarial loss: 0.264992\n",
      "epoch 21; iter: 400; batch classifier loss: 0.370644; batch adversarial loss: 0.345242\n",
      "epoch 21; iter: 600; batch classifier loss: 0.274711; batch adversarial loss: 0.345639\n",
      "epoch 22; iter: 0; batch classifier loss: 0.353586; batch adversarial loss: 0.565987\n",
      "epoch 22; iter: 200; batch classifier loss: 0.373646; batch adversarial loss: 0.448911\n",
      "epoch 22; iter: 400; batch classifier loss: 0.349487; batch adversarial loss: 0.457364\n",
      "epoch 22; iter: 600; batch classifier loss: 0.253485; batch adversarial loss: 0.479157\n",
      "epoch 23; iter: 0; batch classifier loss: 0.315210; batch adversarial loss: 0.556511\n",
      "epoch 23; iter: 200; batch classifier loss: 0.536119; batch adversarial loss: 0.380574\n",
      "epoch 23; iter: 400; batch classifier loss: 0.261690; batch adversarial loss: 0.427218\n",
      "epoch 23; iter: 600; batch classifier loss: 0.364372; batch adversarial loss: 0.347534\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307491; batch adversarial loss: 0.429471\n",
      "epoch 24; iter: 200; batch classifier loss: 0.487825; batch adversarial loss: 0.341634\n",
      "epoch 24; iter: 400; batch classifier loss: 0.383334; batch adversarial loss: 0.489466\n",
      "epoch 24; iter: 600; batch classifier loss: 0.344834; batch adversarial loss: 0.355485\n",
      "epoch 25; iter: 0; batch classifier loss: 0.241565; batch adversarial loss: 0.401478\n",
      "epoch 25; iter: 200; batch classifier loss: 0.363425; batch adversarial loss: 0.484312\n",
      "epoch 25; iter: 400; batch classifier loss: 0.358792; batch adversarial loss: 0.409370\n",
      "epoch 25; iter: 600; batch classifier loss: 0.623480; batch adversarial loss: 0.314667\n",
      "epoch 26; iter: 0; batch classifier loss: 0.339432; batch adversarial loss: 0.319590\n",
      "epoch 26; iter: 200; batch classifier loss: 0.317629; batch adversarial loss: 0.440801\n",
      "epoch 26; iter: 400; batch classifier loss: 0.396432; batch adversarial loss: 0.384681\n",
      "epoch 26; iter: 600; batch classifier loss: 0.395596; batch adversarial loss: 0.485258\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392745; batch adversarial loss: 0.439019\n",
      "epoch 27; iter: 200; batch classifier loss: 0.327114; batch adversarial loss: 0.510342\n",
      "epoch 27; iter: 400; batch classifier loss: 0.340024; batch adversarial loss: 0.517785\n",
      "epoch 27; iter: 600; batch classifier loss: 0.407783; batch adversarial loss: 0.490472\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351139; batch adversarial loss: 0.565330\n",
      "epoch 28; iter: 200; batch classifier loss: 0.449155; batch adversarial loss: 0.432456\n",
      "epoch 28; iter: 400; batch classifier loss: 0.326755; batch adversarial loss: 0.352744\n",
      "epoch 28; iter: 600; batch classifier loss: 0.348895; batch adversarial loss: 0.456547\n",
      "epoch 29; iter: 0; batch classifier loss: 0.333140; batch adversarial loss: 0.512324\n",
      "epoch 29; iter: 200; batch classifier loss: 0.323310; batch adversarial loss: 0.491203\n",
      "epoch 29; iter: 400; batch classifier loss: 0.426787; batch adversarial loss: 0.541520\n",
      "epoch 29; iter: 600; batch classifier loss: 0.332966; batch adversarial loss: 0.403037\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414460; batch adversarial loss: 0.323907\n",
      "epoch 30; iter: 200; batch classifier loss: 0.297895; batch adversarial loss: 0.434924\n",
      "epoch 30; iter: 400; batch classifier loss: 0.344910; batch adversarial loss: 0.473162\n",
      "epoch 30; iter: 600; batch classifier loss: 0.388477; batch adversarial loss: 0.387659\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464839; batch adversarial loss: 0.376440\n",
      "epoch 31; iter: 200; batch classifier loss: 0.353119; batch adversarial loss: 0.486443\n",
      "epoch 31; iter: 400; batch classifier loss: 0.273031; batch adversarial loss: 0.488477\n",
      "epoch 31; iter: 600; batch classifier loss: 0.300892; batch adversarial loss: 0.381361\n",
      "epoch 32; iter: 0; batch classifier loss: 0.337569; batch adversarial loss: 0.375084\n",
      "epoch 32; iter: 200; batch classifier loss: 0.319177; batch adversarial loss: 0.434928\n",
      "epoch 32; iter: 400; batch classifier loss: 0.384588; batch adversarial loss: 0.488283\n",
      "epoch 32; iter: 600; batch classifier loss: 0.317079; batch adversarial loss: 0.437009\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434239; batch adversarial loss: 0.454101\n",
      "epoch 33; iter: 200; batch classifier loss: 0.278907; batch adversarial loss: 0.459211\n",
      "epoch 33; iter: 400; batch classifier loss: 0.419579; batch adversarial loss: 0.431395\n",
      "epoch 33; iter: 600; batch classifier loss: 0.437883; batch adversarial loss: 0.455284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.376806; batch adversarial loss: 0.375304\n",
      "epoch 34; iter: 200; batch classifier loss: 0.403496; batch adversarial loss: 0.400087\n",
      "epoch 34; iter: 400; batch classifier loss: 0.389772; batch adversarial loss: 0.320626\n",
      "epoch 34; iter: 600; batch classifier loss: 0.350604; batch adversarial loss: 0.402152\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422895; batch adversarial loss: 0.487126\n",
      "epoch 35; iter: 200; batch classifier loss: 0.231775; batch adversarial loss: 0.379001\n",
      "epoch 35; iter: 400; batch classifier loss: 0.523286; batch adversarial loss: 0.403845\n",
      "epoch 35; iter: 600; batch classifier loss: 0.541288; batch adversarial loss: 0.372814\n",
      "epoch 36; iter: 0; batch classifier loss: 0.369617; batch adversarial loss: 0.386892\n",
      "epoch 36; iter: 200; batch classifier loss: 0.318659; batch adversarial loss: 0.381493\n",
      "epoch 36; iter: 400; batch classifier loss: 0.552084; batch adversarial loss: 0.367777\n",
      "epoch 36; iter: 600; batch classifier loss: 0.313991; batch adversarial loss: 0.345796\n",
      "epoch 37; iter: 0; batch classifier loss: 0.253672; batch adversarial loss: 0.406015\n",
      "epoch 37; iter: 200; batch classifier loss: 0.391483; batch adversarial loss: 0.341157\n",
      "epoch 37; iter: 400; batch classifier loss: 0.261771; batch adversarial loss: 0.455304\n",
      "epoch 37; iter: 600; batch classifier loss: 0.264700; batch adversarial loss: 0.571286\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418273; batch adversarial loss: 0.431892\n",
      "epoch 38; iter: 200; batch classifier loss: 0.354089; batch adversarial loss: 0.404262\n",
      "epoch 38; iter: 400; batch classifier loss: 0.298138; batch adversarial loss: 0.521506\n",
      "epoch 38; iter: 600; batch classifier loss: 0.368423; batch adversarial loss: 0.454649\n",
      "epoch 39; iter: 0; batch classifier loss: 0.329967; batch adversarial loss: 0.405685\n",
      "epoch 39; iter: 200; batch classifier loss: 0.218981; batch adversarial loss: 0.453624\n",
      "epoch 39; iter: 400; batch classifier loss: 0.284707; batch adversarial loss: 0.247812\n",
      "epoch 39; iter: 600; batch classifier loss: 0.280092; batch adversarial loss: 0.335966\n",
      "epoch 40; iter: 0; batch classifier loss: 0.346396; batch adversarial loss: 0.490544\n",
      "epoch 40; iter: 200; batch classifier loss: 0.417340; batch adversarial loss: 0.482774\n",
      "epoch 40; iter: 400; batch classifier loss: 0.272256; batch adversarial loss: 0.322215\n",
      "epoch 40; iter: 600; batch classifier loss: 0.534989; batch adversarial loss: 0.458398\n",
      "epoch 41; iter: 0; batch classifier loss: 0.380611; batch adversarial loss: 0.407012\n",
      "epoch 41; iter: 200; batch classifier loss: 0.442529; batch adversarial loss: 0.320252\n",
      "epoch 41; iter: 400; batch classifier loss: 0.359726; batch adversarial loss: 0.381635\n",
      "epoch 41; iter: 600; batch classifier loss: 0.189021; batch adversarial loss: 0.296415\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364770; batch adversarial loss: 0.351059\n",
      "epoch 42; iter: 200; batch classifier loss: 0.361335; batch adversarial loss: 0.466908\n",
      "epoch 42; iter: 400; batch classifier loss: 0.485563; batch adversarial loss: 0.545372\n",
      "epoch 42; iter: 600; batch classifier loss: 0.203949; batch adversarial loss: 0.269603\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442787; batch adversarial loss: 0.377483\n",
      "epoch 43; iter: 200; batch classifier loss: 0.292595; batch adversarial loss: 0.457023\n",
      "epoch 43; iter: 400; batch classifier loss: 0.417273; batch adversarial loss: 0.321811\n",
      "epoch 43; iter: 600; batch classifier loss: 0.312741; batch adversarial loss: 0.321314\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443789; batch adversarial loss: 0.450285\n",
      "epoch 44; iter: 200; batch classifier loss: 0.393763; batch adversarial loss: 0.387590\n",
      "epoch 44; iter: 400; batch classifier loss: 0.408524; batch adversarial loss: 0.359978\n",
      "epoch 44; iter: 600; batch classifier loss: 0.297816; batch adversarial loss: 0.403363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.302258; batch adversarial loss: 0.368656\n",
      "epoch 45; iter: 200; batch classifier loss: 0.243083; batch adversarial loss: 0.486097\n",
      "epoch 45; iter: 400; batch classifier loss: 0.450144; batch adversarial loss: 0.458994\n",
      "epoch 45; iter: 600; batch classifier loss: 0.437108; batch adversarial loss: 0.376456\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400201; batch adversarial loss: 0.293195\n",
      "epoch 46; iter: 200; batch classifier loss: 0.343308; batch adversarial loss: 0.542198\n",
      "epoch 46; iter: 400; batch classifier loss: 0.419949; batch adversarial loss: 0.405804\n",
      "epoch 46; iter: 600; batch classifier loss: 0.274243; batch adversarial loss: 0.294391\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425288; batch adversarial loss: 0.377704\n",
      "epoch 47; iter: 200; batch classifier loss: 0.337070; batch adversarial loss: 0.370638\n",
      "epoch 47; iter: 400; batch classifier loss: 0.460652; batch adversarial loss: 0.429101\n",
      "epoch 47; iter: 600; batch classifier loss: 0.442798; batch adversarial loss: 0.372849\n",
      "epoch 48; iter: 0; batch classifier loss: 0.479794; batch adversarial loss: 0.318723\n",
      "epoch 48; iter: 200; batch classifier loss: 0.425136; batch adversarial loss: 0.426243\n",
      "epoch 48; iter: 400; batch classifier loss: 0.301558; batch adversarial loss: 0.426345\n",
      "epoch 48; iter: 600; batch classifier loss: 0.428995; batch adversarial loss: 0.380299\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422576; batch adversarial loss: 0.490835\n",
      "epoch 49; iter: 200; batch classifier loss: 0.283379; batch adversarial loss: 0.404327\n",
      "epoch 49; iter: 400; batch classifier loss: 0.377785; batch adversarial loss: 0.350754\n",
      "epoch 49; iter: 600; batch classifier loss: 0.367732; batch adversarial loss: 0.372578\n",
      "epoch 0; iter: 0; batch classifier loss: 17.304741; batch adversarial loss: 0.680318\n",
      "epoch 0; iter: 200; batch classifier loss: 4.792076; batch adversarial loss: 0.576865\n",
      "epoch 0; iter: 400; batch classifier loss: 0.534440; batch adversarial loss: 0.559221\n",
      "epoch 0; iter: 600; batch classifier loss: 6.451405; batch adversarial loss: 0.523153\n",
      "epoch 1; iter: 0; batch classifier loss: 8.999971; batch adversarial loss: 0.477984\n",
      "epoch 1; iter: 200; batch classifier loss: 12.033274; batch adversarial loss: 0.517864\n",
      "epoch 1; iter: 400; batch classifier loss: 2.230765; batch adversarial loss: 0.520529\n",
      "epoch 1; iter: 600; batch classifier loss: 6.154075; batch adversarial loss: 0.344924\n",
      "epoch 2; iter: 0; batch classifier loss: 1.780530; batch adversarial loss: 0.495332\n",
      "epoch 2; iter: 200; batch classifier loss: 2.167625; batch adversarial loss: 0.417610\n",
      "epoch 2; iter: 400; batch classifier loss: 0.462561; batch adversarial loss: 0.493805\n",
      "epoch 2; iter: 600; batch classifier loss: 0.648299; batch adversarial loss: 0.425780\n",
      "epoch 3; iter: 0; batch classifier loss: 1.943727; batch adversarial loss: 0.420284\n",
      "epoch 3; iter: 200; batch classifier loss: 1.105170; batch adversarial loss: 0.435615\n",
      "epoch 3; iter: 400; batch classifier loss: 0.443452; batch adversarial loss: 0.423366\n",
      "epoch 3; iter: 600; batch classifier loss: 0.714709; batch adversarial loss: 0.431693\n",
      "epoch 4; iter: 0; batch classifier loss: 1.056653; batch adversarial loss: 0.462963\n",
      "epoch 4; iter: 200; batch classifier loss: 0.292360; batch adversarial loss: 0.558938\n",
      "epoch 4; iter: 400; batch classifier loss: 0.713323; batch adversarial loss: 0.388916\n",
      "epoch 4; iter: 600; batch classifier loss: 0.599026; batch adversarial loss: 0.496363\n",
      "epoch 5; iter: 0; batch classifier loss: 0.434599; batch adversarial loss: 0.397995\n",
      "epoch 5; iter: 200; batch classifier loss: 0.317557; batch adversarial loss: 0.523991\n",
      "epoch 5; iter: 400; batch classifier loss: 0.312958; batch adversarial loss: 0.315380\n",
      "epoch 5; iter: 600; batch classifier loss: 0.379729; batch adversarial loss: 0.424744\n",
      "epoch 6; iter: 0; batch classifier loss: 0.435933; batch adversarial loss: 0.376468\n",
      "epoch 6; iter: 200; batch classifier loss: 0.452468; batch adversarial loss: 0.394480\n",
      "epoch 6; iter: 400; batch classifier loss: 0.441513; batch adversarial loss: 0.392306\n",
      "epoch 6; iter: 600; batch classifier loss: 0.281540; batch adversarial loss: 0.502786\n",
      "epoch 7; iter: 0; batch classifier loss: 0.320738; batch adversarial loss: 0.460407\n",
      "epoch 7; iter: 200; batch classifier loss: 0.369488; batch adversarial loss: 0.320434\n",
      "epoch 7; iter: 400; batch classifier loss: 0.319920; batch adversarial loss: 0.508787\n",
      "epoch 7; iter: 600; batch classifier loss: 0.499862; batch adversarial loss: 0.456547\n",
      "epoch 8; iter: 0; batch classifier loss: 1.102857; batch adversarial loss: 0.332831\n",
      "epoch 8; iter: 200; batch classifier loss: 0.385747; batch adversarial loss: 0.399081\n",
      "epoch 8; iter: 400; batch classifier loss: 0.427862; batch adversarial loss: 0.454890\n",
      "epoch 8; iter: 600; batch classifier loss: 0.342722; batch adversarial loss: 0.428239\n",
      "epoch 9; iter: 0; batch classifier loss: 0.355128; batch adversarial loss: 0.326310\n",
      "epoch 9; iter: 200; batch classifier loss: 0.403807; batch adversarial loss: 0.450075\n",
      "epoch 9; iter: 400; batch classifier loss: 0.324804; batch adversarial loss: 0.320568\n",
      "epoch 9; iter: 600; batch classifier loss: 0.527927; batch adversarial loss: 0.433290\n",
      "epoch 10; iter: 0; batch classifier loss: 0.439175; batch adversarial loss: 0.607415\n",
      "epoch 10; iter: 200; batch classifier loss: 0.536245; batch adversarial loss: 0.430767\n",
      "epoch 10; iter: 400; batch classifier loss: 0.531029; batch adversarial loss: 0.387117\n",
      "epoch 10; iter: 600; batch classifier loss: 0.339922; batch adversarial loss: 0.372839\n",
      "epoch 11; iter: 0; batch classifier loss: 0.272497; batch adversarial loss: 0.410342\n",
      "epoch 11; iter: 200; batch classifier loss: 0.332549; batch adversarial loss: 0.323265\n",
      "epoch 11; iter: 400; batch classifier loss: 0.266706; batch adversarial loss: 0.281157\n",
      "epoch 11; iter: 600; batch classifier loss: 0.361612; batch adversarial loss: 0.512023\n",
      "epoch 12; iter: 0; batch classifier loss: 0.320776; batch adversarial loss: 0.512164\n",
      "epoch 12; iter: 200; batch classifier loss: 0.422995; batch adversarial loss: 0.432528\n",
      "epoch 12; iter: 400; batch classifier loss: 0.357520; batch adversarial loss: 0.355166\n",
      "epoch 12; iter: 600; batch classifier loss: 0.338785; batch adversarial loss: 0.477965\n",
      "epoch 13; iter: 0; batch classifier loss: 0.224314; batch adversarial loss: 0.414950\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396607; batch adversarial loss: 0.376915\n",
      "epoch 13; iter: 400; batch classifier loss: 0.379032; batch adversarial loss: 0.394155\n",
      "epoch 13; iter: 600; batch classifier loss: 0.344041; batch adversarial loss: 0.266803\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358697; batch adversarial loss: 0.427866\n",
      "epoch 14; iter: 200; batch classifier loss: 0.287313; batch adversarial loss: 0.345190\n",
      "epoch 14; iter: 400; batch classifier loss: 0.405758; batch adversarial loss: 0.344359\n",
      "epoch 14; iter: 600; batch classifier loss: 0.419752; batch adversarial loss: 0.370423\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391226; batch adversarial loss: 0.414255\n",
      "epoch 15; iter: 200; batch classifier loss: 0.401986; batch adversarial loss: 0.379176\n",
      "epoch 15; iter: 400; batch classifier loss: 0.261262; batch adversarial loss: 0.325246\n",
      "epoch 15; iter: 600; batch classifier loss: 0.642504; batch adversarial loss: 0.421008\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402005; batch adversarial loss: 0.533750\n",
      "epoch 16; iter: 200; batch classifier loss: 0.471184; batch adversarial loss: 0.263533\n",
      "epoch 16; iter: 400; batch classifier loss: 0.313471; batch adversarial loss: 0.315738\n",
      "epoch 16; iter: 600; batch classifier loss: 0.355913; batch adversarial loss: 0.391198\n",
      "epoch 17; iter: 0; batch classifier loss: 0.362165; batch adversarial loss: 0.521551\n",
      "epoch 17; iter: 200; batch classifier loss: 0.315897; batch adversarial loss: 0.518831\n",
      "epoch 17; iter: 400; batch classifier loss: 0.342440; batch adversarial loss: 0.380864\n",
      "epoch 17; iter: 600; batch classifier loss: 0.392115; batch adversarial loss: 0.410930\n",
      "epoch 18; iter: 0; batch classifier loss: 0.229174; batch adversarial loss: 0.348270\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399442; batch adversarial loss: 0.394136\n",
      "epoch 18; iter: 400; batch classifier loss: 0.362673; batch adversarial loss: 0.318450\n",
      "epoch 18; iter: 600; batch classifier loss: 0.349339; batch adversarial loss: 0.513578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315204; batch adversarial loss: 0.328708\n",
      "epoch 19; iter: 200; batch classifier loss: 0.269778; batch adversarial loss: 0.343465\n",
      "epoch 19; iter: 400; batch classifier loss: 0.359644; batch adversarial loss: 0.401187\n",
      "epoch 19; iter: 600; batch classifier loss: 0.388762; batch adversarial loss: 0.426401\n",
      "epoch 20; iter: 0; batch classifier loss: 0.531879; batch adversarial loss: 0.349320\n",
      "epoch 20; iter: 200; batch classifier loss: 0.380671; batch adversarial loss: 0.351575\n",
      "epoch 20; iter: 400; batch classifier loss: 0.406651; batch adversarial loss: 0.497370\n",
      "epoch 20; iter: 600; batch classifier loss: 0.445246; batch adversarial loss: 0.537271\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300713; batch adversarial loss: 0.406714\n",
      "epoch 21; iter: 200; batch classifier loss: 0.280515; batch adversarial loss: 0.315754\n",
      "epoch 21; iter: 400; batch classifier loss: 0.350578; batch adversarial loss: 0.458339\n",
      "epoch 21; iter: 600; batch classifier loss: 0.304299; batch adversarial loss: 0.429337\n",
      "epoch 22; iter: 0; batch classifier loss: 0.398997; batch adversarial loss: 0.373770\n",
      "epoch 22; iter: 200; batch classifier loss: 0.413233; batch adversarial loss: 0.348620\n",
      "epoch 22; iter: 400; batch classifier loss: 0.259721; batch adversarial loss: 0.414111\n",
      "epoch 22; iter: 600; batch classifier loss: 0.444272; batch adversarial loss: 0.463530\n",
      "epoch 23; iter: 0; batch classifier loss: 0.346864; batch adversarial loss: 0.410976\n",
      "epoch 23; iter: 200; batch classifier loss: 0.289681; batch adversarial loss: 0.588755\n",
      "epoch 23; iter: 400; batch classifier loss: 0.745737; batch adversarial loss: 0.369059\n",
      "epoch 23; iter: 600; batch classifier loss: 0.263004; batch adversarial loss: 0.345465\n",
      "epoch 24; iter: 0; batch classifier loss: 0.534264; batch adversarial loss: 0.420751\n",
      "epoch 24; iter: 200; batch classifier loss: 0.367221; batch adversarial loss: 0.423105\n",
      "epoch 24; iter: 400; batch classifier loss: 0.381335; batch adversarial loss: 0.524126\n",
      "epoch 24; iter: 600; batch classifier loss: 0.311879; batch adversarial loss: 0.410913\n",
      "epoch 25; iter: 0; batch classifier loss: 0.295163; batch adversarial loss: 0.487916\n",
      "epoch 25; iter: 200; batch classifier loss: 0.233187; batch adversarial loss: 0.293937\n",
      "epoch 25; iter: 400; batch classifier loss: 0.395466; batch adversarial loss: 0.355402\n",
      "epoch 25; iter: 600; batch classifier loss: 0.357832; batch adversarial loss: 0.401408\n",
      "epoch 26; iter: 0; batch classifier loss: 0.412712; batch adversarial loss: 0.428746\n",
      "epoch 26; iter: 200; batch classifier loss: 0.182503; batch adversarial loss: 0.381422\n",
      "epoch 26; iter: 400; batch classifier loss: 0.405710; batch adversarial loss: 0.449776\n",
      "epoch 26; iter: 600; batch classifier loss: 0.393785; batch adversarial loss: 0.382959\n",
      "epoch 27; iter: 0; batch classifier loss: 0.400929; batch adversarial loss: 0.446370\n",
      "epoch 27; iter: 200; batch classifier loss: 0.240438; batch adversarial loss: 0.431119\n",
      "epoch 27; iter: 400; batch classifier loss: 0.588817; batch adversarial loss: 0.498645\n",
      "epoch 27; iter: 600; batch classifier loss: 0.327157; batch adversarial loss: 0.377103\n",
      "epoch 28; iter: 0; batch classifier loss: 0.297791; batch adversarial loss: 0.484776\n",
      "epoch 28; iter: 200; batch classifier loss: 0.603627; batch adversarial loss: 0.422788\n",
      "epoch 28; iter: 400; batch classifier loss: 0.402484; batch adversarial loss: 0.488542\n",
      "epoch 28; iter: 600; batch classifier loss: 0.488191; batch adversarial loss: 0.357844\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447979; batch adversarial loss: 0.347125\n",
      "epoch 29; iter: 200; batch classifier loss: 0.427390; batch adversarial loss: 0.345364\n",
      "epoch 29; iter: 400; batch classifier loss: 0.207317; batch adversarial loss: 0.473438\n",
      "epoch 29; iter: 600; batch classifier loss: 0.287427; batch adversarial loss: 0.430116\n",
      "epoch 30; iter: 0; batch classifier loss: 0.195123; batch adversarial loss: 0.602118\n",
      "epoch 30; iter: 200; batch classifier loss: 0.366136; batch adversarial loss: 0.323365\n",
      "epoch 30; iter: 400; batch classifier loss: 0.467246; batch adversarial loss: 0.344834\n",
      "epoch 30; iter: 600; batch classifier loss: 0.405895; batch adversarial loss: 0.400956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.279757; batch adversarial loss: 0.375872\n",
      "epoch 31; iter: 200; batch classifier loss: 0.514272; batch adversarial loss: 0.483572\n",
      "epoch 31; iter: 400; batch classifier loss: 0.373337; batch adversarial loss: 0.431868\n",
      "epoch 31; iter: 600; batch classifier loss: 0.499612; batch adversarial loss: 0.401604\n",
      "epoch 32; iter: 0; batch classifier loss: 0.346888; batch adversarial loss: 0.519821\n",
      "epoch 32; iter: 200; batch classifier loss: 0.442832; batch adversarial loss: 0.333731\n",
      "epoch 32; iter: 400; batch classifier loss: 0.385698; batch adversarial loss: 0.445619\n",
      "epoch 32; iter: 600; batch classifier loss: 0.302862; batch adversarial loss: 0.458683\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414685; batch adversarial loss: 0.501038\n",
      "epoch 33; iter: 200; batch classifier loss: 0.167349; batch adversarial loss: 0.317535\n",
      "epoch 33; iter: 400; batch classifier loss: 0.199511; batch adversarial loss: 0.480324\n",
      "epoch 33; iter: 600; batch classifier loss: 1.190453; batch adversarial loss: 0.414149\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418987; batch adversarial loss: 0.430767\n",
      "epoch 34; iter: 200; batch classifier loss: 0.284437; batch adversarial loss: 0.291671\n",
      "epoch 34; iter: 400; batch classifier loss: 0.242688; batch adversarial loss: 0.562277\n",
      "epoch 34; iter: 600; batch classifier loss: 0.334175; batch adversarial loss: 0.434606\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341855; batch adversarial loss: 0.323174\n",
      "epoch 35; iter: 200; batch classifier loss: 0.451424; batch adversarial loss: 0.401932\n",
      "epoch 35; iter: 400; batch classifier loss: 0.335606; batch adversarial loss: 0.427215\n",
      "epoch 35; iter: 600; batch classifier loss: 0.292597; batch adversarial loss: 0.548645\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373425; batch adversarial loss: 0.380733\n",
      "epoch 36; iter: 200; batch classifier loss: 0.400372; batch adversarial loss: 0.463616\n",
      "epoch 36; iter: 400; batch classifier loss: 0.360626; batch adversarial loss: 0.331893\n",
      "epoch 36; iter: 600; batch classifier loss: 0.269657; batch adversarial loss: 0.348236\n",
      "epoch 37; iter: 0; batch classifier loss: 0.367504; batch adversarial loss: 0.507476\n",
      "epoch 37; iter: 200; batch classifier loss: 0.367497; batch adversarial loss: 0.483702\n",
      "epoch 37; iter: 400; batch classifier loss: 0.479943; batch adversarial loss: 0.346515\n",
      "epoch 37; iter: 600; batch classifier loss: 0.287981; batch adversarial loss: 0.435827\n",
      "epoch 38; iter: 0; batch classifier loss: 0.187874; batch adversarial loss: 0.480411\n",
      "epoch 38; iter: 200; batch classifier loss: 0.195317; batch adversarial loss: 0.405131\n",
      "epoch 38; iter: 400; batch classifier loss: 0.497275; batch adversarial loss: 0.357590\n",
      "epoch 38; iter: 600; batch classifier loss: 0.365371; batch adversarial loss: 0.406802\n",
      "epoch 39; iter: 0; batch classifier loss: 0.564846; batch adversarial loss: 0.377759\n",
      "epoch 39; iter: 200; batch classifier loss: 0.495592; batch adversarial loss: 0.346135\n",
      "epoch 39; iter: 400; batch classifier loss: 0.473366; batch adversarial loss: 0.372866\n",
      "epoch 39; iter: 600; batch classifier loss: 0.283361; batch adversarial loss: 0.457484\n",
      "epoch 40; iter: 0; batch classifier loss: 0.318152; batch adversarial loss: 0.375887\n",
      "epoch 40; iter: 200; batch classifier loss: 0.489584; batch adversarial loss: 0.319472\n",
      "epoch 40; iter: 400; batch classifier loss: 0.261828; batch adversarial loss: 0.380814\n",
      "epoch 40; iter: 600; batch classifier loss: 0.491104; batch adversarial loss: 0.465318\n",
      "epoch 41; iter: 0; batch classifier loss: 0.405399; batch adversarial loss: 0.375460\n",
      "epoch 41; iter: 200; batch classifier loss: 0.412458; batch adversarial loss: 0.517601\n",
      "epoch 41; iter: 400; batch classifier loss: 0.482453; batch adversarial loss: 0.373445\n",
      "epoch 41; iter: 600; batch classifier loss: 0.372096; batch adversarial loss: 0.486286\n",
      "epoch 42; iter: 0; batch classifier loss: 0.157456; batch adversarial loss: 0.322499\n",
      "epoch 42; iter: 200; batch classifier loss: 0.279822; batch adversarial loss: 0.372891\n",
      "epoch 42; iter: 400; batch classifier loss: 0.367363; batch adversarial loss: 0.319039\n",
      "epoch 42; iter: 600; batch classifier loss: 0.483520; batch adversarial loss: 0.407981\n",
      "epoch 43; iter: 0; batch classifier loss: 0.285405; batch adversarial loss: 0.486279\n",
      "epoch 43; iter: 200; batch classifier loss: 0.254022; batch adversarial loss: 0.485440\n",
      "epoch 43; iter: 400; batch classifier loss: 0.324023; batch adversarial loss: 0.379163\n",
      "epoch 43; iter: 600; batch classifier loss: 0.327324; batch adversarial loss: 0.343601\n",
      "epoch 44; iter: 0; batch classifier loss: 0.392682; batch adversarial loss: 0.348984\n",
      "epoch 44; iter: 200; batch classifier loss: 0.256429; batch adversarial loss: 0.320499\n",
      "epoch 44; iter: 400; batch classifier loss: 0.376834; batch adversarial loss: 0.207297\n",
      "epoch 44; iter: 600; batch classifier loss: 0.326461; batch adversarial loss: 0.429358\n",
      "epoch 45; iter: 0; batch classifier loss: 0.313240; batch adversarial loss: 0.510821\n",
      "epoch 45; iter: 200; batch classifier loss: 0.336818; batch adversarial loss: 0.297555\n",
      "epoch 45; iter: 400; batch classifier loss: 0.304834; batch adversarial loss: 0.376028\n",
      "epoch 45; iter: 600; batch classifier loss: 0.401028; batch adversarial loss: 0.433514\n",
      "epoch 46; iter: 0; batch classifier loss: 0.433832; batch adversarial loss: 0.378444\n",
      "epoch 46; iter: 200; batch classifier loss: 0.348792; batch adversarial loss: 0.441524\n",
      "epoch 46; iter: 400; batch classifier loss: 0.566971; batch adversarial loss: 0.386708\n",
      "epoch 46; iter: 600; batch classifier loss: 0.312558; batch adversarial loss: 0.484624\n",
      "epoch 47; iter: 0; batch classifier loss: 0.240027; batch adversarial loss: 0.461554\n",
      "epoch 47; iter: 200; batch classifier loss: 0.384345; batch adversarial loss: 0.375551\n",
      "epoch 47; iter: 400; batch classifier loss: 0.281396; batch adversarial loss: 0.334135\n",
      "epoch 47; iter: 600; batch classifier loss: 0.422920; batch adversarial loss: 0.428717\n",
      "epoch 48; iter: 0; batch classifier loss: 0.352456; batch adversarial loss: 0.352448\n",
      "epoch 48; iter: 200; batch classifier loss: 0.349274; batch adversarial loss: 0.440145\n",
      "epoch 48; iter: 400; batch classifier loss: 0.691420; batch adversarial loss: 0.457247\n",
      "epoch 48; iter: 600; batch classifier loss: 0.455128; batch adversarial loss: 0.380340\n",
      "epoch 49; iter: 0; batch classifier loss: 0.349605; batch adversarial loss: 0.293826\n",
      "epoch 49; iter: 200; batch classifier loss: 0.468378; batch adversarial loss: 0.324556\n",
      "epoch 49; iter: 400; batch classifier loss: 0.381338; batch adversarial loss: 0.323323\n",
      "epoch 49; iter: 600; batch classifier loss: 0.274180; batch adversarial loss: 0.497086\n",
      "epoch 0; iter: 0; batch classifier loss: 4.795553; batch adversarial loss: 1.011003\n",
      "epoch 0; iter: 200; batch classifier loss: 4.623007; batch adversarial loss: 0.817653\n",
      "epoch 0; iter: 400; batch classifier loss: 9.942035; batch adversarial loss: 0.618866\n",
      "epoch 0; iter: 600; batch classifier loss: 4.130840; batch adversarial loss: 0.601133\n",
      "epoch 1; iter: 0; batch classifier loss: 1.039753; batch adversarial loss: 0.573679\n",
      "epoch 1; iter: 200; batch classifier loss: 1.589402; batch adversarial loss: 0.594977\n",
      "epoch 1; iter: 400; batch classifier loss: 1.097792; batch adversarial loss: 0.526605\n",
      "epoch 1; iter: 600; batch classifier loss: 1.510933; batch adversarial loss: 0.397585\n",
      "epoch 2; iter: 0; batch classifier loss: 1.076048; batch adversarial loss: 0.496727\n",
      "epoch 2; iter: 200; batch classifier loss: 1.090944; batch adversarial loss: 0.460920\n",
      "epoch 2; iter: 400; batch classifier loss: 1.815244; batch adversarial loss: 0.366271\n",
      "epoch 2; iter: 600; batch classifier loss: 2.222675; batch adversarial loss: 0.368771\n",
      "epoch 3; iter: 0; batch classifier loss: 1.074091; batch adversarial loss: 0.415096\n",
      "epoch 3; iter: 200; batch classifier loss: 1.373989; batch adversarial loss: 0.369927\n",
      "epoch 3; iter: 400; batch classifier loss: 0.342997; batch adversarial loss: 0.523537\n",
      "epoch 3; iter: 600; batch classifier loss: 1.293770; batch adversarial loss: 0.401472\n",
      "epoch 4; iter: 0; batch classifier loss: 1.309157; batch adversarial loss: 0.447386\n",
      "epoch 4; iter: 200; batch classifier loss: 0.381903; batch adversarial loss: 0.375748\n",
      "epoch 4; iter: 400; batch classifier loss: 1.385905; batch adversarial loss: 0.443092\n",
      "epoch 4; iter: 600; batch classifier loss: 0.419009; batch adversarial loss: 0.373719\n",
      "epoch 5; iter: 0; batch classifier loss: 0.376436; batch adversarial loss: 0.423435\n",
      "epoch 5; iter: 200; batch classifier loss: 0.344568; batch adversarial loss: 0.377475\n",
      "epoch 5; iter: 400; batch classifier loss: 1.179490; batch adversarial loss: 0.281851\n",
      "epoch 5; iter: 600; batch classifier loss: 0.319242; batch adversarial loss: 0.386182\n",
      "epoch 6; iter: 0; batch classifier loss: 0.249077; batch adversarial loss: 0.469569\n",
      "epoch 6; iter: 200; batch classifier loss: 0.289420; batch adversarial loss: 0.408315\n",
      "epoch 6; iter: 400; batch classifier loss: 0.854969; batch adversarial loss: 0.342242\n",
      "epoch 6; iter: 600; batch classifier loss: 0.396781; batch adversarial loss: 0.494118\n",
      "epoch 7; iter: 0; batch classifier loss: 0.382276; batch adversarial loss: 0.231428\n",
      "epoch 7; iter: 200; batch classifier loss: 0.403165; batch adversarial loss: 0.354393\n",
      "epoch 7; iter: 400; batch classifier loss: 0.435100; batch adversarial loss: 0.398171\n",
      "epoch 7; iter: 600; batch classifier loss: 0.226959; batch adversarial loss: 0.375145\n",
      "epoch 8; iter: 0; batch classifier loss: 0.266530; batch adversarial loss: 0.506023\n",
      "epoch 8; iter: 200; batch classifier loss: 0.358646; batch adversarial loss: 0.405839\n",
      "epoch 8; iter: 400; batch classifier loss: 0.274369; batch adversarial loss: 0.346692\n",
      "epoch 8; iter: 600; batch classifier loss: 0.270879; batch adversarial loss: 0.263759\n",
      "epoch 9; iter: 0; batch classifier loss: 0.310591; batch adversarial loss: 0.369835\n",
      "epoch 9; iter: 200; batch classifier loss: 0.317697; batch adversarial loss: 0.598793\n",
      "epoch 9; iter: 400; batch classifier loss: 0.339641; batch adversarial loss: 0.427631\n",
      "epoch 9; iter: 600; batch classifier loss: 0.369177; batch adversarial loss: 0.596594\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422542; batch adversarial loss: 0.431189\n",
      "epoch 10; iter: 200; batch classifier loss: 0.351523; batch adversarial loss: 0.307094\n",
      "epoch 10; iter: 400; batch classifier loss: 0.254885; batch adversarial loss: 0.453169\n",
      "epoch 10; iter: 600; batch classifier loss: 0.304198; batch adversarial loss: 0.438910\n",
      "epoch 11; iter: 0; batch classifier loss: 0.442926; batch adversarial loss: 0.246064\n",
      "epoch 11; iter: 200; batch classifier loss: 0.346392; batch adversarial loss: 0.481692\n",
      "epoch 11; iter: 400; batch classifier loss: 0.364699; batch adversarial loss: 0.516332\n",
      "epoch 11; iter: 600; batch classifier loss: 0.376202; batch adversarial loss: 0.377411\n",
      "epoch 12; iter: 0; batch classifier loss: 0.264846; batch adversarial loss: 0.325265\n",
      "epoch 12; iter: 200; batch classifier loss: 0.366219; batch adversarial loss: 0.481841\n",
      "epoch 12; iter: 400; batch classifier loss: 0.422337; batch adversarial loss: 0.265769\n",
      "epoch 12; iter: 600; batch classifier loss: 0.436738; batch adversarial loss: 0.372313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.284127; batch adversarial loss: 0.319714\n",
      "epoch 13; iter: 200; batch classifier loss: 0.304448; batch adversarial loss: 0.372874\n",
      "epoch 13; iter: 400; batch classifier loss: 0.316178; batch adversarial loss: 0.425549\n",
      "epoch 13; iter: 600; batch classifier loss: 0.361071; batch adversarial loss: 0.516513\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431642; batch adversarial loss: 0.387524\n",
      "epoch 14; iter: 200; batch classifier loss: 0.412881; batch adversarial loss: 0.346717\n",
      "epoch 14; iter: 400; batch classifier loss: 0.214815; batch adversarial loss: 0.268964\n",
      "epoch 14; iter: 600; batch classifier loss: 0.350579; batch adversarial loss: 0.513925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.534979; batch adversarial loss: 0.435293\n",
      "epoch 15; iter: 200; batch classifier loss: 0.398012; batch adversarial loss: 0.397820\n",
      "epoch 15; iter: 400; batch classifier loss: 0.411801; batch adversarial loss: 0.505838\n",
      "epoch 15; iter: 600; batch classifier loss: 0.330277; batch adversarial loss: 0.396560\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334260; batch adversarial loss: 0.509914\n",
      "epoch 16; iter: 200; batch classifier loss: 0.373366; batch adversarial loss: 0.426587\n",
      "epoch 16; iter: 400; batch classifier loss: 0.336636; batch adversarial loss: 0.400115\n",
      "epoch 16; iter: 600; batch classifier loss: 0.546199; batch adversarial loss: 0.517047\n",
      "epoch 17; iter: 0; batch classifier loss: 0.233087; batch adversarial loss: 0.352928\n",
      "epoch 17; iter: 200; batch classifier loss: 0.327751; batch adversarial loss: 0.399709\n",
      "epoch 17; iter: 400; batch classifier loss: 0.341764; batch adversarial loss: 0.374136\n",
      "epoch 17; iter: 600; batch classifier loss: 0.278753; batch adversarial loss: 0.377490\n",
      "epoch 18; iter: 0; batch classifier loss: 0.368570; batch adversarial loss: 0.349494\n",
      "epoch 18; iter: 200; batch classifier loss: 0.252274; batch adversarial loss: 0.377233\n",
      "epoch 18; iter: 400; batch classifier loss: 0.312682; batch adversarial loss: 0.475397\n",
      "epoch 18; iter: 600; batch classifier loss: 0.282699; batch adversarial loss: 0.313246\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354963; batch adversarial loss: 0.404155\n",
      "epoch 19; iter: 200; batch classifier loss: 0.401936; batch adversarial loss: 0.400076\n",
      "epoch 19; iter: 400; batch classifier loss: 0.381919; batch adversarial loss: 0.553046\n",
      "epoch 19; iter: 600; batch classifier loss: 0.297544; batch adversarial loss: 0.311929\n",
      "epoch 20; iter: 0; batch classifier loss: 0.682649; batch adversarial loss: 0.319901\n",
      "epoch 20; iter: 200; batch classifier loss: 0.380959; batch adversarial loss: 0.347643\n",
      "epoch 20; iter: 400; batch classifier loss: 0.419766; batch adversarial loss: 0.456231\n",
      "epoch 20; iter: 600; batch classifier loss: 0.321506; batch adversarial loss: 0.406231\n",
      "epoch 21; iter: 0; batch classifier loss: 0.335204; batch adversarial loss: 0.424015\n",
      "epoch 21; iter: 200; batch classifier loss: 0.375710; batch adversarial loss: 0.402301\n",
      "epoch 21; iter: 400; batch classifier loss: 0.366468; batch adversarial loss: 0.346726\n",
      "epoch 21; iter: 600; batch classifier loss: 0.292343; batch adversarial loss: 0.429192\n",
      "epoch 22; iter: 0; batch classifier loss: 0.375467; batch adversarial loss: 0.369887\n",
      "epoch 22; iter: 200; batch classifier loss: 0.387805; batch adversarial loss: 0.412351\n",
      "epoch 22; iter: 400; batch classifier loss: 0.303559; batch adversarial loss: 0.353657\n",
      "epoch 22; iter: 600; batch classifier loss: 0.416546; batch adversarial loss: 0.486918\n",
      "epoch 23; iter: 0; batch classifier loss: 0.348078; batch adversarial loss: 0.569347\n",
      "epoch 23; iter: 200; batch classifier loss: 0.306718; batch adversarial loss: 0.346226\n",
      "epoch 23; iter: 400; batch classifier loss: 0.324266; batch adversarial loss: 0.315912\n",
      "epoch 23; iter: 600; batch classifier loss: 0.316609; batch adversarial loss: 0.288975\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331102; batch adversarial loss: 0.290357\n",
      "epoch 24; iter: 200; batch classifier loss: 0.468818; batch adversarial loss: 0.378386\n",
      "epoch 24; iter: 400; batch classifier loss: 0.325177; batch adversarial loss: 0.563906\n",
      "epoch 24; iter: 600; batch classifier loss: 0.336949; batch adversarial loss: 0.413465\n",
      "epoch 25; iter: 0; batch classifier loss: 0.288593; batch adversarial loss: 0.381958\n",
      "epoch 25; iter: 200; batch classifier loss: 0.385700; batch adversarial loss: 0.318519\n",
      "epoch 25; iter: 400; batch classifier loss: 0.283924; batch adversarial loss: 0.384582\n",
      "epoch 25; iter: 600; batch classifier loss: 0.263072; batch adversarial loss: 0.417438\n",
      "epoch 26; iter: 0; batch classifier loss: 0.327710; batch adversarial loss: 0.378111\n",
      "epoch 26; iter: 200; batch classifier loss: 0.467864; batch adversarial loss: 0.301188\n",
      "epoch 26; iter: 400; batch classifier loss: 0.380047; batch adversarial loss: 0.318923\n",
      "epoch 26; iter: 600; batch classifier loss: 0.448264; batch adversarial loss: 0.464768\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394981; batch adversarial loss: 0.405009\n",
      "epoch 27; iter: 200; batch classifier loss: 0.287601; batch adversarial loss: 0.367729\n",
      "epoch 27; iter: 400; batch classifier loss: 0.309776; batch adversarial loss: 0.415232\n",
      "epoch 27; iter: 600; batch classifier loss: 0.293802; batch adversarial loss: 0.434640\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445863; batch adversarial loss: 0.350865\n",
      "epoch 28; iter: 200; batch classifier loss: 0.438928; batch adversarial loss: 0.392913\n",
      "epoch 28; iter: 400; batch classifier loss: 0.323702; batch adversarial loss: 0.487068\n",
      "epoch 28; iter: 600; batch classifier loss: 0.314226; batch adversarial loss: 0.521413\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434998; batch adversarial loss: 0.566149\n",
      "epoch 29; iter: 200; batch classifier loss: 0.319417; batch adversarial loss: 0.497561\n",
      "epoch 29; iter: 400; batch classifier loss: 0.168752; batch adversarial loss: 0.542162\n",
      "epoch 29; iter: 600; batch classifier loss: 0.404983; batch adversarial loss: 0.455931\n",
      "epoch 30; iter: 0; batch classifier loss: 0.254621; batch adversarial loss: 0.460265\n",
      "epoch 30; iter: 200; batch classifier loss: 0.360733; batch adversarial loss: 0.494969\n",
      "epoch 30; iter: 400; batch classifier loss: 0.359999; batch adversarial loss: 0.547029\n",
      "epoch 30; iter: 600; batch classifier loss: 0.282841; batch adversarial loss: 0.351065\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387355; batch adversarial loss: 0.450150\n",
      "epoch 31; iter: 200; batch classifier loss: 0.424604; batch adversarial loss: 0.426648\n",
      "epoch 31; iter: 400; batch classifier loss: 0.312581; batch adversarial loss: 0.409444\n",
      "epoch 31; iter: 600; batch classifier loss: 0.310914; batch adversarial loss: 0.432648\n",
      "epoch 32; iter: 0; batch classifier loss: 0.294331; batch adversarial loss: 0.426530\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397997; batch adversarial loss: 0.400573\n",
      "epoch 32; iter: 400; batch classifier loss: 0.241491; batch adversarial loss: 0.419085\n",
      "epoch 32; iter: 600; batch classifier loss: 0.483749; batch adversarial loss: 0.485478\n",
      "epoch 33; iter: 0; batch classifier loss: 0.310465; batch adversarial loss: 0.400656\n",
      "epoch 33; iter: 200; batch classifier loss: 0.461393; batch adversarial loss: 0.424526\n",
      "epoch 33; iter: 400; batch classifier loss: 0.459997; batch adversarial loss: 0.353032\n",
      "epoch 33; iter: 600; batch classifier loss: 0.643169; batch adversarial loss: 0.306790\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306637; batch adversarial loss: 0.464762\n",
      "epoch 34; iter: 200; batch classifier loss: 0.358367; batch adversarial loss: 0.431024\n",
      "epoch 34; iter: 400; batch classifier loss: 0.402264; batch adversarial loss: 0.425313\n",
      "epoch 34; iter: 600; batch classifier loss: 0.308883; batch adversarial loss: 0.428386\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414960; batch adversarial loss: 0.387603\n",
      "epoch 35; iter: 200; batch classifier loss: 0.385332; batch adversarial loss: 0.368822\n",
      "epoch 35; iter: 400; batch classifier loss: 0.375361; batch adversarial loss: 0.397496\n",
      "epoch 35; iter: 600; batch classifier loss: 0.351234; batch adversarial loss: 0.303461\n",
      "epoch 36; iter: 0; batch classifier loss: 0.431983; batch adversarial loss: 0.405755\n",
      "epoch 36; iter: 200; batch classifier loss: 0.266970; batch adversarial loss: 0.298950\n",
      "epoch 36; iter: 400; batch classifier loss: 0.281123; batch adversarial loss: 0.397929\n",
      "epoch 36; iter: 600; batch classifier loss: 0.242136; batch adversarial loss: 0.291722\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346205; batch adversarial loss: 0.258803\n",
      "epoch 37; iter: 200; batch classifier loss: 0.402995; batch adversarial loss: 0.349212\n",
      "epoch 37; iter: 400; batch classifier loss: 0.313597; batch adversarial loss: 0.453946\n",
      "epoch 37; iter: 600; batch classifier loss: 0.539492; batch adversarial loss: 0.531918\n",
      "epoch 38; iter: 0; batch classifier loss: 0.388109; batch adversarial loss: 0.431197\n",
      "epoch 38; iter: 200; batch classifier loss: 0.378241; batch adversarial loss: 0.474343\n",
      "epoch 38; iter: 400; batch classifier loss: 0.641986; batch adversarial loss: 0.479352\n",
      "epoch 38; iter: 600; batch classifier loss: 0.360120; batch adversarial loss: 0.300693\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461149; batch adversarial loss: 0.498020\n",
      "epoch 39; iter: 200; batch classifier loss: 0.290718; batch adversarial loss: 0.479134\n",
      "epoch 39; iter: 400; batch classifier loss: 0.439607; batch adversarial loss: 0.526386\n",
      "epoch 39; iter: 600; batch classifier loss: 0.284952; batch adversarial loss: 0.403228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.699930; batch adversarial loss: 0.488468\n",
      "epoch 40; iter: 200; batch classifier loss: 0.476120; batch adversarial loss: 0.372003\n",
      "epoch 40; iter: 400; batch classifier loss: 0.386411; batch adversarial loss: 0.453123\n",
      "epoch 40; iter: 600; batch classifier loss: 0.461422; batch adversarial loss: 0.295621\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378944; batch adversarial loss: 0.371101\n",
      "epoch 41; iter: 200; batch classifier loss: 0.229949; batch adversarial loss: 0.397523\n",
      "epoch 41; iter: 400; batch classifier loss: 0.345079; batch adversarial loss: 0.408948\n",
      "epoch 41; iter: 600; batch classifier loss: 0.460197; batch adversarial loss: 0.322410\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464127; batch adversarial loss: 0.386585\n",
      "epoch 42; iter: 200; batch classifier loss: 0.240404; batch adversarial loss: 0.741114\n",
      "epoch 42; iter: 400; batch classifier loss: 0.336865; batch adversarial loss: 0.293694\n",
      "epoch 42; iter: 600; batch classifier loss: 0.224210; batch adversarial loss: 0.460773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.322725; batch adversarial loss: 0.416292\n",
      "epoch 43; iter: 200; batch classifier loss: 0.431218; batch adversarial loss: 0.348926\n",
      "epoch 43; iter: 400; batch classifier loss: 0.276863; batch adversarial loss: 0.481762\n",
      "epoch 43; iter: 600; batch classifier loss: 0.299661; batch adversarial loss: 0.352499\n",
      "epoch 44; iter: 0; batch classifier loss: 0.357222; batch adversarial loss: 0.427813\n",
      "epoch 44; iter: 200; batch classifier loss: 0.288459; batch adversarial loss: 0.407470\n",
      "epoch 44; iter: 400; batch classifier loss: 0.472314; batch adversarial loss: 0.462266\n",
      "epoch 44; iter: 600; batch classifier loss: 0.337895; batch adversarial loss: 0.555832\n",
      "epoch 45; iter: 0; batch classifier loss: 0.268593; batch adversarial loss: 0.478724\n",
      "epoch 45; iter: 200; batch classifier loss: 0.770661; batch adversarial loss: 0.534734\n",
      "epoch 45; iter: 400; batch classifier loss: 0.406643; batch adversarial loss: 0.320989\n",
      "epoch 45; iter: 600; batch classifier loss: 0.345362; batch adversarial loss: 0.343884\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465977; batch adversarial loss: 0.399879\n",
      "epoch 46; iter: 200; batch classifier loss: 0.374533; batch adversarial loss: 0.419728\n",
      "epoch 46; iter: 400; batch classifier loss: 0.724973; batch adversarial loss: 0.235889\n",
      "epoch 46; iter: 600; batch classifier loss: 0.420685; batch adversarial loss: 0.517716\n",
      "epoch 47; iter: 0; batch classifier loss: 0.309411; batch adversarial loss: 0.425484\n",
      "epoch 47; iter: 200; batch classifier loss: 0.323456; batch adversarial loss: 0.398521\n",
      "epoch 47; iter: 400; batch classifier loss: 0.178218; batch adversarial loss: 0.400240\n",
      "epoch 47; iter: 600; batch classifier loss: 0.386318; batch adversarial loss: 0.402839\n",
      "epoch 48; iter: 0; batch classifier loss: 0.224297; batch adversarial loss: 0.434793\n",
      "epoch 48; iter: 200; batch classifier loss: 0.339686; batch adversarial loss: 0.649144\n",
      "epoch 48; iter: 400; batch classifier loss: 0.422869; batch adversarial loss: 0.341526\n",
      "epoch 48; iter: 600; batch classifier loss: 0.407244; batch adversarial loss: 0.311741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.238395; batch adversarial loss: 0.370308\n",
      "epoch 49; iter: 200; batch classifier loss: 0.469066; batch adversarial loss: 0.400391\n",
      "epoch 49; iter: 400; batch classifier loss: 0.298072; batch adversarial loss: 0.266409\n",
      "epoch 49; iter: 600; batch classifier loss: 0.434994; batch adversarial loss: 0.410128\n",
      "epoch 0; iter: 0; batch classifier loss: 17.368942; batch adversarial loss: 0.538054\n",
      "epoch 0; iter: 200; batch classifier loss: 5.071063; batch adversarial loss: 0.619144\n",
      "epoch 0; iter: 400; batch classifier loss: 4.728633; batch adversarial loss: 0.529286\n",
      "epoch 0; iter: 600; batch classifier loss: 1.346457; batch adversarial loss: 0.498302\n",
      "epoch 1; iter: 0; batch classifier loss: 8.007751; batch adversarial loss: 0.523019\n",
      "epoch 1; iter: 200; batch classifier loss: 6.074393; batch adversarial loss: 0.408650\n",
      "epoch 1; iter: 400; batch classifier loss: 9.757537; batch adversarial loss: 0.381995\n",
      "epoch 1; iter: 600; batch classifier loss: 2.095563; batch adversarial loss: 0.378089\n",
      "epoch 2; iter: 0; batch classifier loss: 0.645968; batch adversarial loss: 0.365276\n",
      "epoch 2; iter: 200; batch classifier loss: 0.863532; batch adversarial loss: 0.381425\n",
      "epoch 2; iter: 400; batch classifier loss: 0.389875; batch adversarial loss: 0.416192\n",
      "epoch 2; iter: 600; batch classifier loss: 0.542163; batch adversarial loss: 0.333689\n",
      "epoch 3; iter: 0; batch classifier loss: 2.300059; batch adversarial loss: 0.443407\n",
      "epoch 3; iter: 200; batch classifier loss: 3.316173; batch adversarial loss: 0.479964\n",
      "epoch 3; iter: 400; batch classifier loss: 0.408706; batch adversarial loss: 0.350151\n",
      "epoch 3; iter: 600; batch classifier loss: 0.959661; batch adversarial loss: 0.429760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.506574; batch adversarial loss: 0.416876\n",
      "epoch 4; iter: 200; batch classifier loss: 0.525117; batch adversarial loss: 0.511222\n",
      "epoch 4; iter: 400; batch classifier loss: 1.173164; batch adversarial loss: 0.534330\n",
      "epoch 4; iter: 600; batch classifier loss: 0.431979; batch adversarial loss: 0.438795\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521672; batch adversarial loss: 0.575295\n",
      "epoch 5; iter: 200; batch classifier loss: 0.441911; batch adversarial loss: 0.527234\n",
      "epoch 5; iter: 400; batch classifier loss: 0.459094; batch adversarial loss: 0.585056\n",
      "epoch 5; iter: 600; batch classifier loss: 0.367811; batch adversarial loss: 0.438357\n",
      "epoch 6; iter: 0; batch classifier loss: 0.434868; batch adversarial loss: 0.465689\n",
      "epoch 6; iter: 200; batch classifier loss: 0.294176; batch adversarial loss: 0.424454\n",
      "epoch 6; iter: 400; batch classifier loss: 0.362906; batch adversarial loss: 0.375858\n",
      "epoch 6; iter: 600; batch classifier loss: 0.384327; batch adversarial loss: 0.373751\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318339; batch adversarial loss: 0.410052\n",
      "epoch 7; iter: 200; batch classifier loss: 0.600222; batch adversarial loss: 0.290617\n",
      "epoch 7; iter: 400; batch classifier loss: 0.343743; batch adversarial loss: 0.415871\n",
      "epoch 7; iter: 600; batch classifier loss: 0.396936; batch adversarial loss: 0.417405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.193780; batch adversarial loss: 0.476556\n",
      "epoch 8; iter: 200; batch classifier loss: 0.413526; batch adversarial loss: 0.289494\n",
      "epoch 8; iter: 400; batch classifier loss: 0.376591; batch adversarial loss: 0.268589\n",
      "epoch 8; iter: 600; batch classifier loss: 0.274576; batch adversarial loss: 0.507785\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369369; batch adversarial loss: 0.291961\n",
      "epoch 9; iter: 200; batch classifier loss: 0.368556; batch adversarial loss: 0.457011\n",
      "epoch 9; iter: 400; batch classifier loss: 0.271998; batch adversarial loss: 0.351174\n",
      "epoch 9; iter: 600; batch classifier loss: 0.449507; batch adversarial loss: 0.468024\n",
      "epoch 10; iter: 0; batch classifier loss: 0.354801; batch adversarial loss: 0.350786\n",
      "epoch 10; iter: 200; batch classifier loss: 0.557559; batch adversarial loss: 0.482862\n",
      "epoch 10; iter: 400; batch classifier loss: 0.312920; batch adversarial loss: 0.426389\n",
      "epoch 10; iter: 600; batch classifier loss: 0.416719; batch adversarial loss: 0.424711\n",
      "epoch 11; iter: 0; batch classifier loss: 0.307516; batch adversarial loss: 0.518615\n",
      "epoch 11; iter: 200; batch classifier loss: 0.427963; batch adversarial loss: 0.458725\n",
      "epoch 11; iter: 400; batch classifier loss: 0.322651; batch adversarial loss: 0.319543\n",
      "epoch 11; iter: 600; batch classifier loss: 0.358936; batch adversarial loss: 0.349188\n",
      "epoch 12; iter: 0; batch classifier loss: 0.374863; batch adversarial loss: 0.318371\n",
      "epoch 12; iter: 200; batch classifier loss: 0.355386; batch adversarial loss: 0.308849\n",
      "epoch 12; iter: 400; batch classifier loss: 0.318144; batch adversarial loss: 0.470409\n",
      "epoch 12; iter: 600; batch classifier loss: 0.434650; batch adversarial loss: 0.448913\n",
      "epoch 13; iter: 0; batch classifier loss: 0.316188; batch adversarial loss: 0.271519\n",
      "epoch 13; iter: 200; batch classifier loss: 0.304833; batch adversarial loss: 0.313605\n",
      "epoch 13; iter: 400; batch classifier loss: 0.263042; batch adversarial loss: 0.368424\n",
      "epoch 13; iter: 600; batch classifier loss: 0.248747; batch adversarial loss: 0.454280\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315323; batch adversarial loss: 0.371567\n",
      "epoch 14; iter: 200; batch classifier loss: 0.377100; batch adversarial loss: 0.290327\n",
      "epoch 14; iter: 400; batch classifier loss: 0.505017; batch adversarial loss: 0.244117\n",
      "epoch 14; iter: 600; batch classifier loss: 0.245483; batch adversarial loss: 0.389581\n",
      "epoch 15; iter: 0; batch classifier loss: 0.256945; batch adversarial loss: 0.423378\n",
      "epoch 15; iter: 200; batch classifier loss: 0.416270; batch adversarial loss: 0.327039\n",
      "epoch 15; iter: 400; batch classifier loss: 0.236008; batch adversarial loss: 0.432791\n",
      "epoch 15; iter: 600; batch classifier loss: 0.349843; batch adversarial loss: 0.341238\n",
      "epoch 16; iter: 0; batch classifier loss: 0.282889; batch adversarial loss: 0.448821\n",
      "epoch 16; iter: 200; batch classifier loss: 0.323447; batch adversarial loss: 0.314358\n",
      "epoch 16; iter: 400; batch classifier loss: 0.352254; batch adversarial loss: 0.494102\n",
      "epoch 16; iter: 600; batch classifier loss: 0.389596; batch adversarial loss: 0.343455\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339011; batch adversarial loss: 0.397611\n",
      "epoch 17; iter: 200; batch classifier loss: 0.217689; batch adversarial loss: 0.410187\n",
      "epoch 17; iter: 400; batch classifier loss: 0.446252; batch adversarial loss: 0.431384\n",
      "epoch 17; iter: 600; batch classifier loss: 0.341785; batch adversarial loss: 0.479539\n",
      "epoch 18; iter: 0; batch classifier loss: 0.278560; batch adversarial loss: 0.234831\n",
      "epoch 18; iter: 200; batch classifier loss: 0.392056; batch adversarial loss: 0.347604\n",
      "epoch 18; iter: 400; batch classifier loss: 0.301061; batch adversarial loss: 0.576572\n",
      "epoch 18; iter: 600; batch classifier loss: 0.427760; batch adversarial loss: 0.349197\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338294; batch adversarial loss: 0.296572\n",
      "epoch 19; iter: 200; batch classifier loss: 0.413223; batch adversarial loss: 0.287860\n",
      "epoch 19; iter: 400; batch classifier loss: 0.322839; batch adversarial loss: 0.432001\n",
      "epoch 19; iter: 600; batch classifier loss: 0.311852; batch adversarial loss: 0.347993\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429552; batch adversarial loss: 0.462966\n",
      "epoch 20; iter: 200; batch classifier loss: 0.380297; batch adversarial loss: 0.540694\n",
      "epoch 20; iter: 400; batch classifier loss: 0.340901; batch adversarial loss: 0.454108\n",
      "epoch 20; iter: 600; batch classifier loss: 0.401372; batch adversarial loss: 0.489012\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338918; batch adversarial loss: 0.491611\n",
      "epoch 21; iter: 200; batch classifier loss: 0.292178; batch adversarial loss: 0.413907\n",
      "epoch 21; iter: 400; batch classifier loss: 0.245768; batch adversarial loss: 0.361906\n",
      "epoch 21; iter: 600; batch classifier loss: 0.288901; batch adversarial loss: 0.405483\n",
      "epoch 22; iter: 0; batch classifier loss: 0.271098; batch adversarial loss: 0.296492\n",
      "epoch 22; iter: 200; batch classifier loss: 0.263186; batch adversarial loss: 0.590216\n",
      "epoch 22; iter: 400; batch classifier loss: 0.336177; batch adversarial loss: 0.434230\n",
      "epoch 22; iter: 600; batch classifier loss: 0.329741; batch adversarial loss: 0.614544\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292476; batch adversarial loss: 0.361046\n",
      "epoch 23; iter: 200; batch classifier loss: 0.315284; batch adversarial loss: 0.364106\n",
      "epoch 23; iter: 400; batch classifier loss: 0.468661; batch adversarial loss: 0.381386\n",
      "epoch 23; iter: 600; batch classifier loss: 0.345008; batch adversarial loss: 0.436586\n",
      "epoch 24; iter: 0; batch classifier loss: 0.489206; batch adversarial loss: 0.385778\n",
      "epoch 24; iter: 200; batch classifier loss: 0.355043; batch adversarial loss: 0.320034\n",
      "epoch 24; iter: 400; batch classifier loss: 0.292207; batch adversarial loss: 0.345814\n",
      "epoch 24; iter: 600; batch classifier loss: 0.371758; batch adversarial loss: 0.409533\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306792; batch adversarial loss: 0.408466\n",
      "epoch 25; iter: 200; batch classifier loss: 0.332298; batch adversarial loss: 0.354306\n",
      "epoch 25; iter: 400; batch classifier loss: 0.804528; batch adversarial loss: 0.439823\n",
      "epoch 25; iter: 600; batch classifier loss: 0.345448; batch adversarial loss: 0.433701\n",
      "epoch 26; iter: 0; batch classifier loss: 0.225669; batch adversarial loss: 0.233611\n",
      "epoch 26; iter: 200; batch classifier loss: 0.303069; batch adversarial loss: 0.330829\n",
      "epoch 26; iter: 400; batch classifier loss: 0.263028; batch adversarial loss: 0.287570\n",
      "epoch 26; iter: 600; batch classifier loss: 0.343727; batch adversarial loss: 0.477467\n",
      "epoch 27; iter: 0; batch classifier loss: 0.375483; batch adversarial loss: 0.329047\n",
      "epoch 27; iter: 200; batch classifier loss: 0.229669; batch adversarial loss: 0.352338\n",
      "epoch 27; iter: 400; batch classifier loss: 0.425402; batch adversarial loss: 0.429513\n",
      "epoch 27; iter: 600; batch classifier loss: 0.430017; batch adversarial loss: 0.571264\n",
      "epoch 28; iter: 0; batch classifier loss: 0.298719; batch adversarial loss: 0.451894\n",
      "epoch 28; iter: 200; batch classifier loss: 0.288962; batch adversarial loss: 0.544034\n",
      "epoch 28; iter: 400; batch classifier loss: 0.233463; batch adversarial loss: 0.349313\n",
      "epoch 28; iter: 600; batch classifier loss: 0.311846; batch adversarial loss: 0.314401\n",
      "epoch 29; iter: 0; batch classifier loss: 0.239776; batch adversarial loss: 0.450071\n",
      "epoch 29; iter: 200; batch classifier loss: 0.305612; batch adversarial loss: 0.598652\n",
      "epoch 29; iter: 400; batch classifier loss: 0.387644; batch adversarial loss: 0.761624\n",
      "epoch 29; iter: 600; batch classifier loss: 0.341378; batch adversarial loss: 0.426556\n",
      "epoch 30; iter: 0; batch classifier loss: 0.274044; batch adversarial loss: 0.481056\n",
      "epoch 30; iter: 200; batch classifier loss: 0.355945; batch adversarial loss: 0.480645\n",
      "epoch 30; iter: 400; batch classifier loss: 0.356409; batch adversarial loss: 0.337191\n",
      "epoch 30; iter: 600; batch classifier loss: 0.308095; batch adversarial loss: 0.454977\n",
      "epoch 31; iter: 0; batch classifier loss: 0.308691; batch adversarial loss: 0.399226\n",
      "epoch 31; iter: 200; batch classifier loss: 0.438580; batch adversarial loss: 0.429550\n",
      "epoch 31; iter: 400; batch classifier loss: 0.233525; batch adversarial loss: 0.382419\n",
      "epoch 31; iter: 600; batch classifier loss: 0.312366; batch adversarial loss: 0.380187\n",
      "epoch 32; iter: 0; batch classifier loss: 0.234394; batch adversarial loss: 0.431357\n",
      "epoch 32; iter: 200; batch classifier loss: 0.357821; batch adversarial loss: 0.408671\n",
      "epoch 32; iter: 400; batch classifier loss: 0.354240; batch adversarial loss: 0.407239\n",
      "epoch 32; iter: 600; batch classifier loss: 0.259359; batch adversarial loss: 0.299898\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481733; batch adversarial loss: 0.343939\n",
      "epoch 33; iter: 200; batch classifier loss: 0.512800; batch adversarial loss: 0.376666\n",
      "epoch 33; iter: 400; batch classifier loss: 0.310072; batch adversarial loss: 0.345802\n",
      "epoch 33; iter: 600; batch classifier loss: 0.430723; batch adversarial loss: 0.435088\n",
      "epoch 34; iter: 0; batch classifier loss: 0.492527; batch adversarial loss: 0.489441\n",
      "epoch 34; iter: 200; batch classifier loss: 0.351598; batch adversarial loss: 0.454909\n",
      "epoch 34; iter: 400; batch classifier loss: 0.362299; batch adversarial loss: 0.397799\n",
      "epoch 34; iter: 600; batch classifier loss: 0.444531; batch adversarial loss: 0.351614\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464443; batch adversarial loss: 0.364900\n",
      "epoch 35; iter: 200; batch classifier loss: 0.269069; batch adversarial loss: 0.426546\n",
      "epoch 35; iter: 400; batch classifier loss: 0.201619; batch adversarial loss: 0.455762\n",
      "epoch 35; iter: 600; batch classifier loss: 0.364483; batch adversarial loss: 0.455792\n",
      "epoch 36; iter: 0; batch classifier loss: 0.259081; batch adversarial loss: 0.424341\n",
      "epoch 36; iter: 200; batch classifier loss: 0.295658; batch adversarial loss: 0.483126\n",
      "epoch 36; iter: 400; batch classifier loss: 0.312851; batch adversarial loss: 0.432162\n",
      "epoch 36; iter: 600; batch classifier loss: 0.392617; batch adversarial loss: 0.396214\n",
      "epoch 37; iter: 0; batch classifier loss: 0.461655; batch adversarial loss: 0.379664\n",
      "epoch 37; iter: 200; batch classifier loss: 0.314164; batch adversarial loss: 0.443250\n",
      "epoch 37; iter: 400; batch classifier loss: 0.532527; batch adversarial loss: 0.292737\n",
      "epoch 37; iter: 600; batch classifier loss: 0.551692; batch adversarial loss: 0.347000\n",
      "epoch 38; iter: 0; batch classifier loss: 0.300620; batch adversarial loss: 0.435567\n",
      "epoch 38; iter: 200; batch classifier loss: 0.354636; batch adversarial loss: 0.480683\n",
      "epoch 38; iter: 400; batch classifier loss: 0.578609; batch adversarial loss: 0.539646\n",
      "epoch 38; iter: 600; batch classifier loss: 0.356096; batch adversarial loss: 0.426923\n",
      "epoch 39; iter: 0; batch classifier loss: 0.345536; batch adversarial loss: 0.271580\n",
      "epoch 39; iter: 200; batch classifier loss: 0.402890; batch adversarial loss: 0.478511\n",
      "epoch 39; iter: 400; batch classifier loss: 0.407570; batch adversarial loss: 0.374541\n",
      "epoch 39; iter: 600; batch classifier loss: 0.468170; batch adversarial loss: 0.344922\n",
      "epoch 40; iter: 0; batch classifier loss: 0.299794; batch adversarial loss: 0.369157\n",
      "epoch 40; iter: 200; batch classifier loss: 0.542098; batch adversarial loss: 0.497933\n",
      "epoch 40; iter: 400; batch classifier loss: 0.327309; batch adversarial loss: 0.425772\n",
      "epoch 40; iter: 600; batch classifier loss: 0.320163; batch adversarial loss: 0.473234\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389280; batch adversarial loss: 0.350274\n",
      "epoch 41; iter: 200; batch classifier loss: 0.388628; batch adversarial loss: 0.523507\n",
      "epoch 41; iter: 400; batch classifier loss: 0.304685; batch adversarial loss: 0.345168\n",
      "epoch 41; iter: 600; batch classifier loss: 0.263516; batch adversarial loss: 0.510884\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419948; batch adversarial loss: 0.314325\n",
      "epoch 42; iter: 200; batch classifier loss: 0.315984; batch adversarial loss: 0.372309\n",
      "epoch 42; iter: 400; batch classifier loss: 0.304561; batch adversarial loss: 0.456149\n",
      "epoch 42; iter: 600; batch classifier loss: 0.324346; batch adversarial loss: 0.372427\n",
      "epoch 43; iter: 0; batch classifier loss: 0.298150; batch adversarial loss: 0.402526\n",
      "epoch 43; iter: 200; batch classifier loss: 0.373621; batch adversarial loss: 0.323862\n",
      "epoch 43; iter: 400; batch classifier loss: 0.477753; batch adversarial loss: 0.370247\n",
      "epoch 43; iter: 600; batch classifier loss: 0.364278; batch adversarial loss: 0.529534\n",
      "epoch 44; iter: 0; batch classifier loss: 0.242521; batch adversarial loss: 0.571527\n",
      "epoch 44; iter: 200; batch classifier loss: 0.493202; batch adversarial loss: 0.264481\n",
      "epoch 44; iter: 400; batch classifier loss: 0.344136; batch adversarial loss: 0.406069\n",
      "epoch 44; iter: 600; batch classifier loss: 0.590238; batch adversarial loss: 0.236944\n",
      "epoch 45; iter: 0; batch classifier loss: 0.334797; batch adversarial loss: 0.398809\n",
      "epoch 45; iter: 200; batch classifier loss: 0.358971; batch adversarial loss: 0.440731\n",
      "epoch 45; iter: 400; batch classifier loss: 0.251655; batch adversarial loss: 0.433784\n",
      "epoch 45; iter: 600; batch classifier loss: 0.487793; batch adversarial loss: 0.402132\n",
      "epoch 46; iter: 0; batch classifier loss: 0.522820; batch adversarial loss: 0.512261\n",
      "epoch 46; iter: 200; batch classifier loss: 0.613352; batch adversarial loss: 0.522548\n",
      "epoch 46; iter: 400; batch classifier loss: 0.370390; batch adversarial loss: 0.407207\n",
      "epoch 46; iter: 600; batch classifier loss: 0.474536; batch adversarial loss: 0.448612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340228; batch adversarial loss: 0.271341\n",
      "epoch 47; iter: 200; batch classifier loss: 0.286449; batch adversarial loss: 0.368057\n",
      "epoch 47; iter: 400; batch classifier loss: 0.358295; batch adversarial loss: 0.440904\n",
      "epoch 47; iter: 600; batch classifier loss: 0.381960; batch adversarial loss: 0.555813\n",
      "epoch 48; iter: 0; batch classifier loss: 0.322991; batch adversarial loss: 0.325777\n",
      "epoch 48; iter: 200; batch classifier loss: 0.367291; batch adversarial loss: 0.306627\n",
      "epoch 48; iter: 400; batch classifier loss: 0.613321; batch adversarial loss: 0.430632\n",
      "epoch 48; iter: 600; batch classifier loss: 0.192125; batch adversarial loss: 0.357809\n",
      "epoch 49; iter: 0; batch classifier loss: 0.245928; batch adversarial loss: 0.418925\n",
      "epoch 49; iter: 200; batch classifier loss: 0.543133; batch adversarial loss: 0.374126\n",
      "epoch 49; iter: 400; batch classifier loss: 0.475367; batch adversarial loss: 0.357255\n",
      "epoch 49; iter: 600; batch classifier loss: 0.366259; batch adversarial loss: 0.519416\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 12.214878; batch adversarial loss: 0.684977\n",
      "epoch 0; iter: 200; batch classifier loss: 14.078918; batch adversarial loss: 0.579280\n",
      "epoch 1; iter: 0; batch classifier loss: 5.434582; batch adversarial loss: 0.588871\n",
      "epoch 1; iter: 200; batch classifier loss: 7.040898; batch adversarial loss: 0.532856\n",
      "epoch 2; iter: 0; batch classifier loss: 9.813115; batch adversarial loss: 0.471245\n",
      "epoch 2; iter: 200; batch classifier loss: 2.437201; batch adversarial loss: 0.501560\n",
      "epoch 3; iter: 0; batch classifier loss: 0.887480; batch adversarial loss: 0.467514\n",
      "epoch 3; iter: 200; batch classifier loss: 2.403565; batch adversarial loss: 0.475649\n",
      "epoch 4; iter: 0; batch classifier loss: 1.225106; batch adversarial loss: 0.493877\n",
      "epoch 4; iter: 200; batch classifier loss: 1.904474; batch adversarial loss: 0.394429\n",
      "epoch 5; iter: 0; batch classifier loss: 1.374161; batch adversarial loss: 0.461912\n",
      "epoch 5; iter: 200; batch classifier loss: 0.371843; batch adversarial loss: 0.396312\n",
      "epoch 6; iter: 0; batch classifier loss: 0.768961; batch adversarial loss: 0.507181\n",
      "epoch 6; iter: 200; batch classifier loss: 0.732197; batch adversarial loss: 0.505494\n",
      "epoch 7; iter: 0; batch classifier loss: 0.409662; batch adversarial loss: 0.380757\n",
      "epoch 7; iter: 200; batch classifier loss: 0.750723; batch adversarial loss: 0.377504\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525811; batch adversarial loss: 0.403513\n",
      "epoch 8; iter: 200; batch classifier loss: 0.333824; batch adversarial loss: 0.405953\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386094; batch adversarial loss: 0.431318\n",
      "epoch 9; iter: 200; batch classifier loss: 0.360323; batch adversarial loss: 0.403783\n",
      "epoch 0; iter: 0; batch classifier loss: 8.011216; batch adversarial loss: 0.747480\n",
      "epoch 0; iter: 200; batch classifier loss: 6.776465; batch adversarial loss: 0.658845\n",
      "epoch 1; iter: 0; batch classifier loss: 7.091243; batch adversarial loss: 0.612161\n",
      "epoch 1; iter: 200; batch classifier loss: 5.746821; batch adversarial loss: 0.526332\n",
      "epoch 2; iter: 0; batch classifier loss: 0.925888; batch adversarial loss: 0.546120\n",
      "epoch 2; iter: 200; batch classifier loss: 1.498751; batch adversarial loss: 0.502668\n",
      "epoch 3; iter: 0; batch classifier loss: 1.756067; batch adversarial loss: 0.485370\n",
      "epoch 3; iter: 200; batch classifier loss: 1.758169; batch adversarial loss: 0.530509\n",
      "epoch 4; iter: 0; batch classifier loss: 1.004735; batch adversarial loss: 0.440353\n",
      "epoch 4; iter: 200; batch classifier loss: 1.708593; batch adversarial loss: 0.419983\n",
      "epoch 5; iter: 0; batch classifier loss: 1.907449; batch adversarial loss: 0.476640\n",
      "epoch 5; iter: 200; batch classifier loss: 0.517619; batch adversarial loss: 0.467756\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482076; batch adversarial loss: 0.514625\n",
      "epoch 6; iter: 200; batch classifier loss: 0.953443; batch adversarial loss: 0.373938\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591288; batch adversarial loss: 0.359591\n",
      "epoch 7; iter: 200; batch classifier loss: 0.516661; batch adversarial loss: 0.374755\n",
      "epoch 8; iter: 0; batch classifier loss: 0.493921; batch adversarial loss: 0.474555\n",
      "epoch 8; iter: 200; batch classifier loss: 0.409321; batch adversarial loss: 0.477467\n",
      "epoch 9; iter: 0; batch classifier loss: 0.380316; batch adversarial loss: 0.460777\n",
      "epoch 9; iter: 200; batch classifier loss: 0.499586; batch adversarial loss: 0.427433\n",
      "epoch 0; iter: 0; batch classifier loss: 10.716786; batch adversarial loss: 0.651283\n",
      "epoch 0; iter: 200; batch classifier loss: 19.673376; batch adversarial loss: 0.589976\n",
      "epoch 1; iter: 0; batch classifier loss: 5.947757; batch adversarial loss: 0.597362\n",
      "epoch 1; iter: 200; batch classifier loss: 21.198067; batch adversarial loss: 0.539623\n",
      "epoch 2; iter: 0; batch classifier loss: 2.644951; batch adversarial loss: 0.470109\n",
      "epoch 2; iter: 200; batch classifier loss: 1.718845; batch adversarial loss: 0.443015\n",
      "epoch 3; iter: 0; batch classifier loss: 3.036210; batch adversarial loss: 0.468283\n",
      "epoch 3; iter: 200; batch classifier loss: 1.055408; batch adversarial loss: 0.497686\n",
      "epoch 4; iter: 0; batch classifier loss: 0.683907; batch adversarial loss: 0.467565\n",
      "epoch 4; iter: 200; batch classifier loss: 1.119954; batch adversarial loss: 0.417985\n",
      "epoch 5; iter: 0; batch classifier loss: 0.535213; batch adversarial loss: 0.465172\n",
      "epoch 5; iter: 200; batch classifier loss: 1.246546; batch adversarial loss: 0.515813\n",
      "epoch 6; iter: 0; batch classifier loss: 0.960349; batch adversarial loss: 0.455345\n",
      "epoch 6; iter: 200; batch classifier loss: 0.907144; batch adversarial loss: 0.462847\n",
      "epoch 7; iter: 0; batch classifier loss: 0.403490; batch adversarial loss: 0.458150\n",
      "epoch 7; iter: 200; batch classifier loss: 0.353396; batch adversarial loss: 0.346844\n",
      "epoch 8; iter: 0; batch classifier loss: 0.480053; batch adversarial loss: 0.425369\n",
      "epoch 8; iter: 200; batch classifier loss: 0.397619; batch adversarial loss: 0.471326\n",
      "epoch 9; iter: 0; batch classifier loss: 0.423602; batch adversarial loss: 0.354351\n",
      "epoch 9; iter: 200; batch classifier loss: 0.575505; batch adversarial loss: 0.416374\n",
      "epoch 0; iter: 0; batch classifier loss: 11.307042; batch adversarial loss: 0.976259\n",
      "epoch 0; iter: 200; batch classifier loss: 3.452851; batch adversarial loss: 1.207581\n",
      "epoch 1; iter: 0; batch classifier loss: 7.377271; batch adversarial loss: 1.152436\n",
      "epoch 1; iter: 200; batch classifier loss: 7.078115; batch adversarial loss: 0.664213\n",
      "epoch 2; iter: 0; batch classifier loss: 2.602492; batch adversarial loss: 0.767241\n",
      "epoch 2; iter: 200; batch classifier loss: 2.769269; batch adversarial loss: 0.710005\n",
      "epoch 3; iter: 0; batch classifier loss: 2.924912; batch adversarial loss: 0.593409\n",
      "epoch 3; iter: 200; batch classifier loss: 4.413556; batch adversarial loss: 0.520348\n",
      "epoch 4; iter: 0; batch classifier loss: 1.305380; batch adversarial loss: 0.561337\n",
      "epoch 4; iter: 200; batch classifier loss: 1.030081; batch adversarial loss: 0.406325\n",
      "epoch 5; iter: 0; batch classifier loss: 10.034670; batch adversarial loss: 0.467393\n",
      "epoch 5; iter: 200; batch classifier loss: 0.685817; batch adversarial loss: 0.384842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541205; batch adversarial loss: 0.410711\n",
      "epoch 6; iter: 200; batch classifier loss: 0.766690; batch adversarial loss: 0.392138\n",
      "epoch 7; iter: 0; batch classifier loss: 0.621433; batch adversarial loss: 0.499693\n",
      "epoch 7; iter: 200; batch classifier loss: 0.752944; batch adversarial loss: 0.415737\n",
      "epoch 8; iter: 0; batch classifier loss: 0.794354; batch adversarial loss: 0.514702\n",
      "epoch 8; iter: 200; batch classifier loss: 0.559284; batch adversarial loss: 0.436093\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527653; batch adversarial loss: 0.548474\n",
      "epoch 9; iter: 200; batch classifier loss: 0.477643; batch adversarial loss: 0.439641\n",
      "epoch 0; iter: 0; batch classifier loss: 5.554685; batch adversarial loss: 0.505732\n",
      "epoch 0; iter: 200; batch classifier loss: 3.840449; batch adversarial loss: 0.624263\n",
      "epoch 1; iter: 0; batch classifier loss: 12.373764; batch adversarial loss: 0.579941\n",
      "epoch 1; iter: 200; batch classifier loss: 2.311142; batch adversarial loss: 0.478169\n",
      "epoch 2; iter: 0; batch classifier loss: 1.829170; batch adversarial loss: 0.500787\n",
      "epoch 2; iter: 200; batch classifier loss: 2.265309; batch adversarial loss: 0.471247\n",
      "epoch 3; iter: 0; batch classifier loss: 0.901340; batch adversarial loss: 0.443789\n",
      "epoch 3; iter: 200; batch classifier loss: 0.873991; batch adversarial loss: 0.519238\n",
      "epoch 4; iter: 0; batch classifier loss: 1.874726; batch adversarial loss: 0.491645\n",
      "epoch 4; iter: 200; batch classifier loss: 0.778293; batch adversarial loss: 0.445376\n",
      "epoch 5; iter: 0; batch classifier loss: 0.482930; batch adversarial loss: 0.453642\n",
      "epoch 5; iter: 200; batch classifier loss: 1.088067; batch adversarial loss: 0.487036\n",
      "epoch 6; iter: 0; batch classifier loss: 0.838729; batch adversarial loss: 0.451287\n",
      "epoch 6; iter: 200; batch classifier loss: 0.537763; batch adversarial loss: 0.518215\n",
      "epoch 7; iter: 0; batch classifier loss: 4.302433; batch adversarial loss: 0.416965\n",
      "epoch 7; iter: 200; batch classifier loss: 0.608241; batch adversarial loss: 0.389644\n",
      "epoch 8; iter: 0; batch classifier loss: 0.389899; batch adversarial loss: 0.568487\n",
      "epoch 8; iter: 200; batch classifier loss: 0.357864; batch adversarial loss: 0.465102\n",
      "epoch 9; iter: 0; batch classifier loss: 0.425882; batch adversarial loss: 0.445320\n",
      "epoch 9; iter: 200; batch classifier loss: 0.508833; batch adversarial loss: 0.409113\n",
      "epoch 0; iter: 0; batch classifier loss: 36.197491; batch adversarial loss: 0.777399\n",
      "epoch 0; iter: 200; batch classifier loss: 10.390396; batch adversarial loss: 0.720985\n",
      "epoch 1; iter: 0; batch classifier loss: 5.908283; batch adversarial loss: 0.697713\n",
      "epoch 1; iter: 200; batch classifier loss: 1.984633; batch adversarial loss: 0.612428\n",
      "epoch 2; iter: 0; batch classifier loss: 2.898286; batch adversarial loss: 0.545367\n",
      "epoch 2; iter: 200; batch classifier loss: 1.286054; batch adversarial loss: 0.573190\n",
      "epoch 3; iter: 0; batch classifier loss: 4.962524; batch adversarial loss: 0.470449\n",
      "epoch 3; iter: 200; batch classifier loss: 2.291068; batch adversarial loss: 0.498387\n",
      "epoch 4; iter: 0; batch classifier loss: 1.830655; batch adversarial loss: 0.449446\n",
      "epoch 4; iter: 200; batch classifier loss: 0.766814; batch adversarial loss: 0.407046\n",
      "epoch 5; iter: 0; batch classifier loss: 0.609958; batch adversarial loss: 0.404584\n",
      "epoch 5; iter: 200; batch classifier loss: 1.156432; batch adversarial loss: 0.439087\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596189; batch adversarial loss: 0.432546\n",
      "epoch 6; iter: 200; batch classifier loss: 0.585964; batch adversarial loss: 0.481268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.749558; batch adversarial loss: 0.504799\n",
      "epoch 7; iter: 200; batch classifier loss: 0.707312; batch adversarial loss: 0.428467\n",
      "epoch 8; iter: 0; batch classifier loss: 0.388990; batch adversarial loss: 0.432139\n",
      "epoch 8; iter: 200; batch classifier loss: 0.638065; batch adversarial loss: 0.469175\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299350; batch adversarial loss: 0.364658\n",
      "epoch 9; iter: 200; batch classifier loss: 0.422279; batch adversarial loss: 0.475394\n",
      "epoch 0; iter: 0; batch classifier loss: 18.532784; batch adversarial loss: 0.833983\n",
      "epoch 0; iter: 200; batch classifier loss: 5.075551; batch adversarial loss: 1.006558\n",
      "epoch 1; iter: 0; batch classifier loss: 4.533322; batch adversarial loss: 0.791797\n",
      "epoch 1; iter: 200; batch classifier loss: 5.664042; batch adversarial loss: 0.584089\n",
      "epoch 2; iter: 0; batch classifier loss: 1.636611; batch adversarial loss: 0.577337\n",
      "epoch 2; iter: 200; batch classifier loss: 1.923170; batch adversarial loss: 0.548548\n",
      "epoch 3; iter: 0; batch classifier loss: 2.095862; batch adversarial loss: 0.533047\n",
      "epoch 3; iter: 200; batch classifier loss: 0.890890; batch adversarial loss: 0.467790\n",
      "epoch 4; iter: 0; batch classifier loss: 1.130098; batch adversarial loss: 0.514020\n",
      "epoch 4; iter: 200; batch classifier loss: 0.493258; batch adversarial loss: 0.425827\n",
      "epoch 5; iter: 0; batch classifier loss: 1.027575; batch adversarial loss: 0.423297\n",
      "epoch 5; iter: 200; batch classifier loss: 0.721579; batch adversarial loss: 0.385025\n",
      "epoch 6; iter: 0; batch classifier loss: 0.653346; batch adversarial loss: 0.465665\n",
      "epoch 6; iter: 200; batch classifier loss: 0.498052; batch adversarial loss: 0.353824\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586508; batch adversarial loss: 0.460515\n",
      "epoch 7; iter: 200; batch classifier loss: 0.713492; batch adversarial loss: 0.410862\n",
      "epoch 8; iter: 0; batch classifier loss: 0.393000; batch adversarial loss: 0.441797\n",
      "epoch 8; iter: 200; batch classifier loss: 0.360073; batch adversarial loss: 0.389298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367093; batch adversarial loss: 0.340929\n",
      "epoch 9; iter: 200; batch classifier loss: 0.424209; batch adversarial loss: 0.481904\n",
      "epoch 0; iter: 0; batch classifier loss: 7.012763; batch adversarial loss: 0.490591\n",
      "epoch 0; iter: 200; batch classifier loss: 5.231005; batch adversarial loss: 0.598205\n",
      "epoch 1; iter: 0; batch classifier loss: 4.999333; batch adversarial loss: 0.567446\n",
      "epoch 1; iter: 200; batch classifier loss: 3.636177; batch adversarial loss: 0.516069\n",
      "epoch 2; iter: 0; batch classifier loss: 1.285478; batch adversarial loss: 0.476249\n",
      "epoch 2; iter: 200; batch classifier loss: 2.362337; batch adversarial loss: 0.529672\n",
      "epoch 3; iter: 0; batch classifier loss: 3.538261; batch adversarial loss: 0.504855\n",
      "epoch 3; iter: 200; batch classifier loss: 1.077138; batch adversarial loss: 0.533420\n",
      "epoch 4; iter: 0; batch classifier loss: 1.160528; batch adversarial loss: 0.428725\n",
      "epoch 4; iter: 200; batch classifier loss: 0.489877; batch adversarial loss: 0.417445\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572732; batch adversarial loss: 0.434720\n",
      "epoch 5; iter: 200; batch classifier loss: 0.735514; batch adversarial loss: 0.444258\n",
      "epoch 6; iter: 0; batch classifier loss: 1.275700; batch adversarial loss: 0.494567\n",
      "epoch 6; iter: 200; batch classifier loss: 0.462748; batch adversarial loss: 0.401466\n",
      "epoch 7; iter: 0; batch classifier loss: 0.631383; batch adversarial loss: 0.388599\n",
      "epoch 7; iter: 200; batch classifier loss: 0.745584; batch adversarial loss: 0.408116\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521022; batch adversarial loss: 0.427494\n",
      "epoch 8; iter: 200; batch classifier loss: 0.366328; batch adversarial loss: 0.505161\n",
      "epoch 9; iter: 0; batch classifier loss: 1.061539; batch adversarial loss: 0.385032\n",
      "epoch 9; iter: 200; batch classifier loss: 0.577001; batch adversarial loss: 0.322894\n",
      "epoch 0; iter: 0; batch classifier loss: 6.351164; batch adversarial loss: 0.724864\n",
      "epoch 0; iter: 200; batch classifier loss: 21.430153; batch adversarial loss: 0.595526\n",
      "epoch 1; iter: 0; batch classifier loss: 27.938194; batch adversarial loss: 0.553629\n",
      "epoch 1; iter: 200; batch classifier loss: 0.570161; batch adversarial loss: 0.542210\n",
      "epoch 2; iter: 0; batch classifier loss: 8.338177; batch adversarial loss: 0.520133\n",
      "epoch 2; iter: 200; batch classifier loss: 3.222274; batch adversarial loss: 0.473370\n",
      "epoch 3; iter: 0; batch classifier loss: 2.793077; batch adversarial loss: 0.500506\n",
      "epoch 3; iter: 200; batch classifier loss: 2.630451; batch adversarial loss: 0.495430\n",
      "epoch 4; iter: 0; batch classifier loss: 1.872567; batch adversarial loss: 0.491489\n",
      "epoch 4; iter: 200; batch classifier loss: 0.587495; batch adversarial loss: 0.439307\n",
      "epoch 5; iter: 0; batch classifier loss: 0.620488; batch adversarial loss: 0.393113\n",
      "epoch 5; iter: 200; batch classifier loss: 0.897280; batch adversarial loss: 0.405255\n",
      "epoch 6; iter: 0; batch classifier loss: 0.690048; batch adversarial loss: 0.456707\n",
      "epoch 6; iter: 200; batch classifier loss: 0.747136; batch adversarial loss: 0.354400\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573738; batch adversarial loss: 0.442300\n",
      "epoch 7; iter: 200; batch classifier loss: 0.363908; batch adversarial loss: 0.398026\n",
      "epoch 8; iter: 0; batch classifier loss: 1.050878; batch adversarial loss: 0.387404\n",
      "epoch 8; iter: 200; batch classifier loss: 0.410176; batch adversarial loss: 0.356334\n",
      "epoch 9; iter: 0; batch classifier loss: 0.391194; batch adversarial loss: 0.321947\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383136; batch adversarial loss: 0.446583\n",
      "epoch 0; iter: 0; batch classifier loss: 11.967372; batch adversarial loss: 0.776632\n",
      "epoch 0; iter: 200; batch classifier loss: 4.985036; batch adversarial loss: 0.630095\n",
      "epoch 1; iter: 0; batch classifier loss: 2.325533; batch adversarial loss: 0.610693\n",
      "epoch 1; iter: 200; batch classifier loss: 8.096378; batch adversarial loss: 0.550107\n",
      "epoch 2; iter: 0; batch classifier loss: 1.621557; batch adversarial loss: 0.511967\n",
      "epoch 2; iter: 200; batch classifier loss: 2.402868; batch adversarial loss: 0.496353\n",
      "epoch 3; iter: 0; batch classifier loss: 3.940606; batch adversarial loss: 0.502594\n",
      "epoch 3; iter: 200; batch classifier loss: 1.294161; batch adversarial loss: 0.447567\n",
      "epoch 4; iter: 0; batch classifier loss: 0.639383; batch adversarial loss: 0.499418\n",
      "epoch 4; iter: 200; batch classifier loss: 0.589500; batch adversarial loss: 0.423208\n",
      "epoch 5; iter: 0; batch classifier loss: 0.398661; batch adversarial loss: 0.424673\n",
      "epoch 5; iter: 200; batch classifier loss: 0.502727; batch adversarial loss: 0.406716\n",
      "epoch 6; iter: 0; batch classifier loss: 0.461225; batch adversarial loss: 0.415208\n",
      "epoch 6; iter: 200; batch classifier loss: 0.623132; batch adversarial loss: 0.435533\n",
      "epoch 7; iter: 0; batch classifier loss: 0.633734; batch adversarial loss: 0.367722\n",
      "epoch 7; iter: 200; batch classifier loss: 0.533471; batch adversarial loss: 0.403779\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432026; batch adversarial loss: 0.435944\n",
      "epoch 8; iter: 200; batch classifier loss: 0.528514; batch adversarial loss: 0.473463\n",
      "epoch 9; iter: 0; batch classifier loss: 0.272207; batch adversarial loss: 0.446701\n",
      "epoch 9; iter: 200; batch classifier loss: 0.313653; batch adversarial loss: 0.345371\n",
      "epoch 0; iter: 0; batch classifier loss: 50.440361; batch adversarial loss: 0.661468\n",
      "epoch 0; iter: 200; batch classifier loss: 10.309437; batch adversarial loss: 0.581266\n",
      "epoch 1; iter: 0; batch classifier loss: 0.791188; batch adversarial loss: 0.521153\n",
      "epoch 1; iter: 200; batch classifier loss: 3.718779; batch adversarial loss: 0.509106\n",
      "epoch 2; iter: 0; batch classifier loss: 5.382303; batch adversarial loss: 0.543946\n",
      "epoch 2; iter: 200; batch classifier loss: 8.447793; batch adversarial loss: 0.446208\n",
      "epoch 3; iter: 0; batch classifier loss: 1.368334; batch adversarial loss: 0.462510\n",
      "epoch 3; iter: 200; batch classifier loss: 1.223474; batch adversarial loss: 0.419757\n",
      "epoch 4; iter: 0; batch classifier loss: 1.074218; batch adversarial loss: 0.447501\n",
      "epoch 4; iter: 200; batch classifier loss: 1.789827; batch adversarial loss: 0.375806\n",
      "epoch 5; iter: 0; batch classifier loss: 0.945731; batch adversarial loss: 0.392894\n",
      "epoch 5; iter: 200; batch classifier loss: 0.643772; batch adversarial loss: 0.428756\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565644; batch adversarial loss: 0.423222\n",
      "epoch 6; iter: 200; batch classifier loss: 0.442286; batch adversarial loss: 0.407891\n",
      "epoch 7; iter: 0; batch classifier loss: 0.344937; batch adversarial loss: 0.411961\n",
      "epoch 7; iter: 200; batch classifier loss: 0.454151; batch adversarial loss: 0.496288\n",
      "epoch 8; iter: 0; batch classifier loss: 0.348017; batch adversarial loss: 0.445037\n",
      "epoch 8; iter: 200; batch classifier loss: 0.436544; batch adversarial loss: 0.386467\n",
      "epoch 9; iter: 0; batch classifier loss: 0.329846; batch adversarial loss: 0.446288\n",
      "epoch 9; iter: 200; batch classifier loss: 0.375151; batch adversarial loss: 0.360719\n",
      "epoch 0; iter: 0; batch classifier loss: 20.936577; batch adversarial loss: 0.528349\n",
      "epoch 0; iter: 200; batch classifier loss: 5.150170; batch adversarial loss: 0.565970\n",
      "epoch 1; iter: 0; batch classifier loss: 2.664195; batch adversarial loss: 0.519601\n",
      "epoch 1; iter: 200; batch classifier loss: 5.362461; batch adversarial loss: 0.484988\n",
      "epoch 2; iter: 0; batch classifier loss: 4.217872; batch adversarial loss: 0.530215\n",
      "epoch 2; iter: 200; batch classifier loss: 1.982666; batch adversarial loss: 0.439801\n",
      "epoch 3; iter: 0; batch classifier loss: 0.833563; batch adversarial loss: 0.456252\n",
      "epoch 3; iter: 200; batch classifier loss: 2.820769; batch adversarial loss: 0.496718\n",
      "epoch 4; iter: 0; batch classifier loss: 2.066185; batch adversarial loss: 0.372950\n",
      "epoch 4; iter: 200; batch classifier loss: 3.275112; batch adversarial loss: 0.592253\n",
      "epoch 5; iter: 0; batch classifier loss: 0.663246; batch adversarial loss: 0.386864\n",
      "epoch 5; iter: 200; batch classifier loss: 0.819485; batch adversarial loss: 0.428518\n",
      "epoch 6; iter: 0; batch classifier loss: 1.170270; batch adversarial loss: 0.455403\n",
      "epoch 6; iter: 200; batch classifier loss: 0.681103; batch adversarial loss: 0.489816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580528; batch adversarial loss: 0.383247\n",
      "epoch 7; iter: 200; batch classifier loss: 0.788786; batch adversarial loss: 0.377836\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334106; batch adversarial loss: 0.404258\n",
      "epoch 8; iter: 200; batch classifier loss: 0.359732; batch adversarial loss: 0.321111\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540706; batch adversarial loss: 0.352368\n",
      "epoch 9; iter: 200; batch classifier loss: 0.401538; batch adversarial loss: 0.345652\n",
      "epoch 0; iter: 0; batch classifier loss: 265.790344; batch adversarial loss: 0.689348\n",
      "epoch 0; iter: 200; batch classifier loss: 11.841557; batch adversarial loss: 0.572981\n",
      "epoch 1; iter: 0; batch classifier loss: 4.739371; batch adversarial loss: 0.505338\n",
      "epoch 1; iter: 200; batch classifier loss: 8.721739; batch adversarial loss: 0.479842\n",
      "epoch 2; iter: 0; batch classifier loss: 4.627299; batch adversarial loss: 0.512886\n",
      "epoch 2; iter: 200; batch classifier loss: 3.115137; batch adversarial loss: 0.475352\n",
      "epoch 3; iter: 0; batch classifier loss: 2.869895; batch adversarial loss: 0.546252\n",
      "epoch 3; iter: 200; batch classifier loss: 11.954963; batch adversarial loss: 0.506819\n",
      "epoch 4; iter: 0; batch classifier loss: 3.081820; batch adversarial loss: 0.443136\n",
      "epoch 4; iter: 200; batch classifier loss: 1.167341; batch adversarial loss: 0.444581\n",
      "epoch 5; iter: 0; batch classifier loss: 0.342085; batch adversarial loss: 0.506719\n",
      "epoch 5; iter: 200; batch classifier loss: 0.902166; batch adversarial loss: 0.472042\n",
      "epoch 6; iter: 0; batch classifier loss: 1.163599; batch adversarial loss: 0.482452\n",
      "epoch 6; iter: 200; batch classifier loss: 0.861596; batch adversarial loss: 0.415860\n",
      "epoch 7; iter: 0; batch classifier loss: 0.354255; batch adversarial loss: 0.420249\n",
      "epoch 7; iter: 200; batch classifier loss: 0.802553; batch adversarial loss: 0.436937\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554828; batch adversarial loss: 0.365431\n",
      "epoch 8; iter: 200; batch classifier loss: 0.599946; batch adversarial loss: 0.442416\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434459; batch adversarial loss: 0.446007\n",
      "epoch 9; iter: 200; batch classifier loss: 0.698130; batch adversarial loss: 0.430846\n",
      "epoch 0; iter: 0; batch classifier loss: 90.120636; batch adversarial loss: 0.515057\n",
      "epoch 0; iter: 200; batch classifier loss: 6.638691; batch adversarial loss: 0.598028\n",
      "epoch 1; iter: 0; batch classifier loss: 1.253009; batch adversarial loss: 0.550788\n",
      "epoch 1; iter: 200; batch classifier loss: 3.699744; batch adversarial loss: 0.546746\n",
      "epoch 2; iter: 0; batch classifier loss: 4.127914; batch adversarial loss: 0.544907\n",
      "epoch 2; iter: 200; batch classifier loss: 2.947104; batch adversarial loss: 0.473892\n",
      "epoch 3; iter: 0; batch classifier loss: 1.911421; batch adversarial loss: 0.459954\n",
      "epoch 3; iter: 200; batch classifier loss: 0.562274; batch adversarial loss: 0.466469\n",
      "epoch 4; iter: 0; batch classifier loss: 1.098438; batch adversarial loss: 0.404575\n",
      "epoch 4; iter: 200; batch classifier loss: 0.725476; batch adversarial loss: 0.405647\n",
      "epoch 5; iter: 0; batch classifier loss: 0.463285; batch adversarial loss: 0.523267\n",
      "epoch 5; iter: 200; batch classifier loss: 0.336517; batch adversarial loss: 0.532920\n",
      "epoch 6; iter: 0; batch classifier loss: 0.442749; batch adversarial loss: 0.510504\n",
      "epoch 6; iter: 200; batch classifier loss: 0.456826; batch adversarial loss: 0.401741\n",
      "epoch 7; iter: 0; batch classifier loss: 0.368902; batch adversarial loss: 0.390229\n",
      "epoch 7; iter: 200; batch classifier loss: 0.454899; batch adversarial loss: 0.390066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.405856; batch adversarial loss: 0.488235\n",
      "epoch 8; iter: 200; batch classifier loss: 0.361979; batch adversarial loss: 0.388912\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392295; batch adversarial loss: 0.372259\n",
      "epoch 9; iter: 200; batch classifier loss: 0.542739; batch adversarial loss: 0.480551\n",
      "epoch 0; iter: 0; batch classifier loss: 87.628258; batch adversarial loss: 0.520955\n",
      "epoch 0; iter: 200; batch classifier loss: 26.326775; batch adversarial loss: 0.580537\n",
      "epoch 1; iter: 0; batch classifier loss: 5.636735; batch adversarial loss: 0.530384\n",
      "epoch 1; iter: 200; batch classifier loss: 2.278542; batch adversarial loss: 0.532165\n",
      "epoch 2; iter: 0; batch classifier loss: 4.261006; batch adversarial loss: 0.519382\n",
      "epoch 2; iter: 200; batch classifier loss: 2.001114; batch adversarial loss: 0.469404\n",
      "epoch 3; iter: 0; batch classifier loss: 4.037943; batch adversarial loss: 0.468089\n",
      "epoch 3; iter: 200; batch classifier loss: 2.340727; batch adversarial loss: 0.482795\n",
      "epoch 4; iter: 0; batch classifier loss: 2.282498; batch adversarial loss: 0.411214\n",
      "epoch 4; iter: 200; batch classifier loss: 1.713242; batch adversarial loss: 0.381357\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630367; batch adversarial loss: 0.428805\n",
      "epoch 5; iter: 200; batch classifier loss: 0.421159; batch adversarial loss: 0.405620\n",
      "epoch 6; iter: 0; batch classifier loss: 0.646509; batch adversarial loss: 0.431317\n",
      "epoch 6; iter: 200; batch classifier loss: 0.687589; batch adversarial loss: 0.465565\n",
      "epoch 7; iter: 0; batch classifier loss: 0.476149; batch adversarial loss: 0.434061\n",
      "epoch 7; iter: 200; batch classifier loss: 0.659758; batch adversarial loss: 0.413849\n",
      "epoch 8; iter: 0; batch classifier loss: 0.594638; batch adversarial loss: 0.478983\n",
      "epoch 8; iter: 200; batch classifier loss: 0.513268; batch adversarial loss: 0.422653\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521478; batch adversarial loss: 0.499234\n",
      "epoch 9; iter: 200; batch classifier loss: 0.482959; batch adversarial loss: 0.426780\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 107.245056; batch adversarial loss: 0.681305\n",
      "epoch 0; iter: 200; batch classifier loss: 9.732801; batch adversarial loss: 0.629141\n",
      "epoch 1; iter: 0; batch classifier loss: 7.389821; batch adversarial loss: 0.611446\n",
      "epoch 1; iter: 200; batch classifier loss: 2.282290; batch adversarial loss: 0.564804\n",
      "epoch 2; iter: 0; batch classifier loss: 2.331112; batch adversarial loss: 0.527813\n",
      "epoch 2; iter: 200; batch classifier loss: 2.804846; batch adversarial loss: 0.452405\n",
      "epoch 3; iter: 0; batch classifier loss: 7.773277; batch adversarial loss: 0.492251\n",
      "epoch 3; iter: 200; batch classifier loss: 4.890495; batch adversarial loss: 0.456404\n",
      "epoch 4; iter: 0; batch classifier loss: 1.140051; batch adversarial loss: 0.453261\n",
      "epoch 4; iter: 200; batch classifier loss: 2.984274; batch adversarial loss: 0.423810\n",
      "epoch 5; iter: 0; batch classifier loss: 8.224146; batch adversarial loss: 0.423818\n",
      "epoch 5; iter: 200; batch classifier loss: 1.807163; batch adversarial loss: 0.396674\n",
      "epoch 6; iter: 0; batch classifier loss: 0.887391; batch adversarial loss: 0.500006\n",
      "epoch 6; iter: 200; batch classifier loss: 0.619701; batch adversarial loss: 0.460420\n",
      "epoch 7; iter: 0; batch classifier loss: 0.682320; batch adversarial loss: 0.394575\n",
      "epoch 7; iter: 200; batch classifier loss: 0.869126; batch adversarial loss: 0.350548\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517363; batch adversarial loss: 0.451116\n",
      "epoch 8; iter: 200; batch classifier loss: 1.104095; batch adversarial loss: 0.439115\n",
      "epoch 9; iter: 0; batch classifier loss: 0.596777; batch adversarial loss: 0.470337\n",
      "epoch 9; iter: 200; batch classifier loss: 0.377173; batch adversarial loss: 0.552723\n",
      "epoch 10; iter: 0; batch classifier loss: 0.382787; batch adversarial loss: 0.467726\n",
      "epoch 10; iter: 200; batch classifier loss: 0.379268; batch adversarial loss: 0.447848\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359073; batch adversarial loss: 0.422969\n",
      "epoch 11; iter: 200; batch classifier loss: 0.311948; batch adversarial loss: 0.500767\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536587; batch adversarial loss: 0.367211\n",
      "epoch 12; iter: 200; batch classifier loss: 0.503468; batch adversarial loss: 0.377429\n",
      "epoch 13; iter: 0; batch classifier loss: 0.737567; batch adversarial loss: 0.400871\n",
      "epoch 13; iter: 200; batch classifier loss: 0.320816; batch adversarial loss: 0.415876\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469031; batch adversarial loss: 0.371350\n",
      "epoch 14; iter: 200; batch classifier loss: 0.435199; batch adversarial loss: 0.348617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.303424; batch adversarial loss: 0.444334\n",
      "epoch 15; iter: 200; batch classifier loss: 0.359014; batch adversarial loss: 0.484703\n",
      "epoch 16; iter: 0; batch classifier loss: 0.838220; batch adversarial loss: 0.494864\n",
      "epoch 16; iter: 200; batch classifier loss: 0.437936; batch adversarial loss: 0.428106\n",
      "epoch 17; iter: 0; batch classifier loss: 0.437520; batch adversarial loss: 0.362016\n",
      "epoch 17; iter: 200; batch classifier loss: 0.363603; batch adversarial loss: 0.389203\n",
      "epoch 18; iter: 0; batch classifier loss: 0.369661; batch adversarial loss: 0.485589\n",
      "epoch 18; iter: 200; batch classifier loss: 0.555311; batch adversarial loss: 0.375447\n",
      "epoch 19; iter: 0; batch classifier loss: 0.339646; batch adversarial loss: 0.410479\n",
      "epoch 19; iter: 200; batch classifier loss: 0.276176; batch adversarial loss: 0.445339\n",
      "epoch 0; iter: 0; batch classifier loss: 36.925331; batch adversarial loss: 0.688954\n",
      "epoch 0; iter: 200; batch classifier loss: 32.141346; batch adversarial loss: 0.580630\n",
      "epoch 1; iter: 0; batch classifier loss: 5.227840; batch adversarial loss: 0.586705\n",
      "epoch 1; iter: 200; batch classifier loss: 3.581164; batch adversarial loss: 0.528348\n",
      "epoch 2; iter: 0; batch classifier loss: 2.866610; batch adversarial loss: 0.474200\n",
      "epoch 2; iter: 200; batch classifier loss: 2.578125; batch adversarial loss: 0.495397\n",
      "epoch 3; iter: 0; batch classifier loss: 3.584958; batch adversarial loss: 0.482591\n",
      "epoch 3; iter: 200; batch classifier loss: 0.458401; batch adversarial loss: 0.446513\n",
      "epoch 4; iter: 0; batch classifier loss: 2.426994; batch adversarial loss: 0.406082\n",
      "epoch 4; iter: 200; batch classifier loss: 1.755441; batch adversarial loss: 0.493961\n",
      "epoch 5; iter: 0; batch classifier loss: 2.122957; batch adversarial loss: 0.448330\n",
      "epoch 5; iter: 200; batch classifier loss: 0.997137; batch adversarial loss: 0.389194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.657320; batch adversarial loss: 0.425912\n",
      "epoch 6; iter: 200; batch classifier loss: 0.743594; batch adversarial loss: 0.403448\n",
      "epoch 7; iter: 0; batch classifier loss: 1.180212; batch adversarial loss: 0.420006\n",
      "epoch 7; iter: 200; batch classifier loss: 0.378871; batch adversarial loss: 0.389461\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495044; batch adversarial loss: 0.414980\n",
      "epoch 8; iter: 200; batch classifier loss: 0.498444; batch adversarial loss: 0.365275\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434010; batch adversarial loss: 0.422838\n",
      "epoch 9; iter: 200; batch classifier loss: 0.637112; batch adversarial loss: 0.355582\n",
      "epoch 10; iter: 0; batch classifier loss: 0.795179; batch adversarial loss: 0.347357\n",
      "epoch 10; iter: 200; batch classifier loss: 0.406910; batch adversarial loss: 0.457923\n",
      "epoch 11; iter: 0; batch classifier loss: 0.693568; batch adversarial loss: 0.453678\n",
      "epoch 11; iter: 200; batch classifier loss: 0.397617; batch adversarial loss: 0.364357\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552424; batch adversarial loss: 0.401425\n",
      "epoch 12; iter: 200; batch classifier loss: 0.447539; batch adversarial loss: 0.484134\n",
      "epoch 13; iter: 0; batch classifier loss: 0.485226; batch adversarial loss: 0.433674\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352224; batch adversarial loss: 0.417879\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331250; batch adversarial loss: 0.454670\n",
      "epoch 14; iter: 200; batch classifier loss: 0.572917; batch adversarial loss: 0.387469\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294095; batch adversarial loss: 0.391196\n",
      "epoch 15; iter: 200; batch classifier loss: 0.362402; batch adversarial loss: 0.408356\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319875; batch adversarial loss: 0.382676\n",
      "epoch 16; iter: 200; batch classifier loss: 0.343882; batch adversarial loss: 0.277747\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390650; batch adversarial loss: 0.380705\n",
      "epoch 17; iter: 200; batch classifier loss: 0.277012; batch adversarial loss: 0.400267\n",
      "epoch 18; iter: 0; batch classifier loss: 0.443450; batch adversarial loss: 0.491469\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373699; batch adversarial loss: 0.343451\n",
      "epoch 19; iter: 0; batch classifier loss: 0.333159; batch adversarial loss: 0.421639\n",
      "epoch 19; iter: 200; batch classifier loss: 0.310243; batch adversarial loss: 0.413870\n",
      "epoch 0; iter: 0; batch classifier loss: 55.902702; batch adversarial loss: 0.696712\n",
      "epoch 0; iter: 200; batch classifier loss: 3.877418; batch adversarial loss: 0.651431\n",
      "epoch 1; iter: 0; batch classifier loss: 6.215471; batch adversarial loss: 0.628219\n",
      "epoch 1; iter: 200; batch classifier loss: 2.509024; batch adversarial loss: 0.542440\n",
      "epoch 2; iter: 0; batch classifier loss: 3.355984; batch adversarial loss: 0.557206\n",
      "epoch 2; iter: 200; batch classifier loss: 3.846752; batch adversarial loss: 0.505897\n",
      "epoch 3; iter: 0; batch classifier loss: 1.529972; batch adversarial loss: 0.502797\n",
      "epoch 3; iter: 200; batch classifier loss: 1.579404; batch adversarial loss: 0.481144\n",
      "epoch 4; iter: 0; batch classifier loss: 1.442420; batch adversarial loss: 0.454690\n",
      "epoch 4; iter: 200; batch classifier loss: 1.169613; batch adversarial loss: 0.449636\n",
      "epoch 5; iter: 0; batch classifier loss: 0.936926; batch adversarial loss: 0.413736\n",
      "epoch 5; iter: 200; batch classifier loss: 1.067072; batch adversarial loss: 0.396935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.812368; batch adversarial loss: 0.441318\n",
      "epoch 6; iter: 200; batch classifier loss: 0.583048; batch adversarial loss: 0.422902\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517406; batch adversarial loss: 0.397319\n",
      "epoch 7; iter: 200; batch classifier loss: 0.372951; batch adversarial loss: 0.476320\n",
      "epoch 8; iter: 0; batch classifier loss: 0.289994; batch adversarial loss: 0.380286\n",
      "epoch 8; iter: 200; batch classifier loss: 0.354465; batch adversarial loss: 0.427881\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384332; batch adversarial loss: 0.402371\n",
      "epoch 9; iter: 200; batch classifier loss: 0.353508; batch adversarial loss: 0.504630\n",
      "epoch 10; iter: 0; batch classifier loss: 0.364094; batch adversarial loss: 0.473630\n",
      "epoch 10; iter: 200; batch classifier loss: 0.357653; batch adversarial loss: 0.561267\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348845; batch adversarial loss: 0.378844\n",
      "epoch 11; iter: 200; batch classifier loss: 0.428908; batch adversarial loss: 0.451790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356818; batch adversarial loss: 0.381695\n",
      "epoch 12; iter: 200; batch classifier loss: 0.490823; batch adversarial loss: 0.538976\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389311; batch adversarial loss: 0.359489\n",
      "epoch 13; iter: 200; batch classifier loss: 0.414825; batch adversarial loss: 0.351777\n",
      "epoch 14; iter: 0; batch classifier loss: 0.428228; batch adversarial loss: 0.403292\n",
      "epoch 14; iter: 200; batch classifier loss: 0.320398; batch adversarial loss: 0.386169\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364721; batch adversarial loss: 0.396125\n",
      "epoch 15; iter: 200; batch classifier loss: 0.515963; batch adversarial loss: 0.404527\n",
      "epoch 16; iter: 0; batch classifier loss: 0.246202; batch adversarial loss: 0.332618\n",
      "epoch 16; iter: 200; batch classifier loss: 0.395349; batch adversarial loss: 0.480028\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349175; batch adversarial loss: 0.443943\n",
      "epoch 17; iter: 200; batch classifier loss: 0.354852; batch adversarial loss: 0.389728\n",
      "epoch 18; iter: 0; batch classifier loss: 0.405337; batch adversarial loss: 0.364496\n",
      "epoch 18; iter: 200; batch classifier loss: 0.368869; batch adversarial loss: 0.403580\n",
      "epoch 19; iter: 0; batch classifier loss: 0.366296; batch adversarial loss: 0.469969\n",
      "epoch 19; iter: 200; batch classifier loss: 0.333029; batch adversarial loss: 0.439901\n",
      "epoch 0; iter: 0; batch classifier loss: 12.422105; batch adversarial loss: 0.590385\n",
      "epoch 0; iter: 200; batch classifier loss: 5.990234; batch adversarial loss: 0.578225\n",
      "epoch 1; iter: 0; batch classifier loss: 15.968173; batch adversarial loss: 0.585259\n",
      "epoch 1; iter: 200; batch classifier loss: 2.892984; batch adversarial loss: 0.542394\n",
      "epoch 2; iter: 0; batch classifier loss: 6.536774; batch adversarial loss: 0.504614\n",
      "epoch 2; iter: 200; batch classifier loss: 2.524394; batch adversarial loss: 0.499267\n",
      "epoch 3; iter: 0; batch classifier loss: 1.917277; batch adversarial loss: 0.448113\n",
      "epoch 3; iter: 200; batch classifier loss: 0.884413; batch adversarial loss: 0.488918\n",
      "epoch 4; iter: 0; batch classifier loss: 1.966141; batch adversarial loss: 0.500355\n",
      "epoch 4; iter: 200; batch classifier loss: 12.533970; batch adversarial loss: 0.455498\n",
      "epoch 5; iter: 0; batch classifier loss: 1.356903; batch adversarial loss: 0.413471\n",
      "epoch 5; iter: 200; batch classifier loss: 0.304914; batch adversarial loss: 0.459911\n",
      "epoch 6; iter: 0; batch classifier loss: 0.746117; batch adversarial loss: 0.483982\n",
      "epoch 6; iter: 200; batch classifier loss: 0.643434; batch adversarial loss: 0.430343\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528869; batch adversarial loss: 0.397797\n",
      "epoch 7; iter: 200; batch classifier loss: 0.744434; batch adversarial loss: 0.478739\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573059; batch adversarial loss: 0.327577\n",
      "epoch 8; iter: 200; batch classifier loss: 0.425621; batch adversarial loss: 0.425412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.609754; batch adversarial loss: 0.455958\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426591; batch adversarial loss: 0.390810\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443360; batch adversarial loss: 0.402168\n",
      "epoch 10; iter: 200; batch classifier loss: 0.381827; batch adversarial loss: 0.467092\n",
      "epoch 11; iter: 0; batch classifier loss: 0.422820; batch adversarial loss: 0.497886\n",
      "epoch 11; iter: 200; batch classifier loss: 0.377183; batch adversarial loss: 0.377296\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285215; batch adversarial loss: 0.405368\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420929; batch adversarial loss: 0.489606\n",
      "epoch 13; iter: 0; batch classifier loss: 0.424713; batch adversarial loss: 0.301294\n",
      "epoch 13; iter: 200; batch classifier loss: 0.469014; batch adversarial loss: 0.425142\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369042; batch adversarial loss: 0.338073\n",
      "epoch 14; iter: 200; batch classifier loss: 0.408390; batch adversarial loss: 0.509070\n",
      "epoch 15; iter: 0; batch classifier loss: 0.317219; batch adversarial loss: 0.351905\n",
      "epoch 15; iter: 200; batch classifier loss: 0.354320; batch adversarial loss: 0.366635\n",
      "epoch 16; iter: 0; batch classifier loss: 0.279071; batch adversarial loss: 0.406211\n",
      "epoch 16; iter: 200; batch classifier loss: 0.307735; batch adversarial loss: 0.388563\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332092; batch adversarial loss: 0.443574\n",
      "epoch 17; iter: 200; batch classifier loss: 0.376572; batch adversarial loss: 0.401945\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333852; batch adversarial loss: 0.330454\n",
      "epoch 18; iter: 200; batch classifier loss: 0.362489; batch adversarial loss: 0.446300\n",
      "epoch 19; iter: 0; batch classifier loss: 0.383522; batch adversarial loss: 0.459079\n",
      "epoch 19; iter: 200; batch classifier loss: 0.420458; batch adversarial loss: 0.383508\n",
      "epoch 0; iter: 0; batch classifier loss: 23.464558; batch adversarial loss: 0.587931\n",
      "epoch 0; iter: 200; batch classifier loss: 4.197035; batch adversarial loss: 0.531038\n",
      "epoch 1; iter: 0; batch classifier loss: 3.677736; batch adversarial loss: 0.554672\n",
      "epoch 1; iter: 200; batch classifier loss: 5.811424; batch adversarial loss: 0.551943\n",
      "epoch 2; iter: 0; batch classifier loss: 2.102425; batch adversarial loss: 0.518279\n",
      "epoch 2; iter: 200; batch classifier loss: 5.905927; batch adversarial loss: 0.496813\n",
      "epoch 3; iter: 0; batch classifier loss: 2.626118; batch adversarial loss: 0.451477\n",
      "epoch 3; iter: 200; batch classifier loss: 2.106250; batch adversarial loss: 0.473740\n",
      "epoch 4; iter: 0; batch classifier loss: 0.977547; batch adversarial loss: 0.453074\n",
      "epoch 4; iter: 200; batch classifier loss: 0.983250; batch adversarial loss: 0.385522\n",
      "epoch 5; iter: 0; batch classifier loss: 0.452421; batch adversarial loss: 0.411920\n",
      "epoch 5; iter: 200; batch classifier loss: 1.662342; batch adversarial loss: 0.462956\n",
      "epoch 6; iter: 0; batch classifier loss: 0.839533; batch adversarial loss: 0.517820\n",
      "epoch 6; iter: 200; batch classifier loss: 0.356152; batch adversarial loss: 0.454673\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548091; batch adversarial loss: 0.467055\n",
      "epoch 7; iter: 200; batch classifier loss: 0.312990; batch adversarial loss: 0.492891\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577424; batch adversarial loss: 0.343971\n",
      "epoch 8; iter: 200; batch classifier loss: 0.369176; batch adversarial loss: 0.449347\n",
      "epoch 9; iter: 0; batch classifier loss: 0.477515; batch adversarial loss: 0.415339\n",
      "epoch 9; iter: 200; batch classifier loss: 0.374739; batch adversarial loss: 0.402788\n",
      "epoch 10; iter: 0; batch classifier loss: 0.329470; batch adversarial loss: 0.424375\n",
      "epoch 10; iter: 200; batch classifier loss: 0.376705; batch adversarial loss: 0.361573\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392585; batch adversarial loss: 0.392430\n",
      "epoch 11; iter: 200; batch classifier loss: 0.313567; batch adversarial loss: 0.383549\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405696; batch adversarial loss: 0.372365\n",
      "epoch 12; iter: 200; batch classifier loss: 0.459789; batch adversarial loss: 0.353631\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276965; batch adversarial loss: 0.553106\n",
      "epoch 13; iter: 200; batch classifier loss: 0.643740; batch adversarial loss: 0.471011\n",
      "epoch 14; iter: 0; batch classifier loss: 0.379451; batch adversarial loss: 0.423608\n",
      "epoch 14; iter: 200; batch classifier loss: 0.358759; batch adversarial loss: 0.340563\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361555; batch adversarial loss: 0.431914\n",
      "epoch 15; iter: 200; batch classifier loss: 0.723701; batch adversarial loss: 0.444751\n",
      "epoch 16; iter: 0; batch classifier loss: 0.411685; batch adversarial loss: 0.428200\n",
      "epoch 16; iter: 200; batch classifier loss: 0.326021; batch adversarial loss: 0.396214\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409355; batch adversarial loss: 0.333670\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339180; batch adversarial loss: 0.478371\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396387; batch adversarial loss: 0.397162\n",
      "epoch 18; iter: 200; batch classifier loss: 0.384195; batch adversarial loss: 0.371974\n",
      "epoch 19; iter: 0; batch classifier loss: 0.402759; batch adversarial loss: 0.444004\n",
      "epoch 19; iter: 200; batch classifier loss: 0.411525; batch adversarial loss: 0.404755\n",
      "epoch 0; iter: 0; batch classifier loss: 9.496947; batch adversarial loss: 0.537558\n",
      "epoch 0; iter: 200; batch classifier loss: 8.526502; batch adversarial loss: 0.578034\n",
      "epoch 1; iter: 0; batch classifier loss: 6.271809; batch adversarial loss: 0.523929\n",
      "epoch 1; iter: 200; batch classifier loss: 3.652846; batch adversarial loss: 0.488790\n",
      "epoch 2; iter: 0; batch classifier loss: 2.176412; batch adversarial loss: 0.462648\n",
      "epoch 2; iter: 200; batch classifier loss: 0.715099; batch adversarial loss: 0.511545\n",
      "epoch 3; iter: 0; batch classifier loss: 2.749386; batch adversarial loss: 0.493996\n",
      "epoch 3; iter: 200; batch classifier loss: 1.626292; batch adversarial loss: 0.427340\n",
      "epoch 4; iter: 0; batch classifier loss: 0.834839; batch adversarial loss: 0.443931\n",
      "epoch 4; iter: 200; batch classifier loss: 0.863145; batch adversarial loss: 0.447478\n",
      "epoch 5; iter: 0; batch classifier loss: 0.316330; batch adversarial loss: 0.400369\n",
      "epoch 5; iter: 200; batch classifier loss: 0.622937; batch adversarial loss: 0.394237\n",
      "epoch 6; iter: 0; batch classifier loss: 0.636981; batch adversarial loss: 0.381794\n",
      "epoch 6; iter: 200; batch classifier loss: 0.474937; batch adversarial loss: 0.363829\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405191; batch adversarial loss: 0.433364\n",
      "epoch 7; iter: 200; batch classifier loss: 0.739104; batch adversarial loss: 0.439482\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316168; batch adversarial loss: 0.429243\n",
      "epoch 8; iter: 200; batch classifier loss: 0.395355; batch adversarial loss: 0.442127\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505564; batch adversarial loss: 0.502481\n",
      "epoch 9; iter: 200; batch classifier loss: 0.514284; batch adversarial loss: 0.406661\n",
      "epoch 10; iter: 0; batch classifier loss: 0.344009; batch adversarial loss: 0.336985\n",
      "epoch 10; iter: 200; batch classifier loss: 0.619099; batch adversarial loss: 0.420477\n",
      "epoch 11; iter: 0; batch classifier loss: 0.303179; batch adversarial loss: 0.453293\n",
      "epoch 11; iter: 200; batch classifier loss: 0.456016; batch adversarial loss: 0.518302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.414775; batch adversarial loss: 0.370765\n",
      "epoch 12; iter: 200; batch classifier loss: 0.553966; batch adversarial loss: 0.444000\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361387; batch adversarial loss: 0.370642\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404276; batch adversarial loss: 0.429954\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387494; batch adversarial loss: 0.469238\n",
      "epoch 14; iter: 200; batch classifier loss: 0.251512; batch adversarial loss: 0.364806\n",
      "epoch 15; iter: 0; batch classifier loss: 0.325003; batch adversarial loss: 0.432800\n",
      "epoch 15; iter: 200; batch classifier loss: 0.298283; batch adversarial loss: 0.428717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366909; batch adversarial loss: 0.387910\n",
      "epoch 16; iter: 200; batch classifier loss: 0.416378; batch adversarial loss: 0.424846\n",
      "epoch 17; iter: 0; batch classifier loss: 0.359036; batch adversarial loss: 0.306658\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339543; batch adversarial loss: 0.350520\n",
      "epoch 18; iter: 0; batch classifier loss: 0.285750; batch adversarial loss: 0.497975\n",
      "epoch 18; iter: 200; batch classifier loss: 0.335400; batch adversarial loss: 0.414938\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344692; batch adversarial loss: 0.337093\n",
      "epoch 19; iter: 200; batch classifier loss: 0.324196; batch adversarial loss: 0.314282\n",
      "epoch 0; iter: 0; batch classifier loss: 111.023346; batch adversarial loss: 0.602925\n",
      "epoch 0; iter: 200; batch classifier loss: 5.389387; batch adversarial loss: 0.583775\n",
      "epoch 1; iter: 0; batch classifier loss: 17.117310; batch adversarial loss: 0.565655\n",
      "epoch 1; iter: 200; batch classifier loss: 5.704652; batch adversarial loss: 0.504351\n",
      "epoch 2; iter: 0; batch classifier loss: 14.118363; batch adversarial loss: 0.530693\n",
      "epoch 2; iter: 200; batch classifier loss: 3.134722; batch adversarial loss: 0.477335\n",
      "epoch 3; iter: 0; batch classifier loss: 2.185276; batch adversarial loss: 0.525555\n",
      "epoch 3; iter: 200; batch classifier loss: 1.287597; batch adversarial loss: 0.502836\n",
      "epoch 4; iter: 0; batch classifier loss: 1.397603; batch adversarial loss: 0.394820\n",
      "epoch 4; iter: 200; batch classifier loss: 1.425584; batch adversarial loss: 0.495858\n",
      "epoch 5; iter: 0; batch classifier loss: 0.659274; batch adversarial loss: 0.437490\n",
      "epoch 5; iter: 200; batch classifier loss: 1.003780; batch adversarial loss: 0.432891\n",
      "epoch 6; iter: 0; batch classifier loss: 0.650106; batch adversarial loss: 0.472764\n",
      "epoch 6; iter: 200; batch classifier loss: 0.711630; batch adversarial loss: 0.485302\n",
      "epoch 7; iter: 0; batch classifier loss: 0.753525; batch adversarial loss: 0.347748\n",
      "epoch 7; iter: 200; batch classifier loss: 0.397149; batch adversarial loss: 0.390083\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485007; batch adversarial loss: 0.415736\n",
      "epoch 8; iter: 200; batch classifier loss: 0.446581; batch adversarial loss: 0.453738\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627745; batch adversarial loss: 0.433750\n",
      "epoch 9; iter: 200; batch classifier loss: 0.435477; batch adversarial loss: 0.400275\n",
      "epoch 10; iter: 0; batch classifier loss: 1.337152; batch adversarial loss: 0.419988\n",
      "epoch 10; iter: 200; batch classifier loss: 0.411613; batch adversarial loss: 0.380813\n",
      "epoch 11; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.482095\n",
      "epoch 11; iter: 200; batch classifier loss: 0.389039; batch adversarial loss: 0.427631\n",
      "epoch 12; iter: 0; batch classifier loss: 0.363416; batch adversarial loss: 0.341812\n",
      "epoch 12; iter: 200; batch classifier loss: 0.453894; batch adversarial loss: 0.407103\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483338; batch adversarial loss: 0.498538\n",
      "epoch 13; iter: 200; batch classifier loss: 0.392821; batch adversarial loss: 0.431315\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335373; batch adversarial loss: 0.405680\n",
      "epoch 14; iter: 200; batch classifier loss: 0.333116; batch adversarial loss: 0.398875\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336931; batch adversarial loss: 0.413025\n",
      "epoch 15; iter: 200; batch classifier loss: 0.303031; batch adversarial loss: 0.445032\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341721; batch adversarial loss: 0.404532\n",
      "epoch 16; iter: 200; batch classifier loss: 0.347908; batch adversarial loss: 0.325645\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409120; batch adversarial loss: 0.407267\n",
      "epoch 17; iter: 200; batch classifier loss: 0.406651; batch adversarial loss: 0.393874\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306976; batch adversarial loss: 0.475699\n",
      "epoch 18; iter: 200; batch classifier loss: 0.593599; batch adversarial loss: 0.410242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340741; batch adversarial loss: 0.379108\n",
      "epoch 19; iter: 200; batch classifier loss: 0.364234; batch adversarial loss: 0.418960\n",
      "epoch 0; iter: 0; batch classifier loss: 23.003441; batch adversarial loss: 0.951105\n",
      "epoch 0; iter: 200; batch classifier loss: 10.107737; batch adversarial loss: 0.783463\n",
      "epoch 1; iter: 0; batch classifier loss: 12.704088; batch adversarial loss: 0.754397\n",
      "epoch 1; iter: 200; batch classifier loss: 3.764652; batch adversarial loss: 0.567111\n",
      "epoch 2; iter: 0; batch classifier loss: 0.801065; batch adversarial loss: 0.657713\n",
      "epoch 2; iter: 200; batch classifier loss: 0.779034; batch adversarial loss: 0.537366\n",
      "epoch 3; iter: 0; batch classifier loss: 1.480013; batch adversarial loss: 0.525097\n",
      "epoch 3; iter: 200; batch classifier loss: 2.858599; batch adversarial loss: 0.484710\n",
      "epoch 4; iter: 0; batch classifier loss: 1.894957; batch adversarial loss: 0.443774\n",
      "epoch 4; iter: 200; batch classifier loss: 1.022135; batch adversarial loss: 0.437472\n",
      "epoch 5; iter: 0; batch classifier loss: 0.583211; batch adversarial loss: 0.503494\n",
      "epoch 5; iter: 200; batch classifier loss: 0.459915; batch adversarial loss: 0.473963\n",
      "epoch 6; iter: 0; batch classifier loss: 0.425167; batch adversarial loss: 0.451856\n",
      "epoch 6; iter: 200; batch classifier loss: 0.633808; batch adversarial loss: 0.490765\n",
      "epoch 7; iter: 0; batch classifier loss: 0.643699; batch adversarial loss: 0.439574\n",
      "epoch 7; iter: 200; batch classifier loss: 0.444222; batch adversarial loss: 0.390415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.407700; batch adversarial loss: 0.401031\n",
      "epoch 8; iter: 200; batch classifier loss: 0.693377; batch adversarial loss: 0.351576\n",
      "epoch 9; iter: 0; batch classifier loss: 0.859961; batch adversarial loss: 0.479633\n",
      "epoch 9; iter: 200; batch classifier loss: 0.439624; batch adversarial loss: 0.387033\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518187; batch adversarial loss: 0.457711\n",
      "epoch 10; iter: 200; batch classifier loss: 0.524561; batch adversarial loss: 0.364516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.410821; batch adversarial loss: 0.452520\n",
      "epoch 11; iter: 200; batch classifier loss: 0.493851; batch adversarial loss: 0.386888\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343086; batch adversarial loss: 0.446652\n",
      "epoch 12; iter: 200; batch classifier loss: 0.635325; batch adversarial loss: 0.437464\n",
      "epoch 13; iter: 0; batch classifier loss: 0.454755; batch adversarial loss: 0.350602\n",
      "epoch 13; iter: 200; batch classifier loss: 0.418725; batch adversarial loss: 0.338403\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442712; batch adversarial loss: 0.456126\n",
      "epoch 14; iter: 200; batch classifier loss: 0.595200; batch adversarial loss: 0.417736\n",
      "epoch 15; iter: 0; batch classifier loss: 0.421805; batch adversarial loss: 0.464295\n",
      "epoch 15; iter: 200; batch classifier loss: 0.433626; batch adversarial loss: 0.418613\n",
      "epoch 16; iter: 0; batch classifier loss: 0.315547; batch adversarial loss: 0.515557\n",
      "epoch 16; iter: 200; batch classifier loss: 0.387724; batch adversarial loss: 0.338712\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453303; batch adversarial loss: 0.307376\n",
      "epoch 17; iter: 200; batch classifier loss: 0.385444; batch adversarial loss: 0.440642\n",
      "epoch 18; iter: 0; batch classifier loss: 0.393678; batch adversarial loss: 0.356650\n",
      "epoch 18; iter: 200; batch classifier loss: 0.303589; batch adversarial loss: 0.445531\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385222; batch adversarial loss: 0.357392\n",
      "epoch 19; iter: 200; batch classifier loss: 0.278720; batch adversarial loss: 0.477413\n",
      "epoch 0; iter: 0; batch classifier loss: 16.671806; batch adversarial loss: 0.950755\n",
      "epoch 0; iter: 200; batch classifier loss: 11.203067; batch adversarial loss: 0.822307\n",
      "epoch 1; iter: 0; batch classifier loss: 9.848139; batch adversarial loss: 0.620327\n",
      "epoch 1; iter: 200; batch classifier loss: 1.529485; batch adversarial loss: 0.575527\n",
      "epoch 2; iter: 0; batch classifier loss: 5.461531; batch adversarial loss: 0.539902\n",
      "epoch 2; iter: 200; batch classifier loss: 3.604828; batch adversarial loss: 0.540922\n",
      "epoch 3; iter: 0; batch classifier loss: 3.891577; batch adversarial loss: 0.489711\n",
      "epoch 3; iter: 200; batch classifier loss: 0.644338; batch adversarial loss: 0.468662\n",
      "epoch 4; iter: 0; batch classifier loss: 0.524832; batch adversarial loss: 0.492534\n",
      "epoch 4; iter: 200; batch classifier loss: 1.663720; batch adversarial loss: 0.458433\n",
      "epoch 5; iter: 0; batch classifier loss: 1.613503; batch adversarial loss: 0.485472\n",
      "epoch 5; iter: 200; batch classifier loss: 0.519706; batch adversarial loss: 0.456137\n",
      "epoch 6; iter: 0; batch classifier loss: 1.033265; batch adversarial loss: 0.450616\n",
      "epoch 6; iter: 200; batch classifier loss: 0.536810; batch adversarial loss: 0.484932\n",
      "epoch 7; iter: 0; batch classifier loss: 0.941236; batch adversarial loss: 0.465283\n",
      "epoch 7; iter: 200; batch classifier loss: 0.601167; batch adversarial loss: 0.388250\n",
      "epoch 8; iter: 0; batch classifier loss: 0.454939; batch adversarial loss: 0.409281\n",
      "epoch 8; iter: 200; batch classifier loss: 0.412744; batch adversarial loss: 0.397687\n",
      "epoch 9; iter: 0; batch classifier loss: 1.592262; batch adversarial loss: 0.492112\n",
      "epoch 9; iter: 200; batch classifier loss: 0.352717; batch adversarial loss: 0.443264\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407587; batch adversarial loss: 0.436577\n",
      "epoch 10; iter: 200; batch classifier loss: 0.283333; batch adversarial loss: 0.355720\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360919; batch adversarial loss: 0.395013\n",
      "epoch 11; iter: 200; batch classifier loss: 0.404116; batch adversarial loss: 0.350285\n",
      "epoch 12; iter: 0; batch classifier loss: 0.423204; batch adversarial loss: 0.284700\n",
      "epoch 12; iter: 200; batch classifier loss: 0.434518; batch adversarial loss: 0.443831\n",
      "epoch 13; iter: 0; batch classifier loss: 0.415612; batch adversarial loss: 0.461658\n",
      "epoch 13; iter: 200; batch classifier loss: 0.310770; batch adversarial loss: 0.387824\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350612; batch adversarial loss: 0.430900\n",
      "epoch 14; iter: 200; batch classifier loss: 0.350776; batch adversarial loss: 0.408313\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381106; batch adversarial loss: 0.448538\n",
      "epoch 15; iter: 200; batch classifier loss: 0.321112; batch adversarial loss: 0.414371\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380024; batch adversarial loss: 0.461191\n",
      "epoch 16; iter: 200; batch classifier loss: 0.356445; batch adversarial loss: 0.267389\n",
      "epoch 17; iter: 0; batch classifier loss: 0.549763; batch adversarial loss: 0.343263\n",
      "epoch 17; iter: 200; batch classifier loss: 0.376590; batch adversarial loss: 0.372991\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414192; batch adversarial loss: 0.501522\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399804; batch adversarial loss: 0.422172\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334242; batch adversarial loss: 0.269014\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316998; batch adversarial loss: 0.393973\n",
      "epoch 0; iter: 0; batch classifier loss: 263.326630; batch adversarial loss: 0.761524\n",
      "epoch 0; iter: 200; batch classifier loss: 12.219410; batch adversarial loss: 0.644105\n",
      "epoch 1; iter: 0; batch classifier loss: 11.055016; batch adversarial loss: 0.606301\n",
      "epoch 1; iter: 200; batch classifier loss: 3.308802; batch adversarial loss: 0.586584\n",
      "epoch 2; iter: 0; batch classifier loss: 5.385059; batch adversarial loss: 0.574482\n",
      "epoch 2; iter: 200; batch classifier loss: 3.200520; batch adversarial loss: 0.533637\n",
      "epoch 3; iter: 0; batch classifier loss: 2.322793; batch adversarial loss: 0.480298\n",
      "epoch 3; iter: 200; batch classifier loss: 3.787323; batch adversarial loss: 0.488005\n",
      "epoch 4; iter: 0; batch classifier loss: 1.032968; batch adversarial loss: 0.410245\n",
      "epoch 4; iter: 200; batch classifier loss: 1.183768; batch adversarial loss: 0.443352\n",
      "epoch 5; iter: 0; batch classifier loss: 1.722809; batch adversarial loss: 0.384441\n",
      "epoch 5; iter: 200; batch classifier loss: 1.088238; batch adversarial loss: 0.463650\n",
      "epoch 6; iter: 0; batch classifier loss: 1.141710; batch adversarial loss: 0.392974\n",
      "epoch 6; iter: 200; batch classifier loss: 1.071334; batch adversarial loss: 0.540269\n",
      "epoch 7; iter: 0; batch classifier loss: 0.373337; batch adversarial loss: 0.372491\n",
      "epoch 7; iter: 200; batch classifier loss: 0.447633; batch adversarial loss: 0.432209\n",
      "epoch 8; iter: 0; batch classifier loss: 0.401107; batch adversarial loss: 0.350847\n",
      "epoch 8; iter: 200; batch classifier loss: 0.809555; batch adversarial loss: 0.419507\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449843; batch adversarial loss: 0.481772\n",
      "epoch 9; iter: 200; batch classifier loss: 0.475206; batch adversarial loss: 0.315229\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422391; batch adversarial loss: 0.382657\n",
      "epoch 10; iter: 200; batch classifier loss: 0.441574; batch adversarial loss: 0.344275\n",
      "epoch 11; iter: 0; batch classifier loss: 1.296222; batch adversarial loss: 0.350504\n",
      "epoch 11; iter: 200; batch classifier loss: 0.410008; batch adversarial loss: 0.405967\n",
      "epoch 12; iter: 0; batch classifier loss: 0.436550; batch adversarial loss: 0.362164\n",
      "epoch 12; iter: 200; batch classifier loss: 0.350476; batch adversarial loss: 0.432394\n",
      "epoch 13; iter: 0; batch classifier loss: 0.397525; batch adversarial loss: 0.419469\n",
      "epoch 13; iter: 200; batch classifier loss: 0.438772; batch adversarial loss: 0.516945\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349871; batch adversarial loss: 0.412193\n",
      "epoch 14; iter: 200; batch classifier loss: 0.313990; batch adversarial loss: 0.452141\n",
      "epoch 15; iter: 0; batch classifier loss: 0.389954; batch adversarial loss: 0.444884\n",
      "epoch 15; iter: 200; batch classifier loss: 0.317652; batch adversarial loss: 0.391820\n",
      "epoch 16; iter: 0; batch classifier loss: 0.264884; batch adversarial loss: 0.475781\n",
      "epoch 16; iter: 200; batch classifier loss: 0.349850; batch adversarial loss: 0.357494\n",
      "epoch 17; iter: 0; batch classifier loss: 0.308337; batch adversarial loss: 0.381269\n",
      "epoch 17; iter: 200; batch classifier loss: 0.371752; batch adversarial loss: 0.498815\n",
      "epoch 18; iter: 0; batch classifier loss: 0.383285; batch adversarial loss: 0.404054\n",
      "epoch 18; iter: 200; batch classifier loss: 0.380797; batch adversarial loss: 0.425679\n",
      "epoch 19; iter: 0; batch classifier loss: 0.402470; batch adversarial loss: 0.396224\n",
      "epoch 19; iter: 200; batch classifier loss: 0.310012; batch adversarial loss: 0.469259\n",
      "epoch 0; iter: 0; batch classifier loss: 27.857565; batch adversarial loss: 0.855076\n",
      "epoch 0; iter: 200; batch classifier loss: 39.419788; batch adversarial loss: 0.685685\n",
      "epoch 1; iter: 0; batch classifier loss: 4.698462; batch adversarial loss: 0.639192\n",
      "epoch 1; iter: 200; batch classifier loss: 4.234228; batch adversarial loss: 0.558861\n",
      "epoch 2; iter: 0; batch classifier loss: 2.863001; batch adversarial loss: 0.545765\n",
      "epoch 2; iter: 200; batch classifier loss: 2.981120; batch adversarial loss: 0.540876\n",
      "epoch 3; iter: 0; batch classifier loss: 1.065368; batch adversarial loss: 0.508281\n",
      "epoch 3; iter: 200; batch classifier loss: 1.368078; batch adversarial loss: 0.479589\n",
      "epoch 4; iter: 0; batch classifier loss: 0.993330; batch adversarial loss: 0.522594\n",
      "epoch 4; iter: 200; batch classifier loss: 2.004692; batch adversarial loss: 0.444272\n",
      "epoch 5; iter: 0; batch classifier loss: 0.741240; batch adversarial loss: 0.441548\n",
      "epoch 5; iter: 200; batch classifier loss: 1.414094; batch adversarial loss: 0.510328\n",
      "epoch 6; iter: 0; batch classifier loss: 0.655087; batch adversarial loss: 0.434801\n",
      "epoch 6; iter: 200; batch classifier loss: 1.334950; batch adversarial loss: 0.443119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.381176; batch adversarial loss: 0.361425\n",
      "epoch 7; iter: 200; batch classifier loss: 0.455545; batch adversarial loss: 0.420946\n",
      "epoch 8; iter: 0; batch classifier loss: 0.352993; batch adversarial loss: 0.390947\n",
      "epoch 8; iter: 200; batch classifier loss: 0.508251; batch adversarial loss: 0.443869\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478178; batch adversarial loss: 0.370876\n",
      "epoch 9; iter: 200; batch classifier loss: 0.497265; batch adversarial loss: 0.483134\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366495; batch adversarial loss: 0.466828\n",
      "epoch 10; iter: 200; batch classifier loss: 0.472736; batch adversarial loss: 0.453967\n",
      "epoch 11; iter: 0; batch classifier loss: 0.321410; batch adversarial loss: 0.480864\n",
      "epoch 11; iter: 200; batch classifier loss: 0.364785; batch adversarial loss: 0.459421\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417418; batch adversarial loss: 0.411879\n",
      "epoch 12; iter: 200; batch classifier loss: 0.362418; batch adversarial loss: 0.399736\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349774; batch adversarial loss: 0.376566\n",
      "epoch 13; iter: 200; batch classifier loss: 0.495990; batch adversarial loss: 0.405315\n",
      "epoch 14; iter: 0; batch classifier loss: 0.460264; batch adversarial loss: 0.480401\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378288; batch adversarial loss: 0.478766\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396398; batch adversarial loss: 0.494714\n",
      "epoch 15; iter: 200; batch classifier loss: 0.439774; batch adversarial loss: 0.311587\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506710; batch adversarial loss: 0.364538\n",
      "epoch 16; iter: 200; batch classifier loss: 0.284911; batch adversarial loss: 0.455116\n",
      "epoch 17; iter: 0; batch classifier loss: 0.401130; batch adversarial loss: 0.358779\n",
      "epoch 17; iter: 200; batch classifier loss: 0.386125; batch adversarial loss: 0.445881\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398502; batch adversarial loss: 0.423892\n",
      "epoch 18; iter: 200; batch classifier loss: 0.411985; batch adversarial loss: 0.468463\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356022; batch adversarial loss: 0.457652\n",
      "epoch 19; iter: 200; batch classifier loss: 0.364620; batch adversarial loss: 0.419411\n",
      "epoch 0; iter: 0; batch classifier loss: 18.710104; batch adversarial loss: 1.140070\n",
      "epoch 0; iter: 200; batch classifier loss: 11.820581; batch adversarial loss: 0.931112\n",
      "epoch 1; iter: 0; batch classifier loss: 5.113486; batch adversarial loss: 0.979378\n",
      "epoch 1; iter: 200; batch classifier loss: 5.573044; batch adversarial loss: 0.761258\n",
      "epoch 2; iter: 0; batch classifier loss: 2.070361; batch adversarial loss: 0.651287\n",
      "epoch 2; iter: 200; batch classifier loss: 2.340007; batch adversarial loss: 0.575432\n",
      "epoch 3; iter: 0; batch classifier loss: 1.665484; batch adversarial loss: 0.543824\n",
      "epoch 3; iter: 200; batch classifier loss: 0.606112; batch adversarial loss: 0.497797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590422; batch adversarial loss: 0.498345\n",
      "epoch 4; iter: 200; batch classifier loss: 1.309627; batch adversarial loss: 0.508362\n",
      "epoch 5; iter: 0; batch classifier loss: 0.398648; batch adversarial loss: 0.461223\n",
      "epoch 5; iter: 200; batch classifier loss: 0.815684; batch adversarial loss: 0.447641\n",
      "epoch 6; iter: 0; batch classifier loss: 0.769243; batch adversarial loss: 0.424039\n",
      "epoch 6; iter: 200; batch classifier loss: 0.496050; batch adversarial loss: 0.441430\n",
      "epoch 7; iter: 0; batch classifier loss: 0.409236; batch adversarial loss: 0.435876\n",
      "epoch 7; iter: 200; batch classifier loss: 0.749727; batch adversarial loss: 0.411319\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618347; batch adversarial loss: 0.515401\n",
      "epoch 8; iter: 200; batch classifier loss: 0.693327; batch adversarial loss: 0.474002\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518318; batch adversarial loss: 0.446582\n",
      "epoch 9; iter: 200; batch classifier loss: 0.350783; batch adversarial loss: 0.433398\n",
      "epoch 10; iter: 0; batch classifier loss: 0.351056; batch adversarial loss: 0.506008\n",
      "epoch 10; iter: 200; batch classifier loss: 0.334229; batch adversarial loss: 0.505620\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313327; batch adversarial loss: 0.458878\n",
      "epoch 11; iter: 200; batch classifier loss: 0.314876; batch adversarial loss: 0.394484\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372927; batch adversarial loss: 0.488875\n",
      "epoch 12; iter: 200; batch classifier loss: 0.439606; batch adversarial loss: 0.350246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.517659; batch adversarial loss: 0.312259\n",
      "epoch 13; iter: 200; batch classifier loss: 0.287545; batch adversarial loss: 0.335577\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432038; batch adversarial loss: 0.306592\n",
      "epoch 14; iter: 200; batch classifier loss: 0.395017; batch adversarial loss: 0.476289\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584225; batch adversarial loss: 0.358541\n",
      "epoch 15; iter: 200; batch classifier loss: 0.348956; batch adversarial loss: 0.482631\n",
      "epoch 16; iter: 0; batch classifier loss: 0.421911; batch adversarial loss: 0.353084\n",
      "epoch 16; iter: 200; batch classifier loss: 0.350502; batch adversarial loss: 0.390350\n",
      "epoch 17; iter: 0; batch classifier loss: 0.433281; batch adversarial loss: 0.474562\n",
      "epoch 17; iter: 200; batch classifier loss: 0.372506; batch adversarial loss: 0.399963\n",
      "epoch 18; iter: 0; batch classifier loss: 0.360252; batch adversarial loss: 0.360474\n",
      "epoch 18; iter: 200; batch classifier loss: 0.319675; batch adversarial loss: 0.420800\n",
      "epoch 19; iter: 0; batch classifier loss: 0.387030; batch adversarial loss: 0.364683\n",
      "epoch 19; iter: 200; batch classifier loss: 0.413379; batch adversarial loss: 0.459624\n",
      "epoch 0; iter: 0; batch classifier loss: 9.132381; batch adversarial loss: 0.642884\n",
      "epoch 0; iter: 200; batch classifier loss: 9.363560; batch adversarial loss: 0.575727\n",
      "epoch 1; iter: 0; batch classifier loss: 3.248934; batch adversarial loss: 0.579902\n",
      "epoch 1; iter: 200; batch classifier loss: 3.454825; batch adversarial loss: 0.504411\n",
      "epoch 2; iter: 0; batch classifier loss: 4.184997; batch adversarial loss: 0.527320\n",
      "epoch 2; iter: 200; batch classifier loss: 1.350770; batch adversarial loss: 0.543770\n",
      "epoch 3; iter: 0; batch classifier loss: 1.385486; batch adversarial loss: 0.436739\n",
      "epoch 3; iter: 200; batch classifier loss: 1.657891; batch adversarial loss: 0.456279\n",
      "epoch 4; iter: 0; batch classifier loss: 1.235032; batch adversarial loss: 0.469978\n",
      "epoch 4; iter: 200; batch classifier loss: 0.974344; batch adversarial loss: 0.421944\n",
      "epoch 5; iter: 0; batch classifier loss: 0.725991; batch adversarial loss: 0.476250\n",
      "epoch 5; iter: 200; batch classifier loss: 0.426527; batch adversarial loss: 0.530059\n",
      "epoch 6; iter: 0; batch classifier loss: 0.410710; batch adversarial loss: 0.412022\n",
      "epoch 6; iter: 200; batch classifier loss: 0.534240; batch adversarial loss: 0.395019\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537917; batch adversarial loss: 0.407558\n",
      "epoch 7; iter: 200; batch classifier loss: 0.367713; batch adversarial loss: 0.429243\n",
      "epoch 8; iter: 0; batch classifier loss: 1.217520; batch adversarial loss: 0.449208\n",
      "epoch 8; iter: 200; batch classifier loss: 0.383436; batch adversarial loss: 0.324339\n",
      "epoch 9; iter: 0; batch classifier loss: 0.485099; batch adversarial loss: 0.397961\n",
      "epoch 9; iter: 200; batch classifier loss: 0.343843; batch adversarial loss: 0.448742\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414361; batch adversarial loss: 0.429107\n",
      "epoch 10; iter: 200; batch classifier loss: 0.433607; batch adversarial loss: 0.505085\n",
      "epoch 11; iter: 0; batch classifier loss: 0.422699; batch adversarial loss: 0.387237\n",
      "epoch 11; iter: 200; batch classifier loss: 0.317515; batch adversarial loss: 0.463520\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402666; batch adversarial loss: 0.351265\n",
      "epoch 12; iter: 200; batch classifier loss: 0.413696; batch adversarial loss: 0.430431\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492458; batch adversarial loss: 0.453355\n",
      "epoch 13; iter: 200; batch classifier loss: 0.314778; batch adversarial loss: 0.393439\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356954; batch adversarial loss: 0.389896\n",
      "epoch 14; iter: 200; batch classifier loss: 0.384804; batch adversarial loss: 0.364329\n",
      "epoch 15; iter: 0; batch classifier loss: 0.392736; batch adversarial loss: 0.333418\n",
      "epoch 15; iter: 200; batch classifier loss: 0.374764; batch adversarial loss: 0.346034\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448323; batch adversarial loss: 0.344036\n",
      "epoch 16; iter: 200; batch classifier loss: 0.351743; batch adversarial loss: 0.438922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.605801; batch adversarial loss: 0.399497\n",
      "epoch 17; iter: 200; batch classifier loss: 0.265053; batch adversarial loss: 0.458663\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414670; batch adversarial loss: 0.475971\n",
      "epoch 18; iter: 200; batch classifier loss: 0.379524; batch adversarial loss: 0.446103\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315825; batch adversarial loss: 0.479188\n",
      "epoch 19; iter: 200; batch classifier loss: 0.398813; batch adversarial loss: 0.455228\n",
      "epoch 0; iter: 0; batch classifier loss: 17.007092; batch adversarial loss: 0.649026\n",
      "epoch 0; iter: 200; batch classifier loss: 20.660328; batch adversarial loss: 0.630148\n",
      "epoch 1; iter: 0; batch classifier loss: 10.265594; batch adversarial loss: 0.615797\n",
      "epoch 1; iter: 200; batch classifier loss: 2.110855; batch adversarial loss: 0.578217\n",
      "epoch 2; iter: 0; batch classifier loss: 5.348953; batch adversarial loss: 0.560885\n",
      "epoch 2; iter: 200; batch classifier loss: 5.602501; batch adversarial loss: 0.492324\n",
      "epoch 3; iter: 0; batch classifier loss: 3.205161; batch adversarial loss: 0.428810\n",
      "epoch 3; iter: 200; batch classifier loss: 1.708217; batch adversarial loss: 0.460390\n",
      "epoch 4; iter: 0; batch classifier loss: 2.068858; batch adversarial loss: 0.478628\n",
      "epoch 4; iter: 200; batch classifier loss: 2.108670; batch adversarial loss: 0.443141\n",
      "epoch 5; iter: 0; batch classifier loss: 0.809123; batch adversarial loss: 0.392601\n",
      "epoch 5; iter: 200; batch classifier loss: 0.532828; batch adversarial loss: 0.438977\n",
      "epoch 6; iter: 0; batch classifier loss: 0.474819; batch adversarial loss: 0.395952\n",
      "epoch 6; iter: 200; batch classifier loss: 0.481346; batch adversarial loss: 0.407720\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571815; batch adversarial loss: 0.353608\n",
      "epoch 7; iter: 200; batch classifier loss: 0.740545; batch adversarial loss: 0.476530\n",
      "epoch 8; iter: 0; batch classifier loss: 0.388354; batch adversarial loss: 0.304913\n",
      "epoch 8; iter: 200; batch classifier loss: 0.379722; batch adversarial loss: 0.377989\n",
      "epoch 9; iter: 0; batch classifier loss: 0.326682; batch adversarial loss: 0.415158\n",
      "epoch 9; iter: 200; batch classifier loss: 0.440160; batch adversarial loss: 0.417462\n",
      "epoch 10; iter: 0; batch classifier loss: 0.418087; batch adversarial loss: 0.359767\n",
      "epoch 10; iter: 200; batch classifier loss: 0.369031; batch adversarial loss: 0.511285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426610; batch adversarial loss: 0.401503\n",
      "epoch 11; iter: 200; batch classifier loss: 0.497087; batch adversarial loss: 0.497224\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410881; batch adversarial loss: 0.479960\n",
      "epoch 12; iter: 200; batch classifier loss: 0.393841; batch adversarial loss: 0.401805\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321666; batch adversarial loss: 0.421104\n",
      "epoch 13; iter: 200; batch classifier loss: 0.461780; batch adversarial loss: 0.358648\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335241; batch adversarial loss: 0.464084\n",
      "epoch 14; iter: 200; batch classifier loss: 0.424748; batch adversarial loss: 0.563661\n",
      "epoch 15; iter: 0; batch classifier loss: 0.505508; batch adversarial loss: 0.435194\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333420; batch adversarial loss: 0.446986\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366112; batch adversarial loss: 0.381884\n",
      "epoch 16; iter: 200; batch classifier loss: 0.370050; batch adversarial loss: 0.431798\n",
      "epoch 17; iter: 0; batch classifier loss: 0.308654; batch adversarial loss: 0.386228\n",
      "epoch 17; iter: 200; batch classifier loss: 0.398085; batch adversarial loss: 0.340313\n",
      "epoch 18; iter: 0; batch classifier loss: 0.315740; batch adversarial loss: 0.393165\n",
      "epoch 18; iter: 200; batch classifier loss: 0.448940; batch adversarial loss: 0.388794\n",
      "epoch 19; iter: 0; batch classifier loss: 0.413380; batch adversarial loss: 0.448335\n",
      "epoch 19; iter: 200; batch classifier loss: 0.305608; batch adversarial loss: 0.347510\n",
      "epoch 0; iter: 0; batch classifier loss: 9.608932; batch adversarial loss: 0.572275\n",
      "epoch 0; iter: 200; batch classifier loss: 2.188300; batch adversarial loss: 0.568832\n",
      "epoch 1; iter: 0; batch classifier loss: 0.783222; batch adversarial loss: 0.569501\n",
      "epoch 1; iter: 200; batch classifier loss: 5.976777; batch adversarial loss: 0.551606\n",
      "epoch 2; iter: 0; batch classifier loss: 5.074836; batch adversarial loss: 0.546708\n",
      "epoch 2; iter: 200; batch classifier loss: 3.613433; batch adversarial loss: 0.490738\n",
      "epoch 3; iter: 0; batch classifier loss: 2.075639; batch adversarial loss: 0.410842\n",
      "epoch 3; iter: 200; batch classifier loss: 2.046584; batch adversarial loss: 0.430970\n",
      "epoch 4; iter: 0; batch classifier loss: 0.664831; batch adversarial loss: 0.468876\n",
      "epoch 4; iter: 200; batch classifier loss: 1.123627; batch adversarial loss: 0.393983\n",
      "epoch 5; iter: 0; batch classifier loss: 0.981030; batch adversarial loss: 0.504588\n",
      "epoch 5; iter: 200; batch classifier loss: 1.362091; batch adversarial loss: 0.458509\n",
      "epoch 6; iter: 0; batch classifier loss: 0.803560; batch adversarial loss: 0.435243\n",
      "epoch 6; iter: 200; batch classifier loss: 1.430836; batch adversarial loss: 0.505555\n",
      "epoch 7; iter: 0; batch classifier loss: 0.846827; batch adversarial loss: 0.343440\n",
      "epoch 7; iter: 200; batch classifier loss: 0.796088; batch adversarial loss: 0.431671\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567301; batch adversarial loss: 0.407601\n",
      "epoch 8; iter: 200; batch classifier loss: 0.435188; batch adversarial loss: 0.427630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.394683; batch adversarial loss: 0.453237\n",
      "epoch 9; iter: 200; batch classifier loss: 0.463792; batch adversarial loss: 0.373071\n",
      "epoch 10; iter: 0; batch classifier loss: 0.451181; batch adversarial loss: 0.425176\n",
      "epoch 10; iter: 200; batch classifier loss: 0.370254; batch adversarial loss: 0.382504\n",
      "epoch 11; iter: 0; batch classifier loss: 0.411637; batch adversarial loss: 0.495481\n",
      "epoch 11; iter: 200; batch classifier loss: 0.457658; batch adversarial loss: 0.388485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360987; batch adversarial loss: 0.395933\n",
      "epoch 12; iter: 200; batch classifier loss: 0.360516; batch adversarial loss: 0.406742\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349384; batch adversarial loss: 0.473729\n",
      "epoch 13; iter: 200; batch classifier loss: 0.338237; batch adversarial loss: 0.319089\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390314; batch adversarial loss: 0.387386\n",
      "epoch 14; iter: 200; batch classifier loss: 0.359070; batch adversarial loss: 0.466591\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302771; batch adversarial loss: 0.501601\n",
      "epoch 15; iter: 200; batch classifier loss: 0.306763; batch adversarial loss: 0.459660\n",
      "epoch 16; iter: 0; batch classifier loss: 0.368137; batch adversarial loss: 0.349954\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399424; batch adversarial loss: 0.332985\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281991; batch adversarial loss: 0.373611\n",
      "epoch 17; iter: 200; batch classifier loss: 0.293106; batch adversarial loss: 0.526132\n",
      "epoch 18; iter: 0; batch classifier loss: 0.344042; batch adversarial loss: 0.404150\n",
      "epoch 18; iter: 200; batch classifier loss: 0.404131; batch adversarial loss: 0.410002\n",
      "epoch 19; iter: 0; batch classifier loss: 0.357761; batch adversarial loss: 0.359900\n",
      "epoch 19; iter: 200; batch classifier loss: 0.284983; batch adversarial loss: 0.342221\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 329.532654; batch adversarial loss: 0.908555\n",
      "epoch 0; iter: 200; batch classifier loss: 5.515047; batch adversarial loss: 0.749690\n",
      "epoch 1; iter: 0; batch classifier loss: 5.675976; batch adversarial loss: 0.674904\n",
      "epoch 1; iter: 200; batch classifier loss: 8.655115; batch adversarial loss: 0.599256\n",
      "epoch 2; iter: 0; batch classifier loss: 2.281492; batch adversarial loss: 0.608355\n",
      "epoch 2; iter: 200; batch classifier loss: 8.819752; batch adversarial loss: 0.530958\n",
      "epoch 3; iter: 0; batch classifier loss: 3.376823; batch adversarial loss: 0.483840\n",
      "epoch 3; iter: 200; batch classifier loss: 2.541023; batch adversarial loss: 0.554546\n",
      "epoch 4; iter: 0; batch classifier loss: 3.869786; batch adversarial loss: 0.508931\n",
      "epoch 4; iter: 200; batch classifier loss: 1.805244; batch adversarial loss: 0.398595\n",
      "epoch 5; iter: 0; batch classifier loss: 1.748465; batch adversarial loss: 0.473836\n",
      "epoch 5; iter: 200; batch classifier loss: 5.002473; batch adversarial loss: 0.377640\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538394; batch adversarial loss: 0.406725\n",
      "epoch 6; iter: 200; batch classifier loss: 1.220253; batch adversarial loss: 0.400338\n",
      "epoch 7; iter: 0; batch classifier loss: 1.027903; batch adversarial loss: 0.447532\n",
      "epoch 7; iter: 200; batch classifier loss: 0.418714; batch adversarial loss: 0.413809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453400; batch adversarial loss: 0.431319\n",
      "epoch 8; iter: 200; batch classifier loss: 0.433901; batch adversarial loss: 0.399970\n",
      "epoch 9; iter: 0; batch classifier loss: 1.953362; batch adversarial loss: 0.389915\n",
      "epoch 9; iter: 200; batch classifier loss: 0.270852; batch adversarial loss: 0.430193\n",
      "epoch 10; iter: 0; batch classifier loss: 0.465805; batch adversarial loss: 0.272561\n",
      "epoch 10; iter: 200; batch classifier loss: 0.443871; batch adversarial loss: 0.495223\n",
      "epoch 11; iter: 0; batch classifier loss: 0.376580; batch adversarial loss: 0.511652\n",
      "epoch 11; iter: 200; batch classifier loss: 0.367253; batch adversarial loss: 0.346130\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427814; batch adversarial loss: 0.417941\n",
      "epoch 12; iter: 200; batch classifier loss: 0.508981; batch adversarial loss: 0.376859\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400359; batch adversarial loss: 0.386727\n",
      "epoch 13; iter: 200; batch classifier loss: 0.412668; batch adversarial loss: 0.349901\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473792; batch adversarial loss: 0.335624\n",
      "epoch 14; iter: 200; batch classifier loss: 0.412779; batch adversarial loss: 0.331936\n",
      "epoch 15; iter: 0; batch classifier loss: 0.663000; batch adversarial loss: 0.458124\n",
      "epoch 15; iter: 200; batch classifier loss: 0.357786; batch adversarial loss: 0.507146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298927; batch adversarial loss: 0.434907\n",
      "epoch 16; iter: 200; batch classifier loss: 0.404889; batch adversarial loss: 0.467722\n",
      "epoch 17; iter: 0; batch classifier loss: 0.326041; batch adversarial loss: 0.426194\n",
      "epoch 17; iter: 200; batch classifier loss: 0.386218; batch adversarial loss: 0.516391\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446429; batch adversarial loss: 0.349522\n",
      "epoch 18; iter: 200; batch classifier loss: 0.628608; batch adversarial loss: 0.338791\n",
      "epoch 19; iter: 0; batch classifier loss: 0.347528; batch adversarial loss: 0.342284\n",
      "epoch 19; iter: 200; batch classifier loss: 0.327667; batch adversarial loss: 0.402479\n",
      "epoch 20; iter: 0; batch classifier loss: 0.465947; batch adversarial loss: 0.375622\n",
      "epoch 20; iter: 200; batch classifier loss: 0.291660; batch adversarial loss: 0.475840\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495708; batch adversarial loss: 0.407182\n",
      "epoch 21; iter: 200; batch classifier loss: 0.408163; batch adversarial loss: 0.402292\n",
      "epoch 22; iter: 0; batch classifier loss: 0.380041; batch adversarial loss: 0.443430\n",
      "epoch 22; iter: 200; batch classifier loss: 0.407835; batch adversarial loss: 0.410210\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400337; batch adversarial loss: 0.389273\n",
      "epoch 23; iter: 200; batch classifier loss: 0.290071; batch adversarial loss: 0.415950\n",
      "epoch 24; iter: 0; batch classifier loss: 0.259639; batch adversarial loss: 0.464698\n",
      "epoch 24; iter: 200; batch classifier loss: 0.297185; batch adversarial loss: 0.417285\n",
      "epoch 25; iter: 0; batch classifier loss: 0.329134; batch adversarial loss: 0.476240\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360512; batch adversarial loss: 0.486104\n",
      "epoch 26; iter: 0; batch classifier loss: 0.342092; batch adversarial loss: 0.529970\n",
      "epoch 26; iter: 200; batch classifier loss: 0.348452; batch adversarial loss: 0.492647\n",
      "epoch 27; iter: 0; batch classifier loss: 0.392525; batch adversarial loss: 0.335341\n",
      "epoch 27; iter: 200; batch classifier loss: 0.326700; batch adversarial loss: 0.512861\n",
      "epoch 28; iter: 0; batch classifier loss: 0.397795; batch adversarial loss: 0.373671\n",
      "epoch 28; iter: 200; batch classifier loss: 0.363338; batch adversarial loss: 0.363645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.350061; batch adversarial loss: 0.442051\n",
      "epoch 29; iter: 200; batch classifier loss: 0.389881; batch adversarial loss: 0.445888\n",
      "epoch 30; iter: 0; batch classifier loss: 0.319963; batch adversarial loss: 0.479704\n",
      "epoch 30; iter: 200; batch classifier loss: 0.316924; batch adversarial loss: 0.391060\n",
      "epoch 31; iter: 0; batch classifier loss: 0.353802; batch adversarial loss: 0.456652\n",
      "epoch 31; iter: 200; batch classifier loss: 0.330550; batch adversarial loss: 0.331094\n",
      "epoch 32; iter: 0; batch classifier loss: 0.384808; batch adversarial loss: 0.419079\n",
      "epoch 32; iter: 200; batch classifier loss: 0.441161; batch adversarial loss: 0.485947\n",
      "epoch 33; iter: 0; batch classifier loss: 0.335280; batch adversarial loss: 0.364913\n",
      "epoch 33; iter: 200; batch classifier loss: 0.337675; batch adversarial loss: 0.404265\n",
      "epoch 34; iter: 0; batch classifier loss: 0.339855; batch adversarial loss: 0.383776\n",
      "epoch 34; iter: 200; batch classifier loss: 0.355211; batch adversarial loss: 0.340843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.285446; batch adversarial loss: 0.543950\n",
      "epoch 35; iter: 200; batch classifier loss: 0.388670; batch adversarial loss: 0.430629\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373328; batch adversarial loss: 0.397034\n",
      "epoch 36; iter: 200; batch classifier loss: 0.334279; batch adversarial loss: 0.505123\n",
      "epoch 37; iter: 0; batch classifier loss: 0.326300; batch adversarial loss: 0.375913\n",
      "epoch 37; iter: 200; batch classifier loss: 0.287517; batch adversarial loss: 0.462247\n",
      "epoch 38; iter: 0; batch classifier loss: 0.364714; batch adversarial loss: 0.323574\n",
      "epoch 38; iter: 200; batch classifier loss: 0.349175; batch adversarial loss: 0.460938\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322468; batch adversarial loss: 0.456801\n",
      "epoch 39; iter: 200; batch classifier loss: 0.288058; batch adversarial loss: 0.518974\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351146; batch adversarial loss: 0.368307\n",
      "epoch 40; iter: 200; batch classifier loss: 0.364579; batch adversarial loss: 0.428881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.284915; batch adversarial loss: 0.403717\n",
      "epoch 41; iter: 200; batch classifier loss: 0.333043; batch adversarial loss: 0.494849\n",
      "epoch 42; iter: 0; batch classifier loss: 0.285525; batch adversarial loss: 0.441732\n",
      "epoch 42; iter: 200; batch classifier loss: 0.518336; batch adversarial loss: 0.515555\n",
      "epoch 43; iter: 0; batch classifier loss: 0.345843; batch adversarial loss: 0.429690\n",
      "epoch 43; iter: 200; batch classifier loss: 0.345348; batch adversarial loss: 0.364338\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365536; batch adversarial loss: 0.518914\n",
      "epoch 44; iter: 200; batch classifier loss: 0.332117; batch adversarial loss: 0.386550\n",
      "epoch 45; iter: 0; batch classifier loss: 0.331446; batch adversarial loss: 0.484716\n",
      "epoch 45; iter: 200; batch classifier loss: 0.369382; batch adversarial loss: 0.427901\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420275; batch adversarial loss: 0.443240\n",
      "epoch 46; iter: 200; batch classifier loss: 0.414998; batch adversarial loss: 0.430419\n",
      "epoch 47; iter: 0; batch classifier loss: 0.504373; batch adversarial loss: 0.402644\n",
      "epoch 47; iter: 200; batch classifier loss: 0.338521; batch adversarial loss: 0.400548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.293360; batch adversarial loss: 0.402945\n",
      "epoch 48; iter: 200; batch classifier loss: 0.376177; batch adversarial loss: 0.420195\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421881; batch adversarial loss: 0.414937\n",
      "epoch 49; iter: 200; batch classifier loss: 0.384158; batch adversarial loss: 0.406025\n",
      "epoch 0; iter: 0; batch classifier loss: 16.611853; batch adversarial loss: 0.693139\n",
      "epoch 0; iter: 200; batch classifier loss: 4.055999; batch adversarial loss: 0.620171\n",
      "epoch 1; iter: 0; batch classifier loss: 10.659282; batch adversarial loss: 0.525008\n",
      "epoch 1; iter: 200; batch classifier loss: 9.919283; batch adversarial loss: 0.513373\n",
      "epoch 2; iter: 0; batch classifier loss: 5.524506; batch adversarial loss: 0.533009\n",
      "epoch 2; iter: 200; batch classifier loss: 2.175591; batch adversarial loss: 0.487621\n",
      "epoch 3; iter: 0; batch classifier loss: 0.592660; batch adversarial loss: 0.489254\n",
      "epoch 3; iter: 200; batch classifier loss: 0.952842; batch adversarial loss: 0.433984\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746063; batch adversarial loss: 0.410868\n",
      "epoch 4; iter: 200; batch classifier loss: 0.880214; batch adversarial loss: 0.489669\n",
      "epoch 5; iter: 0; batch classifier loss: 0.967915; batch adversarial loss: 0.483714\n",
      "epoch 5; iter: 200; batch classifier loss: 0.551474; batch adversarial loss: 0.429834\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531732; batch adversarial loss: 0.366854\n",
      "epoch 6; iter: 200; batch classifier loss: 0.425514; batch adversarial loss: 0.461852\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376155; batch adversarial loss: 0.404264\n",
      "epoch 7; iter: 200; batch classifier loss: 0.456334; batch adversarial loss: 0.465057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.369740; batch adversarial loss: 0.369210\n",
      "epoch 8; iter: 200; batch classifier loss: 0.437541; batch adversarial loss: 0.415004\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334828; batch adversarial loss: 0.350029\n",
      "epoch 9; iter: 200; batch classifier loss: 0.450101; batch adversarial loss: 0.443503\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358500; batch adversarial loss: 0.324423\n",
      "epoch 10; iter: 200; batch classifier loss: 0.356525; batch adversarial loss: 0.476350\n",
      "epoch 11; iter: 0; batch classifier loss: 0.468658; batch adversarial loss: 0.374453\n",
      "epoch 11; iter: 200; batch classifier loss: 0.240490; batch adversarial loss: 0.413232\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285350; batch adversarial loss: 0.506098\n",
      "epoch 12; iter: 200; batch classifier loss: 0.284397; batch adversarial loss: 0.404666\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551789; batch adversarial loss: 0.490944\n",
      "epoch 13; iter: 200; batch classifier loss: 0.361953; batch adversarial loss: 0.402201\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331940; batch adversarial loss: 0.442455\n",
      "epoch 14; iter: 200; batch classifier loss: 0.384193; batch adversarial loss: 0.394318\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329104; batch adversarial loss: 0.405190\n",
      "epoch 15; iter: 200; batch classifier loss: 0.408496; batch adversarial loss: 0.399636\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352693; batch adversarial loss: 0.445750\n",
      "epoch 16; iter: 200; batch classifier loss: 0.437803; batch adversarial loss: 0.338208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535688; batch adversarial loss: 0.349841\n",
      "epoch 17; iter: 200; batch classifier loss: 0.444642; batch adversarial loss: 0.414161\n",
      "epoch 18; iter: 0; batch classifier loss: 0.305181; batch adversarial loss: 0.295182\n",
      "epoch 18; iter: 200; batch classifier loss: 0.429156; batch adversarial loss: 0.341751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.389577; batch adversarial loss: 0.370923\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342562; batch adversarial loss: 0.361682\n",
      "epoch 20; iter: 0; batch classifier loss: 0.357082; batch adversarial loss: 0.362768\n",
      "epoch 20; iter: 200; batch classifier loss: 0.757587; batch adversarial loss: 0.354590\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323059; batch adversarial loss: 0.402460\n",
      "epoch 21; iter: 200; batch classifier loss: 0.408615; batch adversarial loss: 0.376024\n",
      "epoch 22; iter: 0; batch classifier loss: 0.264970; batch adversarial loss: 0.455202\n",
      "epoch 22; iter: 200; batch classifier loss: 0.423021; batch adversarial loss: 0.436170\n",
      "epoch 23; iter: 0; batch classifier loss: 0.269010; batch adversarial loss: 0.360554\n",
      "epoch 23; iter: 200; batch classifier loss: 0.302201; batch adversarial loss: 0.453252\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340475; batch adversarial loss: 0.431904\n",
      "epoch 24; iter: 200; batch classifier loss: 0.265503; batch adversarial loss: 0.404368\n",
      "epoch 25; iter: 0; batch classifier loss: 0.277591; batch adversarial loss: 0.378748\n",
      "epoch 25; iter: 200; batch classifier loss: 0.333343; batch adversarial loss: 0.356766\n",
      "epoch 26; iter: 0; batch classifier loss: 0.224928; batch adversarial loss: 0.400366\n",
      "epoch 26; iter: 200; batch classifier loss: 0.381503; batch adversarial loss: 0.524705\n",
      "epoch 27; iter: 0; batch classifier loss: 0.354142; batch adversarial loss: 0.392653\n",
      "epoch 27; iter: 200; batch classifier loss: 0.314304; batch adversarial loss: 0.444308\n",
      "epoch 28; iter: 0; batch classifier loss: 0.567367; batch adversarial loss: 0.405080\n",
      "epoch 28; iter: 200; batch classifier loss: 0.321309; batch adversarial loss: 0.434767\n",
      "epoch 29; iter: 0; batch classifier loss: 0.332184; batch adversarial loss: 0.420678\n",
      "epoch 29; iter: 200; batch classifier loss: 0.370332; batch adversarial loss: 0.480255\n",
      "epoch 30; iter: 0; batch classifier loss: 0.348935; batch adversarial loss: 0.389819\n",
      "epoch 30; iter: 200; batch classifier loss: 0.315873; batch adversarial loss: 0.436752\n",
      "epoch 31; iter: 0; batch classifier loss: 0.266445; batch adversarial loss: 0.390307\n",
      "epoch 31; iter: 200; batch classifier loss: 0.372226; batch adversarial loss: 0.392013\n",
      "epoch 32; iter: 0; batch classifier loss: 0.334503; batch adversarial loss: 0.359862\n",
      "epoch 32; iter: 200; batch classifier loss: 0.325808; batch adversarial loss: 0.322179\n",
      "epoch 33; iter: 0; batch classifier loss: 0.501645; batch adversarial loss: 0.375089\n",
      "epoch 33; iter: 200; batch classifier loss: 0.398668; batch adversarial loss: 0.458107\n",
      "epoch 34; iter: 0; batch classifier loss: 0.273602; batch adversarial loss: 0.430727\n",
      "epoch 34; iter: 200; batch classifier loss: 0.305863; batch adversarial loss: 0.434207\n",
      "epoch 35; iter: 0; batch classifier loss: 0.330139; batch adversarial loss: 0.401658\n",
      "epoch 35; iter: 200; batch classifier loss: 0.302387; batch adversarial loss: 0.371382\n",
      "epoch 36; iter: 0; batch classifier loss: 0.378190; batch adversarial loss: 0.462207\n",
      "epoch 36; iter: 200; batch classifier loss: 0.271364; batch adversarial loss: 0.425283\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288483; batch adversarial loss: 0.309542\n",
      "epoch 37; iter: 200; batch classifier loss: 0.414154; batch adversarial loss: 0.375750\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359086; batch adversarial loss: 0.458249\n",
      "epoch 38; iter: 200; batch classifier loss: 0.315606; batch adversarial loss: 0.369953\n",
      "epoch 39; iter: 0; batch classifier loss: 0.320917; batch adversarial loss: 0.499986\n",
      "epoch 39; iter: 200; batch classifier loss: 0.427706; batch adversarial loss: 0.360944\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367753; batch adversarial loss: 0.444106\n",
      "epoch 40; iter: 200; batch classifier loss: 0.336047; batch adversarial loss: 0.361380\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425963; batch adversarial loss: 0.371449\n",
      "epoch 41; iter: 200; batch classifier loss: 0.391640; batch adversarial loss: 0.466463\n",
      "epoch 42; iter: 0; batch classifier loss: 0.356374; batch adversarial loss: 0.324707\n",
      "epoch 42; iter: 200; batch classifier loss: 0.371183; batch adversarial loss: 0.390690\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386676; batch adversarial loss: 0.518370\n",
      "epoch 43; iter: 200; batch classifier loss: 0.478631; batch adversarial loss: 0.336110\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428773; batch adversarial loss: 0.328045\n",
      "epoch 44; iter: 200; batch classifier loss: 0.277416; batch adversarial loss: 0.428397\n",
      "epoch 45; iter: 0; batch classifier loss: 0.263521; batch adversarial loss: 0.371075\n",
      "epoch 45; iter: 200; batch classifier loss: 0.413281; batch adversarial loss: 0.429044\n",
      "epoch 46; iter: 0; batch classifier loss: 0.580869; batch adversarial loss: 0.420854\n",
      "epoch 46; iter: 200; batch classifier loss: 0.382943; batch adversarial loss: 0.468939\n",
      "epoch 47; iter: 0; batch classifier loss: 0.252030; batch adversarial loss: 0.399847\n",
      "epoch 47; iter: 200; batch classifier loss: 0.448093; batch adversarial loss: 0.401922\n",
      "epoch 48; iter: 0; batch classifier loss: 0.302065; batch adversarial loss: 0.435628\n",
      "epoch 48; iter: 200; batch classifier loss: 0.454618; batch adversarial loss: 0.447555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369693; batch adversarial loss: 0.423972\n",
      "epoch 49; iter: 200; batch classifier loss: 0.482862; batch adversarial loss: 0.374703\n",
      "epoch 0; iter: 0; batch classifier loss: 9.363217; batch adversarial loss: 0.685411\n",
      "epoch 0; iter: 200; batch classifier loss: 4.494771; batch adversarial loss: 0.594353\n",
      "epoch 1; iter: 0; batch classifier loss: 4.802149; batch adversarial loss: 0.597957\n",
      "epoch 1; iter: 200; batch classifier loss: 4.519000; batch adversarial loss: 0.562824\n",
      "epoch 2; iter: 0; batch classifier loss: 2.270777; batch adversarial loss: 0.503300\n",
      "epoch 2; iter: 200; batch classifier loss: 1.558958; batch adversarial loss: 0.509441\n",
      "epoch 3; iter: 0; batch classifier loss: 0.878887; batch adversarial loss: 0.465954\n",
      "epoch 3; iter: 200; batch classifier loss: 3.605548; batch adversarial loss: 0.417440\n",
      "epoch 4; iter: 0; batch classifier loss: 1.607487; batch adversarial loss: 0.361485\n",
      "epoch 4; iter: 200; batch classifier loss: 1.751851; batch adversarial loss: 0.400780\n",
      "epoch 5; iter: 0; batch classifier loss: 1.117127; batch adversarial loss: 0.424813\n",
      "epoch 5; iter: 200; batch classifier loss: 1.378983; batch adversarial loss: 0.372782\n",
      "epoch 6; iter: 0; batch classifier loss: 1.070642; batch adversarial loss: 0.313892\n",
      "epoch 6; iter: 200; batch classifier loss: 0.714173; batch adversarial loss: 0.439550\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462642; batch adversarial loss: 0.450652\n",
      "epoch 7; iter: 200; batch classifier loss: 0.517761; batch adversarial loss: 0.384759\n",
      "epoch 8; iter: 0; batch classifier loss: 0.318921; batch adversarial loss: 0.407315\n",
      "epoch 8; iter: 200; batch classifier loss: 0.365964; batch adversarial loss: 0.387387\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337763; batch adversarial loss: 0.576968\n",
      "epoch 9; iter: 200; batch classifier loss: 0.366091; batch adversarial loss: 0.328403\n",
      "epoch 10; iter: 0; batch classifier loss: 0.268142; batch adversarial loss: 0.352660\n",
      "epoch 10; iter: 200; batch classifier loss: 0.348959; batch adversarial loss: 0.494297\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332284; batch adversarial loss: 0.472065\n",
      "epoch 11; iter: 200; batch classifier loss: 0.321454; batch adversarial loss: 0.414472\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356694; batch adversarial loss: 0.376267\n",
      "epoch 12; iter: 200; batch classifier loss: 0.466661; batch adversarial loss: 0.485651\n",
      "epoch 13; iter: 0; batch classifier loss: 0.322519; batch adversarial loss: 0.435818\n",
      "epoch 13; iter: 200; batch classifier loss: 0.463890; batch adversarial loss: 0.420905\n",
      "epoch 14; iter: 0; batch classifier loss: 0.603630; batch adversarial loss: 0.494006\n",
      "epoch 14; iter: 200; batch classifier loss: 0.392290; batch adversarial loss: 0.396838\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310310; batch adversarial loss: 0.485457\n",
      "epoch 15; iter: 200; batch classifier loss: 0.381586; batch adversarial loss: 0.491802\n",
      "epoch 16; iter: 0; batch classifier loss: 0.438879; batch adversarial loss: 0.477296\n",
      "epoch 16; iter: 200; batch classifier loss: 0.472557; batch adversarial loss: 0.394364\n",
      "epoch 17; iter: 0; batch classifier loss: 0.303650; batch adversarial loss: 0.377981\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381993; batch adversarial loss: 0.410441\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442097; batch adversarial loss: 0.429355\n",
      "epoch 18; iter: 200; batch classifier loss: 0.308136; batch adversarial loss: 0.436058\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406360; batch adversarial loss: 0.323819\n",
      "epoch 19; iter: 200; batch classifier loss: 0.427505; batch adversarial loss: 0.335851\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325090; batch adversarial loss: 0.436220\n",
      "epoch 20; iter: 200; batch classifier loss: 0.352958; batch adversarial loss: 0.463852\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266866; batch adversarial loss: 0.424376\n",
      "epoch 21; iter: 200; batch classifier loss: 0.405318; batch adversarial loss: 0.401995\n",
      "epoch 22; iter: 0; batch classifier loss: 0.332733; batch adversarial loss: 0.357440\n",
      "epoch 22; iter: 200; batch classifier loss: 0.477583; batch adversarial loss: 0.417711\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436035; batch adversarial loss: 0.423858\n",
      "epoch 23; iter: 200; batch classifier loss: 0.393128; batch adversarial loss: 0.325012\n",
      "epoch 24; iter: 0; batch classifier loss: 0.337731; batch adversarial loss: 0.291073\n",
      "epoch 24; iter: 200; batch classifier loss: 0.371384; batch adversarial loss: 0.431300\n",
      "epoch 25; iter: 0; batch classifier loss: 0.329211; batch adversarial loss: 0.394358\n",
      "epoch 25; iter: 200; batch classifier loss: 0.266988; batch adversarial loss: 0.365895\n",
      "epoch 26; iter: 0; batch classifier loss: 0.335224; batch adversarial loss: 0.429704\n",
      "epoch 26; iter: 200; batch classifier loss: 0.413360; batch adversarial loss: 0.419097\n",
      "epoch 27; iter: 0; batch classifier loss: 0.320091; batch adversarial loss: 0.408531\n",
      "epoch 27; iter: 200; batch classifier loss: 0.353746; batch adversarial loss: 0.316410\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369261; batch adversarial loss: 0.417422\n",
      "epoch 28; iter: 200; batch classifier loss: 0.376558; batch adversarial loss: 0.324778\n",
      "epoch 29; iter: 0; batch classifier loss: 0.396846; batch adversarial loss: 0.249962\n",
      "epoch 29; iter: 200; batch classifier loss: 0.352537; batch adversarial loss: 0.372282\n",
      "epoch 30; iter: 0; batch classifier loss: 0.409824; batch adversarial loss: 0.394960\n",
      "epoch 30; iter: 200; batch classifier loss: 0.320472; batch adversarial loss: 0.348158\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397911; batch adversarial loss: 0.353548\n",
      "epoch 31; iter: 200; batch classifier loss: 0.327272; batch adversarial loss: 0.488622\n",
      "epoch 32; iter: 0; batch classifier loss: 0.356296; batch adversarial loss: 0.489142\n",
      "epoch 32; iter: 200; batch classifier loss: 0.375191; batch adversarial loss: 0.414684\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358268; batch adversarial loss: 0.422225\n",
      "epoch 33; iter: 200; batch classifier loss: 0.509749; batch adversarial loss: 0.457307\n",
      "epoch 34; iter: 0; batch classifier loss: 0.405813; batch adversarial loss: 0.490994\n",
      "epoch 34; iter: 200; batch classifier loss: 0.393703; batch adversarial loss: 0.429063\n",
      "epoch 35; iter: 0; batch classifier loss: 0.545345; batch adversarial loss: 0.323315\n",
      "epoch 35; iter: 200; batch classifier loss: 0.296150; batch adversarial loss: 0.561955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.330391; batch adversarial loss: 0.403080\n",
      "epoch 36; iter: 200; batch classifier loss: 0.458773; batch adversarial loss: 0.379174\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443916; batch adversarial loss: 0.425369\n",
      "epoch 37; iter: 200; batch classifier loss: 0.393514; batch adversarial loss: 0.394808\n",
      "epoch 38; iter: 0; batch classifier loss: 0.289526; batch adversarial loss: 0.476530\n",
      "epoch 38; iter: 200; batch classifier loss: 0.503069; batch adversarial loss: 0.393782\n",
      "epoch 39; iter: 0; batch classifier loss: 0.317919; batch adversarial loss: 0.403921\n",
      "epoch 39; iter: 200; batch classifier loss: 0.446814; batch adversarial loss: 0.416187\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394989; batch adversarial loss: 0.445114\n",
      "epoch 40; iter: 200; batch classifier loss: 0.422015; batch adversarial loss: 0.384506\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388954; batch adversarial loss: 0.361202\n",
      "epoch 41; iter: 200; batch classifier loss: 0.381093; batch adversarial loss: 0.327402\n",
      "epoch 42; iter: 0; batch classifier loss: 0.469257; batch adversarial loss: 0.416124\n",
      "epoch 42; iter: 200; batch classifier loss: 0.308277; batch adversarial loss: 0.370381\n",
      "epoch 43; iter: 0; batch classifier loss: 0.447043; batch adversarial loss: 0.436374\n",
      "epoch 43; iter: 200; batch classifier loss: 0.393610; batch adversarial loss: 0.447254\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468645; batch adversarial loss: 0.365783\n",
      "epoch 44; iter: 200; batch classifier loss: 0.579057; batch adversarial loss: 0.288938\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354307; batch adversarial loss: 0.392322\n",
      "epoch 45; iter: 200; batch classifier loss: 0.278558; batch adversarial loss: 0.503010\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382965; batch adversarial loss: 0.414428\n",
      "epoch 46; iter: 200; batch classifier loss: 0.309391; batch adversarial loss: 0.428085\n",
      "epoch 47; iter: 0; batch classifier loss: 0.501461; batch adversarial loss: 0.368182\n",
      "epoch 47; iter: 200; batch classifier loss: 0.369683; batch adversarial loss: 0.416411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.328348; batch adversarial loss: 0.501019\n",
      "epoch 48; iter: 200; batch classifier loss: 0.339994; batch adversarial loss: 0.432929\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377139; batch adversarial loss: 0.408623\n",
      "epoch 49; iter: 200; batch classifier loss: 0.410823; batch adversarial loss: 0.411343\n",
      "epoch 0; iter: 0; batch classifier loss: 23.155745; batch adversarial loss: 0.624122\n",
      "epoch 0; iter: 200; batch classifier loss: 13.946222; batch adversarial loss: 0.556636\n",
      "epoch 1; iter: 0; batch classifier loss: 11.756433; batch adversarial loss: 0.561141\n",
      "epoch 1; iter: 200; batch classifier loss: 7.493238; batch adversarial loss: 0.454345\n",
      "epoch 2; iter: 0; batch classifier loss: 12.534000; batch adversarial loss: 0.523025\n",
      "epoch 2; iter: 200; batch classifier loss: 4.592229; batch adversarial loss: 0.511408\n",
      "epoch 3; iter: 0; batch classifier loss: 5.148079; batch adversarial loss: 0.372095\n",
      "epoch 3; iter: 200; batch classifier loss: 1.957615; batch adversarial loss: 0.488263\n",
      "epoch 4; iter: 0; batch classifier loss: 1.630054; batch adversarial loss: 0.448092\n",
      "epoch 4; iter: 200; batch classifier loss: 2.855088; batch adversarial loss: 0.490859\n",
      "epoch 5; iter: 0; batch classifier loss: 1.041219; batch adversarial loss: 0.463860\n",
      "epoch 5; iter: 200; batch classifier loss: 1.874696; batch adversarial loss: 0.494277\n",
      "epoch 6; iter: 0; batch classifier loss: 0.697189; batch adversarial loss: 0.383109\n",
      "epoch 6; iter: 200; batch classifier loss: 0.497764; batch adversarial loss: 0.412392\n",
      "epoch 7; iter: 0; batch classifier loss: 0.721217; batch adversarial loss: 0.425648\n",
      "epoch 7; iter: 200; batch classifier loss: 0.899186; batch adversarial loss: 0.470732\n",
      "epoch 8; iter: 0; batch classifier loss: 1.004034; batch adversarial loss: 0.422173\n",
      "epoch 8; iter: 200; batch classifier loss: 0.435705; batch adversarial loss: 0.369370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582286; batch adversarial loss: 0.450796\n",
      "epoch 9; iter: 200; batch classifier loss: 0.367678; batch adversarial loss: 0.370248\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580330; batch adversarial loss: 0.410646\n",
      "epoch 10; iter: 200; batch classifier loss: 0.418874; batch adversarial loss: 0.357771\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447370; batch adversarial loss: 0.476590\n",
      "epoch 11; iter: 200; batch classifier loss: 0.433399; batch adversarial loss: 0.467913\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312861; batch adversarial loss: 0.390779\n",
      "epoch 12; iter: 200; batch classifier loss: 0.511088; batch adversarial loss: 0.474290\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341013; batch adversarial loss: 0.306626\n",
      "epoch 13; iter: 200; batch classifier loss: 0.437070; batch adversarial loss: 0.426513\n",
      "epoch 14; iter: 0; batch classifier loss: 0.410501; batch adversarial loss: 0.412510\n",
      "epoch 14; iter: 200; batch classifier loss: 0.366600; batch adversarial loss: 0.359400\n",
      "epoch 15; iter: 0; batch classifier loss: 0.378719; batch adversarial loss: 0.464081\n",
      "epoch 15; iter: 200; batch classifier loss: 0.426690; batch adversarial loss: 0.407579\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289082; batch adversarial loss: 0.388232\n",
      "epoch 16; iter: 200; batch classifier loss: 0.281312; batch adversarial loss: 0.403391\n",
      "epoch 17; iter: 0; batch classifier loss: 0.395938; batch adversarial loss: 0.296621\n",
      "epoch 17; iter: 200; batch classifier loss: 0.399066; batch adversarial loss: 0.329767\n",
      "epoch 18; iter: 0; batch classifier loss: 0.426829; batch adversarial loss: 0.428747\n",
      "epoch 18; iter: 200; batch classifier loss: 0.404706; batch adversarial loss: 0.482265\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340974; batch adversarial loss: 0.474125\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342661; batch adversarial loss: 0.467158\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432517; batch adversarial loss: 0.337347\n",
      "epoch 20; iter: 200; batch classifier loss: 0.330809; batch adversarial loss: 0.377446\n",
      "epoch 21; iter: 0; batch classifier loss: 0.445833; batch adversarial loss: 0.434837\n",
      "epoch 21; iter: 200; batch classifier loss: 0.313670; batch adversarial loss: 0.365767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.293783; batch adversarial loss: 0.420541\n",
      "epoch 22; iter: 200; batch classifier loss: 0.331840; batch adversarial loss: 0.375610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400541; batch adversarial loss: 0.353790\n",
      "epoch 23; iter: 200; batch classifier loss: 0.364040; batch adversarial loss: 0.286627\n",
      "epoch 24; iter: 0; batch classifier loss: 0.286725; batch adversarial loss: 0.433449\n",
      "epoch 24; iter: 200; batch classifier loss: 0.294968; batch adversarial loss: 0.448009\n",
      "epoch 25; iter: 0; batch classifier loss: 0.324979; batch adversarial loss: 0.453531\n",
      "epoch 25; iter: 200; batch classifier loss: 0.319418; batch adversarial loss: 0.435402\n",
      "epoch 26; iter: 0; batch classifier loss: 0.255397; batch adversarial loss: 0.430139\n",
      "epoch 26; iter: 200; batch classifier loss: 0.292840; batch adversarial loss: 0.454153\n",
      "epoch 27; iter: 0; batch classifier loss: 0.382142; batch adversarial loss: 0.384854\n",
      "epoch 27; iter: 200; batch classifier loss: 0.281065; batch adversarial loss: 0.518208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.298027; batch adversarial loss: 0.449785\n",
      "epoch 28; iter: 200; batch classifier loss: 0.341319; batch adversarial loss: 0.369630\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322128; batch adversarial loss: 0.347442\n",
      "epoch 29; iter: 200; batch classifier loss: 0.379845; batch adversarial loss: 0.419012\n",
      "epoch 30; iter: 0; batch classifier loss: 0.377980; batch adversarial loss: 0.495578\n",
      "epoch 30; iter: 200; batch classifier loss: 0.323274; batch adversarial loss: 0.387692\n",
      "epoch 31; iter: 0; batch classifier loss: 0.321104; batch adversarial loss: 0.328938\n",
      "epoch 31; iter: 200; batch classifier loss: 0.280667; batch adversarial loss: 0.429310\n",
      "epoch 32; iter: 0; batch classifier loss: 0.372036; batch adversarial loss: 0.432396\n",
      "epoch 32; iter: 200; batch classifier loss: 0.412110; batch adversarial loss: 0.333925\n",
      "epoch 33; iter: 0; batch classifier loss: 0.345365; batch adversarial loss: 0.512587\n",
      "epoch 33; iter: 200; batch classifier loss: 0.326192; batch adversarial loss: 0.318779\n",
      "epoch 34; iter: 0; batch classifier loss: 0.308781; batch adversarial loss: 0.395191\n",
      "epoch 34; iter: 200; batch classifier loss: 0.369889; batch adversarial loss: 0.471501\n",
      "epoch 35; iter: 0; batch classifier loss: 0.340187; batch adversarial loss: 0.393096\n",
      "epoch 35; iter: 200; batch classifier loss: 0.329546; batch adversarial loss: 0.407096\n",
      "epoch 36; iter: 0; batch classifier loss: 0.285445; batch adversarial loss: 0.375236\n",
      "epoch 36; iter: 200; batch classifier loss: 0.344265; batch adversarial loss: 0.466623\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399653; batch adversarial loss: 0.399158\n",
      "epoch 37; iter: 200; batch classifier loss: 0.311187; batch adversarial loss: 0.401852\n",
      "epoch 38; iter: 0; batch classifier loss: 0.307205; batch adversarial loss: 0.484565\n",
      "epoch 38; iter: 200; batch classifier loss: 0.344378; batch adversarial loss: 0.345053\n",
      "epoch 39; iter: 0; batch classifier loss: 0.357177; batch adversarial loss: 0.444377\n",
      "epoch 39; iter: 200; batch classifier loss: 0.378977; batch adversarial loss: 0.364597\n",
      "epoch 40; iter: 0; batch classifier loss: 0.316179; batch adversarial loss: 0.347734\n",
      "epoch 40; iter: 200; batch classifier loss: 0.549674; batch adversarial loss: 0.521660\n",
      "epoch 41; iter: 0; batch classifier loss: 0.533111; batch adversarial loss: 0.358418\n",
      "epoch 41; iter: 200; batch classifier loss: 0.334706; batch adversarial loss: 0.410164\n",
      "epoch 42; iter: 0; batch classifier loss: 0.322282; batch adversarial loss: 0.375116\n",
      "epoch 42; iter: 200; batch classifier loss: 0.440736; batch adversarial loss: 0.255370\n",
      "epoch 43; iter: 0; batch classifier loss: 0.337264; batch adversarial loss: 0.495802\n",
      "epoch 43; iter: 200; batch classifier loss: 0.337496; batch adversarial loss: 0.421235\n",
      "epoch 44; iter: 0; batch classifier loss: 0.249221; batch adversarial loss: 0.387715\n",
      "epoch 44; iter: 200; batch classifier loss: 0.361526; batch adversarial loss: 0.417067\n",
      "epoch 45; iter: 0; batch classifier loss: 0.353557; batch adversarial loss: 0.433369\n",
      "epoch 45; iter: 200; batch classifier loss: 0.314916; batch adversarial loss: 0.372665\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400272; batch adversarial loss: 0.386237\n",
      "epoch 46; iter: 200; batch classifier loss: 0.303758; batch adversarial loss: 0.495706\n",
      "epoch 47; iter: 0; batch classifier loss: 0.306975; batch adversarial loss: 0.402537\n",
      "epoch 47; iter: 200; batch classifier loss: 0.377611; batch adversarial loss: 0.491214\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408968; batch adversarial loss: 0.430710\n",
      "epoch 48; iter: 200; batch classifier loss: 0.396160; batch adversarial loss: 0.435647\n",
      "epoch 49; iter: 0; batch classifier loss: 0.330102; batch adversarial loss: 0.347172\n",
      "epoch 49; iter: 200; batch classifier loss: 0.317472; batch adversarial loss: 0.335288\n",
      "epoch 0; iter: 0; batch classifier loss: 56.225555; batch adversarial loss: 0.544444\n",
      "epoch 0; iter: 200; batch classifier loss: 8.802196; batch adversarial loss: 0.536670\n",
      "epoch 1; iter: 0; batch classifier loss: 5.477782; batch adversarial loss: 0.619164\n",
      "epoch 1; iter: 200; batch classifier loss: 6.922031; batch adversarial loss: 0.494849\n",
      "epoch 2; iter: 0; batch classifier loss: 1.568234; batch adversarial loss: 0.443065\n",
      "epoch 2; iter: 200; batch classifier loss: 3.415839; batch adversarial loss: 0.462522\n",
      "epoch 3; iter: 0; batch classifier loss: 1.757772; batch adversarial loss: 0.412407\n",
      "epoch 3; iter: 200; batch classifier loss: 2.268225; batch adversarial loss: 0.476031\n",
      "epoch 4; iter: 0; batch classifier loss: 2.681646; batch adversarial loss: 0.413096\n",
      "epoch 4; iter: 200; batch classifier loss: 1.167846; batch adversarial loss: 0.368785\n",
      "epoch 5; iter: 0; batch classifier loss: 1.566521; batch adversarial loss: 0.446282\n",
      "epoch 5; iter: 200; batch classifier loss: 0.698017; batch adversarial loss: 0.381994\n",
      "epoch 6; iter: 0; batch classifier loss: 0.909560; batch adversarial loss: 0.376841\n",
      "epoch 6; iter: 200; batch classifier loss: 0.363371; batch adversarial loss: 0.440802\n",
      "epoch 7; iter: 0; batch classifier loss: 0.815850; batch adversarial loss: 0.315649\n",
      "epoch 7; iter: 200; batch classifier loss: 0.787349; batch adversarial loss: 0.458332\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397695; batch adversarial loss: 0.419737\n",
      "epoch 8; iter: 200; batch classifier loss: 0.696048; batch adversarial loss: 0.402195\n",
      "epoch 9; iter: 0; batch classifier loss: 0.552492; batch adversarial loss: 0.421747\n",
      "epoch 9; iter: 200; batch classifier loss: 0.389465; batch adversarial loss: 0.414794\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518756; batch adversarial loss: 0.353933\n",
      "epoch 10; iter: 200; batch classifier loss: 0.345880; batch adversarial loss: 0.416967\n",
      "epoch 11; iter: 0; batch classifier loss: 0.423020; batch adversarial loss: 0.389605\n",
      "epoch 11; iter: 200; batch classifier loss: 0.315837; batch adversarial loss: 0.450045\n",
      "epoch 12; iter: 0; batch classifier loss: 0.319714; batch adversarial loss: 0.351238\n",
      "epoch 12; iter: 200; batch classifier loss: 0.311973; batch adversarial loss: 0.478806\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429962; batch adversarial loss: 0.472903\n",
      "epoch 13; iter: 200; batch classifier loss: 0.340088; batch adversarial loss: 0.499131\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507477; batch adversarial loss: 0.379591\n",
      "epoch 14; iter: 200; batch classifier loss: 0.398778; batch adversarial loss: 0.485082\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385011; batch adversarial loss: 0.320240\n",
      "epoch 15; iter: 200; batch classifier loss: 0.511332; batch adversarial loss: 0.437272\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304449; batch adversarial loss: 0.404903\n",
      "epoch 16; iter: 200; batch classifier loss: 0.427168; batch adversarial loss: 0.440206\n",
      "epoch 17; iter: 0; batch classifier loss: 0.436105; batch adversarial loss: 0.421694\n",
      "epoch 17; iter: 200; batch classifier loss: 0.296661; batch adversarial loss: 0.410334\n",
      "epoch 18; iter: 0; batch classifier loss: 0.369556; batch adversarial loss: 0.418726\n",
      "epoch 18; iter: 200; batch classifier loss: 0.343960; batch adversarial loss: 0.369825\n",
      "epoch 19; iter: 0; batch classifier loss: 0.358816; batch adversarial loss: 0.361421\n",
      "epoch 19; iter: 200; batch classifier loss: 0.401199; batch adversarial loss: 0.466481\n",
      "epoch 20; iter: 0; batch classifier loss: 0.382403; batch adversarial loss: 0.406427\n",
      "epoch 20; iter: 200; batch classifier loss: 0.365304; batch adversarial loss: 0.385476\n",
      "epoch 21; iter: 0; batch classifier loss: 0.366330; batch adversarial loss: 0.417785\n",
      "epoch 21; iter: 200; batch classifier loss: 0.314609; batch adversarial loss: 0.394224\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427780; batch adversarial loss: 0.388495\n",
      "epoch 22; iter: 200; batch classifier loss: 0.372270; batch adversarial loss: 0.442999\n",
      "epoch 23; iter: 0; batch classifier loss: 0.314977; batch adversarial loss: 0.435324\n",
      "epoch 23; iter: 200; batch classifier loss: 0.393479; batch adversarial loss: 0.418772\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343146; batch adversarial loss: 0.436986\n",
      "epoch 24; iter: 200; batch classifier loss: 0.327496; batch adversarial loss: 0.528425\n",
      "epoch 25; iter: 0; batch classifier loss: 0.320577; batch adversarial loss: 0.398114\n",
      "epoch 25; iter: 200; batch classifier loss: 0.326273; batch adversarial loss: 0.518885\n",
      "epoch 26; iter: 0; batch classifier loss: 0.289984; batch adversarial loss: 0.412645\n",
      "epoch 26; iter: 200; batch classifier loss: 0.265237; batch adversarial loss: 0.468540\n",
      "epoch 27; iter: 0; batch classifier loss: 0.343275; batch adversarial loss: 0.405361\n",
      "epoch 27; iter: 200; batch classifier loss: 0.342284; batch adversarial loss: 0.321140\n",
      "epoch 28; iter: 0; batch classifier loss: 0.295586; batch adversarial loss: 0.390238\n",
      "epoch 28; iter: 200; batch classifier loss: 0.332485; batch adversarial loss: 0.386212\n",
      "epoch 29; iter: 0; batch classifier loss: 0.244270; batch adversarial loss: 0.441536\n",
      "epoch 29; iter: 200; batch classifier loss: 0.307287; batch adversarial loss: 0.349451\n",
      "epoch 30; iter: 0; batch classifier loss: 0.385567; batch adversarial loss: 0.371919\n",
      "epoch 30; iter: 200; batch classifier loss: 0.394233; batch adversarial loss: 0.407302\n",
      "epoch 31; iter: 0; batch classifier loss: 0.393128; batch adversarial loss: 0.365268\n",
      "epoch 31; iter: 200; batch classifier loss: 0.338874; batch adversarial loss: 0.360766\n",
      "epoch 32; iter: 0; batch classifier loss: 0.242586; batch adversarial loss: 0.472350\n",
      "epoch 32; iter: 200; batch classifier loss: 0.291002; batch adversarial loss: 0.404644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330092; batch adversarial loss: 0.373458\n",
      "epoch 33; iter: 200; batch classifier loss: 0.354608; batch adversarial loss: 0.441058\n",
      "epoch 34; iter: 0; batch classifier loss: 0.377628; batch adversarial loss: 0.395744\n",
      "epoch 34; iter: 200; batch classifier loss: 0.378179; batch adversarial loss: 0.381753\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402765; batch adversarial loss: 0.437680\n",
      "epoch 35; iter: 200; batch classifier loss: 0.241607; batch adversarial loss: 0.332110\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263361; batch adversarial loss: 0.406968\n",
      "epoch 36; iter: 200; batch classifier loss: 0.398349; batch adversarial loss: 0.333694\n",
      "epoch 37; iter: 0; batch classifier loss: 0.397129; batch adversarial loss: 0.406886\n",
      "epoch 37; iter: 200; batch classifier loss: 0.383120; batch adversarial loss: 0.420105\n",
      "epoch 38; iter: 0; batch classifier loss: 0.242338; batch adversarial loss: 0.324443\n",
      "epoch 38; iter: 200; batch classifier loss: 0.291352; batch adversarial loss: 0.381841\n",
      "epoch 39; iter: 0; batch classifier loss: 0.326408; batch adversarial loss: 0.307010\n",
      "epoch 39; iter: 200; batch classifier loss: 0.330411; batch adversarial loss: 0.460125\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351325; batch adversarial loss: 0.501636\n",
      "epoch 40; iter: 200; batch classifier loss: 0.239395; batch adversarial loss: 0.429203\n",
      "epoch 41; iter: 0; batch classifier loss: 0.381029; batch adversarial loss: 0.536103\n",
      "epoch 41; iter: 200; batch classifier loss: 0.347520; batch adversarial loss: 0.365007\n",
      "epoch 42; iter: 0; batch classifier loss: 0.324056; batch adversarial loss: 0.431752\n",
      "epoch 42; iter: 200; batch classifier loss: 0.277993; batch adversarial loss: 0.445714\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365806; batch adversarial loss: 0.307540\n",
      "epoch 43; iter: 200; batch classifier loss: 0.323814; batch adversarial loss: 0.319711\n",
      "epoch 44; iter: 0; batch classifier loss: 0.286898; batch adversarial loss: 0.398394\n",
      "epoch 44; iter: 200; batch classifier loss: 0.351242; batch adversarial loss: 0.418503\n",
      "epoch 45; iter: 0; batch classifier loss: 0.302583; batch adversarial loss: 0.456120\n",
      "epoch 45; iter: 200; batch classifier loss: 0.318954; batch adversarial loss: 0.416397\n",
      "epoch 46; iter: 0; batch classifier loss: 0.360044; batch adversarial loss: 0.460427\n",
      "epoch 46; iter: 200; batch classifier loss: 0.297722; batch adversarial loss: 0.350704\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384696; batch adversarial loss: 0.403558\n",
      "epoch 47; iter: 200; batch classifier loss: 0.402332; batch adversarial loss: 0.432805\n",
      "epoch 48; iter: 0; batch classifier loss: 0.350128; batch adversarial loss: 0.429319\n",
      "epoch 48; iter: 200; batch classifier loss: 0.350639; batch adversarial loss: 0.461893\n",
      "epoch 49; iter: 0; batch classifier loss: 0.341532; batch adversarial loss: 0.498152\n",
      "epoch 49; iter: 200; batch classifier loss: 0.366418; batch adversarial loss: 0.425462\n",
      "epoch 0; iter: 0; batch classifier loss: 27.341602; batch adversarial loss: 0.693835\n",
      "epoch 0; iter: 200; batch classifier loss: 39.782959; batch adversarial loss: 0.595350\n",
      "epoch 1; iter: 0; batch classifier loss: 5.348209; batch adversarial loss: 0.611375\n",
      "epoch 1; iter: 200; batch classifier loss: 9.043827; batch adversarial loss: 0.518913\n",
      "epoch 2; iter: 0; batch classifier loss: 3.713821; batch adversarial loss: 0.516524\n",
      "epoch 2; iter: 200; batch classifier loss: 1.418854; batch adversarial loss: 0.470827\n",
      "epoch 3; iter: 0; batch classifier loss: 1.144547; batch adversarial loss: 0.456312\n",
      "epoch 3; iter: 200; batch classifier loss: 0.768162; batch adversarial loss: 0.478968\n",
      "epoch 4; iter: 0; batch classifier loss: 2.139299; batch adversarial loss: 0.449903\n",
      "epoch 4; iter: 200; batch classifier loss: 0.399661; batch adversarial loss: 0.418139\n",
      "epoch 5; iter: 0; batch classifier loss: 1.739375; batch adversarial loss: 0.436523\n",
      "epoch 5; iter: 200; batch classifier loss: 0.356651; batch adversarial loss: 0.442059\n",
      "epoch 6; iter: 0; batch classifier loss: 1.176187; batch adversarial loss: 0.469970\n",
      "epoch 6; iter: 200; batch classifier loss: 0.992964; batch adversarial loss: 0.419552\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582876; batch adversarial loss: 0.438099\n",
      "epoch 7; iter: 200; batch classifier loss: 0.657409; batch adversarial loss: 0.446819\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495418; batch adversarial loss: 0.472889\n",
      "epoch 8; iter: 200; batch classifier loss: 0.634210; batch adversarial loss: 0.382159\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392991; batch adversarial loss: 0.451919\n",
      "epoch 9; iter: 200; batch classifier loss: 0.493417; batch adversarial loss: 0.565735\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582613; batch adversarial loss: 0.422615\n",
      "epoch 10; iter: 200; batch classifier loss: 0.357436; batch adversarial loss: 0.306845\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369300; batch adversarial loss: 0.403988\n",
      "epoch 11; iter: 200; batch classifier loss: 0.473321; batch adversarial loss: 0.393376\n",
      "epoch 12; iter: 0; batch classifier loss: 0.257025; batch adversarial loss: 0.411438\n",
      "epoch 12; iter: 200; batch classifier loss: 0.435695; batch adversarial loss: 0.353731\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378628; batch adversarial loss: 0.497416\n",
      "epoch 13; iter: 200; batch classifier loss: 0.358247; batch adversarial loss: 0.332843\n",
      "epoch 14; iter: 0; batch classifier loss: 1.203202; batch adversarial loss: 0.336350\n",
      "epoch 14; iter: 200; batch classifier loss: 0.354447; batch adversarial loss: 0.322854\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511297; batch adversarial loss: 0.366928\n",
      "epoch 15; iter: 200; batch classifier loss: 0.335998; batch adversarial loss: 0.365068\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292482; batch adversarial loss: 0.348504\n",
      "epoch 16; iter: 200; batch classifier loss: 0.402395; batch adversarial loss: 0.476923\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322209; batch adversarial loss: 0.456398\n",
      "epoch 17; iter: 200; batch classifier loss: 0.320486; batch adversarial loss: 0.468118\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371056; batch adversarial loss: 0.423631\n",
      "epoch 18; iter: 200; batch classifier loss: 0.377520; batch adversarial loss: 0.383957\n",
      "epoch 19; iter: 0; batch classifier loss: 0.342834; batch adversarial loss: 0.304838\n",
      "epoch 19; iter: 200; batch classifier loss: 0.321364; batch adversarial loss: 0.474844\n",
      "epoch 20; iter: 0; batch classifier loss: 0.336498; batch adversarial loss: 0.542042\n",
      "epoch 20; iter: 200; batch classifier loss: 0.322999; batch adversarial loss: 0.405680\n",
      "epoch 21; iter: 0; batch classifier loss: 0.326005; batch adversarial loss: 0.394609\n",
      "epoch 21; iter: 200; batch classifier loss: 0.438596; batch adversarial loss: 0.414571\n",
      "epoch 22; iter: 0; batch classifier loss: 0.329799; batch adversarial loss: 0.367571\n",
      "epoch 22; iter: 200; batch classifier loss: 0.256710; batch adversarial loss: 0.447149\n",
      "epoch 23; iter: 0; batch classifier loss: 0.389135; batch adversarial loss: 0.310524\n",
      "epoch 23; iter: 200; batch classifier loss: 0.314610; batch adversarial loss: 0.308803\n",
      "epoch 24; iter: 0; batch classifier loss: 0.459567; batch adversarial loss: 0.451116\n",
      "epoch 24; iter: 200; batch classifier loss: 0.274952; batch adversarial loss: 0.410889\n",
      "epoch 25; iter: 0; batch classifier loss: 0.369656; batch adversarial loss: 0.508835\n",
      "epoch 25; iter: 200; batch classifier loss: 0.269708; batch adversarial loss: 0.343944\n",
      "epoch 26; iter: 0; batch classifier loss: 0.361334; batch adversarial loss: 0.426689\n",
      "epoch 26; iter: 200; batch classifier loss: 0.384356; batch adversarial loss: 0.338038\n",
      "epoch 27; iter: 0; batch classifier loss: 0.431751; batch adversarial loss: 0.429718\n",
      "epoch 27; iter: 200; batch classifier loss: 0.329947; batch adversarial loss: 0.428607\n",
      "epoch 28; iter: 0; batch classifier loss: 0.341302; batch adversarial loss: 0.386153\n",
      "epoch 28; iter: 200; batch classifier loss: 0.335369; batch adversarial loss: 0.455857\n",
      "epoch 29; iter: 0; batch classifier loss: 0.346521; batch adversarial loss: 0.329418\n",
      "epoch 29; iter: 200; batch classifier loss: 0.386753; batch adversarial loss: 0.373307\n",
      "epoch 30; iter: 0; batch classifier loss: 0.259382; batch adversarial loss: 0.492470\n",
      "epoch 30; iter: 200; batch classifier loss: 0.412341; batch adversarial loss: 0.343736\n",
      "epoch 31; iter: 0; batch classifier loss: 0.356576; batch adversarial loss: 0.489148\n",
      "epoch 31; iter: 200; batch classifier loss: 0.301787; batch adversarial loss: 0.363150\n",
      "epoch 32; iter: 0; batch classifier loss: 0.314801; batch adversarial loss: 0.330818\n",
      "epoch 32; iter: 200; batch classifier loss: 0.309618; batch adversarial loss: 0.320668\n",
      "epoch 33; iter: 0; batch classifier loss: 0.312427; batch adversarial loss: 0.386577\n",
      "epoch 33; iter: 200; batch classifier loss: 0.542949; batch adversarial loss: 0.382547\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367369; batch adversarial loss: 0.427781\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338419; batch adversarial loss: 0.438118\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427063; batch adversarial loss: 0.430103\n",
      "epoch 35; iter: 200; batch classifier loss: 0.314678; batch adversarial loss: 0.333818\n",
      "epoch 36; iter: 0; batch classifier loss: 0.358273; batch adversarial loss: 0.337104\n",
      "epoch 36; iter: 200; batch classifier loss: 0.428971; batch adversarial loss: 0.445898\n",
      "epoch 37; iter: 0; batch classifier loss: 0.332662; batch adversarial loss: 0.338917\n",
      "epoch 37; iter: 200; batch classifier loss: 0.392502; batch adversarial loss: 0.371773\n",
      "epoch 38; iter: 0; batch classifier loss: 0.367742; batch adversarial loss: 0.515527\n",
      "epoch 38; iter: 200; batch classifier loss: 0.315055; batch adversarial loss: 0.437052\n",
      "epoch 39; iter: 0; batch classifier loss: 0.391704; batch adversarial loss: 0.361712\n",
      "epoch 39; iter: 200; batch classifier loss: 0.459579; batch adversarial loss: 0.457442\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394512; batch adversarial loss: 0.394874\n",
      "epoch 40; iter: 200; batch classifier loss: 0.351003; batch adversarial loss: 0.396174\n",
      "epoch 41; iter: 0; batch classifier loss: 0.280011; batch adversarial loss: 0.443669\n",
      "epoch 41; iter: 200; batch classifier loss: 0.399123; batch adversarial loss: 0.400510\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390218; batch adversarial loss: 0.391661\n",
      "epoch 42; iter: 200; batch classifier loss: 0.393956; batch adversarial loss: 0.377152\n",
      "epoch 43; iter: 0; batch classifier loss: 0.344996; batch adversarial loss: 0.372247\n",
      "epoch 43; iter: 200; batch classifier loss: 0.314380; batch adversarial loss: 0.346874\n",
      "epoch 44; iter: 0; batch classifier loss: 0.354575; batch adversarial loss: 0.438179\n",
      "epoch 44; iter: 200; batch classifier loss: 0.385429; batch adversarial loss: 0.390123\n",
      "epoch 45; iter: 0; batch classifier loss: 0.385210; batch adversarial loss: 0.361829\n",
      "epoch 45; iter: 200; batch classifier loss: 0.329710; batch adversarial loss: 0.406330\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324864; batch adversarial loss: 0.415401\n",
      "epoch 46; iter: 200; batch classifier loss: 0.288805; batch adversarial loss: 0.498776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457233; batch adversarial loss: 0.407762\n",
      "epoch 47; iter: 200; batch classifier loss: 0.339715; batch adversarial loss: 0.385655\n",
      "epoch 48; iter: 0; batch classifier loss: 0.373742; batch adversarial loss: 0.362314\n",
      "epoch 48; iter: 200; batch classifier loss: 0.432122; batch adversarial loss: 0.400383\n",
      "epoch 49; iter: 0; batch classifier loss: 0.535538; batch adversarial loss: 0.480427\n",
      "epoch 49; iter: 200; batch classifier loss: 0.219851; batch adversarial loss: 0.458527\n",
      "epoch 0; iter: 0; batch classifier loss: 14.922040; batch adversarial loss: 0.793422\n",
      "epoch 0; iter: 200; batch classifier loss: 7.699447; batch adversarial loss: 0.727923\n",
      "epoch 1; iter: 0; batch classifier loss: 7.504303; batch adversarial loss: 0.650074\n",
      "epoch 1; iter: 200; batch classifier loss: 7.207359; batch adversarial loss: 0.621862\n",
      "epoch 2; iter: 0; batch classifier loss: 0.417060; batch adversarial loss: 0.587662\n",
      "epoch 2; iter: 200; batch classifier loss: 2.121314; batch adversarial loss: 0.501936\n",
      "epoch 3; iter: 0; batch classifier loss: 2.253648; batch adversarial loss: 0.510018\n",
      "epoch 3; iter: 200; batch classifier loss: 0.981126; batch adversarial loss: 0.534736\n",
      "epoch 4; iter: 0; batch classifier loss: 0.867671; batch adversarial loss: 0.441352\n",
      "epoch 4; iter: 200; batch classifier loss: 1.241543; batch adversarial loss: 0.488228\n",
      "epoch 5; iter: 0; batch classifier loss: 0.366958; batch adversarial loss: 0.385551\n",
      "epoch 5; iter: 200; batch classifier loss: 0.704696; batch adversarial loss: 0.383531\n",
      "epoch 6; iter: 0; batch classifier loss: 5.579603; batch adversarial loss: 0.354627\n",
      "epoch 6; iter: 200; batch classifier loss: 0.338393; batch adversarial loss: 0.420667\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441735; batch adversarial loss: 0.370007\n",
      "epoch 7; iter: 200; batch classifier loss: 0.575492; batch adversarial loss: 0.439370\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577829; batch adversarial loss: 0.493626\n",
      "epoch 8; iter: 200; batch classifier loss: 0.465041; batch adversarial loss: 0.368257\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442175; batch adversarial loss: 0.427888\n",
      "epoch 9; iter: 200; batch classifier loss: 0.344035; batch adversarial loss: 0.466070\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578153; batch adversarial loss: 0.404680\n",
      "epoch 10; iter: 200; batch classifier loss: 0.430553; batch adversarial loss: 0.411036\n",
      "epoch 11; iter: 0; batch classifier loss: 0.785381; batch adversarial loss: 0.497534\n",
      "epoch 11; iter: 200; batch classifier loss: 0.434184; batch adversarial loss: 0.396902\n",
      "epoch 12; iter: 0; batch classifier loss: 0.422820; batch adversarial loss: 0.427571\n",
      "epoch 12; iter: 200; batch classifier loss: 0.402222; batch adversarial loss: 0.436537\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291436; batch adversarial loss: 0.510929\n",
      "epoch 13; iter: 200; batch classifier loss: 0.455472; batch adversarial loss: 0.478625\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280656; batch adversarial loss: 0.424584\n",
      "epoch 14; iter: 200; batch classifier loss: 0.328375; batch adversarial loss: 0.403430\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338924; batch adversarial loss: 0.297208\n",
      "epoch 15; iter: 200; batch classifier loss: 0.394354; batch adversarial loss: 0.363149\n",
      "epoch 16; iter: 0; batch classifier loss: 0.610127; batch adversarial loss: 0.547534\n",
      "epoch 16; iter: 200; batch classifier loss: 0.348762; batch adversarial loss: 0.446344\n",
      "epoch 17; iter: 0; batch classifier loss: 0.351080; batch adversarial loss: 0.392508\n",
      "epoch 17; iter: 200; batch classifier loss: 0.358676; batch adversarial loss: 0.432708\n",
      "epoch 18; iter: 0; batch classifier loss: 0.373079; batch adversarial loss: 0.468154\n",
      "epoch 18; iter: 200; batch classifier loss: 0.391497; batch adversarial loss: 0.428991\n",
      "epoch 19; iter: 0; batch classifier loss: 0.372454; batch adversarial loss: 0.486109\n",
      "epoch 19; iter: 200; batch classifier loss: 0.373787; batch adversarial loss: 0.428523\n",
      "epoch 20; iter: 0; batch classifier loss: 0.450340; batch adversarial loss: 0.389178\n",
      "epoch 20; iter: 200; batch classifier loss: 0.411883; batch adversarial loss: 0.335282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.385114; batch adversarial loss: 0.391948\n",
      "epoch 21; iter: 200; batch classifier loss: 0.375739; batch adversarial loss: 0.369194\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305053; batch adversarial loss: 0.488368\n",
      "epoch 22; iter: 200; batch classifier loss: 0.274330; batch adversarial loss: 0.408085\n",
      "epoch 23; iter: 0; batch classifier loss: 0.349445; batch adversarial loss: 0.347252\n",
      "epoch 23; iter: 200; batch classifier loss: 0.272700; batch adversarial loss: 0.463053\n",
      "epoch 24; iter: 0; batch classifier loss: 0.431583; batch adversarial loss: 0.377059\n",
      "epoch 24; iter: 200; batch classifier loss: 0.273935; batch adversarial loss: 0.397699\n",
      "epoch 25; iter: 0; batch classifier loss: 0.375943; batch adversarial loss: 0.312613\n",
      "epoch 25; iter: 200; batch classifier loss: 0.363998; batch adversarial loss: 0.398434\n",
      "epoch 26; iter: 0; batch classifier loss: 0.323494; batch adversarial loss: 0.373068\n",
      "epoch 26; iter: 200; batch classifier loss: 0.327634; batch adversarial loss: 0.380137\n",
      "epoch 27; iter: 0; batch classifier loss: 0.324715; batch adversarial loss: 0.431365\n",
      "epoch 27; iter: 200; batch classifier loss: 0.359242; batch adversarial loss: 0.374953\n",
      "epoch 28; iter: 0; batch classifier loss: 0.381352; batch adversarial loss: 0.349283\n",
      "epoch 28; iter: 200; batch classifier loss: 0.352166; batch adversarial loss: 0.445290\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323813; batch adversarial loss: 0.398337\n",
      "epoch 29; iter: 200; batch classifier loss: 0.359161; batch adversarial loss: 0.374847\n",
      "epoch 30; iter: 0; batch classifier loss: 0.373639; batch adversarial loss: 0.398667\n",
      "epoch 30; iter: 200; batch classifier loss: 0.315162; batch adversarial loss: 0.456320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.332690; batch adversarial loss: 0.394285\n",
      "epoch 31; iter: 200; batch classifier loss: 0.392004; batch adversarial loss: 0.444287\n",
      "epoch 32; iter: 0; batch classifier loss: 0.326053; batch adversarial loss: 0.383912\n",
      "epoch 32; iter: 200; batch classifier loss: 0.335160; batch adversarial loss: 0.434762\n",
      "epoch 33; iter: 0; batch classifier loss: 0.362023; batch adversarial loss: 0.546813\n",
      "epoch 33; iter: 200; batch classifier loss: 0.342285; batch adversarial loss: 0.353126\n",
      "epoch 34; iter: 0; batch classifier loss: 0.366037; batch adversarial loss: 0.438178\n",
      "epoch 34; iter: 200; batch classifier loss: 0.444138; batch adversarial loss: 0.351189\n",
      "epoch 35; iter: 0; batch classifier loss: 0.387226; batch adversarial loss: 0.388948\n",
      "epoch 35; iter: 200; batch classifier loss: 0.417413; batch adversarial loss: 0.507301\n",
      "epoch 36; iter: 0; batch classifier loss: 0.337865; batch adversarial loss: 0.413988\n",
      "epoch 36; iter: 200; batch classifier loss: 0.435993; batch adversarial loss: 0.429989\n",
      "epoch 37; iter: 0; batch classifier loss: 0.281751; batch adversarial loss: 0.487349\n",
      "epoch 37; iter: 200; batch classifier loss: 0.322815; batch adversarial loss: 0.464630\n",
      "epoch 38; iter: 0; batch classifier loss: 0.316911; batch adversarial loss: 0.402687\n",
      "epoch 38; iter: 200; batch classifier loss: 0.320570; batch adversarial loss: 0.476761\n",
      "epoch 39; iter: 0; batch classifier loss: 0.370530; batch adversarial loss: 0.516245\n",
      "epoch 39; iter: 200; batch classifier loss: 0.465149; batch adversarial loss: 0.374036\n",
      "epoch 40; iter: 0; batch classifier loss: 0.450714; batch adversarial loss: 0.496512\n",
      "epoch 40; iter: 200; batch classifier loss: 0.300706; batch adversarial loss: 0.374428\n",
      "epoch 41; iter: 0; batch classifier loss: 0.372631; batch adversarial loss: 0.393561\n",
      "epoch 41; iter: 200; batch classifier loss: 0.363588; batch adversarial loss: 0.412663\n",
      "epoch 42; iter: 0; batch classifier loss: 0.416413; batch adversarial loss: 0.400527\n",
      "epoch 42; iter: 200; batch classifier loss: 0.363332; batch adversarial loss: 0.397599\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451600; batch adversarial loss: 0.416219\n",
      "epoch 43; iter: 200; batch classifier loss: 0.411663; batch adversarial loss: 0.391809\n",
      "epoch 44; iter: 0; batch classifier loss: 0.370074; batch adversarial loss: 0.345249\n",
      "epoch 44; iter: 200; batch classifier loss: 0.414884; batch adversarial loss: 0.442268\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422015; batch adversarial loss: 0.488375\n",
      "epoch 45; iter: 200; batch classifier loss: 0.424898; batch adversarial loss: 0.402610\n",
      "epoch 46; iter: 0; batch classifier loss: 0.376932; batch adversarial loss: 0.499799\n",
      "epoch 46; iter: 200; batch classifier loss: 0.365718; batch adversarial loss: 0.474282\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373984; batch adversarial loss: 0.459818\n",
      "epoch 47; iter: 200; batch classifier loss: 0.553346; batch adversarial loss: 0.336058\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407184; batch adversarial loss: 0.370940\n",
      "epoch 48; iter: 200; batch classifier loss: 0.408270; batch adversarial loss: 0.444986\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394488; batch adversarial loss: 0.495365\n",
      "epoch 49; iter: 200; batch classifier loss: 0.451707; batch adversarial loss: 0.419141\n",
      "epoch 0; iter: 0; batch classifier loss: 65.742981; batch adversarial loss: 0.697042\n",
      "epoch 0; iter: 200; batch classifier loss: 6.601594; batch adversarial loss: 0.585994\n",
      "epoch 1; iter: 0; batch classifier loss: 5.607629; batch adversarial loss: 0.587536\n",
      "epoch 1; iter: 200; batch classifier loss: 2.679353; batch adversarial loss: 0.517479\n",
      "epoch 2; iter: 0; batch classifier loss: 2.140819; batch adversarial loss: 0.502150\n",
      "epoch 2; iter: 200; batch classifier loss: 6.713581; batch adversarial loss: 0.489477\n",
      "epoch 3; iter: 0; batch classifier loss: 3.529954; batch adversarial loss: 0.497453\n",
      "epoch 3; iter: 200; batch classifier loss: 3.191613; batch adversarial loss: 0.483290\n",
      "epoch 4; iter: 0; batch classifier loss: 1.512652; batch adversarial loss: 0.416609\n",
      "epoch 4; iter: 200; batch classifier loss: 1.651578; batch adversarial loss: 0.453537\n",
      "epoch 5; iter: 0; batch classifier loss: 0.705632; batch adversarial loss: 0.432026\n",
      "epoch 5; iter: 200; batch classifier loss: 0.528425; batch adversarial loss: 0.510919\n",
      "epoch 6; iter: 0; batch classifier loss: 0.990984; batch adversarial loss: 0.475477\n",
      "epoch 6; iter: 200; batch classifier loss: 0.442661; batch adversarial loss: 0.368716\n",
      "epoch 7; iter: 0; batch classifier loss: 0.659955; batch adversarial loss: 0.411456\n",
      "epoch 7; iter: 200; batch classifier loss: 0.533164; batch adversarial loss: 0.448122\n",
      "epoch 8; iter: 0; batch classifier loss: 0.389092; batch adversarial loss: 0.442120\n",
      "epoch 8; iter: 200; batch classifier loss: 0.498184; batch adversarial loss: 0.394096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.411084; batch adversarial loss: 0.457379\n",
      "epoch 9; iter: 200; batch classifier loss: 0.414929; batch adversarial loss: 0.440902\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341356; batch adversarial loss: 0.382469\n",
      "epoch 10; iter: 200; batch classifier loss: 0.380937; batch adversarial loss: 0.427928\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369208; batch adversarial loss: 0.411750\n",
      "epoch 11; iter: 200; batch classifier loss: 0.474807; batch adversarial loss: 0.400925\n",
      "epoch 12; iter: 0; batch classifier loss: 0.611292; batch adversarial loss: 0.529284\n",
      "epoch 12; iter: 200; batch classifier loss: 0.313126; batch adversarial loss: 0.464300\n",
      "epoch 13; iter: 0; batch classifier loss: 0.829801; batch adversarial loss: 0.334009\n",
      "epoch 13; iter: 200; batch classifier loss: 0.483303; batch adversarial loss: 0.351871\n",
      "epoch 14; iter: 0; batch classifier loss: 0.417867; batch adversarial loss: 0.430216\n",
      "epoch 14; iter: 200; batch classifier loss: 0.326071; batch adversarial loss: 0.503532\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401102; batch adversarial loss: 0.372093\n",
      "epoch 15; iter: 200; batch classifier loss: 0.508710; batch adversarial loss: 0.471319\n",
      "epoch 16; iter: 0; batch classifier loss: 0.316451; batch adversarial loss: 0.426685\n",
      "epoch 16; iter: 200; batch classifier loss: 0.301880; batch adversarial loss: 0.416435\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332547; batch adversarial loss: 0.405243\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346446; batch adversarial loss: 0.403126\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314368; batch adversarial loss: 0.402071\n",
      "epoch 18; iter: 200; batch classifier loss: 0.374330; batch adversarial loss: 0.450751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278922; batch adversarial loss: 0.375764\n",
      "epoch 19; iter: 200; batch classifier loss: 0.375946; batch adversarial loss: 0.376284\n",
      "epoch 20; iter: 0; batch classifier loss: 0.341205; batch adversarial loss: 0.503513\n",
      "epoch 20; iter: 200; batch classifier loss: 0.348483; batch adversarial loss: 0.435234\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372706; batch adversarial loss: 0.397968\n",
      "epoch 21; iter: 200; batch classifier loss: 0.391172; batch adversarial loss: 0.369763\n",
      "epoch 22; iter: 0; batch classifier loss: 0.325291; batch adversarial loss: 0.341529\n",
      "epoch 22; iter: 200; batch classifier loss: 0.252387; batch adversarial loss: 0.388301\n",
      "epoch 23; iter: 0; batch classifier loss: 0.323872; batch adversarial loss: 0.449128\n",
      "epoch 23; iter: 200; batch classifier loss: 0.397259; batch adversarial loss: 0.446908\n",
      "epoch 24; iter: 0; batch classifier loss: 0.306364; batch adversarial loss: 0.353675\n",
      "epoch 24; iter: 200; batch classifier loss: 0.329844; batch adversarial loss: 0.412533\n",
      "epoch 25; iter: 0; batch classifier loss: 0.222211; batch adversarial loss: 0.433220\n",
      "epoch 25; iter: 200; batch classifier loss: 0.275349; batch adversarial loss: 0.379320\n",
      "epoch 26; iter: 0; batch classifier loss: 0.305741; batch adversarial loss: 0.344084\n",
      "epoch 26; iter: 200; batch classifier loss: 0.275456; batch adversarial loss: 0.504432\n",
      "epoch 27; iter: 0; batch classifier loss: 0.370413; batch adversarial loss: 0.368139\n",
      "epoch 27; iter: 200; batch classifier loss: 0.366436; batch adversarial loss: 0.496311\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241260; batch adversarial loss: 0.376356\n",
      "epoch 28; iter: 200; batch classifier loss: 0.363019; batch adversarial loss: 0.407445\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394189; batch adversarial loss: 0.399719\n",
      "epoch 29; iter: 200; batch classifier loss: 0.315239; batch adversarial loss: 0.497480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.313100; batch adversarial loss: 0.403574\n",
      "epoch 30; iter: 200; batch classifier loss: 0.381669; batch adversarial loss: 0.409272\n",
      "epoch 31; iter: 0; batch classifier loss: 0.258611; batch adversarial loss: 0.455027\n",
      "epoch 31; iter: 200; batch classifier loss: 0.314366; batch adversarial loss: 0.509522\n",
      "epoch 32; iter: 0; batch classifier loss: 0.350400; batch adversarial loss: 0.390895\n",
      "epoch 32; iter: 200; batch classifier loss: 0.334741; batch adversarial loss: 0.371127\n",
      "epoch 33; iter: 0; batch classifier loss: 0.324864; batch adversarial loss: 0.381251\n",
      "epoch 33; iter: 200; batch classifier loss: 0.383314; batch adversarial loss: 0.523992\n",
      "epoch 34; iter: 0; batch classifier loss: 0.357938; batch adversarial loss: 0.435043\n",
      "epoch 34; iter: 200; batch classifier loss: 0.318681; batch adversarial loss: 0.310576\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376451; batch adversarial loss: 0.344423\n",
      "epoch 35; iter: 200; batch classifier loss: 0.328828; batch adversarial loss: 0.474493\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360154; batch adversarial loss: 0.411083\n",
      "epoch 36; iter: 200; batch classifier loss: 0.389667; batch adversarial loss: 0.410847\n",
      "epoch 37; iter: 0; batch classifier loss: 0.273664; batch adversarial loss: 0.411668\n",
      "epoch 37; iter: 200; batch classifier loss: 0.432851; batch adversarial loss: 0.491972\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417605; batch adversarial loss: 0.460694\n",
      "epoch 38; iter: 200; batch classifier loss: 0.313578; batch adversarial loss: 0.439722\n",
      "epoch 39; iter: 0; batch classifier loss: 0.207782; batch adversarial loss: 0.322924\n",
      "epoch 39; iter: 200; batch classifier loss: 0.331072; batch adversarial loss: 0.445945\n",
      "epoch 40; iter: 0; batch classifier loss: 0.325220; batch adversarial loss: 0.381599\n",
      "epoch 40; iter: 200; batch classifier loss: 0.348022; batch adversarial loss: 0.477195\n",
      "epoch 41; iter: 0; batch classifier loss: 0.312471; batch adversarial loss: 0.318972\n",
      "epoch 41; iter: 200; batch classifier loss: 0.305961; batch adversarial loss: 0.458248\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365169; batch adversarial loss: 0.377581\n",
      "epoch 42; iter: 200; batch classifier loss: 0.365265; batch adversarial loss: 0.388773\n",
      "epoch 43; iter: 0; batch classifier loss: 0.341229; batch adversarial loss: 0.290209\n",
      "epoch 43; iter: 200; batch classifier loss: 0.299228; batch adversarial loss: 0.410620\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394574; batch adversarial loss: 0.393115\n",
      "epoch 44; iter: 200; batch classifier loss: 0.532930; batch adversarial loss: 0.426923\n",
      "epoch 45; iter: 0; batch classifier loss: 0.304396; batch adversarial loss: 0.359464\n",
      "epoch 45; iter: 200; batch classifier loss: 0.287968; batch adversarial loss: 0.346536\n",
      "epoch 46; iter: 0; batch classifier loss: 0.394064; batch adversarial loss: 0.440332\n",
      "epoch 46; iter: 200; batch classifier loss: 0.343289; batch adversarial loss: 0.469927\n",
      "epoch 47; iter: 0; batch classifier loss: 0.293990; batch adversarial loss: 0.411102\n",
      "epoch 47; iter: 200; batch classifier loss: 0.279466; batch adversarial loss: 0.352213\n",
      "epoch 48; iter: 0; batch classifier loss: 0.332564; batch adversarial loss: 0.461251\n",
      "epoch 48; iter: 200; batch classifier loss: 0.316533; batch adversarial loss: 0.293951\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437003; batch adversarial loss: 0.361712\n",
      "epoch 49; iter: 200; batch classifier loss: 0.337669; batch adversarial loss: 0.430157\n",
      "epoch 0; iter: 0; batch classifier loss: 15.840536; batch adversarial loss: 0.685719\n",
      "epoch 0; iter: 200; batch classifier loss: 11.684188; batch adversarial loss: 0.598898\n",
      "epoch 1; iter: 0; batch classifier loss: 1.044115; batch adversarial loss: 0.583994\n",
      "epoch 1; iter: 200; batch classifier loss: 5.309694; batch adversarial loss: 0.518744\n",
      "epoch 2; iter: 0; batch classifier loss: 2.210630; batch adversarial loss: 0.524797\n",
      "epoch 2; iter: 200; batch classifier loss: 4.019298; batch adversarial loss: 0.516426\n",
      "epoch 3; iter: 0; batch classifier loss: 2.230918; batch adversarial loss: 0.436385\n",
      "epoch 3; iter: 200; batch classifier loss: 1.683794; batch adversarial loss: 0.471067\n",
      "epoch 4; iter: 0; batch classifier loss: 2.216363; batch adversarial loss: 0.488028\n",
      "epoch 4; iter: 200; batch classifier loss: 1.904013; batch adversarial loss: 0.480356\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550399; batch adversarial loss: 0.461172\n",
      "epoch 5; iter: 200; batch classifier loss: 0.323653; batch adversarial loss: 0.394214\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513022; batch adversarial loss: 0.462126\n",
      "epoch 6; iter: 200; batch classifier loss: 0.354947; batch adversarial loss: 0.415400\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497953; batch adversarial loss: 0.414220\n",
      "epoch 7; iter: 200; batch classifier loss: 0.659188; batch adversarial loss: 0.426716\n",
      "epoch 8; iter: 0; batch classifier loss: 0.423922; batch adversarial loss: 0.391921\n",
      "epoch 8; iter: 200; batch classifier loss: 0.394488; batch adversarial loss: 0.435555\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364843; batch adversarial loss: 0.345038\n",
      "epoch 9; iter: 200; batch classifier loss: 0.364682; batch adversarial loss: 0.404512\n",
      "epoch 10; iter: 0; batch classifier loss: 0.895652; batch adversarial loss: 0.348735\n",
      "epoch 10; iter: 200; batch classifier loss: 0.367684; batch adversarial loss: 0.502307\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329003; batch adversarial loss: 0.469877\n",
      "epoch 11; iter: 200; batch classifier loss: 0.431584; batch adversarial loss: 0.422838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381078; batch adversarial loss: 0.402171\n",
      "epoch 12; iter: 200; batch classifier loss: 0.241159; batch adversarial loss: 0.340727\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321374; batch adversarial loss: 0.455077\n",
      "epoch 13; iter: 200; batch classifier loss: 0.286340; batch adversarial loss: 0.407086\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352461; batch adversarial loss: 0.331823\n",
      "epoch 14; iter: 200; batch classifier loss: 0.457323; batch adversarial loss: 0.359312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364469; batch adversarial loss: 0.409656\n",
      "epoch 15; iter: 200; batch classifier loss: 0.460461; batch adversarial loss: 0.425265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323736; batch adversarial loss: 0.404570\n",
      "epoch 16; iter: 200; batch classifier loss: 0.377578; batch adversarial loss: 0.468065\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333662; batch adversarial loss: 0.459219\n",
      "epoch 17; iter: 200; batch classifier loss: 0.353418; batch adversarial loss: 0.505000\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306480; batch adversarial loss: 0.412792\n",
      "epoch 18; iter: 200; batch classifier loss: 0.290236; batch adversarial loss: 0.559129\n",
      "epoch 19; iter: 0; batch classifier loss: 0.263877; batch adversarial loss: 0.412146\n",
      "epoch 19; iter: 200; batch classifier loss: 0.273861; batch adversarial loss: 0.429656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.345783; batch adversarial loss: 0.345291\n",
      "epoch 20; iter: 200; batch classifier loss: 0.350566; batch adversarial loss: 0.403665\n",
      "epoch 21; iter: 0; batch classifier loss: 0.361128; batch adversarial loss: 0.349378\n",
      "epoch 21; iter: 200; batch classifier loss: 0.270327; batch adversarial loss: 0.401974\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415350; batch adversarial loss: 0.448337\n",
      "epoch 22; iter: 200; batch classifier loss: 0.377335; batch adversarial loss: 0.476542\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344078; batch adversarial loss: 0.386115\n",
      "epoch 23; iter: 200; batch classifier loss: 0.415744; batch adversarial loss: 0.418323\n",
      "epoch 24; iter: 0; batch classifier loss: 0.380815; batch adversarial loss: 0.371570\n",
      "epoch 24; iter: 200; batch classifier loss: 0.329359; batch adversarial loss: 0.414322\n",
      "epoch 25; iter: 0; batch classifier loss: 0.383109; batch adversarial loss: 0.276534\n",
      "epoch 25; iter: 200; batch classifier loss: 0.345469; batch adversarial loss: 0.445530\n",
      "epoch 26; iter: 0; batch classifier loss: 0.376816; batch adversarial loss: 0.429255\n",
      "epoch 26; iter: 200; batch classifier loss: 0.436967; batch adversarial loss: 0.356596\n",
      "epoch 27; iter: 0; batch classifier loss: 0.317423; batch adversarial loss: 0.397113\n",
      "epoch 27; iter: 200; batch classifier loss: 0.414178; batch adversarial loss: 0.465420\n",
      "epoch 28; iter: 0; batch classifier loss: 0.347144; batch adversarial loss: 0.389060\n",
      "epoch 28; iter: 200; batch classifier loss: 0.343103; batch adversarial loss: 0.392927\n",
      "epoch 29; iter: 0; batch classifier loss: 0.367968; batch adversarial loss: 0.389274\n",
      "epoch 29; iter: 200; batch classifier loss: 0.314852; batch adversarial loss: 0.525082\n",
      "epoch 30; iter: 0; batch classifier loss: 0.286179; batch adversarial loss: 0.288953\n",
      "epoch 30; iter: 200; batch classifier loss: 0.439492; batch adversarial loss: 0.335099\n",
      "epoch 31; iter: 0; batch classifier loss: 0.476196; batch adversarial loss: 0.442901\n",
      "epoch 31; iter: 200; batch classifier loss: 0.357016; batch adversarial loss: 0.350458\n",
      "epoch 32; iter: 0; batch classifier loss: 0.357865; batch adversarial loss: 0.469822\n",
      "epoch 32; iter: 200; batch classifier loss: 0.387416; batch adversarial loss: 0.399602\n",
      "epoch 33; iter: 0; batch classifier loss: 0.311464; batch adversarial loss: 0.365313\n",
      "epoch 33; iter: 200; batch classifier loss: 0.340478; batch adversarial loss: 0.410332\n",
      "epoch 34; iter: 0; batch classifier loss: 0.273713; batch adversarial loss: 0.437075\n",
      "epoch 34; iter: 200; batch classifier loss: 0.312964; batch adversarial loss: 0.442242\n",
      "epoch 35; iter: 0; batch classifier loss: 0.288626; batch adversarial loss: 0.426196\n",
      "epoch 35; iter: 200; batch classifier loss: 0.402903; batch adversarial loss: 0.435529\n",
      "epoch 36; iter: 0; batch classifier loss: 0.413515; batch adversarial loss: 0.381874\n",
      "epoch 36; iter: 200; batch classifier loss: 0.239949; batch adversarial loss: 0.438910\n",
      "epoch 37; iter: 0; batch classifier loss: 0.379065; batch adversarial loss: 0.384261\n",
      "epoch 37; iter: 200; batch classifier loss: 0.319473; batch adversarial loss: 0.487372\n",
      "epoch 38; iter: 0; batch classifier loss: 0.264814; batch adversarial loss: 0.398154\n",
      "epoch 38; iter: 200; batch classifier loss: 0.420980; batch adversarial loss: 0.348471\n",
      "epoch 39; iter: 0; batch classifier loss: 0.336011; batch adversarial loss: 0.391673\n",
      "epoch 39; iter: 200; batch classifier loss: 0.299161; batch adversarial loss: 0.375891\n",
      "epoch 40; iter: 0; batch classifier loss: 0.318446; batch adversarial loss: 0.282443\n",
      "epoch 40; iter: 200; batch classifier loss: 0.337307; batch adversarial loss: 0.279122\n",
      "epoch 41; iter: 0; batch classifier loss: 0.412439; batch adversarial loss: 0.441298\n",
      "epoch 41; iter: 200; batch classifier loss: 0.238753; batch adversarial loss: 0.483235\n",
      "epoch 42; iter: 0; batch classifier loss: 0.302503; batch adversarial loss: 0.471023\n",
      "epoch 42; iter: 200; batch classifier loss: 0.346702; batch adversarial loss: 0.374426\n",
      "epoch 43; iter: 0; batch classifier loss: 0.285882; batch adversarial loss: 0.331007\n",
      "epoch 43; iter: 200; batch classifier loss: 0.334946; batch adversarial loss: 0.468885\n",
      "epoch 44; iter: 0; batch classifier loss: 0.353956; batch adversarial loss: 0.446155\n",
      "epoch 44; iter: 200; batch classifier loss: 0.272053; batch adversarial loss: 0.433010\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441433; batch adversarial loss: 0.415544\n",
      "epoch 45; iter: 200; batch classifier loss: 0.323065; batch adversarial loss: 0.349579\n",
      "epoch 46; iter: 0; batch classifier loss: 0.309100; batch adversarial loss: 0.374369\n",
      "epoch 46; iter: 200; batch classifier loss: 0.368689; batch adversarial loss: 0.441256\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357925; batch adversarial loss: 0.347199\n",
      "epoch 47; iter: 200; batch classifier loss: 0.366876; batch adversarial loss: 0.376054\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451017; batch adversarial loss: 0.348686\n",
      "epoch 48; iter: 200; batch classifier loss: 0.351986; batch adversarial loss: 0.462680\n",
      "epoch 49; iter: 0; batch classifier loss: 0.321539; batch adversarial loss: 0.379608\n",
      "epoch 49; iter: 200; batch classifier loss: 0.375820; batch adversarial loss: 0.380985\n",
      "epoch 0; iter: 0; batch classifier loss: 15.181112; batch adversarial loss: 0.500993\n",
      "epoch 0; iter: 200; batch classifier loss: 1.872786; batch adversarial loss: 0.583112\n",
      "epoch 1; iter: 0; batch classifier loss: 10.868498; batch adversarial loss: 0.589883\n",
      "epoch 1; iter: 200; batch classifier loss: 3.100141; batch adversarial loss: 0.556756\n",
      "epoch 2; iter: 0; batch classifier loss: 4.855075; batch adversarial loss: 0.506709\n",
      "epoch 2; iter: 200; batch classifier loss: 0.802731; batch adversarial loss: 0.411596\n",
      "epoch 3; iter: 0; batch classifier loss: 4.008109; batch adversarial loss: 0.447960\n",
      "epoch 3; iter: 200; batch classifier loss: 2.969278; batch adversarial loss: 0.443390\n",
      "epoch 4; iter: 0; batch classifier loss: 0.888610; batch adversarial loss: 0.458871\n",
      "epoch 4; iter: 200; batch classifier loss: 1.306967; batch adversarial loss: 0.529658\n",
      "epoch 5; iter: 0; batch classifier loss: 1.035979; batch adversarial loss: 0.431376\n",
      "epoch 5; iter: 200; batch classifier loss: 0.769522; batch adversarial loss: 0.479167\n",
      "epoch 6; iter: 0; batch classifier loss: 0.627044; batch adversarial loss: 0.403564\n",
      "epoch 6; iter: 200; batch classifier loss: 0.761506; batch adversarial loss: 0.383568\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541951; batch adversarial loss: 0.381019\n",
      "epoch 7; iter: 200; batch classifier loss: 0.437176; batch adversarial loss: 0.411473\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532138; batch adversarial loss: 0.455929\n",
      "epoch 8; iter: 200; batch classifier loss: 0.302001; batch adversarial loss: 0.467346\n",
      "epoch 9; iter: 0; batch classifier loss: 0.441359; batch adversarial loss: 0.464571\n",
      "epoch 9; iter: 200; batch classifier loss: 0.728248; batch adversarial loss: 0.513358\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339749; batch adversarial loss: 0.365274\n",
      "epoch 10; iter: 200; batch classifier loss: 0.360174; batch adversarial loss: 0.446237\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574838; batch adversarial loss: 0.420343\n",
      "epoch 11; iter: 200; batch classifier loss: 0.548548; batch adversarial loss: 0.397746\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448594; batch adversarial loss: 0.393244\n",
      "epoch 12; iter: 200; batch classifier loss: 0.405183; batch adversarial loss: 0.456490\n",
      "epoch 13; iter: 0; batch classifier loss: 0.376762; batch adversarial loss: 0.335219\n",
      "epoch 13; iter: 200; batch classifier loss: 0.369886; batch adversarial loss: 0.445183\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409626; batch adversarial loss: 0.360030\n",
      "epoch 14; iter: 200; batch classifier loss: 0.297956; batch adversarial loss: 0.406995\n",
      "epoch 15; iter: 0; batch classifier loss: 0.402349; batch adversarial loss: 0.455848\n",
      "epoch 15; iter: 200; batch classifier loss: 0.339189; batch adversarial loss: 0.466154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.397685; batch adversarial loss: 0.470984\n",
      "epoch 16; iter: 200; batch classifier loss: 0.367686; batch adversarial loss: 0.412825\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364238; batch adversarial loss: 0.365695\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339685; batch adversarial loss: 0.345725\n",
      "epoch 18; iter: 0; batch classifier loss: 0.318093; batch adversarial loss: 0.492638\n",
      "epoch 18; iter: 200; batch classifier loss: 0.325662; batch adversarial loss: 0.458824\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310515; batch adversarial loss: 0.457961\n",
      "epoch 19; iter: 200; batch classifier loss: 0.345712; batch adversarial loss: 0.421857\n",
      "epoch 20; iter: 0; batch classifier loss: 0.545401; batch adversarial loss: 0.374811\n",
      "epoch 20; iter: 200; batch classifier loss: 0.383516; batch adversarial loss: 0.435257\n",
      "epoch 21; iter: 0; batch classifier loss: 0.303205; batch adversarial loss: 0.363504\n",
      "epoch 21; iter: 200; batch classifier loss: 0.346480; batch adversarial loss: 0.409922\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291518; batch adversarial loss: 0.446999\n",
      "epoch 22; iter: 200; batch classifier loss: 0.319952; batch adversarial loss: 0.447756\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322232; batch adversarial loss: 0.477758\n",
      "epoch 23; iter: 200; batch classifier loss: 0.362597; batch adversarial loss: 0.346356\n",
      "epoch 24; iter: 0; batch classifier loss: 0.299327; batch adversarial loss: 0.565883\n",
      "epoch 24; iter: 200; batch classifier loss: 0.351535; batch adversarial loss: 0.415006\n",
      "epoch 25; iter: 0; batch classifier loss: 0.347540; batch adversarial loss: 0.469726\n",
      "epoch 25; iter: 200; batch classifier loss: 0.322908; batch adversarial loss: 0.439086\n",
      "epoch 26; iter: 0; batch classifier loss: 0.325345; batch adversarial loss: 0.396716\n",
      "epoch 26; iter: 200; batch classifier loss: 0.420678; batch adversarial loss: 0.373907\n",
      "epoch 27; iter: 0; batch classifier loss: 0.300744; batch adversarial loss: 0.385229\n",
      "epoch 27; iter: 200; batch classifier loss: 0.392609; batch adversarial loss: 0.379586\n",
      "epoch 28; iter: 0; batch classifier loss: 0.395974; batch adversarial loss: 0.349306\n",
      "epoch 28; iter: 200; batch classifier loss: 0.258284; batch adversarial loss: 0.446026\n",
      "epoch 29; iter: 0; batch classifier loss: 0.340353; batch adversarial loss: 0.421319\n",
      "epoch 29; iter: 200; batch classifier loss: 0.327222; batch adversarial loss: 0.466266\n",
      "epoch 30; iter: 0; batch classifier loss: 0.288851; batch adversarial loss: 0.387612\n",
      "epoch 30; iter: 200; batch classifier loss: 0.299922; batch adversarial loss: 0.389901\n",
      "epoch 31; iter: 0; batch classifier loss: 0.324115; batch adversarial loss: 0.420932\n",
      "epoch 31; iter: 200; batch classifier loss: 0.323936; batch adversarial loss: 0.496907\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329963; batch adversarial loss: 0.444619\n",
      "epoch 32; iter: 200; batch classifier loss: 0.317202; batch adversarial loss: 0.568115\n",
      "epoch 33; iter: 0; batch classifier loss: 0.374425; batch adversarial loss: 0.432506\n",
      "epoch 33; iter: 200; batch classifier loss: 0.338525; batch adversarial loss: 0.565662\n",
      "epoch 34; iter: 0; batch classifier loss: 0.281544; batch adversarial loss: 0.438801\n",
      "epoch 34; iter: 200; batch classifier loss: 0.502076; batch adversarial loss: 0.441617\n",
      "epoch 35; iter: 0; batch classifier loss: 0.310866; batch adversarial loss: 0.419507\n",
      "epoch 35; iter: 200; batch classifier loss: 0.396503; batch adversarial loss: 0.389564\n",
      "epoch 36; iter: 0; batch classifier loss: 0.275071; batch adversarial loss: 0.445735\n",
      "epoch 36; iter: 200; batch classifier loss: 0.298254; batch adversarial loss: 0.322210\n",
      "epoch 37; iter: 0; batch classifier loss: 0.333156; batch adversarial loss: 0.462614\n",
      "epoch 37; iter: 200; batch classifier loss: 0.298128; batch adversarial loss: 0.393362\n",
      "epoch 38; iter: 0; batch classifier loss: 0.370081; batch adversarial loss: 0.442190\n",
      "epoch 38; iter: 200; batch classifier loss: 0.430067; batch adversarial loss: 0.267223\n",
      "epoch 39; iter: 0; batch classifier loss: 0.294254; batch adversarial loss: 0.351712\n",
      "epoch 39; iter: 200; batch classifier loss: 0.428402; batch adversarial loss: 0.486096\n",
      "epoch 40; iter: 0; batch classifier loss: 0.325621; batch adversarial loss: 0.389728\n",
      "epoch 40; iter: 200; batch classifier loss: 0.305765; batch adversarial loss: 0.360965\n",
      "epoch 41; iter: 0; batch classifier loss: 0.230550; batch adversarial loss: 0.441236\n",
      "epoch 41; iter: 200; batch classifier loss: 0.230472; batch adversarial loss: 0.381631\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409899; batch adversarial loss: 0.430397\n",
      "epoch 42; iter: 200; batch classifier loss: 0.320762; batch adversarial loss: 0.489125\n",
      "epoch 43; iter: 0; batch classifier loss: 0.317811; batch adversarial loss: 0.480697\n",
      "epoch 43; iter: 200; batch classifier loss: 0.351198; batch adversarial loss: 0.376450\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395717; batch adversarial loss: 0.318757\n",
      "epoch 44; iter: 200; batch classifier loss: 0.417891; batch adversarial loss: 0.401978\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389684; batch adversarial loss: 0.463884\n",
      "epoch 45; iter: 200; batch classifier loss: 0.307710; batch adversarial loss: 0.409069\n",
      "epoch 46; iter: 0; batch classifier loss: 0.325119; batch adversarial loss: 0.440631\n",
      "epoch 46; iter: 200; batch classifier loss: 0.314285; batch adversarial loss: 0.474814\n",
      "epoch 47; iter: 0; batch classifier loss: 0.322944; batch adversarial loss: 0.371127\n",
      "epoch 47; iter: 200; batch classifier loss: 0.324540; batch adversarial loss: 0.349339\n",
      "epoch 48; iter: 0; batch classifier loss: 0.312261; batch adversarial loss: 0.420875\n",
      "epoch 48; iter: 200; batch classifier loss: 0.295156; batch adversarial loss: 0.406006\n",
      "epoch 49; iter: 0; batch classifier loss: 0.312318; batch adversarial loss: 0.428097\n",
      "epoch 49; iter: 200; batch classifier loss: 0.338730; batch adversarial loss: 0.335383\n",
      "epoch 0; iter: 0; batch classifier loss: 268.963013; batch adversarial loss: 0.519082\n",
      "epoch 0; iter: 200; batch classifier loss: 15.163244; batch adversarial loss: 0.635192\n",
      "epoch 1; iter: 0; batch classifier loss: 11.665131; batch adversarial loss: 0.571452\n",
      "epoch 1; iter: 200; batch classifier loss: 5.723105; batch adversarial loss: 0.535396\n",
      "epoch 2; iter: 0; batch classifier loss: 8.709270; batch adversarial loss: 0.496708\n",
      "epoch 2; iter: 200; batch classifier loss: 2.389577; batch adversarial loss: 0.440857\n",
      "epoch 3; iter: 0; batch classifier loss: 2.651845; batch adversarial loss: 0.438316\n",
      "epoch 3; iter: 200; batch classifier loss: 6.029131; batch adversarial loss: 0.424498\n",
      "epoch 4; iter: 0; batch classifier loss: 1.410483; batch adversarial loss: 0.472432\n",
      "epoch 4; iter: 200; batch classifier loss: 1.722852; batch adversarial loss: 0.438097\n",
      "epoch 5; iter: 0; batch classifier loss: 1.593226; batch adversarial loss: 0.433372\n",
      "epoch 5; iter: 200; batch classifier loss: 1.180629; batch adversarial loss: 0.530235\n",
      "epoch 6; iter: 0; batch classifier loss: 0.883665; batch adversarial loss: 0.365123\n",
      "epoch 6; iter: 200; batch classifier loss: 1.366716; batch adversarial loss: 0.430883\n",
      "epoch 7; iter: 0; batch classifier loss: 0.386861; batch adversarial loss: 0.412348\n",
      "epoch 7; iter: 200; batch classifier loss: 0.724043; batch adversarial loss: 0.390836\n",
      "epoch 8; iter: 0; batch classifier loss: 0.863015; batch adversarial loss: 0.417759\n",
      "epoch 8; iter: 200; batch classifier loss: 0.602824; batch adversarial loss: 0.488576\n",
      "epoch 9; iter: 0; batch classifier loss: 0.424939; batch adversarial loss: 0.447461\n",
      "epoch 9; iter: 200; batch classifier loss: 0.411785; batch adversarial loss: 0.416970\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339273; batch adversarial loss: 0.364280\n",
      "epoch 10; iter: 200; batch classifier loss: 0.387717; batch adversarial loss: 0.402972\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420037; batch adversarial loss: 0.389003\n",
      "epoch 11; iter: 200; batch classifier loss: 2.235538; batch adversarial loss: 0.311120\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469131; batch adversarial loss: 0.389038\n",
      "epoch 12; iter: 200; batch classifier loss: 0.328179; batch adversarial loss: 0.399763\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331190; batch adversarial loss: 0.509173\n",
      "epoch 13; iter: 200; batch classifier loss: 0.350234; batch adversarial loss: 0.487675\n",
      "epoch 14; iter: 0; batch classifier loss: 0.778988; batch adversarial loss: 0.470217\n",
      "epoch 14; iter: 200; batch classifier loss: 1.038104; batch adversarial loss: 0.385836\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371785; batch adversarial loss: 0.361726\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333056; batch adversarial loss: 0.348472\n",
      "epoch 16; iter: 0; batch classifier loss: 0.343814; batch adversarial loss: 0.375863\n",
      "epoch 16; iter: 200; batch classifier loss: 0.278791; batch adversarial loss: 0.364083\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330196; batch adversarial loss: 0.437403\n",
      "epoch 17; iter: 200; batch classifier loss: 0.344045; batch adversarial loss: 0.516854\n",
      "epoch 18; iter: 0; batch classifier loss: 0.310264; batch adversarial loss: 0.500331\n",
      "epoch 18; iter: 200; batch classifier loss: 0.398211; batch adversarial loss: 0.419882\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313218; batch adversarial loss: 0.376079\n",
      "epoch 19; iter: 200; batch classifier loss: 0.413848; batch adversarial loss: 0.501488\n",
      "epoch 20; iter: 0; batch classifier loss: 0.410168; batch adversarial loss: 0.384660\n",
      "epoch 20; iter: 200; batch classifier loss: 0.323152; batch adversarial loss: 0.369401\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352366; batch adversarial loss: 0.400780\n",
      "epoch 21; iter: 200; batch classifier loss: 0.306783; batch adversarial loss: 0.437816\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372331; batch adversarial loss: 0.399048\n",
      "epoch 22; iter: 200; batch classifier loss: 0.371232; batch adversarial loss: 0.400115\n",
      "epoch 23; iter: 0; batch classifier loss: 0.303674; batch adversarial loss: 0.442464\n",
      "epoch 23; iter: 200; batch classifier loss: 0.383781; batch adversarial loss: 0.390135\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261565; batch adversarial loss: 0.382506\n",
      "epoch 24; iter: 200; batch classifier loss: 0.342977; batch adversarial loss: 0.443233\n",
      "epoch 25; iter: 0; batch classifier loss: 0.331461; batch adversarial loss: 0.275755\n",
      "epoch 25; iter: 200; batch classifier loss: 0.350352; batch adversarial loss: 0.375920\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343034; batch adversarial loss: 0.458928\n",
      "epoch 26; iter: 200; batch classifier loss: 0.328110; batch adversarial loss: 0.457944\n",
      "epoch 27; iter: 0; batch classifier loss: 0.354827; batch adversarial loss: 0.417508\n",
      "epoch 27; iter: 200; batch classifier loss: 0.368071; batch adversarial loss: 0.360167\n",
      "epoch 28; iter: 0; batch classifier loss: 0.353684; batch adversarial loss: 0.304858\n",
      "epoch 28; iter: 200; batch classifier loss: 0.312226; batch adversarial loss: 0.431249\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324141; batch adversarial loss: 0.469300\n",
      "epoch 29; iter: 200; batch classifier loss: 0.317594; batch adversarial loss: 0.391459\n",
      "epoch 30; iter: 0; batch classifier loss: 0.337307; batch adversarial loss: 0.339313\n",
      "epoch 30; iter: 200; batch classifier loss: 0.349284; batch adversarial loss: 0.420612\n",
      "epoch 31; iter: 0; batch classifier loss: 0.350312; batch adversarial loss: 0.333358\n",
      "epoch 31; iter: 200; batch classifier loss: 0.294565; batch adversarial loss: 0.449119\n",
      "epoch 32; iter: 0; batch classifier loss: 0.290798; batch adversarial loss: 0.389263\n",
      "epoch 32; iter: 200; batch classifier loss: 0.234308; batch adversarial loss: 0.405100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405225; batch adversarial loss: 0.433469\n",
      "epoch 33; iter: 200; batch classifier loss: 0.363547; batch adversarial loss: 0.464058\n",
      "epoch 34; iter: 0; batch classifier loss: 0.333264; batch adversarial loss: 0.318555\n",
      "epoch 34; iter: 200; batch classifier loss: 0.407531; batch adversarial loss: 0.481961\n",
      "epoch 35; iter: 0; batch classifier loss: 0.326118; batch adversarial loss: 0.439836\n",
      "epoch 35; iter: 200; batch classifier loss: 0.463605; batch adversarial loss: 0.319267\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402447; batch adversarial loss: 0.408409\n",
      "epoch 36; iter: 200; batch classifier loss: 0.329930; batch adversarial loss: 0.429043\n",
      "epoch 37; iter: 0; batch classifier loss: 0.380122; batch adversarial loss: 0.423578\n",
      "epoch 37; iter: 200; batch classifier loss: 0.389589; batch adversarial loss: 0.446316\n",
      "epoch 38; iter: 0; batch classifier loss: 0.300033; batch adversarial loss: 0.336300\n",
      "epoch 38; iter: 200; batch classifier loss: 0.392821; batch adversarial loss: 0.379139\n",
      "epoch 39; iter: 0; batch classifier loss: 0.326482; batch adversarial loss: 0.465097\n",
      "epoch 39; iter: 200; batch classifier loss: 0.342844; batch adversarial loss: 0.469654\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411938; batch adversarial loss: 0.399040\n",
      "epoch 40; iter: 200; batch classifier loss: 0.284202; batch adversarial loss: 0.462500\n",
      "epoch 41; iter: 0; batch classifier loss: 0.335766; batch adversarial loss: 0.346868\n",
      "epoch 41; iter: 200; batch classifier loss: 0.281435; batch adversarial loss: 0.370511\n",
      "epoch 42; iter: 0; batch classifier loss: 0.359310; batch adversarial loss: 0.459010\n",
      "epoch 42; iter: 200; batch classifier loss: 0.287112; batch adversarial loss: 0.443006\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400419; batch adversarial loss: 0.452175\n",
      "epoch 43; iter: 200; batch classifier loss: 0.367073; batch adversarial loss: 0.351064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.297474; batch adversarial loss: 0.417784\n",
      "epoch 44; iter: 200; batch classifier loss: 0.297500; batch adversarial loss: 0.393468\n",
      "epoch 45; iter: 0; batch classifier loss: 0.360925; batch adversarial loss: 0.328233\n",
      "epoch 45; iter: 200; batch classifier loss: 0.541281; batch adversarial loss: 0.391240\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372554; batch adversarial loss: 0.361137\n",
      "epoch 46; iter: 200; batch classifier loss: 0.333672; batch adversarial loss: 0.463299\n",
      "epoch 47; iter: 0; batch classifier loss: 0.314601; batch adversarial loss: 0.404514\n",
      "epoch 47; iter: 200; batch classifier loss: 0.468625; batch adversarial loss: 0.400823\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370358; batch adversarial loss: 0.398875\n",
      "epoch 48; iter: 200; batch classifier loss: 0.389873; batch adversarial loss: 0.486021\n",
      "epoch 49; iter: 0; batch classifier loss: 0.304843; batch adversarial loss: 0.428662\n",
      "epoch 49; iter: 200; batch classifier loss: 0.535895; batch adversarial loss: 0.425945\n",
      "epoch 0; iter: 0; batch classifier loss: 109.244904; batch adversarial loss: 1.087448\n",
      "epoch 0; iter: 200; batch classifier loss: 2.702712; batch adversarial loss: 0.877923\n",
      "epoch 1; iter: 0; batch classifier loss: 9.865070; batch adversarial loss: 0.706988\n",
      "epoch 1; iter: 200; batch classifier loss: 7.065355; batch adversarial loss: 0.560911\n",
      "epoch 2; iter: 0; batch classifier loss: 7.768904; batch adversarial loss: 0.584527\n",
      "epoch 2; iter: 200; batch classifier loss: 4.350358; batch adversarial loss: 0.536065\n",
      "epoch 3; iter: 0; batch classifier loss: 2.774987; batch adversarial loss: 0.552679\n",
      "epoch 3; iter: 200; batch classifier loss: 1.758887; batch adversarial loss: 0.497430\n",
      "epoch 4; iter: 0; batch classifier loss: 5.131481; batch adversarial loss: 0.420387\n",
      "epoch 4; iter: 200; batch classifier loss: 2.351838; batch adversarial loss: 0.444446\n",
      "epoch 5; iter: 0; batch classifier loss: 0.813925; batch adversarial loss: 0.421863\n",
      "epoch 5; iter: 200; batch classifier loss: 1.527321; batch adversarial loss: 0.467780\n",
      "epoch 6; iter: 0; batch classifier loss: 0.885978; batch adversarial loss: 0.455825\n",
      "epoch 6; iter: 200; batch classifier loss: 0.985297; batch adversarial loss: 0.500126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.833028; batch adversarial loss: 0.454420\n",
      "epoch 7; iter: 200; batch classifier loss: 0.796883; batch adversarial loss: 0.439673\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566060; batch adversarial loss: 0.419151\n",
      "epoch 8; iter: 200; batch classifier loss: 0.715975; batch adversarial loss: 0.402885\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542595; batch adversarial loss: 0.339469\n",
      "epoch 9; iter: 200; batch classifier loss: 0.513367; batch adversarial loss: 0.464829\n",
      "epoch 10; iter: 0; batch classifier loss: 0.361867; batch adversarial loss: 0.401414\n",
      "epoch 10; iter: 200; batch classifier loss: 0.366331; batch adversarial loss: 0.400261\n",
      "epoch 11; iter: 0; batch classifier loss: 0.436518; batch adversarial loss: 0.358154\n",
      "epoch 11; iter: 200; batch classifier loss: 0.536195; batch adversarial loss: 0.368705\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381202; batch adversarial loss: 0.446922\n",
      "epoch 12; iter: 200; batch classifier loss: 0.408782; batch adversarial loss: 0.345025\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374104; batch adversarial loss: 0.447953\n",
      "epoch 13; iter: 200; batch classifier loss: 0.458963; batch adversarial loss: 0.397880\n",
      "epoch 14; iter: 0; batch classifier loss: 0.533622; batch adversarial loss: 0.466524\n",
      "epoch 14; iter: 200; batch classifier loss: 0.399232; batch adversarial loss: 0.473762\n",
      "epoch 15; iter: 0; batch classifier loss: 0.271738; batch adversarial loss: 0.429966\n",
      "epoch 15; iter: 200; batch classifier loss: 0.327063; batch adversarial loss: 0.284236\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354207; batch adversarial loss: 0.472984\n",
      "epoch 16; iter: 200; batch classifier loss: 0.302788; batch adversarial loss: 0.419615\n",
      "epoch 17; iter: 0; batch classifier loss: 0.379604; batch adversarial loss: 0.396662\n",
      "epoch 17; iter: 200; batch classifier loss: 0.371528; batch adversarial loss: 0.362346\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303191; batch adversarial loss: 0.516419\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399024; batch adversarial loss: 0.426388\n",
      "epoch 19; iter: 0; batch classifier loss: 0.293453; batch adversarial loss: 0.324855\n",
      "epoch 19; iter: 200; batch classifier loss: 0.380100; batch adversarial loss: 0.306576\n",
      "epoch 20; iter: 0; batch classifier loss: 0.343901; batch adversarial loss: 0.394884\n",
      "epoch 20; iter: 200; batch classifier loss: 0.355087; batch adversarial loss: 0.380244\n",
      "epoch 21; iter: 0; batch classifier loss: 0.364947; batch adversarial loss: 0.502541\n",
      "epoch 21; iter: 200; batch classifier loss: 0.286863; batch adversarial loss: 0.425420\n",
      "epoch 22; iter: 0; batch classifier loss: 0.397239; batch adversarial loss: 0.346941\n",
      "epoch 22; iter: 200; batch classifier loss: 0.333868; batch adversarial loss: 0.442347\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534503; batch adversarial loss: 0.388014\n",
      "epoch 23; iter: 200; batch classifier loss: 0.334491; batch adversarial loss: 0.365028\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293164; batch adversarial loss: 0.403242\n",
      "epoch 24; iter: 200; batch classifier loss: 0.308370; batch adversarial loss: 0.381134\n",
      "epoch 25; iter: 0; batch classifier loss: 0.341644; batch adversarial loss: 0.376019\n",
      "epoch 25; iter: 200; batch classifier loss: 0.424083; batch adversarial loss: 0.408554\n",
      "epoch 26; iter: 0; batch classifier loss: 0.279180; batch adversarial loss: 0.511885\n",
      "epoch 26; iter: 200; batch classifier loss: 0.338072; batch adversarial loss: 0.425293\n",
      "epoch 27; iter: 0; batch classifier loss: 0.416348; batch adversarial loss: 0.405104\n",
      "epoch 27; iter: 200; batch classifier loss: 0.292497; batch adversarial loss: 0.471581\n",
      "epoch 28; iter: 0; batch classifier loss: 0.259338; batch adversarial loss: 0.427402\n",
      "epoch 28; iter: 200; batch classifier loss: 0.340338; batch adversarial loss: 0.441655\n",
      "epoch 29; iter: 0; batch classifier loss: 0.283849; batch adversarial loss: 0.437634\n",
      "epoch 29; iter: 200; batch classifier loss: 0.324524; batch adversarial loss: 0.384874\n",
      "epoch 30; iter: 0; batch classifier loss: 0.362438; batch adversarial loss: 0.471484\n",
      "epoch 30; iter: 200; batch classifier loss: 0.356896; batch adversarial loss: 0.450104\n",
      "epoch 31; iter: 0; batch classifier loss: 0.356664; batch adversarial loss: 0.366583\n",
      "epoch 31; iter: 200; batch classifier loss: 0.381347; batch adversarial loss: 0.477796\n",
      "epoch 32; iter: 0; batch classifier loss: 0.351891; batch adversarial loss: 0.376200\n",
      "epoch 32; iter: 200; batch classifier loss: 0.311470; batch adversarial loss: 0.379264\n",
      "epoch 33; iter: 0; batch classifier loss: 0.385243; batch adversarial loss: 0.421601\n",
      "epoch 33; iter: 200; batch classifier loss: 0.324487; batch adversarial loss: 0.329804\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350755; batch adversarial loss: 0.425229\n",
      "epoch 34; iter: 200; batch classifier loss: 0.465062; batch adversarial loss: 0.452723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412453; batch adversarial loss: 0.466743\n",
      "epoch 35; iter: 200; batch classifier loss: 0.284194; batch adversarial loss: 0.530064\n",
      "epoch 36; iter: 0; batch classifier loss: 0.312215; batch adversarial loss: 0.424124\n",
      "epoch 36; iter: 200; batch classifier loss: 0.379441; batch adversarial loss: 0.351124\n",
      "epoch 37; iter: 0; batch classifier loss: 0.280621; batch adversarial loss: 0.497041\n",
      "epoch 37; iter: 200; batch classifier loss: 0.306045; batch adversarial loss: 0.425030\n",
      "epoch 38; iter: 0; batch classifier loss: 0.301030; batch adversarial loss: 0.488457\n",
      "epoch 38; iter: 200; batch classifier loss: 0.448779; batch adversarial loss: 0.423899\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376511; batch adversarial loss: 0.371394\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349385; batch adversarial loss: 0.347754\n",
      "epoch 40; iter: 0; batch classifier loss: 0.426832; batch adversarial loss: 0.514582\n",
      "epoch 40; iter: 200; batch classifier loss: 0.395892; batch adversarial loss: 0.400162\n",
      "epoch 41; iter: 0; batch classifier loss: 0.369606; batch adversarial loss: 0.504565\n",
      "epoch 41; iter: 200; batch classifier loss: 0.386003; batch adversarial loss: 0.401913\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365836; batch adversarial loss: 0.431963\n",
      "epoch 42; iter: 200; batch classifier loss: 0.443295; batch adversarial loss: 0.361061\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398647; batch adversarial loss: 0.418369\n",
      "epoch 43; iter: 200; batch classifier loss: 0.383126; batch adversarial loss: 0.376713\n",
      "epoch 44; iter: 0; batch classifier loss: 0.389283; batch adversarial loss: 0.390084\n",
      "epoch 44; iter: 200; batch classifier loss: 0.509433; batch adversarial loss: 0.391257\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430184; batch adversarial loss: 0.387432\n",
      "epoch 45; iter: 200; batch classifier loss: 0.442908; batch adversarial loss: 0.429446\n",
      "epoch 46; iter: 0; batch classifier loss: 0.349471; batch adversarial loss: 0.447691\n",
      "epoch 46; iter: 200; batch classifier loss: 0.293659; batch adversarial loss: 0.416093\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384940; batch adversarial loss: 0.485348\n",
      "epoch 47; iter: 200; batch classifier loss: 0.416228; batch adversarial loss: 0.523273\n",
      "epoch 48; iter: 0; batch classifier loss: 0.679761; batch adversarial loss: 0.361103\n",
      "epoch 48; iter: 200; batch classifier loss: 0.326467; batch adversarial loss: 0.447376\n",
      "epoch 49; iter: 0; batch classifier loss: 0.307392; batch adversarial loss: 0.354154\n",
      "epoch 49; iter: 200; batch classifier loss: 0.400716; batch adversarial loss: 0.341077\n",
      "epoch 0; iter: 0; batch classifier loss: 13.933676; batch adversarial loss: 0.661896\n",
      "epoch 0; iter: 200; batch classifier loss: 5.220846; batch adversarial loss: 0.607206\n",
      "epoch 1; iter: 0; batch classifier loss: 7.665339; batch adversarial loss: 0.590097\n",
      "epoch 1; iter: 200; batch classifier loss: 6.294322; batch adversarial loss: 0.530637\n",
      "epoch 2; iter: 0; batch classifier loss: 4.270579; batch adversarial loss: 0.519651\n",
      "epoch 2; iter: 200; batch classifier loss: 2.149507; batch adversarial loss: 0.511523\n",
      "epoch 3; iter: 0; batch classifier loss: 2.619835; batch adversarial loss: 0.467644\n",
      "epoch 3; iter: 200; batch classifier loss: 1.814194; batch adversarial loss: 0.463188\n",
      "epoch 4; iter: 0; batch classifier loss: 2.138655; batch adversarial loss: 0.459742\n",
      "epoch 4; iter: 200; batch classifier loss: 1.141173; batch adversarial loss: 0.402796\n",
      "epoch 5; iter: 0; batch classifier loss: 0.790578; batch adversarial loss: 0.478567\n",
      "epoch 5; iter: 200; batch classifier loss: 0.752254; batch adversarial loss: 0.436906\n",
      "epoch 6; iter: 0; batch classifier loss: 0.462085; batch adversarial loss: 0.389740\n",
      "epoch 6; iter: 200; batch classifier loss: 0.475639; batch adversarial loss: 0.452429\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418783; batch adversarial loss: 0.407246\n",
      "epoch 7; iter: 200; batch classifier loss: 0.345397; batch adversarial loss: 0.491786\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495882; batch adversarial loss: 0.368743\n",
      "epoch 8; iter: 200; batch classifier loss: 0.586279; batch adversarial loss: 0.363495\n",
      "epoch 9; iter: 0; batch classifier loss: 0.399368; batch adversarial loss: 0.339186\n",
      "epoch 9; iter: 200; batch classifier loss: 0.371693; batch adversarial loss: 0.411337\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386991; batch adversarial loss: 0.419902\n",
      "epoch 10; iter: 200; batch classifier loss: 0.677526; batch adversarial loss: 0.410682\n",
      "epoch 11; iter: 0; batch classifier loss: 0.712024; batch adversarial loss: 0.497285\n",
      "epoch 11; iter: 200; batch classifier loss: 0.455585; batch adversarial loss: 0.405853\n",
      "epoch 12; iter: 0; batch classifier loss: 0.244443; batch adversarial loss: 0.425210\n",
      "epoch 12; iter: 200; batch classifier loss: 0.335596; batch adversarial loss: 0.480481\n",
      "epoch 13; iter: 0; batch classifier loss: 0.516532; batch adversarial loss: 0.398993\n",
      "epoch 13; iter: 200; batch classifier loss: 0.287633; batch adversarial loss: 0.427613\n",
      "epoch 14; iter: 0; batch classifier loss: 0.380639; batch adversarial loss: 0.383878\n",
      "epoch 14; iter: 200; batch classifier loss: 0.348724; batch adversarial loss: 0.391589\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396085; batch adversarial loss: 0.453172\n",
      "epoch 15; iter: 200; batch classifier loss: 0.469115; batch adversarial loss: 0.402535\n",
      "epoch 16; iter: 0; batch classifier loss: 0.353999; batch adversarial loss: 0.447683\n",
      "epoch 16; iter: 200; batch classifier loss: 0.323325; batch adversarial loss: 0.320966\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310770; batch adversarial loss: 0.320367\n",
      "epoch 17; iter: 200; batch classifier loss: 0.305585; batch adversarial loss: 0.425805\n",
      "epoch 18; iter: 0; batch classifier loss: 0.307798; batch adversarial loss: 0.443920\n",
      "epoch 18; iter: 200; batch classifier loss: 0.349295; batch adversarial loss: 0.473039\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376785; batch adversarial loss: 0.478440\n",
      "epoch 19; iter: 200; batch classifier loss: 0.393154; batch adversarial loss: 0.428001\n",
      "epoch 20; iter: 0; batch classifier loss: 0.328885; batch adversarial loss: 0.375236\n",
      "epoch 20; iter: 200; batch classifier loss: 0.261012; batch adversarial loss: 0.416671\n",
      "epoch 21; iter: 0; batch classifier loss: 0.324649; batch adversarial loss: 0.365872\n",
      "epoch 21; iter: 200; batch classifier loss: 0.294449; batch adversarial loss: 0.514922\n",
      "epoch 22; iter: 0; batch classifier loss: 0.393508; batch adversarial loss: 0.438835\n",
      "epoch 22; iter: 200; batch classifier loss: 0.362963; batch adversarial loss: 0.384977\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308244; batch adversarial loss: 0.430111\n",
      "epoch 23; iter: 200; batch classifier loss: 0.394276; batch adversarial loss: 0.365972\n",
      "epoch 24; iter: 0; batch classifier loss: 0.295347; batch adversarial loss: 0.431745\n",
      "epoch 24; iter: 200; batch classifier loss: 0.354689; batch adversarial loss: 0.361056\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344193; batch adversarial loss: 0.417318\n",
      "epoch 25; iter: 200; batch classifier loss: 0.376224; batch adversarial loss: 0.380352\n",
      "epoch 26; iter: 0; batch classifier loss: 0.368096; batch adversarial loss: 0.351324\n",
      "epoch 26; iter: 200; batch classifier loss: 0.342475; batch adversarial loss: 0.374949\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278117; batch adversarial loss: 0.467832\n",
      "epoch 27; iter: 200; batch classifier loss: 0.300244; batch adversarial loss: 0.430500\n",
      "epoch 28; iter: 0; batch classifier loss: 0.318684; batch adversarial loss: 0.444499\n",
      "epoch 28; iter: 200; batch classifier loss: 0.307278; batch adversarial loss: 0.418320\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488540; batch adversarial loss: 0.448543\n",
      "epoch 29; iter: 200; batch classifier loss: 0.368378; batch adversarial loss: 0.381735\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415232; batch adversarial loss: 0.343664\n",
      "epoch 30; iter: 200; batch classifier loss: 0.285519; batch adversarial loss: 0.440056\n",
      "epoch 31; iter: 0; batch classifier loss: 0.323714; batch adversarial loss: 0.412351\n",
      "epoch 31; iter: 200; batch classifier loss: 0.414388; batch adversarial loss: 0.440060\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405514; batch adversarial loss: 0.421798\n",
      "epoch 32; iter: 200; batch classifier loss: 0.297178; batch adversarial loss: 0.332626\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370483; batch adversarial loss: 0.349924\n",
      "epoch 33; iter: 200; batch classifier loss: 0.253537; batch adversarial loss: 0.373713\n",
      "epoch 34; iter: 0; batch classifier loss: 0.396356; batch adversarial loss: 0.397225\n",
      "epoch 34; iter: 200; batch classifier loss: 0.362564; batch adversarial loss: 0.558373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.362350; batch adversarial loss: 0.401040\n",
      "epoch 35; iter: 200; batch classifier loss: 0.372113; batch adversarial loss: 0.504104\n",
      "epoch 36; iter: 0; batch classifier loss: 0.356626; batch adversarial loss: 0.433301\n",
      "epoch 36; iter: 200; batch classifier loss: 0.300736; batch adversarial loss: 0.394809\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346601; batch adversarial loss: 0.367391\n",
      "epoch 37; iter: 200; batch classifier loss: 0.276447; batch adversarial loss: 0.380133\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382220; batch adversarial loss: 0.366745\n",
      "epoch 38; iter: 200; batch classifier loss: 0.386910; batch adversarial loss: 0.430128\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440885; batch adversarial loss: 0.527841\n",
      "epoch 39; iter: 200; batch classifier loss: 0.365226; batch adversarial loss: 0.484158\n",
      "epoch 40; iter: 0; batch classifier loss: 0.360795; batch adversarial loss: 0.388006\n",
      "epoch 40; iter: 200; batch classifier loss: 0.257871; batch adversarial loss: 0.510040\n",
      "epoch 41; iter: 0; batch classifier loss: 0.521086; batch adversarial loss: 0.359885\n",
      "epoch 41; iter: 200; batch classifier loss: 0.382488; batch adversarial loss: 0.473473\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394816; batch adversarial loss: 0.431160\n",
      "epoch 42; iter: 200; batch classifier loss: 0.459579; batch adversarial loss: 0.317566\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384652; batch adversarial loss: 0.424970\n",
      "epoch 43; iter: 200; batch classifier loss: 0.308529; batch adversarial loss: 0.441292\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475015; batch adversarial loss: 0.429821\n",
      "epoch 44; iter: 200; batch classifier loss: 0.413415; batch adversarial loss: 0.457498\n",
      "epoch 45; iter: 0; batch classifier loss: 0.286351; batch adversarial loss: 0.385535\n",
      "epoch 45; iter: 200; batch classifier loss: 0.327514; batch adversarial loss: 0.476374\n",
      "epoch 46; iter: 0; batch classifier loss: 0.339880; batch adversarial loss: 0.475738\n",
      "epoch 46; iter: 200; batch classifier loss: 0.351277; batch adversarial loss: 0.445913\n",
      "epoch 47; iter: 0; batch classifier loss: 0.306693; batch adversarial loss: 0.453392\n",
      "epoch 47; iter: 200; batch classifier loss: 0.356040; batch adversarial loss: 0.338524\n",
      "epoch 48; iter: 0; batch classifier loss: 0.363094; batch adversarial loss: 0.461437\n",
      "epoch 48; iter: 200; batch classifier loss: 0.286956; batch adversarial loss: 0.447686\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376603; batch adversarial loss: 0.517820\n",
      "epoch 49; iter: 200; batch classifier loss: 0.404850; batch adversarial loss: 0.336009\n",
      "epoch 0; iter: 0; batch classifier loss: 139.692520; batch adversarial loss: 0.551599\n",
      "epoch 0; iter: 200; batch classifier loss: 8.683363; batch adversarial loss: 0.604086\n",
      "epoch 1; iter: 0; batch classifier loss: 12.596033; batch adversarial loss: 0.578791\n",
      "epoch 1; iter: 200; batch classifier loss: 3.658082; batch adversarial loss: 0.555227\n",
      "epoch 2; iter: 0; batch classifier loss: 3.729916; batch adversarial loss: 0.504428\n",
      "epoch 2; iter: 200; batch classifier loss: 4.700743; batch adversarial loss: 0.428109\n",
      "epoch 3; iter: 0; batch classifier loss: 1.356745; batch adversarial loss: 0.451384\n",
      "epoch 3; iter: 200; batch classifier loss: 1.475783; batch adversarial loss: 0.434850\n",
      "epoch 4; iter: 0; batch classifier loss: 6.674363; batch adversarial loss: 0.400324\n",
      "epoch 4; iter: 200; batch classifier loss: 0.722042; batch adversarial loss: 0.465421\n",
      "epoch 5; iter: 0; batch classifier loss: 1.276402; batch adversarial loss: 0.406054\n",
      "epoch 5; iter: 200; batch classifier loss: 0.674874; batch adversarial loss: 0.366990\n",
      "epoch 6; iter: 0; batch classifier loss: 1.306571; batch adversarial loss: 0.442632\n",
      "epoch 6; iter: 200; batch classifier loss: 0.356088; batch adversarial loss: 0.440816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.434566; batch adversarial loss: 0.406352\n",
      "epoch 7; iter: 200; batch classifier loss: 0.440140; batch adversarial loss: 0.401488\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523712; batch adversarial loss: 0.458696\n",
      "epoch 8; iter: 200; batch classifier loss: 0.538075; batch adversarial loss: 0.421056\n",
      "epoch 9; iter: 0; batch classifier loss: 0.457548; batch adversarial loss: 0.359095\n",
      "epoch 9; iter: 200; batch classifier loss: 0.602303; batch adversarial loss: 0.331945\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434032; batch adversarial loss: 0.423704\n",
      "epoch 10; iter: 200; batch classifier loss: 0.352737; batch adversarial loss: 0.488188\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369358; batch adversarial loss: 0.434148\n",
      "epoch 11; iter: 200; batch classifier loss: 0.389461; batch adversarial loss: 0.401439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373535; batch adversarial loss: 0.518135\n",
      "epoch 12; iter: 200; batch classifier loss: 0.463892; batch adversarial loss: 0.429586\n",
      "epoch 13; iter: 0; batch classifier loss: 0.326303; batch adversarial loss: 0.456129\n",
      "epoch 13; iter: 200; batch classifier loss: 0.316389; batch adversarial loss: 0.463120\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413159; batch adversarial loss: 0.436213\n",
      "epoch 14; iter: 200; batch classifier loss: 0.426095; batch adversarial loss: 0.350114\n",
      "epoch 15; iter: 0; batch classifier loss: 0.380179; batch adversarial loss: 0.381201\n",
      "epoch 15; iter: 200; batch classifier loss: 0.270876; batch adversarial loss: 0.402955\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371482; batch adversarial loss: 0.474390\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399635; batch adversarial loss: 0.405981\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320963; batch adversarial loss: 0.404732\n",
      "epoch 17; iter: 200; batch classifier loss: 0.365829; batch adversarial loss: 0.357989\n",
      "epoch 18; iter: 0; batch classifier loss: 0.324966; batch adversarial loss: 0.323795\n",
      "epoch 18; iter: 200; batch classifier loss: 0.349293; batch adversarial loss: 0.387367\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299660; batch adversarial loss: 0.387894\n",
      "epoch 19; iter: 200; batch classifier loss: 0.339617; batch adversarial loss: 0.410626\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426304; batch adversarial loss: 0.411330\n",
      "epoch 20; iter: 200; batch classifier loss: 0.358747; batch adversarial loss: 0.528447\n",
      "epoch 21; iter: 0; batch classifier loss: 0.321827; batch adversarial loss: 0.427794\n",
      "epoch 21; iter: 200; batch classifier loss: 0.327279; batch adversarial loss: 0.371872\n",
      "epoch 22; iter: 0; batch classifier loss: 0.322694; batch adversarial loss: 0.288898\n",
      "epoch 22; iter: 200; batch classifier loss: 0.392572; batch adversarial loss: 0.444802\n",
      "epoch 23; iter: 0; batch classifier loss: 0.314366; batch adversarial loss: 0.323651\n",
      "epoch 23; iter: 200; batch classifier loss: 0.244861; batch adversarial loss: 0.493777\n",
      "epoch 24; iter: 0; batch classifier loss: 0.350034; batch adversarial loss: 0.358425\n",
      "epoch 24; iter: 200; batch classifier loss: 0.352783; batch adversarial loss: 0.373797\n",
      "epoch 25; iter: 0; batch classifier loss: 0.320252; batch adversarial loss: 0.441814\n",
      "epoch 25; iter: 200; batch classifier loss: 0.280106; batch adversarial loss: 0.315070\n",
      "epoch 26; iter: 0; batch classifier loss: 0.386217; batch adversarial loss: 0.415207\n",
      "epoch 26; iter: 200; batch classifier loss: 0.389204; batch adversarial loss: 0.424572\n",
      "epoch 27; iter: 0; batch classifier loss: 0.347157; batch adversarial loss: 0.335565\n",
      "epoch 27; iter: 200; batch classifier loss: 0.325169; batch adversarial loss: 0.382264\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351918; batch adversarial loss: 0.415192\n",
      "epoch 28; iter: 200; batch classifier loss: 0.286319; batch adversarial loss: 0.431399\n",
      "epoch 29; iter: 0; batch classifier loss: 0.334937; batch adversarial loss: 0.443870\n",
      "epoch 29; iter: 200; batch classifier loss: 0.331960; batch adversarial loss: 0.455967\n",
      "epoch 30; iter: 0; batch classifier loss: 0.304661; batch adversarial loss: 0.363967\n",
      "epoch 30; iter: 200; batch classifier loss: 0.312396; batch adversarial loss: 0.424681\n",
      "epoch 31; iter: 0; batch classifier loss: 0.280310; batch adversarial loss: 0.430608\n",
      "epoch 31; iter: 200; batch classifier loss: 0.293504; batch adversarial loss: 0.528341\n",
      "epoch 32; iter: 0; batch classifier loss: 0.303031; batch adversarial loss: 0.447731\n",
      "epoch 32; iter: 200; batch classifier loss: 0.361836; batch adversarial loss: 0.409559\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408590; batch adversarial loss: 0.381767\n",
      "epoch 33; iter: 200; batch classifier loss: 0.377372; batch adversarial loss: 0.358897\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240354; batch adversarial loss: 0.444585\n",
      "epoch 34; iter: 200; batch classifier loss: 0.426948; batch adversarial loss: 0.369354\n",
      "epoch 35; iter: 0; batch classifier loss: 0.445910; batch adversarial loss: 0.360177\n",
      "epoch 35; iter: 200; batch classifier loss: 0.367832; batch adversarial loss: 0.375190\n",
      "epoch 36; iter: 0; batch classifier loss: 0.295668; batch adversarial loss: 0.362231\n",
      "epoch 36; iter: 200; batch classifier loss: 0.352007; batch adversarial loss: 0.456763\n",
      "epoch 37; iter: 0; batch classifier loss: 0.368442; batch adversarial loss: 0.500854\n",
      "epoch 37; iter: 200; batch classifier loss: 0.285319; batch adversarial loss: 0.446203\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414142; batch adversarial loss: 0.490117\n",
      "epoch 38; iter: 200; batch classifier loss: 0.367298; batch adversarial loss: 0.318603\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376883; batch adversarial loss: 0.401708\n",
      "epoch 39; iter: 200; batch classifier loss: 0.424361; batch adversarial loss: 0.432913\n",
      "epoch 40; iter: 0; batch classifier loss: 0.312748; batch adversarial loss: 0.376901\n",
      "epoch 40; iter: 200; batch classifier loss: 0.352467; batch adversarial loss: 0.378613\n",
      "epoch 41; iter: 0; batch classifier loss: 0.376073; batch adversarial loss: 0.351997\n",
      "epoch 41; iter: 200; batch classifier loss: 0.396497; batch adversarial loss: 0.462119\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409493; batch adversarial loss: 0.345858\n",
      "epoch 42; iter: 200; batch classifier loss: 0.388902; batch adversarial loss: 0.459464\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444793; batch adversarial loss: 0.402425\n",
      "epoch 43; iter: 200; batch classifier loss: 0.304801; batch adversarial loss: 0.366355\n",
      "epoch 44; iter: 0; batch classifier loss: 0.275326; batch adversarial loss: 0.377060\n",
      "epoch 44; iter: 200; batch classifier loss: 0.421422; batch adversarial loss: 0.444304\n",
      "epoch 45; iter: 0; batch classifier loss: 0.324515; batch adversarial loss: 0.407764\n",
      "epoch 45; iter: 200; batch classifier loss: 0.415254; batch adversarial loss: 0.402392\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392501; batch adversarial loss: 0.424222\n",
      "epoch 46; iter: 200; batch classifier loss: 0.367226; batch adversarial loss: 0.470912\n",
      "epoch 47; iter: 0; batch classifier loss: 0.303060; batch adversarial loss: 0.530403\n",
      "epoch 47; iter: 200; batch classifier loss: 0.327709; batch adversarial loss: 0.420193\n",
      "epoch 48; iter: 0; batch classifier loss: 0.291929; batch adversarial loss: 0.419631\n",
      "epoch 48; iter: 200; batch classifier loss: 0.455211; batch adversarial loss: 0.462282\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379779; batch adversarial loss: 0.391208\n",
      "epoch 49; iter: 200; batch classifier loss: 0.313953; batch adversarial loss: 0.519251\n",
      "epoch 0; iter: 0; batch classifier loss: 36.964607; batch adversarial loss: 0.507117\n",
      "epoch 0; iter: 200; batch classifier loss: 3.357720; batch adversarial loss: 0.511517\n",
      "epoch 1; iter: 0; batch classifier loss: 12.804275; batch adversarial loss: 0.568692\n",
      "epoch 1; iter: 200; batch classifier loss: 10.884590; batch adversarial loss: 0.547145\n",
      "epoch 2; iter: 0; batch classifier loss: 6.253798; batch adversarial loss: 0.558847\n",
      "epoch 2; iter: 200; batch classifier loss: 3.337410; batch adversarial loss: 0.471028\n",
      "epoch 3; iter: 0; batch classifier loss: 1.184902; batch adversarial loss: 0.476063\n",
      "epoch 3; iter: 200; batch classifier loss: 1.338806; batch adversarial loss: 0.421958\n",
      "epoch 4; iter: 0; batch classifier loss: 1.220234; batch adversarial loss: 0.413212\n",
      "epoch 4; iter: 200; batch classifier loss: 0.721936; batch adversarial loss: 0.410270\n",
      "epoch 5; iter: 0; batch classifier loss: 0.625522; batch adversarial loss: 0.425853\n",
      "epoch 5; iter: 200; batch classifier loss: 0.589473; batch adversarial loss: 0.425490\n",
      "epoch 6; iter: 0; batch classifier loss: 1.512289; batch adversarial loss: 0.380078\n",
      "epoch 6; iter: 200; batch classifier loss: 0.439308; batch adversarial loss: 0.430850\n",
      "epoch 7; iter: 0; batch classifier loss: 0.439664; batch adversarial loss: 0.492826\n",
      "epoch 7; iter: 200; batch classifier loss: 0.496825; batch adversarial loss: 0.333873\n",
      "epoch 8; iter: 0; batch classifier loss: 0.493933; batch adversarial loss: 0.452705\n",
      "epoch 8; iter: 200; batch classifier loss: 0.447070; batch adversarial loss: 0.463370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435495; batch adversarial loss: 0.435717\n",
      "epoch 9; iter: 200; batch classifier loss: 0.342137; batch adversarial loss: 0.429007\n",
      "epoch 10; iter: 0; batch classifier loss: 0.919515; batch adversarial loss: 0.415237\n",
      "epoch 10; iter: 200; batch classifier loss: 0.320907; batch adversarial loss: 0.525087\n",
      "epoch 11; iter: 0; batch classifier loss: 0.387167; batch adversarial loss: 0.504183\n",
      "epoch 11; iter: 200; batch classifier loss: 0.531532; batch adversarial loss: 0.342524\n",
      "epoch 12; iter: 0; batch classifier loss: 0.344165; batch adversarial loss: 0.414937\n",
      "epoch 12; iter: 200; batch classifier loss: 0.443778; batch adversarial loss: 0.433239\n",
      "epoch 13; iter: 0; batch classifier loss: 0.426312; batch adversarial loss: 0.346598\n",
      "epoch 13; iter: 200; batch classifier loss: 0.251732; batch adversarial loss: 0.424183\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491222; batch adversarial loss: 0.403470\n",
      "epoch 14; iter: 200; batch classifier loss: 0.576131; batch adversarial loss: 0.349778\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513145; batch adversarial loss: 0.321808\n",
      "epoch 15; iter: 200; batch classifier loss: 0.314069; batch adversarial loss: 0.473377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.361868; batch adversarial loss: 0.367576\n",
      "epoch 16; iter: 200; batch classifier loss: 0.534033; batch adversarial loss: 0.376589\n",
      "epoch 17; iter: 0; batch classifier loss: 0.303639; batch adversarial loss: 0.338258\n",
      "epoch 17; iter: 200; batch classifier loss: 0.523503; batch adversarial loss: 0.376527\n",
      "epoch 18; iter: 0; batch classifier loss: 0.374350; batch adversarial loss: 0.380265\n",
      "epoch 18; iter: 200; batch classifier loss: 0.390226; batch adversarial loss: 0.494341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.422191; batch adversarial loss: 0.429095\n",
      "epoch 19; iter: 200; batch classifier loss: 0.390040; batch adversarial loss: 0.414022\n",
      "epoch 20; iter: 0; batch classifier loss: 0.382072; batch adversarial loss: 0.356211\n",
      "epoch 20; iter: 200; batch classifier loss: 0.329705; batch adversarial loss: 0.457382\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352062; batch adversarial loss: 0.482305\n",
      "epoch 21; iter: 200; batch classifier loss: 0.283805; batch adversarial loss: 0.493503\n",
      "epoch 22; iter: 0; batch classifier loss: 0.312103; batch adversarial loss: 0.366847\n",
      "epoch 22; iter: 200; batch classifier loss: 0.325295; batch adversarial loss: 0.365129\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378998; batch adversarial loss: 0.373534\n",
      "epoch 23; iter: 200; batch classifier loss: 0.375203; batch adversarial loss: 0.383454\n",
      "epoch 24; iter: 0; batch classifier loss: 0.398658; batch adversarial loss: 0.460015\n",
      "epoch 24; iter: 200; batch classifier loss: 0.302811; batch adversarial loss: 0.379301\n",
      "epoch 25; iter: 0; batch classifier loss: 0.401280; batch adversarial loss: 0.372842\n",
      "epoch 25; iter: 200; batch classifier loss: 0.264347; batch adversarial loss: 0.400598\n",
      "epoch 26; iter: 0; batch classifier loss: 0.294579; batch adversarial loss: 0.424540\n",
      "epoch 26; iter: 200; batch classifier loss: 0.271807; batch adversarial loss: 0.356402\n",
      "epoch 27; iter: 0; batch classifier loss: 0.289153; batch adversarial loss: 0.394446\n",
      "epoch 27; iter: 200; batch classifier loss: 0.321661; batch adversarial loss: 0.392674\n",
      "epoch 28; iter: 0; batch classifier loss: 0.303686; batch adversarial loss: 0.331370\n",
      "epoch 28; iter: 200; batch classifier loss: 0.352424; batch adversarial loss: 0.446328\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406764; batch adversarial loss: 0.415593\n",
      "epoch 29; iter: 200; batch classifier loss: 0.391752; batch adversarial loss: 0.430208\n",
      "epoch 30; iter: 0; batch classifier loss: 0.291299; batch adversarial loss: 0.423776\n",
      "epoch 30; iter: 200; batch classifier loss: 0.393423; batch adversarial loss: 0.362992\n",
      "epoch 31; iter: 0; batch classifier loss: 0.288445; batch adversarial loss: 0.348160\n",
      "epoch 31; iter: 200; batch classifier loss: 0.279572; batch adversarial loss: 0.401090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381759; batch adversarial loss: 0.494743\n",
      "epoch 32; iter: 200; batch classifier loss: 0.371001; batch adversarial loss: 0.358937\n",
      "epoch 33; iter: 0; batch classifier loss: 0.353374; batch adversarial loss: 0.351267\n",
      "epoch 33; iter: 200; batch classifier loss: 0.391835; batch adversarial loss: 0.364318\n",
      "epoch 34; iter: 0; batch classifier loss: 0.378743; batch adversarial loss: 0.566033\n",
      "epoch 34; iter: 200; batch classifier loss: 0.443607; batch adversarial loss: 0.452618\n",
      "epoch 35; iter: 0; batch classifier loss: 0.258715; batch adversarial loss: 0.491097\n",
      "epoch 35; iter: 200; batch classifier loss: 0.324304; batch adversarial loss: 0.433444\n",
      "epoch 36; iter: 0; batch classifier loss: 0.282938; batch adversarial loss: 0.401130\n",
      "epoch 36; iter: 200; batch classifier loss: 0.427690; batch adversarial loss: 0.386898\n",
      "epoch 37; iter: 0; batch classifier loss: 0.284324; batch adversarial loss: 0.503696\n",
      "epoch 37; iter: 200; batch classifier loss: 0.298210; batch adversarial loss: 0.385839\n",
      "epoch 38; iter: 0; batch classifier loss: 0.338501; batch adversarial loss: 0.476531\n",
      "epoch 38; iter: 200; batch classifier loss: 0.361625; batch adversarial loss: 0.424192\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396504; batch adversarial loss: 0.424870\n",
      "epoch 39; iter: 200; batch classifier loss: 0.532750; batch adversarial loss: 0.375472\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393999; batch adversarial loss: 0.403106\n",
      "epoch 40; iter: 200; batch classifier loss: 0.298362; batch adversarial loss: 0.317659\n",
      "epoch 41; iter: 0; batch classifier loss: 0.344982; batch adversarial loss: 0.459292\n",
      "epoch 41; iter: 200; batch classifier loss: 0.368834; batch adversarial loss: 0.359992\n",
      "epoch 42; iter: 0; batch classifier loss: 0.418807; batch adversarial loss: 0.405228\n",
      "epoch 42; iter: 200; batch classifier loss: 0.363895; batch adversarial loss: 0.458964\n",
      "epoch 43; iter: 0; batch classifier loss: 0.315716; batch adversarial loss: 0.336463\n",
      "epoch 43; iter: 200; batch classifier loss: 0.352288; batch adversarial loss: 0.415170\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394712; batch adversarial loss: 0.363051\n",
      "epoch 44; iter: 200; batch classifier loss: 0.396022; batch adversarial loss: 0.319378\n",
      "epoch 45; iter: 0; batch classifier loss: 0.428365; batch adversarial loss: 0.290775\n",
      "epoch 45; iter: 200; batch classifier loss: 0.253305; batch adversarial loss: 0.431880\n",
      "epoch 46; iter: 0; batch classifier loss: 0.455809; batch adversarial loss: 0.430184\n",
      "epoch 46; iter: 200; batch classifier loss: 0.312250; batch adversarial loss: 0.408099\n",
      "epoch 47; iter: 0; batch classifier loss: 0.353967; batch adversarial loss: 0.388413\n",
      "epoch 47; iter: 200; batch classifier loss: 0.399999; batch adversarial loss: 0.473748\n",
      "epoch 48; iter: 0; batch classifier loss: 0.361342; batch adversarial loss: 0.408252\n",
      "epoch 48; iter: 200; batch classifier loss: 0.470203; batch adversarial loss: 0.393865\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377498; batch adversarial loss: 0.397057\n",
      "epoch 49; iter: 200; batch classifier loss: 0.305574; batch adversarial loss: 0.413019\n",
      "Best parameters: adversary_loss_weight     1.000000\n",
      "batch_size               64.000000\n",
      "num_epochs               10.000000\n",
      "acc_mean                  0.830300\n",
      "acc_std                   0.012616\n",
      "f1_mean                   0.566238\n",
      "f1_std                    0.065358\n",
      "SPD_mean                 -0.002101\n",
      "SPD_std                   0.022917\n",
      "DI_mean                   1.012359\n",
      "DI_std                    0.148619\n",
      "EOD_mean                  0.128392\n",
      "EOD_std                   0.044468\n",
      "AOD_mean                  0.075637\n",
      "AOD_std                   0.026290\n",
      "fairness_score            0.014460\n",
      "Name: 6, dtype: float64\n",
      "epoch 0; iter: 0; batch classifier loss: 61.246155; batch adversarial loss: 0.829211\n",
      "epoch 0; iter: 200; batch classifier loss: 8.553354; batch adversarial loss: 0.630307\n",
      "epoch 0; iter: 400; batch classifier loss: 5.968196; batch adversarial loss: 0.579039\n",
      "epoch 0; iter: 600; batch classifier loss: 2.012230; batch adversarial loss: 0.507079\n",
      "epoch 1; iter: 0; batch classifier loss: 5.192625; batch adversarial loss: 0.521802\n",
      "epoch 1; iter: 200; batch classifier loss: 13.134768; batch adversarial loss: 0.499318\n",
      "epoch 1; iter: 400; batch classifier loss: 0.776445; batch adversarial loss: 0.474764\n",
      "epoch 1; iter: 600; batch classifier loss: 1.759318; batch adversarial loss: 0.458002\n",
      "epoch 2; iter: 0; batch classifier loss: 3.310205; batch adversarial loss: 0.508056\n",
      "epoch 2; iter: 200; batch classifier loss: 0.997874; batch adversarial loss: 0.431610\n",
      "epoch 2; iter: 400; batch classifier loss: 1.223675; batch adversarial loss: 0.457100\n",
      "epoch 2; iter: 600; batch classifier loss: 1.612658; batch adversarial loss: 0.475647\n",
      "epoch 3; iter: 0; batch classifier loss: 0.367820; batch adversarial loss: 0.397554\n",
      "epoch 3; iter: 200; batch classifier loss: 1.212815; batch adversarial loss: 0.471181\n",
      "epoch 3; iter: 400; batch classifier loss: 0.357549; batch adversarial loss: 0.303240\n",
      "epoch 3; iter: 600; batch classifier loss: 0.380923; batch adversarial loss: 0.537590\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586219; batch adversarial loss: 0.396243\n",
      "epoch 4; iter: 200; batch classifier loss: 0.299259; batch adversarial loss: 0.438024\n",
      "epoch 4; iter: 400; batch classifier loss: 0.266036; batch adversarial loss: 0.371164\n",
      "epoch 4; iter: 600; batch classifier loss: 0.824129; batch adversarial loss: 0.371840\n",
      "epoch 5; iter: 0; batch classifier loss: 0.356632; batch adversarial loss: 0.340523\n",
      "epoch 5; iter: 200; batch classifier loss: 0.319924; batch adversarial loss: 0.373165\n",
      "epoch 5; iter: 400; batch classifier loss: 0.494392; batch adversarial loss: 0.441937\n",
      "epoch 5; iter: 600; batch classifier loss: 0.530198; batch adversarial loss: 0.465347\n",
      "epoch 6; iter: 0; batch classifier loss: 0.456402; batch adversarial loss: 0.513492\n",
      "epoch 6; iter: 200; batch classifier loss: 0.384303; batch adversarial loss: 0.322747\n",
      "epoch 6; iter: 400; batch classifier loss: 0.196536; batch adversarial loss: 0.403271\n",
      "epoch 6; iter: 600; batch classifier loss: 0.410855; batch adversarial loss: 0.380493\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335723; batch adversarial loss: 0.354081\n",
      "epoch 7; iter: 200; batch classifier loss: 0.340017; batch adversarial loss: 0.527213\n",
      "epoch 7; iter: 400; batch classifier loss: 0.404232; batch adversarial loss: 0.370494\n",
      "epoch 7; iter: 600; batch classifier loss: 0.274906; batch adversarial loss: 0.511498\n",
      "epoch 8; iter: 0; batch classifier loss: 0.244748; batch adversarial loss: 0.266173\n",
      "epoch 8; iter: 200; batch classifier loss: 0.420291; batch adversarial loss: 0.454683\n",
      "epoch 8; iter: 400; batch classifier loss: 0.272446; batch adversarial loss: 0.419815\n",
      "epoch 8; iter: 600; batch classifier loss: 0.353506; batch adversarial loss: 0.476851\n",
      "epoch 9; iter: 0; batch classifier loss: 0.331588; batch adversarial loss: 0.429769\n",
      "epoch 9; iter: 200; batch classifier loss: 0.328233; batch adversarial loss: 0.602582\n",
      "epoch 9; iter: 400; batch classifier loss: 0.364869; batch adversarial loss: 0.437791\n",
      "epoch 9; iter: 600; batch classifier loss: 0.349383; batch adversarial loss: 0.371452\n",
      "epoch 0; iter: 0; batch classifier loss: 11.233564; batch adversarial loss: 0.625483\n",
      "epoch 0; iter: 200; batch classifier loss: 9.088560; batch adversarial loss: 0.606054\n",
      "epoch 0; iter: 400; batch classifier loss: 21.783510; batch adversarial loss: 0.529632\n",
      "epoch 0; iter: 600; batch classifier loss: 5.179008; batch adversarial loss: 0.541014\n",
      "epoch 1; iter: 0; batch classifier loss: 3.802553; batch adversarial loss: 0.510083\n",
      "epoch 1; iter: 200; batch classifier loss: 5.439159; batch adversarial loss: 0.415203\n",
      "epoch 1; iter: 400; batch classifier loss: 3.966079; batch adversarial loss: 0.419766\n",
      "epoch 1; iter: 600; batch classifier loss: 1.928735; batch adversarial loss: 0.421783\n",
      "epoch 2; iter: 0; batch classifier loss: 1.332545; batch adversarial loss: 0.462711\n",
      "epoch 2; iter: 200; batch classifier loss: 0.566347; batch adversarial loss: 0.436621\n",
      "epoch 2; iter: 400; batch classifier loss: 2.312646; batch adversarial loss: 0.372121\n",
      "epoch 2; iter: 600; batch classifier loss: 0.729827; batch adversarial loss: 0.380959\n",
      "epoch 3; iter: 0; batch classifier loss: 0.633334; batch adversarial loss: 0.417228\n",
      "epoch 3; iter: 200; batch classifier loss: 0.295259; batch adversarial loss: 0.357433\n",
      "epoch 3; iter: 400; batch classifier loss: 0.438913; batch adversarial loss: 0.509567\n",
      "epoch 3; iter: 600; batch classifier loss: 1.006531; batch adversarial loss: 0.436880\n",
      "epoch 4; iter: 0; batch classifier loss: 0.787525; batch adversarial loss: 0.426940\n",
      "epoch 4; iter: 200; batch classifier loss: 0.218181; batch adversarial loss: 0.389927\n",
      "epoch 4; iter: 400; batch classifier loss: 0.442839; batch adversarial loss: 0.326312\n",
      "epoch 4; iter: 600; batch classifier loss: 0.414868; batch adversarial loss: 0.383355\n",
      "epoch 5; iter: 0; batch classifier loss: 0.472162; batch adversarial loss: 0.604197\n",
      "epoch 5; iter: 200; batch classifier loss: 0.487807; batch adversarial loss: 0.406191\n",
      "epoch 5; iter: 400; batch classifier loss: 0.371137; batch adversarial loss: 0.423547\n",
      "epoch 5; iter: 600; batch classifier loss: 0.367980; batch adversarial loss: 0.429777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.376373; batch adversarial loss: 0.554649\n",
      "epoch 6; iter: 200; batch classifier loss: 0.769185; batch adversarial loss: 0.405775\n",
      "epoch 6; iter: 400; batch classifier loss: 0.292023; batch adversarial loss: 0.344684\n",
      "epoch 6; iter: 600; batch classifier loss: 0.431079; batch adversarial loss: 0.371156\n",
      "epoch 7; iter: 0; batch classifier loss: 0.314130; batch adversarial loss: 0.425562\n",
      "epoch 7; iter: 200; batch classifier loss: 1.425049; batch adversarial loss: 0.524011\n",
      "epoch 7; iter: 400; batch classifier loss: 0.486056; batch adversarial loss: 0.314574\n",
      "epoch 7; iter: 600; batch classifier loss: 0.260627; batch adversarial loss: 0.392362\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334781; batch adversarial loss: 0.486684\n",
      "epoch 8; iter: 200; batch classifier loss: 0.308885; batch adversarial loss: 0.422279\n",
      "epoch 8; iter: 400; batch classifier loss: 0.326862; batch adversarial loss: 0.349725\n",
      "epoch 8; iter: 600; batch classifier loss: 0.382815; batch adversarial loss: 0.503334\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335610; batch adversarial loss: 0.296543\n",
      "epoch 9; iter: 200; batch classifier loss: 0.747209; batch adversarial loss: 0.450542\n",
      "epoch 9; iter: 400; batch classifier loss: 0.373501; batch adversarial loss: 0.418834\n",
      "epoch 9; iter: 600; batch classifier loss: 0.278129; batch adversarial loss: 0.426019\n",
      "epoch 0; iter: 0; batch classifier loss: 17.509493; batch adversarial loss: 0.638758\n",
      "epoch 0; iter: 200; batch classifier loss: 1.035456; batch adversarial loss: 0.630463\n",
      "epoch 0; iter: 400; batch classifier loss: 2.178797; batch adversarial loss: 0.552093\n",
      "epoch 0; iter: 600; batch classifier loss: 12.229676; batch adversarial loss: 0.566405\n",
      "epoch 1; iter: 0; batch classifier loss: 5.170968; batch adversarial loss: 0.494538\n",
      "epoch 1; iter: 200; batch classifier loss: 3.107252; batch adversarial loss: 0.414611\n",
      "epoch 1; iter: 400; batch classifier loss: 1.719134; batch adversarial loss: 0.424542\n",
      "epoch 1; iter: 600; batch classifier loss: 3.924598; batch adversarial loss: 0.435838\n",
      "epoch 2; iter: 0; batch classifier loss: 1.623606; batch adversarial loss: 0.360309\n",
      "epoch 2; iter: 200; batch classifier loss: 1.275642; batch adversarial loss: 0.418470\n",
      "epoch 2; iter: 400; batch classifier loss: 0.564336; batch adversarial loss: 0.422416\n",
      "epoch 2; iter: 600; batch classifier loss: 12.078324; batch adversarial loss: 0.461122\n",
      "epoch 3; iter: 0; batch classifier loss: 15.105728; batch adversarial loss: 0.293786\n",
      "epoch 3; iter: 200; batch classifier loss: 0.388622; batch adversarial loss: 0.427491\n",
      "epoch 3; iter: 400; batch classifier loss: 0.335240; batch adversarial loss: 0.470646\n",
      "epoch 3; iter: 600; batch classifier loss: 0.831667; batch adversarial loss: 0.439920\n",
      "epoch 4; iter: 0; batch classifier loss: 0.411779; batch adversarial loss: 0.320235\n",
      "epoch 4; iter: 200; batch classifier loss: 0.468182; batch adversarial loss: 0.382015\n",
      "epoch 4; iter: 400; batch classifier loss: 0.904287; batch adversarial loss: 0.476398\n",
      "epoch 4; iter: 600; batch classifier loss: 0.688390; batch adversarial loss: 0.380370\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527455; batch adversarial loss: 0.396459\n",
      "epoch 5; iter: 200; batch classifier loss: 0.439421; batch adversarial loss: 0.374606\n",
      "epoch 5; iter: 400; batch classifier loss: 0.634898; batch adversarial loss: 0.384326\n",
      "epoch 5; iter: 600; batch classifier loss: 0.609655; batch adversarial loss: 0.481776\n",
      "epoch 6; iter: 0; batch classifier loss: 0.389086; batch adversarial loss: 0.584965\n",
      "epoch 6; iter: 200; batch classifier loss: 0.332058; batch adversarial loss: 0.303756\n",
      "epoch 6; iter: 400; batch classifier loss: 0.527555; batch adversarial loss: 0.449051\n",
      "epoch 6; iter: 600; batch classifier loss: 0.462686; batch adversarial loss: 0.503354\n",
      "epoch 7; iter: 0; batch classifier loss: 0.451095; batch adversarial loss: 0.632925\n",
      "epoch 7; iter: 200; batch classifier loss: 0.340337; batch adversarial loss: 0.588770\n",
      "epoch 7; iter: 400; batch classifier loss: 0.265998; batch adversarial loss: 0.540268\n",
      "epoch 7; iter: 600; batch classifier loss: 0.386628; batch adversarial loss: 0.285964\n",
      "epoch 8; iter: 0; batch classifier loss: 0.285870; batch adversarial loss: 0.452829\n",
      "epoch 8; iter: 200; batch classifier loss: 0.730517; batch adversarial loss: 0.313707\n",
      "epoch 8; iter: 400; batch classifier loss: 0.311287; batch adversarial loss: 0.352602\n",
      "epoch 8; iter: 600; batch classifier loss: 0.458566; batch adversarial loss: 0.450802\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462188; batch adversarial loss: 0.339204\n",
      "epoch 9; iter: 200; batch classifier loss: 0.457555; batch adversarial loss: 0.408506\n",
      "epoch 9; iter: 400; batch classifier loss: 0.610301; batch adversarial loss: 0.565859\n",
      "epoch 9; iter: 600; batch classifier loss: 0.245338; batch adversarial loss: 0.318356\n",
      "epoch 0; iter: 0; batch classifier loss: 117.111732; batch adversarial loss: 1.209591\n",
      "epoch 0; iter: 200; batch classifier loss: 26.262222; batch adversarial loss: 1.111756\n",
      "epoch 0; iter: 400; batch classifier loss: 7.531608; batch adversarial loss: 0.796864\n",
      "epoch 0; iter: 600; batch classifier loss: 5.866117; batch adversarial loss: 0.682004\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668594; batch adversarial loss: 0.564424\n",
      "epoch 1; iter: 200; batch classifier loss: 2.800051; batch adversarial loss: 0.479970\n",
      "epoch 1; iter: 400; batch classifier loss: 3.702494; batch adversarial loss: 0.551066\n",
      "epoch 1; iter: 600; batch classifier loss: 1.488905; batch adversarial loss: 0.438923\n",
      "epoch 2; iter: 0; batch classifier loss: 0.932330; batch adversarial loss: 0.438019\n",
      "epoch 2; iter: 200; batch classifier loss: 0.510760; batch adversarial loss: 0.460417\n",
      "epoch 2; iter: 400; batch classifier loss: 0.742317; batch adversarial loss: 0.393747\n",
      "epoch 2; iter: 600; batch classifier loss: 0.594586; batch adversarial loss: 0.479590\n",
      "epoch 3; iter: 0; batch classifier loss: 0.846335; batch adversarial loss: 0.401350\n",
      "epoch 3; iter: 200; batch classifier loss: 0.550122; batch adversarial loss: 0.426085\n",
      "epoch 3; iter: 400; batch classifier loss: 0.610394; batch adversarial loss: 0.404330\n",
      "epoch 3; iter: 600; batch classifier loss: 1.386669; batch adversarial loss: 0.359833\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589355; batch adversarial loss: 0.444839\n",
      "epoch 4; iter: 200; batch classifier loss: 1.390499; batch adversarial loss: 0.344867\n",
      "epoch 4; iter: 400; batch classifier loss: 0.498599; batch adversarial loss: 0.283462\n",
      "epoch 4; iter: 600; batch classifier loss: 0.526388; batch adversarial loss: 0.405591\n",
      "epoch 5; iter: 0; batch classifier loss: 0.467677; batch adversarial loss: 0.293429\n",
      "epoch 5; iter: 200; batch classifier loss: 0.511828; batch adversarial loss: 0.394045\n",
      "epoch 5; iter: 400; batch classifier loss: 0.609646; batch adversarial loss: 0.382354\n",
      "epoch 5; iter: 600; batch classifier loss: 0.361533; batch adversarial loss: 0.515418\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296674; batch adversarial loss: 0.456469\n",
      "epoch 6; iter: 200; batch classifier loss: 0.506347; batch adversarial loss: 0.330832\n",
      "epoch 6; iter: 400; batch classifier loss: 0.329285; batch adversarial loss: 0.340428\n",
      "epoch 6; iter: 600; batch classifier loss: 0.468475; batch adversarial loss: 0.499029\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400867; batch adversarial loss: 0.507135\n",
      "epoch 7; iter: 200; batch classifier loss: 0.511680; batch adversarial loss: 0.420296\n",
      "epoch 7; iter: 400; batch classifier loss: 0.435730; batch adversarial loss: 0.345934\n",
      "epoch 7; iter: 600; batch classifier loss: 0.351990; batch adversarial loss: 0.469750\n",
      "epoch 8; iter: 0; batch classifier loss: 0.297732; batch adversarial loss: 0.501037\n",
      "epoch 8; iter: 200; batch classifier loss: 0.302732; batch adversarial loss: 0.408518\n",
      "epoch 8; iter: 400; batch classifier loss: 0.387623; batch adversarial loss: 0.428655\n",
      "epoch 8; iter: 600; batch classifier loss: 0.484261; batch adversarial loss: 0.481675\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536013; batch adversarial loss: 0.350872\n",
      "epoch 9; iter: 200; batch classifier loss: 0.480370; batch adversarial loss: 0.357221\n",
      "epoch 9; iter: 400; batch classifier loss: 0.462426; batch adversarial loss: 0.392119\n",
      "epoch 9; iter: 600; batch classifier loss: 0.180516; batch adversarial loss: 0.536499\n",
      "epoch 0; iter: 0; batch classifier loss: 8.146049; batch adversarial loss: 0.633351\n",
      "epoch 0; iter: 200; batch classifier loss: 56.621578; batch adversarial loss: 0.620458\n",
      "epoch 0; iter: 400; batch classifier loss: 10.479225; batch adversarial loss: 0.573641\n",
      "epoch 0; iter: 600; batch classifier loss: 3.769779; batch adversarial loss: 0.505568\n",
      "epoch 1; iter: 0; batch classifier loss: 0.377790; batch adversarial loss: 0.470218\n",
      "epoch 1; iter: 200; batch classifier loss: 3.723029; batch adversarial loss: 0.456454\n",
      "epoch 1; iter: 400; batch classifier loss: 1.477336; batch adversarial loss: 0.472473\n",
      "epoch 1; iter: 600; batch classifier loss: 2.865000; batch adversarial loss: 0.509050\n",
      "epoch 2; iter: 0; batch classifier loss: 1.384266; batch adversarial loss: 0.532420\n",
      "epoch 2; iter: 200; batch classifier loss: 7.370454; batch adversarial loss: 0.462413\n",
      "epoch 2; iter: 400; batch classifier loss: 0.841141; batch adversarial loss: 0.475260\n",
      "epoch 2; iter: 600; batch classifier loss: 2.853237; batch adversarial loss: 0.393834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652193; batch adversarial loss: 0.592053\n",
      "epoch 3; iter: 200; batch classifier loss: 0.496964; batch adversarial loss: 0.464795\n",
      "epoch 3; iter: 400; batch classifier loss: 2.179942; batch adversarial loss: 0.540517\n",
      "epoch 3; iter: 600; batch classifier loss: 0.317607; batch adversarial loss: 0.320841\n",
      "epoch 4; iter: 0; batch classifier loss: 1.334309; batch adversarial loss: 0.374750\n",
      "epoch 4; iter: 200; batch classifier loss: 0.663081; batch adversarial loss: 0.402108\n",
      "epoch 4; iter: 400; batch classifier loss: 0.365142; batch adversarial loss: 0.440329\n",
      "epoch 4; iter: 600; batch classifier loss: 0.486884; batch adversarial loss: 0.519722\n",
      "epoch 5; iter: 0; batch classifier loss: 0.769075; batch adversarial loss: 0.281038\n",
      "epoch 5; iter: 200; batch classifier loss: 0.336257; batch adversarial loss: 0.454544\n",
      "epoch 5; iter: 400; batch classifier loss: 0.397497; batch adversarial loss: 0.402697\n",
      "epoch 5; iter: 600; batch classifier loss: 0.441237; batch adversarial loss: 0.453751\n",
      "epoch 6; iter: 0; batch classifier loss: 0.419214; batch adversarial loss: 0.217952\n",
      "epoch 6; iter: 200; batch classifier loss: 0.643720; batch adversarial loss: 0.452976\n",
      "epoch 6; iter: 400; batch classifier loss: 0.372824; batch adversarial loss: 0.351791\n",
      "epoch 6; iter: 600; batch classifier loss: 0.499362; batch adversarial loss: 0.398258\n",
      "epoch 7; iter: 0; batch classifier loss: 0.444939; batch adversarial loss: 0.433627\n",
      "epoch 7; iter: 200; batch classifier loss: 0.328837; batch adversarial loss: 0.437992\n",
      "epoch 7; iter: 400; batch classifier loss: 0.527522; batch adversarial loss: 0.520954\n",
      "epoch 7; iter: 600; batch classifier loss: 0.568056; batch adversarial loss: 0.320839\n",
      "epoch 8; iter: 0; batch classifier loss: 0.294111; batch adversarial loss: 0.319037\n",
      "epoch 8; iter: 200; batch classifier loss: 0.386767; batch adversarial loss: 0.318966\n",
      "epoch 8; iter: 400; batch classifier loss: 0.484766; batch adversarial loss: 0.318004\n",
      "epoch 8; iter: 600; batch classifier loss: 0.386171; batch adversarial loss: 0.423780\n",
      "epoch 9; iter: 0; batch classifier loss: 0.411690; batch adversarial loss: 0.381365\n",
      "epoch 9; iter: 200; batch classifier loss: 0.377689; batch adversarial loss: 0.340831\n",
      "epoch 9; iter: 400; batch classifier loss: 0.405374; batch adversarial loss: 0.321782\n",
      "epoch 9; iter: 600; batch classifier loss: 0.272680; batch adversarial loss: 0.484857\n",
      "epoch 0; iter: 0; batch classifier loss: 16.122543; batch adversarial loss: 0.806463\n",
      "epoch 0; iter: 200; batch classifier loss: 10.316157; batch adversarial loss: 0.741817\n",
      "epoch 0; iter: 400; batch classifier loss: 18.444622; batch adversarial loss: 0.602603\n",
      "epoch 0; iter: 600; batch classifier loss: 10.486238; batch adversarial loss: 0.553384\n",
      "epoch 1; iter: 0; batch classifier loss: 2.317384; batch adversarial loss: 0.571903\n",
      "epoch 1; iter: 200; batch classifier loss: 8.067363; batch adversarial loss: 0.480159\n",
      "epoch 1; iter: 400; batch classifier loss: 6.009363; batch adversarial loss: 0.466799\n",
      "epoch 1; iter: 600; batch classifier loss: 4.438585; batch adversarial loss: 0.520761\n",
      "epoch 2; iter: 0; batch classifier loss: 4.994757; batch adversarial loss: 0.392172\n",
      "epoch 2; iter: 200; batch classifier loss: 2.697287; batch adversarial loss: 0.400514\n",
      "epoch 2; iter: 400; batch classifier loss: 14.983192; batch adversarial loss: 0.357851\n",
      "epoch 2; iter: 600; batch classifier loss: 1.664607; batch adversarial loss: 0.521688\n",
      "epoch 3; iter: 0; batch classifier loss: 1.332164; batch adversarial loss: 0.352394\n",
      "epoch 3; iter: 200; batch classifier loss: 0.933064; batch adversarial loss: 0.390809\n",
      "epoch 3; iter: 400; batch classifier loss: 1.850722; batch adversarial loss: 0.523972\n",
      "epoch 3; iter: 600; batch classifier loss: 1.400494; batch adversarial loss: 0.527128\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354370; batch adversarial loss: 0.307769\n",
      "epoch 4; iter: 200; batch classifier loss: 0.919661; batch adversarial loss: 0.452054\n",
      "epoch 4; iter: 400; batch classifier loss: 0.668232; batch adversarial loss: 0.371588\n",
      "epoch 4; iter: 600; batch classifier loss: 1.020109; batch adversarial loss: 0.309779\n",
      "epoch 5; iter: 0; batch classifier loss: 0.453404; batch adversarial loss: 0.362081\n",
      "epoch 5; iter: 200; batch classifier loss: 0.442636; batch adversarial loss: 0.463703\n",
      "epoch 5; iter: 400; batch classifier loss: 0.349562; batch adversarial loss: 0.412793\n",
      "epoch 5; iter: 600; batch classifier loss: 0.291245; batch adversarial loss: 0.641366\n",
      "epoch 6; iter: 0; batch classifier loss: 0.705628; batch adversarial loss: 0.356703\n",
      "epoch 6; iter: 200; batch classifier loss: 0.224549; batch adversarial loss: 0.418718\n",
      "epoch 6; iter: 400; batch classifier loss: 0.409407; batch adversarial loss: 0.376830\n",
      "epoch 6; iter: 600; batch classifier loss: 0.332392; batch adversarial loss: 0.487157\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607471; batch adversarial loss: 0.369599\n",
      "epoch 7; iter: 200; batch classifier loss: 0.503780; batch adversarial loss: 0.370000\n",
      "epoch 7; iter: 400; batch classifier loss: 0.518684; batch adversarial loss: 0.327840\n",
      "epoch 7; iter: 600; batch classifier loss: 0.384072; batch adversarial loss: 0.369615\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327466; batch adversarial loss: 0.386962\n",
      "epoch 8; iter: 200; batch classifier loss: 0.294940; batch adversarial loss: 0.354116\n",
      "epoch 8; iter: 400; batch classifier loss: 0.322439; batch adversarial loss: 0.371151\n",
      "epoch 8; iter: 600; batch classifier loss: 0.542733; batch adversarial loss: 0.426165\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563225; batch adversarial loss: 0.539225\n",
      "epoch 9; iter: 200; batch classifier loss: 0.353575; batch adversarial loss: 0.297375\n",
      "epoch 9; iter: 400; batch classifier loss: 0.257929; batch adversarial loss: 0.557487\n",
      "epoch 9; iter: 600; batch classifier loss: 0.316912; batch adversarial loss: 0.468182\n",
      "epoch 0; iter: 0; batch classifier loss: 18.809521; batch adversarial loss: 0.501231\n",
      "epoch 0; iter: 200; batch classifier loss: 17.437309; batch adversarial loss: 0.563966\n",
      "epoch 0; iter: 400; batch classifier loss: 4.034090; batch adversarial loss: 0.567726\n",
      "epoch 0; iter: 600; batch classifier loss: 8.557314; batch adversarial loss: 0.483837\n",
      "epoch 1; iter: 0; batch classifier loss: 2.730715; batch adversarial loss: 0.515862\n",
      "epoch 1; iter: 200; batch classifier loss: 39.152184; batch adversarial loss: 0.432963\n",
      "epoch 1; iter: 400; batch classifier loss: 0.811735; batch adversarial loss: 0.458882\n",
      "epoch 1; iter: 600; batch classifier loss: 0.895421; batch adversarial loss: 0.428113\n",
      "epoch 2; iter: 0; batch classifier loss: 2.661637; batch adversarial loss: 0.488743\n",
      "epoch 2; iter: 200; batch classifier loss: 0.936960; batch adversarial loss: 0.521306\n",
      "epoch 2; iter: 400; batch classifier loss: 1.089544; batch adversarial loss: 0.315943\n",
      "epoch 2; iter: 600; batch classifier loss: 0.440506; batch adversarial loss: 0.413541\n",
      "epoch 3; iter: 0; batch classifier loss: 1.571742; batch adversarial loss: 0.377028\n",
      "epoch 3; iter: 200; batch classifier loss: 0.673255; batch adversarial loss: 0.370871\n",
      "epoch 3; iter: 400; batch classifier loss: 0.846875; batch adversarial loss: 0.460727\n",
      "epoch 3; iter: 600; batch classifier loss: 0.375939; batch adversarial loss: 0.366623\n",
      "epoch 4; iter: 0; batch classifier loss: 0.399285; batch adversarial loss: 0.335456\n",
      "epoch 4; iter: 200; batch classifier loss: 0.722961; batch adversarial loss: 0.485927\n",
      "epoch 4; iter: 400; batch classifier loss: 0.332773; batch adversarial loss: 0.432096\n",
      "epoch 4; iter: 600; batch classifier loss: 0.317638; batch adversarial loss: 0.278396\n",
      "epoch 5; iter: 0; batch classifier loss: 0.505972; batch adversarial loss: 0.387303\n",
      "epoch 5; iter: 200; batch classifier loss: 0.395404; batch adversarial loss: 0.334461\n",
      "epoch 5; iter: 400; batch classifier loss: 0.368517; batch adversarial loss: 0.323832\n",
      "epoch 5; iter: 600; batch classifier loss: 0.354867; batch adversarial loss: 0.457155\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393939; batch adversarial loss: 0.396081\n",
      "epoch 6; iter: 200; batch classifier loss: 0.257278; batch adversarial loss: 0.463225\n",
      "epoch 6; iter: 400; batch classifier loss: 0.468088; batch adversarial loss: 0.454133\n",
      "epoch 6; iter: 600; batch classifier loss: 0.379442; batch adversarial loss: 0.327367\n",
      "epoch 7; iter: 0; batch classifier loss: 0.273930; batch adversarial loss: 0.483043\n",
      "epoch 7; iter: 200; batch classifier loss: 0.449850; batch adversarial loss: 0.438774\n",
      "epoch 7; iter: 400; batch classifier loss: 0.352799; batch adversarial loss: 0.295784\n",
      "epoch 7; iter: 600; batch classifier loss: 1.695613; batch adversarial loss: 0.392304\n",
      "epoch 8; iter: 0; batch classifier loss: 0.244381; batch adversarial loss: 0.476470\n",
      "epoch 8; iter: 200; batch classifier loss: 0.417287; batch adversarial loss: 0.294489\n",
      "epoch 8; iter: 400; batch classifier loss: 0.368140; batch adversarial loss: 0.450618\n",
      "epoch 8; iter: 600; batch classifier loss: 0.266067; batch adversarial loss: 0.515274\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436686; batch adversarial loss: 0.317422\n",
      "epoch 9; iter: 200; batch classifier loss: 0.337517; batch adversarial loss: 0.431224\n",
      "epoch 9; iter: 400; batch classifier loss: 0.321804; batch adversarial loss: 0.331668\n",
      "epoch 9; iter: 600; batch classifier loss: 0.448945; batch adversarial loss: 0.344479\n",
      "epoch 0; iter: 0; batch classifier loss: 64.763367; batch adversarial loss: 0.596724\n",
      "epoch 0; iter: 200; batch classifier loss: 35.378986; batch adversarial loss: 0.597751\n",
      "epoch 0; iter: 400; batch classifier loss: 1.649392; batch adversarial loss: 0.530810\n",
      "epoch 0; iter: 600; batch classifier loss: 8.722153; batch adversarial loss: 0.586917\n",
      "epoch 1; iter: 0; batch classifier loss: 1.166466; batch adversarial loss: 0.509028\n",
      "epoch 1; iter: 200; batch classifier loss: 0.879144; batch adversarial loss: 0.544428\n",
      "epoch 1; iter: 400; batch classifier loss: 5.949043; batch adversarial loss: 0.470714\n",
      "epoch 1; iter: 600; batch classifier loss: 4.359437; batch adversarial loss: 0.400875\n",
      "epoch 2; iter: 0; batch classifier loss: 1.246106; batch adversarial loss: 0.456745\n",
      "epoch 2; iter: 200; batch classifier loss: 0.996325; batch adversarial loss: 0.458758\n",
      "epoch 2; iter: 400; batch classifier loss: 1.771827; batch adversarial loss: 0.327557\n",
      "epoch 2; iter: 600; batch classifier loss: 2.225708; batch adversarial loss: 0.300499\n",
      "epoch 3; iter: 0; batch classifier loss: 1.928352; batch adversarial loss: 0.437920\n",
      "epoch 3; iter: 200; batch classifier loss: 0.287908; batch adversarial loss: 0.632220\n",
      "epoch 3; iter: 400; batch classifier loss: 0.607071; batch adversarial loss: 0.600359\n",
      "epoch 3; iter: 600; batch classifier loss: 0.343607; batch adversarial loss: 0.359487\n",
      "epoch 4; iter: 0; batch classifier loss: 0.413190; batch adversarial loss: 0.400216\n",
      "epoch 4; iter: 200; batch classifier loss: 0.638427; batch adversarial loss: 0.553103\n",
      "epoch 4; iter: 400; batch classifier loss: 0.726189; batch adversarial loss: 0.427166\n",
      "epoch 4; iter: 600; batch classifier loss: 1.213840; batch adversarial loss: 0.379166\n",
      "epoch 5; iter: 0; batch classifier loss: 0.638686; batch adversarial loss: 0.440960\n",
      "epoch 5; iter: 200; batch classifier loss: 0.320403; batch adversarial loss: 0.419326\n",
      "epoch 5; iter: 400; batch classifier loss: 0.545962; batch adversarial loss: 0.406077\n",
      "epoch 5; iter: 600; batch classifier loss: 0.348206; batch adversarial loss: 0.424292\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509742; batch adversarial loss: 0.408948\n",
      "epoch 6; iter: 200; batch classifier loss: 0.386393; batch adversarial loss: 0.326572\n",
      "epoch 6; iter: 400; batch classifier loss: 0.459721; batch adversarial loss: 0.484161\n",
      "epoch 6; iter: 600; batch classifier loss: 0.451364; batch adversarial loss: 0.382677\n",
      "epoch 7; iter: 0; batch classifier loss: 0.468553; batch adversarial loss: 0.463320\n",
      "epoch 7; iter: 200; batch classifier loss: 0.412435; batch adversarial loss: 0.400272\n",
      "epoch 7; iter: 400; batch classifier loss: 0.463459; batch adversarial loss: 0.293165\n",
      "epoch 7; iter: 600; batch classifier loss: 0.253521; batch adversarial loss: 0.342497\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390652; batch adversarial loss: 0.451764\n",
      "epoch 8; iter: 200; batch classifier loss: 0.567681; batch adversarial loss: 0.459027\n",
      "epoch 8; iter: 400; batch classifier loss: 0.352389; batch adversarial loss: 0.372427\n",
      "epoch 8; iter: 600; batch classifier loss: 0.344159; batch adversarial loss: 0.456913\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363091; batch adversarial loss: 0.350747\n",
      "epoch 9; iter: 200; batch classifier loss: 0.454574; batch adversarial loss: 0.390208\n",
      "epoch 9; iter: 400; batch classifier loss: 0.306125; batch adversarial loss: 0.539030\n",
      "epoch 9; iter: 600; batch classifier loss: 0.318446; batch adversarial loss: 0.426609\n",
      "epoch 0; iter: 0; batch classifier loss: 26.366953; batch adversarial loss: 0.638312\n",
      "epoch 0; iter: 200; batch classifier loss: 9.641493; batch adversarial loss: 0.582635\n",
      "epoch 0; iter: 400; batch classifier loss: 1.171381; batch adversarial loss: 0.595562\n",
      "epoch 0; iter: 600; batch classifier loss: 1.637566; batch adversarial loss: 0.531102\n",
      "epoch 1; iter: 0; batch classifier loss: 1.890561; batch adversarial loss: 0.542350\n",
      "epoch 1; iter: 200; batch classifier loss: 5.774996; batch adversarial loss: 0.490064\n",
      "epoch 1; iter: 400; batch classifier loss: 2.592563; batch adversarial loss: 0.433248\n",
      "epoch 1; iter: 600; batch classifier loss: 1.966123; batch adversarial loss: 0.451065\n",
      "epoch 2; iter: 0; batch classifier loss: 6.434560; batch adversarial loss: 0.350116\n",
      "epoch 2; iter: 200; batch classifier loss: 8.035868; batch adversarial loss: 0.457417\n",
      "epoch 2; iter: 400; batch classifier loss: 0.341643; batch adversarial loss: 0.401229\n",
      "epoch 2; iter: 600; batch classifier loss: 0.374780; batch adversarial loss: 0.342443\n",
      "epoch 3; iter: 0; batch classifier loss: 0.441274; batch adversarial loss: 0.474854\n",
      "epoch 3; iter: 200; batch classifier loss: 0.199687; batch adversarial loss: 0.490474\n",
      "epoch 3; iter: 400; batch classifier loss: 0.375541; batch adversarial loss: 0.448890\n",
      "epoch 3; iter: 600; batch classifier loss: 0.418936; batch adversarial loss: 0.321427\n",
      "epoch 4; iter: 0; batch classifier loss: 0.322202; batch adversarial loss: 0.420168\n",
      "epoch 4; iter: 200; batch classifier loss: 0.480071; batch adversarial loss: 0.326538\n",
      "epoch 4; iter: 400; batch classifier loss: 0.646704; batch adversarial loss: 0.424541\n",
      "epoch 4; iter: 600; batch classifier loss: 0.318489; batch adversarial loss: 0.404914\n",
      "epoch 5; iter: 0; batch classifier loss: 0.629555; batch adversarial loss: 0.422229\n",
      "epoch 5; iter: 200; batch classifier loss: 0.430206; batch adversarial loss: 0.450095\n",
      "epoch 5; iter: 400; batch classifier loss: 0.461590; batch adversarial loss: 0.265099\n",
      "epoch 5; iter: 600; batch classifier loss: 0.391787; batch adversarial loss: 0.481638\n",
      "epoch 6; iter: 0; batch classifier loss: 0.365534; batch adversarial loss: 0.428225\n",
      "epoch 6; iter: 200; batch classifier loss: 0.489269; batch adversarial loss: 0.521296\n",
      "epoch 6; iter: 400; batch classifier loss: 0.394895; batch adversarial loss: 0.514280\n",
      "epoch 6; iter: 600; batch classifier loss: 0.289431; batch adversarial loss: 0.246094\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372413; batch adversarial loss: 0.548134\n",
      "epoch 7; iter: 200; batch classifier loss: 0.414757; batch adversarial loss: 0.300280\n",
      "epoch 7; iter: 400; batch classifier loss: 0.574179; batch adversarial loss: 0.371719\n",
      "epoch 7; iter: 600; batch classifier loss: 0.430497; batch adversarial loss: 0.494025\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403731; batch adversarial loss: 0.385433\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387942; batch adversarial loss: 0.402243\n",
      "epoch 8; iter: 400; batch classifier loss: 0.275649; batch adversarial loss: 0.290621\n",
      "epoch 8; iter: 600; batch classifier loss: 0.278771; batch adversarial loss: 0.357284\n",
      "epoch 9; iter: 0; batch classifier loss: 0.250626; batch adversarial loss: 0.367951\n",
      "epoch 9; iter: 200; batch classifier loss: 0.393522; batch adversarial loss: 0.561116\n",
      "epoch 9; iter: 400; batch classifier loss: 0.373314; batch adversarial loss: 0.376832\n",
      "epoch 9; iter: 600; batch classifier loss: 0.319507; batch adversarial loss: 0.290638\n",
      "epoch 0; iter: 0; batch classifier loss: 8.064751; batch adversarial loss: 1.418468\n",
      "epoch 0; iter: 200; batch classifier loss: 21.760687; batch adversarial loss: 1.034774\n",
      "epoch 0; iter: 400; batch classifier loss: 10.192133; batch adversarial loss: 0.613866\n",
      "epoch 0; iter: 600; batch classifier loss: 7.441561; batch adversarial loss: 0.745978\n",
      "epoch 1; iter: 0; batch classifier loss: 10.383271; batch adversarial loss: 0.569193\n",
      "epoch 1; iter: 200; batch classifier loss: 12.423785; batch adversarial loss: 0.493534\n",
      "epoch 1; iter: 400; batch classifier loss: 6.212307; batch adversarial loss: 0.597427\n",
      "epoch 1; iter: 600; batch classifier loss: 0.754756; batch adversarial loss: 0.502525\n",
      "epoch 2; iter: 0; batch classifier loss: 3.500314; batch adversarial loss: 0.471585\n",
      "epoch 2; iter: 200; batch classifier loss: 0.457435; batch adversarial loss: 0.534203\n",
      "epoch 2; iter: 400; batch classifier loss: 0.886977; batch adversarial loss: 0.584257\n",
      "epoch 2; iter: 600; batch classifier loss: 0.535611; batch adversarial loss: 0.420577\n",
      "epoch 3; iter: 0; batch classifier loss: 1.704612; batch adversarial loss: 0.477561\n",
      "epoch 3; iter: 200; batch classifier loss: 10.806044; batch adversarial loss: 0.506442\n",
      "epoch 3; iter: 400; batch classifier loss: 0.393693; batch adversarial loss: 0.448031\n",
      "epoch 3; iter: 600; batch classifier loss: 1.143737; batch adversarial loss: 0.338932\n",
      "epoch 4; iter: 0; batch classifier loss: 0.845008; batch adversarial loss: 0.483180\n",
      "epoch 4; iter: 200; batch classifier loss: 0.697664; batch adversarial loss: 0.512561\n",
      "epoch 4; iter: 400; batch classifier loss: 0.444988; batch adversarial loss: 0.522331\n",
      "epoch 4; iter: 600; batch classifier loss: 0.395409; batch adversarial loss: 0.497863\n",
      "epoch 5; iter: 0; batch classifier loss: 0.604675; batch adversarial loss: 0.396833\n",
      "epoch 5; iter: 200; batch classifier loss: 0.367118; batch adversarial loss: 0.362518\n",
      "epoch 5; iter: 400; batch classifier loss: 0.345617; batch adversarial loss: 0.447519\n",
      "epoch 5; iter: 600; batch classifier loss: 0.381159; batch adversarial loss: 0.460767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.442781; batch adversarial loss: 0.251206\n",
      "epoch 6; iter: 200; batch classifier loss: 0.361024; batch adversarial loss: 0.472642\n",
      "epoch 6; iter: 400; batch classifier loss: 0.369981; batch adversarial loss: 0.475544\n",
      "epoch 6; iter: 600; batch classifier loss: 0.432753; batch adversarial loss: 0.379444\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557376; batch adversarial loss: 0.425735\n",
      "epoch 7; iter: 200; batch classifier loss: 0.490089; batch adversarial loss: 0.397823\n",
      "epoch 7; iter: 400; batch classifier loss: 0.518401; batch adversarial loss: 0.564358\n",
      "epoch 7; iter: 600; batch classifier loss: 0.358640; batch adversarial loss: 0.567669\n",
      "epoch 8; iter: 0; batch classifier loss: 0.380965; batch adversarial loss: 0.537376\n",
      "epoch 8; iter: 200; batch classifier loss: 0.279907; batch adversarial loss: 0.358781\n",
      "epoch 8; iter: 400; batch classifier loss: 0.327533; batch adversarial loss: 0.311018\n",
      "epoch 8; iter: 600; batch classifier loss: 0.330883; batch adversarial loss: 0.463952\n",
      "epoch 9; iter: 0; batch classifier loss: 0.447337; batch adversarial loss: 0.294089\n",
      "epoch 9; iter: 200; batch classifier loss: 0.463955; batch adversarial loss: 0.325988\n",
      "epoch 9; iter: 400; batch classifier loss: 0.294430; batch adversarial loss: 0.469529\n",
      "epoch 9; iter: 600; batch classifier loss: 0.322324; batch adversarial loss: 0.429426\n",
      "epoch 0; iter: 0; batch classifier loss: 39.041286; batch adversarial loss: 0.708844\n",
      "epoch 0; iter: 200; batch classifier loss: 1.194441; batch adversarial loss: 0.619645\n",
      "epoch 0; iter: 400; batch classifier loss: 5.200184; batch adversarial loss: 0.567147\n",
      "epoch 0; iter: 600; batch classifier loss: 6.950322; batch adversarial loss: 0.538875\n",
      "epoch 1; iter: 0; batch classifier loss: 7.537108; batch adversarial loss: 0.440935\n",
      "epoch 1; iter: 200; batch classifier loss: 3.967776; batch adversarial loss: 0.475043\n",
      "epoch 1; iter: 400; batch classifier loss: 0.455273; batch adversarial loss: 0.425466\n",
      "epoch 1; iter: 600; batch classifier loss: 2.276263; batch adversarial loss: 0.459114\n",
      "epoch 2; iter: 0; batch classifier loss: 1.357068; batch adversarial loss: 0.451641\n",
      "epoch 2; iter: 200; batch classifier loss: 1.805458; batch adversarial loss: 0.453190\n",
      "epoch 2; iter: 400; batch classifier loss: 0.275832; batch adversarial loss: 0.446444\n",
      "epoch 2; iter: 600; batch classifier loss: 0.324399; batch adversarial loss: 0.390645\n",
      "epoch 3; iter: 0; batch classifier loss: 4.705171; batch adversarial loss: 0.385542\n",
      "epoch 3; iter: 200; batch classifier loss: 0.414313; batch adversarial loss: 0.587674\n",
      "epoch 3; iter: 400; batch classifier loss: 0.286060; batch adversarial loss: 0.346963\n",
      "epoch 3; iter: 600; batch classifier loss: 0.365159; batch adversarial loss: 0.456592\n",
      "epoch 4; iter: 0; batch classifier loss: 0.624586; batch adversarial loss: 0.406107\n",
      "epoch 4; iter: 200; batch classifier loss: 0.319435; batch adversarial loss: 0.400916\n",
      "epoch 4; iter: 400; batch classifier loss: 0.711812; batch adversarial loss: 0.354507\n",
      "epoch 4; iter: 600; batch classifier loss: 1.117846; batch adversarial loss: 0.525592\n",
      "epoch 5; iter: 0; batch classifier loss: 2.299352; batch adversarial loss: 0.366716\n",
      "epoch 5; iter: 200; batch classifier loss: 0.283141; batch adversarial loss: 0.444295\n",
      "epoch 5; iter: 400; batch classifier loss: 0.614539; batch adversarial loss: 0.351484\n",
      "epoch 5; iter: 600; batch classifier loss: 0.469494; batch adversarial loss: 0.495427\n",
      "epoch 6; iter: 0; batch classifier loss: 0.428151; batch adversarial loss: 0.359844\n",
      "epoch 6; iter: 200; batch classifier loss: 0.346619; batch adversarial loss: 0.470008\n",
      "epoch 6; iter: 400; batch classifier loss: 0.521000; batch adversarial loss: 0.386092\n",
      "epoch 6; iter: 600; batch classifier loss: 0.348911; batch adversarial loss: 0.503309\n",
      "epoch 7; iter: 0; batch classifier loss: 0.244706; batch adversarial loss: 0.486534\n",
      "epoch 7; iter: 200; batch classifier loss: 0.421320; batch adversarial loss: 0.409472\n",
      "epoch 7; iter: 400; batch classifier loss: 0.343379; batch adversarial loss: 0.369478\n",
      "epoch 7; iter: 600; batch classifier loss: 0.443512; batch adversarial loss: 0.377516\n",
      "epoch 8; iter: 0; batch classifier loss: 0.387045; batch adversarial loss: 0.426008\n",
      "epoch 8; iter: 200; batch classifier loss: 0.526414; batch adversarial loss: 0.508264\n",
      "epoch 8; iter: 400; batch classifier loss: 0.238004; batch adversarial loss: 0.435480\n",
      "epoch 8; iter: 600; batch classifier loss: 0.298905; batch adversarial loss: 0.378900\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409962; batch adversarial loss: 0.454568\n",
      "epoch 9; iter: 200; batch classifier loss: 0.208445; batch adversarial loss: 0.374817\n",
      "epoch 9; iter: 400; batch classifier loss: 0.448947; batch adversarial loss: 0.348918\n",
      "epoch 9; iter: 600; batch classifier loss: 0.364811; batch adversarial loss: 0.510927\n",
      "epoch 0; iter: 0; batch classifier loss: 30.410334; batch adversarial loss: 0.764696\n",
      "epoch 0; iter: 200; batch classifier loss: 5.495777; batch adversarial loss: 1.184698\n",
      "epoch 0; iter: 400; batch classifier loss: 4.684553; batch adversarial loss: 0.924632\n",
      "epoch 0; iter: 600; batch classifier loss: 8.591801; batch adversarial loss: 0.707172\n",
      "epoch 1; iter: 0; batch classifier loss: 3.787754; batch adversarial loss: 0.555434\n",
      "epoch 1; iter: 200; batch classifier loss: 0.655794; batch adversarial loss: 0.512243\n",
      "epoch 1; iter: 400; batch classifier loss: 5.783245; batch adversarial loss: 0.563182\n",
      "epoch 1; iter: 600; batch classifier loss: 8.467188; batch adversarial loss: 0.464202\n",
      "epoch 2; iter: 0; batch classifier loss: 3.021926; batch adversarial loss: 0.410363\n",
      "epoch 2; iter: 200; batch classifier loss: 2.911392; batch adversarial loss: 0.477611\n",
      "epoch 2; iter: 400; batch classifier loss: 1.722382; batch adversarial loss: 0.506100\n",
      "epoch 2; iter: 600; batch classifier loss: 1.223168; batch adversarial loss: 0.498603\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651346; batch adversarial loss: 0.515720\n",
      "epoch 3; iter: 200; batch classifier loss: 1.096542; batch adversarial loss: 0.321559\n",
      "epoch 3; iter: 400; batch classifier loss: 0.814386; batch adversarial loss: 0.557017\n",
      "epoch 3; iter: 600; batch classifier loss: 0.383753; batch adversarial loss: 0.363928\n",
      "epoch 4; iter: 0; batch classifier loss: 0.962466; batch adversarial loss: 0.400465\n",
      "epoch 4; iter: 200; batch classifier loss: 0.475482; batch adversarial loss: 0.359496\n",
      "epoch 4; iter: 400; batch classifier loss: 0.999004; batch adversarial loss: 0.477309\n",
      "epoch 4; iter: 600; batch classifier loss: 0.840769; batch adversarial loss: 0.503990\n",
      "epoch 5; iter: 0; batch classifier loss: 0.498679; batch adversarial loss: 0.372781\n",
      "epoch 5; iter: 200; batch classifier loss: 1.781698; batch adversarial loss: 0.379086\n",
      "epoch 5; iter: 400; batch classifier loss: 0.429901; batch adversarial loss: 0.369755\n",
      "epoch 5; iter: 600; batch classifier loss: 0.408319; batch adversarial loss: 0.347537\n",
      "epoch 6; iter: 0; batch classifier loss: 0.469612; batch adversarial loss: 0.377756\n",
      "epoch 6; iter: 200; batch classifier loss: 0.345914; batch adversarial loss: 0.428977\n",
      "epoch 6; iter: 400; batch classifier loss: 0.342157; batch adversarial loss: 0.400353\n",
      "epoch 6; iter: 600; batch classifier loss: 0.357675; batch adversarial loss: 0.420168\n",
      "epoch 7; iter: 0; batch classifier loss: 0.396071; batch adversarial loss: 0.309136\n",
      "epoch 7; iter: 200; batch classifier loss: 0.940999; batch adversarial loss: 0.369471\n",
      "epoch 7; iter: 400; batch classifier loss: 0.491209; batch adversarial loss: 0.397355\n",
      "epoch 7; iter: 600; batch classifier loss: 0.322827; batch adversarial loss: 0.406344\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434007; batch adversarial loss: 0.447965\n",
      "epoch 8; iter: 200; batch classifier loss: 0.435488; batch adversarial loss: 0.298062\n",
      "epoch 8; iter: 400; batch classifier loss: 0.442678; batch adversarial loss: 0.409946\n",
      "epoch 8; iter: 600; batch classifier loss: 0.421116; batch adversarial loss: 0.292365\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349191; batch adversarial loss: 0.456414\n",
      "epoch 9; iter: 200; batch classifier loss: 0.524860; batch adversarial loss: 0.366269\n",
      "epoch 9; iter: 400; batch classifier loss: 0.272677; batch adversarial loss: 0.355170\n",
      "epoch 9; iter: 600; batch classifier loss: 0.368349; batch adversarial loss: 0.429917\n",
      "epoch 0; iter: 0; batch classifier loss: 18.542664; batch adversarial loss: 0.642166\n",
      "epoch 0; iter: 200; batch classifier loss: 9.577621; batch adversarial loss: 0.599256\n",
      "epoch 0; iter: 400; batch classifier loss: 0.696881; batch adversarial loss: 0.505443\n",
      "epoch 0; iter: 600; batch classifier loss: 8.819912; batch adversarial loss: 0.500381\n",
      "epoch 1; iter: 0; batch classifier loss: 1.563975; batch adversarial loss: 0.526204\n",
      "epoch 1; iter: 200; batch classifier loss: 4.759679; batch adversarial loss: 0.471270\n",
      "epoch 1; iter: 400; batch classifier loss: 0.444996; batch adversarial loss: 0.508615\n",
      "epoch 1; iter: 600; batch classifier loss: 0.739767; batch adversarial loss: 0.384092\n",
      "epoch 2; iter: 0; batch classifier loss: 0.430374; batch adversarial loss: 0.471890\n",
      "epoch 2; iter: 200; batch classifier loss: 0.293910; batch adversarial loss: 0.423387\n",
      "epoch 2; iter: 400; batch classifier loss: 1.191498; batch adversarial loss: 0.405295\n",
      "epoch 2; iter: 600; batch classifier loss: 0.551324; batch adversarial loss: 0.477286\n",
      "epoch 3; iter: 0; batch classifier loss: 3.625451; batch adversarial loss: 0.461942\n",
      "epoch 3; iter: 200; batch classifier loss: 0.457585; batch adversarial loss: 0.402072\n",
      "epoch 3; iter: 400; batch classifier loss: 0.614313; batch adversarial loss: 0.436127\n",
      "epoch 3; iter: 600; batch classifier loss: 0.420119; batch adversarial loss: 0.418161\n",
      "epoch 4; iter: 0; batch classifier loss: 1.463748; batch adversarial loss: 0.477424\n",
      "epoch 4; iter: 200; batch classifier loss: 0.383719; batch adversarial loss: 0.361605\n",
      "epoch 4; iter: 400; batch classifier loss: 0.702561; batch adversarial loss: 0.303034\n",
      "epoch 4; iter: 600; batch classifier loss: 0.419223; batch adversarial loss: 0.337398\n",
      "epoch 5; iter: 0; batch classifier loss: 1.453472; batch adversarial loss: 0.467294\n",
      "epoch 5; iter: 200; batch classifier loss: 0.282299; batch adversarial loss: 0.393527\n",
      "epoch 5; iter: 400; batch classifier loss: 0.467465; batch adversarial loss: 0.562338\n",
      "epoch 5; iter: 600; batch classifier loss: 0.552364; batch adversarial loss: 0.455283\n",
      "epoch 6; iter: 0; batch classifier loss: 0.339323; batch adversarial loss: 0.413048\n",
      "epoch 6; iter: 200; batch classifier loss: 0.412072; batch adversarial loss: 0.464766\n",
      "epoch 6; iter: 400; batch classifier loss: 0.408189; batch adversarial loss: 0.401196\n",
      "epoch 6; iter: 600; batch classifier loss: 0.546568; batch adversarial loss: 0.467538\n",
      "epoch 7; iter: 0; batch classifier loss: 0.455659; batch adversarial loss: 0.345588\n",
      "epoch 7; iter: 200; batch classifier loss: 0.293049; batch adversarial loss: 0.353140\n",
      "epoch 7; iter: 400; batch classifier loss: 0.283765; batch adversarial loss: 0.458257\n",
      "epoch 7; iter: 600; batch classifier loss: 0.280077; batch adversarial loss: 0.512514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.255919; batch adversarial loss: 0.429613\n",
      "epoch 8; iter: 200; batch classifier loss: 0.503912; batch adversarial loss: 0.458354\n",
      "epoch 8; iter: 400; batch classifier loss: 0.564742; batch adversarial loss: 0.350833\n",
      "epoch 8; iter: 600; batch classifier loss: 0.304933; batch adversarial loss: 0.486802\n",
      "epoch 9; iter: 0; batch classifier loss: 0.355258; batch adversarial loss: 0.379319\n",
      "epoch 9; iter: 200; batch classifier loss: 0.283623; batch adversarial loss: 0.370603\n",
      "epoch 9; iter: 400; batch classifier loss: 0.258637; batch adversarial loss: 0.411818\n",
      "epoch 9; iter: 600; batch classifier loss: 0.422967; batch adversarial loss: 0.485417\n",
      "epoch 0; iter: 0; batch classifier loss: 57.808891; batch adversarial loss: 0.711324\n",
      "epoch 0; iter: 200; batch classifier loss: 3.432083; batch adversarial loss: 0.615563\n",
      "epoch 0; iter: 400; batch classifier loss: 12.953734; batch adversarial loss: 0.568906\n",
      "epoch 0; iter: 600; batch classifier loss: 3.025220; batch adversarial loss: 0.494862\n",
      "epoch 1; iter: 0; batch classifier loss: 5.290481; batch adversarial loss: 0.508440\n",
      "epoch 1; iter: 200; batch classifier loss: 1.043702; batch adversarial loss: 0.483682\n",
      "epoch 1; iter: 400; batch classifier loss: 4.777614; batch adversarial loss: 0.354697\n",
      "epoch 1; iter: 600; batch classifier loss: 0.993885; batch adversarial loss: 0.405177\n",
      "epoch 2; iter: 0; batch classifier loss: 1.017272; batch adversarial loss: 0.455760\n",
      "epoch 2; iter: 200; batch classifier loss: 0.671892; batch adversarial loss: 0.394348\n",
      "epoch 2; iter: 400; batch classifier loss: 3.054275; batch adversarial loss: 0.344454\n",
      "epoch 2; iter: 600; batch classifier loss: 0.655999; batch adversarial loss: 0.410330\n",
      "epoch 3; iter: 0; batch classifier loss: 1.717548; batch adversarial loss: 0.399752\n",
      "epoch 3; iter: 200; batch classifier loss: 1.569762; batch adversarial loss: 0.453291\n",
      "epoch 3; iter: 400; batch classifier loss: 0.481527; batch adversarial loss: 0.469078\n",
      "epoch 3; iter: 600; batch classifier loss: 0.307615; batch adversarial loss: 0.486021\n",
      "epoch 4; iter: 0; batch classifier loss: 1.753598; batch adversarial loss: 0.332496\n",
      "epoch 4; iter: 200; batch classifier loss: 0.571366; batch adversarial loss: 0.359273\n",
      "epoch 4; iter: 400; batch classifier loss: 1.049331; batch adversarial loss: 0.417874\n",
      "epoch 4; iter: 600; batch classifier loss: 0.715180; batch adversarial loss: 0.527470\n",
      "epoch 5; iter: 0; batch classifier loss: 0.495818; batch adversarial loss: 0.422765\n",
      "epoch 5; iter: 200; batch classifier loss: 0.361178; batch adversarial loss: 0.469989\n",
      "epoch 5; iter: 400; batch classifier loss: 0.387957; batch adversarial loss: 0.416794\n",
      "epoch 5; iter: 600; batch classifier loss: 0.283481; batch adversarial loss: 0.433780\n",
      "epoch 6; iter: 0; batch classifier loss: 0.456558; batch adversarial loss: 0.362268\n",
      "epoch 6; iter: 200; batch classifier loss: 0.498369; batch adversarial loss: 0.402967\n",
      "epoch 6; iter: 400; batch classifier loss: 0.346140; batch adversarial loss: 0.517156\n",
      "epoch 6; iter: 600; batch classifier loss: 0.302771; batch adversarial loss: 0.505062\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377782; batch adversarial loss: 0.484361\n",
      "epoch 7; iter: 200; batch classifier loss: 0.373247; batch adversarial loss: 0.519087\n",
      "epoch 7; iter: 400; batch classifier loss: 0.302809; batch adversarial loss: 0.402721\n",
      "epoch 7; iter: 600; batch classifier loss: 0.278243; batch adversarial loss: 0.547061\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327766; batch adversarial loss: 0.556062\n",
      "epoch 8; iter: 200; batch classifier loss: 0.164393; batch adversarial loss: 0.268636\n",
      "epoch 8; iter: 400; batch classifier loss: 0.355308; batch adversarial loss: 0.424784\n",
      "epoch 8; iter: 600; batch classifier loss: 0.326989; batch adversarial loss: 0.372445\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401864; batch adversarial loss: 0.324707\n",
      "epoch 9; iter: 200; batch classifier loss: 0.380178; batch adversarial loss: 0.401178\n",
      "epoch 9; iter: 400; batch classifier loss: 0.417246; batch adversarial loss: 0.319407\n",
      "epoch 9; iter: 600; batch classifier loss: 0.385358; batch adversarial loss: 0.347636\n",
      "epoch 0; iter: 0; batch classifier loss: 14.375153; batch adversarial loss: 0.619688\n",
      "epoch 0; iter: 200; batch classifier loss: 10.531994; batch adversarial loss: 0.601353\n",
      "epoch 0; iter: 400; batch classifier loss: 12.620678; batch adversarial loss: 0.548889\n",
      "epoch 0; iter: 600; batch classifier loss: 1.935864; batch adversarial loss: 0.563125\n",
      "epoch 1; iter: 0; batch classifier loss: 0.997966; batch adversarial loss: 0.471466\n",
      "epoch 1; iter: 200; batch classifier loss: 0.324601; batch adversarial loss: 0.478477\n",
      "epoch 1; iter: 400; batch classifier loss: 1.027291; batch adversarial loss: 0.537123\n",
      "epoch 1; iter: 600; batch classifier loss: 1.270542; batch adversarial loss: 0.566936\n",
      "epoch 2; iter: 0; batch classifier loss: 1.339415; batch adversarial loss: 0.516310\n",
      "epoch 2; iter: 200; batch classifier loss: 0.819298; batch adversarial loss: 0.386455\n",
      "epoch 2; iter: 400; batch classifier loss: 1.862625; batch adversarial loss: 0.478575\n",
      "epoch 2; iter: 600; batch classifier loss: 0.406203; batch adversarial loss: 0.345419\n",
      "epoch 3; iter: 0; batch classifier loss: 1.112301; batch adversarial loss: 0.432577\n",
      "epoch 3; iter: 200; batch classifier loss: 1.402129; batch adversarial loss: 0.446287\n",
      "epoch 3; iter: 400; batch classifier loss: 0.610134; batch adversarial loss: 0.285747\n",
      "epoch 3; iter: 600; batch classifier loss: 3.701093; batch adversarial loss: 0.495548\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555241; batch adversarial loss: 0.425520\n",
      "epoch 4; iter: 200; batch classifier loss: 1.503247; batch adversarial loss: 0.464483\n",
      "epoch 4; iter: 400; batch classifier loss: 0.416940; batch adversarial loss: 0.395435\n",
      "epoch 4; iter: 600; batch classifier loss: 0.636510; batch adversarial loss: 0.423861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373060; batch adversarial loss: 0.374275\n",
      "epoch 5; iter: 200; batch classifier loss: 0.519396; batch adversarial loss: 0.379818\n",
      "epoch 5; iter: 400; batch classifier loss: 0.452905; batch adversarial loss: 0.312873\n",
      "epoch 5; iter: 600; batch classifier loss: 0.380948; batch adversarial loss: 0.481458\n",
      "epoch 6; iter: 0; batch classifier loss: 0.363471; batch adversarial loss: 0.295111\n",
      "epoch 6; iter: 200; batch classifier loss: 0.498042; batch adversarial loss: 0.329651\n",
      "epoch 6; iter: 400; batch classifier loss: 0.415218; batch adversarial loss: 0.429546\n",
      "epoch 6; iter: 600; batch classifier loss: 0.413917; batch adversarial loss: 0.399406\n",
      "epoch 7; iter: 0; batch classifier loss: 0.302772; batch adversarial loss: 0.326492\n",
      "epoch 7; iter: 200; batch classifier loss: 0.620589; batch adversarial loss: 0.457729\n",
      "epoch 7; iter: 400; batch classifier loss: 0.233461; batch adversarial loss: 0.401651\n",
      "epoch 7; iter: 600; batch classifier loss: 0.339186; batch adversarial loss: 0.532785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.364333; batch adversarial loss: 0.397952\n",
      "epoch 8; iter: 200; batch classifier loss: 0.295530; batch adversarial loss: 0.532760\n",
      "epoch 8; iter: 400; batch classifier loss: 0.459703; batch adversarial loss: 0.426649\n",
      "epoch 8; iter: 600; batch classifier loss: 0.503146; batch adversarial loss: 0.466776\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480499; batch adversarial loss: 0.340914\n",
      "epoch 9; iter: 200; batch classifier loss: 0.424624; batch adversarial loss: 0.493099\n",
      "epoch 9; iter: 400; batch classifier loss: 0.364999; batch adversarial loss: 0.549252\n",
      "epoch 9; iter: 600; batch classifier loss: 0.308369; batch adversarial loss: 0.315926\n",
      "epoch 0; iter: 0; batch classifier loss: 7.813500; batch adversarial loss: 0.710795\n",
      "epoch 0; iter: 200; batch classifier loss: 1.242960; batch adversarial loss: 0.607191\n",
      "epoch 0; iter: 400; batch classifier loss: 10.720001; batch adversarial loss: 0.562234\n",
      "epoch 0; iter: 600; batch classifier loss: 1.105900; batch adversarial loss: 0.535455\n",
      "epoch 1; iter: 0; batch classifier loss: 12.569792; batch adversarial loss: 0.401850\n",
      "epoch 1; iter: 200; batch classifier loss: 4.028617; batch adversarial loss: 0.477267\n",
      "epoch 1; iter: 400; batch classifier loss: 2.159602; batch adversarial loss: 0.402628\n",
      "epoch 1; iter: 600; batch classifier loss: 0.362490; batch adversarial loss: 0.472335\n",
      "epoch 2; iter: 0; batch classifier loss: 1.453123; batch adversarial loss: 0.558854\n",
      "epoch 2; iter: 200; batch classifier loss: 5.208351; batch adversarial loss: 0.442821\n",
      "epoch 2; iter: 400; batch classifier loss: 4.969541; batch adversarial loss: 0.430575\n",
      "epoch 2; iter: 600; batch classifier loss: 1.095247; batch adversarial loss: 0.423973\n",
      "epoch 3; iter: 0; batch classifier loss: 1.052537; batch adversarial loss: 0.445242\n",
      "epoch 3; iter: 200; batch classifier loss: 1.781144; batch adversarial loss: 0.504290\n",
      "epoch 3; iter: 400; batch classifier loss: 1.575037; batch adversarial loss: 0.486211\n",
      "epoch 3; iter: 600; batch classifier loss: 1.149020; batch adversarial loss: 0.281819\n",
      "epoch 4; iter: 0; batch classifier loss: 0.561099; batch adversarial loss: 0.305428\n",
      "epoch 4; iter: 200; batch classifier loss: 0.354306; batch adversarial loss: 0.465815\n",
      "epoch 4; iter: 400; batch classifier loss: 0.411834; batch adversarial loss: 0.297723\n",
      "epoch 4; iter: 600; batch classifier loss: 0.747360; batch adversarial loss: 0.352519\n",
      "epoch 5; iter: 0; batch classifier loss: 0.376164; batch adversarial loss: 0.221940\n",
      "epoch 5; iter: 200; batch classifier loss: 0.366542; batch adversarial loss: 0.507151\n",
      "epoch 5; iter: 400; batch classifier loss: 0.465737; batch adversarial loss: 0.456333\n",
      "epoch 5; iter: 600; batch classifier loss: 0.428199; batch adversarial loss: 0.562811\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296291; batch adversarial loss: 0.485443\n",
      "epoch 6; iter: 200; batch classifier loss: 0.297092; batch adversarial loss: 0.400200\n",
      "epoch 6; iter: 400; batch classifier loss: 0.359210; batch adversarial loss: 0.322807\n",
      "epoch 6; iter: 600; batch classifier loss: 0.370377; batch adversarial loss: 0.543513\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360550; batch adversarial loss: 0.321382\n",
      "epoch 7; iter: 200; batch classifier loss: 0.347353; batch adversarial loss: 0.444721\n",
      "epoch 7; iter: 400; batch classifier loss: 0.401882; batch adversarial loss: 0.485525\n",
      "epoch 7; iter: 600; batch classifier loss: 0.603898; batch adversarial loss: 0.245438\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317487; batch adversarial loss: 0.323945\n",
      "epoch 8; iter: 200; batch classifier loss: 0.451689; batch adversarial loss: 0.404930\n",
      "epoch 8; iter: 400; batch classifier loss: 0.362882; batch adversarial loss: 0.457210\n",
      "epoch 8; iter: 600; batch classifier loss: 0.509766; batch adversarial loss: 0.468877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357979; batch adversarial loss: 0.542024\n",
      "epoch 9; iter: 200; batch classifier loss: 0.367684; batch adversarial loss: 0.370059\n",
      "epoch 9; iter: 400; batch classifier loss: 0.315359; batch adversarial loss: 0.396335\n",
      "epoch 9; iter: 600; batch classifier loss: 0.327634; batch adversarial loss: 0.344439\n",
      "epoch 0; iter: 0; batch classifier loss: 21.229128; batch adversarial loss: 0.586215\n",
      "epoch 0; iter: 200; batch classifier loss: 9.413989; batch adversarial loss: 0.644097\n",
      "epoch 0; iter: 400; batch classifier loss: 5.933357; batch adversarial loss: 0.544629\n",
      "epoch 0; iter: 600; batch classifier loss: 7.156433; batch adversarial loss: 0.459229\n",
      "epoch 1; iter: 0; batch classifier loss: 3.565052; batch adversarial loss: 0.391500\n",
      "epoch 1; iter: 200; batch classifier loss: 5.888924; batch adversarial loss: 0.514442\n",
      "epoch 1; iter: 400; batch classifier loss: 2.179438; batch adversarial loss: 0.338114\n",
      "epoch 1; iter: 600; batch classifier loss: 1.459605; batch adversarial loss: 0.421455\n",
      "epoch 2; iter: 0; batch classifier loss: 4.319108; batch adversarial loss: 0.408007\n",
      "epoch 2; iter: 200; batch classifier loss: 1.409212; batch adversarial loss: 0.443077\n",
      "epoch 2; iter: 400; batch classifier loss: 0.805732; batch adversarial loss: 0.500298\n",
      "epoch 2; iter: 600; batch classifier loss: 0.550300; batch adversarial loss: 0.326954\n",
      "epoch 3; iter: 0; batch classifier loss: 1.859596; batch adversarial loss: 0.278300\n",
      "epoch 3; iter: 200; batch classifier loss: 0.734075; batch adversarial loss: 0.356723\n",
      "epoch 3; iter: 400; batch classifier loss: 1.224948; batch adversarial loss: 0.398922\n",
      "epoch 3; iter: 600; batch classifier loss: 0.332275; batch adversarial loss: 0.506516\n",
      "epoch 4; iter: 0; batch classifier loss: 2.299358; batch adversarial loss: 0.408528\n",
      "epoch 4; iter: 200; batch classifier loss: 0.988216; batch adversarial loss: 0.370092\n",
      "epoch 4; iter: 400; batch classifier loss: 0.560990; batch adversarial loss: 0.426616\n",
      "epoch 4; iter: 600; batch classifier loss: 0.397433; batch adversarial loss: 0.459541\n",
      "epoch 5; iter: 0; batch classifier loss: 0.421517; batch adversarial loss: 0.424070\n",
      "epoch 5; iter: 200; batch classifier loss: 0.502913; batch adversarial loss: 0.401111\n",
      "epoch 5; iter: 400; batch classifier loss: 0.408408; batch adversarial loss: 0.409630\n",
      "epoch 5; iter: 600; batch classifier loss: 0.698003; batch adversarial loss: 0.537197\n",
      "epoch 6; iter: 0; batch classifier loss: 0.323273; batch adversarial loss: 0.485865\n",
      "epoch 6; iter: 200; batch classifier loss: 0.301289; batch adversarial loss: 0.296187\n",
      "epoch 6; iter: 400; batch classifier loss: 0.867564; batch adversarial loss: 0.385488\n",
      "epoch 6; iter: 600; batch classifier loss: 0.348230; batch adversarial loss: 0.399050\n",
      "epoch 7; iter: 0; batch classifier loss: 0.404237; batch adversarial loss: 0.490984\n",
      "epoch 7; iter: 200; batch classifier loss: 0.424179; batch adversarial loss: 0.461973\n",
      "epoch 7; iter: 400; batch classifier loss: 0.362681; batch adversarial loss: 0.393051\n",
      "epoch 7; iter: 600; batch classifier loss: 0.444958; batch adversarial loss: 0.317810\n",
      "epoch 8; iter: 0; batch classifier loss: 0.330595; batch adversarial loss: 0.356702\n",
      "epoch 8; iter: 200; batch classifier loss: 0.441641; batch adversarial loss: 0.425346\n",
      "epoch 8; iter: 400; batch classifier loss: 0.441483; batch adversarial loss: 0.490568\n",
      "epoch 8; iter: 600; batch classifier loss: 0.374917; batch adversarial loss: 0.398488\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367363; batch adversarial loss: 0.401436\n",
      "epoch 9; iter: 200; batch classifier loss: 0.320396; batch adversarial loss: 0.319046\n",
      "epoch 9; iter: 400; batch classifier loss: 0.328583; batch adversarial loss: 0.427998\n",
      "epoch 9; iter: 600; batch classifier loss: 0.384740; batch adversarial loss: 0.556899\n",
      "epoch 0; iter: 0; batch classifier loss: 2.408025; batch adversarial loss: 0.661359\n",
      "epoch 0; iter: 200; batch classifier loss: 4.661237; batch adversarial loss: 0.585234\n",
      "epoch 0; iter: 400; batch classifier loss: 5.625966; batch adversarial loss: 0.562849\n",
      "epoch 0; iter: 600; batch classifier loss: 6.601228; batch adversarial loss: 0.527558\n",
      "epoch 1; iter: 0; batch classifier loss: 2.197672; batch adversarial loss: 0.466204\n",
      "epoch 1; iter: 200; batch classifier loss: 0.523343; batch adversarial loss: 0.452352\n",
      "epoch 1; iter: 400; batch classifier loss: 1.244326; batch adversarial loss: 0.397717\n",
      "epoch 1; iter: 600; batch classifier loss: 3.503564; batch adversarial loss: 0.329167\n",
      "epoch 2; iter: 0; batch classifier loss: 1.476047; batch adversarial loss: 0.339040\n",
      "epoch 2; iter: 200; batch classifier loss: 4.737640; batch adversarial loss: 0.315119\n",
      "epoch 2; iter: 400; batch classifier loss: 0.297842; batch adversarial loss: 0.519564\n",
      "epoch 2; iter: 600; batch classifier loss: 1.386771; batch adversarial loss: 0.368923\n",
      "epoch 3; iter: 0; batch classifier loss: 0.331771; batch adversarial loss: 0.427734\n",
      "epoch 3; iter: 200; batch classifier loss: 0.914955; batch adversarial loss: 0.402817\n",
      "epoch 3; iter: 400; batch classifier loss: 0.614915; batch adversarial loss: 0.366558\n",
      "epoch 3; iter: 600; batch classifier loss: 0.558274; batch adversarial loss: 0.667570\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422084; batch adversarial loss: 0.488768\n",
      "epoch 4; iter: 200; batch classifier loss: 0.462382; batch adversarial loss: 0.376147\n",
      "epoch 4; iter: 400; batch classifier loss: 0.259390; batch adversarial loss: 0.430418\n",
      "epoch 4; iter: 600; batch classifier loss: 0.477108; batch adversarial loss: 0.354927\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322183; batch adversarial loss: 0.349280\n",
      "epoch 5; iter: 200; batch classifier loss: 0.346493; batch adversarial loss: 0.306247\n",
      "epoch 5; iter: 400; batch classifier loss: 0.390452; batch adversarial loss: 0.320873\n",
      "epoch 5; iter: 600; batch classifier loss: 0.382657; batch adversarial loss: 0.453179\n",
      "epoch 6; iter: 0; batch classifier loss: 0.316635; batch adversarial loss: 0.500527\n",
      "epoch 6; iter: 200; batch classifier loss: 0.363422; batch adversarial loss: 0.501371\n",
      "epoch 6; iter: 400; batch classifier loss: 0.386526; batch adversarial loss: 0.476614\n",
      "epoch 6; iter: 600; batch classifier loss: 0.383835; batch adversarial loss: 0.347005\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485883; batch adversarial loss: 0.306790\n",
      "epoch 7; iter: 200; batch classifier loss: 0.386661; batch adversarial loss: 0.350515\n",
      "epoch 7; iter: 400; batch classifier loss: 0.303150; batch adversarial loss: 0.297942\n",
      "epoch 7; iter: 600; batch classifier loss: 0.423231; batch adversarial loss: 0.457679\n",
      "epoch 8; iter: 0; batch classifier loss: 0.284181; batch adversarial loss: 0.534837\n",
      "epoch 8; iter: 200; batch classifier loss: 0.415650; batch adversarial loss: 0.488811\n",
      "epoch 8; iter: 400; batch classifier loss: 0.474560; batch adversarial loss: 0.375176\n",
      "epoch 8; iter: 600; batch classifier loss: 0.324184; batch adversarial loss: 0.465733\n",
      "epoch 9; iter: 0; batch classifier loss: 0.493006; batch adversarial loss: 0.346623\n",
      "epoch 9; iter: 200; batch classifier loss: 0.491336; batch adversarial loss: 0.341733\n",
      "epoch 9; iter: 400; batch classifier loss: 0.829946; batch adversarial loss: 0.405894\n",
      "epoch 9; iter: 600; batch classifier loss: 0.346107; batch adversarial loss: 0.319609\n",
      "epoch 0; iter: 0; batch classifier loss: 38.491856; batch adversarial loss: 0.685701\n",
      "epoch 0; iter: 200; batch classifier loss: 25.714296; batch adversarial loss: 0.664382\n",
      "epoch 0; iter: 400; batch classifier loss: 4.778346; batch adversarial loss: 0.614339\n",
      "epoch 0; iter: 600; batch classifier loss: 7.985955; batch adversarial loss: 0.590105\n",
      "epoch 1; iter: 0; batch classifier loss: 6.597237; batch adversarial loss: 0.508497\n",
      "epoch 1; iter: 200; batch classifier loss: 15.270236; batch adversarial loss: 0.513636\n",
      "epoch 1; iter: 400; batch classifier loss: 0.450573; batch adversarial loss: 0.410268\n",
      "epoch 1; iter: 600; batch classifier loss: 6.094020; batch adversarial loss: 0.422969\n",
      "epoch 2; iter: 0; batch classifier loss: 3.254985; batch adversarial loss: 0.526287\n",
      "epoch 2; iter: 200; batch classifier loss: 0.468026; batch adversarial loss: 0.396906\n",
      "epoch 2; iter: 400; batch classifier loss: 0.959136; batch adversarial loss: 0.330864\n",
      "epoch 2; iter: 600; batch classifier loss: 0.408958; batch adversarial loss: 0.381304\n",
      "epoch 3; iter: 0; batch classifier loss: 1.314709; batch adversarial loss: 0.484334\n",
      "epoch 3; iter: 200; batch classifier loss: 0.323185; batch adversarial loss: 0.467641\n",
      "epoch 3; iter: 400; batch classifier loss: 0.330853; batch adversarial loss: 0.307501\n",
      "epoch 3; iter: 600; batch classifier loss: 0.993331; batch adversarial loss: 0.410720\n",
      "epoch 4; iter: 0; batch classifier loss: 0.671693; batch adversarial loss: 0.422284\n",
      "epoch 4; iter: 200; batch classifier loss: 0.401908; batch adversarial loss: 0.278073\n",
      "epoch 4; iter: 400; batch classifier loss: 0.630288; batch adversarial loss: 0.476898\n",
      "epoch 4; iter: 600; batch classifier loss: 0.444384; batch adversarial loss: 0.356691\n",
      "epoch 5; iter: 0; batch classifier loss: 1.194118; batch adversarial loss: 0.348813\n",
      "epoch 5; iter: 200; batch classifier loss: 0.412557; batch adversarial loss: 0.327215\n",
      "epoch 5; iter: 400; batch classifier loss: 0.332486; batch adversarial loss: 0.438787\n",
      "epoch 5; iter: 600; batch classifier loss: 0.516743; batch adversarial loss: 0.401754\n",
      "epoch 6; iter: 0; batch classifier loss: 0.333749; batch adversarial loss: 0.294254\n",
      "epoch 6; iter: 200; batch classifier loss: 0.559258; batch adversarial loss: 0.352063\n",
      "epoch 6; iter: 400; batch classifier loss: 0.329183; batch adversarial loss: 0.435378\n",
      "epoch 6; iter: 600; batch classifier loss: 0.416761; batch adversarial loss: 0.616931\n",
      "epoch 7; iter: 0; batch classifier loss: 0.367702; batch adversarial loss: 0.192179\n",
      "epoch 7; iter: 200; batch classifier loss: 0.357750; batch adversarial loss: 0.459226\n",
      "epoch 7; iter: 400; batch classifier loss: 0.334578; batch adversarial loss: 0.445187\n",
      "epoch 7; iter: 600; batch classifier loss: 0.457663; batch adversarial loss: 0.428894\n",
      "epoch 8; iter: 0; batch classifier loss: 0.391252; batch adversarial loss: 0.369232\n",
      "epoch 8; iter: 200; batch classifier loss: 0.448850; batch adversarial loss: 0.540398\n",
      "epoch 8; iter: 400; batch classifier loss: 0.312882; batch adversarial loss: 0.434788\n",
      "epoch 8; iter: 600; batch classifier loss: 0.308351; batch adversarial loss: 0.397167\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323730; batch adversarial loss: 0.603972\n",
      "epoch 9; iter: 200; batch classifier loss: 0.317251; batch adversarial loss: 0.397249\n",
      "epoch 9; iter: 400; batch classifier loss: 0.250352; batch adversarial loss: 0.450208\n",
      "epoch 9; iter: 600; batch classifier loss: 0.615244; batch adversarial loss: 0.458362\n",
      "epoch 0; iter: 0; batch classifier loss: 21.158367; batch adversarial loss: 0.697268\n",
      "epoch 0; iter: 200; batch classifier loss: 5.957392; batch adversarial loss: 0.598793\n",
      "epoch 0; iter: 400; batch classifier loss: 19.127628; batch adversarial loss: 0.504347\n",
      "epoch 0; iter: 600; batch classifier loss: 7.879447; batch adversarial loss: 0.522678\n",
      "epoch 1; iter: 0; batch classifier loss: 2.077239; batch adversarial loss: 0.529482\n",
      "epoch 1; iter: 200; batch classifier loss: 7.441768; batch adversarial loss: 0.449680\n",
      "epoch 1; iter: 400; batch classifier loss: 0.486589; batch adversarial loss: 0.468952\n",
      "epoch 1; iter: 600; batch classifier loss: 5.767292; batch adversarial loss: 0.465063\n",
      "epoch 2; iter: 0; batch classifier loss: 1.057451; batch adversarial loss: 0.441252\n",
      "epoch 2; iter: 200; batch classifier loss: 0.723328; batch adversarial loss: 0.305236\n",
      "epoch 2; iter: 400; batch classifier loss: 0.456653; batch adversarial loss: 0.510795\n",
      "epoch 2; iter: 600; batch classifier loss: 0.910430; batch adversarial loss: 0.499006\n",
      "epoch 3; iter: 0; batch classifier loss: 2.947385; batch adversarial loss: 0.414263\n",
      "epoch 3; iter: 200; batch classifier loss: 0.408975; batch adversarial loss: 0.468642\n",
      "epoch 3; iter: 400; batch classifier loss: 0.367507; batch adversarial loss: 0.441177\n",
      "epoch 3; iter: 600; batch classifier loss: 1.552465; batch adversarial loss: 0.397299\n",
      "epoch 4; iter: 0; batch classifier loss: 0.382895; batch adversarial loss: 0.317499\n",
      "epoch 4; iter: 200; batch classifier loss: 0.698284; batch adversarial loss: 0.358038\n",
      "epoch 4; iter: 400; batch classifier loss: 0.492919; batch adversarial loss: 0.344351\n",
      "epoch 4; iter: 600; batch classifier loss: 0.259586; batch adversarial loss: 0.483567\n",
      "epoch 5; iter: 0; batch classifier loss: 0.341888; batch adversarial loss: 0.301467\n",
      "epoch 5; iter: 200; batch classifier loss: 0.337599; batch adversarial loss: 0.395370\n",
      "epoch 5; iter: 400; batch classifier loss: 0.351408; batch adversarial loss: 0.548943\n",
      "epoch 5; iter: 600; batch classifier loss: 0.387247; batch adversarial loss: 0.319704\n",
      "epoch 6; iter: 0; batch classifier loss: 0.527854; batch adversarial loss: 0.376669\n",
      "epoch 6; iter: 200; batch classifier loss: 0.344365; batch adversarial loss: 0.543861\n",
      "epoch 6; iter: 400; batch classifier loss: 0.383004; batch adversarial loss: 0.388028\n",
      "epoch 6; iter: 600; batch classifier loss: 0.484385; batch adversarial loss: 0.379646\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615990; batch adversarial loss: 0.296272\n",
      "epoch 7; iter: 200; batch classifier loss: 0.241065; batch adversarial loss: 0.315863\n",
      "epoch 7; iter: 400; batch classifier loss: 0.290909; batch adversarial loss: 0.576510\n",
      "epoch 7; iter: 600; batch classifier loss: 0.378620; batch adversarial loss: 0.381292\n",
      "epoch 8; iter: 0; batch classifier loss: 0.295489; batch adversarial loss: 0.487746\n",
      "epoch 8; iter: 200; batch classifier loss: 0.316951; batch adversarial loss: 0.354757\n",
      "epoch 8; iter: 400; batch classifier loss: 0.527606; batch adversarial loss: 0.430648\n",
      "epoch 8; iter: 600; batch classifier loss: 0.389897; batch adversarial loss: 0.502219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.249283; batch adversarial loss: 0.555973\n",
      "epoch 9; iter: 200; batch classifier loss: 0.361151; batch adversarial loss: 0.503263\n",
      "epoch 9; iter: 400; batch classifier loss: 0.272806; batch adversarial loss: 0.455853\n",
      "epoch 9; iter: 600; batch classifier loss: 0.328252; batch adversarial loss: 0.379590\n",
      "epoch 0; iter: 0; batch classifier loss: 68.394592; batch adversarial loss: 0.693147\n",
      "epoch 0; iter: 200; batch classifier loss: 8.674900; batch adversarial loss: 0.613938\n",
      "epoch 0; iter: 400; batch classifier loss: 4.018152; batch adversarial loss: 0.571750\n",
      "epoch 0; iter: 600; batch classifier loss: 12.157070; batch adversarial loss: 0.522686\n",
      "epoch 1; iter: 0; batch classifier loss: 44.243622; batch adversarial loss: 0.525750\n",
      "epoch 1; iter: 200; batch classifier loss: 5.235813; batch adversarial loss: 0.436038\n",
      "epoch 1; iter: 400; batch classifier loss: 4.117056; batch adversarial loss: 0.475157\n",
      "epoch 1; iter: 600; batch classifier loss: 0.865673; batch adversarial loss: 0.411189\n",
      "epoch 2; iter: 0; batch classifier loss: 5.604451; batch adversarial loss: 0.378329\n",
      "epoch 2; iter: 200; batch classifier loss: 0.450459; batch adversarial loss: 0.389686\n",
      "epoch 2; iter: 400; batch classifier loss: 1.503936; batch adversarial loss: 0.283754\n",
      "epoch 2; iter: 600; batch classifier loss: 1.485447; batch adversarial loss: 0.421487\n",
      "epoch 3; iter: 0; batch classifier loss: 1.182302; batch adversarial loss: 0.392700\n",
      "epoch 3; iter: 200; batch classifier loss: 0.580957; batch adversarial loss: 0.439226\n",
      "epoch 3; iter: 400; batch classifier loss: 0.217842; batch adversarial loss: 0.396705\n",
      "epoch 3; iter: 600; batch classifier loss: 0.410446; batch adversarial loss: 0.476500\n",
      "epoch 4; iter: 0; batch classifier loss: 0.417592; batch adversarial loss: 0.451237\n",
      "epoch 4; iter: 200; batch classifier loss: 1.407729; batch adversarial loss: 0.617917\n",
      "epoch 4; iter: 400; batch classifier loss: 0.573459; batch adversarial loss: 0.476347\n",
      "epoch 4; iter: 600; batch classifier loss: 0.641365; batch adversarial loss: 0.344191\n",
      "epoch 5; iter: 0; batch classifier loss: 0.891747; batch adversarial loss: 0.447559\n",
      "epoch 5; iter: 200; batch classifier loss: 0.538065; batch adversarial loss: 0.408892\n",
      "epoch 5; iter: 400; batch classifier loss: 0.407639; batch adversarial loss: 0.657003\n",
      "epoch 5; iter: 600; batch classifier loss: 0.462735; batch adversarial loss: 0.354469\n",
      "epoch 6; iter: 0; batch classifier loss: 0.370521; batch adversarial loss: 0.482412\n",
      "epoch 6; iter: 200; batch classifier loss: 0.724109; batch adversarial loss: 0.361009\n",
      "epoch 6; iter: 400; batch classifier loss: 0.421921; batch adversarial loss: 0.357697\n",
      "epoch 6; iter: 600; batch classifier loss: 0.362487; batch adversarial loss: 0.432347\n",
      "epoch 7; iter: 0; batch classifier loss: 0.946818; batch adversarial loss: 0.312288\n",
      "epoch 7; iter: 200; batch classifier loss: 0.265575; batch adversarial loss: 0.485161\n",
      "epoch 7; iter: 400; batch classifier loss: 0.364884; batch adversarial loss: 0.366434\n",
      "epoch 7; iter: 600; batch classifier loss: 0.468231; batch adversarial loss: 0.209299\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491608; batch adversarial loss: 0.454556\n",
      "epoch 8; iter: 200; batch classifier loss: 0.380194; batch adversarial loss: 0.483666\n",
      "epoch 8; iter: 400; batch classifier loss: 0.373966; batch adversarial loss: 0.302751\n",
      "epoch 8; iter: 600; batch classifier loss: 0.384702; batch adversarial loss: 0.432041\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346538; batch adversarial loss: 0.318477\n",
      "epoch 9; iter: 200; batch classifier loss: 0.354709; batch adversarial loss: 0.538417\n",
      "epoch 9; iter: 400; batch classifier loss: 0.366942; batch adversarial loss: 0.420896\n",
      "epoch 9; iter: 600; batch classifier loss: 0.437800; batch adversarial loss: 0.292596\n",
      "epoch 0; iter: 0; batch classifier loss: 20.891514; batch adversarial loss: 0.569187\n",
      "epoch 0; iter: 200; batch classifier loss: 5.884351; batch adversarial loss: 0.619202\n",
      "epoch 0; iter: 400; batch classifier loss: 1.241140; batch adversarial loss: 0.513722\n",
      "epoch 0; iter: 600; batch classifier loss: 3.449568; batch adversarial loss: 0.522327\n",
      "epoch 1; iter: 0; batch classifier loss: 2.106326; batch adversarial loss: 0.428735\n",
      "epoch 1; iter: 200; batch classifier loss: 6.982517; batch adversarial loss: 0.468281\n",
      "epoch 1; iter: 400; batch classifier loss: 1.348682; batch adversarial loss: 0.394922\n",
      "epoch 1; iter: 600; batch classifier loss: 1.849385; batch adversarial loss: 0.547402\n",
      "epoch 2; iter: 0; batch classifier loss: 19.400032; batch adversarial loss: 0.436054\n",
      "epoch 2; iter: 200; batch classifier loss: 4.950559; batch adversarial loss: 0.282815\n",
      "epoch 2; iter: 400; batch classifier loss: 0.681043; batch adversarial loss: 0.420352\n",
      "epoch 2; iter: 600; batch classifier loss: 1.768578; batch adversarial loss: 0.387122\n",
      "epoch 3; iter: 0; batch classifier loss: 0.568392; batch adversarial loss: 0.493738\n",
      "epoch 3; iter: 200; batch classifier loss: 0.312915; batch adversarial loss: 0.401468\n",
      "epoch 3; iter: 400; batch classifier loss: 0.363938; batch adversarial loss: 0.367840\n",
      "epoch 3; iter: 600; batch classifier loss: 1.063099; batch adversarial loss: 0.364249\n",
      "epoch 4; iter: 0; batch classifier loss: 0.759653; batch adversarial loss: 0.411596\n",
      "epoch 4; iter: 200; batch classifier loss: 0.342550; batch adversarial loss: 0.616097\n",
      "epoch 4; iter: 400; batch classifier loss: 1.068023; batch adversarial loss: 0.418778\n",
      "epoch 4; iter: 600; batch classifier loss: 1.073682; batch adversarial loss: 0.408413\n",
      "epoch 5; iter: 0; batch classifier loss: 0.392955; batch adversarial loss: 0.468819\n",
      "epoch 5; iter: 200; batch classifier loss: 0.531356; batch adversarial loss: 0.379267\n",
      "epoch 5; iter: 400; batch classifier loss: 0.334603; batch adversarial loss: 0.541195\n",
      "epoch 5; iter: 600; batch classifier loss: 0.743008; batch adversarial loss: 0.402253\n",
      "epoch 6; iter: 0; batch classifier loss: 0.500972; batch adversarial loss: 0.319357\n",
      "epoch 6; iter: 200; batch classifier loss: 0.617110; batch adversarial loss: 0.381061\n",
      "epoch 6; iter: 400; batch classifier loss: 0.358054; batch adversarial loss: 0.455769\n",
      "epoch 6; iter: 600; batch classifier loss: 0.333083; batch adversarial loss: 0.350224\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454992; batch adversarial loss: 0.342819\n",
      "epoch 7; iter: 200; batch classifier loss: 0.334469; batch adversarial loss: 0.485819\n",
      "epoch 7; iter: 400; batch classifier loss: 0.498320; batch adversarial loss: 0.440953\n",
      "epoch 7; iter: 600; batch classifier loss: 0.380757; batch adversarial loss: 0.381114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.259512; batch adversarial loss: 0.495121\n",
      "epoch 8; iter: 200; batch classifier loss: 0.360131; batch adversarial loss: 0.317776\n",
      "epoch 8; iter: 400; batch classifier loss: 0.470740; batch adversarial loss: 0.425457\n",
      "epoch 8; iter: 600; batch classifier loss: 0.467911; batch adversarial loss: 0.490611\n",
      "epoch 9; iter: 0; batch classifier loss: 0.254611; batch adversarial loss: 0.511174\n",
      "epoch 9; iter: 200; batch classifier loss: 0.460607; batch adversarial loss: 0.442775\n",
      "epoch 9; iter: 400; batch classifier loss: 0.370270; batch adversarial loss: 0.341952\n",
      "epoch 9; iter: 600; batch classifier loss: 0.352958; batch adversarial loss: 0.331419\n",
      "epoch 0; iter: 0; batch classifier loss: 22.837969; batch adversarial loss: 0.681669\n",
      "epoch 0; iter: 200; batch classifier loss: 11.507856; batch adversarial loss: 0.605778\n",
      "epoch 0; iter: 400; batch classifier loss: 8.653886; batch adversarial loss: 0.570555\n",
      "epoch 0; iter: 600; batch classifier loss: 8.494362; batch adversarial loss: 0.418287\n",
      "epoch 1; iter: 0; batch classifier loss: 7.220704; batch adversarial loss: 0.483613\n",
      "epoch 1; iter: 200; batch classifier loss: 2.001138; batch adversarial loss: 0.441666\n",
      "epoch 1; iter: 400; batch classifier loss: 0.926652; batch adversarial loss: 0.489611\n",
      "epoch 1; iter: 600; batch classifier loss: 3.765162; batch adversarial loss: 0.469235\n",
      "epoch 2; iter: 0; batch classifier loss: 1.478735; batch adversarial loss: 0.401701\n",
      "epoch 2; iter: 200; batch classifier loss: 0.219531; batch adversarial loss: 0.409956\n",
      "epoch 2; iter: 400; batch classifier loss: 1.406537; batch adversarial loss: 0.426192\n",
      "epoch 2; iter: 600; batch classifier loss: 0.514190; batch adversarial loss: 0.316123\n",
      "epoch 3; iter: 0; batch classifier loss: 1.260368; batch adversarial loss: 0.320150\n",
      "epoch 3; iter: 200; batch classifier loss: 0.386918; batch adversarial loss: 0.342774\n",
      "epoch 3; iter: 400; batch classifier loss: 0.973393; batch adversarial loss: 0.396341\n",
      "epoch 3; iter: 600; batch classifier loss: 0.638679; batch adversarial loss: 0.420362\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528589; batch adversarial loss: 0.445525\n",
      "epoch 4; iter: 200; batch classifier loss: 0.461523; batch adversarial loss: 0.362590\n",
      "epoch 4; iter: 400; batch classifier loss: 0.349841; batch adversarial loss: 0.407004\n",
      "epoch 4; iter: 600; batch classifier loss: 0.499465; batch adversarial loss: 0.465931\n",
      "epoch 5; iter: 0; batch classifier loss: 0.377226; batch adversarial loss: 0.350832\n",
      "epoch 5; iter: 200; batch classifier loss: 0.379132; batch adversarial loss: 0.416388\n",
      "epoch 5; iter: 400; batch classifier loss: 0.386318; batch adversarial loss: 0.508255\n",
      "epoch 5; iter: 600; batch classifier loss: 0.379895; batch adversarial loss: 0.420343\n",
      "epoch 6; iter: 0; batch classifier loss: 0.257793; batch adversarial loss: 0.471507\n",
      "epoch 6; iter: 200; batch classifier loss: 0.421135; batch adversarial loss: 0.543963\n",
      "epoch 6; iter: 400; batch classifier loss: 0.607669; batch adversarial loss: 0.458460\n",
      "epoch 6; iter: 600; batch classifier loss: 0.216090; batch adversarial loss: 0.382431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.885366; batch adversarial loss: 0.437354\n",
      "epoch 7; iter: 200; batch classifier loss: 0.494437; batch adversarial loss: 0.381757\n",
      "epoch 7; iter: 400; batch classifier loss: 0.377350; batch adversarial loss: 0.347908\n",
      "epoch 7; iter: 600; batch classifier loss: 0.447653; batch adversarial loss: 0.461722\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345312; batch adversarial loss: 0.288762\n",
      "epoch 8; iter: 200; batch classifier loss: 0.329752; batch adversarial loss: 0.426547\n",
      "epoch 8; iter: 400; batch classifier loss: 0.576777; batch adversarial loss: 0.297226\n",
      "epoch 8; iter: 600; batch classifier loss: 0.300504; batch adversarial loss: 0.215951\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454312; batch adversarial loss: 0.306830\n",
      "epoch 9; iter: 200; batch classifier loss: 0.458952; batch adversarial loss: 0.317787\n",
      "epoch 9; iter: 400; batch classifier loss: 0.364150; batch adversarial loss: 0.458059\n",
      "epoch 9; iter: 600; batch classifier loss: 0.447408; batch adversarial loss: 0.401804\n",
      "epoch 0; iter: 0; batch classifier loss: 21.606642; batch adversarial loss: 0.683511\n",
      "epoch 0; iter: 200; batch classifier loss: 21.533848; batch adversarial loss: 0.631899\n",
      "epoch 0; iter: 400; batch classifier loss: 7.219304; batch adversarial loss: 0.541647\n",
      "epoch 0; iter: 600; batch classifier loss: 0.727214; batch adversarial loss: 0.514542\n",
      "epoch 1; iter: 0; batch classifier loss: 9.609250; batch adversarial loss: 0.440610\n",
      "epoch 1; iter: 200; batch classifier loss: 9.329034; batch adversarial loss: 0.450502\n",
      "epoch 1; iter: 400; batch classifier loss: 4.001020; batch adversarial loss: 0.424629\n",
      "epoch 1; iter: 600; batch classifier loss: 0.384547; batch adversarial loss: 0.430126\n",
      "epoch 2; iter: 0; batch classifier loss: 0.805611; batch adversarial loss: 0.437185\n",
      "epoch 2; iter: 200; batch classifier loss: 0.561290; batch adversarial loss: 0.604081\n",
      "epoch 2; iter: 400; batch classifier loss: 2.267738; batch adversarial loss: 0.428109\n",
      "epoch 2; iter: 600; batch classifier loss: 0.693157; batch adversarial loss: 0.457521\n",
      "epoch 3; iter: 0; batch classifier loss: 0.890055; batch adversarial loss: 0.445084\n",
      "epoch 3; iter: 200; batch classifier loss: 1.202385; batch adversarial loss: 0.294746\n",
      "epoch 3; iter: 400; batch classifier loss: 1.520016; batch adversarial loss: 0.468247\n",
      "epoch 3; iter: 600; batch classifier loss: 0.402727; batch adversarial loss: 0.345964\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579074; batch adversarial loss: 0.355339\n",
      "epoch 4; iter: 200; batch classifier loss: 0.391238; batch adversarial loss: 0.467059\n",
      "epoch 4; iter: 400; batch classifier loss: 0.598584; batch adversarial loss: 0.406045\n",
      "epoch 4; iter: 600; batch classifier loss: 0.561162; batch adversarial loss: 0.397798\n",
      "epoch 5; iter: 0; batch classifier loss: 0.477405; batch adversarial loss: 0.430849\n",
      "epoch 5; iter: 200; batch classifier loss: 0.261721; batch adversarial loss: 0.397086\n",
      "epoch 5; iter: 400; batch classifier loss: 0.327765; batch adversarial loss: 0.490055\n",
      "epoch 5; iter: 600; batch classifier loss: 0.545196; batch adversarial loss: 0.342770\n",
      "epoch 6; iter: 0; batch classifier loss: 0.717990; batch adversarial loss: 0.467772\n",
      "epoch 6; iter: 200; batch classifier loss: 0.322166; batch adversarial loss: 0.464853\n",
      "epoch 6; iter: 400; batch classifier loss: 0.314789; batch adversarial loss: 0.416681\n",
      "epoch 6; iter: 600; batch classifier loss: 0.305050; batch adversarial loss: 0.406620\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480201; batch adversarial loss: 0.427763\n",
      "epoch 7; iter: 200; batch classifier loss: 0.232720; batch adversarial loss: 0.385837\n",
      "epoch 7; iter: 400; batch classifier loss: 0.299441; batch adversarial loss: 0.345836\n",
      "epoch 7; iter: 600; batch classifier loss: 0.460267; batch adversarial loss: 0.376111\n",
      "epoch 8; iter: 0; batch classifier loss: 0.286997; batch adversarial loss: 0.430463\n",
      "epoch 8; iter: 200; batch classifier loss: 0.297790; batch adversarial loss: 0.425970\n",
      "epoch 8; iter: 400; batch classifier loss: 0.278426; batch adversarial loss: 0.412632\n",
      "epoch 8; iter: 600; batch classifier loss: 0.283533; batch adversarial loss: 0.412490\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340035; batch adversarial loss: 0.381812\n",
      "epoch 9; iter: 200; batch classifier loss: 0.209073; batch adversarial loss: 0.326118\n",
      "epoch 9; iter: 400; batch classifier loss: 0.397688; batch adversarial loss: 0.376721\n",
      "epoch 9; iter: 600; batch classifier loss: 0.341519; batch adversarial loss: 0.539924\n",
      "epoch 0; iter: 0; batch classifier loss: 511.854248; batch adversarial loss: 0.742415\n",
      "epoch 0; iter: 200; batch classifier loss: 12.877525; batch adversarial loss: 0.634833\n",
      "epoch 0; iter: 400; batch classifier loss: 8.195971; batch adversarial loss: 0.565414\n",
      "epoch 0; iter: 600; batch classifier loss: 8.087023; batch adversarial loss: 0.539667\n",
      "epoch 1; iter: 0; batch classifier loss: 3.194272; batch adversarial loss: 0.554204\n",
      "epoch 1; iter: 200; batch classifier loss: 3.805598; batch adversarial loss: 0.467364\n",
      "epoch 1; iter: 400; batch classifier loss: 4.364146; batch adversarial loss: 0.394238\n",
      "epoch 1; iter: 600; batch classifier loss: 3.401401; batch adversarial loss: 0.444894\n",
      "epoch 2; iter: 0; batch classifier loss: 4.698248; batch adversarial loss: 0.480882\n",
      "epoch 2; iter: 200; batch classifier loss: 0.719476; batch adversarial loss: 0.526803\n",
      "epoch 2; iter: 400; batch classifier loss: 0.502061; batch adversarial loss: 0.295163\n",
      "epoch 2; iter: 600; batch classifier loss: 1.114909; batch adversarial loss: 0.414847\n",
      "epoch 3; iter: 0; batch classifier loss: 0.890662; batch adversarial loss: 0.368239\n",
      "epoch 3; iter: 200; batch classifier loss: 0.475098; batch adversarial loss: 0.480303\n",
      "epoch 3; iter: 400; batch classifier loss: 1.292823; batch adversarial loss: 0.386111\n",
      "epoch 3; iter: 600; batch classifier loss: 0.297925; batch adversarial loss: 0.332399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.380748; batch adversarial loss: 0.392013\n",
      "epoch 4; iter: 200; batch classifier loss: 0.443915; batch adversarial loss: 0.438137\n",
      "epoch 4; iter: 400; batch classifier loss: 0.799146; batch adversarial loss: 0.313913\n",
      "epoch 4; iter: 600; batch classifier loss: 0.963578; batch adversarial loss: 0.304223\n",
      "epoch 5; iter: 0; batch classifier loss: 0.966755; batch adversarial loss: 0.507608\n",
      "epoch 5; iter: 200; batch classifier loss: 0.390311; batch adversarial loss: 0.368922\n",
      "epoch 5; iter: 400; batch classifier loss: 0.596326; batch adversarial loss: 0.467548\n",
      "epoch 5; iter: 600; batch classifier loss: 0.436954; batch adversarial loss: 0.451185\n",
      "epoch 6; iter: 0; batch classifier loss: 0.344197; batch adversarial loss: 0.501759\n",
      "epoch 6; iter: 200; batch classifier loss: 0.460096; batch adversarial loss: 0.416069\n",
      "epoch 6; iter: 400; batch classifier loss: 0.656977; batch adversarial loss: 0.427990\n",
      "epoch 6; iter: 600; batch classifier loss: 0.270246; batch adversarial loss: 0.323734\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359815; batch adversarial loss: 0.477418\n",
      "epoch 7; iter: 200; batch classifier loss: 0.373005; batch adversarial loss: 0.352619\n",
      "epoch 7; iter: 400; batch classifier loss: 0.428696; batch adversarial loss: 0.490717\n",
      "epoch 7; iter: 600; batch classifier loss: 0.421960; batch adversarial loss: 0.401092\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467761; batch adversarial loss: 0.489278\n",
      "epoch 8; iter: 200; batch classifier loss: 0.390972; batch adversarial loss: 0.296964\n",
      "epoch 8; iter: 400; batch classifier loss: 0.356068; batch adversarial loss: 0.405464\n",
      "epoch 8; iter: 600; batch classifier loss: 0.492433; batch adversarial loss: 0.435607\n",
      "epoch 9; iter: 0; batch classifier loss: 0.211736; batch adversarial loss: 0.470490\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386928; batch adversarial loss: 0.482600\n",
      "epoch 9; iter: 400; batch classifier loss: 0.446701; batch adversarial loss: 0.448996\n",
      "epoch 9; iter: 600; batch classifier loss: 0.402669; batch adversarial loss: 0.490376\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.833380  0.581487 -0.019885  0.891265  0.107504  0.057892\n",
      "std   0.013587  0.056287  0.029644  0.159518  0.067506  0.038295\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedShuffleSplit, StratifiedKFold\n",
    "from src.metrics import best_hyperparameter_advdeb\n",
    "\n",
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Hyperparameter Search\n",
    "param_grid = {\n",
    "    'adversary_loss_weight': [0.5, 1.0],\n",
    "    'num_epochs':            [10, 20, 50],\n",
    "    'batch_size':            [64, 128]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "grid_results = []\n",
    "# Perform hyperparameter search with 15 stratified shuffle splits\n",
    "for params in grid:\n",
    "    print(f\"Testing config: {params}\")\n",
    "    fold_metrics = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            privileged_groups, unprivileged_groups,\n",
    "            scope_name='adv',\n",
    "            num_epochs=params['num_epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            adversary_loss_weight=params['adversary_loss_weight']\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "    \n",
    "    df_fm = pd.DataFrame(fold_metrics)\n",
    "    agg = df_fm.agg(['mean', 'std'])\n",
    "    \n",
    "    grid_results.append({\n",
    "        **params,\n",
    "        'acc_mean':   agg.loc['mean', 'accuracy'],\n",
    "        'acc_std':    agg.loc['std',  'accuracy'],\n",
    "        'f1_mean':    agg.loc['mean', 'f1_score'],\n",
    "        'f1_std':     agg.loc['std',  'f1_score'],\n",
    "        'SPD_mean':   agg.loc['mean', 'SPD'],\n",
    "        'SPD_std':    agg.loc['std',  'SPD'],\n",
    "        'DI_mean':    agg.loc['mean', 'DI'],\n",
    "        'DI_std':     agg.loc['std',  'DI'],\n",
    "        'EOD_mean':   agg.loc['mean', 'EOD'],\n",
    "        'EOD_std':    agg.loc['std',  'EOD'],\n",
    "        'AOD_mean':   agg.loc['mean', 'AOD'],\n",
    "        'AOD_std':    agg.loc['std',  'AOD'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Hyperparameter Selection\n",
    "best_param = best_hyperparameter_advdeb(results_df)\n",
    "print(f\"Best parameters: {best_param}\")\n",
    "\n",
    "# Final evaluation with StratifiedKFold\n",
    "loss_weight = best_param['adversary_loss_weight']\n",
    "n_epochs    = int(best_param['num_epochs'])\n",
    "batch_sz    = int(best_param['batch_size'])\n",
    "\n",
    "# 4) Run experiment, Evaluate\n",
    "results = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        privileged_groups, unprivileged_groups,\n",
    "        scope_name='adv',\n",
    "        num_epochs=n_epochs,\n",
    "        batch_size=batch_sz,\n",
    "        adversary_loss_weight=loss_weight\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "    \n",
    "# 5) Aggregate results\n",
    "adult_race_metrics = pd.DataFrame(results)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6497f4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', 'Hyperparametertuned Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a3525",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c2fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 11.180571; batch adversarial loss: 0.686823\n",
      "epoch 0; iter: 200; batch classifier loss: 15.442457; batch adversarial loss: 0.646029\n",
      "epoch 0; iter: 400; batch classifier loss: 12.664048; batch adversarial loss: 0.622492\n",
      "epoch 1; iter: 0; batch classifier loss: 56.798271; batch adversarial loss: 0.639511\n",
      "epoch 1; iter: 200; batch classifier loss: 1.051027; batch adversarial loss: 0.592792\n",
      "epoch 1; iter: 400; batch classifier loss: 1.987360; batch adversarial loss: 0.644359\n",
      "epoch 2; iter: 0; batch classifier loss: 0.998826; batch adversarial loss: 0.629803\n",
      "epoch 2; iter: 200; batch classifier loss: 3.019346; batch adversarial loss: 0.605085\n",
      "epoch 2; iter: 400; batch classifier loss: 0.416755; batch adversarial loss: 0.641453\n",
      "epoch 3; iter: 0; batch classifier loss: 0.464090; batch adversarial loss: 0.617592\n",
      "epoch 3; iter: 200; batch classifier loss: 2.023048; batch adversarial loss: 0.541240\n",
      "epoch 3; iter: 400; batch classifier loss: 0.445144; batch adversarial loss: 0.585800\n",
      "epoch 4; iter: 0; batch classifier loss: 0.519440; batch adversarial loss: 0.625095\n",
      "epoch 4; iter: 200; batch classifier loss: 1.042477; batch adversarial loss: 0.642124\n",
      "epoch 4; iter: 400; batch classifier loss: 1.764988; batch adversarial loss: 0.587258\n",
      "epoch 5; iter: 0; batch classifier loss: 0.916989; batch adversarial loss: 0.586543\n",
      "epoch 5; iter: 200; batch classifier loss: 0.774578; batch adversarial loss: 0.631985\n",
      "epoch 5; iter: 400; batch classifier loss: 0.676008; batch adversarial loss: 0.605279\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375950; batch adversarial loss: 0.590219\n",
      "epoch 6; iter: 200; batch classifier loss: 0.319790; batch adversarial loss: 0.615560\n",
      "epoch 6; iter: 400; batch classifier loss: 0.775957; batch adversarial loss: 0.559992\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393374; batch adversarial loss: 0.566800\n",
      "epoch 7; iter: 200; batch classifier loss: 0.374797; batch adversarial loss: 0.551303\n",
      "epoch 7; iter: 400; batch classifier loss: 0.589406; batch adversarial loss: 0.578349\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484521; batch adversarial loss: 0.616767\n",
      "epoch 8; iter: 200; batch classifier loss: 0.306146; batch adversarial loss: 0.595642\n",
      "epoch 8; iter: 400; batch classifier loss: 0.315605; batch adversarial loss: 0.599121\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353009; batch adversarial loss: 0.656867\n",
      "epoch 9; iter: 200; batch classifier loss: 0.348071; batch adversarial loss: 0.633602\n",
      "epoch 9; iter: 400; batch classifier loss: 0.250257; batch adversarial loss: 0.651547\n",
      "epoch 0; iter: 0; batch classifier loss: 11.764974; batch adversarial loss: 0.640152\n",
      "epoch 0; iter: 200; batch classifier loss: 0.635708; batch adversarial loss: 0.675806\n",
      "epoch 0; iter: 400; batch classifier loss: 5.278164; batch adversarial loss: 0.631762\n",
      "epoch 1; iter: 0; batch classifier loss: 2.981779; batch adversarial loss: 0.611094\n",
      "epoch 1; iter: 200; batch classifier loss: 5.310907; batch adversarial loss: 0.627913\n",
      "epoch 1; iter: 400; batch classifier loss: 2.458795; batch adversarial loss: 0.644551\n",
      "epoch 2; iter: 0; batch classifier loss: 2.437360; batch adversarial loss: 0.619594\n",
      "epoch 2; iter: 200; batch classifier loss: 5.145138; batch adversarial loss: 0.606957\n",
      "epoch 2; iter: 400; batch classifier loss: 1.578377; batch adversarial loss: 0.607077\n",
      "epoch 3; iter: 0; batch classifier loss: 0.900108; batch adversarial loss: 0.624372\n",
      "epoch 3; iter: 200; batch classifier loss: 1.400288; batch adversarial loss: 0.578355\n",
      "epoch 3; iter: 400; batch classifier loss: 1.172474; batch adversarial loss: 0.648004\n",
      "epoch 4; iter: 0; batch classifier loss: 1.540819; batch adversarial loss: 0.638121\n",
      "epoch 4; iter: 200; batch classifier loss: 0.367760; batch adversarial loss: 0.687737\n",
      "epoch 4; iter: 400; batch classifier loss: 1.724427; batch adversarial loss: 0.631684\n",
      "epoch 5; iter: 0; batch classifier loss: 0.596510; batch adversarial loss: 0.638979\n",
      "epoch 5; iter: 200; batch classifier loss: 0.783132; batch adversarial loss: 0.563472\n",
      "epoch 5; iter: 400; batch classifier loss: 0.658390; batch adversarial loss: 0.660116\n",
      "epoch 6; iter: 0; batch classifier loss: 1.059219; batch adversarial loss: 0.706242\n",
      "epoch 6; iter: 200; batch classifier loss: 3.565313; batch adversarial loss: 0.572957\n",
      "epoch 6; iter: 400; batch classifier loss: 0.797308; batch adversarial loss: 0.653717\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606582; batch adversarial loss: 0.616585\n",
      "epoch 7; iter: 200; batch classifier loss: 0.380384; batch adversarial loss: 0.590205\n",
      "epoch 7; iter: 400; batch classifier loss: 0.353904; batch adversarial loss: 0.629047\n",
      "epoch 8; iter: 0; batch classifier loss: 0.439184; batch adversarial loss: 0.623542\n",
      "epoch 8; iter: 200; batch classifier loss: 0.318373; batch adversarial loss: 0.579832\n",
      "epoch 8; iter: 400; batch classifier loss: 0.569490; batch adversarial loss: 0.560286\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361209; batch adversarial loss: 0.641207\n",
      "epoch 9; iter: 200; batch classifier loss: 0.407362; batch adversarial loss: 0.656808\n",
      "epoch 9; iter: 400; batch classifier loss: 0.434696; batch adversarial loss: 0.569621\n",
      "epoch 0; iter: 0; batch classifier loss: 7.735092; batch adversarial loss: 1.030943\n",
      "epoch 0; iter: 200; batch classifier loss: 22.113338; batch adversarial loss: 0.955446\n",
      "epoch 0; iter: 400; batch classifier loss: 4.697320; batch adversarial loss: 0.761505\n",
      "epoch 1; iter: 0; batch classifier loss: 5.387946; batch adversarial loss: 0.707991\n",
      "epoch 1; iter: 200; batch classifier loss: 39.474274; batch adversarial loss: 0.688177\n",
      "epoch 1; iter: 400; batch classifier loss: 7.186809; batch adversarial loss: 0.713315\n",
      "epoch 2; iter: 0; batch classifier loss: 8.607777; batch adversarial loss: 0.661472\n",
      "epoch 2; iter: 200; batch classifier loss: 0.634347; batch adversarial loss: 0.653174\n",
      "epoch 2; iter: 400; batch classifier loss: 0.918860; batch adversarial loss: 0.627410\n",
      "epoch 3; iter: 0; batch classifier loss: 0.536724; batch adversarial loss: 0.573700\n",
      "epoch 3; iter: 200; batch classifier loss: 0.545904; batch adversarial loss: 0.664914\n",
      "epoch 3; iter: 400; batch classifier loss: 1.196613; batch adversarial loss: 0.582669\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422291; batch adversarial loss: 0.622114\n",
      "epoch 4; iter: 200; batch classifier loss: 1.157998; batch adversarial loss: 0.675068\n",
      "epoch 4; iter: 400; batch classifier loss: 0.464844; batch adversarial loss: 0.623725\n",
      "epoch 5; iter: 0; batch classifier loss: 1.137689; batch adversarial loss: 0.715760\n",
      "epoch 5; iter: 200; batch classifier loss: 0.447631; batch adversarial loss: 0.628831\n",
      "epoch 5; iter: 400; batch classifier loss: 0.534329; batch adversarial loss: 0.648674\n",
      "epoch 6; iter: 0; batch classifier loss: 0.425137; batch adversarial loss: 0.638754\n",
      "epoch 6; iter: 200; batch classifier loss: 0.534622; batch adversarial loss: 0.632672\n",
      "epoch 6; iter: 400; batch classifier loss: 0.713006; batch adversarial loss: 0.686194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.819460; batch adversarial loss: 0.621815\n",
      "epoch 7; iter: 200; batch classifier loss: 0.514686; batch adversarial loss: 0.632438\n",
      "epoch 7; iter: 400; batch classifier loss: 0.346464; batch adversarial loss: 0.659090\n",
      "epoch 8; iter: 0; batch classifier loss: 0.469008; batch adversarial loss: 0.616067\n",
      "epoch 8; iter: 200; batch classifier loss: 0.318863; batch adversarial loss: 0.565238\n",
      "epoch 8; iter: 400; batch classifier loss: 0.436322; batch adversarial loss: 0.559310\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610950; batch adversarial loss: 0.615767\n",
      "epoch 9; iter: 200; batch classifier loss: 0.378651; batch adversarial loss: 0.628901\n",
      "epoch 9; iter: 400; batch classifier loss: 0.399381; batch adversarial loss: 0.603948\n",
      "epoch 0; iter: 0; batch classifier loss: 59.806099; batch adversarial loss: 0.898319\n",
      "epoch 0; iter: 200; batch classifier loss: 6.942372; batch adversarial loss: 0.769601\n",
      "epoch 0; iter: 400; batch classifier loss: 5.149318; batch adversarial loss: 0.676359\n",
      "epoch 1; iter: 0; batch classifier loss: 5.073971; batch adversarial loss: 0.642410\n",
      "epoch 1; iter: 200; batch classifier loss: 3.305281; batch adversarial loss: 0.666879\n",
      "epoch 1; iter: 400; batch classifier loss: 5.091623; batch adversarial loss: 0.641552\n",
      "epoch 2; iter: 0; batch classifier loss: 1.748074; batch adversarial loss: 0.597309\n",
      "epoch 2; iter: 200; batch classifier loss: 1.549729; batch adversarial loss: 0.635895\n",
      "epoch 2; iter: 400; batch classifier loss: 3.393506; batch adversarial loss: 0.668971\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516566; batch adversarial loss: 0.594896\n",
      "epoch 3; iter: 200; batch classifier loss: 0.792248; batch adversarial loss: 0.607180\n",
      "epoch 3; iter: 400; batch classifier loss: 2.858234; batch adversarial loss: 0.567687\n",
      "epoch 4; iter: 0; batch classifier loss: 0.683971; batch adversarial loss: 0.631906\n",
      "epoch 4; iter: 200; batch classifier loss: 0.371798; batch adversarial loss: 0.586753\n",
      "epoch 4; iter: 400; batch classifier loss: 0.757209; batch adversarial loss: 0.670893\n",
      "epoch 5; iter: 0; batch classifier loss: 0.272802; batch adversarial loss: 0.663945\n",
      "epoch 5; iter: 200; batch classifier loss: 1.310862; batch adversarial loss: 0.614868\n",
      "epoch 5; iter: 400; batch classifier loss: 0.652670; batch adversarial loss: 0.634363\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589470; batch adversarial loss: 0.555186\n",
      "epoch 6; iter: 200; batch classifier loss: 0.418286; batch adversarial loss: 0.614794\n",
      "epoch 6; iter: 400; batch classifier loss: 0.783423; batch adversarial loss: 0.675713\n",
      "epoch 7; iter: 0; batch classifier loss: 0.751749; batch adversarial loss: 0.690901\n",
      "epoch 7; iter: 200; batch classifier loss: 0.709019; batch adversarial loss: 0.593133\n",
      "epoch 7; iter: 400; batch classifier loss: 0.626081; batch adversarial loss: 0.601565\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327570; batch adversarial loss: 0.638682\n",
      "epoch 8; iter: 200; batch classifier loss: 0.427575; batch adversarial loss: 0.608229\n",
      "epoch 8; iter: 400; batch classifier loss: 0.624485; batch adversarial loss: 0.673215\n",
      "epoch 9; iter: 0; batch classifier loss: 0.711847; batch adversarial loss: 0.607592\n",
      "epoch 9; iter: 200; batch classifier loss: 0.381960; batch adversarial loss: 0.717323\n",
      "epoch 9; iter: 400; batch classifier loss: 0.607923; batch adversarial loss: 0.571064\n",
      "epoch 0; iter: 0; batch classifier loss: 8.483044; batch adversarial loss: 0.717707\n",
      "epoch 0; iter: 200; batch classifier loss: 4.283183; batch adversarial loss: 0.680561\n",
      "epoch 0; iter: 400; batch classifier loss: 6.715249; batch adversarial loss: 0.614549\n",
      "epoch 1; iter: 0; batch classifier loss: 8.986540; batch adversarial loss: 0.589258\n",
      "epoch 1; iter: 200; batch classifier loss: 2.429100; batch adversarial loss: 0.572975\n",
      "epoch 1; iter: 400; batch classifier loss: 1.287519; batch adversarial loss: 0.639293\n",
      "epoch 2; iter: 0; batch classifier loss: 3.188888; batch adversarial loss: 0.649085\n",
      "epoch 2; iter: 200; batch classifier loss: 0.496940; batch adversarial loss: 0.630906\n",
      "epoch 2; iter: 400; batch classifier loss: 0.664532; batch adversarial loss: 0.601143\n",
      "epoch 3; iter: 0; batch classifier loss: 0.337513; batch adversarial loss: 0.614015\n",
      "epoch 3; iter: 200; batch classifier loss: 0.285636; batch adversarial loss: 0.641799\n",
      "epoch 3; iter: 400; batch classifier loss: 0.309124; batch adversarial loss: 0.666790\n",
      "epoch 4; iter: 0; batch classifier loss: 1.117059; batch adversarial loss: 0.595927\n",
      "epoch 4; iter: 200; batch classifier loss: 1.322072; batch adversarial loss: 0.655476\n",
      "epoch 4; iter: 400; batch classifier loss: 1.137919; batch adversarial loss: 0.681042\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496200; batch adversarial loss: 0.661689\n",
      "epoch 5; iter: 200; batch classifier loss: 0.271537; batch adversarial loss: 0.637478\n",
      "epoch 5; iter: 400; batch classifier loss: 0.371274; batch adversarial loss: 0.630993\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590527; batch adversarial loss: 0.602423\n",
      "epoch 6; iter: 200; batch classifier loss: 0.587705; batch adversarial loss: 0.755646\n",
      "epoch 6; iter: 400; batch classifier loss: 0.347482; batch adversarial loss: 0.668491\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474071; batch adversarial loss: 0.621705\n",
      "epoch 7; iter: 200; batch classifier loss: 0.386462; batch adversarial loss: 0.669714\n",
      "epoch 7; iter: 400; batch classifier loss: 0.356109; batch adversarial loss: 0.611054\n",
      "epoch 8; iter: 0; batch classifier loss: 0.658415; batch adversarial loss: 0.617104\n",
      "epoch 8; iter: 200; batch classifier loss: 0.593095; batch adversarial loss: 0.668742\n",
      "epoch 8; iter: 400; batch classifier loss: 0.244655; batch adversarial loss: 0.613963\n",
      "epoch 9; iter: 0; batch classifier loss: 0.368480; batch adversarial loss: 0.608617\n",
      "epoch 9; iter: 200; batch classifier loss: 0.275147; batch adversarial loss: 0.575744\n",
      "epoch 9; iter: 400; batch classifier loss: 0.368206; batch adversarial loss: 0.587668\n",
      "epoch 0; iter: 0; batch classifier loss: 14.776112; batch adversarial loss: 0.697283\n",
      "epoch 0; iter: 200; batch classifier loss: 4.509230; batch adversarial loss: 0.611476\n",
      "epoch 0; iter: 400; batch classifier loss: 7.419542; batch adversarial loss: 0.732751\n",
      "epoch 1; iter: 0; batch classifier loss: 2.400146; batch adversarial loss: 0.683472\n",
      "epoch 1; iter: 200; batch classifier loss: 2.693187; batch adversarial loss: 0.637560\n",
      "epoch 1; iter: 400; batch classifier loss: 5.189114; batch adversarial loss: 0.632860\n",
      "epoch 2; iter: 0; batch classifier loss: 1.764650; batch adversarial loss: 0.636536\n",
      "epoch 2; iter: 200; batch classifier loss: 12.688205; batch adversarial loss: 0.649927\n",
      "epoch 2; iter: 400; batch classifier loss: 13.796227; batch adversarial loss: 0.603550\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585644; batch adversarial loss: 0.639585\n",
      "epoch 3; iter: 200; batch classifier loss: 0.769741; batch adversarial loss: 0.579248\n",
      "epoch 3; iter: 400; batch classifier loss: 0.613954; batch adversarial loss: 0.586795\n",
      "epoch 4; iter: 0; batch classifier loss: 2.707882; batch adversarial loss: 0.677924\n",
      "epoch 4; iter: 200; batch classifier loss: 0.463996; batch adversarial loss: 0.701065\n",
      "epoch 4; iter: 400; batch classifier loss: 0.908952; batch adversarial loss: 0.577578\n",
      "epoch 5; iter: 0; batch classifier loss: 0.636770; batch adversarial loss: 0.626414\n",
      "epoch 5; iter: 200; batch classifier loss: 0.867932; batch adversarial loss: 0.591446\n",
      "epoch 5; iter: 400; batch classifier loss: 0.470128; batch adversarial loss: 0.590581\n",
      "epoch 6; iter: 0; batch classifier loss: 0.481012; batch adversarial loss: 0.610770\n",
      "epoch 6; iter: 200; batch classifier loss: 0.611249; batch adversarial loss: 0.640206\n",
      "epoch 6; iter: 400; batch classifier loss: 0.407422; batch adversarial loss: 0.495212\n",
      "epoch 7; iter: 0; batch classifier loss: 0.348852; batch adversarial loss: 0.651456\n",
      "epoch 7; iter: 200; batch classifier loss: 0.467328; batch adversarial loss: 0.634143\n",
      "epoch 7; iter: 400; batch classifier loss: 0.503374; batch adversarial loss: 0.691359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513340; batch adversarial loss: 0.611997\n",
      "epoch 8; iter: 200; batch classifier loss: 0.411758; batch adversarial loss: 0.717496\n",
      "epoch 8; iter: 400; batch classifier loss: 0.625358; batch adversarial loss: 0.615057\n",
      "epoch 9; iter: 0; batch classifier loss: 0.410022; batch adversarial loss: 0.656398\n",
      "epoch 9; iter: 200; batch classifier loss: 1.709601; batch adversarial loss: 0.595699\n",
      "epoch 9; iter: 400; batch classifier loss: 0.417084; batch adversarial loss: 0.585228\n",
      "epoch 0; iter: 0; batch classifier loss: 3.990314; batch adversarial loss: 0.779775\n",
      "epoch 0; iter: 200; batch classifier loss: 2.303639; batch adversarial loss: 0.718176\n",
      "epoch 0; iter: 400; batch classifier loss: 7.471576; batch adversarial loss: 0.679239\n",
      "epoch 1; iter: 0; batch classifier loss: 5.713396; batch adversarial loss: 0.674449\n",
      "epoch 1; iter: 200; batch classifier loss: 3.353006; batch adversarial loss: 0.633919\n",
      "epoch 1; iter: 400; batch classifier loss: 6.725755; batch adversarial loss: 0.632429\n",
      "epoch 2; iter: 0; batch classifier loss: 2.063723; batch adversarial loss: 0.587967\n",
      "epoch 2; iter: 200; batch classifier loss: 1.864664; batch adversarial loss: 0.671738\n",
      "epoch 2; iter: 400; batch classifier loss: 1.564319; batch adversarial loss: 0.593043\n",
      "epoch 3; iter: 0; batch classifier loss: 0.737982; batch adversarial loss: 0.614503\n",
      "epoch 3; iter: 200; batch classifier loss: 1.010975; batch adversarial loss: 0.608501\n",
      "epoch 3; iter: 400; batch classifier loss: 0.325167; batch adversarial loss: 0.623187\n",
      "epoch 4; iter: 0; batch classifier loss: 0.447723; batch adversarial loss: 0.575376\n",
      "epoch 4; iter: 200; batch classifier loss: 1.002982; batch adversarial loss: 0.681250\n",
      "epoch 4; iter: 400; batch classifier loss: 1.103926; batch adversarial loss: 0.635428\n",
      "epoch 5; iter: 0; batch classifier loss: 0.270362; batch adversarial loss: 0.660825\n",
      "epoch 5; iter: 200; batch classifier loss: 0.325456; batch adversarial loss: 0.609276\n",
      "epoch 5; iter: 400; batch classifier loss: 0.284729; batch adversarial loss: 0.672716\n",
      "epoch 6; iter: 0; batch classifier loss: 0.643748; batch adversarial loss: 0.707707\n",
      "epoch 6; iter: 200; batch classifier loss: 0.288826; batch adversarial loss: 0.648541\n",
      "epoch 6; iter: 400; batch classifier loss: 0.397156; batch adversarial loss: 0.525004\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486831; batch adversarial loss: 0.576366\n",
      "epoch 7; iter: 200; batch classifier loss: 0.418476; batch adversarial loss: 0.616522\n",
      "epoch 7; iter: 400; batch classifier loss: 0.353687; batch adversarial loss: 0.658153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.351159; batch adversarial loss: 0.653873\n",
      "epoch 8; iter: 200; batch classifier loss: 0.468501; batch adversarial loss: 0.650638\n",
      "epoch 8; iter: 400; batch classifier loss: 0.418545; batch adversarial loss: 0.607354\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359537; batch adversarial loss: 0.613061\n",
      "epoch 9; iter: 200; batch classifier loss: 0.380890; batch adversarial loss: 0.624802\n",
      "epoch 9; iter: 400; batch classifier loss: 0.392578; batch adversarial loss: 0.570279\n",
      "epoch 0; iter: 0; batch classifier loss: 586.529663; batch adversarial loss: 0.619619\n",
      "epoch 0; iter: 200; batch classifier loss: 1.871452; batch adversarial loss: 0.618707\n",
      "epoch 0; iter: 400; batch classifier loss: 0.656594; batch adversarial loss: 0.660665\n",
      "epoch 1; iter: 0; batch classifier loss: 0.927727; batch adversarial loss: 0.599103\n",
      "epoch 1; iter: 200; batch classifier loss: 2.008916; batch adversarial loss: 0.704964\n",
      "epoch 1; iter: 400; batch classifier loss: 4.212781; batch adversarial loss: 0.575192\n",
      "epoch 2; iter: 0; batch classifier loss: 0.852681; batch adversarial loss: 0.598907\n",
      "epoch 2; iter: 200; batch classifier loss: 3.578876; batch adversarial loss: 0.658997\n",
      "epoch 2; iter: 400; batch classifier loss: 8.635242; batch adversarial loss: 0.677707\n",
      "epoch 3; iter: 0; batch classifier loss: 4.368752; batch adversarial loss: 0.648019\n",
      "epoch 3; iter: 200; batch classifier loss: 1.280356; batch adversarial loss: 0.565925\n",
      "epoch 3; iter: 400; batch classifier loss: 0.628932; batch adversarial loss: 0.640602\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422761; batch adversarial loss: 0.593149\n",
      "epoch 4; iter: 200; batch classifier loss: 1.029417; batch adversarial loss: 0.604157\n",
      "epoch 4; iter: 400; batch classifier loss: 1.498965; batch adversarial loss: 0.642800\n",
      "epoch 5; iter: 0; batch classifier loss: 2.585400; batch adversarial loss: 0.700596\n",
      "epoch 5; iter: 200; batch classifier loss: 3.678336; batch adversarial loss: 0.641468\n",
      "epoch 5; iter: 400; batch classifier loss: 1.253882; batch adversarial loss: 0.638238\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486659; batch adversarial loss: 0.663363\n",
      "epoch 6; iter: 200; batch classifier loss: 0.990703; batch adversarial loss: 0.708106\n",
      "epoch 6; iter: 400; batch classifier loss: 0.543279; batch adversarial loss: 0.644768\n",
      "epoch 7; iter: 0; batch classifier loss: 0.431106; batch adversarial loss: 0.618090\n",
      "epoch 7; iter: 200; batch classifier loss: 0.404598; batch adversarial loss: 0.663976\n",
      "epoch 7; iter: 400; batch classifier loss: 0.495422; batch adversarial loss: 0.536986\n",
      "epoch 8; iter: 0; batch classifier loss: 0.623609; batch adversarial loss: 0.691301\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401004; batch adversarial loss: 0.532513\n",
      "epoch 8; iter: 400; batch classifier loss: 0.190499; batch adversarial loss: 0.681853\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602250; batch adversarial loss: 0.700010\n",
      "epoch 9; iter: 200; batch classifier loss: 0.452510; batch adversarial loss: 0.731795\n",
      "epoch 9; iter: 400; batch classifier loss: 0.447017; batch adversarial loss: 0.559615\n",
      "epoch 0; iter: 0; batch classifier loss: 25.506176; batch adversarial loss: 0.686379\n",
      "epoch 0; iter: 200; batch classifier loss: 2.487040; batch adversarial loss: 0.646541\n",
      "epoch 0; iter: 400; batch classifier loss: 5.634415; batch adversarial loss: 0.596530\n",
      "epoch 1; iter: 0; batch classifier loss: 4.696917; batch adversarial loss: 0.625586\n",
      "epoch 1; iter: 200; batch classifier loss: 1.476038; batch adversarial loss: 0.585139\n",
      "epoch 1; iter: 400; batch classifier loss: 0.754542; batch adversarial loss: 0.629025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.478421; batch adversarial loss: 0.605830\n",
      "epoch 2; iter: 200; batch classifier loss: 3.189926; batch adversarial loss: 0.556727\n",
      "epoch 2; iter: 400; batch classifier loss: 0.428268; batch adversarial loss: 0.599454\n",
      "epoch 3; iter: 0; batch classifier loss: 2.144971; batch adversarial loss: 0.649984\n",
      "epoch 3; iter: 200; batch classifier loss: 0.631449; batch adversarial loss: 0.623431\n",
      "epoch 3; iter: 400; batch classifier loss: 0.588168; batch adversarial loss: 0.553650\n",
      "epoch 4; iter: 0; batch classifier loss: 0.500551; batch adversarial loss: 0.662576\n",
      "epoch 4; iter: 200; batch classifier loss: 2.151822; batch adversarial loss: 0.683061\n",
      "epoch 4; iter: 400; batch classifier loss: 0.381127; batch adversarial loss: 0.576832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.373850; batch adversarial loss: 0.672984\n",
      "epoch 5; iter: 200; batch classifier loss: 0.388413; batch adversarial loss: 0.625666\n",
      "epoch 5; iter: 400; batch classifier loss: 0.314737; batch adversarial loss: 0.604521\n",
      "epoch 6; iter: 0; batch classifier loss: 0.363702; batch adversarial loss: 0.583024\n",
      "epoch 6; iter: 200; batch classifier loss: 0.650802; batch adversarial loss: 0.649107\n",
      "epoch 6; iter: 400; batch classifier loss: 0.575941; batch adversarial loss: 0.612004\n",
      "epoch 7; iter: 0; batch classifier loss: 0.644697; batch adversarial loss: 0.652969\n",
      "epoch 7; iter: 200; batch classifier loss: 0.910177; batch adversarial loss: 0.730823\n",
      "epoch 7; iter: 400; batch classifier loss: 0.569301; batch adversarial loss: 0.639975\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479680; batch adversarial loss: 0.606470\n",
      "epoch 8; iter: 200; batch classifier loss: 0.528785; batch adversarial loss: 0.626213\n",
      "epoch 8; iter: 400; batch classifier loss: 0.350434; batch adversarial loss: 0.660929\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530568; batch adversarial loss: 0.580621\n",
      "epoch 9; iter: 200; batch classifier loss: 0.361841; batch adversarial loss: 0.596580\n",
      "epoch 9; iter: 400; batch classifier loss: 0.406106; batch adversarial loss: 0.648535\n",
      "epoch 0; iter: 0; batch classifier loss: 3.214529; batch adversarial loss: 0.688993\n",
      "epoch 0; iter: 200; batch classifier loss: 13.960217; batch adversarial loss: 0.639777\n",
      "epoch 0; iter: 400; batch classifier loss: 17.169601; batch adversarial loss: 0.620573\n",
      "epoch 1; iter: 0; batch classifier loss: 1.686459; batch adversarial loss: 0.652243\n",
      "epoch 1; iter: 200; batch classifier loss: 5.689064; batch adversarial loss: 0.679063\n",
      "epoch 1; iter: 400; batch classifier loss: 3.968107; batch adversarial loss: 0.604190\n",
      "epoch 2; iter: 0; batch classifier loss: 3.683316; batch adversarial loss: 0.678159\n",
      "epoch 2; iter: 200; batch classifier loss: 0.425504; batch adversarial loss: 0.622564\n",
      "epoch 2; iter: 400; batch classifier loss: 1.197264; batch adversarial loss: 0.628885\n",
      "epoch 3; iter: 0; batch classifier loss: 1.622540; batch adversarial loss: 0.630690\n",
      "epoch 3; iter: 200; batch classifier loss: 0.335646; batch adversarial loss: 0.638361\n",
      "epoch 3; iter: 400; batch classifier loss: 4.194751; batch adversarial loss: 0.617384\n",
      "epoch 4; iter: 0; batch classifier loss: 0.688129; batch adversarial loss: 0.579904\n",
      "epoch 4; iter: 200; batch classifier loss: 0.370418; batch adversarial loss: 0.584957\n",
      "epoch 4; iter: 400; batch classifier loss: 0.505115; batch adversarial loss: 0.573844\n",
      "epoch 5; iter: 0; batch classifier loss: 0.481961; batch adversarial loss: 0.600234\n",
      "epoch 5; iter: 200; batch classifier loss: 0.568332; batch adversarial loss: 0.713155\n",
      "epoch 5; iter: 400; batch classifier loss: 0.580754; batch adversarial loss: 0.639974\n",
      "epoch 6; iter: 0; batch classifier loss: 1.680284; batch adversarial loss: 0.691337\n",
      "epoch 6; iter: 200; batch classifier loss: 0.404735; batch adversarial loss: 0.653114\n",
      "epoch 6; iter: 400; batch classifier loss: 0.315440; batch adversarial loss: 0.685950\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537871; batch adversarial loss: 0.676816\n",
      "epoch 7; iter: 200; batch classifier loss: 0.548495; batch adversarial loss: 0.710191\n",
      "epoch 7; iter: 400; batch classifier loss: 0.438269; batch adversarial loss: 0.588793\n",
      "epoch 8; iter: 0; batch classifier loss: 0.423845; batch adversarial loss: 0.595803\n",
      "epoch 8; iter: 200; batch classifier loss: 0.427187; batch adversarial loss: 0.637395\n",
      "epoch 8; iter: 400; batch classifier loss: 1.027258; batch adversarial loss: 0.695555\n",
      "epoch 9; iter: 0; batch classifier loss: 0.546275; batch adversarial loss: 0.647331\n",
      "epoch 9; iter: 200; batch classifier loss: 0.330957; batch adversarial loss: 0.627490\n",
      "epoch 9; iter: 400; batch classifier loss: 0.537246; batch adversarial loss: 0.582156\n",
      "epoch 0; iter: 0; batch classifier loss: 4.035693; batch adversarial loss: 0.652574\n",
      "epoch 0; iter: 200; batch classifier loss: 5.649822; batch adversarial loss: 0.699349\n",
      "epoch 0; iter: 400; batch classifier loss: 6.462163; batch adversarial loss: 0.730126\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718698; batch adversarial loss: 0.624502\n",
      "epoch 1; iter: 200; batch classifier loss: 4.068723; batch adversarial loss: 0.629810\n",
      "epoch 1; iter: 400; batch classifier loss: 11.846716; batch adversarial loss: 0.618541\n",
      "epoch 2; iter: 0; batch classifier loss: 1.653741; batch adversarial loss: 0.635944\n",
      "epoch 2; iter: 200; batch classifier loss: 5.133505; batch adversarial loss: 0.624618\n",
      "epoch 2; iter: 400; batch classifier loss: 0.857737; batch adversarial loss: 0.622328\n",
      "epoch 3; iter: 0; batch classifier loss: 0.950017; batch adversarial loss: 0.627295\n",
      "epoch 3; iter: 200; batch classifier loss: 2.873738; batch adversarial loss: 0.682785\n",
      "epoch 3; iter: 400; batch classifier loss: 1.261384; batch adversarial loss: 0.628454\n",
      "epoch 4; iter: 0; batch classifier loss: 2.155991; batch adversarial loss: 0.603081\n",
      "epoch 4; iter: 200; batch classifier loss: 1.837260; batch adversarial loss: 0.647214\n",
      "epoch 4; iter: 400; batch classifier loss: 0.498186; batch adversarial loss: 0.613789\n",
      "epoch 5; iter: 0; batch classifier loss: 2.084389; batch adversarial loss: 0.622140\n",
      "epoch 5; iter: 200; batch classifier loss: 0.563265; batch adversarial loss: 0.615099\n",
      "epoch 5; iter: 400; batch classifier loss: 0.360398; batch adversarial loss: 0.658561\n",
      "epoch 6; iter: 0; batch classifier loss: 0.428641; batch adversarial loss: 0.655376\n",
      "epoch 6; iter: 200; batch classifier loss: 0.649789; batch adversarial loss: 0.589398\n",
      "epoch 6; iter: 400; batch classifier loss: 0.507594; batch adversarial loss: 0.578930\n",
      "epoch 7; iter: 0; batch classifier loss: 0.683762; batch adversarial loss: 0.744152\n",
      "epoch 7; iter: 200; batch classifier loss: 0.373933; batch adversarial loss: 0.603990\n",
      "epoch 7; iter: 400; batch classifier loss: 0.425917; batch adversarial loss: 0.599296\n",
      "epoch 8; iter: 0; batch classifier loss: 0.391389; batch adversarial loss: 0.581034\n",
      "epoch 8; iter: 200; batch classifier loss: 0.949981; batch adversarial loss: 0.576555\n",
      "epoch 8; iter: 400; batch classifier loss: 0.393464; batch adversarial loss: 0.723139\n",
      "epoch 9; iter: 0; batch classifier loss: 0.350699; batch adversarial loss: 0.669974\n",
      "epoch 9; iter: 200; batch classifier loss: 0.325308; batch adversarial loss: 0.658633\n",
      "epoch 9; iter: 400; batch classifier loss: 0.676790; batch adversarial loss: 0.625703\n",
      "epoch 0; iter: 0; batch classifier loss: 7.004299; batch adversarial loss: 0.649741\n",
      "epoch 0; iter: 200; batch classifier loss: 7.545903; batch adversarial loss: 0.628871\n",
      "epoch 0; iter: 400; batch classifier loss: 2.322054; batch adversarial loss: 0.626074\n",
      "epoch 1; iter: 0; batch classifier loss: 1.016883; batch adversarial loss: 0.627804\n",
      "epoch 1; iter: 200; batch classifier loss: 0.405795; batch adversarial loss: 0.587592\n",
      "epoch 1; iter: 400; batch classifier loss: 4.773104; batch adversarial loss: 0.586204\n",
      "epoch 2; iter: 0; batch classifier loss: 1.240017; batch adversarial loss: 0.616481\n",
      "epoch 2; iter: 200; batch classifier loss: 0.816473; batch adversarial loss: 0.636115\n",
      "epoch 2; iter: 400; batch classifier loss: 4.164393; batch adversarial loss: 0.624584\n",
      "epoch 3; iter: 0; batch classifier loss: 0.689830; batch adversarial loss: 0.610417\n",
      "epoch 3; iter: 200; batch classifier loss: 1.102216; batch adversarial loss: 0.574140\n",
      "epoch 3; iter: 400; batch classifier loss: 0.285423; batch adversarial loss: 0.600256\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405688; batch adversarial loss: 0.596491\n",
      "epoch 4; iter: 200; batch classifier loss: 0.752978; batch adversarial loss: 0.549699\n",
      "epoch 4; iter: 400; batch classifier loss: 0.392311; batch adversarial loss: 0.603669\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581844; batch adversarial loss: 0.628553\n",
      "epoch 5; iter: 200; batch classifier loss: 0.537060; batch adversarial loss: 0.663397\n",
      "epoch 5; iter: 400; batch classifier loss: 0.691139; batch adversarial loss: 0.590464\n",
      "epoch 6; iter: 0; batch classifier loss: 3.256958; batch adversarial loss: 0.614512\n",
      "epoch 6; iter: 200; batch classifier loss: 0.291972; batch adversarial loss: 0.662391\n",
      "epoch 6; iter: 400; batch classifier loss: 2.273134; batch adversarial loss: 0.601208\n",
      "epoch 7; iter: 0; batch classifier loss: 0.266384; batch adversarial loss: 0.645651\n",
      "epoch 7; iter: 200; batch classifier loss: 0.372404; batch adversarial loss: 0.565507\n",
      "epoch 7; iter: 400; batch classifier loss: 0.645055; batch adversarial loss: 0.543471\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368189; batch adversarial loss: 0.636615\n",
      "epoch 8; iter: 200; batch classifier loss: 0.280449; batch adversarial loss: 0.643093\n",
      "epoch 8; iter: 400; batch classifier loss: 0.335457; batch adversarial loss: 0.617303\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488526; batch adversarial loss: 0.647179\n",
      "epoch 9; iter: 200; batch classifier loss: 0.355047; batch adversarial loss: 0.675815\n",
      "epoch 9; iter: 400; batch classifier loss: 0.259256; batch adversarial loss: 0.621603\n",
      "epoch 0; iter: 0; batch classifier loss: 87.148956; batch adversarial loss: 0.678325\n",
      "epoch 0; iter: 200; batch classifier loss: 1.450363; batch adversarial loss: 0.660294\n",
      "epoch 0; iter: 400; batch classifier loss: 2.627287; batch adversarial loss: 0.627403\n",
      "epoch 1; iter: 0; batch classifier loss: 4.084209; batch adversarial loss: 0.622200\n",
      "epoch 1; iter: 200; batch classifier loss: 0.718137; batch adversarial loss: 0.725007\n",
      "epoch 1; iter: 400; batch classifier loss: 1.961775; batch adversarial loss: 0.653057\n",
      "epoch 2; iter: 0; batch classifier loss: 0.344975; batch adversarial loss: 0.603562\n",
      "epoch 2; iter: 200; batch classifier loss: 1.811154; batch adversarial loss: 0.643786\n",
      "epoch 2; iter: 400; batch classifier loss: 3.664342; batch adversarial loss: 0.597642\n",
      "epoch 3; iter: 0; batch classifier loss: 7.653997; batch adversarial loss: 0.602414\n",
      "epoch 3; iter: 200; batch classifier loss: 6.459552; batch adversarial loss: 0.581119\n",
      "epoch 3; iter: 400; batch classifier loss: 0.856307; batch adversarial loss: 0.597386\n",
      "epoch 4; iter: 0; batch classifier loss: 7.190400; batch adversarial loss: 0.699620\n",
      "epoch 4; iter: 200; batch classifier loss: 0.395591; batch adversarial loss: 0.658880\n",
      "epoch 4; iter: 400; batch classifier loss: 1.555454; batch adversarial loss: 0.574635\n",
      "epoch 5; iter: 0; batch classifier loss: 0.641918; batch adversarial loss: 0.629340\n",
      "epoch 5; iter: 200; batch classifier loss: 0.958206; batch adversarial loss: 0.640864\n",
      "epoch 5; iter: 400; batch classifier loss: 0.336427; batch adversarial loss: 0.584476\n",
      "epoch 6; iter: 0; batch classifier loss: 0.798610; batch adversarial loss: 0.603588\n",
      "epoch 6; iter: 200; batch classifier loss: 0.435300; batch adversarial loss: 0.679616\n",
      "epoch 6; iter: 400; batch classifier loss: 0.548381; batch adversarial loss: 0.686020\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491794; batch adversarial loss: 0.594989\n",
      "epoch 7; iter: 200; batch classifier loss: 0.587982; batch adversarial loss: 0.566340\n",
      "epoch 7; iter: 400; batch classifier loss: 0.408890; batch adversarial loss: 0.605487\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550927; batch adversarial loss: 0.613370\n",
      "epoch 8; iter: 200; batch classifier loss: 0.355403; batch adversarial loss: 0.633191\n",
      "epoch 8; iter: 400; batch classifier loss: 0.495989; batch adversarial loss: 0.639566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.970533; batch adversarial loss: 0.706535\n",
      "epoch 9; iter: 200; batch classifier loss: 0.320734; batch adversarial loss: 0.651840\n",
      "epoch 9; iter: 400; batch classifier loss: 0.533138; batch adversarial loss: 0.576844\n",
      "epoch 0; iter: 0; batch classifier loss: 25.574324; batch adversarial loss: 0.707782\n",
      "epoch 0; iter: 200; batch classifier loss: 10.919651; batch adversarial loss: 0.647194\n",
      "epoch 0; iter: 400; batch classifier loss: 13.934793; batch adversarial loss: 0.615865\n",
      "epoch 1; iter: 0; batch classifier loss: 3.593421; batch adversarial loss: 0.631554\n",
      "epoch 1; iter: 200; batch classifier loss: 7.600719; batch adversarial loss: 0.575342\n",
      "epoch 1; iter: 400; batch classifier loss: 1.157683; batch adversarial loss: 0.596625\n",
      "epoch 2; iter: 0; batch classifier loss: 1.276143; batch adversarial loss: 0.623916\n",
      "epoch 2; iter: 200; batch classifier loss: 1.166526; batch adversarial loss: 0.663887\n",
      "epoch 2; iter: 400; batch classifier loss: 2.788158; batch adversarial loss: 0.670435\n",
      "epoch 3; iter: 0; batch classifier loss: 1.425247; batch adversarial loss: 0.619287\n",
      "epoch 3; iter: 200; batch classifier loss: 2.889339; batch adversarial loss: 0.590127\n",
      "epoch 3; iter: 400; batch classifier loss: 0.369831; batch adversarial loss: 0.536102\n",
      "epoch 4; iter: 0; batch classifier loss: 5.105420; batch adversarial loss: 0.690310\n",
      "epoch 4; iter: 200; batch classifier loss: 0.503105; batch adversarial loss: 0.667420\n",
      "epoch 4; iter: 400; batch classifier loss: 0.659140; batch adversarial loss: 0.648393\n",
      "epoch 5; iter: 0; batch classifier loss: 0.435683; batch adversarial loss: 0.626712\n",
      "epoch 5; iter: 200; batch classifier loss: 0.899006; batch adversarial loss: 0.628811\n",
      "epoch 5; iter: 400; batch classifier loss: 0.484085; batch adversarial loss: 0.607125\n",
      "epoch 6; iter: 0; batch classifier loss: 0.768146; batch adversarial loss: 0.550009\n",
      "epoch 6; iter: 200; batch classifier loss: 0.558268; batch adversarial loss: 0.685440\n",
      "epoch 6; iter: 400; batch classifier loss: 0.642230; batch adversarial loss: 0.594423\n",
      "epoch 7; iter: 0; batch classifier loss: 0.236455; batch adversarial loss: 0.664357\n",
      "epoch 7; iter: 200; batch classifier loss: 0.414054; batch adversarial loss: 0.538713\n",
      "epoch 7; iter: 400; batch classifier loss: 0.331066; batch adversarial loss: 0.619143\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485399; batch adversarial loss: 0.628906\n",
      "epoch 8; iter: 200; batch classifier loss: 0.329938; batch adversarial loss: 0.599155\n",
      "epoch 8; iter: 400; batch classifier loss: 0.590109; batch adversarial loss: 0.614897\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426667; batch adversarial loss: 0.667884\n",
      "epoch 9; iter: 200; batch classifier loss: 0.260678; batch adversarial loss: 0.657288\n",
      "epoch 9; iter: 400; batch classifier loss: 0.390666; batch adversarial loss: 0.646466\n",
      "epoch 0; iter: 0; batch classifier loss: 41.822559; batch adversarial loss: 0.692129\n",
      "epoch 0; iter: 200; batch classifier loss: 10.274611; batch adversarial loss: 0.640059\n",
      "epoch 0; iter: 400; batch classifier loss: 9.224977; batch adversarial loss: 0.835897\n",
      "epoch 1; iter: 0; batch classifier loss: 2.495910; batch adversarial loss: 0.642256\n",
      "epoch 1; iter: 200; batch classifier loss: 0.766428; batch adversarial loss: 0.651684\n",
      "epoch 1; iter: 400; batch classifier loss: 1.797810; batch adversarial loss: 0.607011\n",
      "epoch 2; iter: 0; batch classifier loss: 5.611426; batch adversarial loss: 0.565189\n",
      "epoch 2; iter: 200; batch classifier loss: 56.267715; batch adversarial loss: 0.649210\n",
      "epoch 2; iter: 400; batch classifier loss: 6.963560; batch adversarial loss: 0.615876\n",
      "epoch 3; iter: 0; batch classifier loss: 1.550799; batch adversarial loss: 0.657799\n",
      "epoch 3; iter: 200; batch classifier loss: 1.059009; batch adversarial loss: 0.623415\n",
      "epoch 3; iter: 400; batch classifier loss: 0.649684; batch adversarial loss: 0.685314\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496384; batch adversarial loss: 0.685862\n",
      "epoch 4; iter: 200; batch classifier loss: 0.850774; batch adversarial loss: 0.584684\n",
      "epoch 4; iter: 400; batch classifier loss: 0.301476; batch adversarial loss: 0.615231\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387230; batch adversarial loss: 0.569976\n",
      "epoch 5; iter: 200; batch classifier loss: 0.949702; batch adversarial loss: 0.592606\n",
      "epoch 5; iter: 400; batch classifier loss: 0.569521; batch adversarial loss: 0.682091\n",
      "epoch 6; iter: 0; batch classifier loss: 0.389558; batch adversarial loss: 0.550124\n",
      "epoch 6; iter: 200; batch classifier loss: 0.537576; batch adversarial loss: 0.600383\n",
      "epoch 6; iter: 400; batch classifier loss: 0.335834; batch adversarial loss: 0.614190\n",
      "epoch 7; iter: 0; batch classifier loss: 0.370714; batch adversarial loss: 0.633774\n",
      "epoch 7; iter: 200; batch classifier loss: 1.350636; batch adversarial loss: 0.592287\n",
      "epoch 7; iter: 400; batch classifier loss: 0.351753; batch adversarial loss: 0.578998\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505491; batch adversarial loss: 0.659450\n",
      "epoch 8; iter: 200; batch classifier loss: 0.397290; batch adversarial loss: 0.589969\n",
      "epoch 8; iter: 400; batch classifier loss: 0.403183; batch adversarial loss: 0.548060\n",
      "epoch 9; iter: 0; batch classifier loss: 0.238694; batch adversarial loss: 0.698051\n",
      "epoch 9; iter: 200; batch classifier loss: 0.651182; batch adversarial loss: 0.505653\n",
      "epoch 9; iter: 400; batch classifier loss: 0.352161; batch adversarial loss: 0.591806\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 27.191406; batch adversarial loss: 0.672674\n",
      "epoch 0; iter: 200; batch classifier loss: 7.256950; batch adversarial loss: 0.677234\n",
      "epoch 0; iter: 400; batch classifier loss: 3.958085; batch adversarial loss: 0.612664\n",
      "epoch 1; iter: 0; batch classifier loss: 4.898579; batch adversarial loss: 0.663879\n",
      "epoch 1; iter: 200; batch classifier loss: 4.630551; batch adversarial loss: 0.552810\n",
      "epoch 1; iter: 400; batch classifier loss: 2.684982; batch adversarial loss: 0.590426\n",
      "epoch 2; iter: 0; batch classifier loss: 5.614746; batch adversarial loss: 0.607579\n",
      "epoch 2; iter: 200; batch classifier loss: 3.145185; batch adversarial loss: 0.652411\n",
      "epoch 2; iter: 400; batch classifier loss: 4.653765; batch adversarial loss: 0.560114\n",
      "epoch 3; iter: 0; batch classifier loss: 3.296485; batch adversarial loss: 0.581882\n",
      "epoch 3; iter: 200; batch classifier loss: 0.417441; batch adversarial loss: 0.682904\n",
      "epoch 3; iter: 400; batch classifier loss: 11.550704; batch adversarial loss: 0.615176\n",
      "epoch 4; iter: 0; batch classifier loss: 1.024664; batch adversarial loss: 0.705404\n",
      "epoch 4; iter: 200; batch classifier loss: 0.488820; batch adversarial loss: 0.609034\n",
      "epoch 4; iter: 400; batch classifier loss: 0.698106; batch adversarial loss: 0.616977\n",
      "epoch 5; iter: 0; batch classifier loss: 0.369767; batch adversarial loss: 0.613837\n",
      "epoch 5; iter: 200; batch classifier loss: 0.332867; batch adversarial loss: 0.676913\n",
      "epoch 5; iter: 400; batch classifier loss: 0.660939; batch adversarial loss: 0.658827\n",
      "epoch 6; iter: 0; batch classifier loss: 0.495767; batch adversarial loss: 0.648564\n",
      "epoch 6; iter: 200; batch classifier loss: 0.401732; batch adversarial loss: 0.594509\n",
      "epoch 6; iter: 400; batch classifier loss: 0.381411; batch adversarial loss: 0.651160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315368; batch adversarial loss: 0.655119\n",
      "epoch 7; iter: 200; batch classifier loss: 0.482476; batch adversarial loss: 0.622210\n",
      "epoch 7; iter: 400; batch classifier loss: 0.619710; batch adversarial loss: 0.571192\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359883; batch adversarial loss: 0.688077\n",
      "epoch 8; iter: 200; batch classifier loss: 0.652802; batch adversarial loss: 0.710285\n",
      "epoch 8; iter: 400; batch classifier loss: 0.523800; batch adversarial loss: 0.540052\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634798; batch adversarial loss: 0.605575\n",
      "epoch 9; iter: 200; batch classifier loss: 0.370083; batch adversarial loss: 0.576352\n",
      "epoch 9; iter: 400; batch classifier loss: 0.376506; batch adversarial loss: 0.582300\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358800; batch adversarial loss: 0.663962\n",
      "epoch 10; iter: 200; batch classifier loss: 0.361990; batch adversarial loss: 0.730116\n",
      "epoch 10; iter: 400; batch classifier loss: 0.396406; batch adversarial loss: 0.639172\n",
      "epoch 11; iter: 0; batch classifier loss: 0.423672; batch adversarial loss: 0.613990\n",
      "epoch 11; iter: 200; batch classifier loss: 0.292780; batch adversarial loss: 0.586620\n",
      "epoch 11; iter: 400; batch classifier loss: 0.471077; batch adversarial loss: 0.607877\n",
      "epoch 12; iter: 0; batch classifier loss: 0.784069; batch adversarial loss: 0.586989\n",
      "epoch 12; iter: 200; batch classifier loss: 0.263936; batch adversarial loss: 0.706456\n",
      "epoch 12; iter: 400; batch classifier loss: 0.478634; batch adversarial loss: 0.620926\n",
      "epoch 13; iter: 0; batch classifier loss: 0.322397; batch adversarial loss: 0.575476\n",
      "epoch 13; iter: 200; batch classifier loss: 0.275553; batch adversarial loss: 0.618650\n",
      "epoch 13; iter: 400; batch classifier loss: 0.255500; batch adversarial loss: 0.666029\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554650; batch adversarial loss: 0.579016\n",
      "epoch 14; iter: 200; batch classifier loss: 0.469174; batch adversarial loss: 0.608711\n",
      "epoch 14; iter: 400; batch classifier loss: 0.272198; batch adversarial loss: 0.624078\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347385; batch adversarial loss: 0.640704\n",
      "epoch 15; iter: 200; batch classifier loss: 0.176721; batch adversarial loss: 0.700432\n",
      "epoch 15; iter: 400; batch classifier loss: 0.439869; batch adversarial loss: 0.596052\n",
      "epoch 16; iter: 0; batch classifier loss: 0.589519; batch adversarial loss: 0.601083\n",
      "epoch 16; iter: 200; batch classifier loss: 0.234540; batch adversarial loss: 0.631786\n",
      "epoch 16; iter: 400; batch classifier loss: 0.398749; batch adversarial loss: 0.655980\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347042; batch adversarial loss: 0.618209\n",
      "epoch 17; iter: 200; batch classifier loss: 0.375276; batch adversarial loss: 0.613648\n",
      "epoch 17; iter: 400; batch classifier loss: 0.364481; batch adversarial loss: 0.657654\n",
      "epoch 18; iter: 0; batch classifier loss: 0.355998; batch adversarial loss: 0.594908\n",
      "epoch 18; iter: 200; batch classifier loss: 0.459762; batch adversarial loss: 0.583745\n",
      "epoch 18; iter: 400; batch classifier loss: 0.513655; batch adversarial loss: 0.684728\n",
      "epoch 19; iter: 0; batch classifier loss: 0.394151; batch adversarial loss: 0.627287\n",
      "epoch 19; iter: 200; batch classifier loss: 0.493759; batch adversarial loss: 0.671734\n",
      "epoch 19; iter: 400; batch classifier loss: 0.416647; batch adversarial loss: 0.550995\n",
      "epoch 0; iter: 0; batch classifier loss: 67.708260; batch adversarial loss: 0.774932\n",
      "epoch 0; iter: 200; batch classifier loss: 1.141611; batch adversarial loss: 0.669427\n",
      "epoch 0; iter: 400; batch classifier loss: 2.887506; batch adversarial loss: 0.663492\n",
      "epoch 1; iter: 0; batch classifier loss: 1.470090; batch adversarial loss: 0.661973\n",
      "epoch 1; iter: 200; batch classifier loss: 3.770126; batch adversarial loss: 0.682186\n",
      "epoch 1; iter: 400; batch classifier loss: 2.609081; batch adversarial loss: 0.661752\n",
      "epoch 2; iter: 0; batch classifier loss: 3.321954; batch adversarial loss: 0.550404\n",
      "epoch 2; iter: 200; batch classifier loss: 0.583909; batch adversarial loss: 0.646210\n",
      "epoch 2; iter: 400; batch classifier loss: 2.693923; batch adversarial loss: 0.651320\n",
      "epoch 3; iter: 0; batch classifier loss: 2.290113; batch adversarial loss: 0.595228\n",
      "epoch 3; iter: 200; batch classifier loss: 1.456756; batch adversarial loss: 0.610576\n",
      "epoch 3; iter: 400; batch classifier loss: 0.649577; batch adversarial loss: 0.580112\n",
      "epoch 4; iter: 0; batch classifier loss: 0.611020; batch adversarial loss: 0.595015\n",
      "epoch 4; iter: 200; batch classifier loss: 0.612213; batch adversarial loss: 0.655545\n",
      "epoch 4; iter: 400; batch classifier loss: 0.279913; batch adversarial loss: 0.605344\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549410; batch adversarial loss: 0.599596\n",
      "epoch 5; iter: 200; batch classifier loss: 0.304660; batch adversarial loss: 0.663658\n",
      "epoch 5; iter: 400; batch classifier loss: 0.436180; batch adversarial loss: 0.646862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609171; batch adversarial loss: 0.652885\n",
      "epoch 6; iter: 200; batch classifier loss: 0.452108; batch adversarial loss: 0.684966\n",
      "epoch 6; iter: 400; batch classifier loss: 0.497171; batch adversarial loss: 0.690472\n",
      "epoch 7; iter: 0; batch classifier loss: 0.292654; batch adversarial loss: 0.630904\n",
      "epoch 7; iter: 200; batch classifier loss: 0.626919; batch adversarial loss: 0.595174\n",
      "epoch 7; iter: 400; batch classifier loss: 0.382311; batch adversarial loss: 0.655309\n",
      "epoch 8; iter: 0; batch classifier loss: 0.412727; batch adversarial loss: 0.606723\n",
      "epoch 8; iter: 200; batch classifier loss: 0.328572; batch adversarial loss: 0.634786\n",
      "epoch 8; iter: 400; batch classifier loss: 0.421645; batch adversarial loss: 0.628660\n",
      "epoch 9; iter: 0; batch classifier loss: 0.287695; batch adversarial loss: 0.628627\n",
      "epoch 9; iter: 200; batch classifier loss: 0.332891; batch adversarial loss: 0.537422\n",
      "epoch 9; iter: 400; batch classifier loss: 0.369441; batch adversarial loss: 0.643851\n",
      "epoch 10; iter: 0; batch classifier loss: 0.347567; batch adversarial loss: 0.660477\n",
      "epoch 10; iter: 200; batch classifier loss: 0.328583; batch adversarial loss: 0.566177\n",
      "epoch 10; iter: 400; batch classifier loss: 0.339388; batch adversarial loss: 0.613926\n",
      "epoch 11; iter: 0; batch classifier loss: 0.504944; batch adversarial loss: 0.634836\n",
      "epoch 11; iter: 200; batch classifier loss: 0.319689; batch adversarial loss: 0.661365\n",
      "epoch 11; iter: 400; batch classifier loss: 0.266509; batch adversarial loss: 0.634728\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377644; batch adversarial loss: 0.619498\n",
      "epoch 12; iter: 200; batch classifier loss: 0.347424; batch adversarial loss: 0.659348\n",
      "epoch 12; iter: 400; batch classifier loss: 0.222113; batch adversarial loss: 0.658924\n",
      "epoch 13; iter: 0; batch classifier loss: 0.297935; batch adversarial loss: 0.641833\n",
      "epoch 13; iter: 200; batch classifier loss: 0.358560; batch adversarial loss: 0.625913\n",
      "epoch 13; iter: 400; batch classifier loss: 0.411918; batch adversarial loss: 0.705290\n",
      "epoch 14; iter: 0; batch classifier loss: 0.443277; batch adversarial loss: 0.636460\n",
      "epoch 14; iter: 200; batch classifier loss: 0.393383; batch adversarial loss: 0.578285\n",
      "epoch 14; iter: 400; batch classifier loss: 0.388842; batch adversarial loss: 0.596409\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266000; batch adversarial loss: 0.626304\n",
      "epoch 15; iter: 200; batch classifier loss: 0.370045; batch adversarial loss: 0.683334\n",
      "epoch 15; iter: 400; batch classifier loss: 0.531166; batch adversarial loss: 0.584406\n",
      "epoch 16; iter: 0; batch classifier loss: 0.308289; batch adversarial loss: 0.561355\n",
      "epoch 16; iter: 200; batch classifier loss: 0.666207; batch adversarial loss: 0.633428\n",
      "epoch 16; iter: 400; batch classifier loss: 0.268137; batch adversarial loss: 0.601340\n",
      "epoch 17; iter: 0; batch classifier loss: 0.360468; batch adversarial loss: 0.681507\n",
      "epoch 17; iter: 200; batch classifier loss: 0.439539; batch adversarial loss: 0.648207\n",
      "epoch 17; iter: 400; batch classifier loss: 0.411552; batch adversarial loss: 0.592216\n",
      "epoch 18; iter: 0; batch classifier loss: 0.276105; batch adversarial loss: 0.593091\n",
      "epoch 18; iter: 200; batch classifier loss: 0.414543; batch adversarial loss: 0.619838\n",
      "epoch 18; iter: 400; batch classifier loss: 0.323689; batch adversarial loss: 0.576784\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430403; batch adversarial loss: 0.650644\n",
      "epoch 19; iter: 200; batch classifier loss: 0.407074; batch adversarial loss: 0.603357\n",
      "epoch 19; iter: 400; batch classifier loss: 0.278298; batch adversarial loss: 0.665342\n",
      "epoch 0; iter: 0; batch classifier loss: 10.346565; batch adversarial loss: 0.738098\n",
      "epoch 0; iter: 200; batch classifier loss: 7.457172; batch adversarial loss: 0.624284\n",
      "epoch 0; iter: 400; batch classifier loss: 2.970145; batch adversarial loss: 0.697127\n",
      "epoch 1; iter: 0; batch classifier loss: 2.577810; batch adversarial loss: 0.628079\n",
      "epoch 1; iter: 200; batch classifier loss: 2.843384; batch adversarial loss: 0.594878\n",
      "epoch 1; iter: 400; batch classifier loss: 5.496121; batch adversarial loss: 0.606107\n",
      "epoch 2; iter: 0; batch classifier loss: 2.140549; batch adversarial loss: 0.620185\n",
      "epoch 2; iter: 200; batch classifier loss: 3.170867; batch adversarial loss: 0.609871\n",
      "epoch 2; iter: 400; batch classifier loss: 0.427293; batch adversarial loss: 0.634778\n",
      "epoch 3; iter: 0; batch classifier loss: 0.377697; batch adversarial loss: 0.663719\n",
      "epoch 3; iter: 200; batch classifier loss: 0.652071; batch adversarial loss: 0.540869\n",
      "epoch 3; iter: 400; batch classifier loss: 0.544901; batch adversarial loss: 0.615429\n",
      "epoch 4; iter: 0; batch classifier loss: 1.174500; batch adversarial loss: 0.598925\n",
      "epoch 4; iter: 200; batch classifier loss: 1.043126; batch adversarial loss: 0.623538\n",
      "epoch 4; iter: 400; batch classifier loss: 1.278746; batch adversarial loss: 0.573866\n",
      "epoch 5; iter: 0; batch classifier loss: 0.445681; batch adversarial loss: 0.695363\n",
      "epoch 5; iter: 200; batch classifier loss: 0.894474; batch adversarial loss: 0.614228\n",
      "epoch 5; iter: 400; batch classifier loss: 0.344573; batch adversarial loss: 0.638114\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322077; batch adversarial loss: 0.555728\n",
      "epoch 6; iter: 200; batch classifier loss: 0.448667; batch adversarial loss: 0.556077\n",
      "epoch 6; iter: 400; batch classifier loss: 0.484772; batch adversarial loss: 0.596155\n",
      "epoch 7; iter: 0; batch classifier loss: 0.652506; batch adversarial loss: 0.527262\n",
      "epoch 7; iter: 200; batch classifier loss: 0.488474; batch adversarial loss: 0.549867\n",
      "epoch 7; iter: 400; batch classifier loss: 0.460276; batch adversarial loss: 0.559803\n",
      "epoch 8; iter: 0; batch classifier loss: 0.407037; batch adversarial loss: 0.748112\n",
      "epoch 8; iter: 200; batch classifier loss: 0.548095; batch adversarial loss: 0.586414\n",
      "epoch 8; iter: 400; batch classifier loss: 0.325228; batch adversarial loss: 0.664676\n",
      "epoch 9; iter: 0; batch classifier loss: 0.413141; batch adversarial loss: 0.703536\n",
      "epoch 9; iter: 200; batch classifier loss: 0.379287; batch adversarial loss: 0.667145\n",
      "epoch 9; iter: 400; batch classifier loss: 0.419883; batch adversarial loss: 0.638187\n",
      "epoch 10; iter: 0; batch classifier loss: 1.217984; batch adversarial loss: 0.645531\n",
      "epoch 10; iter: 200; batch classifier loss: 0.472266; batch adversarial loss: 0.582892\n",
      "epoch 10; iter: 400; batch classifier loss: 0.337872; batch adversarial loss: 0.575738\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267196; batch adversarial loss: 0.591472\n",
      "epoch 11; iter: 200; batch classifier loss: 0.347915; batch adversarial loss: 0.611485\n",
      "epoch 11; iter: 400; batch classifier loss: 0.249236; batch adversarial loss: 0.722200\n",
      "epoch 12; iter: 0; batch classifier loss: 0.246076; batch adversarial loss: 0.621553\n",
      "epoch 12; iter: 200; batch classifier loss: 0.356011; batch adversarial loss: 0.590580\n",
      "epoch 12; iter: 400; batch classifier loss: 0.397050; batch adversarial loss: 0.560294\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384496; batch adversarial loss: 0.623725\n",
      "epoch 13; iter: 200; batch classifier loss: 0.318907; batch adversarial loss: 0.712626\n",
      "epoch 13; iter: 400; batch classifier loss: 0.389458; batch adversarial loss: 0.674986\n",
      "epoch 14; iter: 0; batch classifier loss: 0.245882; batch adversarial loss: 0.600546\n",
      "epoch 14; iter: 200; batch classifier loss: 0.773412; batch adversarial loss: 0.630060\n",
      "epoch 14; iter: 400; batch classifier loss: 0.373924; batch adversarial loss: 0.635398\n",
      "epoch 15; iter: 0; batch classifier loss: 0.369626; batch adversarial loss: 0.576315\n",
      "epoch 15; iter: 200; batch classifier loss: 0.339115; batch adversarial loss: 0.597864\n",
      "epoch 15; iter: 400; batch classifier loss: 0.271466; batch adversarial loss: 0.642850\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419210; batch adversarial loss: 0.664208\n",
      "epoch 16; iter: 200; batch classifier loss: 0.307002; batch adversarial loss: 0.602701\n",
      "epoch 16; iter: 400; batch classifier loss: 0.603043; batch adversarial loss: 0.578894\n",
      "epoch 17; iter: 0; batch classifier loss: 0.483400; batch adversarial loss: 0.559286\n",
      "epoch 17; iter: 200; batch classifier loss: 0.323835; batch adversarial loss: 0.586956\n",
      "epoch 17; iter: 400; batch classifier loss: 0.290605; batch adversarial loss: 0.649246\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463657; batch adversarial loss: 0.626083\n",
      "epoch 18; iter: 200; batch classifier loss: 0.417223; batch adversarial loss: 0.625193\n",
      "epoch 18; iter: 400; batch classifier loss: 0.349665; batch adversarial loss: 0.619916\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337958; batch adversarial loss: 0.654519\n",
      "epoch 19; iter: 200; batch classifier loss: 0.233593; batch adversarial loss: 0.667009\n",
      "epoch 19; iter: 400; batch classifier loss: 0.423780; batch adversarial loss: 0.665171\n",
      "epoch 0; iter: 0; batch classifier loss: 3.804784; batch adversarial loss: 0.790066\n",
      "epoch 0; iter: 200; batch classifier loss: 2.108787; batch adversarial loss: 0.662571\n",
      "epoch 0; iter: 400; batch classifier loss: 4.116683; batch adversarial loss: 0.638260\n",
      "epoch 1; iter: 0; batch classifier loss: 8.551120; batch adversarial loss: 0.659845\n",
      "epoch 1; iter: 200; batch classifier loss: 1.134203; batch adversarial loss: 0.646349\n",
      "epoch 1; iter: 400; batch classifier loss: 1.086690; batch adversarial loss: 0.610374\n",
      "epoch 2; iter: 0; batch classifier loss: 7.177503; batch adversarial loss: 0.659078\n",
      "epoch 2; iter: 200; batch classifier loss: 1.310329; batch adversarial loss: 0.683682\n",
      "epoch 2; iter: 400; batch classifier loss: 2.238680; batch adversarial loss: 0.644145\n",
      "epoch 3; iter: 0; batch classifier loss: 1.873188; batch adversarial loss: 0.689174\n",
      "epoch 3; iter: 200; batch classifier loss: 0.625781; batch adversarial loss: 0.674699\n",
      "epoch 3; iter: 400; batch classifier loss: 1.571322; batch adversarial loss: 0.554123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.430420; batch adversarial loss: 0.596871\n",
      "epoch 4; iter: 200; batch classifier loss: 1.236587; batch adversarial loss: 0.613766\n",
      "epoch 4; iter: 400; batch classifier loss: 0.427522; batch adversarial loss: 0.640144\n",
      "epoch 5; iter: 0; batch classifier loss: 2.336169; batch adversarial loss: 0.625780\n",
      "epoch 5; iter: 200; batch classifier loss: 2.303414; batch adversarial loss: 0.652826\n",
      "epoch 5; iter: 400; batch classifier loss: 0.430592; batch adversarial loss: 0.655717\n",
      "epoch 6; iter: 0; batch classifier loss: 0.944584; batch adversarial loss: 0.656323\n",
      "epoch 6; iter: 200; batch classifier loss: 0.416775; batch adversarial loss: 0.610787\n",
      "epoch 6; iter: 400; batch classifier loss: 0.425487; batch adversarial loss: 0.686950\n",
      "epoch 7; iter: 0; batch classifier loss: 0.926872; batch adversarial loss: 0.609613\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416250; batch adversarial loss: 0.660205\n",
      "epoch 7; iter: 400; batch classifier loss: 0.441366; batch adversarial loss: 0.686567\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562959; batch adversarial loss: 0.666507\n",
      "epoch 8; iter: 200; batch classifier loss: 0.262173; batch adversarial loss: 0.575744\n",
      "epoch 8; iter: 400; batch classifier loss: 0.639898; batch adversarial loss: 0.589216\n",
      "epoch 9; iter: 0; batch classifier loss: 0.588134; batch adversarial loss: 0.612258\n",
      "epoch 9; iter: 200; batch classifier loss: 0.380520; batch adversarial loss: 0.552522\n",
      "epoch 9; iter: 400; batch classifier loss: 0.391316; batch adversarial loss: 0.672558\n",
      "epoch 10; iter: 0; batch classifier loss: 0.456214; batch adversarial loss: 0.626256\n",
      "epoch 10; iter: 200; batch classifier loss: 0.301230; batch adversarial loss: 0.636893\n",
      "epoch 10; iter: 400; batch classifier loss: 0.287316; batch adversarial loss: 0.606530\n",
      "epoch 11; iter: 0; batch classifier loss: 0.449758; batch adversarial loss: 0.622051\n",
      "epoch 11; iter: 200; batch classifier loss: 0.317899; batch adversarial loss: 0.631906\n",
      "epoch 11; iter: 400; batch classifier loss: 0.666148; batch adversarial loss: 0.653920\n",
      "epoch 12; iter: 0; batch classifier loss: 0.381740; batch adversarial loss: 0.650693\n",
      "epoch 12; iter: 200; batch classifier loss: 0.481077; batch adversarial loss: 0.597793\n",
      "epoch 12; iter: 400; batch classifier loss: 0.409695; batch adversarial loss: 0.598771\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295744; batch adversarial loss: 0.709446\n",
      "epoch 13; iter: 200; batch classifier loss: 0.283819; batch adversarial loss: 0.600967\n",
      "epoch 13; iter: 400; batch classifier loss: 0.321475; batch adversarial loss: 0.637368\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431729; batch adversarial loss: 0.589999\n",
      "epoch 14; iter: 200; batch classifier loss: 0.265291; batch adversarial loss: 0.608874\n",
      "epoch 14; iter: 400; batch classifier loss: 0.489384; batch adversarial loss: 0.576032\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440657; batch adversarial loss: 0.576458\n",
      "epoch 15; iter: 200; batch classifier loss: 0.384374; batch adversarial loss: 0.599835\n",
      "epoch 15; iter: 400; batch classifier loss: 0.285523; batch adversarial loss: 0.610984\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260314; batch adversarial loss: 0.667166\n",
      "epoch 16; iter: 200; batch classifier loss: 0.270515; batch adversarial loss: 0.617263\n",
      "epoch 16; iter: 400; batch classifier loss: 0.389696; batch adversarial loss: 0.647667\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409678; batch adversarial loss: 0.605199\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381553; batch adversarial loss: 0.606724\n",
      "epoch 17; iter: 400; batch classifier loss: 0.547044; batch adversarial loss: 0.687761\n",
      "epoch 18; iter: 0; batch classifier loss: 0.256820; batch adversarial loss: 0.642845\n",
      "epoch 18; iter: 200; batch classifier loss: 0.269047; batch adversarial loss: 0.604102\n",
      "epoch 18; iter: 400; batch classifier loss: 0.427777; batch adversarial loss: 0.577564\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287347; batch adversarial loss: 0.633814\n",
      "epoch 19; iter: 200; batch classifier loss: 0.251202; batch adversarial loss: 0.601186\n",
      "epoch 19; iter: 400; batch classifier loss: 0.259841; batch adversarial loss: 0.683684\n",
      "epoch 0; iter: 0; batch classifier loss: 20.278030; batch adversarial loss: 0.661117\n",
      "epoch 0; iter: 200; batch classifier loss: 7.477262; batch adversarial loss: 0.665434\n",
      "epoch 0; iter: 400; batch classifier loss: 4.596374; batch adversarial loss: 0.589869\n",
      "epoch 1; iter: 0; batch classifier loss: 1.460280; batch adversarial loss: 0.620670\n",
      "epoch 1; iter: 200; batch classifier loss: 6.068130; batch adversarial loss: 0.600296\n",
      "epoch 1; iter: 400; batch classifier loss: 2.699371; batch adversarial loss: 0.541373\n",
      "epoch 2; iter: 0; batch classifier loss: 1.918372; batch adversarial loss: 0.540611\n",
      "epoch 2; iter: 200; batch classifier loss: 1.394173; batch adversarial loss: 0.690184\n",
      "epoch 2; iter: 400; batch classifier loss: 2.836775; batch adversarial loss: 0.652837\n",
      "epoch 3; iter: 0; batch classifier loss: 1.196286; batch adversarial loss: 0.667635\n",
      "epoch 3; iter: 200; batch classifier loss: 0.577173; batch adversarial loss: 0.622401\n",
      "epoch 3; iter: 400; batch classifier loss: 0.535339; batch adversarial loss: 0.567133\n",
      "epoch 4; iter: 0; batch classifier loss: 1.192661; batch adversarial loss: 0.593745\n",
      "epoch 4; iter: 200; batch classifier loss: 0.443696; batch adversarial loss: 0.659955\n",
      "epoch 4; iter: 400; batch classifier loss: 0.322326; batch adversarial loss: 0.691433\n",
      "epoch 5; iter: 0; batch classifier loss: 0.853136; batch adversarial loss: 0.658860\n",
      "epoch 5; iter: 200; batch classifier loss: 0.780298; batch adversarial loss: 0.639551\n",
      "epoch 5; iter: 400; batch classifier loss: 0.717066; batch adversarial loss: 0.651751\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335643; batch adversarial loss: 0.575477\n",
      "epoch 6; iter: 200; batch classifier loss: 0.593494; batch adversarial loss: 0.728584\n",
      "epoch 6; iter: 400; batch classifier loss: 0.342660; batch adversarial loss: 0.604237\n",
      "epoch 7; iter: 0; batch classifier loss: 0.264079; batch adversarial loss: 0.670772\n",
      "epoch 7; iter: 200; batch classifier loss: 0.564306; batch adversarial loss: 0.572547\n",
      "epoch 7; iter: 400; batch classifier loss: 0.479439; batch adversarial loss: 0.545197\n",
      "epoch 8; iter: 0; batch classifier loss: 0.376955; batch adversarial loss: 0.657595\n",
      "epoch 8; iter: 200; batch classifier loss: 0.724970; batch adversarial loss: 0.613162\n",
      "epoch 8; iter: 400; batch classifier loss: 0.762485; batch adversarial loss: 0.576271\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529775; batch adversarial loss: 0.641694\n",
      "epoch 9; iter: 200; batch classifier loss: 0.541877; batch adversarial loss: 0.543705\n",
      "epoch 9; iter: 400; batch classifier loss: 0.490481; batch adversarial loss: 0.649695\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426185; batch adversarial loss: 0.649482\n",
      "epoch 10; iter: 200; batch classifier loss: 0.369168; batch adversarial loss: 0.622906\n",
      "epoch 10; iter: 400; batch classifier loss: 0.298165; batch adversarial loss: 0.591375\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371141; batch adversarial loss: 0.565215\n",
      "epoch 11; iter: 200; batch classifier loss: 0.471335; batch adversarial loss: 0.667263\n",
      "epoch 11; iter: 400; batch classifier loss: 0.474251; batch adversarial loss: 0.676197\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357825; batch adversarial loss: 0.614697\n",
      "epoch 12; iter: 200; batch classifier loss: 0.386980; batch adversarial loss: 0.626639\n",
      "epoch 12; iter: 400; batch classifier loss: 0.413891; batch adversarial loss: 0.684502\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553835; batch adversarial loss: 0.607787\n",
      "epoch 13; iter: 200; batch classifier loss: 0.468007; batch adversarial loss: 0.623166\n",
      "epoch 13; iter: 400; batch classifier loss: 0.360292; batch adversarial loss: 0.613273\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456238; batch adversarial loss: 0.586158\n",
      "epoch 14; iter: 200; batch classifier loss: 0.361493; batch adversarial loss: 0.630536\n",
      "epoch 14; iter: 400; batch classifier loss: 0.489602; batch adversarial loss: 0.601185\n",
      "epoch 15; iter: 0; batch classifier loss: 0.251691; batch adversarial loss: 0.667705\n",
      "epoch 15; iter: 200; batch classifier loss: 0.301969; batch adversarial loss: 0.645240\n",
      "epoch 15; iter: 400; batch classifier loss: 0.390746; batch adversarial loss: 0.610792\n",
      "epoch 16; iter: 0; batch classifier loss: 0.417476; batch adversarial loss: 0.630013\n",
      "epoch 16; iter: 200; batch classifier loss: 0.444753; batch adversarial loss: 0.665169\n",
      "epoch 16; iter: 400; batch classifier loss: 0.473676; batch adversarial loss: 0.687547\n",
      "epoch 17; iter: 0; batch classifier loss: 0.267373; batch adversarial loss: 0.607158\n",
      "epoch 17; iter: 200; batch classifier loss: 0.333366; batch adversarial loss: 0.684667\n",
      "epoch 17; iter: 400; batch classifier loss: 0.384456; batch adversarial loss: 0.678455\n",
      "epoch 18; iter: 0; batch classifier loss: 0.494487; batch adversarial loss: 0.649228\n",
      "epoch 18; iter: 200; batch classifier loss: 0.238761; batch adversarial loss: 0.667008\n",
      "epoch 18; iter: 400; batch classifier loss: 0.486192; batch adversarial loss: 0.550110\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206732; batch adversarial loss: 0.534815\n",
      "epoch 19; iter: 200; batch classifier loss: 0.538219; batch adversarial loss: 0.692714\n",
      "epoch 19; iter: 400; batch classifier loss: 0.382621; batch adversarial loss: 0.633441\n",
      "epoch 0; iter: 0; batch classifier loss: 23.130051; batch adversarial loss: 0.749126\n",
      "epoch 0; iter: 200; batch classifier loss: 19.729572; batch adversarial loss: 0.684279\n",
      "epoch 0; iter: 400; batch classifier loss: 4.591872; batch adversarial loss: 0.609110\n",
      "epoch 1; iter: 0; batch classifier loss: 9.803745; batch adversarial loss: 0.637237\n",
      "epoch 1; iter: 200; batch classifier loss: 3.950287; batch adversarial loss: 0.642792\n",
      "epoch 1; iter: 400; batch classifier loss: 1.311271; batch adversarial loss: 0.602871\n",
      "epoch 2; iter: 0; batch classifier loss: 0.954624; batch adversarial loss: 0.667453\n",
      "epoch 2; iter: 200; batch classifier loss: 2.174551; batch adversarial loss: 0.644083\n",
      "epoch 2; iter: 400; batch classifier loss: 2.091547; batch adversarial loss: 0.602895\n",
      "epoch 3; iter: 0; batch classifier loss: 3.302814; batch adversarial loss: 0.629191\n",
      "epoch 3; iter: 200; batch classifier loss: 1.042752; batch adversarial loss: 0.598254\n",
      "epoch 3; iter: 400; batch classifier loss: 1.522469; batch adversarial loss: 0.630548\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513541; batch adversarial loss: 0.655702\n",
      "epoch 4; iter: 200; batch classifier loss: 0.568569; batch adversarial loss: 0.569132\n",
      "epoch 4; iter: 400; batch classifier loss: 0.278056; batch adversarial loss: 0.690184\n",
      "epoch 5; iter: 0; batch classifier loss: 0.304973; batch adversarial loss: 0.652367\n",
      "epoch 5; iter: 200; batch classifier loss: 0.543396; batch adversarial loss: 0.649006\n",
      "epoch 5; iter: 400; batch classifier loss: 0.318388; batch adversarial loss: 0.600148\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502235; batch adversarial loss: 0.647778\n",
      "epoch 6; iter: 200; batch classifier loss: 0.357706; batch adversarial loss: 0.636532\n",
      "epoch 6; iter: 400; batch classifier loss: 0.547897; batch adversarial loss: 0.644185\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595684; batch adversarial loss: 0.570496\n",
      "epoch 7; iter: 200; batch classifier loss: 0.604012; batch adversarial loss: 0.598989\n",
      "epoch 7; iter: 400; batch classifier loss: 0.565389; batch adversarial loss: 0.649922\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417237; batch adversarial loss: 0.694588\n",
      "epoch 8; iter: 200; batch classifier loss: 0.627642; batch adversarial loss: 0.632304\n",
      "epoch 8; iter: 400; batch classifier loss: 0.690251; batch adversarial loss: 0.595796\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539096; batch adversarial loss: 0.574867\n",
      "epoch 9; iter: 200; batch classifier loss: 0.588139; batch adversarial loss: 0.711143\n",
      "epoch 9; iter: 400; batch classifier loss: 0.572439; batch adversarial loss: 0.691126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346814; batch adversarial loss: 0.576570\n",
      "epoch 10; iter: 200; batch classifier loss: 0.378437; batch adversarial loss: 0.643254\n",
      "epoch 10; iter: 400; batch classifier loss: 0.405941; batch adversarial loss: 0.641918\n",
      "epoch 11; iter: 0; batch classifier loss: 0.248521; batch adversarial loss: 0.609455\n",
      "epoch 11; iter: 200; batch classifier loss: 0.820353; batch adversarial loss: 0.618148\n",
      "epoch 11; iter: 400; batch classifier loss: 0.350560; batch adversarial loss: 0.584097\n",
      "epoch 12; iter: 0; batch classifier loss: 0.442808; batch adversarial loss: 0.641014\n",
      "epoch 12; iter: 200; batch classifier loss: 0.318688; batch adversarial loss: 0.603486\n",
      "epoch 12; iter: 400; batch classifier loss: 0.327644; batch adversarial loss: 0.676590\n",
      "epoch 13; iter: 0; batch classifier loss: 0.387520; batch adversarial loss: 0.721132\n",
      "epoch 13; iter: 200; batch classifier loss: 0.381179; batch adversarial loss: 0.579061\n",
      "epoch 13; iter: 400; batch classifier loss: 0.335947; batch adversarial loss: 0.706820\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330632; batch adversarial loss: 0.650721\n",
      "epoch 14; iter: 200; batch classifier loss: 0.533080; batch adversarial loss: 0.608396\n",
      "epoch 14; iter: 400; batch classifier loss: 0.382118; batch adversarial loss: 0.671022\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358323; batch adversarial loss: 0.729173\n",
      "epoch 15; iter: 200; batch classifier loss: 0.452229; batch adversarial loss: 0.600421\n",
      "epoch 15; iter: 400; batch classifier loss: 0.370873; batch adversarial loss: 0.688832\n",
      "epoch 16; iter: 0; batch classifier loss: 0.325566; batch adversarial loss: 0.681756\n",
      "epoch 16; iter: 200; batch classifier loss: 0.472132; batch adversarial loss: 0.592549\n",
      "epoch 16; iter: 400; batch classifier loss: 0.391426; batch adversarial loss: 0.645247\n",
      "epoch 17; iter: 0; batch classifier loss: 0.431925; batch adversarial loss: 0.589983\n",
      "epoch 17; iter: 200; batch classifier loss: 0.287467; batch adversarial loss: 0.597656\n",
      "epoch 17; iter: 400; batch classifier loss: 0.291895; batch adversarial loss: 0.499914\n",
      "epoch 18; iter: 0; batch classifier loss: 0.381250; batch adversarial loss: 0.693429\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341498; batch adversarial loss: 0.530432\n",
      "epoch 18; iter: 400; batch classifier loss: 0.509845; batch adversarial loss: 0.531253\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334897; batch adversarial loss: 0.674608\n",
      "epoch 19; iter: 200; batch classifier loss: 0.460276; batch adversarial loss: 0.601892\n",
      "epoch 19; iter: 400; batch classifier loss: 0.338049; batch adversarial loss: 0.581817\n",
      "epoch 0; iter: 0; batch classifier loss: 27.220411; batch adversarial loss: 0.677705\n",
      "epoch 0; iter: 200; batch classifier loss: 2.510161; batch adversarial loss: 0.663372\n",
      "epoch 0; iter: 400; batch classifier loss: 6.591297; batch adversarial loss: 0.710241\n",
      "epoch 1; iter: 0; batch classifier loss: 2.705419; batch adversarial loss: 0.605235\n",
      "epoch 1; iter: 200; batch classifier loss: 5.729372; batch adversarial loss: 0.626587\n",
      "epoch 1; iter: 400; batch classifier loss: 0.459064; batch adversarial loss: 0.640662\n",
      "epoch 2; iter: 0; batch classifier loss: 1.153450; batch adversarial loss: 0.533624\n",
      "epoch 2; iter: 200; batch classifier loss: 3.403423; batch adversarial loss: 0.599159\n",
      "epoch 2; iter: 400; batch classifier loss: 0.770777; batch adversarial loss: 0.521765\n",
      "epoch 3; iter: 0; batch classifier loss: 1.701584; batch adversarial loss: 0.634989\n",
      "epoch 3; iter: 200; batch classifier loss: 0.474112; batch adversarial loss: 0.538015\n",
      "epoch 3; iter: 400; batch classifier loss: 0.346684; batch adversarial loss: 0.574317\n",
      "epoch 4; iter: 0; batch classifier loss: 1.720092; batch adversarial loss: 0.582786\n",
      "epoch 4; iter: 200; batch classifier loss: 0.542578; batch adversarial loss: 0.609469\n",
      "epoch 4; iter: 400; batch classifier loss: 0.516742; batch adversarial loss: 0.639920\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587444; batch adversarial loss: 0.605213\n",
      "epoch 5; iter: 200; batch classifier loss: 0.354646; batch adversarial loss: 0.653880\n",
      "epoch 5; iter: 400; batch classifier loss: 0.470119; batch adversarial loss: 0.644440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357223; batch adversarial loss: 0.682326\n",
      "epoch 6; iter: 200; batch classifier loss: 0.318344; batch adversarial loss: 0.699756\n",
      "epoch 6; iter: 400; batch classifier loss: 0.543963; batch adversarial loss: 0.636762\n",
      "epoch 7; iter: 0; batch classifier loss: 0.425935; batch adversarial loss: 0.662350\n",
      "epoch 7; iter: 200; batch classifier loss: 0.456545; batch adversarial loss: 0.632227\n",
      "epoch 7; iter: 400; batch classifier loss: 0.430215; batch adversarial loss: 0.618969\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466590; batch adversarial loss: 0.619539\n",
      "epoch 8; iter: 200; batch classifier loss: 0.426037; batch adversarial loss: 0.619750\n",
      "epoch 8; iter: 400; batch classifier loss: 0.523749; batch adversarial loss: 0.611756\n",
      "epoch 9; iter: 0; batch classifier loss: 0.425508; batch adversarial loss: 0.581962\n",
      "epoch 9; iter: 200; batch classifier loss: 0.546491; batch adversarial loss: 0.559287\n",
      "epoch 9; iter: 400; batch classifier loss: 0.379148; batch adversarial loss: 0.586415\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297065; batch adversarial loss: 0.635037\n",
      "epoch 10; iter: 200; batch classifier loss: 0.338080; batch adversarial loss: 0.665285\n",
      "epoch 10; iter: 400; batch classifier loss: 0.373492; batch adversarial loss: 0.659810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592251; batch adversarial loss: 0.569662\n",
      "epoch 11; iter: 200; batch classifier loss: 0.514696; batch adversarial loss: 0.609894\n",
      "epoch 11; iter: 400; batch classifier loss: 0.363129; batch adversarial loss: 0.664731\n",
      "epoch 12; iter: 0; batch classifier loss: 0.607474; batch adversarial loss: 0.569487\n",
      "epoch 12; iter: 200; batch classifier loss: 0.398913; batch adversarial loss: 0.642499\n",
      "epoch 12; iter: 400; batch classifier loss: 0.296350; batch adversarial loss: 0.642025\n",
      "epoch 13; iter: 0; batch classifier loss: 0.248656; batch adversarial loss: 0.531318\n",
      "epoch 13; iter: 200; batch classifier loss: 0.386454; batch adversarial loss: 0.642568\n",
      "epoch 13; iter: 400; batch classifier loss: 0.323314; batch adversarial loss: 0.698538\n",
      "epoch 14; iter: 0; batch classifier loss: 0.210000; batch adversarial loss: 0.642730\n",
      "epoch 14; iter: 200; batch classifier loss: 0.167371; batch adversarial loss: 0.605071\n",
      "epoch 14; iter: 400; batch classifier loss: 0.335988; batch adversarial loss: 0.591095\n",
      "epoch 15; iter: 0; batch classifier loss: 0.327067; batch adversarial loss: 0.664309\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341846; batch adversarial loss: 0.637504\n",
      "epoch 15; iter: 400; batch classifier loss: 0.385910; batch adversarial loss: 0.685156\n",
      "epoch 16; iter: 0; batch classifier loss: 0.328750; batch adversarial loss: 0.645234\n",
      "epoch 16; iter: 200; batch classifier loss: 0.390862; batch adversarial loss: 0.616696\n",
      "epoch 16; iter: 400; batch classifier loss: 0.356697; batch adversarial loss: 0.642282\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347646; batch adversarial loss: 0.601569\n",
      "epoch 17; iter: 200; batch classifier loss: 0.394951; batch adversarial loss: 0.614514\n",
      "epoch 17; iter: 400; batch classifier loss: 0.409644; batch adversarial loss: 0.541145\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419494; batch adversarial loss: 0.577157\n",
      "epoch 18; iter: 200; batch classifier loss: 0.383028; batch adversarial loss: 0.621644\n",
      "epoch 18; iter: 400; batch classifier loss: 0.400185; batch adversarial loss: 0.656621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487294; batch adversarial loss: 0.573314\n",
      "epoch 19; iter: 200; batch classifier loss: 0.417372; batch adversarial loss: 0.663279\n",
      "epoch 19; iter: 400; batch classifier loss: 0.446882; batch adversarial loss: 0.552456\n",
      "epoch 0; iter: 0; batch classifier loss: 40.825653; batch adversarial loss: 0.695059\n",
      "epoch 0; iter: 200; batch classifier loss: 6.618874; batch adversarial loss: 0.636085\n",
      "epoch 0; iter: 400; batch classifier loss: 0.960125; batch adversarial loss: 0.649011\n",
      "epoch 1; iter: 0; batch classifier loss: 2.808936; batch adversarial loss: 0.597771\n",
      "epoch 1; iter: 200; batch classifier loss: 9.328909; batch adversarial loss: 0.627873\n",
      "epoch 1; iter: 400; batch classifier loss: 0.482029; batch adversarial loss: 0.577007\n",
      "epoch 2; iter: 0; batch classifier loss: 3.049782; batch adversarial loss: 0.597849\n",
      "epoch 2; iter: 200; batch classifier loss: 5.317318; batch adversarial loss: 0.582753\n",
      "epoch 2; iter: 400; batch classifier loss: 2.753434; batch adversarial loss: 0.550010\n",
      "epoch 3; iter: 0; batch classifier loss: 3.512345; batch adversarial loss: 0.593241\n",
      "epoch 3; iter: 200; batch classifier loss: 0.571455; batch adversarial loss: 0.562267\n",
      "epoch 3; iter: 400; batch classifier loss: 0.460382; batch adversarial loss: 0.632850\n",
      "epoch 4; iter: 0; batch classifier loss: 0.906823; batch adversarial loss: 0.528831\n",
      "epoch 4; iter: 200; batch classifier loss: 1.666839; batch adversarial loss: 0.678373\n",
      "epoch 4; iter: 400; batch classifier loss: 0.502607; batch adversarial loss: 0.580982\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562685; batch adversarial loss: 0.676701\n",
      "epoch 5; iter: 200; batch classifier loss: 0.287488; batch adversarial loss: 0.631375\n",
      "epoch 5; iter: 400; batch classifier loss: 0.629487; batch adversarial loss: 0.661233\n",
      "epoch 6; iter: 0; batch classifier loss: 0.315672; batch adversarial loss: 0.692449\n",
      "epoch 6; iter: 200; batch classifier loss: 0.439183; batch adversarial loss: 0.588153\n",
      "epoch 6; iter: 400; batch classifier loss: 0.330376; batch adversarial loss: 0.610732\n",
      "epoch 7; iter: 0; batch classifier loss: 0.313294; batch adversarial loss: 0.668639\n",
      "epoch 7; iter: 200; batch classifier loss: 0.281216; batch adversarial loss: 0.671020\n",
      "epoch 7; iter: 400; batch classifier loss: 0.610295; batch adversarial loss: 0.579227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.469625; batch adversarial loss: 0.598951\n",
      "epoch 8; iter: 200; batch classifier loss: 0.355560; batch adversarial loss: 0.672002\n",
      "epoch 8; iter: 400; batch classifier loss: 0.314035; batch adversarial loss: 0.662694\n",
      "epoch 9; iter: 0; batch classifier loss: 0.334441; batch adversarial loss: 0.607328\n",
      "epoch 9; iter: 200; batch classifier loss: 0.367402; batch adversarial loss: 0.664961\n",
      "epoch 9; iter: 400; batch classifier loss: 0.384240; batch adversarial loss: 0.623053\n",
      "epoch 10; iter: 0; batch classifier loss: 0.221741; batch adversarial loss: 0.596240\n",
      "epoch 10; iter: 200; batch classifier loss: 0.293739; batch adversarial loss: 0.635151\n",
      "epoch 10; iter: 400; batch classifier loss: 0.588846; batch adversarial loss: 0.617229\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291724; batch adversarial loss: 0.596492\n",
      "epoch 11; iter: 200; batch classifier loss: 0.210173; batch adversarial loss: 0.674211\n",
      "epoch 11; iter: 400; batch classifier loss: 0.461246; batch adversarial loss: 0.620572\n",
      "epoch 12; iter: 0; batch classifier loss: 0.271755; batch adversarial loss: 0.618486\n",
      "epoch 12; iter: 200; batch classifier loss: 0.207170; batch adversarial loss: 0.623614\n",
      "epoch 12; iter: 400; batch classifier loss: 0.575738; batch adversarial loss: 0.565118\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275290; batch adversarial loss: 0.613288\n",
      "epoch 13; iter: 200; batch classifier loss: 0.282509; batch adversarial loss: 0.652925\n",
      "epoch 13; iter: 400; batch classifier loss: 0.408635; batch adversarial loss: 0.616096\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367516; batch adversarial loss: 0.637593\n",
      "epoch 14; iter: 200; batch classifier loss: 0.399904; batch adversarial loss: 0.645178\n",
      "epoch 14; iter: 400; batch classifier loss: 0.474595; batch adversarial loss: 0.576262\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337009; batch adversarial loss: 0.689599\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380307; batch adversarial loss: 0.604331\n",
      "epoch 15; iter: 400; batch classifier loss: 0.392433; batch adversarial loss: 0.628116\n",
      "epoch 16; iter: 0; batch classifier loss: 0.446661; batch adversarial loss: 0.609628\n",
      "epoch 16; iter: 200; batch classifier loss: 0.389831; batch adversarial loss: 0.607941\n",
      "epoch 16; iter: 400; batch classifier loss: 0.468063; batch adversarial loss: 0.641646\n",
      "epoch 17; iter: 0; batch classifier loss: 0.222716; batch adversarial loss: 0.630745\n",
      "epoch 17; iter: 200; batch classifier loss: 0.405632; batch adversarial loss: 0.597224\n",
      "epoch 17; iter: 400; batch classifier loss: 0.391676; batch adversarial loss: 0.620048\n",
      "epoch 18; iter: 0; batch classifier loss: 0.365047; batch adversarial loss: 0.702911\n",
      "epoch 18; iter: 200; batch classifier loss: 0.195477; batch adversarial loss: 0.681549\n",
      "epoch 18; iter: 400; batch classifier loss: 0.377758; batch adversarial loss: 0.651431\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397584; batch adversarial loss: 0.577660\n",
      "epoch 19; iter: 200; batch classifier loss: 0.365221; batch adversarial loss: 0.658093\n",
      "epoch 19; iter: 400; batch classifier loss: 0.361560; batch adversarial loss: 0.657769\n",
      "epoch 0; iter: 0; batch classifier loss: 4.536173; batch adversarial loss: 0.685441\n",
      "epoch 0; iter: 200; batch classifier loss: 21.222912; batch adversarial loss: 0.695381\n",
      "epoch 0; iter: 400; batch classifier loss: 1.273335; batch adversarial loss: 0.628873\n",
      "epoch 1; iter: 0; batch classifier loss: 16.902992; batch adversarial loss: 0.616315\n",
      "epoch 1; iter: 200; batch classifier loss: 0.852982; batch adversarial loss: 0.583628\n",
      "epoch 1; iter: 400; batch classifier loss: 7.090655; batch adversarial loss: 0.570747\n",
      "epoch 2; iter: 0; batch classifier loss: 2.483422; batch adversarial loss: 0.553829\n",
      "epoch 2; iter: 200; batch classifier loss: 2.964715; batch adversarial loss: 0.652923\n",
      "epoch 2; iter: 400; batch classifier loss: 2.491538; batch adversarial loss: 0.568164\n",
      "epoch 3; iter: 0; batch classifier loss: 0.436763; batch adversarial loss: 0.635316\n",
      "epoch 3; iter: 200; batch classifier loss: 2.363639; batch adversarial loss: 0.683200\n",
      "epoch 3; iter: 400; batch classifier loss: 2.567352; batch adversarial loss: 0.660815\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537696; batch adversarial loss: 0.606461\n",
      "epoch 4; iter: 200; batch classifier loss: 0.874636; batch adversarial loss: 0.562792\n",
      "epoch 4; iter: 400; batch classifier loss: 0.309505; batch adversarial loss: 0.665858\n",
      "epoch 5; iter: 0; batch classifier loss: 0.315824; batch adversarial loss: 0.625895\n",
      "epoch 5; iter: 200; batch classifier loss: 0.420470; batch adversarial loss: 0.662351\n",
      "epoch 5; iter: 400; batch classifier loss: 0.345396; batch adversarial loss: 0.609965\n",
      "epoch 6; iter: 0; batch classifier loss: 0.270812; batch adversarial loss: 0.619040\n",
      "epoch 6; iter: 200; batch classifier loss: 1.322856; batch adversarial loss: 0.654009\n",
      "epoch 6; iter: 400; batch classifier loss: 0.510291; batch adversarial loss: 0.691708\n",
      "epoch 7; iter: 0; batch classifier loss: 0.699666; batch adversarial loss: 0.690270\n",
      "epoch 7; iter: 200; batch classifier loss: 0.749019; batch adversarial loss: 0.588308\n",
      "epoch 7; iter: 400; batch classifier loss: 0.449615; batch adversarial loss: 0.624518\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298530; batch adversarial loss: 0.633844\n",
      "epoch 8; iter: 200; batch classifier loss: 0.512363; batch adversarial loss: 0.580388\n",
      "epoch 8; iter: 400; batch classifier loss: 0.514683; batch adversarial loss: 0.654487\n",
      "epoch 9; iter: 0; batch classifier loss: 0.351452; batch adversarial loss: 0.504782\n",
      "epoch 9; iter: 200; batch classifier loss: 0.397546; batch adversarial loss: 0.571227\n",
      "epoch 9; iter: 400; batch classifier loss: 0.284168; batch adversarial loss: 0.664088\n",
      "epoch 10; iter: 0; batch classifier loss: 0.415604; batch adversarial loss: 0.629771\n",
      "epoch 10; iter: 200; batch classifier loss: 0.456011; batch adversarial loss: 0.593564\n",
      "epoch 10; iter: 400; batch classifier loss: 0.497974; batch adversarial loss: 0.608886\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490037; batch adversarial loss: 0.519174\n",
      "epoch 11; iter: 200; batch classifier loss: 0.545197; batch adversarial loss: 0.614265\n",
      "epoch 11; iter: 400; batch classifier loss: 0.376339; batch adversarial loss: 0.573343\n",
      "epoch 12; iter: 0; batch classifier loss: 0.573008; batch adversarial loss: 0.688904\n",
      "epoch 12; iter: 200; batch classifier loss: 0.370750; batch adversarial loss: 0.615267\n",
      "epoch 12; iter: 400; batch classifier loss: 0.303133; batch adversarial loss: 0.619250\n",
      "epoch 13; iter: 0; batch classifier loss: 0.640039; batch adversarial loss: 0.626700\n",
      "epoch 13; iter: 200; batch classifier loss: 0.270855; batch adversarial loss: 0.649995\n",
      "epoch 13; iter: 400; batch classifier loss: 0.478810; batch adversarial loss: 0.656125\n",
      "epoch 14; iter: 0; batch classifier loss: 0.388083; batch adversarial loss: 0.587273\n",
      "epoch 14; iter: 200; batch classifier loss: 0.409144; batch adversarial loss: 0.674889\n",
      "epoch 14; iter: 400; batch classifier loss: 0.297295; batch adversarial loss: 0.610406\n",
      "epoch 15; iter: 0; batch classifier loss: 0.294894; batch adversarial loss: 0.643117\n",
      "epoch 15; iter: 200; batch classifier loss: 0.519469; batch adversarial loss: 0.587633\n",
      "epoch 15; iter: 400; batch classifier loss: 0.341119; batch adversarial loss: 0.674630\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314381; batch adversarial loss: 0.633062\n",
      "epoch 16; iter: 200; batch classifier loss: 0.356296; batch adversarial loss: 0.618114\n",
      "epoch 16; iter: 400; batch classifier loss: 0.399030; batch adversarial loss: 0.539901\n",
      "epoch 17; iter: 0; batch classifier loss: 0.449682; batch adversarial loss: 0.668727\n",
      "epoch 17; iter: 200; batch classifier loss: 0.506704; batch adversarial loss: 0.588414\n",
      "epoch 17; iter: 400; batch classifier loss: 0.367261; batch adversarial loss: 0.573454\n",
      "epoch 18; iter: 0; batch classifier loss: 0.315845; batch adversarial loss: 0.599143\n",
      "epoch 18; iter: 200; batch classifier loss: 0.573026; batch adversarial loss: 0.608928\n",
      "epoch 18; iter: 400; batch classifier loss: 0.262284; batch adversarial loss: 0.640160\n",
      "epoch 19; iter: 0; batch classifier loss: 0.956167; batch adversarial loss: 0.641999\n",
      "epoch 19; iter: 200; batch classifier loss: 0.447906; batch adversarial loss: 0.650478\n",
      "epoch 19; iter: 400; batch classifier loss: 0.266444; batch adversarial loss: 0.658379\n",
      "epoch 0; iter: 0; batch classifier loss: 12.621796; batch adversarial loss: 0.688977\n",
      "epoch 0; iter: 200; batch classifier loss: 6.994717; batch adversarial loss: 0.613511\n",
      "epoch 0; iter: 400; batch classifier loss: 1.607650; batch adversarial loss: 0.680435\n",
      "epoch 1; iter: 0; batch classifier loss: 5.682889; batch adversarial loss: 0.623771\n",
      "epoch 1; iter: 200; batch classifier loss: 10.054840; batch adversarial loss: 0.617054\n",
      "epoch 1; iter: 400; batch classifier loss: 8.405521; batch adversarial loss: 0.592536\n",
      "epoch 2; iter: 0; batch classifier loss: 5.493659; batch adversarial loss: 0.671293\n",
      "epoch 2; iter: 200; batch classifier loss: 7.758265; batch adversarial loss: 0.655653\n",
      "epoch 2; iter: 400; batch classifier loss: 1.099286; batch adversarial loss: 0.728525\n",
      "epoch 3; iter: 0; batch classifier loss: 9.918948; batch adversarial loss: 0.714604\n",
      "epoch 3; iter: 200; batch classifier loss: 2.023173; batch adversarial loss: 0.589346\n",
      "epoch 3; iter: 400; batch classifier loss: 0.567912; batch adversarial loss: 0.621504\n",
      "epoch 4; iter: 0; batch classifier loss: 1.617539; batch adversarial loss: 0.698855\n",
      "epoch 4; iter: 200; batch classifier loss: 0.742712; batch adversarial loss: 0.594410\n",
      "epoch 4; iter: 400; batch classifier loss: 1.382821; batch adversarial loss: 0.629526\n",
      "epoch 5; iter: 0; batch classifier loss: 2.371031; batch adversarial loss: 0.620956\n",
      "epoch 5; iter: 200; batch classifier loss: 0.187853; batch adversarial loss: 0.681602\n",
      "epoch 5; iter: 400; batch classifier loss: 1.626057; batch adversarial loss: 0.668644\n",
      "epoch 6; iter: 0; batch classifier loss: 1.030857; batch adversarial loss: 0.606686\n",
      "epoch 6; iter: 200; batch classifier loss: 0.834897; batch adversarial loss: 0.680196\n",
      "epoch 6; iter: 400; batch classifier loss: 0.609204; batch adversarial loss: 0.592727\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519173; batch adversarial loss: 0.599380\n",
      "epoch 7; iter: 200; batch classifier loss: 0.752190; batch adversarial loss: 0.566026\n",
      "epoch 7; iter: 400; batch classifier loss: 0.394129; batch adversarial loss: 0.627343\n",
      "epoch 8; iter: 0; batch classifier loss: 0.448563; batch adversarial loss: 0.584735\n",
      "epoch 8; iter: 200; batch classifier loss: 0.443286; batch adversarial loss: 0.626768\n",
      "epoch 8; iter: 400; batch classifier loss: 0.344319; batch adversarial loss: 0.682126\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436647; batch adversarial loss: 0.654534\n",
      "epoch 9; iter: 200; batch classifier loss: 0.479274; batch adversarial loss: 0.619012\n",
      "epoch 9; iter: 400; batch classifier loss: 0.426785; batch adversarial loss: 0.590850\n",
      "epoch 10; iter: 0; batch classifier loss: 0.658495; batch adversarial loss: 0.523535\n",
      "epoch 10; iter: 200; batch classifier loss: 0.317890; batch adversarial loss: 0.611212\n",
      "epoch 10; iter: 400; batch classifier loss: 0.342882; batch adversarial loss: 0.550634\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509188; batch adversarial loss: 0.580050\n",
      "epoch 11; iter: 200; batch classifier loss: 0.420207; batch adversarial loss: 0.662085\n",
      "epoch 11; iter: 400; batch classifier loss: 0.482715; batch adversarial loss: 0.748450\n",
      "epoch 12; iter: 0; batch classifier loss: 0.288271; batch adversarial loss: 0.626471\n",
      "epoch 12; iter: 200; batch classifier loss: 0.394236; batch adversarial loss: 0.575447\n",
      "epoch 12; iter: 400; batch classifier loss: 0.348778; batch adversarial loss: 0.657091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522860; batch adversarial loss: 0.578818\n",
      "epoch 13; iter: 200; batch classifier loss: 0.445586; batch adversarial loss: 0.749704\n",
      "epoch 13; iter: 400; batch classifier loss: 0.515267; batch adversarial loss: 0.617799\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299063; batch adversarial loss: 0.627252\n",
      "epoch 14; iter: 200; batch classifier loss: 0.516976; batch adversarial loss: 0.681698\n",
      "epoch 14; iter: 400; batch classifier loss: 0.412157; batch adversarial loss: 0.549551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.455786; batch adversarial loss: 0.644278\n",
      "epoch 15; iter: 200; batch classifier loss: 0.265750; batch adversarial loss: 0.619584\n",
      "epoch 15; iter: 400; batch classifier loss: 0.310471; batch adversarial loss: 0.613401\n",
      "epoch 16; iter: 0; batch classifier loss: 0.217589; batch adversarial loss: 0.629022\n",
      "epoch 16; iter: 200; batch classifier loss: 0.434899; batch adversarial loss: 0.613359\n",
      "epoch 16; iter: 400; batch classifier loss: 0.531452; batch adversarial loss: 0.579707\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473534; batch adversarial loss: 0.675242\n",
      "epoch 17; iter: 200; batch classifier loss: 0.277862; batch adversarial loss: 0.703348\n",
      "epoch 17; iter: 400; batch classifier loss: 0.500208; batch adversarial loss: 0.701345\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338498; batch adversarial loss: 0.611095\n",
      "epoch 18; iter: 200; batch classifier loss: 0.510702; batch adversarial loss: 0.609823\n",
      "epoch 18; iter: 400; batch classifier loss: 0.260266; batch adversarial loss: 0.634928\n",
      "epoch 19; iter: 0; batch classifier loss: 0.626917; batch adversarial loss: 0.625209\n",
      "epoch 19; iter: 200; batch classifier loss: 0.400247; batch adversarial loss: 0.653181\n",
      "epoch 19; iter: 400; batch classifier loss: 0.435099; batch adversarial loss: 0.696754\n",
      "epoch 0; iter: 0; batch classifier loss: 30.553793; batch adversarial loss: 0.649329\n",
      "epoch 0; iter: 200; batch classifier loss: 18.561478; batch adversarial loss: 0.611146\n",
      "epoch 0; iter: 400; batch classifier loss: 10.221064; batch adversarial loss: 0.689549\n",
      "epoch 1; iter: 0; batch classifier loss: 0.932234; batch adversarial loss: 0.655230\n",
      "epoch 1; iter: 200; batch classifier loss: 2.063688; batch adversarial loss: 0.686719\n",
      "epoch 1; iter: 400; batch classifier loss: 5.657832; batch adversarial loss: 0.601413\n",
      "epoch 2; iter: 0; batch classifier loss: 0.466366; batch adversarial loss: 0.634734\n",
      "epoch 2; iter: 200; batch classifier loss: 3.492367; batch adversarial loss: 0.635029\n",
      "epoch 2; iter: 400; batch classifier loss: 4.220038; batch adversarial loss: 0.589114\n",
      "epoch 3; iter: 0; batch classifier loss: 5.812098; batch adversarial loss: 0.626958\n",
      "epoch 3; iter: 200; batch classifier loss: 1.751402; batch adversarial loss: 0.630294\n",
      "epoch 3; iter: 400; batch classifier loss: 1.593454; batch adversarial loss: 0.619081\n",
      "epoch 4; iter: 0; batch classifier loss: 0.650225; batch adversarial loss: 0.614884\n",
      "epoch 4; iter: 200; batch classifier loss: 1.852793; batch adversarial loss: 0.676844\n",
      "epoch 4; iter: 400; batch classifier loss: 0.361494; batch adversarial loss: 0.707778\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362212; batch adversarial loss: 0.613463\n",
      "epoch 5; iter: 200; batch classifier loss: 1.176858; batch adversarial loss: 0.663191\n",
      "epoch 5; iter: 400; batch classifier loss: 0.676569; batch adversarial loss: 0.585203\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579105; batch adversarial loss: 0.653590\n",
      "epoch 6; iter: 200; batch classifier loss: 0.581826; batch adversarial loss: 0.634089\n",
      "epoch 6; iter: 400; batch classifier loss: 0.695957; batch adversarial loss: 0.580853\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338075; batch adversarial loss: 0.602949\n",
      "epoch 7; iter: 200; batch classifier loss: 3.050696; batch adversarial loss: 0.560139\n",
      "epoch 7; iter: 400; batch classifier loss: 1.218022; batch adversarial loss: 0.573895\n",
      "epoch 8; iter: 0; batch classifier loss: 0.646626; batch adversarial loss: 0.625978\n",
      "epoch 8; iter: 200; batch classifier loss: 0.609786; batch adversarial loss: 0.608034\n",
      "epoch 8; iter: 400; batch classifier loss: 0.409260; batch adversarial loss: 0.571620\n",
      "epoch 9; iter: 0; batch classifier loss: 0.428141; batch adversarial loss: 0.732624\n",
      "epoch 9; iter: 200; batch classifier loss: 0.448734; batch adversarial loss: 0.543642\n",
      "epoch 9; iter: 400; batch classifier loss: 0.346091; batch adversarial loss: 0.687912\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466446; batch adversarial loss: 0.691658\n",
      "epoch 10; iter: 200; batch classifier loss: 0.389516; batch adversarial loss: 0.570460\n",
      "epoch 10; iter: 400; batch classifier loss: 0.342579; batch adversarial loss: 0.619216\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373109; batch adversarial loss: 0.610734\n",
      "epoch 11; iter: 200; batch classifier loss: 0.409492; batch adversarial loss: 0.561640\n",
      "epoch 11; iter: 400; batch classifier loss: 0.378884; batch adversarial loss: 0.630321\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313922; batch adversarial loss: 0.627409\n",
      "epoch 12; iter: 200; batch classifier loss: 0.254359; batch adversarial loss: 0.665396\n",
      "epoch 12; iter: 400; batch classifier loss: 0.303943; batch adversarial loss: 0.640755\n",
      "epoch 13; iter: 0; batch classifier loss: 0.402120; batch adversarial loss: 0.663532\n",
      "epoch 13; iter: 200; batch classifier loss: 0.341916; batch adversarial loss: 0.661991\n",
      "epoch 13; iter: 400; batch classifier loss: 0.464829; batch adversarial loss: 0.593538\n",
      "epoch 14; iter: 0; batch classifier loss: 0.341935; batch adversarial loss: 0.609802\n",
      "epoch 14; iter: 200; batch classifier loss: 0.476629; batch adversarial loss: 0.622058\n",
      "epoch 14; iter: 400; batch classifier loss: 0.456906; batch adversarial loss: 0.669348\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347325; batch adversarial loss: 0.586907\n",
      "epoch 15; iter: 200; batch classifier loss: 0.252069; batch adversarial loss: 0.642413\n",
      "epoch 15; iter: 400; batch classifier loss: 0.343055; batch adversarial loss: 0.582765\n",
      "epoch 16; iter: 0; batch classifier loss: 0.462051; batch adversarial loss: 0.627479\n",
      "epoch 16; iter: 200; batch classifier loss: 0.341495; batch adversarial loss: 0.521968\n",
      "epoch 16; iter: 400; batch classifier loss: 0.370106; batch adversarial loss: 0.621421\n",
      "epoch 17; iter: 0; batch classifier loss: 0.342241; batch adversarial loss: 0.623124\n",
      "epoch 17; iter: 200; batch classifier loss: 0.255536; batch adversarial loss: 0.621729\n",
      "epoch 17; iter: 400; batch classifier loss: 0.671011; batch adversarial loss: 0.668064\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348626; batch adversarial loss: 0.664896\n",
      "epoch 18; iter: 200; batch classifier loss: 0.470681; batch adversarial loss: 0.653555\n",
      "epoch 18; iter: 400; batch classifier loss: 0.378740; batch adversarial loss: 0.614326\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426081; batch adversarial loss: 0.674537\n",
      "epoch 19; iter: 200; batch classifier loss: 0.281352; batch adversarial loss: 0.674842\n",
      "epoch 19; iter: 400; batch classifier loss: 0.341941; batch adversarial loss: 0.628529\n",
      "epoch 0; iter: 0; batch classifier loss: 8.263870; batch adversarial loss: 0.645496\n",
      "epoch 0; iter: 200; batch classifier loss: 2.817590; batch adversarial loss: 0.659252\n",
      "epoch 0; iter: 400; batch classifier loss: 4.736693; batch adversarial loss: 0.708415\n",
      "epoch 1; iter: 0; batch classifier loss: 0.769424; batch adversarial loss: 0.665114\n",
      "epoch 1; iter: 200; batch classifier loss: 3.045273; batch adversarial loss: 0.642810\n",
      "epoch 1; iter: 400; batch classifier loss: 2.295539; batch adversarial loss: 0.669165\n",
      "epoch 2; iter: 0; batch classifier loss: 8.204773; batch adversarial loss: 0.638207\n",
      "epoch 2; iter: 200; batch classifier loss: 3.439039; batch adversarial loss: 0.654523\n",
      "epoch 2; iter: 400; batch classifier loss: 0.715156; batch adversarial loss: 0.650674\n",
      "epoch 3; iter: 0; batch classifier loss: 2.609081; batch adversarial loss: 0.669652\n",
      "epoch 3; iter: 200; batch classifier loss: 3.765676; batch adversarial loss: 0.636880\n",
      "epoch 3; iter: 400; batch classifier loss: 1.053810; batch adversarial loss: 0.642145\n",
      "epoch 4; iter: 0; batch classifier loss: 0.509575; batch adversarial loss: 0.642967\n",
      "epoch 4; iter: 200; batch classifier loss: 0.980277; batch adversarial loss: 0.604131\n",
      "epoch 4; iter: 400; batch classifier loss: 1.421908; batch adversarial loss: 0.666159\n",
      "epoch 5; iter: 0; batch classifier loss: 1.044054; batch adversarial loss: 0.635492\n",
      "epoch 5; iter: 200; batch classifier loss: 0.273971; batch adversarial loss: 0.581423\n",
      "epoch 5; iter: 400; batch classifier loss: 0.371948; batch adversarial loss: 0.705055\n",
      "epoch 6; iter: 0; batch classifier loss: 1.045781; batch adversarial loss: 0.583548\n",
      "epoch 6; iter: 200; batch classifier loss: 1.708657; batch adversarial loss: 0.631543\n",
      "epoch 6; iter: 400; batch classifier loss: 0.575556; batch adversarial loss: 0.636493\n",
      "epoch 7; iter: 0; batch classifier loss: 0.650027; batch adversarial loss: 0.629058\n",
      "epoch 7; iter: 200; batch classifier loss: 0.344989; batch adversarial loss: 0.624206\n",
      "epoch 7; iter: 400; batch classifier loss: 1.990991; batch adversarial loss: 0.645093\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438238; batch adversarial loss: 0.708820\n",
      "epoch 8; iter: 200; batch classifier loss: 0.304390; batch adversarial loss: 0.648980\n",
      "epoch 8; iter: 400; batch classifier loss: 0.510580; batch adversarial loss: 0.541216\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569104; batch adversarial loss: 0.600558\n",
      "epoch 9; iter: 200; batch classifier loss: 0.749611; batch adversarial loss: 0.619902\n",
      "epoch 9; iter: 400; batch classifier loss: 0.304841; batch adversarial loss: 0.573435\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517911; batch adversarial loss: 0.672689\n",
      "epoch 10; iter: 200; batch classifier loss: 0.511319; batch adversarial loss: 0.563268\n",
      "epoch 10; iter: 400; batch classifier loss: 0.488084; batch adversarial loss: 0.653926\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404482; batch adversarial loss: 0.580370\n",
      "epoch 11; iter: 200; batch classifier loss: 0.277364; batch adversarial loss: 0.609342\n",
      "epoch 11; iter: 400; batch classifier loss: 0.367342; batch adversarial loss: 0.608708\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398907; batch adversarial loss: 0.680093\n",
      "epoch 12; iter: 200; batch classifier loss: 0.319283; batch adversarial loss: 0.654751\n",
      "epoch 12; iter: 400; batch classifier loss: 0.382750; batch adversarial loss: 0.633652\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336354; batch adversarial loss: 0.632871\n",
      "epoch 13; iter: 200; batch classifier loss: 0.369037; batch adversarial loss: 0.580213\n",
      "epoch 13; iter: 400; batch classifier loss: 0.316912; batch adversarial loss: 0.619480\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265443; batch adversarial loss: 0.627131\n",
      "epoch 14; iter: 200; batch classifier loss: 0.312996; batch adversarial loss: 0.639634\n",
      "epoch 14; iter: 400; batch classifier loss: 0.489160; batch adversarial loss: 0.565643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427257; batch adversarial loss: 0.624920\n",
      "epoch 15; iter: 200; batch classifier loss: 0.512687; batch adversarial loss: 0.552230\n",
      "epoch 15; iter: 400; batch classifier loss: 0.422961; batch adversarial loss: 0.535063\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292678; batch adversarial loss: 0.572526\n",
      "epoch 16; iter: 200; batch classifier loss: 0.446719; batch adversarial loss: 0.649831\n",
      "epoch 16; iter: 400; batch classifier loss: 0.419323; batch adversarial loss: 0.633151\n",
      "epoch 17; iter: 0; batch classifier loss: 0.358238; batch adversarial loss: 0.653196\n",
      "epoch 17; iter: 200; batch classifier loss: 0.539940; batch adversarial loss: 0.699433\n",
      "epoch 17; iter: 400; batch classifier loss: 0.338196; batch adversarial loss: 0.684332\n",
      "epoch 18; iter: 0; batch classifier loss: 0.372304; batch adversarial loss: 0.505904\n",
      "epoch 18; iter: 200; batch classifier loss: 0.498612; batch adversarial loss: 0.582107\n",
      "epoch 18; iter: 400; batch classifier loss: 0.448028; batch adversarial loss: 0.631305\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362107; batch adversarial loss: 0.581753\n",
      "epoch 19; iter: 200; batch classifier loss: 0.394730; batch adversarial loss: 0.628718\n",
      "epoch 19; iter: 400; batch classifier loss: 0.644437; batch adversarial loss: 0.638249\n",
      "epoch 0; iter: 0; batch classifier loss: 35.346088; batch adversarial loss: 0.608363\n",
      "epoch 0; iter: 200; batch classifier loss: 3.851500; batch adversarial loss: 0.654679\n",
      "epoch 0; iter: 400; batch classifier loss: 15.515248; batch adversarial loss: 0.618206\n",
      "epoch 1; iter: 0; batch classifier loss: 3.822746; batch adversarial loss: 0.559274\n",
      "epoch 1; iter: 200; batch classifier loss: 2.191962; batch adversarial loss: 0.590627\n",
      "epoch 1; iter: 400; batch classifier loss: 5.794390; batch adversarial loss: 0.700694\n",
      "epoch 2; iter: 0; batch classifier loss: 4.765881; batch adversarial loss: 0.583346\n",
      "epoch 2; iter: 200; batch classifier loss: 1.790819; batch adversarial loss: 0.581533\n",
      "epoch 2; iter: 400; batch classifier loss: 0.412622; batch adversarial loss: 0.701063\n",
      "epoch 3; iter: 0; batch classifier loss: 2.088994; batch adversarial loss: 0.641864\n",
      "epoch 3; iter: 200; batch classifier loss: 0.266146; batch adversarial loss: 0.661149\n",
      "epoch 3; iter: 400; batch classifier loss: 0.475327; batch adversarial loss: 0.626981\n",
      "epoch 4; iter: 0; batch classifier loss: 2.293839; batch adversarial loss: 0.644054\n",
      "epoch 4; iter: 200; batch classifier loss: 0.397491; batch adversarial loss: 0.594693\n",
      "epoch 4; iter: 400; batch classifier loss: 0.503192; batch adversarial loss: 0.629528\n",
      "epoch 5; iter: 0; batch classifier loss: 1.191971; batch adversarial loss: 0.687764\n",
      "epoch 5; iter: 200; batch classifier loss: 0.517945; batch adversarial loss: 0.606267\n",
      "epoch 5; iter: 400; batch classifier loss: 1.296939; batch adversarial loss: 0.634346\n",
      "epoch 6; iter: 0; batch classifier loss: 0.301324; batch adversarial loss: 0.689336\n",
      "epoch 6; iter: 200; batch classifier loss: 0.332152; batch adversarial loss: 0.650928\n",
      "epoch 6; iter: 400; batch classifier loss: 0.456648; batch adversarial loss: 0.683865\n",
      "epoch 7; iter: 0; batch classifier loss: 0.838252; batch adversarial loss: 0.541850\n",
      "epoch 7; iter: 200; batch classifier loss: 0.718557; batch adversarial loss: 0.543331\n",
      "epoch 7; iter: 400; batch classifier loss: 0.634790; batch adversarial loss: 0.611269\n",
      "epoch 8; iter: 0; batch classifier loss: 0.393099; batch adversarial loss: 0.577670\n",
      "epoch 8; iter: 200; batch classifier loss: 0.368450; batch adversarial loss: 0.667547\n",
      "epoch 8; iter: 400; batch classifier loss: 0.416377; batch adversarial loss: 0.594048\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500480; batch adversarial loss: 0.629834\n",
      "epoch 9; iter: 200; batch classifier loss: 0.330828; batch adversarial loss: 0.684755\n",
      "epoch 9; iter: 400; batch classifier loss: 0.517028; batch adversarial loss: 0.607206\n",
      "epoch 10; iter: 0; batch classifier loss: 0.387585; batch adversarial loss: 0.643403\n",
      "epoch 10; iter: 200; batch classifier loss: 0.551491; batch adversarial loss: 0.707645\n",
      "epoch 10; iter: 400; batch classifier loss: 0.321200; batch adversarial loss: 0.658333\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514033; batch adversarial loss: 0.621542\n",
      "epoch 11; iter: 200; batch classifier loss: 0.483733; batch adversarial loss: 0.564105\n",
      "epoch 11; iter: 400; batch classifier loss: 0.333558; batch adversarial loss: 0.696277\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341015; batch adversarial loss: 0.648882\n",
      "epoch 12; iter: 200; batch classifier loss: 0.320327; batch adversarial loss: 0.568593\n",
      "epoch 12; iter: 400; batch classifier loss: 0.286309; batch adversarial loss: 0.660383\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419004; batch adversarial loss: 0.575531\n",
      "epoch 13; iter: 200; batch classifier loss: 0.416476; batch adversarial loss: 0.646301\n",
      "epoch 13; iter: 400; batch classifier loss: 0.376032; batch adversarial loss: 0.634640\n",
      "epoch 14; iter: 0; batch classifier loss: 0.541870; batch adversarial loss: 0.545087\n",
      "epoch 14; iter: 200; batch classifier loss: 0.361294; batch adversarial loss: 0.708028\n",
      "epoch 14; iter: 400; batch classifier loss: 0.403106; batch adversarial loss: 0.602289\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347708; batch adversarial loss: 0.654521\n",
      "epoch 15; iter: 200; batch classifier loss: 0.519261; batch adversarial loss: 0.648485\n",
      "epoch 15; iter: 400; batch classifier loss: 0.354673; batch adversarial loss: 0.599376\n",
      "epoch 16; iter: 0; batch classifier loss: 0.305774; batch adversarial loss: 0.592384\n",
      "epoch 16; iter: 200; batch classifier loss: 0.299211; batch adversarial loss: 0.693138\n",
      "epoch 16; iter: 400; batch classifier loss: 0.312852; batch adversarial loss: 0.560921\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372045; batch adversarial loss: 0.575690\n",
      "epoch 17; iter: 200; batch classifier loss: 0.292946; batch adversarial loss: 0.672905\n",
      "epoch 17; iter: 400; batch classifier loss: 0.390810; batch adversarial loss: 0.633660\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410352; batch adversarial loss: 0.682395\n",
      "epoch 18; iter: 200; batch classifier loss: 0.250218; batch adversarial loss: 0.689082\n",
      "epoch 18; iter: 400; batch classifier loss: 0.371240; batch adversarial loss: 0.581858\n",
      "epoch 19; iter: 0; batch classifier loss: 0.421337; batch adversarial loss: 0.581324\n",
      "epoch 19; iter: 200; batch classifier loss: 0.454738; batch adversarial loss: 0.662462\n",
      "epoch 19; iter: 400; batch classifier loss: 0.370421; batch adversarial loss: 0.663451\n",
      "epoch 0; iter: 0; batch classifier loss: 23.708973; batch adversarial loss: 0.765866\n",
      "epoch 0; iter: 200; batch classifier loss: 4.746436; batch adversarial loss: 0.680077\n",
      "epoch 0; iter: 400; batch classifier loss: 14.467782; batch adversarial loss: 0.617487\n",
      "epoch 1; iter: 0; batch classifier loss: 3.216157; batch adversarial loss: 0.649924\n",
      "epoch 1; iter: 200; batch classifier loss: 4.896605; batch adversarial loss: 0.647365\n",
      "epoch 1; iter: 400; batch classifier loss: 5.251256; batch adversarial loss: 0.529762\n",
      "epoch 2; iter: 0; batch classifier loss: 5.413602; batch adversarial loss: 0.599707\n",
      "epoch 2; iter: 200; batch classifier loss: 17.511225; batch adversarial loss: 0.613347\n",
      "epoch 2; iter: 400; batch classifier loss: 0.844276; batch adversarial loss: 0.557247\n",
      "epoch 3; iter: 0; batch classifier loss: 3.059566; batch adversarial loss: 0.579179\n",
      "epoch 3; iter: 200; batch classifier loss: 1.483009; batch adversarial loss: 0.629791\n",
      "epoch 3; iter: 400; batch classifier loss: 0.627480; batch adversarial loss: 0.555983\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443472; batch adversarial loss: 0.626873\n",
      "epoch 4; iter: 200; batch classifier loss: 0.961570; batch adversarial loss: 0.672649\n",
      "epoch 4; iter: 400; batch classifier loss: 1.490546; batch adversarial loss: 0.626094\n",
      "epoch 5; iter: 0; batch classifier loss: 0.915274; batch adversarial loss: 0.667344\n",
      "epoch 5; iter: 200; batch classifier loss: 1.229983; batch adversarial loss: 0.625498\n",
      "epoch 5; iter: 400; batch classifier loss: 0.540359; batch adversarial loss: 0.629257\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480444; batch adversarial loss: 0.550430\n",
      "epoch 6; iter: 200; batch classifier loss: 0.570696; batch adversarial loss: 0.602137\n",
      "epoch 6; iter: 400; batch classifier loss: 0.433699; batch adversarial loss: 0.688911\n",
      "epoch 7; iter: 0; batch classifier loss: 0.304990; batch adversarial loss: 0.587486\n",
      "epoch 7; iter: 200; batch classifier loss: 0.465491; batch adversarial loss: 0.670363\n",
      "epoch 7; iter: 400; batch classifier loss: 0.453165; batch adversarial loss: 0.624849\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361066; batch adversarial loss: 0.615417\n",
      "epoch 8; iter: 200; batch classifier loss: 0.610910; batch adversarial loss: 0.592389\n",
      "epoch 8; iter: 400; batch classifier loss: 0.437725; batch adversarial loss: 0.582222\n",
      "epoch 9; iter: 0; batch classifier loss: 0.299799; batch adversarial loss: 0.659025\n",
      "epoch 9; iter: 200; batch classifier loss: 0.320246; batch adversarial loss: 0.532259\n",
      "epoch 9; iter: 400; batch classifier loss: 0.298319; batch adversarial loss: 0.649194\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503288; batch adversarial loss: 0.618240\n",
      "epoch 10; iter: 200; batch classifier loss: 0.379932; batch adversarial loss: 0.563078\n",
      "epoch 10; iter: 400; batch classifier loss: 0.284183; batch adversarial loss: 0.620058\n",
      "epoch 11; iter: 0; batch classifier loss: 0.352293; batch adversarial loss: 0.535937\n",
      "epoch 11; iter: 200; batch classifier loss: 0.374324; batch adversarial loss: 0.548477\n",
      "epoch 11; iter: 400; batch classifier loss: 0.458392; batch adversarial loss: 0.695379\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410486; batch adversarial loss: 0.615186\n",
      "epoch 12; iter: 200; batch classifier loss: 0.553810; batch adversarial loss: 0.572609\n",
      "epoch 12; iter: 400; batch classifier loss: 0.447635; batch adversarial loss: 0.768444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430613; batch adversarial loss: 0.637597\n",
      "epoch 13; iter: 200; batch classifier loss: 0.246126; batch adversarial loss: 0.599132\n",
      "epoch 13; iter: 400; batch classifier loss: 0.442154; batch adversarial loss: 0.546347\n",
      "epoch 14; iter: 0; batch classifier loss: 0.422468; batch adversarial loss: 0.665162\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379614; batch adversarial loss: 0.625875\n",
      "epoch 14; iter: 400; batch classifier loss: 0.311292; batch adversarial loss: 0.574517\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424464; batch adversarial loss: 0.646701\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353947; batch adversarial loss: 0.668985\n",
      "epoch 15; iter: 400; batch classifier loss: 0.404654; batch adversarial loss: 0.657858\n",
      "epoch 16; iter: 0; batch classifier loss: 0.157505; batch adversarial loss: 0.683997\n",
      "epoch 16; iter: 200; batch classifier loss: 0.416800; batch adversarial loss: 0.637900\n",
      "epoch 16; iter: 400; batch classifier loss: 0.434787; batch adversarial loss: 0.578069\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269041; batch adversarial loss: 0.668416\n",
      "epoch 17; iter: 200; batch classifier loss: 0.380799; batch adversarial loss: 0.545857\n",
      "epoch 17; iter: 400; batch classifier loss: 0.365055; batch adversarial loss: 0.583822\n",
      "epoch 18; iter: 0; batch classifier loss: 0.457791; batch adversarial loss: 0.602385\n",
      "epoch 18; iter: 200; batch classifier loss: 0.511416; batch adversarial loss: 0.639862\n",
      "epoch 18; iter: 400; batch classifier loss: 0.329975; batch adversarial loss: 0.579994\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400986; batch adversarial loss: 0.631070\n",
      "epoch 19; iter: 200; batch classifier loss: 0.527156; batch adversarial loss: 0.621922\n",
      "epoch 19; iter: 400; batch classifier loss: 0.372037; batch adversarial loss: 0.485405\n",
      "epoch 0; iter: 0; batch classifier loss: 53.750244; batch adversarial loss: 0.691587\n",
      "epoch 0; iter: 200; batch classifier loss: 6.294194; batch adversarial loss: 0.644750\n",
      "epoch 0; iter: 400; batch classifier loss: 5.313729; batch adversarial loss: 0.651591\n",
      "epoch 1; iter: 0; batch classifier loss: 11.166117; batch adversarial loss: 0.644122\n",
      "epoch 1; iter: 200; batch classifier loss: 1.495507; batch adversarial loss: 0.621208\n",
      "epoch 1; iter: 400; batch classifier loss: 4.198901; batch adversarial loss: 0.607686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.375296; batch adversarial loss: 0.640076\n",
      "epoch 2; iter: 200; batch classifier loss: 1.333203; batch adversarial loss: 0.691501\n",
      "epoch 2; iter: 400; batch classifier loss: 1.524803; batch adversarial loss: 0.608214\n",
      "epoch 3; iter: 0; batch classifier loss: 3.786807; batch adversarial loss: 0.634287\n",
      "epoch 3; iter: 200; batch classifier loss: 0.693933; batch adversarial loss: 0.550179\n",
      "epoch 3; iter: 400; batch classifier loss: 1.424738; batch adversarial loss: 0.661603\n",
      "epoch 4; iter: 0; batch classifier loss: 0.769044; batch adversarial loss: 0.610472\n",
      "epoch 4; iter: 200; batch classifier loss: 1.753970; batch adversarial loss: 0.614376\n",
      "epoch 4; iter: 400; batch classifier loss: 0.805366; batch adversarial loss: 0.641020\n",
      "epoch 5; iter: 0; batch classifier loss: 1.627371; batch adversarial loss: 0.596262\n",
      "epoch 5; iter: 200; batch classifier loss: 0.690949; batch adversarial loss: 0.574400\n",
      "epoch 5; iter: 400; batch classifier loss: 0.602756; batch adversarial loss: 0.542079\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607662; batch adversarial loss: 0.618896\n",
      "epoch 6; iter: 200; batch classifier loss: 0.365368; batch adversarial loss: 0.652458\n",
      "epoch 6; iter: 400; batch classifier loss: 0.264870; batch adversarial loss: 0.608053\n",
      "epoch 7; iter: 0; batch classifier loss: 0.628051; batch adversarial loss: 0.633929\n",
      "epoch 7; iter: 200; batch classifier loss: 0.505445; batch adversarial loss: 0.588703\n",
      "epoch 7; iter: 400; batch classifier loss: 0.295302; batch adversarial loss: 0.649641\n",
      "epoch 8; iter: 0; batch classifier loss: 0.410427; batch adversarial loss: 0.623769\n",
      "epoch 8; iter: 200; batch classifier loss: 0.269929; batch adversarial loss: 0.664999\n",
      "epoch 8; iter: 400; batch classifier loss: 0.372603; batch adversarial loss: 0.667396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381060; batch adversarial loss: 0.661553\n",
      "epoch 9; iter: 200; batch classifier loss: 0.261765; batch adversarial loss: 0.605857\n",
      "epoch 9; iter: 400; batch classifier loss: 0.354359; batch adversarial loss: 0.643303\n",
      "epoch 10; iter: 0; batch classifier loss: 0.378022; batch adversarial loss: 0.686301\n",
      "epoch 10; iter: 200; batch classifier loss: 0.459823; batch adversarial loss: 0.647724\n",
      "epoch 10; iter: 400; batch classifier loss: 0.241564; batch adversarial loss: 0.619583\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389395; batch adversarial loss: 0.546135\n",
      "epoch 11; iter: 200; batch classifier loss: 0.380832; batch adversarial loss: 0.586374\n",
      "epoch 11; iter: 400; batch classifier loss: 0.554590; batch adversarial loss: 0.682797\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295076; batch adversarial loss: 0.684259\n",
      "epoch 12; iter: 200; batch classifier loss: 0.413221; batch adversarial loss: 0.587905\n",
      "epoch 12; iter: 400; batch classifier loss: 0.480531; batch adversarial loss: 0.582228\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389362; batch adversarial loss: 0.641822\n",
      "epoch 13; iter: 200; batch classifier loss: 0.270929; batch adversarial loss: 0.658232\n",
      "epoch 13; iter: 400; batch classifier loss: 0.282323; batch adversarial loss: 0.613066\n",
      "epoch 14; iter: 0; batch classifier loss: 0.179485; batch adversarial loss: 0.610222\n",
      "epoch 14; iter: 200; batch classifier loss: 0.512179; batch adversarial loss: 0.668649\n",
      "epoch 14; iter: 400; batch classifier loss: 0.298925; batch adversarial loss: 0.607796\n",
      "epoch 15; iter: 0; batch classifier loss: 0.353867; batch adversarial loss: 0.678348\n",
      "epoch 15; iter: 200; batch classifier loss: 0.325638; batch adversarial loss: 0.621963\n",
      "epoch 15; iter: 400; batch classifier loss: 0.351889; batch adversarial loss: 0.623554\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464484; batch adversarial loss: 0.675421\n",
      "epoch 16; iter: 200; batch classifier loss: 0.449643; batch adversarial loss: 0.624323\n",
      "epoch 16; iter: 400; batch classifier loss: 0.402298; batch adversarial loss: 0.560456\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335980; batch adversarial loss: 0.641045\n",
      "epoch 17; iter: 200; batch classifier loss: 0.367034; batch adversarial loss: 0.621790\n",
      "epoch 17; iter: 400; batch classifier loss: 0.345343; batch adversarial loss: 0.642750\n",
      "epoch 18; iter: 0; batch classifier loss: 0.393143; batch adversarial loss: 0.681880\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336507; batch adversarial loss: 0.597071\n",
      "epoch 18; iter: 400; batch classifier loss: 0.415427; batch adversarial loss: 0.611801\n",
      "epoch 19; iter: 0; batch classifier loss: 0.502957; batch adversarial loss: 0.624750\n",
      "epoch 19; iter: 200; batch classifier loss: 0.438290; batch adversarial loss: 0.585246\n",
      "epoch 19; iter: 400; batch classifier loss: 0.396503; batch adversarial loss: 0.625151\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 6.293197; batch adversarial loss: 1.166736\n",
      "epoch 0; iter: 200; batch classifier loss: 8.353965; batch adversarial loss: 0.985449\n",
      "epoch 0; iter: 400; batch classifier loss: 1.614857; batch adversarial loss: 0.876204\n",
      "epoch 1; iter: 0; batch classifier loss: 9.548191; batch adversarial loss: 0.826526\n",
      "epoch 1; iter: 200; batch classifier loss: 2.396015; batch adversarial loss: 0.731472\n",
      "epoch 1; iter: 400; batch classifier loss: 7.402390; batch adversarial loss: 0.686968\n",
      "epoch 2; iter: 0; batch classifier loss: 6.171026; batch adversarial loss: 0.619357\n",
      "epoch 2; iter: 200; batch classifier loss: 2.761094; batch adversarial loss: 0.747766\n",
      "epoch 2; iter: 400; batch classifier loss: 2.283529; batch adversarial loss: 0.655470\n",
      "epoch 3; iter: 0; batch classifier loss: 2.585181; batch adversarial loss: 0.615848\n",
      "epoch 3; iter: 200; batch classifier loss: 1.021010; batch adversarial loss: 0.699781\n",
      "epoch 3; iter: 400; batch classifier loss: 0.858738; batch adversarial loss: 0.621446\n",
      "epoch 4; iter: 0; batch classifier loss: 0.780201; batch adversarial loss: 0.617150\n",
      "epoch 4; iter: 200; batch classifier loss: 0.643448; batch adversarial loss: 0.585161\n",
      "epoch 4; iter: 400; batch classifier loss: 0.599623; batch adversarial loss: 0.549691\n",
      "epoch 5; iter: 0; batch classifier loss: 0.446181; batch adversarial loss: 0.667696\n",
      "epoch 5; iter: 200; batch classifier loss: 0.634185; batch adversarial loss: 0.557897\n",
      "epoch 5; iter: 400; batch classifier loss: 1.052234; batch adversarial loss: 0.629080\n",
      "epoch 6; iter: 0; batch classifier loss: 0.695983; batch adversarial loss: 0.599011\n",
      "epoch 6; iter: 200; batch classifier loss: 0.437134; batch adversarial loss: 0.694175\n",
      "epoch 6; iter: 400; batch classifier loss: 0.559383; batch adversarial loss: 0.589038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.363490; batch adversarial loss: 0.677554\n",
      "epoch 7; iter: 200; batch classifier loss: 0.550466; batch adversarial loss: 0.631399\n",
      "epoch 7; iter: 400; batch classifier loss: 0.586316; batch adversarial loss: 0.607887\n",
      "epoch 8; iter: 0; batch classifier loss: 0.321651; batch adversarial loss: 0.643000\n",
      "epoch 8; iter: 200; batch classifier loss: 0.920446; batch adversarial loss: 0.643274\n",
      "epoch 8; iter: 400; batch classifier loss: 0.580046; batch adversarial loss: 0.666043\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407313; batch adversarial loss: 0.665233\n",
      "epoch 9; iter: 200; batch classifier loss: 0.487896; batch adversarial loss: 0.679249\n",
      "epoch 9; iter: 400; batch classifier loss: 0.392683; batch adversarial loss: 0.656338\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486838; batch adversarial loss: 0.576328\n",
      "epoch 10; iter: 200; batch classifier loss: 0.384831; batch adversarial loss: 0.601151\n",
      "epoch 10; iter: 400; batch classifier loss: 0.397923; batch adversarial loss: 0.633039\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428834; batch adversarial loss: 0.515812\n",
      "epoch 11; iter: 200; batch classifier loss: 0.505140; batch adversarial loss: 0.603238\n",
      "epoch 11; iter: 400; batch classifier loss: 0.328691; batch adversarial loss: 0.658465\n",
      "epoch 12; iter: 0; batch classifier loss: 0.406715; batch adversarial loss: 0.557133\n",
      "epoch 12; iter: 200; batch classifier loss: 0.514040; batch adversarial loss: 0.622724\n",
      "epoch 12; iter: 400; batch classifier loss: 0.410123; batch adversarial loss: 0.607177\n",
      "epoch 13; iter: 0; batch classifier loss: 0.322487; batch adversarial loss: 0.645862\n",
      "epoch 13; iter: 200; batch classifier loss: 0.299107; batch adversarial loss: 0.602607\n",
      "epoch 13; iter: 400; batch classifier loss: 0.348599; batch adversarial loss: 0.562328\n",
      "epoch 14; iter: 0; batch classifier loss: 0.281943; batch adversarial loss: 0.622423\n",
      "epoch 14; iter: 200; batch classifier loss: 0.524637; batch adversarial loss: 0.628459\n",
      "epoch 14; iter: 400; batch classifier loss: 0.596518; batch adversarial loss: 0.545963\n",
      "epoch 15; iter: 0; batch classifier loss: 0.266467; batch adversarial loss: 0.694367\n",
      "epoch 15; iter: 200; batch classifier loss: 0.454239; batch adversarial loss: 0.622440\n",
      "epoch 15; iter: 400; batch classifier loss: 0.260968; batch adversarial loss: 0.658666\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378606; batch adversarial loss: 0.599153\n",
      "epoch 16; iter: 200; batch classifier loss: 0.247189; batch adversarial loss: 0.581558\n",
      "epoch 16; iter: 400; batch classifier loss: 0.313188; batch adversarial loss: 0.592910\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317769; batch adversarial loss: 0.536327\n",
      "epoch 17; iter: 200; batch classifier loss: 0.483583; batch adversarial loss: 0.605150\n",
      "epoch 17; iter: 400; batch classifier loss: 0.369240; batch adversarial loss: 0.532079\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439666; batch adversarial loss: 0.598820\n",
      "epoch 18; iter: 200; batch classifier loss: 0.366887; batch adversarial loss: 0.605971\n",
      "epoch 18; iter: 400; batch classifier loss: 0.362851; batch adversarial loss: 0.667680\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458881; batch adversarial loss: 0.662210\n",
      "epoch 19; iter: 200; batch classifier loss: 0.407965; batch adversarial loss: 0.611813\n",
      "epoch 19; iter: 400; batch classifier loss: 0.325351; batch adversarial loss: 0.636674\n",
      "epoch 20; iter: 0; batch classifier loss: 0.696551; batch adversarial loss: 0.719460\n",
      "epoch 20; iter: 200; batch classifier loss: 0.512189; batch adversarial loss: 0.627846\n",
      "epoch 20; iter: 400; batch classifier loss: 0.399177; batch adversarial loss: 0.598485\n",
      "epoch 21; iter: 0; batch classifier loss: 0.377592; batch adversarial loss: 0.626871\n",
      "epoch 21; iter: 200; batch classifier loss: 0.309029; batch adversarial loss: 0.612679\n",
      "epoch 21; iter: 400; batch classifier loss: 0.489297; batch adversarial loss: 0.592527\n",
      "epoch 22; iter: 0; batch classifier loss: 0.326382; batch adversarial loss: 0.714718\n",
      "epoch 22; iter: 200; batch classifier loss: 0.323713; batch adversarial loss: 0.622858\n",
      "epoch 22; iter: 400; batch classifier loss: 0.523667; batch adversarial loss: 0.697041\n",
      "epoch 23; iter: 0; batch classifier loss: 0.525404; batch adversarial loss: 0.699665\n",
      "epoch 23; iter: 200; batch classifier loss: 0.386645; batch adversarial loss: 0.602399\n",
      "epoch 23; iter: 400; batch classifier loss: 0.415383; batch adversarial loss: 0.586967\n",
      "epoch 24; iter: 0; batch classifier loss: 0.353395; batch adversarial loss: 0.594831\n",
      "epoch 24; iter: 200; batch classifier loss: 0.549054; batch adversarial loss: 0.561103\n",
      "epoch 24; iter: 400; batch classifier loss: 0.427608; batch adversarial loss: 0.615519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.277625; batch adversarial loss: 0.740800\n",
      "epoch 25; iter: 200; batch classifier loss: 0.461782; batch adversarial loss: 0.654402\n",
      "epoch 25; iter: 400; batch classifier loss: 0.524493; batch adversarial loss: 0.585578\n",
      "epoch 26; iter: 0; batch classifier loss: 0.233242; batch adversarial loss: 0.580800\n",
      "epoch 26; iter: 200; batch classifier loss: 0.393065; batch adversarial loss: 0.605027\n",
      "epoch 26; iter: 400; batch classifier loss: 0.234772; batch adversarial loss: 0.654195\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362609; batch adversarial loss: 0.606048\n",
      "epoch 27; iter: 200; batch classifier loss: 0.416231; batch adversarial loss: 0.689219\n",
      "epoch 27; iter: 400; batch classifier loss: 0.453042; batch adversarial loss: 0.651557\n",
      "epoch 28; iter: 0; batch classifier loss: 0.647359; batch adversarial loss: 0.657160\n",
      "epoch 28; iter: 200; batch classifier loss: 0.416524; batch adversarial loss: 0.598771\n",
      "epoch 28; iter: 400; batch classifier loss: 0.383842; batch adversarial loss: 0.605850\n",
      "epoch 29; iter: 0; batch classifier loss: 0.331847; batch adversarial loss: 0.597775\n",
      "epoch 29; iter: 200; batch classifier loss: 0.536415; batch adversarial loss: 0.678747\n",
      "epoch 29; iter: 400; batch classifier loss: 0.564735; batch adversarial loss: 0.711049\n",
      "epoch 30; iter: 0; batch classifier loss: 0.501715; batch adversarial loss: 0.610687\n",
      "epoch 30; iter: 200; batch classifier loss: 0.197305; batch adversarial loss: 0.627092\n",
      "epoch 30; iter: 400; batch classifier loss: 0.406837; batch adversarial loss: 0.665872\n",
      "epoch 31; iter: 0; batch classifier loss: 0.319689; batch adversarial loss: 0.641813\n",
      "epoch 31; iter: 200; batch classifier loss: 0.334225; batch adversarial loss: 0.599783\n",
      "epoch 31; iter: 400; batch classifier loss: 0.495146; batch adversarial loss: 0.607895\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484213; batch adversarial loss: 0.615474\n",
      "epoch 32; iter: 200; batch classifier loss: 0.511507; batch adversarial loss: 0.694332\n",
      "epoch 32; iter: 400; batch classifier loss: 1.036137; batch adversarial loss: 0.566644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.262037; batch adversarial loss: 0.612448\n",
      "epoch 33; iter: 200; batch classifier loss: 0.358148; batch adversarial loss: 0.627014\n",
      "epoch 33; iter: 400; batch classifier loss: 0.536434; batch adversarial loss: 0.568861\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494293; batch adversarial loss: 0.579589\n",
      "epoch 34; iter: 200; batch classifier loss: 0.538181; batch adversarial loss: 0.631565\n",
      "epoch 34; iter: 400; batch classifier loss: 0.607608; batch adversarial loss: 0.670812\n",
      "epoch 35; iter: 0; batch classifier loss: 0.385207; batch adversarial loss: 0.620323\n",
      "epoch 35; iter: 200; batch classifier loss: 0.356501; batch adversarial loss: 0.677712\n",
      "epoch 35; iter: 400; batch classifier loss: 0.572163; batch adversarial loss: 0.559787\n",
      "epoch 36; iter: 0; batch classifier loss: 0.629966; batch adversarial loss: 0.539712\n",
      "epoch 36; iter: 200; batch classifier loss: 0.490654; batch adversarial loss: 0.544995\n",
      "epoch 36; iter: 400; batch classifier loss: 0.407255; batch adversarial loss: 0.653999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.662467; batch adversarial loss: 0.628179\n",
      "epoch 37; iter: 200; batch classifier loss: 0.621476; batch adversarial loss: 0.600440\n",
      "epoch 37; iter: 400; batch classifier loss: 0.558055; batch adversarial loss: 0.654764\n",
      "epoch 38; iter: 0; batch classifier loss: 0.653961; batch adversarial loss: 0.644553\n",
      "epoch 38; iter: 200; batch classifier loss: 0.437367; batch adversarial loss: 0.617118\n",
      "epoch 38; iter: 400; batch classifier loss: 0.497008; batch adversarial loss: 0.613773\n",
      "epoch 39; iter: 0; batch classifier loss: 0.487792; batch adversarial loss: 0.661262\n",
      "epoch 39; iter: 200; batch classifier loss: 0.555286; batch adversarial loss: 0.605913\n",
      "epoch 39; iter: 400; batch classifier loss: 0.661537; batch adversarial loss: 0.580683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465646; batch adversarial loss: 0.686522\n",
      "epoch 40; iter: 200; batch classifier loss: 0.350401; batch adversarial loss: 0.581326\n",
      "epoch 40; iter: 400; batch classifier loss: 0.406190; batch adversarial loss: 0.622373\n",
      "epoch 41; iter: 0; batch classifier loss: 0.246555; batch adversarial loss: 0.607555\n",
      "epoch 41; iter: 200; batch classifier loss: 0.426328; batch adversarial loss: 0.542833\n",
      "epoch 41; iter: 400; batch classifier loss: 0.523317; batch adversarial loss: 0.635835\n",
      "epoch 42; iter: 0; batch classifier loss: 0.354406; batch adversarial loss: 0.663461\n",
      "epoch 42; iter: 200; batch classifier loss: 0.635806; batch adversarial loss: 0.629907\n",
      "epoch 42; iter: 400; batch classifier loss: 0.332977; batch adversarial loss: 0.607320\n",
      "epoch 43; iter: 0; batch classifier loss: 0.514105; batch adversarial loss: 0.722068\n",
      "epoch 43; iter: 200; batch classifier loss: 0.644484; batch adversarial loss: 0.681575\n",
      "epoch 43; iter: 400; batch classifier loss: 0.452030; batch adversarial loss: 0.718616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.676118; batch adversarial loss: 0.594633\n",
      "epoch 44; iter: 200; batch classifier loss: 0.503611; batch adversarial loss: 0.637159\n",
      "epoch 44; iter: 400; batch classifier loss: 0.488697; batch adversarial loss: 0.648644\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376485; batch adversarial loss: 0.617961\n",
      "epoch 45; iter: 200; batch classifier loss: 0.340255; batch adversarial loss: 0.574966\n",
      "epoch 45; iter: 400; batch classifier loss: 0.481688; batch adversarial loss: 0.615457\n",
      "epoch 46; iter: 0; batch classifier loss: 0.475695; batch adversarial loss: 0.692516\n",
      "epoch 46; iter: 200; batch classifier loss: 0.325762; batch adversarial loss: 0.564596\n",
      "epoch 46; iter: 400; batch classifier loss: 0.517116; batch adversarial loss: 0.602014\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482542; batch adversarial loss: 0.564038\n",
      "epoch 47; iter: 200; batch classifier loss: 0.557978; batch adversarial loss: 0.617575\n",
      "epoch 47; iter: 400; batch classifier loss: 1.443307; batch adversarial loss: 0.651558\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464443; batch adversarial loss: 0.612432\n",
      "epoch 48; iter: 200; batch classifier loss: 0.592360; batch adversarial loss: 0.620918\n",
      "epoch 48; iter: 400; batch classifier loss: 0.867852; batch adversarial loss: 0.567711\n",
      "epoch 49; iter: 0; batch classifier loss: 0.707620; batch adversarial loss: 0.592707\n",
      "epoch 49; iter: 200; batch classifier loss: 0.392956; batch adversarial loss: 0.640097\n",
      "epoch 49; iter: 400; batch classifier loss: 0.281383; batch adversarial loss: 0.654239\n",
      "epoch 0; iter: 0; batch classifier loss: 7.461286; batch adversarial loss: 0.725592\n",
      "epoch 0; iter: 200; batch classifier loss: 10.567243; batch adversarial loss: 0.659790\n",
      "epoch 0; iter: 400; batch classifier loss: 1.875670; batch adversarial loss: 0.676380\n",
      "epoch 1; iter: 0; batch classifier loss: 0.850226; batch adversarial loss: 0.636829\n",
      "epoch 1; iter: 200; batch classifier loss: 4.515391; batch adversarial loss: 0.621965\n",
      "epoch 1; iter: 400; batch classifier loss: 2.412263; batch adversarial loss: 0.618458\n",
      "epoch 2; iter: 0; batch classifier loss: 0.685262; batch adversarial loss: 0.684727\n",
      "epoch 2; iter: 200; batch classifier loss: 3.352948; batch adversarial loss: 0.597540\n",
      "epoch 2; iter: 400; batch classifier loss: 0.324646; batch adversarial loss: 0.590666\n",
      "epoch 3; iter: 0; batch classifier loss: 3.266593; batch adversarial loss: 0.659413\n",
      "epoch 3; iter: 200; batch classifier loss: 0.985752; batch adversarial loss: 0.680932\n",
      "epoch 3; iter: 400; batch classifier loss: 0.376785; batch adversarial loss: 0.634256\n",
      "epoch 4; iter: 0; batch classifier loss: 0.688398; batch adversarial loss: 0.597256\n",
      "epoch 4; iter: 200; batch classifier loss: 1.130200; batch adversarial loss: 0.605259\n",
      "epoch 4; iter: 400; batch classifier loss: 0.365986; batch adversarial loss: 0.595808\n",
      "epoch 5; iter: 0; batch classifier loss: 0.326022; batch adversarial loss: 0.624558\n",
      "epoch 5; iter: 200; batch classifier loss: 0.548631; batch adversarial loss: 0.538407\n",
      "epoch 5; iter: 400; batch classifier loss: 1.099025; batch adversarial loss: 0.568506\n",
      "epoch 6; iter: 0; batch classifier loss: 0.886364; batch adversarial loss: 0.587522\n",
      "epoch 6; iter: 200; batch classifier loss: 0.218965; batch adversarial loss: 0.654607\n",
      "epoch 6; iter: 400; batch classifier loss: 1.420467; batch adversarial loss: 0.651644\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458920; batch adversarial loss: 0.604623\n",
      "epoch 7; iter: 200; batch classifier loss: 0.366211; batch adversarial loss: 0.585494\n",
      "epoch 7; iter: 400; batch classifier loss: 0.470554; batch adversarial loss: 0.562575\n",
      "epoch 8; iter: 0; batch classifier loss: 0.716420; batch adversarial loss: 0.643048\n",
      "epoch 8; iter: 200; batch classifier loss: 0.395669; batch adversarial loss: 0.578692\n",
      "epoch 8; iter: 400; batch classifier loss: 0.303844; batch adversarial loss: 0.579411\n",
      "epoch 9; iter: 0; batch classifier loss: 0.288316; batch adversarial loss: 0.590025\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383584; batch adversarial loss: 0.548444\n",
      "epoch 9; iter: 400; batch classifier loss: 0.551873; batch adversarial loss: 0.548940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472270; batch adversarial loss: 0.628303\n",
      "epoch 10; iter: 200; batch classifier loss: 0.492511; batch adversarial loss: 0.629249\n",
      "epoch 10; iter: 400; batch classifier loss: 0.301939; batch adversarial loss: 0.635398\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371638; batch adversarial loss: 0.651955\n",
      "epoch 11; iter: 200; batch classifier loss: 0.352769; batch adversarial loss: 0.653629\n",
      "epoch 11; iter: 400; batch classifier loss: 0.358065; batch adversarial loss: 0.669110\n",
      "epoch 12; iter: 0; batch classifier loss: 0.635719; batch adversarial loss: 0.601475\n",
      "epoch 12; iter: 200; batch classifier loss: 0.422727; batch adversarial loss: 0.613054\n",
      "epoch 12; iter: 400; batch classifier loss: 0.352890; batch adversarial loss: 0.683000\n",
      "epoch 13; iter: 0; batch classifier loss: 0.453709; batch adversarial loss: 0.642714\n",
      "epoch 13; iter: 200; batch classifier loss: 0.338377; batch adversarial loss: 0.640661\n",
      "epoch 13; iter: 400; batch classifier loss: 0.383142; batch adversarial loss: 0.673570\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408142; batch adversarial loss: 0.618295\n",
      "epoch 14; iter: 200; batch classifier loss: 0.399997; batch adversarial loss: 0.643170\n",
      "epoch 14; iter: 400; batch classifier loss: 0.303474; batch adversarial loss: 0.604934\n",
      "epoch 15; iter: 0; batch classifier loss: 0.225831; batch adversarial loss: 0.630162\n",
      "epoch 15; iter: 200; batch classifier loss: 0.368159; batch adversarial loss: 0.613555\n",
      "epoch 15; iter: 400; batch classifier loss: 0.292508; batch adversarial loss: 0.630013\n",
      "epoch 16; iter: 0; batch classifier loss: 0.308937; batch adversarial loss: 0.632068\n",
      "epoch 16; iter: 200; batch classifier loss: 0.368731; batch adversarial loss: 0.595545\n",
      "epoch 16; iter: 400; batch classifier loss: 0.292542; batch adversarial loss: 0.687661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.434434; batch adversarial loss: 0.586067\n",
      "epoch 17; iter: 200; batch classifier loss: 0.386975; batch adversarial loss: 0.650828\n",
      "epoch 17; iter: 400; batch classifier loss: 0.418283; batch adversarial loss: 0.597589\n",
      "epoch 18; iter: 0; batch classifier loss: 0.346377; batch adversarial loss: 0.564499\n",
      "epoch 18; iter: 200; batch classifier loss: 0.459755; batch adversarial loss: 0.694104\n",
      "epoch 18; iter: 400; batch classifier loss: 0.282025; batch adversarial loss: 0.645598\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310175; batch adversarial loss: 0.617541\n",
      "epoch 19; iter: 200; batch classifier loss: 0.273078; batch adversarial loss: 0.599429\n",
      "epoch 19; iter: 400; batch classifier loss: 0.418262; batch adversarial loss: 0.661274\n",
      "epoch 20; iter: 0; batch classifier loss: 0.358268; batch adversarial loss: 0.649462\n",
      "epoch 20; iter: 200; batch classifier loss: 0.499517; batch adversarial loss: 0.618791\n",
      "epoch 20; iter: 400; batch classifier loss: 0.416767; batch adversarial loss: 0.640255\n",
      "epoch 21; iter: 0; batch classifier loss: 0.249510; batch adversarial loss: 0.612967\n",
      "epoch 21; iter: 200; batch classifier loss: 0.341380; batch adversarial loss: 0.638217\n",
      "epoch 21; iter: 400; batch classifier loss: 0.483351; batch adversarial loss: 0.677532\n",
      "epoch 22; iter: 0; batch classifier loss: 0.323126; batch adversarial loss: 0.616338\n",
      "epoch 22; iter: 200; batch classifier loss: 0.425330; batch adversarial loss: 0.604625\n",
      "epoch 22; iter: 400; batch classifier loss: 0.292256; batch adversarial loss: 0.670709\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502138; batch adversarial loss: 0.607315\n",
      "epoch 23; iter: 200; batch classifier loss: 0.382948; batch adversarial loss: 0.616953\n",
      "epoch 23; iter: 400; batch classifier loss: 0.467488; batch adversarial loss: 0.618644\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422096; batch adversarial loss: 0.609693\n",
      "epoch 24; iter: 200; batch classifier loss: 0.344720; batch adversarial loss: 0.633764\n",
      "epoch 24; iter: 400; batch classifier loss: 0.294605; batch adversarial loss: 0.593780\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420619; batch adversarial loss: 0.636044\n",
      "epoch 25; iter: 200; batch classifier loss: 0.492378; batch adversarial loss: 0.610338\n",
      "epoch 25; iter: 400; batch classifier loss: 0.337166; batch adversarial loss: 0.555470\n",
      "epoch 26; iter: 0; batch classifier loss: 0.252241; batch adversarial loss: 0.608508\n",
      "epoch 26; iter: 200; batch classifier loss: 0.426177; batch adversarial loss: 0.621071\n",
      "epoch 26; iter: 400; batch classifier loss: 0.427191; batch adversarial loss: 0.630047\n",
      "epoch 27; iter: 0; batch classifier loss: 0.509724; batch adversarial loss: 0.653320\n",
      "epoch 27; iter: 200; batch classifier loss: 0.463102; batch adversarial loss: 0.618480\n",
      "epoch 27; iter: 400; batch classifier loss: 0.245933; batch adversarial loss: 0.624980\n",
      "epoch 28; iter: 0; batch classifier loss: 0.329887; batch adversarial loss: 0.665022\n",
      "epoch 28; iter: 200; batch classifier loss: 0.297136; batch adversarial loss: 0.632095\n",
      "epoch 28; iter: 400; batch classifier loss: 0.331664; batch adversarial loss: 0.609047\n",
      "epoch 29; iter: 0; batch classifier loss: 0.426422; batch adversarial loss: 0.564349\n",
      "epoch 29; iter: 200; batch classifier loss: 0.371781; batch adversarial loss: 0.600920\n",
      "epoch 29; iter: 400; batch classifier loss: 0.629107; batch adversarial loss: 0.572229\n",
      "epoch 30; iter: 0; batch classifier loss: 0.369966; batch adversarial loss: 0.620389\n",
      "epoch 30; iter: 200; batch classifier loss: 0.260232; batch adversarial loss: 0.667854\n",
      "epoch 30; iter: 400; batch classifier loss: 0.446381; batch adversarial loss: 0.609658\n",
      "epoch 31; iter: 0; batch classifier loss: 0.487000; batch adversarial loss: 0.560619\n",
      "epoch 31; iter: 200; batch classifier loss: 0.365081; batch adversarial loss: 0.626192\n",
      "epoch 31; iter: 400; batch classifier loss: 0.378643; batch adversarial loss: 0.669863\n",
      "epoch 32; iter: 0; batch classifier loss: 0.526582; batch adversarial loss: 0.584303\n",
      "epoch 32; iter: 200; batch classifier loss: 0.507484; batch adversarial loss: 0.662459\n",
      "epoch 32; iter: 400; batch classifier loss: 0.396680; batch adversarial loss: 0.649408\n",
      "epoch 33; iter: 0; batch classifier loss: 0.331614; batch adversarial loss: 0.674860\n",
      "epoch 33; iter: 200; batch classifier loss: 0.613938; batch adversarial loss: 0.648548\n",
      "epoch 33; iter: 400; batch classifier loss: 0.392068; batch adversarial loss: 0.594078\n",
      "epoch 34; iter: 0; batch classifier loss: 0.592827; batch adversarial loss: 0.610083\n",
      "epoch 34; iter: 200; batch classifier loss: 0.450038; batch adversarial loss: 0.547472\n",
      "epoch 34; iter: 400; batch classifier loss: 0.383783; batch adversarial loss: 0.703053\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485909; batch adversarial loss: 0.589715\n",
      "epoch 35; iter: 200; batch classifier loss: 0.448426; batch adversarial loss: 0.600748\n",
      "epoch 35; iter: 400; batch classifier loss: 0.338952; batch adversarial loss: 0.601259\n",
      "epoch 36; iter: 0; batch classifier loss: 0.256591; batch adversarial loss: 0.586515\n",
      "epoch 36; iter: 200; batch classifier loss: 0.364415; batch adversarial loss: 0.612345\n",
      "epoch 36; iter: 400; batch classifier loss: 0.435394; batch adversarial loss: 0.622449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.584312; batch adversarial loss: 0.622319\n",
      "epoch 37; iter: 200; batch classifier loss: 0.549734; batch adversarial loss: 0.639109\n",
      "epoch 37; iter: 400; batch classifier loss: 0.325985; batch adversarial loss: 0.608404\n",
      "epoch 38; iter: 0; batch classifier loss: 0.585280; batch adversarial loss: 0.650002\n",
      "epoch 38; iter: 200; batch classifier loss: 0.614402; batch adversarial loss: 0.692982\n",
      "epoch 38; iter: 400; batch classifier loss: 0.372047; batch adversarial loss: 0.656399\n",
      "epoch 39; iter: 0; batch classifier loss: 0.370173; batch adversarial loss: 0.552619\n",
      "epoch 39; iter: 200; batch classifier loss: 0.391154; batch adversarial loss: 0.640262\n",
      "epoch 39; iter: 400; batch classifier loss: 0.486066; batch adversarial loss: 0.712630\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444880; batch adversarial loss: 0.607237\n",
      "epoch 40; iter: 200; batch classifier loss: 0.544430; batch adversarial loss: 0.658217\n",
      "epoch 40; iter: 400; batch classifier loss: 0.416358; batch adversarial loss: 0.601132\n",
      "epoch 41; iter: 0; batch classifier loss: 0.546232; batch adversarial loss: 0.600017\n",
      "epoch 41; iter: 200; batch classifier loss: 0.383622; batch adversarial loss: 0.655964\n",
      "epoch 41; iter: 400; batch classifier loss: 0.543454; batch adversarial loss: 0.585928\n",
      "epoch 42; iter: 0; batch classifier loss: 0.353122; batch adversarial loss: 0.640170\n",
      "epoch 42; iter: 200; batch classifier loss: 0.613635; batch adversarial loss: 0.593569\n",
      "epoch 42; iter: 400; batch classifier loss: 0.387588; batch adversarial loss: 0.596355\n",
      "epoch 43; iter: 0; batch classifier loss: 0.358058; batch adversarial loss: 0.597846\n",
      "epoch 43; iter: 200; batch classifier loss: 0.209831; batch adversarial loss: 0.587854\n",
      "epoch 43; iter: 400; batch classifier loss: 0.294095; batch adversarial loss: 0.708980\n",
      "epoch 44; iter: 0; batch classifier loss: 0.567271; batch adversarial loss: 0.647540\n",
      "epoch 44; iter: 200; batch classifier loss: 0.338473; batch adversarial loss: 0.646614\n",
      "epoch 44; iter: 400; batch classifier loss: 0.549208; batch adversarial loss: 0.520290\n",
      "epoch 45; iter: 0; batch classifier loss: 0.312460; batch adversarial loss: 0.659879\n",
      "epoch 45; iter: 200; batch classifier loss: 0.474343; batch adversarial loss: 0.510611\n",
      "epoch 45; iter: 400; batch classifier loss: 0.478620; batch adversarial loss: 0.616875\n",
      "epoch 46; iter: 0; batch classifier loss: 0.522033; batch adversarial loss: 0.552815\n",
      "epoch 46; iter: 200; batch classifier loss: 0.219374; batch adversarial loss: 0.713936\n",
      "epoch 46; iter: 400; batch classifier loss: 0.273128; batch adversarial loss: 0.636745\n",
      "epoch 47; iter: 0; batch classifier loss: 0.364405; batch adversarial loss: 0.571551\n",
      "epoch 47; iter: 200; batch classifier loss: 0.303657; batch adversarial loss: 0.569494\n",
      "epoch 47; iter: 400; batch classifier loss: 0.675416; batch adversarial loss: 0.683787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385543; batch adversarial loss: 0.692116\n",
      "epoch 48; iter: 200; batch classifier loss: 0.527045; batch adversarial loss: 0.666550\n",
      "epoch 48; iter: 400; batch classifier loss: 0.589923; batch adversarial loss: 0.593299\n",
      "epoch 49; iter: 0; batch classifier loss: 0.527114; batch adversarial loss: 0.657343\n",
      "epoch 49; iter: 200; batch classifier loss: 0.424682; batch adversarial loss: 0.653472\n",
      "epoch 49; iter: 400; batch classifier loss: 0.630097; batch adversarial loss: 0.622583\n",
      "epoch 0; iter: 0; batch classifier loss: 29.081879; batch adversarial loss: 0.795784\n",
      "epoch 0; iter: 200; batch classifier loss: 24.636818; batch adversarial loss: 0.657509\n",
      "epoch 0; iter: 400; batch classifier loss: 6.864268; batch adversarial loss: 0.616018\n",
      "epoch 1; iter: 0; batch classifier loss: 8.292581; batch adversarial loss: 0.640887\n",
      "epoch 1; iter: 200; batch classifier loss: 4.231676; batch adversarial loss: 0.618289\n",
      "epoch 1; iter: 400; batch classifier loss: 7.751154; batch adversarial loss: 0.572441\n",
      "epoch 2; iter: 0; batch classifier loss: 5.652985; batch adversarial loss: 0.612298\n",
      "epoch 2; iter: 200; batch classifier loss: 2.594354; batch adversarial loss: 0.610509\n",
      "epoch 2; iter: 400; batch classifier loss: 0.414519; batch adversarial loss: 0.491551\n",
      "epoch 3; iter: 0; batch classifier loss: 1.277851; batch adversarial loss: 0.638256\n",
      "epoch 3; iter: 200; batch classifier loss: 0.687267; batch adversarial loss: 0.674332\n",
      "epoch 3; iter: 400; batch classifier loss: 0.370541; batch adversarial loss: 0.601891\n",
      "epoch 4; iter: 0; batch classifier loss: 1.452817; batch adversarial loss: 0.614596\n",
      "epoch 4; iter: 200; batch classifier loss: 0.336086; batch adversarial loss: 0.586411\n",
      "epoch 4; iter: 400; batch classifier loss: 0.396049; batch adversarial loss: 0.556792\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539875; batch adversarial loss: 0.531427\n",
      "epoch 5; iter: 200; batch classifier loss: 0.548750; batch adversarial loss: 0.578468\n",
      "epoch 5; iter: 400; batch classifier loss: 1.155499; batch adversarial loss: 0.587363\n",
      "epoch 6; iter: 0; batch classifier loss: 0.751483; batch adversarial loss: 0.626719\n",
      "epoch 6; iter: 200; batch classifier loss: 1.201685; batch adversarial loss: 0.599700\n",
      "epoch 6; iter: 400; batch classifier loss: 0.724673; batch adversarial loss: 0.653844\n",
      "epoch 7; iter: 0; batch classifier loss: 0.439196; batch adversarial loss: 0.600750\n",
      "epoch 7; iter: 200; batch classifier loss: 0.371127; batch adversarial loss: 0.589800\n",
      "epoch 7; iter: 400; batch classifier loss: 0.369675; batch adversarial loss: 0.650742\n",
      "epoch 8; iter: 0; batch classifier loss: 0.750299; batch adversarial loss: 0.623840\n",
      "epoch 8; iter: 200; batch classifier loss: 0.485660; batch adversarial loss: 0.699691\n",
      "epoch 8; iter: 400; batch classifier loss: 0.482184; batch adversarial loss: 0.628503\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500765; batch adversarial loss: 0.582423\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426828; batch adversarial loss: 0.658072\n",
      "epoch 9; iter: 400; batch classifier loss: 0.193532; batch adversarial loss: 0.649616\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485035; batch adversarial loss: 0.623080\n",
      "epoch 10; iter: 200; batch classifier loss: 0.410860; batch adversarial loss: 0.660726\n",
      "epoch 10; iter: 400; batch classifier loss: 0.213489; batch adversarial loss: 0.684712\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372738; batch adversarial loss: 0.575923\n",
      "epoch 11; iter: 200; batch classifier loss: 0.298089; batch adversarial loss: 0.603718\n",
      "epoch 11; iter: 400; batch classifier loss: 0.491306; batch adversarial loss: 0.652041\n",
      "epoch 12; iter: 0; batch classifier loss: 0.292732; batch adversarial loss: 0.688682\n",
      "epoch 12; iter: 200; batch classifier loss: 0.452460; batch adversarial loss: 0.592758\n",
      "epoch 12; iter: 400; batch classifier loss: 0.351389; batch adversarial loss: 0.660153\n",
      "epoch 13; iter: 0; batch classifier loss: 0.206420; batch adversarial loss: 0.620065\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326759; batch adversarial loss: 0.522227\n",
      "epoch 13; iter: 400; batch classifier loss: 0.386586; batch adversarial loss: 0.650216\n",
      "epoch 14; iter: 0; batch classifier loss: 0.269733; batch adversarial loss: 0.613555\n",
      "epoch 14; iter: 200; batch classifier loss: 0.409701; batch adversarial loss: 0.586558\n",
      "epoch 14; iter: 400; batch classifier loss: 0.330369; batch adversarial loss: 0.662138\n",
      "epoch 15; iter: 0; batch classifier loss: 0.439858; batch adversarial loss: 0.559339\n",
      "epoch 15; iter: 200; batch classifier loss: 0.523329; batch adversarial loss: 0.584553\n",
      "epoch 15; iter: 400; batch classifier loss: 0.406974; batch adversarial loss: 0.658185\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408536; batch adversarial loss: 0.631454\n",
      "epoch 16; iter: 200; batch classifier loss: 0.451336; batch adversarial loss: 0.559403\n",
      "epoch 16; iter: 400; batch classifier loss: 0.440044; batch adversarial loss: 0.724577\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348200; batch adversarial loss: 0.666576\n",
      "epoch 17; iter: 200; batch classifier loss: 0.413138; batch adversarial loss: 0.639788\n",
      "epoch 17; iter: 400; batch classifier loss: 0.360879; batch adversarial loss: 0.669119\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500138; batch adversarial loss: 0.616985\n",
      "epoch 18; iter: 200; batch classifier loss: 0.390922; batch adversarial loss: 0.640923\n",
      "epoch 18; iter: 400; batch classifier loss: 0.372563; batch adversarial loss: 0.667250\n",
      "epoch 19; iter: 0; batch classifier loss: 0.351771; batch adversarial loss: 0.563027\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346584; batch adversarial loss: 0.662237\n",
      "epoch 19; iter: 400; batch classifier loss: 0.380105; batch adversarial loss: 0.614153\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285887; batch adversarial loss: 0.677543\n",
      "epoch 20; iter: 200; batch classifier loss: 0.381587; batch adversarial loss: 0.596522\n",
      "epoch 20; iter: 400; batch classifier loss: 0.312944; batch adversarial loss: 0.620282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490420; batch adversarial loss: 0.606117\n",
      "epoch 21; iter: 200; batch classifier loss: 0.367971; batch adversarial loss: 0.661881\n",
      "epoch 21; iter: 400; batch classifier loss: 0.334790; batch adversarial loss: 0.687805\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472810; batch adversarial loss: 0.646066\n",
      "epoch 22; iter: 200; batch classifier loss: 0.282819; batch adversarial loss: 0.626975\n",
      "epoch 22; iter: 400; batch classifier loss: 0.355280; batch adversarial loss: 0.635665\n",
      "epoch 23; iter: 0; batch classifier loss: 0.307053; batch adversarial loss: 0.596053\n",
      "epoch 23; iter: 200; batch classifier loss: 0.466961; batch adversarial loss: 0.589443\n",
      "epoch 23; iter: 400; batch classifier loss: 0.508783; batch adversarial loss: 0.608641\n",
      "epoch 24; iter: 0; batch classifier loss: 0.426418; batch adversarial loss: 0.685049\n",
      "epoch 24; iter: 200; batch classifier loss: 0.594669; batch adversarial loss: 0.634230\n",
      "epoch 24; iter: 400; batch classifier loss: 0.284279; batch adversarial loss: 0.604181\n",
      "epoch 25; iter: 0; batch classifier loss: 0.559051; batch adversarial loss: 0.586017\n",
      "epoch 25; iter: 200; batch classifier loss: 0.292355; batch adversarial loss: 0.669263\n",
      "epoch 25; iter: 400; batch classifier loss: 0.409242; batch adversarial loss: 0.650691\n",
      "epoch 26; iter: 0; batch classifier loss: 0.289345; batch adversarial loss: 0.649337\n",
      "epoch 26; iter: 200; batch classifier loss: 0.352574; batch adversarial loss: 0.582710\n",
      "epoch 26; iter: 400; batch classifier loss: 0.446290; batch adversarial loss: 0.616615\n",
      "epoch 27; iter: 0; batch classifier loss: 0.288534; batch adversarial loss: 0.592675\n",
      "epoch 27; iter: 200; batch classifier loss: 0.414896; batch adversarial loss: 0.593491\n",
      "epoch 27; iter: 400; batch classifier loss: 0.227209; batch adversarial loss: 0.655276\n",
      "epoch 28; iter: 0; batch classifier loss: 0.300024; batch adversarial loss: 0.585491\n",
      "epoch 28; iter: 200; batch classifier loss: 0.565816; batch adversarial loss: 0.545088\n",
      "epoch 28; iter: 400; batch classifier loss: 0.281888; batch adversarial loss: 0.588996\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397102; batch adversarial loss: 0.661649\n",
      "epoch 29; iter: 200; batch classifier loss: 0.449363; batch adversarial loss: 0.627222\n",
      "epoch 29; iter: 400; batch classifier loss: 0.904154; batch adversarial loss: 0.589836\n",
      "epoch 30; iter: 0; batch classifier loss: 0.366943; batch adversarial loss: 0.543445\n",
      "epoch 30; iter: 200; batch classifier loss: 0.440023; batch adversarial loss: 0.657291\n",
      "epoch 30; iter: 400; batch classifier loss: 0.324896; batch adversarial loss: 0.582829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.539023; batch adversarial loss: 0.552540\n",
      "epoch 31; iter: 200; batch classifier loss: 1.159026; batch adversarial loss: 0.611822\n",
      "epoch 31; iter: 400; batch classifier loss: 0.367425; batch adversarial loss: 0.681608\n",
      "epoch 32; iter: 0; batch classifier loss: 0.498515; batch adversarial loss: 0.630594\n",
      "epoch 32; iter: 200; batch classifier loss: 0.408798; batch adversarial loss: 0.649016\n",
      "epoch 32; iter: 400; batch classifier loss: 0.531625; batch adversarial loss: 0.679896\n",
      "epoch 33; iter: 0; batch classifier loss: 0.297898; batch adversarial loss: 0.586023\n",
      "epoch 33; iter: 200; batch classifier loss: 0.388670; batch adversarial loss: 0.617711\n",
      "epoch 33; iter: 400; batch classifier loss: 0.271555; batch adversarial loss: 0.660189\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499282; batch adversarial loss: 0.652239\n",
      "epoch 34; iter: 200; batch classifier loss: 0.402588; batch adversarial loss: 0.621252\n",
      "epoch 34; iter: 400; batch classifier loss: 0.571301; batch adversarial loss: 0.669875\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341467; batch adversarial loss: 0.639300\n",
      "epoch 35; iter: 200; batch classifier loss: 0.501989; batch adversarial loss: 0.638571\n",
      "epoch 35; iter: 400; batch classifier loss: 0.391209; batch adversarial loss: 0.542588\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365891; batch adversarial loss: 0.660040\n",
      "epoch 36; iter: 200; batch classifier loss: 0.476235; batch adversarial loss: 0.677588\n",
      "epoch 36; iter: 400; batch classifier loss: 0.393362; batch adversarial loss: 0.661447\n",
      "epoch 37; iter: 0; batch classifier loss: 0.376141; batch adversarial loss: 0.648438\n",
      "epoch 37; iter: 200; batch classifier loss: 0.630266; batch adversarial loss: 0.608278\n",
      "epoch 37; iter: 400; batch classifier loss: 0.323853; batch adversarial loss: 0.614972\n",
      "epoch 38; iter: 0; batch classifier loss: 0.650712; batch adversarial loss: 0.608476\n",
      "epoch 38; iter: 200; batch classifier loss: 0.411319; batch adversarial loss: 0.656952\n",
      "epoch 38; iter: 400; batch classifier loss: 0.491139; batch adversarial loss: 0.634187\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421165; batch adversarial loss: 0.578653\n",
      "epoch 39; iter: 200; batch classifier loss: 0.178759; batch adversarial loss: 0.601297\n",
      "epoch 39; iter: 400; batch classifier loss: 0.448344; batch adversarial loss: 0.556112\n",
      "epoch 40; iter: 0; batch classifier loss: 0.338935; batch adversarial loss: 0.690506\n",
      "epoch 40; iter: 200; batch classifier loss: 0.594759; batch adversarial loss: 0.626429\n",
      "epoch 40; iter: 400; batch classifier loss: 0.349408; batch adversarial loss: 0.573524\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450396; batch adversarial loss: 0.595192\n",
      "epoch 41; iter: 200; batch classifier loss: 0.464900; batch adversarial loss: 0.669310\n",
      "epoch 41; iter: 400; batch classifier loss: 0.370594; batch adversarial loss: 0.659871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.309609; batch adversarial loss: 0.657802\n",
      "epoch 42; iter: 200; batch classifier loss: 0.393016; batch adversarial loss: 0.600779\n",
      "epoch 42; iter: 400; batch classifier loss: 0.522650; batch adversarial loss: 0.637755\n",
      "epoch 43; iter: 0; batch classifier loss: 0.366903; batch adversarial loss: 0.674610\n",
      "epoch 43; iter: 200; batch classifier loss: 0.512632; batch adversarial loss: 0.575139\n",
      "epoch 43; iter: 400; batch classifier loss: 0.323684; batch adversarial loss: 0.626475\n",
      "epoch 44; iter: 0; batch classifier loss: 0.340477; batch adversarial loss: 0.608610\n",
      "epoch 44; iter: 200; batch classifier loss: 0.568565; batch adversarial loss: 0.553662\n",
      "epoch 44; iter: 400; batch classifier loss: 0.470652; batch adversarial loss: 0.593725\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400624; batch adversarial loss: 0.597442\n",
      "epoch 45; iter: 200; batch classifier loss: 0.399221; batch adversarial loss: 0.673638\n",
      "epoch 45; iter: 400; batch classifier loss: 0.379752; batch adversarial loss: 0.592974\n",
      "epoch 46; iter: 0; batch classifier loss: 0.562805; batch adversarial loss: 0.703081\n",
      "epoch 46; iter: 200; batch classifier loss: 0.258206; batch adversarial loss: 0.645099\n",
      "epoch 46; iter: 400; batch classifier loss: 0.577636; batch adversarial loss: 0.588281\n",
      "epoch 47; iter: 0; batch classifier loss: 0.296315; batch adversarial loss: 0.694946\n",
      "epoch 47; iter: 200; batch classifier loss: 0.425726; batch adversarial loss: 0.547143\n",
      "epoch 47; iter: 400; batch classifier loss: 0.573635; batch adversarial loss: 0.635499\n",
      "epoch 48; iter: 0; batch classifier loss: 0.448200; batch adversarial loss: 0.623514\n",
      "epoch 48; iter: 200; batch classifier loss: 0.423638; batch adversarial loss: 0.567348\n",
      "epoch 48; iter: 400; batch classifier loss: 0.599902; batch adversarial loss: 0.562817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.759362; batch adversarial loss: 0.677166\n",
      "epoch 49; iter: 200; batch classifier loss: 0.408509; batch adversarial loss: 0.581785\n",
      "epoch 49; iter: 400; batch classifier loss: 0.346969; batch adversarial loss: 0.686003\n",
      "epoch 0; iter: 0; batch classifier loss: 25.123718; batch adversarial loss: 0.748319\n",
      "epoch 0; iter: 200; batch classifier loss: 7.849180; batch adversarial loss: 0.676246\n",
      "epoch 0; iter: 400; batch classifier loss: 5.758203; batch adversarial loss: 0.675999\n",
      "epoch 1; iter: 0; batch classifier loss: 6.196159; batch adversarial loss: 0.648673\n",
      "epoch 1; iter: 200; batch classifier loss: 0.973242; batch adversarial loss: 0.624570\n",
      "epoch 1; iter: 400; batch classifier loss: 2.341203; batch adversarial loss: 0.662532\n",
      "epoch 2; iter: 0; batch classifier loss: 0.934259; batch adversarial loss: 0.625541\n",
      "epoch 2; iter: 200; batch classifier loss: 0.470467; batch adversarial loss: 0.653105\n",
      "epoch 2; iter: 400; batch classifier loss: 0.764746; batch adversarial loss: 0.632193\n",
      "epoch 3; iter: 0; batch classifier loss: 4.046127; batch adversarial loss: 0.593116\n",
      "epoch 3; iter: 200; batch classifier loss: 1.597515; batch adversarial loss: 0.672906\n",
      "epoch 3; iter: 400; batch classifier loss: 3.275099; batch adversarial loss: 0.598773\n",
      "epoch 4; iter: 0; batch classifier loss: 0.333818; batch adversarial loss: 0.602755\n",
      "epoch 4; iter: 200; batch classifier loss: 1.121060; batch adversarial loss: 0.651817\n",
      "epoch 4; iter: 400; batch classifier loss: 0.294113; batch adversarial loss: 0.674173\n",
      "epoch 5; iter: 0; batch classifier loss: 0.992887; batch adversarial loss: 0.636166\n",
      "epoch 5; iter: 200; batch classifier loss: 0.461122; batch adversarial loss: 0.643436\n",
      "epoch 5; iter: 400; batch classifier loss: 0.409868; batch adversarial loss: 0.588116\n",
      "epoch 6; iter: 0; batch classifier loss: 0.762569; batch adversarial loss: 0.536031\n",
      "epoch 6; iter: 200; batch classifier loss: 0.350593; batch adversarial loss: 0.691186\n",
      "epoch 6; iter: 400; batch classifier loss: 0.680506; batch adversarial loss: 0.685760\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507953; batch adversarial loss: 0.603221\n",
      "epoch 7; iter: 200; batch classifier loss: 0.518746; batch adversarial loss: 0.701910\n",
      "epoch 7; iter: 400; batch classifier loss: 0.377476; batch adversarial loss: 0.568910\n",
      "epoch 8; iter: 0; batch classifier loss: 0.323485; batch adversarial loss: 0.661041\n",
      "epoch 8; iter: 200; batch classifier loss: 1.151390; batch adversarial loss: 0.646237\n",
      "epoch 8; iter: 400; batch classifier loss: 0.385216; batch adversarial loss: 0.640523\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346268; batch adversarial loss: 0.659421\n",
      "epoch 9; iter: 200; batch classifier loss: 0.337254; batch adversarial loss: 0.592039\n",
      "epoch 9; iter: 400; batch classifier loss: 0.370807; batch adversarial loss: 0.613924\n",
      "epoch 10; iter: 0; batch classifier loss: 0.447493; batch adversarial loss: 0.584381\n",
      "epoch 10; iter: 200; batch classifier loss: 0.372167; batch adversarial loss: 0.603678\n",
      "epoch 10; iter: 400; batch classifier loss: 0.323235; batch adversarial loss: 0.673303\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343628; batch adversarial loss: 0.599643\n",
      "epoch 11; iter: 200; batch classifier loss: 0.369607; batch adversarial loss: 0.600380\n",
      "epoch 11; iter: 400; batch classifier loss: 0.278110; batch adversarial loss: 0.620502\n",
      "epoch 12; iter: 0; batch classifier loss: 0.384341; batch adversarial loss: 0.595274\n",
      "epoch 12; iter: 200; batch classifier loss: 0.248297; batch adversarial loss: 0.563566\n",
      "epoch 12; iter: 400; batch classifier loss: 0.407561; batch adversarial loss: 0.591024\n",
      "epoch 13; iter: 0; batch classifier loss: 0.345392; batch adversarial loss: 0.660741\n",
      "epoch 13; iter: 200; batch classifier loss: 0.337597; batch adversarial loss: 0.649025\n",
      "epoch 13; iter: 400; batch classifier loss: 0.425220; batch adversarial loss: 0.605696\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477088; batch adversarial loss: 0.625600\n",
      "epoch 14; iter: 200; batch classifier loss: 0.357027; batch adversarial loss: 0.610133\n",
      "epoch 14; iter: 400; batch classifier loss: 0.350379; batch adversarial loss: 0.572751\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307477; batch adversarial loss: 0.531737\n",
      "epoch 15; iter: 200; batch classifier loss: 0.285593; batch adversarial loss: 0.638731\n",
      "epoch 15; iter: 400; batch classifier loss: 0.406451; batch adversarial loss: 0.582625\n",
      "epoch 16; iter: 0; batch classifier loss: 0.431800; batch adversarial loss: 0.622455\n",
      "epoch 16; iter: 200; batch classifier loss: 0.450987; batch adversarial loss: 0.512179\n",
      "epoch 16; iter: 400; batch classifier loss: 0.339852; batch adversarial loss: 0.605313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368724; batch adversarial loss: 0.567184\n",
      "epoch 17; iter: 200; batch classifier loss: 0.422126; batch adversarial loss: 0.693822\n",
      "epoch 17; iter: 400; batch classifier loss: 0.325663; batch adversarial loss: 0.600626\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319621; batch adversarial loss: 0.562952\n",
      "epoch 18; iter: 200; batch classifier loss: 0.294989; batch adversarial loss: 0.574796\n",
      "epoch 18; iter: 400; batch classifier loss: 0.259421; batch adversarial loss: 0.656733\n",
      "epoch 19; iter: 0; batch classifier loss: 0.415980; batch adversarial loss: 0.576523\n",
      "epoch 19; iter: 200; batch classifier loss: 0.384663; batch adversarial loss: 0.562592\n",
      "epoch 19; iter: 400; batch classifier loss: 0.191812; batch adversarial loss: 0.584349\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356061; batch adversarial loss: 0.610950\n",
      "epoch 20; iter: 200; batch classifier loss: 0.423911; batch adversarial loss: 0.626848\n",
      "epoch 20; iter: 400; batch classifier loss: 0.536183; batch adversarial loss: 0.630477\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495701; batch adversarial loss: 0.610573\n",
      "epoch 21; iter: 200; batch classifier loss: 0.465460; batch adversarial loss: 0.725147\n",
      "epoch 21; iter: 400; batch classifier loss: 0.298823; batch adversarial loss: 0.626439\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472291; batch adversarial loss: 0.613362\n",
      "epoch 22; iter: 200; batch classifier loss: 0.481782; batch adversarial loss: 0.529592\n",
      "epoch 22; iter: 400; batch classifier loss: 0.377637; batch adversarial loss: 0.622205\n",
      "epoch 23; iter: 0; batch classifier loss: 0.352601; batch adversarial loss: 0.612351\n",
      "epoch 23; iter: 200; batch classifier loss: 0.479080; batch adversarial loss: 0.582664\n",
      "epoch 23; iter: 400; batch classifier loss: 0.175642; batch adversarial loss: 0.675898\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491111; batch adversarial loss: 0.613636\n",
      "epoch 24; iter: 200; batch classifier loss: 0.517977; batch adversarial loss: 0.641210\n",
      "epoch 24; iter: 400; batch classifier loss: 0.512713; batch adversarial loss: 0.548843\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262158; batch adversarial loss: 0.648705\n",
      "epoch 25; iter: 200; batch classifier loss: 0.384404; batch adversarial loss: 0.565907\n",
      "epoch 25; iter: 400; batch classifier loss: 0.337111; batch adversarial loss: 0.596811\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319613; batch adversarial loss: 0.637863\n",
      "epoch 26; iter: 200; batch classifier loss: 0.408841; batch adversarial loss: 0.556496\n",
      "epoch 26; iter: 400; batch classifier loss: 0.490134; batch adversarial loss: 0.650672\n",
      "epoch 27; iter: 0; batch classifier loss: 0.426973; batch adversarial loss: 0.581302\n",
      "epoch 27; iter: 200; batch classifier loss: 0.395219; batch adversarial loss: 0.570154\n",
      "epoch 27; iter: 400; batch classifier loss: 0.497428; batch adversarial loss: 0.714774\n",
      "epoch 28; iter: 0; batch classifier loss: 0.332261; batch adversarial loss: 0.574587\n",
      "epoch 28; iter: 200; batch classifier loss: 0.506006; batch adversarial loss: 0.612752\n",
      "epoch 28; iter: 400; batch classifier loss: 0.310499; batch adversarial loss: 0.518339\n",
      "epoch 29; iter: 0; batch classifier loss: 0.521878; batch adversarial loss: 0.610439\n",
      "epoch 29; iter: 200; batch classifier loss: 0.371377; batch adversarial loss: 0.640956\n",
      "epoch 29; iter: 400; batch classifier loss: 0.395775; batch adversarial loss: 0.647826\n",
      "epoch 30; iter: 0; batch classifier loss: 0.334540; batch adversarial loss: 0.601021\n",
      "epoch 30; iter: 200; batch classifier loss: 0.459339; batch adversarial loss: 0.632194\n",
      "epoch 30; iter: 400; batch classifier loss: 0.445071; batch adversarial loss: 0.570986\n",
      "epoch 31; iter: 0; batch classifier loss: 0.564777; batch adversarial loss: 0.707518\n",
      "epoch 31; iter: 200; batch classifier loss: 0.396576; batch adversarial loss: 0.674746\n",
      "epoch 31; iter: 400; batch classifier loss: 0.528054; batch adversarial loss: 0.603485\n",
      "epoch 32; iter: 0; batch classifier loss: 0.357197; batch adversarial loss: 0.576662\n",
      "epoch 32; iter: 200; batch classifier loss: 0.329065; batch adversarial loss: 0.636057\n",
      "epoch 32; iter: 400; batch classifier loss: 0.320282; batch adversarial loss: 0.660813\n",
      "epoch 33; iter: 0; batch classifier loss: 1.142608; batch adversarial loss: 0.623078\n",
      "epoch 33; iter: 200; batch classifier loss: 0.913208; batch adversarial loss: 0.613113\n",
      "epoch 33; iter: 400; batch classifier loss: 0.391074; batch adversarial loss: 0.577450\n",
      "epoch 34; iter: 0; batch classifier loss: 0.280333; batch adversarial loss: 0.558242\n",
      "epoch 34; iter: 200; batch classifier loss: 0.667386; batch adversarial loss: 0.691794\n",
      "epoch 34; iter: 400; batch classifier loss: 0.297011; batch adversarial loss: 0.557855\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485668; batch adversarial loss: 0.661348\n",
      "epoch 35; iter: 200; batch classifier loss: 0.378783; batch adversarial loss: 0.654065\n",
      "epoch 35; iter: 400; batch classifier loss: 0.632417; batch adversarial loss: 0.602003\n",
      "epoch 36; iter: 0; batch classifier loss: 0.306952; batch adversarial loss: 0.655406\n",
      "epoch 36; iter: 200; batch classifier loss: 0.438525; batch adversarial loss: 0.684346\n",
      "epoch 36; iter: 400; batch classifier loss: 0.349165; batch adversarial loss: 0.620299\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388279; batch adversarial loss: 0.575082\n",
      "epoch 37; iter: 200; batch classifier loss: 0.488145; batch adversarial loss: 0.597343\n",
      "epoch 37; iter: 400; batch classifier loss: 0.318168; batch adversarial loss: 0.597664\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476864; batch adversarial loss: 0.585156\n",
      "epoch 38; iter: 200; batch classifier loss: 0.493300; batch adversarial loss: 0.566183\n",
      "epoch 38; iter: 400; batch classifier loss: 0.559855; batch adversarial loss: 0.675078\n",
      "epoch 39; iter: 0; batch classifier loss: 0.615474; batch adversarial loss: 0.555400\n",
      "epoch 39; iter: 200; batch classifier loss: 0.470539; batch adversarial loss: 0.610892\n",
      "epoch 39; iter: 400; batch classifier loss: 0.336250; batch adversarial loss: 0.564378\n",
      "epoch 40; iter: 0; batch classifier loss: 0.355479; batch adversarial loss: 0.669837\n",
      "epoch 40; iter: 200; batch classifier loss: 0.535509; batch adversarial loss: 0.663740\n",
      "epoch 40; iter: 400; batch classifier loss: 0.529650; batch adversarial loss: 0.652239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.498087; batch adversarial loss: 0.562675\n",
      "epoch 41; iter: 200; batch classifier loss: 0.254791; batch adversarial loss: 0.578794\n",
      "epoch 41; iter: 400; batch classifier loss: 0.484320; batch adversarial loss: 0.578260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431933; batch adversarial loss: 0.607145\n",
      "epoch 42; iter: 200; batch classifier loss: 0.574094; batch adversarial loss: 0.621382\n",
      "epoch 42; iter: 400; batch classifier loss: 0.414107; batch adversarial loss: 0.670791\n",
      "epoch 43; iter: 0; batch classifier loss: 0.456346; batch adversarial loss: 0.659021\n",
      "epoch 43; iter: 200; batch classifier loss: 0.419006; batch adversarial loss: 0.667786\n",
      "epoch 43; iter: 400; batch classifier loss: 0.449977; batch adversarial loss: 0.733358\n",
      "epoch 44; iter: 0; batch classifier loss: 0.491395; batch adversarial loss: 0.580681\n",
      "epoch 44; iter: 200; batch classifier loss: 0.485381; batch adversarial loss: 0.545935\n",
      "epoch 44; iter: 400; batch classifier loss: 0.287461; batch adversarial loss: 0.588470\n",
      "epoch 45; iter: 0; batch classifier loss: 0.386984; batch adversarial loss: 0.676803\n",
      "epoch 45; iter: 200; batch classifier loss: 0.480545; batch adversarial loss: 0.631680\n",
      "epoch 45; iter: 400; batch classifier loss: 0.519737; batch adversarial loss: 0.632320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.301169; batch adversarial loss: 0.581509\n",
      "epoch 46; iter: 200; batch classifier loss: 0.563578; batch adversarial loss: 0.647092\n",
      "epoch 46; iter: 400; batch classifier loss: 0.357033; batch adversarial loss: 0.674891\n",
      "epoch 47; iter: 0; batch classifier loss: 0.724044; batch adversarial loss: 0.587449\n",
      "epoch 47; iter: 200; batch classifier loss: 0.480932; batch adversarial loss: 0.622811\n",
      "epoch 47; iter: 400; batch classifier loss: 0.422111; batch adversarial loss: 0.657141\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371083; batch adversarial loss: 0.671826\n",
      "epoch 48; iter: 200; batch classifier loss: 0.411081; batch adversarial loss: 0.617340\n",
      "epoch 48; iter: 400; batch classifier loss: 0.565683; batch adversarial loss: 0.554742\n",
      "epoch 49; iter: 0; batch classifier loss: 0.540557; batch adversarial loss: 0.684399\n",
      "epoch 49; iter: 200; batch classifier loss: 0.670547; batch adversarial loss: 0.659725\n",
      "epoch 49; iter: 400; batch classifier loss: 0.224117; batch adversarial loss: 0.710781\n",
      "epoch 0; iter: 0; batch classifier loss: 6.578314; batch adversarial loss: 0.976833\n",
      "epoch 0; iter: 200; batch classifier loss: 2.059608; batch adversarial loss: 0.703688\n",
      "epoch 0; iter: 400; batch classifier loss: 53.758011; batch adversarial loss: 0.673069\n",
      "epoch 1; iter: 0; batch classifier loss: 13.477815; batch adversarial loss: 0.673972\n",
      "epoch 1; iter: 200; batch classifier loss: 2.909726; batch adversarial loss: 0.661319\n",
      "epoch 1; iter: 400; batch classifier loss: 5.915196; batch adversarial loss: 0.642866\n",
      "epoch 2; iter: 0; batch classifier loss: 5.127757; batch adversarial loss: 0.711812\n",
      "epoch 2; iter: 200; batch classifier loss: 0.662434; batch adversarial loss: 0.689822\n",
      "epoch 2; iter: 400; batch classifier loss: 0.334696; batch adversarial loss: 0.595086\n",
      "epoch 3; iter: 0; batch classifier loss: 1.838547; batch adversarial loss: 0.630856\n",
      "epoch 3; iter: 200; batch classifier loss: 0.507513; batch adversarial loss: 0.618801\n",
      "epoch 3; iter: 400; batch classifier loss: 0.937891; batch adversarial loss: 0.672818\n",
      "epoch 4; iter: 0; batch classifier loss: 0.298340; batch adversarial loss: 0.592036\n",
      "epoch 4; iter: 200; batch classifier loss: 1.463552; batch adversarial loss: 0.621456\n",
      "epoch 4; iter: 400; batch classifier loss: 0.354341; batch adversarial loss: 0.618601\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621127; batch adversarial loss: 0.643447\n",
      "epoch 5; iter: 200; batch classifier loss: 0.473866; batch adversarial loss: 0.628534\n",
      "epoch 5; iter: 400; batch classifier loss: 0.301021; batch adversarial loss: 0.638473\n",
      "epoch 6; iter: 0; batch classifier loss: 0.403492; batch adversarial loss: 0.597858\n",
      "epoch 6; iter: 200; batch classifier loss: 0.607704; batch adversarial loss: 0.635894\n",
      "epoch 6; iter: 400; batch classifier loss: 0.585998; batch adversarial loss: 0.594665\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493173; batch adversarial loss: 0.658357\n",
      "epoch 7; iter: 200; batch classifier loss: 0.294445; batch adversarial loss: 0.660178\n",
      "epoch 7; iter: 400; batch classifier loss: 0.369619; batch adversarial loss: 0.608872\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508304; batch adversarial loss: 0.643222\n",
      "epoch 8; iter: 200; batch classifier loss: 1.399208; batch adversarial loss: 0.598218\n",
      "epoch 8; iter: 400; batch classifier loss: 0.411884; batch adversarial loss: 0.589273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.326047; batch adversarial loss: 0.650428\n",
      "epoch 9; iter: 200; batch classifier loss: 0.457081; batch adversarial loss: 0.619298\n",
      "epoch 9; iter: 400; batch classifier loss: 0.263075; batch adversarial loss: 0.650068\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472491; batch adversarial loss: 0.646962\n",
      "epoch 10; iter: 200; batch classifier loss: 0.398866; batch adversarial loss: 0.607510\n",
      "epoch 10; iter: 400; batch classifier loss: 0.478792; batch adversarial loss: 0.593516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.312086; batch adversarial loss: 0.568140\n",
      "epoch 11; iter: 200; batch classifier loss: 0.370082; batch adversarial loss: 0.667051\n",
      "epoch 11; iter: 400; batch classifier loss: 0.426922; batch adversarial loss: 0.552438\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440117; batch adversarial loss: 0.638592\n",
      "epoch 12; iter: 200; batch classifier loss: 0.348267; batch adversarial loss: 0.573472\n",
      "epoch 12; iter: 400; batch classifier loss: 0.316922; batch adversarial loss: 0.604571\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392925; batch adversarial loss: 0.598117\n",
      "epoch 13; iter: 200; batch classifier loss: 0.280371; batch adversarial loss: 0.593812\n",
      "epoch 13; iter: 400; batch classifier loss: 0.363256; batch adversarial loss: 0.636577\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322120; batch adversarial loss: 0.565912\n",
      "epoch 14; iter: 200; batch classifier loss: 0.261651; batch adversarial loss: 0.641110\n",
      "epoch 14; iter: 400; batch classifier loss: 0.451644; batch adversarial loss: 0.618773\n",
      "epoch 15; iter: 0; batch classifier loss: 0.419633; batch adversarial loss: 0.609430\n",
      "epoch 15; iter: 200; batch classifier loss: 0.431479; batch adversarial loss: 0.559949\n",
      "epoch 15; iter: 400; batch classifier loss: 0.312428; batch adversarial loss: 0.674458\n",
      "epoch 16; iter: 0; batch classifier loss: 0.521483; batch adversarial loss: 0.647180\n",
      "epoch 16; iter: 200; batch classifier loss: 0.245882; batch adversarial loss: 0.702472\n",
      "epoch 16; iter: 400; batch classifier loss: 0.369559; batch adversarial loss: 0.567313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357200; batch adversarial loss: 0.643116\n",
      "epoch 17; iter: 200; batch classifier loss: 0.340206; batch adversarial loss: 0.566557\n",
      "epoch 17; iter: 400; batch classifier loss: 0.316980; batch adversarial loss: 0.632286\n",
      "epoch 18; iter: 0; batch classifier loss: 0.356080; batch adversarial loss: 0.608038\n",
      "epoch 18; iter: 200; batch classifier loss: 0.312300; batch adversarial loss: 0.593037\n",
      "epoch 18; iter: 400; batch classifier loss: 0.309221; batch adversarial loss: 0.579690\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476295; batch adversarial loss: 0.595121\n",
      "epoch 19; iter: 200; batch classifier loss: 0.202472; batch adversarial loss: 0.629000\n",
      "epoch 19; iter: 400; batch classifier loss: 0.296528; batch adversarial loss: 0.602973\n",
      "epoch 20; iter: 0; batch classifier loss: 0.326275; batch adversarial loss: 0.660273\n",
      "epoch 20; iter: 200; batch classifier loss: 0.242245; batch adversarial loss: 0.628032\n",
      "epoch 20; iter: 400; batch classifier loss: 0.312123; batch adversarial loss: 0.681365\n",
      "epoch 21; iter: 0; batch classifier loss: 0.490210; batch adversarial loss: 0.594321\n",
      "epoch 21; iter: 200; batch classifier loss: 0.318843; batch adversarial loss: 0.648562\n",
      "epoch 21; iter: 400; batch classifier loss: 0.467211; batch adversarial loss: 0.674544\n",
      "epoch 22; iter: 0; batch classifier loss: 0.346200; batch adversarial loss: 0.587535\n",
      "epoch 22; iter: 200; batch classifier loss: 0.362020; batch adversarial loss: 0.689454\n",
      "epoch 22; iter: 400; batch classifier loss: 0.274854; batch adversarial loss: 0.566407\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430177; batch adversarial loss: 0.645184\n",
      "epoch 23; iter: 200; batch classifier loss: 0.280050; batch adversarial loss: 0.613126\n",
      "epoch 23; iter: 400; batch classifier loss: 0.297070; batch adversarial loss: 0.612898\n",
      "epoch 24; iter: 0; batch classifier loss: 0.395640; batch adversarial loss: 0.651615\n",
      "epoch 24; iter: 200; batch classifier loss: 0.367141; batch adversarial loss: 0.617312\n",
      "epoch 24; iter: 400; batch classifier loss: 0.391461; batch adversarial loss: 0.621500\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326888; batch adversarial loss: 0.649000\n",
      "epoch 25; iter: 200; batch classifier loss: 0.415012; batch adversarial loss: 0.611625\n",
      "epoch 25; iter: 400; batch classifier loss: 0.334315; batch adversarial loss: 0.601283\n",
      "epoch 26; iter: 0; batch classifier loss: 0.555499; batch adversarial loss: 0.640013\n",
      "epoch 26; iter: 200; batch classifier loss: 0.437658; batch adversarial loss: 0.694026\n",
      "epoch 26; iter: 400; batch classifier loss: 0.542686; batch adversarial loss: 0.584692\n",
      "epoch 27; iter: 0; batch classifier loss: 0.557208; batch adversarial loss: 0.560971\n",
      "epoch 27; iter: 200; batch classifier loss: 0.269585; batch adversarial loss: 0.661557\n",
      "epoch 27; iter: 400; batch classifier loss: 0.464488; batch adversarial loss: 0.634116\n",
      "epoch 28; iter: 0; batch classifier loss: 0.256498; batch adversarial loss: 0.659497\n",
      "epoch 28; iter: 200; batch classifier loss: 0.307796; batch adversarial loss: 0.633303\n",
      "epoch 28; iter: 400; batch classifier loss: 0.366171; batch adversarial loss: 0.625891\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388337; batch adversarial loss: 0.611660\n",
      "epoch 29; iter: 200; batch classifier loss: 0.369237; batch adversarial loss: 0.536819\n",
      "epoch 29; iter: 400; batch classifier loss: 0.531804; batch adversarial loss: 0.649809\n",
      "epoch 30; iter: 0; batch classifier loss: 0.357936; batch adversarial loss: 0.606893\n",
      "epoch 30; iter: 200; batch classifier loss: 0.268675; batch adversarial loss: 0.645021\n",
      "epoch 30; iter: 400; batch classifier loss: 0.451931; batch adversarial loss: 0.634367\n",
      "epoch 31; iter: 0; batch classifier loss: 0.327944; batch adversarial loss: 0.629845\n",
      "epoch 31; iter: 200; batch classifier loss: 0.322786; batch adversarial loss: 0.599037\n",
      "epoch 31; iter: 400; batch classifier loss: 0.740468; batch adversarial loss: 0.611775\n",
      "epoch 32; iter: 0; batch classifier loss: 0.515726; batch adversarial loss: 0.626007\n",
      "epoch 32; iter: 200; batch classifier loss: 0.403996; batch adversarial loss: 0.645007\n",
      "epoch 32; iter: 400; batch classifier loss: 0.406854; batch adversarial loss: 0.666878\n",
      "epoch 33; iter: 0; batch classifier loss: 0.568192; batch adversarial loss: 0.655880\n",
      "epoch 33; iter: 200; batch classifier loss: 0.345857; batch adversarial loss: 0.649301\n",
      "epoch 33; iter: 400; batch classifier loss: 0.373907; batch adversarial loss: 0.653864\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435863; batch adversarial loss: 0.647664\n",
      "epoch 34; iter: 200; batch classifier loss: 0.326806; batch adversarial loss: 0.711485\n",
      "epoch 34; iter: 400; batch classifier loss: 0.496749; batch adversarial loss: 0.639918\n",
      "epoch 35; iter: 0; batch classifier loss: 0.321887; batch adversarial loss: 0.622645\n",
      "epoch 35; iter: 200; batch classifier loss: 0.453440; batch adversarial loss: 0.672617\n",
      "epoch 35; iter: 400; batch classifier loss: 0.382780; batch adversarial loss: 0.677781\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390076; batch adversarial loss: 0.605610\n",
      "epoch 36; iter: 200; batch classifier loss: 0.505653; batch adversarial loss: 0.618537\n",
      "epoch 36; iter: 400; batch classifier loss: 0.516656; batch adversarial loss: 0.670776\n",
      "epoch 37; iter: 0; batch classifier loss: 0.349985; batch adversarial loss: 0.740106\n",
      "epoch 37; iter: 200; batch classifier loss: 0.382798; batch adversarial loss: 0.662864\n",
      "epoch 37; iter: 400; batch classifier loss: 0.506709; batch adversarial loss: 0.636802\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382438; batch adversarial loss: 0.658153\n",
      "epoch 38; iter: 200; batch classifier loss: 0.497776; batch adversarial loss: 0.597621\n",
      "epoch 38; iter: 400; batch classifier loss: 0.404254; batch adversarial loss: 0.608511\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435199; batch adversarial loss: 0.624347\n",
      "epoch 39; iter: 200; batch classifier loss: 0.586726; batch adversarial loss: 0.591985\n",
      "epoch 39; iter: 400; batch classifier loss: 0.553057; batch adversarial loss: 0.605790\n",
      "epoch 40; iter: 0; batch classifier loss: 0.245653; batch adversarial loss: 0.625967\n",
      "epoch 40; iter: 200; batch classifier loss: 0.465099; batch adversarial loss: 0.632192\n",
      "epoch 40; iter: 400; batch classifier loss: 0.378889; batch adversarial loss: 0.564227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.478163; batch adversarial loss: 0.563244\n",
      "epoch 41; iter: 200; batch classifier loss: 0.537207; batch adversarial loss: 0.594509\n",
      "epoch 41; iter: 400; batch classifier loss: 0.479923; batch adversarial loss: 0.651034\n",
      "epoch 42; iter: 0; batch classifier loss: 0.479931; batch adversarial loss: 0.581579\n",
      "epoch 42; iter: 200; batch classifier loss: 0.274031; batch adversarial loss: 0.708242\n",
      "epoch 42; iter: 400; batch classifier loss: 0.623122; batch adversarial loss: 0.651489\n",
      "epoch 43; iter: 0; batch classifier loss: 0.282231; batch adversarial loss: 0.560320\n",
      "epoch 43; iter: 200; batch classifier loss: 0.533219; batch adversarial loss: 0.607194\n",
      "epoch 43; iter: 400; batch classifier loss: 0.229064; batch adversarial loss: 0.692335\n",
      "epoch 44; iter: 0; batch classifier loss: 0.411902; batch adversarial loss: 0.581857\n",
      "epoch 44; iter: 200; batch classifier loss: 0.353254; batch adversarial loss: 0.611667\n",
      "epoch 44; iter: 400; batch classifier loss: 0.293244; batch adversarial loss: 0.587535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.340690; batch adversarial loss: 0.629677\n",
      "epoch 45; iter: 200; batch classifier loss: 0.394291; batch adversarial loss: 0.601658\n",
      "epoch 45; iter: 400; batch classifier loss: 0.419212; batch adversarial loss: 0.591140\n",
      "epoch 46; iter: 0; batch classifier loss: 0.523579; batch adversarial loss: 0.642223\n",
      "epoch 46; iter: 200; batch classifier loss: 0.489230; batch adversarial loss: 0.689869\n",
      "epoch 46; iter: 400; batch classifier loss: 0.349358; batch adversarial loss: 0.643822\n",
      "epoch 47; iter: 0; batch classifier loss: 0.246117; batch adversarial loss: 0.605823\n",
      "epoch 47; iter: 200; batch classifier loss: 0.360974; batch adversarial loss: 0.622620\n",
      "epoch 47; iter: 400; batch classifier loss: 0.306004; batch adversarial loss: 0.650158\n",
      "epoch 48; iter: 0; batch classifier loss: 0.518850; batch adversarial loss: 0.599909\n",
      "epoch 48; iter: 200; batch classifier loss: 0.639376; batch adversarial loss: 0.635008\n",
      "epoch 48; iter: 400; batch classifier loss: 0.584675; batch adversarial loss: 0.667687\n",
      "epoch 49; iter: 0; batch classifier loss: 0.381531; batch adversarial loss: 0.625648\n",
      "epoch 49; iter: 200; batch classifier loss: 0.432669; batch adversarial loss: 0.571209\n",
      "epoch 49; iter: 400; batch classifier loss: 0.732843; batch adversarial loss: 0.616140\n",
      "epoch 0; iter: 0; batch classifier loss: 29.791027; batch adversarial loss: 0.717064\n",
      "epoch 0; iter: 200; batch classifier loss: 4.891575; batch adversarial loss: 0.667921\n",
      "epoch 0; iter: 400; batch classifier loss: 13.189319; batch adversarial loss: 0.624387\n",
      "epoch 1; iter: 0; batch classifier loss: 6.920424; batch adversarial loss: 0.594516\n",
      "epoch 1; iter: 200; batch classifier loss: 3.745520; batch adversarial loss: 0.586345\n",
      "epoch 1; iter: 400; batch classifier loss: 5.922455; batch adversarial loss: 0.584501\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652600; batch adversarial loss: 0.608108\n",
      "epoch 2; iter: 200; batch classifier loss: 8.390918; batch adversarial loss: 0.572221\n",
      "epoch 2; iter: 400; batch classifier loss: 2.102502; batch adversarial loss: 0.652164\n",
      "epoch 3; iter: 0; batch classifier loss: 2.697160; batch adversarial loss: 0.640996\n",
      "epoch 3; iter: 200; batch classifier loss: 0.393040; batch adversarial loss: 0.592062\n",
      "epoch 3; iter: 400; batch classifier loss: 1.086760; batch adversarial loss: 0.705584\n",
      "epoch 4; iter: 0; batch classifier loss: 2.511433; batch adversarial loss: 0.615712\n",
      "epoch 4; iter: 200; batch classifier loss: 1.295417; batch adversarial loss: 0.592399\n",
      "epoch 4; iter: 400; batch classifier loss: 0.448622; batch adversarial loss: 0.625051\n",
      "epoch 5; iter: 0; batch classifier loss: 2.269360; batch adversarial loss: 0.622711\n",
      "epoch 5; iter: 200; batch classifier loss: 0.810765; batch adversarial loss: 0.642551\n",
      "epoch 5; iter: 400; batch classifier loss: 0.782367; batch adversarial loss: 0.652869\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414830; batch adversarial loss: 0.633936\n",
      "epoch 6; iter: 200; batch classifier loss: 0.387878; batch adversarial loss: 0.635586\n",
      "epoch 6; iter: 400; batch classifier loss: 0.453095; batch adversarial loss: 0.635766\n",
      "epoch 7; iter: 0; batch classifier loss: 0.333673; batch adversarial loss: 0.647795\n",
      "epoch 7; iter: 200; batch classifier loss: 0.888638; batch adversarial loss: 0.625023\n",
      "epoch 7; iter: 400; batch classifier loss: 0.546613; batch adversarial loss: 0.624177\n",
      "epoch 8; iter: 0; batch classifier loss: 0.346776; batch adversarial loss: 0.647520\n",
      "epoch 8; iter: 200; batch classifier loss: 0.374822; batch adversarial loss: 0.565197\n",
      "epoch 8; iter: 400; batch classifier loss: 0.494123; batch adversarial loss: 0.652925\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314744; batch adversarial loss: 0.632170\n",
      "epoch 9; iter: 200; batch classifier loss: 0.595629; batch adversarial loss: 0.614935\n",
      "epoch 9; iter: 400; batch classifier loss: 0.618205; batch adversarial loss: 0.649456\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302004; batch adversarial loss: 0.651138\n",
      "epoch 10; iter: 200; batch classifier loss: 0.389042; batch adversarial loss: 0.625297\n",
      "epoch 10; iter: 400; batch classifier loss: 0.418138; batch adversarial loss: 0.642087\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491326; batch adversarial loss: 0.670201\n",
      "epoch 11; iter: 200; batch classifier loss: 0.272803; batch adversarial loss: 0.612522\n",
      "epoch 11; iter: 400; batch classifier loss: 0.546324; batch adversarial loss: 0.591040\n",
      "epoch 12; iter: 0; batch classifier loss: 0.336067; batch adversarial loss: 0.648149\n",
      "epoch 12; iter: 200; batch classifier loss: 0.232038; batch adversarial loss: 0.614280\n",
      "epoch 12; iter: 400; batch classifier loss: 0.538714; batch adversarial loss: 0.642981\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370576; batch adversarial loss: 0.607596\n",
      "epoch 13; iter: 200; batch classifier loss: 0.496489; batch adversarial loss: 0.589902\n",
      "epoch 13; iter: 400; batch classifier loss: 0.337199; batch adversarial loss: 0.651499\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442192; batch adversarial loss: 0.685178\n",
      "epoch 14; iter: 200; batch classifier loss: 0.213877; batch adversarial loss: 0.694015\n",
      "epoch 14; iter: 400; batch classifier loss: 0.332066; batch adversarial loss: 0.692297\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274638; batch adversarial loss: 0.647824\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341487; batch adversarial loss: 0.598224\n",
      "epoch 15; iter: 400; batch classifier loss: 0.361304; batch adversarial loss: 0.628134\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468856; batch adversarial loss: 0.617284\n",
      "epoch 16; iter: 200; batch classifier loss: 0.287585; batch adversarial loss: 0.636087\n",
      "epoch 16; iter: 400; batch classifier loss: 0.490760; batch adversarial loss: 0.606440\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398918; batch adversarial loss: 0.573289\n",
      "epoch 17; iter: 200; batch classifier loss: 0.245565; batch adversarial loss: 0.664199\n",
      "epoch 17; iter: 400; batch classifier loss: 0.332378; batch adversarial loss: 0.544962\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371588; batch adversarial loss: 0.584386\n",
      "epoch 18; iter: 200; batch classifier loss: 0.347386; batch adversarial loss: 0.586328\n",
      "epoch 18; iter: 400; batch classifier loss: 0.314592; batch adversarial loss: 0.594299\n",
      "epoch 19; iter: 0; batch classifier loss: 0.497231; batch adversarial loss: 0.609611\n",
      "epoch 19; iter: 200; batch classifier loss: 0.409436; batch adversarial loss: 0.634538\n",
      "epoch 19; iter: 400; batch classifier loss: 0.349663; batch adversarial loss: 0.643671\n",
      "epoch 20; iter: 0; batch classifier loss: 0.362899; batch adversarial loss: 0.630727\n",
      "epoch 20; iter: 200; batch classifier loss: 0.369246; batch adversarial loss: 0.672568\n",
      "epoch 20; iter: 400; batch classifier loss: 0.556114; batch adversarial loss: 0.670002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427531; batch adversarial loss: 0.589265\n",
      "epoch 21; iter: 200; batch classifier loss: 0.366870; batch adversarial loss: 0.582382\n",
      "epoch 21; iter: 400; batch classifier loss: 0.265898; batch adversarial loss: 0.631873\n",
      "epoch 22; iter: 0; batch classifier loss: 0.320475; batch adversarial loss: 0.602498\n",
      "epoch 22; iter: 200; batch classifier loss: 0.347307; batch adversarial loss: 0.628751\n",
      "epoch 22; iter: 400; batch classifier loss: 0.608547; batch adversarial loss: 0.587930\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473714; batch adversarial loss: 0.693195\n",
      "epoch 23; iter: 200; batch classifier loss: 0.421925; batch adversarial loss: 0.663746\n",
      "epoch 23; iter: 400; batch classifier loss: 0.440045; batch adversarial loss: 0.601103\n",
      "epoch 24; iter: 0; batch classifier loss: 0.291337; batch adversarial loss: 0.664389\n",
      "epoch 24; iter: 200; batch classifier loss: 0.470681; batch adversarial loss: 0.556122\n",
      "epoch 24; iter: 400; batch classifier loss: 0.367027; batch adversarial loss: 0.658234\n",
      "epoch 25; iter: 0; batch classifier loss: 0.229261; batch adversarial loss: 0.632418\n",
      "epoch 25; iter: 200; batch classifier loss: 0.401831; batch adversarial loss: 0.566018\n",
      "epoch 25; iter: 400; batch classifier loss: 0.428325; batch adversarial loss: 0.683819\n",
      "epoch 26; iter: 0; batch classifier loss: 0.443673; batch adversarial loss: 0.576761\n",
      "epoch 26; iter: 200; batch classifier loss: 0.540872; batch adversarial loss: 0.634610\n",
      "epoch 26; iter: 400; batch classifier loss: 0.391370; batch adversarial loss: 0.635881\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471243; batch adversarial loss: 0.632993\n",
      "epoch 27; iter: 200; batch classifier loss: 0.475827; batch adversarial loss: 0.690181\n",
      "epoch 27; iter: 400; batch classifier loss: 0.371477; batch adversarial loss: 0.629970\n",
      "epoch 28; iter: 0; batch classifier loss: 0.318346; batch adversarial loss: 0.602553\n",
      "epoch 28; iter: 200; batch classifier loss: 0.338344; batch adversarial loss: 0.681892\n",
      "epoch 28; iter: 400; batch classifier loss: 0.539049; batch adversarial loss: 0.586671\n",
      "epoch 29; iter: 0; batch classifier loss: 0.378212; batch adversarial loss: 0.625585\n",
      "epoch 29; iter: 200; batch classifier loss: 0.426868; batch adversarial loss: 0.667728\n",
      "epoch 29; iter: 400; batch classifier loss: 0.266720; batch adversarial loss: 0.634856\n",
      "epoch 30; iter: 0; batch classifier loss: 0.333762; batch adversarial loss: 0.605805\n",
      "epoch 30; iter: 200; batch classifier loss: 0.331393; batch adversarial loss: 0.658025\n",
      "epoch 30; iter: 400; batch classifier loss: 0.358988; batch adversarial loss: 0.679865\n",
      "epoch 31; iter: 0; batch classifier loss: 0.708901; batch adversarial loss: 0.652977\n",
      "epoch 31; iter: 200; batch classifier loss: 0.711473; batch adversarial loss: 0.586839\n",
      "epoch 31; iter: 400; batch classifier loss: 0.529995; batch adversarial loss: 0.619175\n",
      "epoch 32; iter: 0; batch classifier loss: 0.515918; batch adversarial loss: 0.683293\n",
      "epoch 32; iter: 200; batch classifier loss: 0.463903; batch adversarial loss: 0.665079\n",
      "epoch 32; iter: 400; batch classifier loss: 0.458394; batch adversarial loss: 0.573149\n",
      "epoch 33; iter: 0; batch classifier loss: 0.254136; batch adversarial loss: 0.653882\n",
      "epoch 33; iter: 200; batch classifier loss: 0.377313; batch adversarial loss: 0.605258\n",
      "epoch 33; iter: 400; batch classifier loss: 0.299450; batch adversarial loss: 0.691541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.265515; batch adversarial loss: 0.578224\n",
      "epoch 34; iter: 200; batch classifier loss: 0.274752; batch adversarial loss: 0.655218\n",
      "epoch 34; iter: 400; batch classifier loss: 0.338075; batch adversarial loss: 0.690809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448045; batch adversarial loss: 0.647491\n",
      "epoch 35; iter: 200; batch classifier loss: 0.560030; batch adversarial loss: 0.650090\n",
      "epoch 35; iter: 400; batch classifier loss: 0.478983; batch adversarial loss: 0.624482\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404181; batch adversarial loss: 0.601573\n",
      "epoch 36; iter: 200; batch classifier loss: 0.559807; batch adversarial loss: 0.585305\n",
      "epoch 36; iter: 400; batch classifier loss: 0.325055; batch adversarial loss: 0.628895\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444574; batch adversarial loss: 0.595348\n",
      "epoch 37; iter: 200; batch classifier loss: 0.552821; batch adversarial loss: 0.615349\n",
      "epoch 37; iter: 400; batch classifier loss: 0.435239; batch adversarial loss: 0.609104\n",
      "epoch 38; iter: 0; batch classifier loss: 0.372985; batch adversarial loss: 0.665350\n",
      "epoch 38; iter: 200; batch classifier loss: 0.459315; batch adversarial loss: 0.603139\n",
      "epoch 38; iter: 400; batch classifier loss: 0.456199; batch adversarial loss: 0.614749\n",
      "epoch 39; iter: 0; batch classifier loss: 0.175269; batch adversarial loss: 0.659084\n",
      "epoch 39; iter: 200; batch classifier loss: 0.485569; batch adversarial loss: 0.649917\n",
      "epoch 39; iter: 400; batch classifier loss: 0.370492; batch adversarial loss: 0.592305\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443569; batch adversarial loss: 0.745078\n",
      "epoch 40; iter: 200; batch classifier loss: 0.799063; batch adversarial loss: 0.624383\n",
      "epoch 40; iter: 400; batch classifier loss: 0.452019; batch adversarial loss: 0.613073\n",
      "epoch 41; iter: 0; batch classifier loss: 0.522028; batch adversarial loss: 0.615036\n",
      "epoch 41; iter: 200; batch classifier loss: 0.421743; batch adversarial loss: 0.649563\n",
      "epoch 41; iter: 400; batch classifier loss: 0.511061; batch adversarial loss: 0.706749\n",
      "epoch 42; iter: 0; batch classifier loss: 0.203765; batch adversarial loss: 0.670607\n",
      "epoch 42; iter: 200; batch classifier loss: 0.465275; batch adversarial loss: 0.634028\n",
      "epoch 42; iter: 400; batch classifier loss: 0.466934; batch adversarial loss: 0.640386\n",
      "epoch 43; iter: 0; batch classifier loss: 0.700483; batch adversarial loss: 0.650548\n",
      "epoch 43; iter: 200; batch classifier loss: 0.494475; batch adversarial loss: 0.597645\n",
      "epoch 43; iter: 400; batch classifier loss: 0.365589; batch adversarial loss: 0.708038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.614577; batch adversarial loss: 0.649154\n",
      "epoch 44; iter: 200; batch classifier loss: 0.249320; batch adversarial loss: 0.645388\n",
      "epoch 44; iter: 400; batch classifier loss: 0.539266; batch adversarial loss: 0.639644\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506800; batch adversarial loss: 0.587759\n",
      "epoch 45; iter: 200; batch classifier loss: 0.243646; batch adversarial loss: 0.711317\n",
      "epoch 45; iter: 400; batch classifier loss: 0.408465; batch adversarial loss: 0.581180\n",
      "epoch 46; iter: 0; batch classifier loss: 0.623840; batch adversarial loss: 0.644162\n",
      "epoch 46; iter: 200; batch classifier loss: 0.658614; batch adversarial loss: 0.606130\n",
      "epoch 46; iter: 400; batch classifier loss: 0.212805; batch adversarial loss: 0.640692\n",
      "epoch 47; iter: 0; batch classifier loss: 0.568015; batch adversarial loss: 0.595652\n",
      "epoch 47; iter: 200; batch classifier loss: 0.442023; batch adversarial loss: 0.602453\n",
      "epoch 47; iter: 400; batch classifier loss: 0.318936; batch adversarial loss: 0.546039\n",
      "epoch 48; iter: 0; batch classifier loss: 0.705440; batch adversarial loss: 0.634615\n",
      "epoch 48; iter: 200; batch classifier loss: 0.183990; batch adversarial loss: 0.669891\n",
      "epoch 48; iter: 400; batch classifier loss: 0.436807; batch adversarial loss: 0.669308\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466300; batch adversarial loss: 0.643555\n",
      "epoch 49; iter: 200; batch classifier loss: 0.478851; batch adversarial loss: 0.576988\n",
      "epoch 49; iter: 400; batch classifier loss: 0.239218; batch adversarial loss: 0.659247\n",
      "epoch 0; iter: 0; batch classifier loss: 33.754776; batch adversarial loss: 0.954078\n",
      "epoch 0; iter: 200; batch classifier loss: 0.732398; batch adversarial loss: 0.675555\n",
      "epoch 0; iter: 400; batch classifier loss: 2.741652; batch adversarial loss: 0.675447\n",
      "epoch 1; iter: 0; batch classifier loss: 2.644605; batch adversarial loss: 0.647479\n",
      "epoch 1; iter: 200; batch classifier loss: 4.958362; batch adversarial loss: 0.660668\n",
      "epoch 1; iter: 400; batch classifier loss: 5.194986; batch adversarial loss: 0.638751\n",
      "epoch 2; iter: 0; batch classifier loss: 1.235439; batch adversarial loss: 0.582397\n",
      "epoch 2; iter: 200; batch classifier loss: 1.916069; batch adversarial loss: 0.582178\n",
      "epoch 2; iter: 400; batch classifier loss: 3.251791; batch adversarial loss: 0.736088\n",
      "epoch 3; iter: 0; batch classifier loss: 1.046209; batch adversarial loss: 0.626630\n",
      "epoch 3; iter: 200; batch classifier loss: 0.623571; batch adversarial loss: 0.627096\n",
      "epoch 3; iter: 400; batch classifier loss: 2.918287; batch adversarial loss: 0.581539\n",
      "epoch 4; iter: 0; batch classifier loss: 0.352272; batch adversarial loss: 0.716082\n",
      "epoch 4; iter: 200; batch classifier loss: 0.496157; batch adversarial loss: 0.627361\n",
      "epoch 4; iter: 400; batch classifier loss: 1.567381; batch adversarial loss: 0.650773\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592463; batch adversarial loss: 0.615379\n",
      "epoch 5; iter: 200; batch classifier loss: 0.638264; batch adversarial loss: 0.562282\n",
      "epoch 5; iter: 400; batch classifier loss: 0.750019; batch adversarial loss: 0.630542\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402195; batch adversarial loss: 0.543383\n",
      "epoch 6; iter: 200; batch classifier loss: 0.302795; batch adversarial loss: 0.636723\n",
      "epoch 6; iter: 400; batch classifier loss: 0.802612; batch adversarial loss: 0.586508\n",
      "epoch 7; iter: 0; batch classifier loss: 0.431556; batch adversarial loss: 0.677198\n",
      "epoch 7; iter: 200; batch classifier loss: 0.441746; batch adversarial loss: 0.630239\n",
      "epoch 7; iter: 400; batch classifier loss: 0.459937; batch adversarial loss: 0.588720\n",
      "epoch 8; iter: 0; batch classifier loss: 0.345921; batch adversarial loss: 0.620851\n",
      "epoch 8; iter: 200; batch classifier loss: 0.384229; batch adversarial loss: 0.634652\n",
      "epoch 8; iter: 400; batch classifier loss: 0.394685; batch adversarial loss: 0.635550\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571175; batch adversarial loss: 0.617966\n",
      "epoch 9; iter: 200; batch classifier loss: 0.404657; batch adversarial loss: 0.613423\n",
      "epoch 9; iter: 400; batch classifier loss: 0.381627; batch adversarial loss: 0.653554\n",
      "epoch 10; iter: 0; batch classifier loss: 0.345869; batch adversarial loss: 0.611817\n",
      "epoch 10; iter: 200; batch classifier loss: 0.380818; batch adversarial loss: 0.680906\n",
      "epoch 10; iter: 400; batch classifier loss: 0.356390; batch adversarial loss: 0.686304\n",
      "epoch 11; iter: 0; batch classifier loss: 0.363206; batch adversarial loss: 0.637297\n",
      "epoch 11; iter: 200; batch classifier loss: 0.293171; batch adversarial loss: 0.695930\n",
      "epoch 11; iter: 400; batch classifier loss: 0.333880; batch adversarial loss: 0.592288\n",
      "epoch 12; iter: 0; batch classifier loss: 0.209037; batch adversarial loss: 0.640510\n",
      "epoch 12; iter: 200; batch classifier loss: 0.408784; batch adversarial loss: 0.678938\n",
      "epoch 12; iter: 400; batch classifier loss: 0.488298; batch adversarial loss: 0.638975\n",
      "epoch 13; iter: 0; batch classifier loss: 0.692376; batch adversarial loss: 0.640594\n",
      "epoch 13; iter: 200; batch classifier loss: 0.334246; batch adversarial loss: 0.601582\n",
      "epoch 13; iter: 400; batch classifier loss: 0.333389; batch adversarial loss: 0.565016\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368688; batch adversarial loss: 0.692459\n",
      "epoch 14; iter: 200; batch classifier loss: 0.256599; batch adversarial loss: 0.571672\n",
      "epoch 14; iter: 400; batch classifier loss: 0.286683; batch adversarial loss: 0.552789\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469920; batch adversarial loss: 0.562092\n",
      "epoch 15; iter: 200; batch classifier loss: 0.429739; batch adversarial loss: 0.671139\n",
      "epoch 15; iter: 400; batch classifier loss: 0.247181; batch adversarial loss: 0.558205\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366026; batch adversarial loss: 0.597115\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383938; batch adversarial loss: 0.621160\n",
      "epoch 16; iter: 400; batch classifier loss: 0.348841; batch adversarial loss: 0.630644\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366330; batch adversarial loss: 0.635120\n",
      "epoch 17; iter: 200; batch classifier loss: 0.377308; batch adversarial loss: 0.612601\n",
      "epoch 17; iter: 400; batch classifier loss: 0.467909; batch adversarial loss: 0.593304\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295018; batch adversarial loss: 0.656411\n",
      "epoch 18; iter: 200; batch classifier loss: 0.337878; batch adversarial loss: 0.578982\n",
      "epoch 18; iter: 400; batch classifier loss: 0.354841; batch adversarial loss: 0.621183\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400642; batch adversarial loss: 0.595150\n",
      "epoch 19; iter: 200; batch classifier loss: 0.453707; batch adversarial loss: 0.545279\n",
      "epoch 19; iter: 400; batch classifier loss: 0.457455; batch adversarial loss: 0.562032\n",
      "epoch 20; iter: 0; batch classifier loss: 0.350155; batch adversarial loss: 0.657383\n",
      "epoch 20; iter: 200; batch classifier loss: 0.281979; batch adversarial loss: 0.604347\n",
      "epoch 20; iter: 400; batch classifier loss: 0.272113; batch adversarial loss: 0.675111\n",
      "epoch 21; iter: 0; batch classifier loss: 0.268039; batch adversarial loss: 0.626302\n",
      "epoch 21; iter: 200; batch classifier loss: 0.437938; batch adversarial loss: 0.607692\n",
      "epoch 21; iter: 400; batch classifier loss: 0.283500; batch adversarial loss: 0.674228\n",
      "epoch 22; iter: 0; batch classifier loss: 0.445755; batch adversarial loss: 0.636414\n",
      "epoch 22; iter: 200; batch classifier loss: 0.260297; batch adversarial loss: 0.609171\n",
      "epoch 22; iter: 400; batch classifier loss: 0.224075; batch adversarial loss: 0.597546\n",
      "epoch 23; iter: 0; batch classifier loss: 0.267629; batch adversarial loss: 0.638385\n",
      "epoch 23; iter: 200; batch classifier loss: 0.431596; batch adversarial loss: 0.594158\n",
      "epoch 23; iter: 400; batch classifier loss: 0.456288; batch adversarial loss: 0.537620\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361619; batch adversarial loss: 0.637846\n",
      "epoch 24; iter: 200; batch classifier loss: 0.398910; batch adversarial loss: 0.702403\n",
      "epoch 24; iter: 400; batch classifier loss: 0.471628; batch adversarial loss: 0.663134\n",
      "epoch 25; iter: 0; batch classifier loss: 0.284174; batch adversarial loss: 0.627330\n",
      "epoch 25; iter: 200; batch classifier loss: 0.287558; batch adversarial loss: 0.646542\n",
      "epoch 25; iter: 400; batch classifier loss: 0.551300; batch adversarial loss: 0.611267\n",
      "epoch 26; iter: 0; batch classifier loss: 0.414441; batch adversarial loss: 0.613387\n",
      "epoch 26; iter: 200; batch classifier loss: 0.356691; batch adversarial loss: 0.739099\n",
      "epoch 26; iter: 400; batch classifier loss: 0.318061; batch adversarial loss: 0.664987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421546; batch adversarial loss: 0.626841\n",
      "epoch 27; iter: 200; batch classifier loss: 0.370814; batch adversarial loss: 0.637388\n",
      "epoch 27; iter: 400; batch classifier loss: 0.355793; batch adversarial loss: 0.708364\n",
      "epoch 28; iter: 0; batch classifier loss: 0.359835; batch adversarial loss: 0.606609\n",
      "epoch 28; iter: 200; batch classifier loss: 0.266215; batch adversarial loss: 0.664717\n",
      "epoch 28; iter: 400; batch classifier loss: 0.481983; batch adversarial loss: 0.634606\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444430; batch adversarial loss: 0.516532\n",
      "epoch 29; iter: 200; batch classifier loss: 0.329838; batch adversarial loss: 0.558007\n",
      "epoch 29; iter: 400; batch classifier loss: 0.303754; batch adversarial loss: 0.674526\n",
      "epoch 30; iter: 0; batch classifier loss: 0.188233; batch adversarial loss: 0.662513\n",
      "epoch 30; iter: 200; batch classifier loss: 0.542069; batch adversarial loss: 0.678855\n",
      "epoch 30; iter: 400; batch classifier loss: 0.317295; batch adversarial loss: 0.596153\n",
      "epoch 31; iter: 0; batch classifier loss: 0.485993; batch adversarial loss: 0.611021\n",
      "epoch 31; iter: 200; batch classifier loss: 0.564934; batch adversarial loss: 0.621349\n",
      "epoch 31; iter: 400; batch classifier loss: 0.286826; batch adversarial loss: 0.711236\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425559; batch adversarial loss: 0.654966\n",
      "epoch 32; iter: 200; batch classifier loss: 0.373420; batch adversarial loss: 0.693067\n",
      "epoch 32; iter: 400; batch classifier loss: 0.523482; batch adversarial loss: 0.605710\n",
      "epoch 33; iter: 0; batch classifier loss: 0.529360; batch adversarial loss: 0.569627\n",
      "epoch 33; iter: 200; batch classifier loss: 0.369041; batch adversarial loss: 0.642127\n",
      "epoch 33; iter: 400; batch classifier loss: 0.398157; batch adversarial loss: 0.591814\n",
      "epoch 34; iter: 0; batch classifier loss: 0.403876; batch adversarial loss: 0.613639\n",
      "epoch 34; iter: 200; batch classifier loss: 0.328728; batch adversarial loss: 0.634772\n",
      "epoch 34; iter: 400; batch classifier loss: 0.450812; batch adversarial loss: 0.553150\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485149; batch adversarial loss: 0.591053\n",
      "epoch 35; iter: 200; batch classifier loss: 0.341718; batch adversarial loss: 0.628275\n",
      "epoch 35; iter: 400; batch classifier loss: 0.347512; batch adversarial loss: 0.693587\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368804; batch adversarial loss: 0.631681\n",
      "epoch 36; iter: 200; batch classifier loss: 0.357628; batch adversarial loss: 0.616771\n",
      "epoch 36; iter: 400; batch classifier loss: 0.420186; batch adversarial loss: 0.613885\n",
      "epoch 37; iter: 0; batch classifier loss: 0.488575; batch adversarial loss: 0.598624\n",
      "epoch 37; iter: 200; batch classifier loss: 0.278861; batch adversarial loss: 0.671490\n",
      "epoch 37; iter: 400; batch classifier loss: 0.546920; batch adversarial loss: 0.658425\n",
      "epoch 38; iter: 0; batch classifier loss: 0.339470; batch adversarial loss: 0.596845\n",
      "epoch 38; iter: 200; batch classifier loss: 0.508109; batch adversarial loss: 0.621823\n",
      "epoch 38; iter: 400; batch classifier loss: 0.497805; batch adversarial loss: 0.513245\n",
      "epoch 39; iter: 0; batch classifier loss: 0.439990; batch adversarial loss: 0.619366\n",
      "epoch 39; iter: 200; batch classifier loss: 0.634375; batch adversarial loss: 0.709543\n",
      "epoch 39; iter: 400; batch classifier loss: 0.379768; batch adversarial loss: 0.571867\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490257; batch adversarial loss: 0.610896\n",
      "epoch 40; iter: 200; batch classifier loss: 0.359309; batch adversarial loss: 0.675465\n",
      "epoch 40; iter: 400; batch classifier loss: 0.410430; batch adversarial loss: 0.605630\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454890; batch adversarial loss: 0.611811\n",
      "epoch 41; iter: 200; batch classifier loss: 0.651562; batch adversarial loss: 0.607307\n",
      "epoch 41; iter: 400; batch classifier loss: 0.487065; batch adversarial loss: 0.611981\n",
      "epoch 42; iter: 0; batch classifier loss: 0.367827; batch adversarial loss: 0.690893\n",
      "epoch 42; iter: 200; batch classifier loss: 0.301013; batch adversarial loss: 0.654456\n",
      "epoch 42; iter: 400; batch classifier loss: 0.301332; batch adversarial loss: 0.576340\n",
      "epoch 43; iter: 0; batch classifier loss: 0.428669; batch adversarial loss: 0.645561\n",
      "epoch 43; iter: 200; batch classifier loss: 0.436929; batch adversarial loss: 0.675523\n",
      "epoch 43; iter: 400; batch classifier loss: 0.496534; batch adversarial loss: 0.654673\n",
      "epoch 44; iter: 0; batch classifier loss: 0.282146; batch adversarial loss: 0.567922\n",
      "epoch 44; iter: 200; batch classifier loss: 0.702323; batch adversarial loss: 0.600702\n",
      "epoch 44; iter: 400; batch classifier loss: 0.521440; batch adversarial loss: 0.579338\n",
      "epoch 45; iter: 0; batch classifier loss: 0.639351; batch adversarial loss: 0.637380\n",
      "epoch 45; iter: 200; batch classifier loss: 0.284623; batch adversarial loss: 0.663736\n",
      "epoch 45; iter: 400; batch classifier loss: 0.527213; batch adversarial loss: 0.694042\n",
      "epoch 46; iter: 0; batch classifier loss: 0.481078; batch adversarial loss: 0.572589\n",
      "epoch 46; iter: 200; batch classifier loss: 0.535420; batch adversarial loss: 0.644332\n",
      "epoch 46; iter: 400; batch classifier loss: 0.682439; batch adversarial loss: 0.615458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.517278; batch adversarial loss: 0.547343\n",
      "epoch 47; iter: 200; batch classifier loss: 0.485544; batch adversarial loss: 0.568694\n",
      "epoch 47; iter: 400; batch classifier loss: 0.351371; batch adversarial loss: 0.671234\n",
      "epoch 48; iter: 0; batch classifier loss: 0.585773; batch adversarial loss: 0.627045\n",
      "epoch 48; iter: 200; batch classifier loss: 0.244887; batch adversarial loss: 0.622016\n",
      "epoch 48; iter: 400; batch classifier loss: 0.234030; batch adversarial loss: 0.559554\n",
      "epoch 49; iter: 0; batch classifier loss: 0.343963; batch adversarial loss: 0.595512\n",
      "epoch 49; iter: 200; batch classifier loss: 0.243982; batch adversarial loss: 0.654683\n",
      "epoch 49; iter: 400; batch classifier loss: 0.460264; batch adversarial loss: 0.623007\n",
      "epoch 0; iter: 0; batch classifier loss: 396.002411; batch adversarial loss: 0.681485\n",
      "epoch 0; iter: 200; batch classifier loss: 1.876394; batch adversarial loss: 0.654583\n",
      "epoch 0; iter: 400; batch classifier loss: 11.031591; batch adversarial loss: 0.644431\n",
      "epoch 1; iter: 0; batch classifier loss: 4.970128; batch adversarial loss: 0.644116\n",
      "epoch 1; iter: 200; batch classifier loss: 5.592132; batch adversarial loss: 0.666473\n",
      "epoch 1; iter: 400; batch classifier loss: 17.298141; batch adversarial loss: 0.612306\n",
      "epoch 2; iter: 0; batch classifier loss: 7.195466; batch adversarial loss: 0.619051\n",
      "epoch 2; iter: 200; batch classifier loss: 6.061041; batch adversarial loss: 0.664948\n",
      "epoch 2; iter: 400; batch classifier loss: 1.123567; batch adversarial loss: 0.633874\n",
      "epoch 3; iter: 0; batch classifier loss: 2.649994; batch adversarial loss: 0.617748\n",
      "epoch 3; iter: 200; batch classifier loss: 2.812409; batch adversarial loss: 0.612480\n",
      "epoch 3; iter: 400; batch classifier loss: 0.688090; batch adversarial loss: 0.668929\n",
      "epoch 4; iter: 0; batch classifier loss: 1.728505; batch adversarial loss: 0.635891\n",
      "epoch 4; iter: 200; batch classifier loss: 1.502506; batch adversarial loss: 0.622597\n",
      "epoch 4; iter: 400; batch classifier loss: 2.049867; batch adversarial loss: 0.648178\n",
      "epoch 5; iter: 0; batch classifier loss: 1.483239; batch adversarial loss: 0.693784\n",
      "epoch 5; iter: 200; batch classifier loss: 0.772755; batch adversarial loss: 0.611894\n",
      "epoch 5; iter: 400; batch classifier loss: 0.458261; batch adversarial loss: 0.596736\n",
      "epoch 6; iter: 0; batch classifier loss: 0.634599; batch adversarial loss: 0.685960\n",
      "epoch 6; iter: 200; batch classifier loss: 0.539333; batch adversarial loss: 0.693324\n",
      "epoch 6; iter: 400; batch classifier loss: 0.520170; batch adversarial loss: 0.630728\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510007; batch adversarial loss: 0.624689\n",
      "epoch 7; iter: 200; batch classifier loss: 0.372727; batch adversarial loss: 0.691550\n",
      "epoch 7; iter: 400; batch classifier loss: 0.474729; batch adversarial loss: 0.631896\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572913; batch adversarial loss: 0.627100\n",
      "epoch 8; iter: 200; batch classifier loss: 0.260321; batch adversarial loss: 0.583400\n",
      "epoch 8; iter: 400; batch classifier loss: 0.565336; batch adversarial loss: 0.610006\n",
      "epoch 9; iter: 0; batch classifier loss: 0.330934; batch adversarial loss: 0.600896\n",
      "epoch 9; iter: 200; batch classifier loss: 0.314098; batch adversarial loss: 0.573556\n",
      "epoch 9; iter: 400; batch classifier loss: 0.480407; batch adversarial loss: 0.675458\n",
      "epoch 10; iter: 0; batch classifier loss: 0.304920; batch adversarial loss: 0.605124\n",
      "epoch 10; iter: 200; batch classifier loss: 0.439497; batch adversarial loss: 0.584334\n",
      "epoch 10; iter: 400; batch classifier loss: 0.295050; batch adversarial loss: 0.578543\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331911; batch adversarial loss: 0.632098\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383479; batch adversarial loss: 0.657025\n",
      "epoch 11; iter: 400; batch classifier loss: 0.313435; batch adversarial loss: 0.612931\n",
      "epoch 12; iter: 0; batch classifier loss: 0.378368; batch adversarial loss: 0.681575\n",
      "epoch 12; iter: 200; batch classifier loss: 0.380527; batch adversarial loss: 0.673592\n",
      "epoch 12; iter: 400; batch classifier loss: 0.318938; batch adversarial loss: 0.725249\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323739; batch adversarial loss: 0.538560\n",
      "epoch 13; iter: 200; batch classifier loss: 0.345052; batch adversarial loss: 0.649562\n",
      "epoch 13; iter: 400; batch classifier loss: 0.180241; batch adversarial loss: 0.614649\n",
      "epoch 14; iter: 0; batch classifier loss: 0.889979; batch adversarial loss: 0.642104\n",
      "epoch 14; iter: 200; batch classifier loss: 0.265678; batch adversarial loss: 0.624145\n",
      "epoch 14; iter: 400; batch classifier loss: 0.317407; batch adversarial loss: 0.576375\n",
      "epoch 15; iter: 0; batch classifier loss: 0.341659; batch adversarial loss: 0.607627\n",
      "epoch 15; iter: 200; batch classifier loss: 0.409802; batch adversarial loss: 0.659710\n",
      "epoch 15; iter: 400; batch classifier loss: 0.337155; batch adversarial loss: 0.595297\n",
      "epoch 16; iter: 0; batch classifier loss: 0.375643; batch adversarial loss: 0.613439\n",
      "epoch 16; iter: 200; batch classifier loss: 0.379673; batch adversarial loss: 0.609559\n",
      "epoch 16; iter: 400; batch classifier loss: 0.557459; batch adversarial loss: 0.694248\n",
      "epoch 17; iter: 0; batch classifier loss: 0.417602; batch adversarial loss: 0.604854\n",
      "epoch 17; iter: 200; batch classifier loss: 0.414071; batch adversarial loss: 0.619185\n",
      "epoch 17; iter: 400; batch classifier loss: 0.170977; batch adversarial loss: 0.654384\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454913; batch adversarial loss: 0.675614\n",
      "epoch 18; iter: 200; batch classifier loss: 0.455397; batch adversarial loss: 0.674538\n",
      "epoch 18; iter: 400; batch classifier loss: 0.374533; batch adversarial loss: 0.562679\n",
      "epoch 19; iter: 0; batch classifier loss: 0.268329; batch adversarial loss: 0.633680\n",
      "epoch 19; iter: 200; batch classifier loss: 0.361896; batch adversarial loss: 0.621882\n",
      "epoch 19; iter: 400; batch classifier loss: 0.272045; batch adversarial loss: 0.603236\n",
      "epoch 20; iter: 0; batch classifier loss: 0.390455; batch adversarial loss: 0.623762\n",
      "epoch 20; iter: 200; batch classifier loss: 0.572204; batch adversarial loss: 0.667472\n",
      "epoch 20; iter: 400; batch classifier loss: 0.683432; batch adversarial loss: 0.633568\n",
      "epoch 21; iter: 0; batch classifier loss: 0.356794; batch adversarial loss: 0.548101\n",
      "epoch 21; iter: 200; batch classifier loss: 0.345770; batch adversarial loss: 0.649073\n",
      "epoch 21; iter: 400; batch classifier loss: 0.437009; batch adversarial loss: 0.610747\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450313; batch adversarial loss: 0.597713\n",
      "epoch 22; iter: 200; batch classifier loss: 0.425778; batch adversarial loss: 0.671525\n",
      "epoch 22; iter: 400; batch classifier loss: 0.348965; batch adversarial loss: 0.665045\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458451; batch adversarial loss: 0.561011\n",
      "epoch 23; iter: 200; batch classifier loss: 0.404746; batch adversarial loss: 0.672975\n",
      "epoch 23; iter: 400; batch classifier loss: 0.357704; batch adversarial loss: 0.559925\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427604; batch adversarial loss: 0.626545\n",
      "epoch 24; iter: 200; batch classifier loss: 0.689946; batch adversarial loss: 0.622231\n",
      "epoch 24; iter: 400; batch classifier loss: 0.268546; batch adversarial loss: 0.666383\n",
      "epoch 25; iter: 0; batch classifier loss: 0.483019; batch adversarial loss: 0.597255\n",
      "epoch 25; iter: 200; batch classifier loss: 0.419711; batch adversarial loss: 0.634784\n",
      "epoch 25; iter: 400; batch classifier loss: 0.329020; batch adversarial loss: 0.656582\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456901; batch adversarial loss: 0.568064\n",
      "epoch 26; iter: 200; batch classifier loss: 0.307844; batch adversarial loss: 0.596893\n",
      "epoch 26; iter: 400; batch classifier loss: 0.421922; batch adversarial loss: 0.621478\n",
      "epoch 27; iter: 0; batch classifier loss: 0.438189; batch adversarial loss: 0.533928\n",
      "epoch 27; iter: 200; batch classifier loss: 0.326385; batch adversarial loss: 0.582954\n",
      "epoch 27; iter: 400; batch classifier loss: 0.400099; batch adversarial loss: 0.579139\n",
      "epoch 28; iter: 0; batch classifier loss: 0.343352; batch adversarial loss: 0.647950\n",
      "epoch 28; iter: 200; batch classifier loss: 0.310908; batch adversarial loss: 0.648647\n",
      "epoch 28; iter: 400; batch classifier loss: 0.403605; batch adversarial loss: 0.580590\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461011; batch adversarial loss: 0.554838\n",
      "epoch 29; iter: 200; batch classifier loss: 0.504808; batch adversarial loss: 0.631133\n",
      "epoch 29; iter: 400; batch classifier loss: 0.392616; batch adversarial loss: 0.662463\n",
      "epoch 30; iter: 0; batch classifier loss: 0.333751; batch adversarial loss: 0.537320\n",
      "epoch 30; iter: 200; batch classifier loss: 0.625862; batch adversarial loss: 0.595218\n",
      "epoch 30; iter: 400; batch classifier loss: 0.375722; batch adversarial loss: 0.658593\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437161; batch adversarial loss: 0.658257\n",
      "epoch 31; iter: 200; batch classifier loss: 0.368145; batch adversarial loss: 0.662797\n",
      "epoch 31; iter: 400; batch classifier loss: 0.372313; batch adversarial loss: 0.611743\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433049; batch adversarial loss: 0.610087\n",
      "epoch 32; iter: 200; batch classifier loss: 0.247019; batch adversarial loss: 0.665911\n",
      "epoch 32; iter: 400; batch classifier loss: 0.504650; batch adversarial loss: 0.677564\n",
      "epoch 33; iter: 0; batch classifier loss: 0.341322; batch adversarial loss: 0.599310\n",
      "epoch 33; iter: 200; batch classifier loss: 0.980971; batch adversarial loss: 0.606359\n",
      "epoch 33; iter: 400; batch classifier loss: 0.445495; batch adversarial loss: 0.629429\n",
      "epoch 34; iter: 0; batch classifier loss: 0.385402; batch adversarial loss: 0.643445\n",
      "epoch 34; iter: 200; batch classifier loss: 0.610872; batch adversarial loss: 0.570605\n",
      "epoch 34; iter: 400; batch classifier loss: 0.310535; batch adversarial loss: 0.674988\n",
      "epoch 35; iter: 0; batch classifier loss: 0.297159; batch adversarial loss: 0.674550\n",
      "epoch 35; iter: 200; batch classifier loss: 0.379642; batch adversarial loss: 0.673622\n",
      "epoch 35; iter: 400; batch classifier loss: 0.288694; batch adversarial loss: 0.652683\n",
      "epoch 36; iter: 0; batch classifier loss: 0.611225; batch adversarial loss: 0.699562\n",
      "epoch 36; iter: 200; batch classifier loss: 0.740305; batch adversarial loss: 0.621718\n",
      "epoch 36; iter: 400; batch classifier loss: 0.256375; batch adversarial loss: 0.623174\n",
      "epoch 37; iter: 0; batch classifier loss: 0.592676; batch adversarial loss: 0.689287\n",
      "epoch 37; iter: 200; batch classifier loss: 0.455048; batch adversarial loss: 0.674065\n",
      "epoch 37; iter: 400; batch classifier loss: 0.623817; batch adversarial loss: 0.593710\n",
      "epoch 38; iter: 0; batch classifier loss: 0.377648; batch adversarial loss: 0.647094\n",
      "epoch 38; iter: 200; batch classifier loss: 0.527685; batch adversarial loss: 0.610329\n",
      "epoch 38; iter: 400; batch classifier loss: 0.345383; batch adversarial loss: 0.592187\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440200; batch adversarial loss: 0.605977\n",
      "epoch 39; iter: 200; batch classifier loss: 0.574208; batch adversarial loss: 0.608701\n",
      "epoch 39; iter: 400; batch classifier loss: 0.422229; batch adversarial loss: 0.582695\n",
      "epoch 40; iter: 0; batch classifier loss: 0.492526; batch adversarial loss: 0.605681\n",
      "epoch 40; iter: 200; batch classifier loss: 0.362100; batch adversarial loss: 0.608339\n",
      "epoch 40; iter: 400; batch classifier loss: 0.463279; batch adversarial loss: 0.646415\n",
      "epoch 41; iter: 0; batch classifier loss: 0.349841; batch adversarial loss: 0.626686\n",
      "epoch 41; iter: 200; batch classifier loss: 0.390350; batch adversarial loss: 0.610535\n",
      "epoch 41; iter: 400; batch classifier loss: 0.204081; batch adversarial loss: 0.708024\n",
      "epoch 42; iter: 0; batch classifier loss: 0.401403; batch adversarial loss: 0.646174\n",
      "epoch 42; iter: 200; batch classifier loss: 0.285303; batch adversarial loss: 0.620373\n",
      "epoch 42; iter: 400; batch classifier loss: 0.389950; batch adversarial loss: 0.674515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.358265; batch adversarial loss: 0.663784\n",
      "epoch 43; iter: 200; batch classifier loss: 0.467239; batch adversarial loss: 0.537270\n",
      "epoch 43; iter: 400; batch classifier loss: 0.626793; batch adversarial loss: 0.639935\n",
      "epoch 44; iter: 0; batch classifier loss: 0.235329; batch adversarial loss: 0.620411\n",
      "epoch 44; iter: 200; batch classifier loss: 0.334215; batch adversarial loss: 0.529482\n",
      "epoch 44; iter: 400; batch classifier loss: 0.423545; batch adversarial loss: 0.545816\n",
      "epoch 45; iter: 0; batch classifier loss: 0.325639; batch adversarial loss: 0.657475\n",
      "epoch 45; iter: 200; batch classifier loss: 0.439969; batch adversarial loss: 0.637758\n",
      "epoch 45; iter: 400; batch classifier loss: 0.390626; batch adversarial loss: 0.641712\n",
      "epoch 46; iter: 0; batch classifier loss: 0.312144; batch adversarial loss: 0.592960\n",
      "epoch 46; iter: 200; batch classifier loss: 0.590844; batch adversarial loss: 0.683099\n",
      "epoch 46; iter: 400; batch classifier loss: 0.364249; batch adversarial loss: 0.616962\n",
      "epoch 47; iter: 0; batch classifier loss: 0.247104; batch adversarial loss: 0.644909\n",
      "epoch 47; iter: 200; batch classifier loss: 0.274153; batch adversarial loss: 0.627942\n",
      "epoch 47; iter: 400; batch classifier loss: 0.389518; batch adversarial loss: 0.598003\n",
      "epoch 48; iter: 0; batch classifier loss: 0.362671; batch adversarial loss: 0.697476\n",
      "epoch 48; iter: 200; batch classifier loss: 0.675992; batch adversarial loss: 0.595200\n",
      "epoch 48; iter: 400; batch classifier loss: 0.471239; batch adversarial loss: 0.615859\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410831; batch adversarial loss: 0.665953\n",
      "epoch 49; iter: 200; batch classifier loss: 0.604847; batch adversarial loss: 0.645567\n",
      "epoch 49; iter: 400; batch classifier loss: 0.459708; batch adversarial loss: 0.576869\n",
      "epoch 0; iter: 0; batch classifier loss: 34.521435; batch adversarial loss: 0.682793\n",
      "epoch 0; iter: 200; batch classifier loss: 3.787764; batch adversarial loss: 0.672796\n",
      "epoch 0; iter: 400; batch classifier loss: 2.878808; batch adversarial loss: 0.646851\n",
      "epoch 1; iter: 0; batch classifier loss: 2.644695; batch adversarial loss: 0.599591\n",
      "epoch 1; iter: 200; batch classifier loss: 0.246324; batch adversarial loss: 0.675024\n",
      "epoch 1; iter: 400; batch classifier loss: 1.535244; batch adversarial loss: 0.637075\n",
      "epoch 2; iter: 0; batch classifier loss: 3.065745; batch adversarial loss: 0.675611\n",
      "epoch 2; iter: 200; batch classifier loss: 1.341694; batch adversarial loss: 0.673972\n",
      "epoch 2; iter: 400; batch classifier loss: 1.427711; batch adversarial loss: 0.658942\n",
      "epoch 3; iter: 0; batch classifier loss: 6.374784; batch adversarial loss: 0.633521\n",
      "epoch 3; iter: 200; batch classifier loss: 0.705655; batch adversarial loss: 0.609127\n",
      "epoch 3; iter: 400; batch classifier loss: 1.308245; batch adversarial loss: 0.658003\n",
      "epoch 4; iter: 0; batch classifier loss: 2.595063; batch adversarial loss: 0.628705\n",
      "epoch 4; iter: 200; batch classifier loss: 0.455949; batch adversarial loss: 0.581764\n",
      "epoch 4; iter: 400; batch classifier loss: 0.488474; batch adversarial loss: 0.631036\n",
      "epoch 5; iter: 0; batch classifier loss: 0.423133; batch adversarial loss: 0.590452\n",
      "epoch 5; iter: 200; batch classifier loss: 0.530339; batch adversarial loss: 0.592579\n",
      "epoch 5; iter: 400; batch classifier loss: 0.790692; batch adversarial loss: 0.609580\n",
      "epoch 6; iter: 0; batch classifier loss: 1.084373; batch adversarial loss: 0.626779\n",
      "epoch 6; iter: 200; batch classifier loss: 0.442606; batch adversarial loss: 0.663849\n",
      "epoch 6; iter: 400; batch classifier loss: 0.772183; batch adversarial loss: 0.623146\n",
      "epoch 7; iter: 0; batch classifier loss: 0.712424; batch adversarial loss: 0.591826\n",
      "epoch 7; iter: 200; batch classifier loss: 0.485267; batch adversarial loss: 0.702456\n",
      "epoch 7; iter: 400; batch classifier loss: 0.484718; batch adversarial loss: 0.669282\n",
      "epoch 8; iter: 0; batch classifier loss: 0.441542; batch adversarial loss: 0.615416\n",
      "epoch 8; iter: 200; batch classifier loss: 0.366560; batch adversarial loss: 0.628234\n",
      "epoch 8; iter: 400; batch classifier loss: 0.429917; batch adversarial loss: 0.607096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311053; batch adversarial loss: 0.669452\n",
      "epoch 9; iter: 200; batch classifier loss: 0.495833; batch adversarial loss: 0.624819\n",
      "epoch 9; iter: 400; batch classifier loss: 0.362418; batch adversarial loss: 0.637560\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529643; batch adversarial loss: 0.596018\n",
      "epoch 10; iter: 200; batch classifier loss: 0.377811; batch adversarial loss: 0.610216\n",
      "epoch 10; iter: 400; batch classifier loss: 0.379967; batch adversarial loss: 0.626306\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348319; batch adversarial loss: 0.625628\n",
      "epoch 11; iter: 200; batch classifier loss: 0.577209; batch adversarial loss: 0.604033\n",
      "epoch 11; iter: 400; batch classifier loss: 0.375118; batch adversarial loss: 0.635670\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343925; batch adversarial loss: 0.693850\n",
      "epoch 12; iter: 200; batch classifier loss: 0.315949; batch adversarial loss: 0.594147\n",
      "epoch 12; iter: 400; batch classifier loss: 0.301236; batch adversarial loss: 0.611987\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321849; batch adversarial loss: 0.651009\n",
      "epoch 13; iter: 200; batch classifier loss: 0.416937; batch adversarial loss: 0.695398\n",
      "epoch 13; iter: 400; batch classifier loss: 0.385526; batch adversarial loss: 0.546432\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314694; batch adversarial loss: 0.595164\n",
      "epoch 14; iter: 200; batch classifier loss: 0.313458; batch adversarial loss: 0.584555\n",
      "epoch 14; iter: 400; batch classifier loss: 0.496536; batch adversarial loss: 0.583424\n",
      "epoch 15; iter: 0; batch classifier loss: 0.434456; batch adversarial loss: 0.656681\n",
      "epoch 15; iter: 200; batch classifier loss: 0.216457; batch adversarial loss: 0.693536\n",
      "epoch 15; iter: 400; batch classifier loss: 0.405273; batch adversarial loss: 0.607123\n",
      "epoch 16; iter: 0; batch classifier loss: 0.412069; batch adversarial loss: 0.561049\n",
      "epoch 16; iter: 200; batch classifier loss: 0.362721; batch adversarial loss: 0.570227\n",
      "epoch 16; iter: 400; batch classifier loss: 0.291957; batch adversarial loss: 0.690747\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409157; batch adversarial loss: 0.640248\n",
      "epoch 17; iter: 200; batch classifier loss: 0.414428; batch adversarial loss: 0.732458\n",
      "epoch 17; iter: 400; batch classifier loss: 0.366027; batch adversarial loss: 0.620071\n",
      "epoch 18; iter: 0; batch classifier loss: 0.344948; batch adversarial loss: 0.507320\n",
      "epoch 18; iter: 200; batch classifier loss: 0.286451; batch adversarial loss: 0.566286\n",
      "epoch 18; iter: 400; batch classifier loss: 0.352367; batch adversarial loss: 0.576004\n",
      "epoch 19; iter: 0; batch classifier loss: 0.351992; batch adversarial loss: 0.640795\n",
      "epoch 19; iter: 200; batch classifier loss: 0.459991; batch adversarial loss: 0.654158\n",
      "epoch 19; iter: 400; batch classifier loss: 0.487626; batch adversarial loss: 0.632483\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314531; batch adversarial loss: 0.681285\n",
      "epoch 20; iter: 200; batch classifier loss: 0.446327; batch adversarial loss: 0.616663\n",
      "epoch 20; iter: 400; batch classifier loss: 0.238911; batch adversarial loss: 0.628796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.356914; batch adversarial loss: 0.555884\n",
      "epoch 21; iter: 200; batch classifier loss: 0.309073; batch adversarial loss: 0.634280\n",
      "epoch 21; iter: 400; batch classifier loss: 0.384092; batch adversarial loss: 0.818014\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464290; batch adversarial loss: 0.558730\n",
      "epoch 22; iter: 200; batch classifier loss: 0.331524; batch adversarial loss: 0.600640\n",
      "epoch 22; iter: 400; batch classifier loss: 0.315294; batch adversarial loss: 0.629904\n",
      "epoch 23; iter: 0; batch classifier loss: 0.278658; batch adversarial loss: 0.612585\n",
      "epoch 23; iter: 200; batch classifier loss: 0.404526; batch adversarial loss: 0.646235\n",
      "epoch 23; iter: 400; batch classifier loss: 0.385417; batch adversarial loss: 0.629118\n",
      "epoch 24; iter: 0; batch classifier loss: 0.253677; batch adversarial loss: 0.628726\n",
      "epoch 24; iter: 200; batch classifier loss: 0.476475; batch adversarial loss: 0.593835\n",
      "epoch 24; iter: 400; batch classifier loss: 0.449063; batch adversarial loss: 0.566827\n",
      "epoch 25; iter: 0; batch classifier loss: 0.318503; batch adversarial loss: 0.667557\n",
      "epoch 25; iter: 200; batch classifier loss: 0.553273; batch adversarial loss: 0.570622\n",
      "epoch 25; iter: 400; batch classifier loss: 0.288261; batch adversarial loss: 0.624979\n",
      "epoch 26; iter: 0; batch classifier loss: 0.278098; batch adversarial loss: 0.670830\n",
      "epoch 26; iter: 200; batch classifier loss: 0.445237; batch adversarial loss: 0.544431\n",
      "epoch 26; iter: 400; batch classifier loss: 0.241047; batch adversarial loss: 0.630541\n",
      "epoch 27; iter: 0; batch classifier loss: 0.503814; batch adversarial loss: 0.641659\n",
      "epoch 27; iter: 200; batch classifier loss: 0.398551; batch adversarial loss: 0.619145\n",
      "epoch 27; iter: 400; batch classifier loss: 0.292599; batch adversarial loss: 0.623245\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315565; batch adversarial loss: 0.613964\n",
      "epoch 28; iter: 200; batch classifier loss: 0.372492; batch adversarial loss: 0.603973\n",
      "epoch 28; iter: 400; batch classifier loss: 0.560454; batch adversarial loss: 0.646842\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263911; batch adversarial loss: 0.608685\n",
      "epoch 29; iter: 200; batch classifier loss: 0.485644; batch adversarial loss: 0.605441\n",
      "epoch 29; iter: 400; batch classifier loss: 0.381411; batch adversarial loss: 0.578158\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365413; batch adversarial loss: 0.630294\n",
      "epoch 30; iter: 200; batch classifier loss: 0.483290; batch adversarial loss: 0.677174\n",
      "epoch 30; iter: 400; batch classifier loss: 0.406252; batch adversarial loss: 0.591495\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417456; batch adversarial loss: 0.625636\n",
      "epoch 31; iter: 200; batch classifier loss: 0.394176; batch adversarial loss: 0.584748\n",
      "epoch 31; iter: 400; batch classifier loss: 0.661569; batch adversarial loss: 0.611963\n",
      "epoch 32; iter: 0; batch classifier loss: 0.406734; batch adversarial loss: 0.612745\n",
      "epoch 32; iter: 200; batch classifier loss: 0.338597; batch adversarial loss: 0.667091\n",
      "epoch 32; iter: 400; batch classifier loss: 0.549584; batch adversarial loss: 0.623542\n",
      "epoch 33; iter: 0; batch classifier loss: 0.290798; batch adversarial loss: 0.647996\n",
      "epoch 33; iter: 200; batch classifier loss: 0.427863; batch adversarial loss: 0.708119\n",
      "epoch 33; iter: 400; batch classifier loss: 0.348721; batch adversarial loss: 0.665583\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475931; batch adversarial loss: 0.649990\n",
      "epoch 34; iter: 200; batch classifier loss: 0.470710; batch adversarial loss: 0.561028\n",
      "epoch 34; iter: 400; batch classifier loss: 0.721985; batch adversarial loss: 0.669619\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419490; batch adversarial loss: 0.584026\n",
      "epoch 35; iter: 200; batch classifier loss: 0.361611; batch adversarial loss: 0.667165\n",
      "epoch 35; iter: 400; batch classifier loss: 0.306655; batch adversarial loss: 0.723935\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443726; batch adversarial loss: 0.567705\n",
      "epoch 36; iter: 200; batch classifier loss: 0.390723; batch adversarial loss: 0.601374\n",
      "epoch 36; iter: 400; batch classifier loss: 0.313145; batch adversarial loss: 0.567529\n",
      "epoch 37; iter: 0; batch classifier loss: 0.547557; batch adversarial loss: 0.711786\n",
      "epoch 37; iter: 200; batch classifier loss: 0.228366; batch adversarial loss: 0.668714\n",
      "epoch 37; iter: 400; batch classifier loss: 0.388613; batch adversarial loss: 0.612074\n",
      "epoch 38; iter: 0; batch classifier loss: 0.319751; batch adversarial loss: 0.634510\n",
      "epoch 38; iter: 200; batch classifier loss: 0.457226; batch adversarial loss: 0.680839\n",
      "epoch 38; iter: 400; batch classifier loss: 0.423582; batch adversarial loss: 0.661902\n",
      "epoch 39; iter: 0; batch classifier loss: 0.405257; batch adversarial loss: 0.792380\n",
      "epoch 39; iter: 200; batch classifier loss: 0.456590; batch adversarial loss: 0.681757\n",
      "epoch 39; iter: 400; batch classifier loss: 0.288265; batch adversarial loss: 0.611680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.498532; batch adversarial loss: 0.563595\n",
      "epoch 40; iter: 200; batch classifier loss: 0.491140; batch adversarial loss: 0.663996\n",
      "epoch 40; iter: 400; batch classifier loss: 0.397309; batch adversarial loss: 0.658032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454638; batch adversarial loss: 0.609896\n",
      "epoch 41; iter: 200; batch classifier loss: 0.212658; batch adversarial loss: 0.700773\n",
      "epoch 41; iter: 400; batch classifier loss: 0.331324; batch adversarial loss: 0.637325\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385009; batch adversarial loss: 0.542047\n",
      "epoch 42; iter: 200; batch classifier loss: 0.186104; batch adversarial loss: 0.607693\n",
      "epoch 42; iter: 400; batch classifier loss: 0.470493; batch adversarial loss: 0.557150\n",
      "epoch 43; iter: 0; batch classifier loss: 0.308457; batch adversarial loss: 0.572361\n",
      "epoch 43; iter: 200; batch classifier loss: 0.387173; batch adversarial loss: 0.646337\n",
      "epoch 43; iter: 400; batch classifier loss: 0.322713; batch adversarial loss: 0.654095\n",
      "epoch 44; iter: 0; batch classifier loss: 0.520747; batch adversarial loss: 0.630503\n",
      "epoch 44; iter: 200; batch classifier loss: 0.394495; batch adversarial loss: 0.598853\n",
      "epoch 44; iter: 400; batch classifier loss: 0.459854; batch adversarial loss: 0.643888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.600957; batch adversarial loss: 0.523971\n",
      "epoch 45; iter: 200; batch classifier loss: 0.441583; batch adversarial loss: 0.593238\n",
      "epoch 45; iter: 400; batch classifier loss: 0.503092; batch adversarial loss: 0.590649\n",
      "epoch 46; iter: 0; batch classifier loss: 0.579300; batch adversarial loss: 0.701629\n",
      "epoch 46; iter: 200; batch classifier loss: 0.466907; batch adversarial loss: 0.604286\n",
      "epoch 46; iter: 400; batch classifier loss: 0.425396; batch adversarial loss: 0.589786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.449953; batch adversarial loss: 0.633703\n",
      "epoch 47; iter: 200; batch classifier loss: 0.338358; batch adversarial loss: 0.676363\n",
      "epoch 47; iter: 400; batch classifier loss: 0.417621; batch adversarial loss: 0.652568\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387893; batch adversarial loss: 0.642080\n",
      "epoch 48; iter: 200; batch classifier loss: 0.255635; batch adversarial loss: 0.668309\n",
      "epoch 48; iter: 400; batch classifier loss: 0.474392; batch adversarial loss: 0.669908\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407692; batch adversarial loss: 0.590303\n",
      "epoch 49; iter: 200; batch classifier loss: 0.478757; batch adversarial loss: 0.574243\n",
      "epoch 49; iter: 400; batch classifier loss: 1.063985; batch adversarial loss: 0.557670\n",
      "epoch 0; iter: 0; batch classifier loss: 117.374756; batch adversarial loss: 0.874664\n",
      "epoch 0; iter: 200; batch classifier loss: 7.007095; batch adversarial loss: 0.736618\n",
      "epoch 0; iter: 400; batch classifier loss: 3.366522; batch adversarial loss: 0.692500\n",
      "epoch 1; iter: 0; batch classifier loss: 8.975710; batch adversarial loss: 0.698669\n",
      "epoch 1; iter: 200; batch classifier loss: 3.668149; batch adversarial loss: 0.656485\n",
      "epoch 1; iter: 400; batch classifier loss: 6.126875; batch adversarial loss: 0.690534\n",
      "epoch 2; iter: 0; batch classifier loss: 1.087412; batch adversarial loss: 0.563318\n",
      "epoch 2; iter: 200; batch classifier loss: 0.537662; batch adversarial loss: 0.607462\n",
      "epoch 2; iter: 400; batch classifier loss: 5.658093; batch adversarial loss: 0.604908\n",
      "epoch 3; iter: 0; batch classifier loss: 2.673933; batch adversarial loss: 0.663033\n",
      "epoch 3; iter: 200; batch classifier loss: 3.369292; batch adversarial loss: 0.570255\n",
      "epoch 3; iter: 400; batch classifier loss: 0.640171; batch adversarial loss: 0.651100\n",
      "epoch 4; iter: 0; batch classifier loss: 0.194630; batch adversarial loss: 0.689779\n",
      "epoch 4; iter: 200; batch classifier loss: 0.425446; batch adversarial loss: 0.584340\n",
      "epoch 4; iter: 400; batch classifier loss: 0.419694; batch adversarial loss: 0.602320\n",
      "epoch 5; iter: 0; batch classifier loss: 0.679771; batch adversarial loss: 0.679266\n",
      "epoch 5; iter: 200; batch classifier loss: 0.960355; batch adversarial loss: 0.692095\n",
      "epoch 5; iter: 400; batch classifier loss: 10.994863; batch adversarial loss: 0.633585\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404849; batch adversarial loss: 0.648428\n",
      "epoch 6; iter: 200; batch classifier loss: 0.527494; batch adversarial loss: 0.618342\n",
      "epoch 6; iter: 400; batch classifier loss: 0.500165; batch adversarial loss: 0.561641\n",
      "epoch 7; iter: 0; batch classifier loss: 0.404020; batch adversarial loss: 0.678085\n",
      "epoch 7; iter: 200; batch classifier loss: 0.434775; batch adversarial loss: 0.729763\n",
      "epoch 7; iter: 400; batch classifier loss: 0.716167; batch adversarial loss: 0.619218\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434485; batch adversarial loss: 0.560034\n",
      "epoch 8; iter: 200; batch classifier loss: 0.312841; batch adversarial loss: 0.609882\n",
      "epoch 8; iter: 400; batch classifier loss: 0.499175; batch adversarial loss: 0.594165\n",
      "epoch 9; iter: 0; batch classifier loss: 0.277846; batch adversarial loss: 0.677976\n",
      "epoch 9; iter: 200; batch classifier loss: 0.509547; batch adversarial loss: 0.714918\n",
      "epoch 9; iter: 400; batch classifier loss: 0.472743; batch adversarial loss: 0.597401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565876; batch adversarial loss: 0.680810\n",
      "epoch 10; iter: 200; batch classifier loss: 0.588794; batch adversarial loss: 0.592673\n",
      "epoch 10; iter: 400; batch classifier loss: 0.589660; batch adversarial loss: 0.707134\n",
      "epoch 11; iter: 0; batch classifier loss: 1.101590; batch adversarial loss: 0.603451\n",
      "epoch 11; iter: 200; batch classifier loss: 0.319962; batch adversarial loss: 0.628361\n",
      "epoch 11; iter: 400; batch classifier loss: 0.396159; batch adversarial loss: 0.650319\n",
      "epoch 12; iter: 0; batch classifier loss: 0.479618; batch adversarial loss: 0.576149\n",
      "epoch 12; iter: 200; batch classifier loss: 0.477026; batch adversarial loss: 0.625915\n",
      "epoch 12; iter: 400; batch classifier loss: 0.311242; batch adversarial loss: 0.624241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493768; batch adversarial loss: 0.619593\n",
      "epoch 13; iter: 200; batch classifier loss: 0.472026; batch adversarial loss: 0.671667\n",
      "epoch 13; iter: 400; batch classifier loss: 0.438390; batch adversarial loss: 0.664817\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368639; batch adversarial loss: 0.616020\n",
      "epoch 14; iter: 200; batch classifier loss: 0.338998; batch adversarial loss: 0.554819\n",
      "epoch 14; iter: 400; batch classifier loss: 0.376123; batch adversarial loss: 0.636853\n",
      "epoch 15; iter: 0; batch classifier loss: 0.335898; batch adversarial loss: 0.637728\n",
      "epoch 15; iter: 200; batch classifier loss: 0.352301; batch adversarial loss: 0.614849\n",
      "epoch 15; iter: 400; batch classifier loss: 0.422453; batch adversarial loss: 0.672224\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293747; batch adversarial loss: 0.672840\n",
      "epoch 16; iter: 200; batch classifier loss: 0.336092; batch adversarial loss: 0.613550\n",
      "epoch 16; iter: 400; batch classifier loss: 0.398319; batch adversarial loss: 0.665711\n",
      "epoch 17; iter: 0; batch classifier loss: 0.379623; batch adversarial loss: 0.613404\n",
      "epoch 17; iter: 200; batch classifier loss: 0.550145; batch adversarial loss: 0.698274\n",
      "epoch 17; iter: 400; batch classifier loss: 0.249499; batch adversarial loss: 0.671429\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298312; batch adversarial loss: 0.634075\n",
      "epoch 18; iter: 200; batch classifier loss: 0.288594; batch adversarial loss: 0.678869\n",
      "epoch 18; iter: 400; batch classifier loss: 0.350383; batch adversarial loss: 0.674208\n",
      "epoch 19; iter: 0; batch classifier loss: 0.411126; batch adversarial loss: 0.564424\n",
      "epoch 19; iter: 200; batch classifier loss: 0.284050; batch adversarial loss: 0.635249\n",
      "epoch 19; iter: 400; batch classifier loss: 0.288812; batch adversarial loss: 0.599643\n",
      "epoch 20; iter: 0; batch classifier loss: 0.402090; batch adversarial loss: 0.602459\n",
      "epoch 20; iter: 200; batch classifier loss: 0.317066; batch adversarial loss: 0.649417\n",
      "epoch 20; iter: 400; batch classifier loss: 0.389227; batch adversarial loss: 0.630924\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541332; batch adversarial loss: 0.567760\n",
      "epoch 21; iter: 200; batch classifier loss: 0.490600; batch adversarial loss: 0.678603\n",
      "epoch 21; iter: 400; batch classifier loss: 0.403174; batch adversarial loss: 0.722484\n",
      "epoch 22; iter: 0; batch classifier loss: 0.407372; batch adversarial loss: 0.590454\n",
      "epoch 22; iter: 200; batch classifier loss: 0.422314; batch adversarial loss: 0.679174\n",
      "epoch 22; iter: 400; batch classifier loss: 0.446064; batch adversarial loss: 0.705687\n",
      "epoch 23; iter: 0; batch classifier loss: 0.341183; batch adversarial loss: 0.622333\n",
      "epoch 23; iter: 200; batch classifier loss: 0.391070; batch adversarial loss: 0.582752\n",
      "epoch 23; iter: 400; batch classifier loss: 0.492244; batch adversarial loss: 0.536159\n",
      "epoch 24; iter: 0; batch classifier loss: 0.344258; batch adversarial loss: 0.666695\n",
      "epoch 24; iter: 200; batch classifier loss: 0.493108; batch adversarial loss: 0.603748\n",
      "epoch 24; iter: 400; batch classifier loss: 0.282894; batch adversarial loss: 0.663671\n",
      "epoch 25; iter: 0; batch classifier loss: 0.350305; batch adversarial loss: 0.623585\n",
      "epoch 25; iter: 200; batch classifier loss: 0.390706; batch adversarial loss: 0.534016\n",
      "epoch 25; iter: 400; batch classifier loss: 0.662820; batch adversarial loss: 0.584397\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455240; batch adversarial loss: 0.678904\n",
      "epoch 26; iter: 200; batch classifier loss: 0.262435; batch adversarial loss: 0.619335\n",
      "epoch 26; iter: 400; batch classifier loss: 0.456838; batch adversarial loss: 0.581620\n",
      "epoch 27; iter: 0; batch classifier loss: 0.689707; batch adversarial loss: 0.645337\n",
      "epoch 27; iter: 200; batch classifier loss: 0.469616; batch adversarial loss: 0.622747\n",
      "epoch 27; iter: 400; batch classifier loss: 0.403173; batch adversarial loss: 0.621939\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422345; batch adversarial loss: 0.580272\n",
      "epoch 28; iter: 200; batch classifier loss: 0.571051; batch adversarial loss: 0.619301\n",
      "epoch 28; iter: 400; batch classifier loss: 0.400187; batch adversarial loss: 0.637925\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397746; batch adversarial loss: 0.599671\n",
      "epoch 29; iter: 200; batch classifier loss: 0.573041; batch adversarial loss: 0.593984\n",
      "epoch 29; iter: 400; batch classifier loss: 0.419774; batch adversarial loss: 0.631771\n",
      "epoch 30; iter: 0; batch classifier loss: 0.317438; batch adversarial loss: 0.616724\n",
      "epoch 30; iter: 200; batch classifier loss: 0.504132; batch adversarial loss: 0.586494\n",
      "epoch 30; iter: 400; batch classifier loss: 0.355085; batch adversarial loss: 0.717482\n",
      "epoch 31; iter: 0; batch classifier loss: 0.440484; batch adversarial loss: 0.627118\n",
      "epoch 31; iter: 200; batch classifier loss: 0.440908; batch adversarial loss: 0.518367\n",
      "epoch 31; iter: 400; batch classifier loss: 0.292861; batch adversarial loss: 0.604468\n",
      "epoch 32; iter: 0; batch classifier loss: 0.535409; batch adversarial loss: 0.563938\n",
      "epoch 32; iter: 200; batch classifier loss: 0.541044; batch adversarial loss: 0.652117\n",
      "epoch 32; iter: 400; batch classifier loss: 0.352338; batch adversarial loss: 0.560511\n",
      "epoch 33; iter: 0; batch classifier loss: 0.510533; batch adversarial loss: 0.560469\n",
      "epoch 33; iter: 200; batch classifier loss: 0.271438; batch adversarial loss: 0.605098\n",
      "epoch 33; iter: 400; batch classifier loss: 0.372251; batch adversarial loss: 0.581468\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430238; batch adversarial loss: 0.654947\n",
      "epoch 34; iter: 200; batch classifier loss: 0.396749; batch adversarial loss: 0.643863\n",
      "epoch 34; iter: 400; batch classifier loss: 0.715964; batch adversarial loss: 0.627793\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497561; batch adversarial loss: 0.589463\n",
      "epoch 35; iter: 200; batch classifier loss: 0.404846; batch adversarial loss: 0.639330\n",
      "epoch 35; iter: 400; batch classifier loss: 0.414979; batch adversarial loss: 0.649744\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425463; batch adversarial loss: 0.617502\n",
      "epoch 36; iter: 200; batch classifier loss: 0.354371; batch adversarial loss: 0.632066\n",
      "epoch 36; iter: 400; batch classifier loss: 0.431627; batch adversarial loss: 0.637743\n",
      "epoch 37; iter: 0; batch classifier loss: 0.540592; batch adversarial loss: 0.593576\n",
      "epoch 37; iter: 200; batch classifier loss: 0.363185; batch adversarial loss: 0.557951\n",
      "epoch 37; iter: 400; batch classifier loss: 0.428459; batch adversarial loss: 0.590232\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386742; batch adversarial loss: 0.667360\n",
      "epoch 38; iter: 200; batch classifier loss: 0.397029; batch adversarial loss: 0.560652\n",
      "epoch 38; iter: 400; batch classifier loss: 0.298240; batch adversarial loss: 0.651211\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399528; batch adversarial loss: 0.656470\n",
      "epoch 39; iter: 200; batch classifier loss: 1.219115; batch adversarial loss: 0.655864\n",
      "epoch 39; iter: 400; batch classifier loss: 0.333760; batch adversarial loss: 0.599538\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361558; batch adversarial loss: 0.637342\n",
      "epoch 40; iter: 200; batch classifier loss: 0.474797; batch adversarial loss: 0.607890\n",
      "epoch 40; iter: 400; batch classifier loss: 0.550656; batch adversarial loss: 0.566312\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421728; batch adversarial loss: 0.696233\n",
      "epoch 41; iter: 200; batch classifier loss: 0.398313; batch adversarial loss: 0.594834\n",
      "epoch 41; iter: 400; batch classifier loss: 0.405553; batch adversarial loss: 0.592567\n",
      "epoch 42; iter: 0; batch classifier loss: 0.740974; batch adversarial loss: 0.647814\n",
      "epoch 42; iter: 200; batch classifier loss: 0.359100; batch adversarial loss: 0.617193\n",
      "epoch 42; iter: 400; batch classifier loss: 0.466340; batch adversarial loss: 0.561448\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435742; batch adversarial loss: 0.679087\n",
      "epoch 43; iter: 200; batch classifier loss: 0.440672; batch adversarial loss: 0.595766\n",
      "epoch 43; iter: 400; batch classifier loss: 0.421110; batch adversarial loss: 0.644953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.333937; batch adversarial loss: 0.665957\n",
      "epoch 44; iter: 200; batch classifier loss: 0.389790; batch adversarial loss: 0.690561\n",
      "epoch 44; iter: 400; batch classifier loss: 0.448252; batch adversarial loss: 0.492379\n",
      "epoch 45; iter: 0; batch classifier loss: 0.696548; batch adversarial loss: 0.670401\n",
      "epoch 45; iter: 200; batch classifier loss: 0.680891; batch adversarial loss: 0.585420\n",
      "epoch 45; iter: 400; batch classifier loss: 1.054079; batch adversarial loss: 0.700298\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370268; batch adversarial loss: 0.591441\n",
      "epoch 46; iter: 200; batch classifier loss: 0.504075; batch adversarial loss: 0.593954\n",
      "epoch 46; iter: 400; batch classifier loss: 0.625898; batch adversarial loss: 0.625420\n",
      "epoch 47; iter: 0; batch classifier loss: 0.558003; batch adversarial loss: 0.639848\n",
      "epoch 47; iter: 200; batch classifier loss: 0.606848; batch adversarial loss: 0.628440\n",
      "epoch 47; iter: 400; batch classifier loss: 0.470456; batch adversarial loss: 0.586737\n",
      "epoch 48; iter: 0; batch classifier loss: 0.547606; batch adversarial loss: 0.581839\n",
      "epoch 48; iter: 200; batch classifier loss: 0.431273; batch adversarial loss: 0.648217\n",
      "epoch 48; iter: 400; batch classifier loss: 0.724180; batch adversarial loss: 0.662328\n",
      "epoch 49; iter: 0; batch classifier loss: 0.517266; batch adversarial loss: 0.590838\n",
      "epoch 49; iter: 200; batch classifier loss: 0.337442; batch adversarial loss: 0.649651\n",
      "epoch 49; iter: 400; batch classifier loss: 0.342976; batch adversarial loss: 0.558083\n",
      "epoch 0; iter: 0; batch classifier loss: 35.415756; batch adversarial loss: 0.919191\n",
      "epoch 0; iter: 200; batch classifier loss: 3.460128; batch adversarial loss: 0.681142\n",
      "epoch 0; iter: 400; batch classifier loss: 21.415785; batch adversarial loss: 0.719332\n",
      "epoch 1; iter: 0; batch classifier loss: 3.280070; batch adversarial loss: 0.621514\n",
      "epoch 1; iter: 200; batch classifier loss: 5.169255; batch adversarial loss: 0.623515\n",
      "epoch 1; iter: 400; batch classifier loss: 2.828802; batch adversarial loss: 0.601145\n",
      "epoch 2; iter: 0; batch classifier loss: 1.573182; batch adversarial loss: 0.647769\n",
      "epoch 2; iter: 200; batch classifier loss: 0.961803; batch adversarial loss: 0.601965\n",
      "epoch 2; iter: 400; batch classifier loss: 1.639540; batch adversarial loss: 0.614974\n",
      "epoch 3; iter: 0; batch classifier loss: 1.561987; batch adversarial loss: 0.785331\n",
      "epoch 3; iter: 200; batch classifier loss: 1.198035; batch adversarial loss: 0.672750\n",
      "epoch 3; iter: 400; batch classifier loss: 0.483212; batch adversarial loss: 0.636061\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538987; batch adversarial loss: 0.610681\n",
      "epoch 4; iter: 200; batch classifier loss: 0.396980; batch adversarial loss: 0.548501\n",
      "epoch 4; iter: 400; batch classifier loss: 0.479022; batch adversarial loss: 0.707203\n",
      "epoch 5; iter: 0; batch classifier loss: 1.303844; batch adversarial loss: 0.613479\n",
      "epoch 5; iter: 200; batch classifier loss: 0.667152; batch adversarial loss: 0.622232\n",
      "epoch 5; iter: 400; batch classifier loss: 0.390209; batch adversarial loss: 0.630930\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583795; batch adversarial loss: 0.653760\n",
      "epoch 6; iter: 200; batch classifier loss: 0.642255; batch adversarial loss: 0.641038\n",
      "epoch 6; iter: 400; batch classifier loss: 0.468508; batch adversarial loss: 0.620342\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580209; batch adversarial loss: 0.627908\n",
      "epoch 7; iter: 200; batch classifier loss: 0.806950; batch adversarial loss: 0.630165\n",
      "epoch 7; iter: 400; batch classifier loss: 0.252797; batch adversarial loss: 0.706119\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394050; batch adversarial loss: 0.611778\n",
      "epoch 8; iter: 200; batch classifier loss: 0.412838; batch adversarial loss: 0.601841\n",
      "epoch 8; iter: 400; batch classifier loss: 0.751912; batch adversarial loss: 0.573712\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371055; batch adversarial loss: 0.660016\n",
      "epoch 9; iter: 200; batch classifier loss: 0.802980; batch adversarial loss: 0.591503\n",
      "epoch 9; iter: 400; batch classifier loss: 0.446316; batch adversarial loss: 0.633399\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307721; batch adversarial loss: 0.656829\n",
      "epoch 10; iter: 200; batch classifier loss: 0.444444; batch adversarial loss: 0.576227\n",
      "epoch 10; iter: 400; batch classifier loss: 0.402393; batch adversarial loss: 0.625738\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420249; batch adversarial loss: 0.618946\n",
      "epoch 11; iter: 200; batch classifier loss: 0.595448; batch adversarial loss: 0.586072\n",
      "epoch 11; iter: 400; batch classifier loss: 0.472669; batch adversarial loss: 0.636832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.304899; batch adversarial loss: 0.605871\n",
      "epoch 12; iter: 200; batch classifier loss: 0.252664; batch adversarial loss: 0.685668\n",
      "epoch 12; iter: 400; batch classifier loss: 0.272467; batch adversarial loss: 0.567049\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539878; batch adversarial loss: 0.632273\n",
      "epoch 13; iter: 200; batch classifier loss: 0.324081; batch adversarial loss: 0.646631\n",
      "epoch 13; iter: 400; batch classifier loss: 0.337950; batch adversarial loss: 0.720678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349479; batch adversarial loss: 0.538061\n",
      "epoch 14; iter: 200; batch classifier loss: 0.321734; batch adversarial loss: 0.650187\n",
      "epoch 14; iter: 400; batch classifier loss: 0.428198; batch adversarial loss: 0.678216\n",
      "epoch 15; iter: 0; batch classifier loss: 0.455971; batch adversarial loss: 0.628218\n",
      "epoch 15; iter: 200; batch classifier loss: 0.439288; batch adversarial loss: 0.515106\n",
      "epoch 15; iter: 400; batch classifier loss: 0.345558; batch adversarial loss: 0.631040\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453608; batch adversarial loss: 0.567376\n",
      "epoch 16; iter: 200; batch classifier loss: 0.260847; batch adversarial loss: 0.614922\n",
      "epoch 16; iter: 400; batch classifier loss: 0.202288; batch adversarial loss: 0.583046\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319630; batch adversarial loss: 0.622952\n",
      "epoch 17; iter: 200; batch classifier loss: 0.385992; batch adversarial loss: 0.644824\n",
      "epoch 17; iter: 400; batch classifier loss: 0.286881; batch adversarial loss: 0.620745\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290372; batch adversarial loss: 0.598258\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341699; batch adversarial loss: 0.600507\n",
      "epoch 18; iter: 400; batch classifier loss: 0.531168; batch adversarial loss: 0.627410\n",
      "epoch 19; iter: 0; batch classifier loss: 0.401007; batch adversarial loss: 0.633972\n",
      "epoch 19; iter: 200; batch classifier loss: 0.476518; batch adversarial loss: 0.654872\n",
      "epoch 19; iter: 400; batch classifier loss: 0.325539; batch adversarial loss: 0.597602\n",
      "epoch 20; iter: 0; batch classifier loss: 0.273359; batch adversarial loss: 0.627669\n",
      "epoch 20; iter: 200; batch classifier loss: 0.331710; batch adversarial loss: 0.549744\n",
      "epoch 20; iter: 400; batch classifier loss: 0.521626; batch adversarial loss: 0.718083\n",
      "epoch 21; iter: 0; batch classifier loss: 0.247149; batch adversarial loss: 0.608147\n",
      "epoch 21; iter: 200; batch classifier loss: 0.386769; batch adversarial loss: 0.640401\n",
      "epoch 21; iter: 400; batch classifier loss: 0.331530; batch adversarial loss: 0.669333\n",
      "epoch 22; iter: 0; batch classifier loss: 0.461007; batch adversarial loss: 0.686688\n",
      "epoch 22; iter: 200; batch classifier loss: 0.386405; batch adversarial loss: 0.650588\n",
      "epoch 22; iter: 400; batch classifier loss: 0.405204; batch adversarial loss: 0.623055\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426228; batch adversarial loss: 0.550924\n",
      "epoch 23; iter: 200; batch classifier loss: 0.329568; batch adversarial loss: 0.694291\n",
      "epoch 23; iter: 400; batch classifier loss: 0.415379; batch adversarial loss: 0.605283\n",
      "epoch 24; iter: 0; batch classifier loss: 0.409366; batch adversarial loss: 0.686634\n",
      "epoch 24; iter: 200; batch classifier loss: 0.374278; batch adversarial loss: 0.616571\n",
      "epoch 24; iter: 400; batch classifier loss: 0.326987; batch adversarial loss: 0.615606\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420658; batch adversarial loss: 0.741703\n",
      "epoch 25; iter: 200; batch classifier loss: 0.374712; batch adversarial loss: 0.536277\n",
      "epoch 25; iter: 400; batch classifier loss: 0.343260; batch adversarial loss: 0.605970\n",
      "epoch 26; iter: 0; batch classifier loss: 0.270325; batch adversarial loss: 0.624117\n",
      "epoch 26; iter: 200; batch classifier loss: 0.287141; batch adversarial loss: 0.628831\n",
      "epoch 26; iter: 400; batch classifier loss: 0.221036; batch adversarial loss: 0.577917\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327377; batch adversarial loss: 0.662564\n",
      "epoch 27; iter: 200; batch classifier loss: 0.356520; batch adversarial loss: 0.666160\n",
      "epoch 27; iter: 400; batch classifier loss: 0.481673; batch adversarial loss: 0.649866\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453957; batch adversarial loss: 0.654674\n",
      "epoch 28; iter: 200; batch classifier loss: 0.569015; batch adversarial loss: 0.576254\n",
      "epoch 28; iter: 400; batch classifier loss: 0.425886; batch adversarial loss: 0.673154\n",
      "epoch 29; iter: 0; batch classifier loss: 0.335956; batch adversarial loss: 0.552590\n",
      "epoch 29; iter: 200; batch classifier loss: 0.420983; batch adversarial loss: 0.648127\n",
      "epoch 29; iter: 400; batch classifier loss: 0.449449; batch adversarial loss: 0.652322\n",
      "epoch 30; iter: 0; batch classifier loss: 0.368719; batch adversarial loss: 0.591581\n",
      "epoch 30; iter: 200; batch classifier loss: 0.510219; batch adversarial loss: 0.638101\n",
      "epoch 30; iter: 400; batch classifier loss: 0.438102; batch adversarial loss: 0.654189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397713; batch adversarial loss: 0.646518\n",
      "epoch 31; iter: 200; batch classifier loss: 0.494955; batch adversarial loss: 0.636436\n",
      "epoch 31; iter: 400; batch classifier loss: 0.436588; batch adversarial loss: 0.614302\n",
      "epoch 32; iter: 0; batch classifier loss: 0.317172; batch adversarial loss: 0.577398\n",
      "epoch 32; iter: 200; batch classifier loss: 0.343334; batch adversarial loss: 0.599489\n",
      "epoch 32; iter: 400; batch classifier loss: 0.374961; batch adversarial loss: 0.610782\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386479; batch adversarial loss: 0.641389\n",
      "epoch 33; iter: 200; batch classifier loss: 0.387988; batch adversarial loss: 0.645177\n",
      "epoch 33; iter: 400; batch classifier loss: 0.399168; batch adversarial loss: 0.594243\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415166; batch adversarial loss: 0.568639\n",
      "epoch 34; iter: 200; batch classifier loss: 0.415652; batch adversarial loss: 0.667981\n",
      "epoch 34; iter: 400; batch classifier loss: 0.354966; batch adversarial loss: 0.583500\n",
      "epoch 35; iter: 0; batch classifier loss: 0.380148; batch adversarial loss: 0.663651\n",
      "epoch 35; iter: 200; batch classifier loss: 0.352649; batch adversarial loss: 0.598472\n",
      "epoch 35; iter: 400; batch classifier loss: 0.390016; batch adversarial loss: 0.595917\n",
      "epoch 36; iter: 0; batch classifier loss: 0.528387; batch adversarial loss: 0.602981\n",
      "epoch 36; iter: 200; batch classifier loss: 0.330823; batch adversarial loss: 0.695266\n",
      "epoch 36; iter: 400; batch classifier loss: 0.411389; batch adversarial loss: 0.559194\n",
      "epoch 37; iter: 0; batch classifier loss: 0.305412; batch adversarial loss: 0.597553\n",
      "epoch 37; iter: 200; batch classifier loss: 0.585180; batch adversarial loss: 0.646312\n",
      "epoch 37; iter: 400; batch classifier loss: 0.359272; batch adversarial loss: 0.651819\n",
      "epoch 38; iter: 0; batch classifier loss: 0.627830; batch adversarial loss: 0.574542\n",
      "epoch 38; iter: 200; batch classifier loss: 0.372537; batch adversarial loss: 0.707563\n",
      "epoch 38; iter: 400; batch classifier loss: 0.455133; batch adversarial loss: 0.611909\n",
      "epoch 39; iter: 0; batch classifier loss: 0.369670; batch adversarial loss: 0.652557\n",
      "epoch 39; iter: 200; batch classifier loss: 0.229238; batch adversarial loss: 0.662208\n",
      "epoch 39; iter: 400; batch classifier loss: 0.372131; batch adversarial loss: 0.611846\n",
      "epoch 40; iter: 0; batch classifier loss: 0.517459; batch adversarial loss: 0.607332\n",
      "epoch 40; iter: 200; batch classifier loss: 0.557571; batch adversarial loss: 0.744091\n",
      "epoch 40; iter: 400; batch classifier loss: 0.513921; batch adversarial loss: 0.574711\n",
      "epoch 41; iter: 0; batch classifier loss: 0.531074; batch adversarial loss: 0.642759\n",
      "epoch 41; iter: 200; batch classifier loss: 0.437283; batch adversarial loss: 0.622899\n",
      "epoch 41; iter: 400; batch classifier loss: 0.566972; batch adversarial loss: 0.576774\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455496; batch adversarial loss: 0.648391\n",
      "epoch 42; iter: 200; batch classifier loss: 0.385169; batch adversarial loss: 0.666853\n",
      "epoch 42; iter: 400; batch classifier loss: 0.644967; batch adversarial loss: 0.637589\n",
      "epoch 43; iter: 0; batch classifier loss: 0.372704; batch adversarial loss: 0.616935\n",
      "epoch 43; iter: 200; batch classifier loss: 0.507336; batch adversarial loss: 0.663369\n",
      "epoch 43; iter: 400; batch classifier loss: 0.282403; batch adversarial loss: 0.655860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.330994; batch adversarial loss: 0.627477\n",
      "epoch 44; iter: 200; batch classifier loss: 0.332212; batch adversarial loss: 0.661241\n",
      "epoch 44; iter: 400; batch classifier loss: 0.447033; batch adversarial loss: 0.621101\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382921; batch adversarial loss: 0.636766\n",
      "epoch 45; iter: 200; batch classifier loss: 0.286437; batch adversarial loss: 0.726563\n",
      "epoch 45; iter: 400; batch classifier loss: 0.285398; batch adversarial loss: 0.678206\n",
      "epoch 46; iter: 0; batch classifier loss: 0.366608; batch adversarial loss: 0.585053\n",
      "epoch 46; iter: 200; batch classifier loss: 0.431190; batch adversarial loss: 0.570857\n",
      "epoch 46; iter: 400; batch classifier loss: 0.489321; batch adversarial loss: 0.671642\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463681; batch adversarial loss: 0.587244\n",
      "epoch 47; iter: 200; batch classifier loss: 0.338902; batch adversarial loss: 0.646164\n",
      "epoch 47; iter: 400; batch classifier loss: 0.592905; batch adversarial loss: 0.708474\n",
      "epoch 48; iter: 0; batch classifier loss: 0.307894; batch adversarial loss: 0.605875\n",
      "epoch 48; iter: 200; batch classifier loss: 0.354832; batch adversarial loss: 0.672026\n",
      "epoch 48; iter: 400; batch classifier loss: 0.453558; batch adversarial loss: 0.628363\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458191; batch adversarial loss: 0.521858\n",
      "epoch 49; iter: 200; batch classifier loss: 0.524145; batch adversarial loss: 0.610685\n",
      "epoch 49; iter: 400; batch classifier loss: 0.317610; batch adversarial loss: 0.583830\n",
      "epoch 0; iter: 0; batch classifier loss: 8.709350; batch adversarial loss: 0.743407\n",
      "epoch 0; iter: 200; batch classifier loss: 6.306866; batch adversarial loss: 0.882330\n",
      "epoch 0; iter: 400; batch classifier loss: 5.500639; batch adversarial loss: 0.722960\n",
      "epoch 1; iter: 0; batch classifier loss: 4.588720; batch adversarial loss: 0.668012\n",
      "epoch 1; iter: 200; batch classifier loss: 3.092252; batch adversarial loss: 0.712420\n",
      "epoch 1; iter: 400; batch classifier loss: 6.264322; batch adversarial loss: 0.637935\n",
      "epoch 2; iter: 0; batch classifier loss: 3.098235; batch adversarial loss: 0.633850\n",
      "epoch 2; iter: 200; batch classifier loss: 2.186373; batch adversarial loss: 0.656761\n",
      "epoch 2; iter: 400; batch classifier loss: 1.260055; batch adversarial loss: 0.644493\n",
      "epoch 3; iter: 0; batch classifier loss: 2.697771; batch adversarial loss: 0.581378\n",
      "epoch 3; iter: 200; batch classifier loss: 1.795358; batch adversarial loss: 0.698070\n",
      "epoch 3; iter: 400; batch classifier loss: 0.605249; batch adversarial loss: 0.616768\n",
      "epoch 4; iter: 0; batch classifier loss: 1.968034; batch adversarial loss: 0.560602\n",
      "epoch 4; iter: 200; batch classifier loss: 1.054020; batch adversarial loss: 0.583581\n",
      "epoch 4; iter: 400; batch classifier loss: 0.287561; batch adversarial loss: 0.578394\n",
      "epoch 5; iter: 0; batch classifier loss: 1.721771; batch adversarial loss: 0.696045\n",
      "epoch 5; iter: 200; batch classifier loss: 0.388908; batch adversarial loss: 0.609056\n",
      "epoch 5; iter: 400; batch classifier loss: 0.414462; batch adversarial loss: 0.603726\n",
      "epoch 6; iter: 0; batch classifier loss: 0.422208; batch adversarial loss: 0.656303\n",
      "epoch 6; iter: 200; batch classifier loss: 0.330323; batch adversarial loss: 0.650437\n",
      "epoch 6; iter: 400; batch classifier loss: 0.618325; batch adversarial loss: 0.572068\n",
      "epoch 7; iter: 0; batch classifier loss: 0.423245; batch adversarial loss: 0.619967\n",
      "epoch 7; iter: 200; batch classifier loss: 0.854052; batch adversarial loss: 0.646720\n",
      "epoch 7; iter: 400; batch classifier loss: 0.285444; batch adversarial loss: 0.589170\n",
      "epoch 8; iter: 0; batch classifier loss: 0.410918; batch adversarial loss: 0.574100\n",
      "epoch 8; iter: 200; batch classifier loss: 0.472781; batch adversarial loss: 0.618184\n",
      "epoch 8; iter: 400; batch classifier loss: 0.583628; batch adversarial loss: 0.586011\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476987; batch adversarial loss: 0.548043\n",
      "epoch 9; iter: 200; batch classifier loss: 0.332371; batch adversarial loss: 0.611345\n",
      "epoch 9; iter: 400; batch classifier loss: 0.281497; batch adversarial loss: 0.550545\n",
      "epoch 10; iter: 0; batch classifier loss: 0.442848; batch adversarial loss: 0.555487\n",
      "epoch 10; iter: 200; batch classifier loss: 0.405985; batch adversarial loss: 0.616465\n",
      "epoch 10; iter: 400; batch classifier loss: 0.342979; batch adversarial loss: 0.560096\n",
      "epoch 11; iter: 0; batch classifier loss: 0.436892; batch adversarial loss: 0.636876\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449369; batch adversarial loss: 0.572258\n",
      "epoch 11; iter: 400; batch classifier loss: 0.326623; batch adversarial loss: 0.653675\n",
      "epoch 12; iter: 0; batch classifier loss: 0.415024; batch adversarial loss: 0.679750\n",
      "epoch 12; iter: 200; batch classifier loss: 0.897628; batch adversarial loss: 0.680350\n",
      "epoch 12; iter: 400; batch classifier loss: 0.529937; batch adversarial loss: 0.520763\n",
      "epoch 13; iter: 0; batch classifier loss: 0.401180; batch adversarial loss: 0.639500\n",
      "epoch 13; iter: 200; batch classifier loss: 0.407900; batch adversarial loss: 0.580274\n",
      "epoch 13; iter: 400; batch classifier loss: 0.337277; batch adversarial loss: 0.561346\n",
      "epoch 14; iter: 0; batch classifier loss: 0.280151; batch adversarial loss: 0.606559\n",
      "epoch 14; iter: 200; batch classifier loss: 0.339616; batch adversarial loss: 0.652108\n",
      "epoch 14; iter: 400; batch classifier loss: 0.359786; batch adversarial loss: 0.572715\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344586; batch adversarial loss: 0.649177\n",
      "epoch 15; iter: 200; batch classifier loss: 0.311810; batch adversarial loss: 0.659571\n",
      "epoch 15; iter: 400; batch classifier loss: 0.452512; batch adversarial loss: 0.664556\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357813; batch adversarial loss: 0.602925\n",
      "epoch 16; iter: 200; batch classifier loss: 0.527356; batch adversarial loss: 0.527264\n",
      "epoch 16; iter: 400; batch classifier loss: 0.390234; batch adversarial loss: 0.648293\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539434; batch adversarial loss: 0.588657\n",
      "epoch 17; iter: 200; batch classifier loss: 0.430497; batch adversarial loss: 0.644321\n",
      "epoch 17; iter: 400; batch classifier loss: 0.315975; batch adversarial loss: 0.628047\n",
      "epoch 18; iter: 0; batch classifier loss: 0.377142; batch adversarial loss: 0.622748\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373666; batch adversarial loss: 0.629652\n",
      "epoch 18; iter: 400; batch classifier loss: 0.405702; batch adversarial loss: 0.577139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.270173; batch adversarial loss: 0.624358\n",
      "epoch 19; iter: 200; batch classifier loss: 0.433685; batch adversarial loss: 0.661276\n",
      "epoch 19; iter: 400; batch classifier loss: 0.302133; batch adversarial loss: 0.588610\n",
      "epoch 20; iter: 0; batch classifier loss: 0.427606; batch adversarial loss: 0.654078\n",
      "epoch 20; iter: 200; batch classifier loss: 0.350519; batch adversarial loss: 0.655742\n",
      "epoch 20; iter: 400; batch classifier loss: 0.411578; batch adversarial loss: 0.664701\n",
      "epoch 21; iter: 0; batch classifier loss: 0.223973; batch adversarial loss: 0.655714\n",
      "epoch 21; iter: 200; batch classifier loss: 0.338358; batch adversarial loss: 0.724410\n",
      "epoch 21; iter: 400; batch classifier loss: 0.357460; batch adversarial loss: 0.592942\n",
      "epoch 22; iter: 0; batch classifier loss: 0.343492; batch adversarial loss: 0.610677\n",
      "epoch 22; iter: 200; batch classifier loss: 0.450922; batch adversarial loss: 0.616402\n",
      "epoch 22; iter: 400; batch classifier loss: 0.494830; batch adversarial loss: 0.740106\n",
      "epoch 23; iter: 0; batch classifier loss: 0.238925; batch adversarial loss: 0.686344\n",
      "epoch 23; iter: 200; batch classifier loss: 0.385245; batch adversarial loss: 0.581755\n",
      "epoch 23; iter: 400; batch classifier loss: 0.325107; batch adversarial loss: 0.562788\n",
      "epoch 24; iter: 0; batch classifier loss: 0.484740; batch adversarial loss: 0.493902\n",
      "epoch 24; iter: 200; batch classifier loss: 0.506155; batch adversarial loss: 0.651311\n",
      "epoch 24; iter: 400; batch classifier loss: 0.442053; batch adversarial loss: 0.673934\n",
      "epoch 25; iter: 0; batch classifier loss: 0.249284; batch adversarial loss: 0.613469\n",
      "epoch 25; iter: 200; batch classifier loss: 0.352686; batch adversarial loss: 0.637774\n",
      "epoch 25; iter: 400; batch classifier loss: 0.315300; batch adversarial loss: 0.581365\n",
      "epoch 26; iter: 0; batch classifier loss: 0.227949; batch adversarial loss: 0.681926\n",
      "epoch 26; iter: 200; batch classifier loss: 0.436136; batch adversarial loss: 0.689306\n",
      "epoch 26; iter: 400; batch classifier loss: 0.294702; batch adversarial loss: 0.612606\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425729; batch adversarial loss: 0.636764\n",
      "epoch 27; iter: 200; batch classifier loss: 0.287134; batch adversarial loss: 0.701441\n",
      "epoch 27; iter: 400; batch classifier loss: 0.327410; batch adversarial loss: 0.721845\n",
      "epoch 28; iter: 0; batch classifier loss: 0.318688; batch adversarial loss: 0.575721\n",
      "epoch 28; iter: 200; batch classifier loss: 0.256774; batch adversarial loss: 0.661817\n",
      "epoch 28; iter: 400; batch classifier loss: 0.424001; batch adversarial loss: 0.692976\n",
      "epoch 29; iter: 0; batch classifier loss: 0.329477; batch adversarial loss: 0.694264\n",
      "epoch 29; iter: 200; batch classifier loss: 0.432968; batch adversarial loss: 0.618330\n",
      "epoch 29; iter: 400; batch classifier loss: 0.451882; batch adversarial loss: 0.614450\n",
      "epoch 30; iter: 0; batch classifier loss: 0.387640; batch adversarial loss: 0.596770\n",
      "epoch 30; iter: 200; batch classifier loss: 0.568630; batch adversarial loss: 0.550332\n",
      "epoch 30; iter: 400; batch classifier loss: 0.456434; batch adversarial loss: 0.663631\n",
      "epoch 31; iter: 0; batch classifier loss: 0.262688; batch adversarial loss: 0.707378\n",
      "epoch 31; iter: 200; batch classifier loss: 0.487603; batch adversarial loss: 0.650159\n",
      "epoch 31; iter: 400; batch classifier loss: 0.344584; batch adversarial loss: 0.630354\n",
      "epoch 32; iter: 0; batch classifier loss: 0.530759; batch adversarial loss: 0.593378\n",
      "epoch 32; iter: 200; batch classifier loss: 0.662393; batch adversarial loss: 0.693682\n",
      "epoch 32; iter: 400; batch classifier loss: 0.353398; batch adversarial loss: 0.593396\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424835; batch adversarial loss: 0.618575\n",
      "epoch 33; iter: 200; batch classifier loss: 0.513072; batch adversarial loss: 0.599655\n",
      "epoch 33; iter: 400; batch classifier loss: 0.279393; batch adversarial loss: 0.622676\n",
      "epoch 34; iter: 0; batch classifier loss: 0.295505; batch adversarial loss: 0.655214\n",
      "epoch 34; iter: 200; batch classifier loss: 0.364212; batch adversarial loss: 0.622147\n",
      "epoch 34; iter: 400; batch classifier loss: 0.572016; batch adversarial loss: 0.570033\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485594; batch adversarial loss: 0.657056\n",
      "epoch 35; iter: 200; batch classifier loss: 0.423601; batch adversarial loss: 0.657548\n",
      "epoch 35; iter: 400; batch classifier loss: 0.512806; batch adversarial loss: 0.686809\n",
      "epoch 36; iter: 0; batch classifier loss: 0.550048; batch adversarial loss: 0.526552\n",
      "epoch 36; iter: 200; batch classifier loss: 0.485984; batch adversarial loss: 0.676763\n",
      "epoch 36; iter: 400; batch classifier loss: 0.597008; batch adversarial loss: 0.598229\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476777; batch adversarial loss: 0.633220\n",
      "epoch 37; iter: 200; batch classifier loss: 0.357956; batch adversarial loss: 0.566656\n",
      "epoch 37; iter: 400; batch classifier loss: 0.476175; batch adversarial loss: 0.670632\n",
      "epoch 38; iter: 0; batch classifier loss: 0.366560; batch adversarial loss: 0.603087\n",
      "epoch 38; iter: 200; batch classifier loss: 0.417589; batch adversarial loss: 0.658189\n",
      "epoch 38; iter: 400; batch classifier loss: 0.392317; batch adversarial loss: 0.706536\n",
      "epoch 39; iter: 0; batch classifier loss: 0.388413; batch adversarial loss: 0.642971\n",
      "epoch 39; iter: 200; batch classifier loss: 0.319951; batch adversarial loss: 0.612452\n",
      "epoch 39; iter: 400; batch classifier loss: 0.469744; batch adversarial loss: 0.688332\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466699; batch adversarial loss: 0.561847\n",
      "epoch 40; iter: 200; batch classifier loss: 0.357121; batch adversarial loss: 0.650398\n",
      "epoch 40; iter: 400; batch classifier loss: 0.495313; batch adversarial loss: 0.565767\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397767; batch adversarial loss: 0.544212\n",
      "epoch 41; iter: 200; batch classifier loss: 0.378593; batch adversarial loss: 0.632278\n",
      "epoch 41; iter: 400; batch classifier loss: 0.478268; batch adversarial loss: 0.618367\n",
      "epoch 42; iter: 0; batch classifier loss: 0.380249; batch adversarial loss: 0.583449\n",
      "epoch 42; iter: 200; batch classifier loss: 0.430321; batch adversarial loss: 0.642490\n",
      "epoch 42; iter: 400; batch classifier loss: 0.506703; batch adversarial loss: 0.643620\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454641; batch adversarial loss: 0.672345\n",
      "epoch 43; iter: 200; batch classifier loss: 0.535577; batch adversarial loss: 0.621376\n",
      "epoch 43; iter: 400; batch classifier loss: 0.539237; batch adversarial loss: 0.596499\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443644; batch adversarial loss: 0.672451\n",
      "epoch 44; iter: 200; batch classifier loss: 0.304965; batch adversarial loss: 0.621692\n",
      "epoch 44; iter: 400; batch classifier loss: 0.363441; batch adversarial loss: 0.591559\n",
      "epoch 45; iter: 0; batch classifier loss: 0.284009; batch adversarial loss: 0.691063\n",
      "epoch 45; iter: 200; batch classifier loss: 0.436409; batch adversarial loss: 0.562113\n",
      "epoch 45; iter: 400; batch classifier loss: 0.406062; batch adversarial loss: 0.653212\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381395; batch adversarial loss: 0.716129\n",
      "epoch 46; iter: 200; batch classifier loss: 0.639854; batch adversarial loss: 0.645296\n",
      "epoch 46; iter: 400; batch classifier loss: 0.633146; batch adversarial loss: 0.653638\n",
      "epoch 47; iter: 0; batch classifier loss: 0.571837; batch adversarial loss: 0.635948\n",
      "epoch 47; iter: 200; batch classifier loss: 0.339715; batch adversarial loss: 0.651218\n",
      "epoch 47; iter: 400; batch classifier loss: 0.778365; batch adversarial loss: 0.588574\n",
      "epoch 48; iter: 0; batch classifier loss: 0.480400; batch adversarial loss: 0.507995\n",
      "epoch 48; iter: 200; batch classifier loss: 0.336009; batch adversarial loss: 0.654267\n",
      "epoch 48; iter: 400; batch classifier loss: 0.436712; batch adversarial loss: 0.613550\n",
      "epoch 49; iter: 0; batch classifier loss: 0.502974; batch adversarial loss: 0.667293\n",
      "epoch 49; iter: 200; batch classifier loss: 0.519071; batch adversarial loss: 0.487010\n",
      "epoch 49; iter: 400; batch classifier loss: 0.326008; batch adversarial loss: 0.657011\n",
      "epoch 0; iter: 0; batch classifier loss: 27.933739; batch adversarial loss: 0.668228\n",
      "epoch 0; iter: 200; batch classifier loss: 5.125368; batch adversarial loss: 0.689033\n",
      "epoch 0; iter: 400; batch classifier loss: 0.453676; batch adversarial loss: 0.586884\n",
      "epoch 1; iter: 0; batch classifier loss: 7.250453; batch adversarial loss: 0.573089\n",
      "epoch 1; iter: 200; batch classifier loss: 3.630135; batch adversarial loss: 0.599393\n",
      "epoch 1; iter: 400; batch classifier loss: 4.941546; batch adversarial loss: 0.590914\n",
      "epoch 2; iter: 0; batch classifier loss: 11.417789; batch adversarial loss: 0.547238\n",
      "epoch 2; iter: 200; batch classifier loss: 17.373653; batch adversarial loss: 0.649278\n",
      "epoch 2; iter: 400; batch classifier loss: 4.253811; batch adversarial loss: 0.644798\n",
      "epoch 3; iter: 0; batch classifier loss: 2.225488; batch adversarial loss: 0.638024\n",
      "epoch 3; iter: 200; batch classifier loss: 3.463595; batch adversarial loss: 0.665254\n",
      "epoch 3; iter: 400; batch classifier loss: 1.063453; batch adversarial loss: 0.619029\n",
      "epoch 4; iter: 0; batch classifier loss: 1.383567; batch adversarial loss: 0.673801\n",
      "epoch 4; iter: 200; batch classifier loss: 0.616786; batch adversarial loss: 0.667187\n",
      "epoch 4; iter: 400; batch classifier loss: 0.363178; batch adversarial loss: 0.635556\n",
      "epoch 5; iter: 0; batch classifier loss: 1.402463; batch adversarial loss: 0.566487\n",
      "epoch 5; iter: 200; batch classifier loss: 0.446611; batch adversarial loss: 0.672067\n",
      "epoch 5; iter: 400; batch classifier loss: 0.850051; batch adversarial loss: 0.648379\n",
      "epoch 6; iter: 0; batch classifier loss: 2.043031; batch adversarial loss: 0.642707\n",
      "epoch 6; iter: 200; batch classifier loss: 0.750939; batch adversarial loss: 0.683825\n",
      "epoch 6; iter: 400; batch classifier loss: 0.448977; batch adversarial loss: 0.719037\n",
      "epoch 7; iter: 0; batch classifier loss: 0.649648; batch adversarial loss: 0.659509\n",
      "epoch 7; iter: 200; batch classifier loss: 0.249375; batch adversarial loss: 0.643174\n",
      "epoch 7; iter: 400; batch classifier loss: 0.410825; batch adversarial loss: 0.589546\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508170; batch adversarial loss: 0.648970\n",
      "epoch 8; iter: 200; batch classifier loss: 0.410847; batch adversarial loss: 0.656878\n",
      "epoch 8; iter: 400; batch classifier loss: 0.383688; batch adversarial loss: 0.658617\n",
      "epoch 9; iter: 0; batch classifier loss: 0.313200; batch adversarial loss: 0.742450\n",
      "epoch 9; iter: 200; batch classifier loss: 0.432071; batch adversarial loss: 0.575293\n",
      "epoch 9; iter: 400; batch classifier loss: 0.267986; batch adversarial loss: 0.708433\n",
      "epoch 10; iter: 0; batch classifier loss: 0.377491; batch adversarial loss: 0.671407\n",
      "epoch 10; iter: 200; batch classifier loss: 0.456132; batch adversarial loss: 0.572563\n",
      "epoch 10; iter: 400; batch classifier loss: 0.576759; batch adversarial loss: 0.626583\n",
      "epoch 11; iter: 0; batch classifier loss: 0.383359; batch adversarial loss: 0.516937\n",
      "epoch 11; iter: 200; batch classifier loss: 0.291288; batch adversarial loss: 0.666437\n",
      "epoch 11; iter: 400; batch classifier loss: 0.413815; batch adversarial loss: 0.579863\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299295; batch adversarial loss: 0.621605\n",
      "epoch 12; iter: 200; batch classifier loss: 0.340436; batch adversarial loss: 0.655819\n",
      "epoch 12; iter: 400; batch classifier loss: 0.413122; batch adversarial loss: 0.670733\n",
      "epoch 13; iter: 0; batch classifier loss: 0.486314; batch adversarial loss: 0.611168\n",
      "epoch 13; iter: 200; batch classifier loss: 0.402605; batch adversarial loss: 0.658197\n",
      "epoch 13; iter: 400; batch classifier loss: 0.313469; batch adversarial loss: 0.699326\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389467; batch adversarial loss: 0.525149\n",
      "epoch 14; iter: 200; batch classifier loss: 0.447054; batch adversarial loss: 0.666974\n",
      "epoch 14; iter: 400; batch classifier loss: 0.529468; batch adversarial loss: 0.623300\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469500; batch adversarial loss: 0.685440\n",
      "epoch 15; iter: 200; batch classifier loss: 0.393411; batch adversarial loss: 0.621437\n",
      "epoch 15; iter: 400; batch classifier loss: 0.424464; batch adversarial loss: 0.526741\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319172; batch adversarial loss: 0.683488\n",
      "epoch 16; iter: 200; batch classifier loss: 0.346179; batch adversarial loss: 0.569706\n",
      "epoch 16; iter: 400; batch classifier loss: 0.399414; batch adversarial loss: 0.610529\n",
      "epoch 17; iter: 0; batch classifier loss: 0.485003; batch adversarial loss: 0.549670\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339674; batch adversarial loss: 0.665955\n",
      "epoch 17; iter: 400; batch classifier loss: 0.561059; batch adversarial loss: 0.557206\n",
      "epoch 18; iter: 0; batch classifier loss: 0.532639; batch adversarial loss: 0.597988\n",
      "epoch 18; iter: 200; batch classifier loss: 0.428104; batch adversarial loss: 0.633119\n",
      "epoch 18; iter: 400; batch classifier loss: 0.290385; batch adversarial loss: 0.668320\n",
      "epoch 19; iter: 0; batch classifier loss: 0.363727; batch adversarial loss: 0.629926\n",
      "epoch 19; iter: 200; batch classifier loss: 0.322390; batch adversarial loss: 0.610247\n",
      "epoch 19; iter: 400; batch classifier loss: 0.350945; batch adversarial loss: 0.581119\n",
      "epoch 20; iter: 0; batch classifier loss: 0.315027; batch adversarial loss: 0.660847\n",
      "epoch 20; iter: 200; batch classifier loss: 0.389507; batch adversarial loss: 0.720451\n",
      "epoch 20; iter: 400; batch classifier loss: 0.457552; batch adversarial loss: 0.528132\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454736; batch adversarial loss: 0.587116\n",
      "epoch 21; iter: 200; batch classifier loss: 0.335951; batch adversarial loss: 0.570579\n",
      "epoch 21; iter: 400; batch classifier loss: 0.436484; batch adversarial loss: 0.596004\n",
      "epoch 22; iter: 0; batch classifier loss: 0.393178; batch adversarial loss: 0.560957\n",
      "epoch 22; iter: 200; batch classifier loss: 0.459404; batch adversarial loss: 0.612369\n",
      "epoch 22; iter: 400; batch classifier loss: 0.505278; batch adversarial loss: 0.640659\n",
      "epoch 23; iter: 0; batch classifier loss: 0.405241; batch adversarial loss: 0.637357\n",
      "epoch 23; iter: 200; batch classifier loss: 0.209877; batch adversarial loss: 0.631876\n",
      "epoch 23; iter: 400; batch classifier loss: 0.227014; batch adversarial loss: 0.619464\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400479; batch adversarial loss: 0.632826\n",
      "epoch 24; iter: 200; batch classifier loss: 0.172134; batch adversarial loss: 0.650203\n",
      "epoch 24; iter: 400; batch classifier loss: 0.376168; batch adversarial loss: 0.602859\n",
      "epoch 25; iter: 0; batch classifier loss: 0.244041; batch adversarial loss: 0.753235\n",
      "epoch 25; iter: 200; batch classifier loss: 0.283611; batch adversarial loss: 0.608825\n",
      "epoch 25; iter: 400; batch classifier loss: 0.630949; batch adversarial loss: 0.585432\n",
      "epoch 26; iter: 0; batch classifier loss: 0.354645; batch adversarial loss: 0.690362\n",
      "epoch 26; iter: 200; batch classifier loss: 0.455525; batch adversarial loss: 0.616673\n",
      "epoch 26; iter: 400; batch classifier loss: 0.415743; batch adversarial loss: 0.550107\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274929; batch adversarial loss: 0.547880\n",
      "epoch 27; iter: 200; batch classifier loss: 0.443105; batch adversarial loss: 0.594648\n",
      "epoch 27; iter: 400; batch classifier loss: 0.361479; batch adversarial loss: 0.582654\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402639; batch adversarial loss: 0.578027\n",
      "epoch 28; iter: 200; batch classifier loss: 0.323991; batch adversarial loss: 0.675884\n",
      "epoch 28; iter: 400; batch classifier loss: 0.465390; batch adversarial loss: 0.639024\n",
      "epoch 29; iter: 0; batch classifier loss: 0.336529; batch adversarial loss: 0.622816\n",
      "epoch 29; iter: 200; batch classifier loss: 0.436437; batch adversarial loss: 0.623760\n",
      "epoch 29; iter: 400; batch classifier loss: 0.388680; batch adversarial loss: 0.640437\n",
      "epoch 30; iter: 0; batch classifier loss: 0.450099; batch adversarial loss: 0.619960\n",
      "epoch 30; iter: 200; batch classifier loss: 0.522515; batch adversarial loss: 0.668472\n",
      "epoch 30; iter: 400; batch classifier loss: 0.321814; batch adversarial loss: 0.643640\n",
      "epoch 31; iter: 0; batch classifier loss: 0.562675; batch adversarial loss: 0.704562\n",
      "epoch 31; iter: 200; batch classifier loss: 0.349061; batch adversarial loss: 0.658507\n",
      "epoch 31; iter: 400; batch classifier loss: 0.361392; batch adversarial loss: 0.590776\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459795; batch adversarial loss: 0.746878\n",
      "epoch 32; iter: 200; batch classifier loss: 0.346137; batch adversarial loss: 0.689955\n",
      "epoch 32; iter: 400; batch classifier loss: 0.838466; batch adversarial loss: 0.583692\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433618; batch adversarial loss: 0.581886\n",
      "epoch 33; iter: 200; batch classifier loss: 0.261896; batch adversarial loss: 0.724980\n",
      "epoch 33; iter: 400; batch classifier loss: 0.407381; batch adversarial loss: 0.608098\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453924; batch adversarial loss: 0.560687\n",
      "epoch 34; iter: 200; batch classifier loss: 0.356871; batch adversarial loss: 0.618216\n",
      "epoch 34; iter: 400; batch classifier loss: 0.224858; batch adversarial loss: 0.698379\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478303; batch adversarial loss: 0.604634\n",
      "epoch 35; iter: 200; batch classifier loss: 0.401370; batch adversarial loss: 0.681850\n",
      "epoch 35; iter: 400; batch classifier loss: 0.210990; batch adversarial loss: 0.704694\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293920; batch adversarial loss: 0.686725\n",
      "epoch 36; iter: 200; batch classifier loss: 0.465975; batch adversarial loss: 0.692520\n",
      "epoch 36; iter: 400; batch classifier loss: 0.421194; batch adversarial loss: 0.642671\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414462; batch adversarial loss: 0.607510\n",
      "epoch 37; iter: 200; batch classifier loss: 0.469947; batch adversarial loss: 0.658361\n",
      "epoch 37; iter: 400; batch classifier loss: 0.329084; batch adversarial loss: 0.657483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.510275; batch adversarial loss: 0.652142\n",
      "epoch 38; iter: 200; batch classifier loss: 0.410100; batch adversarial loss: 0.621186\n",
      "epoch 38; iter: 400; batch classifier loss: 0.255648; batch adversarial loss: 0.717188\n",
      "epoch 39; iter: 0; batch classifier loss: 0.497859; batch adversarial loss: 0.651563\n",
      "epoch 39; iter: 200; batch classifier loss: 0.322465; batch adversarial loss: 0.660752\n",
      "epoch 39; iter: 400; batch classifier loss: 0.247757; batch adversarial loss: 0.716455\n",
      "epoch 40; iter: 0; batch classifier loss: 1.047074; batch adversarial loss: 0.591434\n",
      "epoch 40; iter: 200; batch classifier loss: 0.490377; batch adversarial loss: 0.578284\n",
      "epoch 40; iter: 400; batch classifier loss: 0.859658; batch adversarial loss: 0.576396\n",
      "epoch 41; iter: 0; batch classifier loss: 0.545638; batch adversarial loss: 0.642890\n",
      "epoch 41; iter: 200; batch classifier loss: 0.383710; batch adversarial loss: 0.563713\n",
      "epoch 41; iter: 400; batch classifier loss: 0.515008; batch adversarial loss: 0.639482\n",
      "epoch 42; iter: 0; batch classifier loss: 0.359123; batch adversarial loss: 0.594390\n",
      "epoch 42; iter: 200; batch classifier loss: 0.597041; batch adversarial loss: 0.545662\n",
      "epoch 42; iter: 400; batch classifier loss: 0.404554; batch adversarial loss: 0.604895\n",
      "epoch 43; iter: 0; batch classifier loss: 0.521612; batch adversarial loss: 0.604315\n",
      "epoch 43; iter: 200; batch classifier loss: 0.457115; batch adversarial loss: 0.570722\n",
      "epoch 43; iter: 400; batch classifier loss: 0.388344; batch adversarial loss: 0.584444\n",
      "epoch 44; iter: 0; batch classifier loss: 0.475551; batch adversarial loss: 0.558837\n",
      "epoch 44; iter: 200; batch classifier loss: 0.453469; batch adversarial loss: 0.551491\n",
      "epoch 44; iter: 400; batch classifier loss: 0.408831; batch adversarial loss: 0.601918\n",
      "epoch 45; iter: 0; batch classifier loss: 0.724720; batch adversarial loss: 0.600483\n",
      "epoch 45; iter: 200; batch classifier loss: 0.328495; batch adversarial loss: 0.594335\n",
      "epoch 45; iter: 400; batch classifier loss: 0.375744; batch adversarial loss: 0.620288\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324560; batch adversarial loss: 0.624924\n",
      "epoch 46; iter: 200; batch classifier loss: 0.403037; batch adversarial loss: 0.639935\n",
      "epoch 46; iter: 400; batch classifier loss: 0.648909; batch adversarial loss: 0.626997\n",
      "epoch 47; iter: 0; batch classifier loss: 0.494878; batch adversarial loss: 0.644737\n",
      "epoch 47; iter: 200; batch classifier loss: 0.505641; batch adversarial loss: 0.521581\n",
      "epoch 47; iter: 400; batch classifier loss: 0.336657; batch adversarial loss: 0.607869\n",
      "epoch 48; iter: 0; batch classifier loss: 0.126686; batch adversarial loss: 0.651999\n",
      "epoch 48; iter: 200; batch classifier loss: 0.246266; batch adversarial loss: 0.612294\n",
      "epoch 48; iter: 400; batch classifier loss: 0.348179; batch adversarial loss: 0.668384\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432138; batch adversarial loss: 0.661580\n",
      "epoch 49; iter: 200; batch classifier loss: 0.327954; batch adversarial loss: 0.672042\n",
      "epoch 49; iter: 400; batch classifier loss: 0.480148; batch adversarial loss: 0.577363\n",
      "epoch 0; iter: 0; batch classifier loss: 14.436561; batch adversarial loss: 0.681294\n",
      "epoch 0; iter: 200; batch classifier loss: 8.731953; batch adversarial loss: 0.632082\n",
      "epoch 0; iter: 400; batch classifier loss: 5.951377; batch adversarial loss: 0.637843\n",
      "epoch 1; iter: 0; batch classifier loss: 3.543535; batch adversarial loss: 0.693937\n",
      "epoch 1; iter: 200; batch classifier loss: 3.865164; batch adversarial loss: 0.635967\n",
      "epoch 1; iter: 400; batch classifier loss: 0.361500; batch adversarial loss: 0.726976\n",
      "epoch 2; iter: 0; batch classifier loss: 3.061754; batch adversarial loss: 0.682408\n",
      "epoch 2; iter: 200; batch classifier loss: 0.611859; batch adversarial loss: 0.645668\n",
      "epoch 2; iter: 400; batch classifier loss: 2.040323; batch adversarial loss: 0.693466\n",
      "epoch 3; iter: 0; batch classifier loss: 0.505705; batch adversarial loss: 0.661510\n",
      "epoch 3; iter: 200; batch classifier loss: 1.231762; batch adversarial loss: 0.590253\n",
      "epoch 3; iter: 400; batch classifier loss: 0.724554; batch adversarial loss: 0.706853\n",
      "epoch 4; iter: 0; batch classifier loss: 0.448859; batch adversarial loss: 0.614072\n",
      "epoch 4; iter: 200; batch classifier loss: 0.498758; batch adversarial loss: 0.704647\n",
      "epoch 4; iter: 400; batch classifier loss: 0.370390; batch adversarial loss: 0.583836\n",
      "epoch 5; iter: 0; batch classifier loss: 0.954221; batch adversarial loss: 0.630756\n",
      "epoch 5; iter: 200; batch classifier loss: 0.391479; batch adversarial loss: 0.669468\n",
      "epoch 5; iter: 400; batch classifier loss: 0.883314; batch adversarial loss: 0.633690\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582483; batch adversarial loss: 0.603714\n",
      "epoch 6; iter: 200; batch classifier loss: 0.434519; batch adversarial loss: 0.656943\n",
      "epoch 6; iter: 400; batch classifier loss: 0.474398; batch adversarial loss: 0.641022\n",
      "epoch 7; iter: 0; batch classifier loss: 0.487835; batch adversarial loss: 0.574037\n",
      "epoch 7; iter: 200; batch classifier loss: 1.723432; batch adversarial loss: 0.597654\n",
      "epoch 7; iter: 400; batch classifier loss: 0.316012; batch adversarial loss: 0.733543\n",
      "epoch 8; iter: 0; batch classifier loss: 0.454713; batch adversarial loss: 0.643526\n",
      "epoch 8; iter: 200; batch classifier loss: 0.352712; batch adversarial loss: 0.638268\n",
      "epoch 8; iter: 400; batch classifier loss: 0.349437; batch adversarial loss: 0.603484\n",
      "epoch 9; iter: 0; batch classifier loss: 0.619827; batch adversarial loss: 0.654985\n",
      "epoch 9; iter: 200; batch classifier loss: 0.440921; batch adversarial loss: 0.545592\n",
      "epoch 9; iter: 400; batch classifier loss: 0.444521; batch adversarial loss: 0.634952\n",
      "epoch 10; iter: 0; batch classifier loss: 0.340627; batch adversarial loss: 0.620526\n",
      "epoch 10; iter: 200; batch classifier loss: 0.426499; batch adversarial loss: 0.656589\n",
      "epoch 10; iter: 400; batch classifier loss: 0.420398; batch adversarial loss: 0.588095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.297694; batch adversarial loss: 0.639516\n",
      "epoch 11; iter: 200; batch classifier loss: 0.370313; batch adversarial loss: 0.664284\n",
      "epoch 11; iter: 400; batch classifier loss: 0.265389; batch adversarial loss: 0.626085\n",
      "epoch 12; iter: 0; batch classifier loss: 0.387435; batch adversarial loss: 0.671784\n",
      "epoch 12; iter: 200; batch classifier loss: 0.364241; batch adversarial loss: 0.572822\n",
      "epoch 12; iter: 400; batch classifier loss: 0.303580; batch adversarial loss: 0.608011\n",
      "epoch 13; iter: 0; batch classifier loss: 0.271947; batch adversarial loss: 0.611400\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396022; batch adversarial loss: 0.643114\n",
      "epoch 13; iter: 400; batch classifier loss: 0.306584; batch adversarial loss: 0.657940\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466912; batch adversarial loss: 0.694375\n",
      "epoch 14; iter: 200; batch classifier loss: 0.243503; batch adversarial loss: 0.559492\n",
      "epoch 14; iter: 400; batch classifier loss: 0.270708; batch adversarial loss: 0.634600\n",
      "epoch 15; iter: 0; batch classifier loss: 0.360437; batch adversarial loss: 0.523887\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341907; batch adversarial loss: 0.602218\n",
      "epoch 15; iter: 400; batch classifier loss: 0.327727; batch adversarial loss: 0.584214\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341467; batch adversarial loss: 0.626027\n",
      "epoch 16; iter: 200; batch classifier loss: 0.385713; batch adversarial loss: 0.566444\n",
      "epoch 16; iter: 400; batch classifier loss: 0.444540; batch adversarial loss: 0.602888\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314976; batch adversarial loss: 0.503168\n",
      "epoch 17; iter: 200; batch classifier loss: 0.417420; batch adversarial loss: 0.614802\n",
      "epoch 17; iter: 400; batch classifier loss: 0.346380; batch adversarial loss: 0.527082\n",
      "epoch 18; iter: 0; batch classifier loss: 0.445322; batch adversarial loss: 0.681414\n",
      "epoch 18; iter: 200; batch classifier loss: 0.453748; batch adversarial loss: 0.647771\n",
      "epoch 18; iter: 400; batch classifier loss: 0.326544; batch adversarial loss: 0.596415\n",
      "epoch 19; iter: 0; batch classifier loss: 0.386184; batch adversarial loss: 0.675794\n",
      "epoch 19; iter: 200; batch classifier loss: 0.282137; batch adversarial loss: 0.564557\n",
      "epoch 19; iter: 400; batch classifier loss: 0.401570; batch adversarial loss: 0.615426\n",
      "epoch 20; iter: 0; batch classifier loss: 0.257168; batch adversarial loss: 0.673769\n",
      "epoch 20; iter: 200; batch classifier loss: 0.268577; batch adversarial loss: 0.681460\n",
      "epoch 20; iter: 400; batch classifier loss: 0.424202; batch adversarial loss: 0.669347\n",
      "epoch 21; iter: 0; batch classifier loss: 0.330154; batch adversarial loss: 0.664732\n",
      "epoch 21; iter: 200; batch classifier loss: 0.332554; batch adversarial loss: 0.656449\n",
      "epoch 21; iter: 400; batch classifier loss: 0.308914; batch adversarial loss: 0.679371\n",
      "epoch 22; iter: 0; batch classifier loss: 0.188125; batch adversarial loss: 0.631238\n",
      "epoch 22; iter: 200; batch classifier loss: 0.531208; batch adversarial loss: 0.648774\n",
      "epoch 22; iter: 400; batch classifier loss: 0.488151; batch adversarial loss: 0.574499\n",
      "epoch 23; iter: 0; batch classifier loss: 0.377199; batch adversarial loss: 0.680223\n",
      "epoch 23; iter: 200; batch classifier loss: 0.304279; batch adversarial loss: 0.567242\n",
      "epoch 23; iter: 400; batch classifier loss: 0.278917; batch adversarial loss: 0.658996\n",
      "epoch 24; iter: 0; batch classifier loss: 0.357376; batch adversarial loss: 0.700545\n",
      "epoch 24; iter: 200; batch classifier loss: 0.399180; batch adversarial loss: 0.626164\n",
      "epoch 24; iter: 400; batch classifier loss: 0.227629; batch adversarial loss: 0.606227\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555418; batch adversarial loss: 0.598603\n",
      "epoch 25; iter: 200; batch classifier loss: 0.425514; batch adversarial loss: 0.662328\n",
      "epoch 25; iter: 400; batch classifier loss: 0.357583; batch adversarial loss: 0.582501\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319344; batch adversarial loss: 0.644848\n",
      "epoch 26; iter: 200; batch classifier loss: 0.431642; batch adversarial loss: 0.658007\n",
      "epoch 26; iter: 400; batch classifier loss: 0.397979; batch adversarial loss: 0.579650\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445458; batch adversarial loss: 0.553160\n",
      "epoch 27; iter: 200; batch classifier loss: 0.401192; batch adversarial loss: 0.649325\n",
      "epoch 27; iter: 400; batch classifier loss: 0.472903; batch adversarial loss: 0.568927\n",
      "epoch 28; iter: 0; batch classifier loss: 0.354650; batch adversarial loss: 0.671710\n",
      "epoch 28; iter: 200; batch classifier loss: 0.497859; batch adversarial loss: 0.595532\n",
      "epoch 28; iter: 400; batch classifier loss: 0.559862; batch adversarial loss: 0.584079\n",
      "epoch 29; iter: 0; batch classifier loss: 0.278080; batch adversarial loss: 0.633308\n",
      "epoch 29; iter: 200; batch classifier loss: 0.365499; batch adversarial loss: 0.580922\n",
      "epoch 29; iter: 400; batch classifier loss: 0.586391; batch adversarial loss: 0.656882\n",
      "epoch 30; iter: 0; batch classifier loss: 0.678507; batch adversarial loss: 0.627938\n",
      "epoch 30; iter: 200; batch classifier loss: 0.398231; batch adversarial loss: 0.690699\n",
      "epoch 30; iter: 400; batch classifier loss: 0.366586; batch adversarial loss: 0.662839\n",
      "epoch 31; iter: 0; batch classifier loss: 0.238335; batch adversarial loss: 0.610007\n",
      "epoch 31; iter: 200; batch classifier loss: 1.367437; batch adversarial loss: 0.635078\n",
      "epoch 31; iter: 400; batch classifier loss: 0.316018; batch adversarial loss: 0.624462\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364147; batch adversarial loss: 0.632466\n",
      "epoch 32; iter: 200; batch classifier loss: 0.336045; batch adversarial loss: 0.642676\n",
      "epoch 32; iter: 400; batch classifier loss: 0.332348; batch adversarial loss: 0.648960\n",
      "epoch 33; iter: 0; batch classifier loss: 0.513676; batch adversarial loss: 0.613058\n",
      "epoch 33; iter: 200; batch classifier loss: 0.594658; batch adversarial loss: 0.574342\n",
      "epoch 33; iter: 400; batch classifier loss: 0.564161; batch adversarial loss: 0.562039\n",
      "epoch 34; iter: 0; batch classifier loss: 0.358759; batch adversarial loss: 0.621193\n",
      "epoch 34; iter: 200; batch classifier loss: 0.562219; batch adversarial loss: 0.623695\n",
      "epoch 34; iter: 400; batch classifier loss: 0.384943; batch adversarial loss: 0.620675\n",
      "epoch 35; iter: 0; batch classifier loss: 0.418810; batch adversarial loss: 0.652222\n",
      "epoch 35; iter: 200; batch classifier loss: 0.371224; batch adversarial loss: 0.638397\n",
      "epoch 35; iter: 400; batch classifier loss: 0.384941; batch adversarial loss: 0.585655\n",
      "epoch 36; iter: 0; batch classifier loss: 0.531100; batch adversarial loss: 0.615672\n",
      "epoch 36; iter: 200; batch classifier loss: 0.455399; batch adversarial loss: 0.623828\n",
      "epoch 36; iter: 400; batch classifier loss: 0.456381; batch adversarial loss: 0.566914\n",
      "epoch 37; iter: 0; batch classifier loss: 0.462376; batch adversarial loss: 0.731351\n",
      "epoch 37; iter: 200; batch classifier loss: 0.284510; batch adversarial loss: 0.684926\n",
      "epoch 37; iter: 400; batch classifier loss: 0.352534; batch adversarial loss: 0.663033\n",
      "epoch 38; iter: 0; batch classifier loss: 0.387488; batch adversarial loss: 0.642860\n",
      "epoch 38; iter: 200; batch classifier loss: 0.357892; batch adversarial loss: 0.594963\n",
      "epoch 38; iter: 400; batch classifier loss: 0.248328; batch adversarial loss: 0.624097\n",
      "epoch 39; iter: 0; batch classifier loss: 0.354520; batch adversarial loss: 0.680779\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349275; batch adversarial loss: 0.614234\n",
      "epoch 39; iter: 400; batch classifier loss: 0.535176; batch adversarial loss: 0.625821\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406071; batch adversarial loss: 0.653407\n",
      "epoch 40; iter: 200; batch classifier loss: 0.326480; batch adversarial loss: 0.686206\n",
      "epoch 40; iter: 400; batch classifier loss: 0.352263; batch adversarial loss: 0.600607\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430621; batch adversarial loss: 0.534287\n",
      "epoch 41; iter: 200; batch classifier loss: 0.465791; batch adversarial loss: 0.630004\n",
      "epoch 41; iter: 400; batch classifier loss: 0.289673; batch adversarial loss: 0.541147\n",
      "epoch 42; iter: 0; batch classifier loss: 0.666301; batch adversarial loss: 0.604663\n",
      "epoch 42; iter: 200; batch classifier loss: 0.340555; batch adversarial loss: 0.683351\n",
      "epoch 42; iter: 400; batch classifier loss: 0.511549; batch adversarial loss: 0.619451\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423835; batch adversarial loss: 0.678104\n",
      "epoch 43; iter: 200; batch classifier loss: 0.372815; batch adversarial loss: 0.612225\n",
      "epoch 43; iter: 400; batch classifier loss: 0.347568; batch adversarial loss: 0.660691\n",
      "epoch 44; iter: 0; batch classifier loss: 0.374496; batch adversarial loss: 0.682247\n",
      "epoch 44; iter: 200; batch classifier loss: 0.515392; batch adversarial loss: 0.683326\n",
      "epoch 44; iter: 400; batch classifier loss: 0.664044; batch adversarial loss: 0.628729\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479325; batch adversarial loss: 0.662061\n",
      "epoch 45; iter: 200; batch classifier loss: 0.340138; batch adversarial loss: 0.583942\n",
      "epoch 45; iter: 400; batch classifier loss: 0.382628; batch adversarial loss: 0.609352\n",
      "epoch 46; iter: 0; batch classifier loss: 0.323120; batch adversarial loss: 0.695134\n",
      "epoch 46; iter: 200; batch classifier loss: 0.374314; batch adversarial loss: 0.591542\n",
      "epoch 46; iter: 400; batch classifier loss: 0.561937; batch adversarial loss: 0.576951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.459444; batch adversarial loss: 0.592868\n",
      "epoch 47; iter: 200; batch classifier loss: 0.500901; batch adversarial loss: 0.618416\n",
      "epoch 47; iter: 400; batch classifier loss: 0.299247; batch adversarial loss: 0.663534\n",
      "epoch 48; iter: 0; batch classifier loss: 0.483440; batch adversarial loss: 0.618075\n",
      "epoch 48; iter: 200; batch classifier loss: 0.307418; batch adversarial loss: 0.651458\n",
      "epoch 48; iter: 400; batch classifier loss: 0.337382; batch adversarial loss: 0.612081\n",
      "epoch 49; iter: 0; batch classifier loss: 0.329360; batch adversarial loss: 0.583944\n",
      "epoch 49; iter: 200; batch classifier loss: 0.412273; batch adversarial loss: 0.615855\n",
      "epoch 49; iter: 400; batch classifier loss: 0.490907; batch adversarial loss: 0.577545\n",
      "epoch 0; iter: 0; batch classifier loss: 10.920667; batch adversarial loss: 0.696423\n",
      "epoch 0; iter: 200; batch classifier loss: 9.486862; batch adversarial loss: 0.648784\n",
      "epoch 0; iter: 400; batch classifier loss: 5.491017; batch adversarial loss: 0.651186\n",
      "epoch 1; iter: 0; batch classifier loss: 3.765615; batch adversarial loss: 0.662805\n",
      "epoch 1; iter: 200; batch classifier loss: 3.147633; batch adversarial loss: 0.583668\n",
      "epoch 1; iter: 400; batch classifier loss: 2.655724; batch adversarial loss: 0.662170\n",
      "epoch 2; iter: 0; batch classifier loss: 6.707294; batch adversarial loss: 0.639362\n",
      "epoch 2; iter: 200; batch classifier loss: 0.929457; batch adversarial loss: 0.643876\n",
      "epoch 2; iter: 400; batch classifier loss: 2.845362; batch adversarial loss: 0.617403\n",
      "epoch 3; iter: 0; batch classifier loss: 0.823955; batch adversarial loss: 0.647364\n",
      "epoch 3; iter: 200; batch classifier loss: 1.271052; batch adversarial loss: 0.677287\n",
      "epoch 3; iter: 400; batch classifier loss: 0.383178; batch adversarial loss: 0.689426\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583374; batch adversarial loss: 0.666801\n",
      "epoch 4; iter: 200; batch classifier loss: 1.930109; batch adversarial loss: 0.664415\n",
      "epoch 4; iter: 400; batch classifier loss: 0.709017; batch adversarial loss: 0.628989\n",
      "epoch 5; iter: 0; batch classifier loss: 0.440182; batch adversarial loss: 0.652354\n",
      "epoch 5; iter: 200; batch classifier loss: 0.524874; batch adversarial loss: 0.656764\n",
      "epoch 5; iter: 400; batch classifier loss: 0.720585; batch adversarial loss: 0.627899\n",
      "epoch 6; iter: 0; batch classifier loss: 0.426829; batch adversarial loss: 0.597931\n",
      "epoch 6; iter: 200; batch classifier loss: 0.858990; batch adversarial loss: 0.553629\n",
      "epoch 6; iter: 400; batch classifier loss: 0.430392; batch adversarial loss: 0.642393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.374593; batch adversarial loss: 0.645526\n",
      "epoch 7; iter: 200; batch classifier loss: 0.311337; batch adversarial loss: 0.626297\n",
      "epoch 7; iter: 400; batch classifier loss: 0.398041; batch adversarial loss: 0.556852\n",
      "epoch 8; iter: 0; batch classifier loss: 0.302026; batch adversarial loss: 0.572791\n",
      "epoch 8; iter: 200; batch classifier loss: 0.655941; batch adversarial loss: 0.594548\n",
      "epoch 8; iter: 400; batch classifier loss: 0.326121; batch adversarial loss: 0.703722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.417835; batch adversarial loss: 0.529679\n",
      "epoch 9; iter: 200; batch classifier loss: 0.356423; batch adversarial loss: 0.616265\n",
      "epoch 9; iter: 400; batch classifier loss: 0.575375; batch adversarial loss: 0.686873\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486960; batch adversarial loss: 0.717873\n",
      "epoch 10; iter: 200; batch classifier loss: 0.742171; batch adversarial loss: 0.604728\n",
      "epoch 10; iter: 400; batch classifier loss: 0.336365; batch adversarial loss: 0.642998\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580898; batch adversarial loss: 0.629086\n",
      "epoch 11; iter: 200; batch classifier loss: 0.364895; batch adversarial loss: 0.556967\n",
      "epoch 11; iter: 400; batch classifier loss: 0.351553; batch adversarial loss: 0.614540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413167; batch adversarial loss: 0.683006\n",
      "epoch 12; iter: 200; batch classifier loss: 0.477085; batch adversarial loss: 0.673507\n",
      "epoch 12; iter: 400; batch classifier loss: 0.342659; batch adversarial loss: 0.601451\n",
      "epoch 13; iter: 0; batch classifier loss: 0.358117; batch adversarial loss: 0.634920\n",
      "epoch 13; iter: 200; batch classifier loss: 0.364727; batch adversarial loss: 0.659056\n",
      "epoch 13; iter: 400; batch classifier loss: 0.411609; batch adversarial loss: 0.629739\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501093; batch adversarial loss: 0.607506\n",
      "epoch 14; iter: 200; batch classifier loss: 0.341182; batch adversarial loss: 0.668661\n",
      "epoch 14; iter: 400; batch classifier loss: 0.298795; batch adversarial loss: 0.673619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.308937; batch adversarial loss: 0.671093\n",
      "epoch 15; iter: 200; batch classifier loss: 0.460392; batch adversarial loss: 0.553382\n",
      "epoch 15; iter: 400; batch classifier loss: 0.275624; batch adversarial loss: 0.683341\n",
      "epoch 16; iter: 0; batch classifier loss: 0.329549; batch adversarial loss: 0.639371\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399376; batch adversarial loss: 0.587121\n",
      "epoch 16; iter: 400; batch classifier loss: 0.373145; batch adversarial loss: 0.571133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296936; batch adversarial loss: 0.653497\n",
      "epoch 17; iter: 200; batch classifier loss: 0.450163; batch adversarial loss: 0.616607\n",
      "epoch 17; iter: 400; batch classifier loss: 0.466446; batch adversarial loss: 0.700625\n",
      "epoch 18; iter: 0; batch classifier loss: 0.250785; batch adversarial loss: 0.661811\n",
      "epoch 18; iter: 200; batch classifier loss: 0.388108; batch adversarial loss: 0.592093\n",
      "epoch 18; iter: 400; batch classifier loss: 0.278295; batch adversarial loss: 0.606618\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400951; batch adversarial loss: 0.615104\n",
      "epoch 19; iter: 200; batch classifier loss: 0.366708; batch adversarial loss: 0.580909\n",
      "epoch 19; iter: 400; batch classifier loss: 0.353309; batch adversarial loss: 0.684178\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337657; batch adversarial loss: 0.631235\n",
      "epoch 20; iter: 200; batch classifier loss: 0.367225; batch adversarial loss: 0.722529\n",
      "epoch 20; iter: 400; batch classifier loss: 0.386013; batch adversarial loss: 0.634053\n",
      "epoch 21; iter: 0; batch classifier loss: 0.373212; batch adversarial loss: 0.633854\n",
      "epoch 21; iter: 200; batch classifier loss: 0.293120; batch adversarial loss: 0.657871\n",
      "epoch 21; iter: 400; batch classifier loss: 0.484110; batch adversarial loss: 0.668425\n",
      "epoch 22; iter: 0; batch classifier loss: 0.445790; batch adversarial loss: 0.627541\n",
      "epoch 22; iter: 200; batch classifier loss: 0.293902; batch adversarial loss: 0.651399\n",
      "epoch 22; iter: 400; batch classifier loss: 0.312116; batch adversarial loss: 0.653136\n",
      "epoch 23; iter: 0; batch classifier loss: 0.309988; batch adversarial loss: 0.598417\n",
      "epoch 23; iter: 200; batch classifier loss: 0.311309; batch adversarial loss: 0.645565\n",
      "epoch 23; iter: 400; batch classifier loss: 0.454201; batch adversarial loss: 0.652230\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499370; batch adversarial loss: 0.610876\n",
      "epoch 24; iter: 200; batch classifier loss: 0.317348; batch adversarial loss: 0.630170\n",
      "epoch 24; iter: 400; batch classifier loss: 0.323565; batch adversarial loss: 0.596465\n",
      "epoch 25; iter: 0; batch classifier loss: 0.395547; batch adversarial loss: 0.565472\n",
      "epoch 25; iter: 200; batch classifier loss: 0.504309; batch adversarial loss: 0.606076\n",
      "epoch 25; iter: 400; batch classifier loss: 0.358808; batch adversarial loss: 0.713365\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424202; batch adversarial loss: 0.585594\n",
      "epoch 26; iter: 200; batch classifier loss: 0.391084; batch adversarial loss: 0.618559\n",
      "epoch 26; iter: 400; batch classifier loss: 0.332446; batch adversarial loss: 0.609823\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330290; batch adversarial loss: 0.617354\n",
      "epoch 27; iter: 200; batch classifier loss: 0.441278; batch adversarial loss: 0.639068\n",
      "epoch 27; iter: 400; batch classifier loss: 0.318764; batch adversarial loss: 0.622555\n",
      "epoch 28; iter: 0; batch classifier loss: 0.364713; batch adversarial loss: 0.597071\n",
      "epoch 28; iter: 200; batch classifier loss: 0.391292; batch adversarial loss: 0.672447\n",
      "epoch 28; iter: 400; batch classifier loss: 0.579871; batch adversarial loss: 0.664832\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315061; batch adversarial loss: 0.667231\n",
      "epoch 29; iter: 200; batch classifier loss: 0.258806; batch adversarial loss: 0.716472\n",
      "epoch 29; iter: 400; batch classifier loss: 0.365069; batch adversarial loss: 0.608432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.334847; batch adversarial loss: 0.629031\n",
      "epoch 30; iter: 200; batch classifier loss: 0.274797; batch adversarial loss: 0.658541\n",
      "epoch 30; iter: 400; batch classifier loss: 0.269785; batch adversarial loss: 0.665367\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414856; batch adversarial loss: 0.577178\n",
      "epoch 31; iter: 200; batch classifier loss: 0.432117; batch adversarial loss: 0.709192\n",
      "epoch 31; iter: 400; batch classifier loss: 0.347831; batch adversarial loss: 0.617606\n",
      "epoch 32; iter: 0; batch classifier loss: 0.347658; batch adversarial loss: 0.591139\n",
      "epoch 32; iter: 200; batch classifier loss: 0.650265; batch adversarial loss: 0.639434\n",
      "epoch 32; iter: 400; batch classifier loss: 0.357099; batch adversarial loss: 0.600693\n",
      "epoch 33; iter: 0; batch classifier loss: 0.575028; batch adversarial loss: 0.675326\n",
      "epoch 33; iter: 200; batch classifier loss: 0.552889; batch adversarial loss: 0.602342\n",
      "epoch 33; iter: 400; batch classifier loss: 0.614885; batch adversarial loss: 0.683398\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420644; batch adversarial loss: 0.580175\n",
      "epoch 34; iter: 200; batch classifier loss: 0.376465; batch adversarial loss: 0.631534\n",
      "epoch 34; iter: 400; batch classifier loss: 0.353724; batch adversarial loss: 0.593781\n",
      "epoch 35; iter: 0; batch classifier loss: 0.468200; batch adversarial loss: 0.635950\n",
      "epoch 35; iter: 200; batch classifier loss: 0.325120; batch adversarial loss: 0.633900\n",
      "epoch 35; iter: 400; batch classifier loss: 0.325248; batch adversarial loss: 0.667179\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505038; batch adversarial loss: 0.662414\n",
      "epoch 36; iter: 200; batch classifier loss: 0.440655; batch adversarial loss: 0.633263\n",
      "epoch 36; iter: 400; batch classifier loss: 0.391512; batch adversarial loss: 0.606378\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444132; batch adversarial loss: 0.633631\n",
      "epoch 37; iter: 200; batch classifier loss: 0.337142; batch adversarial loss: 0.567089\n",
      "epoch 37; iter: 400; batch classifier loss: 1.290800; batch adversarial loss: 0.569252\n",
      "epoch 38; iter: 0; batch classifier loss: 0.484051; batch adversarial loss: 0.528349\n",
      "epoch 38; iter: 200; batch classifier loss: 0.404103; batch adversarial loss: 0.717940\n",
      "epoch 38; iter: 400; batch classifier loss: 0.469614; batch adversarial loss: 0.656897\n",
      "epoch 39; iter: 0; batch classifier loss: 0.425026; batch adversarial loss: 0.605813\n",
      "epoch 39; iter: 200; batch classifier loss: 0.373398; batch adversarial loss: 0.690250\n",
      "epoch 39; iter: 400; batch classifier loss: 0.527926; batch adversarial loss: 0.652749\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399759; batch adversarial loss: 0.627533\n",
      "epoch 40; iter: 200; batch classifier loss: 0.371396; batch adversarial loss: 0.645289\n",
      "epoch 40; iter: 400; batch classifier loss: 0.481127; batch adversarial loss: 0.624028\n",
      "epoch 41; iter: 0; batch classifier loss: 0.500554; batch adversarial loss: 0.562556\n",
      "epoch 41; iter: 200; batch classifier loss: 0.758703; batch adversarial loss: 0.614669\n",
      "epoch 41; iter: 400; batch classifier loss: 0.538554; batch adversarial loss: 0.532547\n",
      "epoch 42; iter: 0; batch classifier loss: 0.616743; batch adversarial loss: 0.635673\n",
      "epoch 42; iter: 200; batch classifier loss: 0.588744; batch adversarial loss: 0.548854\n",
      "epoch 42; iter: 400; batch classifier loss: 0.551878; batch adversarial loss: 0.645441\n",
      "epoch 43; iter: 0; batch classifier loss: 0.542481; batch adversarial loss: 0.646709\n",
      "epoch 43; iter: 200; batch classifier loss: 0.339611; batch adversarial loss: 0.634965\n",
      "epoch 43; iter: 400; batch classifier loss: 0.395712; batch adversarial loss: 0.593375\n",
      "epoch 44; iter: 0; batch classifier loss: 0.716470; batch adversarial loss: 0.573547\n",
      "epoch 44; iter: 200; batch classifier loss: 0.594863; batch adversarial loss: 0.622803\n",
      "epoch 44; iter: 400; batch classifier loss: 0.633827; batch adversarial loss: 0.648272\n",
      "epoch 45; iter: 0; batch classifier loss: 0.508367; batch adversarial loss: 0.626547\n",
      "epoch 45; iter: 200; batch classifier loss: 0.598858; batch adversarial loss: 0.679643\n",
      "epoch 45; iter: 400; batch classifier loss: 0.377157; batch adversarial loss: 0.584946\n",
      "epoch 46; iter: 0; batch classifier loss: 0.492185; batch adversarial loss: 0.591085\n",
      "epoch 46; iter: 200; batch classifier loss: 0.401512; batch adversarial loss: 0.699377\n",
      "epoch 46; iter: 400; batch classifier loss: 0.312688; batch adversarial loss: 0.648010\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450730; batch adversarial loss: 0.559624\n",
      "epoch 47; iter: 200; batch classifier loss: 0.460854; batch adversarial loss: 0.697459\n",
      "epoch 47; iter: 400; batch classifier loss: 0.349860; batch adversarial loss: 0.625312\n",
      "epoch 48; iter: 0; batch classifier loss: 0.254393; batch adversarial loss: 0.678062\n",
      "epoch 48; iter: 200; batch classifier loss: 0.605911; batch adversarial loss: 0.648833\n",
      "epoch 48; iter: 400; batch classifier loss: 0.534854; batch adversarial loss: 0.558545\n",
      "epoch 49; iter: 0; batch classifier loss: 0.356021; batch adversarial loss: 0.592429\n",
      "epoch 49; iter: 200; batch classifier loss: 0.616258; batch adversarial loss: 0.583591\n",
      "epoch 49; iter: 400; batch classifier loss: 0.589560; batch adversarial loss: 0.615863\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 34.305847; batch adversarial loss: 0.687954\n",
      "epoch 0; iter: 200; batch classifier loss: 1.697049; batch adversarial loss: 0.654212\n",
      "epoch 1; iter: 0; batch classifier loss: 4.638799; batch adversarial loss: 0.609371\n",
      "epoch 1; iter: 200; batch classifier loss: 6.909592; batch adversarial loss: 0.625706\n",
      "epoch 2; iter: 0; batch classifier loss: 3.851526; batch adversarial loss: 0.566195\n",
      "epoch 2; iter: 200; batch classifier loss: 2.283378; batch adversarial loss: 0.641733\n",
      "epoch 3; iter: 0; batch classifier loss: 2.617671; batch adversarial loss: 0.637726\n",
      "epoch 3; iter: 200; batch classifier loss: 2.205779; batch adversarial loss: 0.648935\n",
      "epoch 4; iter: 0; batch classifier loss: 2.498895; batch adversarial loss: 0.650918\n",
      "epoch 4; iter: 200; batch classifier loss: 2.411098; batch adversarial loss: 0.659703\n",
      "epoch 5; iter: 0; batch classifier loss: 1.843856; batch adversarial loss: 0.632780\n",
      "epoch 5; iter: 200; batch classifier loss: 0.818129; batch adversarial loss: 0.611824\n",
      "epoch 6; iter: 0; batch classifier loss: 1.694043; batch adversarial loss: 0.650472\n",
      "epoch 6; iter: 200; batch classifier loss: 0.527183; batch adversarial loss: 0.624896\n",
      "epoch 7; iter: 0; batch classifier loss: 0.766346; batch adversarial loss: 0.659250\n",
      "epoch 7; iter: 200; batch classifier loss: 0.860964; batch adversarial loss: 0.645480\n",
      "epoch 8; iter: 0; batch classifier loss: 0.756740; batch adversarial loss: 0.645362\n",
      "epoch 8; iter: 200; batch classifier loss: 0.536164; batch adversarial loss: 0.645994\n",
      "epoch 9; iter: 0; batch classifier loss: 0.727255; batch adversarial loss: 0.619345\n",
      "epoch 9; iter: 200; batch classifier loss: 0.517109; batch adversarial loss: 0.661515\n",
      "epoch 0; iter: 0; batch classifier loss: 19.824656; batch adversarial loss: 0.687596\n",
      "epoch 0; iter: 200; batch classifier loss: 4.438919; batch adversarial loss: 0.635093\n",
      "epoch 1; iter: 0; batch classifier loss: 6.559841; batch adversarial loss: 0.646204\n",
      "epoch 1; iter: 200; batch classifier loss: 3.166455; batch adversarial loss: 0.663472\n",
      "epoch 2; iter: 0; batch classifier loss: 2.697604; batch adversarial loss: 0.655261\n",
      "epoch 2; iter: 200; batch classifier loss: 3.287074; batch adversarial loss: 0.654900\n",
      "epoch 3; iter: 0; batch classifier loss: 3.912882; batch adversarial loss: 0.611147\n",
      "epoch 3; iter: 200; batch classifier loss: 3.803851; batch adversarial loss: 0.676872\n",
      "epoch 4; iter: 0; batch classifier loss: 2.122800; batch adversarial loss: 0.644930\n",
      "epoch 4; iter: 200; batch classifier loss: 1.754963; batch adversarial loss: 0.684541\n",
      "epoch 5; iter: 0; batch classifier loss: 0.858210; batch adversarial loss: 0.634915\n",
      "epoch 5; iter: 200; batch classifier loss: 0.565080; batch adversarial loss: 0.631370\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541741; batch adversarial loss: 0.607128\n",
      "epoch 6; iter: 200; batch classifier loss: 0.917356; batch adversarial loss: 0.616808\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513109; batch adversarial loss: 0.600259\n",
      "epoch 7; iter: 200; batch classifier loss: 0.515846; batch adversarial loss: 0.651056\n",
      "epoch 8; iter: 0; batch classifier loss: 0.875954; batch adversarial loss: 0.652639\n",
      "epoch 8; iter: 200; batch classifier loss: 0.608601; batch adversarial loss: 0.652638\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488839; batch adversarial loss: 0.604986\n",
      "epoch 9; iter: 200; batch classifier loss: 0.475540; batch adversarial loss: 0.563498\n",
      "epoch 0; iter: 0; batch classifier loss: 29.047846; batch adversarial loss: 0.674571\n",
      "epoch 0; iter: 200; batch classifier loss: 10.033938; batch adversarial loss: 0.649870\n",
      "epoch 1; iter: 0; batch classifier loss: 17.842033; batch adversarial loss: 0.687087\n",
      "epoch 1; iter: 200; batch classifier loss: 1.863925; batch adversarial loss: 0.642544\n",
      "epoch 2; iter: 0; batch classifier loss: 3.408579; batch adversarial loss: 0.723943\n",
      "epoch 2; iter: 200; batch classifier loss: 0.642233; batch adversarial loss: 0.653994\n",
      "epoch 3; iter: 0; batch classifier loss: 5.119295; batch adversarial loss: 0.681918\n",
      "epoch 3; iter: 200; batch classifier loss: 3.355259; batch adversarial loss: 0.633929\n",
      "epoch 4; iter: 0; batch classifier loss: 4.318635; batch adversarial loss: 0.727688\n",
      "epoch 4; iter: 200; batch classifier loss: 0.531928; batch adversarial loss: 0.608564\n",
      "epoch 5; iter: 0; batch classifier loss: 0.721931; batch adversarial loss: 0.623186\n",
      "epoch 5; iter: 200; batch classifier loss: 0.919966; batch adversarial loss: 0.618108\n",
      "epoch 6; iter: 0; batch classifier loss: 1.549087; batch adversarial loss: 0.628851\n",
      "epoch 6; iter: 200; batch classifier loss: 0.579127; batch adversarial loss: 0.653799\n",
      "epoch 7; iter: 0; batch classifier loss: 0.722177; batch adversarial loss: 0.645408\n",
      "epoch 7; iter: 200; batch classifier loss: 0.373080; batch adversarial loss: 0.630753\n",
      "epoch 8; iter: 0; batch classifier loss: 0.910686; batch adversarial loss: 0.617418\n",
      "epoch 8; iter: 200; batch classifier loss: 3.118244; batch adversarial loss: 0.623549\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569200; batch adversarial loss: 0.593140\n",
      "epoch 9; iter: 200; batch classifier loss: 0.336265; batch adversarial loss: 0.621374\n",
      "epoch 0; iter: 0; batch classifier loss: 27.859440; batch adversarial loss: 0.680139\n",
      "epoch 0; iter: 200; batch classifier loss: 11.662033; batch adversarial loss: 0.716577\n",
      "epoch 1; iter: 0; batch classifier loss: 10.852228; batch adversarial loss: 0.717581\n",
      "epoch 1; iter: 200; batch classifier loss: 10.162954; batch adversarial loss: 0.671538\n",
      "epoch 2; iter: 0; batch classifier loss: 12.792039; batch adversarial loss: 0.668790\n",
      "epoch 2; iter: 200; batch classifier loss: 3.089206; batch adversarial loss: 0.682157\n",
      "epoch 3; iter: 0; batch classifier loss: 11.192132; batch adversarial loss: 0.716769\n",
      "epoch 3; iter: 200; batch classifier loss: 2.665322; batch adversarial loss: 0.687134\n",
      "epoch 4; iter: 0; batch classifier loss: 2.679146; batch adversarial loss: 0.666960\n",
      "epoch 4; iter: 200; batch classifier loss: 2.065763; batch adversarial loss: 0.650289\n",
      "epoch 5; iter: 0; batch classifier loss: 1.592591; batch adversarial loss: 0.612769\n",
      "epoch 5; iter: 200; batch classifier loss: 1.075665; batch adversarial loss: 0.648130\n",
      "epoch 6; iter: 0; batch classifier loss: 2.286499; batch adversarial loss: 0.618553\n",
      "epoch 6; iter: 200; batch classifier loss: 0.980108; batch adversarial loss: 0.628255\n",
      "epoch 7; iter: 0; batch classifier loss: 1.389306; batch adversarial loss: 0.623174\n",
      "epoch 7; iter: 200; batch classifier loss: 0.495645; batch adversarial loss: 0.579548\n",
      "epoch 8; iter: 0; batch classifier loss: 0.614919; batch adversarial loss: 0.608882\n",
      "epoch 8; iter: 200; batch classifier loss: 0.717249; batch adversarial loss: 0.582289\n",
      "epoch 9; iter: 0; batch classifier loss: 0.700719; batch adversarial loss: 0.669764\n",
      "epoch 9; iter: 200; batch classifier loss: 0.600213; batch adversarial loss: 0.645694\n",
      "epoch 0; iter: 0; batch classifier loss: 27.333088; batch adversarial loss: 0.919831\n",
      "epoch 0; iter: 200; batch classifier loss: 3.979280; batch adversarial loss: 0.683468\n",
      "epoch 1; iter: 0; batch classifier loss: 6.409951; batch adversarial loss: 0.674027\n",
      "epoch 1; iter: 200; batch classifier loss: 16.350262; batch adversarial loss: 0.671053\n",
      "epoch 2; iter: 0; batch classifier loss: 7.741745; batch adversarial loss: 0.656879\n",
      "epoch 2; iter: 200; batch classifier loss: 1.824180; batch adversarial loss: 0.659600\n",
      "epoch 3; iter: 0; batch classifier loss: 2.108148; batch adversarial loss: 0.593372\n",
      "epoch 3; iter: 200; batch classifier loss: 1.915899; batch adversarial loss: 0.656326\n",
      "epoch 4; iter: 0; batch classifier loss: 1.099750; batch adversarial loss: 0.638288\n",
      "epoch 4; iter: 200; batch classifier loss: 0.594043; batch adversarial loss: 0.631817\n",
      "epoch 5; iter: 0; batch classifier loss: 0.957245; batch adversarial loss: 0.636393\n",
      "epoch 5; iter: 200; batch classifier loss: 0.559929; batch adversarial loss: 0.573726\n",
      "epoch 6; iter: 0; batch classifier loss: 0.748893; batch adversarial loss: 0.632214\n",
      "epoch 6; iter: 200; batch classifier loss: 0.417125; batch adversarial loss: 0.663235\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611488; batch adversarial loss: 0.631622\n",
      "epoch 7; iter: 200; batch classifier loss: 0.542477; batch adversarial loss: 0.657693\n",
      "epoch 8; iter: 0; batch classifier loss: 0.653529; batch adversarial loss: 0.621224\n",
      "epoch 8; iter: 200; batch classifier loss: 0.491400; batch adversarial loss: 0.623227\n",
      "epoch 9; iter: 0; batch classifier loss: 1.114339; batch adversarial loss: 0.598116\n",
      "epoch 9; iter: 200; batch classifier loss: 0.438910; batch adversarial loss: 0.622229\n",
      "epoch 0; iter: 0; batch classifier loss: 24.209766; batch adversarial loss: 0.962077\n",
      "epoch 0; iter: 200; batch classifier loss: 6.593286; batch adversarial loss: 0.695551\n",
      "epoch 1; iter: 0; batch classifier loss: 1.366060; batch adversarial loss: 0.668804\n",
      "epoch 1; iter: 200; batch classifier loss: 4.043926; batch adversarial loss: 0.681520\n",
      "epoch 2; iter: 0; batch classifier loss: 3.473988; batch adversarial loss: 0.714921\n",
      "epoch 2; iter: 200; batch classifier loss: 2.553560; batch adversarial loss: 0.679115\n",
      "epoch 3; iter: 0; batch classifier loss: 1.971036; batch adversarial loss: 0.707377\n",
      "epoch 3; iter: 200; batch classifier loss: 1.379793; batch adversarial loss: 0.654160\n",
      "epoch 4; iter: 0; batch classifier loss: 1.283299; batch adversarial loss: 0.691375\n",
      "epoch 4; iter: 200; batch classifier loss: 1.411497; batch adversarial loss: 0.613802\n",
      "epoch 5; iter: 0; batch classifier loss: 1.463389; batch adversarial loss: 0.612753\n",
      "epoch 5; iter: 200; batch classifier loss: 3.529943; batch adversarial loss: 0.641625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.654027; batch adversarial loss: 0.614737\n",
      "epoch 6; iter: 200; batch classifier loss: 0.522245; batch adversarial loss: 0.625942\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557249; batch adversarial loss: 0.652454\n",
      "epoch 7; iter: 200; batch classifier loss: 0.536948; batch adversarial loss: 0.617738\n",
      "epoch 8; iter: 0; batch classifier loss: 0.437946; batch adversarial loss: 0.607643\n",
      "epoch 8; iter: 200; batch classifier loss: 0.355904; batch adversarial loss: 0.583636\n",
      "epoch 9; iter: 0; batch classifier loss: 0.315289; batch adversarial loss: 0.663007\n",
      "epoch 9; iter: 200; batch classifier loss: 0.359865; batch adversarial loss: 0.624969\n",
      "epoch 0; iter: 0; batch classifier loss: 10.768810; batch adversarial loss: 0.755398\n",
      "epoch 0; iter: 200; batch classifier loss: 7.596897; batch adversarial loss: 0.721359\n",
      "epoch 1; iter: 0; batch classifier loss: 11.764072; batch adversarial loss: 0.684256\n",
      "epoch 1; iter: 200; batch classifier loss: 3.654965; batch adversarial loss: 0.650199\n",
      "epoch 2; iter: 0; batch classifier loss: 6.944649; batch adversarial loss: 0.635299\n",
      "epoch 2; iter: 200; batch classifier loss: 0.789387; batch adversarial loss: 0.639965\n",
      "epoch 3; iter: 0; batch classifier loss: 2.210769; batch adversarial loss: 0.582018\n",
      "epoch 3; iter: 200; batch classifier loss: 1.086541; batch adversarial loss: 0.671975\n",
      "epoch 4; iter: 0; batch classifier loss: 0.599707; batch adversarial loss: 0.597824\n",
      "epoch 4; iter: 200; batch classifier loss: 1.414452; batch adversarial loss: 0.647179\n",
      "epoch 5; iter: 0; batch classifier loss: 1.808115; batch adversarial loss: 0.670322\n",
      "epoch 5; iter: 200; batch classifier loss: 1.581529; batch adversarial loss: 0.603463\n",
      "epoch 6; iter: 0; batch classifier loss: 0.960434; batch adversarial loss: 0.619955\n",
      "epoch 6; iter: 200; batch classifier loss: 0.618723; batch adversarial loss: 0.656015\n",
      "epoch 7; iter: 0; batch classifier loss: 1.337948; batch adversarial loss: 0.617628\n",
      "epoch 7; iter: 200; batch classifier loss: 0.553144; batch adversarial loss: 0.654024\n",
      "epoch 8; iter: 0; batch classifier loss: 0.745290; batch adversarial loss: 0.620731\n",
      "epoch 8; iter: 200; batch classifier loss: 0.647795; batch adversarial loss: 0.623461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595895; batch adversarial loss: 0.678991\n",
      "epoch 9; iter: 200; batch classifier loss: 2.304713; batch adversarial loss: 0.643056\n",
      "epoch 0; iter: 0; batch classifier loss: 27.112955; batch adversarial loss: 0.787529\n",
      "epoch 0; iter: 200; batch classifier loss: 5.537216; batch adversarial loss: 0.672412\n",
      "epoch 1; iter: 0; batch classifier loss: 4.167651; batch adversarial loss: 0.676299\n",
      "epoch 1; iter: 200; batch classifier loss: 3.264186; batch adversarial loss: 0.674679\n",
      "epoch 2; iter: 0; batch classifier loss: 3.725594; batch adversarial loss: 0.638937\n",
      "epoch 2; iter: 200; batch classifier loss: 11.218794; batch adversarial loss: 0.593752\n",
      "epoch 3; iter: 0; batch classifier loss: 3.509344; batch adversarial loss: 0.617164\n",
      "epoch 3; iter: 200; batch classifier loss: 1.515781; batch adversarial loss: 0.661735\n",
      "epoch 4; iter: 0; batch classifier loss: 1.407298; batch adversarial loss: 0.591815\n",
      "epoch 4; iter: 200; batch classifier loss: 2.265815; batch adversarial loss: 0.614504\n",
      "epoch 5; iter: 0; batch classifier loss: 1.530931; batch adversarial loss: 0.632046\n",
      "epoch 5; iter: 200; batch classifier loss: 0.595289; batch adversarial loss: 0.601884\n",
      "epoch 6; iter: 0; batch classifier loss: 1.093685; batch adversarial loss: 0.645476\n",
      "epoch 6; iter: 200; batch classifier loss: 0.958117; batch adversarial loss: 0.644789\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435285; batch adversarial loss: 0.643744\n",
      "epoch 7; iter: 200; batch classifier loss: 0.494313; batch adversarial loss: 0.590091\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497803; batch adversarial loss: 0.608277\n",
      "epoch 8; iter: 200; batch classifier loss: 0.438686; batch adversarial loss: 0.586579\n",
      "epoch 9; iter: 0; batch classifier loss: 0.448207; batch adversarial loss: 0.600214\n",
      "epoch 9; iter: 200; batch classifier loss: 0.526527; batch adversarial loss: 0.587231\n",
      "epoch 0; iter: 0; batch classifier loss: 14.324864; batch adversarial loss: 0.642399\n",
      "epoch 0; iter: 200; batch classifier loss: 3.693810; batch adversarial loss: 0.631158\n",
      "epoch 1; iter: 0; batch classifier loss: 4.521553; batch adversarial loss: 0.643831\n",
      "epoch 1; iter: 200; batch classifier loss: 1.822520; batch adversarial loss: 0.638766\n",
      "epoch 2; iter: 0; batch classifier loss: 3.449882; batch adversarial loss: 0.667363\n",
      "epoch 2; iter: 200; batch classifier loss: 2.018204; batch adversarial loss: 0.606411\n",
      "epoch 3; iter: 0; batch classifier loss: 3.903847; batch adversarial loss: 0.604525\n",
      "epoch 3; iter: 200; batch classifier loss: 3.417931; batch adversarial loss: 0.643116\n",
      "epoch 4; iter: 0; batch classifier loss: 1.609154; batch adversarial loss: 0.595835\n",
      "epoch 4; iter: 200; batch classifier loss: 1.498321; batch adversarial loss: 0.645805\n",
      "epoch 5; iter: 0; batch classifier loss: 0.578289; batch adversarial loss: 0.572579\n",
      "epoch 5; iter: 200; batch classifier loss: 1.103833; batch adversarial loss: 0.640765\n",
      "epoch 6; iter: 0; batch classifier loss: 0.881862; batch adversarial loss: 0.696561\n",
      "epoch 6; iter: 200; batch classifier loss: 0.521126; batch adversarial loss: 0.604145\n",
      "epoch 7; iter: 0; batch classifier loss: 0.776307; batch adversarial loss: 0.643941\n",
      "epoch 7; iter: 200; batch classifier loss: 0.692194; batch adversarial loss: 0.574107\n",
      "epoch 8; iter: 0; batch classifier loss: 0.531179; batch adversarial loss: 0.615059\n",
      "epoch 8; iter: 200; batch classifier loss: 0.429259; batch adversarial loss: 0.573260\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506081; batch adversarial loss: 0.621120\n",
      "epoch 9; iter: 200; batch classifier loss: 0.293623; batch adversarial loss: 0.627609\n",
      "epoch 0; iter: 0; batch classifier loss: 32.506874; batch adversarial loss: 0.763622\n",
      "epoch 0; iter: 200; batch classifier loss: 8.644445; batch adversarial loss: 0.701026\n",
      "epoch 1; iter: 0; batch classifier loss: 5.900220; batch adversarial loss: 0.660976\n",
      "epoch 1; iter: 200; batch classifier loss: 9.684915; batch adversarial loss: 0.646893\n",
      "epoch 2; iter: 0; batch classifier loss: 3.572234; batch adversarial loss: 0.653823\n",
      "epoch 2; iter: 200; batch classifier loss: 1.471018; batch adversarial loss: 0.621728\n",
      "epoch 3; iter: 0; batch classifier loss: 2.457041; batch adversarial loss: 0.589512\n",
      "epoch 3; iter: 200; batch classifier loss: 1.465096; batch adversarial loss: 0.643499\n",
      "epoch 4; iter: 0; batch classifier loss: 2.029063; batch adversarial loss: 0.629725\n",
      "epoch 4; iter: 200; batch classifier loss: 0.926012; batch adversarial loss: 0.582648\n",
      "epoch 5; iter: 0; batch classifier loss: 0.696097; batch adversarial loss: 0.633899\n",
      "epoch 5; iter: 200; batch classifier loss: 0.822227; batch adversarial loss: 0.576265\n",
      "epoch 6; iter: 0; batch classifier loss: 1.135215; batch adversarial loss: 0.561917\n",
      "epoch 6; iter: 200; batch classifier loss: 0.680958; batch adversarial loss: 0.557194\n",
      "epoch 7; iter: 0; batch classifier loss: 0.439054; batch adversarial loss: 0.644987\n",
      "epoch 7; iter: 200; batch classifier loss: 1.116017; batch adversarial loss: 0.626329\n",
      "epoch 8; iter: 0; batch classifier loss: 0.742636; batch adversarial loss: 0.639405\n",
      "epoch 8; iter: 200; batch classifier loss: 0.878946; batch adversarial loss: 0.587957\n",
      "epoch 9; iter: 0; batch classifier loss: 0.425869; batch adversarial loss: 0.639051\n",
      "epoch 9; iter: 200; batch classifier loss: 0.495536; batch adversarial loss: 0.640021\n",
      "epoch 0; iter: 0; batch classifier loss: 62.571526; batch adversarial loss: 0.691840\n",
      "epoch 0; iter: 200; batch classifier loss: 8.396841; batch adversarial loss: 0.647982\n",
      "epoch 1; iter: 0; batch classifier loss: 8.273094; batch adversarial loss: 0.670841\n",
      "epoch 1; iter: 200; batch classifier loss: 2.128471; batch adversarial loss: 0.627640\n",
      "epoch 2; iter: 0; batch classifier loss: 3.978029; batch adversarial loss: 0.635541\n",
      "epoch 2; iter: 200; batch classifier loss: 4.247152; batch adversarial loss: 0.609811\n",
      "epoch 3; iter: 0; batch classifier loss: 2.176173; batch adversarial loss: 0.663954\n",
      "epoch 3; iter: 200; batch classifier loss: 1.556995; batch adversarial loss: 0.661488\n",
      "epoch 4; iter: 0; batch classifier loss: 1.735174; batch adversarial loss: 0.617103\n",
      "epoch 4; iter: 200; batch classifier loss: 0.555713; batch adversarial loss: 0.615987\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524229; batch adversarial loss: 0.561990\n",
      "epoch 5; iter: 200; batch classifier loss: 0.713194; batch adversarial loss: 0.635672\n",
      "epoch 6; iter: 0; batch classifier loss: 0.786532; batch adversarial loss: 0.644235\n",
      "epoch 6; iter: 200; batch classifier loss: 0.804490; batch adversarial loss: 0.580225\n",
      "epoch 7; iter: 0; batch classifier loss: 0.859461; batch adversarial loss: 0.597420\n",
      "epoch 7; iter: 200; batch classifier loss: 1.029202; batch adversarial loss: 0.614227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.777964; batch adversarial loss: 0.600694\n",
      "epoch 8; iter: 200; batch classifier loss: 0.646514; batch adversarial loss: 0.617141\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525779; batch adversarial loss: 0.586554\n",
      "epoch 9; iter: 200; batch classifier loss: 0.394208; batch adversarial loss: 0.632359\n",
      "epoch 0; iter: 0; batch classifier loss: 22.181349; batch adversarial loss: 0.600222\n",
      "epoch 0; iter: 200; batch classifier loss: 23.715603; batch adversarial loss: 0.664528\n",
      "epoch 1; iter: 0; batch classifier loss: 4.849201; batch adversarial loss: 0.630665\n",
      "epoch 1; iter: 200; batch classifier loss: 8.887949; batch adversarial loss: 0.666040\n",
      "epoch 2; iter: 0; batch classifier loss: 3.788102; batch adversarial loss: 0.588344\n",
      "epoch 2; iter: 200; batch classifier loss: 3.167165; batch adversarial loss: 0.650898\n",
      "epoch 3; iter: 0; batch classifier loss: 3.133422; batch adversarial loss: 0.694981\n",
      "epoch 3; iter: 200; batch classifier loss: 3.279615; batch adversarial loss: 0.603515\n",
      "epoch 4; iter: 0; batch classifier loss: 0.840746; batch adversarial loss: 0.638737\n",
      "epoch 4; iter: 200; batch classifier loss: 2.285019; batch adversarial loss: 0.675903\n",
      "epoch 5; iter: 0; batch classifier loss: 5.606600; batch adversarial loss: 0.605649\n",
      "epoch 5; iter: 200; batch classifier loss: 0.324552; batch adversarial loss: 0.647582\n",
      "epoch 6; iter: 0; batch classifier loss: 0.953585; batch adversarial loss: 0.612145\n",
      "epoch 6; iter: 200; batch classifier loss: 0.542680; batch adversarial loss: 0.693429\n",
      "epoch 7; iter: 0; batch classifier loss: 0.950814; batch adversarial loss: 0.600871\n",
      "epoch 7; iter: 200; batch classifier loss: 0.597417; batch adversarial loss: 0.601795\n",
      "epoch 8; iter: 0; batch classifier loss: 0.986580; batch adversarial loss: 0.587795\n",
      "epoch 8; iter: 200; batch classifier loss: 1.992322; batch adversarial loss: 0.642888\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504904; batch adversarial loss: 0.662997\n",
      "epoch 9; iter: 200; batch classifier loss: 0.657225; batch adversarial loss: 0.650463\n",
      "epoch 0; iter: 0; batch classifier loss: 33.022648; batch adversarial loss: 0.662803\n",
      "epoch 0; iter: 200; batch classifier loss: 12.423321; batch adversarial loss: 0.648260\n",
      "epoch 1; iter: 0; batch classifier loss: 2.556456; batch adversarial loss: 0.601492\n",
      "epoch 1; iter: 200; batch classifier loss: 4.204000; batch adversarial loss: 0.655912\n",
      "epoch 2; iter: 0; batch classifier loss: 8.459851; batch adversarial loss: 0.626644\n",
      "epoch 2; iter: 200; batch classifier loss: 3.359468; batch adversarial loss: 0.582942\n",
      "epoch 3; iter: 0; batch classifier loss: 3.289992; batch adversarial loss: 0.647206\n",
      "epoch 3; iter: 200; batch classifier loss: 3.063029; batch adversarial loss: 0.636734\n",
      "epoch 4; iter: 0; batch classifier loss: 2.198061; batch adversarial loss: 0.625574\n",
      "epoch 4; iter: 200; batch classifier loss: 1.237080; batch adversarial loss: 0.560022\n",
      "epoch 5; iter: 0; batch classifier loss: 1.400647; batch adversarial loss: 0.640086\n",
      "epoch 5; iter: 200; batch classifier loss: 2.190048; batch adversarial loss: 0.575698\n",
      "epoch 6; iter: 0; batch classifier loss: 0.982023; batch adversarial loss: 0.636608\n",
      "epoch 6; iter: 200; batch classifier loss: 0.343328; batch adversarial loss: 0.619969\n",
      "epoch 7; iter: 0; batch classifier loss: 1.963486; batch adversarial loss: 0.701549\n",
      "epoch 7; iter: 200; batch classifier loss: 1.078612; batch adversarial loss: 0.595459\n",
      "epoch 8; iter: 0; batch classifier loss: 0.686018; batch adversarial loss: 0.613225\n",
      "epoch 8; iter: 200; batch classifier loss: 0.802085; batch adversarial loss: 0.627872\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532721; batch adversarial loss: 0.604639\n",
      "epoch 9; iter: 200; batch classifier loss: 0.550357; batch adversarial loss: 0.689548\n",
      "epoch 0; iter: 0; batch classifier loss: 9.200413; batch adversarial loss: 0.730869\n",
      "epoch 0; iter: 200; batch classifier loss: 3.725082; batch adversarial loss: 0.827211\n",
      "epoch 1; iter: 0; batch classifier loss: 3.347147; batch adversarial loss: 0.691813\n",
      "epoch 1; iter: 200; batch classifier loss: 6.522662; batch adversarial loss: 0.647167\n",
      "epoch 2; iter: 0; batch classifier loss: 5.110474; batch adversarial loss: 0.660027\n",
      "epoch 2; iter: 200; batch classifier loss: 2.413522; batch adversarial loss: 0.678003\n",
      "epoch 3; iter: 0; batch classifier loss: 6.408787; batch adversarial loss: 0.676401\n",
      "epoch 3; iter: 200; batch classifier loss: 2.980051; batch adversarial loss: 0.680748\n",
      "epoch 4; iter: 0; batch classifier loss: 6.207701; batch adversarial loss: 0.677843\n",
      "epoch 4; iter: 200; batch classifier loss: 1.309835; batch adversarial loss: 0.644526\n",
      "epoch 5; iter: 0; batch classifier loss: 14.997322; batch adversarial loss: 0.608299\n",
      "epoch 5; iter: 200; batch classifier loss: 3.257967; batch adversarial loss: 0.589112\n",
      "epoch 6; iter: 0; batch classifier loss: 0.621211; batch adversarial loss: 0.694617\n",
      "epoch 6; iter: 200; batch classifier loss: 1.604881; batch adversarial loss: 0.604423\n",
      "epoch 7; iter: 0; batch classifier loss: 0.444884; batch adversarial loss: 0.604632\n",
      "epoch 7; iter: 200; batch classifier loss: 0.875522; batch adversarial loss: 0.619166\n",
      "epoch 8; iter: 0; batch classifier loss: 0.386557; batch adversarial loss: 0.653908\n",
      "epoch 8; iter: 200; batch classifier loss: 0.850745; batch adversarial loss: 0.611266\n",
      "epoch 9; iter: 0; batch classifier loss: 0.691894; batch adversarial loss: 0.605043\n",
      "epoch 9; iter: 200; batch classifier loss: 1.052667; batch adversarial loss: 0.618135\n",
      "epoch 0; iter: 0; batch classifier loss: 17.251091; batch adversarial loss: 0.769401\n",
      "epoch 0; iter: 200; batch classifier loss: 5.152676; batch adversarial loss: 0.839570\n",
      "epoch 1; iter: 0; batch classifier loss: 8.241578; batch adversarial loss: 0.840896\n",
      "epoch 1; iter: 200; batch classifier loss: 3.237417; batch adversarial loss: 0.759807\n",
      "epoch 2; iter: 0; batch classifier loss: 3.227518; batch adversarial loss: 0.654263\n",
      "epoch 2; iter: 200; batch classifier loss: 4.561517; batch adversarial loss: 0.659772\n",
      "epoch 3; iter: 0; batch classifier loss: 4.413210; batch adversarial loss: 0.633420\n",
      "epoch 3; iter: 200; batch classifier loss: 1.832878; batch adversarial loss: 0.660615\n",
      "epoch 4; iter: 0; batch classifier loss: 0.812802; batch adversarial loss: 0.656103\n",
      "epoch 4; iter: 200; batch classifier loss: 0.393193; batch adversarial loss: 0.681012\n",
      "epoch 5; iter: 0; batch classifier loss: 2.106294; batch adversarial loss: 0.670043\n",
      "epoch 5; iter: 200; batch classifier loss: 1.564438; batch adversarial loss: 0.630494\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606974; batch adversarial loss: 0.709508\n",
      "epoch 6; iter: 200; batch classifier loss: 1.417799; batch adversarial loss: 0.602839\n",
      "epoch 7; iter: 0; batch classifier loss: 1.101747; batch adversarial loss: 0.614448\n",
      "epoch 7; iter: 200; batch classifier loss: 0.962188; batch adversarial loss: 0.582388\n",
      "epoch 8; iter: 0; batch classifier loss: 0.408174; batch adversarial loss: 0.653282\n",
      "epoch 8; iter: 200; batch classifier loss: 0.428726; batch adversarial loss: 0.614081\n",
      "epoch 9; iter: 0; batch classifier loss: 0.641701; batch adversarial loss: 0.602576\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386473; batch adversarial loss: 0.657282\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 13.375783; batch adversarial loss: 0.794815\n",
      "epoch 0; iter: 200; batch classifier loss: 4.024805; batch adversarial loss: 0.691333\n",
      "epoch 1; iter: 0; batch classifier loss: 2.514254; batch adversarial loss: 0.681194\n",
      "epoch 1; iter: 200; batch classifier loss: 3.125229; batch adversarial loss: 0.627328\n",
      "epoch 2; iter: 0; batch classifier loss: 4.258841; batch adversarial loss: 0.651651\n",
      "epoch 2; iter: 200; batch classifier loss: 2.691570; batch adversarial loss: 0.644499\n",
      "epoch 3; iter: 0; batch classifier loss: 4.415036; batch adversarial loss: 0.613983\n",
      "epoch 3; iter: 200; batch classifier loss: 1.180899; batch adversarial loss: 0.615018\n",
      "epoch 4; iter: 0; batch classifier loss: 0.737705; batch adversarial loss: 0.608361\n",
      "epoch 4; iter: 200; batch classifier loss: 1.317636; batch adversarial loss: 0.640938\n",
      "epoch 5; iter: 0; batch classifier loss: 1.933905; batch adversarial loss: 0.645321\n",
      "epoch 5; iter: 200; batch classifier loss: 0.715341; batch adversarial loss: 0.595644\n",
      "epoch 6; iter: 0; batch classifier loss: 0.476293; batch adversarial loss: 0.654524\n",
      "epoch 6; iter: 200; batch classifier loss: 1.063078; batch adversarial loss: 0.607729\n",
      "epoch 7; iter: 0; batch classifier loss: 0.943454; batch adversarial loss: 0.633101\n",
      "epoch 7; iter: 200; batch classifier loss: 0.802479; batch adversarial loss: 0.577477\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428111; batch adversarial loss: 0.677250\n",
      "epoch 8; iter: 200; batch classifier loss: 0.436012; batch adversarial loss: 0.612324\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496015; batch adversarial loss: 0.646633\n",
      "epoch 9; iter: 200; batch classifier loss: 0.356740; batch adversarial loss: 0.663906\n",
      "epoch 10; iter: 0; batch classifier loss: 0.336596; batch adversarial loss: 0.588703\n",
      "epoch 10; iter: 200; batch classifier loss: 0.561822; batch adversarial loss: 0.577379\n",
      "epoch 11; iter: 0; batch classifier loss: 1.435926; batch adversarial loss: 0.601495\n",
      "epoch 11; iter: 200; batch classifier loss: 0.369200; batch adversarial loss: 0.704843\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491612; batch adversarial loss: 0.632025\n",
      "epoch 12; iter: 200; batch classifier loss: 0.450943; batch adversarial loss: 0.655192\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407942; batch adversarial loss: 0.649931\n",
      "epoch 13; iter: 200; batch classifier loss: 0.391383; batch adversarial loss: 0.629886\n",
      "epoch 14; iter: 0; batch classifier loss: 0.379746; batch adversarial loss: 0.630437\n",
      "epoch 14; iter: 200; batch classifier loss: 0.673260; batch adversarial loss: 0.631405\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395666; batch adversarial loss: 0.672509\n",
      "epoch 15; iter: 200; batch classifier loss: 0.424672; batch adversarial loss: 0.681786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382127; batch adversarial loss: 0.617449\n",
      "epoch 16; iter: 200; batch classifier loss: 0.449255; batch adversarial loss: 0.629863\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466167; batch adversarial loss: 0.623895\n",
      "epoch 17; iter: 200; batch classifier loss: 0.414404; batch adversarial loss: 0.577162\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366540; batch adversarial loss: 0.611627\n",
      "epoch 18; iter: 200; batch classifier loss: 0.351583; batch adversarial loss: 0.608861\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306635; batch adversarial loss: 0.627362\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342807; batch adversarial loss: 0.637538\n",
      "epoch 0; iter: 0; batch classifier loss: 17.310329; batch adversarial loss: 0.694149\n",
      "epoch 0; iter: 200; batch classifier loss: 7.269655; batch adversarial loss: 0.642394\n",
      "epoch 1; iter: 0; batch classifier loss: 5.453200; batch adversarial loss: 0.653277\n",
      "epoch 1; iter: 200; batch classifier loss: 3.770740; batch adversarial loss: 0.613909\n",
      "epoch 2; iter: 0; batch classifier loss: 2.114880; batch adversarial loss: 0.630250\n",
      "epoch 2; iter: 200; batch classifier loss: 1.385958; batch adversarial loss: 0.575698\n",
      "epoch 3; iter: 0; batch classifier loss: 1.723843; batch adversarial loss: 0.631092\n",
      "epoch 3; iter: 200; batch classifier loss: 3.628344; batch adversarial loss: 0.610403\n",
      "epoch 4; iter: 0; batch classifier loss: 2.019879; batch adversarial loss: 0.621086\n",
      "epoch 4; iter: 200; batch classifier loss: 0.432661; batch adversarial loss: 0.624434\n",
      "epoch 5; iter: 0; batch classifier loss: 0.426882; batch adversarial loss: 0.669304\n",
      "epoch 5; iter: 200; batch classifier loss: 0.355254; batch adversarial loss: 0.614846\n",
      "epoch 6; iter: 0; batch classifier loss: 1.473140; batch adversarial loss: 0.554201\n",
      "epoch 6; iter: 200; batch classifier loss: 0.405463; batch adversarial loss: 0.639785\n",
      "epoch 7; iter: 0; batch classifier loss: 0.358065; batch adversarial loss: 0.649793\n",
      "epoch 7; iter: 200; batch classifier loss: 0.661810; batch adversarial loss: 0.599636\n",
      "epoch 8; iter: 0; batch classifier loss: 0.388284; batch adversarial loss: 0.577386\n",
      "epoch 8; iter: 200; batch classifier loss: 0.585385; batch adversarial loss: 0.633842\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612622; batch adversarial loss: 0.553858\n",
      "epoch 9; iter: 200; batch classifier loss: 0.715189; batch adversarial loss: 0.634517\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386252; batch adversarial loss: 0.604029\n",
      "epoch 10; iter: 200; batch classifier loss: 0.391877; batch adversarial loss: 0.593982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347867; batch adversarial loss: 0.607510\n",
      "epoch 11; iter: 200; batch classifier loss: 0.406702; batch adversarial loss: 0.606046\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348749; batch adversarial loss: 0.624546\n",
      "epoch 12; iter: 200; batch classifier loss: 0.370014; batch adversarial loss: 0.611797\n",
      "epoch 13; iter: 0; batch classifier loss: 0.422819; batch adversarial loss: 0.629653\n",
      "epoch 13; iter: 200; batch classifier loss: 0.508953; batch adversarial loss: 0.608892\n",
      "epoch 14; iter: 0; batch classifier loss: 0.631365; batch adversarial loss: 0.616991\n",
      "epoch 14; iter: 200; batch classifier loss: 0.321003; batch adversarial loss: 0.692017\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398317; batch adversarial loss: 0.644667\n",
      "epoch 15; iter: 200; batch classifier loss: 0.452314; batch adversarial loss: 0.607088\n",
      "epoch 16; iter: 0; batch classifier loss: 0.438074; batch adversarial loss: 0.562998\n",
      "epoch 16; iter: 200; batch classifier loss: 0.534422; batch adversarial loss: 0.620477\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524658; batch adversarial loss: 0.556447\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346749; batch adversarial loss: 0.582171\n",
      "epoch 18; iter: 0; batch classifier loss: 0.330319; batch adversarial loss: 0.623579\n",
      "epoch 18; iter: 200; batch classifier loss: 0.465859; batch adversarial loss: 0.583046\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355210; batch adversarial loss: 0.577584\n",
      "epoch 19; iter: 200; batch classifier loss: 0.507966; batch adversarial loss: 0.650207\n",
      "epoch 0; iter: 0; batch classifier loss: 163.016235; batch adversarial loss: 0.854267\n",
      "epoch 0; iter: 200; batch classifier loss: 1.794883; batch adversarial loss: 0.681931\n",
      "epoch 1; iter: 0; batch classifier loss: 3.096881; batch adversarial loss: 0.728266\n",
      "epoch 1; iter: 200; batch classifier loss: 4.576569; batch adversarial loss: 0.683174\n",
      "epoch 2; iter: 0; batch classifier loss: 5.757645; batch adversarial loss: 0.682216\n",
      "epoch 2; iter: 200; batch classifier loss: 2.434242; batch adversarial loss: 0.642196\n",
      "epoch 3; iter: 0; batch classifier loss: 3.875556; batch adversarial loss: 0.634947\n",
      "epoch 3; iter: 200; batch classifier loss: 2.628128; batch adversarial loss: 0.613225\n",
      "epoch 4; iter: 0; batch classifier loss: 1.507629; batch adversarial loss: 0.662467\n",
      "epoch 4; iter: 200; batch classifier loss: 2.976168; batch adversarial loss: 0.631103\n",
      "epoch 5; iter: 0; batch classifier loss: 3.686237; batch adversarial loss: 0.575558\n",
      "epoch 5; iter: 200; batch classifier loss: 1.381804; batch adversarial loss: 0.629332\n",
      "epoch 6; iter: 0; batch classifier loss: 1.560067; batch adversarial loss: 0.650621\n",
      "epoch 6; iter: 200; batch classifier loss: 5.439835; batch adversarial loss: 0.628282\n",
      "epoch 7; iter: 0; batch classifier loss: 0.318928; batch adversarial loss: 0.630620\n",
      "epoch 7; iter: 200; batch classifier loss: 1.215457; batch adversarial loss: 0.636975\n",
      "epoch 8; iter: 0; batch classifier loss: 0.858672; batch adversarial loss: 0.670405\n",
      "epoch 8; iter: 200; batch classifier loss: 0.644984; batch adversarial loss: 0.623121\n",
      "epoch 9; iter: 0; batch classifier loss: 1.233007; batch adversarial loss: 0.568963\n",
      "epoch 9; iter: 200; batch classifier loss: 0.580983; batch adversarial loss: 0.624626\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509281; batch adversarial loss: 0.690010\n",
      "epoch 10; iter: 200; batch classifier loss: 0.517950; batch adversarial loss: 0.620811\n",
      "epoch 11; iter: 0; batch classifier loss: 0.390839; batch adversarial loss: 0.654352\n",
      "epoch 11; iter: 200; batch classifier loss: 0.536092; batch adversarial loss: 0.614086\n",
      "epoch 12; iter: 0; batch classifier loss: 0.610483; batch adversarial loss: 0.650283\n",
      "epoch 12; iter: 200; batch classifier loss: 0.461121; batch adversarial loss: 0.574638\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348068; batch adversarial loss: 0.687918\n",
      "epoch 13; iter: 200; batch classifier loss: 0.392005; batch adversarial loss: 0.575176\n",
      "epoch 14; iter: 0; batch classifier loss: 0.361777; batch adversarial loss: 0.657760\n",
      "epoch 14; iter: 200; batch classifier loss: 0.425121; batch adversarial loss: 0.584526\n",
      "epoch 15; iter: 0; batch classifier loss: 0.677812; batch adversarial loss: 0.617199\n",
      "epoch 15; iter: 200; batch classifier loss: 0.434813; batch adversarial loss: 0.588851\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448059; batch adversarial loss: 0.636698\n",
      "epoch 16; iter: 200; batch classifier loss: 0.397018; batch adversarial loss: 0.611463\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327658; batch adversarial loss: 0.701672\n",
      "epoch 17; iter: 200; batch classifier loss: 0.344496; batch adversarial loss: 0.632767\n",
      "epoch 18; iter: 0; batch classifier loss: 0.382279; batch adversarial loss: 0.605977\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336192; batch adversarial loss: 0.611777\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331605; batch adversarial loss: 0.606356\n",
      "epoch 19; iter: 200; batch classifier loss: 0.408545; batch adversarial loss: 0.555176\n",
      "epoch 0; iter: 0; batch classifier loss: 25.610647; batch adversarial loss: 0.684541\n",
      "epoch 0; iter: 200; batch classifier loss: 11.871195; batch adversarial loss: 0.655791\n",
      "epoch 1; iter: 0; batch classifier loss: 4.598903; batch adversarial loss: 0.640528\n",
      "epoch 1; iter: 200; batch classifier loss: 4.642401; batch adversarial loss: 0.654670\n",
      "epoch 2; iter: 0; batch classifier loss: 2.769112; batch adversarial loss: 0.592725\n",
      "epoch 2; iter: 200; batch classifier loss: 2.026634; batch adversarial loss: 0.653381\n",
      "epoch 3; iter: 0; batch classifier loss: 4.204519; batch adversarial loss: 0.643819\n",
      "epoch 3; iter: 200; batch classifier loss: 1.868537; batch adversarial loss: 0.592362\n",
      "epoch 4; iter: 0; batch classifier loss: 0.677085; batch adversarial loss: 0.567467\n",
      "epoch 4; iter: 200; batch classifier loss: 1.146290; batch adversarial loss: 0.576573\n",
      "epoch 5; iter: 0; batch classifier loss: 2.007604; batch adversarial loss: 0.581469\n",
      "epoch 5; iter: 200; batch classifier loss: 0.458482; batch adversarial loss: 0.675305\n",
      "epoch 6; iter: 0; batch classifier loss: 0.813098; batch adversarial loss: 0.613937\n",
      "epoch 6; iter: 200; batch classifier loss: 0.614219; batch adversarial loss: 0.665867\n",
      "epoch 7; iter: 0; batch classifier loss: 2.556917; batch adversarial loss: 0.592602\n",
      "epoch 7; iter: 200; batch classifier loss: 1.216955; batch adversarial loss: 0.622232\n",
      "epoch 8; iter: 0; batch classifier loss: 0.967412; batch adversarial loss: 0.560998\n",
      "epoch 8; iter: 200; batch classifier loss: 0.490503; batch adversarial loss: 0.616603\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555984; batch adversarial loss: 0.619962\n",
      "epoch 9; iter: 200; batch classifier loss: 0.465320; batch adversarial loss: 0.587695\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512888; batch adversarial loss: 0.616555\n",
      "epoch 10; iter: 200; batch classifier loss: 0.519955; batch adversarial loss: 0.624732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342026; batch adversarial loss: 0.601188\n",
      "epoch 11; iter: 200; batch classifier loss: 0.529009; batch adversarial loss: 0.655814\n",
      "epoch 12; iter: 0; batch classifier loss: 0.395526; batch adversarial loss: 0.618505\n",
      "epoch 12; iter: 200; batch classifier loss: 0.405872; batch adversarial loss: 0.572486\n",
      "epoch 13; iter: 0; batch classifier loss: 0.687228; batch adversarial loss: 0.646659\n",
      "epoch 13; iter: 200; batch classifier loss: 0.420911; batch adversarial loss: 0.650956\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504859; batch adversarial loss: 0.588909\n",
      "epoch 14; iter: 200; batch classifier loss: 0.383234; batch adversarial loss: 0.686365\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398702; batch adversarial loss: 0.651958\n",
      "epoch 15; iter: 200; batch classifier loss: 0.293719; batch adversarial loss: 0.595581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495745; batch adversarial loss: 0.614159\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399003; batch adversarial loss: 0.647466\n",
      "epoch 17; iter: 0; batch classifier loss: 0.358025; batch adversarial loss: 0.633087\n",
      "epoch 17; iter: 200; batch classifier loss: 0.395301; batch adversarial loss: 0.628477\n",
      "epoch 18; iter: 0; batch classifier loss: 0.417082; batch adversarial loss: 0.556011\n",
      "epoch 18; iter: 200; batch classifier loss: 0.332071; batch adversarial loss: 0.625268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374261; batch adversarial loss: 0.691218\n",
      "epoch 19; iter: 200; batch classifier loss: 0.290825; batch adversarial loss: 0.652310\n",
      "epoch 0; iter: 0; batch classifier loss: 67.516777; batch adversarial loss: 0.700534\n",
      "epoch 0; iter: 200; batch classifier loss: 4.802396; batch adversarial loss: 0.701207\n",
      "epoch 1; iter: 0; batch classifier loss: 35.954334; batch adversarial loss: 0.675765\n",
      "epoch 1; iter: 200; batch classifier loss: 9.114258; batch adversarial loss: 0.648492\n",
      "epoch 2; iter: 0; batch classifier loss: 3.640619; batch adversarial loss: 0.636400\n",
      "epoch 2; iter: 200; batch classifier loss: 1.385967; batch adversarial loss: 0.608195\n",
      "epoch 3; iter: 0; batch classifier loss: 1.882464; batch adversarial loss: 0.627500\n",
      "epoch 3; iter: 200; batch classifier loss: 1.434059; batch adversarial loss: 0.648057\n",
      "epoch 4; iter: 0; batch classifier loss: 2.867057; batch adversarial loss: 0.569857\n",
      "epoch 4; iter: 200; batch classifier loss: 0.668437; batch adversarial loss: 0.646224\n",
      "epoch 5; iter: 0; batch classifier loss: 0.796529; batch adversarial loss: 0.610937\n",
      "epoch 5; iter: 200; batch classifier loss: 1.216518; batch adversarial loss: 0.589310\n",
      "epoch 6; iter: 0; batch classifier loss: 0.655108; batch adversarial loss: 0.669457\n",
      "epoch 6; iter: 200; batch classifier loss: 0.925940; batch adversarial loss: 0.628311\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454419; batch adversarial loss: 0.615567\n",
      "epoch 7; iter: 200; batch classifier loss: 0.817922; batch adversarial loss: 0.642130\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576573; batch adversarial loss: 0.634476\n",
      "epoch 8; iter: 200; batch classifier loss: 0.683090; batch adversarial loss: 0.586878\n",
      "epoch 9; iter: 0; batch classifier loss: 0.327978; batch adversarial loss: 0.592478\n",
      "epoch 9; iter: 200; batch classifier loss: 0.672986; batch adversarial loss: 0.647466\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438386; batch adversarial loss: 0.680899\n",
      "epoch 10; iter: 200; batch classifier loss: 0.473848; batch adversarial loss: 0.628672\n",
      "epoch 11; iter: 0; batch classifier loss: 0.445927; batch adversarial loss: 0.664952\n",
      "epoch 11; iter: 200; batch classifier loss: 0.465835; batch adversarial loss: 0.569420\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506164; batch adversarial loss: 0.686813\n",
      "epoch 12; iter: 200; batch classifier loss: 0.330083; batch adversarial loss: 0.565582\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328799; batch adversarial loss: 0.577268\n",
      "epoch 13; iter: 200; batch classifier loss: 0.393373; batch adversarial loss: 0.634287\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438386; batch adversarial loss: 0.631702\n",
      "epoch 14; iter: 200; batch classifier loss: 0.417712; batch adversarial loss: 0.615602\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334054; batch adversarial loss: 0.592085\n",
      "epoch 15; iter: 200; batch classifier loss: 0.636346; batch adversarial loss: 0.671278\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503332; batch adversarial loss: 0.624539\n",
      "epoch 16; iter: 200; batch classifier loss: 0.369518; batch adversarial loss: 0.620417\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269992; batch adversarial loss: 0.659154\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349822; batch adversarial loss: 0.604671\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298971; batch adversarial loss: 0.667067\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399577; batch adversarial loss: 0.620408\n",
      "epoch 19; iter: 0; batch classifier loss: 0.336735; batch adversarial loss: 0.637277\n",
      "epoch 19; iter: 200; batch classifier loss: 0.356969; batch adversarial loss: 0.617243\n",
      "epoch 0; iter: 0; batch classifier loss: 38.721920; batch adversarial loss: 0.792201\n",
      "epoch 0; iter: 200; batch classifier loss: 5.426563; batch adversarial loss: 0.635192\n",
      "epoch 1; iter: 0; batch classifier loss: 4.056124; batch adversarial loss: 0.685118\n",
      "epoch 1; iter: 200; batch classifier loss: 6.800839; batch adversarial loss: 0.647178\n",
      "epoch 2; iter: 0; batch classifier loss: 2.151925; batch adversarial loss: 0.640795\n",
      "epoch 2; iter: 200; batch classifier loss: 3.926524; batch adversarial loss: 0.606266\n",
      "epoch 3; iter: 0; batch classifier loss: 5.253396; batch adversarial loss: 0.645890\n",
      "epoch 3; iter: 200; batch classifier loss: 5.255263; batch adversarial loss: 0.601088\n",
      "epoch 4; iter: 0; batch classifier loss: 1.465123; batch adversarial loss: 0.622502\n",
      "epoch 4; iter: 200; batch classifier loss: 1.755361; batch adversarial loss: 0.616359\n",
      "epoch 5; iter: 0; batch classifier loss: 0.803245; batch adversarial loss: 0.637311\n",
      "epoch 5; iter: 200; batch classifier loss: 1.131604; batch adversarial loss: 0.661646\n",
      "epoch 6; iter: 0; batch classifier loss: 1.216696; batch adversarial loss: 0.661968\n",
      "epoch 6; iter: 200; batch classifier loss: 0.434398; batch adversarial loss: 0.634534\n",
      "epoch 7; iter: 0; batch classifier loss: 1.113461; batch adversarial loss: 0.552029\n",
      "epoch 7; iter: 200; batch classifier loss: 0.666780; batch adversarial loss: 0.649266\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567272; batch adversarial loss: 0.708555\n",
      "epoch 8; iter: 200; batch classifier loss: 0.622517; batch adversarial loss: 0.636116\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526235; batch adversarial loss: 0.614022\n",
      "epoch 9; iter: 200; batch classifier loss: 0.665068; batch adversarial loss: 0.633412\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557384; batch adversarial loss: 0.617155\n",
      "epoch 10; iter: 200; batch classifier loss: 0.555071; batch adversarial loss: 0.651869\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492123; batch adversarial loss: 0.624582\n",
      "epoch 11; iter: 200; batch classifier loss: 0.688411; batch adversarial loss: 0.615214\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481317; batch adversarial loss: 0.608776\n",
      "epoch 12; iter: 200; batch classifier loss: 0.349124; batch adversarial loss: 0.544743\n",
      "epoch 13; iter: 0; batch classifier loss: 0.450239; batch adversarial loss: 0.573217\n",
      "epoch 13; iter: 200; batch classifier loss: 0.677368; batch adversarial loss: 0.663995\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475287; batch adversarial loss: 0.599420\n",
      "epoch 14; iter: 200; batch classifier loss: 0.319283; batch adversarial loss: 0.633995\n",
      "epoch 15; iter: 0; batch classifier loss: 0.455098; batch adversarial loss: 0.567626\n",
      "epoch 15; iter: 200; batch classifier loss: 0.587150; batch adversarial loss: 0.611803\n",
      "epoch 16; iter: 0; batch classifier loss: 0.292428; batch adversarial loss: 0.596884\n",
      "epoch 16; iter: 200; batch classifier loss: 0.675757; batch adversarial loss: 0.640019\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322293; batch adversarial loss: 0.625864\n",
      "epoch 17; iter: 200; batch classifier loss: 0.904126; batch adversarial loss: 0.603781\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345533; batch adversarial loss: 0.676269\n",
      "epoch 18; iter: 200; batch classifier loss: 0.411274; batch adversarial loss: 0.588138\n",
      "epoch 19; iter: 0; batch classifier loss: 0.553391; batch adversarial loss: 0.645939\n",
      "epoch 19; iter: 200; batch classifier loss: 0.381052; batch adversarial loss: 0.605550\n",
      "epoch 0; iter: 0; batch classifier loss: 43.309807; batch adversarial loss: 1.404287\n",
      "epoch 0; iter: 200; batch classifier loss: 4.411333; batch adversarial loss: 1.096555\n",
      "epoch 1; iter: 0; batch classifier loss: 8.215219; batch adversarial loss: 1.040351\n",
      "epoch 1; iter: 200; batch classifier loss: 3.007888; batch adversarial loss: 0.673598\n",
      "epoch 2; iter: 0; batch classifier loss: 11.915035; batch adversarial loss: 0.794311\n",
      "epoch 2; iter: 200; batch classifier loss: 1.763115; batch adversarial loss: 0.687360\n",
      "epoch 3; iter: 0; batch classifier loss: 0.815795; batch adversarial loss: 0.722105\n",
      "epoch 3; iter: 200; batch classifier loss: 1.696285; batch adversarial loss: 0.595962\n",
      "epoch 4; iter: 0; batch classifier loss: 3.051723; batch adversarial loss: 0.672812\n",
      "epoch 4; iter: 200; batch classifier loss: 1.333626; batch adversarial loss: 0.655109\n",
      "epoch 5; iter: 0; batch classifier loss: 2.526868; batch adversarial loss: 0.658041\n",
      "epoch 5; iter: 200; batch classifier loss: 0.867974; batch adversarial loss: 0.668820\n",
      "epoch 6; iter: 0; batch classifier loss: 1.911922; batch adversarial loss: 0.655941\n",
      "epoch 6; iter: 200; batch classifier loss: 0.991900; batch adversarial loss: 0.628892\n",
      "epoch 7; iter: 0; batch classifier loss: 1.898636; batch adversarial loss: 0.645561\n",
      "epoch 7; iter: 200; batch classifier loss: 0.942883; batch adversarial loss: 0.674787\n",
      "epoch 8; iter: 0; batch classifier loss: 0.605938; batch adversarial loss: 0.534932\n",
      "epoch 8; iter: 200; batch classifier loss: 0.433652; batch adversarial loss: 0.619540\n",
      "epoch 9; iter: 0; batch classifier loss: 0.681731; batch adversarial loss: 0.618023\n",
      "epoch 9; iter: 200; batch classifier loss: 0.513624; batch adversarial loss: 0.555223\n",
      "epoch 10; iter: 0; batch classifier loss: 0.417864; batch adversarial loss: 0.636244\n",
      "epoch 10; iter: 200; batch classifier loss: 0.439347; batch adversarial loss: 0.627036\n",
      "epoch 11; iter: 0; batch classifier loss: 0.950968; batch adversarial loss: 0.586239\n",
      "epoch 11; iter: 200; batch classifier loss: 0.405420; batch adversarial loss: 0.630256\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498024; batch adversarial loss: 0.608934\n",
      "epoch 12; iter: 200; batch classifier loss: 0.436703; batch adversarial loss: 0.639760\n",
      "epoch 13; iter: 0; batch classifier loss: 0.442104; batch adversarial loss: 0.635265\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404304; batch adversarial loss: 0.656444\n",
      "epoch 14; iter: 0; batch classifier loss: 0.714591; batch adversarial loss: 0.645029\n",
      "epoch 14; iter: 200; batch classifier loss: 0.436535; batch adversarial loss: 0.647921\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406698; batch adversarial loss: 0.625013\n",
      "epoch 15; iter: 200; batch classifier loss: 0.477639; batch adversarial loss: 0.667261\n",
      "epoch 16; iter: 0; batch classifier loss: 0.434587; batch adversarial loss: 0.655393\n",
      "epoch 16; iter: 200; batch classifier loss: 0.418226; batch adversarial loss: 0.616172\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336988; batch adversarial loss: 0.613175\n",
      "epoch 17; iter: 200; batch classifier loss: 0.371949; batch adversarial loss: 0.692500\n",
      "epoch 18; iter: 0; batch classifier loss: 0.392648; batch adversarial loss: 0.602143\n",
      "epoch 18; iter: 200; batch classifier loss: 0.413692; batch adversarial loss: 0.615255\n",
      "epoch 19; iter: 0; batch classifier loss: 0.421073; batch adversarial loss: 0.591060\n",
      "epoch 19; iter: 200; batch classifier loss: 0.409712; batch adversarial loss: 0.642342\n",
      "epoch 0; iter: 0; batch classifier loss: 18.527281; batch adversarial loss: 0.676907\n",
      "epoch 0; iter: 200; batch classifier loss: 3.951191; batch adversarial loss: 0.619068\n",
      "epoch 1; iter: 0; batch classifier loss: 7.430105; batch adversarial loss: 0.626400\n",
      "epoch 1; iter: 200; batch classifier loss: 4.795127; batch adversarial loss: 0.652071\n",
      "epoch 2; iter: 0; batch classifier loss: 1.030013; batch adversarial loss: 0.627117\n",
      "epoch 2; iter: 200; batch classifier loss: 1.761095; batch adversarial loss: 0.646134\n",
      "epoch 3; iter: 0; batch classifier loss: 0.684890; batch adversarial loss: 0.611597\n",
      "epoch 3; iter: 200; batch classifier loss: 1.074246; batch adversarial loss: 0.637722\n",
      "epoch 4; iter: 0; batch classifier loss: 1.496028; batch adversarial loss: 0.596422\n",
      "epoch 4; iter: 200; batch classifier loss: 0.502595; batch adversarial loss: 0.626909\n",
      "epoch 5; iter: 0; batch classifier loss: 1.029815; batch adversarial loss: 0.604729\n",
      "epoch 5; iter: 200; batch classifier loss: 1.484960; batch adversarial loss: 0.625416\n",
      "epoch 6; iter: 0; batch classifier loss: 0.721320; batch adversarial loss: 0.595846\n",
      "epoch 6; iter: 200; batch classifier loss: 0.557745; batch adversarial loss: 0.672347\n",
      "epoch 7; iter: 0; batch classifier loss: 0.577393; batch adversarial loss: 0.628959\n",
      "epoch 7; iter: 200; batch classifier loss: 0.362234; batch adversarial loss: 0.607419\n",
      "epoch 8; iter: 0; batch classifier loss: 1.244828; batch adversarial loss: 0.693717\n",
      "epoch 8; iter: 200; batch classifier loss: 0.501646; batch adversarial loss: 0.619907\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511897; batch adversarial loss: 0.586472\n",
      "epoch 9; iter: 200; batch classifier loss: 0.849666; batch adversarial loss: 0.647951\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400547; batch adversarial loss: 0.624928\n",
      "epoch 10; iter: 200; batch classifier loss: 0.368661; batch adversarial loss: 0.635354\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404278; batch adversarial loss: 0.600422\n",
      "epoch 11; iter: 200; batch classifier loss: 0.468059; batch adversarial loss: 0.632081\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390593; batch adversarial loss: 0.593907\n",
      "epoch 12; iter: 200; batch classifier loss: 0.374259; batch adversarial loss: 0.617365\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350455; batch adversarial loss: 0.657035\n",
      "epoch 13; iter: 200; batch classifier loss: 0.426789; batch adversarial loss: 0.648368\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406155; batch adversarial loss: 0.596969\n",
      "epoch 14; iter: 200; batch classifier loss: 0.396416; batch adversarial loss: 0.621754\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287319; batch adversarial loss: 0.589225\n",
      "epoch 15; iter: 200; batch classifier loss: 0.492221; batch adversarial loss: 0.684921\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331834; batch adversarial loss: 0.675023\n",
      "epoch 16; iter: 200; batch classifier loss: 0.607338; batch adversarial loss: 0.606256\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373587; batch adversarial loss: 0.544885\n",
      "epoch 17; iter: 200; batch classifier loss: 0.318401; batch adversarial loss: 0.629860\n",
      "epoch 18; iter: 0; batch classifier loss: 0.406876; batch adversarial loss: 0.664824\n",
      "epoch 18; iter: 200; batch classifier loss: 0.308833; batch adversarial loss: 0.636898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.377081; batch adversarial loss: 0.629478\n",
      "epoch 19; iter: 200; batch classifier loss: 0.474523; batch adversarial loss: 0.582648\n",
      "epoch 0; iter: 0; batch classifier loss: 185.740417; batch adversarial loss: 0.912181\n",
      "epoch 0; iter: 200; batch classifier loss: 4.587749; batch adversarial loss: 0.690155\n",
      "epoch 1; iter: 0; batch classifier loss: 10.362035; batch adversarial loss: 0.683526\n",
      "epoch 1; iter: 200; batch classifier loss: 6.435456; batch adversarial loss: 0.686083\n",
      "epoch 2; iter: 0; batch classifier loss: 11.359820; batch adversarial loss: 0.703540\n",
      "epoch 2; iter: 200; batch classifier loss: 1.778242; batch adversarial loss: 0.664773\n",
      "epoch 3; iter: 0; batch classifier loss: 4.024275; batch adversarial loss: 0.660334\n",
      "epoch 3; iter: 200; batch classifier loss: 4.046700; batch adversarial loss: 0.631777\n",
      "epoch 4; iter: 0; batch classifier loss: 3.484391; batch adversarial loss: 0.611827\n",
      "epoch 4; iter: 200; batch classifier loss: 1.459392; batch adversarial loss: 0.660718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.769286; batch adversarial loss: 0.636510\n",
      "epoch 5; iter: 200; batch classifier loss: 0.848521; batch adversarial loss: 0.652625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.623178; batch adversarial loss: 0.586541\n",
      "epoch 6; iter: 200; batch classifier loss: 0.501434; batch adversarial loss: 0.633052\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587581; batch adversarial loss: 0.646196\n",
      "epoch 7; iter: 200; batch classifier loss: 0.999326; batch adversarial loss: 0.632867\n",
      "epoch 8; iter: 0; batch classifier loss: 0.938334; batch adversarial loss: 0.657149\n",
      "epoch 8; iter: 200; batch classifier loss: 0.593306; batch adversarial loss: 0.672141\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343480; batch adversarial loss: 0.560305\n",
      "epoch 9; iter: 200; batch classifier loss: 0.580906; batch adversarial loss: 0.649007\n",
      "epoch 10; iter: 0; batch classifier loss: 0.417949; batch adversarial loss: 0.654328\n",
      "epoch 10; iter: 200; batch classifier loss: 0.551114; batch adversarial loss: 0.622635\n",
      "epoch 11; iter: 0; batch classifier loss: 0.335015; batch adversarial loss: 0.656262\n",
      "epoch 11; iter: 200; batch classifier loss: 0.672862; batch adversarial loss: 0.626872\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417086; batch adversarial loss: 0.664797\n",
      "epoch 12; iter: 200; batch classifier loss: 0.456172; batch adversarial loss: 0.588340\n",
      "epoch 13; iter: 0; batch classifier loss: 0.375176; batch adversarial loss: 0.599693\n",
      "epoch 13; iter: 200; batch classifier loss: 0.390549; batch adversarial loss: 0.657256\n",
      "epoch 14; iter: 0; batch classifier loss: 0.549302; batch adversarial loss: 0.622186\n",
      "epoch 14; iter: 200; batch classifier loss: 0.353514; batch adversarial loss: 0.659469\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456492; batch adversarial loss: 0.637530\n",
      "epoch 15; iter: 200; batch classifier loss: 0.471417; batch adversarial loss: 0.626706\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337927; batch adversarial loss: 0.636066\n",
      "epoch 16; iter: 200; batch classifier loss: 0.334217; batch adversarial loss: 0.591860\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309584; batch adversarial loss: 0.633573\n",
      "epoch 17; iter: 200; batch classifier loss: 0.398072; batch adversarial loss: 0.615489\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308222; batch adversarial loss: 0.593587\n",
      "epoch 18; iter: 200; batch classifier loss: 0.403941; batch adversarial loss: 0.624125\n",
      "epoch 19; iter: 0; batch classifier loss: 0.371463; batch adversarial loss: 0.580042\n",
      "epoch 19; iter: 200; batch classifier loss: 0.384178; batch adversarial loss: 0.619404\n",
      "epoch 0; iter: 0; batch classifier loss: 19.776745; batch adversarial loss: 0.617130\n",
      "epoch 0; iter: 200; batch classifier loss: 6.551877; batch adversarial loss: 0.610797\n",
      "epoch 1; iter: 0; batch classifier loss: 3.255954; batch adversarial loss: 0.678128\n",
      "epoch 1; iter: 200; batch classifier loss: 11.484115; batch adversarial loss: 0.665017\n",
      "epoch 2; iter: 0; batch classifier loss: 4.716162; batch adversarial loss: 0.571199\n",
      "epoch 2; iter: 200; batch classifier loss: 1.001973; batch adversarial loss: 0.626249\n",
      "epoch 3; iter: 0; batch classifier loss: 3.448339; batch adversarial loss: 0.681029\n",
      "epoch 3; iter: 200; batch classifier loss: 2.172280; batch adversarial loss: 0.739504\n",
      "epoch 4; iter: 0; batch classifier loss: 0.861520; batch adversarial loss: 0.613344\n",
      "epoch 4; iter: 200; batch classifier loss: 0.551901; batch adversarial loss: 0.629359\n",
      "epoch 5; iter: 0; batch classifier loss: 1.482293; batch adversarial loss: 0.603770\n",
      "epoch 5; iter: 200; batch classifier loss: 1.105197; batch adversarial loss: 0.599950\n",
      "epoch 6; iter: 0; batch classifier loss: 0.753109; batch adversarial loss: 0.563048\n",
      "epoch 6; iter: 200; batch classifier loss: 0.622961; batch adversarial loss: 0.600515\n",
      "epoch 7; iter: 0; batch classifier loss: 0.923325; batch adversarial loss: 0.627975\n",
      "epoch 7; iter: 200; batch classifier loss: 0.661418; batch adversarial loss: 0.662915\n",
      "epoch 8; iter: 0; batch classifier loss: 0.719691; batch adversarial loss: 0.593891\n",
      "epoch 8; iter: 200; batch classifier loss: 0.504087; batch adversarial loss: 0.532084\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616021; batch adversarial loss: 0.616302\n",
      "epoch 9; iter: 200; batch classifier loss: 0.420774; batch adversarial loss: 0.636823\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400675; batch adversarial loss: 0.679140\n",
      "epoch 10; iter: 200; batch classifier loss: 0.340668; batch adversarial loss: 0.661718\n",
      "epoch 11; iter: 0; batch classifier loss: 0.375342; batch adversarial loss: 0.616795\n",
      "epoch 11; iter: 200; batch classifier loss: 0.386925; batch adversarial loss: 0.626333\n",
      "epoch 12; iter: 0; batch classifier loss: 0.362411; batch adversarial loss: 0.623094\n",
      "epoch 12; iter: 200; batch classifier loss: 0.551886; batch adversarial loss: 0.665029\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312541; batch adversarial loss: 0.570884\n",
      "epoch 13; iter: 200; batch classifier loss: 0.373711; batch adversarial loss: 0.600081\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389306; batch adversarial loss: 0.661490\n",
      "epoch 14; iter: 200; batch classifier loss: 0.509192; batch adversarial loss: 0.596063\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451750; batch adversarial loss: 0.621274\n",
      "epoch 15; iter: 200; batch classifier loss: 0.491295; batch adversarial loss: 0.628742\n",
      "epoch 16; iter: 0; batch classifier loss: 0.339729; batch adversarial loss: 0.665688\n",
      "epoch 16; iter: 200; batch classifier loss: 0.363942; batch adversarial loss: 0.607301\n",
      "epoch 17; iter: 0; batch classifier loss: 0.335943; batch adversarial loss: 0.530722\n",
      "epoch 17; iter: 200; batch classifier loss: 0.287375; batch adversarial loss: 0.651798\n",
      "epoch 18; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.597203\n",
      "epoch 18; iter: 200; batch classifier loss: 0.414810; batch adversarial loss: 0.628931\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338052; batch adversarial loss: 0.603695\n",
      "epoch 19; iter: 200; batch classifier loss: 0.327116; batch adversarial loss: 0.635654\n",
      "epoch 0; iter: 0; batch classifier loss: 13.939488; batch adversarial loss: 0.802913\n",
      "epoch 0; iter: 200; batch classifier loss: 12.669424; batch adversarial loss: 0.763440\n",
      "epoch 1; iter: 0; batch classifier loss: 12.976574; batch adversarial loss: 0.717669\n",
      "epoch 1; iter: 200; batch classifier loss: 4.597258; batch adversarial loss: 0.658788\n",
      "epoch 2; iter: 0; batch classifier loss: 5.762652; batch adversarial loss: 0.713113\n",
      "epoch 2; iter: 200; batch classifier loss: 12.652071; batch adversarial loss: 0.668536\n",
      "epoch 3; iter: 0; batch classifier loss: 3.585215; batch adversarial loss: 0.640763\n",
      "epoch 3; iter: 200; batch classifier loss: 2.847655; batch adversarial loss: 0.665751\n",
      "epoch 4; iter: 0; batch classifier loss: 0.670062; batch adversarial loss: 0.674058\n",
      "epoch 4; iter: 200; batch classifier loss: 1.773702; batch adversarial loss: 0.630519\n",
      "epoch 5; iter: 0; batch classifier loss: 2.212301; batch adversarial loss: 0.542728\n",
      "epoch 5; iter: 200; batch classifier loss: 0.817998; batch adversarial loss: 0.651344\n",
      "epoch 6; iter: 0; batch classifier loss: 1.231462; batch adversarial loss: 0.652740\n",
      "epoch 6; iter: 200; batch classifier loss: 0.714542; batch adversarial loss: 0.660138\n",
      "epoch 7; iter: 0; batch classifier loss: 0.752625; batch adversarial loss: 0.625810\n",
      "epoch 7; iter: 200; batch classifier loss: 0.786758; batch adversarial loss: 0.673905\n",
      "epoch 8; iter: 0; batch classifier loss: 0.677246; batch adversarial loss: 0.627290\n",
      "epoch 8; iter: 200; batch classifier loss: 0.526902; batch adversarial loss: 0.641663\n",
      "epoch 9; iter: 0; batch classifier loss: 0.322539; batch adversarial loss: 0.575209\n",
      "epoch 9; iter: 200; batch classifier loss: 0.475100; batch adversarial loss: 0.586151\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563328; batch adversarial loss: 0.690089\n",
      "epoch 10; iter: 200; batch classifier loss: 0.417355; batch adversarial loss: 0.621145\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441244; batch adversarial loss: 0.623652\n",
      "epoch 11; iter: 200; batch classifier loss: 0.360229; batch adversarial loss: 0.599347\n",
      "epoch 12; iter: 0; batch classifier loss: 0.374980; batch adversarial loss: 0.576257\n",
      "epoch 12; iter: 200; batch classifier loss: 0.286916; batch adversarial loss: 0.622461\n",
      "epoch 13; iter: 0; batch classifier loss: 0.442565; batch adversarial loss: 0.609026\n",
      "epoch 13; iter: 200; batch classifier loss: 0.452163; batch adversarial loss: 0.596182\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396374; batch adversarial loss: 0.638814\n",
      "epoch 14; iter: 200; batch classifier loss: 0.441724; batch adversarial loss: 0.644002\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288007; batch adversarial loss: 0.573508\n",
      "epoch 15; iter: 200; batch classifier loss: 0.350332; batch adversarial loss: 0.595493\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378602; batch adversarial loss: 0.657430\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357191; batch adversarial loss: 0.675818\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383747; batch adversarial loss: 0.637800\n",
      "epoch 17; iter: 200; batch classifier loss: 0.330023; batch adversarial loss: 0.601871\n",
      "epoch 18; iter: 0; batch classifier loss: 0.340539; batch adversarial loss: 0.649111\n",
      "epoch 18; iter: 200; batch classifier loss: 0.260139; batch adversarial loss: 0.680663\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335710; batch adversarial loss: 0.593818\n",
      "epoch 19; iter: 200; batch classifier loss: 0.338209; batch adversarial loss: 0.599737\n",
      "epoch 0; iter: 0; batch classifier loss: 11.074867; batch adversarial loss: 0.687112\n",
      "epoch 0; iter: 200; batch classifier loss: 10.809458; batch adversarial loss: 0.636844\n",
      "epoch 1; iter: 0; batch classifier loss: 9.513906; batch adversarial loss: 0.612382\n",
      "epoch 1; iter: 200; batch classifier loss: 4.144384; batch adversarial loss: 0.640009\n",
      "epoch 2; iter: 0; batch classifier loss: 6.019790; batch adversarial loss: 0.665916\n",
      "epoch 2; iter: 200; batch classifier loss: 3.851123; batch adversarial loss: 0.638907\n",
      "epoch 3; iter: 0; batch classifier loss: 1.492170; batch adversarial loss: 0.646835\n",
      "epoch 3; iter: 200; batch classifier loss: 1.761539; batch adversarial loss: 0.650594\n",
      "epoch 4; iter: 0; batch classifier loss: 2.218306; batch adversarial loss: 0.625898\n",
      "epoch 4; iter: 200; batch classifier loss: 0.722482; batch adversarial loss: 0.625205\n",
      "epoch 5; iter: 0; batch classifier loss: 1.620049; batch adversarial loss: 0.637231\n",
      "epoch 5; iter: 200; batch classifier loss: 0.451426; batch adversarial loss: 0.593156\n",
      "epoch 6; iter: 0; batch classifier loss: 1.383490; batch adversarial loss: 0.577214\n",
      "epoch 6; iter: 200; batch classifier loss: 0.731978; batch adversarial loss: 0.592971\n",
      "epoch 7; iter: 0; batch classifier loss: 1.144190; batch adversarial loss: 0.669546\n",
      "epoch 7; iter: 200; batch classifier loss: 1.050894; batch adversarial loss: 0.591573\n",
      "epoch 8; iter: 0; batch classifier loss: 0.425298; batch adversarial loss: 0.614931\n",
      "epoch 8; iter: 200; batch classifier loss: 0.449718; batch adversarial loss: 0.642182\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612013; batch adversarial loss: 0.554333\n",
      "epoch 9; iter: 200; batch classifier loss: 0.516540; batch adversarial loss: 0.618771\n",
      "epoch 10; iter: 0; batch classifier loss: 0.733758; batch adversarial loss: 0.577524\n",
      "epoch 10; iter: 200; batch classifier loss: 0.362190; batch adversarial loss: 0.653602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533006; batch adversarial loss: 0.635406\n",
      "epoch 11; iter: 200; batch classifier loss: 0.429262; batch adversarial loss: 0.682631\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377438; batch adversarial loss: 0.649966\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420484; batch adversarial loss: 0.633218\n",
      "epoch 13; iter: 0; batch classifier loss: 0.273487; batch adversarial loss: 0.596943\n",
      "epoch 13; iter: 200; batch classifier loss: 0.423419; batch adversarial loss: 0.622361\n",
      "epoch 14; iter: 0; batch classifier loss: 0.446039; batch adversarial loss: 0.616638\n",
      "epoch 14; iter: 200; batch classifier loss: 0.307111; batch adversarial loss: 0.672114\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313269; batch adversarial loss: 0.618931\n",
      "epoch 15; iter: 200; batch classifier loss: 0.306962; batch adversarial loss: 0.696304\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437313; batch adversarial loss: 0.598923\n",
      "epoch 16; iter: 200; batch classifier loss: 0.401428; batch adversarial loss: 0.627922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328600; batch adversarial loss: 0.640159\n",
      "epoch 17; iter: 200; batch classifier loss: 0.374153; batch adversarial loss: 0.646825\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384132; batch adversarial loss: 0.624838\n",
      "epoch 18; iter: 200; batch classifier loss: 0.432509; batch adversarial loss: 0.630999\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463455; batch adversarial loss: 0.624204\n",
      "epoch 19; iter: 200; batch classifier loss: 0.370624; batch adversarial loss: 0.611129\n",
      "epoch 0; iter: 0; batch classifier loss: 32.579014; batch adversarial loss: 0.785842\n",
      "epoch 0; iter: 200; batch classifier loss: 11.233404; batch adversarial loss: 0.675087\n",
      "epoch 1; iter: 0; batch classifier loss: 14.678608; batch adversarial loss: 0.808082\n",
      "epoch 1; iter: 200; batch classifier loss: 10.233735; batch adversarial loss: 0.770543\n",
      "epoch 2; iter: 0; batch classifier loss: 4.735301; batch adversarial loss: 0.696812\n",
      "epoch 2; iter: 200; batch classifier loss: 5.980763; batch adversarial loss: 0.745017\n",
      "epoch 3; iter: 0; batch classifier loss: 4.177382; batch adversarial loss: 0.686097\n",
      "epoch 3; iter: 200; batch classifier loss: 0.564719; batch adversarial loss: 0.686546\n",
      "epoch 4; iter: 0; batch classifier loss: 2.724124; batch adversarial loss: 0.677429\n",
      "epoch 4; iter: 200; batch classifier loss: 2.208343; batch adversarial loss: 0.632969\n",
      "epoch 5; iter: 0; batch classifier loss: 1.212020; batch adversarial loss: 0.595557\n",
      "epoch 5; iter: 200; batch classifier loss: 0.393441; batch adversarial loss: 0.653975\n",
      "epoch 6; iter: 0; batch classifier loss: 1.155067; batch adversarial loss: 0.660702\n",
      "epoch 6; iter: 200; batch classifier loss: 0.751803; batch adversarial loss: 0.590070\n",
      "epoch 7; iter: 0; batch classifier loss: 1.747262; batch adversarial loss: 0.643195\n",
      "epoch 7; iter: 200; batch classifier loss: 0.506056; batch adversarial loss: 0.677560\n",
      "epoch 8; iter: 0; batch classifier loss: 0.932480; batch adversarial loss: 0.619407\n",
      "epoch 8; iter: 200; batch classifier loss: 1.226150; batch adversarial loss: 0.666614\n",
      "epoch 9; iter: 0; batch classifier loss: 1.548928; batch adversarial loss: 0.629430\n",
      "epoch 9; iter: 200; batch classifier loss: 0.873666; batch adversarial loss: 0.603267\n",
      "epoch 10; iter: 0; batch classifier loss: 0.925610; batch adversarial loss: 0.595169\n",
      "epoch 10; iter: 200; batch classifier loss: 0.431986; batch adversarial loss: 0.659979\n",
      "epoch 11; iter: 0; batch classifier loss: 4.415520; batch adversarial loss: 0.593998\n",
      "epoch 11; iter: 200; batch classifier loss: 0.486216; batch adversarial loss: 0.605691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.446445; batch adversarial loss: 0.571741\n",
      "epoch 12; iter: 200; batch classifier loss: 0.463648; batch adversarial loss: 0.637536\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411816; batch adversarial loss: 0.629593\n",
      "epoch 13; iter: 200; batch classifier loss: 0.358004; batch adversarial loss: 0.671770\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351980; batch adversarial loss: 0.594178\n",
      "epoch 14; iter: 200; batch classifier loss: 0.298314; batch adversarial loss: 0.630364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363475; batch adversarial loss: 0.594255\n",
      "epoch 15; iter: 200; batch classifier loss: 0.425129; batch adversarial loss: 0.652289\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346683; batch adversarial loss: 0.663436\n",
      "epoch 16; iter: 200; batch classifier loss: 0.433814; batch adversarial loss: 0.642946\n",
      "epoch 17; iter: 0; batch classifier loss: 0.399875; batch adversarial loss: 0.581339\n",
      "epoch 17; iter: 200; batch classifier loss: 0.506463; batch adversarial loss: 0.647505\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309359; batch adversarial loss: 0.623441\n",
      "epoch 18; iter: 200; batch classifier loss: 0.330808; batch adversarial loss: 0.622018\n",
      "epoch 19; iter: 0; batch classifier loss: 0.308089; batch adversarial loss: 0.630676\n",
      "epoch 19; iter: 200; batch classifier loss: 0.412331; batch adversarial loss: 0.672985\n",
      "epoch 0; iter: 0; batch classifier loss: 47.150356; batch adversarial loss: 0.801296\n",
      "epoch 0; iter: 200; batch classifier loss: 5.763409; batch adversarial loss: 0.723814\n",
      "epoch 1; iter: 0; batch classifier loss: 3.076399; batch adversarial loss: 0.737840\n",
      "epoch 1; iter: 200; batch classifier loss: 3.291828; batch adversarial loss: 0.682293\n",
      "epoch 2; iter: 0; batch classifier loss: 3.694067; batch adversarial loss: 0.624340\n",
      "epoch 2; iter: 200; batch classifier loss: 1.891229; batch adversarial loss: 0.643183\n",
      "epoch 3; iter: 0; batch classifier loss: 2.550506; batch adversarial loss: 0.650683\n",
      "epoch 3; iter: 200; batch classifier loss: 1.951557; batch adversarial loss: 0.648237\n",
      "epoch 4; iter: 0; batch classifier loss: 1.297332; batch adversarial loss: 0.646891\n",
      "epoch 4; iter: 200; batch classifier loss: 2.287985; batch adversarial loss: 0.655832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.994139; batch adversarial loss: 0.629468\n",
      "epoch 5; iter: 200; batch classifier loss: 0.492014; batch adversarial loss: 0.634674\n",
      "epoch 6; iter: 0; batch classifier loss: 0.748745; batch adversarial loss: 0.637702\n",
      "epoch 6; iter: 200; batch classifier loss: 0.807843; batch adversarial loss: 0.612065\n",
      "epoch 7; iter: 0; batch classifier loss: 0.759470; batch adversarial loss: 0.648938\n",
      "epoch 7; iter: 200; batch classifier loss: 0.729962; batch adversarial loss: 0.642034\n",
      "epoch 8; iter: 0; batch classifier loss: 1.118152; batch adversarial loss: 0.613828\n",
      "epoch 8; iter: 200; batch classifier loss: 0.320794; batch adversarial loss: 0.713163\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565365; batch adversarial loss: 0.587153\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383238; batch adversarial loss: 0.590521\n",
      "epoch 10; iter: 0; batch classifier loss: 0.427746; batch adversarial loss: 0.665720\n",
      "epoch 10; iter: 200; batch classifier loss: 0.387833; batch adversarial loss: 0.600664\n",
      "epoch 11; iter: 0; batch classifier loss: 0.349770; batch adversarial loss: 0.590822\n",
      "epoch 11; iter: 200; batch classifier loss: 0.703842; batch adversarial loss: 0.606556\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529953; batch adversarial loss: 0.614963\n",
      "epoch 12; iter: 200; batch classifier loss: 0.415826; batch adversarial loss: 0.635142\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417812; batch adversarial loss: 0.588003\n",
      "epoch 13; iter: 200; batch classifier loss: 0.429094; batch adversarial loss: 0.637016\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544581; batch adversarial loss: 0.633344\n",
      "epoch 14; iter: 200; batch classifier loss: 0.375234; batch adversarial loss: 0.636818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454183; batch adversarial loss: 0.578307\n",
      "epoch 15; iter: 200; batch classifier loss: 0.574346; batch adversarial loss: 0.602746\n",
      "epoch 16; iter: 0; batch classifier loss: 0.345450; batch adversarial loss: 0.648983\n",
      "epoch 16; iter: 200; batch classifier loss: 0.473866; batch adversarial loss: 0.663589\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373980; batch adversarial loss: 0.616727\n",
      "epoch 17; iter: 200; batch classifier loss: 0.386559; batch adversarial loss: 0.614742\n",
      "epoch 18; iter: 0; batch classifier loss: 0.397724; batch adversarial loss: 0.664414\n",
      "epoch 18; iter: 200; batch classifier loss: 0.281500; batch adversarial loss: 0.668094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437774; batch adversarial loss: 0.589077\n",
      "epoch 19; iter: 200; batch classifier loss: 0.288368; batch adversarial loss: 0.629587\n",
      "epoch 0; iter: 0; batch classifier loss: 7.947491; batch adversarial loss: 0.689266\n",
      "epoch 0; iter: 200; batch classifier loss: 6.249808; batch adversarial loss: 0.653515\n",
      "epoch 1; iter: 0; batch classifier loss: 15.666440; batch adversarial loss: 0.667814\n",
      "epoch 1; iter: 200; batch classifier loss: 5.656152; batch adversarial loss: 0.642310\n",
      "epoch 2; iter: 0; batch classifier loss: 41.226109; batch adversarial loss: 0.630110\n",
      "epoch 2; iter: 200; batch classifier loss: 1.456609; batch adversarial loss: 0.607106\n",
      "epoch 3; iter: 0; batch classifier loss: 2.715253; batch adversarial loss: 0.637241\n",
      "epoch 3; iter: 200; batch classifier loss: 3.327636; batch adversarial loss: 0.643401\n",
      "epoch 4; iter: 0; batch classifier loss: 0.953944; batch adversarial loss: 0.639967\n",
      "epoch 4; iter: 200; batch classifier loss: 1.286474; batch adversarial loss: 0.606772\n",
      "epoch 5; iter: 0; batch classifier loss: 1.273318; batch adversarial loss: 0.621563\n",
      "epoch 5; iter: 200; batch classifier loss: 0.868242; batch adversarial loss: 0.595619\n",
      "epoch 6; iter: 0; batch classifier loss: 0.967943; batch adversarial loss: 0.559712\n",
      "epoch 6; iter: 200; batch classifier loss: 0.563345; batch adversarial loss: 0.682663\n",
      "epoch 7; iter: 0; batch classifier loss: 0.430050; batch adversarial loss: 0.593965\n",
      "epoch 7; iter: 200; batch classifier loss: 0.512393; batch adversarial loss: 0.651325\n",
      "epoch 8; iter: 0; batch classifier loss: 0.803512; batch adversarial loss: 0.603923\n",
      "epoch 8; iter: 200; batch classifier loss: 0.402849; batch adversarial loss: 0.627853\n",
      "epoch 9; iter: 0; batch classifier loss: 0.497068; batch adversarial loss: 0.649229\n",
      "epoch 9; iter: 200; batch classifier loss: 0.639247; batch adversarial loss: 0.636690\n",
      "epoch 10; iter: 0; batch classifier loss: 0.891865; batch adversarial loss: 0.572933\n",
      "epoch 10; iter: 200; batch classifier loss: 0.471549; batch adversarial loss: 0.641101\n",
      "epoch 11; iter: 0; batch classifier loss: 0.455195; batch adversarial loss: 0.594580\n",
      "epoch 11; iter: 200; batch classifier loss: 0.514955; batch adversarial loss: 0.577876\n",
      "epoch 12; iter: 0; batch classifier loss: 0.446971; batch adversarial loss: 0.644006\n",
      "epoch 12; iter: 200; batch classifier loss: 0.550192; batch adversarial loss: 0.623506\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350690; batch adversarial loss: 0.582821\n",
      "epoch 13; iter: 200; batch classifier loss: 0.485729; batch adversarial loss: 0.584771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506775; batch adversarial loss: 0.603565\n",
      "epoch 14; iter: 200; batch classifier loss: 0.387653; batch adversarial loss: 0.652489\n",
      "epoch 15; iter: 0; batch classifier loss: 0.342603; batch adversarial loss: 0.656936\n",
      "epoch 15; iter: 200; batch classifier loss: 0.522893; batch adversarial loss: 0.578555\n",
      "epoch 16; iter: 0; batch classifier loss: 0.268820; batch adversarial loss: 0.661921\n",
      "epoch 16; iter: 200; batch classifier loss: 0.397881; batch adversarial loss: 0.624313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430092; batch adversarial loss: 0.650193\n",
      "epoch 17; iter: 200; batch classifier loss: 0.320391; batch adversarial loss: 0.582488\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319621; batch adversarial loss: 0.589382\n",
      "epoch 18; iter: 200; batch classifier loss: 0.442943; batch adversarial loss: 0.633936\n",
      "epoch 19; iter: 0; batch classifier loss: 0.433454; batch adversarial loss: 0.608102\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429085; batch adversarial loss: 0.549772\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 308.837280; batch adversarial loss: 0.824516\n",
      "epoch 0; iter: 200; batch classifier loss: 7.702754; batch adversarial loss: 0.761623\n",
      "epoch 1; iter: 0; batch classifier loss: 5.932555; batch adversarial loss: 0.661865\n",
      "epoch 1; iter: 200; batch classifier loss: 9.793984; batch adversarial loss: 0.674039\n",
      "epoch 2; iter: 0; batch classifier loss: 4.960724; batch adversarial loss: 0.671227\n",
      "epoch 2; iter: 200; batch classifier loss: 2.001101; batch adversarial loss: 0.634009\n",
      "epoch 3; iter: 0; batch classifier loss: 4.656163; batch adversarial loss: 0.660216\n",
      "epoch 3; iter: 200; batch classifier loss: 4.805992; batch adversarial loss: 0.590922\n",
      "epoch 4; iter: 0; batch classifier loss: 1.444622; batch adversarial loss: 0.619041\n",
      "epoch 4; iter: 200; batch classifier loss: 2.186028; batch adversarial loss: 0.627161\n",
      "epoch 5; iter: 0; batch classifier loss: 1.197754; batch adversarial loss: 0.557619\n",
      "epoch 5; iter: 200; batch classifier loss: 0.887359; batch adversarial loss: 0.707346\n",
      "epoch 6; iter: 0; batch classifier loss: 1.581642; batch adversarial loss: 0.648910\n",
      "epoch 6; iter: 200; batch classifier loss: 0.542005; batch adversarial loss: 0.619459\n",
      "epoch 7; iter: 0; batch classifier loss: 0.257167; batch adversarial loss: 0.633325\n",
      "epoch 7; iter: 200; batch classifier loss: 0.395611; batch adversarial loss: 0.604920\n",
      "epoch 8; iter: 0; batch classifier loss: 1.057013; batch adversarial loss: 0.648263\n",
      "epoch 8; iter: 200; batch classifier loss: 1.312080; batch adversarial loss: 0.602499\n",
      "epoch 9; iter: 0; batch classifier loss: 0.672760; batch adversarial loss: 0.616525\n",
      "epoch 9; iter: 200; batch classifier loss: 0.462350; batch adversarial loss: 0.638012\n",
      "epoch 10; iter: 0; batch classifier loss: 0.652548; batch adversarial loss: 0.610323\n",
      "epoch 10; iter: 200; batch classifier loss: 0.956668; batch adversarial loss: 0.618588\n",
      "epoch 11; iter: 0; batch classifier loss: 0.399525; batch adversarial loss: 0.593525\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412034; batch adversarial loss: 0.587466\n",
      "epoch 12; iter: 0; batch classifier loss: 0.543876; batch adversarial loss: 0.629467\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420855; batch adversarial loss: 0.703647\n",
      "epoch 13; iter: 0; batch classifier loss: 0.423219; batch adversarial loss: 0.628630\n",
      "epoch 13; iter: 200; batch classifier loss: 0.463201; batch adversarial loss: 0.612299\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489467; batch adversarial loss: 0.614243\n",
      "epoch 14; iter: 200; batch classifier loss: 0.708724; batch adversarial loss: 0.584739\n",
      "epoch 15; iter: 0; batch classifier loss: 1.035330; batch adversarial loss: 0.665958\n",
      "epoch 15; iter: 200; batch classifier loss: 0.384853; batch adversarial loss: 0.663615\n",
      "epoch 16; iter: 0; batch classifier loss: 0.425493; batch adversarial loss: 0.630398\n",
      "epoch 16; iter: 200; batch classifier loss: 0.538504; batch adversarial loss: 0.656268\n",
      "epoch 17; iter: 0; batch classifier loss: 0.395862; batch adversarial loss: 0.622696\n",
      "epoch 17; iter: 200; batch classifier loss: 0.525252; batch adversarial loss: 0.586181\n",
      "epoch 18; iter: 0; batch classifier loss: 0.480950; batch adversarial loss: 0.635708\n",
      "epoch 18; iter: 200; batch classifier loss: 0.445367; batch adversarial loss: 0.628227\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447388; batch adversarial loss: 0.669482\n",
      "epoch 19; iter: 200; batch classifier loss: 0.435476; batch adversarial loss: 0.650849\n",
      "epoch 20; iter: 0; batch classifier loss: 0.633441; batch adversarial loss: 0.607935\n",
      "epoch 20; iter: 200; batch classifier loss: 0.501074; batch adversarial loss: 0.591803\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469200; batch adversarial loss: 0.603418\n",
      "epoch 21; iter: 200; batch classifier loss: 0.378736; batch adversarial loss: 0.614531\n",
      "epoch 22; iter: 0; batch classifier loss: 0.375528; batch adversarial loss: 0.588603\n",
      "epoch 22; iter: 200; batch classifier loss: 0.340024; batch adversarial loss: 0.587714\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344231; batch adversarial loss: 0.635619\n",
      "epoch 23; iter: 200; batch classifier loss: 0.383001; batch adversarial loss: 0.614166\n",
      "epoch 24; iter: 0; batch classifier loss: 0.386083; batch adversarial loss: 0.573895\n",
      "epoch 24; iter: 200; batch classifier loss: 0.325209; batch adversarial loss: 0.603827\n",
      "epoch 25; iter: 0; batch classifier loss: 0.301856; batch adversarial loss: 0.613645\n",
      "epoch 25; iter: 200; batch classifier loss: 0.307912; batch adversarial loss: 0.636447\n",
      "epoch 26; iter: 0; batch classifier loss: 0.415541; batch adversarial loss: 0.597134\n",
      "epoch 26; iter: 200; batch classifier loss: 0.357074; batch adversarial loss: 0.651607\n",
      "epoch 27; iter: 0; batch classifier loss: 0.406039; batch adversarial loss: 0.605683\n",
      "epoch 27; iter: 200; batch classifier loss: 0.399782; batch adversarial loss: 0.644881\n",
      "epoch 28; iter: 0; batch classifier loss: 0.388768; batch adversarial loss: 0.596912\n",
      "epoch 28; iter: 200; batch classifier loss: 0.341557; batch adversarial loss: 0.626300\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338951; batch adversarial loss: 0.575154\n",
      "epoch 29; iter: 200; batch classifier loss: 0.313066; batch adversarial loss: 0.677204\n",
      "epoch 30; iter: 0; batch classifier loss: 0.413765; batch adversarial loss: 0.587497\n",
      "epoch 30; iter: 200; batch classifier loss: 0.282571; batch adversarial loss: 0.636884\n",
      "epoch 31; iter: 0; batch classifier loss: 0.381153; batch adversarial loss: 0.649670\n",
      "epoch 31; iter: 200; batch classifier loss: 0.394492; batch adversarial loss: 0.613096\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400102; batch adversarial loss: 0.596391\n",
      "epoch 32; iter: 200; batch classifier loss: 0.324533; batch adversarial loss: 0.596767\n",
      "epoch 33; iter: 0; batch classifier loss: 0.364531; batch adversarial loss: 0.606983\n",
      "epoch 33; iter: 200; batch classifier loss: 0.346781; batch adversarial loss: 0.670273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.333233; batch adversarial loss: 0.647064\n",
      "epoch 34; iter: 200; batch classifier loss: 0.261575; batch adversarial loss: 0.613281\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422536; batch adversarial loss: 0.643337\n",
      "epoch 35; iter: 200; batch classifier loss: 0.378572; batch adversarial loss: 0.633970\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405537; batch adversarial loss: 0.573864\n",
      "epoch 36; iter: 200; batch classifier loss: 0.354955; batch adversarial loss: 0.650875\n",
      "epoch 37; iter: 0; batch classifier loss: 0.263739; batch adversarial loss: 0.599491\n",
      "epoch 37; iter: 200; batch classifier loss: 0.371851; batch adversarial loss: 0.626510\n",
      "epoch 38; iter: 0; batch classifier loss: 0.299212; batch adversarial loss: 0.655931\n",
      "epoch 38; iter: 200; batch classifier loss: 0.344414; batch adversarial loss: 0.594600\n",
      "epoch 39; iter: 0; batch classifier loss: 0.636019; batch adversarial loss: 0.606967\n",
      "epoch 39; iter: 200; batch classifier loss: 0.418054; batch adversarial loss: 0.576707\n",
      "epoch 40; iter: 0; batch classifier loss: 0.353816; batch adversarial loss: 0.560153\n",
      "epoch 40; iter: 200; batch classifier loss: 0.415982; batch adversarial loss: 0.625034\n",
      "epoch 41; iter: 0; batch classifier loss: 0.246491; batch adversarial loss: 0.672510\n",
      "epoch 41; iter: 200; batch classifier loss: 0.384330; batch adversarial loss: 0.613831\n",
      "epoch 42; iter: 0; batch classifier loss: 0.362618; batch adversarial loss: 0.634688\n",
      "epoch 42; iter: 200; batch classifier loss: 0.381575; batch adversarial loss: 0.635074\n",
      "epoch 43; iter: 0; batch classifier loss: 0.350567; batch adversarial loss: 0.634233\n",
      "epoch 43; iter: 200; batch classifier loss: 0.281407; batch adversarial loss: 0.577336\n",
      "epoch 44; iter: 0; batch classifier loss: 0.287429; batch adversarial loss: 0.600593\n",
      "epoch 44; iter: 200; batch classifier loss: 0.349370; batch adversarial loss: 0.643220\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336844; batch adversarial loss: 0.636315\n",
      "epoch 45; iter: 200; batch classifier loss: 0.251388; batch adversarial loss: 0.618372\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324040; batch adversarial loss: 0.573855\n",
      "epoch 46; iter: 200; batch classifier loss: 0.270764; batch adversarial loss: 0.656080\n",
      "epoch 47; iter: 0; batch classifier loss: 0.272253; batch adversarial loss: 0.669578\n",
      "epoch 47; iter: 200; batch classifier loss: 0.362644; batch adversarial loss: 0.590986\n",
      "epoch 48; iter: 0; batch classifier loss: 0.398996; batch adversarial loss: 0.578528\n",
      "epoch 48; iter: 200; batch classifier loss: 0.405453; batch adversarial loss: 0.608049\n",
      "epoch 49; iter: 0; batch classifier loss: 0.330070; batch adversarial loss: 0.660638\n",
      "epoch 49; iter: 200; batch classifier loss: 0.461986; batch adversarial loss: 0.610976\n",
      "epoch 0; iter: 0; batch classifier loss: 64.056877; batch adversarial loss: 0.683166\n",
      "epoch 0; iter: 200; batch classifier loss: 9.712795; batch adversarial loss: 0.659649\n",
      "epoch 1; iter: 0; batch classifier loss: 2.898802; batch adversarial loss: 0.630062\n",
      "epoch 1; iter: 200; batch classifier loss: 10.573372; batch adversarial loss: 0.681903\n",
      "epoch 2; iter: 0; batch classifier loss: 4.305972; batch adversarial loss: 0.648274\n",
      "epoch 2; iter: 200; batch classifier loss: 8.035603; batch adversarial loss: 0.630693\n",
      "epoch 3; iter: 0; batch classifier loss: 2.973814; batch adversarial loss: 0.626793\n",
      "epoch 3; iter: 200; batch classifier loss: 3.678542; batch adversarial loss: 0.610332\n",
      "epoch 4; iter: 0; batch classifier loss: 1.933077; batch adversarial loss: 0.598515\n",
      "epoch 4; iter: 200; batch classifier loss: 3.226970; batch adversarial loss: 0.661421\n",
      "epoch 5; iter: 0; batch classifier loss: 4.594602; batch adversarial loss: 0.663224\n",
      "epoch 5; iter: 200; batch classifier loss: 0.959080; batch adversarial loss: 0.702007\n",
      "epoch 6; iter: 0; batch classifier loss: 0.793351; batch adversarial loss: 0.578261\n",
      "epoch 6; iter: 200; batch classifier loss: 1.381063; batch adversarial loss: 0.614078\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595203; batch adversarial loss: 0.590928\n",
      "epoch 7; iter: 200; batch classifier loss: 0.444515; batch adversarial loss: 0.593687\n",
      "epoch 8; iter: 0; batch classifier loss: 1.156346; batch adversarial loss: 0.614093\n",
      "epoch 8; iter: 200; batch classifier loss: 0.676981; batch adversarial loss: 0.635671\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357735; batch adversarial loss: 0.659962\n",
      "epoch 9; iter: 200; batch classifier loss: 0.443998; batch adversarial loss: 0.598304\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405584; batch adversarial loss: 0.649537\n",
      "epoch 10; iter: 200; batch classifier loss: 0.302678; batch adversarial loss: 0.609776\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448392; batch adversarial loss: 0.613354\n",
      "epoch 11; iter: 200; batch classifier loss: 1.346568; batch adversarial loss: 0.613874\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577996; batch adversarial loss: 0.553409\n",
      "epoch 12; iter: 200; batch classifier loss: 0.521199; batch adversarial loss: 0.646569\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412999; batch adversarial loss: 0.631545\n",
      "epoch 13; iter: 200; batch classifier loss: 0.435235; batch adversarial loss: 0.602897\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340441; batch adversarial loss: 0.641091\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378145; batch adversarial loss: 0.660212\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373365; batch adversarial loss: 0.577913\n",
      "epoch 15; iter: 200; batch classifier loss: 0.421358; batch adversarial loss: 0.623720\n",
      "epoch 16; iter: 0; batch classifier loss: 0.422638; batch adversarial loss: 0.649704\n",
      "epoch 16; iter: 200; batch classifier loss: 0.346870; batch adversarial loss: 0.682255\n",
      "epoch 17; iter: 0; batch classifier loss: 0.408507; batch adversarial loss: 0.633656\n",
      "epoch 17; iter: 200; batch classifier loss: 0.378173; batch adversarial loss: 0.686251\n",
      "epoch 18; iter: 0; batch classifier loss: 0.347185; batch adversarial loss: 0.575901\n",
      "epoch 18; iter: 200; batch classifier loss: 0.434754; batch adversarial loss: 0.669475\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338935; batch adversarial loss: 0.655783\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372043; batch adversarial loss: 0.625979\n",
      "epoch 20; iter: 0; batch classifier loss: 0.350242; batch adversarial loss: 0.622428\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368343; batch adversarial loss: 0.622838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.347290; batch adversarial loss: 0.656856\n",
      "epoch 21; iter: 200; batch classifier loss: 0.319601; batch adversarial loss: 0.688116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.324558; batch adversarial loss: 0.680122\n",
      "epoch 22; iter: 200; batch classifier loss: 0.282489; batch adversarial loss: 0.639381\n",
      "epoch 23; iter: 0; batch classifier loss: 0.369781; batch adversarial loss: 0.626037\n",
      "epoch 23; iter: 200; batch classifier loss: 0.377865; batch adversarial loss: 0.622209\n",
      "epoch 24; iter: 0; batch classifier loss: 0.317427; batch adversarial loss: 0.634320\n",
      "epoch 24; iter: 200; batch classifier loss: 0.313330; batch adversarial loss: 0.582815\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339062; batch adversarial loss: 0.598867\n",
      "epoch 25; iter: 200; batch classifier loss: 0.420072; batch adversarial loss: 0.685464\n",
      "epoch 26; iter: 0; batch classifier loss: 0.381048; batch adversarial loss: 0.677928\n",
      "epoch 26; iter: 200; batch classifier loss: 0.389391; batch adversarial loss: 0.636292\n",
      "epoch 27; iter: 0; batch classifier loss: 0.365202; batch adversarial loss: 0.634100\n",
      "epoch 27; iter: 200; batch classifier loss: 0.379262; batch adversarial loss: 0.612271\n",
      "epoch 28; iter: 0; batch classifier loss: 0.302637; batch adversarial loss: 0.648665\n",
      "epoch 28; iter: 200; batch classifier loss: 0.420826; batch adversarial loss: 0.616039\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447169; batch adversarial loss: 0.572641\n",
      "epoch 29; iter: 200; batch classifier loss: 0.313972; batch adversarial loss: 0.669840\n",
      "epoch 30; iter: 0; batch classifier loss: 0.360021; batch adversarial loss: 0.632530\n",
      "epoch 30; iter: 200; batch classifier loss: 0.371103; batch adversarial loss: 0.621563\n",
      "epoch 31; iter: 0; batch classifier loss: 0.335401; batch adversarial loss: 0.606288\n",
      "epoch 31; iter: 200; batch classifier loss: 0.324267; batch adversarial loss: 0.612114\n",
      "epoch 32; iter: 0; batch classifier loss: 0.372320; batch adversarial loss: 0.605373\n",
      "epoch 32; iter: 200; batch classifier loss: 0.471484; batch adversarial loss: 0.641617\n",
      "epoch 33; iter: 0; batch classifier loss: 0.569549; batch adversarial loss: 0.623972\n",
      "epoch 33; iter: 200; batch classifier loss: 0.262847; batch adversarial loss: 0.647840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393747; batch adversarial loss: 0.621349\n",
      "epoch 34; iter: 200; batch classifier loss: 0.311295; batch adversarial loss: 0.605153\n",
      "epoch 35; iter: 0; batch classifier loss: 0.303630; batch adversarial loss: 0.611885\n",
      "epoch 35; iter: 200; batch classifier loss: 0.394688; batch adversarial loss: 0.603569\n",
      "epoch 36; iter: 0; batch classifier loss: 0.346442; batch adversarial loss: 0.604635\n",
      "epoch 36; iter: 200; batch classifier loss: 0.360752; batch adversarial loss: 0.580307\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460609; batch adversarial loss: 0.566591\n",
      "epoch 37; iter: 200; batch classifier loss: 0.351189; batch adversarial loss: 0.688275\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409419; batch adversarial loss: 0.677406\n",
      "epoch 38; iter: 200; batch classifier loss: 0.319710; batch adversarial loss: 0.631484\n",
      "epoch 39; iter: 0; batch classifier loss: 0.365558; batch adversarial loss: 0.633032\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349759; batch adversarial loss: 0.619754\n",
      "epoch 40; iter: 0; batch classifier loss: 0.373649; batch adversarial loss: 0.586209\n",
      "epoch 40; iter: 200; batch classifier loss: 0.278302; batch adversarial loss: 0.627716\n",
      "epoch 41; iter: 0; batch classifier loss: 0.274338; batch adversarial loss: 0.555748\n",
      "epoch 41; iter: 200; batch classifier loss: 0.341267; batch adversarial loss: 0.610025\n",
      "epoch 42; iter: 0; batch classifier loss: 0.340754; batch adversarial loss: 0.623729\n",
      "epoch 42; iter: 200; batch classifier loss: 0.322334; batch adversarial loss: 0.580802\n",
      "epoch 43; iter: 0; batch classifier loss: 0.297730; batch adversarial loss: 0.644626\n",
      "epoch 43; iter: 200; batch classifier loss: 0.300652; batch adversarial loss: 0.595744\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504966; batch adversarial loss: 0.577899\n",
      "epoch 44; iter: 200; batch classifier loss: 0.325849; batch adversarial loss: 0.680625\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403232; batch adversarial loss: 0.685988\n",
      "epoch 45; iter: 200; batch classifier loss: 0.417727; batch adversarial loss: 0.637405\n",
      "epoch 46; iter: 0; batch classifier loss: 0.363118; batch adversarial loss: 0.629626\n",
      "epoch 46; iter: 200; batch classifier loss: 0.521682; batch adversarial loss: 0.665272\n",
      "epoch 47; iter: 0; batch classifier loss: 0.400526; batch adversarial loss: 0.667419\n",
      "epoch 47; iter: 200; batch classifier loss: 0.408854; batch adversarial loss: 0.588633\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430945; batch adversarial loss: 0.635083\n",
      "epoch 48; iter: 200; batch classifier loss: 0.307091; batch adversarial loss: 0.621699\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377366; batch adversarial loss: 0.644675\n",
      "epoch 49; iter: 200; batch classifier loss: 0.503626; batch adversarial loss: 0.589644\n",
      "epoch 0; iter: 0; batch classifier loss: 34.961304; batch adversarial loss: 0.721561\n",
      "epoch 0; iter: 200; batch classifier loss: 7.510877; batch adversarial loss: 0.797471\n",
      "epoch 1; iter: 0; batch classifier loss: 3.179923; batch adversarial loss: 0.698574\n",
      "epoch 1; iter: 200; batch classifier loss: 10.903620; batch adversarial loss: 0.628540\n",
      "epoch 2; iter: 0; batch classifier loss: 1.170520; batch adversarial loss: 0.652252\n",
      "epoch 2; iter: 200; batch classifier loss: 2.633678; batch adversarial loss: 0.620384\n",
      "epoch 3; iter: 0; batch classifier loss: 12.123381; batch adversarial loss: 0.634780\n",
      "epoch 3; iter: 200; batch classifier loss: 1.631285; batch adversarial loss: 0.673767\n",
      "epoch 4; iter: 0; batch classifier loss: 0.636920; batch adversarial loss: 0.670122\n",
      "epoch 4; iter: 200; batch classifier loss: 1.500878; batch adversarial loss: 0.653837\n",
      "epoch 5; iter: 0; batch classifier loss: 0.864773; batch adversarial loss: 0.643935\n",
      "epoch 5; iter: 200; batch classifier loss: 0.589085; batch adversarial loss: 0.575315\n",
      "epoch 6; iter: 0; batch classifier loss: 0.614792; batch adversarial loss: 0.643827\n",
      "epoch 6; iter: 200; batch classifier loss: 0.346917; batch adversarial loss: 0.609236\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465789; batch adversarial loss: 0.568186\n",
      "epoch 7; iter: 200; batch classifier loss: 0.472715; batch adversarial loss: 0.588428\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466663; batch adversarial loss: 0.568415\n",
      "epoch 8; iter: 200; batch classifier loss: 0.392220; batch adversarial loss: 0.621977\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349978; batch adversarial loss: 0.585123\n",
      "epoch 9; iter: 200; batch classifier loss: 0.460247; batch adversarial loss: 0.600363\n",
      "epoch 10; iter: 0; batch classifier loss: 0.416728; batch adversarial loss: 0.654428\n",
      "epoch 10; iter: 200; batch classifier loss: 1.046271; batch adversarial loss: 0.631655\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560951; batch adversarial loss: 0.669987\n",
      "epoch 11; iter: 200; batch classifier loss: 0.313384; batch adversarial loss: 0.663909\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407591; batch adversarial loss: 0.653110\n",
      "epoch 12; iter: 200; batch classifier loss: 0.337282; batch adversarial loss: 0.633992\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421842; batch adversarial loss: 0.602754\n",
      "epoch 13; iter: 200; batch classifier loss: 0.466194; batch adversarial loss: 0.615295\n",
      "epoch 14; iter: 0; batch classifier loss: 0.271021; batch adversarial loss: 0.670026\n",
      "epoch 14; iter: 200; batch classifier loss: 0.439228; batch adversarial loss: 0.644538\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415941; batch adversarial loss: 0.642418\n",
      "epoch 15; iter: 200; batch classifier loss: 0.389698; batch adversarial loss: 0.550663\n",
      "epoch 16; iter: 0; batch classifier loss: 0.432738; batch adversarial loss: 0.664137\n",
      "epoch 16; iter: 200; batch classifier loss: 0.433624; batch adversarial loss: 0.580537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481734; batch adversarial loss: 0.623484\n",
      "epoch 17; iter: 200; batch classifier loss: 0.285216; batch adversarial loss: 0.620481\n",
      "epoch 18; iter: 0; batch classifier loss: 0.401617; batch adversarial loss: 0.649945\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371514; batch adversarial loss: 0.647436\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468458; batch adversarial loss: 0.652441\n",
      "epoch 19; iter: 200; batch classifier loss: 0.404272; batch adversarial loss: 0.640245\n",
      "epoch 20; iter: 0; batch classifier loss: 0.390231; batch adversarial loss: 0.618594\n",
      "epoch 20; iter: 200; batch classifier loss: 0.390165; batch adversarial loss: 0.616433\n",
      "epoch 21; iter: 0; batch classifier loss: 0.353623; batch adversarial loss: 0.626237\n",
      "epoch 21; iter: 200; batch classifier loss: 0.335478; batch adversarial loss: 0.560623\n",
      "epoch 22; iter: 0; batch classifier loss: 0.383774; batch adversarial loss: 0.642752\n",
      "epoch 22; iter: 200; batch classifier loss: 0.322797; batch adversarial loss: 0.663375\n",
      "epoch 23; iter: 0; batch classifier loss: 0.407300; batch adversarial loss: 0.656067\n",
      "epoch 23; iter: 200; batch classifier loss: 0.365017; batch adversarial loss: 0.615196\n",
      "epoch 24; iter: 0; batch classifier loss: 0.333071; batch adversarial loss: 0.558104\n",
      "epoch 24; iter: 200; batch classifier loss: 0.372320; batch adversarial loss: 0.619646\n",
      "epoch 25; iter: 0; batch classifier loss: 0.337450; batch adversarial loss: 0.626075\n",
      "epoch 25; iter: 200; batch classifier loss: 0.338901; batch adversarial loss: 0.719804\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366892; batch adversarial loss: 0.611356\n",
      "epoch 26; iter: 200; batch classifier loss: 0.362967; batch adversarial loss: 0.588001\n",
      "epoch 27; iter: 0; batch classifier loss: 0.331107; batch adversarial loss: 0.650867\n",
      "epoch 27; iter: 200; batch classifier loss: 0.381339; batch adversarial loss: 0.654770\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362355; batch adversarial loss: 0.647052\n",
      "epoch 28; iter: 200; batch classifier loss: 0.369207; batch adversarial loss: 0.607788\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303997; batch adversarial loss: 0.644074\n",
      "epoch 29; iter: 200; batch classifier loss: 0.452837; batch adversarial loss: 0.612216\n",
      "epoch 30; iter: 0; batch classifier loss: 0.306910; batch adversarial loss: 0.695629\n",
      "epoch 30; iter: 200; batch classifier loss: 0.378191; batch adversarial loss: 0.693628\n",
      "epoch 31; iter: 0; batch classifier loss: 0.322010; batch adversarial loss: 0.668984\n",
      "epoch 31; iter: 200; batch classifier loss: 0.297404; batch adversarial loss: 0.624097\n",
      "epoch 32; iter: 0; batch classifier loss: 0.347910; batch adversarial loss: 0.563318\n",
      "epoch 32; iter: 200; batch classifier loss: 0.400279; batch adversarial loss: 0.562744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.374771; batch adversarial loss: 0.592052\n",
      "epoch 33; iter: 200; batch classifier loss: 0.410199; batch adversarial loss: 0.625184\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390319; batch adversarial loss: 0.613382\n",
      "epoch 34; iter: 200; batch classifier loss: 0.332742; batch adversarial loss: 0.699240\n",
      "epoch 35; iter: 0; batch classifier loss: 0.323710; batch adversarial loss: 0.564919\n",
      "epoch 35; iter: 200; batch classifier loss: 0.349998; batch adversarial loss: 0.624036\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397495; batch adversarial loss: 0.612344\n",
      "epoch 36; iter: 200; batch classifier loss: 0.317040; batch adversarial loss: 0.576272\n",
      "epoch 37; iter: 0; batch classifier loss: 0.481871; batch adversarial loss: 0.571507\n",
      "epoch 37; iter: 200; batch classifier loss: 0.277852; batch adversarial loss: 0.637386\n",
      "epoch 38; iter: 0; batch classifier loss: 0.394638; batch adversarial loss: 0.624574\n",
      "epoch 38; iter: 200; batch classifier loss: 0.430196; batch adversarial loss: 0.674111\n",
      "epoch 39; iter: 0; batch classifier loss: 0.289305; batch adversarial loss: 0.624037\n",
      "epoch 39; iter: 200; batch classifier loss: 0.328349; batch adversarial loss: 0.656913\n",
      "epoch 40; iter: 0; batch classifier loss: 0.312632; batch adversarial loss: 0.602653\n",
      "epoch 40; iter: 200; batch classifier loss: 0.359011; batch adversarial loss: 0.603870\n",
      "epoch 41; iter: 0; batch classifier loss: 0.304444; batch adversarial loss: 0.650967\n",
      "epoch 41; iter: 200; batch classifier loss: 0.318128; batch adversarial loss: 0.626083\n",
      "epoch 42; iter: 0; batch classifier loss: 0.358499; batch adversarial loss: 0.640539\n",
      "epoch 42; iter: 200; batch classifier loss: 0.332079; batch adversarial loss: 0.632796\n",
      "epoch 43; iter: 0; batch classifier loss: 0.370689; batch adversarial loss: 0.615301\n",
      "epoch 43; iter: 200; batch classifier loss: 0.452149; batch adversarial loss: 0.636305\n",
      "epoch 44; iter: 0; batch classifier loss: 0.289202; batch adversarial loss: 0.592369\n",
      "epoch 44; iter: 200; batch classifier loss: 0.299720; batch adversarial loss: 0.633256\n",
      "epoch 45; iter: 0; batch classifier loss: 0.358787; batch adversarial loss: 0.641409\n",
      "epoch 45; iter: 200; batch classifier loss: 0.482443; batch adversarial loss: 0.579723\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483742; batch adversarial loss: 0.668854\n",
      "epoch 46; iter: 200; batch classifier loss: 0.515708; batch adversarial loss: 0.591383\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389685; batch adversarial loss: 0.647859\n",
      "epoch 47; iter: 200; batch classifier loss: 0.394633; batch adversarial loss: 0.596619\n",
      "epoch 48; iter: 0; batch classifier loss: 0.317359; batch adversarial loss: 0.639553\n",
      "epoch 48; iter: 200; batch classifier loss: 0.437089; batch adversarial loss: 0.667364\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383118; batch adversarial loss: 0.600493\n",
      "epoch 49; iter: 200; batch classifier loss: 0.539441; batch adversarial loss: 0.585789\n",
      "epoch 0; iter: 0; batch classifier loss: 35.790146; batch adversarial loss: 0.853315\n",
      "epoch 0; iter: 200; batch classifier loss: 26.760153; batch adversarial loss: 0.754980\n",
      "epoch 1; iter: 0; batch classifier loss: 81.973900; batch adversarial loss: 0.734586\n",
      "epoch 1; iter: 200; batch classifier loss: 4.438937; batch adversarial loss: 0.725472\n",
      "epoch 2; iter: 0; batch classifier loss: 4.156508; batch adversarial loss: 0.674679\n",
      "epoch 2; iter: 200; batch classifier loss: 3.089041; batch adversarial loss: 0.624593\n",
      "epoch 3; iter: 0; batch classifier loss: 11.838340; batch adversarial loss: 0.719243\n",
      "epoch 3; iter: 200; batch classifier loss: 1.941202; batch adversarial loss: 0.629850\n",
      "epoch 4; iter: 0; batch classifier loss: 1.967749; batch adversarial loss: 0.619647\n",
      "epoch 4; iter: 200; batch classifier loss: 0.797183; batch adversarial loss: 0.628514\n",
      "epoch 5; iter: 0; batch classifier loss: 1.604831; batch adversarial loss: 0.621853\n",
      "epoch 5; iter: 200; batch classifier loss: 1.450156; batch adversarial loss: 0.694855\n",
      "epoch 6; iter: 0; batch classifier loss: 12.603737; batch adversarial loss: 0.664606\n",
      "epoch 6; iter: 200; batch classifier loss: 1.440926; batch adversarial loss: 0.649235\n",
      "epoch 7; iter: 0; batch classifier loss: 0.408219; batch adversarial loss: 0.616476\n",
      "epoch 7; iter: 200; batch classifier loss: 0.589582; batch adversarial loss: 0.579544\n",
      "epoch 8; iter: 0; batch classifier loss: 1.006046; batch adversarial loss: 0.618623\n",
      "epoch 8; iter: 200; batch classifier loss: 0.909684; batch adversarial loss: 0.608066\n",
      "epoch 9; iter: 0; batch classifier loss: 0.789736; batch adversarial loss: 0.622711\n",
      "epoch 9; iter: 200; batch classifier loss: 0.773117; batch adversarial loss: 0.624306\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517631; batch adversarial loss: 0.592884\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420895; batch adversarial loss: 0.598791\n",
      "epoch 11; iter: 0; batch classifier loss: 0.442860; batch adversarial loss: 0.602760\n",
      "epoch 11; iter: 200; batch classifier loss: 0.463448; batch adversarial loss: 0.611817\n",
      "epoch 12; iter: 0; batch classifier loss: 0.322818; batch adversarial loss: 0.626406\n",
      "epoch 12; iter: 200; batch classifier loss: 0.938504; batch adversarial loss: 0.630427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372308; batch adversarial loss: 0.610229\n",
      "epoch 13; iter: 200; batch classifier loss: 0.541035; batch adversarial loss: 0.649103\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409469; batch adversarial loss: 0.629245\n",
      "epoch 14; iter: 200; batch classifier loss: 0.362321; batch adversarial loss: 0.658058\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489674; batch adversarial loss: 0.606777\n",
      "epoch 15; iter: 200; batch classifier loss: 0.484052; batch adversarial loss: 0.611444\n",
      "epoch 16; iter: 0; batch classifier loss: 0.390005; batch adversarial loss: 0.663993\n",
      "epoch 16; iter: 200; batch classifier loss: 0.367627; batch adversarial loss: 0.574979\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383665; batch adversarial loss: 0.618114\n",
      "epoch 17; iter: 200; batch classifier loss: 0.407296; batch adversarial loss: 0.614338\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454284; batch adversarial loss: 0.562039\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371442; batch adversarial loss: 0.646895\n",
      "epoch 19; iter: 0; batch classifier loss: 0.342871; batch adversarial loss: 0.627714\n",
      "epoch 19; iter: 200; batch classifier loss: 0.470753; batch adversarial loss: 0.589858\n",
      "epoch 20; iter: 0; batch classifier loss: 0.370156; batch adversarial loss: 0.599274\n",
      "epoch 20; iter: 200; batch classifier loss: 0.364100; batch adversarial loss: 0.637389\n",
      "epoch 21; iter: 0; batch classifier loss: 0.357321; batch adversarial loss: 0.642979\n",
      "epoch 21; iter: 200; batch classifier loss: 0.319562; batch adversarial loss: 0.628538\n",
      "epoch 22; iter: 0; batch classifier loss: 0.347051; batch adversarial loss: 0.588597\n",
      "epoch 22; iter: 200; batch classifier loss: 0.349653; batch adversarial loss: 0.588526\n",
      "epoch 23; iter: 0; batch classifier loss: 0.757575; batch adversarial loss: 0.644226\n",
      "epoch 23; iter: 200; batch classifier loss: 0.342124; batch adversarial loss: 0.614277\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364774; batch adversarial loss: 0.677775\n",
      "epoch 24; iter: 200; batch classifier loss: 0.313805; batch adversarial loss: 0.566121\n",
      "epoch 25; iter: 0; batch classifier loss: 0.319600; batch adversarial loss: 0.641145\n",
      "epoch 25; iter: 200; batch classifier loss: 0.366797; batch adversarial loss: 0.642254\n",
      "epoch 26; iter: 0; batch classifier loss: 0.320447; batch adversarial loss: 0.598399\n",
      "epoch 26; iter: 200; batch classifier loss: 0.331324; batch adversarial loss: 0.601953\n",
      "epoch 27; iter: 0; batch classifier loss: 0.339143; batch adversarial loss: 0.609191\n",
      "epoch 27; iter: 200; batch classifier loss: 0.322137; batch adversarial loss: 0.634242\n",
      "epoch 28; iter: 0; batch classifier loss: 0.384192; batch adversarial loss: 0.589616\n",
      "epoch 28; iter: 200; batch classifier loss: 0.408945; batch adversarial loss: 0.602171\n",
      "epoch 29; iter: 0; batch classifier loss: 0.364777; batch adversarial loss: 0.616979\n",
      "epoch 29; iter: 200; batch classifier loss: 0.352423; batch adversarial loss: 0.587391\n",
      "epoch 30; iter: 0; batch classifier loss: 0.343864; batch adversarial loss: 0.632910\n",
      "epoch 30; iter: 200; batch classifier loss: 0.321761; batch adversarial loss: 0.669729\n",
      "epoch 31; iter: 0; batch classifier loss: 0.370690; batch adversarial loss: 0.681666\n",
      "epoch 31; iter: 200; batch classifier loss: 0.297463; batch adversarial loss: 0.657225\n",
      "epoch 32; iter: 0; batch classifier loss: 0.305147; batch adversarial loss: 0.677635\n",
      "epoch 32; iter: 200; batch classifier loss: 0.476663; batch adversarial loss: 0.650473\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424265; batch adversarial loss: 0.625573\n",
      "epoch 33; iter: 200; batch classifier loss: 0.462478; batch adversarial loss: 0.581935\n",
      "epoch 34; iter: 0; batch classifier loss: 0.388457; batch adversarial loss: 0.677339\n",
      "epoch 34; iter: 200; batch classifier loss: 0.394675; batch adversarial loss: 0.594245\n",
      "epoch 35; iter: 0; batch classifier loss: 0.365911; batch adversarial loss: 0.639506\n",
      "epoch 35; iter: 200; batch classifier loss: 0.450216; batch adversarial loss: 0.626297\n",
      "epoch 36; iter: 0; batch classifier loss: 0.288350; batch adversarial loss: 0.687362\n",
      "epoch 36; iter: 200; batch classifier loss: 0.407239; batch adversarial loss: 0.590655\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495560; batch adversarial loss: 0.621015\n",
      "epoch 37; iter: 200; batch classifier loss: 0.346272; batch adversarial loss: 0.567135\n",
      "epoch 38; iter: 0; batch classifier loss: 0.345427; batch adversarial loss: 0.619652\n",
      "epoch 38; iter: 200; batch classifier loss: 0.387268; batch adversarial loss: 0.659823\n",
      "epoch 39; iter: 0; batch classifier loss: 0.328295; batch adversarial loss: 0.595032\n",
      "epoch 39; iter: 200; batch classifier loss: 0.314337; batch adversarial loss: 0.667036\n",
      "epoch 40; iter: 0; batch classifier loss: 0.317246; batch adversarial loss: 0.655750\n",
      "epoch 40; iter: 200; batch classifier loss: 0.359237; batch adversarial loss: 0.635668\n",
      "epoch 41; iter: 0; batch classifier loss: 0.447309; batch adversarial loss: 0.665562\n",
      "epoch 41; iter: 200; batch classifier loss: 0.283796; batch adversarial loss: 0.618089\n",
      "epoch 42; iter: 0; batch classifier loss: 0.336974; batch adversarial loss: 0.646710\n",
      "epoch 42; iter: 200; batch classifier loss: 0.336992; batch adversarial loss: 0.679636\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362645; batch adversarial loss: 0.654977\n",
      "epoch 43; iter: 200; batch classifier loss: 0.337751; batch adversarial loss: 0.644850\n",
      "epoch 44; iter: 0; batch classifier loss: 0.316530; batch adversarial loss: 0.576587\n",
      "epoch 44; iter: 200; batch classifier loss: 0.339142; batch adversarial loss: 0.612422\n",
      "epoch 45; iter: 0; batch classifier loss: 0.288309; batch adversarial loss: 0.642640\n",
      "epoch 45; iter: 200; batch classifier loss: 0.348723; batch adversarial loss: 0.610457\n",
      "epoch 46; iter: 0; batch classifier loss: 0.274136; batch adversarial loss: 0.623556\n",
      "epoch 46; iter: 200; batch classifier loss: 0.435660; batch adversarial loss: 0.668213\n",
      "epoch 47; iter: 0; batch classifier loss: 0.390412; batch adversarial loss: 0.601030\n",
      "epoch 47; iter: 200; batch classifier loss: 0.257986; batch adversarial loss: 0.636660\n",
      "epoch 48; iter: 0; batch classifier loss: 0.499049; batch adversarial loss: 0.643839\n",
      "epoch 48; iter: 200; batch classifier loss: 0.301037; batch adversarial loss: 0.644261\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421570; batch adversarial loss: 0.612312\n",
      "epoch 49; iter: 200; batch classifier loss: 0.360664; batch adversarial loss: 0.595884\n",
      "epoch 0; iter: 0; batch classifier loss: 25.201664; batch adversarial loss: 0.640789\n",
      "epoch 0; iter: 200; batch classifier loss: 7.017321; batch adversarial loss: 0.649977\n",
      "epoch 1; iter: 0; batch classifier loss: 4.968934; batch adversarial loss: 0.656464\n",
      "epoch 1; iter: 200; batch classifier loss: 4.192914; batch adversarial loss: 0.634180\n",
      "epoch 2; iter: 0; batch classifier loss: 4.200525; batch adversarial loss: 0.649339\n",
      "epoch 2; iter: 200; batch classifier loss: 1.029223; batch adversarial loss: 0.609614\n",
      "epoch 3; iter: 0; batch classifier loss: 1.171189; batch adversarial loss: 0.621756\n",
      "epoch 3; iter: 200; batch classifier loss: 1.341661; batch adversarial loss: 0.609199\n",
      "epoch 4; iter: 0; batch classifier loss: 1.277003; batch adversarial loss: 0.610317\n",
      "epoch 4; iter: 200; batch classifier loss: 0.376909; batch adversarial loss: 0.672179\n",
      "epoch 5; iter: 0; batch classifier loss: 0.645123; batch adversarial loss: 0.576376\n",
      "epoch 5; iter: 200; batch classifier loss: 1.397320; batch adversarial loss: 0.705228\n",
      "epoch 6; iter: 0; batch classifier loss: 0.786267; batch adversarial loss: 0.677220\n",
      "epoch 6; iter: 200; batch classifier loss: 0.499208; batch adversarial loss: 0.592752\n",
      "epoch 7; iter: 0; batch classifier loss: 0.752134; batch adversarial loss: 0.611002\n",
      "epoch 7; iter: 200; batch classifier loss: 0.708671; batch adversarial loss: 0.634327\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585482; batch adversarial loss: 0.673182\n",
      "epoch 8; iter: 200; batch classifier loss: 0.439809; batch adversarial loss: 0.601281\n",
      "epoch 9; iter: 0; batch classifier loss: 0.622001; batch adversarial loss: 0.597316\n",
      "epoch 9; iter: 200; batch classifier loss: 0.477431; batch adversarial loss: 0.634624\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413869; batch adversarial loss: 0.636842\n",
      "epoch 10; iter: 200; batch classifier loss: 0.544294; batch adversarial loss: 0.647046\n",
      "epoch 11; iter: 0; batch classifier loss: 0.317558; batch adversarial loss: 0.583768\n",
      "epoch 11; iter: 200; batch classifier loss: 0.483500; batch adversarial loss: 0.627842\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531913; batch adversarial loss: 0.566700\n",
      "epoch 12; iter: 200; batch classifier loss: 0.456615; batch adversarial loss: 0.645339\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394664; batch adversarial loss: 0.644312\n",
      "epoch 13; iter: 200; batch classifier loss: 0.433380; batch adversarial loss: 0.603907\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412425; batch adversarial loss: 0.616762\n",
      "epoch 14; iter: 200; batch classifier loss: 0.291800; batch adversarial loss: 0.642207\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405875; batch adversarial loss: 0.613518\n",
      "epoch 15; iter: 200; batch classifier loss: 0.438647; batch adversarial loss: 0.593856\n",
      "epoch 16; iter: 0; batch classifier loss: 0.399043; batch adversarial loss: 0.667238\n",
      "epoch 16; iter: 200; batch classifier loss: 0.365918; batch adversarial loss: 0.617658\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494273; batch adversarial loss: 0.595477\n",
      "epoch 17; iter: 200; batch classifier loss: 0.417915; batch adversarial loss: 0.634160\n",
      "epoch 18; iter: 0; batch classifier loss: 0.315996; batch adversarial loss: 0.671935\n",
      "epoch 18; iter: 200; batch classifier loss: 0.386179; batch adversarial loss: 0.609074\n",
      "epoch 19; iter: 0; batch classifier loss: 0.407976; batch adversarial loss: 0.650998\n",
      "epoch 19; iter: 200; batch classifier loss: 0.419778; batch adversarial loss: 0.624398\n",
      "epoch 20; iter: 0; batch classifier loss: 0.318857; batch adversarial loss: 0.658371\n",
      "epoch 20; iter: 200; batch classifier loss: 0.418488; batch adversarial loss: 0.685115\n",
      "epoch 21; iter: 0; batch classifier loss: 0.408352; batch adversarial loss: 0.628959\n",
      "epoch 21; iter: 200; batch classifier loss: 0.346343; batch adversarial loss: 0.594706\n",
      "epoch 22; iter: 0; batch classifier loss: 0.326738; batch adversarial loss: 0.694300\n",
      "epoch 22; iter: 200; batch classifier loss: 0.339409; batch adversarial loss: 0.619964\n",
      "epoch 23; iter: 0; batch classifier loss: 0.409115; batch adversarial loss: 0.561309\n",
      "epoch 23; iter: 200; batch classifier loss: 0.337605; batch adversarial loss: 0.645091\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387466; batch adversarial loss: 0.644426\n",
      "epoch 24; iter: 200; batch classifier loss: 0.369286; batch adversarial loss: 0.632722\n",
      "epoch 25; iter: 0; batch classifier loss: 0.213231; batch adversarial loss: 0.682058\n",
      "epoch 25; iter: 200; batch classifier loss: 0.355932; batch adversarial loss: 0.704753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.314427; batch adversarial loss: 0.618494\n",
      "epoch 26; iter: 200; batch classifier loss: 0.385333; batch adversarial loss: 0.579778\n",
      "epoch 27; iter: 0; batch classifier loss: 0.431420; batch adversarial loss: 0.619746\n",
      "epoch 27; iter: 200; batch classifier loss: 0.631748; batch adversarial loss: 0.621313\n",
      "epoch 28; iter: 0; batch classifier loss: 0.310686; batch adversarial loss: 0.686908\n",
      "epoch 28; iter: 200; batch classifier loss: 0.374259; batch adversarial loss: 0.620917\n",
      "epoch 29; iter: 0; batch classifier loss: 0.341164; batch adversarial loss: 0.672561\n",
      "epoch 29; iter: 200; batch classifier loss: 0.243818; batch adversarial loss: 0.663055\n",
      "epoch 30; iter: 0; batch classifier loss: 0.308087; batch adversarial loss: 0.604083\n",
      "epoch 30; iter: 200; batch classifier loss: 0.380011; batch adversarial loss: 0.649368\n",
      "epoch 31; iter: 0; batch classifier loss: 0.357004; batch adversarial loss: 0.587754\n",
      "epoch 31; iter: 200; batch classifier loss: 0.327622; batch adversarial loss: 0.658705\n",
      "epoch 32; iter: 0; batch classifier loss: 0.366017; batch adversarial loss: 0.619384\n",
      "epoch 32; iter: 200; batch classifier loss: 0.341445; batch adversarial loss: 0.627880\n",
      "epoch 33; iter: 0; batch classifier loss: 0.381006; batch adversarial loss: 0.637811\n",
      "epoch 33; iter: 200; batch classifier loss: 0.318491; batch adversarial loss: 0.608359\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276219; batch adversarial loss: 0.633956\n",
      "epoch 34; iter: 200; batch classifier loss: 0.405546; batch adversarial loss: 0.611334\n",
      "epoch 35; iter: 0; batch classifier loss: 0.294660; batch adversarial loss: 0.616257\n",
      "epoch 35; iter: 200; batch classifier loss: 0.405031; batch adversarial loss: 0.628684\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420793; batch adversarial loss: 0.625214\n",
      "epoch 36; iter: 200; batch classifier loss: 0.424796; batch adversarial loss: 0.636082\n",
      "epoch 37; iter: 0; batch classifier loss: 0.479633; batch adversarial loss: 0.634304\n",
      "epoch 37; iter: 200; batch classifier loss: 0.324046; batch adversarial loss: 0.630383\n",
      "epoch 38; iter: 0; batch classifier loss: 0.375063; batch adversarial loss: 0.588743\n",
      "epoch 38; iter: 200; batch classifier loss: 0.349744; batch adversarial loss: 0.587781\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433170; batch adversarial loss: 0.626098\n",
      "epoch 39; iter: 200; batch classifier loss: 0.589585; batch adversarial loss: 0.594711\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381118; batch adversarial loss: 0.579962\n",
      "epoch 40; iter: 200; batch classifier loss: 0.472430; batch adversarial loss: 0.600175\n",
      "epoch 41; iter: 0; batch classifier loss: 0.299231; batch adversarial loss: 0.630475\n",
      "epoch 41; iter: 200; batch classifier loss: 0.318556; batch adversarial loss: 0.624753\n",
      "epoch 42; iter: 0; batch classifier loss: 0.307399; batch adversarial loss: 0.586011\n",
      "epoch 42; iter: 200; batch classifier loss: 0.404587; batch adversarial loss: 0.611072\n",
      "epoch 43; iter: 0; batch classifier loss: 0.266164; batch adversarial loss: 0.627590\n",
      "epoch 43; iter: 200; batch classifier loss: 0.298257; batch adversarial loss: 0.655468\n",
      "epoch 44; iter: 0; batch classifier loss: 0.359556; batch adversarial loss: 0.601420\n",
      "epoch 44; iter: 200; batch classifier loss: 0.335597; batch adversarial loss: 0.670555\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376594; batch adversarial loss: 0.670497\n",
      "epoch 45; iter: 200; batch classifier loss: 0.486617; batch adversarial loss: 0.674407\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465641; batch adversarial loss: 0.598876\n",
      "epoch 46; iter: 200; batch classifier loss: 0.361702; batch adversarial loss: 0.642431\n",
      "epoch 47; iter: 0; batch classifier loss: 0.344249; batch adversarial loss: 0.603635\n",
      "epoch 47; iter: 200; batch classifier loss: 0.457077; batch adversarial loss: 0.595369\n",
      "epoch 48; iter: 0; batch classifier loss: 0.287701; batch adversarial loss: 0.638317\n",
      "epoch 48; iter: 200; batch classifier loss: 0.231352; batch adversarial loss: 0.678741\n",
      "epoch 49; iter: 0; batch classifier loss: 0.443410; batch adversarial loss: 0.619512\n",
      "epoch 49; iter: 200; batch classifier loss: 0.387429; batch adversarial loss: 0.661996\n",
      "epoch 0; iter: 0; batch classifier loss: 82.033058; batch adversarial loss: 0.741575\n",
      "epoch 0; iter: 200; batch classifier loss: 35.443024; batch adversarial loss: 0.674679\n",
      "epoch 1; iter: 0; batch classifier loss: 6.725743; batch adversarial loss: 0.653326\n",
      "epoch 1; iter: 200; batch classifier loss: 5.043005; batch adversarial loss: 0.627038\n",
      "epoch 2; iter: 0; batch classifier loss: 7.755160; batch adversarial loss: 0.636090\n",
      "epoch 2; iter: 200; batch classifier loss: 9.692677; batch adversarial loss: 0.606341\n",
      "epoch 3; iter: 0; batch classifier loss: 2.433604; batch adversarial loss: 0.635466\n",
      "epoch 3; iter: 200; batch classifier loss: 3.642392; batch adversarial loss: 0.657003\n",
      "epoch 4; iter: 0; batch classifier loss: 1.595336; batch adversarial loss: 0.686883\n",
      "epoch 4; iter: 200; batch classifier loss: 1.852201; batch adversarial loss: 0.597784\n",
      "epoch 5; iter: 0; batch classifier loss: 3.725802; batch adversarial loss: 0.600736\n",
      "epoch 5; iter: 200; batch classifier loss: 0.460550; batch adversarial loss: 0.590823\n",
      "epoch 6; iter: 0; batch classifier loss: 5.508015; batch adversarial loss: 0.643402\n",
      "epoch 6; iter: 200; batch classifier loss: 0.759775; batch adversarial loss: 0.621855\n",
      "epoch 7; iter: 0; batch classifier loss: 1.484603; batch adversarial loss: 0.659288\n",
      "epoch 7; iter: 200; batch classifier loss: 0.966576; batch adversarial loss: 0.641994\n",
      "epoch 8; iter: 0; batch classifier loss: 0.973556; batch adversarial loss: 0.618318\n",
      "epoch 8; iter: 200; batch classifier loss: 0.434666; batch adversarial loss: 0.667284\n",
      "epoch 9; iter: 0; batch classifier loss: 0.846042; batch adversarial loss: 0.599673\n",
      "epoch 9; iter: 200; batch classifier loss: 1.105308; batch adversarial loss: 0.621917\n",
      "epoch 10; iter: 0; batch classifier loss: 0.713643; batch adversarial loss: 0.658722\n",
      "epoch 10; iter: 200; batch classifier loss: 0.452104; batch adversarial loss: 0.615984\n",
      "epoch 11; iter: 0; batch classifier loss: 0.458299; batch adversarial loss: 0.598294\n",
      "epoch 11; iter: 200; batch classifier loss: 0.512399; batch adversarial loss: 0.653982\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495117; batch adversarial loss: 0.684184\n",
      "epoch 12; iter: 200; batch classifier loss: 0.503024; batch adversarial loss: 0.615515\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522841; batch adversarial loss: 0.631128\n",
      "epoch 13; iter: 200; batch classifier loss: 0.406915; batch adversarial loss: 0.622425\n",
      "epoch 14; iter: 0; batch classifier loss: 0.421055; batch adversarial loss: 0.637681\n",
      "epoch 14; iter: 200; batch classifier loss: 0.370116; batch adversarial loss: 0.656952\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409449; batch adversarial loss: 0.668416\n",
      "epoch 15; iter: 200; batch classifier loss: 0.373408; batch adversarial loss: 0.548690\n",
      "epoch 16; iter: 0; batch classifier loss: 0.386409; batch adversarial loss: 0.675575\n",
      "epoch 16; iter: 200; batch classifier loss: 0.328225; batch adversarial loss: 0.620023\n",
      "epoch 17; iter: 0; batch classifier loss: 0.422074; batch adversarial loss: 0.571436\n",
      "epoch 17; iter: 200; batch classifier loss: 0.322262; batch adversarial loss: 0.631523\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359924; batch adversarial loss: 0.650870\n",
      "epoch 18; iter: 200; batch classifier loss: 0.498948; batch adversarial loss: 0.580086\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301657; batch adversarial loss: 0.633396\n",
      "epoch 19; iter: 200; batch classifier loss: 0.589388; batch adversarial loss: 0.645236\n",
      "epoch 20; iter: 0; batch classifier loss: 0.348415; batch adversarial loss: 0.597112\n",
      "epoch 20; iter: 200; batch classifier loss: 0.305897; batch adversarial loss: 0.671574\n",
      "epoch 21; iter: 0; batch classifier loss: 0.361765; batch adversarial loss: 0.615260\n",
      "epoch 21; iter: 200; batch classifier loss: 0.357433; batch adversarial loss: 0.632698\n",
      "epoch 22; iter: 0; batch classifier loss: 0.338754; batch adversarial loss: 0.599177\n",
      "epoch 22; iter: 200; batch classifier loss: 0.392772; batch adversarial loss: 0.542563\n",
      "epoch 23; iter: 0; batch classifier loss: 0.397759; batch adversarial loss: 0.576136\n",
      "epoch 23; iter: 200; batch classifier loss: 0.288160; batch adversarial loss: 0.602333\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307933; batch adversarial loss: 0.686226\n",
      "epoch 24; iter: 200; batch classifier loss: 0.306899; batch adversarial loss: 0.575159\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396944; batch adversarial loss: 0.640665\n",
      "epoch 25; iter: 200; batch classifier loss: 0.671601; batch adversarial loss: 0.616241\n",
      "epoch 26; iter: 0; batch classifier loss: 0.300157; batch adversarial loss: 0.687099\n",
      "epoch 26; iter: 200; batch classifier loss: 0.287283; batch adversarial loss: 0.644695\n",
      "epoch 27; iter: 0; batch classifier loss: 0.346866; batch adversarial loss: 0.591170\n",
      "epoch 27; iter: 200; batch classifier loss: 0.230608; batch adversarial loss: 0.622624\n",
      "epoch 28; iter: 0; batch classifier loss: 0.332088; batch adversarial loss: 0.584684\n",
      "epoch 28; iter: 200; batch classifier loss: 0.391284; batch adversarial loss: 0.619698\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447949; batch adversarial loss: 0.617799\n",
      "epoch 29; iter: 200; batch classifier loss: 0.274613; batch adversarial loss: 0.666349\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422780; batch adversarial loss: 0.607118\n",
      "epoch 30; iter: 200; batch classifier loss: 0.270466; batch adversarial loss: 0.595369\n",
      "epoch 31; iter: 0; batch classifier loss: 0.303949; batch adversarial loss: 0.673536\n",
      "epoch 31; iter: 200; batch classifier loss: 0.405667; batch adversarial loss: 0.623694\n",
      "epoch 32; iter: 0; batch classifier loss: 0.341266; batch adversarial loss: 0.662970\n",
      "epoch 32; iter: 200; batch classifier loss: 0.359109; batch adversarial loss: 0.620810\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344476; batch adversarial loss: 0.649062\n",
      "epoch 33; iter: 200; batch classifier loss: 0.466487; batch adversarial loss: 0.668386\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418500; batch adversarial loss: 0.601565\n",
      "epoch 34; iter: 200; batch classifier loss: 0.252867; batch adversarial loss: 0.626566\n",
      "epoch 35; iter: 0; batch classifier loss: 0.333347; batch adversarial loss: 0.550660\n",
      "epoch 35; iter: 200; batch classifier loss: 0.411272; batch adversarial loss: 0.594520\n",
      "epoch 36; iter: 0; batch classifier loss: 0.285893; batch adversarial loss: 0.599341\n",
      "epoch 36; iter: 200; batch classifier loss: 0.719286; batch adversarial loss: 0.598887\n",
      "epoch 37; iter: 0; batch classifier loss: 0.493891; batch adversarial loss: 0.601663\n",
      "epoch 37; iter: 200; batch classifier loss: 0.359919; batch adversarial loss: 0.591537\n",
      "epoch 38; iter: 0; batch classifier loss: 0.341689; batch adversarial loss: 0.601671\n",
      "epoch 38; iter: 200; batch classifier loss: 0.391158; batch adversarial loss: 0.630685\n",
      "epoch 39; iter: 0; batch classifier loss: 0.327660; batch adversarial loss: 0.644286\n",
      "epoch 39; iter: 200; batch classifier loss: 0.514547; batch adversarial loss: 0.571376\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361448; batch adversarial loss: 0.601813\n",
      "epoch 40; iter: 200; batch classifier loss: 0.353332; batch adversarial loss: 0.637259\n",
      "epoch 41; iter: 0; batch classifier loss: 0.304907; batch adversarial loss: 0.629465\n",
      "epoch 41; iter: 200; batch classifier loss: 0.377655; batch adversarial loss: 0.576542\n",
      "epoch 42; iter: 0; batch classifier loss: 0.341173; batch adversarial loss: 0.667665\n",
      "epoch 42; iter: 200; batch classifier loss: 0.325712; batch adversarial loss: 0.615964\n",
      "epoch 43; iter: 0; batch classifier loss: 0.340920; batch adversarial loss: 0.598775\n",
      "epoch 43; iter: 200; batch classifier loss: 0.350054; batch adversarial loss: 0.639826\n",
      "epoch 44; iter: 0; batch classifier loss: 0.325747; batch adversarial loss: 0.631598\n",
      "epoch 44; iter: 200; batch classifier loss: 0.374136; batch adversarial loss: 0.597051\n",
      "epoch 45; iter: 0; batch classifier loss: 0.369862; batch adversarial loss: 0.623941\n",
      "epoch 45; iter: 200; batch classifier loss: 0.336977; batch adversarial loss: 0.599311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.321794; batch adversarial loss: 0.592917\n",
      "epoch 46; iter: 200; batch classifier loss: 0.457273; batch adversarial loss: 0.626224\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350281; batch adversarial loss: 0.669690\n",
      "epoch 47; iter: 200; batch classifier loss: 0.413470; batch adversarial loss: 0.685609\n",
      "epoch 48; iter: 0; batch classifier loss: 0.338169; batch adversarial loss: 0.620275\n",
      "epoch 48; iter: 200; batch classifier loss: 0.370108; batch adversarial loss: 0.632470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.338412; batch adversarial loss: 0.600121\n",
      "epoch 49; iter: 200; batch classifier loss: 0.460103; batch adversarial loss: 0.612923\n",
      "epoch 0; iter: 0; batch classifier loss: 269.750458; batch adversarial loss: 0.691075\n",
      "epoch 0; iter: 200; batch classifier loss: 14.388734; batch adversarial loss: 0.661394\n",
      "epoch 1; iter: 0; batch classifier loss: 7.807670; batch adversarial loss: 0.676121\n",
      "epoch 1; iter: 200; batch classifier loss: 3.073295; batch adversarial loss: 0.601871\n",
      "epoch 2; iter: 0; batch classifier loss: 6.780832; batch adversarial loss: 0.630526\n",
      "epoch 2; iter: 200; batch classifier loss: 4.840034; batch adversarial loss: 0.613775\n",
      "epoch 3; iter: 0; batch classifier loss: 1.172299; batch adversarial loss: 0.626518\n",
      "epoch 3; iter: 200; batch classifier loss: 3.258627; batch adversarial loss: 0.652839\n",
      "epoch 4; iter: 0; batch classifier loss: 2.972233; batch adversarial loss: 0.631150\n",
      "epoch 4; iter: 200; batch classifier loss: 0.658853; batch adversarial loss: 0.631159\n",
      "epoch 5; iter: 0; batch classifier loss: 0.902963; batch adversarial loss: 0.643354\n",
      "epoch 5; iter: 200; batch classifier loss: 1.469147; batch adversarial loss: 0.617634\n",
      "epoch 6; iter: 0; batch classifier loss: 1.750557; batch adversarial loss: 0.668889\n",
      "epoch 6; iter: 200; batch classifier loss: 2.117166; batch adversarial loss: 0.603115\n",
      "epoch 7; iter: 0; batch classifier loss: 0.742983; batch adversarial loss: 0.645591\n",
      "epoch 7; iter: 200; batch classifier loss: 0.683265; batch adversarial loss: 0.624689\n",
      "epoch 8; iter: 0; batch classifier loss: 0.709830; batch adversarial loss: 0.626280\n",
      "epoch 8; iter: 200; batch classifier loss: 0.489842; batch adversarial loss: 0.599348\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418926; batch adversarial loss: 0.608244\n",
      "epoch 9; iter: 200; batch classifier loss: 0.341461; batch adversarial loss: 0.648167\n",
      "epoch 10; iter: 0; batch classifier loss: 0.597443; batch adversarial loss: 0.644925\n",
      "epoch 10; iter: 200; batch classifier loss: 0.554025; batch adversarial loss: 0.626668\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505853; batch adversarial loss: 0.664837\n",
      "epoch 11; iter: 200; batch classifier loss: 0.423772; batch adversarial loss: 0.597225\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504025; batch adversarial loss: 0.626400\n",
      "epoch 12; iter: 200; batch classifier loss: 0.513621; batch adversarial loss: 0.606246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.595749; batch adversarial loss: 0.629286\n",
      "epoch 13; iter: 200; batch classifier loss: 0.553258; batch adversarial loss: 0.602674\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461785; batch adversarial loss: 0.623859\n",
      "epoch 14; iter: 200; batch classifier loss: 0.449799; batch adversarial loss: 0.611513\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334693; batch adversarial loss: 0.656021\n",
      "epoch 15; iter: 200; batch classifier loss: 0.359264; batch adversarial loss: 0.558481\n",
      "epoch 16; iter: 0; batch classifier loss: 0.436312; batch adversarial loss: 0.602551\n",
      "epoch 16; iter: 200; batch classifier loss: 0.373327; batch adversarial loss: 0.568620\n",
      "epoch 17; iter: 0; batch classifier loss: 0.534150; batch adversarial loss: 0.633962\n",
      "epoch 17; iter: 200; batch classifier loss: 0.323399; batch adversarial loss: 0.607277\n",
      "epoch 18; iter: 0; batch classifier loss: 0.307717; batch adversarial loss: 0.654045\n",
      "epoch 18; iter: 200; batch classifier loss: 0.324446; batch adversarial loss: 0.603016\n",
      "epoch 19; iter: 0; batch classifier loss: 0.449710; batch adversarial loss: 0.607796\n",
      "epoch 19; iter: 200; batch classifier loss: 0.379171; batch adversarial loss: 0.636716\n",
      "epoch 20; iter: 0; batch classifier loss: 0.301465; batch adversarial loss: 0.685961\n",
      "epoch 20; iter: 200; batch classifier loss: 0.460400; batch adversarial loss: 0.630350\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280373; batch adversarial loss: 0.610161\n",
      "epoch 21; iter: 200; batch classifier loss: 0.417731; batch adversarial loss: 0.655610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372394; batch adversarial loss: 0.655013\n",
      "epoch 22; iter: 200; batch classifier loss: 0.368843; batch adversarial loss: 0.625440\n",
      "epoch 23; iter: 0; batch classifier loss: 0.331978; batch adversarial loss: 0.676968\n",
      "epoch 23; iter: 200; batch classifier loss: 0.510586; batch adversarial loss: 0.568339\n",
      "epoch 24; iter: 0; batch classifier loss: 0.320291; batch adversarial loss: 0.653537\n",
      "epoch 24; iter: 200; batch classifier loss: 0.279980; batch adversarial loss: 0.605958\n",
      "epoch 25; iter: 0; batch classifier loss: 0.260156; batch adversarial loss: 0.599397\n",
      "epoch 25; iter: 200; batch classifier loss: 0.393835; batch adversarial loss: 0.656015\n",
      "epoch 26; iter: 0; batch classifier loss: 0.323564; batch adversarial loss: 0.615068\n",
      "epoch 26; iter: 200; batch classifier loss: 0.350626; batch adversarial loss: 0.639421\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391664; batch adversarial loss: 0.646102\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310579; batch adversarial loss: 0.612800\n",
      "epoch 28; iter: 0; batch classifier loss: 0.394694; batch adversarial loss: 0.626795\n",
      "epoch 28; iter: 200; batch classifier loss: 0.395095; batch adversarial loss: 0.614393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.356974; batch adversarial loss: 0.527928\n",
      "epoch 29; iter: 200; batch classifier loss: 0.405888; batch adversarial loss: 0.587948\n",
      "epoch 30; iter: 0; batch classifier loss: 0.345688; batch adversarial loss: 0.662834\n",
      "epoch 30; iter: 200; batch classifier loss: 0.332766; batch adversarial loss: 0.644369\n",
      "epoch 31; iter: 0; batch classifier loss: 0.372646; batch adversarial loss: 0.670500\n",
      "epoch 31; iter: 200; batch classifier loss: 0.399785; batch adversarial loss: 0.687523\n",
      "epoch 32; iter: 0; batch classifier loss: 0.655223; batch adversarial loss: 0.637225\n",
      "epoch 32; iter: 200; batch classifier loss: 0.373642; batch adversarial loss: 0.541807\n",
      "epoch 33; iter: 0; batch classifier loss: 0.292727; batch adversarial loss: 0.615124\n",
      "epoch 33; iter: 200; batch classifier loss: 0.343677; batch adversarial loss: 0.638828\n",
      "epoch 34; iter: 0; batch classifier loss: 0.244243; batch adversarial loss: 0.621946\n",
      "epoch 34; iter: 200; batch classifier loss: 0.336866; batch adversarial loss: 0.719862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.316695; batch adversarial loss: 0.602943\n",
      "epoch 35; iter: 200; batch classifier loss: 0.421803; batch adversarial loss: 0.665287\n",
      "epoch 36; iter: 0; batch classifier loss: 0.332954; batch adversarial loss: 0.597005\n",
      "epoch 36; iter: 200; batch classifier loss: 0.310324; batch adversarial loss: 0.693483\n",
      "epoch 37; iter: 0; batch classifier loss: 0.295274; batch adversarial loss: 0.629958\n",
      "epoch 37; iter: 200; batch classifier loss: 0.340382; batch adversarial loss: 0.619639\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373389; batch adversarial loss: 0.626495\n",
      "epoch 38; iter: 200; batch classifier loss: 0.412280; batch adversarial loss: 0.644555\n",
      "epoch 39; iter: 0; batch classifier loss: 0.340822; batch adversarial loss: 0.661582\n",
      "epoch 39; iter: 200; batch classifier loss: 0.367819; batch adversarial loss: 0.596600\n",
      "epoch 40; iter: 0; batch classifier loss: 0.375831; batch adversarial loss: 0.711180\n",
      "epoch 40; iter: 200; batch classifier loss: 0.398807; batch adversarial loss: 0.674131\n",
      "epoch 41; iter: 0; batch classifier loss: 0.375461; batch adversarial loss: 0.647998\n",
      "epoch 41; iter: 200; batch classifier loss: 0.336695; batch adversarial loss: 0.584713\n",
      "epoch 42; iter: 0; batch classifier loss: 0.342792; batch adversarial loss: 0.620171\n",
      "epoch 42; iter: 200; batch classifier loss: 0.290119; batch adversarial loss: 0.593935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395638; batch adversarial loss: 0.604432\n",
      "epoch 43; iter: 200; batch classifier loss: 0.294274; batch adversarial loss: 0.610424\n",
      "epoch 44; iter: 0; batch classifier loss: 0.320650; batch adversarial loss: 0.640676\n",
      "epoch 44; iter: 200; batch classifier loss: 0.466106; batch adversarial loss: 0.569726\n",
      "epoch 45; iter: 0; batch classifier loss: 0.347650; batch adversarial loss: 0.663314\n",
      "epoch 45; iter: 200; batch classifier loss: 0.345477; batch adversarial loss: 0.707958\n",
      "epoch 46; iter: 0; batch classifier loss: 0.373118; batch adversarial loss: 0.643901\n",
      "epoch 46; iter: 200; batch classifier loss: 0.508297; batch adversarial loss: 0.621715\n",
      "epoch 47; iter: 0; batch classifier loss: 0.395737; batch adversarial loss: 0.661004\n",
      "epoch 47; iter: 200; batch classifier loss: 0.409475; batch adversarial loss: 0.603315\n",
      "epoch 48; iter: 0; batch classifier loss: 0.307627; batch adversarial loss: 0.585671\n",
      "epoch 48; iter: 200; batch classifier loss: 0.324451; batch adversarial loss: 0.642842\n",
      "epoch 49; iter: 0; batch classifier loss: 0.313487; batch adversarial loss: 0.589918\n",
      "epoch 49; iter: 200; batch classifier loss: 0.294825; batch adversarial loss: 0.662199\n",
      "epoch 0; iter: 0; batch classifier loss: 64.807869; batch adversarial loss: 0.762786\n",
      "epoch 0; iter: 200; batch classifier loss: 4.813123; batch adversarial loss: 0.678804\n",
      "epoch 1; iter: 0; batch classifier loss: 13.266325; batch adversarial loss: 0.667077\n",
      "epoch 1; iter: 200; batch classifier loss: 5.195024; batch adversarial loss: 0.650977\n",
      "epoch 2; iter: 0; batch classifier loss: 3.044578; batch adversarial loss: 0.629423\n",
      "epoch 2; iter: 200; batch classifier loss: 3.827520; batch adversarial loss: 0.645969\n",
      "epoch 3; iter: 0; batch classifier loss: 2.769598; batch adversarial loss: 0.627741\n",
      "epoch 3; iter: 200; batch classifier loss: 2.124089; batch adversarial loss: 0.617543\n",
      "epoch 4; iter: 0; batch classifier loss: 1.664951; batch adversarial loss: 0.640737\n",
      "epoch 4; iter: 200; batch classifier loss: 2.151876; batch adversarial loss: 0.575145\n",
      "epoch 5; iter: 0; batch classifier loss: 0.676801; batch adversarial loss: 0.645462\n",
      "epoch 5; iter: 200; batch classifier loss: 1.042391; batch adversarial loss: 0.566572\n",
      "epoch 6; iter: 0; batch classifier loss: 0.865651; batch adversarial loss: 0.586357\n",
      "epoch 6; iter: 200; batch classifier loss: 0.669042; batch adversarial loss: 0.608518\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596255; batch adversarial loss: 0.638752\n",
      "epoch 7; iter: 200; batch classifier loss: 0.738608; batch adversarial loss: 0.671159\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511995; batch adversarial loss: 0.580041\n",
      "epoch 8; iter: 200; batch classifier loss: 0.904534; batch adversarial loss: 0.635520\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499039; batch adversarial loss: 0.606755\n",
      "epoch 9; iter: 200; batch classifier loss: 0.513571; batch adversarial loss: 0.611710\n",
      "epoch 10; iter: 0; batch classifier loss: 0.628683; batch adversarial loss: 0.611505\n",
      "epoch 10; iter: 200; batch classifier loss: 0.511057; batch adversarial loss: 0.619046\n",
      "epoch 11; iter: 0; batch classifier loss: 0.493412; batch adversarial loss: 0.644980\n",
      "epoch 11; iter: 200; batch classifier loss: 0.569538; batch adversarial loss: 0.569723\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488263; batch adversarial loss: 0.587722\n",
      "epoch 12; iter: 200; batch classifier loss: 0.421160; batch adversarial loss: 0.593872\n",
      "epoch 13; iter: 0; batch classifier loss: 0.354499; batch adversarial loss: 0.601970\n",
      "epoch 13; iter: 200; batch classifier loss: 0.395138; batch adversarial loss: 0.599626\n",
      "epoch 14; iter: 0; batch classifier loss: 0.341200; batch adversarial loss: 0.629181\n",
      "epoch 14; iter: 200; batch classifier loss: 0.393267; batch adversarial loss: 0.617357\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344967; batch adversarial loss: 0.616091\n",
      "epoch 15; iter: 200; batch classifier loss: 0.552187; batch adversarial loss: 0.632082\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413801; batch adversarial loss: 0.663360\n",
      "epoch 16; iter: 200; batch classifier loss: 0.395609; batch adversarial loss: 0.654721\n",
      "epoch 17; iter: 0; batch classifier loss: 0.311837; batch adversarial loss: 0.617059\n",
      "epoch 17; iter: 200; batch classifier loss: 0.312925; batch adversarial loss: 0.646583\n",
      "epoch 18; iter: 0; batch classifier loss: 0.293664; batch adversarial loss: 0.629646\n",
      "epoch 18; iter: 200; batch classifier loss: 0.344711; batch adversarial loss: 0.650331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.372733; batch adversarial loss: 0.568324\n",
      "epoch 19; iter: 200; batch classifier loss: 0.345318; batch adversarial loss: 0.649376\n",
      "epoch 20; iter: 0; batch classifier loss: 0.296808; batch adversarial loss: 0.606775\n",
      "epoch 20; iter: 200; batch classifier loss: 0.457655; batch adversarial loss: 0.573930\n",
      "epoch 21; iter: 0; batch classifier loss: 0.288626; batch adversarial loss: 0.620258\n",
      "epoch 21; iter: 200; batch classifier loss: 0.313649; batch adversarial loss: 0.597918\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331277; batch adversarial loss: 0.623186\n",
      "epoch 22; iter: 200; batch classifier loss: 0.430859; batch adversarial loss: 0.639047\n",
      "epoch 23; iter: 0; batch classifier loss: 0.319027; batch adversarial loss: 0.615592\n",
      "epoch 23; iter: 200; batch classifier loss: 0.303105; batch adversarial loss: 0.607764\n",
      "epoch 24; iter: 0; batch classifier loss: 0.372954; batch adversarial loss: 0.660771\n",
      "epoch 24; iter: 200; batch classifier loss: 0.417364; batch adversarial loss: 0.576464\n",
      "epoch 25; iter: 0; batch classifier loss: 0.289931; batch adversarial loss: 0.564184\n",
      "epoch 25; iter: 200; batch classifier loss: 0.363754; batch adversarial loss: 0.645932\n",
      "epoch 26; iter: 0; batch classifier loss: 0.325500; batch adversarial loss: 0.654785\n",
      "epoch 26; iter: 200; batch classifier loss: 0.310798; batch adversarial loss: 0.677035\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390352; batch adversarial loss: 0.570822\n",
      "epoch 27; iter: 200; batch classifier loss: 0.394337; batch adversarial loss: 0.658822\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315917; batch adversarial loss: 0.566924\n",
      "epoch 28; iter: 200; batch classifier loss: 0.356676; batch adversarial loss: 0.614860\n",
      "epoch 29; iter: 0; batch classifier loss: 0.480536; batch adversarial loss: 0.723265\n",
      "epoch 29; iter: 200; batch classifier loss: 0.307968; batch adversarial loss: 0.647097\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390715; batch adversarial loss: 0.612602\n",
      "epoch 30; iter: 200; batch classifier loss: 0.338057; batch adversarial loss: 0.631925\n",
      "epoch 31; iter: 0; batch classifier loss: 0.371160; batch adversarial loss: 0.649316\n",
      "epoch 31; iter: 200; batch classifier loss: 0.317371; batch adversarial loss: 0.573493\n",
      "epoch 32; iter: 0; batch classifier loss: 0.386405; batch adversarial loss: 0.624394\n",
      "epoch 32; iter: 200; batch classifier loss: 0.375085; batch adversarial loss: 0.706251\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412030; batch adversarial loss: 0.630317\n",
      "epoch 33; iter: 200; batch classifier loss: 0.349129; batch adversarial loss: 0.677620\n",
      "epoch 34; iter: 0; batch classifier loss: 0.343042; batch adversarial loss: 0.681981\n",
      "epoch 34; iter: 200; batch classifier loss: 0.423535; batch adversarial loss: 0.645528\n",
      "epoch 35; iter: 0; batch classifier loss: 0.391706; batch adversarial loss: 0.614219\n",
      "epoch 35; iter: 200; batch classifier loss: 0.279413; batch adversarial loss: 0.650132\n",
      "epoch 36; iter: 0; batch classifier loss: 0.310240; batch adversarial loss: 0.650383\n",
      "epoch 36; iter: 200; batch classifier loss: 0.312603; batch adversarial loss: 0.578216\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415399; batch adversarial loss: 0.617709\n",
      "epoch 37; iter: 200; batch classifier loss: 0.298768; batch adversarial loss: 0.654296\n",
      "epoch 38; iter: 0; batch classifier loss: 0.352125; batch adversarial loss: 0.647843\n",
      "epoch 38; iter: 200; batch classifier loss: 0.352632; batch adversarial loss: 0.638002\n",
      "epoch 39; iter: 0; batch classifier loss: 0.330158; batch adversarial loss: 0.655009\n",
      "epoch 39; iter: 200; batch classifier loss: 0.262904; batch adversarial loss: 0.672481\n",
      "epoch 40; iter: 0; batch classifier loss: 0.304981; batch adversarial loss: 0.605680\n",
      "epoch 40; iter: 200; batch classifier loss: 0.314860; batch adversarial loss: 0.624204\n",
      "epoch 41; iter: 0; batch classifier loss: 0.313333; batch adversarial loss: 0.628873\n",
      "epoch 41; iter: 200; batch classifier loss: 0.404282; batch adversarial loss: 0.601761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393783; batch adversarial loss: 0.584103\n",
      "epoch 42; iter: 200; batch classifier loss: 0.455909; batch adversarial loss: 0.631370\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400466; batch adversarial loss: 0.652728\n",
      "epoch 43; iter: 200; batch classifier loss: 0.285776; batch adversarial loss: 0.609695\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401027; batch adversarial loss: 0.581138\n",
      "epoch 44; iter: 200; batch classifier loss: 0.319720; batch adversarial loss: 0.589884\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393503; batch adversarial loss: 0.567654\n",
      "epoch 45; iter: 200; batch classifier loss: 0.310028; batch adversarial loss: 0.641134\n",
      "epoch 46; iter: 0; batch classifier loss: 0.486508; batch adversarial loss: 0.619857\n",
      "epoch 46; iter: 200; batch classifier loss: 0.374438; batch adversarial loss: 0.651563\n",
      "epoch 47; iter: 0; batch classifier loss: 0.465650; batch adversarial loss: 0.604548\n",
      "epoch 47; iter: 200; batch classifier loss: 0.312918; batch adversarial loss: 0.586568\n",
      "epoch 48; iter: 0; batch classifier loss: 0.488396; batch adversarial loss: 0.591012\n",
      "epoch 48; iter: 200; batch classifier loss: 0.425182; batch adversarial loss: 0.644642\n",
      "epoch 49; iter: 0; batch classifier loss: 0.510600; batch adversarial loss: 0.578303\n",
      "epoch 49; iter: 200; batch classifier loss: 0.383330; batch adversarial loss: 0.601071\n",
      "epoch 0; iter: 0; batch classifier loss: 17.958515; batch adversarial loss: 0.677387\n",
      "epoch 0; iter: 200; batch classifier loss: 3.891574; batch adversarial loss: 0.679123\n",
      "epoch 1; iter: 0; batch classifier loss: 9.212122; batch adversarial loss: 0.619269\n",
      "epoch 1; iter: 200; batch classifier loss: 8.019278; batch adversarial loss: 0.675618\n",
      "epoch 2; iter: 0; batch classifier loss: 4.000555; batch adversarial loss: 0.649210\n",
      "epoch 2; iter: 200; batch classifier loss: 4.857021; batch adversarial loss: 0.640932\n",
      "epoch 3; iter: 0; batch classifier loss: 1.970971; batch adversarial loss: 0.648665\n",
      "epoch 3; iter: 200; batch classifier loss: 2.142705; batch adversarial loss: 0.628835\n",
      "epoch 4; iter: 0; batch classifier loss: 1.924506; batch adversarial loss: 0.629313\n",
      "epoch 4; iter: 200; batch classifier loss: 1.957044; batch adversarial loss: 0.638056\n",
      "epoch 5; iter: 0; batch classifier loss: 0.770403; batch adversarial loss: 0.620184\n",
      "epoch 5; iter: 200; batch classifier loss: 1.446331; batch adversarial loss: 0.609616\n",
      "epoch 6; iter: 0; batch classifier loss: 2.211778; batch adversarial loss: 0.570015\n",
      "epoch 6; iter: 200; batch classifier loss: 1.733187; batch adversarial loss: 0.621956\n",
      "epoch 7; iter: 0; batch classifier loss: 0.672014; batch adversarial loss: 0.601374\n",
      "epoch 7; iter: 200; batch classifier loss: 0.800542; batch adversarial loss: 0.601824\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397428; batch adversarial loss: 0.649402\n",
      "epoch 8; iter: 200; batch classifier loss: 0.726450; batch adversarial loss: 0.615004\n",
      "epoch 9; iter: 0; batch classifier loss: 1.041997; batch adversarial loss: 0.587171\n",
      "epoch 9; iter: 200; batch classifier loss: 0.442214; batch adversarial loss: 0.639398\n",
      "epoch 10; iter: 0; batch classifier loss: 0.858311; batch adversarial loss: 0.618676\n",
      "epoch 10; iter: 200; batch classifier loss: 0.526663; batch adversarial loss: 0.628149\n",
      "epoch 11; iter: 0; batch classifier loss: 3.080980; batch adversarial loss: 0.656182\n",
      "epoch 11; iter: 200; batch classifier loss: 0.548241; batch adversarial loss: 0.606596\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408187; batch adversarial loss: 0.620240\n",
      "epoch 12; iter: 200; batch classifier loss: 0.804870; batch adversarial loss: 0.600809\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556007; batch adversarial loss: 0.577929\n",
      "epoch 13; iter: 200; batch classifier loss: 0.424196; batch adversarial loss: 0.632088\n",
      "epoch 14; iter: 0; batch classifier loss: 0.534172; batch adversarial loss: 0.610222\n",
      "epoch 14; iter: 200; batch classifier loss: 0.734395; batch adversarial loss: 0.643470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371278; batch adversarial loss: 0.637462\n",
      "epoch 15; iter: 200; batch classifier loss: 0.442626; batch adversarial loss: 0.610004\n",
      "epoch 16; iter: 0; batch classifier loss: 0.625479; batch adversarial loss: 0.661735\n",
      "epoch 16; iter: 200; batch classifier loss: 0.448062; batch adversarial loss: 0.605216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.497926; batch adversarial loss: 0.569342\n",
      "epoch 17; iter: 200; batch classifier loss: 0.305069; batch adversarial loss: 0.665390\n",
      "epoch 18; iter: 0; batch classifier loss: 0.620574; batch adversarial loss: 0.646663\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382895; batch adversarial loss: 0.658290\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550408; batch adversarial loss: 0.624620\n",
      "epoch 19; iter: 200; batch classifier loss: 0.512683; batch adversarial loss: 0.632813\n",
      "epoch 20; iter: 0; batch classifier loss: 0.377361; batch adversarial loss: 0.592502\n",
      "epoch 20; iter: 200; batch classifier loss: 0.444673; batch adversarial loss: 0.703504\n",
      "epoch 21; iter: 0; batch classifier loss: 0.390516; batch adversarial loss: 0.571614\n",
      "epoch 21; iter: 200; batch classifier loss: 0.427498; batch adversarial loss: 0.602043\n",
      "epoch 22; iter: 0; batch classifier loss: 0.292036; batch adversarial loss: 0.645940\n",
      "epoch 22; iter: 200; batch classifier loss: 0.392824; batch adversarial loss: 0.618367\n",
      "epoch 23; iter: 0; batch classifier loss: 0.343383; batch adversarial loss: 0.611970\n",
      "epoch 23; iter: 200; batch classifier loss: 0.363023; batch adversarial loss: 0.668726\n",
      "epoch 24; iter: 0; batch classifier loss: 0.392644; batch adversarial loss: 0.610507\n",
      "epoch 24; iter: 200; batch classifier loss: 0.338847; batch adversarial loss: 0.587528\n",
      "epoch 25; iter: 0; batch classifier loss: 0.312302; batch adversarial loss: 0.630616\n",
      "epoch 25; iter: 200; batch classifier loss: 0.420776; batch adversarial loss: 0.509421\n",
      "epoch 26; iter: 0; batch classifier loss: 0.401412; batch adversarial loss: 0.653211\n",
      "epoch 26; iter: 200; batch classifier loss: 0.394871; batch adversarial loss: 0.628027\n",
      "epoch 27; iter: 0; batch classifier loss: 0.308070; batch adversarial loss: 0.636938\n",
      "epoch 27; iter: 200; batch classifier loss: 0.325858; batch adversarial loss: 0.644146\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413779; batch adversarial loss: 0.569269\n",
      "epoch 28; iter: 200; batch classifier loss: 0.405910; batch adversarial loss: 0.611518\n",
      "epoch 29; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.597549\n",
      "epoch 29; iter: 200; batch classifier loss: 0.386418; batch adversarial loss: 0.657812\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323025; batch adversarial loss: 0.640173\n",
      "epoch 30; iter: 200; batch classifier loss: 0.446404; batch adversarial loss: 0.642294\n",
      "epoch 31; iter: 0; batch classifier loss: 0.341785; batch adversarial loss: 0.608592\n",
      "epoch 31; iter: 200; batch classifier loss: 0.390831; batch adversarial loss: 0.631090\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318045; batch adversarial loss: 0.638489\n",
      "epoch 32; iter: 200; batch classifier loss: 0.291034; batch adversarial loss: 0.668457\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358573; batch adversarial loss: 0.606125\n",
      "epoch 33; iter: 200; batch classifier loss: 0.316202; batch adversarial loss: 0.607820\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404077; batch adversarial loss: 0.624644\n",
      "epoch 34; iter: 200; batch classifier loss: 0.329673; batch adversarial loss: 0.582319\n",
      "epoch 35; iter: 0; batch classifier loss: 0.438163; batch adversarial loss: 0.614922\n",
      "epoch 35; iter: 200; batch classifier loss: 0.449681; batch adversarial loss: 0.615659\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460611; batch adversarial loss: 0.572424\n",
      "epoch 36; iter: 200; batch classifier loss: 0.364852; batch adversarial loss: 0.650175\n",
      "epoch 37; iter: 0; batch classifier loss: 0.308332; batch adversarial loss: 0.635524\n",
      "epoch 37; iter: 200; batch classifier loss: 0.368609; batch adversarial loss: 0.629804\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404124; batch adversarial loss: 0.626877\n",
      "epoch 38; iter: 200; batch classifier loss: 0.360101; batch adversarial loss: 0.595322\n",
      "epoch 39; iter: 0; batch classifier loss: 0.269333; batch adversarial loss: 0.634139\n",
      "epoch 39; iter: 200; batch classifier loss: 0.464376; batch adversarial loss: 0.586496\n",
      "epoch 40; iter: 0; batch classifier loss: 0.359615; batch adversarial loss: 0.598511\n",
      "epoch 40; iter: 200; batch classifier loss: 0.456570; batch adversarial loss: 0.646862\n",
      "epoch 41; iter: 0; batch classifier loss: 0.369273; batch adversarial loss: 0.588003\n",
      "epoch 41; iter: 200; batch classifier loss: 0.322407; batch adversarial loss: 0.647273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393807; batch adversarial loss: 0.604017\n",
      "epoch 42; iter: 200; batch classifier loss: 0.437057; batch adversarial loss: 0.604044\n",
      "epoch 43; iter: 0; batch classifier loss: 0.329983; batch adversarial loss: 0.681882\n",
      "epoch 43; iter: 200; batch classifier loss: 0.327956; batch adversarial loss: 0.593664\n",
      "epoch 44; iter: 0; batch classifier loss: 0.518445; batch adversarial loss: 0.597729\n",
      "epoch 44; iter: 200; batch classifier loss: 0.412725; batch adversarial loss: 0.612034\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354994; batch adversarial loss: 0.593684\n",
      "epoch 45; iter: 200; batch classifier loss: 0.420508; batch adversarial loss: 0.599329\n",
      "epoch 46; iter: 0; batch classifier loss: 0.278095; batch adversarial loss: 0.640537\n",
      "epoch 46; iter: 200; batch classifier loss: 0.742628; batch adversarial loss: 0.599934\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471726; batch adversarial loss: 0.616556\n",
      "epoch 47; iter: 200; batch classifier loss: 0.548665; batch adversarial loss: 0.654372\n",
      "epoch 48; iter: 0; batch classifier loss: 0.352167; batch adversarial loss: 0.572558\n",
      "epoch 48; iter: 200; batch classifier loss: 0.391653; batch adversarial loss: 0.605672\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390929; batch adversarial loss: 0.610359\n",
      "epoch 49; iter: 200; batch classifier loss: 0.359592; batch adversarial loss: 0.631021\n",
      "epoch 0; iter: 0; batch classifier loss: 3.637748; batch adversarial loss: 0.747246\n",
      "epoch 0; iter: 200; batch classifier loss: 3.622814; batch adversarial loss: 0.712700\n",
      "epoch 1; iter: 0; batch classifier loss: 16.823145; batch adversarial loss: 0.608815\n",
      "epoch 1; iter: 200; batch classifier loss: 6.674813; batch adversarial loss: 0.678522\n",
      "epoch 2; iter: 0; batch classifier loss: 3.935425; batch adversarial loss: 0.603319\n",
      "epoch 2; iter: 200; batch classifier loss: 2.803862; batch adversarial loss: 0.576500\n",
      "epoch 3; iter: 0; batch classifier loss: 5.096810; batch adversarial loss: 0.593121\n",
      "epoch 3; iter: 200; batch classifier loss: 3.276474; batch adversarial loss: 0.625334\n",
      "epoch 4; iter: 0; batch classifier loss: 1.917623; batch adversarial loss: 0.670332\n",
      "epoch 4; iter: 200; batch classifier loss: 2.671736; batch adversarial loss: 0.599543\n",
      "epoch 5; iter: 0; batch classifier loss: 4.368455; batch adversarial loss: 0.592391\n",
      "epoch 5; iter: 200; batch classifier loss: 1.107518; batch adversarial loss: 0.616446\n",
      "epoch 6; iter: 0; batch classifier loss: 0.523786; batch adversarial loss: 0.614540\n",
      "epoch 6; iter: 200; batch classifier loss: 0.660030; batch adversarial loss: 0.633013\n",
      "epoch 7; iter: 0; batch classifier loss: 1.976627; batch adversarial loss: 0.653308\n",
      "epoch 7; iter: 200; batch classifier loss: 0.611568; batch adversarial loss: 0.640399\n",
      "epoch 8; iter: 0; batch classifier loss: 1.030071; batch adversarial loss: 0.630415\n",
      "epoch 8; iter: 200; batch classifier loss: 0.569957; batch adversarial loss: 0.619347\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480518; batch adversarial loss: 0.603453\n",
      "epoch 9; iter: 200; batch classifier loss: 0.332345; batch adversarial loss: 0.637576\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586213; batch adversarial loss: 0.592514\n",
      "epoch 10; iter: 200; batch classifier loss: 0.485592; batch adversarial loss: 0.621685\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440957; batch adversarial loss: 0.642103\n",
      "epoch 11; iter: 200; batch classifier loss: 0.396304; batch adversarial loss: 0.579893\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373984; batch adversarial loss: 0.613900\n",
      "epoch 12; iter: 200; batch classifier loss: 0.462356; batch adversarial loss: 0.621853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.447651; batch adversarial loss: 0.656052\n",
      "epoch 13; iter: 200; batch classifier loss: 0.321990; batch adversarial loss: 0.662073\n",
      "epoch 14; iter: 0; batch classifier loss: 0.444894; batch adversarial loss: 0.589512\n",
      "epoch 14; iter: 200; batch classifier loss: 0.400528; batch adversarial loss: 0.638679\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506522; batch adversarial loss: 0.632105\n",
      "epoch 15; iter: 200; batch classifier loss: 0.338814; batch adversarial loss: 0.601532\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319881; batch adversarial loss: 0.644033\n",
      "epoch 16; iter: 200; batch classifier loss: 0.836382; batch adversarial loss: 0.637049\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426943; batch adversarial loss: 0.607657\n",
      "epoch 17; iter: 200; batch classifier loss: 0.342920; batch adversarial loss: 0.552978\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469422; batch adversarial loss: 0.589213\n",
      "epoch 18; iter: 200; batch classifier loss: 0.267868; batch adversarial loss: 0.602353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287590; batch adversarial loss: 0.603502\n",
      "epoch 19; iter: 200; batch classifier loss: 0.323734; batch adversarial loss: 0.568394\n",
      "epoch 20; iter: 0; batch classifier loss: 0.289934; batch adversarial loss: 0.643789\n",
      "epoch 20; iter: 200; batch classifier loss: 0.240775; batch adversarial loss: 0.603340\n",
      "epoch 21; iter: 0; batch classifier loss: 0.378223; batch adversarial loss: 0.602866\n",
      "epoch 21; iter: 200; batch classifier loss: 0.387014; batch adversarial loss: 0.604937\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350658; batch adversarial loss: 0.629184\n",
      "epoch 22; iter: 200; batch classifier loss: 0.397302; batch adversarial loss: 0.629047\n",
      "epoch 23; iter: 0; batch classifier loss: 0.434955; batch adversarial loss: 0.524152\n",
      "epoch 23; iter: 200; batch classifier loss: 0.319555; batch adversarial loss: 0.611204\n",
      "epoch 24; iter: 0; batch classifier loss: 0.342603; batch adversarial loss: 0.627638\n",
      "epoch 24; iter: 200; batch classifier loss: 0.396019; batch adversarial loss: 0.676481\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402238; batch adversarial loss: 0.649478\n",
      "epoch 25; iter: 200; batch classifier loss: 0.326582; batch adversarial loss: 0.559725\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338808; batch adversarial loss: 0.615681\n",
      "epoch 26; iter: 200; batch classifier loss: 0.340216; batch adversarial loss: 0.655027\n",
      "epoch 27; iter: 0; batch classifier loss: 0.429086; batch adversarial loss: 0.633845\n",
      "epoch 27; iter: 200; batch classifier loss: 0.307610; batch adversarial loss: 0.663360\n",
      "epoch 28; iter: 0; batch classifier loss: 0.389238; batch adversarial loss: 0.712403\n",
      "epoch 28; iter: 200; batch classifier loss: 0.332982; batch adversarial loss: 0.630036\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406283; batch adversarial loss: 0.621497\n",
      "epoch 29; iter: 200; batch classifier loss: 0.358109; batch adversarial loss: 0.638721\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433887; batch adversarial loss: 0.617317\n",
      "epoch 30; iter: 200; batch classifier loss: 0.381151; batch adversarial loss: 0.605524\n",
      "epoch 31; iter: 0; batch classifier loss: 0.343964; batch adversarial loss: 0.605756\n",
      "epoch 31; iter: 200; batch classifier loss: 0.230209; batch adversarial loss: 0.655675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434548; batch adversarial loss: 0.573323\n",
      "epoch 32; iter: 200; batch classifier loss: 0.261274; batch adversarial loss: 0.586385\n",
      "epoch 33; iter: 0; batch classifier loss: 0.369803; batch adversarial loss: 0.638072\n",
      "epoch 33; iter: 200; batch classifier loss: 0.383818; batch adversarial loss: 0.676745\n",
      "epoch 34; iter: 0; batch classifier loss: 0.300169; batch adversarial loss: 0.601087\n",
      "epoch 34; iter: 200; batch classifier loss: 0.263048; batch adversarial loss: 0.653091\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400654; batch adversarial loss: 0.680016\n",
      "epoch 35; iter: 200; batch classifier loss: 0.293696; batch adversarial loss: 0.568358\n",
      "epoch 36; iter: 0; batch classifier loss: 0.341849; batch adversarial loss: 0.653313\n",
      "epoch 36; iter: 200; batch classifier loss: 0.253130; batch adversarial loss: 0.618449\n",
      "epoch 37; iter: 0; batch classifier loss: 0.352915; batch adversarial loss: 0.658804\n",
      "epoch 37; iter: 200; batch classifier loss: 0.288834; batch adversarial loss: 0.661246\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390467; batch adversarial loss: 0.662618\n",
      "epoch 38; iter: 200; batch classifier loss: 0.360709; batch adversarial loss: 0.660075\n",
      "epoch 39; iter: 0; batch classifier loss: 0.311885; batch adversarial loss: 0.625929\n",
      "epoch 39; iter: 200; batch classifier loss: 0.405093; batch adversarial loss: 0.570220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.320722; batch adversarial loss: 0.638319\n",
      "epoch 40; iter: 200; batch classifier loss: 0.402689; batch adversarial loss: 0.653082\n",
      "epoch 41; iter: 0; batch classifier loss: 0.326681; batch adversarial loss: 0.574275\n",
      "epoch 41; iter: 200; batch classifier loss: 0.445465; batch adversarial loss: 0.628780\n",
      "epoch 42; iter: 0; batch classifier loss: 0.363161; batch adversarial loss: 0.619908\n",
      "epoch 42; iter: 200; batch classifier loss: 0.341779; batch adversarial loss: 0.645509\n",
      "epoch 43; iter: 0; batch classifier loss: 0.332984; batch adversarial loss: 0.596375\n",
      "epoch 43; iter: 200; batch classifier loss: 0.370053; batch adversarial loss: 0.613213\n",
      "epoch 44; iter: 0; batch classifier loss: 0.525044; batch adversarial loss: 0.622182\n",
      "epoch 44; iter: 200; batch classifier loss: 0.422965; batch adversarial loss: 0.675113\n",
      "epoch 45; iter: 0; batch classifier loss: 0.328882; batch adversarial loss: 0.620984\n",
      "epoch 45; iter: 200; batch classifier loss: 0.310567; batch adversarial loss: 0.701806\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508107; batch adversarial loss: 0.675902\n",
      "epoch 46; iter: 200; batch classifier loss: 0.377625; batch adversarial loss: 0.627007\n",
      "epoch 47; iter: 0; batch classifier loss: 0.396558; batch adversarial loss: 0.637573\n",
      "epoch 47; iter: 200; batch classifier loss: 0.509449; batch adversarial loss: 0.641564\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417759; batch adversarial loss: 0.698988\n",
      "epoch 48; iter: 200; batch classifier loss: 0.415565; batch adversarial loss: 0.577285\n",
      "epoch 49; iter: 0; batch classifier loss: 0.355581; batch adversarial loss: 0.648189\n",
      "epoch 49; iter: 200; batch classifier loss: 0.312472; batch adversarial loss: 0.666051\n",
      "epoch 0; iter: 0; batch classifier loss: 59.591866; batch adversarial loss: 0.710461\n",
      "epoch 0; iter: 200; batch classifier loss: 4.299624; batch adversarial loss: 0.668772\n",
      "epoch 1; iter: 0; batch classifier loss: 6.605071; batch adversarial loss: 0.672522\n",
      "epoch 1; iter: 200; batch classifier loss: 1.839719; batch adversarial loss: 0.658910\n",
      "epoch 2; iter: 0; batch classifier loss: 7.426445; batch adversarial loss: 0.664664\n",
      "epoch 2; iter: 200; batch classifier loss: 1.943788; batch adversarial loss: 0.614562\n",
      "epoch 3; iter: 0; batch classifier loss: 3.411608; batch adversarial loss: 0.653209\n",
      "epoch 3; iter: 200; batch classifier loss: 3.683951; batch adversarial loss: 0.653712\n",
      "epoch 4; iter: 0; batch classifier loss: 3.253084; batch adversarial loss: 0.688217\n",
      "epoch 4; iter: 200; batch classifier loss: 1.167814; batch adversarial loss: 0.615200\n",
      "epoch 5; iter: 0; batch classifier loss: 0.406166; batch adversarial loss: 0.638023\n",
      "epoch 5; iter: 200; batch classifier loss: 1.545924; batch adversarial loss: 0.630722\n",
      "epoch 6; iter: 0; batch classifier loss: 0.785793; batch adversarial loss: 0.674504\n",
      "epoch 6; iter: 200; batch classifier loss: 0.602040; batch adversarial loss: 0.638725\n",
      "epoch 7; iter: 0; batch classifier loss: 0.422331; batch adversarial loss: 0.662683\n",
      "epoch 7; iter: 200; batch classifier loss: 0.636485; batch adversarial loss: 0.621272\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587728; batch adversarial loss: 0.655732\n",
      "epoch 8; iter: 200; batch classifier loss: 0.402106; batch adversarial loss: 0.590832\n",
      "epoch 9; iter: 0; batch classifier loss: 0.723851; batch adversarial loss: 0.633384\n",
      "epoch 9; iter: 200; batch classifier loss: 0.696765; batch adversarial loss: 0.642272\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537013; batch adversarial loss: 0.594959\n",
      "epoch 10; iter: 200; batch classifier loss: 0.679916; batch adversarial loss: 0.588333\n",
      "epoch 11; iter: 0; batch classifier loss: 0.422651; batch adversarial loss: 0.649898\n",
      "epoch 11; iter: 200; batch classifier loss: 0.523836; batch adversarial loss: 0.620908\n",
      "epoch 12; iter: 0; batch classifier loss: 0.328250; batch adversarial loss: 0.617994\n",
      "epoch 12; iter: 200; batch classifier loss: 0.576156; batch adversarial loss: 0.649758\n",
      "epoch 13; iter: 0; batch classifier loss: 0.425981; batch adversarial loss: 0.620106\n",
      "epoch 13; iter: 200; batch classifier loss: 0.411269; batch adversarial loss: 0.635899\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470116; batch adversarial loss: 0.662483\n",
      "epoch 14; iter: 200; batch classifier loss: 0.395958; batch adversarial loss: 0.631182\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462274; batch adversarial loss: 0.633540\n",
      "epoch 15; iter: 200; batch classifier loss: 0.314470; batch adversarial loss: 0.570002\n",
      "epoch 16; iter: 0; batch classifier loss: 0.537645; batch adversarial loss: 0.617145\n",
      "epoch 16; iter: 200; batch classifier loss: 0.381578; batch adversarial loss: 0.609972\n",
      "epoch 17; iter: 0; batch classifier loss: 0.440503; batch adversarial loss: 0.603219\n",
      "epoch 17; iter: 200; batch classifier loss: 0.487082; batch adversarial loss: 0.629130\n",
      "epoch 18; iter: 0; batch classifier loss: 0.309245; batch adversarial loss: 0.699542\n",
      "epoch 18; iter: 200; batch classifier loss: 0.323209; batch adversarial loss: 0.661911\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440110; batch adversarial loss: 0.581724\n",
      "epoch 19; iter: 200; batch classifier loss: 0.276025; batch adversarial loss: 0.598954\n",
      "epoch 20; iter: 0; batch classifier loss: 0.400681; batch adversarial loss: 0.601813\n",
      "epoch 20; iter: 200; batch classifier loss: 0.357383; batch adversarial loss: 0.622378\n",
      "epoch 21; iter: 0; batch classifier loss: 0.376763; batch adversarial loss: 0.620246\n",
      "epoch 21; iter: 200; batch classifier loss: 0.426448; batch adversarial loss: 0.658196\n",
      "epoch 22; iter: 0; batch classifier loss: 0.367544; batch adversarial loss: 0.617770\n",
      "epoch 22; iter: 200; batch classifier loss: 0.338955; batch adversarial loss: 0.612038\n",
      "epoch 23; iter: 0; batch classifier loss: 0.369687; batch adversarial loss: 0.670106\n",
      "epoch 23; iter: 200; batch classifier loss: 0.321597; batch adversarial loss: 0.593445\n",
      "epoch 24; iter: 0; batch classifier loss: 0.389458; batch adversarial loss: 0.622761\n",
      "epoch 24; iter: 200; batch classifier loss: 0.435922; batch adversarial loss: 0.607208\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311511; batch adversarial loss: 0.615848\n",
      "epoch 25; iter: 200; batch classifier loss: 0.455212; batch adversarial loss: 0.607854\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363319; batch adversarial loss: 0.628988\n",
      "epoch 26; iter: 200; batch classifier loss: 0.389807; batch adversarial loss: 0.617761\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445650; batch adversarial loss: 0.572590\n",
      "epoch 27; iter: 200; batch classifier loss: 0.334299; batch adversarial loss: 0.633027\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342609; batch adversarial loss: 0.607277\n",
      "epoch 28; iter: 200; batch classifier loss: 0.458415; batch adversarial loss: 0.628541\n",
      "epoch 29; iter: 0; batch classifier loss: 0.332643; batch adversarial loss: 0.610222\n",
      "epoch 29; iter: 200; batch classifier loss: 0.350481; batch adversarial loss: 0.673214\n",
      "epoch 30; iter: 0; batch classifier loss: 0.387546; batch adversarial loss: 0.662280\n",
      "epoch 30; iter: 200; batch classifier loss: 0.332949; batch adversarial loss: 0.608623\n",
      "epoch 31; iter: 0; batch classifier loss: 0.341940; batch adversarial loss: 0.591819\n",
      "epoch 31; iter: 200; batch classifier loss: 0.275115; batch adversarial loss: 0.666384\n",
      "epoch 32; iter: 0; batch classifier loss: 0.372150; batch adversarial loss: 0.645368\n",
      "epoch 32; iter: 200; batch classifier loss: 0.328347; batch adversarial loss: 0.620897\n",
      "epoch 33; iter: 0; batch classifier loss: 0.314711; batch adversarial loss: 0.609372\n",
      "epoch 33; iter: 200; batch classifier loss: 0.273185; batch adversarial loss: 0.629968\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363692; batch adversarial loss: 0.637839\n",
      "epoch 34; iter: 200; batch classifier loss: 0.360914; batch adversarial loss: 0.615755\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425626; batch adversarial loss: 0.594209\n",
      "epoch 35; iter: 200; batch classifier loss: 0.461734; batch adversarial loss: 0.586888\n",
      "epoch 36; iter: 0; batch classifier loss: 0.334913; batch adversarial loss: 0.596444\n",
      "epoch 36; iter: 200; batch classifier loss: 0.371792; batch adversarial loss: 0.595526\n",
      "epoch 37; iter: 0; batch classifier loss: 0.430997; batch adversarial loss: 0.594888\n",
      "epoch 37; iter: 200; batch classifier loss: 0.323191; batch adversarial loss: 0.646662\n",
      "epoch 38; iter: 0; batch classifier loss: 0.541109; batch adversarial loss: 0.648145\n",
      "epoch 38; iter: 200; batch classifier loss: 0.262653; batch adversarial loss: 0.643296\n",
      "epoch 39; iter: 0; batch classifier loss: 0.314705; batch adversarial loss: 0.604348\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349565; batch adversarial loss: 0.599761\n",
      "epoch 40; iter: 0; batch classifier loss: 0.326916; batch adversarial loss: 0.634504\n",
      "epoch 40; iter: 200; batch classifier loss: 0.349908; batch adversarial loss: 0.631206\n",
      "epoch 41; iter: 0; batch classifier loss: 0.432320; batch adversarial loss: 0.623849\n",
      "epoch 41; iter: 200; batch classifier loss: 0.339427; batch adversarial loss: 0.632642\n",
      "epoch 42; iter: 0; batch classifier loss: 0.424701; batch adversarial loss: 0.634897\n",
      "epoch 42; iter: 200; batch classifier loss: 0.335148; batch adversarial loss: 0.643726\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383555; batch adversarial loss: 0.650023\n",
      "epoch 43; iter: 200; batch classifier loss: 0.711689; batch adversarial loss: 0.662883\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369716; batch adversarial loss: 0.711818\n",
      "epoch 44; iter: 200; batch classifier loss: 0.298499; batch adversarial loss: 0.639404\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520008; batch adversarial loss: 0.609765\n",
      "epoch 45; iter: 200; batch classifier loss: 0.441412; batch adversarial loss: 0.574583\n",
      "epoch 46; iter: 0; batch classifier loss: 0.278592; batch adversarial loss: 0.646579\n",
      "epoch 46; iter: 200; batch classifier loss: 0.275148; batch adversarial loss: 0.641630\n",
      "epoch 47; iter: 0; batch classifier loss: 0.344057; batch adversarial loss: 0.595489\n",
      "epoch 47; iter: 200; batch classifier loss: 0.408150; batch adversarial loss: 0.679519\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433535; batch adversarial loss: 0.632394\n",
      "epoch 48; iter: 200; batch classifier loss: 0.422945; batch adversarial loss: 0.635168\n",
      "epoch 49; iter: 0; batch classifier loss: 0.356685; batch adversarial loss: 0.656063\n",
      "epoch 49; iter: 200; batch classifier loss: 0.403866; batch adversarial loss: 0.586171\n",
      "epoch 0; iter: 0; batch classifier loss: 13.808859; batch adversarial loss: 0.739518\n",
      "epoch 0; iter: 200; batch classifier loss: 8.417320; batch adversarial loss: 0.669014\n",
      "epoch 1; iter: 0; batch classifier loss: 10.469110; batch adversarial loss: 0.671088\n",
      "epoch 1; iter: 200; batch classifier loss: 3.043895; batch adversarial loss: 0.648938\n",
      "epoch 2; iter: 0; batch classifier loss: 6.581138; batch adversarial loss: 0.639817\n",
      "epoch 2; iter: 200; batch classifier loss: 2.795888; batch adversarial loss: 0.632731\n",
      "epoch 3; iter: 0; batch classifier loss: 3.053521; batch adversarial loss: 0.606155\n",
      "epoch 3; iter: 200; batch classifier loss: 0.624474; batch adversarial loss: 0.601992\n",
      "epoch 4; iter: 0; batch classifier loss: 1.485035; batch adversarial loss: 0.632440\n",
      "epoch 4; iter: 200; batch classifier loss: 1.449666; batch adversarial loss: 0.594249\n",
      "epoch 5; iter: 0; batch classifier loss: 2.415917; batch adversarial loss: 0.544332\n",
      "epoch 5; iter: 200; batch classifier loss: 1.063639; batch adversarial loss: 0.609708\n",
      "epoch 6; iter: 0; batch classifier loss: 0.421529; batch adversarial loss: 0.564455\n",
      "epoch 6; iter: 200; batch classifier loss: 0.354953; batch adversarial loss: 0.629300\n",
      "epoch 7; iter: 0; batch classifier loss: 0.753734; batch adversarial loss: 0.594142\n",
      "epoch 7; iter: 200; batch classifier loss: 0.389964; batch adversarial loss: 0.616714\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506205; batch adversarial loss: 0.638960\n",
      "epoch 8; iter: 200; batch classifier loss: 0.425879; batch adversarial loss: 0.617978\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494926; batch adversarial loss: 0.650396\n",
      "epoch 9; iter: 200; batch classifier loss: 0.477635; batch adversarial loss: 0.650628\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386550; batch adversarial loss: 0.611485\n",
      "epoch 10; iter: 200; batch classifier loss: 0.485945; batch adversarial loss: 0.563143\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529786; batch adversarial loss: 0.604371\n",
      "epoch 11; iter: 200; batch classifier loss: 0.580577; batch adversarial loss: 0.587068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.696235; batch adversarial loss: 0.639145\n",
      "epoch 12; iter: 200; batch classifier loss: 0.315043; batch adversarial loss: 0.613058\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492588; batch adversarial loss: 0.608693\n",
      "epoch 13; iter: 200; batch classifier loss: 0.387208; batch adversarial loss: 0.633494\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406912; batch adversarial loss: 0.593045\n",
      "epoch 14; iter: 200; batch classifier loss: 0.452884; batch adversarial loss: 0.630096\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337953; batch adversarial loss: 0.614393\n",
      "epoch 15; iter: 200; batch classifier loss: 0.420040; batch adversarial loss: 0.666341\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348149; batch adversarial loss: 0.638625\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352161; batch adversarial loss: 0.567491\n",
      "epoch 17; iter: 0; batch classifier loss: 0.341635; batch adversarial loss: 0.657667\n",
      "epoch 17; iter: 200; batch classifier loss: 0.333856; batch adversarial loss: 0.616962\n",
      "epoch 18; iter: 0; batch classifier loss: 0.634833; batch adversarial loss: 0.663814\n",
      "epoch 18; iter: 200; batch classifier loss: 0.367568; batch adversarial loss: 0.612237\n",
      "epoch 19; iter: 0; batch classifier loss: 0.353799; batch adversarial loss: 0.568514\n",
      "epoch 19; iter: 200; batch classifier loss: 0.333921; batch adversarial loss: 0.652320\n",
      "epoch 20; iter: 0; batch classifier loss: 0.306392; batch adversarial loss: 0.582450\n",
      "epoch 20; iter: 200; batch classifier loss: 0.301253; batch adversarial loss: 0.643071\n",
      "epoch 21; iter: 0; batch classifier loss: 0.343833; batch adversarial loss: 0.642283\n",
      "epoch 21; iter: 200; batch classifier loss: 0.359398; batch adversarial loss: 0.575489\n",
      "epoch 22; iter: 0; batch classifier loss: 0.292163; batch adversarial loss: 0.655128\n",
      "epoch 22; iter: 200; batch classifier loss: 0.586852; batch adversarial loss: 0.561221\n",
      "epoch 23; iter: 0; batch classifier loss: 0.360226; batch adversarial loss: 0.589806\n",
      "epoch 23; iter: 200; batch classifier loss: 0.360236; batch adversarial loss: 0.662368\n",
      "epoch 24; iter: 0; batch classifier loss: 0.365020; batch adversarial loss: 0.575150\n",
      "epoch 24; iter: 200; batch classifier loss: 0.338591; batch adversarial loss: 0.628198\n",
      "epoch 25; iter: 0; batch classifier loss: 0.408977; batch adversarial loss: 0.641541\n",
      "epoch 25; iter: 200; batch classifier loss: 0.329070; batch adversarial loss: 0.601138\n",
      "epoch 26; iter: 0; batch classifier loss: 0.341412; batch adversarial loss: 0.647546\n",
      "epoch 26; iter: 200; batch classifier loss: 0.308067; batch adversarial loss: 0.642716\n",
      "epoch 27; iter: 0; batch classifier loss: 0.374632; batch adversarial loss: 0.573016\n",
      "epoch 27; iter: 200; batch classifier loss: 0.407618; batch adversarial loss: 0.661379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.332521; batch adversarial loss: 0.609776\n",
      "epoch 28; iter: 200; batch classifier loss: 0.331813; batch adversarial loss: 0.536230\n",
      "epoch 29; iter: 0; batch classifier loss: 0.378541; batch adversarial loss: 0.663088\n",
      "epoch 29; iter: 200; batch classifier loss: 0.350554; batch adversarial loss: 0.623479\n",
      "epoch 30; iter: 0; batch classifier loss: 0.275841; batch adversarial loss: 0.677066\n",
      "epoch 30; iter: 200; batch classifier loss: 0.311704; batch adversarial loss: 0.691316\n",
      "epoch 31; iter: 0; batch classifier loss: 0.394156; batch adversarial loss: 0.637921\n",
      "epoch 31; iter: 200; batch classifier loss: 0.342013; batch adversarial loss: 0.645523\n",
      "epoch 32; iter: 0; batch classifier loss: 0.396581; batch adversarial loss: 0.586923\n",
      "epoch 32; iter: 200; batch classifier loss: 0.352763; batch adversarial loss: 0.638769\n",
      "epoch 33; iter: 0; batch classifier loss: 0.327502; batch adversarial loss: 0.589483\n",
      "epoch 33; iter: 200; batch classifier loss: 0.368539; batch adversarial loss: 0.696287\n",
      "epoch 34; iter: 0; batch classifier loss: 0.384931; batch adversarial loss: 0.636601\n",
      "epoch 34; iter: 200; batch classifier loss: 0.393166; batch adversarial loss: 0.627280\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337953; batch adversarial loss: 0.629774\n",
      "epoch 35; iter: 200; batch classifier loss: 0.282425; batch adversarial loss: 0.551386\n",
      "epoch 36; iter: 0; batch classifier loss: 0.377125; batch adversarial loss: 0.654806\n",
      "epoch 36; iter: 200; batch classifier loss: 0.305696; batch adversarial loss: 0.666960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395511; batch adversarial loss: 0.639291\n",
      "epoch 37; iter: 200; batch classifier loss: 0.342368; batch adversarial loss: 0.604234\n",
      "epoch 38; iter: 0; batch classifier loss: 0.422906; batch adversarial loss: 0.614435\n",
      "epoch 38; iter: 200; batch classifier loss: 0.321623; batch adversarial loss: 0.639447\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489590; batch adversarial loss: 0.619701\n",
      "epoch 39; iter: 200; batch classifier loss: 0.396319; batch adversarial loss: 0.606352\n",
      "epoch 40; iter: 0; batch classifier loss: 0.336994; batch adversarial loss: 0.620787\n",
      "epoch 40; iter: 200; batch classifier loss: 0.371421; batch adversarial loss: 0.616937\n",
      "epoch 41; iter: 0; batch classifier loss: 0.343387; batch adversarial loss: 0.580962\n",
      "epoch 41; iter: 200; batch classifier loss: 0.344843; batch adversarial loss: 0.668518\n",
      "epoch 42; iter: 0; batch classifier loss: 0.363859; batch adversarial loss: 0.608911\n",
      "epoch 42; iter: 200; batch classifier loss: 0.277932; batch adversarial loss: 0.638246\n",
      "epoch 43; iter: 0; batch classifier loss: 0.360058; batch adversarial loss: 0.616762\n",
      "epoch 43; iter: 200; batch classifier loss: 0.468477; batch adversarial loss: 0.636653\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490544; batch adversarial loss: 0.574743\n",
      "epoch 44; iter: 200; batch classifier loss: 0.352193; batch adversarial loss: 0.604409\n",
      "epoch 45; iter: 0; batch classifier loss: 0.550829; batch adversarial loss: 0.603012\n",
      "epoch 45; iter: 200; batch classifier loss: 0.336012; batch adversarial loss: 0.612070\n",
      "epoch 46; iter: 0; batch classifier loss: 0.701495; batch adversarial loss: 0.581333\n",
      "epoch 46; iter: 200; batch classifier loss: 0.412235; batch adversarial loss: 0.629514\n",
      "epoch 47; iter: 0; batch classifier loss: 0.234326; batch adversarial loss: 0.631865\n",
      "epoch 47; iter: 200; batch classifier loss: 0.302256; batch adversarial loss: 0.638420\n",
      "epoch 48; iter: 0; batch classifier loss: 0.381165; batch adversarial loss: 0.558931\n",
      "epoch 48; iter: 200; batch classifier loss: 0.244155; batch adversarial loss: 0.603410\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418312; batch adversarial loss: 0.630132\n",
      "epoch 49; iter: 200; batch classifier loss: 0.390168; batch adversarial loss: 0.628058\n",
      "epoch 0; iter: 0; batch classifier loss: 11.827085; batch adversarial loss: 0.655066\n",
      "epoch 0; iter: 200; batch classifier loss: 3.981789; batch adversarial loss: 0.673019\n",
      "epoch 1; iter: 0; batch classifier loss: 7.223438; batch adversarial loss: 0.649436\n",
      "epoch 1; iter: 200; batch classifier loss: 2.584151; batch adversarial loss: 0.629869\n",
      "epoch 2; iter: 0; batch classifier loss: 4.304646; batch adversarial loss: 0.652370\n",
      "epoch 2; iter: 200; batch classifier loss: 2.864884; batch adversarial loss: 0.637931\n",
      "epoch 3; iter: 0; batch classifier loss: 0.745908; batch adversarial loss: 0.616617\n",
      "epoch 3; iter: 200; batch classifier loss: 1.576778; batch adversarial loss: 0.607151\n",
      "epoch 4; iter: 0; batch classifier loss: 1.715276; batch adversarial loss: 0.647506\n",
      "epoch 4; iter: 200; batch classifier loss: 2.129308; batch adversarial loss: 0.652214\n",
      "epoch 5; iter: 0; batch classifier loss: 1.587660; batch adversarial loss: 0.600822\n",
      "epoch 5; iter: 200; batch classifier loss: 1.318299; batch adversarial loss: 0.610152\n",
      "epoch 6; iter: 0; batch classifier loss: 0.756846; batch adversarial loss: 0.614968\n",
      "epoch 6; iter: 200; batch classifier loss: 0.679690; batch adversarial loss: 0.553974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411840; batch adversarial loss: 0.576129\n",
      "epoch 7; iter: 200; batch classifier loss: 0.720168; batch adversarial loss: 0.651902\n",
      "epoch 8; iter: 0; batch classifier loss: 3.613791; batch adversarial loss: 0.646906\n",
      "epoch 8; iter: 200; batch classifier loss: 0.511670; batch adversarial loss: 0.634567\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453750; batch adversarial loss: 0.683619\n",
      "epoch 9; iter: 200; batch classifier loss: 0.731522; batch adversarial loss: 0.640566\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308327; batch adversarial loss: 0.643657\n",
      "epoch 10; iter: 200; batch classifier loss: 0.404371; batch adversarial loss: 0.637316\n",
      "epoch 11; iter: 0; batch classifier loss: 0.422293; batch adversarial loss: 0.597202\n",
      "epoch 11; iter: 200; batch classifier loss: 0.411291; batch adversarial loss: 0.628372\n",
      "epoch 12; iter: 0; batch classifier loss: 0.451423; batch adversarial loss: 0.615429\n",
      "epoch 12; iter: 200; batch classifier loss: 0.408095; batch adversarial loss: 0.669403\n",
      "epoch 13; iter: 0; batch classifier loss: 0.366304; batch adversarial loss: 0.646626\n",
      "epoch 13; iter: 200; batch classifier loss: 0.485587; batch adversarial loss: 0.587527\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322464; batch adversarial loss: 0.602817\n",
      "epoch 14; iter: 200; batch classifier loss: 0.337421; batch adversarial loss: 0.574925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348475; batch adversarial loss: 0.642141\n",
      "epoch 15; iter: 200; batch classifier loss: 0.337415; batch adversarial loss: 0.619981\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311580; batch adversarial loss: 0.616817\n",
      "epoch 16; iter: 200; batch classifier loss: 0.415583; batch adversarial loss: 0.645814\n",
      "epoch 17; iter: 0; batch classifier loss: 0.386191; batch adversarial loss: 0.650630\n",
      "epoch 17; iter: 200; batch classifier loss: 0.336966; batch adversarial loss: 0.625740\n",
      "epoch 18; iter: 0; batch classifier loss: 0.263983; batch adversarial loss: 0.576330\n",
      "epoch 18; iter: 200; batch classifier loss: 0.331901; batch adversarial loss: 0.597549\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425048; batch adversarial loss: 0.608588\n",
      "epoch 19; iter: 200; batch classifier loss: 0.273345; batch adversarial loss: 0.664332\n",
      "epoch 20; iter: 0; batch classifier loss: 0.405933; batch adversarial loss: 0.613684\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379187; batch adversarial loss: 0.605589\n",
      "epoch 21; iter: 0; batch classifier loss: 0.280901; batch adversarial loss: 0.604838\n",
      "epoch 21; iter: 200; batch classifier loss: 0.345632; batch adversarial loss: 0.577548\n",
      "epoch 22; iter: 0; batch classifier loss: 0.338993; batch adversarial loss: 0.592794\n",
      "epoch 22; iter: 200; batch classifier loss: 0.315684; batch adversarial loss: 0.627884\n",
      "epoch 23; iter: 0; batch classifier loss: 0.338747; batch adversarial loss: 0.597056\n",
      "epoch 23; iter: 200; batch classifier loss: 0.341405; batch adversarial loss: 0.635640\n",
      "epoch 24; iter: 0; batch classifier loss: 0.391665; batch adversarial loss: 0.559789\n",
      "epoch 24; iter: 200; batch classifier loss: 0.367267; batch adversarial loss: 0.719266\n",
      "epoch 25; iter: 0; batch classifier loss: 0.317028; batch adversarial loss: 0.607228\n",
      "epoch 25; iter: 200; batch classifier loss: 0.389459; batch adversarial loss: 0.570753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.324505; batch adversarial loss: 0.619430\n",
      "epoch 26; iter: 200; batch classifier loss: 0.373831; batch adversarial loss: 0.653188\n",
      "epoch 27; iter: 0; batch classifier loss: 0.256184; batch adversarial loss: 0.623369\n",
      "epoch 27; iter: 200; batch classifier loss: 0.344731; batch adversarial loss: 0.680076\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369489; batch adversarial loss: 0.669523\n",
      "epoch 28; iter: 200; batch classifier loss: 0.365960; batch adversarial loss: 0.662438\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358138; batch adversarial loss: 0.635732\n",
      "epoch 29; iter: 200; batch classifier loss: 0.394207; batch adversarial loss: 0.626374\n",
      "epoch 30; iter: 0; batch classifier loss: 0.344912; batch adversarial loss: 0.618804\n",
      "epoch 30; iter: 200; batch classifier loss: 0.375670; batch adversarial loss: 0.599555\n",
      "epoch 31; iter: 0; batch classifier loss: 0.383304; batch adversarial loss: 0.703408\n",
      "epoch 31; iter: 200; batch classifier loss: 0.375321; batch adversarial loss: 0.569629\n",
      "epoch 32; iter: 0; batch classifier loss: 0.269413; batch adversarial loss: 0.588117\n",
      "epoch 32; iter: 200; batch classifier loss: 0.278135; batch adversarial loss: 0.602310\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370560; batch adversarial loss: 0.647371\n",
      "epoch 33; iter: 200; batch classifier loss: 0.347134; batch adversarial loss: 0.626472\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431857; batch adversarial loss: 0.562536\n",
      "epoch 34; iter: 200; batch classifier loss: 0.465366; batch adversarial loss: 0.640154\n",
      "epoch 35; iter: 0; batch classifier loss: 0.409257; batch adversarial loss: 0.603256\n",
      "epoch 35; iter: 200; batch classifier loss: 0.402229; batch adversarial loss: 0.640973\n",
      "epoch 36; iter: 0; batch classifier loss: 0.320400; batch adversarial loss: 0.659292\n",
      "epoch 36; iter: 200; batch classifier loss: 0.404748; batch adversarial loss: 0.627679\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428514; batch adversarial loss: 0.633327\n",
      "epoch 37; iter: 200; batch classifier loss: 0.350810; batch adversarial loss: 0.705435\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359236; batch adversarial loss: 0.639588\n",
      "epoch 38; iter: 200; batch classifier loss: 0.373373; batch adversarial loss: 0.564731\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446436; batch adversarial loss: 0.620580\n",
      "epoch 39; iter: 200; batch classifier loss: 0.385991; batch adversarial loss: 0.587402\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381482; batch adversarial loss: 0.664191\n",
      "epoch 40; iter: 200; batch classifier loss: 0.317532; batch adversarial loss: 0.649567\n",
      "epoch 41; iter: 0; batch classifier loss: 0.300627; batch adversarial loss: 0.611099\n",
      "epoch 41; iter: 200; batch classifier loss: 0.379102; batch adversarial loss: 0.608999\n",
      "epoch 42; iter: 0; batch classifier loss: 0.324907; batch adversarial loss: 0.639646\n",
      "epoch 42; iter: 200; batch classifier loss: 0.377940; batch adversarial loss: 0.683469\n",
      "epoch 43; iter: 0; batch classifier loss: 0.420407; batch adversarial loss: 0.626094\n",
      "epoch 43; iter: 200; batch classifier loss: 0.362547; batch adversarial loss: 0.647224\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464159; batch adversarial loss: 0.580309\n",
      "epoch 44; iter: 200; batch classifier loss: 0.318567; batch adversarial loss: 0.595701\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449396; batch adversarial loss: 0.601502\n",
      "epoch 45; iter: 200; batch classifier loss: 0.328724; batch adversarial loss: 0.624254\n",
      "epoch 46; iter: 0; batch classifier loss: 0.449825; batch adversarial loss: 0.656210\n",
      "epoch 46; iter: 200; batch classifier loss: 0.383924; batch adversarial loss: 0.658549\n",
      "epoch 47; iter: 0; batch classifier loss: 0.345256; batch adversarial loss: 0.649895\n",
      "epoch 47; iter: 200; batch classifier loss: 0.274887; batch adversarial loss: 0.633958\n",
      "epoch 48; iter: 0; batch classifier loss: 0.362615; batch adversarial loss: 0.662573\n",
      "epoch 48; iter: 200; batch classifier loss: 0.489924; batch adversarial loss: 0.611197\n",
      "epoch 49; iter: 0; batch classifier loss: 0.340125; batch adversarial loss: 0.647962\n",
      "epoch 49; iter: 200; batch classifier loss: 0.398528; batch adversarial loss: 0.552649\n",
      "epoch 0; iter: 0; batch classifier loss: 21.002926; batch adversarial loss: 0.743276\n",
      "epoch 0; iter: 200; batch classifier loss: 5.283463; batch adversarial loss: 0.737054\n",
      "epoch 1; iter: 0; batch classifier loss: 11.852294; batch adversarial loss: 0.657188\n",
      "epoch 1; iter: 200; batch classifier loss: 5.876215; batch adversarial loss: 0.635625\n",
      "epoch 2; iter: 0; batch classifier loss: 24.280064; batch adversarial loss: 0.621626\n",
      "epoch 2; iter: 200; batch classifier loss: 4.089623; batch adversarial loss: 0.619483\n",
      "epoch 3; iter: 0; batch classifier loss: 1.523490; batch adversarial loss: 0.702555\n",
      "epoch 3; iter: 200; batch classifier loss: 2.102867; batch adversarial loss: 0.670667\n",
      "epoch 4; iter: 0; batch classifier loss: 2.319323; batch adversarial loss: 0.615136\n",
      "epoch 4; iter: 200; batch classifier loss: 1.207845; batch adversarial loss: 0.636398\n",
      "epoch 5; iter: 0; batch classifier loss: 1.268879; batch adversarial loss: 0.642620\n",
      "epoch 5; iter: 200; batch classifier loss: 0.712845; batch adversarial loss: 0.577014\n",
      "epoch 6; iter: 0; batch classifier loss: 1.893222; batch adversarial loss: 0.657159\n",
      "epoch 6; iter: 200; batch classifier loss: 1.538954; batch adversarial loss: 0.610037\n",
      "epoch 7; iter: 0; batch classifier loss: 1.336865; batch adversarial loss: 0.614038\n",
      "epoch 7; iter: 200; batch classifier loss: 0.543907; batch adversarial loss: 0.618878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.493354; batch adversarial loss: 0.690340\n",
      "epoch 8; iter: 200; batch classifier loss: 0.876288; batch adversarial loss: 0.620717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516958; batch adversarial loss: 0.630303\n",
      "epoch 9; iter: 200; batch classifier loss: 0.715712; batch adversarial loss: 0.632407\n",
      "epoch 10; iter: 0; batch classifier loss: 0.707703; batch adversarial loss: 0.604355\n",
      "epoch 10; iter: 200; batch classifier loss: 0.477345; batch adversarial loss: 0.600967\n",
      "epoch 11; iter: 0; batch classifier loss: 0.442186; batch adversarial loss: 0.586704\n",
      "epoch 11; iter: 200; batch classifier loss: 0.499182; batch adversarial loss: 0.547244\n",
      "epoch 12; iter: 0; batch classifier loss: 0.437456; batch adversarial loss: 0.644644\n",
      "epoch 12; iter: 200; batch classifier loss: 0.507116; batch adversarial loss: 0.575129\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384115; batch adversarial loss: 0.578230\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353781; batch adversarial loss: 0.702912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.426619; batch adversarial loss: 0.601553\n",
      "epoch 14; iter: 200; batch classifier loss: 0.380169; batch adversarial loss: 0.645304\n",
      "epoch 15; iter: 0; batch classifier loss: 0.459410; batch adversarial loss: 0.539751\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430386; batch adversarial loss: 0.585943\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536325; batch adversarial loss: 0.628171\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380983; batch adversarial loss: 0.638170\n",
      "epoch 17; iter: 0; batch classifier loss: 0.311245; batch adversarial loss: 0.650539\n",
      "epoch 17; iter: 200; batch classifier loss: 0.358595; batch adversarial loss: 0.629130\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370338; batch adversarial loss: 0.668885\n",
      "epoch 18; iter: 200; batch classifier loss: 0.340233; batch adversarial loss: 0.672620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350342; batch adversarial loss: 0.642198\n",
      "epoch 19; iter: 200; batch classifier loss: 0.371058; batch adversarial loss: 0.587446\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466509; batch adversarial loss: 0.596505\n",
      "epoch 20; iter: 200; batch classifier loss: 0.352829; batch adversarial loss: 0.557081\n",
      "epoch 21; iter: 0; batch classifier loss: 0.322400; batch adversarial loss: 0.653120\n",
      "epoch 21; iter: 200; batch classifier loss: 0.283500; batch adversarial loss: 0.661265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.408549; batch adversarial loss: 0.648091\n",
      "epoch 22; iter: 200; batch classifier loss: 0.240907; batch adversarial loss: 0.671964\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454140; batch adversarial loss: 0.589823\n",
      "epoch 23; iter: 200; batch classifier loss: 0.348498; batch adversarial loss: 0.624498\n",
      "epoch 24; iter: 0; batch classifier loss: 0.394069; batch adversarial loss: 0.614983\n",
      "epoch 24; iter: 200; batch classifier loss: 0.311839; batch adversarial loss: 0.628644\n",
      "epoch 25; iter: 0; batch classifier loss: 0.355249; batch adversarial loss: 0.656637\n",
      "epoch 25; iter: 200; batch classifier loss: 0.349142; batch adversarial loss: 0.630468\n",
      "epoch 26; iter: 0; batch classifier loss: 0.365029; batch adversarial loss: 0.647612\n",
      "epoch 26; iter: 200; batch classifier loss: 0.367725; batch adversarial loss: 0.643643\n",
      "epoch 27; iter: 0; batch classifier loss: 0.423540; batch adversarial loss: 0.547637\n",
      "epoch 27; iter: 200; batch classifier loss: 0.360722; batch adversarial loss: 0.578003\n",
      "epoch 28; iter: 0; batch classifier loss: 0.373825; batch adversarial loss: 0.617959\n",
      "epoch 28; iter: 200; batch classifier loss: 0.377993; batch adversarial loss: 0.664180\n",
      "epoch 29; iter: 0; batch classifier loss: 0.359960; batch adversarial loss: 0.600717\n",
      "epoch 29; iter: 200; batch classifier loss: 0.379405; batch adversarial loss: 0.678209\n",
      "epoch 30; iter: 0; batch classifier loss: 0.335484; batch adversarial loss: 0.535138\n",
      "epoch 30; iter: 200; batch classifier loss: 0.464489; batch adversarial loss: 0.570068\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320708; batch adversarial loss: 0.647148\n",
      "epoch 31; iter: 200; batch classifier loss: 0.353233; batch adversarial loss: 0.614160\n",
      "epoch 32; iter: 0; batch classifier loss: 0.402092; batch adversarial loss: 0.593343\n",
      "epoch 32; iter: 200; batch classifier loss: 0.405863; batch adversarial loss: 0.627023\n",
      "epoch 33; iter: 0; batch classifier loss: 0.282776; batch adversarial loss: 0.665062\n",
      "epoch 33; iter: 200; batch classifier loss: 0.378367; batch adversarial loss: 0.718692\n",
      "epoch 34; iter: 0; batch classifier loss: 0.307176; batch adversarial loss: 0.620733\n",
      "epoch 34; iter: 200; batch classifier loss: 0.306177; batch adversarial loss: 0.636663\n",
      "epoch 35; iter: 0; batch classifier loss: 0.408951; batch adversarial loss: 0.646526\n",
      "epoch 35; iter: 200; batch classifier loss: 0.264582; batch adversarial loss: 0.652178\n",
      "epoch 36; iter: 0; batch classifier loss: 0.226640; batch adversarial loss: 0.653616\n",
      "epoch 36; iter: 200; batch classifier loss: 0.380708; batch adversarial loss: 0.579546\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458162; batch adversarial loss: 0.642208\n",
      "epoch 37; iter: 200; batch classifier loss: 0.297035; batch adversarial loss: 0.655788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.269515; batch adversarial loss: 0.618092\n",
      "epoch 38; iter: 200; batch classifier loss: 0.315366; batch adversarial loss: 0.645309\n",
      "epoch 39; iter: 0; batch classifier loss: 0.308063; batch adversarial loss: 0.593071\n",
      "epoch 39; iter: 200; batch classifier loss: 0.291393; batch adversarial loss: 0.601196\n",
      "epoch 40; iter: 0; batch classifier loss: 0.269133; batch adversarial loss: 0.634137\n",
      "epoch 40; iter: 200; batch classifier loss: 0.511872; batch adversarial loss: 0.588748\n",
      "epoch 41; iter: 0; batch classifier loss: 0.392618; batch adversarial loss: 0.585119\n",
      "epoch 41; iter: 200; batch classifier loss: 0.337968; batch adversarial loss: 0.560668\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459585; batch adversarial loss: 0.613200\n",
      "epoch 42; iter: 200; batch classifier loss: 0.382816; batch adversarial loss: 0.601950\n",
      "epoch 43; iter: 0; batch classifier loss: 0.655252; batch adversarial loss: 0.678345\n",
      "epoch 43; iter: 200; batch classifier loss: 0.351489; batch adversarial loss: 0.617886\n",
      "epoch 44; iter: 0; batch classifier loss: 0.300826; batch adversarial loss: 0.595771\n",
      "epoch 44; iter: 200; batch classifier loss: 0.451975; batch adversarial loss: 0.617509\n",
      "epoch 45; iter: 0; batch classifier loss: 0.246105; batch adversarial loss: 0.640703\n",
      "epoch 45; iter: 200; batch classifier loss: 0.295049; batch adversarial loss: 0.636104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.351563; batch adversarial loss: 0.623295\n",
      "epoch 46; iter: 200; batch classifier loss: 0.447892; batch adversarial loss: 0.623334\n",
      "epoch 47; iter: 0; batch classifier loss: 0.360236; batch adversarial loss: 0.588213\n",
      "epoch 47; iter: 200; batch classifier loss: 0.403579; batch adversarial loss: 0.608902\n",
      "epoch 48; iter: 0; batch classifier loss: 0.309335; batch adversarial loss: 0.611191\n",
      "epoch 48; iter: 200; batch classifier loss: 0.330323; batch adversarial loss: 0.627896\n",
      "epoch 49; iter: 0; batch classifier loss: 0.336252; batch adversarial loss: 0.650653\n",
      "epoch 49; iter: 200; batch classifier loss: 0.261153; batch adversarial loss: 0.620934\n",
      "epoch 0; iter: 0; batch classifier loss: 133.891418; batch adversarial loss: 0.704137\n",
      "epoch 0; iter: 200; batch classifier loss: 38.245342; batch adversarial loss: 0.711692\n",
      "epoch 1; iter: 0; batch classifier loss: 13.725320; batch adversarial loss: 0.711080\n",
      "epoch 1; iter: 200; batch classifier loss: 14.082077; batch adversarial loss: 0.728262\n",
      "epoch 2; iter: 0; batch classifier loss: 8.657731; batch adversarial loss: 0.700463\n",
      "epoch 2; iter: 200; batch classifier loss: 3.648063; batch adversarial loss: 0.647970\n",
      "epoch 3; iter: 0; batch classifier loss: 5.255121; batch adversarial loss: 0.637870\n",
      "epoch 3; iter: 200; batch classifier loss: 2.040262; batch adversarial loss: 0.629469\n",
      "epoch 4; iter: 0; batch classifier loss: 0.982361; batch adversarial loss: 0.664557\n",
      "epoch 4; iter: 200; batch classifier loss: 0.508966; batch adversarial loss: 0.673233\n",
      "epoch 5; iter: 0; batch classifier loss: 1.240014; batch adversarial loss: 0.629503\n",
      "epoch 5; iter: 200; batch classifier loss: 1.634254; batch adversarial loss: 0.645097\n",
      "epoch 6; iter: 0; batch classifier loss: 1.067577; batch adversarial loss: 0.617877\n",
      "epoch 6; iter: 200; batch classifier loss: 1.267459; batch adversarial loss: 0.625001\n",
      "epoch 7; iter: 0; batch classifier loss: 1.057174; batch adversarial loss: 0.667694\n",
      "epoch 7; iter: 200; batch classifier loss: 0.946609; batch adversarial loss: 0.609672\n",
      "epoch 8; iter: 0; batch classifier loss: 0.957680; batch adversarial loss: 0.671793\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401770; batch adversarial loss: 0.648077\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332147; batch adversarial loss: 0.605549\n",
      "epoch 9; iter: 200; batch classifier loss: 0.633015; batch adversarial loss: 0.610436\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446767; batch adversarial loss: 0.636550\n",
      "epoch 10; iter: 200; batch classifier loss: 0.372526; batch adversarial loss: 0.634036\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420880; batch adversarial loss: 0.659594\n",
      "epoch 11; iter: 200; batch classifier loss: 0.619750; batch adversarial loss: 0.612805\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404467; batch adversarial loss: 0.567471\n",
      "epoch 12; iter: 200; batch classifier loss: 0.410665; batch adversarial loss: 0.667280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419361; batch adversarial loss: 0.654273\n",
      "epoch 13; iter: 200; batch classifier loss: 0.413912; batch adversarial loss: 0.630844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352222; batch adversarial loss: 0.633515\n",
      "epoch 14; iter: 200; batch classifier loss: 0.294276; batch adversarial loss: 0.653226\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458084; batch adversarial loss: 0.628599\n",
      "epoch 15; iter: 200; batch classifier loss: 0.361537; batch adversarial loss: 0.676095\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418890; batch adversarial loss: 0.644683\n",
      "epoch 16; iter: 200; batch classifier loss: 0.364368; batch adversarial loss: 0.630385\n",
      "epoch 17; iter: 0; batch classifier loss: 0.343389; batch adversarial loss: 0.627318\n",
      "epoch 17; iter: 200; batch classifier loss: 0.299298; batch adversarial loss: 0.600795\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354925; batch adversarial loss: 0.640102\n",
      "epoch 18; iter: 200; batch classifier loss: 0.317097; batch adversarial loss: 0.649502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354243; batch adversarial loss: 0.582815\n",
      "epoch 19; iter: 200; batch classifier loss: 0.328308; batch adversarial loss: 0.675683\n",
      "epoch 20; iter: 0; batch classifier loss: 0.310158; batch adversarial loss: 0.593243\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368647; batch adversarial loss: 0.606691\n",
      "epoch 21; iter: 0; batch classifier loss: 0.294318; batch adversarial loss: 0.626075\n",
      "epoch 21; iter: 200; batch classifier loss: 0.268380; batch adversarial loss: 0.636538\n",
      "epoch 22; iter: 0; batch classifier loss: 0.416016; batch adversarial loss: 0.593966\n",
      "epoch 22; iter: 200; batch classifier loss: 0.305164; batch adversarial loss: 0.623825\n",
      "epoch 23; iter: 0; batch classifier loss: 0.352092; batch adversarial loss: 0.655433\n",
      "epoch 23; iter: 200; batch classifier loss: 0.353852; batch adversarial loss: 0.588145\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565257; batch adversarial loss: 0.647921\n",
      "epoch 24; iter: 200; batch classifier loss: 0.369476; batch adversarial loss: 0.585446\n",
      "epoch 25; iter: 0; batch classifier loss: 0.386149; batch adversarial loss: 0.650208\n",
      "epoch 25; iter: 200; batch classifier loss: 0.359353; batch adversarial loss: 0.591942\n",
      "epoch 26; iter: 0; batch classifier loss: 0.408897; batch adversarial loss: 0.653368\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336506; batch adversarial loss: 0.603168\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414038; batch adversarial loss: 0.586429\n",
      "epoch 27; iter: 200; batch classifier loss: 0.413503; batch adversarial loss: 0.593939\n",
      "epoch 28; iter: 0; batch classifier loss: 0.349250; batch adversarial loss: 0.620047\n",
      "epoch 28; iter: 200; batch classifier loss: 0.315477; batch adversarial loss: 0.602378\n",
      "epoch 29; iter: 0; batch classifier loss: 0.242802; batch adversarial loss: 0.657695\n",
      "epoch 29; iter: 200; batch classifier loss: 0.380762; batch adversarial loss: 0.630102\n",
      "epoch 30; iter: 0; batch classifier loss: 0.279597; batch adversarial loss: 0.578483\n",
      "epoch 30; iter: 200; batch classifier loss: 0.420692; batch adversarial loss: 0.656471\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334649; batch adversarial loss: 0.632439\n",
      "epoch 31; iter: 200; batch classifier loss: 0.313092; batch adversarial loss: 0.679388\n",
      "epoch 32; iter: 0; batch classifier loss: 0.305096; batch adversarial loss: 0.594146\n",
      "epoch 32; iter: 200; batch classifier loss: 0.514520; batch adversarial loss: 0.619424\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452715; batch adversarial loss: 0.606977\n",
      "epoch 33; iter: 200; batch classifier loss: 0.350791; batch adversarial loss: 0.628799\n",
      "epoch 34; iter: 0; batch classifier loss: 0.304550; batch adversarial loss: 0.640501\n",
      "epoch 34; iter: 200; batch classifier loss: 0.429880; batch adversarial loss: 0.608604\n",
      "epoch 35; iter: 0; batch classifier loss: 0.291768; batch adversarial loss: 0.576463\n",
      "epoch 35; iter: 200; batch classifier loss: 0.343427; batch adversarial loss: 0.653827\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373362; batch adversarial loss: 0.634140\n",
      "epoch 36; iter: 200; batch classifier loss: 0.295177; batch adversarial loss: 0.624466\n",
      "epoch 37; iter: 0; batch classifier loss: 0.354239; batch adversarial loss: 0.637836\n",
      "epoch 37; iter: 200; batch classifier loss: 0.363668; batch adversarial loss: 0.586382\n",
      "epoch 38; iter: 0; batch classifier loss: 0.357457; batch adversarial loss: 0.615957\n",
      "epoch 38; iter: 200; batch classifier loss: 0.278044; batch adversarial loss: 0.574212\n",
      "epoch 39; iter: 0; batch classifier loss: 0.306275; batch adversarial loss: 0.611200\n",
      "epoch 39; iter: 200; batch classifier loss: 0.352239; batch adversarial loss: 0.621399\n",
      "epoch 40; iter: 0; batch classifier loss: 0.248887; batch adversarial loss: 0.638731\n",
      "epoch 40; iter: 200; batch classifier loss: 0.344057; batch adversarial loss: 0.603355\n",
      "epoch 41; iter: 0; batch classifier loss: 0.326387; batch adversarial loss: 0.625763\n",
      "epoch 41; iter: 200; batch classifier loss: 0.342907; batch adversarial loss: 0.630170\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247955; batch adversarial loss: 0.625911\n",
      "epoch 42; iter: 200; batch classifier loss: 0.364832; batch adversarial loss: 0.615490\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328123; batch adversarial loss: 0.556441\n",
      "epoch 43; iter: 200; batch classifier loss: 0.365357; batch adversarial loss: 0.642132\n",
      "epoch 44; iter: 0; batch classifier loss: 0.292829; batch adversarial loss: 0.647032\n",
      "epoch 44; iter: 200; batch classifier loss: 0.358602; batch adversarial loss: 0.631759\n",
      "epoch 45; iter: 0; batch classifier loss: 0.409547; batch adversarial loss: 0.648727\n",
      "epoch 45; iter: 200; batch classifier loss: 0.406969; batch adversarial loss: 0.619230\n",
      "epoch 46; iter: 0; batch classifier loss: 0.414570; batch adversarial loss: 0.621107\n",
      "epoch 46; iter: 200; batch classifier loss: 0.292092; batch adversarial loss: 0.588746\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325448; batch adversarial loss: 0.634817\n",
      "epoch 47; iter: 200; batch classifier loss: 0.276276; batch adversarial loss: 0.620279\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416045; batch adversarial loss: 0.572442\n",
      "epoch 48; iter: 200; batch classifier loss: 0.398094; batch adversarial loss: 0.667560\n",
      "epoch 49; iter: 0; batch classifier loss: 0.414949; batch adversarial loss: 0.606676\n",
      "epoch 49; iter: 200; batch classifier loss: 0.302103; batch adversarial loss: 0.585743\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 8.534068; batch adversarial loss: 0.636385\n",
      "epoch 0; iter: 200; batch classifier loss: 6.888056; batch adversarial loss: 0.671826\n",
      "epoch 0; iter: 400; batch classifier loss: 7.127074; batch adversarial loss: 0.637712\n",
      "epoch 1; iter: 0; batch classifier loss: 22.083420; batch adversarial loss: 0.592065\n",
      "epoch 1; iter: 200; batch classifier loss: 2.847230; batch adversarial loss: 0.636365\n",
      "epoch 1; iter: 400; batch classifier loss: 6.759041; batch adversarial loss: 0.676528\n",
      "epoch 2; iter: 0; batch classifier loss: 14.933527; batch adversarial loss: 0.598453\n",
      "epoch 2; iter: 200; batch classifier loss: 1.000746; batch adversarial loss: 0.542941\n",
      "epoch 2; iter: 400; batch classifier loss: 3.409456; batch adversarial loss: 0.661139\n",
      "epoch 3; iter: 0; batch classifier loss: 0.790132; batch adversarial loss: 0.676944\n",
      "epoch 3; iter: 200; batch classifier loss: 1.393125; batch adversarial loss: 0.614331\n",
      "epoch 3; iter: 400; batch classifier loss: 1.078140; batch adversarial loss: 0.596115\n",
      "epoch 4; iter: 0; batch classifier loss: 0.357645; batch adversarial loss: 0.574867\n",
      "epoch 4; iter: 200; batch classifier loss: 0.335221; batch adversarial loss: 0.718008\n",
      "epoch 4; iter: 400; batch classifier loss: 1.367415; batch adversarial loss: 0.606822\n",
      "epoch 5; iter: 0; batch classifier loss: 0.700621; batch adversarial loss: 0.697518\n",
      "epoch 5; iter: 200; batch classifier loss: 0.443543; batch adversarial loss: 0.575087\n",
      "epoch 5; iter: 400; batch classifier loss: 0.466018; batch adversarial loss: 0.617395\n",
      "epoch 6; iter: 0; batch classifier loss: 0.360021; batch adversarial loss: 0.559960\n",
      "epoch 6; iter: 200; batch classifier loss: 0.478912; batch adversarial loss: 0.643788\n",
      "epoch 6; iter: 400; batch classifier loss: 0.449556; batch adversarial loss: 0.566063\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418006; batch adversarial loss: 0.659385\n",
      "epoch 7; iter: 200; batch classifier loss: 0.195127; batch adversarial loss: 0.681688\n",
      "epoch 7; iter: 400; batch classifier loss: 0.376558; batch adversarial loss: 0.593055\n",
      "epoch 8; iter: 0; batch classifier loss: 0.281937; batch adversarial loss: 0.614356\n",
      "epoch 8; iter: 200; batch classifier loss: 0.356040; batch adversarial loss: 0.579618\n",
      "epoch 8; iter: 400; batch classifier loss: 0.525586; batch adversarial loss: 0.594083\n",
      "epoch 9; iter: 0; batch classifier loss: 0.459818; batch adversarial loss: 0.611536\n",
      "epoch 9; iter: 200; batch classifier loss: 0.346121; batch adversarial loss: 0.637890\n",
      "epoch 9; iter: 400; batch classifier loss: 0.381599; batch adversarial loss: 0.593422\n",
      "epoch 0; iter: 0; batch classifier loss: 40.548618; batch adversarial loss: 0.693236\n",
      "epoch 0; iter: 200; batch classifier loss: 13.518926; batch adversarial loss: 0.663627\n",
      "epoch 0; iter: 400; batch classifier loss: 6.145363; batch adversarial loss: 0.638553\n",
      "epoch 1; iter: 0; batch classifier loss: 3.056608; batch adversarial loss: 0.605277\n",
      "epoch 1; iter: 200; batch classifier loss: 0.292394; batch adversarial loss: 0.601013\n",
      "epoch 1; iter: 400; batch classifier loss: 0.906147; batch adversarial loss: 0.647184\n",
      "epoch 2; iter: 0; batch classifier loss: 1.449179; batch adversarial loss: 0.531875\n",
      "epoch 2; iter: 200; batch classifier loss: 1.953858; batch adversarial loss: 0.657742\n",
      "epoch 2; iter: 400; batch classifier loss: 1.850063; batch adversarial loss: 0.494965\n",
      "epoch 3; iter: 0; batch classifier loss: 0.350622; batch adversarial loss: 0.648314\n",
      "epoch 3; iter: 200; batch classifier loss: 0.927035; batch adversarial loss: 0.650635\n",
      "epoch 3; iter: 400; batch classifier loss: 4.322256; batch adversarial loss: 0.612235\n",
      "epoch 4; iter: 0; batch classifier loss: 0.471108; batch adversarial loss: 0.587901\n",
      "epoch 4; iter: 200; batch classifier loss: 0.311078; batch adversarial loss: 0.671075\n",
      "epoch 4; iter: 400; batch classifier loss: 1.640713; batch adversarial loss: 0.646019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.293590; batch adversarial loss: 0.617992\n",
      "epoch 5; iter: 200; batch classifier loss: 0.763650; batch adversarial loss: 0.591775\n",
      "epoch 5; iter: 400; batch classifier loss: 0.858469; batch adversarial loss: 0.572923\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393133; batch adversarial loss: 0.594684\n",
      "epoch 6; iter: 200; batch classifier loss: 0.506543; batch adversarial loss: 0.614147\n",
      "epoch 6; iter: 400; batch classifier loss: 0.309832; batch adversarial loss: 0.542494\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562210; batch adversarial loss: 0.631411\n",
      "epoch 7; iter: 200; batch classifier loss: 0.349708; batch adversarial loss: 0.627137\n",
      "epoch 7; iter: 400; batch classifier loss: 0.328645; batch adversarial loss: 0.686240\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479025; batch adversarial loss: 0.687407\n",
      "epoch 8; iter: 200; batch classifier loss: 0.477065; batch adversarial loss: 0.649282\n",
      "epoch 8; iter: 400; batch classifier loss: 0.420741; batch adversarial loss: 0.699646\n",
      "epoch 9; iter: 0; batch classifier loss: 0.304233; batch adversarial loss: 0.646538\n",
      "epoch 9; iter: 200; batch classifier loss: 1.594034; batch adversarial loss: 0.695924\n",
      "epoch 9; iter: 400; batch classifier loss: 0.517483; batch adversarial loss: 0.647714\n",
      "epoch 0; iter: 0; batch classifier loss: 49.607731; batch adversarial loss: 0.693324\n",
      "epoch 0; iter: 200; batch classifier loss: 1.780145; batch adversarial loss: 0.662931\n",
      "epoch 0; iter: 400; batch classifier loss: 7.734569; batch adversarial loss: 0.618899\n",
      "epoch 1; iter: 0; batch classifier loss: 7.782095; batch adversarial loss: 0.614898\n",
      "epoch 1; iter: 200; batch classifier loss: 4.066439; batch adversarial loss: 0.615655\n",
      "epoch 1; iter: 400; batch classifier loss: 2.143723; batch adversarial loss: 0.649650\n",
      "epoch 2; iter: 0; batch classifier loss: 1.768210; batch adversarial loss: 0.619724\n",
      "epoch 2; iter: 200; batch classifier loss: 6.881929; batch adversarial loss: 0.656768\n",
      "epoch 2; iter: 400; batch classifier loss: 4.480167; batch adversarial loss: 0.575374\n",
      "epoch 3; iter: 0; batch classifier loss: 1.673132; batch adversarial loss: 0.608396\n",
      "epoch 3; iter: 200; batch classifier loss: 1.584624; batch adversarial loss: 0.650910\n",
      "epoch 3; iter: 400; batch classifier loss: 0.915146; batch adversarial loss: 0.634436\n",
      "epoch 4; iter: 0; batch classifier loss: 1.205550; batch adversarial loss: 0.560955\n",
      "epoch 4; iter: 200; batch classifier loss: 1.384874; batch adversarial loss: 0.667455\n",
      "epoch 4; iter: 400; batch classifier loss: 2.987248; batch adversarial loss: 0.638595\n",
      "epoch 5; iter: 0; batch classifier loss: 0.748728; batch adversarial loss: 0.516616\n",
      "epoch 5; iter: 200; batch classifier loss: 1.226816; batch adversarial loss: 0.670568\n",
      "epoch 5; iter: 400; batch classifier loss: 0.428308; batch adversarial loss: 0.586001\n",
      "epoch 6; iter: 0; batch classifier loss: 0.436298; batch adversarial loss: 0.645588\n",
      "epoch 6; iter: 200; batch classifier loss: 1.144437; batch adversarial loss: 0.632623\n",
      "epoch 6; iter: 400; batch classifier loss: 1.573138; batch adversarial loss: 0.602920\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418678; batch adversarial loss: 0.639093\n",
      "epoch 7; iter: 200; batch classifier loss: 0.350127; batch adversarial loss: 0.686540\n",
      "epoch 7; iter: 400; batch classifier loss: 0.429228; batch adversarial loss: 0.589473\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541313; batch adversarial loss: 0.597171\n",
      "epoch 8; iter: 200; batch classifier loss: 0.480997; batch adversarial loss: 0.625284\n",
      "epoch 8; iter: 400; batch classifier loss: 0.393483; batch adversarial loss: 0.586659\n",
      "epoch 9; iter: 0; batch classifier loss: 0.593853; batch adversarial loss: 0.684692\n",
      "epoch 9; iter: 200; batch classifier loss: 0.468496; batch adversarial loss: 0.615051\n",
      "epoch 9; iter: 400; batch classifier loss: 0.277476; batch adversarial loss: 0.729095\n",
      "epoch 0; iter: 0; batch classifier loss: 3.993253; batch adversarial loss: 0.914674\n",
      "epoch 0; iter: 200; batch classifier loss: 10.058047; batch adversarial loss: 0.713213\n",
      "epoch 0; iter: 400; batch classifier loss: 2.854925; batch adversarial loss: 0.675559\n",
      "epoch 1; iter: 0; batch classifier loss: 1.712618; batch adversarial loss: 0.649861\n",
      "epoch 1; iter: 200; batch classifier loss: 2.761564; batch adversarial loss: 0.672510\n",
      "epoch 1; iter: 400; batch classifier loss: 1.543103; batch adversarial loss: 0.605637\n",
      "epoch 2; iter: 0; batch classifier loss: 0.552913; batch adversarial loss: 0.668433\n",
      "epoch 2; iter: 200; batch classifier loss: 6.285689; batch adversarial loss: 0.638176\n",
      "epoch 2; iter: 400; batch classifier loss: 1.362274; batch adversarial loss: 0.652992\n",
      "epoch 3; iter: 0; batch classifier loss: 0.351399; batch adversarial loss: 0.615798\n",
      "epoch 3; iter: 200; batch classifier loss: 1.330811; batch adversarial loss: 0.619979\n",
      "epoch 3; iter: 400; batch classifier loss: 2.080465; batch adversarial loss: 0.574501\n",
      "epoch 4; iter: 0; batch classifier loss: 0.438933; batch adversarial loss: 0.589525\n",
      "epoch 4; iter: 200; batch classifier loss: 0.522182; batch adversarial loss: 0.659896\n",
      "epoch 4; iter: 400; batch classifier loss: 2.020732; batch adversarial loss: 0.585592\n",
      "epoch 5; iter: 0; batch classifier loss: 0.429829; batch adversarial loss: 0.612997\n",
      "epoch 5; iter: 200; batch classifier loss: 0.469518; batch adversarial loss: 0.633344\n",
      "epoch 5; iter: 400; batch classifier loss: 0.683425; batch adversarial loss: 0.570119\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515247; batch adversarial loss: 0.675661\n",
      "epoch 6; iter: 200; batch classifier loss: 0.495633; batch adversarial loss: 0.572624\n",
      "epoch 6; iter: 400; batch classifier loss: 0.496073; batch adversarial loss: 0.753134\n",
      "epoch 7; iter: 0; batch classifier loss: 0.345763; batch adversarial loss: 0.664655\n",
      "epoch 7; iter: 200; batch classifier loss: 0.372818; batch adversarial loss: 0.635304\n",
      "epoch 7; iter: 400; batch classifier loss: 0.431371; batch adversarial loss: 0.636766\n",
      "epoch 8; iter: 0; batch classifier loss: 0.326425; batch adversarial loss: 0.615055\n",
      "epoch 8; iter: 200; batch classifier loss: 0.281908; batch adversarial loss: 0.657918\n",
      "epoch 8; iter: 400; batch classifier loss: 0.525660; batch adversarial loss: 0.666985\n",
      "epoch 9; iter: 0; batch classifier loss: 0.671426; batch adversarial loss: 0.530816\n",
      "epoch 9; iter: 200; batch classifier loss: 0.361178; batch adversarial loss: 0.641282\n",
      "epoch 9; iter: 400; batch classifier loss: 0.362887; batch adversarial loss: 0.669158\n",
      "epoch 0; iter: 0; batch classifier loss: 128.782516; batch adversarial loss: 0.938909\n",
      "epoch 0; iter: 200; batch classifier loss: 8.847481; batch adversarial loss: 0.686876\n",
      "epoch 0; iter: 400; batch classifier loss: 0.384797; batch adversarial loss: 0.664578\n",
      "epoch 1; iter: 0; batch classifier loss: 0.512037; batch adversarial loss: 0.629554\n",
      "epoch 1; iter: 200; batch classifier loss: 1.963671; batch adversarial loss: 0.635470\n",
      "epoch 1; iter: 400; batch classifier loss: 2.034081; batch adversarial loss: 0.660300\n",
      "epoch 2; iter: 0; batch classifier loss: 1.451700; batch adversarial loss: 0.610727\n",
      "epoch 2; iter: 200; batch classifier loss: 4.556805; batch adversarial loss: 0.658411\n",
      "epoch 2; iter: 400; batch classifier loss: 1.334783; batch adversarial loss: 0.595922\n",
      "epoch 3; iter: 0; batch classifier loss: 2.130605; batch adversarial loss: 0.579086\n",
      "epoch 3; iter: 200; batch classifier loss: 0.548015; batch adversarial loss: 0.635048\n",
      "epoch 3; iter: 400; batch classifier loss: 2.018795; batch adversarial loss: 0.617156\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545156; batch adversarial loss: 0.658599\n",
      "epoch 4; iter: 200; batch classifier loss: 1.979953; batch adversarial loss: 0.595157\n",
      "epoch 4; iter: 400; batch classifier loss: 0.453539; batch adversarial loss: 0.605992\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614243; batch adversarial loss: 0.696346\n",
      "epoch 5; iter: 200; batch classifier loss: 0.866970; batch adversarial loss: 0.564326\n",
      "epoch 5; iter: 400; batch classifier loss: 0.514905; batch adversarial loss: 0.546248\n",
      "epoch 6; iter: 0; batch classifier loss: 0.286039; batch adversarial loss: 0.628764\n",
      "epoch 6; iter: 200; batch classifier loss: 0.626262; batch adversarial loss: 0.610314\n",
      "epoch 6; iter: 400; batch classifier loss: 0.204799; batch adversarial loss: 0.571884\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392005; batch adversarial loss: 0.668677\n",
      "epoch 7; iter: 200; batch classifier loss: 0.391227; batch adversarial loss: 0.636938\n",
      "epoch 7; iter: 400; batch classifier loss: 0.406145; batch adversarial loss: 0.613419\n",
      "epoch 8; iter: 0; batch classifier loss: 1.481139; batch adversarial loss: 0.593091\n",
      "epoch 8; iter: 200; batch classifier loss: 0.302285; batch adversarial loss: 0.668464\n",
      "epoch 8; iter: 400; batch classifier loss: 0.561264; batch adversarial loss: 0.583330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398699; batch adversarial loss: 0.618245\n",
      "epoch 9; iter: 200; batch classifier loss: 0.331142; batch adversarial loss: 0.706963\n",
      "epoch 9; iter: 400; batch classifier loss: 0.557690; batch adversarial loss: 0.573845\n",
      "epoch 0; iter: 0; batch classifier loss: 18.648647; batch adversarial loss: 0.787913\n",
      "epoch 0; iter: 200; batch classifier loss: 16.856947; batch adversarial loss: 0.652315\n",
      "epoch 0; iter: 400; batch classifier loss: 5.033772; batch adversarial loss: 0.660101\n",
      "epoch 1; iter: 0; batch classifier loss: 1.445603; batch adversarial loss: 0.690945\n",
      "epoch 1; iter: 200; batch classifier loss: 1.486498; batch adversarial loss: 0.632085\n",
      "epoch 1; iter: 400; batch classifier loss: 0.476635; batch adversarial loss: 0.609181\n",
      "epoch 2; iter: 0; batch classifier loss: 0.784516; batch adversarial loss: 0.694026\n",
      "epoch 2; iter: 200; batch classifier loss: 5.319013; batch adversarial loss: 0.612789\n",
      "epoch 2; iter: 400; batch classifier loss: 1.201344; batch adversarial loss: 0.657790\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616394; batch adversarial loss: 0.566814\n",
      "epoch 3; iter: 200; batch classifier loss: 3.154199; batch adversarial loss: 0.583998\n",
      "epoch 3; iter: 400; batch classifier loss: 1.015734; batch adversarial loss: 0.591440\n",
      "epoch 4; iter: 0; batch classifier loss: 0.433302; batch adversarial loss: 0.614918\n",
      "epoch 4; iter: 200; batch classifier loss: 2.043797; batch adversarial loss: 0.616509\n",
      "epoch 4; iter: 400; batch classifier loss: 0.549129; batch adversarial loss: 0.648162\n",
      "epoch 5; iter: 0; batch classifier loss: 0.799274; batch adversarial loss: 0.631965\n",
      "epoch 5; iter: 200; batch classifier loss: 0.824897; batch adversarial loss: 0.724726\n",
      "epoch 5; iter: 400; batch classifier loss: 0.573254; batch adversarial loss: 0.649644\n",
      "epoch 6; iter: 0; batch classifier loss: 0.289802; batch adversarial loss: 0.663368\n",
      "epoch 6; iter: 200; batch classifier loss: 0.440688; batch adversarial loss: 0.653537\n",
      "epoch 6; iter: 400; batch classifier loss: 0.304204; batch adversarial loss: 0.654386\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565110; batch adversarial loss: 0.663508\n",
      "epoch 7; iter: 200; batch classifier loss: 0.359911; batch adversarial loss: 0.564247\n",
      "epoch 7; iter: 400; batch classifier loss: 0.375402; batch adversarial loss: 0.636730\n",
      "epoch 8; iter: 0; batch classifier loss: 0.355687; batch adversarial loss: 0.558909\n",
      "epoch 8; iter: 200; batch classifier loss: 0.443655; batch adversarial loss: 0.576258\n",
      "epoch 8; iter: 400; batch classifier loss: 0.266152; batch adversarial loss: 0.590120\n",
      "epoch 9; iter: 0; batch classifier loss: 0.350864; batch adversarial loss: 0.613145\n",
      "epoch 9; iter: 200; batch classifier loss: 0.268098; batch adversarial loss: 0.625975\n",
      "epoch 9; iter: 400; batch classifier loss: 0.336631; batch adversarial loss: 0.633632\n",
      "epoch 0; iter: 0; batch classifier loss: 269.649048; batch adversarial loss: 0.676442\n",
      "epoch 0; iter: 200; batch classifier loss: 14.071400; batch adversarial loss: 0.647055\n",
      "epoch 0; iter: 400; batch classifier loss: 7.005700; batch adversarial loss: 0.614433\n",
      "epoch 1; iter: 0; batch classifier loss: 1.160583; batch adversarial loss: 0.651520\n",
      "epoch 1; iter: 200; batch classifier loss: 7.916539; batch adversarial loss: 0.596952\n",
      "epoch 1; iter: 400; batch classifier loss: 2.694310; batch adversarial loss: 0.631322\n",
      "epoch 2; iter: 0; batch classifier loss: 5.741279; batch adversarial loss: 0.615282\n",
      "epoch 2; iter: 200; batch classifier loss: 2.125946; batch adversarial loss: 0.637400\n",
      "epoch 2; iter: 400; batch classifier loss: 1.051968; batch adversarial loss: 0.681766\n",
      "epoch 3; iter: 0; batch classifier loss: 3.833779; batch adversarial loss: 0.663585\n",
      "epoch 3; iter: 200; batch classifier loss: 0.501617; batch adversarial loss: 0.630427\n",
      "epoch 3; iter: 400; batch classifier loss: 0.433973; batch adversarial loss: 0.546181\n",
      "epoch 4; iter: 0; batch classifier loss: 0.214109; batch adversarial loss: 0.587909\n",
      "epoch 4; iter: 200; batch classifier loss: 1.804628; batch adversarial loss: 0.531751\n",
      "epoch 4; iter: 400; batch classifier loss: 1.087891; batch adversarial loss: 0.651481\n",
      "epoch 5; iter: 0; batch classifier loss: 1.254793; batch adversarial loss: 0.684440\n",
      "epoch 5; iter: 200; batch classifier loss: 0.606049; batch adversarial loss: 0.551209\n",
      "epoch 5; iter: 400; batch classifier loss: 0.387500; batch adversarial loss: 0.685323\n",
      "epoch 6; iter: 0; batch classifier loss: 1.144532; batch adversarial loss: 0.604832\n",
      "epoch 6; iter: 200; batch classifier loss: 0.733136; batch adversarial loss: 0.534969\n",
      "epoch 6; iter: 400; batch classifier loss: 0.579721; batch adversarial loss: 0.684306\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545789; batch adversarial loss: 0.659644\n",
      "epoch 7; iter: 200; batch classifier loss: 0.733964; batch adversarial loss: 0.650596\n",
      "epoch 7; iter: 400; batch classifier loss: 0.450414; batch adversarial loss: 0.629819\n",
      "epoch 8; iter: 0; batch classifier loss: 0.393624; batch adversarial loss: 0.602226\n",
      "epoch 8; iter: 200; batch classifier loss: 0.597015; batch adversarial loss: 0.587270\n",
      "epoch 8; iter: 400; batch classifier loss: 0.769029; batch adversarial loss: 0.581545\n",
      "epoch 9; iter: 0; batch classifier loss: 0.524311; batch adversarial loss: 0.700536\n",
      "epoch 9; iter: 200; batch classifier loss: 0.247695; batch adversarial loss: 0.667471\n",
      "epoch 9; iter: 400; batch classifier loss: 3.158444; batch adversarial loss: 0.567424\n",
      "epoch 0; iter: 0; batch classifier loss: 163.128494; batch adversarial loss: 0.749585\n",
      "epoch 0; iter: 200; batch classifier loss: 1.630746; batch adversarial loss: 0.655120\n",
      "epoch 0; iter: 400; batch classifier loss: 4.765821; batch adversarial loss: 0.673116\n",
      "epoch 1; iter: 0; batch classifier loss: 1.972542; batch adversarial loss: 0.659695\n",
      "epoch 1; iter: 200; batch classifier loss: 4.662673; batch adversarial loss: 0.746357\n",
      "epoch 1; iter: 400; batch classifier loss: 5.266928; batch adversarial loss: 0.604615\n",
      "epoch 2; iter: 0; batch classifier loss: 0.664705; batch adversarial loss: 0.626570\n",
      "epoch 2; iter: 200; batch classifier loss: 1.906417; batch adversarial loss: 0.625375\n",
      "epoch 2; iter: 400; batch classifier loss: 2.154411; batch adversarial loss: 0.618098\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573098; batch adversarial loss: 0.567963\n",
      "epoch 3; iter: 200; batch classifier loss: 2.696758; batch adversarial loss: 0.552691\n",
      "epoch 3; iter: 400; batch classifier loss: 2.255027; batch adversarial loss: 0.591894\n",
      "epoch 4; iter: 0; batch classifier loss: 1.848837; batch adversarial loss: 0.682122\n",
      "epoch 4; iter: 200; batch classifier loss: 0.504760; batch adversarial loss: 0.593976\n",
      "epoch 4; iter: 400; batch classifier loss: 0.525194; batch adversarial loss: 0.628391\n",
      "epoch 5; iter: 0; batch classifier loss: 0.378289; batch adversarial loss: 0.655946\n",
      "epoch 5; iter: 200; batch classifier loss: 0.451010; batch adversarial loss: 0.601135\n",
      "epoch 5; iter: 400; batch classifier loss: 1.460565; batch adversarial loss: 0.568177\n",
      "epoch 6; iter: 0; batch classifier loss: 0.722090; batch adversarial loss: 0.606954\n",
      "epoch 6; iter: 200; batch classifier loss: 0.411717; batch adversarial loss: 0.574944\n",
      "epoch 6; iter: 400; batch classifier loss: 0.540537; batch adversarial loss: 0.567041\n",
      "epoch 7; iter: 0; batch classifier loss: 0.412917; batch adversarial loss: 0.597288\n",
      "epoch 7; iter: 200; batch classifier loss: 0.528371; batch adversarial loss: 0.661139\n",
      "epoch 7; iter: 400; batch classifier loss: 0.365152; batch adversarial loss: 0.632151\n",
      "epoch 8; iter: 0; batch classifier loss: 0.436021; batch adversarial loss: 0.616201\n",
      "epoch 8; iter: 200; batch classifier loss: 0.472930; batch adversarial loss: 0.653172\n",
      "epoch 8; iter: 400; batch classifier loss: 0.322252; batch adversarial loss: 0.723288\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576063; batch adversarial loss: 0.640008\n",
      "epoch 9; iter: 200; batch classifier loss: 0.527069; batch adversarial loss: 0.603358\n",
      "epoch 9; iter: 400; batch classifier loss: 0.512107; batch adversarial loss: 0.596420\n",
      "epoch 0; iter: 0; batch classifier loss: 25.773998; batch adversarial loss: 0.687045\n",
      "epoch 0; iter: 200; batch classifier loss: 4.580540; batch adversarial loss: 0.622824\n",
      "epoch 0; iter: 400; batch classifier loss: 0.834849; batch adversarial loss: 0.621676\n",
      "epoch 1; iter: 0; batch classifier loss: 5.503271; batch adversarial loss: 0.586755\n",
      "epoch 1; iter: 200; batch classifier loss: 3.930568; batch adversarial loss: 0.600205\n",
      "epoch 1; iter: 400; batch classifier loss: 0.469298; batch adversarial loss: 0.652818\n",
      "epoch 2; iter: 0; batch classifier loss: 5.228517; batch adversarial loss: 0.646652\n",
      "epoch 2; iter: 200; batch classifier loss: 7.286801; batch adversarial loss: 0.589169\n",
      "epoch 2; iter: 400; batch classifier loss: 9.742516; batch adversarial loss: 0.662895\n",
      "epoch 3; iter: 0; batch classifier loss: 8.439179; batch adversarial loss: 0.554916\n",
      "epoch 3; iter: 200; batch classifier loss: 1.756515; batch adversarial loss: 0.655228\n",
      "epoch 3; iter: 400; batch classifier loss: 1.029370; batch adversarial loss: 0.587188\n",
      "epoch 4; iter: 0; batch classifier loss: 0.460933; batch adversarial loss: 0.612981\n",
      "epoch 4; iter: 200; batch classifier loss: 1.307696; batch adversarial loss: 0.601152\n",
      "epoch 4; iter: 400; batch classifier loss: 1.081705; batch adversarial loss: 0.662265\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409772; batch adversarial loss: 0.592181\n",
      "epoch 5; iter: 200; batch classifier loss: 0.472994; batch adversarial loss: 0.683989\n",
      "epoch 5; iter: 400; batch classifier loss: 1.250749; batch adversarial loss: 0.580044\n",
      "epoch 6; iter: 0; batch classifier loss: 1.056261; batch adversarial loss: 0.647712\n",
      "epoch 6; iter: 200; batch classifier loss: 0.631464; batch adversarial loss: 0.639387\n",
      "epoch 6; iter: 400; batch classifier loss: 0.346267; batch adversarial loss: 0.637862\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453920; batch adversarial loss: 0.572950\n",
      "epoch 7; iter: 200; batch classifier loss: 0.265171; batch adversarial loss: 0.587704\n",
      "epoch 7; iter: 400; batch classifier loss: 0.387917; batch adversarial loss: 0.594683\n",
      "epoch 8; iter: 0; batch classifier loss: 0.682736; batch adversarial loss: 0.695374\n",
      "epoch 8; iter: 200; batch classifier loss: 0.366938; batch adversarial loss: 0.704409\n",
      "epoch 8; iter: 400; batch classifier loss: 0.478332; batch adversarial loss: 0.595638\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284866; batch adversarial loss: 0.622673\n",
      "epoch 9; iter: 200; batch classifier loss: 0.209883; batch adversarial loss: 0.719297\n",
      "epoch 9; iter: 400; batch classifier loss: 0.266107; batch adversarial loss: 0.653315\n",
      "epoch 0; iter: 0; batch classifier loss: 7.923272; batch adversarial loss: 0.673371\n",
      "epoch 0; iter: 200; batch classifier loss: 2.313603; batch adversarial loss: 0.657964\n",
      "epoch 0; iter: 400; batch classifier loss: 2.097337; batch adversarial loss: 0.669054\n",
      "epoch 1; iter: 0; batch classifier loss: 70.928444; batch adversarial loss: 0.642450\n",
      "epoch 1; iter: 200; batch classifier loss: 0.559658; batch adversarial loss: 0.615724\n",
      "epoch 1; iter: 400; batch classifier loss: 3.723630; batch adversarial loss: 0.542315\n",
      "epoch 2; iter: 0; batch classifier loss: 3.517112; batch adversarial loss: 0.662556\n",
      "epoch 2; iter: 200; batch classifier loss: 0.557032; batch adversarial loss: 0.550030\n",
      "epoch 2; iter: 400; batch classifier loss: 2.845356; batch adversarial loss: 0.672740\n",
      "epoch 3; iter: 0; batch classifier loss: 4.720531; batch adversarial loss: 0.623337\n",
      "epoch 3; iter: 200; batch classifier loss: 2.736110; batch adversarial loss: 0.584778\n",
      "epoch 3; iter: 400; batch classifier loss: 1.168791; batch adversarial loss: 0.713692\n",
      "epoch 4; iter: 0; batch classifier loss: 1.075442; batch adversarial loss: 0.551778\n",
      "epoch 4; iter: 200; batch classifier loss: 0.529111; batch adversarial loss: 0.636673\n",
      "epoch 4; iter: 400; batch classifier loss: 0.800451; batch adversarial loss: 0.586088\n",
      "epoch 5; iter: 0; batch classifier loss: 0.340244; batch adversarial loss: 0.595594\n",
      "epoch 5; iter: 200; batch classifier loss: 0.685114; batch adversarial loss: 0.646789\n",
      "epoch 5; iter: 400; batch classifier loss: 0.617737; batch adversarial loss: 0.690632\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524202; batch adversarial loss: 0.673717\n",
      "epoch 6; iter: 200; batch classifier loss: 0.515687; batch adversarial loss: 0.648910\n",
      "epoch 6; iter: 400; batch classifier loss: 0.340723; batch adversarial loss: 0.648627\n",
      "epoch 7; iter: 0; batch classifier loss: 0.402422; batch adversarial loss: 0.678800\n",
      "epoch 7; iter: 200; batch classifier loss: 0.581695; batch adversarial loss: 0.582586\n",
      "epoch 7; iter: 400; batch classifier loss: 0.352363; batch adversarial loss: 0.556623\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521052; batch adversarial loss: 0.605502\n",
      "epoch 8; iter: 200; batch classifier loss: 0.446442; batch adversarial loss: 0.610833\n",
      "epoch 8; iter: 400; batch classifier loss: 0.290921; batch adversarial loss: 0.698635\n",
      "epoch 9; iter: 0; batch classifier loss: 0.393546; batch adversarial loss: 0.689032\n",
      "epoch 9; iter: 200; batch classifier loss: 0.502506; batch adversarial loss: 0.653743\n",
      "epoch 9; iter: 400; batch classifier loss: 0.300364; batch adversarial loss: 0.630269\n",
      "epoch 0; iter: 0; batch classifier loss: 36.036701; batch adversarial loss: 0.692139\n",
      "epoch 0; iter: 200; batch classifier loss: 6.196373; batch adversarial loss: 0.609857\n",
      "epoch 0; iter: 400; batch classifier loss: 2.032820; batch adversarial loss: 0.689589\n",
      "epoch 1; iter: 0; batch classifier loss: 12.252963; batch adversarial loss: 0.743945\n",
      "epoch 1; iter: 200; batch classifier loss: 5.498146; batch adversarial loss: 0.599070\n",
      "epoch 1; iter: 400; batch classifier loss: 1.536625; batch adversarial loss: 0.634370\n",
      "epoch 2; iter: 0; batch classifier loss: 0.998260; batch adversarial loss: 0.627032\n",
      "epoch 2; iter: 200; batch classifier loss: 5.074078; batch adversarial loss: 0.645528\n",
      "epoch 2; iter: 400; batch classifier loss: 1.874413; batch adversarial loss: 0.710263\n",
      "epoch 3; iter: 0; batch classifier loss: 1.189288; batch adversarial loss: 0.663278\n",
      "epoch 3; iter: 200; batch classifier loss: 0.711953; batch adversarial loss: 0.606345\n",
      "epoch 3; iter: 400; batch classifier loss: 1.872852; batch adversarial loss: 0.615450\n",
      "epoch 4; iter: 0; batch classifier loss: 0.368914; batch adversarial loss: 0.545121\n",
      "epoch 4; iter: 200; batch classifier loss: 0.755962; batch adversarial loss: 0.580751\n",
      "epoch 4; iter: 400; batch classifier loss: 0.973244; batch adversarial loss: 0.583376\n",
      "epoch 5; iter: 0; batch classifier loss: 1.181764; batch adversarial loss: 0.566326\n",
      "epoch 5; iter: 200; batch classifier loss: 0.371619; batch adversarial loss: 0.627476\n",
      "epoch 5; iter: 400; batch classifier loss: 0.412756; batch adversarial loss: 0.531168\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552906; batch adversarial loss: 0.571814\n",
      "epoch 6; iter: 200; batch classifier loss: 0.560110; batch adversarial loss: 0.608387\n",
      "epoch 6; iter: 400; batch classifier loss: 0.791732; batch adversarial loss: 0.616156\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400929; batch adversarial loss: 0.615183\n",
      "epoch 7; iter: 200; batch classifier loss: 0.319585; batch adversarial loss: 0.603895\n",
      "epoch 7; iter: 400; batch classifier loss: 0.332718; batch adversarial loss: 0.518246\n",
      "epoch 8; iter: 0; batch classifier loss: 0.278804; batch adversarial loss: 0.686987\n",
      "epoch 8; iter: 200; batch classifier loss: 0.339715; batch adversarial loss: 0.629053\n",
      "epoch 8; iter: 400; batch classifier loss: 0.779197; batch adversarial loss: 0.623038\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312706; batch adversarial loss: 0.618674\n",
      "epoch 9; iter: 200; batch classifier loss: 0.707847; batch adversarial loss: 0.543120\n",
      "epoch 9; iter: 400; batch classifier loss: 0.599313; batch adversarial loss: 0.656891\n",
      "epoch 0; iter: 0; batch classifier loss: 39.295177; batch adversarial loss: 0.701074\n",
      "epoch 0; iter: 200; batch classifier loss: 8.034593; batch adversarial loss: 0.671304\n",
      "epoch 0; iter: 400; batch classifier loss: 14.036576; batch adversarial loss: 0.688531\n",
      "epoch 1; iter: 0; batch classifier loss: 2.507454; batch adversarial loss: 0.684073\n",
      "epoch 1; iter: 200; batch classifier loss: 2.440179; batch adversarial loss: 0.662098\n",
      "epoch 1; iter: 400; batch classifier loss: 2.210431; batch adversarial loss: 0.634987\n",
      "epoch 2; iter: 0; batch classifier loss: 1.633701; batch adversarial loss: 0.643535\n",
      "epoch 2; iter: 200; batch classifier loss: 4.871382; batch adversarial loss: 0.597425\n",
      "epoch 2; iter: 400; batch classifier loss: 0.493444; batch adversarial loss: 0.606448\n",
      "epoch 3; iter: 0; batch classifier loss: 1.014279; batch adversarial loss: 0.645808\n",
      "epoch 3; iter: 200; batch classifier loss: 1.831193; batch adversarial loss: 0.584425\n",
      "epoch 3; iter: 400; batch classifier loss: 0.991754; batch adversarial loss: 0.630794\n",
      "epoch 4; iter: 0; batch classifier loss: 1.695677; batch adversarial loss: 0.620921\n",
      "epoch 4; iter: 200; batch classifier loss: 0.560446; batch adversarial loss: 0.585647\n",
      "epoch 4; iter: 400; batch classifier loss: 0.383127; batch adversarial loss: 0.611621\n",
      "epoch 5; iter: 0; batch classifier loss: 0.749336; batch adversarial loss: 0.508566\n",
      "epoch 5; iter: 200; batch classifier loss: 0.411255; batch adversarial loss: 0.583332\n",
      "epoch 5; iter: 400; batch classifier loss: 0.826540; batch adversarial loss: 0.647121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.464579; batch adversarial loss: 0.608903\n",
      "epoch 6; iter: 200; batch classifier loss: 1.700369; batch adversarial loss: 0.655897\n",
      "epoch 6; iter: 400; batch classifier loss: 0.304848; batch adversarial loss: 0.672699\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528447; batch adversarial loss: 0.616649\n",
      "epoch 7; iter: 200; batch classifier loss: 0.601482; batch adversarial loss: 0.586924\n",
      "epoch 7; iter: 400; batch classifier loss: 0.468668; batch adversarial loss: 0.575665\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500077; batch adversarial loss: 0.706882\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401592; batch adversarial loss: 0.605002\n",
      "epoch 8; iter: 400; batch classifier loss: 0.340513; batch adversarial loss: 0.644537\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526079; batch adversarial loss: 0.608053\n",
      "epoch 9; iter: 200; batch classifier loss: 0.592483; batch adversarial loss: 0.592637\n",
      "epoch 9; iter: 400; batch classifier loss: 0.439800; batch adversarial loss: 0.593876\n",
      "epoch 0; iter: 0; batch classifier loss: 84.110489; batch adversarial loss: 0.807760\n",
      "epoch 0; iter: 200; batch classifier loss: 10.776173; batch adversarial loss: 0.711171\n",
      "epoch 0; iter: 400; batch classifier loss: 7.811733; batch adversarial loss: 0.657657\n",
      "epoch 1; iter: 0; batch classifier loss: 2.026173; batch adversarial loss: 0.622430\n",
      "epoch 1; iter: 200; batch classifier loss: 0.766992; batch adversarial loss: 0.662051\n",
      "epoch 1; iter: 400; batch classifier loss: 0.440988; batch adversarial loss: 0.699138\n",
      "epoch 2; iter: 0; batch classifier loss: 7.553771; batch adversarial loss: 0.664589\n",
      "epoch 2; iter: 200; batch classifier loss: 2.271236; batch adversarial loss: 0.684333\n",
      "epoch 2; iter: 400; batch classifier loss: 3.671206; batch adversarial loss: 0.629688\n",
      "epoch 3; iter: 0; batch classifier loss: 0.350511; batch adversarial loss: 0.663472\n",
      "epoch 3; iter: 200; batch classifier loss: 4.107696; batch adversarial loss: 0.669065\n",
      "epoch 3; iter: 400; batch classifier loss: 2.300631; batch adversarial loss: 0.653355\n",
      "epoch 4; iter: 0; batch classifier loss: 0.306512; batch adversarial loss: 0.617661\n",
      "epoch 4; iter: 200; batch classifier loss: 1.518014; batch adversarial loss: 0.659272\n",
      "epoch 4; iter: 400; batch classifier loss: 0.385414; batch adversarial loss: 0.625963\n",
      "epoch 5; iter: 0; batch classifier loss: 0.762848; batch adversarial loss: 0.656695\n",
      "epoch 5; iter: 200; batch classifier loss: 1.066607; batch adversarial loss: 0.647149\n",
      "epoch 5; iter: 400; batch classifier loss: 0.337032; batch adversarial loss: 0.664814\n",
      "epoch 6; iter: 0; batch classifier loss: 0.411870; batch adversarial loss: 0.673579\n",
      "epoch 6; iter: 200; batch classifier loss: 0.507051; batch adversarial loss: 0.621563\n",
      "epoch 6; iter: 400; batch classifier loss: 0.858916; batch adversarial loss: 0.647931\n",
      "epoch 7; iter: 0; batch classifier loss: 0.428682; batch adversarial loss: 0.673890\n",
      "epoch 7; iter: 200; batch classifier loss: 0.423087; batch adversarial loss: 0.648659\n",
      "epoch 7; iter: 400; batch classifier loss: 0.451699; batch adversarial loss: 0.631445\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610225; batch adversarial loss: 0.556988\n",
      "epoch 8; iter: 200; batch classifier loss: 0.397977; batch adversarial loss: 0.715428\n",
      "epoch 8; iter: 400; batch classifier loss: 0.632085; batch adversarial loss: 0.687531\n",
      "epoch 9; iter: 0; batch classifier loss: 0.387937; batch adversarial loss: 0.656087\n",
      "epoch 9; iter: 200; batch classifier loss: 0.437480; batch adversarial loss: 0.663761\n",
      "epoch 9; iter: 400; batch classifier loss: 0.385814; batch adversarial loss: 0.594097\n",
      "epoch 0; iter: 0; batch classifier loss: 17.523478; batch adversarial loss: 0.706761\n",
      "epoch 0; iter: 200; batch classifier loss: 14.596512; batch adversarial loss: 0.655010\n",
      "epoch 0; iter: 400; batch classifier loss: 11.515617; batch adversarial loss: 0.687304\n",
      "epoch 1; iter: 0; batch classifier loss: 5.956250; batch adversarial loss: 0.632163\n",
      "epoch 1; iter: 200; batch classifier loss: 10.774250; batch adversarial loss: 0.627817\n",
      "epoch 1; iter: 400; batch classifier loss: 4.042324; batch adversarial loss: 0.626581\n",
      "epoch 2; iter: 0; batch classifier loss: 4.741481; batch adversarial loss: 0.581698\n",
      "epoch 2; iter: 200; batch classifier loss: 1.481561; batch adversarial loss: 0.653985\n",
      "epoch 2; iter: 400; batch classifier loss: 6.789154; batch adversarial loss: 0.649925\n",
      "epoch 3; iter: 0; batch classifier loss: 1.350349; batch adversarial loss: 0.671850\n",
      "epoch 3; iter: 200; batch classifier loss: 5.176420; batch adversarial loss: 0.633543\n",
      "epoch 3; iter: 400; batch classifier loss: 1.267219; batch adversarial loss: 0.671138\n",
      "epoch 4; iter: 0; batch classifier loss: 0.404875; batch adversarial loss: 0.696791\n",
      "epoch 4; iter: 200; batch classifier loss: 0.431418; batch adversarial loss: 0.665145\n",
      "epoch 4; iter: 400; batch classifier loss: 1.136415; batch adversarial loss: 0.731379\n",
      "epoch 5; iter: 0; batch classifier loss: 1.535157; batch adversarial loss: 0.719732\n",
      "epoch 5; iter: 200; batch classifier loss: 0.422691; batch adversarial loss: 0.664970\n",
      "epoch 5; iter: 400; batch classifier loss: 0.561700; batch adversarial loss: 0.600987\n",
      "epoch 6; iter: 0; batch classifier loss: 0.314192; batch adversarial loss: 0.590143\n",
      "epoch 6; iter: 200; batch classifier loss: 0.389368; batch adversarial loss: 0.620901\n",
      "epoch 6; iter: 400; batch classifier loss: 0.268054; batch adversarial loss: 0.626172\n",
      "epoch 7; iter: 0; batch classifier loss: 0.463709; batch adversarial loss: 0.701207\n",
      "epoch 7; iter: 200; batch classifier loss: 0.333651; batch adversarial loss: 0.595228\n",
      "epoch 7; iter: 400; batch classifier loss: 0.553421; batch adversarial loss: 0.589479\n",
      "epoch 8; iter: 0; batch classifier loss: 0.312810; batch adversarial loss: 0.623086\n",
      "epoch 8; iter: 200; batch classifier loss: 0.393786; batch adversarial loss: 0.598770\n",
      "epoch 8; iter: 400; batch classifier loss: 0.740877; batch adversarial loss: 0.641001\n",
      "epoch 9; iter: 0; batch classifier loss: 0.741925; batch adversarial loss: 0.572959\n",
      "epoch 9; iter: 200; batch classifier loss: 0.292316; batch adversarial loss: 0.627025\n",
      "epoch 9; iter: 400; batch classifier loss: 0.421422; batch adversarial loss: 0.611398\n",
      "epoch 0; iter: 0; batch classifier loss: 29.851906; batch adversarial loss: 0.724667\n",
      "epoch 0; iter: 200; batch classifier loss: 5.840372; batch adversarial loss: 0.681609\n",
      "epoch 0; iter: 400; batch classifier loss: 6.550815; batch adversarial loss: 0.659412\n",
      "epoch 1; iter: 0; batch classifier loss: 12.472507; batch adversarial loss: 0.620663\n",
      "epoch 1; iter: 200; batch classifier loss: 1.564523; batch adversarial loss: 0.640817\n",
      "epoch 1; iter: 400; batch classifier loss: 2.538057; batch adversarial loss: 0.675204\n",
      "epoch 2; iter: 0; batch classifier loss: 2.084773; batch adversarial loss: 0.628932\n",
      "epoch 2; iter: 200; batch classifier loss: 7.501549; batch adversarial loss: 0.514395\n",
      "epoch 2; iter: 400; batch classifier loss: 0.340720; batch adversarial loss: 0.601474\n",
      "epoch 3; iter: 0; batch classifier loss: 0.199023; batch adversarial loss: 0.691216\n",
      "epoch 3; iter: 200; batch classifier loss: 1.836585; batch adversarial loss: 0.682885\n",
      "epoch 3; iter: 400; batch classifier loss: 1.415743; batch adversarial loss: 0.588472\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538583; batch adversarial loss: 0.561302\n",
      "epoch 4; iter: 200; batch classifier loss: 1.775880; batch adversarial loss: 0.616071\n",
      "epoch 4; iter: 400; batch classifier loss: 0.524728; batch adversarial loss: 0.637405\n",
      "epoch 5; iter: 0; batch classifier loss: 1.037029; batch adversarial loss: 0.630950\n",
      "epoch 5; iter: 200; batch classifier loss: 0.915060; batch adversarial loss: 0.633776\n",
      "epoch 5; iter: 400; batch classifier loss: 0.420158; batch adversarial loss: 0.567660\n",
      "epoch 6; iter: 0; batch classifier loss: 0.390736; batch adversarial loss: 0.681709\n",
      "epoch 6; iter: 200; batch classifier loss: 0.386164; batch adversarial loss: 0.681947\n",
      "epoch 6; iter: 400; batch classifier loss: 0.646959; batch adversarial loss: 0.578728\n",
      "epoch 7; iter: 0; batch classifier loss: 0.313642; batch adversarial loss: 0.621335\n",
      "epoch 7; iter: 200; batch classifier loss: 0.774103; batch adversarial loss: 0.583697\n",
      "epoch 7; iter: 400; batch classifier loss: 0.447969; batch adversarial loss: 0.622250\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435536; batch adversarial loss: 0.680781\n",
      "epoch 8; iter: 200; batch classifier loss: 0.273769; batch adversarial loss: 0.687106\n",
      "epoch 8; iter: 400; batch classifier loss: 0.295910; batch adversarial loss: 0.617841\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414206; batch adversarial loss: 0.666585\n",
      "epoch 9; iter: 200; batch classifier loss: 0.333696; batch adversarial loss: 0.547539\n",
      "epoch 9; iter: 400; batch classifier loss: 0.375048; batch adversarial loss: 0.566719\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 30.710182; batch adversarial loss: 0.526970\n",
      "epoch 0; iter: 200; batch classifier loss: 5.332255; batch adversarial loss: 0.586329\n",
      "epoch 0; iter: 400; batch classifier loss: 7.695353; batch adversarial loss: 0.663364\n",
      "epoch 1; iter: 0; batch classifier loss: 2.812138; batch adversarial loss: 0.702448\n",
      "epoch 1; iter: 200; batch classifier loss: 2.155892; batch adversarial loss: 0.564343\n",
      "epoch 1; iter: 400; batch classifier loss: 5.889894; batch adversarial loss: 0.547000\n",
      "epoch 2; iter: 0; batch classifier loss: 3.170144; batch adversarial loss: 0.669567\n",
      "epoch 2; iter: 200; batch classifier loss: 1.021939; batch adversarial loss: 0.611723\n",
      "epoch 2; iter: 400; batch classifier loss: 0.531273; batch adversarial loss: 0.729483\n",
      "epoch 3; iter: 0; batch classifier loss: 0.394335; batch adversarial loss: 0.595643\n",
      "epoch 3; iter: 200; batch classifier loss: 2.692468; batch adversarial loss: 0.619914\n",
      "epoch 3; iter: 400; batch classifier loss: 1.248355; batch adversarial loss: 0.665350\n",
      "epoch 4; iter: 0; batch classifier loss: 1.880561; batch adversarial loss: 0.632854\n",
      "epoch 4; iter: 200; batch classifier loss: 0.402790; batch adversarial loss: 0.665179\n",
      "epoch 4; iter: 400; batch classifier loss: 1.301848; batch adversarial loss: 0.654339\n",
      "epoch 5; iter: 0; batch classifier loss: 1.349741; batch adversarial loss: 0.634643\n",
      "epoch 5; iter: 200; batch classifier loss: 0.923212; batch adversarial loss: 0.614797\n",
      "epoch 5; iter: 400; batch classifier loss: 0.804487; batch adversarial loss: 0.585831\n",
      "epoch 6; iter: 0; batch classifier loss: 0.429567; batch adversarial loss: 0.648129\n",
      "epoch 6; iter: 200; batch classifier loss: 0.310723; batch adversarial loss: 0.672768\n",
      "epoch 6; iter: 400; batch classifier loss: 0.462679; batch adversarial loss: 0.664076\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490633; batch adversarial loss: 0.702589\n",
      "epoch 7; iter: 200; batch classifier loss: 0.380995; batch adversarial loss: 0.609859\n",
      "epoch 7; iter: 400; batch classifier loss: 0.273341; batch adversarial loss: 0.636451\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428571; batch adversarial loss: 0.646803\n",
      "epoch 8; iter: 200; batch classifier loss: 0.436125; batch adversarial loss: 0.702958\n",
      "epoch 8; iter: 400; batch classifier loss: 0.374383; batch adversarial loss: 0.627692\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438468; batch adversarial loss: 0.668272\n",
      "epoch 9; iter: 200; batch classifier loss: 0.865144; batch adversarial loss: 0.698359\n",
      "epoch 9; iter: 400; batch classifier loss: 0.398769; batch adversarial loss: 0.650445\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509396; batch adversarial loss: 0.581721\n",
      "epoch 10; iter: 200; batch classifier loss: 0.362316; batch adversarial loss: 0.573393\n",
      "epoch 10; iter: 400; batch classifier loss: 0.389758; batch adversarial loss: 0.610812\n",
      "epoch 11; iter: 0; batch classifier loss: 0.390067; batch adversarial loss: 0.626500\n",
      "epoch 11; iter: 200; batch classifier loss: 0.559266; batch adversarial loss: 0.641133\n",
      "epoch 11; iter: 400; batch classifier loss: 0.345592; batch adversarial loss: 0.651688\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352036; batch adversarial loss: 0.663611\n",
      "epoch 12; iter: 200; batch classifier loss: 0.481364; batch adversarial loss: 0.532579\n",
      "epoch 12; iter: 400; batch classifier loss: 0.419558; batch adversarial loss: 0.611352\n",
      "epoch 13; iter: 0; batch classifier loss: 0.238712; batch adversarial loss: 0.702309\n",
      "epoch 13; iter: 200; batch classifier loss: 0.591161; batch adversarial loss: 0.587700\n",
      "epoch 13; iter: 400; batch classifier loss: 0.362923; batch adversarial loss: 0.616258\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484445; batch adversarial loss: 0.659388\n",
      "epoch 14; iter: 200; batch classifier loss: 0.251398; batch adversarial loss: 0.582836\n",
      "epoch 14; iter: 400; batch classifier loss: 0.377835; batch adversarial loss: 0.655728\n",
      "epoch 15; iter: 0; batch classifier loss: 0.319448; batch adversarial loss: 0.648109\n",
      "epoch 15; iter: 200; batch classifier loss: 0.367083; batch adversarial loss: 0.619640\n",
      "epoch 15; iter: 400; batch classifier loss: 0.365946; batch adversarial loss: 0.610523\n",
      "epoch 16; iter: 0; batch classifier loss: 0.546457; batch adversarial loss: 0.613333\n",
      "epoch 16; iter: 200; batch classifier loss: 0.209371; batch adversarial loss: 0.634075\n",
      "epoch 16; iter: 400; batch classifier loss: 0.310608; batch adversarial loss: 0.571612\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286368; batch adversarial loss: 0.660261\n",
      "epoch 17; iter: 200; batch classifier loss: 0.506684; batch adversarial loss: 0.670093\n",
      "epoch 17; iter: 400; batch classifier loss: 0.465148; batch adversarial loss: 0.551488\n",
      "epoch 18; iter: 0; batch classifier loss: 0.281051; batch adversarial loss: 0.657868\n",
      "epoch 18; iter: 200; batch classifier loss: 0.389939; batch adversarial loss: 0.623952\n",
      "epoch 18; iter: 400; batch classifier loss: 0.477002; batch adversarial loss: 0.711815\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362517; batch adversarial loss: 0.632499\n",
      "epoch 19; iter: 200; batch classifier loss: 0.498987; batch adversarial loss: 0.720333\n",
      "epoch 19; iter: 400; batch classifier loss: 0.291357; batch adversarial loss: 0.559579\n",
      "epoch 0; iter: 0; batch classifier loss: 89.364967; batch adversarial loss: 0.679281\n",
      "epoch 0; iter: 200; batch classifier loss: 4.081596; batch adversarial loss: 0.625912\n",
      "epoch 0; iter: 400; batch classifier loss: 5.843903; batch adversarial loss: 0.630450\n",
      "epoch 1; iter: 0; batch classifier loss: 8.696356; batch adversarial loss: 0.693462\n",
      "epoch 1; iter: 200; batch classifier loss: 2.334862; batch adversarial loss: 0.654582\n",
      "epoch 1; iter: 400; batch classifier loss: 2.485422; batch adversarial loss: 0.609986\n",
      "epoch 2; iter: 0; batch classifier loss: 2.285028; batch adversarial loss: 0.606289\n",
      "epoch 2; iter: 200; batch classifier loss: 1.335702; batch adversarial loss: 0.644495\n",
      "epoch 2; iter: 400; batch classifier loss: 1.539987; batch adversarial loss: 0.594377\n",
      "epoch 3; iter: 0; batch classifier loss: 0.394010; batch adversarial loss: 0.580813\n",
      "epoch 3; iter: 200; batch classifier loss: 1.152567; batch adversarial loss: 0.602023\n",
      "epoch 3; iter: 400; batch classifier loss: 1.056505; batch adversarial loss: 0.634741\n",
      "epoch 4; iter: 0; batch classifier loss: 0.694941; batch adversarial loss: 0.675595\n",
      "epoch 4; iter: 200; batch classifier loss: 0.636409; batch adversarial loss: 0.636824\n",
      "epoch 4; iter: 400; batch classifier loss: 0.552857; batch adversarial loss: 0.572427\n",
      "epoch 5; iter: 0; batch classifier loss: 0.284171; batch adversarial loss: 0.630234\n",
      "epoch 5; iter: 200; batch classifier loss: 1.069637; batch adversarial loss: 0.663011\n",
      "epoch 5; iter: 400; batch classifier loss: 1.243964; batch adversarial loss: 0.556970\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558757; batch adversarial loss: 0.607947\n",
      "epoch 6; iter: 200; batch classifier loss: 0.571628; batch adversarial loss: 0.663428\n",
      "epoch 6; iter: 400; batch classifier loss: 1.252680; batch adversarial loss: 0.662802\n",
      "epoch 7; iter: 0; batch classifier loss: 0.551297; batch adversarial loss: 0.608617\n",
      "epoch 7; iter: 200; batch classifier loss: 0.528556; batch adversarial loss: 0.575483\n",
      "epoch 7; iter: 400; batch classifier loss: 1.746472; batch adversarial loss: 0.618351\n",
      "epoch 8; iter: 0; batch classifier loss: 0.450040; batch adversarial loss: 0.506271\n",
      "epoch 8; iter: 200; batch classifier loss: 0.513760; batch adversarial loss: 0.565478\n",
      "epoch 8; iter: 400; batch classifier loss: 0.389689; batch adversarial loss: 0.711929\n",
      "epoch 9; iter: 0; batch classifier loss: 0.638549; batch adversarial loss: 0.626908\n",
      "epoch 9; iter: 200; batch classifier loss: 0.469043; batch adversarial loss: 0.552759\n",
      "epoch 9; iter: 400; batch classifier loss: 0.869407; batch adversarial loss: 0.661493\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426611; batch adversarial loss: 0.617691\n",
      "epoch 10; iter: 200; batch classifier loss: 0.476077; batch adversarial loss: 0.621970\n",
      "epoch 10; iter: 400; batch classifier loss: 0.752468; batch adversarial loss: 0.721374\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309385; batch adversarial loss: 0.604021\n",
      "epoch 11; iter: 200; batch classifier loss: 0.474684; batch adversarial loss: 0.623883\n",
      "epoch 11; iter: 400; batch classifier loss: 0.561180; batch adversarial loss: 0.592383\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306728; batch adversarial loss: 0.601565\n",
      "epoch 12; iter: 200; batch classifier loss: 0.366303; batch adversarial loss: 0.613492\n",
      "epoch 12; iter: 400; batch classifier loss: 0.417289; batch adversarial loss: 0.589355\n",
      "epoch 13; iter: 0; batch classifier loss: 0.416090; batch adversarial loss: 0.624844\n",
      "epoch 13; iter: 200; batch classifier loss: 0.357864; batch adversarial loss: 0.604021\n",
      "epoch 13; iter: 400; batch classifier loss: 0.503621; batch adversarial loss: 0.571491\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360971; batch adversarial loss: 0.631657\n",
      "epoch 14; iter: 200; batch classifier loss: 0.369727; batch adversarial loss: 0.625579\n",
      "epoch 14; iter: 400; batch classifier loss: 0.408887; batch adversarial loss: 0.634779\n",
      "epoch 15; iter: 0; batch classifier loss: 0.397597; batch adversarial loss: 0.601329\n",
      "epoch 15; iter: 200; batch classifier loss: 0.385863; batch adversarial loss: 0.631756\n",
      "epoch 15; iter: 400; batch classifier loss: 0.299060; batch adversarial loss: 0.570405\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336113; batch adversarial loss: 0.612256\n",
      "epoch 16; iter: 200; batch classifier loss: 0.500452; batch adversarial loss: 0.719881\n",
      "epoch 16; iter: 400; batch classifier loss: 0.316177; batch adversarial loss: 0.678030\n",
      "epoch 17; iter: 0; batch classifier loss: 0.216471; batch adversarial loss: 0.619481\n",
      "epoch 17; iter: 200; batch classifier loss: 0.202832; batch adversarial loss: 0.672608\n",
      "epoch 17; iter: 400; batch classifier loss: 0.347991; batch adversarial loss: 0.612241\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302467; batch adversarial loss: 0.606319\n",
      "epoch 18; iter: 200; batch classifier loss: 0.264858; batch adversarial loss: 0.651018\n",
      "epoch 18; iter: 400; batch classifier loss: 0.388430; batch adversarial loss: 0.616011\n",
      "epoch 19; iter: 0; batch classifier loss: 0.341088; batch adversarial loss: 0.610585\n",
      "epoch 19; iter: 200; batch classifier loss: 0.455943; batch adversarial loss: 0.588053\n",
      "epoch 19; iter: 400; batch classifier loss: 0.259656; batch adversarial loss: 0.705682\n",
      "epoch 0; iter: 0; batch classifier loss: 3.562779; batch adversarial loss: 1.218538\n",
      "epoch 0; iter: 200; batch classifier loss: 3.703303; batch adversarial loss: 1.066213\n",
      "epoch 0; iter: 400; batch classifier loss: 40.536728; batch adversarial loss: 0.844412\n",
      "epoch 1; iter: 0; batch classifier loss: 9.887487; batch adversarial loss: 0.874139\n",
      "epoch 1; iter: 200; batch classifier loss: 1.005015; batch adversarial loss: 0.838556\n",
      "epoch 1; iter: 400; batch classifier loss: 3.881218; batch adversarial loss: 0.641237\n",
      "epoch 2; iter: 0; batch classifier loss: 1.965464; batch adversarial loss: 0.699187\n",
      "epoch 2; iter: 200; batch classifier loss: 0.457496; batch adversarial loss: 0.676024\n",
      "epoch 2; iter: 400; batch classifier loss: 0.709529; batch adversarial loss: 0.660486\n",
      "epoch 3; iter: 0; batch classifier loss: 13.891017; batch adversarial loss: 0.654237\n",
      "epoch 3; iter: 200; batch classifier loss: 1.670002; batch adversarial loss: 0.654410\n",
      "epoch 3; iter: 400; batch classifier loss: 5.529864; batch adversarial loss: 0.661411\n",
      "epoch 4; iter: 0; batch classifier loss: 0.830699; batch adversarial loss: 0.634750\n",
      "epoch 4; iter: 200; batch classifier loss: 1.628761; batch adversarial loss: 0.594284\n",
      "epoch 4; iter: 400; batch classifier loss: 0.818543; batch adversarial loss: 0.626680\n",
      "epoch 5; iter: 0; batch classifier loss: 0.699538; batch adversarial loss: 0.667783\n",
      "epoch 5; iter: 200; batch classifier loss: 0.690956; batch adversarial loss: 0.570157\n",
      "epoch 5; iter: 400; batch classifier loss: 0.706226; batch adversarial loss: 0.557251\n",
      "epoch 6; iter: 0; batch classifier loss: 0.764546; batch adversarial loss: 0.594873\n",
      "epoch 6; iter: 200; batch classifier loss: 0.373325; batch adversarial loss: 0.684207\n",
      "epoch 6; iter: 400; batch classifier loss: 0.355795; batch adversarial loss: 0.674586\n",
      "epoch 7; iter: 0; batch classifier loss: 0.370004; batch adversarial loss: 0.642357\n",
      "epoch 7; iter: 200; batch classifier loss: 1.593525; batch adversarial loss: 0.619918\n",
      "epoch 7; iter: 400; batch classifier loss: 0.407646; batch adversarial loss: 0.697293\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535822; batch adversarial loss: 0.549591\n",
      "epoch 8; iter: 200; batch classifier loss: 0.415823; batch adversarial loss: 0.591306\n",
      "epoch 8; iter: 400; batch classifier loss: 0.455153; batch adversarial loss: 0.595872\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418328; batch adversarial loss: 0.633798\n",
      "epoch 9; iter: 200; batch classifier loss: 0.271092; batch adversarial loss: 0.644902\n",
      "epoch 9; iter: 400; batch classifier loss: 0.252086; batch adversarial loss: 0.644562\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343053; batch adversarial loss: 0.731339\n",
      "epoch 10; iter: 200; batch classifier loss: 0.436849; batch adversarial loss: 0.594940\n",
      "epoch 10; iter: 400; batch classifier loss: 0.284466; batch adversarial loss: 0.584395\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348105; batch adversarial loss: 0.668825\n",
      "epoch 11; iter: 200; batch classifier loss: 1.144492; batch adversarial loss: 0.613189\n",
      "epoch 11; iter: 400; batch classifier loss: 0.269592; batch adversarial loss: 0.653326\n",
      "epoch 12; iter: 0; batch classifier loss: 0.799351; batch adversarial loss: 0.582150\n",
      "epoch 12; iter: 200; batch classifier loss: 0.359665; batch adversarial loss: 0.603064\n",
      "epoch 12; iter: 400; batch classifier loss: 0.478345; batch adversarial loss: 0.556666\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279218; batch adversarial loss: 0.652084\n",
      "epoch 13; iter: 200; batch classifier loss: 0.362023; batch adversarial loss: 0.711951\n",
      "epoch 13; iter: 400; batch classifier loss: 0.318266; batch adversarial loss: 0.698754\n",
      "epoch 14; iter: 0; batch classifier loss: 0.553716; batch adversarial loss: 0.587166\n",
      "epoch 14; iter: 200; batch classifier loss: 0.435683; batch adversarial loss: 0.564175\n",
      "epoch 14; iter: 400; batch classifier loss: 0.375529; batch adversarial loss: 0.579562\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362670; batch adversarial loss: 0.643997\n",
      "epoch 15; iter: 200; batch classifier loss: 0.297716; batch adversarial loss: 0.652970\n",
      "epoch 15; iter: 400; batch classifier loss: 0.226976; batch adversarial loss: 0.668683\n",
      "epoch 16; iter: 0; batch classifier loss: 0.480644; batch adversarial loss: 0.573899\n",
      "epoch 16; iter: 200; batch classifier loss: 0.329498; batch adversarial loss: 0.557282\n",
      "epoch 16; iter: 400; batch classifier loss: 0.323705; batch adversarial loss: 0.614180\n",
      "epoch 17; iter: 0; batch classifier loss: 0.456876; batch adversarial loss: 0.621761\n",
      "epoch 17; iter: 200; batch classifier loss: 0.361888; batch adversarial loss: 0.640434\n",
      "epoch 17; iter: 400; batch classifier loss: 0.386790; batch adversarial loss: 0.612738\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271690; batch adversarial loss: 0.546452\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373291; batch adversarial loss: 0.554889\n",
      "epoch 18; iter: 400; batch classifier loss: 0.256311; batch adversarial loss: 0.640415\n",
      "epoch 19; iter: 0; batch classifier loss: 0.428509; batch adversarial loss: 0.609390\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316812; batch adversarial loss: 0.640597\n",
      "epoch 19; iter: 400; batch classifier loss: 0.351260; batch adversarial loss: 0.624587\n",
      "epoch 0; iter: 0; batch classifier loss: 2.470268; batch adversarial loss: 0.823134\n",
      "epoch 0; iter: 200; batch classifier loss: 39.443760; batch adversarial loss: 0.661766\n",
      "epoch 0; iter: 400; batch classifier loss: 12.532751; batch adversarial loss: 0.661039\n",
      "epoch 1; iter: 0; batch classifier loss: 1.687454; batch adversarial loss: 0.603797\n",
      "epoch 1; iter: 200; batch classifier loss: 0.613097; batch adversarial loss: 0.669967\n",
      "epoch 1; iter: 400; batch classifier loss: 5.347738; batch adversarial loss: 0.646860\n",
      "epoch 2; iter: 0; batch classifier loss: 0.880736; batch adversarial loss: 0.622264\n",
      "epoch 2; iter: 200; batch classifier loss: 4.035774; batch adversarial loss: 0.613909\n",
      "epoch 2; iter: 400; batch classifier loss: 6.088671; batch adversarial loss: 0.589771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.807130; batch adversarial loss: 0.673534\n",
      "epoch 3; iter: 200; batch classifier loss: 1.837511; batch adversarial loss: 0.628309\n",
      "epoch 3; iter: 400; batch classifier loss: 1.456997; batch adversarial loss: 0.574394\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583466; batch adversarial loss: 0.725678\n",
      "epoch 4; iter: 200; batch classifier loss: 0.325437; batch adversarial loss: 0.650735\n",
      "epoch 4; iter: 400; batch classifier loss: 0.534244; batch adversarial loss: 0.641854\n",
      "epoch 5; iter: 0; batch classifier loss: 1.779711; batch adversarial loss: 0.564221\n",
      "epoch 5; iter: 200; batch classifier loss: 0.407000; batch adversarial loss: 0.631286\n",
      "epoch 5; iter: 400; batch classifier loss: 0.885226; batch adversarial loss: 0.612127\n",
      "epoch 6; iter: 0; batch classifier loss: 0.296994; batch adversarial loss: 0.576003\n",
      "epoch 6; iter: 200; batch classifier loss: 0.284378; batch adversarial loss: 0.671279\n",
      "epoch 6; iter: 400; batch classifier loss: 0.440226; batch adversarial loss: 0.695315\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573384; batch adversarial loss: 0.545945\n",
      "epoch 7; iter: 200; batch classifier loss: 0.450089; batch adversarial loss: 0.698194\n",
      "epoch 7; iter: 400; batch classifier loss: 0.335178; batch adversarial loss: 0.612813\n",
      "epoch 8; iter: 0; batch classifier loss: 0.709723; batch adversarial loss: 0.542688\n",
      "epoch 8; iter: 200; batch classifier loss: 2.009143; batch adversarial loss: 0.604483\n",
      "epoch 8; iter: 400; batch classifier loss: 0.503424; batch adversarial loss: 0.682189\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345480; batch adversarial loss: 0.668690\n",
      "epoch 9; iter: 200; batch classifier loss: 0.299043; batch adversarial loss: 0.770217\n",
      "epoch 9; iter: 400; batch classifier loss: 0.359751; batch adversarial loss: 0.623207\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523146; batch adversarial loss: 0.603292\n",
      "epoch 10; iter: 200; batch classifier loss: 0.574018; batch adversarial loss: 0.631844\n",
      "epoch 10; iter: 400; batch classifier loss: 0.368557; batch adversarial loss: 0.648831\n",
      "epoch 11; iter: 0; batch classifier loss: 0.932300; batch adversarial loss: 0.694841\n",
      "epoch 11; iter: 200; batch classifier loss: 0.444626; batch adversarial loss: 0.619469\n",
      "epoch 11; iter: 400; batch classifier loss: 0.296771; batch adversarial loss: 0.602928\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349014; batch adversarial loss: 0.634101\n",
      "epoch 12; iter: 200; batch classifier loss: 0.331356; batch adversarial loss: 0.678376\n",
      "epoch 12; iter: 400; batch classifier loss: 0.433268; batch adversarial loss: 0.552739\n",
      "epoch 13; iter: 0; batch classifier loss: 0.244657; batch adversarial loss: 0.615171\n",
      "epoch 13; iter: 200; batch classifier loss: 0.303136; batch adversarial loss: 0.669426\n",
      "epoch 13; iter: 400; batch classifier loss: 0.255174; batch adversarial loss: 0.565128\n",
      "epoch 14; iter: 0; batch classifier loss: 0.417206; batch adversarial loss: 0.610150\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378139; batch adversarial loss: 0.638860\n",
      "epoch 14; iter: 400; batch classifier loss: 0.461230; batch adversarial loss: 0.603166\n",
      "epoch 15; iter: 0; batch classifier loss: 0.304681; batch adversarial loss: 0.630697\n",
      "epoch 15; iter: 200; batch classifier loss: 0.383040; batch adversarial loss: 0.589139\n",
      "epoch 15; iter: 400; batch classifier loss: 0.318585; batch adversarial loss: 0.712479\n",
      "epoch 16; iter: 0; batch classifier loss: 0.255241; batch adversarial loss: 0.651191\n",
      "epoch 16; iter: 200; batch classifier loss: 0.402211; batch adversarial loss: 0.617449\n",
      "epoch 16; iter: 400; batch classifier loss: 0.406255; batch adversarial loss: 0.625227\n",
      "epoch 17; iter: 0; batch classifier loss: 0.341732; batch adversarial loss: 0.738980\n",
      "epoch 17; iter: 200; batch classifier loss: 0.316939; batch adversarial loss: 0.691100\n",
      "epoch 17; iter: 400; batch classifier loss: 0.382406; batch adversarial loss: 0.655454\n",
      "epoch 18; iter: 0; batch classifier loss: 0.395375; batch adversarial loss: 0.573164\n",
      "epoch 18; iter: 200; batch classifier loss: 0.334374; batch adversarial loss: 0.615314\n",
      "epoch 18; iter: 400; batch classifier loss: 0.440175; batch adversarial loss: 0.578094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376639; batch adversarial loss: 0.698868\n",
      "epoch 19; iter: 200; batch classifier loss: 0.498288; batch adversarial loss: 0.605649\n",
      "epoch 19; iter: 400; batch classifier loss: 0.433031; batch adversarial loss: 0.525827\n",
      "epoch 0; iter: 0; batch classifier loss: 5.592622; batch adversarial loss: 0.673697\n",
      "epoch 0; iter: 200; batch classifier loss: 7.201319; batch adversarial loss: 0.655023\n",
      "epoch 0; iter: 400; batch classifier loss: 12.813317; batch adversarial loss: 0.690251\n",
      "epoch 1; iter: 0; batch classifier loss: 6.029648; batch adversarial loss: 0.690546\n",
      "epoch 1; iter: 200; batch classifier loss: 1.649349; batch adversarial loss: 0.646505\n",
      "epoch 1; iter: 400; batch classifier loss: 3.210078; batch adversarial loss: 0.587112\n",
      "epoch 2; iter: 0; batch classifier loss: 10.601527; batch adversarial loss: 0.662944\n",
      "epoch 2; iter: 200; batch classifier loss: 2.246580; batch adversarial loss: 0.563259\n",
      "epoch 2; iter: 400; batch classifier loss: 1.721910; batch adversarial loss: 0.581499\n",
      "epoch 3; iter: 0; batch classifier loss: 1.509616; batch adversarial loss: 0.631099\n",
      "epoch 3; iter: 200; batch classifier loss: 0.758644; batch adversarial loss: 0.681739\n",
      "epoch 3; iter: 400; batch classifier loss: 0.229282; batch adversarial loss: 0.616258\n",
      "epoch 4; iter: 0; batch classifier loss: 0.470286; batch adversarial loss: 0.632122\n",
      "epoch 4; iter: 200; batch classifier loss: 0.768490; batch adversarial loss: 0.666226\n",
      "epoch 4; iter: 400; batch classifier loss: 0.689370; batch adversarial loss: 0.635906\n",
      "epoch 5; iter: 0; batch classifier loss: 0.692263; batch adversarial loss: 0.681548\n",
      "epoch 5; iter: 200; batch classifier loss: 0.606596; batch adversarial loss: 0.652265\n",
      "epoch 5; iter: 400; batch classifier loss: 0.540040; batch adversarial loss: 0.581117\n",
      "epoch 6; iter: 0; batch classifier loss: 0.412365; batch adversarial loss: 0.646364\n",
      "epoch 6; iter: 200; batch classifier loss: 0.408253; batch adversarial loss: 0.591168\n",
      "epoch 6; iter: 400; batch classifier loss: 0.521859; batch adversarial loss: 0.592967\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492071; batch adversarial loss: 0.563959\n",
      "epoch 7; iter: 200; batch classifier loss: 0.739576; batch adversarial loss: 0.574335\n",
      "epoch 7; iter: 400; batch classifier loss: 0.300687; batch adversarial loss: 0.545032\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322254; batch adversarial loss: 0.654722\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452533; batch adversarial loss: 0.673788\n",
      "epoch 8; iter: 400; batch classifier loss: 0.421637; batch adversarial loss: 0.596424\n",
      "epoch 9; iter: 0; batch classifier loss: 0.365470; batch adversarial loss: 0.584696\n",
      "epoch 9; iter: 200; batch classifier loss: 0.247319; batch adversarial loss: 0.640152\n",
      "epoch 9; iter: 400; batch classifier loss: 0.266845; batch adversarial loss: 0.636883\n",
      "epoch 10; iter: 0; batch classifier loss: 0.421008; batch adversarial loss: 0.536633\n",
      "epoch 10; iter: 200; batch classifier loss: 0.457951; batch adversarial loss: 0.587937\n",
      "epoch 10; iter: 400; batch classifier loss: 0.408675; batch adversarial loss: 0.613617\n",
      "epoch 11; iter: 0; batch classifier loss: 0.444944; batch adversarial loss: 0.596106\n",
      "epoch 11; iter: 200; batch classifier loss: 0.283146; batch adversarial loss: 0.704020\n",
      "epoch 11; iter: 400; batch classifier loss: 0.296974; batch adversarial loss: 0.684396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407178; batch adversarial loss: 0.605786\n",
      "epoch 12; iter: 200; batch classifier loss: 0.388310; batch adversarial loss: 0.668697\n",
      "epoch 12; iter: 400; batch classifier loss: 0.323026; batch adversarial loss: 0.725551\n",
      "epoch 13; iter: 0; batch classifier loss: 0.306055; batch adversarial loss: 0.636022\n",
      "epoch 13; iter: 200; batch classifier loss: 0.318247; batch adversarial loss: 0.685539\n",
      "epoch 13; iter: 400; batch classifier loss: 0.361727; batch adversarial loss: 0.697259\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292918; batch adversarial loss: 0.619071\n",
      "epoch 14; iter: 200; batch classifier loss: 0.429102; batch adversarial loss: 0.649253\n",
      "epoch 14; iter: 400; batch classifier loss: 0.648703; batch adversarial loss: 0.636165\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324778; batch adversarial loss: 0.606269\n",
      "epoch 15; iter: 200; batch classifier loss: 0.480358; batch adversarial loss: 0.631537\n",
      "epoch 15; iter: 400; batch classifier loss: 0.446597; batch adversarial loss: 0.586730\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333326; batch adversarial loss: 0.671434\n",
      "epoch 16; iter: 200; batch classifier loss: 0.485987; batch adversarial loss: 0.577264\n",
      "epoch 16; iter: 400; batch classifier loss: 0.423712; batch adversarial loss: 0.626702\n",
      "epoch 17; iter: 0; batch classifier loss: 0.223440; batch adversarial loss: 0.606466\n",
      "epoch 17; iter: 200; batch classifier loss: 0.403982; batch adversarial loss: 0.607902\n",
      "epoch 17; iter: 400; batch classifier loss: 0.407935; batch adversarial loss: 0.630076\n",
      "epoch 18; iter: 0; batch classifier loss: 0.395230; batch adversarial loss: 0.649307\n",
      "epoch 18; iter: 200; batch classifier loss: 0.444172; batch adversarial loss: 0.616028\n",
      "epoch 18; iter: 400; batch classifier loss: 0.636161; batch adversarial loss: 0.663729\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444630; batch adversarial loss: 0.622512\n",
      "epoch 19; iter: 200; batch classifier loss: 0.242669; batch adversarial loss: 0.711318\n",
      "epoch 19; iter: 400; batch classifier loss: 0.266933; batch adversarial loss: 0.630650\n",
      "epoch 0; iter: 0; batch classifier loss: 124.944824; batch adversarial loss: 0.704938\n",
      "epoch 0; iter: 200; batch classifier loss: 16.444572; batch adversarial loss: 0.850366\n",
      "epoch 0; iter: 400; batch classifier loss: 15.645914; batch adversarial loss: 0.860142\n",
      "epoch 1; iter: 0; batch classifier loss: 9.838438; batch adversarial loss: 0.831487\n",
      "epoch 1; iter: 200; batch classifier loss: 12.773540; batch adversarial loss: 0.675077\n",
      "epoch 1; iter: 400; batch classifier loss: 4.243055; batch adversarial loss: 0.621004\n",
      "epoch 2; iter: 0; batch classifier loss: 4.939573; batch adversarial loss: 0.686226\n",
      "epoch 2; iter: 200; batch classifier loss: 3.206124; batch adversarial loss: 0.675167\n",
      "epoch 2; iter: 400; batch classifier loss: 4.362284; batch adversarial loss: 0.669371\n",
      "epoch 3; iter: 0; batch classifier loss: 1.429534; batch adversarial loss: 0.601710\n",
      "epoch 3; iter: 200; batch classifier loss: 0.473637; batch adversarial loss: 0.554729\n",
      "epoch 3; iter: 400; batch classifier loss: 4.201987; batch adversarial loss: 0.630946\n",
      "epoch 4; iter: 0; batch classifier loss: 1.973082; batch adversarial loss: 0.590317\n",
      "epoch 4; iter: 200; batch classifier loss: 1.621652; batch adversarial loss: 0.531936\n",
      "epoch 4; iter: 400; batch classifier loss: 1.087380; batch adversarial loss: 0.638185\n",
      "epoch 5; iter: 0; batch classifier loss: 0.482463; batch adversarial loss: 0.611961\n",
      "epoch 5; iter: 200; batch classifier loss: 1.211740; batch adversarial loss: 0.687792\n",
      "epoch 5; iter: 400; batch classifier loss: 0.582137; batch adversarial loss: 0.566841\n",
      "epoch 6; iter: 0; batch classifier loss: 0.333187; batch adversarial loss: 0.568859\n",
      "epoch 6; iter: 200; batch classifier loss: 0.459892; batch adversarial loss: 0.634447\n",
      "epoch 6; iter: 400; batch classifier loss: 0.548923; batch adversarial loss: 0.660942\n",
      "epoch 7; iter: 0; batch classifier loss: 3.591253; batch adversarial loss: 0.574010\n",
      "epoch 7; iter: 200; batch classifier loss: 0.606909; batch adversarial loss: 0.607327\n",
      "epoch 7; iter: 400; batch classifier loss: 1.200442; batch adversarial loss: 0.569507\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466637; batch adversarial loss: 0.705677\n",
      "epoch 8; iter: 200; batch classifier loss: 0.340273; batch adversarial loss: 0.663472\n",
      "epoch 8; iter: 400; batch classifier loss: 0.557068; batch adversarial loss: 0.663461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627773; batch adversarial loss: 0.587287\n",
      "epoch 9; iter: 200; batch classifier loss: 0.433715; batch adversarial loss: 0.620127\n",
      "epoch 9; iter: 400; batch classifier loss: 0.729257; batch adversarial loss: 0.575494\n",
      "epoch 10; iter: 0; batch classifier loss: 0.412582; batch adversarial loss: 0.623470\n",
      "epoch 10; iter: 200; batch classifier loss: 0.422656; batch adversarial loss: 0.697444\n",
      "epoch 10; iter: 400; batch classifier loss: 0.585212; batch adversarial loss: 0.605215\n",
      "epoch 11; iter: 0; batch classifier loss: 0.357543; batch adversarial loss: 0.633847\n",
      "epoch 11; iter: 200; batch classifier loss: 0.350106; batch adversarial loss: 0.719603\n",
      "epoch 11; iter: 400; batch classifier loss: 0.424872; batch adversarial loss: 0.555405\n",
      "epoch 12; iter: 0; batch classifier loss: 0.650377; batch adversarial loss: 0.664392\n",
      "epoch 12; iter: 200; batch classifier loss: 0.401865; batch adversarial loss: 0.567108\n",
      "epoch 12; iter: 400; batch classifier loss: 0.415265; batch adversarial loss: 0.666546\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381548; batch adversarial loss: 0.631141\n",
      "epoch 13; iter: 200; batch classifier loss: 0.372826; batch adversarial loss: 0.614812\n",
      "epoch 13; iter: 400; batch classifier loss: 0.398875; batch adversarial loss: 0.681130\n",
      "epoch 14; iter: 0; batch classifier loss: 0.505724; batch adversarial loss: 0.623091\n",
      "epoch 14; iter: 200; batch classifier loss: 0.287175; batch adversarial loss: 0.713318\n",
      "epoch 14; iter: 400; batch classifier loss: 0.423586; batch adversarial loss: 0.600838\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435689; batch adversarial loss: 0.510922\n",
      "epoch 15; iter: 200; batch classifier loss: 0.344656; batch adversarial loss: 0.670118\n",
      "epoch 15; iter: 400; batch classifier loss: 0.346207; batch adversarial loss: 0.731754\n",
      "epoch 16; iter: 0; batch classifier loss: 0.447610; batch adversarial loss: 0.629916\n",
      "epoch 16; iter: 200; batch classifier loss: 0.400568; batch adversarial loss: 0.619527\n",
      "epoch 16; iter: 400; batch classifier loss: 0.363131; batch adversarial loss: 0.652276\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327063; batch adversarial loss: 0.606058\n",
      "epoch 17; iter: 200; batch classifier loss: 0.335203; batch adversarial loss: 0.671556\n",
      "epoch 17; iter: 400; batch classifier loss: 0.417029; batch adversarial loss: 0.603452\n",
      "epoch 18; iter: 0; batch classifier loss: 0.353467; batch adversarial loss: 0.641120\n",
      "epoch 18; iter: 200; batch classifier loss: 0.483855; batch adversarial loss: 0.614051\n",
      "epoch 18; iter: 400; batch classifier loss: 0.362601; batch adversarial loss: 0.671317\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424173; batch adversarial loss: 0.687018\n",
      "epoch 19; iter: 200; batch classifier loss: 0.272966; batch adversarial loss: 0.669703\n",
      "epoch 19; iter: 400; batch classifier loss: 0.331518; batch adversarial loss: 0.666358\n",
      "epoch 0; iter: 0; batch classifier loss: 19.416721; batch adversarial loss: 0.731452\n",
      "epoch 0; iter: 200; batch classifier loss: 1.079721; batch adversarial loss: 0.684639\n",
      "epoch 0; iter: 400; batch classifier loss: 3.198154; batch adversarial loss: 0.665822\n",
      "epoch 1; iter: 0; batch classifier loss: 5.794414; batch adversarial loss: 0.656841\n",
      "epoch 1; iter: 200; batch classifier loss: 6.498414; batch adversarial loss: 0.629788\n",
      "epoch 1; iter: 400; batch classifier loss: 3.434126; batch adversarial loss: 0.619606\n",
      "epoch 2; iter: 0; batch classifier loss: 2.540505; batch adversarial loss: 0.550273\n",
      "epoch 2; iter: 200; batch classifier loss: 3.094433; batch adversarial loss: 0.601883\n",
      "epoch 2; iter: 400; batch classifier loss: 1.388258; batch adversarial loss: 0.660889\n",
      "epoch 3; iter: 0; batch classifier loss: 1.478001; batch adversarial loss: 0.540702\n",
      "epoch 3; iter: 200; batch classifier loss: 0.860658; batch adversarial loss: 0.663391\n",
      "epoch 3; iter: 400; batch classifier loss: 0.530665; batch adversarial loss: 0.654850\n",
      "epoch 4; iter: 0; batch classifier loss: 0.700074; batch adversarial loss: 0.621754\n",
      "epoch 4; iter: 200; batch classifier loss: 0.842437; batch adversarial loss: 0.587525\n",
      "epoch 4; iter: 400; batch classifier loss: 1.453050; batch adversarial loss: 0.634628\n",
      "epoch 5; iter: 0; batch classifier loss: 0.814972; batch adversarial loss: 0.571380\n",
      "epoch 5; iter: 200; batch classifier loss: 0.705785; batch adversarial loss: 0.643724\n",
      "epoch 5; iter: 400; batch classifier loss: 0.822590; batch adversarial loss: 0.549208\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517384; batch adversarial loss: 0.561081\n",
      "epoch 6; iter: 200; batch classifier loss: 0.392659; batch adversarial loss: 0.635459\n",
      "epoch 6; iter: 400; batch classifier loss: 0.461869; batch adversarial loss: 0.585963\n",
      "epoch 7; iter: 0; batch classifier loss: 0.648933; batch adversarial loss: 0.689608\n",
      "epoch 7; iter: 200; batch classifier loss: 0.396810; batch adversarial loss: 0.594642\n",
      "epoch 7; iter: 400; batch classifier loss: 0.448344; batch adversarial loss: 0.602277\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568870; batch adversarial loss: 0.653360\n",
      "epoch 8; iter: 200; batch classifier loss: 0.449425; batch adversarial loss: 0.585104\n",
      "epoch 8; iter: 400; batch classifier loss: 0.392309; batch adversarial loss: 0.671010\n",
      "epoch 9; iter: 0; batch classifier loss: 0.744136; batch adversarial loss: 0.606747\n",
      "epoch 9; iter: 200; batch classifier loss: 0.403955; batch adversarial loss: 0.649836\n",
      "epoch 9; iter: 400; batch classifier loss: 0.386504; batch adversarial loss: 0.672371\n",
      "epoch 10; iter: 0; batch classifier loss: 0.439763; batch adversarial loss: 0.633159\n",
      "epoch 10; iter: 200; batch classifier loss: 0.276376; batch adversarial loss: 0.605310\n",
      "epoch 10; iter: 400; batch classifier loss: 0.341651; batch adversarial loss: 0.594417\n",
      "epoch 11; iter: 0; batch classifier loss: 0.335900; batch adversarial loss: 0.570353\n",
      "epoch 11; iter: 200; batch classifier loss: 0.357948; batch adversarial loss: 0.600949\n",
      "epoch 11; iter: 400; batch classifier loss: 0.345054; batch adversarial loss: 0.561435\n",
      "epoch 12; iter: 0; batch classifier loss: 0.627762; batch adversarial loss: 0.608493\n",
      "epoch 12; iter: 200; batch classifier loss: 0.384843; batch adversarial loss: 0.643878\n",
      "epoch 12; iter: 400; batch classifier loss: 0.278233; batch adversarial loss: 0.641398\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491157; batch adversarial loss: 0.658543\n",
      "epoch 13; iter: 200; batch classifier loss: 0.456875; batch adversarial loss: 0.580491\n",
      "epoch 13; iter: 400; batch classifier loss: 0.437832; batch adversarial loss: 0.678375\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438394; batch adversarial loss: 0.654732\n",
      "epoch 14; iter: 200; batch classifier loss: 0.258998; batch adversarial loss: 0.622979\n",
      "epoch 14; iter: 400; batch classifier loss: 0.558187; batch adversarial loss: 0.620440\n",
      "epoch 15; iter: 0; batch classifier loss: 0.305790; batch adversarial loss: 0.599329\n",
      "epoch 15; iter: 200; batch classifier loss: 0.357636; batch adversarial loss: 0.675708\n",
      "epoch 15; iter: 400; batch classifier loss: 0.376915; batch adversarial loss: 0.555456\n",
      "epoch 16; iter: 0; batch classifier loss: 0.432598; batch adversarial loss: 0.640200\n",
      "epoch 16; iter: 200; batch classifier loss: 0.416266; batch adversarial loss: 0.632465\n",
      "epoch 16; iter: 400; batch classifier loss: 0.382533; batch adversarial loss: 0.621800\n",
      "epoch 17; iter: 0; batch classifier loss: 1.116328; batch adversarial loss: 0.554690\n",
      "epoch 17; iter: 200; batch classifier loss: 0.483931; batch adversarial loss: 0.599679\n",
      "epoch 17; iter: 400; batch classifier loss: 0.431980; batch adversarial loss: 0.574810\n",
      "epoch 18; iter: 0; batch classifier loss: 0.290776; batch adversarial loss: 0.604131\n",
      "epoch 18; iter: 200; batch classifier loss: 0.391771; batch adversarial loss: 0.609994\n",
      "epoch 18; iter: 400; batch classifier loss: 0.435257; batch adversarial loss: 0.545621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.285913; batch adversarial loss: 0.670317\n",
      "epoch 19; iter: 200; batch classifier loss: 0.448074; batch adversarial loss: 0.688140\n",
      "epoch 19; iter: 400; batch classifier loss: 0.396989; batch adversarial loss: 0.733392\n",
      "epoch 0; iter: 0; batch classifier loss: 157.081970; batch adversarial loss: 0.771106\n",
      "epoch 0; iter: 200; batch classifier loss: 14.707429; batch adversarial loss: 0.687635\n",
      "epoch 0; iter: 400; batch classifier loss: 8.569075; batch adversarial loss: 0.687645\n",
      "epoch 1; iter: 0; batch classifier loss: 4.735103; batch adversarial loss: 0.660759\n",
      "epoch 1; iter: 200; batch classifier loss: 1.574515; batch adversarial loss: 0.683460\n",
      "epoch 1; iter: 400; batch classifier loss: 5.091156; batch adversarial loss: 0.651437\n",
      "epoch 2; iter: 0; batch classifier loss: 0.953633; batch adversarial loss: 0.581011\n",
      "epoch 2; iter: 200; batch classifier loss: 2.168811; batch adversarial loss: 0.646777\n",
      "epoch 2; iter: 400; batch classifier loss: 0.616953; batch adversarial loss: 0.568203\n",
      "epoch 3; iter: 0; batch classifier loss: 0.315861; batch adversarial loss: 0.642032\n",
      "epoch 3; iter: 200; batch classifier loss: 1.389458; batch adversarial loss: 0.599073\n",
      "epoch 3; iter: 400; batch classifier loss: 0.668303; batch adversarial loss: 0.634474\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577635; batch adversarial loss: 0.655616\n",
      "epoch 4; iter: 200; batch classifier loss: 1.908649; batch adversarial loss: 0.643349\n",
      "epoch 4; iter: 400; batch classifier loss: 0.502371; batch adversarial loss: 0.627583\n",
      "epoch 5; iter: 0; batch classifier loss: 0.308791; batch adversarial loss: 0.580655\n",
      "epoch 5; iter: 200; batch classifier loss: 0.820219; batch adversarial loss: 0.656414\n",
      "epoch 5; iter: 400; batch classifier loss: 0.441200; batch adversarial loss: 0.676366\n",
      "epoch 6; iter: 0; batch classifier loss: 0.358081; batch adversarial loss: 0.560651\n",
      "epoch 6; iter: 200; batch classifier loss: 0.589461; batch adversarial loss: 0.655136\n",
      "epoch 6; iter: 400; batch classifier loss: 0.426740; batch adversarial loss: 0.575664\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385909; batch adversarial loss: 0.556018\n",
      "epoch 7; iter: 200; batch classifier loss: 0.325610; batch adversarial loss: 0.658017\n",
      "epoch 7; iter: 400; batch classifier loss: 0.502941; batch adversarial loss: 0.630482\n",
      "epoch 8; iter: 0; batch classifier loss: 0.494848; batch adversarial loss: 0.661899\n",
      "epoch 8; iter: 200; batch classifier loss: 0.311578; batch adversarial loss: 0.642047\n",
      "epoch 8; iter: 400; batch classifier loss: 0.563423; batch adversarial loss: 0.698024\n",
      "epoch 9; iter: 0; batch classifier loss: 0.186097; batch adversarial loss: 0.622702\n",
      "epoch 9; iter: 200; batch classifier loss: 0.390067; batch adversarial loss: 0.700353\n",
      "epoch 9; iter: 400; batch classifier loss: 0.386543; batch adversarial loss: 0.584550\n",
      "epoch 10; iter: 0; batch classifier loss: 0.436403; batch adversarial loss: 0.641815\n",
      "epoch 10; iter: 200; batch classifier loss: 0.337101; batch adversarial loss: 0.615039\n",
      "epoch 10; iter: 400; batch classifier loss: 0.485469; batch adversarial loss: 0.581431\n",
      "epoch 11; iter: 0; batch classifier loss: 0.341530; batch adversarial loss: 0.652714\n",
      "epoch 11; iter: 200; batch classifier loss: 0.424196; batch adversarial loss: 0.658882\n",
      "epoch 11; iter: 400; batch classifier loss: 0.395255; batch adversarial loss: 0.520962\n",
      "epoch 12; iter: 0; batch classifier loss: 0.205166; batch adversarial loss: 0.586132\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391073; batch adversarial loss: 0.610742\n",
      "epoch 12; iter: 400; batch classifier loss: 0.399006; batch adversarial loss: 0.579091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373022; batch adversarial loss: 0.661176\n",
      "epoch 13; iter: 200; batch classifier loss: 0.429483; batch adversarial loss: 0.681878\n",
      "epoch 13; iter: 400; batch classifier loss: 0.295054; batch adversarial loss: 0.631927\n",
      "epoch 14; iter: 0; batch classifier loss: 0.400048; batch adversarial loss: 0.685079\n",
      "epoch 14; iter: 200; batch classifier loss: 0.372284; batch adversarial loss: 0.523445\n",
      "epoch 14; iter: 400; batch classifier loss: 0.382636; batch adversarial loss: 0.626891\n",
      "epoch 15; iter: 0; batch classifier loss: 0.407214; batch adversarial loss: 0.574923\n",
      "epoch 15; iter: 200; batch classifier loss: 0.220827; batch adversarial loss: 0.690254\n",
      "epoch 15; iter: 400; batch classifier loss: 0.451400; batch adversarial loss: 0.615191\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296899; batch adversarial loss: 0.579268\n",
      "epoch 16; iter: 200; batch classifier loss: 0.513580; batch adversarial loss: 0.564335\n",
      "epoch 16; iter: 400; batch classifier loss: 0.384692; batch adversarial loss: 0.595222\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317787; batch adversarial loss: 0.676008\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349471; batch adversarial loss: 0.639417\n",
      "epoch 17; iter: 400; batch classifier loss: 0.223432; batch adversarial loss: 0.633470\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528141; batch adversarial loss: 0.579702\n",
      "epoch 18; iter: 200; batch classifier loss: 0.233497; batch adversarial loss: 0.645656\n",
      "epoch 18; iter: 400; batch classifier loss: 0.448799; batch adversarial loss: 0.588310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469142; batch adversarial loss: 0.662848\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346512; batch adversarial loss: 0.595298\n",
      "epoch 19; iter: 400; batch classifier loss: 0.457243; batch adversarial loss: 0.682600\n",
      "epoch 0; iter: 0; batch classifier loss: 18.082769; batch adversarial loss: 0.649463\n",
      "epoch 0; iter: 200; batch classifier loss: 6.842044; batch adversarial loss: 0.656661\n",
      "epoch 0; iter: 400; batch classifier loss: 6.757964; batch adversarial loss: 0.652622\n",
      "epoch 1; iter: 0; batch classifier loss: 3.704843; batch adversarial loss: 0.581402\n",
      "epoch 1; iter: 200; batch classifier loss: 9.221821; batch adversarial loss: 0.617958\n",
      "epoch 1; iter: 400; batch classifier loss: 5.488484; batch adversarial loss: 0.589556\n",
      "epoch 2; iter: 0; batch classifier loss: 3.980595; batch adversarial loss: 0.661202\n",
      "epoch 2; iter: 200; batch classifier loss: 1.160800; batch adversarial loss: 0.603763\n",
      "epoch 2; iter: 400; batch classifier loss: 2.119510; batch adversarial loss: 0.623235\n",
      "epoch 3; iter: 0; batch classifier loss: 2.512484; batch adversarial loss: 0.582109\n",
      "epoch 3; iter: 200; batch classifier loss: 0.699277; batch adversarial loss: 0.583488\n",
      "epoch 3; iter: 400; batch classifier loss: 0.532973; batch adversarial loss: 0.633108\n",
      "epoch 4; iter: 0; batch classifier loss: 1.221090; batch adversarial loss: 0.579761\n",
      "epoch 4; iter: 200; batch classifier loss: 0.554866; batch adversarial loss: 0.676978\n",
      "epoch 4; iter: 400; batch classifier loss: 0.393447; batch adversarial loss: 0.645190\n",
      "epoch 5; iter: 0; batch classifier loss: 1.079016; batch adversarial loss: 0.573905\n",
      "epoch 5; iter: 200; batch classifier loss: 0.367719; batch adversarial loss: 0.584674\n",
      "epoch 5; iter: 400; batch classifier loss: 0.371436; batch adversarial loss: 0.641642\n",
      "epoch 6; iter: 0; batch classifier loss: 0.371869; batch adversarial loss: 0.619664\n",
      "epoch 6; iter: 200; batch classifier loss: 0.603202; batch adversarial loss: 0.675980\n",
      "epoch 6; iter: 400; batch classifier loss: 0.277235; batch adversarial loss: 0.656143\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548424; batch adversarial loss: 0.589307\n",
      "epoch 7; iter: 200; batch classifier loss: 0.483753; batch adversarial loss: 0.685873\n",
      "epoch 7; iter: 400; batch classifier loss: 0.374712; batch adversarial loss: 0.583683\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552587; batch adversarial loss: 0.541257\n",
      "epoch 8; iter: 200; batch classifier loss: 0.390617; batch adversarial loss: 0.665289\n",
      "epoch 8; iter: 400; batch classifier loss: 0.284311; batch adversarial loss: 0.607340\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528317; batch adversarial loss: 0.695609\n",
      "epoch 9; iter: 200; batch classifier loss: 0.456913; batch adversarial loss: 0.529809\n",
      "epoch 9; iter: 400; batch classifier loss: 0.692178; batch adversarial loss: 0.658679\n",
      "epoch 10; iter: 0; batch classifier loss: 0.202185; batch adversarial loss: 0.643458\n",
      "epoch 10; iter: 200; batch classifier loss: 0.303182; batch adversarial loss: 0.619320\n",
      "epoch 10; iter: 400; batch classifier loss: 0.321786; batch adversarial loss: 0.610727\n",
      "epoch 11; iter: 0; batch classifier loss: 0.243516; batch adversarial loss: 0.600643\n",
      "epoch 11; iter: 200; batch classifier loss: 0.255895; batch adversarial loss: 0.641343\n",
      "epoch 11; iter: 400; batch classifier loss: 0.234979; batch adversarial loss: 0.636886\n",
      "epoch 12; iter: 0; batch classifier loss: 0.434886; batch adversarial loss: 0.650035\n",
      "epoch 12; iter: 200; batch classifier loss: 0.349794; batch adversarial loss: 0.693673\n",
      "epoch 12; iter: 400; batch classifier loss: 0.503922; batch adversarial loss: 0.575848\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336732; batch adversarial loss: 0.595392\n",
      "epoch 13; iter: 200; batch classifier loss: 0.431969; batch adversarial loss: 0.659873\n",
      "epoch 13; iter: 400; batch classifier loss: 0.660683; batch adversarial loss: 0.685647\n",
      "epoch 14; iter: 0; batch classifier loss: 0.439932; batch adversarial loss: 0.534769\n",
      "epoch 14; iter: 200; batch classifier loss: 0.433739; batch adversarial loss: 0.595727\n",
      "epoch 14; iter: 400; batch classifier loss: 0.389451; batch adversarial loss: 0.639969\n",
      "epoch 15; iter: 0; batch classifier loss: 0.378860; batch adversarial loss: 0.618611\n",
      "epoch 15; iter: 200; batch classifier loss: 0.344171; batch adversarial loss: 0.659777\n",
      "epoch 15; iter: 400; batch classifier loss: 0.284658; batch adversarial loss: 0.658077\n",
      "epoch 16; iter: 0; batch classifier loss: 0.396443; batch adversarial loss: 0.710691\n",
      "epoch 16; iter: 200; batch classifier loss: 0.529602; batch adversarial loss: 0.635360\n",
      "epoch 16; iter: 400; batch classifier loss: 0.464371; batch adversarial loss: 0.587533\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339017; batch adversarial loss: 0.722853\n",
      "epoch 17; iter: 200; batch classifier loss: 0.308259; batch adversarial loss: 0.677032\n",
      "epoch 17; iter: 400; batch classifier loss: 0.357356; batch adversarial loss: 0.707525\n",
      "epoch 18; iter: 0; batch classifier loss: 0.392247; batch adversarial loss: 0.623836\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321531; batch adversarial loss: 0.625322\n",
      "epoch 18; iter: 400; batch classifier loss: 0.472126; batch adversarial loss: 0.570514\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505262; batch adversarial loss: 0.550868\n",
      "epoch 19; iter: 200; batch classifier loss: 0.197342; batch adversarial loss: 0.687551\n",
      "epoch 19; iter: 400; batch classifier loss: 0.488639; batch adversarial loss: 0.648261\n",
      "epoch 0; iter: 0; batch classifier loss: 12.867870; batch adversarial loss: 1.106623\n",
      "epoch 0; iter: 200; batch classifier loss: 13.812483; batch adversarial loss: 0.777904\n",
      "epoch 0; iter: 400; batch classifier loss: 6.214249; batch adversarial loss: 0.718487\n",
      "epoch 1; iter: 0; batch classifier loss: 7.992464; batch adversarial loss: 0.747040\n",
      "epoch 1; iter: 200; batch classifier loss: 8.682899; batch adversarial loss: 0.703205\n",
      "epoch 1; iter: 400; batch classifier loss: 4.736349; batch adversarial loss: 0.663807\n",
      "epoch 2; iter: 0; batch classifier loss: 3.720506; batch adversarial loss: 0.720201\n",
      "epoch 2; iter: 200; batch classifier loss: 4.990421; batch adversarial loss: 0.593009\n",
      "epoch 2; iter: 400; batch classifier loss: 0.757206; batch adversarial loss: 0.737641\n",
      "epoch 3; iter: 0; batch classifier loss: 2.236837; batch adversarial loss: 0.578193\n",
      "epoch 3; iter: 200; batch classifier loss: 1.194426; batch adversarial loss: 0.633410\n",
      "epoch 3; iter: 400; batch classifier loss: 0.738575; batch adversarial loss: 0.674500\n",
      "epoch 4; iter: 0; batch classifier loss: 0.767042; batch adversarial loss: 0.583923\n",
      "epoch 4; iter: 200; batch classifier loss: 1.246617; batch adversarial loss: 0.662380\n",
      "epoch 4; iter: 400; batch classifier loss: 0.802102; batch adversarial loss: 0.503190\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365417; batch adversarial loss: 0.612406\n",
      "epoch 5; iter: 200; batch classifier loss: 0.613438; batch adversarial loss: 0.594213\n",
      "epoch 5; iter: 400; batch classifier loss: 0.362734; batch adversarial loss: 0.509486\n",
      "epoch 6; iter: 0; batch classifier loss: 0.417565; batch adversarial loss: 0.660906\n",
      "epoch 6; iter: 200; batch classifier loss: 0.429713; batch adversarial loss: 0.607550\n",
      "epoch 6; iter: 400; batch classifier loss: 0.490169; batch adversarial loss: 0.569245\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569160; batch adversarial loss: 0.638764\n",
      "epoch 7; iter: 200; batch classifier loss: 0.403458; batch adversarial loss: 0.644121\n",
      "epoch 7; iter: 400; batch classifier loss: 0.997613; batch adversarial loss: 0.572228\n",
      "epoch 8; iter: 0; batch classifier loss: 0.420090; batch adversarial loss: 0.623733\n",
      "epoch 8; iter: 200; batch classifier loss: 0.417693; batch adversarial loss: 0.638713\n",
      "epoch 8; iter: 400; batch classifier loss: 0.334699; batch adversarial loss: 0.660224\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500721; batch adversarial loss: 0.671864\n",
      "epoch 9; iter: 200; batch classifier loss: 0.469179; batch adversarial loss: 0.609032\n",
      "epoch 9; iter: 400; batch classifier loss: 0.435714; batch adversarial loss: 0.564976\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321901; batch adversarial loss: 0.577771\n",
      "epoch 10; iter: 200; batch classifier loss: 0.505575; batch adversarial loss: 0.599130\n",
      "epoch 10; iter: 400; batch classifier loss: 0.459143; batch adversarial loss: 0.680200\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361566; batch adversarial loss: 0.559742\n",
      "epoch 11; iter: 200; batch classifier loss: 0.277256; batch adversarial loss: 0.599988\n",
      "epoch 11; iter: 400; batch classifier loss: 0.274181; batch adversarial loss: 0.622035\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310098; batch adversarial loss: 0.656262\n",
      "epoch 12; iter: 200; batch classifier loss: 0.282629; batch adversarial loss: 0.697606\n",
      "epoch 12; iter: 400; batch classifier loss: 0.479021; batch adversarial loss: 0.614715\n",
      "epoch 13; iter: 0; batch classifier loss: 0.377047; batch adversarial loss: 0.638677\n",
      "epoch 13; iter: 200; batch classifier loss: 0.423518; batch adversarial loss: 0.674532\n",
      "epoch 13; iter: 400; batch classifier loss: 0.370507; batch adversarial loss: 0.610629\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334612; batch adversarial loss: 0.553041\n",
      "epoch 14; iter: 200; batch classifier loss: 0.442747; batch adversarial loss: 0.530148\n",
      "epoch 14; iter: 400; batch classifier loss: 0.329680; batch adversarial loss: 0.636281\n",
      "epoch 15; iter: 0; batch classifier loss: 0.280639; batch adversarial loss: 0.602891\n",
      "epoch 15; iter: 200; batch classifier loss: 0.328457; batch adversarial loss: 0.566594\n",
      "epoch 15; iter: 400; batch classifier loss: 0.338208; batch adversarial loss: 0.674775\n",
      "epoch 16; iter: 0; batch classifier loss: 0.373975; batch adversarial loss: 0.633113\n",
      "epoch 16; iter: 200; batch classifier loss: 0.512161; batch adversarial loss: 0.611115\n",
      "epoch 16; iter: 400; batch classifier loss: 0.337111; batch adversarial loss: 0.636280\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486059; batch adversarial loss: 0.533104\n",
      "epoch 17; iter: 200; batch classifier loss: 0.454006; batch adversarial loss: 0.616463\n",
      "epoch 17; iter: 400; batch classifier loss: 0.300551; batch adversarial loss: 0.624624\n",
      "epoch 18; iter: 0; batch classifier loss: 0.241893; batch adversarial loss: 0.652840\n",
      "epoch 18; iter: 200; batch classifier loss: 0.370993; batch adversarial loss: 0.603097\n",
      "epoch 18; iter: 400; batch classifier loss: 0.334119; batch adversarial loss: 0.650937\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483828; batch adversarial loss: 0.692557\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429778; batch adversarial loss: 0.605344\n",
      "epoch 19; iter: 400; batch classifier loss: 0.392781; batch adversarial loss: 0.650119\n",
      "epoch 0; iter: 0; batch classifier loss: 469.916199; batch adversarial loss: 0.693147\n",
      "epoch 0; iter: 200; batch classifier loss: 1.193575; batch adversarial loss: 0.652282\n",
      "epoch 0; iter: 400; batch classifier loss: 0.480469; batch adversarial loss: 0.653369\n",
      "epoch 1; iter: 0; batch classifier loss: 3.658979; batch adversarial loss: 0.708968\n",
      "epoch 1; iter: 200; batch classifier loss: 2.450773; batch adversarial loss: 0.646551\n",
      "epoch 1; iter: 400; batch classifier loss: 6.266210; batch adversarial loss: 0.613547\n",
      "epoch 2; iter: 0; batch classifier loss: 0.811397; batch adversarial loss: 0.650702\n",
      "epoch 2; iter: 200; batch classifier loss: 0.865103; batch adversarial loss: 0.668735\n",
      "epoch 2; iter: 400; batch classifier loss: 4.830809; batch adversarial loss: 0.691367\n",
      "epoch 3; iter: 0; batch classifier loss: 0.839249; batch adversarial loss: 0.677354\n",
      "epoch 3; iter: 200; batch classifier loss: 0.671046; batch adversarial loss: 0.607814\n",
      "epoch 3; iter: 400; batch classifier loss: 0.483397; batch adversarial loss: 0.573624\n",
      "epoch 4; iter: 0; batch classifier loss: 1.799422; batch adversarial loss: 0.622526\n",
      "epoch 4; iter: 200; batch classifier loss: 0.634272; batch adversarial loss: 0.561241\n",
      "epoch 4; iter: 400; batch classifier loss: 0.612632; batch adversarial loss: 0.674484\n",
      "epoch 5; iter: 0; batch classifier loss: 0.627782; batch adversarial loss: 0.623182\n",
      "epoch 5; iter: 200; batch classifier loss: 1.610896; batch adversarial loss: 0.602062\n",
      "epoch 5; iter: 400; batch classifier loss: 0.305568; batch adversarial loss: 0.622890\n",
      "epoch 6; iter: 0; batch classifier loss: 0.380097; batch adversarial loss: 0.567697\n",
      "epoch 6; iter: 200; batch classifier loss: 0.596905; batch adversarial loss: 0.588214\n",
      "epoch 6; iter: 400; batch classifier loss: 0.355711; batch adversarial loss: 0.605217\n",
      "epoch 7; iter: 0; batch classifier loss: 0.735451; batch adversarial loss: 0.598065\n",
      "epoch 7; iter: 200; batch classifier loss: 0.444476; batch adversarial loss: 0.597591\n",
      "epoch 7; iter: 400; batch classifier loss: 0.338917; batch adversarial loss: 0.740945\n",
      "epoch 8; iter: 0; batch classifier loss: 0.301477; batch adversarial loss: 0.554386\n",
      "epoch 8; iter: 200; batch classifier loss: 0.311711; batch adversarial loss: 0.627091\n",
      "epoch 8; iter: 400; batch classifier loss: 0.532621; batch adversarial loss: 0.637313\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420262; batch adversarial loss: 0.733781\n",
      "epoch 9; iter: 200; batch classifier loss: 0.337361; batch adversarial loss: 0.639294\n",
      "epoch 9; iter: 400; batch classifier loss: 0.573277; batch adversarial loss: 0.609074\n",
      "epoch 10; iter: 0; batch classifier loss: 0.478797; batch adversarial loss: 0.687817\n",
      "epoch 10; iter: 200; batch classifier loss: 0.310170; batch adversarial loss: 0.634522\n",
      "epoch 10; iter: 400; batch classifier loss: 0.421741; batch adversarial loss: 0.598031\n",
      "epoch 11; iter: 0; batch classifier loss: 0.648137; batch adversarial loss: 0.539512\n",
      "epoch 11; iter: 200; batch classifier loss: 0.464537; batch adversarial loss: 0.597968\n",
      "epoch 11; iter: 400; batch classifier loss: 0.554515; batch adversarial loss: 0.595377\n",
      "epoch 12; iter: 0; batch classifier loss: 0.406614; batch adversarial loss: 0.645904\n",
      "epoch 12; iter: 200; batch classifier loss: 0.308002; batch adversarial loss: 0.602468\n",
      "epoch 12; iter: 400; batch classifier loss: 0.307482; batch adversarial loss: 0.636977\n",
      "epoch 13; iter: 0; batch classifier loss: 0.785336; batch adversarial loss: 0.672315\n",
      "epoch 13; iter: 200; batch classifier loss: 0.422689; batch adversarial loss: 0.611380\n",
      "epoch 13; iter: 400; batch classifier loss: 0.257861; batch adversarial loss: 0.707991\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459973; batch adversarial loss: 0.612619\n",
      "epoch 14; iter: 200; batch classifier loss: 0.464994; batch adversarial loss: 0.573119\n",
      "epoch 14; iter: 400; batch classifier loss: 0.385750; batch adversarial loss: 0.618799\n",
      "epoch 15; iter: 0; batch classifier loss: 0.404826; batch adversarial loss: 0.694351\n",
      "epoch 15; iter: 200; batch classifier loss: 0.421386; batch adversarial loss: 0.627724\n",
      "epoch 15; iter: 400; batch classifier loss: 0.306928; batch adversarial loss: 0.634115\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324202; batch adversarial loss: 0.744900\n",
      "epoch 16; iter: 200; batch classifier loss: 0.445732; batch adversarial loss: 0.588144\n",
      "epoch 16; iter: 400; batch classifier loss: 0.294058; batch adversarial loss: 0.637989\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289868; batch adversarial loss: 0.580390\n",
      "epoch 17; iter: 200; batch classifier loss: 0.360708; batch adversarial loss: 0.570202\n",
      "epoch 17; iter: 400; batch classifier loss: 0.449259; batch adversarial loss: 0.594035\n",
      "epoch 18; iter: 0; batch classifier loss: 0.289035; batch adversarial loss: 0.647105\n",
      "epoch 18; iter: 200; batch classifier loss: 0.439421; batch adversarial loss: 0.613561\n",
      "epoch 18; iter: 400; batch classifier loss: 0.309186; batch adversarial loss: 0.632750\n",
      "epoch 19; iter: 0; batch classifier loss: 0.353099; batch adversarial loss: 0.675617\n",
      "epoch 19; iter: 200; batch classifier loss: 0.282183; batch adversarial loss: 0.638331\n",
      "epoch 19; iter: 400; batch classifier loss: 0.331580; batch adversarial loss: 0.650011\n",
      "epoch 0; iter: 0; batch classifier loss: 80.543625; batch adversarial loss: 0.703239\n",
      "epoch 0; iter: 200; batch classifier loss: 12.468120; batch adversarial loss: 0.642780\n",
      "epoch 0; iter: 400; batch classifier loss: 5.576724; batch adversarial loss: 0.627064\n",
      "epoch 1; iter: 0; batch classifier loss: 3.148079; batch adversarial loss: 0.627067\n",
      "epoch 1; iter: 200; batch classifier loss: 0.936512; batch adversarial loss: 0.671332\n",
      "epoch 1; iter: 400; batch classifier loss: 9.227365; batch adversarial loss: 0.647207\n",
      "epoch 2; iter: 0; batch classifier loss: 3.944379; batch adversarial loss: 0.613633\n",
      "epoch 2; iter: 200; batch classifier loss: 0.440993; batch adversarial loss: 0.647096\n",
      "epoch 2; iter: 400; batch classifier loss: 5.291919; batch adversarial loss: 0.648337\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406363; batch adversarial loss: 0.516896\n",
      "epoch 3; iter: 200; batch classifier loss: 1.068527; batch adversarial loss: 0.617811\n",
      "epoch 3; iter: 400; batch classifier loss: 1.255971; batch adversarial loss: 0.573479\n",
      "epoch 4; iter: 0; batch classifier loss: 0.986332; batch adversarial loss: 0.635814\n",
      "epoch 4; iter: 200; batch classifier loss: 0.566318; batch adversarial loss: 0.662810\n",
      "epoch 4; iter: 400; batch classifier loss: 1.329402; batch adversarial loss: 0.618989\n",
      "epoch 5; iter: 0; batch classifier loss: 0.438345; batch adversarial loss: 0.609896\n",
      "epoch 5; iter: 200; batch classifier loss: 0.474623; batch adversarial loss: 0.612339\n",
      "epoch 5; iter: 400; batch classifier loss: 0.714634; batch adversarial loss: 0.631190\n",
      "epoch 6; iter: 0; batch classifier loss: 1.027600; batch adversarial loss: 0.648246\n",
      "epoch 6; iter: 200; batch classifier loss: 0.492334; batch adversarial loss: 0.548810\n",
      "epoch 6; iter: 400; batch classifier loss: 0.497327; batch adversarial loss: 0.638258\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456420; batch adversarial loss: 0.640907\n",
      "epoch 7; iter: 200; batch classifier loss: 0.224053; batch adversarial loss: 0.625742\n",
      "epoch 7; iter: 400; batch classifier loss: 0.290722; batch adversarial loss: 0.703415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342826; batch adversarial loss: 0.641350\n",
      "epoch 8; iter: 200; batch classifier loss: 0.283809; batch adversarial loss: 0.626777\n",
      "epoch 8; iter: 400; batch classifier loss: 0.872227; batch adversarial loss: 0.614521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437449; batch adversarial loss: 0.624659\n",
      "epoch 9; iter: 200; batch classifier loss: 0.312062; batch adversarial loss: 0.670777\n",
      "epoch 9; iter: 400; batch classifier loss: 0.237226; batch adversarial loss: 0.564613\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375770; batch adversarial loss: 0.624780\n",
      "epoch 10; iter: 200; batch classifier loss: 0.463737; batch adversarial loss: 0.556373\n",
      "epoch 10; iter: 400; batch classifier loss: 0.372495; batch adversarial loss: 0.557776\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331164; batch adversarial loss: 0.600532\n",
      "epoch 11; iter: 200; batch classifier loss: 0.278845; batch adversarial loss: 0.688007\n",
      "epoch 11; iter: 400; batch classifier loss: 0.401176; batch adversarial loss: 0.606847\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469397; batch adversarial loss: 0.577133\n",
      "epoch 12; iter: 200; batch classifier loss: 0.301818; batch adversarial loss: 0.616560\n",
      "epoch 12; iter: 400; batch classifier loss: 0.314571; batch adversarial loss: 0.657202\n",
      "epoch 13; iter: 0; batch classifier loss: 0.288693; batch adversarial loss: 0.603848\n",
      "epoch 13; iter: 200; batch classifier loss: 0.399269; batch adversarial loss: 0.697279\n",
      "epoch 13; iter: 400; batch classifier loss: 0.312832; batch adversarial loss: 0.668966\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354266; batch adversarial loss: 0.645161\n",
      "epoch 14; iter: 200; batch classifier loss: 0.368592; batch adversarial loss: 0.671575\n",
      "epoch 14; iter: 400; batch classifier loss: 0.496549; batch adversarial loss: 0.580241\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289303; batch adversarial loss: 0.657419\n",
      "epoch 15; iter: 200; batch classifier loss: 0.481733; batch adversarial loss: 0.571330\n",
      "epoch 15; iter: 400; batch classifier loss: 0.473923; batch adversarial loss: 0.640499\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283559; batch adversarial loss: 0.595758\n",
      "epoch 16; iter: 200; batch classifier loss: 0.363253; batch adversarial loss: 0.608215\n",
      "epoch 16; iter: 400; batch classifier loss: 0.392865; batch adversarial loss: 0.617554\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276258; batch adversarial loss: 0.650750\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343396; batch adversarial loss: 0.636376\n",
      "epoch 17; iter: 400; batch classifier loss: 0.399688; batch adversarial loss: 0.668097\n",
      "epoch 18; iter: 0; batch classifier loss: 0.440378; batch adversarial loss: 0.577133\n",
      "epoch 18; iter: 200; batch classifier loss: 0.468218; batch adversarial loss: 0.662563\n",
      "epoch 18; iter: 400; batch classifier loss: 0.423552; batch adversarial loss: 0.580329\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281907; batch adversarial loss: 0.685269\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385815; batch adversarial loss: 0.665762\n",
      "epoch 19; iter: 400; batch classifier loss: 0.314306; batch adversarial loss: 0.558107\n",
      "epoch 0; iter: 0; batch classifier loss: 10.163340; batch adversarial loss: 0.876883\n",
      "epoch 0; iter: 200; batch classifier loss: 11.046556; batch adversarial loss: 0.748237\n",
      "epoch 0; iter: 400; batch classifier loss: 3.656261; batch adversarial loss: 0.655808\n",
      "epoch 1; iter: 0; batch classifier loss: 11.368816; batch adversarial loss: 0.613952\n",
      "epoch 1; iter: 200; batch classifier loss: 3.623572; batch adversarial loss: 0.692671\n",
      "epoch 1; iter: 400; batch classifier loss: 3.166059; batch adversarial loss: 0.635215\n",
      "epoch 2; iter: 0; batch classifier loss: 30.956881; batch adversarial loss: 0.639187\n",
      "epoch 2; iter: 200; batch classifier loss: 3.626553; batch adversarial loss: 0.614530\n",
      "epoch 2; iter: 400; batch classifier loss: 1.826501; batch adversarial loss: 0.599538\n",
      "epoch 3; iter: 0; batch classifier loss: 2.453486; batch adversarial loss: 0.642370\n",
      "epoch 3; iter: 200; batch classifier loss: 2.367510; batch adversarial loss: 0.622018\n",
      "epoch 3; iter: 400; batch classifier loss: 0.537654; batch adversarial loss: 0.610520\n",
      "epoch 4; iter: 0; batch classifier loss: 3.517990; batch adversarial loss: 0.677809\n",
      "epoch 4; iter: 200; batch classifier loss: 0.408037; batch adversarial loss: 0.666779\n",
      "epoch 4; iter: 400; batch classifier loss: 0.379132; batch adversarial loss: 0.624682\n",
      "epoch 5; iter: 0; batch classifier loss: 1.327167; batch adversarial loss: 0.641524\n",
      "epoch 5; iter: 200; batch classifier loss: 1.000492; batch adversarial loss: 0.630729\n",
      "epoch 5; iter: 400; batch classifier loss: 0.981441; batch adversarial loss: 0.546243\n",
      "epoch 6; iter: 0; batch classifier loss: 1.127512; batch adversarial loss: 0.630566\n",
      "epoch 6; iter: 200; batch classifier loss: 0.533356; batch adversarial loss: 0.629049\n",
      "epoch 6; iter: 400; batch classifier loss: 0.599742; batch adversarial loss: 0.606962\n",
      "epoch 7; iter: 0; batch classifier loss: 0.455211; batch adversarial loss: 0.617246\n",
      "epoch 7; iter: 200; batch classifier loss: 0.398048; batch adversarial loss: 0.558668\n",
      "epoch 7; iter: 400; batch classifier loss: 0.470698; batch adversarial loss: 0.679883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.693710; batch adversarial loss: 0.559576\n",
      "epoch 8; iter: 200; batch classifier loss: 0.450297; batch adversarial loss: 0.554814\n",
      "epoch 8; iter: 400; batch classifier loss: 0.443735; batch adversarial loss: 0.592208\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398050; batch adversarial loss: 0.606088\n",
      "epoch 9; iter: 200; batch classifier loss: 0.349202; batch adversarial loss: 0.639663\n",
      "epoch 9; iter: 400; batch classifier loss: 0.388421; batch adversarial loss: 0.602780\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472776; batch adversarial loss: 0.620143\n",
      "epoch 10; iter: 200; batch classifier loss: 0.471089; batch adversarial loss: 0.627685\n",
      "epoch 10; iter: 400; batch classifier loss: 0.345959; batch adversarial loss: 0.628278\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345884; batch adversarial loss: 0.606000\n",
      "epoch 11; iter: 200; batch classifier loss: 0.498305; batch adversarial loss: 0.591413\n",
      "epoch 11; iter: 400; batch classifier loss: 0.345083; batch adversarial loss: 0.552565\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477291; batch adversarial loss: 0.648394\n",
      "epoch 12; iter: 200; batch classifier loss: 0.290362; batch adversarial loss: 0.648765\n",
      "epoch 12; iter: 400; batch classifier loss: 0.354799; batch adversarial loss: 0.565165\n",
      "epoch 13; iter: 0; batch classifier loss: 0.270690; batch adversarial loss: 0.647496\n",
      "epoch 13; iter: 200; batch classifier loss: 0.296268; batch adversarial loss: 0.588767\n",
      "epoch 13; iter: 400; batch classifier loss: 0.414172; batch adversarial loss: 0.610892\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481591; batch adversarial loss: 0.613514\n",
      "epoch 14; iter: 200; batch classifier loss: 0.366857; batch adversarial loss: 0.622814\n",
      "epoch 14; iter: 400; batch classifier loss: 0.417520; batch adversarial loss: 0.629714\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386055; batch adversarial loss: 0.564468\n",
      "epoch 15; iter: 200; batch classifier loss: 0.439721; batch adversarial loss: 0.623171\n",
      "epoch 15; iter: 400; batch classifier loss: 0.268866; batch adversarial loss: 0.615575\n",
      "epoch 16; iter: 0; batch classifier loss: 0.406305; batch adversarial loss: 0.643567\n",
      "epoch 16; iter: 200; batch classifier loss: 0.417079; batch adversarial loss: 0.739943\n",
      "epoch 16; iter: 400; batch classifier loss: 0.168854; batch adversarial loss: 0.588846\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486121; batch adversarial loss: 0.628352\n",
      "epoch 17; iter: 200; batch classifier loss: 0.478702; batch adversarial loss: 0.630785\n",
      "epoch 17; iter: 400; batch classifier loss: 0.246971; batch adversarial loss: 0.723491\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320381; batch adversarial loss: 0.687136\n",
      "epoch 18; iter: 200; batch classifier loss: 0.442461; batch adversarial loss: 0.688796\n",
      "epoch 18; iter: 400; batch classifier loss: 0.477333; batch adversarial loss: 0.612467\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379378; batch adversarial loss: 0.554559\n",
      "epoch 19; iter: 200; batch classifier loss: 0.369866; batch adversarial loss: 0.644263\n",
      "epoch 19; iter: 400; batch classifier loss: 0.330541; batch adversarial loss: 0.569992\n",
      "epoch 0; iter: 0; batch classifier loss: 19.335598; batch adversarial loss: 0.724647\n",
      "epoch 0; iter: 200; batch classifier loss: 4.497281; batch adversarial loss: 0.661117\n",
      "epoch 0; iter: 400; batch classifier loss: 7.340214; batch adversarial loss: 0.636453\n",
      "epoch 1; iter: 0; batch classifier loss: 7.469234; batch adversarial loss: 0.614810\n",
      "epoch 1; iter: 200; batch classifier loss: 2.413296; batch adversarial loss: 0.623356\n",
      "epoch 1; iter: 400; batch classifier loss: 2.636847; batch adversarial loss: 0.604927\n",
      "epoch 2; iter: 0; batch classifier loss: 1.006429; batch adversarial loss: 0.701407\n",
      "epoch 2; iter: 200; batch classifier loss: 1.893165; batch adversarial loss: 0.598537\n",
      "epoch 2; iter: 400; batch classifier loss: 0.971604; batch adversarial loss: 0.619000\n",
      "epoch 3; iter: 0; batch classifier loss: 0.380099; batch adversarial loss: 0.568132\n",
      "epoch 3; iter: 200; batch classifier loss: 0.733993; batch adversarial loss: 0.579791\n",
      "epoch 3; iter: 400; batch classifier loss: 0.900042; batch adversarial loss: 0.559802\n",
      "epoch 4; iter: 0; batch classifier loss: 1.891702; batch adversarial loss: 0.662701\n",
      "epoch 4; iter: 200; batch classifier loss: 1.052800; batch adversarial loss: 0.560222\n",
      "epoch 4; iter: 400; batch classifier loss: 0.410312; batch adversarial loss: 0.541080\n",
      "epoch 5; iter: 0; batch classifier loss: 0.699604; batch adversarial loss: 0.609884\n",
      "epoch 5; iter: 200; batch classifier loss: 0.280759; batch adversarial loss: 0.598133\n",
      "epoch 5; iter: 400; batch classifier loss: 0.524978; batch adversarial loss: 0.604676\n",
      "epoch 6; iter: 0; batch classifier loss: 0.327192; batch adversarial loss: 0.687579\n",
      "epoch 6; iter: 200; batch classifier loss: 0.355389; batch adversarial loss: 0.718885\n",
      "epoch 6; iter: 400; batch classifier loss: 0.608309; batch adversarial loss: 0.584248\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405465; batch adversarial loss: 0.647729\n",
      "epoch 7; iter: 200; batch classifier loss: 0.453176; batch adversarial loss: 0.541263\n",
      "epoch 7; iter: 400; batch classifier loss: 0.599197; batch adversarial loss: 0.640128\n",
      "epoch 8; iter: 0; batch classifier loss: 0.361696; batch adversarial loss: 0.644597\n",
      "epoch 8; iter: 200; batch classifier loss: 0.409883; batch adversarial loss: 0.568414\n",
      "epoch 8; iter: 400; batch classifier loss: 1.176718; batch adversarial loss: 0.554489\n",
      "epoch 9; iter: 0; batch classifier loss: 0.468886; batch adversarial loss: 0.621312\n",
      "epoch 9; iter: 200; batch classifier loss: 0.459315; batch adversarial loss: 0.577312\n",
      "epoch 9; iter: 400; batch classifier loss: 0.457308; batch adversarial loss: 0.608129\n",
      "epoch 10; iter: 0; batch classifier loss: 0.903532; batch adversarial loss: 0.647636\n",
      "epoch 10; iter: 200; batch classifier loss: 0.219638; batch adversarial loss: 0.657909\n",
      "epoch 10; iter: 400; batch classifier loss: 0.566969; batch adversarial loss: 0.664307\n",
      "epoch 11; iter: 0; batch classifier loss: 0.509134; batch adversarial loss: 0.655216\n",
      "epoch 11; iter: 200; batch classifier loss: 0.355337; batch adversarial loss: 0.634288\n",
      "epoch 11; iter: 400; batch classifier loss: 0.448033; batch adversarial loss: 0.565434\n",
      "epoch 12; iter: 0; batch classifier loss: 0.424694; batch adversarial loss: 0.607459\n",
      "epoch 12; iter: 200; batch classifier loss: 0.342766; batch adversarial loss: 0.578837\n",
      "epoch 12; iter: 400; batch classifier loss: 0.391670; batch adversarial loss: 0.697059\n",
      "epoch 13; iter: 0; batch classifier loss: 0.359324; batch adversarial loss: 0.680345\n",
      "epoch 13; iter: 200; batch classifier loss: 0.382349; batch adversarial loss: 0.608855\n",
      "epoch 13; iter: 400; batch classifier loss: 0.330800; batch adversarial loss: 0.600395\n",
      "epoch 14; iter: 0; batch classifier loss: 0.326162; batch adversarial loss: 0.618868\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416710; batch adversarial loss: 0.705349\n",
      "epoch 14; iter: 400; batch classifier loss: 0.346030; batch adversarial loss: 0.654213\n",
      "epoch 15; iter: 0; batch classifier loss: 0.335582; batch adversarial loss: 0.680939\n",
      "epoch 15; iter: 200; batch classifier loss: 0.483139; batch adversarial loss: 0.508176\n",
      "epoch 15; iter: 400; batch classifier loss: 0.366849; batch adversarial loss: 0.604719\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307655; batch adversarial loss: 0.648278\n",
      "epoch 16; iter: 200; batch classifier loss: 0.367697; batch adversarial loss: 0.614393\n",
      "epoch 16; iter: 400; batch classifier loss: 0.553739; batch adversarial loss: 0.582376\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391101; batch adversarial loss: 0.582304\n",
      "epoch 17; iter: 200; batch classifier loss: 0.445153; batch adversarial loss: 0.590100\n",
      "epoch 17; iter: 400; batch classifier loss: 0.327647; batch adversarial loss: 0.586040\n",
      "epoch 18; iter: 0; batch classifier loss: 0.426648; batch adversarial loss: 0.664715\n",
      "epoch 18; iter: 200; batch classifier loss: 0.340628; batch adversarial loss: 0.679317\n",
      "epoch 18; iter: 400; batch classifier loss: 0.545215; batch adversarial loss: 0.678620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.312041; batch adversarial loss: 0.672876\n",
      "epoch 19; iter: 200; batch classifier loss: 0.333651; batch adversarial loss: 0.638971\n",
      "epoch 19; iter: 400; batch classifier loss: 0.369191; batch adversarial loss: 0.623634\n",
      "epoch 0; iter: 0; batch classifier loss: 11.809421; batch adversarial loss: 0.676278\n",
      "epoch 0; iter: 200; batch classifier loss: 19.319307; batch adversarial loss: 0.639867\n",
      "epoch 0; iter: 400; batch classifier loss: 17.489399; batch adversarial loss: 0.655039\n",
      "epoch 1; iter: 0; batch classifier loss: 9.335261; batch adversarial loss: 0.568115\n",
      "epoch 1; iter: 200; batch classifier loss: 14.272202; batch adversarial loss: 0.635572\n",
      "epoch 1; iter: 400; batch classifier loss: 2.550151; batch adversarial loss: 0.595340\n",
      "epoch 2; iter: 0; batch classifier loss: 6.384791; batch adversarial loss: 0.587702\n",
      "epoch 2; iter: 200; batch classifier loss: 1.986795; batch adversarial loss: 0.567762\n",
      "epoch 2; iter: 400; batch classifier loss: 0.624885; batch adversarial loss: 0.591183\n",
      "epoch 3; iter: 0; batch classifier loss: 3.712804; batch adversarial loss: 0.564695\n",
      "epoch 3; iter: 200; batch classifier loss: 0.524432; batch adversarial loss: 0.581472\n",
      "epoch 3; iter: 400; batch classifier loss: 0.394020; batch adversarial loss: 0.611776\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539602; batch adversarial loss: 0.729467\n",
      "epoch 4; iter: 200; batch classifier loss: 0.826163; batch adversarial loss: 0.655665\n",
      "epoch 4; iter: 400; batch classifier loss: 0.796975; batch adversarial loss: 0.746558\n",
      "epoch 5; iter: 0; batch classifier loss: 0.336768; batch adversarial loss: 0.570301\n",
      "epoch 5; iter: 200; batch classifier loss: 5.978012; batch adversarial loss: 0.686680\n",
      "epoch 5; iter: 400; batch classifier loss: 1.228324; batch adversarial loss: 0.631842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310111; batch adversarial loss: 0.633707\n",
      "epoch 6; iter: 200; batch classifier loss: 0.385868; batch adversarial loss: 0.560892\n",
      "epoch 6; iter: 400; batch classifier loss: 0.538742; batch adversarial loss: 0.624782\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486257; batch adversarial loss: 0.647215\n",
      "epoch 7; iter: 200; batch classifier loss: 0.536673; batch adversarial loss: 0.598152\n",
      "epoch 7; iter: 400; batch classifier loss: 0.494501; batch adversarial loss: 0.553212\n",
      "epoch 8; iter: 0; batch classifier loss: 0.406191; batch adversarial loss: 0.723366\n",
      "epoch 8; iter: 200; batch classifier loss: 0.404204; batch adversarial loss: 0.566600\n",
      "epoch 8; iter: 400; batch classifier loss: 0.347686; batch adversarial loss: 0.582457\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449534; batch adversarial loss: 0.615780\n",
      "epoch 9; iter: 200; batch classifier loss: 0.381726; batch adversarial loss: 0.676559\n",
      "epoch 9; iter: 400; batch classifier loss: 0.504781; batch adversarial loss: 0.664037\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541410; batch adversarial loss: 0.641349\n",
      "epoch 10; iter: 200; batch classifier loss: 0.368509; batch adversarial loss: 0.656780\n",
      "epoch 10; iter: 400; batch classifier loss: 0.400967; batch adversarial loss: 0.604043\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379300; batch adversarial loss: 0.606748\n",
      "epoch 11; iter: 200; batch classifier loss: 0.465469; batch adversarial loss: 0.517387\n",
      "epoch 11; iter: 400; batch classifier loss: 0.461919; batch adversarial loss: 0.559396\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455435; batch adversarial loss: 0.588773\n",
      "epoch 12; iter: 200; batch classifier loss: 0.320295; batch adversarial loss: 0.617423\n",
      "epoch 12; iter: 400; batch classifier loss: 0.422108; batch adversarial loss: 0.650780\n",
      "epoch 13; iter: 0; batch classifier loss: 0.413756; batch adversarial loss: 0.588436\n",
      "epoch 13; iter: 200; batch classifier loss: 0.365510; batch adversarial loss: 0.626512\n",
      "epoch 13; iter: 400; batch classifier loss: 0.508827; batch adversarial loss: 0.556202\n",
      "epoch 14; iter: 0; batch classifier loss: 0.375421; batch adversarial loss: 0.644862\n",
      "epoch 14; iter: 200; batch classifier loss: 0.339423; batch adversarial loss: 0.569327\n",
      "epoch 14; iter: 400; batch classifier loss: 0.374453; batch adversarial loss: 0.629427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376235; batch adversarial loss: 0.658729\n",
      "epoch 15; iter: 200; batch classifier loss: 0.571130; batch adversarial loss: 0.572063\n",
      "epoch 15; iter: 400; batch classifier loss: 0.411689; batch adversarial loss: 0.653373\n",
      "epoch 16; iter: 0; batch classifier loss: 0.407742; batch adversarial loss: 0.642687\n",
      "epoch 16; iter: 200; batch classifier loss: 0.394075; batch adversarial loss: 0.555380\n",
      "epoch 16; iter: 400; batch classifier loss: 0.428126; batch adversarial loss: 0.530440\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364888; batch adversarial loss: 0.652108\n",
      "epoch 17; iter: 200; batch classifier loss: 0.289702; batch adversarial loss: 0.684064\n",
      "epoch 17; iter: 400; batch classifier loss: 0.624886; batch adversarial loss: 0.605599\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338125; batch adversarial loss: 0.582269\n",
      "epoch 18; iter: 200; batch classifier loss: 0.483734; batch adversarial loss: 0.590535\n",
      "epoch 18; iter: 400; batch classifier loss: 0.420821; batch adversarial loss: 0.569134\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509581; batch adversarial loss: 0.641877\n",
      "epoch 19; iter: 200; batch classifier loss: 0.399147; batch adversarial loss: 0.665257\n",
      "epoch 19; iter: 400; batch classifier loss: 0.551982; batch adversarial loss: 0.549172\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 20.132462; batch adversarial loss: 0.702816\n",
      "epoch 0; iter: 200; batch classifier loss: 0.713231; batch adversarial loss: 0.606050\n",
      "epoch 0; iter: 400; batch classifier loss: 19.177414; batch adversarial loss: 0.609136\n",
      "epoch 1; iter: 0; batch classifier loss: 1.569222; batch adversarial loss: 0.679724\n",
      "epoch 1; iter: 200; batch classifier loss: 12.005820; batch adversarial loss: 0.629354\n",
      "epoch 1; iter: 400; batch classifier loss: 2.676214; batch adversarial loss: 0.665689\n",
      "epoch 2; iter: 0; batch classifier loss: 5.211954; batch adversarial loss: 0.637942\n",
      "epoch 2; iter: 200; batch classifier loss: 1.716546; batch adversarial loss: 0.588190\n",
      "epoch 2; iter: 400; batch classifier loss: 9.423591; batch adversarial loss: 0.688146\n",
      "epoch 3; iter: 0; batch classifier loss: 2.593580; batch adversarial loss: 0.635960\n",
      "epoch 3; iter: 200; batch classifier loss: 0.466510; batch adversarial loss: 0.606333\n",
      "epoch 3; iter: 400; batch classifier loss: 0.804362; batch adversarial loss: 0.602423\n",
      "epoch 4; iter: 0; batch classifier loss: 1.109795; batch adversarial loss: 0.583405\n",
      "epoch 4; iter: 200; batch classifier loss: 0.916692; batch adversarial loss: 0.587352\n",
      "epoch 4; iter: 400; batch classifier loss: 1.379674; batch adversarial loss: 0.616267\n",
      "epoch 5; iter: 0; batch classifier loss: 1.527725; batch adversarial loss: 0.632974\n",
      "epoch 5; iter: 200; batch classifier loss: 0.795755; batch adversarial loss: 0.585427\n",
      "epoch 5; iter: 400; batch classifier loss: 0.783355; batch adversarial loss: 0.603546\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485302; batch adversarial loss: 0.552601\n",
      "epoch 6; iter: 200; batch classifier loss: 0.497302; batch adversarial loss: 0.762356\n",
      "epoch 6; iter: 400; batch classifier loss: 0.412139; batch adversarial loss: 0.620268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458593; batch adversarial loss: 0.635637\n",
      "epoch 7; iter: 200; batch classifier loss: 0.434215; batch adversarial loss: 0.573055\n",
      "epoch 7; iter: 400; batch classifier loss: 0.675513; batch adversarial loss: 0.555696\n",
      "epoch 8; iter: 0; batch classifier loss: 0.414524; batch adversarial loss: 0.622855\n",
      "epoch 8; iter: 200; batch classifier loss: 0.459443; batch adversarial loss: 0.616875\n",
      "epoch 8; iter: 400; batch classifier loss: 0.309867; batch adversarial loss: 0.658678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.397789; batch adversarial loss: 0.586963\n",
      "epoch 9; iter: 200; batch classifier loss: 0.437875; batch adversarial loss: 0.586283\n",
      "epoch 9; iter: 400; batch classifier loss: 0.411684; batch adversarial loss: 0.643781\n",
      "epoch 10; iter: 0; batch classifier loss: 0.298945; batch adversarial loss: 0.667663\n",
      "epoch 10; iter: 200; batch classifier loss: 0.398042; batch adversarial loss: 0.659578\n",
      "epoch 10; iter: 400; batch classifier loss: 0.419337; batch adversarial loss: 0.622990\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522345; batch adversarial loss: 0.589544\n",
      "epoch 11; iter: 200; batch classifier loss: 0.438895; batch adversarial loss: 0.644812\n",
      "epoch 11; iter: 400; batch classifier loss: 0.297243; batch adversarial loss: 0.646736\n",
      "epoch 12; iter: 0; batch classifier loss: 0.445102; batch adversarial loss: 0.624215\n",
      "epoch 12; iter: 200; batch classifier loss: 0.570141; batch adversarial loss: 0.522970\n",
      "epoch 12; iter: 400; batch classifier loss: 0.349524; batch adversarial loss: 0.599404\n",
      "epoch 13; iter: 0; batch classifier loss: 0.969244; batch adversarial loss: 0.611799\n",
      "epoch 13; iter: 200; batch classifier loss: 0.400332; batch adversarial loss: 0.679500\n",
      "epoch 13; iter: 400; batch classifier loss: 0.305221; batch adversarial loss: 0.690188\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390689; batch adversarial loss: 0.702262\n",
      "epoch 14; iter: 200; batch classifier loss: 0.439608; batch adversarial loss: 0.640781\n",
      "epoch 14; iter: 400; batch classifier loss: 0.659479; batch adversarial loss: 0.617349\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313742; batch adversarial loss: 0.779119\n",
      "epoch 15; iter: 200; batch classifier loss: 0.384499; batch adversarial loss: 0.593314\n",
      "epoch 15; iter: 400; batch classifier loss: 0.468804; batch adversarial loss: 0.615747\n",
      "epoch 16; iter: 0; batch classifier loss: 0.451675; batch adversarial loss: 0.543655\n",
      "epoch 16; iter: 200; batch classifier loss: 0.581804; batch adversarial loss: 0.590483\n",
      "epoch 16; iter: 400; batch classifier loss: 0.410744; batch adversarial loss: 0.674297\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337139; batch adversarial loss: 0.684942\n",
      "epoch 17; iter: 200; batch classifier loss: 0.421425; batch adversarial loss: 0.700857\n",
      "epoch 17; iter: 400; batch classifier loss: 0.441956; batch adversarial loss: 0.628982\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304681; batch adversarial loss: 0.607486\n",
      "epoch 18; iter: 200; batch classifier loss: 0.359897; batch adversarial loss: 0.661371\n",
      "epoch 18; iter: 400; batch classifier loss: 0.361140; batch adversarial loss: 0.645578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322929; batch adversarial loss: 0.635467\n",
      "epoch 19; iter: 200; batch classifier loss: 0.330435; batch adversarial loss: 0.605073\n",
      "epoch 19; iter: 400; batch classifier loss: 0.365151; batch adversarial loss: 0.589516\n",
      "epoch 20; iter: 0; batch classifier loss: 0.227209; batch adversarial loss: 0.611508\n",
      "epoch 20; iter: 200; batch classifier loss: 0.272592; batch adversarial loss: 0.572250\n",
      "epoch 20; iter: 400; batch classifier loss: 0.312097; batch adversarial loss: 0.694246\n",
      "epoch 21; iter: 0; batch classifier loss: 0.348175; batch adversarial loss: 0.614537\n",
      "epoch 21; iter: 200; batch classifier loss: 0.170173; batch adversarial loss: 0.638493\n",
      "epoch 21; iter: 400; batch classifier loss: 0.358633; batch adversarial loss: 0.606931\n",
      "epoch 22; iter: 0; batch classifier loss: 0.297200; batch adversarial loss: 0.627262\n",
      "epoch 22; iter: 200; batch classifier loss: 0.302830; batch adversarial loss: 0.650051\n",
      "epoch 22; iter: 400; batch classifier loss: 0.333225; batch adversarial loss: 0.612240\n",
      "epoch 23; iter: 0; batch classifier loss: 0.361071; batch adversarial loss: 0.560796\n",
      "epoch 23; iter: 200; batch classifier loss: 0.228985; batch adversarial loss: 0.652850\n",
      "epoch 23; iter: 400; batch classifier loss: 0.391978; batch adversarial loss: 0.635390\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477621; batch adversarial loss: 0.633247\n",
      "epoch 24; iter: 200; batch classifier loss: 0.290460; batch adversarial loss: 0.613749\n",
      "epoch 24; iter: 400; batch classifier loss: 0.329937; batch adversarial loss: 0.559359\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442527; batch adversarial loss: 0.658651\n",
      "epoch 25; iter: 200; batch classifier loss: 0.225998; batch adversarial loss: 0.552941\n",
      "epoch 25; iter: 400; batch classifier loss: 0.645445; batch adversarial loss: 0.589973\n",
      "epoch 26; iter: 0; batch classifier loss: 0.536326; batch adversarial loss: 0.703026\n",
      "epoch 26; iter: 200; batch classifier loss: 0.354722; batch adversarial loss: 0.619058\n",
      "epoch 26; iter: 400; batch classifier loss: 0.334255; batch adversarial loss: 0.636731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.384452; batch adversarial loss: 0.610277\n",
      "epoch 27; iter: 200; batch classifier loss: 0.373846; batch adversarial loss: 0.684986\n",
      "epoch 27; iter: 400; batch classifier loss: 0.576712; batch adversarial loss: 0.627610\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440619; batch adversarial loss: 0.622303\n",
      "epoch 28; iter: 200; batch classifier loss: 0.295395; batch adversarial loss: 0.613240\n",
      "epoch 28; iter: 400; batch classifier loss: 0.266139; batch adversarial loss: 0.660951\n",
      "epoch 29; iter: 0; batch classifier loss: 0.415462; batch adversarial loss: 0.597635\n",
      "epoch 29; iter: 200; batch classifier loss: 0.396184; batch adversarial loss: 0.603710\n",
      "epoch 29; iter: 400; batch classifier loss: 0.521178; batch adversarial loss: 0.659915\n",
      "epoch 30; iter: 0; batch classifier loss: 0.516354; batch adversarial loss: 0.658893\n",
      "epoch 30; iter: 200; batch classifier loss: 0.424962; batch adversarial loss: 0.640913\n",
      "epoch 30; iter: 400; batch classifier loss: 0.553909; batch adversarial loss: 0.609358\n",
      "epoch 31; iter: 0; batch classifier loss: 0.389918; batch adversarial loss: 0.658040\n",
      "epoch 31; iter: 200; batch classifier loss: 0.455229; batch adversarial loss: 0.707578\n",
      "epoch 31; iter: 400; batch classifier loss: 0.349841; batch adversarial loss: 0.606254\n",
      "epoch 32; iter: 0; batch classifier loss: 0.369118; batch adversarial loss: 0.664119\n",
      "epoch 32; iter: 200; batch classifier loss: 0.444841; batch adversarial loss: 0.626603\n",
      "epoch 32; iter: 400; batch classifier loss: 0.652437; batch adversarial loss: 0.611599\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518088; batch adversarial loss: 0.676631\n",
      "epoch 33; iter: 200; batch classifier loss: 0.419795; batch adversarial loss: 0.560432\n",
      "epoch 33; iter: 400; batch classifier loss: 0.507126; batch adversarial loss: 0.616127\n",
      "epoch 34; iter: 0; batch classifier loss: 0.586771; batch adversarial loss: 0.625986\n",
      "epoch 34; iter: 200; batch classifier loss: 0.415497; batch adversarial loss: 0.602268\n",
      "epoch 34; iter: 400; batch classifier loss: 0.457524; batch adversarial loss: 0.631106\n",
      "epoch 35; iter: 0; batch classifier loss: 0.592687; batch adversarial loss: 0.649655\n",
      "epoch 35; iter: 200; batch classifier loss: 0.331566; batch adversarial loss: 0.579867\n",
      "epoch 35; iter: 400; batch classifier loss: 0.390905; batch adversarial loss: 0.629082\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425640; batch adversarial loss: 0.603375\n",
      "epoch 36; iter: 200; batch classifier loss: 0.332517; batch adversarial loss: 0.676515\n",
      "epoch 36; iter: 400; batch classifier loss: 0.708414; batch adversarial loss: 0.591008\n",
      "epoch 37; iter: 0; batch classifier loss: 0.357182; batch adversarial loss: 0.598747\n",
      "epoch 37; iter: 200; batch classifier loss: 0.217218; batch adversarial loss: 0.631927\n",
      "epoch 37; iter: 400; batch classifier loss: 0.429213; batch adversarial loss: 0.590005\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453803; batch adversarial loss: 0.633939\n",
      "epoch 38; iter: 200; batch classifier loss: 0.501242; batch adversarial loss: 0.578067\n",
      "epoch 38; iter: 400; batch classifier loss: 0.546899; batch adversarial loss: 0.691469\n",
      "epoch 39; iter: 0; batch classifier loss: 0.266932; batch adversarial loss: 0.601139\n",
      "epoch 39; iter: 200; batch classifier loss: 0.392933; batch adversarial loss: 0.575261\n",
      "epoch 39; iter: 400; batch classifier loss: 0.691235; batch adversarial loss: 0.705127\n",
      "epoch 40; iter: 0; batch classifier loss: 0.311161; batch adversarial loss: 0.727225\n",
      "epoch 40; iter: 200; batch classifier loss: 0.361494; batch adversarial loss: 0.614781\n",
      "epoch 40; iter: 400; batch classifier loss: 0.452629; batch adversarial loss: 0.646018\n",
      "epoch 41; iter: 0; batch classifier loss: 0.383071; batch adversarial loss: 0.658362\n",
      "epoch 41; iter: 200; batch classifier loss: 0.382248; batch adversarial loss: 0.565579\n",
      "epoch 41; iter: 400; batch classifier loss: 0.287451; batch adversarial loss: 0.680143\n",
      "epoch 42; iter: 0; batch classifier loss: 0.341008; batch adversarial loss: 0.589219\n",
      "epoch 42; iter: 200; batch classifier loss: 0.273665; batch adversarial loss: 0.719061\n",
      "epoch 42; iter: 400; batch classifier loss: 0.624580; batch adversarial loss: 0.766316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.518328; batch adversarial loss: 0.576800\n",
      "epoch 43; iter: 200; batch classifier loss: 0.367846; batch adversarial loss: 0.589158\n",
      "epoch 43; iter: 400; batch classifier loss: 0.442971; batch adversarial loss: 0.587359\n",
      "epoch 44; iter: 0; batch classifier loss: 1.007383; batch adversarial loss: 0.615797\n",
      "epoch 44; iter: 200; batch classifier loss: 1.493502; batch adversarial loss: 0.690466\n",
      "epoch 44; iter: 400; batch classifier loss: 0.366971; batch adversarial loss: 0.657992\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439836; batch adversarial loss: 0.608405\n",
      "epoch 45; iter: 200; batch classifier loss: 0.503084; batch adversarial loss: 0.621524\n",
      "epoch 45; iter: 400; batch classifier loss: 0.453439; batch adversarial loss: 0.609582\n",
      "epoch 46; iter: 0; batch classifier loss: 0.399393; batch adversarial loss: 0.683065\n",
      "epoch 46; iter: 200; batch classifier loss: 0.599161; batch adversarial loss: 0.668641\n",
      "epoch 46; iter: 400; batch classifier loss: 1.026859; batch adversarial loss: 0.593285\n",
      "epoch 47; iter: 0; batch classifier loss: 0.392454; batch adversarial loss: 0.534673\n",
      "epoch 47; iter: 200; batch classifier loss: 0.462116; batch adversarial loss: 0.628685\n",
      "epoch 47; iter: 400; batch classifier loss: 0.532471; batch adversarial loss: 0.564472\n",
      "epoch 48; iter: 0; batch classifier loss: 0.344560; batch adversarial loss: 0.675789\n",
      "epoch 48; iter: 200; batch classifier loss: 0.564155; batch adversarial loss: 0.582353\n",
      "epoch 48; iter: 400; batch classifier loss: 0.654330; batch adversarial loss: 0.650666\n",
      "epoch 49; iter: 0; batch classifier loss: 0.445280; batch adversarial loss: 0.609258\n",
      "epoch 49; iter: 200; batch classifier loss: 0.405374; batch adversarial loss: 0.567086\n",
      "epoch 49; iter: 400; batch classifier loss: 0.423970; batch adversarial loss: 0.601182\n",
      "epoch 0; iter: 0; batch classifier loss: 179.737518; batch adversarial loss: 0.690763\n",
      "epoch 0; iter: 200; batch classifier loss: 25.438534; batch adversarial loss: 0.684818\n",
      "epoch 0; iter: 400; batch classifier loss: 5.262723; batch adversarial loss: 0.613100\n",
      "epoch 1; iter: 0; batch classifier loss: 2.306226; batch adversarial loss: 0.693237\n",
      "epoch 1; iter: 200; batch classifier loss: 18.154640; batch adversarial loss: 0.637075\n",
      "epoch 1; iter: 400; batch classifier loss: 0.877333; batch adversarial loss: 0.664290\n",
      "epoch 2; iter: 0; batch classifier loss: 3.450083; batch adversarial loss: 0.639032\n",
      "epoch 2; iter: 200; batch classifier loss: 1.163132; batch adversarial loss: 0.616431\n",
      "epoch 2; iter: 400; batch classifier loss: 0.597502; batch adversarial loss: 0.635982\n",
      "epoch 3; iter: 0; batch classifier loss: 5.755683; batch adversarial loss: 0.650140\n",
      "epoch 3; iter: 200; batch classifier loss: 0.310472; batch adversarial loss: 0.666119\n",
      "epoch 3; iter: 400; batch classifier loss: 0.394845; batch adversarial loss: 0.603744\n",
      "epoch 4; iter: 0; batch classifier loss: 0.458335; batch adversarial loss: 0.634144\n",
      "epoch 4; iter: 200; batch classifier loss: 1.161115; batch adversarial loss: 0.614075\n",
      "epoch 4; iter: 400; batch classifier loss: 0.845884; batch adversarial loss: 0.647126\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607578; batch adversarial loss: 0.675126\n",
      "epoch 5; iter: 200; batch classifier loss: 1.011964; batch adversarial loss: 0.658022\n",
      "epoch 5; iter: 400; batch classifier loss: 1.143943; batch adversarial loss: 0.721486\n",
      "epoch 6; iter: 0; batch classifier loss: 0.244914; batch adversarial loss: 0.688283\n",
      "epoch 6; iter: 200; batch classifier loss: 0.602184; batch adversarial loss: 0.610273\n",
      "epoch 6; iter: 400; batch classifier loss: 0.845611; batch adversarial loss: 0.652095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471466; batch adversarial loss: 0.613356\n",
      "epoch 7; iter: 200; batch classifier loss: 0.996399; batch adversarial loss: 0.677239\n",
      "epoch 7; iter: 400; batch classifier loss: 0.485505; batch adversarial loss: 0.689917\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569275; batch adversarial loss: 0.603316\n",
      "epoch 8; iter: 200; batch classifier loss: 0.531307; batch adversarial loss: 0.609148\n",
      "epoch 8; iter: 400; batch classifier loss: 0.397530; batch adversarial loss: 0.660703\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544746; batch adversarial loss: 0.617653\n",
      "epoch 9; iter: 200; batch classifier loss: 0.345114; batch adversarial loss: 0.596934\n",
      "epoch 9; iter: 400; batch classifier loss: 0.280302; batch adversarial loss: 0.687837\n",
      "epoch 10; iter: 0; batch classifier loss: 0.328999; batch adversarial loss: 0.649458\n",
      "epoch 10; iter: 200; batch classifier loss: 0.479789; batch adversarial loss: 0.645377\n",
      "epoch 10; iter: 400; batch classifier loss: 0.271027; batch adversarial loss: 0.609538\n",
      "epoch 11; iter: 0; batch classifier loss: 0.463164; batch adversarial loss: 0.553988\n",
      "epoch 11; iter: 200; batch classifier loss: 0.453008; batch adversarial loss: 0.573368\n",
      "epoch 11; iter: 400; batch classifier loss: 0.309628; batch adversarial loss: 0.632293\n",
      "epoch 12; iter: 0; batch classifier loss: 0.438224; batch adversarial loss: 0.707828\n",
      "epoch 12; iter: 200; batch classifier loss: 0.388569; batch adversarial loss: 0.588269\n",
      "epoch 12; iter: 400; batch classifier loss: 0.388120; batch adversarial loss: 0.596973\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373012; batch adversarial loss: 0.619590\n",
      "epoch 13; iter: 200; batch classifier loss: 0.435500; batch adversarial loss: 0.584865\n",
      "epoch 13; iter: 400; batch classifier loss: 0.303814; batch adversarial loss: 0.577147\n",
      "epoch 14; iter: 0; batch classifier loss: 1.022388; batch adversarial loss: 0.623467\n",
      "epoch 14; iter: 200; batch classifier loss: 0.252924; batch adversarial loss: 0.600787\n",
      "epoch 14; iter: 400; batch classifier loss: 0.371897; batch adversarial loss: 0.685164\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454730; batch adversarial loss: 0.629066\n",
      "epoch 15; iter: 200; batch classifier loss: 0.409804; batch adversarial loss: 0.592565\n",
      "epoch 15; iter: 400; batch classifier loss: 0.401909; batch adversarial loss: 0.651007\n",
      "epoch 16; iter: 0; batch classifier loss: 0.325869; batch adversarial loss: 0.543197\n",
      "epoch 16; iter: 200; batch classifier loss: 0.243355; batch adversarial loss: 0.622613\n",
      "epoch 16; iter: 400; batch classifier loss: 0.452813; batch adversarial loss: 0.628369\n",
      "epoch 17; iter: 0; batch classifier loss: 0.406582; batch adversarial loss: 0.656927\n",
      "epoch 17; iter: 200; batch classifier loss: 0.424474; batch adversarial loss: 0.581255\n",
      "epoch 17; iter: 400; batch classifier loss: 0.627470; batch adversarial loss: 0.635603\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342175; batch adversarial loss: 0.578587\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326732; batch adversarial loss: 0.685777\n",
      "epoch 18; iter: 400; batch classifier loss: 0.335083; batch adversarial loss: 0.682597\n",
      "epoch 19; iter: 0; batch classifier loss: 0.702781; batch adversarial loss: 0.612117\n",
      "epoch 19; iter: 200; batch classifier loss: 0.226413; batch adversarial loss: 0.651915\n",
      "epoch 19; iter: 400; batch classifier loss: 0.547358; batch adversarial loss: 0.659100\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324136; batch adversarial loss: 0.603352\n",
      "epoch 20; iter: 200; batch classifier loss: 0.349937; batch adversarial loss: 0.652466\n",
      "epoch 20; iter: 400; batch classifier loss: 0.331034; batch adversarial loss: 0.692619\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429947; batch adversarial loss: 0.661437\n",
      "epoch 21; iter: 200; batch classifier loss: 0.430960; batch adversarial loss: 0.595825\n",
      "epoch 21; iter: 400; batch classifier loss: 0.509392; batch adversarial loss: 0.544743\n",
      "epoch 22; iter: 0; batch classifier loss: 0.379627; batch adversarial loss: 0.650593\n",
      "epoch 22; iter: 200; batch classifier loss: 0.359574; batch adversarial loss: 0.704639\n",
      "epoch 22; iter: 400; batch classifier loss: 0.346785; batch adversarial loss: 0.674367\n",
      "epoch 23; iter: 0; batch classifier loss: 0.384284; batch adversarial loss: 0.578102\n",
      "epoch 23; iter: 200; batch classifier loss: 0.293973; batch adversarial loss: 0.667185\n",
      "epoch 23; iter: 400; batch classifier loss: 0.330689; batch adversarial loss: 0.675795\n",
      "epoch 24; iter: 0; batch classifier loss: 0.374028; batch adversarial loss: 0.670257\n",
      "epoch 24; iter: 200; batch classifier loss: 0.465479; batch adversarial loss: 0.699391\n",
      "epoch 24; iter: 400; batch classifier loss: 0.451326; batch adversarial loss: 0.623432\n",
      "epoch 25; iter: 0; batch classifier loss: 0.342124; batch adversarial loss: 0.597120\n",
      "epoch 25; iter: 200; batch classifier loss: 0.381440; batch adversarial loss: 0.594271\n",
      "epoch 25; iter: 400; batch classifier loss: 0.335619; batch adversarial loss: 0.551763\n",
      "epoch 26; iter: 0; batch classifier loss: 0.442744; batch adversarial loss: 0.695100\n",
      "epoch 26; iter: 200; batch classifier loss: 0.338481; batch adversarial loss: 0.678690\n",
      "epoch 26; iter: 400; batch classifier loss: 0.404742; batch adversarial loss: 0.648261\n",
      "epoch 27; iter: 0; batch classifier loss: 0.226042; batch adversarial loss: 0.639185\n",
      "epoch 27; iter: 200; batch classifier loss: 0.351545; batch adversarial loss: 0.596843\n",
      "epoch 27; iter: 400; batch classifier loss: 0.348893; batch adversarial loss: 0.607338\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438906; batch adversarial loss: 0.690766\n",
      "epoch 28; iter: 200; batch classifier loss: 0.403450; batch adversarial loss: 0.671782\n",
      "epoch 28; iter: 400; batch classifier loss: 0.317427; batch adversarial loss: 0.610000\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514267; batch adversarial loss: 0.552510\n",
      "epoch 29; iter: 200; batch classifier loss: 0.326687; batch adversarial loss: 0.582845\n",
      "epoch 29; iter: 400; batch classifier loss: 0.325100; batch adversarial loss: 0.650113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.622197; batch adversarial loss: 0.684002\n",
      "epoch 30; iter: 200; batch classifier loss: 0.335649; batch adversarial loss: 0.650910\n",
      "epoch 30; iter: 400; batch classifier loss: 0.422429; batch adversarial loss: 0.625559\n",
      "epoch 31; iter: 0; batch classifier loss: 0.549505; batch adversarial loss: 0.641071\n",
      "epoch 31; iter: 200; batch classifier loss: 0.428708; batch adversarial loss: 0.578411\n",
      "epoch 31; iter: 400; batch classifier loss: 0.439638; batch adversarial loss: 0.580161\n",
      "epoch 32; iter: 0; batch classifier loss: 0.228656; batch adversarial loss: 0.694188\n",
      "epoch 32; iter: 200; batch classifier loss: 0.469943; batch adversarial loss: 0.670429\n",
      "epoch 32; iter: 400; batch classifier loss: 0.321572; batch adversarial loss: 0.606326\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432166; batch adversarial loss: 0.669259\n",
      "epoch 33; iter: 200; batch classifier loss: 0.334218; batch adversarial loss: 0.590742\n",
      "epoch 33; iter: 400; batch classifier loss: 0.462656; batch adversarial loss: 0.628980\n",
      "epoch 34; iter: 0; batch classifier loss: 0.326636; batch adversarial loss: 0.613319\n",
      "epoch 34; iter: 200; batch classifier loss: 0.447948; batch adversarial loss: 0.610611\n",
      "epoch 34; iter: 400; batch classifier loss: 0.490519; batch adversarial loss: 0.641409\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404537; batch adversarial loss: 0.529283\n",
      "epoch 35; iter: 200; batch classifier loss: 0.498082; batch adversarial loss: 0.550346\n",
      "epoch 35; iter: 400; batch classifier loss: 0.620326; batch adversarial loss: 0.598477\n",
      "epoch 36; iter: 0; batch classifier loss: 0.226162; batch adversarial loss: 0.589747\n",
      "epoch 36; iter: 200; batch classifier loss: 0.286069; batch adversarial loss: 0.616444\n",
      "epoch 36; iter: 400; batch classifier loss: 0.450208; batch adversarial loss: 0.597740\n",
      "epoch 37; iter: 0; batch classifier loss: 0.559966; batch adversarial loss: 0.607380\n",
      "epoch 37; iter: 200; batch classifier loss: 0.416382; batch adversarial loss: 0.646476\n",
      "epoch 37; iter: 400; batch classifier loss: 0.483103; batch adversarial loss: 0.617673\n",
      "epoch 38; iter: 0; batch classifier loss: 0.300555; batch adversarial loss: 0.612559\n",
      "epoch 38; iter: 200; batch classifier loss: 0.347673; batch adversarial loss: 0.606986\n",
      "epoch 38; iter: 400; batch classifier loss: 0.483559; batch adversarial loss: 0.599750\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410741; batch adversarial loss: 0.673345\n",
      "epoch 39; iter: 200; batch classifier loss: 0.387601; batch adversarial loss: 0.610240\n",
      "epoch 39; iter: 400; batch classifier loss: 0.330636; batch adversarial loss: 0.656690\n",
      "epoch 40; iter: 0; batch classifier loss: 0.534911; batch adversarial loss: 0.619361\n",
      "epoch 40; iter: 200; batch classifier loss: 0.402819; batch adversarial loss: 0.695418\n",
      "epoch 40; iter: 400; batch classifier loss: 0.441522; batch adversarial loss: 0.641986\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265963; batch adversarial loss: 0.638810\n",
      "epoch 41; iter: 200; batch classifier loss: 0.257669; batch adversarial loss: 0.592129\n",
      "epoch 41; iter: 400; batch classifier loss: 0.258965; batch adversarial loss: 0.610480\n",
      "epoch 42; iter: 0; batch classifier loss: 0.643420; batch adversarial loss: 0.664360\n",
      "epoch 42; iter: 200; batch classifier loss: 0.623311; batch adversarial loss: 0.589710\n",
      "epoch 42; iter: 400; batch classifier loss: 0.504125; batch adversarial loss: 0.565177\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394467; batch adversarial loss: 0.626274\n",
      "epoch 43; iter: 200; batch classifier loss: 0.473081; batch adversarial loss: 0.577682\n",
      "epoch 43; iter: 400; batch classifier loss: 0.304478; batch adversarial loss: 0.603434\n",
      "epoch 44; iter: 0; batch classifier loss: 0.533709; batch adversarial loss: 0.631591\n",
      "epoch 44; iter: 200; batch classifier loss: 0.300324; batch adversarial loss: 0.579948\n",
      "epoch 44; iter: 400; batch classifier loss: 0.508171; batch adversarial loss: 0.610675\n",
      "epoch 45; iter: 0; batch classifier loss: 0.454825; batch adversarial loss: 0.642622\n",
      "epoch 45; iter: 200; batch classifier loss: 0.392928; batch adversarial loss: 0.551628\n",
      "epoch 45; iter: 400; batch classifier loss: 0.232904; batch adversarial loss: 0.678655\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324887; batch adversarial loss: 0.599806\n",
      "epoch 46; iter: 200; batch classifier loss: 0.409890; batch adversarial loss: 0.651840\n",
      "epoch 46; iter: 400; batch classifier loss: 0.430149; batch adversarial loss: 0.669694\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428773; batch adversarial loss: 0.622601\n",
      "epoch 47; iter: 200; batch classifier loss: 0.409162; batch adversarial loss: 0.569661\n",
      "epoch 47; iter: 400; batch classifier loss: 0.271180; batch adversarial loss: 0.695271\n",
      "epoch 48; iter: 0; batch classifier loss: 0.525653; batch adversarial loss: 0.624955\n",
      "epoch 48; iter: 200; batch classifier loss: 0.358441; batch adversarial loss: 0.611331\n",
      "epoch 48; iter: 400; batch classifier loss: 0.484599; batch adversarial loss: 0.640191\n",
      "epoch 49; iter: 0; batch classifier loss: 0.418106; batch adversarial loss: 0.604136\n",
      "epoch 49; iter: 200; batch classifier loss: 0.217616; batch adversarial loss: 0.621787\n",
      "epoch 49; iter: 400; batch classifier loss: 0.463230; batch adversarial loss: 0.682467\n",
      "epoch 0; iter: 0; batch classifier loss: 277.638947; batch adversarial loss: 0.721010\n",
      "epoch 0; iter: 200; batch classifier loss: 2.256592; batch adversarial loss: 0.666046\n",
      "epoch 0; iter: 400; batch classifier loss: 3.497217; batch adversarial loss: 0.653958\n",
      "epoch 1; iter: 0; batch classifier loss: 2.735386; batch adversarial loss: 0.636550\n",
      "epoch 1; iter: 200; batch classifier loss: 2.574006; batch adversarial loss: 0.634571\n",
      "epoch 1; iter: 400; batch classifier loss: 1.101057; batch adversarial loss: 0.663443\n",
      "epoch 2; iter: 0; batch classifier loss: 2.543517; batch adversarial loss: 0.668862\n",
      "epoch 2; iter: 200; batch classifier loss: 2.538946; batch adversarial loss: 0.660969\n",
      "epoch 2; iter: 400; batch classifier loss: 0.804315; batch adversarial loss: 0.577599\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677737; batch adversarial loss: 0.588481\n",
      "epoch 3; iter: 200; batch classifier loss: 0.534349; batch adversarial loss: 0.591956\n",
      "epoch 3; iter: 400; batch classifier loss: 0.280222; batch adversarial loss: 0.741232\n",
      "epoch 4; iter: 0; batch classifier loss: 0.364441; batch adversarial loss: 0.571981\n",
      "epoch 4; iter: 200; batch classifier loss: 0.622883; batch adversarial loss: 0.645139\n",
      "epoch 4; iter: 400; batch classifier loss: 0.907048; batch adversarial loss: 0.646338\n",
      "epoch 5; iter: 0; batch classifier loss: 0.497368; batch adversarial loss: 0.748633\n",
      "epoch 5; iter: 200; batch classifier loss: 3.185578; batch adversarial loss: 0.640868\n",
      "epoch 5; iter: 400; batch classifier loss: 0.696771; batch adversarial loss: 0.677454\n",
      "epoch 6; iter: 0; batch classifier loss: 1.708903; batch adversarial loss: 0.603878\n",
      "epoch 6; iter: 200; batch classifier loss: 0.535632; batch adversarial loss: 0.637098\n",
      "epoch 6; iter: 400; batch classifier loss: 0.456381; batch adversarial loss: 0.625783\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501141; batch adversarial loss: 0.670061\n",
      "epoch 7; iter: 200; batch classifier loss: 0.663032; batch adversarial loss: 0.606449\n",
      "epoch 7; iter: 400; batch classifier loss: 0.490883; batch adversarial loss: 0.628706\n",
      "epoch 8; iter: 0; batch classifier loss: 0.324948; batch adversarial loss: 0.646889\n",
      "epoch 8; iter: 200; batch classifier loss: 0.461924; batch adversarial loss: 0.646191\n",
      "epoch 8; iter: 400; batch classifier loss: 0.401118; batch adversarial loss: 0.669693\n",
      "epoch 9; iter: 0; batch classifier loss: 0.425995; batch adversarial loss: 0.556297\n",
      "epoch 9; iter: 200; batch classifier loss: 0.379854; batch adversarial loss: 0.681094\n",
      "epoch 9; iter: 400; batch classifier loss: 0.492683; batch adversarial loss: 0.601405\n",
      "epoch 10; iter: 0; batch classifier loss: 0.359484; batch adversarial loss: 0.614640\n",
      "epoch 10; iter: 200; batch classifier loss: 0.261927; batch adversarial loss: 0.630727\n",
      "epoch 10; iter: 400; batch classifier loss: 0.563885; batch adversarial loss: 0.599982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559106; batch adversarial loss: 0.571213\n",
      "epoch 11; iter: 200; batch classifier loss: 0.519561; batch adversarial loss: 0.595842\n",
      "epoch 11; iter: 400; batch classifier loss: 0.297336; batch adversarial loss: 0.744926\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398890; batch adversarial loss: 0.604117\n",
      "epoch 12; iter: 200; batch classifier loss: 0.279397; batch adversarial loss: 0.605375\n",
      "epoch 12; iter: 400; batch classifier loss: 0.378511; batch adversarial loss: 0.611733\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369540; batch adversarial loss: 0.561244\n",
      "epoch 13; iter: 200; batch classifier loss: 0.337339; batch adversarial loss: 0.591751\n",
      "epoch 13; iter: 400; batch classifier loss: 0.330384; batch adversarial loss: 0.650460\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350655; batch adversarial loss: 0.714125\n",
      "epoch 14; iter: 200; batch classifier loss: 0.347156; batch adversarial loss: 0.662679\n",
      "epoch 14; iter: 400; batch classifier loss: 0.253507; batch adversarial loss: 0.697023\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330027; batch adversarial loss: 0.578382\n",
      "epoch 15; iter: 200; batch classifier loss: 0.459112; batch adversarial loss: 0.623630\n",
      "epoch 15; iter: 400; batch classifier loss: 0.306604; batch adversarial loss: 0.616076\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532283; batch adversarial loss: 0.552177\n",
      "epoch 16; iter: 200; batch classifier loss: 0.254164; batch adversarial loss: 0.679183\n",
      "epoch 16; iter: 400; batch classifier loss: 0.319666; batch adversarial loss: 0.622880\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296752; batch adversarial loss: 0.554838\n",
      "epoch 17; iter: 200; batch classifier loss: 0.302065; batch adversarial loss: 0.652071\n",
      "epoch 17; iter: 400; batch classifier loss: 0.467407; batch adversarial loss: 0.691889\n",
      "epoch 18; iter: 0; batch classifier loss: 0.347835; batch adversarial loss: 0.654167\n",
      "epoch 18; iter: 200; batch classifier loss: 0.274957; batch adversarial loss: 0.647575\n",
      "epoch 18; iter: 400; batch classifier loss: 0.381424; batch adversarial loss: 0.691003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321329; batch adversarial loss: 0.708459\n",
      "epoch 19; iter: 200; batch classifier loss: 0.528350; batch adversarial loss: 0.628119\n",
      "epoch 19; iter: 400; batch classifier loss: 0.428629; batch adversarial loss: 0.592432\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285498; batch adversarial loss: 0.590969\n",
      "epoch 20; iter: 200; batch classifier loss: 0.304540; batch adversarial loss: 0.647955\n",
      "epoch 20; iter: 400; batch classifier loss: 0.227484; batch adversarial loss: 0.649417\n",
      "epoch 21; iter: 0; batch classifier loss: 0.569204; batch adversarial loss: 0.652625\n",
      "epoch 21; iter: 200; batch classifier loss: 0.431401; batch adversarial loss: 0.666261\n",
      "epoch 21; iter: 400; batch classifier loss: 0.343557; batch adversarial loss: 0.632169\n",
      "epoch 22; iter: 0; batch classifier loss: 0.363234; batch adversarial loss: 0.580327\n",
      "epoch 22; iter: 200; batch classifier loss: 0.426576; batch adversarial loss: 0.664343\n",
      "epoch 22; iter: 400; batch classifier loss: 0.238036; batch adversarial loss: 0.626810\n",
      "epoch 23; iter: 0; batch classifier loss: 0.356303; batch adversarial loss: 0.561524\n",
      "epoch 23; iter: 200; batch classifier loss: 0.470028; batch adversarial loss: 0.626507\n",
      "epoch 23; iter: 400; batch classifier loss: 0.444239; batch adversarial loss: 0.624920\n",
      "epoch 24; iter: 0; batch classifier loss: 0.712674; batch adversarial loss: 0.597893\n",
      "epoch 24; iter: 200; batch classifier loss: 0.464461; batch adversarial loss: 0.594950\n",
      "epoch 24; iter: 400; batch classifier loss: 0.318912; batch adversarial loss: 0.610099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417860; batch adversarial loss: 0.621810\n",
      "epoch 25; iter: 200; batch classifier loss: 0.378252; batch adversarial loss: 0.642364\n",
      "epoch 25; iter: 400; batch classifier loss: 0.393069; batch adversarial loss: 0.675045\n",
      "epoch 26; iter: 0; batch classifier loss: 0.280071; batch adversarial loss: 0.624901\n",
      "epoch 26; iter: 200; batch classifier loss: 0.652736; batch adversarial loss: 0.598749\n",
      "epoch 26; iter: 400; batch classifier loss: 0.319757; batch adversarial loss: 0.631654\n",
      "epoch 27; iter: 0; batch classifier loss: 0.375184; batch adversarial loss: 0.628120\n",
      "epoch 27; iter: 200; batch classifier loss: 0.354510; batch adversarial loss: 0.673847\n",
      "epoch 27; iter: 400; batch classifier loss: 1.190127; batch adversarial loss: 0.606584\n",
      "epoch 28; iter: 0; batch classifier loss: 0.387031; batch adversarial loss: 0.683827\n",
      "epoch 28; iter: 200; batch classifier loss: 0.446963; batch adversarial loss: 0.657226\n",
      "epoch 28; iter: 400; batch classifier loss: 0.402458; batch adversarial loss: 0.592600\n",
      "epoch 29; iter: 0; batch classifier loss: 0.246775; batch adversarial loss: 0.699794\n",
      "epoch 29; iter: 200; batch classifier loss: 0.330998; batch adversarial loss: 0.565885\n",
      "epoch 29; iter: 400; batch classifier loss: 0.205337; batch adversarial loss: 0.663655\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342275; batch adversarial loss: 0.601347\n",
      "epoch 30; iter: 200; batch classifier loss: 0.351895; batch adversarial loss: 0.673059\n",
      "epoch 30; iter: 400; batch classifier loss: 0.419464; batch adversarial loss: 0.605048\n",
      "epoch 31; iter: 0; batch classifier loss: 0.357093; batch adversarial loss: 0.578799\n",
      "epoch 31; iter: 200; batch classifier loss: 0.509322; batch adversarial loss: 0.620290\n",
      "epoch 31; iter: 400; batch classifier loss: 0.531990; batch adversarial loss: 0.626199\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361538; batch adversarial loss: 0.662654\n",
      "epoch 32; iter: 200; batch classifier loss: 0.357907; batch adversarial loss: 0.639497\n",
      "epoch 32; iter: 400; batch classifier loss: 0.376514; batch adversarial loss: 0.620896\n",
      "epoch 33; iter: 0; batch classifier loss: 0.564177; batch adversarial loss: 0.600523\n",
      "epoch 33; iter: 200; batch classifier loss: 0.544176; batch adversarial loss: 0.635336\n",
      "epoch 33; iter: 400; batch classifier loss: 0.413877; batch adversarial loss: 0.705502\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491873; batch adversarial loss: 0.668909\n",
      "epoch 34; iter: 200; batch classifier loss: 0.611654; batch adversarial loss: 0.629887\n",
      "epoch 34; iter: 400; batch classifier loss: 0.410263; batch adversarial loss: 0.578136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479969; batch adversarial loss: 0.644339\n",
      "epoch 35; iter: 200; batch classifier loss: 0.364267; batch adversarial loss: 0.623990\n",
      "epoch 35; iter: 400; batch classifier loss: 0.404520; batch adversarial loss: 0.627300\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347977; batch adversarial loss: 0.641559\n",
      "epoch 36; iter: 200; batch classifier loss: 0.410167; batch adversarial loss: 0.592930\n",
      "epoch 36; iter: 400; batch classifier loss: 0.594139; batch adversarial loss: 0.624803\n",
      "epoch 37; iter: 0; batch classifier loss: 0.515698; batch adversarial loss: 0.666288\n",
      "epoch 37; iter: 200; batch classifier loss: 0.416197; batch adversarial loss: 0.606353\n",
      "epoch 37; iter: 400; batch classifier loss: 0.570164; batch adversarial loss: 0.673908\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408980; batch adversarial loss: 0.724433\n",
      "epoch 38; iter: 200; batch classifier loss: 0.551771; batch adversarial loss: 0.556700\n",
      "epoch 38; iter: 400; batch classifier loss: 0.394283; batch adversarial loss: 0.698944\n",
      "epoch 39; iter: 0; batch classifier loss: 0.507000; batch adversarial loss: 0.592907\n",
      "epoch 39; iter: 200; batch classifier loss: 0.512536; batch adversarial loss: 0.622275\n",
      "epoch 39; iter: 400; batch classifier loss: 0.411418; batch adversarial loss: 0.671452\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398893; batch adversarial loss: 0.556669\n",
      "epoch 40; iter: 200; batch classifier loss: 0.362167; batch adversarial loss: 0.629722\n",
      "epoch 40; iter: 400; batch classifier loss: 0.427621; batch adversarial loss: 0.608550\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453786; batch adversarial loss: 0.722154\n",
      "epoch 41; iter: 200; batch classifier loss: 0.563954; batch adversarial loss: 0.571351\n",
      "epoch 41; iter: 400; batch classifier loss: 0.669059; batch adversarial loss: 0.529665\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426021; batch adversarial loss: 0.609011\n",
      "epoch 42; iter: 200; batch classifier loss: 0.320757; batch adversarial loss: 0.650335\n",
      "epoch 42; iter: 400; batch classifier loss: 0.749860; batch adversarial loss: 0.622555\n",
      "epoch 43; iter: 0; batch classifier loss: 0.444448; batch adversarial loss: 0.666165\n",
      "epoch 43; iter: 200; batch classifier loss: 0.451222; batch adversarial loss: 0.741366\n",
      "epoch 43; iter: 400; batch classifier loss: 0.425422; batch adversarial loss: 0.637601\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446684; batch adversarial loss: 0.566321\n",
      "epoch 44; iter: 200; batch classifier loss: 0.590198; batch adversarial loss: 0.597308\n",
      "epoch 44; iter: 400; batch classifier loss: 0.337500; batch adversarial loss: 0.637870\n",
      "epoch 45; iter: 0; batch classifier loss: 0.469171; batch adversarial loss: 0.585836\n",
      "epoch 45; iter: 200; batch classifier loss: 0.519301; batch adversarial loss: 0.581665\n",
      "epoch 45; iter: 400; batch classifier loss: 0.548627; batch adversarial loss: 0.574805\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500803; batch adversarial loss: 0.665080\n",
      "epoch 46; iter: 200; batch classifier loss: 0.418441; batch adversarial loss: 0.557174\n",
      "epoch 46; iter: 400; batch classifier loss: 0.580941; batch adversarial loss: 0.602206\n",
      "epoch 47; iter: 0; batch classifier loss: 0.358237; batch adversarial loss: 0.575263\n",
      "epoch 47; iter: 200; batch classifier loss: 0.542857; batch adversarial loss: 0.575280\n",
      "epoch 47; iter: 400; batch classifier loss: 0.498956; batch adversarial loss: 0.681990\n",
      "epoch 48; iter: 0; batch classifier loss: 0.340482; batch adversarial loss: 0.681978\n",
      "epoch 48; iter: 200; batch classifier loss: 0.417063; batch adversarial loss: 0.670247\n",
      "epoch 48; iter: 400; batch classifier loss: 0.467648; batch adversarial loss: 0.591991\n",
      "epoch 49; iter: 0; batch classifier loss: 0.531456; batch adversarial loss: 0.593370\n",
      "epoch 49; iter: 200; batch classifier loss: 0.348774; batch adversarial loss: 0.630773\n",
      "epoch 49; iter: 400; batch classifier loss: 0.404257; batch adversarial loss: 0.616268\n",
      "epoch 0; iter: 0; batch classifier loss: 8.385489; batch adversarial loss: 0.718551\n",
      "epoch 0; iter: 200; batch classifier loss: 5.070651; batch adversarial loss: 0.636146\n",
      "epoch 0; iter: 400; batch classifier loss: 7.267576; batch adversarial loss: 0.634120\n",
      "epoch 1; iter: 0; batch classifier loss: 5.428071; batch adversarial loss: 0.552537\n",
      "epoch 1; iter: 200; batch classifier loss: 1.684965; batch adversarial loss: 0.545915\n",
      "epoch 1; iter: 400; batch classifier loss: 1.994919; batch adversarial loss: 0.650909\n",
      "epoch 2; iter: 0; batch classifier loss: 3.148343; batch adversarial loss: 0.618117\n",
      "epoch 2; iter: 200; batch classifier loss: 5.530767; batch adversarial loss: 0.598884\n",
      "epoch 2; iter: 400; batch classifier loss: 1.597622; batch adversarial loss: 0.635118\n",
      "epoch 3; iter: 0; batch classifier loss: 0.378439; batch adversarial loss: 0.568403\n",
      "epoch 3; iter: 200; batch classifier loss: 1.234361; batch adversarial loss: 0.527970\n",
      "epoch 3; iter: 400; batch classifier loss: 1.574904; batch adversarial loss: 0.564905\n",
      "epoch 4; iter: 0; batch classifier loss: 5.612450; batch adversarial loss: 0.625335\n",
      "epoch 4; iter: 200; batch classifier loss: 0.493557; batch adversarial loss: 0.613082\n",
      "epoch 4; iter: 400; batch classifier loss: 0.287382; batch adversarial loss: 0.598769\n",
      "epoch 5; iter: 0; batch classifier loss: 1.424463; batch adversarial loss: 0.757422\n",
      "epoch 5; iter: 200; batch classifier loss: 0.387267; batch adversarial loss: 0.601751\n",
      "epoch 5; iter: 400; batch classifier loss: 0.354389; batch adversarial loss: 0.557196\n",
      "epoch 6; iter: 0; batch classifier loss: 0.363511; batch adversarial loss: 0.710231\n",
      "epoch 6; iter: 200; batch classifier loss: 0.544514; batch adversarial loss: 0.627640\n",
      "epoch 6; iter: 400; batch classifier loss: 0.957206; batch adversarial loss: 0.719315\n",
      "epoch 7; iter: 0; batch classifier loss: 0.425509; batch adversarial loss: 0.683683\n",
      "epoch 7; iter: 200; batch classifier loss: 0.695362; batch adversarial loss: 0.579761\n",
      "epoch 7; iter: 400; batch classifier loss: 0.403780; batch adversarial loss: 0.601284\n",
      "epoch 8; iter: 0; batch classifier loss: 0.452694; batch adversarial loss: 0.765566\n",
      "epoch 8; iter: 200; batch classifier loss: 0.405991; batch adversarial loss: 0.640874\n",
      "epoch 8; iter: 400; batch classifier loss: 0.611316; batch adversarial loss: 0.544570\n",
      "epoch 9; iter: 0; batch classifier loss: 0.198087; batch adversarial loss: 0.571632\n",
      "epoch 9; iter: 200; batch classifier loss: 0.582769; batch adversarial loss: 0.604871\n",
      "epoch 9; iter: 400; batch classifier loss: 0.333181; batch adversarial loss: 0.629035\n",
      "epoch 10; iter: 0; batch classifier loss: 0.216988; batch adversarial loss: 0.615433\n",
      "epoch 10; iter: 200; batch classifier loss: 0.390500; batch adversarial loss: 0.602983\n",
      "epoch 10; iter: 400; batch classifier loss: 0.251784; batch adversarial loss: 0.601476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.434763; batch adversarial loss: 0.614288\n",
      "epoch 11; iter: 200; batch classifier loss: 0.517714; batch adversarial loss: 0.657376\n",
      "epoch 11; iter: 400; batch classifier loss: 0.336252; batch adversarial loss: 0.691717\n",
      "epoch 12; iter: 0; batch classifier loss: 0.462696; batch adversarial loss: 0.500899\n",
      "epoch 12; iter: 200; batch classifier loss: 0.451679; batch adversarial loss: 0.723064\n",
      "epoch 12; iter: 400; batch classifier loss: 0.411507; batch adversarial loss: 0.606044\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336982; batch adversarial loss: 0.644447\n",
      "epoch 13; iter: 200; batch classifier loss: 0.357833; batch adversarial loss: 0.564975\n",
      "epoch 13; iter: 400; batch classifier loss: 0.437852; batch adversarial loss: 0.616630\n",
      "epoch 14; iter: 0; batch classifier loss: 0.425676; batch adversarial loss: 0.650016\n",
      "epoch 14; iter: 200; batch classifier loss: 0.211111; batch adversarial loss: 0.574416\n",
      "epoch 14; iter: 400; batch classifier loss: 0.299419; batch adversarial loss: 0.625295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.320792; batch adversarial loss: 0.606269\n",
      "epoch 15; iter: 200; batch classifier loss: 0.329806; batch adversarial loss: 0.620412\n",
      "epoch 15; iter: 400; batch classifier loss: 0.253573; batch adversarial loss: 0.631312\n",
      "epoch 16; iter: 0; batch classifier loss: 0.244178; batch adversarial loss: 0.610176\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357883; batch adversarial loss: 0.630608\n",
      "epoch 16; iter: 400; batch classifier loss: 0.460652; batch adversarial loss: 0.665110\n",
      "epoch 17; iter: 0; batch classifier loss: 0.296742; batch adversarial loss: 0.613140\n",
      "epoch 17; iter: 200; batch classifier loss: 0.360640; batch adversarial loss: 0.671237\n",
      "epoch 17; iter: 400; batch classifier loss: 0.454904; batch adversarial loss: 0.584590\n",
      "epoch 18; iter: 0; batch classifier loss: 0.296301; batch adversarial loss: 0.612345\n",
      "epoch 18; iter: 200; batch classifier loss: 0.501341; batch adversarial loss: 0.617311\n",
      "epoch 18; iter: 400; batch classifier loss: 1.082256; batch adversarial loss: 0.602083\n",
      "epoch 19; iter: 0; batch classifier loss: 0.383066; batch adversarial loss: 0.578803\n",
      "epoch 19; iter: 200; batch classifier loss: 0.435768; batch adversarial loss: 0.605809\n",
      "epoch 19; iter: 400; batch classifier loss: 0.298223; batch adversarial loss: 0.642213\n",
      "epoch 20; iter: 0; batch classifier loss: 0.247439; batch adversarial loss: 0.621733\n",
      "epoch 20; iter: 200; batch classifier loss: 0.577863; batch adversarial loss: 0.662251\n",
      "epoch 20; iter: 400; batch classifier loss: 0.413696; batch adversarial loss: 0.589912\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456481; batch adversarial loss: 0.673736\n",
      "epoch 21; iter: 200; batch classifier loss: 0.332969; batch adversarial loss: 0.607581\n",
      "epoch 21; iter: 400; batch classifier loss: 0.269488; batch adversarial loss: 0.649230\n",
      "epoch 22; iter: 0; batch classifier loss: 0.400927; batch adversarial loss: 0.559008\n",
      "epoch 22; iter: 200; batch classifier loss: 0.367611; batch adversarial loss: 0.613520\n",
      "epoch 22; iter: 400; batch classifier loss: 0.507052; batch adversarial loss: 0.585900\n",
      "epoch 23; iter: 0; batch classifier loss: 0.253923; batch adversarial loss: 0.593529\n",
      "epoch 23; iter: 200; batch classifier loss: 0.291815; batch adversarial loss: 0.648751\n",
      "epoch 23; iter: 400; batch classifier loss: 0.293012; batch adversarial loss: 0.599706\n",
      "epoch 24; iter: 0; batch classifier loss: 0.283947; batch adversarial loss: 0.582441\n",
      "epoch 24; iter: 200; batch classifier loss: 0.406832; batch adversarial loss: 0.610407\n",
      "epoch 24; iter: 400; batch classifier loss: 0.430199; batch adversarial loss: 0.683522\n",
      "epoch 25; iter: 0; batch classifier loss: 0.379337; batch adversarial loss: 0.621037\n",
      "epoch 25; iter: 200; batch classifier loss: 0.392966; batch adversarial loss: 0.614122\n",
      "epoch 25; iter: 400; batch classifier loss: 0.342824; batch adversarial loss: 0.669333\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458186; batch adversarial loss: 0.626967\n",
      "epoch 26; iter: 200; batch classifier loss: 0.552385; batch adversarial loss: 0.585082\n",
      "epoch 26; iter: 400; batch classifier loss: 0.376814; batch adversarial loss: 0.638091\n",
      "epoch 27; iter: 0; batch classifier loss: 0.373849; batch adversarial loss: 0.636593\n",
      "epoch 27; iter: 200; batch classifier loss: 0.505015; batch adversarial loss: 0.625756\n",
      "epoch 27; iter: 400; batch classifier loss: 0.313022; batch adversarial loss: 0.667213\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362625; batch adversarial loss: 0.617312\n",
      "epoch 28; iter: 200; batch classifier loss: 0.449427; batch adversarial loss: 0.600517\n",
      "epoch 28; iter: 400; batch classifier loss: 0.504278; batch adversarial loss: 0.618176\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433888; batch adversarial loss: 0.625305\n",
      "epoch 29; iter: 200; batch classifier loss: 0.192124; batch adversarial loss: 0.641474\n",
      "epoch 29; iter: 400; batch classifier loss: 0.417754; batch adversarial loss: 0.592479\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397221; batch adversarial loss: 0.743136\n",
      "epoch 30; iter: 200; batch classifier loss: 0.382576; batch adversarial loss: 0.610733\n",
      "epoch 30; iter: 400; batch classifier loss: 0.441852; batch adversarial loss: 0.655851\n",
      "epoch 31; iter: 0; batch classifier loss: 0.337750; batch adversarial loss: 0.658641\n",
      "epoch 31; iter: 200; batch classifier loss: 0.292679; batch adversarial loss: 0.659382\n",
      "epoch 31; iter: 400; batch classifier loss: 0.470710; batch adversarial loss: 0.617416\n",
      "epoch 32; iter: 0; batch classifier loss: 0.317023; batch adversarial loss: 0.700794\n",
      "epoch 32; iter: 200; batch classifier loss: 0.257633; batch adversarial loss: 0.591552\n",
      "epoch 32; iter: 400; batch classifier loss: 0.361638; batch adversarial loss: 0.616693\n",
      "epoch 33; iter: 0; batch classifier loss: 0.282373; batch adversarial loss: 0.701830\n",
      "epoch 33; iter: 200; batch classifier loss: 0.310013; batch adversarial loss: 0.652093\n",
      "epoch 33; iter: 400; batch classifier loss: 0.417499; batch adversarial loss: 0.589181\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404129; batch adversarial loss: 0.557614\n",
      "epoch 34; iter: 200; batch classifier loss: 0.210480; batch adversarial loss: 0.688774\n",
      "epoch 34; iter: 400; batch classifier loss: 0.409411; batch adversarial loss: 0.600458\n",
      "epoch 35; iter: 0; batch classifier loss: 0.384282; batch adversarial loss: 0.611828\n",
      "epoch 35; iter: 200; batch classifier loss: 0.578166; batch adversarial loss: 0.639574\n",
      "epoch 35; iter: 400; batch classifier loss: 0.571069; batch adversarial loss: 0.695499\n",
      "epoch 36; iter: 0; batch classifier loss: 0.534177; batch adversarial loss: 0.604540\n",
      "epoch 36; iter: 200; batch classifier loss: 0.497961; batch adversarial loss: 0.611708\n",
      "epoch 36; iter: 400; batch classifier loss: 0.392165; batch adversarial loss: 0.650166\n",
      "epoch 37; iter: 0; batch classifier loss: 0.330334; batch adversarial loss: 0.576427\n",
      "epoch 37; iter: 200; batch classifier loss: 0.378048; batch adversarial loss: 0.699609\n",
      "epoch 37; iter: 400; batch classifier loss: 0.592649; batch adversarial loss: 0.634230\n",
      "epoch 38; iter: 0; batch classifier loss: 0.613725; batch adversarial loss: 0.608693\n",
      "epoch 38; iter: 200; batch classifier loss: 0.366001; batch adversarial loss: 0.691982\n",
      "epoch 38; iter: 400; batch classifier loss: 0.538782; batch adversarial loss: 0.632755\n",
      "epoch 39; iter: 0; batch classifier loss: 0.390611; batch adversarial loss: 0.658446\n",
      "epoch 39; iter: 200; batch classifier loss: 0.289286; batch adversarial loss: 0.594141\n",
      "epoch 39; iter: 400; batch classifier loss: 0.431035; batch adversarial loss: 0.570322\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419893; batch adversarial loss: 0.621002\n",
      "epoch 40; iter: 200; batch classifier loss: 0.303766; batch adversarial loss: 0.556617\n",
      "epoch 40; iter: 400; batch classifier loss: 0.358806; batch adversarial loss: 0.617349\n",
      "epoch 41; iter: 0; batch classifier loss: 0.317605; batch adversarial loss: 0.593149\n",
      "epoch 41; iter: 200; batch classifier loss: 0.366150; batch adversarial loss: 0.577434\n",
      "epoch 41; iter: 400; batch classifier loss: 0.666603; batch adversarial loss: 0.572842\n",
      "epoch 42; iter: 0; batch classifier loss: 0.676641; batch adversarial loss: 0.666817\n",
      "epoch 42; iter: 200; batch classifier loss: 0.297199; batch adversarial loss: 0.578916\n",
      "epoch 42; iter: 400; batch classifier loss: 0.317158; batch adversarial loss: 0.594872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.313293; batch adversarial loss: 0.657156\n",
      "epoch 43; iter: 200; batch classifier loss: 0.561941; batch adversarial loss: 0.661457\n",
      "epoch 43; iter: 400; batch classifier loss: 0.598300; batch adversarial loss: 0.560281\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321561; batch adversarial loss: 0.591685\n",
      "epoch 44; iter: 200; batch classifier loss: 0.468392; batch adversarial loss: 0.676940\n",
      "epoch 44; iter: 400; batch classifier loss: 0.557819; batch adversarial loss: 0.622922\n",
      "epoch 45; iter: 0; batch classifier loss: 0.621348; batch adversarial loss: 0.593599\n",
      "epoch 45; iter: 200; batch classifier loss: 0.551598; batch adversarial loss: 0.602324\n",
      "epoch 45; iter: 400; batch classifier loss: 0.444557; batch adversarial loss: 0.606546\n",
      "epoch 46; iter: 0; batch classifier loss: 0.390486; batch adversarial loss: 0.606355\n",
      "epoch 46; iter: 200; batch classifier loss: 0.889074; batch adversarial loss: 0.603990\n",
      "epoch 46; iter: 400; batch classifier loss: 0.584024; batch adversarial loss: 0.671450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.263631; batch adversarial loss: 0.575847\n",
      "epoch 47; iter: 200; batch classifier loss: 0.719771; batch adversarial loss: 0.658721\n",
      "epoch 47; iter: 400; batch classifier loss: 0.688725; batch adversarial loss: 0.624674\n",
      "epoch 48; iter: 0; batch classifier loss: 0.358269; batch adversarial loss: 0.653771\n",
      "epoch 48; iter: 200; batch classifier loss: 0.370539; batch adversarial loss: 0.619085\n",
      "epoch 48; iter: 400; batch classifier loss: 0.549282; batch adversarial loss: 0.610782\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389110; batch adversarial loss: 0.648057\n",
      "epoch 49; iter: 200; batch classifier loss: 0.272566; batch adversarial loss: 0.665089\n",
      "epoch 49; iter: 400; batch classifier loss: 0.481271; batch adversarial loss: 0.642880\n",
      "epoch 0; iter: 0; batch classifier loss: 12.275954; batch adversarial loss: 0.665578\n",
      "epoch 0; iter: 200; batch classifier loss: 21.317938; batch adversarial loss: 0.670450\n",
      "epoch 0; iter: 400; batch classifier loss: 2.873301; batch adversarial loss: 0.650853\n",
      "epoch 1; iter: 0; batch classifier loss: 19.235916; batch adversarial loss: 0.648162\n",
      "epoch 1; iter: 200; batch classifier loss: 7.214109; batch adversarial loss: 0.630908\n",
      "epoch 1; iter: 400; batch classifier loss: 1.516447; batch adversarial loss: 0.687573\n",
      "epoch 2; iter: 0; batch classifier loss: 0.519913; batch adversarial loss: 0.561510\n",
      "epoch 2; iter: 200; batch classifier loss: 1.806319; batch adversarial loss: 0.642330\n",
      "epoch 2; iter: 400; batch classifier loss: 0.456633; batch adversarial loss: 0.551663\n",
      "epoch 3; iter: 0; batch classifier loss: 0.519402; batch adversarial loss: 0.656949\n",
      "epoch 3; iter: 200; batch classifier loss: 0.337491; batch adversarial loss: 0.602576\n",
      "epoch 3; iter: 400; batch classifier loss: 2.571560; batch adversarial loss: 0.627282\n",
      "epoch 4; iter: 0; batch classifier loss: 1.216997; batch adversarial loss: 0.634265\n",
      "epoch 4; iter: 200; batch classifier loss: 0.577003; batch adversarial loss: 0.652584\n",
      "epoch 4; iter: 400; batch classifier loss: 0.604359; batch adversarial loss: 0.673578\n",
      "epoch 5; iter: 0; batch classifier loss: 1.502825; batch adversarial loss: 0.671659\n",
      "epoch 5; iter: 200; batch classifier loss: 0.472169; batch adversarial loss: 0.607001\n",
      "epoch 5; iter: 400; batch classifier loss: 0.492363; batch adversarial loss: 0.671255\n",
      "epoch 6; iter: 0; batch classifier loss: 0.405421; batch adversarial loss: 0.630770\n",
      "epoch 6; iter: 200; batch classifier loss: 0.358714; batch adversarial loss: 0.733978\n",
      "epoch 6; iter: 400; batch classifier loss: 0.436929; batch adversarial loss: 0.644806\n",
      "epoch 7; iter: 0; batch classifier loss: 0.472107; batch adversarial loss: 0.673496\n",
      "epoch 7; iter: 200; batch classifier loss: 0.378737; batch adversarial loss: 0.632937\n",
      "epoch 7; iter: 400; batch classifier loss: 0.430130; batch adversarial loss: 0.613807\n",
      "epoch 8; iter: 0; batch classifier loss: 0.392616; batch adversarial loss: 0.666285\n",
      "epoch 8; iter: 200; batch classifier loss: 0.336796; batch adversarial loss: 0.655326\n",
      "epoch 8; iter: 400; batch classifier loss: 0.366859; batch adversarial loss: 0.586063\n",
      "epoch 9; iter: 0; batch classifier loss: 0.633447; batch adversarial loss: 0.679385\n",
      "epoch 9; iter: 200; batch classifier loss: 0.402557; batch adversarial loss: 0.697358\n",
      "epoch 9; iter: 400; batch classifier loss: 0.267842; batch adversarial loss: 0.669433\n",
      "epoch 10; iter: 0; batch classifier loss: 1.024443; batch adversarial loss: 0.690735\n",
      "epoch 10; iter: 200; batch classifier loss: 0.455070; batch adversarial loss: 0.606418\n",
      "epoch 10; iter: 400; batch classifier loss: 0.326969; batch adversarial loss: 0.685738\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533594; batch adversarial loss: 0.580661\n",
      "epoch 11; iter: 200; batch classifier loss: 0.332838; batch adversarial loss: 0.629114\n",
      "epoch 11; iter: 400; batch classifier loss: 0.268464; batch adversarial loss: 0.575903\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476672; batch adversarial loss: 0.687087\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420276; batch adversarial loss: 0.641940\n",
      "epoch 12; iter: 400; batch classifier loss: 0.460536; batch adversarial loss: 0.623132\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340531; batch adversarial loss: 0.637097\n",
      "epoch 13; iter: 200; batch classifier loss: 0.411853; batch adversarial loss: 0.633182\n",
      "epoch 13; iter: 400; batch classifier loss: 0.340754; batch adversarial loss: 0.665919\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403030; batch adversarial loss: 0.659257\n",
      "epoch 14; iter: 200; batch classifier loss: 0.458221; batch adversarial loss: 0.540322\n",
      "epoch 14; iter: 400; batch classifier loss: 0.471811; batch adversarial loss: 0.564826\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456378; batch adversarial loss: 0.615135\n",
      "epoch 15; iter: 200; batch classifier loss: 0.384220; batch adversarial loss: 0.630547\n",
      "epoch 15; iter: 400; batch classifier loss: 0.352839; batch adversarial loss: 0.644376\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379534; batch adversarial loss: 0.603582\n",
      "epoch 16; iter: 200; batch classifier loss: 0.311423; batch adversarial loss: 0.680262\n",
      "epoch 16; iter: 400; batch classifier loss: 0.368441; batch adversarial loss: 0.579854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383602; batch adversarial loss: 0.672538\n",
      "epoch 17; iter: 200; batch classifier loss: 0.502837; batch adversarial loss: 0.696754\n",
      "epoch 17; iter: 400; batch classifier loss: 0.368529; batch adversarial loss: 0.734167\n",
      "epoch 18; iter: 0; batch classifier loss: 0.418921; batch adversarial loss: 0.649316\n",
      "epoch 18; iter: 200; batch classifier loss: 0.420311; batch adversarial loss: 0.605592\n",
      "epoch 18; iter: 400; batch classifier loss: 0.347633; batch adversarial loss: 0.643832\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374331; batch adversarial loss: 0.597677\n",
      "epoch 19; iter: 200; batch classifier loss: 0.247977; batch adversarial loss: 0.652787\n",
      "epoch 19; iter: 400; batch classifier loss: 0.364241; batch adversarial loss: 0.625278\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210962; batch adversarial loss: 0.713378\n",
      "epoch 20; iter: 200; batch classifier loss: 0.246279; batch adversarial loss: 0.625047\n",
      "epoch 20; iter: 400; batch classifier loss: 0.211699; batch adversarial loss: 0.604960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.370274; batch adversarial loss: 0.645381\n",
      "epoch 21; iter: 200; batch classifier loss: 0.387611; batch adversarial loss: 0.655344\n",
      "epoch 21; iter: 400; batch classifier loss: 0.389696; batch adversarial loss: 0.697590\n",
      "epoch 22; iter: 0; batch classifier loss: 0.317234; batch adversarial loss: 0.679360\n",
      "epoch 22; iter: 200; batch classifier loss: 0.560033; batch adversarial loss: 0.711323\n",
      "epoch 22; iter: 400; batch classifier loss: 0.391568; batch adversarial loss: 0.593771\n",
      "epoch 23; iter: 0; batch classifier loss: 0.513107; batch adversarial loss: 0.666910\n",
      "epoch 23; iter: 200; batch classifier loss: 0.298456; batch adversarial loss: 0.647683\n",
      "epoch 23; iter: 400; batch classifier loss: 0.532039; batch adversarial loss: 0.626355\n",
      "epoch 24; iter: 0; batch classifier loss: 0.248950; batch adversarial loss: 0.625741\n",
      "epoch 24; iter: 200; batch classifier loss: 0.323636; batch adversarial loss: 0.681623\n",
      "epoch 24; iter: 400; batch classifier loss: 0.283813; batch adversarial loss: 0.607650\n",
      "epoch 25; iter: 0; batch classifier loss: 0.467192; batch adversarial loss: 0.564608\n",
      "epoch 25; iter: 200; batch classifier loss: 0.404338; batch adversarial loss: 0.705975\n",
      "epoch 25; iter: 400; batch classifier loss: 0.477016; batch adversarial loss: 0.660873\n",
      "epoch 26; iter: 0; batch classifier loss: 0.345396; batch adversarial loss: 0.563765\n",
      "epoch 26; iter: 200; batch classifier loss: 0.466632; batch adversarial loss: 0.620918\n",
      "epoch 26; iter: 400; batch classifier loss: 0.380582; batch adversarial loss: 0.680602\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441958; batch adversarial loss: 0.649332\n",
      "epoch 27; iter: 200; batch classifier loss: 0.319274; batch adversarial loss: 0.678738\n",
      "epoch 27; iter: 400; batch classifier loss: 0.333400; batch adversarial loss: 0.612176\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452279; batch adversarial loss: 0.640046\n",
      "epoch 28; iter: 200; batch classifier loss: 0.519136; batch adversarial loss: 0.610898\n",
      "epoch 28; iter: 400; batch classifier loss: 0.258637; batch adversarial loss: 0.663024\n",
      "epoch 29; iter: 0; batch classifier loss: 0.417502; batch adversarial loss: 0.635788\n",
      "epoch 29; iter: 200; batch classifier loss: 0.398076; batch adversarial loss: 0.544380\n",
      "epoch 29; iter: 400; batch classifier loss: 0.375801; batch adversarial loss: 0.579619\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437397; batch adversarial loss: 0.612710\n",
      "epoch 30; iter: 200; batch classifier loss: 0.320579; batch adversarial loss: 0.612318\n",
      "epoch 30; iter: 400; batch classifier loss: 0.657843; batch adversarial loss: 0.596740\n",
      "epoch 31; iter: 0; batch classifier loss: 0.356505; batch adversarial loss: 0.640593\n",
      "epoch 31; iter: 200; batch classifier loss: 0.409892; batch adversarial loss: 0.682867\n",
      "epoch 31; iter: 400; batch classifier loss: 0.362222; batch adversarial loss: 0.627618\n",
      "epoch 32; iter: 0; batch classifier loss: 0.373684; batch adversarial loss: 0.722819\n",
      "epoch 32; iter: 200; batch classifier loss: 0.262929; batch adversarial loss: 0.648847\n",
      "epoch 32; iter: 400; batch classifier loss: 0.434033; batch adversarial loss: 0.645535\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323187; batch adversarial loss: 0.656436\n",
      "epoch 33; iter: 200; batch classifier loss: 0.260649; batch adversarial loss: 0.646841\n",
      "epoch 33; iter: 400; batch classifier loss: 0.317565; batch adversarial loss: 0.638920\n",
      "epoch 34; iter: 0; batch classifier loss: 0.532859; batch adversarial loss: 0.652690\n",
      "epoch 34; iter: 200; batch classifier loss: 0.519793; batch adversarial loss: 0.727865\n",
      "epoch 34; iter: 400; batch classifier loss: 0.344144; batch adversarial loss: 0.607523\n",
      "epoch 35; iter: 0; batch classifier loss: 0.349043; batch adversarial loss: 0.631468\n",
      "epoch 35; iter: 200; batch classifier loss: 0.738814; batch adversarial loss: 0.640341\n",
      "epoch 35; iter: 400; batch classifier loss: 0.452211; batch adversarial loss: 0.604366\n",
      "epoch 36; iter: 0; batch classifier loss: 0.290254; batch adversarial loss: 0.663910\n",
      "epoch 36; iter: 200; batch classifier loss: 0.564187; batch adversarial loss: 0.654385\n",
      "epoch 36; iter: 400; batch classifier loss: 0.511237; batch adversarial loss: 0.596386\n",
      "epoch 37; iter: 0; batch classifier loss: 0.838321; batch adversarial loss: 0.696330\n",
      "epoch 37; iter: 200; batch classifier loss: 0.485662; batch adversarial loss: 0.647554\n",
      "epoch 37; iter: 400; batch classifier loss: 0.413114; batch adversarial loss: 0.641843\n",
      "epoch 38; iter: 0; batch classifier loss: 0.365018; batch adversarial loss: 0.600157\n",
      "epoch 38; iter: 200; batch classifier loss: 0.586637; batch adversarial loss: 0.665244\n",
      "epoch 38; iter: 400; batch classifier loss: 0.345811; batch adversarial loss: 0.702953\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432486; batch adversarial loss: 0.581619\n",
      "epoch 39; iter: 200; batch classifier loss: 0.469497; batch adversarial loss: 0.604637\n",
      "epoch 39; iter: 400; batch classifier loss: 0.499856; batch adversarial loss: 0.648048\n",
      "epoch 40; iter: 0; batch classifier loss: 0.362876; batch adversarial loss: 0.597943\n",
      "epoch 40; iter: 200; batch classifier loss: 0.498736; batch adversarial loss: 0.618282\n",
      "epoch 40; iter: 400; batch classifier loss: 0.622046; batch adversarial loss: 0.625131\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416874; batch adversarial loss: 0.664881\n",
      "epoch 41; iter: 200; batch classifier loss: 0.707130; batch adversarial loss: 0.679462\n",
      "epoch 41; iter: 400; batch classifier loss: 0.473877; batch adversarial loss: 0.585094\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448139; batch adversarial loss: 0.590520\n",
      "epoch 42; iter: 200; batch classifier loss: 0.484484; batch adversarial loss: 0.599081\n",
      "epoch 42; iter: 400; batch classifier loss: 0.660134; batch adversarial loss: 0.641973\n",
      "epoch 43; iter: 0; batch classifier loss: 0.551307; batch adversarial loss: 0.584553\n",
      "epoch 43; iter: 200; batch classifier loss: 0.616579; batch adversarial loss: 0.589729\n",
      "epoch 43; iter: 400; batch classifier loss: 0.302877; batch adversarial loss: 0.671897\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455396; batch adversarial loss: 0.577290\n",
      "epoch 44; iter: 200; batch classifier loss: 0.156645; batch adversarial loss: 0.709781\n",
      "epoch 44; iter: 400; batch classifier loss: 0.614922; batch adversarial loss: 0.680265\n",
      "epoch 45; iter: 0; batch classifier loss: 0.625546; batch adversarial loss: 0.527252\n",
      "epoch 45; iter: 200; batch classifier loss: 0.457245; batch adversarial loss: 0.642330\n",
      "epoch 45; iter: 400; batch classifier loss: 0.468522; batch adversarial loss: 0.591901\n",
      "epoch 46; iter: 0; batch classifier loss: 0.465035; batch adversarial loss: 0.667051\n",
      "epoch 46; iter: 200; batch classifier loss: 0.444256; batch adversarial loss: 0.660798\n",
      "epoch 46; iter: 400; batch classifier loss: 0.531289; batch adversarial loss: 0.633809\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476585; batch adversarial loss: 0.645769\n",
      "epoch 47; iter: 200; batch classifier loss: 0.596561; batch adversarial loss: 0.632790\n",
      "epoch 47; iter: 400; batch classifier loss: 0.351579; batch adversarial loss: 0.561004\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597683; batch adversarial loss: 0.599688\n",
      "epoch 48; iter: 200; batch classifier loss: 0.557556; batch adversarial loss: 0.617402\n",
      "epoch 48; iter: 400; batch classifier loss: 0.479490; batch adversarial loss: 0.601546\n",
      "epoch 49; iter: 0; batch classifier loss: 0.514550; batch adversarial loss: 0.693031\n",
      "epoch 49; iter: 200; batch classifier loss: 0.342484; batch adversarial loss: 0.582047\n",
      "epoch 49; iter: 400; batch classifier loss: 0.464752; batch adversarial loss: 0.686138\n",
      "epoch 0; iter: 0; batch classifier loss: 163.325043; batch adversarial loss: 0.715823\n",
      "epoch 0; iter: 200; batch classifier loss: 14.992255; batch adversarial loss: 0.689177\n",
      "epoch 0; iter: 400; batch classifier loss: 5.376040; batch adversarial loss: 0.648515\n",
      "epoch 1; iter: 0; batch classifier loss: 7.576998; batch adversarial loss: 0.635303\n",
      "epoch 1; iter: 200; batch classifier loss: 5.685071; batch adversarial loss: 0.659637\n",
      "epoch 1; iter: 400; batch classifier loss: 1.179105; batch adversarial loss: 0.660504\n",
      "epoch 2; iter: 0; batch classifier loss: 4.969540; batch adversarial loss: 0.583774\n",
      "epoch 2; iter: 200; batch classifier loss: 2.408898; batch adversarial loss: 0.577771\n",
      "epoch 2; iter: 400; batch classifier loss: 0.347729; batch adversarial loss: 0.664229\n",
      "epoch 3; iter: 0; batch classifier loss: 1.856158; batch adversarial loss: 0.615970\n",
      "epoch 3; iter: 200; batch classifier loss: 1.444381; batch adversarial loss: 0.670494\n",
      "epoch 3; iter: 400; batch classifier loss: 1.990143; batch adversarial loss: 0.583198\n",
      "epoch 4; iter: 0; batch classifier loss: 2.101924; batch adversarial loss: 0.649315\n",
      "epoch 4; iter: 200; batch classifier loss: 1.538750; batch adversarial loss: 0.590979\n",
      "epoch 4; iter: 400; batch classifier loss: 0.946872; batch adversarial loss: 0.677638\n",
      "epoch 5; iter: 0; batch classifier loss: 0.966690; batch adversarial loss: 0.610807\n",
      "epoch 5; iter: 200; batch classifier loss: 1.002183; batch adversarial loss: 0.647241\n",
      "epoch 5; iter: 400; batch classifier loss: 0.463997; batch adversarial loss: 0.605591\n",
      "epoch 6; iter: 0; batch classifier loss: 0.887289; batch adversarial loss: 0.641892\n",
      "epoch 6; iter: 200; batch classifier loss: 0.626239; batch adversarial loss: 0.637774\n",
      "epoch 6; iter: 400; batch classifier loss: 0.452190; batch adversarial loss: 0.646628\n",
      "epoch 7; iter: 0; batch classifier loss: 0.723283; batch adversarial loss: 0.550303\n",
      "epoch 7; iter: 200; batch classifier loss: 0.468637; batch adversarial loss: 0.651642\n",
      "epoch 7; iter: 400; batch classifier loss: 0.460487; batch adversarial loss: 0.548345\n",
      "epoch 8; iter: 0; batch classifier loss: 0.304955; batch adversarial loss: 0.608054\n",
      "epoch 8; iter: 200; batch classifier loss: 0.557042; batch adversarial loss: 0.572501\n",
      "epoch 8; iter: 400; batch classifier loss: 0.536679; batch adversarial loss: 0.598180\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416450; batch adversarial loss: 0.659407\n",
      "epoch 9; iter: 200; batch classifier loss: 0.358565; batch adversarial loss: 0.649205\n",
      "epoch 9; iter: 400; batch classifier loss: 0.414431; batch adversarial loss: 0.680902\n",
      "epoch 10; iter: 0; batch classifier loss: 2.394620; batch adversarial loss: 0.600028\n",
      "epoch 10; iter: 200; batch classifier loss: 0.382799; batch adversarial loss: 0.626584\n",
      "epoch 10; iter: 400; batch classifier loss: 0.452833; batch adversarial loss: 0.584734\n",
      "epoch 11; iter: 0; batch classifier loss: 0.280285; batch adversarial loss: 0.590814\n",
      "epoch 11; iter: 200; batch classifier loss: 0.415638; batch adversarial loss: 0.634784\n",
      "epoch 11; iter: 400; batch classifier loss: 0.448860; batch adversarial loss: 0.607945\n",
      "epoch 12; iter: 0; batch classifier loss: 0.256682; batch adversarial loss: 0.598003\n",
      "epoch 12; iter: 200; batch classifier loss: 0.328200; batch adversarial loss: 0.677183\n",
      "epoch 12; iter: 400; batch classifier loss: 0.461424; batch adversarial loss: 0.699402\n",
      "epoch 13; iter: 0; batch classifier loss: 0.251716; batch adversarial loss: 0.665723\n",
      "epoch 13; iter: 200; batch classifier loss: 0.359791; batch adversarial loss: 0.680683\n",
      "epoch 13; iter: 400; batch classifier loss: 0.605501; batch adversarial loss: 0.600854\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367446; batch adversarial loss: 0.648035\n",
      "epoch 14; iter: 200; batch classifier loss: 0.528242; batch adversarial loss: 0.607921\n",
      "epoch 14; iter: 400; batch classifier loss: 0.309554; batch adversarial loss: 0.635176\n",
      "epoch 15; iter: 0; batch classifier loss: 0.403375; batch adversarial loss: 0.582926\n",
      "epoch 15; iter: 200; batch classifier loss: 0.324490; batch adversarial loss: 0.649493\n",
      "epoch 15; iter: 400; batch classifier loss: 0.295202; batch adversarial loss: 0.580475\n",
      "epoch 16; iter: 0; batch classifier loss: 0.255052; batch adversarial loss: 0.630726\n",
      "epoch 16; iter: 200; batch classifier loss: 0.409145; batch adversarial loss: 0.583628\n",
      "epoch 16; iter: 400; batch classifier loss: 0.227792; batch adversarial loss: 0.657794\n",
      "epoch 17; iter: 0; batch classifier loss: 0.239694; batch adversarial loss: 0.660647\n",
      "epoch 17; iter: 200; batch classifier loss: 0.536712; batch adversarial loss: 0.544449\n",
      "epoch 17; iter: 400; batch classifier loss: 0.400450; batch adversarial loss: 0.624789\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322865; batch adversarial loss: 0.580479\n",
      "epoch 18; iter: 200; batch classifier loss: 0.303593; batch adversarial loss: 0.647621\n",
      "epoch 18; iter: 400; batch classifier loss: 0.379178; batch adversarial loss: 0.570530\n",
      "epoch 19; iter: 0; batch classifier loss: 0.394740; batch adversarial loss: 0.605994\n",
      "epoch 19; iter: 200; batch classifier loss: 0.375700; batch adversarial loss: 0.623740\n",
      "epoch 19; iter: 400; batch classifier loss: 0.320097; batch adversarial loss: 0.643974\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478633; batch adversarial loss: 0.593542\n",
      "epoch 20; iter: 200; batch classifier loss: 0.229571; batch adversarial loss: 0.637402\n",
      "epoch 20; iter: 400; batch classifier loss: 0.490344; batch adversarial loss: 0.647462\n",
      "epoch 21; iter: 0; batch classifier loss: 0.512778; batch adversarial loss: 0.631820\n",
      "epoch 21; iter: 200; batch classifier loss: 0.404816; batch adversarial loss: 0.626741\n",
      "epoch 21; iter: 400; batch classifier loss: 0.387557; batch adversarial loss: 0.543923\n",
      "epoch 22; iter: 0; batch classifier loss: 0.316472; batch adversarial loss: 0.624186\n",
      "epoch 22; iter: 200; batch classifier loss: 0.351059; batch adversarial loss: 0.571987\n",
      "epoch 22; iter: 400; batch classifier loss: 0.305635; batch adversarial loss: 0.649697\n",
      "epoch 23; iter: 0; batch classifier loss: 0.310254; batch adversarial loss: 0.636963\n",
      "epoch 23; iter: 200; batch classifier loss: 0.273810; batch adversarial loss: 0.602986\n",
      "epoch 23; iter: 400; batch classifier loss: 0.386147; batch adversarial loss: 0.619592\n",
      "epoch 24; iter: 0; batch classifier loss: 0.833221; batch adversarial loss: 0.655018\n",
      "epoch 24; iter: 200; batch classifier loss: 0.495552; batch adversarial loss: 0.680315\n",
      "epoch 24; iter: 400; batch classifier loss: 0.428897; batch adversarial loss: 0.663670\n",
      "epoch 25; iter: 0; batch classifier loss: 0.448414; batch adversarial loss: 0.588322\n",
      "epoch 25; iter: 200; batch classifier loss: 0.379391; batch adversarial loss: 0.609395\n",
      "epoch 25; iter: 400; batch classifier loss: 0.485631; batch adversarial loss: 0.608011\n",
      "epoch 26; iter: 0; batch classifier loss: 0.373013; batch adversarial loss: 0.690202\n",
      "epoch 26; iter: 200; batch classifier loss: 0.254010; batch adversarial loss: 0.681007\n",
      "epoch 26; iter: 400; batch classifier loss: 0.373448; batch adversarial loss: 0.659622\n",
      "epoch 27; iter: 0; batch classifier loss: 0.530691; batch adversarial loss: 0.568900\n",
      "epoch 27; iter: 200; batch classifier loss: 0.574902; batch adversarial loss: 0.537566\n",
      "epoch 27; iter: 400; batch classifier loss: 0.438278; batch adversarial loss: 0.530659\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472739; batch adversarial loss: 0.619982\n",
      "epoch 28; iter: 200; batch classifier loss: 0.590187; batch adversarial loss: 0.644191\n",
      "epoch 28; iter: 400; batch classifier loss: 0.381233; batch adversarial loss: 0.646906\n",
      "epoch 29; iter: 0; batch classifier loss: 0.483758; batch adversarial loss: 0.621514\n",
      "epoch 29; iter: 200; batch classifier loss: 0.426522; batch adversarial loss: 0.644257\n",
      "epoch 29; iter: 400; batch classifier loss: 0.419773; batch adversarial loss: 0.625895\n",
      "epoch 30; iter: 0; batch classifier loss: 0.383898; batch adversarial loss: 0.664527\n",
      "epoch 30; iter: 200; batch classifier loss: 0.504520; batch adversarial loss: 0.602436\n",
      "epoch 30; iter: 400; batch classifier loss: 0.514987; batch adversarial loss: 0.642699\n",
      "epoch 31; iter: 0; batch classifier loss: 0.303425; batch adversarial loss: 0.755149\n",
      "epoch 31; iter: 200; batch classifier loss: 0.542339; batch adversarial loss: 0.602419\n",
      "epoch 31; iter: 400; batch classifier loss: 0.440816; batch adversarial loss: 0.625520\n",
      "epoch 32; iter: 0; batch classifier loss: 0.561164; batch adversarial loss: 0.614258\n",
      "epoch 32; iter: 200; batch classifier loss: 0.530774; batch adversarial loss: 0.637431\n",
      "epoch 32; iter: 400; batch classifier loss: 0.763051; batch adversarial loss: 0.582012\n",
      "epoch 33; iter: 0; batch classifier loss: 0.236062; batch adversarial loss: 0.661447\n",
      "epoch 33; iter: 200; batch classifier loss: 0.514267; batch adversarial loss: 0.701557\n",
      "epoch 33; iter: 400; batch classifier loss: 0.259873; batch adversarial loss: 0.634926\n",
      "epoch 34; iter: 0; batch classifier loss: 0.440364; batch adversarial loss: 0.620826\n",
      "epoch 34; iter: 200; batch classifier loss: 0.658521; batch adversarial loss: 0.593803\n",
      "epoch 34; iter: 400; batch classifier loss: 0.584527; batch adversarial loss: 0.620413\n",
      "epoch 35; iter: 0; batch classifier loss: 0.519024; batch adversarial loss: 0.558595\n",
      "epoch 35; iter: 200; batch classifier loss: 0.558158; batch adversarial loss: 0.667669\n",
      "epoch 35; iter: 400; batch classifier loss: 0.339334; batch adversarial loss: 0.617735\n",
      "epoch 36; iter: 0; batch classifier loss: 0.268166; batch adversarial loss: 0.680014\n",
      "epoch 36; iter: 200; batch classifier loss: 0.446124; batch adversarial loss: 0.641481\n",
      "epoch 36; iter: 400; batch classifier loss: 0.374664; batch adversarial loss: 0.663745\n",
      "epoch 37; iter: 0; batch classifier loss: 0.297609; batch adversarial loss: 0.577963\n",
      "epoch 37; iter: 200; batch classifier loss: 0.733452; batch adversarial loss: 0.624017\n",
      "epoch 37; iter: 400; batch classifier loss: 0.393912; batch adversarial loss: 0.550703\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504210; batch adversarial loss: 0.640832\n",
      "epoch 38; iter: 200; batch classifier loss: 0.575393; batch adversarial loss: 0.603756\n",
      "epoch 38; iter: 400; batch classifier loss: 0.530546; batch adversarial loss: 0.540161\n",
      "epoch 39; iter: 0; batch classifier loss: 0.944296; batch adversarial loss: 0.596908\n",
      "epoch 39; iter: 200; batch classifier loss: 0.585563; batch adversarial loss: 0.669806\n",
      "epoch 39; iter: 400; batch classifier loss: 0.269271; batch adversarial loss: 0.693588\n",
      "epoch 40; iter: 0; batch classifier loss: 0.779941; batch adversarial loss: 0.652148\n",
      "epoch 40; iter: 200; batch classifier loss: 0.695744; batch adversarial loss: 0.612101\n",
      "epoch 40; iter: 400; batch classifier loss: 0.466653; batch adversarial loss: 0.699997\n",
      "epoch 41; iter: 0; batch classifier loss: 0.674082; batch adversarial loss: 0.565821\n",
      "epoch 41; iter: 200; batch classifier loss: 0.596763; batch adversarial loss: 0.609217\n",
      "epoch 41; iter: 400; batch classifier loss: 0.344561; batch adversarial loss: 0.628313\n",
      "epoch 42; iter: 0; batch classifier loss: 0.562010; batch adversarial loss: 0.626700\n",
      "epoch 42; iter: 200; batch classifier loss: 0.417647; batch adversarial loss: 0.653094\n",
      "epoch 42; iter: 400; batch classifier loss: 0.345885; batch adversarial loss: 0.688454\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433093; batch adversarial loss: 0.627492\n",
      "epoch 43; iter: 200; batch classifier loss: 0.660637; batch adversarial loss: 0.661206\n",
      "epoch 43; iter: 400; batch classifier loss: 0.484458; batch adversarial loss: 0.614246\n",
      "epoch 44; iter: 0; batch classifier loss: 0.482659; batch adversarial loss: 0.652495\n",
      "epoch 44; iter: 200; batch classifier loss: 0.430197; batch adversarial loss: 0.650063\n",
      "epoch 44; iter: 400; batch classifier loss: 0.255862; batch adversarial loss: 0.601846\n",
      "epoch 45; iter: 0; batch classifier loss: 0.578488; batch adversarial loss: 0.542042\n",
      "epoch 45; iter: 200; batch classifier loss: 0.371239; batch adversarial loss: 0.641446\n",
      "epoch 45; iter: 400; batch classifier loss: 0.216304; batch adversarial loss: 0.655202\n",
      "epoch 46; iter: 0; batch classifier loss: 0.349756; batch adversarial loss: 0.642680\n",
      "epoch 46; iter: 200; batch classifier loss: 0.344869; batch adversarial loss: 0.665141\n",
      "epoch 46; iter: 400; batch classifier loss: 0.413013; batch adversarial loss: 0.681229\n",
      "epoch 47; iter: 0; batch classifier loss: 0.292508; batch adversarial loss: 0.675604\n",
      "epoch 47; iter: 200; batch classifier loss: 0.203686; batch adversarial loss: 0.580436\n",
      "epoch 47; iter: 400; batch classifier loss: 0.463837; batch adversarial loss: 0.681433\n",
      "epoch 48; iter: 0; batch classifier loss: 0.321567; batch adversarial loss: 0.669327\n",
      "epoch 48; iter: 200; batch classifier loss: 0.184737; batch adversarial loss: 0.734343\n",
      "epoch 48; iter: 400; batch classifier loss: 0.715111; batch adversarial loss: 0.644191\n",
      "epoch 49; iter: 0; batch classifier loss: 0.769914; batch adversarial loss: 0.564688\n",
      "epoch 49; iter: 200; batch classifier loss: 0.583623; batch adversarial loss: 0.724769\n",
      "epoch 49; iter: 400; batch classifier loss: 0.527774; batch adversarial loss: 0.571644\n",
      "epoch 0; iter: 0; batch classifier loss: 19.775837; batch adversarial loss: 0.749431\n",
      "epoch 0; iter: 200; batch classifier loss: 16.331266; batch adversarial loss: 0.667563\n",
      "epoch 0; iter: 400; batch classifier loss: 5.384053; batch adversarial loss: 0.644848\n",
      "epoch 1; iter: 0; batch classifier loss: 4.856380; batch adversarial loss: 0.668307\n",
      "epoch 1; iter: 200; batch classifier loss: 5.103153; batch adversarial loss: 0.587682\n",
      "epoch 1; iter: 400; batch classifier loss: 0.585045; batch adversarial loss: 0.622555\n",
      "epoch 2; iter: 0; batch classifier loss: 0.317887; batch adversarial loss: 0.672303\n",
      "epoch 2; iter: 200; batch classifier loss: 0.972076; batch adversarial loss: 0.661443\n",
      "epoch 2; iter: 400; batch classifier loss: 1.745582; batch adversarial loss: 0.569396\n",
      "epoch 3; iter: 0; batch classifier loss: 3.199129; batch adversarial loss: 0.697849\n",
      "epoch 3; iter: 200; batch classifier loss: 1.309108; batch adversarial loss: 0.633280\n",
      "epoch 3; iter: 400; batch classifier loss: 0.643184; batch adversarial loss: 0.686602\n",
      "epoch 4; iter: 0; batch classifier loss: 1.097106; batch adversarial loss: 0.625685\n",
      "epoch 4; iter: 200; batch classifier loss: 0.474122; batch adversarial loss: 0.687739\n",
      "epoch 4; iter: 400; batch classifier loss: 0.448870; batch adversarial loss: 0.620622\n",
      "epoch 5; iter: 0; batch classifier loss: 0.408114; batch adversarial loss: 0.623817\n",
      "epoch 5; iter: 200; batch classifier loss: 0.379913; batch adversarial loss: 0.635298\n",
      "epoch 5; iter: 400; batch classifier loss: 0.434211; batch adversarial loss: 0.570132\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579109; batch adversarial loss: 0.622032\n",
      "epoch 6; iter: 200; batch classifier loss: 0.377653; batch adversarial loss: 0.612806\n",
      "epoch 6; iter: 400; batch classifier loss: 0.436405; batch adversarial loss: 0.626172\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376730; batch adversarial loss: 0.546219\n",
      "epoch 7; iter: 200; batch classifier loss: 0.495578; batch adversarial loss: 0.664630\n",
      "epoch 7; iter: 400; batch classifier loss: 0.327643; batch adversarial loss: 0.597498\n",
      "epoch 8; iter: 0; batch classifier loss: 0.259278; batch adversarial loss: 0.627755\n",
      "epoch 8; iter: 200; batch classifier loss: 0.665595; batch adversarial loss: 0.650023\n",
      "epoch 8; iter: 400; batch classifier loss: 0.433800; batch adversarial loss: 0.605642\n",
      "epoch 9; iter: 0; batch classifier loss: 0.373685; batch adversarial loss: 0.612493\n",
      "epoch 9; iter: 200; batch classifier loss: 0.414774; batch adversarial loss: 0.610097\n",
      "epoch 9; iter: 400; batch classifier loss: 0.319537; batch adversarial loss: 0.608559\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374844; batch adversarial loss: 0.579380\n",
      "epoch 10; iter: 200; batch classifier loss: 0.276298; batch adversarial loss: 0.630320\n",
      "epoch 10; iter: 400; batch classifier loss: 0.328367; batch adversarial loss: 0.609546\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368129; batch adversarial loss: 0.624662\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449640; batch adversarial loss: 0.586381\n",
      "epoch 11; iter: 400; batch classifier loss: 0.529541; batch adversarial loss: 0.585014\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398374; batch adversarial loss: 0.581095\n",
      "epoch 12; iter: 200; batch classifier loss: 0.329028; batch adversarial loss: 0.631071\n",
      "epoch 12; iter: 400; batch classifier loss: 0.381307; batch adversarial loss: 0.612955\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378443; batch adversarial loss: 0.622335\n",
      "epoch 13; iter: 200; batch classifier loss: 0.263524; batch adversarial loss: 0.563699\n",
      "epoch 13; iter: 400; batch classifier loss: 0.371473; batch adversarial loss: 0.662291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435896; batch adversarial loss: 0.677560\n",
      "epoch 14; iter: 200; batch classifier loss: 0.415309; batch adversarial loss: 0.640526\n",
      "epoch 14; iter: 400; batch classifier loss: 0.329341; batch adversarial loss: 0.647503\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495783; batch adversarial loss: 0.580450\n",
      "epoch 15; iter: 200; batch classifier loss: 0.324669; batch adversarial loss: 0.664042\n",
      "epoch 15; iter: 400; batch classifier loss: 0.437488; batch adversarial loss: 0.592302\n",
      "epoch 16; iter: 0; batch classifier loss: 0.392796; batch adversarial loss: 0.633254\n",
      "epoch 16; iter: 200; batch classifier loss: 0.438188; batch adversarial loss: 0.542372\n",
      "epoch 16; iter: 400; batch classifier loss: 0.413024; batch adversarial loss: 0.728381\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508647; batch adversarial loss: 0.635032\n",
      "epoch 17; iter: 200; batch classifier loss: 0.296334; batch adversarial loss: 0.607555\n",
      "epoch 17; iter: 400; batch classifier loss: 0.346695; batch adversarial loss: 0.626398\n",
      "epoch 18; iter: 0; batch classifier loss: 0.610470; batch adversarial loss: 0.675345\n",
      "epoch 18; iter: 200; batch classifier loss: 0.466193; batch adversarial loss: 0.596656\n",
      "epoch 18; iter: 400; batch classifier loss: 0.435687; batch adversarial loss: 0.593951\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334522; batch adversarial loss: 0.704939\n",
      "epoch 19; iter: 200; batch classifier loss: 0.378615; batch adversarial loss: 0.627544\n",
      "epoch 19; iter: 400; batch classifier loss: 0.501433; batch adversarial loss: 0.571828\n",
      "epoch 20; iter: 0; batch classifier loss: 0.302826; batch adversarial loss: 0.588079\n",
      "epoch 20; iter: 200; batch classifier loss: 0.520846; batch adversarial loss: 0.650001\n",
      "epoch 20; iter: 400; batch classifier loss: 0.501548; batch adversarial loss: 0.686298\n",
      "epoch 21; iter: 0; batch classifier loss: 0.348944; batch adversarial loss: 0.688088\n",
      "epoch 21; iter: 200; batch classifier loss: 0.471517; batch adversarial loss: 0.628073\n",
      "epoch 21; iter: 400; batch classifier loss: 0.338934; batch adversarial loss: 0.605323\n",
      "epoch 22; iter: 0; batch classifier loss: 0.392442; batch adversarial loss: 0.642358\n",
      "epoch 22; iter: 200; batch classifier loss: 0.576952; batch adversarial loss: 0.598545\n",
      "epoch 22; iter: 400; batch classifier loss: 0.651315; batch adversarial loss: 0.593332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.359762; batch adversarial loss: 0.656168\n",
      "epoch 23; iter: 200; batch classifier loss: 0.446989; batch adversarial loss: 0.592075\n",
      "epoch 23; iter: 400; batch classifier loss: 0.423884; batch adversarial loss: 0.608495\n",
      "epoch 24; iter: 0; batch classifier loss: 0.353881; batch adversarial loss: 0.656400\n",
      "epoch 24; iter: 200; batch classifier loss: 0.376208; batch adversarial loss: 0.605915\n",
      "epoch 24; iter: 400; batch classifier loss: 0.324777; batch adversarial loss: 0.615551\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517234; batch adversarial loss: 0.656788\n",
      "epoch 25; iter: 200; batch classifier loss: 0.387983; batch adversarial loss: 0.620133\n",
      "epoch 25; iter: 400; batch classifier loss: 0.626094; batch adversarial loss: 0.634300\n",
      "epoch 26; iter: 0; batch classifier loss: 0.698493; batch adversarial loss: 0.575612\n",
      "epoch 26; iter: 200; batch classifier loss: 0.382430; batch adversarial loss: 0.662806\n",
      "epoch 26; iter: 400; batch classifier loss: 0.488871; batch adversarial loss: 0.643089\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362494; batch adversarial loss: 0.605899\n",
      "epoch 27; iter: 200; batch classifier loss: 0.426110; batch adversarial loss: 0.583354\n",
      "epoch 27; iter: 400; batch classifier loss: 0.313145; batch adversarial loss: 0.607111\n",
      "epoch 28; iter: 0; batch classifier loss: 0.228100; batch adversarial loss: 0.614290\n",
      "epoch 28; iter: 200; batch classifier loss: 0.327253; batch adversarial loss: 0.695815\n",
      "epoch 28; iter: 400; batch classifier loss: 0.205923; batch adversarial loss: 0.582270\n",
      "epoch 29; iter: 0; batch classifier loss: 0.340183; batch adversarial loss: 0.608913\n",
      "epoch 29; iter: 200; batch classifier loss: 0.306675; batch adversarial loss: 0.634987\n",
      "epoch 29; iter: 400; batch classifier loss: 0.486951; batch adversarial loss: 0.596295\n",
      "epoch 30; iter: 0; batch classifier loss: 0.236340; batch adversarial loss: 0.606881\n",
      "epoch 30; iter: 200; batch classifier loss: 0.387475; batch adversarial loss: 0.668981\n",
      "epoch 30; iter: 400; batch classifier loss: 0.301098; batch adversarial loss: 0.661097\n",
      "epoch 31; iter: 0; batch classifier loss: 0.391942; batch adversarial loss: 0.654335\n",
      "epoch 31; iter: 200; batch classifier loss: 0.552749; batch adversarial loss: 0.567245\n",
      "epoch 31; iter: 400; batch classifier loss: 0.442947; batch adversarial loss: 0.577070\n",
      "epoch 32; iter: 0; batch classifier loss: 0.524536; batch adversarial loss: 0.681702\n",
      "epoch 32; iter: 200; batch classifier loss: 0.358607; batch adversarial loss: 0.752891\n",
      "epoch 32; iter: 400; batch classifier loss: 0.461947; batch adversarial loss: 0.627572\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437480; batch adversarial loss: 0.631828\n",
      "epoch 33; iter: 200; batch classifier loss: 0.334181; batch adversarial loss: 0.733333\n",
      "epoch 33; iter: 400; batch classifier loss: 0.328423; batch adversarial loss: 0.577332\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279898; batch adversarial loss: 0.576053\n",
      "epoch 34; iter: 200; batch classifier loss: 0.393241; batch adversarial loss: 0.622662\n",
      "epoch 34; iter: 400; batch classifier loss: 0.571937; batch adversarial loss: 0.661661\n",
      "epoch 35; iter: 0; batch classifier loss: 0.384884; batch adversarial loss: 0.620026\n",
      "epoch 35; iter: 200; batch classifier loss: 0.478449; batch adversarial loss: 0.732098\n",
      "epoch 35; iter: 400; batch classifier loss: 0.411898; batch adversarial loss: 0.688072\n",
      "epoch 36; iter: 0; batch classifier loss: 0.322651; batch adversarial loss: 0.618520\n",
      "epoch 36; iter: 200; batch classifier loss: 0.464989; batch adversarial loss: 0.605070\n",
      "epoch 36; iter: 400; batch classifier loss: 0.416742; batch adversarial loss: 0.645154\n",
      "epoch 37; iter: 0; batch classifier loss: 0.792214; batch adversarial loss: 0.553307\n",
      "epoch 37; iter: 200; batch classifier loss: 0.447164; batch adversarial loss: 0.575056\n",
      "epoch 37; iter: 400; batch classifier loss: 0.544892; batch adversarial loss: 0.538520\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486357; batch adversarial loss: 0.650041\n",
      "epoch 38; iter: 200; batch classifier loss: 0.562043; batch adversarial loss: 0.654211\n",
      "epoch 38; iter: 400; batch classifier loss: 0.489081; batch adversarial loss: 0.550644\n",
      "epoch 39; iter: 0; batch classifier loss: 0.479988; batch adversarial loss: 0.648885\n",
      "epoch 39; iter: 200; batch classifier loss: 0.273505; batch adversarial loss: 0.672543\n",
      "epoch 39; iter: 400; batch classifier loss: 0.263243; batch adversarial loss: 0.672808\n",
      "epoch 40; iter: 0; batch classifier loss: 0.306099; batch adversarial loss: 0.554108\n",
      "epoch 40; iter: 200; batch classifier loss: 0.484461; batch adversarial loss: 0.563049\n",
      "epoch 40; iter: 400; batch classifier loss: 0.282551; batch adversarial loss: 0.613516\n",
      "epoch 41; iter: 0; batch classifier loss: 0.296519; batch adversarial loss: 0.692803\n",
      "epoch 41; iter: 200; batch classifier loss: 0.484309; batch adversarial loss: 0.643421\n",
      "epoch 41; iter: 400; batch classifier loss: 0.748548; batch adversarial loss: 0.668529\n",
      "epoch 42; iter: 0; batch classifier loss: 0.564683; batch adversarial loss: 0.671569\n",
      "epoch 42; iter: 200; batch classifier loss: 0.362885; batch adversarial loss: 0.685805\n",
      "epoch 42; iter: 400; batch classifier loss: 0.366118; batch adversarial loss: 0.606230\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382225; batch adversarial loss: 0.639325\n",
      "epoch 43; iter: 200; batch classifier loss: 0.441606; batch adversarial loss: 0.557211\n",
      "epoch 43; iter: 400; batch classifier loss: 0.285831; batch adversarial loss: 0.560666\n",
      "epoch 44; iter: 0; batch classifier loss: 0.512529; batch adversarial loss: 0.504656\n",
      "epoch 44; iter: 200; batch classifier loss: 0.160643; batch adversarial loss: 0.582258\n",
      "epoch 44; iter: 400; batch classifier loss: 0.364517; batch adversarial loss: 0.679520\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434493; batch adversarial loss: 0.546842\n",
      "epoch 45; iter: 200; batch classifier loss: 0.397252; batch adversarial loss: 0.703014\n",
      "epoch 45; iter: 400; batch classifier loss: 0.690770; batch adversarial loss: 0.599661\n",
      "epoch 46; iter: 0; batch classifier loss: 0.359256; batch adversarial loss: 0.614171\n",
      "epoch 46; iter: 200; batch classifier loss: 0.307318; batch adversarial loss: 0.619768\n",
      "epoch 46; iter: 400; batch classifier loss: 0.581334; batch adversarial loss: 0.633649\n",
      "epoch 47; iter: 0; batch classifier loss: 1.174189; batch adversarial loss: 0.686425\n",
      "epoch 47; iter: 200; batch classifier loss: 0.390438; batch adversarial loss: 0.690176\n",
      "epoch 47; iter: 400; batch classifier loss: 0.376765; batch adversarial loss: 0.620973\n",
      "epoch 48; iter: 0; batch classifier loss: 0.299980; batch adversarial loss: 0.552476\n",
      "epoch 48; iter: 200; batch classifier loss: 0.964470; batch adversarial loss: 0.616741\n",
      "epoch 48; iter: 400; batch classifier loss: 0.392102; batch adversarial loss: 0.605500\n",
      "epoch 49; iter: 0; batch classifier loss: 0.613248; batch adversarial loss: 0.629986\n",
      "epoch 49; iter: 200; batch classifier loss: 0.379332; batch adversarial loss: 0.625618\n",
      "epoch 49; iter: 400; batch classifier loss: 0.412217; batch adversarial loss: 0.669250\n",
      "epoch 0; iter: 0; batch classifier loss: 8.543464; batch adversarial loss: 0.752964\n",
      "epoch 0; iter: 200; batch classifier loss: 6.161132; batch adversarial loss: 0.878262\n",
      "epoch 0; iter: 400; batch classifier loss: 6.111184; batch adversarial loss: 0.785802\n",
      "epoch 1; iter: 0; batch classifier loss: 11.705853; batch adversarial loss: 0.662621\n",
      "epoch 1; iter: 200; batch classifier loss: 1.961860; batch adversarial loss: 0.650637\n",
      "epoch 1; iter: 400; batch classifier loss: 4.651584; batch adversarial loss: 0.648616\n",
      "epoch 2; iter: 0; batch classifier loss: 19.172258; batch adversarial loss: 0.589704\n",
      "epoch 2; iter: 200; batch classifier loss: 3.016717; batch adversarial loss: 0.700846\n",
      "epoch 2; iter: 400; batch classifier loss: 4.053030; batch adversarial loss: 0.680466\n",
      "epoch 3; iter: 0; batch classifier loss: 0.833623; batch adversarial loss: 0.655574\n",
      "epoch 3; iter: 200; batch classifier loss: 3.535855; batch adversarial loss: 0.594153\n",
      "epoch 3; iter: 400; batch classifier loss: 0.400507; batch adversarial loss: 0.560937\n",
      "epoch 4; iter: 0; batch classifier loss: 0.930935; batch adversarial loss: 0.593619\n",
      "epoch 4; iter: 200; batch classifier loss: 0.746310; batch adversarial loss: 0.634332\n",
      "epoch 4; iter: 400; batch classifier loss: 0.787539; batch adversarial loss: 0.599923\n",
      "epoch 5; iter: 0; batch classifier loss: 1.126155; batch adversarial loss: 0.614694\n",
      "epoch 5; iter: 200; batch classifier loss: 0.334602; batch adversarial loss: 0.599392\n",
      "epoch 5; iter: 400; batch classifier loss: 0.978697; batch adversarial loss: 0.693408\n",
      "epoch 6; iter: 0; batch classifier loss: 0.845130; batch adversarial loss: 0.645744\n",
      "epoch 6; iter: 200; batch classifier loss: 0.669843; batch adversarial loss: 0.553193\n",
      "epoch 6; iter: 400; batch classifier loss: 0.835473; batch adversarial loss: 0.606339\n",
      "epoch 7; iter: 0; batch classifier loss: 0.356271; batch adversarial loss: 0.699501\n",
      "epoch 7; iter: 200; batch classifier loss: 0.293704; batch adversarial loss: 0.633608\n",
      "epoch 7; iter: 400; batch classifier loss: 0.370106; batch adversarial loss: 0.605117\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486653; batch adversarial loss: 0.663607\n",
      "epoch 8; iter: 200; batch classifier loss: 0.456370; batch adversarial loss: 0.608204\n",
      "epoch 8; iter: 400; batch classifier loss: 0.319726; batch adversarial loss: 0.664716\n",
      "epoch 9; iter: 0; batch classifier loss: 0.378693; batch adversarial loss: 0.614145\n",
      "epoch 9; iter: 200; batch classifier loss: 0.716049; batch adversarial loss: 0.550848\n",
      "epoch 9; iter: 400; batch classifier loss: 0.417897; batch adversarial loss: 0.651985\n",
      "epoch 10; iter: 0; batch classifier loss: 0.497324; batch adversarial loss: 0.624496\n",
      "epoch 10; iter: 200; batch classifier loss: 0.430395; batch adversarial loss: 0.654079\n",
      "epoch 10; iter: 400; batch classifier loss: 0.446541; batch adversarial loss: 0.646127\n",
      "epoch 11; iter: 0; batch classifier loss: 0.438468; batch adversarial loss: 0.632238\n",
      "epoch 11; iter: 200; batch classifier loss: 0.298890; batch adversarial loss: 0.626294\n",
      "epoch 11; iter: 400; batch classifier loss: 0.335592; batch adversarial loss: 0.740477\n",
      "epoch 12; iter: 0; batch classifier loss: 0.306660; batch adversarial loss: 0.616465\n",
      "epoch 12; iter: 200; batch classifier loss: 0.359027; batch adversarial loss: 0.549311\n",
      "epoch 12; iter: 400; batch classifier loss: 0.418861; batch adversarial loss: 0.559952\n",
      "epoch 13; iter: 0; batch classifier loss: 0.240721; batch adversarial loss: 0.656154\n",
      "epoch 13; iter: 200; batch classifier loss: 0.250047; batch adversarial loss: 0.690855\n",
      "epoch 13; iter: 400; batch classifier loss: 0.438030; batch adversarial loss: 0.613200\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283878; batch adversarial loss: 0.531815\n",
      "epoch 14; iter: 200; batch classifier loss: 0.469991; batch adversarial loss: 0.624863\n",
      "epoch 14; iter: 400; batch classifier loss: 0.243388; batch adversarial loss: 0.669777\n",
      "epoch 15; iter: 0; batch classifier loss: 0.412268; batch adversarial loss: 0.596766\n",
      "epoch 15; iter: 200; batch classifier loss: 0.446242; batch adversarial loss: 0.679659\n",
      "epoch 15; iter: 400; batch classifier loss: 0.265067; batch adversarial loss: 0.645231\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376320; batch adversarial loss: 0.619227\n",
      "epoch 16; iter: 200; batch classifier loss: 0.400235; batch adversarial loss: 0.645462\n",
      "epoch 16; iter: 400; batch classifier loss: 0.333981; batch adversarial loss: 0.632656\n",
      "epoch 17; iter: 0; batch classifier loss: 0.396404; batch adversarial loss: 0.619256\n",
      "epoch 17; iter: 200; batch classifier loss: 0.413348; batch adversarial loss: 0.593555\n",
      "epoch 17; iter: 400; batch classifier loss: 0.240859; batch adversarial loss: 0.675758\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264376; batch adversarial loss: 0.733030\n",
      "epoch 18; iter: 200; batch classifier loss: 0.335685; batch adversarial loss: 0.593553\n",
      "epoch 18; iter: 400; batch classifier loss: 0.533385; batch adversarial loss: 0.650366\n",
      "epoch 19; iter: 0; batch classifier loss: 0.572132; batch adversarial loss: 0.679022\n",
      "epoch 19; iter: 200; batch classifier loss: 0.482922; batch adversarial loss: 0.658544\n",
      "epoch 19; iter: 400; batch classifier loss: 0.512702; batch adversarial loss: 0.643384\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385682; batch adversarial loss: 0.570695\n",
      "epoch 20; iter: 200; batch classifier loss: 0.299919; batch adversarial loss: 0.605156\n",
      "epoch 20; iter: 400; batch classifier loss: 0.412912; batch adversarial loss: 0.661750\n",
      "epoch 21; iter: 0; batch classifier loss: 0.509429; batch adversarial loss: 0.503107\n",
      "epoch 21; iter: 200; batch classifier loss: 0.351554; batch adversarial loss: 0.623674\n",
      "epoch 21; iter: 400; batch classifier loss: 0.389983; batch adversarial loss: 0.588439\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427150; batch adversarial loss: 0.563152\n",
      "epoch 22; iter: 200; batch classifier loss: 0.246188; batch adversarial loss: 0.563075\n",
      "epoch 22; iter: 400; batch classifier loss: 0.404606; batch adversarial loss: 0.649250\n",
      "epoch 23; iter: 0; batch classifier loss: 0.301296; batch adversarial loss: 0.541970\n",
      "epoch 23; iter: 200; batch classifier loss: 0.432992; batch adversarial loss: 0.684756\n",
      "epoch 23; iter: 400; batch classifier loss: 0.339807; batch adversarial loss: 0.574180\n",
      "epoch 24; iter: 0; batch classifier loss: 0.633069; batch adversarial loss: 0.602059\n",
      "epoch 24; iter: 200; batch classifier loss: 0.396512; batch adversarial loss: 0.665178\n",
      "epoch 24; iter: 400; batch classifier loss: 0.468372; batch adversarial loss: 0.660796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417709; batch adversarial loss: 0.608989\n",
      "epoch 25; iter: 200; batch classifier loss: 0.395950; batch adversarial loss: 0.584803\n",
      "epoch 25; iter: 400; batch classifier loss: 0.428544; batch adversarial loss: 0.643078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511168; batch adversarial loss: 0.602482\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336496; batch adversarial loss: 0.654827\n",
      "epoch 26; iter: 400; batch classifier loss: 0.568014; batch adversarial loss: 0.685818\n",
      "epoch 27; iter: 0; batch classifier loss: 0.930395; batch adversarial loss: 0.581173\n",
      "epoch 27; iter: 200; batch classifier loss: 0.466091; batch adversarial loss: 0.632005\n",
      "epoch 27; iter: 400; batch classifier loss: 0.629818; batch adversarial loss: 0.647277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.434573; batch adversarial loss: 0.669158\n",
      "epoch 28; iter: 200; batch classifier loss: 0.469582; batch adversarial loss: 0.593859\n",
      "epoch 28; iter: 400; batch classifier loss: 0.450075; batch adversarial loss: 0.596856\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534572; batch adversarial loss: 0.604967\n",
      "epoch 29; iter: 200; batch classifier loss: 0.577428; batch adversarial loss: 0.608181\n",
      "epoch 29; iter: 400; batch classifier loss: 0.534825; batch adversarial loss: 0.583860\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264448; batch adversarial loss: 0.596048\n",
      "epoch 30; iter: 200; batch classifier loss: 0.435938; batch adversarial loss: 0.597750\n",
      "epoch 30; iter: 400; batch classifier loss: 0.576514; batch adversarial loss: 0.555693\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421956; batch adversarial loss: 0.672656\n",
      "epoch 31; iter: 200; batch classifier loss: 0.485940; batch adversarial loss: 0.604287\n",
      "epoch 31; iter: 400; batch classifier loss: 0.516801; batch adversarial loss: 0.555735\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516950; batch adversarial loss: 0.677168\n",
      "epoch 32; iter: 200; batch classifier loss: 0.722422; batch adversarial loss: 0.575608\n",
      "epoch 32; iter: 400; batch classifier loss: 0.543038; batch adversarial loss: 0.605024\n",
      "epoch 33; iter: 0; batch classifier loss: 0.514634; batch adversarial loss: 0.626571\n",
      "epoch 33; iter: 200; batch classifier loss: 0.431562; batch adversarial loss: 0.584871\n",
      "epoch 33; iter: 400; batch classifier loss: 0.495182; batch adversarial loss: 0.594901\n",
      "epoch 34; iter: 0; batch classifier loss: 0.613409; batch adversarial loss: 0.594131\n",
      "epoch 34; iter: 200; batch classifier loss: 0.413098; batch adversarial loss: 0.615855\n",
      "epoch 34; iter: 400; batch classifier loss: 0.546676; batch adversarial loss: 0.623613\n",
      "epoch 35; iter: 0; batch classifier loss: 0.316645; batch adversarial loss: 0.596221\n",
      "epoch 35; iter: 200; batch classifier loss: 0.797324; batch adversarial loss: 0.670184\n",
      "epoch 35; iter: 400; batch classifier loss: 0.286969; batch adversarial loss: 0.555788\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480284; batch adversarial loss: 0.696230\n",
      "epoch 36; iter: 200; batch classifier loss: 0.500783; batch adversarial loss: 0.690609\n",
      "epoch 36; iter: 400; batch classifier loss: 0.328663; batch adversarial loss: 0.610837\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459623; batch adversarial loss: 0.655689\n",
      "epoch 37; iter: 200; batch classifier loss: 0.384329; batch adversarial loss: 0.621709\n",
      "epoch 37; iter: 400; batch classifier loss: 0.306875; batch adversarial loss: 0.611045\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453108; batch adversarial loss: 0.689565\n",
      "epoch 38; iter: 200; batch classifier loss: 0.257967; batch adversarial loss: 0.568273\n",
      "epoch 38; iter: 400; batch classifier loss: 0.409295; batch adversarial loss: 0.594968\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396525; batch adversarial loss: 0.651691\n",
      "epoch 39; iter: 200; batch classifier loss: 0.633005; batch adversarial loss: 0.579630\n",
      "epoch 39; iter: 400; batch classifier loss: 0.445551; batch adversarial loss: 0.622947\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390820; batch adversarial loss: 0.640026\n",
      "epoch 40; iter: 200; batch classifier loss: 0.522898; batch adversarial loss: 0.704855\n",
      "epoch 40; iter: 400; batch classifier loss: 0.542423; batch adversarial loss: 0.695039\n",
      "epoch 41; iter: 0; batch classifier loss: 0.580109; batch adversarial loss: 0.579527\n",
      "epoch 41; iter: 200; batch classifier loss: 0.651740; batch adversarial loss: 0.628396\n",
      "epoch 41; iter: 400; batch classifier loss: 0.553359; batch adversarial loss: 0.608871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299763; batch adversarial loss: 0.649988\n",
      "epoch 42; iter: 200; batch classifier loss: 0.510656; batch adversarial loss: 0.635289\n",
      "epoch 42; iter: 400; batch classifier loss: 0.392884; batch adversarial loss: 0.662898\n",
      "epoch 43; iter: 0; batch classifier loss: 0.695704; batch adversarial loss: 0.696604\n",
      "epoch 43; iter: 200; batch classifier loss: 0.522256; batch adversarial loss: 0.650410\n",
      "epoch 43; iter: 400; batch classifier loss: 0.392969; batch adversarial loss: 0.645068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.368403; batch adversarial loss: 0.633936\n",
      "epoch 44; iter: 200; batch classifier loss: 0.498363; batch adversarial loss: 0.687593\n",
      "epoch 44; iter: 400; batch classifier loss: 0.278017; batch adversarial loss: 0.655501\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384433; batch adversarial loss: 0.705091\n",
      "epoch 45; iter: 200; batch classifier loss: 0.625207; batch adversarial loss: 0.585598\n",
      "epoch 45; iter: 400; batch classifier loss: 0.313368; batch adversarial loss: 0.622659\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396015; batch adversarial loss: 0.621329\n",
      "epoch 46; iter: 200; batch classifier loss: 0.423364; batch adversarial loss: 0.564464\n",
      "epoch 46; iter: 400; batch classifier loss: 0.472882; batch adversarial loss: 0.642580\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350456; batch adversarial loss: 0.654055\n",
      "epoch 47; iter: 200; batch classifier loss: 0.320239; batch adversarial loss: 0.627550\n",
      "epoch 47; iter: 400; batch classifier loss: 0.501110; batch adversarial loss: 0.603570\n",
      "epoch 48; iter: 0; batch classifier loss: 0.257820; batch adversarial loss: 0.629003\n",
      "epoch 48; iter: 200; batch classifier loss: 0.333940; batch adversarial loss: 0.632069\n",
      "epoch 48; iter: 400; batch classifier loss: 0.529654; batch adversarial loss: 0.595617\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452715; batch adversarial loss: 0.570767\n",
      "epoch 49; iter: 200; batch classifier loss: 0.452753; batch adversarial loss: 0.594120\n",
      "epoch 49; iter: 400; batch classifier loss: 0.472532; batch adversarial loss: 0.631836\n",
      "epoch 0; iter: 0; batch classifier loss: 20.874542; batch adversarial loss: 0.667932\n",
      "epoch 0; iter: 200; batch classifier loss: 1.492573; batch adversarial loss: 0.612961\n",
      "epoch 0; iter: 400; batch classifier loss: 11.181618; batch adversarial loss: 0.614984\n",
      "epoch 1; iter: 0; batch classifier loss: 3.578072; batch adversarial loss: 0.598979\n",
      "epoch 1; iter: 200; batch classifier loss: 5.433111; batch adversarial loss: 0.565871\n",
      "epoch 1; iter: 400; batch classifier loss: 7.867409; batch adversarial loss: 0.523822\n",
      "epoch 2; iter: 0; batch classifier loss: 1.140950; batch adversarial loss: 0.581648\n",
      "epoch 2; iter: 200; batch classifier loss: 0.312133; batch adversarial loss: 0.616620\n",
      "epoch 2; iter: 400; batch classifier loss: 1.052384; batch adversarial loss: 0.584748\n",
      "epoch 3; iter: 0; batch classifier loss: 3.288240; batch adversarial loss: 0.584646\n",
      "epoch 3; iter: 200; batch classifier loss: 1.798247; batch adversarial loss: 0.653558\n",
      "epoch 3; iter: 400; batch classifier loss: 0.378723; batch adversarial loss: 0.651828\n",
      "epoch 4; iter: 0; batch classifier loss: 0.386437; batch adversarial loss: 0.622094\n",
      "epoch 4; iter: 200; batch classifier loss: 0.626297; batch adversarial loss: 0.648039\n",
      "epoch 4; iter: 400; batch classifier loss: 0.560773; batch adversarial loss: 0.590543\n",
      "epoch 5; iter: 0; batch classifier loss: 0.891493; batch adversarial loss: 0.663778\n",
      "epoch 5; iter: 200; batch classifier loss: 0.406382; batch adversarial loss: 0.770000\n",
      "epoch 5; iter: 400; batch classifier loss: 0.332113; batch adversarial loss: 0.586103\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522336; batch adversarial loss: 0.639548\n",
      "epoch 6; iter: 200; batch classifier loss: 0.392544; batch adversarial loss: 0.585766\n",
      "epoch 6; iter: 400; batch classifier loss: 0.798514; batch adversarial loss: 0.610952\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563752; batch adversarial loss: 0.564551\n",
      "epoch 7; iter: 200; batch classifier loss: 0.224130; batch adversarial loss: 0.642460\n",
      "epoch 7; iter: 400; batch classifier loss: 0.717283; batch adversarial loss: 0.657328\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451844; batch adversarial loss: 0.649593\n",
      "epoch 8; iter: 200; batch classifier loss: 0.297065; batch adversarial loss: 0.591394\n",
      "epoch 8; iter: 400; batch classifier loss: 0.337362; batch adversarial loss: 0.603423\n",
      "epoch 9; iter: 0; batch classifier loss: 0.251107; batch adversarial loss: 0.670196\n",
      "epoch 9; iter: 200; batch classifier loss: 0.343121; batch adversarial loss: 0.647879\n",
      "epoch 9; iter: 400; batch classifier loss: 0.410566; batch adversarial loss: 0.612515\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375183; batch adversarial loss: 0.624945\n",
      "epoch 10; iter: 200; batch classifier loss: 0.365373; batch adversarial loss: 0.639467\n",
      "epoch 10; iter: 400; batch classifier loss: 0.338349; batch adversarial loss: 0.611344\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371461; batch adversarial loss: 0.608642\n",
      "epoch 11; iter: 200; batch classifier loss: 0.396937; batch adversarial loss: 0.588604\n",
      "epoch 11; iter: 400; batch classifier loss: 0.417143; batch adversarial loss: 0.658206\n",
      "epoch 12; iter: 0; batch classifier loss: 0.323898; batch adversarial loss: 0.620541\n",
      "epoch 12; iter: 200; batch classifier loss: 0.422115; batch adversarial loss: 0.578348\n",
      "epoch 12; iter: 400; batch classifier loss: 0.313113; batch adversarial loss: 0.660458\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384189; batch adversarial loss: 0.670088\n",
      "epoch 13; iter: 200; batch classifier loss: 0.432412; batch adversarial loss: 0.635223\n",
      "epoch 13; iter: 400; batch classifier loss: 0.441182; batch adversarial loss: 0.582790\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368818; batch adversarial loss: 0.600659\n",
      "epoch 14; iter: 200; batch classifier loss: 0.237752; batch adversarial loss: 0.597373\n",
      "epoch 14; iter: 400; batch classifier loss: 0.328063; batch adversarial loss: 0.603274\n",
      "epoch 15; iter: 0; batch classifier loss: 0.412441; batch adversarial loss: 0.614915\n",
      "epoch 15; iter: 200; batch classifier loss: 0.460464; batch adversarial loss: 0.616161\n",
      "epoch 15; iter: 400; batch classifier loss: 0.322917; batch adversarial loss: 0.653576\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370341; batch adversarial loss: 0.616626\n",
      "epoch 16; iter: 200; batch classifier loss: 0.324498; batch adversarial loss: 0.583077\n",
      "epoch 16; iter: 400; batch classifier loss: 0.432256; batch adversarial loss: 0.514498\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371263; batch adversarial loss: 0.576691\n",
      "epoch 17; iter: 200; batch classifier loss: 0.365329; batch adversarial loss: 0.684691\n",
      "epoch 17; iter: 400; batch classifier loss: 0.617858; batch adversarial loss: 0.571952\n",
      "epoch 18; iter: 0; batch classifier loss: 0.369179; batch adversarial loss: 0.608931\n",
      "epoch 18; iter: 200; batch classifier loss: 0.301432; batch adversarial loss: 0.598037\n",
      "epoch 18; iter: 400; batch classifier loss: 0.356074; batch adversarial loss: 0.546001\n",
      "epoch 19; iter: 0; batch classifier loss: 0.175050; batch adversarial loss: 0.631975\n",
      "epoch 19; iter: 200; batch classifier loss: 0.251639; batch adversarial loss: 0.606245\n",
      "epoch 19; iter: 400; batch classifier loss: 0.386845; batch adversarial loss: 0.607949\n",
      "epoch 20; iter: 0; batch classifier loss: 0.393190; batch adversarial loss: 0.604351\n",
      "epoch 20; iter: 200; batch classifier loss: 0.246544; batch adversarial loss: 0.611452\n",
      "epoch 20; iter: 400; batch classifier loss: 0.393215; batch adversarial loss: 0.582038\n",
      "epoch 21; iter: 0; batch classifier loss: 0.376147; batch adversarial loss: 0.556300\n",
      "epoch 21; iter: 200; batch classifier loss: 0.487323; batch adversarial loss: 0.623810\n",
      "epoch 21; iter: 400; batch classifier loss: 0.375731; batch adversarial loss: 0.625003\n",
      "epoch 22; iter: 0; batch classifier loss: 0.238279; batch adversarial loss: 0.632309\n",
      "epoch 22; iter: 200; batch classifier loss: 0.577479; batch adversarial loss: 0.561674\n",
      "epoch 22; iter: 400; batch classifier loss: 0.481539; batch adversarial loss: 0.625075\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380906; batch adversarial loss: 0.652541\n",
      "epoch 23; iter: 200; batch classifier loss: 0.373990; batch adversarial loss: 0.660585\n",
      "epoch 23; iter: 400; batch classifier loss: 0.473960; batch adversarial loss: 0.738621\n",
      "epoch 24; iter: 0; batch classifier loss: 0.337873; batch adversarial loss: 0.594746\n",
      "epoch 24; iter: 200; batch classifier loss: 0.385445; batch adversarial loss: 0.653168\n",
      "epoch 24; iter: 400; batch classifier loss: 0.230032; batch adversarial loss: 0.609343\n",
      "epoch 25; iter: 0; batch classifier loss: 0.299895; batch adversarial loss: 0.604757\n",
      "epoch 25; iter: 200; batch classifier loss: 0.583028; batch adversarial loss: 0.642282\n",
      "epoch 25; iter: 400; batch classifier loss: 0.260581; batch adversarial loss: 0.661917\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387699; batch adversarial loss: 0.609149\n",
      "epoch 26; iter: 200; batch classifier loss: 0.496746; batch adversarial loss: 0.572507\n",
      "epoch 26; iter: 400; batch classifier loss: 0.539376; batch adversarial loss: 0.575655\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411412; batch adversarial loss: 0.713594\n",
      "epoch 27; iter: 200; batch classifier loss: 0.457002; batch adversarial loss: 0.631254\n",
      "epoch 27; iter: 400; batch classifier loss: 0.531081; batch adversarial loss: 0.587240\n",
      "epoch 28; iter: 0; batch classifier loss: 0.381077; batch adversarial loss: 0.643534\n",
      "epoch 28; iter: 200; batch classifier loss: 0.536185; batch adversarial loss: 0.634054\n",
      "epoch 28; iter: 400; batch classifier loss: 0.437048; batch adversarial loss: 0.600845\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447818; batch adversarial loss: 0.584684\n",
      "epoch 29; iter: 200; batch classifier loss: 0.485059; batch adversarial loss: 0.675552\n",
      "epoch 29; iter: 400; batch classifier loss: 0.347485; batch adversarial loss: 0.555658\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365307; batch adversarial loss: 0.530071\n",
      "epoch 30; iter: 200; batch classifier loss: 0.391361; batch adversarial loss: 0.582418\n",
      "epoch 30; iter: 400; batch classifier loss: 0.397544; batch adversarial loss: 0.626270\n",
      "epoch 31; iter: 0; batch classifier loss: 0.345466; batch adversarial loss: 0.592965\n",
      "epoch 31; iter: 200; batch classifier loss: 0.481553; batch adversarial loss: 0.543122\n",
      "epoch 31; iter: 400; batch classifier loss: 0.482614; batch adversarial loss: 0.668766\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381564; batch adversarial loss: 0.575094\n",
      "epoch 32; iter: 200; batch classifier loss: 0.396358; batch adversarial loss: 0.595071\n",
      "epoch 32; iter: 400; batch classifier loss: 0.556040; batch adversarial loss: 0.566731\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489835; batch adversarial loss: 0.602647\n",
      "epoch 33; iter: 200; batch classifier loss: 0.385948; batch adversarial loss: 0.627842\n",
      "epoch 33; iter: 400; batch classifier loss: 0.591097; batch adversarial loss: 0.637511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.347609; batch adversarial loss: 0.597482\n",
      "epoch 34; iter: 200; batch classifier loss: 0.411789; batch adversarial loss: 0.670703\n",
      "epoch 34; iter: 400; batch classifier loss: 0.278342; batch adversarial loss: 0.668805\n",
      "epoch 35; iter: 0; batch classifier loss: 0.311490; batch adversarial loss: 0.697257\n",
      "epoch 35; iter: 200; batch classifier loss: 0.626686; batch adversarial loss: 0.594986\n",
      "epoch 35; iter: 400; batch classifier loss: 0.248711; batch adversarial loss: 0.665846\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485108; batch adversarial loss: 0.647987\n",
      "epoch 36; iter: 200; batch classifier loss: 0.766741; batch adversarial loss: 0.583898\n",
      "epoch 36; iter: 400; batch classifier loss: 0.329523; batch adversarial loss: 0.718765\n",
      "epoch 37; iter: 0; batch classifier loss: 0.308489; batch adversarial loss: 0.690444\n",
      "epoch 37; iter: 200; batch classifier loss: 0.635408; batch adversarial loss: 0.605209\n",
      "epoch 37; iter: 400; batch classifier loss: 0.480557; batch adversarial loss: 0.614998\n",
      "epoch 38; iter: 0; batch classifier loss: 0.264234; batch adversarial loss: 0.618238\n",
      "epoch 38; iter: 200; batch classifier loss: 0.291257; batch adversarial loss: 0.660421\n",
      "epoch 38; iter: 400; batch classifier loss: 0.619371; batch adversarial loss: 0.645019\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448569; batch adversarial loss: 0.690239\n",
      "epoch 39; iter: 200; batch classifier loss: 0.364733; batch adversarial loss: 0.695125\n",
      "epoch 39; iter: 400; batch classifier loss: 0.559354; batch adversarial loss: 0.536415\n",
      "epoch 40; iter: 0; batch classifier loss: 0.339967; batch adversarial loss: 0.718226\n",
      "epoch 40; iter: 200; batch classifier loss: 0.677367; batch adversarial loss: 0.628422\n",
      "epoch 40; iter: 400; batch classifier loss: 0.385585; batch adversarial loss: 0.615112\n",
      "epoch 41; iter: 0; batch classifier loss: 0.620205; batch adversarial loss: 0.553264\n",
      "epoch 41; iter: 200; batch classifier loss: 0.381190; batch adversarial loss: 0.646717\n",
      "epoch 41; iter: 400; batch classifier loss: 0.377623; batch adversarial loss: 0.665287\n",
      "epoch 42; iter: 0; batch classifier loss: 0.334776; batch adversarial loss: 0.638538\n",
      "epoch 42; iter: 200; batch classifier loss: 0.307066; batch adversarial loss: 0.666876\n",
      "epoch 42; iter: 400; batch classifier loss: 0.648645; batch adversarial loss: 0.648045\n",
      "epoch 43; iter: 0; batch classifier loss: 0.320748; batch adversarial loss: 0.642397\n",
      "epoch 43; iter: 200; batch classifier loss: 0.402764; batch adversarial loss: 0.654622\n",
      "epoch 43; iter: 400; batch classifier loss: 0.494357; batch adversarial loss: 0.572799\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321620; batch adversarial loss: 0.627660\n",
      "epoch 44; iter: 200; batch classifier loss: 0.469008; batch adversarial loss: 0.706938\n",
      "epoch 44; iter: 400; batch classifier loss: 1.494529; batch adversarial loss: 0.564596\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412433; batch adversarial loss: 0.700065\n",
      "epoch 45; iter: 200; batch classifier loss: 0.470882; batch adversarial loss: 0.669044\n",
      "epoch 45; iter: 400; batch classifier loss: 0.492441; batch adversarial loss: 0.638187\n",
      "epoch 46; iter: 0; batch classifier loss: 0.447920; batch adversarial loss: 0.640017\n",
      "epoch 46; iter: 200; batch classifier loss: 0.547115; batch adversarial loss: 0.611998\n",
      "epoch 46; iter: 400; batch classifier loss: 0.224713; batch adversarial loss: 0.659319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.538884; batch adversarial loss: 0.697409\n",
      "epoch 47; iter: 200; batch classifier loss: 0.361636; batch adversarial loss: 0.619103\n",
      "epoch 47; iter: 400; batch classifier loss: 1.018025; batch adversarial loss: 0.569944\n",
      "epoch 48; iter: 0; batch classifier loss: 0.509361; batch adversarial loss: 0.606145\n",
      "epoch 48; iter: 200; batch classifier loss: 0.402761; batch adversarial loss: 0.569210\n",
      "epoch 48; iter: 400; batch classifier loss: 0.634390; batch adversarial loss: 0.592685\n",
      "epoch 49; iter: 0; batch classifier loss: 0.677320; batch adversarial loss: 0.599543\n",
      "epoch 49; iter: 200; batch classifier loss: 0.419576; batch adversarial loss: 0.629593\n",
      "epoch 49; iter: 400; batch classifier loss: 0.471619; batch adversarial loss: 0.638812\n",
      "epoch 0; iter: 0; batch classifier loss: 47.358021; batch adversarial loss: 0.687499\n",
      "epoch 0; iter: 200; batch classifier loss: 9.536183; batch adversarial loss: 0.638354\n",
      "epoch 0; iter: 400; batch classifier loss: 5.773314; batch adversarial loss: 0.618740\n",
      "epoch 1; iter: 0; batch classifier loss: 18.773863; batch adversarial loss: 0.651965\n",
      "epoch 1; iter: 200; batch classifier loss: 0.572744; batch adversarial loss: 0.543747\n",
      "epoch 1; iter: 400; batch classifier loss: 5.411015; batch adversarial loss: 0.553604\n",
      "epoch 2; iter: 0; batch classifier loss: 2.833337; batch adversarial loss: 0.634929\n",
      "epoch 2; iter: 200; batch classifier loss: 2.579997; batch adversarial loss: 0.592392\n",
      "epoch 2; iter: 400; batch classifier loss: 0.250898; batch adversarial loss: 0.682451\n",
      "epoch 3; iter: 0; batch classifier loss: 3.551121; batch adversarial loss: 0.629373\n",
      "epoch 3; iter: 200; batch classifier loss: 0.432113; batch adversarial loss: 0.562084\n",
      "epoch 3; iter: 400; batch classifier loss: 0.184307; batch adversarial loss: 0.661892\n",
      "epoch 4; iter: 0; batch classifier loss: 1.557443; batch adversarial loss: 0.690197\n",
      "epoch 4; iter: 200; batch classifier loss: 0.857432; batch adversarial loss: 0.627960\n",
      "epoch 4; iter: 400; batch classifier loss: 0.495898; batch adversarial loss: 0.649937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.523248; batch adversarial loss: 0.734031\n",
      "epoch 5; iter: 200; batch classifier loss: 1.199320; batch adversarial loss: 0.576523\n",
      "epoch 5; iter: 400; batch classifier loss: 0.842865; batch adversarial loss: 0.622026\n",
      "epoch 6; iter: 0; batch classifier loss: 0.684651; batch adversarial loss: 0.650725\n",
      "epoch 6; iter: 200; batch classifier loss: 0.368732; batch adversarial loss: 0.634808\n",
      "epoch 6; iter: 400; batch classifier loss: 0.517521; batch adversarial loss: 0.574771\n",
      "epoch 7; iter: 0; batch classifier loss: 1.371794; batch adversarial loss: 0.680843\n",
      "epoch 7; iter: 200; batch classifier loss: 0.668525; batch adversarial loss: 0.644434\n",
      "epoch 7; iter: 400; batch classifier loss: 0.387099; batch adversarial loss: 0.627927\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396866; batch adversarial loss: 0.590839\n",
      "epoch 8; iter: 200; batch classifier loss: 0.364446; batch adversarial loss: 0.582935\n",
      "epoch 8; iter: 400; batch classifier loss: 0.396621; batch adversarial loss: 0.608323\n",
      "epoch 9; iter: 0; batch classifier loss: 0.306101; batch adversarial loss: 0.596774\n",
      "epoch 9; iter: 200; batch classifier loss: 0.403278; batch adversarial loss: 0.656139\n",
      "epoch 9; iter: 400; batch classifier loss: 0.274807; batch adversarial loss: 0.669002\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337770; batch adversarial loss: 0.585046\n",
      "epoch 10; iter: 200; batch classifier loss: 0.547778; batch adversarial loss: 0.569358\n",
      "epoch 10; iter: 400; batch classifier loss: 0.523903; batch adversarial loss: 0.609339\n",
      "epoch 11; iter: 0; batch classifier loss: 0.396196; batch adversarial loss: 0.565875\n",
      "epoch 11; iter: 200; batch classifier loss: 0.319351; batch adversarial loss: 0.588524\n",
      "epoch 11; iter: 400; batch classifier loss: 0.502037; batch adversarial loss: 0.616223\n",
      "epoch 12; iter: 0; batch classifier loss: 0.328841; batch adversarial loss: 0.553836\n",
      "epoch 12; iter: 200; batch classifier loss: 0.304487; batch adversarial loss: 0.602141\n",
      "epoch 12; iter: 400; batch classifier loss: 0.348770; batch adversarial loss: 0.623802\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400868; batch adversarial loss: 0.655013\n",
      "epoch 13; iter: 200; batch classifier loss: 0.374787; batch adversarial loss: 0.592730\n",
      "epoch 13; iter: 400; batch classifier loss: 0.321220; batch adversarial loss: 0.609443\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240453; batch adversarial loss: 0.665860\n",
      "epoch 14; iter: 200; batch classifier loss: 0.291089; batch adversarial loss: 0.639325\n",
      "epoch 14; iter: 400; batch classifier loss: 0.363172; batch adversarial loss: 0.627740\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487569; batch adversarial loss: 0.636044\n",
      "epoch 15; iter: 200; batch classifier loss: 0.331945; batch adversarial loss: 0.617413\n",
      "epoch 15; iter: 400; batch classifier loss: 0.211416; batch adversarial loss: 0.602614\n",
      "epoch 16; iter: 0; batch classifier loss: 0.401185; batch adversarial loss: 0.581026\n",
      "epoch 16; iter: 200; batch classifier loss: 0.395140; batch adversarial loss: 0.619978\n",
      "epoch 16; iter: 400; batch classifier loss: 0.414745; batch adversarial loss: 0.559343\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330955; batch adversarial loss: 0.600646\n",
      "epoch 17; iter: 200; batch classifier loss: 0.254021; batch adversarial loss: 0.603784\n",
      "epoch 17; iter: 400; batch classifier loss: 0.574774; batch adversarial loss: 0.569693\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350914; batch adversarial loss: 0.578927\n",
      "epoch 18; iter: 200; batch classifier loss: 0.252589; batch adversarial loss: 0.686556\n",
      "epoch 18; iter: 400; batch classifier loss: 0.350439; batch adversarial loss: 0.678387\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299578; batch adversarial loss: 0.547307\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347295; batch adversarial loss: 0.616708\n",
      "epoch 19; iter: 400; batch classifier loss: 0.308546; batch adversarial loss: 0.632295\n",
      "epoch 20; iter: 0; batch classifier loss: 0.641057; batch adversarial loss: 0.559604\n",
      "epoch 20; iter: 200; batch classifier loss: 0.584679; batch adversarial loss: 0.611676\n",
      "epoch 20; iter: 400; batch classifier loss: 0.511814; batch adversarial loss: 0.669057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.443781; batch adversarial loss: 0.545826\n",
      "epoch 21; iter: 200; batch classifier loss: 0.396532; batch adversarial loss: 0.660179\n",
      "epoch 21; iter: 400; batch classifier loss: 0.340563; batch adversarial loss: 0.674531\n",
      "epoch 22; iter: 0; batch classifier loss: 0.442286; batch adversarial loss: 0.585894\n",
      "epoch 22; iter: 200; batch classifier loss: 0.299053; batch adversarial loss: 0.632813\n",
      "epoch 22; iter: 400; batch classifier loss: 0.303111; batch adversarial loss: 0.597606\n",
      "epoch 23; iter: 0; batch classifier loss: 0.516373; batch adversarial loss: 0.612284\n",
      "epoch 23; iter: 200; batch classifier loss: 0.469655; batch adversarial loss: 0.559541\n",
      "epoch 23; iter: 400; batch classifier loss: 0.345972; batch adversarial loss: 0.694343\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505288; batch adversarial loss: 0.626008\n",
      "epoch 24; iter: 200; batch classifier loss: 0.547010; batch adversarial loss: 0.615027\n",
      "epoch 24; iter: 400; batch classifier loss: 0.343687; batch adversarial loss: 0.625834\n",
      "epoch 25; iter: 0; batch classifier loss: 0.638298; batch adversarial loss: 0.678103\n",
      "epoch 25; iter: 200; batch classifier loss: 0.240413; batch adversarial loss: 0.677285\n",
      "epoch 25; iter: 400; batch classifier loss: 0.337319; batch adversarial loss: 0.552063\n",
      "epoch 26; iter: 0; batch classifier loss: 0.272403; batch adversarial loss: 0.693391\n",
      "epoch 26; iter: 200; batch classifier loss: 0.364791; batch adversarial loss: 0.593508\n",
      "epoch 26; iter: 400; batch classifier loss: 0.398342; batch adversarial loss: 0.627611\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383097; batch adversarial loss: 0.611364\n",
      "epoch 27; iter: 200; batch classifier loss: 0.427057; batch adversarial loss: 0.682938\n",
      "epoch 27; iter: 400; batch classifier loss: 0.427046; batch adversarial loss: 0.628076\n",
      "epoch 28; iter: 0; batch classifier loss: 0.293793; batch adversarial loss: 0.653975\n",
      "epoch 28; iter: 200; batch classifier loss: 0.486811; batch adversarial loss: 0.613443\n",
      "epoch 28; iter: 400; batch classifier loss: 0.316876; batch adversarial loss: 0.681460\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258991; batch adversarial loss: 0.606335\n",
      "epoch 29; iter: 200; batch classifier loss: 0.361095; batch adversarial loss: 0.579075\n",
      "epoch 29; iter: 400; batch classifier loss: 0.678815; batch adversarial loss: 0.656700\n",
      "epoch 30; iter: 0; batch classifier loss: 0.352063; batch adversarial loss: 0.640964\n",
      "epoch 30; iter: 200; batch classifier loss: 0.441902; batch adversarial loss: 0.746564\n",
      "epoch 30; iter: 400; batch classifier loss: 0.404690; batch adversarial loss: 0.568782\n",
      "epoch 31; iter: 0; batch classifier loss: 0.304909; batch adversarial loss: 0.598415\n",
      "epoch 31; iter: 200; batch classifier loss: 0.376544; batch adversarial loss: 0.665789\n",
      "epoch 31; iter: 400; batch classifier loss: 0.387542; batch adversarial loss: 0.577941\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461636; batch adversarial loss: 0.697268\n",
      "epoch 32; iter: 200; batch classifier loss: 0.219289; batch adversarial loss: 0.661400\n",
      "epoch 32; iter: 400; batch classifier loss: 0.425765; batch adversarial loss: 0.640952\n",
      "epoch 33; iter: 0; batch classifier loss: 0.180681; batch adversarial loss: 0.647769\n",
      "epoch 33; iter: 200; batch classifier loss: 0.454406; batch adversarial loss: 0.566644\n",
      "epoch 33; iter: 400; batch classifier loss: 0.444846; batch adversarial loss: 0.658885\n",
      "epoch 34; iter: 0; batch classifier loss: 0.381192; batch adversarial loss: 0.656052\n",
      "epoch 34; iter: 200; batch classifier loss: 0.284626; batch adversarial loss: 0.662256\n",
      "epoch 34; iter: 400; batch classifier loss: 0.548624; batch adversarial loss: 0.604558\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337493; batch adversarial loss: 0.589356\n",
      "epoch 35; iter: 200; batch classifier loss: 0.597388; batch adversarial loss: 0.629530\n",
      "epoch 35; iter: 400; batch classifier loss: 0.705517; batch adversarial loss: 0.680398\n",
      "epoch 36; iter: 0; batch classifier loss: 0.336074; batch adversarial loss: 0.666824\n",
      "epoch 36; iter: 200; batch classifier loss: 0.613579; batch adversarial loss: 0.589065\n",
      "epoch 36; iter: 400; batch classifier loss: 0.544864; batch adversarial loss: 0.594992\n",
      "epoch 37; iter: 0; batch classifier loss: 0.465383; batch adversarial loss: 0.638695\n",
      "epoch 37; iter: 200; batch classifier loss: 0.292131; batch adversarial loss: 0.676595\n",
      "epoch 37; iter: 400; batch classifier loss: 0.565436; batch adversarial loss: 0.736233\n",
      "epoch 38; iter: 0; batch classifier loss: 0.594342; batch adversarial loss: 0.638408\n",
      "epoch 38; iter: 200; batch classifier loss: 0.422192; batch adversarial loss: 0.625590\n",
      "epoch 38; iter: 400; batch classifier loss: 0.611724; batch adversarial loss: 0.676349\n",
      "epoch 39; iter: 0; batch classifier loss: 0.369472; batch adversarial loss: 0.570332\n",
      "epoch 39; iter: 200; batch classifier loss: 0.515108; batch adversarial loss: 0.537126\n",
      "epoch 39; iter: 400; batch classifier loss: 0.381756; batch adversarial loss: 0.578884\n",
      "epoch 40; iter: 0; batch classifier loss: 0.331795; batch adversarial loss: 0.649085\n",
      "epoch 40; iter: 200; batch classifier loss: 0.393993; batch adversarial loss: 0.588230\n",
      "epoch 40; iter: 400; batch classifier loss: 0.500279; batch adversarial loss: 0.568009\n",
      "epoch 41; iter: 0; batch classifier loss: 0.608018; batch adversarial loss: 0.685053\n",
      "epoch 41; iter: 200; batch classifier loss: 0.410786; batch adversarial loss: 0.604143\n",
      "epoch 41; iter: 400; batch classifier loss: 0.342662; batch adversarial loss: 0.622043\n",
      "epoch 42; iter: 0; batch classifier loss: 0.497249; batch adversarial loss: 0.633145\n",
      "epoch 42; iter: 200; batch classifier loss: 0.796944; batch adversarial loss: 0.555784\n",
      "epoch 42; iter: 400; batch classifier loss: 0.280981; batch adversarial loss: 0.608557\n",
      "epoch 43; iter: 0; batch classifier loss: 0.717447; batch adversarial loss: 0.659497\n",
      "epoch 43; iter: 200; batch classifier loss: 0.533661; batch adversarial loss: 0.588776\n",
      "epoch 43; iter: 400; batch classifier loss: 0.581030; batch adversarial loss: 0.578797\n",
      "epoch 44; iter: 0; batch classifier loss: 0.345458; batch adversarial loss: 0.691994\n",
      "epoch 44; iter: 200; batch classifier loss: 0.530446; batch adversarial loss: 0.619595\n",
      "epoch 44; iter: 400; batch classifier loss: 0.464684; batch adversarial loss: 0.623236\n",
      "epoch 45; iter: 0; batch classifier loss: 0.327182; batch adversarial loss: 0.630852\n",
      "epoch 45; iter: 200; batch classifier loss: 0.583078; batch adversarial loss: 0.619576\n",
      "epoch 45; iter: 400; batch classifier loss: 0.555748; batch adversarial loss: 0.582014\n",
      "epoch 46; iter: 0; batch classifier loss: 0.507839; batch adversarial loss: 0.573202\n",
      "epoch 46; iter: 200; batch classifier loss: 0.428469; batch adversarial loss: 0.636663\n",
      "epoch 46; iter: 400; batch classifier loss: 0.396353; batch adversarial loss: 0.634071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460614; batch adversarial loss: 0.642335\n",
      "epoch 47; iter: 200; batch classifier loss: 0.333660; batch adversarial loss: 0.611291\n",
      "epoch 47; iter: 400; batch classifier loss: 0.489288; batch adversarial loss: 0.574595\n",
      "epoch 48; iter: 0; batch classifier loss: 0.706882; batch adversarial loss: 0.617638\n",
      "epoch 48; iter: 200; batch classifier loss: 0.585869; batch adversarial loss: 0.662809\n",
      "epoch 48; iter: 400; batch classifier loss: 0.544154; batch adversarial loss: 0.588051\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422333; batch adversarial loss: 0.582206\n",
      "epoch 49; iter: 200; batch classifier loss: 0.475761; batch adversarial loss: 0.584221\n",
      "epoch 49; iter: 400; batch classifier loss: 0.860315; batch adversarial loss: 0.721681\n",
      "epoch 0; iter: 0; batch classifier loss: 22.297672; batch adversarial loss: 0.654358\n",
      "epoch 0; iter: 200; batch classifier loss: 5.967833; batch adversarial loss: 0.672282\n",
      "epoch 0; iter: 400; batch classifier loss: 2.709817; batch adversarial loss: 0.626675\n",
      "epoch 1; iter: 0; batch classifier loss: 2.928341; batch adversarial loss: 0.677440\n",
      "epoch 1; iter: 200; batch classifier loss: 0.409699; batch adversarial loss: 0.662180\n",
      "epoch 1; iter: 400; batch classifier loss: 0.942006; batch adversarial loss: 0.652640\n",
      "epoch 2; iter: 0; batch classifier loss: 2.654622; batch adversarial loss: 0.685619\n",
      "epoch 2; iter: 200; batch classifier loss: 0.545264; batch adversarial loss: 0.657789\n",
      "epoch 2; iter: 400; batch classifier loss: 0.281262; batch adversarial loss: 0.601681\n",
      "epoch 3; iter: 0; batch classifier loss: 1.692137; batch adversarial loss: 0.652617\n",
      "epoch 3; iter: 200; batch classifier loss: 0.889958; batch adversarial loss: 0.655001\n",
      "epoch 3; iter: 400; batch classifier loss: 2.281356; batch adversarial loss: 0.614432\n",
      "epoch 4; iter: 0; batch classifier loss: 1.402621; batch adversarial loss: 0.632606\n",
      "epoch 4; iter: 200; batch classifier loss: 0.523299; batch adversarial loss: 0.610859\n",
      "epoch 4; iter: 400; batch classifier loss: 1.025309; batch adversarial loss: 0.762573\n",
      "epoch 5; iter: 0; batch classifier loss: 0.683511; batch adversarial loss: 0.578923\n",
      "epoch 5; iter: 200; batch classifier loss: 0.513207; batch adversarial loss: 0.586760\n",
      "epoch 5; iter: 400; batch classifier loss: 2.073747; batch adversarial loss: 0.655730\n",
      "epoch 6; iter: 0; batch classifier loss: 1.503681; batch adversarial loss: 0.538350\n",
      "epoch 6; iter: 200; batch classifier loss: 0.691388; batch adversarial loss: 0.655633\n",
      "epoch 6; iter: 400; batch classifier loss: 0.299790; batch adversarial loss: 0.551201\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512366; batch adversarial loss: 0.527442\n",
      "epoch 7; iter: 200; batch classifier loss: 0.876933; batch adversarial loss: 0.590072\n",
      "epoch 7; iter: 400; batch classifier loss: 0.499366; batch adversarial loss: 0.570911\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518669; batch adversarial loss: 0.566992\n",
      "epoch 8; iter: 200; batch classifier loss: 0.341061; batch adversarial loss: 0.638223\n",
      "epoch 8; iter: 400; batch classifier loss: 0.698891; batch adversarial loss: 0.676638\n",
      "epoch 9; iter: 0; batch classifier loss: 0.491172; batch adversarial loss: 0.630250\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383323; batch adversarial loss: 0.632011\n",
      "epoch 9; iter: 400; batch classifier loss: 0.336779; batch adversarial loss: 0.631956\n",
      "epoch 10; iter: 0; batch classifier loss: 0.330715; batch adversarial loss: 0.641548\n",
      "epoch 10; iter: 200; batch classifier loss: 0.215480; batch adversarial loss: 0.623883\n",
      "epoch 10; iter: 400; batch classifier loss: 0.264250; batch adversarial loss: 0.632122\n",
      "epoch 11; iter: 0; batch classifier loss: 0.330828; batch adversarial loss: 0.619215\n",
      "epoch 11; iter: 200; batch classifier loss: 0.403560; batch adversarial loss: 0.574006\n",
      "epoch 11; iter: 400; batch classifier loss: 0.330959; batch adversarial loss: 0.700134\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348826; batch adversarial loss: 0.584700\n",
      "epoch 12; iter: 200; batch classifier loss: 0.262413; batch adversarial loss: 0.682030\n",
      "epoch 12; iter: 400; batch classifier loss: 0.346594; batch adversarial loss: 0.524392\n",
      "epoch 13; iter: 0; batch classifier loss: 0.449300; batch adversarial loss: 0.616647\n",
      "epoch 13; iter: 200; batch classifier loss: 0.402254; batch adversarial loss: 0.647048\n",
      "epoch 13; iter: 400; batch classifier loss: 0.398979; batch adversarial loss: 0.611962\n",
      "epoch 14; iter: 0; batch classifier loss: 0.240143; batch adversarial loss: 0.612839\n",
      "epoch 14; iter: 200; batch classifier loss: 0.290169; batch adversarial loss: 0.627250\n",
      "epoch 14; iter: 400; batch classifier loss: 0.485031; batch adversarial loss: 0.661184\n",
      "epoch 15; iter: 0; batch classifier loss: 0.367361; batch adversarial loss: 0.713212\n",
      "epoch 15; iter: 200; batch classifier loss: 0.401228; batch adversarial loss: 0.612689\n",
      "epoch 15; iter: 400; batch classifier loss: 0.443850; batch adversarial loss: 0.677148\n",
      "epoch 16; iter: 0; batch classifier loss: 0.384702; batch adversarial loss: 0.641123\n",
      "epoch 16; iter: 200; batch classifier loss: 0.433255; batch adversarial loss: 0.650965\n",
      "epoch 16; iter: 400; batch classifier loss: 0.597366; batch adversarial loss: 0.656548\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366812; batch adversarial loss: 0.620772\n",
      "epoch 17; iter: 200; batch classifier loss: 0.326411; batch adversarial loss: 0.619830\n",
      "epoch 17; iter: 400; batch classifier loss: 0.362767; batch adversarial loss: 0.571679\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345588; batch adversarial loss: 0.627622\n",
      "epoch 18; iter: 200; batch classifier loss: 0.548100; batch adversarial loss: 0.608002\n",
      "epoch 18; iter: 400; batch classifier loss: 0.530326; batch adversarial loss: 0.663116\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456188; batch adversarial loss: 0.639574\n",
      "epoch 19; iter: 200; batch classifier loss: 0.419314; batch adversarial loss: 0.687004\n",
      "epoch 19; iter: 400; batch classifier loss: 0.481791; batch adversarial loss: 0.651362\n",
      "epoch 20; iter: 0; batch classifier loss: 0.362975; batch adversarial loss: 0.644826\n",
      "epoch 20; iter: 200; batch classifier loss: 0.370819; batch adversarial loss: 0.633758\n",
      "epoch 20; iter: 400; batch classifier loss: 0.550525; batch adversarial loss: 0.647041\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545034; batch adversarial loss: 0.573030\n",
      "epoch 21; iter: 200; batch classifier loss: 0.244048; batch adversarial loss: 0.548539\n",
      "epoch 21; iter: 400; batch classifier loss: 0.440789; batch adversarial loss: 0.624995\n",
      "epoch 22; iter: 0; batch classifier loss: 0.369699; batch adversarial loss: 0.566453\n",
      "epoch 22; iter: 200; batch classifier loss: 0.373910; batch adversarial loss: 0.646175\n",
      "epoch 22; iter: 400; batch classifier loss: 0.598545; batch adversarial loss: 0.601581\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396481; batch adversarial loss: 0.683864\n",
      "epoch 23; iter: 200; batch classifier loss: 0.632423; batch adversarial loss: 0.630022\n",
      "epoch 23; iter: 400; batch classifier loss: 0.585191; batch adversarial loss: 0.564102\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435211; batch adversarial loss: 0.655310\n",
      "epoch 24; iter: 200; batch classifier loss: 0.622977; batch adversarial loss: 0.576625\n",
      "epoch 24; iter: 400; batch classifier loss: 0.401056; batch adversarial loss: 0.641034\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344553; batch adversarial loss: 0.628793\n",
      "epoch 25; iter: 200; batch classifier loss: 0.794996; batch adversarial loss: 0.629183\n",
      "epoch 25; iter: 400; batch classifier loss: 0.336591; batch adversarial loss: 0.646025\n",
      "epoch 26; iter: 0; batch classifier loss: 0.591623; batch adversarial loss: 0.704409\n",
      "epoch 26; iter: 200; batch classifier loss: 0.429562; batch adversarial loss: 0.667945\n",
      "epoch 26; iter: 400; batch classifier loss: 0.469292; batch adversarial loss: 0.636280\n",
      "epoch 27; iter: 0; batch classifier loss: 0.344782; batch adversarial loss: 0.633571\n",
      "epoch 27; iter: 200; batch classifier loss: 0.431080; batch adversarial loss: 0.620936\n",
      "epoch 27; iter: 400; batch classifier loss: 0.412538; batch adversarial loss: 0.627477\n",
      "epoch 28; iter: 0; batch classifier loss: 1.197427; batch adversarial loss: 0.568445\n",
      "epoch 28; iter: 200; batch classifier loss: 0.461696; batch adversarial loss: 0.639606\n",
      "epoch 28; iter: 400; batch classifier loss: 0.486946; batch adversarial loss: 0.652587\n",
      "epoch 29; iter: 0; batch classifier loss: 0.822896; batch adversarial loss: 0.562710\n",
      "epoch 29; iter: 200; batch classifier loss: 0.617547; batch adversarial loss: 0.616830\n",
      "epoch 29; iter: 400; batch classifier loss: 0.289391; batch adversarial loss: 0.642499\n",
      "epoch 30; iter: 0; batch classifier loss: 0.794924; batch adversarial loss: 0.650227\n",
      "epoch 30; iter: 200; batch classifier loss: 0.428112; batch adversarial loss: 0.675810\n",
      "epoch 30; iter: 400; batch classifier loss: 1.250317; batch adversarial loss: 0.607849\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320105; batch adversarial loss: 0.616838\n",
      "epoch 31; iter: 200; batch classifier loss: 0.368393; batch adversarial loss: 0.593877\n",
      "epoch 31; iter: 400; batch classifier loss: 0.491182; batch adversarial loss: 0.631734\n",
      "epoch 32; iter: 0; batch classifier loss: 0.495453; batch adversarial loss: 0.651817\n",
      "epoch 32; iter: 200; batch classifier loss: 0.601902; batch adversarial loss: 0.610164\n",
      "epoch 32; iter: 400; batch classifier loss: 0.465837; batch adversarial loss: 0.827223\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498743; batch adversarial loss: 0.608273\n",
      "epoch 33; iter: 200; batch classifier loss: 0.859590; batch adversarial loss: 0.691185\n",
      "epoch 33; iter: 400; batch classifier loss: 0.475525; batch adversarial loss: 0.611858\n",
      "epoch 34; iter: 0; batch classifier loss: 0.542694; batch adversarial loss: 0.490150\n",
      "epoch 34; iter: 200; batch classifier loss: 0.264510; batch adversarial loss: 0.606757\n",
      "epoch 34; iter: 400; batch classifier loss: 0.627177; batch adversarial loss: 0.594950\n",
      "epoch 35; iter: 0; batch classifier loss: 0.449333; batch adversarial loss: 0.678599\n",
      "epoch 35; iter: 200; batch classifier loss: 0.601266; batch adversarial loss: 0.577883\n",
      "epoch 35; iter: 400; batch classifier loss: 0.387411; batch adversarial loss: 0.621009\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432527; batch adversarial loss: 0.560912\n",
      "epoch 36; iter: 200; batch classifier loss: 0.213491; batch adversarial loss: 0.698743\n",
      "epoch 36; iter: 400; batch classifier loss: 0.742770; batch adversarial loss: 0.622970\n",
      "epoch 37; iter: 0; batch classifier loss: 0.374066; batch adversarial loss: 0.681543\n",
      "epoch 37; iter: 200; batch classifier loss: 0.698247; batch adversarial loss: 0.548394\n",
      "epoch 37; iter: 400; batch classifier loss: 0.366236; batch adversarial loss: 0.656866\n",
      "epoch 38; iter: 0; batch classifier loss: 0.214641; batch adversarial loss: 0.667811\n",
      "epoch 38; iter: 200; batch classifier loss: 0.301130; batch adversarial loss: 0.646908\n",
      "epoch 38; iter: 400; batch classifier loss: 0.452243; batch adversarial loss: 0.535618\n",
      "epoch 39; iter: 0; batch classifier loss: 0.335913; batch adversarial loss: 0.671927\n",
      "epoch 39; iter: 200; batch classifier loss: 0.210362; batch adversarial loss: 0.635333\n",
      "epoch 39; iter: 400; batch classifier loss: 0.513747; batch adversarial loss: 0.667970\n",
      "epoch 40; iter: 0; batch classifier loss: 1.628766; batch adversarial loss: 0.602690\n",
      "epoch 40; iter: 200; batch classifier loss: 0.508429; batch adversarial loss: 0.616676\n",
      "epoch 40; iter: 400; batch classifier loss: 0.612585; batch adversarial loss: 0.633199\n",
      "epoch 41; iter: 0; batch classifier loss: 0.531748; batch adversarial loss: 0.627455\n",
      "epoch 41; iter: 200; batch classifier loss: 0.538534; batch adversarial loss: 0.570043\n",
      "epoch 41; iter: 400; batch classifier loss: 0.349189; batch adversarial loss: 0.625439\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455897; batch adversarial loss: 0.629893\n",
      "epoch 42; iter: 200; batch classifier loss: 0.241091; batch adversarial loss: 0.616485\n",
      "epoch 42; iter: 400; batch classifier loss: 0.345900; batch adversarial loss: 0.601760\n",
      "epoch 43; iter: 0; batch classifier loss: 0.539858; batch adversarial loss: 0.540371\n",
      "epoch 43; iter: 200; batch classifier loss: 0.262030; batch adversarial loss: 0.568544\n",
      "epoch 43; iter: 400; batch classifier loss: 0.316839; batch adversarial loss: 0.735026\n",
      "epoch 44; iter: 0; batch classifier loss: 0.817585; batch adversarial loss: 0.668052\n",
      "epoch 44; iter: 200; batch classifier loss: 0.364359; batch adversarial loss: 0.657700\n",
      "epoch 44; iter: 400; batch classifier loss: 0.358545; batch adversarial loss: 0.643196\n",
      "epoch 45; iter: 0; batch classifier loss: 0.503791; batch adversarial loss: 0.664812\n",
      "epoch 45; iter: 200; batch classifier loss: 0.333518; batch adversarial loss: 0.641354\n",
      "epoch 45; iter: 400; batch classifier loss: 0.367705; batch adversarial loss: 0.542726\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508291; batch adversarial loss: 0.592062\n",
      "epoch 46; iter: 200; batch classifier loss: 0.655499; batch adversarial loss: 0.654865\n",
      "epoch 46; iter: 400; batch classifier loss: 0.455068; batch adversarial loss: 0.537614\n",
      "epoch 47; iter: 0; batch classifier loss: 0.347566; batch adversarial loss: 0.620502\n",
      "epoch 47; iter: 200; batch classifier loss: 0.748012; batch adversarial loss: 0.638149\n",
      "epoch 47; iter: 400; batch classifier loss: 0.424298; batch adversarial loss: 0.648679\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482840; batch adversarial loss: 0.660885\n",
      "epoch 48; iter: 200; batch classifier loss: 0.483140; batch adversarial loss: 0.690591\n",
      "epoch 48; iter: 400; batch classifier loss: 0.355732; batch adversarial loss: 0.638905\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390265; batch adversarial loss: 0.621791\n",
      "epoch 49; iter: 200; batch classifier loss: 0.427055; batch adversarial loss: 0.575825\n",
      "epoch 49; iter: 400; batch classifier loss: 0.629000; batch adversarial loss: 0.654200\n",
      "epoch 0; iter: 0; batch classifier loss: 5.530693; batch adversarial loss: 0.694181\n",
      "epoch 0; iter: 200; batch classifier loss: 1.507844; batch adversarial loss: 0.672788\n",
      "epoch 0; iter: 400; batch classifier loss: 2.442837; batch adversarial loss: 0.621012\n",
      "epoch 1; iter: 0; batch classifier loss: 3.928512; batch adversarial loss: 0.584385\n",
      "epoch 1; iter: 200; batch classifier loss: 2.400091; batch adversarial loss: 0.549574\n",
      "epoch 1; iter: 400; batch classifier loss: 23.639105; batch adversarial loss: 0.638978\n",
      "epoch 2; iter: 0; batch classifier loss: 1.336310; batch adversarial loss: 0.566953\n",
      "epoch 2; iter: 200; batch classifier loss: 0.859025; batch adversarial loss: 0.612226\n",
      "epoch 2; iter: 400; batch classifier loss: 1.324715; batch adversarial loss: 0.639186\n",
      "epoch 3; iter: 0; batch classifier loss: 1.843767; batch adversarial loss: 0.690987\n",
      "epoch 3; iter: 200; batch classifier loss: 1.197803; batch adversarial loss: 0.536573\n",
      "epoch 3; iter: 400; batch classifier loss: 1.804720; batch adversarial loss: 0.573767\n",
      "epoch 4; iter: 0; batch classifier loss: 0.490278; batch adversarial loss: 0.557139\n",
      "epoch 4; iter: 200; batch classifier loss: 1.051192; batch adversarial loss: 0.669817\n",
      "epoch 4; iter: 400; batch classifier loss: 0.395720; batch adversarial loss: 0.646955\n",
      "epoch 5; iter: 0; batch classifier loss: 0.712425; batch adversarial loss: 0.641407\n",
      "epoch 5; iter: 200; batch classifier loss: 0.328585; batch adversarial loss: 0.575345\n",
      "epoch 5; iter: 400; batch classifier loss: 0.591885; batch adversarial loss: 0.742687\n",
      "epoch 6; iter: 0; batch classifier loss: 0.707005; batch adversarial loss: 0.606066\n",
      "epoch 6; iter: 200; batch classifier loss: 0.347001; batch adversarial loss: 0.650715\n",
      "epoch 6; iter: 400; batch classifier loss: 0.419339; batch adversarial loss: 0.633827\n",
      "epoch 7; iter: 0; batch classifier loss: 0.729241; batch adversarial loss: 0.544637\n",
      "epoch 7; iter: 200; batch classifier loss: 0.471800; batch adversarial loss: 0.650826\n",
      "epoch 7; iter: 400; batch classifier loss: 0.900893; batch adversarial loss: 0.625204\n",
      "epoch 8; iter: 0; batch classifier loss: 0.414443; batch adversarial loss: 0.603644\n",
      "epoch 8; iter: 200; batch classifier loss: 0.537040; batch adversarial loss: 0.644779\n",
      "epoch 8; iter: 400; batch classifier loss: 0.591877; batch adversarial loss: 0.650296\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510447; batch adversarial loss: 0.643810\n",
      "epoch 9; iter: 200; batch classifier loss: 0.403183; batch adversarial loss: 0.626595\n",
      "epoch 9; iter: 400; batch classifier loss: 0.281549; batch adversarial loss: 0.630404\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280481; batch adversarial loss: 0.634031\n",
      "epoch 10; iter: 200; batch classifier loss: 0.605962; batch adversarial loss: 0.571038\n",
      "epoch 10; iter: 400; batch classifier loss: 0.389252; batch adversarial loss: 0.595255\n",
      "epoch 11; iter: 0; batch classifier loss: 0.312989; batch adversarial loss: 0.603725\n",
      "epoch 11; iter: 200; batch classifier loss: 0.384788; batch adversarial loss: 0.679688\n",
      "epoch 11; iter: 400; batch classifier loss: 0.489618; batch adversarial loss: 0.546725\n",
      "epoch 12; iter: 0; batch classifier loss: 0.675402; batch adversarial loss: 0.638690\n",
      "epoch 12; iter: 200; batch classifier loss: 0.285465; batch adversarial loss: 0.598963\n",
      "epoch 12; iter: 400; batch classifier loss: 0.303806; batch adversarial loss: 0.625851\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335792; batch adversarial loss: 0.590378\n",
      "epoch 13; iter: 200; batch classifier loss: 0.367119; batch adversarial loss: 0.569897\n",
      "epoch 13; iter: 400; batch classifier loss: 0.296725; batch adversarial loss: 0.624171\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527078; batch adversarial loss: 0.622673\n",
      "epoch 14; iter: 200; batch classifier loss: 0.262009; batch adversarial loss: 0.636114\n",
      "epoch 14; iter: 400; batch classifier loss: 0.428006; batch adversarial loss: 0.650275\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424918; batch adversarial loss: 0.561993\n",
      "epoch 15; iter: 200; batch classifier loss: 0.313270; batch adversarial loss: 0.696765\n",
      "epoch 15; iter: 400; batch classifier loss: 0.493762; batch adversarial loss: 0.604134\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311007; batch adversarial loss: 0.588848\n",
      "epoch 16; iter: 200; batch classifier loss: 0.353367; batch adversarial loss: 0.627749\n",
      "epoch 16; iter: 400; batch classifier loss: 0.292810; batch adversarial loss: 0.696841\n",
      "epoch 17; iter: 0; batch classifier loss: 0.457308; batch adversarial loss: 0.654677\n",
      "epoch 17; iter: 200; batch classifier loss: 0.402478; batch adversarial loss: 0.543266\n",
      "epoch 17; iter: 400; batch classifier loss: 0.308950; batch adversarial loss: 0.656670\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463904; batch adversarial loss: 0.614225\n",
      "epoch 18; iter: 200; batch classifier loss: 0.304194; batch adversarial loss: 0.517939\n",
      "epoch 18; iter: 400; batch classifier loss: 0.487958; batch adversarial loss: 0.588434\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397710; batch adversarial loss: 0.601328\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316460; batch adversarial loss: 0.691200\n",
      "epoch 19; iter: 400; batch classifier loss: 0.373287; batch adversarial loss: 0.643808\n",
      "epoch 20; iter: 0; batch classifier loss: 0.389931; batch adversarial loss: 0.651247\n",
      "epoch 20; iter: 200; batch classifier loss: 0.424298; batch adversarial loss: 0.656167\n",
      "epoch 20; iter: 400; batch classifier loss: 0.351667; batch adversarial loss: 0.594295\n",
      "epoch 21; iter: 0; batch classifier loss: 0.377810; batch adversarial loss: 0.624740\n",
      "epoch 21; iter: 200; batch classifier loss: 0.509074; batch adversarial loss: 0.691193\n",
      "epoch 21; iter: 400; batch classifier loss: 0.420893; batch adversarial loss: 0.677789\n",
      "epoch 22; iter: 0; batch classifier loss: 0.445271; batch adversarial loss: 0.580734\n",
      "epoch 22; iter: 200; batch classifier loss: 0.478001; batch adversarial loss: 0.623643\n",
      "epoch 22; iter: 400; batch classifier loss: 0.352698; batch adversarial loss: 0.606180\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486197; batch adversarial loss: 0.557715\n",
      "epoch 23; iter: 200; batch classifier loss: 0.402858; batch adversarial loss: 0.676394\n",
      "epoch 23; iter: 400; batch classifier loss: 0.504586; batch adversarial loss: 0.564723\n",
      "epoch 24; iter: 0; batch classifier loss: 0.185929; batch adversarial loss: 0.620329\n",
      "epoch 24; iter: 200; batch classifier loss: 0.370661; batch adversarial loss: 0.603509\n",
      "epoch 24; iter: 400; batch classifier loss: 0.357035; batch adversarial loss: 0.590966\n",
      "epoch 25; iter: 0; batch classifier loss: 0.315468; batch adversarial loss: 0.746554\n",
      "epoch 25; iter: 200; batch classifier loss: 0.395829; batch adversarial loss: 0.646576\n",
      "epoch 25; iter: 400; batch classifier loss: 0.232147; batch adversarial loss: 0.671592\n",
      "epoch 26; iter: 0; batch classifier loss: 0.514646; batch adversarial loss: 0.584678\n",
      "epoch 26; iter: 200; batch classifier loss: 0.347571; batch adversarial loss: 0.603372\n",
      "epoch 26; iter: 400; batch classifier loss: 0.657211; batch adversarial loss: 0.637223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.450173; batch adversarial loss: 0.633121\n",
      "epoch 27; iter: 200; batch classifier loss: 0.572114; batch adversarial loss: 0.690733\n",
      "epoch 27; iter: 400; batch classifier loss: 0.194469; batch adversarial loss: 0.613013\n",
      "epoch 28; iter: 0; batch classifier loss: 0.417778; batch adversarial loss: 0.563904\n",
      "epoch 28; iter: 200; batch classifier loss: 0.366546; batch adversarial loss: 0.598587\n",
      "epoch 28; iter: 400; batch classifier loss: 0.317588; batch adversarial loss: 0.670021\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258737; batch adversarial loss: 0.625923\n",
      "epoch 29; iter: 200; batch classifier loss: 0.384844; batch adversarial loss: 0.552095\n",
      "epoch 29; iter: 400; batch classifier loss: 0.482832; batch adversarial loss: 0.624529\n",
      "epoch 30; iter: 0; batch classifier loss: 0.359630; batch adversarial loss: 0.646268\n",
      "epoch 30; iter: 200; batch classifier loss: 0.225136; batch adversarial loss: 0.707581\n",
      "epoch 30; iter: 400; batch classifier loss: 0.383913; batch adversarial loss: 0.668848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.378042; batch adversarial loss: 0.677981\n",
      "epoch 31; iter: 200; batch classifier loss: 0.446656; batch adversarial loss: 0.493667\n",
      "epoch 31; iter: 400; batch classifier loss: 0.521855; batch adversarial loss: 0.657126\n",
      "epoch 32; iter: 0; batch classifier loss: 0.251613; batch adversarial loss: 0.581722\n",
      "epoch 32; iter: 200; batch classifier loss: 0.495071; batch adversarial loss: 0.635105\n",
      "epoch 32; iter: 400; batch classifier loss: 0.438166; batch adversarial loss: 0.609662\n",
      "epoch 33; iter: 0; batch classifier loss: 0.255108; batch adversarial loss: 0.650333\n",
      "epoch 33; iter: 200; batch classifier loss: 0.319543; batch adversarial loss: 0.655728\n",
      "epoch 33; iter: 400; batch classifier loss: 0.372874; batch adversarial loss: 0.614646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.604503; batch adversarial loss: 0.668028\n",
      "epoch 34; iter: 200; batch classifier loss: 0.440001; batch adversarial loss: 0.598777\n",
      "epoch 34; iter: 400; batch classifier loss: 0.210369; batch adversarial loss: 0.662829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.210077; batch adversarial loss: 0.654921\n",
      "epoch 35; iter: 200; batch classifier loss: 0.349401; batch adversarial loss: 0.680494\n",
      "epoch 35; iter: 400; batch classifier loss: 0.374849; batch adversarial loss: 0.677621\n",
      "epoch 36; iter: 0; batch classifier loss: 0.611367; batch adversarial loss: 0.559774\n",
      "epoch 36; iter: 200; batch classifier loss: 0.327130; batch adversarial loss: 0.687443\n",
      "epoch 36; iter: 400; batch classifier loss: 0.330600; batch adversarial loss: 0.611533\n",
      "epoch 37; iter: 0; batch classifier loss: 0.464510; batch adversarial loss: 0.640034\n",
      "epoch 37; iter: 200; batch classifier loss: 0.563372; batch adversarial loss: 0.587958\n",
      "epoch 37; iter: 400; batch classifier loss: 0.389718; batch adversarial loss: 0.571041\n",
      "epoch 38; iter: 0; batch classifier loss: 0.288993; batch adversarial loss: 0.609687\n",
      "epoch 38; iter: 200; batch classifier loss: 0.356730; batch adversarial loss: 0.706658\n",
      "epoch 38; iter: 400; batch classifier loss: 0.350840; batch adversarial loss: 0.630522\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499128; batch adversarial loss: 0.593003\n",
      "epoch 39; iter: 200; batch classifier loss: 0.589815; batch adversarial loss: 0.691642\n",
      "epoch 39; iter: 400; batch classifier loss: 0.620797; batch adversarial loss: 0.571304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.306966; batch adversarial loss: 0.670854\n",
      "epoch 40; iter: 200; batch classifier loss: 0.404529; batch adversarial loss: 0.636750\n",
      "epoch 40; iter: 400; batch classifier loss: 0.768945; batch adversarial loss: 0.651736\n",
      "epoch 41; iter: 0; batch classifier loss: 0.282166; batch adversarial loss: 0.669832\n",
      "epoch 41; iter: 200; batch classifier loss: 0.587642; batch adversarial loss: 0.659262\n",
      "epoch 41; iter: 400; batch classifier loss: 0.229474; batch adversarial loss: 0.664415\n",
      "epoch 42; iter: 0; batch classifier loss: 0.519808; batch adversarial loss: 0.578314\n",
      "epoch 42; iter: 200; batch classifier loss: 0.353973; batch adversarial loss: 0.615222\n",
      "epoch 42; iter: 400; batch classifier loss: 0.562048; batch adversarial loss: 0.575016\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390252; batch adversarial loss: 0.603390\n",
      "epoch 43; iter: 200; batch classifier loss: 0.373071; batch adversarial loss: 0.617621\n",
      "epoch 43; iter: 400; batch classifier loss: 0.573546; batch adversarial loss: 0.645493\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388235; batch adversarial loss: 0.655554\n",
      "epoch 44; iter: 200; batch classifier loss: 0.453330; batch adversarial loss: 0.722838\n",
      "epoch 44; iter: 400; batch classifier loss: 0.595408; batch adversarial loss: 0.650230\n",
      "epoch 45; iter: 0; batch classifier loss: 0.609188; batch adversarial loss: 0.566583\n",
      "epoch 45; iter: 200; batch classifier loss: 0.368193; batch adversarial loss: 0.609277\n",
      "epoch 45; iter: 400; batch classifier loss: 0.402462; batch adversarial loss: 0.593061\n",
      "epoch 46; iter: 0; batch classifier loss: 0.310569; batch adversarial loss: 0.595728\n",
      "epoch 46; iter: 200; batch classifier loss: 0.232671; batch adversarial loss: 0.582819\n",
      "epoch 46; iter: 400; batch classifier loss: 0.488260; batch adversarial loss: 0.584554\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484867; batch adversarial loss: 0.610036\n",
      "epoch 47; iter: 200; batch classifier loss: 0.499879; batch adversarial loss: 0.692381\n",
      "epoch 47; iter: 400; batch classifier loss: 0.533424; batch adversarial loss: 0.628260\n",
      "epoch 48; iter: 0; batch classifier loss: 0.879320; batch adversarial loss: 0.629500\n",
      "epoch 48; iter: 200; batch classifier loss: 0.535072; batch adversarial loss: 0.675606\n",
      "epoch 48; iter: 400; batch classifier loss: 0.401222; batch adversarial loss: 0.665943\n",
      "epoch 49; iter: 0; batch classifier loss: 0.219753; batch adversarial loss: 0.629645\n",
      "epoch 49; iter: 200; batch classifier loss: 0.255176; batch adversarial loss: 0.572916\n",
      "epoch 49; iter: 400; batch classifier loss: 0.506381; batch adversarial loss: 0.649514\n",
      "epoch 0; iter: 0; batch classifier loss: 22.290691; batch adversarial loss: 0.693075\n",
      "epoch 0; iter: 200; batch classifier loss: 7.963454; batch adversarial loss: 0.664777\n",
      "epoch 0; iter: 400; batch classifier loss: 8.547450; batch adversarial loss: 0.648068\n",
      "epoch 1; iter: 0; batch classifier loss: 2.517495; batch adversarial loss: 0.607489\n",
      "epoch 1; iter: 200; batch classifier loss: 9.211192; batch adversarial loss: 0.594756\n",
      "epoch 1; iter: 400; batch classifier loss: 1.067209; batch adversarial loss: 0.584165\n",
      "epoch 2; iter: 0; batch classifier loss: 2.146595; batch adversarial loss: 0.664718\n",
      "epoch 2; iter: 200; batch classifier loss: 3.715404; batch adversarial loss: 0.675585\n",
      "epoch 2; iter: 400; batch classifier loss: 0.289587; batch adversarial loss: 0.686709\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637424; batch adversarial loss: 0.636529\n",
      "epoch 3; iter: 200; batch classifier loss: 2.379670; batch adversarial loss: 0.561782\n",
      "epoch 3; iter: 400; batch classifier loss: 2.069432; batch adversarial loss: 0.599708\n",
      "epoch 4; iter: 0; batch classifier loss: 2.020547; batch adversarial loss: 0.682972\n",
      "epoch 4; iter: 200; batch classifier loss: 0.758419; batch adversarial loss: 0.562557\n",
      "epoch 4; iter: 400; batch classifier loss: 0.379154; batch adversarial loss: 0.669344\n",
      "epoch 5; iter: 0; batch classifier loss: 0.302746; batch adversarial loss: 0.635723\n",
      "epoch 5; iter: 200; batch classifier loss: 0.481824; batch adversarial loss: 0.633437\n",
      "epoch 5; iter: 400; batch classifier loss: 0.340509; batch adversarial loss: 0.601692\n",
      "epoch 6; iter: 0; batch classifier loss: 0.394821; batch adversarial loss: 0.657356\n",
      "epoch 6; iter: 200; batch classifier loss: 0.815212; batch adversarial loss: 0.626151\n",
      "epoch 6; iter: 400; batch classifier loss: 0.381896; batch adversarial loss: 0.656898\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594107; batch adversarial loss: 0.629724\n",
      "epoch 7; iter: 200; batch classifier loss: 0.362985; batch adversarial loss: 0.611194\n",
      "epoch 7; iter: 400; batch classifier loss: 0.588961; batch adversarial loss: 0.681154\n",
      "epoch 8; iter: 0; batch classifier loss: 0.944397; batch adversarial loss: 0.650731\n",
      "epoch 8; iter: 200; batch classifier loss: 0.490212; batch adversarial loss: 0.686020\n",
      "epoch 8; iter: 400; batch classifier loss: 0.316389; batch adversarial loss: 0.582438\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242193; batch adversarial loss: 0.702850\n",
      "epoch 9; iter: 200; batch classifier loss: 0.483911; batch adversarial loss: 0.668237\n",
      "epoch 9; iter: 400; batch classifier loss: 0.355513; batch adversarial loss: 0.631152\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371404; batch adversarial loss: 0.627499\n",
      "epoch 10; iter: 200; batch classifier loss: 0.325709; batch adversarial loss: 0.660248\n",
      "epoch 10; iter: 400; batch classifier loss: 0.548680; batch adversarial loss: 0.621208\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456723; batch adversarial loss: 0.561023\n",
      "epoch 11; iter: 200; batch classifier loss: 0.276570; batch adversarial loss: 0.576663\n",
      "epoch 11; iter: 400; batch classifier loss: 0.252381; batch adversarial loss: 0.595700\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383775; batch adversarial loss: 0.635651\n",
      "epoch 12; iter: 200; batch classifier loss: 0.277801; batch adversarial loss: 0.565464\n",
      "epoch 12; iter: 400; batch classifier loss: 0.263995; batch adversarial loss: 0.685133\n",
      "epoch 13; iter: 0; batch classifier loss: 0.322509; batch adversarial loss: 0.653186\n",
      "epoch 13; iter: 200; batch classifier loss: 0.408670; batch adversarial loss: 0.622903\n",
      "epoch 13; iter: 400; batch classifier loss: 0.498985; batch adversarial loss: 0.649782\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286609; batch adversarial loss: 0.553294\n",
      "epoch 14; iter: 200; batch classifier loss: 0.269434; batch adversarial loss: 0.544537\n",
      "epoch 14; iter: 400; batch classifier loss: 0.235061; batch adversarial loss: 0.648755\n",
      "epoch 15; iter: 0; batch classifier loss: 0.153884; batch adversarial loss: 0.596229\n",
      "epoch 15; iter: 200; batch classifier loss: 0.719032; batch adversarial loss: 0.619600\n",
      "epoch 15; iter: 400; batch classifier loss: 0.964313; batch adversarial loss: 0.710888\n",
      "epoch 16; iter: 0; batch classifier loss: 0.517932; batch adversarial loss: 0.644732\n",
      "epoch 16; iter: 200; batch classifier loss: 0.326247; batch adversarial loss: 0.645094\n",
      "epoch 16; iter: 400; batch classifier loss: 0.427109; batch adversarial loss: 0.674039\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368048; batch adversarial loss: 0.578268\n",
      "epoch 17; iter: 200; batch classifier loss: 0.433342; batch adversarial loss: 0.595731\n",
      "epoch 17; iter: 400; batch classifier loss: 0.321187; batch adversarial loss: 0.643673\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384443; batch adversarial loss: 0.607720\n",
      "epoch 18; iter: 200; batch classifier loss: 0.426403; batch adversarial loss: 0.570761\n",
      "epoch 18; iter: 400; batch classifier loss: 0.279647; batch adversarial loss: 0.618954\n",
      "epoch 19; iter: 0; batch classifier loss: 0.782627; batch adversarial loss: 0.625877\n",
      "epoch 19; iter: 200; batch classifier loss: 0.449551; batch adversarial loss: 0.607742\n",
      "epoch 19; iter: 400; batch classifier loss: 0.501468; batch adversarial loss: 0.601649\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480122; batch adversarial loss: 0.574191\n",
      "epoch 20; iter: 200; batch classifier loss: 0.348859; batch adversarial loss: 0.601819\n",
      "epoch 20; iter: 400; batch classifier loss: 0.379994; batch adversarial loss: 0.597587\n",
      "epoch 21; iter: 0; batch classifier loss: 0.393312; batch adversarial loss: 0.609911\n",
      "epoch 21; iter: 200; batch classifier loss: 0.522466; batch adversarial loss: 0.617965\n",
      "epoch 21; iter: 400; batch classifier loss: 0.315161; batch adversarial loss: 0.656894\n",
      "epoch 22; iter: 0; batch classifier loss: 0.336221; batch adversarial loss: 0.671539\n",
      "epoch 22; iter: 200; batch classifier loss: 0.525134; batch adversarial loss: 0.607896\n",
      "epoch 22; iter: 400; batch classifier loss: 0.304826; batch adversarial loss: 0.672922\n",
      "epoch 23; iter: 0; batch classifier loss: 0.304860; batch adversarial loss: 0.661159\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374987; batch adversarial loss: 0.653661\n",
      "epoch 23; iter: 400; batch classifier loss: 0.269873; batch adversarial loss: 0.681574\n",
      "epoch 24; iter: 0; batch classifier loss: 0.348013; batch adversarial loss: 0.587854\n",
      "epoch 24; iter: 200; batch classifier loss: 0.247643; batch adversarial loss: 0.658953\n",
      "epoch 24; iter: 400; batch classifier loss: 0.594925; batch adversarial loss: 0.560317\n",
      "epoch 25; iter: 0; batch classifier loss: 0.302556; batch adversarial loss: 0.594703\n",
      "epoch 25; iter: 200; batch classifier loss: 0.320832; batch adversarial loss: 0.608329\n",
      "epoch 25; iter: 400; batch classifier loss: 0.561949; batch adversarial loss: 0.620726\n",
      "epoch 26; iter: 0; batch classifier loss: 0.439081; batch adversarial loss: 0.675281\n",
      "epoch 26; iter: 200; batch classifier loss: 0.351246; batch adversarial loss: 0.618743\n",
      "epoch 26; iter: 400; batch classifier loss: 0.318784; batch adversarial loss: 0.636914\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443275; batch adversarial loss: 0.594941\n",
      "epoch 27; iter: 200; batch classifier loss: 0.426382; batch adversarial loss: 0.649706\n",
      "epoch 27; iter: 400; batch classifier loss: 0.506185; batch adversarial loss: 0.654848\n",
      "epoch 28; iter: 0; batch classifier loss: 0.423282; batch adversarial loss: 0.613867\n",
      "epoch 28; iter: 200; batch classifier loss: 0.369504; batch adversarial loss: 0.661370\n",
      "epoch 28; iter: 400; batch classifier loss: 0.379865; batch adversarial loss: 0.653819\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439302; batch adversarial loss: 0.635810\n",
      "epoch 29; iter: 200; batch classifier loss: 0.470629; batch adversarial loss: 0.596509\n",
      "epoch 29; iter: 400; batch classifier loss: 0.386198; batch adversarial loss: 0.589714\n",
      "epoch 30; iter: 0; batch classifier loss: 0.608814; batch adversarial loss: 0.536771\n",
      "epoch 30; iter: 200; batch classifier loss: 0.424263; batch adversarial loss: 0.619874\n",
      "epoch 30; iter: 400; batch classifier loss: 0.267534; batch adversarial loss: 0.594386\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464354; batch adversarial loss: 0.589804\n",
      "epoch 31; iter: 200; batch classifier loss: 0.495168; batch adversarial loss: 0.640829\n",
      "epoch 31; iter: 400; batch classifier loss: 0.197616; batch adversarial loss: 0.662051\n",
      "epoch 32; iter: 0; batch classifier loss: 0.362745; batch adversarial loss: 0.562139\n",
      "epoch 32; iter: 200; batch classifier loss: 0.535865; batch adversarial loss: 0.740617\n",
      "epoch 32; iter: 400; batch classifier loss: 0.170048; batch adversarial loss: 0.720543\n",
      "epoch 33; iter: 0; batch classifier loss: 0.492057; batch adversarial loss: 0.637607\n",
      "epoch 33; iter: 200; batch classifier loss: 0.380678; batch adversarial loss: 0.724219\n",
      "epoch 33; iter: 400; batch classifier loss: 0.548934; batch adversarial loss: 0.645514\n",
      "epoch 34; iter: 0; batch classifier loss: 0.617851; batch adversarial loss: 0.683592\n",
      "epoch 34; iter: 200; batch classifier loss: 0.410676; batch adversarial loss: 0.637757\n",
      "epoch 34; iter: 400; batch classifier loss: 0.521902; batch adversarial loss: 0.610689\n",
      "epoch 35; iter: 0; batch classifier loss: 0.370895; batch adversarial loss: 0.647111\n",
      "epoch 35; iter: 200; batch classifier loss: 0.408871; batch adversarial loss: 0.616675\n",
      "epoch 35; iter: 400; batch classifier loss: 0.425129; batch adversarial loss: 0.609465\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347130; batch adversarial loss: 0.594556\n",
      "epoch 36; iter: 200; batch classifier loss: 0.361308; batch adversarial loss: 0.622986\n",
      "epoch 36; iter: 400; batch classifier loss: 0.757759; batch adversarial loss: 0.626370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.336048; batch adversarial loss: 0.560133\n",
      "epoch 37; iter: 200; batch classifier loss: 0.372763; batch adversarial loss: 0.614125\n",
      "epoch 37; iter: 400; batch classifier loss: 0.427720; batch adversarial loss: 0.568681\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437894; batch adversarial loss: 0.602527\n",
      "epoch 38; iter: 200; batch classifier loss: 0.523762; batch adversarial loss: 0.624321\n",
      "epoch 38; iter: 400; batch classifier loss: 0.548679; batch adversarial loss: 0.635942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485564; batch adversarial loss: 0.583168\n",
      "epoch 39; iter: 200; batch classifier loss: 0.345526; batch adversarial loss: 0.602975\n",
      "epoch 39; iter: 400; batch classifier loss: 0.497890; batch adversarial loss: 0.653810\n",
      "epoch 40; iter: 0; batch classifier loss: 0.740858; batch adversarial loss: 0.670646\n",
      "epoch 40; iter: 200; batch classifier loss: 0.304929; batch adversarial loss: 0.638727\n",
      "epoch 40; iter: 400; batch classifier loss: 0.395265; batch adversarial loss: 0.675786\n",
      "epoch 41; iter: 0; batch classifier loss: 0.316356; batch adversarial loss: 0.635226\n",
      "epoch 41; iter: 200; batch classifier loss: 0.415682; batch adversarial loss: 0.633905\n",
      "epoch 41; iter: 400; batch classifier loss: 0.341475; batch adversarial loss: 0.608109\n",
      "epoch 42; iter: 0; batch classifier loss: 0.169108; batch adversarial loss: 0.640268\n",
      "epoch 42; iter: 200; batch classifier loss: 0.408424; batch adversarial loss: 0.606839\n",
      "epoch 42; iter: 400; batch classifier loss: 0.345250; batch adversarial loss: 0.654567\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449766; batch adversarial loss: 0.588931\n",
      "epoch 43; iter: 200; batch classifier loss: 0.396706; batch adversarial loss: 0.598278\n",
      "epoch 43; iter: 400; batch classifier loss: 0.363903; batch adversarial loss: 0.639474\n",
      "epoch 44; iter: 0; batch classifier loss: 0.798303; batch adversarial loss: 0.648544\n",
      "epoch 44; iter: 200; batch classifier loss: 0.598096; batch adversarial loss: 0.555230\n",
      "epoch 44; iter: 400; batch classifier loss: 0.230615; batch adversarial loss: 0.615051\n",
      "epoch 45; iter: 0; batch classifier loss: 0.306373; batch adversarial loss: 0.570299\n",
      "epoch 45; iter: 200; batch classifier loss: 0.509456; batch adversarial loss: 0.634824\n",
      "epoch 45; iter: 400; batch classifier loss: 0.450414; batch adversarial loss: 0.629303\n",
      "epoch 46; iter: 0; batch classifier loss: 0.325057; batch adversarial loss: 0.650276\n",
      "epoch 46; iter: 200; batch classifier loss: 0.549108; batch adversarial loss: 0.662944\n",
      "epoch 46; iter: 400; batch classifier loss: 0.463313; batch adversarial loss: 0.612257\n",
      "epoch 47; iter: 0; batch classifier loss: 0.254512; batch adversarial loss: 0.644678\n",
      "epoch 47; iter: 200; batch classifier loss: 0.633795; batch adversarial loss: 0.656523\n",
      "epoch 47; iter: 400; batch classifier loss: 0.362248; batch adversarial loss: 0.630762\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429439; batch adversarial loss: 0.772219\n",
      "epoch 48; iter: 200; batch classifier loss: 0.379802; batch adversarial loss: 0.640452\n",
      "epoch 48; iter: 400; batch classifier loss: 0.477860; batch adversarial loss: 0.582266\n",
      "epoch 49; iter: 0; batch classifier loss: 0.298252; batch adversarial loss: 0.531768\n",
      "epoch 49; iter: 200; batch classifier loss: 0.272101; batch adversarial loss: 0.650383\n",
      "epoch 49; iter: 400; batch classifier loss: 0.696146; batch adversarial loss: 0.613019\n",
      "epoch 0; iter: 0; batch classifier loss: 25.878193; batch adversarial loss: 0.680335\n",
      "epoch 0; iter: 200; batch classifier loss: 3.966792; batch adversarial loss: 0.653621\n",
      "epoch 0; iter: 400; batch classifier loss: 0.569818; batch adversarial loss: 0.599977\n",
      "epoch 1; iter: 0; batch classifier loss: 13.315355; batch adversarial loss: 0.630755\n",
      "epoch 1; iter: 200; batch classifier loss: 11.369192; batch adversarial loss: 0.606137\n",
      "epoch 1; iter: 400; batch classifier loss: 1.625769; batch adversarial loss: 0.624573\n",
      "epoch 2; iter: 0; batch classifier loss: 3.192382; batch adversarial loss: 0.634834\n",
      "epoch 2; iter: 200; batch classifier loss: 1.395488; batch adversarial loss: 0.696369\n",
      "epoch 2; iter: 400; batch classifier loss: 2.558723; batch adversarial loss: 0.604801\n",
      "epoch 3; iter: 0; batch classifier loss: 5.352626; batch adversarial loss: 0.636352\n",
      "epoch 3; iter: 200; batch classifier loss: 1.745740; batch adversarial loss: 0.663543\n",
      "epoch 3; iter: 400; batch classifier loss: 1.935842; batch adversarial loss: 0.513296\n",
      "epoch 4; iter: 0; batch classifier loss: 1.428764; batch adversarial loss: 0.623547\n",
      "epoch 4; iter: 200; batch classifier loss: 4.789727; batch adversarial loss: 0.660123\n",
      "epoch 4; iter: 400; batch classifier loss: 0.621899; batch adversarial loss: 0.627451\n",
      "epoch 5; iter: 0; batch classifier loss: 0.448572; batch adversarial loss: 0.584495\n",
      "epoch 5; iter: 200; batch classifier loss: 0.273899; batch adversarial loss: 0.652180\n",
      "epoch 5; iter: 400; batch classifier loss: 0.303684; batch adversarial loss: 0.640781\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414602; batch adversarial loss: 0.534727\n",
      "epoch 6; iter: 200; batch classifier loss: 0.455197; batch adversarial loss: 0.595165\n",
      "epoch 6; iter: 400; batch classifier loss: 0.379565; batch adversarial loss: 0.598703\n",
      "epoch 7; iter: 0; batch classifier loss: 0.844299; batch adversarial loss: 0.621652\n",
      "epoch 7; iter: 200; batch classifier loss: 0.730845; batch adversarial loss: 0.632067\n",
      "epoch 7; iter: 400; batch classifier loss: 0.854571; batch adversarial loss: 0.591074\n",
      "epoch 8; iter: 0; batch classifier loss: 0.736102; batch adversarial loss: 0.609202\n",
      "epoch 8; iter: 200; batch classifier loss: 0.462910; batch adversarial loss: 0.643203\n",
      "epoch 8; iter: 400; batch classifier loss: 0.325890; batch adversarial loss: 0.634913\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474894; batch adversarial loss: 0.684304\n",
      "epoch 9; iter: 200; batch classifier loss: 0.603005; batch adversarial loss: 0.669948\n",
      "epoch 9; iter: 400; batch classifier loss: 0.485150; batch adversarial loss: 0.555596\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542917; batch adversarial loss: 0.663793\n",
      "epoch 10; iter: 200; batch classifier loss: 0.688858; batch adversarial loss: 0.609052\n",
      "epoch 10; iter: 400; batch classifier loss: 0.524681; batch adversarial loss: 0.601920\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309458; batch adversarial loss: 0.644787\n",
      "epoch 11; iter: 200; batch classifier loss: 0.462041; batch adversarial loss: 0.578179\n",
      "epoch 11; iter: 400; batch classifier loss: 0.350675; batch adversarial loss: 0.638838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357096; batch adversarial loss: 0.537990\n",
      "epoch 12; iter: 200; batch classifier loss: 0.394689; batch adversarial loss: 0.614602\n",
      "epoch 12; iter: 400; batch classifier loss: 0.503796; batch adversarial loss: 0.568846\n",
      "epoch 13; iter: 0; batch classifier loss: 0.464570; batch adversarial loss: 0.614399\n",
      "epoch 13; iter: 200; batch classifier loss: 0.393549; batch adversarial loss: 0.661146\n",
      "epoch 13; iter: 400; batch classifier loss: 0.431095; batch adversarial loss: 0.561322\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370042; batch adversarial loss: 0.569873\n",
      "epoch 14; iter: 200; batch classifier loss: 0.422033; batch adversarial loss: 0.671340\n",
      "epoch 14; iter: 400; batch classifier loss: 0.381232; batch adversarial loss: 0.543628\n",
      "epoch 15; iter: 0; batch classifier loss: 0.408486; batch adversarial loss: 0.642041\n",
      "epoch 15; iter: 200; batch classifier loss: 0.412121; batch adversarial loss: 0.629779\n",
      "epoch 15; iter: 400; batch classifier loss: 0.361265; batch adversarial loss: 0.654408\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363810; batch adversarial loss: 0.647789\n",
      "epoch 16; iter: 200; batch classifier loss: 0.552747; batch adversarial loss: 0.569701\n",
      "epoch 16; iter: 400; batch classifier loss: 0.284292; batch adversarial loss: 0.665674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339931; batch adversarial loss: 0.649223\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364318; batch adversarial loss: 0.591685\n",
      "epoch 17; iter: 400; batch classifier loss: 0.433760; batch adversarial loss: 0.592901\n",
      "epoch 18; iter: 0; batch classifier loss: 0.412596; batch adversarial loss: 0.552847\n",
      "epoch 18; iter: 200; batch classifier loss: 0.251455; batch adversarial loss: 0.672354\n",
      "epoch 18; iter: 400; batch classifier loss: 0.370871; batch adversarial loss: 0.584936\n",
      "epoch 19; iter: 0; batch classifier loss: 0.348647; batch adversarial loss: 0.691243\n",
      "epoch 19; iter: 200; batch classifier loss: 0.358527; batch adversarial loss: 0.629498\n",
      "epoch 19; iter: 400; batch classifier loss: 0.386801; batch adversarial loss: 0.654787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.354426; batch adversarial loss: 0.589873\n",
      "epoch 20; iter: 200; batch classifier loss: 0.486338; batch adversarial loss: 0.667330\n",
      "epoch 20; iter: 400; batch classifier loss: 0.378759; batch adversarial loss: 0.649865\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336460; batch adversarial loss: 0.688604\n",
      "epoch 21; iter: 200; batch classifier loss: 0.340621; batch adversarial loss: 0.615865\n",
      "epoch 21; iter: 400; batch classifier loss: 0.365938; batch adversarial loss: 0.646161\n",
      "epoch 22; iter: 0; batch classifier loss: 0.272915; batch adversarial loss: 0.696458\n",
      "epoch 22; iter: 200; batch classifier loss: 0.262969; batch adversarial loss: 0.653924\n",
      "epoch 22; iter: 400; batch classifier loss: 0.613939; batch adversarial loss: 0.752597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423247; batch adversarial loss: 0.589262\n",
      "epoch 23; iter: 200; batch classifier loss: 0.353719; batch adversarial loss: 0.653143\n",
      "epoch 23; iter: 400; batch classifier loss: 0.485725; batch adversarial loss: 0.659775\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403950; batch adversarial loss: 0.621847\n",
      "epoch 24; iter: 200; batch classifier loss: 0.224499; batch adversarial loss: 0.581885\n",
      "epoch 24; iter: 400; batch classifier loss: 0.317304; batch adversarial loss: 0.733124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484126; batch adversarial loss: 0.599994\n",
      "epoch 25; iter: 200; batch classifier loss: 0.394538; batch adversarial loss: 0.635073\n",
      "epoch 25; iter: 400; batch classifier loss: 0.570746; batch adversarial loss: 0.571020\n",
      "epoch 26; iter: 0; batch classifier loss: 0.374278; batch adversarial loss: 0.658992\n",
      "epoch 26; iter: 200; batch classifier loss: 0.631290; batch adversarial loss: 0.602050\n",
      "epoch 26; iter: 400; batch classifier loss: 0.471271; batch adversarial loss: 0.642254\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471229; batch adversarial loss: 0.649149\n",
      "epoch 27; iter: 200; batch classifier loss: 0.342255; batch adversarial loss: 0.654420\n",
      "epoch 27; iter: 400; batch classifier loss: 0.338134; batch adversarial loss: 0.663741\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274148; batch adversarial loss: 0.563946\n",
      "epoch 28; iter: 200; batch classifier loss: 0.268298; batch adversarial loss: 0.628209\n",
      "epoch 28; iter: 400; batch classifier loss: 0.359922; batch adversarial loss: 0.660881\n",
      "epoch 29; iter: 0; batch classifier loss: 0.559560; batch adversarial loss: 0.599468\n",
      "epoch 29; iter: 200; batch classifier loss: 0.436929; batch adversarial loss: 0.668965\n",
      "epoch 29; iter: 400; batch classifier loss: 0.302022; batch adversarial loss: 0.604366\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407512; batch adversarial loss: 0.599585\n",
      "epoch 30; iter: 200; batch classifier loss: 0.314260; batch adversarial loss: 0.679447\n",
      "epoch 30; iter: 400; batch classifier loss: 0.235895; batch adversarial loss: 0.614203\n",
      "epoch 31; iter: 0; batch classifier loss: 0.542505; batch adversarial loss: 0.672607\n",
      "epoch 31; iter: 200; batch classifier loss: 0.405842; batch adversarial loss: 0.635072\n",
      "epoch 31; iter: 400; batch classifier loss: 0.277109; batch adversarial loss: 0.725077\n",
      "epoch 32; iter: 0; batch classifier loss: 0.456369; batch adversarial loss: 0.643147\n",
      "epoch 32; iter: 200; batch classifier loss: 0.353295; batch adversarial loss: 0.584398\n",
      "epoch 32; iter: 400; batch classifier loss: 0.435262; batch adversarial loss: 0.679397\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444187; batch adversarial loss: 0.648410\n",
      "epoch 33; iter: 200; batch classifier loss: 0.355930; batch adversarial loss: 0.563236\n",
      "epoch 33; iter: 400; batch classifier loss: 0.438642; batch adversarial loss: 0.619636\n",
      "epoch 34; iter: 0; batch classifier loss: 0.652324; batch adversarial loss: 0.600374\n",
      "epoch 34; iter: 200; batch classifier loss: 0.447210; batch adversarial loss: 0.677509\n",
      "epoch 34; iter: 400; batch classifier loss: 0.439775; batch adversarial loss: 0.649095\n",
      "epoch 35; iter: 0; batch classifier loss: 0.346732; batch adversarial loss: 0.606518\n",
      "epoch 35; iter: 200; batch classifier loss: 0.412434; batch adversarial loss: 0.524961\n",
      "epoch 35; iter: 400; batch classifier loss: 0.232897; batch adversarial loss: 0.668703\n",
      "epoch 36; iter: 0; batch classifier loss: 0.398660; batch adversarial loss: 0.664245\n",
      "epoch 36; iter: 200; batch classifier loss: 0.356545; batch adversarial loss: 0.665835\n",
      "epoch 36; iter: 400; batch classifier loss: 0.586006; batch adversarial loss: 0.660886\n",
      "epoch 37; iter: 0; batch classifier loss: 0.245470; batch adversarial loss: 0.650003\n",
      "epoch 37; iter: 200; batch classifier loss: 0.308659; batch adversarial loss: 0.642589\n",
      "epoch 37; iter: 400; batch classifier loss: 0.441658; batch adversarial loss: 0.619316\n",
      "epoch 38; iter: 0; batch classifier loss: 0.374774; batch adversarial loss: 0.647619\n",
      "epoch 38; iter: 200; batch classifier loss: 0.424084; batch adversarial loss: 0.615113\n",
      "epoch 38; iter: 400; batch classifier loss: 0.313115; batch adversarial loss: 0.546790\n",
      "epoch 39; iter: 0; batch classifier loss: 0.477106; batch adversarial loss: 0.752746\n",
      "epoch 39; iter: 200; batch classifier loss: 0.263629; batch adversarial loss: 0.657300\n",
      "epoch 39; iter: 400; batch classifier loss: 0.468348; batch adversarial loss: 0.616343\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246046; batch adversarial loss: 0.600924\n",
      "epoch 40; iter: 200; batch classifier loss: 0.450174; batch adversarial loss: 0.673200\n",
      "epoch 40; iter: 400; batch classifier loss: 0.331125; batch adversarial loss: 0.648854\n",
      "epoch 41; iter: 0; batch classifier loss: 0.496674; batch adversarial loss: 0.637580\n",
      "epoch 41; iter: 200; batch classifier loss: 0.376317; batch adversarial loss: 0.611059\n",
      "epoch 41; iter: 400; batch classifier loss: 0.365459; batch adversarial loss: 0.634620\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417492; batch adversarial loss: 0.592879\n",
      "epoch 42; iter: 200; batch classifier loss: 0.403388; batch adversarial loss: 0.611984\n",
      "epoch 42; iter: 400; batch classifier loss: 0.403321; batch adversarial loss: 0.602973\n",
      "epoch 43; iter: 0; batch classifier loss: 0.332369; batch adversarial loss: 0.525370\n",
      "epoch 43; iter: 200; batch classifier loss: 0.291192; batch adversarial loss: 0.621834\n",
      "epoch 43; iter: 400; batch classifier loss: 0.298136; batch adversarial loss: 0.735296\n",
      "epoch 44; iter: 0; batch classifier loss: 0.788964; batch adversarial loss: 0.576269\n",
      "epoch 44; iter: 200; batch classifier loss: 0.364896; batch adversarial loss: 0.678924\n",
      "epoch 44; iter: 400; batch classifier loss: 0.288880; batch adversarial loss: 0.659536\n",
      "epoch 45; iter: 0; batch classifier loss: 0.618125; batch adversarial loss: 0.569696\n",
      "epoch 45; iter: 200; batch classifier loss: 0.581442; batch adversarial loss: 0.527951\n",
      "epoch 45; iter: 400; batch classifier loss: 0.359456; batch adversarial loss: 0.692158\n",
      "epoch 46; iter: 0; batch classifier loss: 0.618420; batch adversarial loss: 0.602250\n",
      "epoch 46; iter: 200; batch classifier loss: 0.332347; batch adversarial loss: 0.669516\n",
      "epoch 46; iter: 400; batch classifier loss: 0.438392; batch adversarial loss: 0.672132\n",
      "epoch 47; iter: 0; batch classifier loss: 0.344972; batch adversarial loss: 0.570934\n",
      "epoch 47; iter: 200; batch classifier loss: 0.396115; batch adversarial loss: 0.647542\n",
      "epoch 47; iter: 400; batch classifier loss: 0.694985; batch adversarial loss: 0.617921\n",
      "epoch 48; iter: 0; batch classifier loss: 0.316613; batch adversarial loss: 0.595132\n",
      "epoch 48; iter: 200; batch classifier loss: 0.460985; batch adversarial loss: 0.671574\n",
      "epoch 48; iter: 400; batch classifier loss: 0.478360; batch adversarial loss: 0.610401\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385383; batch adversarial loss: 0.634916\n",
      "epoch 49; iter: 200; batch classifier loss: 0.349353; batch adversarial loss: 0.630857\n",
      "epoch 49; iter: 400; batch classifier loss: 0.499988; batch adversarial loss: 0.670040\n",
      "epoch 0; iter: 0; batch classifier loss: 53.445980; batch adversarial loss: 0.675297\n",
      "epoch 0; iter: 200; batch classifier loss: 6.376499; batch adversarial loss: 0.620689\n",
      "epoch 0; iter: 400; batch classifier loss: 15.615064; batch adversarial loss: 0.658905\n",
      "epoch 1; iter: 0; batch classifier loss: 3.887001; batch adversarial loss: 0.543922\n",
      "epoch 1; iter: 200; batch classifier loss: 3.237823; batch adversarial loss: 0.571751\n",
      "epoch 1; iter: 400; batch classifier loss: 3.152999; batch adversarial loss: 0.631139\n",
      "epoch 2; iter: 0; batch classifier loss: 0.865807; batch adversarial loss: 0.654361\n",
      "epoch 2; iter: 200; batch classifier loss: 4.130529; batch adversarial loss: 0.657607\n",
      "epoch 2; iter: 400; batch classifier loss: 2.577441; batch adversarial loss: 0.656812\n",
      "epoch 3; iter: 0; batch classifier loss: 1.136948; batch adversarial loss: 0.541461\n",
      "epoch 3; iter: 200; batch classifier loss: 0.502049; batch adversarial loss: 0.663719\n",
      "epoch 3; iter: 400; batch classifier loss: 0.738315; batch adversarial loss: 0.673968\n",
      "epoch 4; iter: 0; batch classifier loss: 2.540831; batch adversarial loss: 0.606999\n",
      "epoch 4; iter: 200; batch classifier loss: 1.077700; batch adversarial loss: 0.658025\n",
      "epoch 4; iter: 400; batch classifier loss: 0.701216; batch adversarial loss: 0.590349\n",
      "epoch 5; iter: 0; batch classifier loss: 1.438910; batch adversarial loss: 0.648459\n",
      "epoch 5; iter: 200; batch classifier loss: 0.336868; batch adversarial loss: 0.612491\n",
      "epoch 5; iter: 400; batch classifier loss: 0.642672; batch adversarial loss: 0.603748\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524451; batch adversarial loss: 0.686126\n",
      "epoch 6; iter: 200; batch classifier loss: 0.410452; batch adversarial loss: 0.534864\n",
      "epoch 6; iter: 400; batch classifier loss: 0.445368; batch adversarial loss: 0.621945\n",
      "epoch 7; iter: 0; batch classifier loss: 0.254081; batch adversarial loss: 0.672731\n",
      "epoch 7; iter: 200; batch classifier loss: 0.452666; batch adversarial loss: 0.691119\n",
      "epoch 7; iter: 400; batch classifier loss: 0.371565; batch adversarial loss: 0.648525\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537413; batch adversarial loss: 0.683456\n",
      "epoch 8; iter: 200; batch classifier loss: 0.600375; batch adversarial loss: 0.740012\n",
      "epoch 8; iter: 400; batch classifier loss: 0.473604; batch adversarial loss: 0.607233\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574929; batch adversarial loss: 0.626178\n",
      "epoch 9; iter: 200; batch classifier loss: 0.504685; batch adversarial loss: 0.657748\n",
      "epoch 9; iter: 400; batch classifier loss: 0.421712; batch adversarial loss: 0.626441\n",
      "epoch 10; iter: 0; batch classifier loss: 0.452904; batch adversarial loss: 0.601033\n",
      "epoch 10; iter: 200; batch classifier loss: 0.528800; batch adversarial loss: 0.590979\n",
      "epoch 10; iter: 400; batch classifier loss: 0.286958; batch adversarial loss: 0.607047\n",
      "epoch 11; iter: 0; batch classifier loss: 0.382161; batch adversarial loss: 0.611678\n",
      "epoch 11; iter: 200; batch classifier loss: 0.353702; batch adversarial loss: 0.633926\n",
      "epoch 11; iter: 400; batch classifier loss: 0.370389; batch adversarial loss: 0.616741\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343464; batch adversarial loss: 0.653044\n",
      "epoch 12; iter: 200; batch classifier loss: 0.440525; batch adversarial loss: 0.617091\n",
      "epoch 12; iter: 400; batch classifier loss: 0.298524; batch adversarial loss: 0.622859\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483428; batch adversarial loss: 0.639635\n",
      "epoch 13; iter: 200; batch classifier loss: 0.478996; batch adversarial loss: 0.579102\n",
      "epoch 13; iter: 400; batch classifier loss: 0.312217; batch adversarial loss: 0.680016\n",
      "epoch 14; iter: 0; batch classifier loss: 0.411209; batch adversarial loss: 0.658598\n",
      "epoch 14; iter: 200; batch classifier loss: 0.332874; batch adversarial loss: 0.559924\n",
      "epoch 14; iter: 400; batch classifier loss: 0.275756; batch adversarial loss: 0.563328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376349; batch adversarial loss: 0.586389\n",
      "epoch 15; iter: 200; batch classifier loss: 0.365601; batch adversarial loss: 0.690105\n",
      "epoch 15; iter: 400; batch classifier loss: 0.438672; batch adversarial loss: 0.510244\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260412; batch adversarial loss: 0.637521\n",
      "epoch 16; iter: 200; batch classifier loss: 0.391698; batch adversarial loss: 0.612039\n",
      "epoch 16; iter: 400; batch classifier loss: 0.324788; batch adversarial loss: 0.707060\n",
      "epoch 17; iter: 0; batch classifier loss: 0.580910; batch adversarial loss: 0.615286\n",
      "epoch 17; iter: 200; batch classifier loss: 0.395806; batch adversarial loss: 0.574222\n",
      "epoch 17; iter: 400; batch classifier loss: 0.365212; batch adversarial loss: 0.714728\n",
      "epoch 18; iter: 0; batch classifier loss: 0.555106; batch adversarial loss: 0.649656\n",
      "epoch 18; iter: 200; batch classifier loss: 0.409969; batch adversarial loss: 0.668053\n",
      "epoch 18; iter: 400; batch classifier loss: 0.510039; batch adversarial loss: 0.594203\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356121; batch adversarial loss: 0.576065\n",
      "epoch 19; iter: 200; batch classifier loss: 0.532355; batch adversarial loss: 0.682165\n",
      "epoch 19; iter: 400; batch classifier loss: 0.396360; batch adversarial loss: 0.629588\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494134; batch adversarial loss: 0.608018\n",
      "epoch 20; iter: 200; batch classifier loss: 0.493065; batch adversarial loss: 0.673775\n",
      "epoch 20; iter: 400; batch classifier loss: 0.401378; batch adversarial loss: 0.589828\n",
      "epoch 21; iter: 0; batch classifier loss: 0.485625; batch adversarial loss: 0.607829\n",
      "epoch 21; iter: 200; batch classifier loss: 0.501224; batch adversarial loss: 0.663255\n",
      "epoch 21; iter: 400; batch classifier loss: 0.377093; batch adversarial loss: 0.678160\n",
      "epoch 22; iter: 0; batch classifier loss: 0.388052; batch adversarial loss: 0.606491\n",
      "epoch 22; iter: 200; batch classifier loss: 0.588673; batch adversarial loss: 0.608216\n",
      "epoch 22; iter: 400; batch classifier loss: 0.303927; batch adversarial loss: 0.662087\n",
      "epoch 23; iter: 0; batch classifier loss: 0.274218; batch adversarial loss: 0.645604\n",
      "epoch 23; iter: 200; batch classifier loss: 0.470805; batch adversarial loss: 0.605794\n",
      "epoch 23; iter: 400; batch classifier loss: 0.403316; batch adversarial loss: 0.706465\n",
      "epoch 24; iter: 0; batch classifier loss: 0.388141; batch adversarial loss: 0.634625\n",
      "epoch 24; iter: 200; batch classifier loss: 0.381153; batch adversarial loss: 0.576604\n",
      "epoch 24; iter: 400; batch classifier loss: 0.337741; batch adversarial loss: 0.586479\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443205; batch adversarial loss: 0.572474\n",
      "epoch 25; iter: 200; batch classifier loss: 0.509499; batch adversarial loss: 0.647857\n",
      "epoch 25; iter: 400; batch classifier loss: 0.623928; batch adversarial loss: 0.667837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329346; batch adversarial loss: 0.647005\n",
      "epoch 26; iter: 200; batch classifier loss: 0.466131; batch adversarial loss: 0.626427\n",
      "epoch 26; iter: 400; batch classifier loss: 0.375423; batch adversarial loss: 0.630563\n",
      "epoch 27; iter: 0; batch classifier loss: 0.393255; batch adversarial loss: 0.651914\n",
      "epoch 27; iter: 200; batch classifier loss: 0.322531; batch adversarial loss: 0.663550\n",
      "epoch 27; iter: 400; batch classifier loss: 0.422054; batch adversarial loss: 0.641110\n",
      "epoch 28; iter: 0; batch classifier loss: 0.366182; batch adversarial loss: 0.695860\n",
      "epoch 28; iter: 200; batch classifier loss: 0.373735; batch adversarial loss: 0.657755\n",
      "epoch 28; iter: 400; batch classifier loss: 0.516761; batch adversarial loss: 0.599725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.570500; batch adversarial loss: 0.590268\n",
      "epoch 29; iter: 200; batch classifier loss: 0.471484; batch adversarial loss: 0.600834\n",
      "epoch 29; iter: 400; batch classifier loss: 0.328858; batch adversarial loss: 0.629335\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513195; batch adversarial loss: 0.676301\n",
      "epoch 30; iter: 200; batch classifier loss: 0.335884; batch adversarial loss: 0.624057\n",
      "epoch 30; iter: 400; batch classifier loss: 0.588769; batch adversarial loss: 0.608874\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463335; batch adversarial loss: 0.589077\n",
      "epoch 31; iter: 200; batch classifier loss: 0.364289; batch adversarial loss: 0.568229\n",
      "epoch 31; iter: 400; batch classifier loss: 0.442072; batch adversarial loss: 0.643301\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441481; batch adversarial loss: 0.664736\n",
      "epoch 32; iter: 200; batch classifier loss: 0.653736; batch adversarial loss: 0.541688\n",
      "epoch 32; iter: 400; batch classifier loss: 0.314259; batch adversarial loss: 0.632543\n",
      "epoch 33; iter: 0; batch classifier loss: 0.378265; batch adversarial loss: 0.569910\n",
      "epoch 33; iter: 200; batch classifier loss: 0.420659; batch adversarial loss: 0.613504\n",
      "epoch 33; iter: 400; batch classifier loss: 0.418690; batch adversarial loss: 0.607895\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310071; batch adversarial loss: 0.577327\n",
      "epoch 34; iter: 200; batch classifier loss: 0.568995; batch adversarial loss: 0.712456\n",
      "epoch 34; iter: 400; batch classifier loss: 0.327103; batch adversarial loss: 0.640910\n",
      "epoch 35; iter: 0; batch classifier loss: 0.443443; batch adversarial loss: 0.599152\n",
      "epoch 35; iter: 200; batch classifier loss: 0.326695; batch adversarial loss: 0.638114\n",
      "epoch 35; iter: 400; batch classifier loss: 0.358822; batch adversarial loss: 0.636829\n",
      "epoch 36; iter: 0; batch classifier loss: 0.445011; batch adversarial loss: 0.609966\n",
      "epoch 36; iter: 200; batch classifier loss: 0.388884; batch adversarial loss: 0.668136\n",
      "epoch 36; iter: 400; batch classifier loss: 0.411181; batch adversarial loss: 0.693055\n",
      "epoch 37; iter: 0; batch classifier loss: 0.478786; batch adversarial loss: 0.585624\n",
      "epoch 37; iter: 200; batch classifier loss: 0.371736; batch adversarial loss: 0.624206\n",
      "epoch 37; iter: 400; batch classifier loss: 0.444129; batch adversarial loss: 0.631980\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381959; batch adversarial loss: 0.658717\n",
      "epoch 38; iter: 200; batch classifier loss: 0.519920; batch adversarial loss: 0.676108\n",
      "epoch 38; iter: 400; batch classifier loss: 0.517518; batch adversarial loss: 0.613607\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448970; batch adversarial loss: 0.569266\n",
      "epoch 39; iter: 200; batch classifier loss: 0.200291; batch adversarial loss: 0.622963\n",
      "epoch 39; iter: 400; batch classifier loss: 0.360197; batch adversarial loss: 0.675685\n",
      "epoch 40; iter: 0; batch classifier loss: 0.517158; batch adversarial loss: 0.625537\n",
      "epoch 40; iter: 200; batch classifier loss: 0.377431; batch adversarial loss: 0.640932\n",
      "epoch 40; iter: 400; batch classifier loss: 0.521860; batch adversarial loss: 0.726680\n",
      "epoch 41; iter: 0; batch classifier loss: 0.641409; batch adversarial loss: 0.607279\n",
      "epoch 41; iter: 200; batch classifier loss: 0.309123; batch adversarial loss: 0.668898\n",
      "epoch 41; iter: 400; batch classifier loss: 0.321477; batch adversarial loss: 0.640678\n",
      "epoch 42; iter: 0; batch classifier loss: 0.238333; batch adversarial loss: 0.653397\n",
      "epoch 42; iter: 200; batch classifier loss: 0.445169; batch adversarial loss: 0.618413\n",
      "epoch 42; iter: 400; batch classifier loss: 0.345042; batch adversarial loss: 0.616415\n",
      "epoch 43; iter: 0; batch classifier loss: 0.282895; batch adversarial loss: 0.573931\n",
      "epoch 43; iter: 200; batch classifier loss: 0.424642; batch adversarial loss: 0.649864\n",
      "epoch 43; iter: 400; batch classifier loss: 0.630404; batch adversarial loss: 0.678634\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437749; batch adversarial loss: 0.674278\n",
      "epoch 44; iter: 200; batch classifier loss: 0.335081; batch adversarial loss: 0.593463\n",
      "epoch 44; iter: 400; batch classifier loss: 1.630922; batch adversarial loss: 0.556786\n",
      "epoch 45; iter: 0; batch classifier loss: 0.302488; batch adversarial loss: 0.602643\n",
      "epoch 45; iter: 200; batch classifier loss: 0.921157; batch adversarial loss: 0.539034\n",
      "epoch 45; iter: 400; batch classifier loss: 0.284693; batch adversarial loss: 0.598387\n",
      "epoch 46; iter: 0; batch classifier loss: 0.473842; batch adversarial loss: 0.661483\n",
      "epoch 46; iter: 200; batch classifier loss: 0.529334; batch adversarial loss: 0.728169\n",
      "epoch 46; iter: 400; batch classifier loss: 0.372635; batch adversarial loss: 0.570190\n",
      "epoch 47; iter: 0; batch classifier loss: 0.364629; batch adversarial loss: 0.556729\n",
      "epoch 47; iter: 200; batch classifier loss: 0.585971; batch adversarial loss: 0.603188\n",
      "epoch 47; iter: 400; batch classifier loss: 0.591717; batch adversarial loss: 0.652919\n",
      "epoch 48; iter: 0; batch classifier loss: 0.581640; batch adversarial loss: 0.643102\n",
      "epoch 48; iter: 200; batch classifier loss: 0.448546; batch adversarial loss: 0.646426\n",
      "epoch 48; iter: 400; batch classifier loss: 0.296034; batch adversarial loss: 0.678067\n",
      "epoch 49; iter: 0; batch classifier loss: 0.549120; batch adversarial loss: 0.609252\n",
      "epoch 49; iter: 200; batch classifier loss: 0.414217; batch adversarial loss: 0.664383\n",
      "epoch 49; iter: 400; batch classifier loss: 0.689458; batch adversarial loss: 0.631922\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 13.181447; batch adversarial loss: 0.698450\n",
      "epoch 0; iter: 200; batch classifier loss: 11.751506; batch adversarial loss: 0.657422\n",
      "epoch 1; iter: 0; batch classifier loss: 24.790802; batch adversarial loss: 0.655397\n",
      "epoch 1; iter: 200; batch classifier loss: 1.427132; batch adversarial loss: 0.650185\n",
      "epoch 2; iter: 0; batch classifier loss: 1.789403; batch adversarial loss: 0.636697\n",
      "epoch 2; iter: 200; batch classifier loss: 1.451687; batch adversarial loss: 0.635176\n",
      "epoch 3; iter: 0; batch classifier loss: 3.168941; batch adversarial loss: 0.638138\n",
      "epoch 3; iter: 200; batch classifier loss: 1.877897; batch adversarial loss: 0.608059\n",
      "epoch 4; iter: 0; batch classifier loss: 0.487395; batch adversarial loss: 0.562178\n",
      "epoch 4; iter: 200; batch classifier loss: 1.168316; batch adversarial loss: 0.616169\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483671; batch adversarial loss: 0.630214\n",
      "epoch 5; iter: 200; batch classifier loss: 0.398785; batch adversarial loss: 0.607934\n",
      "epoch 6; iter: 0; batch classifier loss: 0.329537; batch adversarial loss: 0.633012\n",
      "epoch 6; iter: 200; batch classifier loss: 1.027101; batch adversarial loss: 0.588445\n",
      "epoch 7; iter: 0; batch classifier loss: 0.946637; batch adversarial loss: 0.562585\n",
      "epoch 7; iter: 200; batch classifier loss: 0.606232; batch adversarial loss: 0.631140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550688; batch adversarial loss: 0.597895\n",
      "epoch 8; iter: 200; batch classifier loss: 0.540836; batch adversarial loss: 0.604104\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354365; batch adversarial loss: 0.622620\n",
      "epoch 9; iter: 200; batch classifier loss: 0.649206; batch adversarial loss: 0.666937\n",
      "epoch 0; iter: 0; batch classifier loss: 379.958527; batch adversarial loss: 0.978249\n",
      "epoch 0; iter: 200; batch classifier loss: 11.812895; batch adversarial loss: 0.994215\n",
      "epoch 1; iter: 0; batch classifier loss: 17.126560; batch adversarial loss: 0.879641\n",
      "epoch 1; iter: 200; batch classifier loss: 6.872368; batch adversarial loss: 0.725548\n",
      "epoch 2; iter: 0; batch classifier loss: 4.954139; batch adversarial loss: 0.774864\n",
      "epoch 2; iter: 200; batch classifier loss: 6.496958; batch adversarial loss: 0.741696\n",
      "epoch 3; iter: 0; batch classifier loss: 5.314143; batch adversarial loss: 0.753350\n",
      "epoch 3; iter: 200; batch classifier loss: 1.218733; batch adversarial loss: 0.696808\n",
      "epoch 4; iter: 0; batch classifier loss: 0.790572; batch adversarial loss: 0.597244\n",
      "epoch 4; iter: 200; batch classifier loss: 5.786502; batch adversarial loss: 0.658047\n",
      "epoch 5; iter: 0; batch classifier loss: 1.721118; batch adversarial loss: 0.674087\n",
      "epoch 5; iter: 200; batch classifier loss: 0.965187; batch adversarial loss: 0.672463\n",
      "epoch 6; iter: 0; batch classifier loss: 0.940121; batch adversarial loss: 0.602123\n",
      "epoch 6; iter: 200; batch classifier loss: 0.565231; batch adversarial loss: 0.624658\n",
      "epoch 7; iter: 0; batch classifier loss: 0.798699; batch adversarial loss: 0.591502\n",
      "epoch 7; iter: 200; batch classifier loss: 0.653134; batch adversarial loss: 0.633613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475190; batch adversarial loss: 0.576612\n",
      "epoch 8; iter: 200; batch classifier loss: 0.578017; batch adversarial loss: 0.616205\n",
      "epoch 9; iter: 0; batch classifier loss: 0.607299; batch adversarial loss: 0.607038\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386113; batch adversarial loss: 0.647604\n",
      "epoch 0; iter: 0; batch classifier loss: 13.914451; batch adversarial loss: 0.692225\n",
      "epoch 0; iter: 200; batch classifier loss: 10.814526; batch adversarial loss: 0.669477\n",
      "epoch 1; iter: 0; batch classifier loss: 3.120488; batch adversarial loss: 0.650454\n",
      "epoch 1; iter: 200; batch classifier loss: 8.911385; batch adversarial loss: 0.643961\n",
      "epoch 2; iter: 0; batch classifier loss: 5.834170; batch adversarial loss: 0.617919\n",
      "epoch 2; iter: 200; batch classifier loss: 1.964289; batch adversarial loss: 0.607297\n",
      "epoch 3; iter: 0; batch classifier loss: 4.965097; batch adversarial loss: 0.672876\n",
      "epoch 3; iter: 200; batch classifier loss: 1.111031; batch adversarial loss: 0.619787\n",
      "epoch 4; iter: 0; batch classifier loss: 6.610584; batch adversarial loss: 0.647008\n",
      "epoch 4; iter: 200; batch classifier loss: 0.611371; batch adversarial loss: 0.651369\n",
      "epoch 5; iter: 0; batch classifier loss: 1.425908; batch adversarial loss: 0.676541\n",
      "epoch 5; iter: 200; batch classifier loss: 0.968339; batch adversarial loss: 0.652969\n",
      "epoch 6; iter: 0; batch classifier loss: 1.035495; batch adversarial loss: 0.648260\n",
      "epoch 6; iter: 200; batch classifier loss: 1.178686; batch adversarial loss: 0.577491\n",
      "epoch 7; iter: 0; batch classifier loss: 1.007977; batch adversarial loss: 0.644147\n",
      "epoch 7; iter: 200; batch classifier loss: 0.464766; batch adversarial loss: 0.619099\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512800; batch adversarial loss: 0.648814\n",
      "epoch 8; iter: 200; batch classifier loss: 0.656450; batch adversarial loss: 0.648383\n",
      "epoch 9; iter: 0; batch classifier loss: 1.789634; batch adversarial loss: 0.633893\n",
      "epoch 9; iter: 200; batch classifier loss: 0.451200; batch adversarial loss: 0.669447\n",
      "epoch 0; iter: 0; batch classifier loss: 9.518643; batch adversarial loss: 0.697695\n",
      "epoch 0; iter: 200; batch classifier loss: 6.851501; batch adversarial loss: 0.648324\n",
      "epoch 1; iter: 0; batch classifier loss: 15.191007; batch adversarial loss: 0.659950\n",
      "epoch 1; iter: 200; batch classifier loss: 13.487352; batch adversarial loss: 0.641284\n",
      "epoch 2; iter: 0; batch classifier loss: 19.020924; batch adversarial loss: 0.649358\n",
      "epoch 2; iter: 200; batch classifier loss: 3.277910; batch adversarial loss: 0.602869\n",
      "epoch 3; iter: 0; batch classifier loss: 4.627187; batch adversarial loss: 0.628055\n",
      "epoch 3; iter: 200; batch classifier loss: 0.804251; batch adversarial loss: 0.598122\n",
      "epoch 4; iter: 0; batch classifier loss: 5.860382; batch adversarial loss: 0.658414\n",
      "epoch 4; iter: 200; batch classifier loss: 5.930111; batch adversarial loss: 0.616218\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574624; batch adversarial loss: 0.624992\n",
      "epoch 5; iter: 200; batch classifier loss: 0.400969; batch adversarial loss: 0.594046\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526745; batch adversarial loss: 0.641986\n",
      "epoch 6; iter: 200; batch classifier loss: 1.600727; batch adversarial loss: 0.606811\n",
      "epoch 7; iter: 0; batch classifier loss: 1.012138; batch adversarial loss: 0.641842\n",
      "epoch 7; iter: 200; batch classifier loss: 2.030761; batch adversarial loss: 0.625072\n",
      "epoch 8; iter: 0; batch classifier loss: 1.263237; batch adversarial loss: 0.626541\n",
      "epoch 8; iter: 200; batch classifier loss: 0.774420; batch adversarial loss: 0.634936\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602794; batch adversarial loss: 0.552402\n",
      "epoch 9; iter: 200; batch classifier loss: 1.390557; batch adversarial loss: 0.574023\n",
      "epoch 0; iter: 0; batch classifier loss: 25.047308; batch adversarial loss: 0.632518\n",
      "epoch 0; iter: 200; batch classifier loss: 3.522483; batch adversarial loss: 0.674979\n",
      "epoch 1; iter: 0; batch classifier loss: 8.393992; batch adversarial loss: 0.631605\n",
      "epoch 1; iter: 200; batch classifier loss: 10.716945; batch adversarial loss: 0.633322\n",
      "epoch 2; iter: 0; batch classifier loss: 6.365854; batch adversarial loss: 0.605241\n",
      "epoch 2; iter: 200; batch classifier loss: 3.197805; batch adversarial loss: 0.612913\n",
      "epoch 3; iter: 0; batch classifier loss: 3.265299; batch adversarial loss: 0.656995\n",
      "epoch 3; iter: 200; batch classifier loss: 9.054668; batch adversarial loss: 0.680069\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564976; batch adversarial loss: 0.650406\n",
      "epoch 4; iter: 200; batch classifier loss: 0.628304; batch adversarial loss: 0.666369\n",
      "epoch 5; iter: 0; batch classifier loss: 0.915660; batch adversarial loss: 0.569822\n",
      "epoch 5; iter: 200; batch classifier loss: 1.315493; batch adversarial loss: 0.609274\n",
      "epoch 6; iter: 0; batch classifier loss: 1.354967; batch adversarial loss: 0.607916\n",
      "epoch 6; iter: 200; batch classifier loss: 0.583826; batch adversarial loss: 0.549631\n",
      "epoch 7; iter: 0; batch classifier loss: 0.408330; batch adversarial loss: 0.646523\n",
      "epoch 7; iter: 200; batch classifier loss: 0.678408; batch adversarial loss: 0.608197\n",
      "epoch 8; iter: 0; batch classifier loss: 0.753872; batch adversarial loss: 0.639175\n",
      "epoch 8; iter: 200; batch classifier loss: 0.459290; batch adversarial loss: 0.615986\n",
      "epoch 9; iter: 0; batch classifier loss: 0.387774; batch adversarial loss: 0.638248\n",
      "epoch 9; iter: 200; batch classifier loss: 0.590011; batch adversarial loss: 0.607725\n",
      "epoch 0; iter: 0; batch classifier loss: 24.922970; batch adversarial loss: 0.693898\n",
      "epoch 0; iter: 200; batch classifier loss: 25.009493; batch adversarial loss: 0.632035\n",
      "epoch 1; iter: 0; batch classifier loss: 6.187433; batch adversarial loss: 0.609695\n",
      "epoch 1; iter: 200; batch classifier loss: 1.838986; batch adversarial loss: 0.589201\n",
      "epoch 2; iter: 0; batch classifier loss: 7.103230; batch adversarial loss: 0.611337\n",
      "epoch 2; iter: 200; batch classifier loss: 2.200020; batch adversarial loss: 0.646610\n",
      "epoch 3; iter: 0; batch classifier loss: 3.220834; batch adversarial loss: 0.670596\n",
      "epoch 3; iter: 200; batch classifier loss: 2.404456; batch adversarial loss: 0.651715\n",
      "epoch 4; iter: 0; batch classifier loss: 0.736279; batch adversarial loss: 0.653093\n",
      "epoch 4; iter: 200; batch classifier loss: 6.251507; batch adversarial loss: 0.622141\n",
      "epoch 5; iter: 0; batch classifier loss: 0.407351; batch adversarial loss: 0.584305\n",
      "epoch 5; iter: 200; batch classifier loss: 0.596503; batch adversarial loss: 0.623008\n",
      "epoch 6; iter: 0; batch classifier loss: 0.938257; batch adversarial loss: 0.589183\n",
      "epoch 6; iter: 200; batch classifier loss: 0.556187; batch adversarial loss: 0.638292\n",
      "epoch 7; iter: 0; batch classifier loss: 0.638294; batch adversarial loss: 0.638843\n",
      "epoch 7; iter: 200; batch classifier loss: 0.774880; batch adversarial loss: 0.672868\n",
      "epoch 8; iter: 0; batch classifier loss: 0.477466; batch adversarial loss: 0.629794\n",
      "epoch 8; iter: 200; batch classifier loss: 0.461491; batch adversarial loss: 0.663960\n",
      "epoch 9; iter: 0; batch classifier loss: 0.441731; batch adversarial loss: 0.642047\n",
      "epoch 9; iter: 200; batch classifier loss: 0.637147; batch adversarial loss: 0.673374\n",
      "epoch 0; iter: 0; batch classifier loss: 8.337379; batch adversarial loss: 0.698012\n",
      "epoch 0; iter: 200; batch classifier loss: 5.587987; batch adversarial loss: 0.754538\n",
      "epoch 1; iter: 0; batch classifier loss: 7.323362; batch adversarial loss: 0.674632\n",
      "epoch 1; iter: 200; batch classifier loss: 3.622437; batch adversarial loss: 0.678391\n",
      "epoch 2; iter: 0; batch classifier loss: 5.242058; batch adversarial loss: 0.634776\n",
      "epoch 2; iter: 200; batch classifier loss: 3.805995; batch adversarial loss: 0.659239\n",
      "epoch 3; iter: 0; batch classifier loss: 1.684023; batch adversarial loss: 0.673934\n",
      "epoch 3; iter: 200; batch classifier loss: 1.523343; batch adversarial loss: 0.599509\n",
      "epoch 4; iter: 0; batch classifier loss: 1.424608; batch adversarial loss: 0.696394\n",
      "epoch 4; iter: 200; batch classifier loss: 1.384623; batch adversarial loss: 0.601811\n",
      "epoch 5; iter: 0; batch classifier loss: 1.055315; batch adversarial loss: 0.662107\n",
      "epoch 5; iter: 200; batch classifier loss: 0.796990; batch adversarial loss: 0.631850\n",
      "epoch 6; iter: 0; batch classifier loss: 0.416754; batch adversarial loss: 0.668556\n",
      "epoch 6; iter: 200; batch classifier loss: 0.668475; batch adversarial loss: 0.647155\n",
      "epoch 7; iter: 0; batch classifier loss: 0.988980; batch adversarial loss: 0.636425\n",
      "epoch 7; iter: 200; batch classifier loss: 0.547638; batch adversarial loss: 0.668029\n",
      "epoch 8; iter: 0; batch classifier loss: 0.445254; batch adversarial loss: 0.649996\n",
      "epoch 8; iter: 200; batch classifier loss: 0.888255; batch adversarial loss: 0.660857\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404365; batch adversarial loss: 0.612513\n",
      "epoch 9; iter: 200; batch classifier loss: 0.650706; batch adversarial loss: 0.646800\n",
      "epoch 0; iter: 0; batch classifier loss: 54.495228; batch adversarial loss: 0.695338\n",
      "epoch 0; iter: 200; batch classifier loss: 6.099047; batch adversarial loss: 0.670252\n",
      "epoch 1; iter: 0; batch classifier loss: 8.264320; batch adversarial loss: 0.647931\n",
      "epoch 1; iter: 200; batch classifier loss: 3.838438; batch adversarial loss: 0.617086\n",
      "epoch 2; iter: 0; batch classifier loss: 3.834761; batch adversarial loss: 0.618337\n",
      "epoch 2; iter: 200; batch classifier loss: 8.346941; batch adversarial loss: 0.646059\n",
      "epoch 3; iter: 0; batch classifier loss: 1.130952; batch adversarial loss: 0.617109\n",
      "epoch 3; iter: 200; batch classifier loss: 2.357202; batch adversarial loss: 0.603443\n",
      "epoch 4; iter: 0; batch classifier loss: 0.832120; batch adversarial loss: 0.636153\n",
      "epoch 4; iter: 200; batch classifier loss: 5.065419; batch adversarial loss: 0.587224\n",
      "epoch 5; iter: 0; batch classifier loss: 2.373860; batch adversarial loss: 0.653249\n",
      "epoch 5; iter: 200; batch classifier loss: 8.372210; batch adversarial loss: 0.646134\n",
      "epoch 6; iter: 0; batch classifier loss: 0.409857; batch adversarial loss: 0.654323\n",
      "epoch 6; iter: 200; batch classifier loss: 0.658760; batch adversarial loss: 0.634854\n",
      "epoch 7; iter: 0; batch classifier loss: 0.964720; batch adversarial loss: 0.607574\n",
      "epoch 7; iter: 200; batch classifier loss: 0.739444; batch adversarial loss: 0.638557\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503444; batch adversarial loss: 0.605855\n",
      "epoch 8; iter: 200; batch classifier loss: 0.649615; batch adversarial loss: 0.636887\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516286; batch adversarial loss: 0.673579\n",
      "epoch 9; iter: 200; batch classifier loss: 0.717963; batch adversarial loss: 0.589104\n",
      "epoch 0; iter: 0; batch classifier loss: 62.959869; batch adversarial loss: 0.701450\n",
      "epoch 0; iter: 200; batch classifier loss: 14.734475; batch adversarial loss: 0.660006\n",
      "epoch 1; iter: 0; batch classifier loss: 13.190067; batch adversarial loss: 0.650903\n",
      "epoch 1; iter: 200; batch classifier loss: 11.700581; batch adversarial loss: 0.634069\n",
      "epoch 2; iter: 0; batch classifier loss: 13.452442; batch adversarial loss: 0.631530\n",
      "epoch 2; iter: 200; batch classifier loss: 6.745501; batch adversarial loss: 0.631885\n",
      "epoch 3; iter: 0; batch classifier loss: 2.109870; batch adversarial loss: 0.636517\n",
      "epoch 3; iter: 200; batch classifier loss: 2.952230; batch adversarial loss: 0.624263\n",
      "epoch 4; iter: 0; batch classifier loss: 1.595899; batch adversarial loss: 0.656783\n",
      "epoch 4; iter: 200; batch classifier loss: 0.624042; batch adversarial loss: 0.596149\n",
      "epoch 5; iter: 0; batch classifier loss: 2.189403; batch adversarial loss: 0.615241\n",
      "epoch 5; iter: 200; batch classifier loss: 1.250340; batch adversarial loss: 0.682605\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482290; batch adversarial loss: 0.620232\n",
      "epoch 6; iter: 200; batch classifier loss: 1.019931; batch adversarial loss: 0.663995\n",
      "epoch 7; iter: 0; batch classifier loss: 1.248710; batch adversarial loss: 0.684506\n",
      "epoch 7; iter: 200; batch classifier loss: 0.404060; batch adversarial loss: 0.604580\n",
      "epoch 8; iter: 0; batch classifier loss: 0.817021; batch adversarial loss: 0.625176\n",
      "epoch 8; iter: 200; batch classifier loss: 0.881553; batch adversarial loss: 0.660181\n",
      "epoch 9; iter: 0; batch classifier loss: 0.632167; batch adversarial loss: 0.554826\n",
      "epoch 9; iter: 200; batch classifier loss: 0.619602; batch adversarial loss: 0.645649\n",
      "epoch 0; iter: 0; batch classifier loss: 22.215771; batch adversarial loss: 0.653470\n",
      "epoch 0; iter: 200; batch classifier loss: 5.136583; batch adversarial loss: 0.650676\n",
      "epoch 1; iter: 0; batch classifier loss: 1.498757; batch adversarial loss: 0.683145\n",
      "epoch 1; iter: 200; batch classifier loss: 1.289344; batch adversarial loss: 0.671138\n",
      "epoch 2; iter: 0; batch classifier loss: 1.861027; batch adversarial loss: 0.608349\n",
      "epoch 2; iter: 200; batch classifier loss: 1.370325; batch adversarial loss: 0.645937\n",
      "epoch 3; iter: 0; batch classifier loss: 3.142459; batch adversarial loss: 0.611617\n",
      "epoch 3; iter: 200; batch classifier loss: 4.467855; batch adversarial loss: 0.588168\n",
      "epoch 4; iter: 0; batch classifier loss: 1.043682; batch adversarial loss: 0.632993\n",
      "epoch 4; iter: 200; batch classifier loss: 1.004975; batch adversarial loss: 0.578607\n",
      "epoch 5; iter: 0; batch classifier loss: 1.970103; batch adversarial loss: 0.647645\n",
      "epoch 5; iter: 200; batch classifier loss: 1.188563; batch adversarial loss: 0.605737\n",
      "epoch 6; iter: 0; batch classifier loss: 1.513252; batch adversarial loss: 0.630739\n",
      "epoch 6; iter: 200; batch classifier loss: 0.613633; batch adversarial loss: 0.643465\n",
      "epoch 7; iter: 0; batch classifier loss: 1.205922; batch adversarial loss: 0.675994\n",
      "epoch 7; iter: 200; batch classifier loss: 0.434623; batch adversarial loss: 0.605763\n",
      "epoch 8; iter: 0; batch classifier loss: 0.702431; batch adversarial loss: 0.647798\n",
      "epoch 8; iter: 200; batch classifier loss: 0.466151; batch adversarial loss: 0.617287\n",
      "epoch 9; iter: 0; batch classifier loss: 1.060955; batch adversarial loss: 0.630308\n",
      "epoch 9; iter: 200; batch classifier loss: 0.590020; batch adversarial loss: 0.631891\n",
      "epoch 0; iter: 0; batch classifier loss: 13.585908; batch adversarial loss: 1.116229\n",
      "epoch 0; iter: 200; batch classifier loss: 25.182508; batch adversarial loss: 0.873380\n",
      "epoch 1; iter: 0; batch classifier loss: 8.877460; batch adversarial loss: 0.946179\n",
      "epoch 1; iter: 200; batch classifier loss: 4.480544; batch adversarial loss: 0.730643\n",
      "epoch 2; iter: 0; batch classifier loss: 12.029043; batch adversarial loss: 0.727116\n",
      "epoch 2; iter: 200; batch classifier loss: 4.911937; batch adversarial loss: 0.645500\n",
      "epoch 3; iter: 0; batch classifier loss: 3.047173; batch adversarial loss: 0.644771\n",
      "epoch 3; iter: 200; batch classifier loss: 0.912589; batch adversarial loss: 0.653110\n",
      "epoch 4; iter: 0; batch classifier loss: 1.805580; batch adversarial loss: 0.626981\n",
      "epoch 4; iter: 200; batch classifier loss: 0.699828; batch adversarial loss: 0.665506\n",
      "epoch 5; iter: 0; batch classifier loss: 1.994392; batch adversarial loss: 0.613235\n",
      "epoch 5; iter: 200; batch classifier loss: 0.767905; batch adversarial loss: 0.631210\n",
      "epoch 6; iter: 0; batch classifier loss: 0.784726; batch adversarial loss: 0.586302\n",
      "epoch 6; iter: 200; batch classifier loss: 0.456029; batch adversarial loss: 0.605470\n",
      "epoch 7; iter: 0; batch classifier loss: 0.842667; batch adversarial loss: 0.645653\n",
      "epoch 7; iter: 200; batch classifier loss: 3.500311; batch adversarial loss: 0.644591\n",
      "epoch 8; iter: 0; batch classifier loss: 0.729372; batch adversarial loss: 0.632430\n",
      "epoch 8; iter: 200; batch classifier loss: 0.549950; batch adversarial loss: 0.607713\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460349; batch adversarial loss: 0.578669\n",
      "epoch 9; iter: 200; batch classifier loss: 0.489176; batch adversarial loss: 0.629209\n",
      "epoch 0; iter: 0; batch classifier loss: 19.227905; batch adversarial loss: 0.672138\n",
      "epoch 0; iter: 200; batch classifier loss: 5.912876; batch adversarial loss: 0.645109\n",
      "epoch 1; iter: 0; batch classifier loss: 10.451664; batch adversarial loss: 0.623534\n",
      "epoch 1; iter: 200; batch classifier loss: 2.000762; batch adversarial loss: 0.587309\n",
      "epoch 2; iter: 0; batch classifier loss: 11.381945; batch adversarial loss: 0.610247\n",
      "epoch 2; iter: 200; batch classifier loss: 1.220372; batch adversarial loss: 0.632654\n",
      "epoch 3; iter: 0; batch classifier loss: 1.837649; batch adversarial loss: 0.639885\n",
      "epoch 3; iter: 200; batch classifier loss: 0.705881; batch adversarial loss: 0.640947\n",
      "epoch 4; iter: 0; batch classifier loss: 1.073055; batch adversarial loss: 0.589571\n",
      "epoch 4; iter: 200; batch classifier loss: 0.488518; batch adversarial loss: 0.647985\n",
      "epoch 5; iter: 0; batch classifier loss: 1.591992; batch adversarial loss: 0.638644\n",
      "epoch 5; iter: 200; batch classifier loss: 0.611639; batch adversarial loss: 0.574090\n",
      "epoch 6; iter: 0; batch classifier loss: 0.751939; batch adversarial loss: 0.582864\n",
      "epoch 6; iter: 200; batch classifier loss: 1.037638; batch adversarial loss: 0.598676\n",
      "epoch 7; iter: 0; batch classifier loss: 0.451692; batch adversarial loss: 0.614630\n",
      "epoch 7; iter: 200; batch classifier loss: 0.978914; batch adversarial loss: 0.659594\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368146; batch adversarial loss: 0.676481\n",
      "epoch 8; iter: 200; batch classifier loss: 0.402905; batch adversarial loss: 0.634397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434186; batch adversarial loss: 0.659016\n",
      "epoch 9; iter: 200; batch classifier loss: 0.453270; batch adversarial loss: 0.597694\n",
      "epoch 0; iter: 0; batch classifier loss: 16.053921; batch adversarial loss: 0.667111\n",
      "epoch 0; iter: 200; batch classifier loss: 14.939790; batch adversarial loss: 0.631649\n",
      "epoch 1; iter: 0; batch classifier loss: 2.979478; batch adversarial loss: 0.634265\n",
      "epoch 1; iter: 200; batch classifier loss: 6.870079; batch adversarial loss: 0.610519\n",
      "epoch 2; iter: 0; batch classifier loss: 2.832330; batch adversarial loss: 0.638016\n",
      "epoch 2; iter: 200; batch classifier loss: 5.964564; batch adversarial loss: 0.585034\n",
      "epoch 3; iter: 0; batch classifier loss: 1.423519; batch adversarial loss: 0.669041\n",
      "epoch 3; iter: 200; batch classifier loss: 4.536082; batch adversarial loss: 0.573286\n",
      "epoch 4; iter: 0; batch classifier loss: 3.177333; batch adversarial loss: 0.627520\n",
      "epoch 4; iter: 200; batch classifier loss: 1.381125; batch adversarial loss: 0.602939\n",
      "epoch 5; iter: 0; batch classifier loss: 1.690144; batch adversarial loss: 0.634625\n",
      "epoch 5; iter: 200; batch classifier loss: 0.737259; batch adversarial loss: 0.619031\n",
      "epoch 6; iter: 0; batch classifier loss: 2.179301; batch adversarial loss: 0.617576\n",
      "epoch 6; iter: 200; batch classifier loss: 3.966909; batch adversarial loss: 0.652617\n",
      "epoch 7; iter: 0; batch classifier loss: 0.759817; batch adversarial loss: 0.582065\n",
      "epoch 7; iter: 200; batch classifier loss: 0.407257; batch adversarial loss: 0.608506\n",
      "epoch 8; iter: 0; batch classifier loss: 1.055182; batch adversarial loss: 0.623014\n",
      "epoch 8; iter: 200; batch classifier loss: 0.725165; batch adversarial loss: 0.606412\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522423; batch adversarial loss: 0.650286\n",
      "epoch 9; iter: 200; batch classifier loss: 0.769999; batch adversarial loss: 0.565059\n",
      "epoch 0; iter: 0; batch classifier loss: 14.894388; batch adversarial loss: 0.705624\n",
      "epoch 0; iter: 200; batch classifier loss: 4.665111; batch adversarial loss: 0.660359\n",
      "epoch 1; iter: 0; batch classifier loss: 13.373539; batch adversarial loss: 0.651400\n",
      "epoch 1; iter: 200; batch classifier loss: 7.101179; batch adversarial loss: 0.603978\n",
      "epoch 2; iter: 0; batch classifier loss: 3.376984; batch adversarial loss: 0.697366\n",
      "epoch 2; iter: 200; batch classifier loss: 1.687026; batch adversarial loss: 0.655028\n",
      "epoch 3; iter: 0; batch classifier loss: 3.204948; batch adversarial loss: 0.602992\n",
      "epoch 3; iter: 200; batch classifier loss: 2.459635; batch adversarial loss: 0.655568\n",
      "epoch 4; iter: 0; batch classifier loss: 1.058434; batch adversarial loss: 0.663068\n",
      "epoch 4; iter: 200; batch classifier loss: 1.728381; batch adversarial loss: 0.558903\n",
      "epoch 5; iter: 0; batch classifier loss: 1.236962; batch adversarial loss: 0.630253\n",
      "epoch 5; iter: 200; batch classifier loss: 1.004963; batch adversarial loss: 0.625985\n",
      "epoch 6; iter: 0; batch classifier loss: 1.202051; batch adversarial loss: 0.639678\n",
      "epoch 6; iter: 200; batch classifier loss: 0.943143; batch adversarial loss: 0.613638\n",
      "epoch 7; iter: 0; batch classifier loss: 1.459900; batch adversarial loss: 0.632354\n",
      "epoch 7; iter: 200; batch classifier loss: 0.695787; batch adversarial loss: 0.657287\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512896; batch adversarial loss: 0.644508\n",
      "epoch 8; iter: 200; batch classifier loss: 0.595771; batch adversarial loss: 0.620076\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527289; batch adversarial loss: 0.563843\n",
      "epoch 9; iter: 200; batch classifier loss: 0.489426; batch adversarial loss: 0.635069\n",
      "epoch 0; iter: 0; batch classifier loss: 127.411011; batch adversarial loss: 0.709686\n",
      "epoch 0; iter: 200; batch classifier loss: 8.823181; batch adversarial loss: 0.694967\n",
      "epoch 1; iter: 0; batch classifier loss: 7.653005; batch adversarial loss: 0.668142\n",
      "epoch 1; iter: 200; batch classifier loss: 9.313171; batch adversarial loss: 0.657059\n",
      "epoch 2; iter: 0; batch classifier loss: 2.900137; batch adversarial loss: 0.655707\n",
      "epoch 2; iter: 200; batch classifier loss: 10.723946; batch adversarial loss: 0.636292\n",
      "epoch 3; iter: 0; batch classifier loss: 2.560359; batch adversarial loss: 0.612661\n",
      "epoch 3; iter: 200; batch classifier loss: 2.775956; batch adversarial loss: 0.684614\n",
      "epoch 4; iter: 0; batch classifier loss: 3.112321; batch adversarial loss: 0.604954\n",
      "epoch 4; iter: 200; batch classifier loss: 2.161822; batch adversarial loss: 0.616035\n",
      "epoch 5; iter: 0; batch classifier loss: 2.512281; batch adversarial loss: 0.666713\n",
      "epoch 5; iter: 200; batch classifier loss: 1.630803; batch adversarial loss: 0.640662\n",
      "epoch 6; iter: 0; batch classifier loss: 0.791898; batch adversarial loss: 0.649762\n",
      "epoch 6; iter: 200; batch classifier loss: 0.626474; batch adversarial loss: 0.641537\n",
      "epoch 7; iter: 0; batch classifier loss: 0.639650; batch adversarial loss: 0.653960\n",
      "epoch 7; iter: 200; batch classifier loss: 0.890221; batch adversarial loss: 0.554342\n",
      "epoch 8; iter: 0; batch classifier loss: 0.762589; batch adversarial loss: 0.601900\n",
      "epoch 8; iter: 200; batch classifier loss: 0.477517; batch adversarial loss: 0.612596\n",
      "epoch 9; iter: 0; batch classifier loss: 0.370612; batch adversarial loss: 0.625165\n",
      "epoch 9; iter: 200; batch classifier loss: 0.831100; batch adversarial loss: 0.666939\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 22.788994; batch adversarial loss: 1.508926\n",
      "epoch 0; iter: 200; batch classifier loss: 8.740669; batch adversarial loss: 0.771929\n",
      "epoch 1; iter: 0; batch classifier loss: 33.517700; batch adversarial loss: 1.096251\n",
      "epoch 1; iter: 200; batch classifier loss: 6.317958; batch adversarial loss: 0.849687\n",
      "epoch 2; iter: 0; batch classifier loss: 6.157103; batch adversarial loss: 0.892664\n",
      "epoch 2; iter: 200; batch classifier loss: 3.420680; batch adversarial loss: 0.795607\n",
      "epoch 3; iter: 0; batch classifier loss: 3.248169; batch adversarial loss: 0.754851\n",
      "epoch 3; iter: 200; batch classifier loss: 1.731319; batch adversarial loss: 0.647624\n",
      "epoch 4; iter: 0; batch classifier loss: 3.401343; batch adversarial loss: 0.674507\n",
      "epoch 4; iter: 200; batch classifier loss: 2.648847; batch adversarial loss: 0.690929\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587446; batch adversarial loss: 0.647108\n",
      "epoch 5; iter: 200; batch classifier loss: 0.652643; batch adversarial loss: 0.654200\n",
      "epoch 6; iter: 0; batch classifier loss: 0.433153; batch adversarial loss: 0.641981\n",
      "epoch 6; iter: 200; batch classifier loss: 0.886485; batch adversarial loss: 0.673371\n",
      "epoch 7; iter: 0; batch classifier loss: 1.043016; batch adversarial loss: 0.615052\n",
      "epoch 7; iter: 200; batch classifier loss: 0.839678; batch adversarial loss: 0.653310\n",
      "epoch 8; iter: 0; batch classifier loss: 0.735757; batch adversarial loss: 0.601462\n",
      "epoch 8; iter: 200; batch classifier loss: 0.683566; batch adversarial loss: 0.619498\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354460; batch adversarial loss: 0.689909\n",
      "epoch 9; iter: 200; batch classifier loss: 0.635603; batch adversarial loss: 0.668801\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434923; batch adversarial loss: 0.617517\n",
      "epoch 10; iter: 200; batch classifier loss: 1.173524; batch adversarial loss: 0.618424\n",
      "epoch 11; iter: 0; batch classifier loss: 0.471121; batch adversarial loss: 0.639472\n",
      "epoch 11; iter: 200; batch classifier loss: 0.535165; batch adversarial loss: 0.636314\n",
      "epoch 12; iter: 0; batch classifier loss: 0.453115; batch adversarial loss: 0.584791\n",
      "epoch 12; iter: 200; batch classifier loss: 0.589867; batch adversarial loss: 0.586840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448806; batch adversarial loss: 0.690882\n",
      "epoch 13; iter: 200; batch classifier loss: 0.393055; batch adversarial loss: 0.587617\n",
      "epoch 14; iter: 0; batch classifier loss: 0.405250; batch adversarial loss: 0.623291\n",
      "epoch 14; iter: 200; batch classifier loss: 0.472697; batch adversarial loss: 0.629729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.397947; batch adversarial loss: 0.637736\n",
      "epoch 15; iter: 200; batch classifier loss: 0.420103; batch adversarial loss: 0.615735\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414384; batch adversarial loss: 0.589981\n",
      "epoch 16; iter: 200; batch classifier loss: 0.382779; batch adversarial loss: 0.602390\n",
      "epoch 17; iter: 0; batch classifier loss: 0.482875; batch adversarial loss: 0.629171\n",
      "epoch 17; iter: 200; batch classifier loss: 0.431672; batch adversarial loss: 0.614843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531669; batch adversarial loss: 0.597854\n",
      "epoch 18; iter: 200; batch classifier loss: 0.475512; batch adversarial loss: 0.656116\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465891; batch adversarial loss: 0.612577\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372027; batch adversarial loss: 0.650406\n",
      "epoch 0; iter: 0; batch classifier loss: 29.223661; batch adversarial loss: 0.739801\n",
      "epoch 0; iter: 200; batch classifier loss: 11.907454; batch adversarial loss: 0.864165\n",
      "epoch 1; iter: 0; batch classifier loss: 4.560192; batch adversarial loss: 0.900877\n",
      "epoch 1; iter: 200; batch classifier loss: 5.051798; batch adversarial loss: 0.681244\n",
      "epoch 2; iter: 0; batch classifier loss: 5.662149; batch adversarial loss: 0.687262\n",
      "epoch 2; iter: 200; batch classifier loss: 3.912190; batch adversarial loss: 0.686423\n",
      "epoch 3; iter: 0; batch classifier loss: 2.189657; batch adversarial loss: 0.682190\n",
      "epoch 3; iter: 200; batch classifier loss: 1.991744; batch adversarial loss: 0.664272\n",
      "epoch 4; iter: 0; batch classifier loss: 2.606190; batch adversarial loss: 0.656027\n",
      "epoch 4; iter: 200; batch classifier loss: 3.162330; batch adversarial loss: 0.645324\n",
      "epoch 5; iter: 0; batch classifier loss: 1.348314; batch adversarial loss: 0.659801\n",
      "epoch 5; iter: 200; batch classifier loss: 1.745399; batch adversarial loss: 0.661579\n",
      "epoch 6; iter: 0; batch classifier loss: 1.500185; batch adversarial loss: 0.630947\n",
      "epoch 6; iter: 200; batch classifier loss: 0.595426; batch adversarial loss: 0.544595\n",
      "epoch 7; iter: 0; batch classifier loss: 0.449279; batch adversarial loss: 0.591597\n",
      "epoch 7; iter: 200; batch classifier loss: 0.316216; batch adversarial loss: 0.597580\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532435; batch adversarial loss: 0.589496\n",
      "epoch 8; iter: 200; batch classifier loss: 0.521038; batch adversarial loss: 0.659814\n",
      "epoch 9; iter: 0; batch classifier loss: 0.365860; batch adversarial loss: 0.629387\n",
      "epoch 9; iter: 200; batch classifier loss: 0.327228; batch adversarial loss: 0.615127\n",
      "epoch 10; iter: 0; batch classifier loss: 0.273973; batch adversarial loss: 0.607717\n",
      "epoch 10; iter: 200; batch classifier loss: 0.484980; batch adversarial loss: 0.604979\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389760; batch adversarial loss: 0.665673\n",
      "epoch 11; iter: 200; batch classifier loss: 0.501758; batch adversarial loss: 0.633232\n",
      "epoch 12; iter: 0; batch classifier loss: 0.435742; batch adversarial loss: 0.637368\n",
      "epoch 12; iter: 200; batch classifier loss: 0.422649; batch adversarial loss: 0.593436\n",
      "epoch 13; iter: 0; batch classifier loss: 0.655978; batch adversarial loss: 0.642557\n",
      "epoch 13; iter: 200; batch classifier loss: 0.348432; batch adversarial loss: 0.647962\n",
      "epoch 14; iter: 0; batch classifier loss: 0.415942; batch adversarial loss: 0.619758\n",
      "epoch 14; iter: 200; batch classifier loss: 0.375768; batch adversarial loss: 0.634648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.339505; batch adversarial loss: 0.641536\n",
      "epoch 15; iter: 200; batch classifier loss: 0.681146; batch adversarial loss: 0.622817\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391354; batch adversarial loss: 0.611567\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304639; batch adversarial loss: 0.667222\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465157; batch adversarial loss: 0.605524\n",
      "epoch 17; iter: 200; batch classifier loss: 0.255496; batch adversarial loss: 0.648820\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391716; batch adversarial loss: 0.639457\n",
      "epoch 18; iter: 200; batch classifier loss: 0.339904; batch adversarial loss: 0.625304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.414689; batch adversarial loss: 0.642072\n",
      "epoch 19; iter: 200; batch classifier loss: 0.353872; batch adversarial loss: 0.568631\n",
      "epoch 0; iter: 0; batch classifier loss: 18.381550; batch adversarial loss: 0.711637\n",
      "epoch 0; iter: 200; batch classifier loss: 7.889306; batch adversarial loss: 0.647109\n",
      "epoch 1; iter: 0; batch classifier loss: 6.742522; batch adversarial loss: 0.625723\n",
      "epoch 1; iter: 200; batch classifier loss: 7.559373; batch adversarial loss: 0.630214\n",
      "epoch 2; iter: 0; batch classifier loss: 6.637178; batch adversarial loss: 0.617042\n",
      "epoch 2; iter: 200; batch classifier loss: 4.788549; batch adversarial loss: 0.647277\n",
      "epoch 3; iter: 0; batch classifier loss: 1.395952; batch adversarial loss: 0.710224\n",
      "epoch 3; iter: 200; batch classifier loss: 1.811344; batch adversarial loss: 0.669442\n",
      "epoch 4; iter: 0; batch classifier loss: 2.362574; batch adversarial loss: 0.632029\n",
      "epoch 4; iter: 200; batch classifier loss: 0.694125; batch adversarial loss: 0.676055\n",
      "epoch 5; iter: 0; batch classifier loss: 0.753410; batch adversarial loss: 0.653562\n",
      "epoch 5; iter: 200; batch classifier loss: 1.057228; batch adversarial loss: 0.658582\n",
      "epoch 6; iter: 0; batch classifier loss: 1.813638; batch adversarial loss: 0.555492\n",
      "epoch 6; iter: 200; batch classifier loss: 0.852186; batch adversarial loss: 0.614652\n",
      "epoch 7; iter: 0; batch classifier loss: 0.787630; batch adversarial loss: 0.637567\n",
      "epoch 7; iter: 200; batch classifier loss: 0.544562; batch adversarial loss: 0.650576\n",
      "epoch 8; iter: 0; batch classifier loss: 1.085914; batch adversarial loss: 0.656298\n",
      "epoch 8; iter: 200; batch classifier loss: 0.483618; batch adversarial loss: 0.566077\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472876; batch adversarial loss: 0.614411\n",
      "epoch 9; iter: 200; batch classifier loss: 0.823933; batch adversarial loss: 0.666391\n",
      "epoch 10; iter: 0; batch classifier loss: 0.646969; batch adversarial loss: 0.670809\n",
      "epoch 10; iter: 200; batch classifier loss: 0.723586; batch adversarial loss: 0.624124\n",
      "epoch 11; iter: 0; batch classifier loss: 0.434356; batch adversarial loss: 0.628303\n",
      "epoch 11; iter: 200; batch classifier loss: 0.815963; batch adversarial loss: 0.638272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.420936; batch adversarial loss: 0.629251\n",
      "epoch 12; iter: 200; batch classifier loss: 0.458464; batch adversarial loss: 0.627461\n",
      "epoch 13; iter: 0; batch classifier loss: 0.337728; batch adversarial loss: 0.700362\n",
      "epoch 13; iter: 200; batch classifier loss: 0.426095; batch adversarial loss: 0.628322\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367371; batch adversarial loss: 0.616385\n",
      "epoch 14; iter: 200; batch classifier loss: 0.414532; batch adversarial loss: 0.612886\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474658; batch adversarial loss: 0.611091\n",
      "epoch 15; iter: 200; batch classifier loss: 0.340068; batch adversarial loss: 0.637880\n",
      "epoch 16; iter: 0; batch classifier loss: 0.275003; batch adversarial loss: 0.604106\n",
      "epoch 16; iter: 200; batch classifier loss: 0.432129; batch adversarial loss: 0.637909\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424570; batch adversarial loss: 0.635478\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345970; batch adversarial loss: 0.699592\n",
      "epoch 18; iter: 0; batch classifier loss: 0.380200; batch adversarial loss: 0.599762\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399632; batch adversarial loss: 0.616448\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406727; batch adversarial loss: 0.653913\n",
      "epoch 19; iter: 200; batch classifier loss: 0.441715; batch adversarial loss: 0.670643\n",
      "epoch 0; iter: 0; batch classifier loss: 25.227226; batch adversarial loss: 0.662193\n",
      "epoch 0; iter: 200; batch classifier loss: 5.931406; batch adversarial loss: 0.649232\n",
      "epoch 1; iter: 0; batch classifier loss: 3.816326; batch adversarial loss: 0.698828\n",
      "epoch 1; iter: 200; batch classifier loss: 8.062525; batch adversarial loss: 0.681322\n",
      "epoch 2; iter: 0; batch classifier loss: 10.677359; batch adversarial loss: 0.632791\n",
      "epoch 2; iter: 200; batch classifier loss: 1.153226; batch adversarial loss: 0.621755\n",
      "epoch 3; iter: 0; batch classifier loss: 1.405969; batch adversarial loss: 0.620145\n",
      "epoch 3; iter: 200; batch classifier loss: 0.688160; batch adversarial loss: 0.666374\n",
      "epoch 4; iter: 0; batch classifier loss: 1.855544; batch adversarial loss: 0.620812\n",
      "epoch 4; iter: 200; batch classifier loss: 0.510306; batch adversarial loss: 0.616545\n",
      "epoch 5; iter: 0; batch classifier loss: 1.255097; batch adversarial loss: 0.635916\n",
      "epoch 5; iter: 200; batch classifier loss: 0.890521; batch adversarial loss: 0.674906\n",
      "epoch 6; iter: 0; batch classifier loss: 1.432443; batch adversarial loss: 0.669529\n",
      "epoch 6; iter: 200; batch classifier loss: 0.562025; batch adversarial loss: 0.661956\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416440; batch adversarial loss: 0.629606\n",
      "epoch 7; iter: 200; batch classifier loss: 0.430090; batch adversarial loss: 0.624828\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600623; batch adversarial loss: 0.643627\n",
      "epoch 8; iter: 200; batch classifier loss: 0.395488; batch adversarial loss: 0.644342\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474941; batch adversarial loss: 0.595101\n",
      "epoch 9; iter: 200; batch classifier loss: 0.386721; batch adversarial loss: 0.629805\n",
      "epoch 10; iter: 0; batch classifier loss: 0.404411; batch adversarial loss: 0.579698\n",
      "epoch 10; iter: 200; batch classifier loss: 0.308582; batch adversarial loss: 0.644344\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554941; batch adversarial loss: 0.622749\n",
      "epoch 11; iter: 200; batch classifier loss: 0.478156; batch adversarial loss: 0.616551\n",
      "epoch 12; iter: 0; batch classifier loss: 0.433374; batch adversarial loss: 0.667006\n",
      "epoch 12; iter: 200; batch classifier loss: 0.451522; batch adversarial loss: 0.640737\n",
      "epoch 13; iter: 0; batch classifier loss: 0.463852; batch adversarial loss: 0.595320\n",
      "epoch 13; iter: 200; batch classifier loss: 0.367105; batch adversarial loss: 0.633927\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331876; batch adversarial loss: 0.623074\n",
      "epoch 14; iter: 200; batch classifier loss: 0.475581; batch adversarial loss: 0.617648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.423274; batch adversarial loss: 0.640248\n",
      "epoch 15; iter: 200; batch classifier loss: 0.436568; batch adversarial loss: 0.592924\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403520; batch adversarial loss: 0.663018\n",
      "epoch 16; iter: 200; batch classifier loss: 0.359529; batch adversarial loss: 0.598292\n",
      "epoch 17; iter: 0; batch classifier loss: 0.342513; batch adversarial loss: 0.640777\n",
      "epoch 17; iter: 200; batch classifier loss: 0.412890; batch adversarial loss: 0.627309\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370680; batch adversarial loss: 0.620442\n",
      "epoch 18; iter: 200; batch classifier loss: 0.429513; batch adversarial loss: 0.606909\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354414; batch adversarial loss: 0.582378\n",
      "epoch 19; iter: 200; batch classifier loss: 0.355161; batch adversarial loss: 0.658205\n",
      "epoch 0; iter: 0; batch classifier loss: 9.506716; batch adversarial loss: 0.802074\n",
      "epoch 0; iter: 200; batch classifier loss: 11.416257; batch adversarial loss: 0.802634\n",
      "epoch 1; iter: 0; batch classifier loss: 7.036179; batch adversarial loss: 0.743410\n",
      "epoch 1; iter: 200; batch classifier loss: 9.240192; batch adversarial loss: 0.642325\n",
      "epoch 2; iter: 0; batch classifier loss: 5.187921; batch adversarial loss: 0.654503\n",
      "epoch 2; iter: 200; batch classifier loss: 2.524509; batch adversarial loss: 0.635216\n",
      "epoch 3; iter: 0; batch classifier loss: 1.973913; batch adversarial loss: 0.617821\n",
      "epoch 3; iter: 200; batch classifier loss: 1.273631; batch adversarial loss: 0.648015\n",
      "epoch 4; iter: 0; batch classifier loss: 2.989417; batch adversarial loss: 0.646758\n",
      "epoch 4; iter: 200; batch classifier loss: 1.050047; batch adversarial loss: 0.630752\n",
      "epoch 5; iter: 0; batch classifier loss: 2.099257; batch adversarial loss: 0.615185\n",
      "epoch 5; iter: 200; batch classifier loss: 1.182648; batch adversarial loss: 0.624624\n",
      "epoch 6; iter: 0; batch classifier loss: 0.505171; batch adversarial loss: 0.621054\n",
      "epoch 6; iter: 200; batch classifier loss: 0.451547; batch adversarial loss: 0.645423\n",
      "epoch 7; iter: 0; batch classifier loss: 0.628114; batch adversarial loss: 0.576744\n",
      "epoch 7; iter: 200; batch classifier loss: 1.048382; batch adversarial loss: 0.594156\n",
      "epoch 8; iter: 0; batch classifier loss: 0.714477; batch adversarial loss: 0.650385\n",
      "epoch 8; iter: 200; batch classifier loss: 0.437213; batch adversarial loss: 0.620915\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475502; batch adversarial loss: 0.622983\n",
      "epoch 9; iter: 200; batch classifier loss: 0.366787; batch adversarial loss: 0.609161\n",
      "epoch 10; iter: 0; batch classifier loss: 0.600375; batch adversarial loss: 0.647644\n",
      "epoch 10; iter: 200; batch classifier loss: 0.533442; batch adversarial loss: 0.582599\n",
      "epoch 11; iter: 0; batch classifier loss: 0.449945; batch adversarial loss: 0.622014\n",
      "epoch 11; iter: 200; batch classifier loss: 0.374012; batch adversarial loss: 0.637868\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571626; batch adversarial loss: 0.592120\n",
      "epoch 12; iter: 200; batch classifier loss: 0.475541; batch adversarial loss: 0.662189\n",
      "epoch 13; iter: 0; batch classifier loss: 0.367140; batch adversarial loss: 0.641232\n",
      "epoch 13; iter: 200; batch classifier loss: 0.332775; batch adversarial loss: 0.678281\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462169; batch adversarial loss: 0.649794\n",
      "epoch 14; iter: 200; batch classifier loss: 0.372435; batch adversarial loss: 0.594380\n",
      "epoch 15; iter: 0; batch classifier loss: 0.464342; batch adversarial loss: 0.616335\n",
      "epoch 15; iter: 200; batch classifier loss: 0.477023; batch adversarial loss: 0.566611\n",
      "epoch 16; iter: 0; batch classifier loss: 0.322844; batch adversarial loss: 0.622834\n",
      "epoch 16; iter: 200; batch classifier loss: 0.457548; batch adversarial loss: 0.592728\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364443; batch adversarial loss: 0.661304\n",
      "epoch 17; iter: 200; batch classifier loss: 0.302760; batch adversarial loss: 0.643945\n",
      "epoch 18; iter: 0; batch classifier loss: 0.372747; batch adversarial loss: 0.633892\n",
      "epoch 18; iter: 200; batch classifier loss: 0.343305; batch adversarial loss: 0.660618\n",
      "epoch 19; iter: 0; batch classifier loss: 0.330699; batch adversarial loss: 0.615258\n",
      "epoch 19; iter: 200; batch classifier loss: 0.383604; batch adversarial loss: 0.603567\n",
      "epoch 0; iter: 0; batch classifier loss: 52.202011; batch adversarial loss: 0.692409\n",
      "epoch 0; iter: 200; batch classifier loss: 7.012336; batch adversarial loss: 0.662426\n",
      "epoch 1; iter: 0; batch classifier loss: 14.101480; batch adversarial loss: 0.663121\n",
      "epoch 1; iter: 200; batch classifier loss: 2.318337; batch adversarial loss: 0.624341\n",
      "epoch 2; iter: 0; batch classifier loss: 3.825578; batch adversarial loss: 0.651965\n",
      "epoch 2; iter: 200; batch classifier loss: 1.858488; batch adversarial loss: 0.625104\n",
      "epoch 3; iter: 0; batch classifier loss: 3.267011; batch adversarial loss: 0.628382\n",
      "epoch 3; iter: 200; batch classifier loss: 0.614533; batch adversarial loss: 0.649398\n",
      "epoch 4; iter: 0; batch classifier loss: 1.312308; batch adversarial loss: 0.691724\n",
      "epoch 4; iter: 200; batch classifier loss: 2.246462; batch adversarial loss: 0.587958\n",
      "epoch 5; iter: 0; batch classifier loss: 0.747238; batch adversarial loss: 0.609123\n",
      "epoch 5; iter: 200; batch classifier loss: 0.469781; batch adversarial loss: 0.651323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.529507; batch adversarial loss: 0.630069\n",
      "epoch 6; iter: 200; batch classifier loss: 1.007059; batch adversarial loss: 0.580283\n",
      "epoch 7; iter: 0; batch classifier loss: 1.323269; batch adversarial loss: 0.565302\n",
      "epoch 7; iter: 200; batch classifier loss: 0.785837; batch adversarial loss: 0.624205\n",
      "epoch 8; iter: 0; batch classifier loss: 0.784506; batch adversarial loss: 0.669696\n",
      "epoch 8; iter: 200; batch classifier loss: 0.771952; batch adversarial loss: 0.617806\n",
      "epoch 9; iter: 0; batch classifier loss: 0.647834; batch adversarial loss: 0.608720\n",
      "epoch 9; iter: 200; batch classifier loss: 0.250529; batch adversarial loss: 0.639647\n",
      "epoch 10; iter: 0; batch classifier loss: 0.427939; batch adversarial loss: 0.565140\n",
      "epoch 10; iter: 200; batch classifier loss: 0.377426; batch adversarial loss: 0.645972\n",
      "epoch 11; iter: 0; batch classifier loss: 0.383209; batch adversarial loss: 0.616287\n",
      "epoch 11; iter: 200; batch classifier loss: 0.571284; batch adversarial loss: 0.621869\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312483; batch adversarial loss: 0.617635\n",
      "epoch 12; iter: 200; batch classifier loss: 0.528381; batch adversarial loss: 0.613766\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412965; batch adversarial loss: 0.585980\n",
      "epoch 13; iter: 200; batch classifier loss: 0.523569; batch adversarial loss: 0.607610\n",
      "epoch 14; iter: 0; batch classifier loss: 0.522951; batch adversarial loss: 0.635327\n",
      "epoch 14; iter: 200; batch classifier loss: 0.742280; batch adversarial loss: 0.639192\n",
      "epoch 15; iter: 0; batch classifier loss: 0.787916; batch adversarial loss: 0.613678\n",
      "epoch 15; iter: 200; batch classifier loss: 0.463284; batch adversarial loss: 0.620268\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344655; batch adversarial loss: 0.685074\n",
      "epoch 16; iter: 200; batch classifier loss: 0.389402; batch adversarial loss: 0.646581\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333774; batch adversarial loss: 0.599449\n",
      "epoch 17; iter: 200; batch classifier loss: 0.350992; batch adversarial loss: 0.659164\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361990; batch adversarial loss: 0.635062\n",
      "epoch 18; iter: 200; batch classifier loss: 0.381428; batch adversarial loss: 0.571960\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365904; batch adversarial loss: 0.659817\n",
      "epoch 19; iter: 200; batch classifier loss: 0.484408; batch adversarial loss: 0.667969\n",
      "epoch 0; iter: 0; batch classifier loss: 12.917564; batch adversarial loss: 0.664047\n",
      "epoch 0; iter: 200; batch classifier loss: 16.085281; batch adversarial loss: 0.651989\n",
      "epoch 1; iter: 0; batch classifier loss: 4.296875; batch adversarial loss: 0.611909\n",
      "epoch 1; iter: 200; batch classifier loss: 3.898915; batch adversarial loss: 0.753146\n",
      "epoch 2; iter: 0; batch classifier loss: 4.422975; batch adversarial loss: 0.669188\n",
      "epoch 2; iter: 200; batch classifier loss: 4.220981; batch adversarial loss: 0.656233\n",
      "epoch 3; iter: 0; batch classifier loss: 2.000263; batch adversarial loss: 0.682520\n",
      "epoch 3; iter: 200; batch classifier loss: 2.363629; batch adversarial loss: 0.676090\n",
      "epoch 4; iter: 0; batch classifier loss: 2.654521; batch adversarial loss: 0.662581\n",
      "epoch 4; iter: 200; batch classifier loss: 1.168287; batch adversarial loss: 0.661049\n",
      "epoch 5; iter: 0; batch classifier loss: 0.774389; batch adversarial loss: 0.645427\n",
      "epoch 5; iter: 200; batch classifier loss: 1.379526; batch adversarial loss: 0.678771\n",
      "epoch 6; iter: 0; batch classifier loss: 1.445496; batch adversarial loss: 0.650568\n",
      "epoch 6; iter: 200; batch classifier loss: 0.408137; batch adversarial loss: 0.688025\n",
      "epoch 7; iter: 0; batch classifier loss: 0.726015; batch adversarial loss: 0.648624\n",
      "epoch 7; iter: 200; batch classifier loss: 0.512983; batch adversarial loss: 0.668641\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377628; batch adversarial loss: 0.628754\n",
      "epoch 8; iter: 200; batch classifier loss: 0.742819; batch adversarial loss: 0.638676\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581083; batch adversarial loss: 0.575518\n",
      "epoch 9; iter: 200; batch classifier loss: 0.504185; batch adversarial loss: 0.602001\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468554; batch adversarial loss: 0.641216\n",
      "epoch 10; iter: 200; batch classifier loss: 1.924675; batch adversarial loss: 0.642187\n",
      "epoch 11; iter: 0; batch classifier loss: 0.755955; batch adversarial loss: 0.659428\n",
      "epoch 11; iter: 200; batch classifier loss: 0.392599; batch adversarial loss: 0.634175\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390756; batch adversarial loss: 0.604015\n",
      "epoch 12; iter: 200; batch classifier loss: 0.456554; batch adversarial loss: 0.642832\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407835; batch adversarial loss: 0.695793\n",
      "epoch 13; iter: 200; batch classifier loss: 0.599202; batch adversarial loss: 0.621065\n",
      "epoch 14; iter: 0; batch classifier loss: 0.378379; batch adversarial loss: 0.663888\n",
      "epoch 14; iter: 200; batch classifier loss: 0.350609; batch adversarial loss: 0.621600\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454996; batch adversarial loss: 0.634246\n",
      "epoch 15; iter: 200; batch classifier loss: 0.570084; batch adversarial loss: 0.625852\n",
      "epoch 16; iter: 0; batch classifier loss: 0.340903; batch adversarial loss: 0.652002\n",
      "epoch 16; iter: 200; batch classifier loss: 0.404561; batch adversarial loss: 0.662136\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375253; batch adversarial loss: 0.602296\n",
      "epoch 17; iter: 200; batch classifier loss: 0.419620; batch adversarial loss: 0.617622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335758; batch adversarial loss: 0.668749\n",
      "epoch 18; iter: 200; batch classifier loss: 0.370947; batch adversarial loss: 0.633998\n",
      "epoch 19; iter: 0; batch classifier loss: 0.432847; batch adversarial loss: 0.593875\n",
      "epoch 19; iter: 200; batch classifier loss: 0.354799; batch adversarial loss: 0.614506\n",
      "epoch 0; iter: 0; batch classifier loss: 12.755899; batch adversarial loss: 0.671209\n",
      "epoch 0; iter: 200; batch classifier loss: 1.477875; batch adversarial loss: 0.668846\n",
      "epoch 1; iter: 0; batch classifier loss: 14.525154; batch adversarial loss: 0.649645\n",
      "epoch 1; iter: 200; batch classifier loss: 4.108509; batch adversarial loss: 0.622310\n",
      "epoch 2; iter: 0; batch classifier loss: 8.242889; batch adversarial loss: 0.639856\n",
      "epoch 2; iter: 200; batch classifier loss: 1.101917; batch adversarial loss: 0.603783\n",
      "epoch 3; iter: 0; batch classifier loss: 2.369986; batch adversarial loss: 0.628901\n",
      "epoch 3; iter: 200; batch classifier loss: 3.687477; batch adversarial loss: 0.639921\n",
      "epoch 4; iter: 0; batch classifier loss: 1.171619; batch adversarial loss: 0.621292\n",
      "epoch 4; iter: 200; batch classifier loss: 1.260478; batch adversarial loss: 0.642008\n",
      "epoch 5; iter: 0; batch classifier loss: 0.948575; batch adversarial loss: 0.638251\n",
      "epoch 5; iter: 200; batch classifier loss: 1.384112; batch adversarial loss: 0.637375\n",
      "epoch 6; iter: 0; batch classifier loss: 1.277925; batch adversarial loss: 0.580429\n",
      "epoch 6; iter: 200; batch classifier loss: 1.366360; batch adversarial loss: 0.615660\n",
      "epoch 7; iter: 0; batch classifier loss: 1.011199; batch adversarial loss: 0.605375\n",
      "epoch 7; iter: 200; batch classifier loss: 0.600321; batch adversarial loss: 0.635102\n",
      "epoch 8; iter: 0; batch classifier loss: 1.026900; batch adversarial loss: 0.630984\n",
      "epoch 8; iter: 200; batch classifier loss: 0.730133; batch adversarial loss: 0.623523\n",
      "epoch 9; iter: 0; batch classifier loss: 0.898341; batch adversarial loss: 0.679178\n",
      "epoch 9; iter: 200; batch classifier loss: 0.373694; batch adversarial loss: 0.618609\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455169; batch adversarial loss: 0.606802\n",
      "epoch 10; iter: 200; batch classifier loss: 0.402330; batch adversarial loss: 0.658805\n",
      "epoch 11; iter: 0; batch classifier loss: 0.443529; batch adversarial loss: 0.643424\n",
      "epoch 11; iter: 200; batch classifier loss: 0.378054; batch adversarial loss: 0.607417\n",
      "epoch 12; iter: 0; batch classifier loss: 0.435257; batch adversarial loss: 0.613157\n",
      "epoch 12; iter: 200; batch classifier loss: 0.581473; batch adversarial loss: 0.637504\n",
      "epoch 13; iter: 0; batch classifier loss: 0.422057; batch adversarial loss: 0.599222\n",
      "epoch 13; iter: 200; batch classifier loss: 0.698407; batch adversarial loss: 0.674896\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449780; batch adversarial loss: 0.669753\n",
      "epoch 14; iter: 200; batch classifier loss: 0.461472; batch adversarial loss: 0.612216\n",
      "epoch 15; iter: 0; batch classifier loss: 0.630278; batch adversarial loss: 0.636134\n",
      "epoch 15; iter: 200; batch classifier loss: 0.328890; batch adversarial loss: 0.578741\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358341; batch adversarial loss: 0.636446\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342709; batch adversarial loss: 0.607446\n",
      "epoch 17; iter: 0; batch classifier loss: 0.686380; batch adversarial loss: 0.612459\n",
      "epoch 17; iter: 200; batch classifier loss: 0.353740; batch adversarial loss: 0.615687\n",
      "epoch 18; iter: 0; batch classifier loss: 0.356639; batch adversarial loss: 0.662117\n",
      "epoch 18; iter: 200; batch classifier loss: 0.328590; batch adversarial loss: 0.650714\n",
      "epoch 19; iter: 0; batch classifier loss: 0.372150; batch adversarial loss: 0.617877\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346659; batch adversarial loss: 0.644892\n",
      "epoch 0; iter: 0; batch classifier loss: 21.123245; batch adversarial loss: 0.688946\n",
      "epoch 0; iter: 200; batch classifier loss: 17.264538; batch adversarial loss: 0.673306\n",
      "epoch 1; iter: 0; batch classifier loss: 13.492202; batch adversarial loss: 0.657167\n",
      "epoch 1; iter: 200; batch classifier loss: 9.710121; batch adversarial loss: 0.671294\n",
      "epoch 2; iter: 0; batch classifier loss: 6.410815; batch adversarial loss: 0.636878\n",
      "epoch 2; iter: 200; batch classifier loss: 2.407554; batch adversarial loss: 0.586345\n",
      "epoch 3; iter: 0; batch classifier loss: 0.917561; batch adversarial loss: 0.590619\n",
      "epoch 3; iter: 200; batch classifier loss: 1.287962; batch adversarial loss: 0.591674\n",
      "epoch 4; iter: 0; batch classifier loss: 2.549254; batch adversarial loss: 0.566330\n",
      "epoch 4; iter: 200; batch classifier loss: 0.947200; batch adversarial loss: 0.635846\n",
      "epoch 5; iter: 0; batch classifier loss: 0.850752; batch adversarial loss: 0.646914\n",
      "epoch 5; iter: 200; batch classifier loss: 2.696316; batch adversarial loss: 0.594575\n",
      "epoch 6; iter: 0; batch classifier loss: 1.674686; batch adversarial loss: 0.564379\n",
      "epoch 6; iter: 200; batch classifier loss: 0.761999; batch adversarial loss: 0.643510\n",
      "epoch 7; iter: 0; batch classifier loss: 0.797483; batch adversarial loss: 0.621647\n",
      "epoch 7; iter: 200; batch classifier loss: 0.529689; batch adversarial loss: 0.628007\n",
      "epoch 8; iter: 0; batch classifier loss: 0.714920; batch adversarial loss: 0.550260\n",
      "epoch 8; iter: 200; batch classifier loss: 0.343311; batch adversarial loss: 0.674479\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586357; batch adversarial loss: 0.673887\n",
      "epoch 9; iter: 200; batch classifier loss: 0.523846; batch adversarial loss: 0.621171\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518633; batch adversarial loss: 0.644067\n",
      "epoch 10; iter: 200; batch classifier loss: 0.473562; batch adversarial loss: 0.650061\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454757; batch adversarial loss: 0.628988\n",
      "epoch 11; iter: 200; batch classifier loss: 0.323893; batch adversarial loss: 0.606664\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377942; batch adversarial loss: 0.600598\n",
      "epoch 12; iter: 200; batch classifier loss: 0.535049; batch adversarial loss: 0.596402\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342982; batch adversarial loss: 0.629682\n",
      "epoch 13; iter: 200; batch classifier loss: 0.372973; batch adversarial loss: 0.684247\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373545; batch adversarial loss: 0.639807\n",
      "epoch 14; iter: 200; batch classifier loss: 0.353565; batch adversarial loss: 0.623551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.315714; batch adversarial loss: 0.623999\n",
      "epoch 15; iter: 200; batch classifier loss: 0.337355; batch adversarial loss: 0.658092\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482503; batch adversarial loss: 0.625058\n",
      "epoch 16; iter: 200; batch classifier loss: 0.468454; batch adversarial loss: 0.638668\n",
      "epoch 17; iter: 0; batch classifier loss: 0.432230; batch adversarial loss: 0.611781\n",
      "epoch 17; iter: 200; batch classifier loss: 0.382882; batch adversarial loss: 0.653375\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398157; batch adversarial loss: 0.624208\n",
      "epoch 18; iter: 200; batch classifier loss: 0.376973; batch adversarial loss: 0.592607\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325458; batch adversarial loss: 0.676021\n",
      "epoch 19; iter: 200; batch classifier loss: 0.602740; batch adversarial loss: 0.657016\n",
      "epoch 0; iter: 0; batch classifier loss: 33.300236; batch adversarial loss: 0.764514\n",
      "epoch 0; iter: 200; batch classifier loss: 10.557357; batch adversarial loss: 0.659312\n",
      "epoch 1; iter: 0; batch classifier loss: 8.791220; batch adversarial loss: 0.683365\n",
      "epoch 1; iter: 200; batch classifier loss: 6.979084; batch adversarial loss: 0.659384\n",
      "epoch 2; iter: 0; batch classifier loss: 3.125765; batch adversarial loss: 0.642270\n",
      "epoch 2; iter: 200; batch classifier loss: 3.852382; batch adversarial loss: 0.692223\n",
      "epoch 3; iter: 0; batch classifier loss: 3.040499; batch adversarial loss: 0.653264\n",
      "epoch 3; iter: 200; batch classifier loss: 2.478989; batch adversarial loss: 0.643735\n",
      "epoch 4; iter: 0; batch classifier loss: 0.771295; batch adversarial loss: 0.668810\n",
      "epoch 4; iter: 200; batch classifier loss: 1.011081; batch adversarial loss: 0.623125\n",
      "epoch 5; iter: 0; batch classifier loss: 1.243035; batch adversarial loss: 0.620580\n",
      "epoch 5; iter: 200; batch classifier loss: 0.468250; batch adversarial loss: 0.602172\n",
      "epoch 6; iter: 0; batch classifier loss: 0.980060; batch adversarial loss: 0.614183\n",
      "epoch 6; iter: 200; batch classifier loss: 0.865364; batch adversarial loss: 0.623015\n",
      "epoch 7; iter: 0; batch classifier loss: 0.677144; batch adversarial loss: 0.609118\n",
      "epoch 7; iter: 200; batch classifier loss: 0.383600; batch adversarial loss: 0.582712\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316923; batch adversarial loss: 0.653291\n",
      "epoch 8; iter: 200; batch classifier loss: 0.755227; batch adversarial loss: 0.636519\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476429; batch adversarial loss: 0.611122\n",
      "epoch 9; iter: 200; batch classifier loss: 0.466615; batch adversarial loss: 0.634169\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455041; batch adversarial loss: 0.598300\n",
      "epoch 10; iter: 200; batch classifier loss: 0.575729; batch adversarial loss: 0.623241\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371787; batch adversarial loss: 0.622483\n",
      "epoch 11; iter: 200; batch classifier loss: 0.420535; batch adversarial loss: 0.610744\n",
      "epoch 12; iter: 0; batch classifier loss: 0.409955; batch adversarial loss: 0.616088\n",
      "epoch 12; iter: 200; batch classifier loss: 0.494993; batch adversarial loss: 0.552652\n",
      "epoch 13; iter: 0; batch classifier loss: 0.300994; batch adversarial loss: 0.661256\n",
      "epoch 13; iter: 200; batch classifier loss: 0.258260; batch adversarial loss: 0.656712\n",
      "epoch 14; iter: 0; batch classifier loss: 0.357188; batch adversarial loss: 0.615834\n",
      "epoch 14; iter: 200; batch classifier loss: 0.392440; batch adversarial loss: 0.612507\n",
      "epoch 15; iter: 0; batch classifier loss: 0.421760; batch adversarial loss: 0.597044\n",
      "epoch 15; iter: 200; batch classifier loss: 0.324926; batch adversarial loss: 0.649659\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355104; batch adversarial loss: 0.588904\n",
      "epoch 16; iter: 200; batch classifier loss: 0.604107; batch adversarial loss: 0.629446\n",
      "epoch 17; iter: 0; batch classifier loss: 0.535522; batch adversarial loss: 0.610873\n",
      "epoch 17; iter: 200; batch classifier loss: 0.372806; batch adversarial loss: 0.637487\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362672; batch adversarial loss: 0.647109\n",
      "epoch 18; iter: 200; batch classifier loss: 0.432133; batch adversarial loss: 0.560603\n",
      "epoch 19; iter: 0; batch classifier loss: 0.313439; batch adversarial loss: 0.651535\n",
      "epoch 19; iter: 200; batch classifier loss: 0.426237; batch adversarial loss: 0.605326\n",
      "epoch 0; iter: 0; batch classifier loss: 22.319799; batch adversarial loss: 0.670480\n",
      "epoch 0; iter: 200; batch classifier loss: 2.576357; batch adversarial loss: 0.655720\n",
      "epoch 1; iter: 0; batch classifier loss: 8.010492; batch adversarial loss: 0.654918\n",
      "epoch 1; iter: 200; batch classifier loss: 8.343267; batch adversarial loss: 0.649618\n",
      "epoch 2; iter: 0; batch classifier loss: 11.191159; batch adversarial loss: 0.638673\n",
      "epoch 2; iter: 200; batch classifier loss: 2.043077; batch adversarial loss: 0.612239\n",
      "epoch 3; iter: 0; batch classifier loss: 3.783012; batch adversarial loss: 0.618631\n",
      "epoch 3; iter: 200; batch classifier loss: 2.551650; batch adversarial loss: 0.646880\n",
      "epoch 4; iter: 0; batch classifier loss: 1.598280; batch adversarial loss: 0.568001\n",
      "epoch 4; iter: 200; batch classifier loss: 1.455473; batch adversarial loss: 0.634947\n",
      "epoch 5; iter: 0; batch classifier loss: 1.578539; batch adversarial loss: 0.613773\n",
      "epoch 5; iter: 200; batch classifier loss: 0.598170; batch adversarial loss: 0.631467\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401681; batch adversarial loss: 0.677913\n",
      "epoch 6; iter: 200; batch classifier loss: 1.071767; batch adversarial loss: 0.606212\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612643; batch adversarial loss: 0.619584\n",
      "epoch 7; iter: 200; batch classifier loss: 0.680613; batch adversarial loss: 0.700347\n",
      "epoch 8; iter: 0; batch classifier loss: 0.894735; batch adversarial loss: 0.610220\n",
      "epoch 8; iter: 200; batch classifier loss: 0.767615; batch adversarial loss: 0.598021\n",
      "epoch 9; iter: 0; batch classifier loss: 0.838406; batch adversarial loss: 0.589457\n",
      "epoch 9; iter: 200; batch classifier loss: 0.865923; batch adversarial loss: 0.616234\n",
      "epoch 10; iter: 0; batch classifier loss: 0.596373; batch adversarial loss: 0.679888\n",
      "epoch 10; iter: 200; batch classifier loss: 0.464984; batch adversarial loss: 0.568015\n",
      "epoch 11; iter: 0; batch classifier loss: 0.701219; batch adversarial loss: 0.577394\n",
      "epoch 11; iter: 200; batch classifier loss: 0.486611; batch adversarial loss: 0.609689\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334830; batch adversarial loss: 0.642226\n",
      "epoch 12; iter: 200; batch classifier loss: 0.365085; batch adversarial loss: 0.600796\n",
      "epoch 13; iter: 0; batch classifier loss: 0.404642; batch adversarial loss: 0.544255\n",
      "epoch 13; iter: 200; batch classifier loss: 0.520141; batch adversarial loss: 0.588078\n",
      "epoch 14; iter: 0; batch classifier loss: 0.429051; batch adversarial loss: 0.602217\n",
      "epoch 14; iter: 200; batch classifier loss: 0.417913; batch adversarial loss: 0.662682\n",
      "epoch 15; iter: 0; batch classifier loss: 0.919858; batch adversarial loss: 0.620288\n",
      "epoch 15; iter: 200; batch classifier loss: 0.365656; batch adversarial loss: 0.646762\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531170; batch adversarial loss: 0.654384\n",
      "epoch 16; iter: 200; batch classifier loss: 0.363897; batch adversarial loss: 0.584747\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383889; batch adversarial loss: 0.679466\n",
      "epoch 17; iter: 200; batch classifier loss: 0.403046; batch adversarial loss: 0.614174\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317846; batch adversarial loss: 0.647849\n",
      "epoch 18; iter: 200; batch classifier loss: 0.362316; batch adversarial loss: 0.628157\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396992; batch adversarial loss: 0.637693\n",
      "epoch 19; iter: 200; batch classifier loss: 0.397449; batch adversarial loss: 0.622766\n",
      "epoch 0; iter: 0; batch classifier loss: 6.776845; batch adversarial loss: 0.920811\n",
      "epoch 0; iter: 200; batch classifier loss: 13.361149; batch adversarial loss: 0.812846\n",
      "epoch 1; iter: 0; batch classifier loss: 7.897655; batch adversarial loss: 0.731634\n",
      "epoch 1; iter: 200; batch classifier loss: 4.678421; batch adversarial loss: 0.824390\n",
      "epoch 2; iter: 0; batch classifier loss: 5.085818; batch adversarial loss: 0.804820\n",
      "epoch 2; iter: 200; batch classifier loss: 3.593900; batch adversarial loss: 0.743963\n",
      "epoch 3; iter: 0; batch classifier loss: 2.624676; batch adversarial loss: 0.715849\n",
      "epoch 3; iter: 200; batch classifier loss: 3.692495; batch adversarial loss: 0.604917\n",
      "epoch 4; iter: 0; batch classifier loss: 1.272983; batch adversarial loss: 0.658853\n",
      "epoch 4; iter: 200; batch classifier loss: 1.041194; batch adversarial loss: 0.652276\n",
      "epoch 5; iter: 0; batch classifier loss: 1.247975; batch adversarial loss: 0.684748\n",
      "epoch 5; iter: 200; batch classifier loss: 1.072482; batch adversarial loss: 0.572767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.712261; batch adversarial loss: 0.643886\n",
      "epoch 6; iter: 200; batch classifier loss: 0.530932; batch adversarial loss: 0.584824\n",
      "epoch 7; iter: 0; batch classifier loss: 0.765327; batch adversarial loss: 0.580654\n",
      "epoch 7; iter: 200; batch classifier loss: 0.643227; batch adversarial loss: 0.694643\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535951; batch adversarial loss: 0.615481\n",
      "epoch 8; iter: 200; batch classifier loss: 0.619384; batch adversarial loss: 0.629330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.328182; batch adversarial loss: 0.635842\n",
      "epoch 9; iter: 200; batch classifier loss: 0.461788; batch adversarial loss: 0.646690\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430630; batch adversarial loss: 0.638809\n",
      "epoch 10; iter: 200; batch classifier loss: 0.549721; batch adversarial loss: 0.596842\n",
      "epoch 11; iter: 0; batch classifier loss: 0.450759; batch adversarial loss: 0.627107\n",
      "epoch 11; iter: 200; batch classifier loss: 0.461121; batch adversarial loss: 0.658660\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360365; batch adversarial loss: 0.613145\n",
      "epoch 12; iter: 200; batch classifier loss: 0.529502; batch adversarial loss: 0.672401\n",
      "epoch 13; iter: 0; batch classifier loss: 0.416045; batch adversarial loss: 0.655542\n",
      "epoch 13; iter: 200; batch classifier loss: 0.365625; batch adversarial loss: 0.582632\n",
      "epoch 14; iter: 0; batch classifier loss: 0.377782; batch adversarial loss: 0.605226\n",
      "epoch 14; iter: 200; batch classifier loss: 0.394922; batch adversarial loss: 0.657793\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489742; batch adversarial loss: 0.629391\n",
      "epoch 15; iter: 200; batch classifier loss: 0.344912; batch adversarial loss: 0.650218\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419605; batch adversarial loss: 0.665094\n",
      "epoch 16; iter: 200; batch classifier loss: 0.389791; batch adversarial loss: 0.656743\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331824; batch adversarial loss: 0.623715\n",
      "epoch 17; iter: 200; batch classifier loss: 0.460537; batch adversarial loss: 0.651215\n",
      "epoch 18; iter: 0; batch classifier loss: 0.411105; batch adversarial loss: 0.649026\n",
      "epoch 18; iter: 200; batch classifier loss: 0.815082; batch adversarial loss: 0.626184\n",
      "epoch 19; iter: 0; batch classifier loss: 0.346409; batch adversarial loss: 0.659880\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376294; batch adversarial loss: 0.641015\n",
      "epoch 0; iter: 0; batch classifier loss: 8.031734; batch adversarial loss: 0.676229\n",
      "epoch 0; iter: 200; batch classifier loss: 4.770853; batch adversarial loss: 0.678484\n",
      "epoch 1; iter: 0; batch classifier loss: 9.393206; batch adversarial loss: 0.610729\n",
      "epoch 1; iter: 200; batch classifier loss: 2.795020; batch adversarial loss: 0.628336\n",
      "epoch 2; iter: 0; batch classifier loss: 4.370952; batch adversarial loss: 0.653022\n",
      "epoch 2; iter: 200; batch classifier loss: 5.507236; batch adversarial loss: 0.647103\n",
      "epoch 3; iter: 0; batch classifier loss: 3.020566; batch adversarial loss: 0.670461\n",
      "epoch 3; iter: 200; batch classifier loss: 2.085522; batch adversarial loss: 0.635134\n",
      "epoch 4; iter: 0; batch classifier loss: 2.243107; batch adversarial loss: 0.649937\n",
      "epoch 4; iter: 200; batch classifier loss: 0.937359; batch adversarial loss: 0.657690\n",
      "epoch 5; iter: 0; batch classifier loss: 1.283739; batch adversarial loss: 0.651755\n",
      "epoch 5; iter: 200; batch classifier loss: 1.201357; batch adversarial loss: 0.677625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.991777; batch adversarial loss: 0.657078\n",
      "epoch 6; iter: 200; batch classifier loss: 0.912476; batch adversarial loss: 0.621134\n",
      "epoch 7; iter: 0; batch classifier loss: 0.642676; batch adversarial loss: 0.614582\n",
      "epoch 7; iter: 200; batch classifier loss: 0.630528; batch adversarial loss: 0.600227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.440958; batch adversarial loss: 0.632668\n",
      "epoch 8; iter: 200; batch classifier loss: 1.292451; batch adversarial loss: 0.619132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564762; batch adversarial loss: 0.676780\n",
      "epoch 9; iter: 200; batch classifier loss: 0.320587; batch adversarial loss: 0.607590\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485504; batch adversarial loss: 0.628856\n",
      "epoch 10; iter: 200; batch classifier loss: 0.463952; batch adversarial loss: 0.672992\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332841; batch adversarial loss: 0.620194\n",
      "epoch 11; iter: 200; batch classifier loss: 0.471852; batch adversarial loss: 0.604026\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410094; batch adversarial loss: 0.631601\n",
      "epoch 12; iter: 200; batch classifier loss: 0.554085; batch adversarial loss: 0.614288\n",
      "epoch 13; iter: 0; batch classifier loss: 0.451970; batch adversarial loss: 0.681029\n",
      "epoch 13; iter: 200; batch classifier loss: 0.510258; batch adversarial loss: 0.600224\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311853; batch adversarial loss: 0.608001\n",
      "epoch 14; iter: 200; batch classifier loss: 0.392457; batch adversarial loss: 0.613591\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440737; batch adversarial loss: 0.606745\n",
      "epoch 15; iter: 200; batch classifier loss: 0.432220; batch adversarial loss: 0.630674\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408823; batch adversarial loss: 0.608712\n",
      "epoch 16; iter: 200; batch classifier loss: 0.369284; batch adversarial loss: 0.631401\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340401; batch adversarial loss: 0.643715\n",
      "epoch 17; iter: 200; batch classifier loss: 0.524118; batch adversarial loss: 0.589090\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508833; batch adversarial loss: 0.641000\n",
      "epoch 18; iter: 200; batch classifier loss: 0.302532; batch adversarial loss: 0.681345\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440577; batch adversarial loss: 0.608482\n",
      "epoch 19; iter: 200; batch classifier loss: 0.355711; batch adversarial loss: 0.579252\n",
      "epoch 0; iter: 0; batch classifier loss: 20.817574; batch adversarial loss: 1.102361\n",
      "epoch 0; iter: 200; batch classifier loss: 3.544972; batch adversarial loss: 0.923430\n",
      "epoch 1; iter: 0; batch classifier loss: 8.374181; batch adversarial loss: 0.904460\n",
      "epoch 1; iter: 200; batch classifier loss: 8.704438; batch adversarial loss: 0.762259\n",
      "epoch 2; iter: 0; batch classifier loss: 6.275706; batch adversarial loss: 0.713597\n",
      "epoch 2; iter: 200; batch classifier loss: 17.089006; batch adversarial loss: 0.693337\n",
      "epoch 3; iter: 0; batch classifier loss: 7.931736; batch adversarial loss: 0.666600\n",
      "epoch 3; iter: 200; batch classifier loss: 3.757527; batch adversarial loss: 0.636798\n",
      "epoch 4; iter: 0; batch classifier loss: 3.524322; batch adversarial loss: 0.649709\n",
      "epoch 4; iter: 200; batch classifier loss: 1.589390; batch adversarial loss: 0.623902\n",
      "epoch 5; iter: 0; batch classifier loss: 2.955001; batch adversarial loss: 0.601964\n",
      "epoch 5; iter: 200; batch classifier loss: 1.305066; batch adversarial loss: 0.597472\n",
      "epoch 6; iter: 0; batch classifier loss: 2.679273; batch adversarial loss: 0.643589\n",
      "epoch 6; iter: 200; batch classifier loss: 0.958936; batch adversarial loss: 0.647728\n",
      "epoch 7; iter: 0; batch classifier loss: 1.135782; batch adversarial loss: 0.633788\n",
      "epoch 7; iter: 200; batch classifier loss: 1.701092; batch adversarial loss: 0.605203\n",
      "epoch 8; iter: 0; batch classifier loss: 0.960635; batch adversarial loss: 0.654408\n",
      "epoch 8; iter: 200; batch classifier loss: 0.914970; batch adversarial loss: 0.593964\n",
      "epoch 9; iter: 0; batch classifier loss: 1.419083; batch adversarial loss: 0.629659\n",
      "epoch 9; iter: 200; batch classifier loss: 0.969982; batch adversarial loss: 0.622458\n",
      "epoch 10; iter: 0; batch classifier loss: 0.676084; batch adversarial loss: 0.578749\n",
      "epoch 10; iter: 200; batch classifier loss: 0.776942; batch adversarial loss: 0.630142\n",
      "epoch 11; iter: 0; batch classifier loss: 0.643827; batch adversarial loss: 0.635567\n",
      "epoch 11; iter: 200; batch classifier loss: 0.370354; batch adversarial loss: 0.621032\n",
      "epoch 12; iter: 0; batch classifier loss: 0.458367; batch adversarial loss: 0.650547\n",
      "epoch 12; iter: 200; batch classifier loss: 0.405659; batch adversarial loss: 0.648145\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418240; batch adversarial loss: 0.694171\n",
      "epoch 13; iter: 200; batch classifier loss: 0.762984; batch adversarial loss: 0.625819\n",
      "epoch 14; iter: 0; batch classifier loss: 0.302414; batch adversarial loss: 0.663808\n",
      "epoch 14; iter: 200; batch classifier loss: 0.426288; batch adversarial loss: 0.598205\n",
      "epoch 15; iter: 0; batch classifier loss: 0.346133; batch adversarial loss: 0.588587\n",
      "epoch 15; iter: 200; batch classifier loss: 0.305853; batch adversarial loss: 0.627343\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437946; batch adversarial loss: 0.659247\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352046; batch adversarial loss: 0.575920\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304482; batch adversarial loss: 0.599129\n",
      "epoch 17; iter: 200; batch classifier loss: 0.290366; batch adversarial loss: 0.607742\n",
      "epoch 18; iter: 0; batch classifier loss: 0.365654; batch adversarial loss: 0.596861\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399661; batch adversarial loss: 0.624662\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324359; batch adversarial loss: 0.697910\n",
      "epoch 19; iter: 200; batch classifier loss: 0.345632; batch adversarial loss: 0.611588\n",
      "epoch 0; iter: 0; batch classifier loss: 37.895714; batch adversarial loss: 0.693636\n",
      "epoch 0; iter: 200; batch classifier loss: 6.593347; batch adversarial loss: 0.642609\n",
      "epoch 1; iter: 0; batch classifier loss: 2.463560; batch adversarial loss: 0.633206\n",
      "epoch 1; iter: 200; batch classifier loss: 13.209207; batch adversarial loss: 0.625992\n",
      "epoch 2; iter: 0; batch classifier loss: 2.207928; batch adversarial loss: 0.592656\n",
      "epoch 2; iter: 200; batch classifier loss: 7.811656; batch adversarial loss: 0.608162\n",
      "epoch 3; iter: 0; batch classifier loss: 3.674623; batch adversarial loss: 0.649327\n",
      "epoch 3; iter: 200; batch classifier loss: 2.179898; batch adversarial loss: 0.618037\n",
      "epoch 4; iter: 0; batch classifier loss: 2.067946; batch adversarial loss: 0.622353\n",
      "epoch 4; iter: 200; batch classifier loss: 0.852570; batch adversarial loss: 0.700912\n",
      "epoch 5; iter: 0; batch classifier loss: 1.038653; batch adversarial loss: 0.634215\n",
      "epoch 5; iter: 200; batch classifier loss: 0.964906; batch adversarial loss: 0.563985\n",
      "epoch 6; iter: 0; batch classifier loss: 0.616567; batch adversarial loss: 0.606270\n",
      "epoch 6; iter: 200; batch classifier loss: 1.826437; batch adversarial loss: 0.624711\n",
      "epoch 7; iter: 0; batch classifier loss: 1.184477; batch adversarial loss: 0.614965\n",
      "epoch 7; iter: 200; batch classifier loss: 0.836376; batch adversarial loss: 0.640412\n",
      "epoch 8; iter: 0; batch classifier loss: 0.903844; batch adversarial loss: 0.618644\n",
      "epoch 8; iter: 200; batch classifier loss: 0.611460; batch adversarial loss: 0.617666\n",
      "epoch 9; iter: 0; batch classifier loss: 0.615415; batch adversarial loss: 0.634411\n",
      "epoch 9; iter: 200; batch classifier loss: 1.950233; batch adversarial loss: 0.602244\n",
      "epoch 10; iter: 0; batch classifier loss: 0.402681; batch adversarial loss: 0.625060\n",
      "epoch 10; iter: 200; batch classifier loss: 0.445181; batch adversarial loss: 0.640052\n",
      "epoch 11; iter: 0; batch classifier loss: 0.421802; batch adversarial loss: 0.632145\n",
      "epoch 11; iter: 200; batch classifier loss: 0.818718; batch adversarial loss: 0.631256\n",
      "epoch 12; iter: 0; batch classifier loss: 0.445194; batch adversarial loss: 0.617460\n",
      "epoch 12; iter: 200; batch classifier loss: 0.448087; batch adversarial loss: 0.620853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.435514; batch adversarial loss: 0.623228\n",
      "epoch 13; iter: 200; batch classifier loss: 0.455779; batch adversarial loss: 0.649867\n",
      "epoch 14; iter: 0; batch classifier loss: 0.401762; batch adversarial loss: 0.590579\n",
      "epoch 14; iter: 200; batch classifier loss: 0.345488; batch adversarial loss: 0.623704\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508814; batch adversarial loss: 0.546425\n",
      "epoch 15; iter: 200; batch classifier loss: 0.457958; batch adversarial loss: 0.575054\n",
      "epoch 16; iter: 0; batch classifier loss: 0.321659; batch adversarial loss: 0.599075\n",
      "epoch 16; iter: 200; batch classifier loss: 0.558926; batch adversarial loss: 0.632755\n",
      "epoch 17; iter: 0; batch classifier loss: 0.548642; batch adversarial loss: 0.583680\n",
      "epoch 17; iter: 200; batch classifier loss: 0.337806; batch adversarial loss: 0.611667\n",
      "epoch 18; iter: 0; batch classifier loss: 0.340876; batch adversarial loss: 0.668944\n",
      "epoch 18; iter: 200; batch classifier loss: 0.424344; batch adversarial loss: 0.616970\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337421; batch adversarial loss: 0.603257\n",
      "epoch 19; iter: 200; batch classifier loss: 0.356831; batch adversarial loss: 0.629483\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 15.850466; batch adversarial loss: 0.782762\n",
      "epoch 0; iter: 200; batch classifier loss: 2.652245; batch adversarial loss: 0.681073\n",
      "epoch 1; iter: 0; batch classifier loss: 3.283684; batch adversarial loss: 0.664565\n",
      "epoch 1; iter: 200; batch classifier loss: 3.743475; batch adversarial loss: 0.627849\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647649; batch adversarial loss: 0.617886\n",
      "epoch 2; iter: 200; batch classifier loss: 2.164288; batch adversarial loss: 0.618679\n",
      "epoch 3; iter: 0; batch classifier loss: 1.655913; batch adversarial loss: 0.612284\n",
      "epoch 3; iter: 200; batch classifier loss: 3.934113; batch adversarial loss: 0.612734\n",
      "epoch 4; iter: 0; batch classifier loss: 3.401149; batch adversarial loss: 0.652842\n",
      "epoch 4; iter: 200; batch classifier loss: 2.434506; batch adversarial loss: 0.655325\n",
      "epoch 5; iter: 0; batch classifier loss: 2.545885; batch adversarial loss: 0.623643\n",
      "epoch 5; iter: 200; batch classifier loss: 2.005200; batch adversarial loss: 0.616077\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504123; batch adversarial loss: 0.590781\n",
      "epoch 6; iter: 200; batch classifier loss: 0.444016; batch adversarial loss: 0.606221\n",
      "epoch 7; iter: 0; batch classifier loss: 1.102915; batch adversarial loss: 0.663122\n",
      "epoch 7; iter: 200; batch classifier loss: 0.759875; batch adversarial loss: 0.613241\n",
      "epoch 8; iter: 0; batch classifier loss: 0.600406; batch adversarial loss: 0.624270\n",
      "epoch 8; iter: 200; batch classifier loss: 0.834464; batch adversarial loss: 0.635341\n",
      "epoch 9; iter: 0; batch classifier loss: 0.422266; batch adversarial loss: 0.619505\n",
      "epoch 9; iter: 200; batch classifier loss: 0.404153; batch adversarial loss: 0.664217\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634197; batch adversarial loss: 0.648582\n",
      "epoch 10; iter: 200; batch classifier loss: 0.464676; batch adversarial loss: 0.635186\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347198; batch adversarial loss: 0.654146\n",
      "epoch 11; iter: 200; batch classifier loss: 0.562827; batch adversarial loss: 0.628309\n",
      "epoch 12; iter: 0; batch classifier loss: 0.733975; batch adversarial loss: 0.628805\n",
      "epoch 12; iter: 200; batch classifier loss: 0.437900; batch adversarial loss: 0.594997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497368; batch adversarial loss: 0.650255\n",
      "epoch 13; iter: 200; batch classifier loss: 0.423958; batch adversarial loss: 0.653826\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315208; batch adversarial loss: 0.650394\n",
      "epoch 14; iter: 200; batch classifier loss: 0.407004; batch adversarial loss: 0.652998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.340694; batch adversarial loss: 0.650056\n",
      "epoch 15; iter: 200; batch classifier loss: 0.437871; batch adversarial loss: 0.650517\n",
      "epoch 16; iter: 0; batch classifier loss: 0.401001; batch adversarial loss: 0.650791\n",
      "epoch 16; iter: 200; batch classifier loss: 0.452310; batch adversarial loss: 0.641544\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319711; batch adversarial loss: 0.619810\n",
      "epoch 17; iter: 200; batch classifier loss: 0.448906; batch adversarial loss: 0.612852\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452778; batch adversarial loss: 0.621700\n",
      "epoch 18; iter: 200; batch classifier loss: 0.420934; batch adversarial loss: 0.667090\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343725; batch adversarial loss: 0.640463\n",
      "epoch 19; iter: 200; batch classifier loss: 0.370629; batch adversarial loss: 0.585620\n",
      "epoch 20; iter: 0; batch classifier loss: 0.355091; batch adversarial loss: 0.665281\n",
      "epoch 20; iter: 200; batch classifier loss: 0.370763; batch adversarial loss: 0.687873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.381076; batch adversarial loss: 0.587073\n",
      "epoch 21; iter: 200; batch classifier loss: 0.321531; batch adversarial loss: 0.638923\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475924; batch adversarial loss: 0.630683\n",
      "epoch 22; iter: 200; batch classifier loss: 0.452786; batch adversarial loss: 0.623491\n",
      "epoch 23; iter: 0; batch classifier loss: 0.383032; batch adversarial loss: 0.612269\n",
      "epoch 23; iter: 200; batch classifier loss: 0.315195; batch adversarial loss: 0.578564\n",
      "epoch 24; iter: 0; batch classifier loss: 0.399932; batch adversarial loss: 0.579459\n",
      "epoch 24; iter: 200; batch classifier loss: 0.465898; batch adversarial loss: 0.574018\n",
      "epoch 25; iter: 0; batch classifier loss: 0.359232; batch adversarial loss: 0.658099\n",
      "epoch 25; iter: 200; batch classifier loss: 0.402554; batch adversarial loss: 0.709377\n",
      "epoch 26; iter: 0; batch classifier loss: 0.386462; batch adversarial loss: 0.615797\n",
      "epoch 26; iter: 200; batch classifier loss: 0.422216; batch adversarial loss: 0.577011\n",
      "epoch 27; iter: 0; batch classifier loss: 0.348992; batch adversarial loss: 0.646735\n",
      "epoch 27; iter: 200; batch classifier loss: 0.345155; batch adversarial loss: 0.588314\n",
      "epoch 28; iter: 0; batch classifier loss: 0.348869; batch adversarial loss: 0.607444\n",
      "epoch 28; iter: 200; batch classifier loss: 0.394275; batch adversarial loss: 0.610943\n",
      "epoch 29; iter: 0; batch classifier loss: 0.347907; batch adversarial loss: 0.657362\n",
      "epoch 29; iter: 200; batch classifier loss: 0.315198; batch adversarial loss: 0.612542\n",
      "epoch 30; iter: 0; batch classifier loss: 0.316432; batch adversarial loss: 0.631168\n",
      "epoch 30; iter: 200; batch classifier loss: 0.317511; batch adversarial loss: 0.620820\n",
      "epoch 31; iter: 0; batch classifier loss: 0.363440; batch adversarial loss: 0.603023\n",
      "epoch 31; iter: 200; batch classifier loss: 0.311412; batch adversarial loss: 0.638538\n",
      "epoch 32; iter: 0; batch classifier loss: 0.298731; batch adversarial loss: 0.658310\n",
      "epoch 32; iter: 200; batch classifier loss: 0.487432; batch adversarial loss: 0.647559\n",
      "epoch 33; iter: 0; batch classifier loss: 0.374835; batch adversarial loss: 0.662122\n",
      "epoch 33; iter: 200; batch classifier loss: 0.414387; batch adversarial loss: 0.580454\n",
      "epoch 34; iter: 0; batch classifier loss: 0.455329; batch adversarial loss: 0.609895\n",
      "epoch 34; iter: 200; batch classifier loss: 0.414517; batch adversarial loss: 0.572169\n",
      "epoch 35; iter: 0; batch classifier loss: 0.373760; batch adversarial loss: 0.677522\n",
      "epoch 35; iter: 200; batch classifier loss: 0.403885; batch adversarial loss: 0.604532\n",
      "epoch 36; iter: 0; batch classifier loss: 0.351747; batch adversarial loss: 0.601087\n",
      "epoch 36; iter: 200; batch classifier loss: 0.346654; batch adversarial loss: 0.632775\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417760; batch adversarial loss: 0.676046\n",
      "epoch 37; iter: 200; batch classifier loss: 0.446949; batch adversarial loss: 0.642871\n",
      "epoch 38; iter: 0; batch classifier loss: 0.349761; batch adversarial loss: 0.634719\n",
      "epoch 38; iter: 200; batch classifier loss: 0.404688; batch adversarial loss: 0.660099\n",
      "epoch 39; iter: 0; batch classifier loss: 0.554185; batch adversarial loss: 0.597512\n",
      "epoch 39; iter: 200; batch classifier loss: 0.394976; batch adversarial loss: 0.573961\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391822; batch adversarial loss: 0.620864\n",
      "epoch 40; iter: 200; batch classifier loss: 0.420414; batch adversarial loss: 0.607122\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406962; batch adversarial loss: 0.628133\n",
      "epoch 41; iter: 200; batch classifier loss: 0.390442; batch adversarial loss: 0.608445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374571; batch adversarial loss: 0.597534\n",
      "epoch 42; iter: 200; batch classifier loss: 0.446039; batch adversarial loss: 0.657311\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439513; batch adversarial loss: 0.583456\n",
      "epoch 43; iter: 200; batch classifier loss: 0.437275; batch adversarial loss: 0.617483\n",
      "epoch 44; iter: 0; batch classifier loss: 0.380404; batch adversarial loss: 0.623512\n",
      "epoch 44; iter: 200; batch classifier loss: 0.353620; batch adversarial loss: 0.623306\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443118; batch adversarial loss: 0.587406\n",
      "epoch 45; iter: 200; batch classifier loss: 0.390229; batch adversarial loss: 0.568061\n",
      "epoch 46; iter: 0; batch classifier loss: 0.579358; batch adversarial loss: 0.639292\n",
      "epoch 46; iter: 200; batch classifier loss: 0.500776; batch adversarial loss: 0.617364\n",
      "epoch 47; iter: 0; batch classifier loss: 0.406516; batch adversarial loss: 0.626662\n",
      "epoch 47; iter: 200; batch classifier loss: 0.357947; batch adversarial loss: 0.628346\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385903; batch adversarial loss: 0.668503\n",
      "epoch 48; iter: 200; batch classifier loss: 0.297162; batch adversarial loss: 0.645097\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401195; batch adversarial loss: 0.584699\n",
      "epoch 49; iter: 200; batch classifier loss: 0.463745; batch adversarial loss: 0.668245\n",
      "epoch 0; iter: 0; batch classifier loss: 52.262699; batch adversarial loss: 0.934503\n",
      "epoch 0; iter: 200; batch classifier loss: 4.523028; batch adversarial loss: 0.675174\n",
      "epoch 1; iter: 0; batch classifier loss: 4.184181; batch adversarial loss: 0.674910\n",
      "epoch 1; iter: 200; batch classifier loss: 7.610850; batch adversarial loss: 0.665319\n",
      "epoch 2; iter: 0; batch classifier loss: 2.511209; batch adversarial loss: 0.644183\n",
      "epoch 2; iter: 200; batch classifier loss: 3.136180; batch adversarial loss: 0.596402\n",
      "epoch 3; iter: 0; batch classifier loss: 21.647793; batch adversarial loss: 0.621118\n",
      "epoch 3; iter: 200; batch classifier loss: 1.364818; batch adversarial loss: 0.658163\n",
      "epoch 4; iter: 0; batch classifier loss: 1.786069; batch adversarial loss: 0.633709\n",
      "epoch 4; iter: 200; batch classifier loss: 0.648176; batch adversarial loss: 0.662315\n",
      "epoch 5; iter: 0; batch classifier loss: 1.341722; batch adversarial loss: 0.644242\n",
      "epoch 5; iter: 200; batch classifier loss: 0.383737; batch adversarial loss: 0.668017\n",
      "epoch 6; iter: 0; batch classifier loss: 0.588515; batch adversarial loss: 0.642973\n",
      "epoch 6; iter: 200; batch classifier loss: 0.729849; batch adversarial loss: 0.607543\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360673; batch adversarial loss: 0.613441\n",
      "epoch 7; iter: 200; batch classifier loss: 0.625689; batch adversarial loss: 0.598517\n",
      "epoch 8; iter: 0; batch classifier loss: 0.409104; batch adversarial loss: 0.642500\n",
      "epoch 8; iter: 200; batch classifier loss: 0.384698; batch adversarial loss: 0.629181\n",
      "epoch 9; iter: 0; batch classifier loss: 0.463190; batch adversarial loss: 0.668529\n",
      "epoch 9; iter: 200; batch classifier loss: 0.498891; batch adversarial loss: 0.668233\n",
      "epoch 10; iter: 0; batch classifier loss: 0.379227; batch adversarial loss: 0.651376\n",
      "epoch 10; iter: 200; batch classifier loss: 0.447604; batch adversarial loss: 0.659906\n",
      "epoch 11; iter: 0; batch classifier loss: 1.791767; batch adversarial loss: 0.583008\n",
      "epoch 11; iter: 200; batch classifier loss: 0.379120; batch adversarial loss: 0.621920\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398475; batch adversarial loss: 0.658638\n",
      "epoch 12; iter: 200; batch classifier loss: 0.410491; batch adversarial loss: 0.596080\n",
      "epoch 13; iter: 0; batch classifier loss: 0.731910; batch adversarial loss: 0.594128\n",
      "epoch 13; iter: 200; batch classifier loss: 0.388008; batch adversarial loss: 0.592737\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412651; batch adversarial loss: 0.631273\n",
      "epoch 14; iter: 200; batch classifier loss: 0.294722; batch adversarial loss: 0.622748\n",
      "epoch 15; iter: 0; batch classifier loss: 0.351420; batch adversarial loss: 0.569695\n",
      "epoch 15; iter: 200; batch classifier loss: 0.401438; batch adversarial loss: 0.622548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522339; batch adversarial loss: 0.628256\n",
      "epoch 16; iter: 200; batch classifier loss: 0.494939; batch adversarial loss: 0.673556\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331392; batch adversarial loss: 0.646235\n",
      "epoch 17; iter: 200; batch classifier loss: 0.579602; batch adversarial loss: 0.658733\n",
      "epoch 18; iter: 0; batch classifier loss: 0.368371; batch adversarial loss: 0.640565\n",
      "epoch 18; iter: 200; batch classifier loss: 0.264284; batch adversarial loss: 0.677339\n",
      "epoch 19; iter: 0; batch classifier loss: 0.410371; batch adversarial loss: 0.593982\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372194; batch adversarial loss: 0.619256\n",
      "epoch 20; iter: 0; batch classifier loss: 0.351629; batch adversarial loss: 0.590213\n",
      "epoch 20; iter: 200; batch classifier loss: 0.401992; batch adversarial loss: 0.571863\n",
      "epoch 21; iter: 0; batch classifier loss: 0.367470; batch adversarial loss: 0.658705\n",
      "epoch 21; iter: 200; batch classifier loss: 0.440147; batch adversarial loss: 0.644023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.329918; batch adversarial loss: 0.579056\n",
      "epoch 22; iter: 200; batch classifier loss: 0.430062; batch adversarial loss: 0.632607\n",
      "epoch 23; iter: 0; batch classifier loss: 0.366337; batch adversarial loss: 0.628334\n",
      "epoch 23; iter: 200; batch classifier loss: 0.320475; batch adversarial loss: 0.587041\n",
      "epoch 24; iter: 0; batch classifier loss: 0.346508; batch adversarial loss: 0.647098\n",
      "epoch 24; iter: 200; batch classifier loss: 0.384226; batch adversarial loss: 0.663115\n",
      "epoch 25; iter: 0; batch classifier loss: 0.416637; batch adversarial loss: 0.620945\n",
      "epoch 25; iter: 200; batch classifier loss: 0.318168; batch adversarial loss: 0.641349\n",
      "epoch 26; iter: 0; batch classifier loss: 0.478567; batch adversarial loss: 0.597911\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336111; batch adversarial loss: 0.637004\n",
      "epoch 27; iter: 0; batch classifier loss: 0.326187; batch adversarial loss: 0.607183\n",
      "epoch 27; iter: 200; batch classifier loss: 0.442399; batch adversarial loss: 0.569369\n",
      "epoch 28; iter: 0; batch classifier loss: 0.398755; batch adversarial loss: 0.607888\n",
      "epoch 28; iter: 200; batch classifier loss: 0.282403; batch adversarial loss: 0.650549\n",
      "epoch 29; iter: 0; batch classifier loss: 0.383151; batch adversarial loss: 0.595261\n",
      "epoch 29; iter: 200; batch classifier loss: 0.373659; batch adversarial loss: 0.615649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.338822; batch adversarial loss: 0.673357\n",
      "epoch 30; iter: 200; batch classifier loss: 0.288661; batch adversarial loss: 0.637265\n",
      "epoch 31; iter: 0; batch classifier loss: 0.319389; batch adversarial loss: 0.678326\n",
      "epoch 31; iter: 200; batch classifier loss: 0.447809; batch adversarial loss: 0.627380\n",
      "epoch 32; iter: 0; batch classifier loss: 0.303692; batch adversarial loss: 0.617175\n",
      "epoch 32; iter: 200; batch classifier loss: 0.375395; batch adversarial loss: 0.613178\n",
      "epoch 33; iter: 0; batch classifier loss: 0.382748; batch adversarial loss: 0.595574\n",
      "epoch 33; iter: 200; batch classifier loss: 0.322489; batch adversarial loss: 0.606208\n",
      "epoch 34; iter: 0; batch classifier loss: 0.283040; batch adversarial loss: 0.643999\n",
      "epoch 34; iter: 200; batch classifier loss: 0.341800; batch adversarial loss: 0.667642\n",
      "epoch 35; iter: 0; batch classifier loss: 0.312284; batch adversarial loss: 0.613431\n",
      "epoch 35; iter: 200; batch classifier loss: 0.382718; batch adversarial loss: 0.578344\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434532; batch adversarial loss: 0.602562\n",
      "epoch 36; iter: 200; batch classifier loss: 0.392895; batch adversarial loss: 0.612851\n",
      "epoch 37; iter: 0; batch classifier loss: 0.280083; batch adversarial loss: 0.676780\n",
      "epoch 37; iter: 200; batch classifier loss: 0.505949; batch adversarial loss: 0.572170\n",
      "epoch 38; iter: 0; batch classifier loss: 0.378515; batch adversarial loss: 0.627384\n",
      "epoch 38; iter: 200; batch classifier loss: 0.371064; batch adversarial loss: 0.646527\n",
      "epoch 39; iter: 0; batch classifier loss: 0.324015; batch adversarial loss: 0.629046\n",
      "epoch 39; iter: 200; batch classifier loss: 0.343629; batch adversarial loss: 0.622881\n",
      "epoch 40; iter: 0; batch classifier loss: 0.470990; batch adversarial loss: 0.610070\n",
      "epoch 40; iter: 200; batch classifier loss: 0.330797; batch adversarial loss: 0.630800\n",
      "epoch 41; iter: 0; batch classifier loss: 0.291563; batch adversarial loss: 0.632036\n",
      "epoch 41; iter: 200; batch classifier loss: 0.451584; batch adversarial loss: 0.615835\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390202; batch adversarial loss: 0.606444\n",
      "epoch 42; iter: 200; batch classifier loss: 0.371763; batch adversarial loss: 0.593361\n",
      "epoch 43; iter: 0; batch classifier loss: 0.329712; batch adversarial loss: 0.618885\n",
      "epoch 43; iter: 200; batch classifier loss: 0.461290; batch adversarial loss: 0.666796\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433224; batch adversarial loss: 0.630970\n",
      "epoch 44; iter: 200; batch classifier loss: 0.295510; batch adversarial loss: 0.622565\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432099; batch adversarial loss: 0.645792\n",
      "epoch 45; iter: 200; batch classifier loss: 0.439207; batch adversarial loss: 0.618109\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370283; batch adversarial loss: 0.627118\n",
      "epoch 46; iter: 200; batch classifier loss: 0.604530; batch adversarial loss: 0.617886\n",
      "epoch 47; iter: 0; batch classifier loss: 0.338846; batch adversarial loss: 0.587359\n",
      "epoch 47; iter: 200; batch classifier loss: 0.319577; batch adversarial loss: 0.600785\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446466; batch adversarial loss: 0.598079\n",
      "epoch 48; iter: 200; batch classifier loss: 0.266953; batch adversarial loss: 0.646281\n",
      "epoch 49; iter: 0; batch classifier loss: 0.494743; batch adversarial loss: 0.600738\n",
      "epoch 49; iter: 200; batch classifier loss: 0.403599; batch adversarial loss: 0.605038\n",
      "epoch 0; iter: 0; batch classifier loss: 10.667272; batch adversarial loss: 0.686000\n",
      "epoch 0; iter: 200; batch classifier loss: 2.187868; batch adversarial loss: 0.628379\n",
      "epoch 1; iter: 0; batch classifier loss: 4.903064; batch adversarial loss: 0.619307\n",
      "epoch 1; iter: 200; batch classifier loss: 6.874827; batch adversarial loss: 0.669296\n",
      "epoch 2; iter: 0; batch classifier loss: 13.218570; batch adversarial loss: 0.624402\n",
      "epoch 2; iter: 200; batch classifier loss: 7.578254; batch adversarial loss: 0.675154\n",
      "epoch 3; iter: 0; batch classifier loss: 3.057552; batch adversarial loss: 0.668379\n",
      "epoch 3; iter: 200; batch classifier loss: 1.683880; batch adversarial loss: 0.635627\n",
      "epoch 4; iter: 0; batch classifier loss: 4.099536; batch adversarial loss: 0.626042\n",
      "epoch 4; iter: 200; batch classifier loss: 6.549674; batch adversarial loss: 0.614066\n",
      "epoch 5; iter: 0; batch classifier loss: 0.879537; batch adversarial loss: 0.628201\n",
      "epoch 5; iter: 200; batch classifier loss: 1.633253; batch adversarial loss: 0.638848\n",
      "epoch 6; iter: 0; batch classifier loss: 0.479240; batch adversarial loss: 0.638222\n",
      "epoch 6; iter: 200; batch classifier loss: 0.353420; batch adversarial loss: 0.667138\n",
      "epoch 7; iter: 0; batch classifier loss: 1.349774; batch adversarial loss: 0.571244\n",
      "epoch 7; iter: 200; batch classifier loss: 0.604608; batch adversarial loss: 0.643792\n",
      "epoch 8; iter: 0; batch classifier loss: 1.717106; batch adversarial loss: 0.603587\n",
      "epoch 8; iter: 200; batch classifier loss: 1.669937; batch adversarial loss: 0.603388\n",
      "epoch 9; iter: 0; batch classifier loss: 0.929596; batch adversarial loss: 0.604968\n",
      "epoch 9; iter: 200; batch classifier loss: 0.509326; batch adversarial loss: 0.624866\n",
      "epoch 10; iter: 0; batch classifier loss: 0.987209; batch adversarial loss: 0.640072\n",
      "epoch 10; iter: 200; batch classifier loss: 0.593057; batch adversarial loss: 0.586937\n",
      "epoch 11; iter: 0; batch classifier loss: 0.798075; batch adversarial loss: 0.638904\n",
      "epoch 11; iter: 200; batch classifier loss: 0.375325; batch adversarial loss: 0.593838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329115; batch adversarial loss: 0.610356\n",
      "epoch 12; iter: 200; batch classifier loss: 0.517117; batch adversarial loss: 0.669928\n",
      "epoch 13; iter: 0; batch classifier loss: 0.426349; batch adversarial loss: 0.588484\n",
      "epoch 13; iter: 200; batch classifier loss: 0.289597; batch adversarial loss: 0.617712\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261751; batch adversarial loss: 0.628670\n",
      "epoch 14; iter: 200; batch classifier loss: 0.334339; batch adversarial loss: 0.660796\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390571; batch adversarial loss: 0.589347\n",
      "epoch 15; iter: 200; batch classifier loss: 0.384688; batch adversarial loss: 0.646459\n",
      "epoch 16; iter: 0; batch classifier loss: 0.345603; batch adversarial loss: 0.697872\n",
      "epoch 16; iter: 200; batch classifier loss: 0.439603; batch adversarial loss: 0.567894\n",
      "epoch 17; iter: 0; batch classifier loss: 0.609030; batch adversarial loss: 0.682832\n",
      "epoch 17; iter: 200; batch classifier loss: 0.692568; batch adversarial loss: 0.649067\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273444; batch adversarial loss: 0.612356\n",
      "epoch 18; iter: 200; batch classifier loss: 0.376089; batch adversarial loss: 0.588583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331587; batch adversarial loss: 0.669314\n",
      "epoch 19; iter: 200; batch classifier loss: 0.365820; batch adversarial loss: 0.611642\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342757; batch adversarial loss: 0.619839\n",
      "epoch 20; iter: 200; batch classifier loss: 0.400354; batch adversarial loss: 0.629288\n",
      "epoch 21; iter: 0; batch classifier loss: 0.356257; batch adversarial loss: 0.621096\n",
      "epoch 21; iter: 200; batch classifier loss: 0.388349; batch adversarial loss: 0.590646\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466269; batch adversarial loss: 0.645405\n",
      "epoch 22; iter: 200; batch classifier loss: 0.379924; batch adversarial loss: 0.617656\n",
      "epoch 23; iter: 0; batch classifier loss: 0.353298; batch adversarial loss: 0.629748\n",
      "epoch 23; iter: 200; batch classifier loss: 0.338903; batch adversarial loss: 0.595704\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362901; batch adversarial loss: 0.641871\n",
      "epoch 24; iter: 200; batch classifier loss: 0.428796; batch adversarial loss: 0.640437\n",
      "epoch 25; iter: 0; batch classifier loss: 0.414213; batch adversarial loss: 0.648801\n",
      "epoch 25; iter: 200; batch classifier loss: 0.296624; batch adversarial loss: 0.613078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334082; batch adversarial loss: 0.586511\n",
      "epoch 26; iter: 200; batch classifier loss: 0.281180; batch adversarial loss: 0.633935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327215; batch adversarial loss: 0.667995\n",
      "epoch 27; iter: 200; batch classifier loss: 0.367170; batch adversarial loss: 0.619259\n",
      "epoch 28; iter: 0; batch classifier loss: 0.292466; batch adversarial loss: 0.597720\n",
      "epoch 28; iter: 200; batch classifier loss: 0.421594; batch adversarial loss: 0.604067\n",
      "epoch 29; iter: 0; batch classifier loss: 0.316367; batch adversarial loss: 0.657465\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338467; batch adversarial loss: 0.569427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.360517; batch adversarial loss: 0.580244\n",
      "epoch 30; iter: 200; batch classifier loss: 0.454194; batch adversarial loss: 0.635417\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366433; batch adversarial loss: 0.591081\n",
      "epoch 31; iter: 200; batch classifier loss: 0.306056; batch adversarial loss: 0.648159\n",
      "epoch 32; iter: 0; batch classifier loss: 0.290063; batch adversarial loss: 0.636140\n",
      "epoch 32; iter: 200; batch classifier loss: 0.345249; batch adversarial loss: 0.629416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.556621; batch adversarial loss: 0.615969\n",
      "epoch 33; iter: 200; batch classifier loss: 0.287282; batch adversarial loss: 0.590414\n",
      "epoch 34; iter: 0; batch classifier loss: 0.303221; batch adversarial loss: 0.589138\n",
      "epoch 34; iter: 200; batch classifier loss: 0.506637; batch adversarial loss: 0.533479\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441192; batch adversarial loss: 0.628365\n",
      "epoch 35; iter: 200; batch classifier loss: 0.438945; batch adversarial loss: 0.653112\n",
      "epoch 36; iter: 0; batch classifier loss: 0.663145; batch adversarial loss: 0.576609\n",
      "epoch 36; iter: 200; batch classifier loss: 0.415039; batch adversarial loss: 0.565569\n",
      "epoch 37; iter: 0; batch classifier loss: 0.589484; batch adversarial loss: 0.623587\n",
      "epoch 37; iter: 200; batch classifier loss: 0.336633; batch adversarial loss: 0.621094\n",
      "epoch 38; iter: 0; batch classifier loss: 0.341144; batch adversarial loss: 0.644040\n",
      "epoch 38; iter: 200; batch classifier loss: 0.400730; batch adversarial loss: 0.682724\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407708; batch adversarial loss: 0.609330\n",
      "epoch 39; iter: 200; batch classifier loss: 0.418940; batch adversarial loss: 0.676015\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436817; batch adversarial loss: 0.650623\n",
      "epoch 40; iter: 200; batch classifier loss: 0.376031; batch adversarial loss: 0.661637\n",
      "epoch 41; iter: 0; batch classifier loss: 0.328198; batch adversarial loss: 0.655716\n",
      "epoch 41; iter: 200; batch classifier loss: 0.298099; batch adversarial loss: 0.638382\n",
      "epoch 42; iter: 0; batch classifier loss: 0.425426; batch adversarial loss: 0.616201\n",
      "epoch 42; iter: 200; batch classifier loss: 0.318710; batch adversarial loss: 0.623217\n",
      "epoch 43; iter: 0; batch classifier loss: 0.360584; batch adversarial loss: 0.648444\n",
      "epoch 43; iter: 200; batch classifier loss: 0.358938; batch adversarial loss: 0.588330\n",
      "epoch 44; iter: 0; batch classifier loss: 0.421756; batch adversarial loss: 0.638871\n",
      "epoch 44; iter: 200; batch classifier loss: 0.402801; batch adversarial loss: 0.613312\n",
      "epoch 45; iter: 0; batch classifier loss: 0.390548; batch adversarial loss: 0.597974\n",
      "epoch 45; iter: 200; batch classifier loss: 0.297751; batch adversarial loss: 0.662584\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428461; batch adversarial loss: 0.639538\n",
      "epoch 46; iter: 200; batch classifier loss: 0.536299; batch adversarial loss: 0.614268\n",
      "epoch 47; iter: 0; batch classifier loss: 0.363746; batch adversarial loss: 0.571913\n",
      "epoch 47; iter: 200; batch classifier loss: 0.386889; batch adversarial loss: 0.621284\n",
      "epoch 48; iter: 0; batch classifier loss: 0.304436; batch adversarial loss: 0.644117\n",
      "epoch 48; iter: 200; batch classifier loss: 0.365783; batch adversarial loss: 0.644159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371022; batch adversarial loss: 0.617758\n",
      "epoch 49; iter: 200; batch classifier loss: 0.366204; batch adversarial loss: 0.571579\n",
      "epoch 0; iter: 0; batch classifier loss: 128.136261; batch adversarial loss: 0.773321\n",
      "epoch 0; iter: 200; batch classifier loss: 4.371793; batch adversarial loss: 0.700081\n",
      "epoch 1; iter: 0; batch classifier loss: 11.154590; batch adversarial loss: 0.679013\n",
      "epoch 1; iter: 200; batch classifier loss: 8.283151; batch adversarial loss: 0.637055\n",
      "epoch 2; iter: 0; batch classifier loss: 4.901032; batch adversarial loss: 0.691186\n",
      "epoch 2; iter: 200; batch classifier loss: 29.738276; batch adversarial loss: 0.617609\n",
      "epoch 3; iter: 0; batch classifier loss: 1.316506; batch adversarial loss: 0.616930\n",
      "epoch 3; iter: 200; batch classifier loss: 2.537256; batch adversarial loss: 0.654788\n",
      "epoch 4; iter: 0; batch classifier loss: 3.257607; batch adversarial loss: 0.709376\n",
      "epoch 4; iter: 200; batch classifier loss: 3.630406; batch adversarial loss: 0.636273\n",
      "epoch 5; iter: 0; batch classifier loss: 1.047359; batch adversarial loss: 0.634186\n",
      "epoch 5; iter: 200; batch classifier loss: 3.559541; batch adversarial loss: 0.625874\n",
      "epoch 6; iter: 0; batch classifier loss: 0.803658; batch adversarial loss: 0.648328\n",
      "epoch 6; iter: 200; batch classifier loss: 0.866932; batch adversarial loss: 0.640638\n",
      "epoch 7; iter: 0; batch classifier loss: 1.388040; batch adversarial loss: 0.660815\n",
      "epoch 7; iter: 200; batch classifier loss: 0.774829; batch adversarial loss: 0.692820\n",
      "epoch 8; iter: 0; batch classifier loss: 1.493837; batch adversarial loss: 0.614074\n",
      "epoch 8; iter: 200; batch classifier loss: 0.681497; batch adversarial loss: 0.612015\n",
      "epoch 9; iter: 0; batch classifier loss: 1.418922; batch adversarial loss: 0.647317\n",
      "epoch 9; iter: 200; batch classifier loss: 0.653422; batch adversarial loss: 0.627611\n",
      "epoch 10; iter: 0; batch classifier loss: 0.831986; batch adversarial loss: 0.608779\n",
      "epoch 10; iter: 200; batch classifier loss: 0.682876; batch adversarial loss: 0.630974\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564166; batch adversarial loss: 0.632961\n",
      "epoch 11; iter: 200; batch classifier loss: 0.566976; batch adversarial loss: 0.642253\n",
      "epoch 12; iter: 0; batch classifier loss: 0.358137; batch adversarial loss: 0.570611\n",
      "epoch 12; iter: 200; batch classifier loss: 0.694420; batch adversarial loss: 0.597989\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480050; batch adversarial loss: 0.646900\n",
      "epoch 13; iter: 200; batch classifier loss: 0.447705; batch adversarial loss: 0.653064\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412863; batch adversarial loss: 0.626898\n",
      "epoch 14; iter: 200; batch classifier loss: 0.499297; batch adversarial loss: 0.658705\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520304; batch adversarial loss: 0.620936\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392237; batch adversarial loss: 0.626975\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352709; batch adversarial loss: 0.634012\n",
      "epoch 16; iter: 200; batch classifier loss: 0.836636; batch adversarial loss: 0.641523\n",
      "epoch 17; iter: 0; batch classifier loss: 0.359403; batch adversarial loss: 0.662461\n",
      "epoch 17; iter: 200; batch classifier loss: 0.467924; batch adversarial loss: 0.623145\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366407; batch adversarial loss: 0.669834\n",
      "epoch 18; iter: 200; batch classifier loss: 0.379878; batch adversarial loss: 0.603314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.306726; batch adversarial loss: 0.638633\n",
      "epoch 19; iter: 200; batch classifier loss: 0.390337; batch adversarial loss: 0.643516\n",
      "epoch 20; iter: 0; batch classifier loss: 0.384267; batch adversarial loss: 0.634270\n",
      "epoch 20; iter: 200; batch classifier loss: 0.398177; batch adversarial loss: 0.619858\n",
      "epoch 21; iter: 0; batch classifier loss: 0.575671; batch adversarial loss: 0.623103\n",
      "epoch 21; iter: 200; batch classifier loss: 0.523476; batch adversarial loss: 0.574679\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437561; batch adversarial loss: 0.633066\n",
      "epoch 22; iter: 200; batch classifier loss: 0.412645; batch adversarial loss: 0.610425\n",
      "epoch 23; iter: 0; batch classifier loss: 0.329953; batch adversarial loss: 0.607889\n",
      "epoch 23; iter: 200; batch classifier loss: 0.435656; batch adversarial loss: 0.588445\n",
      "epoch 24; iter: 0; batch classifier loss: 0.393652; batch adversarial loss: 0.563356\n",
      "epoch 24; iter: 200; batch classifier loss: 0.383098; batch adversarial loss: 0.611753\n",
      "epoch 25; iter: 0; batch classifier loss: 0.328074; batch adversarial loss: 0.639589\n",
      "epoch 25; iter: 200; batch classifier loss: 0.381627; batch adversarial loss: 0.579554\n",
      "epoch 26; iter: 0; batch classifier loss: 0.382750; batch adversarial loss: 0.598145\n",
      "epoch 26; iter: 200; batch classifier loss: 0.417285; batch adversarial loss: 0.583359\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424185; batch adversarial loss: 0.620576\n",
      "epoch 27; iter: 200; batch classifier loss: 0.314893; batch adversarial loss: 0.638937\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291431; batch adversarial loss: 0.688245\n",
      "epoch 28; iter: 200; batch classifier loss: 0.338200; batch adversarial loss: 0.585156\n",
      "epoch 29; iter: 0; batch classifier loss: 0.412487; batch adversarial loss: 0.626221\n",
      "epoch 29; iter: 200; batch classifier loss: 0.355335; batch adversarial loss: 0.593064\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406139; batch adversarial loss: 0.635091\n",
      "epoch 30; iter: 200; batch classifier loss: 0.314355; batch adversarial loss: 0.585383\n",
      "epoch 31; iter: 0; batch classifier loss: 0.378710; batch adversarial loss: 0.620890\n",
      "epoch 31; iter: 200; batch classifier loss: 0.327624; batch adversarial loss: 0.592527\n",
      "epoch 32; iter: 0; batch classifier loss: 0.374133; batch adversarial loss: 0.623063\n",
      "epoch 32; iter: 200; batch classifier loss: 0.380365; batch adversarial loss: 0.648039\n",
      "epoch 33; iter: 0; batch classifier loss: 0.368060; batch adversarial loss: 0.638100\n",
      "epoch 33; iter: 200; batch classifier loss: 0.377247; batch adversarial loss: 0.660773\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420236; batch adversarial loss: 0.621378\n",
      "epoch 34; iter: 200; batch classifier loss: 0.443084; batch adversarial loss: 0.569071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371419; batch adversarial loss: 0.640581\n",
      "epoch 35; iter: 200; batch classifier loss: 0.314082; batch adversarial loss: 0.666752\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368958; batch adversarial loss: 0.642855\n",
      "epoch 36; iter: 200; batch classifier loss: 0.435155; batch adversarial loss: 0.654910\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474979; batch adversarial loss: 0.588430\n",
      "epoch 37; iter: 200; batch classifier loss: 0.336790; batch adversarial loss: 0.584775\n",
      "epoch 38; iter: 0; batch classifier loss: 0.327018; batch adversarial loss: 0.638046\n",
      "epoch 38; iter: 200; batch classifier loss: 0.451135; batch adversarial loss: 0.635244\n",
      "epoch 39; iter: 0; batch classifier loss: 0.332154; batch adversarial loss: 0.568844\n",
      "epoch 39; iter: 200; batch classifier loss: 0.343446; batch adversarial loss: 0.633815\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428885; batch adversarial loss: 0.645677\n",
      "epoch 40; iter: 200; batch classifier loss: 0.358768; batch adversarial loss: 0.676850\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433668; batch adversarial loss: 0.640062\n",
      "epoch 41; iter: 200; batch classifier loss: 0.443978; batch adversarial loss: 0.645713\n",
      "epoch 42; iter: 0; batch classifier loss: 0.321626; batch adversarial loss: 0.631124\n",
      "epoch 42; iter: 200; batch classifier loss: 0.364684; batch adversarial loss: 0.637952\n",
      "epoch 43; iter: 0; batch classifier loss: 0.350977; batch adversarial loss: 0.638045\n",
      "epoch 43; iter: 200; batch classifier loss: 0.335488; batch adversarial loss: 0.592237\n",
      "epoch 44; iter: 0; batch classifier loss: 0.312478; batch adversarial loss: 0.668685\n",
      "epoch 44; iter: 200; batch classifier loss: 0.472919; batch adversarial loss: 0.613551\n",
      "epoch 45; iter: 0; batch classifier loss: 0.517128; batch adversarial loss: 0.637194\n",
      "epoch 45; iter: 200; batch classifier loss: 0.414244; batch adversarial loss: 0.609711\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378828; batch adversarial loss: 0.598482\n",
      "epoch 46; iter: 200; batch classifier loss: 0.315247; batch adversarial loss: 0.627260\n",
      "epoch 47; iter: 0; batch classifier loss: 0.311914; batch adversarial loss: 0.635686\n",
      "epoch 47; iter: 200; batch classifier loss: 0.348101; batch adversarial loss: 0.651271\n",
      "epoch 48; iter: 0; batch classifier loss: 0.473491; batch adversarial loss: 0.679585\n",
      "epoch 48; iter: 200; batch classifier loss: 0.558128; batch adversarial loss: 0.575774\n",
      "epoch 49; iter: 0; batch classifier loss: 0.502782; batch adversarial loss: 0.633835\n",
      "epoch 49; iter: 200; batch classifier loss: 0.366794; batch adversarial loss: 0.681930\n",
      "epoch 0; iter: 0; batch classifier loss: 104.822556; batch adversarial loss: 0.810080\n",
      "epoch 0; iter: 200; batch classifier loss: 9.230994; batch adversarial loss: 0.731901\n",
      "epoch 1; iter: 0; batch classifier loss: 6.377584; batch adversarial loss: 0.692110\n",
      "epoch 1; iter: 200; batch classifier loss: 8.300114; batch adversarial loss: 0.672698\n",
      "epoch 2; iter: 0; batch classifier loss: 12.363472; batch adversarial loss: 0.673546\n",
      "epoch 2; iter: 200; batch classifier loss: 2.861296; batch adversarial loss: 0.622391\n",
      "epoch 3; iter: 0; batch classifier loss: 2.444290; batch adversarial loss: 0.582209\n",
      "epoch 3; iter: 200; batch classifier loss: 2.441620; batch adversarial loss: 0.645424\n",
      "epoch 4; iter: 0; batch classifier loss: 5.963706; batch adversarial loss: 0.649658\n",
      "epoch 4; iter: 200; batch classifier loss: 1.782721; batch adversarial loss: 0.640275\n",
      "epoch 5; iter: 0; batch classifier loss: 1.147243; batch adversarial loss: 0.635922\n",
      "epoch 5; iter: 200; batch classifier loss: 0.591426; batch adversarial loss: 0.602478\n",
      "epoch 6; iter: 0; batch classifier loss: 0.737858; batch adversarial loss: 0.694166\n",
      "epoch 6; iter: 200; batch classifier loss: 1.131866; batch adversarial loss: 0.668650\n",
      "epoch 7; iter: 0; batch classifier loss: 1.569475; batch adversarial loss: 0.633561\n",
      "epoch 7; iter: 200; batch classifier loss: 0.581650; batch adversarial loss: 0.634557\n",
      "epoch 8; iter: 0; batch classifier loss: 1.481463; batch adversarial loss: 0.670931\n",
      "epoch 8; iter: 200; batch classifier loss: 1.247868; batch adversarial loss: 0.626611\n",
      "epoch 9; iter: 0; batch classifier loss: 0.834441; batch adversarial loss: 0.637748\n",
      "epoch 9; iter: 200; batch classifier loss: 0.406435; batch adversarial loss: 0.660963\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464082; batch adversarial loss: 0.647600\n",
      "epoch 10; iter: 200; batch classifier loss: 0.415255; batch adversarial loss: 0.628982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568364; batch adversarial loss: 0.652339\n",
      "epoch 11; iter: 200; batch classifier loss: 0.417229; batch adversarial loss: 0.660031\n",
      "epoch 12; iter: 0; batch classifier loss: 0.482966; batch adversarial loss: 0.601608\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420921; batch adversarial loss: 0.644257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.366339; batch adversarial loss: 0.584132\n",
      "epoch 13; iter: 200; batch classifier loss: 0.575903; batch adversarial loss: 0.602912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.366675; batch adversarial loss: 0.646910\n",
      "epoch 14; iter: 200; batch classifier loss: 0.372906; batch adversarial loss: 0.596973\n",
      "epoch 15; iter: 0; batch classifier loss: 0.450820; batch adversarial loss: 0.669588\n",
      "epoch 15; iter: 200; batch classifier loss: 0.367373; batch adversarial loss: 0.606814\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500818; batch adversarial loss: 0.561651\n",
      "epoch 16; iter: 200; batch classifier loss: 0.403184; batch adversarial loss: 0.612833\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443761; batch adversarial loss: 0.613605\n",
      "epoch 17; iter: 200; batch classifier loss: 0.650479; batch adversarial loss: 0.617715\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485311; batch adversarial loss: 0.641950\n",
      "epoch 18; iter: 200; batch classifier loss: 0.316644; batch adversarial loss: 0.579088\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311028; batch adversarial loss: 0.619653\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350930; batch adversarial loss: 0.650371\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430476; batch adversarial loss: 0.615542\n",
      "epoch 20; iter: 200; batch classifier loss: 0.406336; batch adversarial loss: 0.628024\n",
      "epoch 21; iter: 0; batch classifier loss: 0.468659; batch adversarial loss: 0.602892\n",
      "epoch 21; iter: 200; batch classifier loss: 0.454809; batch adversarial loss: 0.628235\n",
      "epoch 22; iter: 0; batch classifier loss: 0.336382; batch adversarial loss: 0.616196\n",
      "epoch 22; iter: 200; batch classifier loss: 0.412397; batch adversarial loss: 0.595833\n",
      "epoch 23; iter: 0; batch classifier loss: 0.315436; batch adversarial loss: 0.689487\n",
      "epoch 23; iter: 200; batch classifier loss: 0.321147; batch adversarial loss: 0.631045\n",
      "epoch 24; iter: 0; batch classifier loss: 0.412473; batch adversarial loss: 0.694466\n",
      "epoch 24; iter: 200; batch classifier loss: 0.240864; batch adversarial loss: 0.610142\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431954; batch adversarial loss: 0.635014\n",
      "epoch 25; iter: 200; batch classifier loss: 0.435391; batch adversarial loss: 0.589685\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387157; batch adversarial loss: 0.659315\n",
      "epoch 26; iter: 200; batch classifier loss: 0.292783; batch adversarial loss: 0.693379\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321366; batch adversarial loss: 0.665226\n",
      "epoch 27; iter: 200; batch classifier loss: 0.409455; batch adversarial loss: 0.602230\n",
      "epoch 28; iter: 0; batch classifier loss: 0.374779; batch adversarial loss: 0.642160\n",
      "epoch 28; iter: 200; batch classifier loss: 0.323312; batch adversarial loss: 0.584366\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388452; batch adversarial loss: 0.637568\n",
      "epoch 29; iter: 200; batch classifier loss: 0.403664; batch adversarial loss: 0.603051\n",
      "epoch 30; iter: 0; batch classifier loss: 0.271113; batch adversarial loss: 0.613520\n",
      "epoch 30; iter: 200; batch classifier loss: 0.259638; batch adversarial loss: 0.616220\n",
      "epoch 31; iter: 0; batch classifier loss: 0.392504; batch adversarial loss: 0.627203\n",
      "epoch 31; iter: 200; batch classifier loss: 0.339495; batch adversarial loss: 0.631556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.375662; batch adversarial loss: 0.600921\n",
      "epoch 32; iter: 200; batch classifier loss: 0.351749; batch adversarial loss: 0.586631\n",
      "epoch 33; iter: 0; batch classifier loss: 0.276618; batch adversarial loss: 0.631565\n",
      "epoch 33; iter: 200; batch classifier loss: 0.248247; batch adversarial loss: 0.664625\n",
      "epoch 34; iter: 0; batch classifier loss: 0.370987; batch adversarial loss: 0.602739\n",
      "epoch 34; iter: 200; batch classifier loss: 0.452468; batch adversarial loss: 0.662215\n",
      "epoch 35; iter: 0; batch classifier loss: 0.414872; batch adversarial loss: 0.588650\n",
      "epoch 35; iter: 200; batch classifier loss: 0.377295; batch adversarial loss: 0.585580\n",
      "epoch 36; iter: 0; batch classifier loss: 0.364869; batch adversarial loss: 0.651521\n",
      "epoch 36; iter: 200; batch classifier loss: 0.365733; batch adversarial loss: 0.617229\n",
      "epoch 37; iter: 0; batch classifier loss: 0.517081; batch adversarial loss: 0.630720\n",
      "epoch 37; iter: 200; batch classifier loss: 0.352850; batch adversarial loss: 0.615437\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373292; batch adversarial loss: 0.676089\n",
      "epoch 38; iter: 200; batch classifier loss: 0.452355; batch adversarial loss: 0.683271\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418539; batch adversarial loss: 0.577711\n",
      "epoch 39; iter: 200; batch classifier loss: 0.334512; batch adversarial loss: 0.700952\n",
      "epoch 40; iter: 0; batch classifier loss: 0.274791; batch adversarial loss: 0.651286\n",
      "epoch 40; iter: 200; batch classifier loss: 0.383078; batch adversarial loss: 0.580336\n",
      "epoch 41; iter: 0; batch classifier loss: 0.277923; batch adversarial loss: 0.608119\n",
      "epoch 41; iter: 200; batch classifier loss: 0.355878; batch adversarial loss: 0.643771\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421542; batch adversarial loss: 0.661731\n",
      "epoch 42; iter: 200; batch classifier loss: 0.490657; batch adversarial loss: 0.652216\n",
      "epoch 43; iter: 0; batch classifier loss: 0.367786; batch adversarial loss: 0.623155\n",
      "epoch 43; iter: 200; batch classifier loss: 0.397515; batch adversarial loss: 0.637729\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358262; batch adversarial loss: 0.619846\n",
      "epoch 44; iter: 200; batch classifier loss: 0.335393; batch adversarial loss: 0.650792\n",
      "epoch 45; iter: 0; batch classifier loss: 0.341424; batch adversarial loss: 0.614774\n",
      "epoch 45; iter: 200; batch classifier loss: 0.467544; batch adversarial loss: 0.643035\n",
      "epoch 46; iter: 0; batch classifier loss: 0.376670; batch adversarial loss: 0.654362\n",
      "epoch 46; iter: 200; batch classifier loss: 0.313124; batch adversarial loss: 0.674987\n",
      "epoch 47; iter: 0; batch classifier loss: 0.382270; batch adversarial loss: 0.652655\n",
      "epoch 47; iter: 200; batch classifier loss: 0.360245; batch adversarial loss: 0.671966\n",
      "epoch 48; iter: 0; batch classifier loss: 0.390207; batch adversarial loss: 0.623709\n",
      "epoch 48; iter: 200; batch classifier loss: 0.320432; batch adversarial loss: 0.640500\n",
      "epoch 49; iter: 0; batch classifier loss: 0.538450; batch adversarial loss: 0.669979\n",
      "epoch 49; iter: 200; batch classifier loss: 0.383921; batch adversarial loss: 0.673429\n",
      "epoch 0; iter: 0; batch classifier loss: 75.937988; batch adversarial loss: 0.847753\n",
      "epoch 0; iter: 200; batch classifier loss: 0.797848; batch adversarial loss: 0.703134\n",
      "epoch 1; iter: 0; batch classifier loss: 8.802726; batch adversarial loss: 0.681368\n",
      "epoch 1; iter: 200; batch classifier loss: 2.426613; batch adversarial loss: 0.649453\n",
      "epoch 2; iter: 0; batch classifier loss: 3.852141; batch adversarial loss: 0.624894\n",
      "epoch 2; iter: 200; batch classifier loss: 4.944366; batch adversarial loss: 0.646277\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017428; batch adversarial loss: 0.615167\n",
      "epoch 3; iter: 200; batch classifier loss: 1.722973; batch adversarial loss: 0.639412\n",
      "epoch 4; iter: 0; batch classifier loss: 1.715349; batch adversarial loss: 0.615327\n",
      "epoch 4; iter: 200; batch classifier loss: 1.357987; batch adversarial loss: 0.621067\n",
      "epoch 5; iter: 0; batch classifier loss: 4.014961; batch adversarial loss: 0.576190\n",
      "epoch 5; iter: 200; batch classifier loss: 1.246349; batch adversarial loss: 0.674671\n",
      "epoch 6; iter: 0; batch classifier loss: 0.420239; batch adversarial loss: 0.650447\n",
      "epoch 6; iter: 200; batch classifier loss: 4.308526; batch adversarial loss: 0.627693\n",
      "epoch 7; iter: 0; batch classifier loss: 0.926908; batch adversarial loss: 0.629046\n",
      "epoch 7; iter: 200; batch classifier loss: 0.790411; batch adversarial loss: 0.562051\n",
      "epoch 8; iter: 0; batch classifier loss: 0.924953; batch adversarial loss: 0.649110\n",
      "epoch 8; iter: 200; batch classifier loss: 0.792952; batch adversarial loss: 0.586521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.957887; batch adversarial loss: 0.596665\n",
      "epoch 9; iter: 200; batch classifier loss: 0.498309; batch adversarial loss: 0.604432\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321544; batch adversarial loss: 0.653233\n",
      "epoch 10; iter: 200; batch classifier loss: 0.510241; batch adversarial loss: 0.601891\n",
      "epoch 11; iter: 0; batch classifier loss: 0.497122; batch adversarial loss: 0.598893\n",
      "epoch 11; iter: 200; batch classifier loss: 0.382363; batch adversarial loss: 0.656652\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352366; batch adversarial loss: 0.644608\n",
      "epoch 12; iter: 200; batch classifier loss: 0.457265; batch adversarial loss: 0.654267\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552564; batch adversarial loss: 0.584311\n",
      "epoch 13; iter: 200; batch classifier loss: 0.529932; batch adversarial loss: 0.645492\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396948; batch adversarial loss: 0.643556\n",
      "epoch 14; iter: 200; batch classifier loss: 0.413600; batch adversarial loss: 0.620822\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409506; batch adversarial loss: 0.633038\n",
      "epoch 15; iter: 200; batch classifier loss: 0.474920; batch adversarial loss: 0.637214\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297413; batch adversarial loss: 0.686039\n",
      "epoch 16; iter: 200; batch classifier loss: 0.293581; batch adversarial loss: 0.627534\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363168; batch adversarial loss: 0.610471\n",
      "epoch 17; iter: 200; batch classifier loss: 0.312500; batch adversarial loss: 0.607395\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531307; batch adversarial loss: 0.711234\n",
      "epoch 18; iter: 200; batch classifier loss: 0.409743; batch adversarial loss: 0.649676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408819; batch adversarial loss: 0.685111\n",
      "epoch 19; iter: 200; batch classifier loss: 0.302903; batch adversarial loss: 0.630176\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325754; batch adversarial loss: 0.591560\n",
      "epoch 20; iter: 200; batch classifier loss: 0.378172; batch adversarial loss: 0.662951\n",
      "epoch 21; iter: 0; batch classifier loss: 0.331126; batch adversarial loss: 0.596653\n",
      "epoch 21; iter: 200; batch classifier loss: 0.303365; batch adversarial loss: 0.642346\n",
      "epoch 22; iter: 0; batch classifier loss: 0.383271; batch adversarial loss: 0.643177\n",
      "epoch 22; iter: 200; batch classifier loss: 0.395284; batch adversarial loss: 0.575810\n",
      "epoch 23; iter: 0; batch classifier loss: 0.361851; batch adversarial loss: 0.575847\n",
      "epoch 23; iter: 200; batch classifier loss: 0.340479; batch adversarial loss: 0.693965\n",
      "epoch 24; iter: 0; batch classifier loss: 0.341152; batch adversarial loss: 0.630026\n",
      "epoch 24; iter: 200; batch classifier loss: 0.335797; batch adversarial loss: 0.613342\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436363; batch adversarial loss: 0.643332\n",
      "epoch 25; iter: 200; batch classifier loss: 0.366509; batch adversarial loss: 0.621314\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378526; batch adversarial loss: 0.610316\n",
      "epoch 26; iter: 200; batch classifier loss: 0.331188; batch adversarial loss: 0.607373\n",
      "epoch 27; iter: 0; batch classifier loss: 0.288175; batch adversarial loss: 0.647151\n",
      "epoch 27; iter: 200; batch classifier loss: 0.343069; batch adversarial loss: 0.634633\n",
      "epoch 28; iter: 0; batch classifier loss: 0.330356; batch adversarial loss: 0.635211\n",
      "epoch 28; iter: 200; batch classifier loss: 0.260042; batch adversarial loss: 0.576593\n",
      "epoch 29; iter: 0; batch classifier loss: 0.344780; batch adversarial loss: 0.657098\n",
      "epoch 29; iter: 200; batch classifier loss: 0.342985; batch adversarial loss: 0.566389\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323285; batch adversarial loss: 0.636181\n",
      "epoch 30; iter: 200; batch classifier loss: 0.389226; batch adversarial loss: 0.671461\n",
      "epoch 31; iter: 0; batch classifier loss: 0.286952; batch adversarial loss: 0.601597\n",
      "epoch 31; iter: 200; batch classifier loss: 0.370837; batch adversarial loss: 0.602587\n",
      "epoch 32; iter: 0; batch classifier loss: 0.366693; batch adversarial loss: 0.656541\n",
      "epoch 32; iter: 200; batch classifier loss: 0.353039; batch adversarial loss: 0.608207\n",
      "epoch 33; iter: 0; batch classifier loss: 0.382682; batch adversarial loss: 0.597136\n",
      "epoch 33; iter: 200; batch classifier loss: 0.329434; batch adversarial loss: 0.595325\n",
      "epoch 34; iter: 0; batch classifier loss: 0.245184; batch adversarial loss: 0.633106\n",
      "epoch 34; iter: 200; batch classifier loss: 0.461667; batch adversarial loss: 0.643524\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472056; batch adversarial loss: 0.626865\n",
      "epoch 35; iter: 200; batch classifier loss: 0.414248; batch adversarial loss: 0.675842\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439822; batch adversarial loss: 0.594336\n",
      "epoch 36; iter: 200; batch classifier loss: 0.267387; batch adversarial loss: 0.621641\n",
      "epoch 37; iter: 0; batch classifier loss: 0.283530; batch adversarial loss: 0.682012\n",
      "epoch 37; iter: 200; batch classifier loss: 0.454062; batch adversarial loss: 0.656229\n",
      "epoch 38; iter: 0; batch classifier loss: 0.301676; batch adversarial loss: 0.662022\n",
      "epoch 38; iter: 200; batch classifier loss: 0.358632; batch adversarial loss: 0.655054\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407668; batch adversarial loss: 0.607984\n",
      "epoch 39; iter: 200; batch classifier loss: 0.419268; batch adversarial loss: 0.571148\n",
      "epoch 40; iter: 0; batch classifier loss: 0.454990; batch adversarial loss: 0.684828\n",
      "epoch 40; iter: 200; batch classifier loss: 0.381406; batch adversarial loss: 0.631425\n",
      "epoch 41; iter: 0; batch classifier loss: 0.420445; batch adversarial loss: 0.631070\n",
      "epoch 41; iter: 200; batch classifier loss: 0.377210; batch adversarial loss: 0.679919\n",
      "epoch 42; iter: 0; batch classifier loss: 0.446086; batch adversarial loss: 0.633204\n",
      "epoch 42; iter: 200; batch classifier loss: 0.365846; batch adversarial loss: 0.619652\n",
      "epoch 43; iter: 0; batch classifier loss: 0.453055; batch adversarial loss: 0.583234\n",
      "epoch 43; iter: 200; batch classifier loss: 0.350404; batch adversarial loss: 0.667829\n",
      "epoch 44; iter: 0; batch classifier loss: 0.391405; batch adversarial loss: 0.603438\n",
      "epoch 44; iter: 200; batch classifier loss: 0.353757; batch adversarial loss: 0.565647\n",
      "epoch 45; iter: 0; batch classifier loss: 0.612684; batch adversarial loss: 0.609965\n",
      "epoch 45; iter: 200; batch classifier loss: 0.313368; batch adversarial loss: 0.564923\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459924; batch adversarial loss: 0.628267\n",
      "epoch 46; iter: 200; batch classifier loss: 0.484637; batch adversarial loss: 0.622134\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461624; batch adversarial loss: 0.636057\n",
      "epoch 47; iter: 200; batch classifier loss: 0.409478; batch adversarial loss: 0.611217\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404752; batch adversarial loss: 0.610037\n",
      "epoch 48; iter: 200; batch classifier loss: 0.408074; batch adversarial loss: 0.609426\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451882; batch adversarial loss: 0.661216\n",
      "epoch 49; iter: 200; batch classifier loss: 0.302547; batch adversarial loss: 0.605136\n",
      "epoch 0; iter: 0; batch classifier loss: 5.779207; batch adversarial loss: 0.721235\n",
      "epoch 0; iter: 200; batch classifier loss: 3.516287; batch adversarial loss: 0.646739\n",
      "epoch 1; iter: 0; batch classifier loss: 19.139084; batch adversarial loss: 0.647580\n",
      "epoch 1; iter: 200; batch classifier loss: 5.821781; batch adversarial loss: 0.619236\n",
      "epoch 2; iter: 0; batch classifier loss: 1.089195; batch adversarial loss: 0.623068\n",
      "epoch 2; iter: 200; batch classifier loss: 1.575141; batch adversarial loss: 0.578545\n",
      "epoch 3; iter: 0; batch classifier loss: 4.751976; batch adversarial loss: 0.600694\n",
      "epoch 3; iter: 200; batch classifier loss: 13.470562; batch adversarial loss: 0.550407\n",
      "epoch 4; iter: 0; batch classifier loss: 2.634648; batch adversarial loss: 0.636186\n",
      "epoch 4; iter: 200; batch classifier loss: 0.761060; batch adversarial loss: 0.618793\n",
      "epoch 5; iter: 0; batch classifier loss: 0.481039; batch adversarial loss: 0.638953\n",
      "epoch 5; iter: 200; batch classifier loss: 0.822376; batch adversarial loss: 0.606328\n",
      "epoch 6; iter: 0; batch classifier loss: 0.382200; batch adversarial loss: 0.625948\n",
      "epoch 6; iter: 200; batch classifier loss: 1.233792; batch adversarial loss: 0.562100\n",
      "epoch 7; iter: 0; batch classifier loss: 0.878471; batch adversarial loss: 0.599331\n",
      "epoch 7; iter: 200; batch classifier loss: 0.871136; batch adversarial loss: 0.613913\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613354; batch adversarial loss: 0.560136\n",
      "epoch 8; iter: 200; batch classifier loss: 0.986698; batch adversarial loss: 0.596222\n",
      "epoch 9; iter: 0; batch classifier loss: 0.690563; batch adversarial loss: 0.562214\n",
      "epoch 9; iter: 200; batch classifier loss: 1.035216; batch adversarial loss: 0.637420\n",
      "epoch 10; iter: 0; batch classifier loss: 0.424979; batch adversarial loss: 0.605669\n",
      "epoch 10; iter: 200; batch classifier loss: 0.424973; batch adversarial loss: 0.635111\n",
      "epoch 11; iter: 0; batch classifier loss: 1.498019; batch adversarial loss: 0.611502\n",
      "epoch 11; iter: 200; batch classifier loss: 0.476240; batch adversarial loss: 0.646999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.403391; batch adversarial loss: 0.590748\n",
      "epoch 12; iter: 200; batch classifier loss: 0.341411; batch adversarial loss: 0.644280\n",
      "epoch 13; iter: 0; batch classifier loss: 0.469189; batch adversarial loss: 0.615704\n",
      "epoch 13; iter: 200; batch classifier loss: 0.408653; batch adversarial loss: 0.650036\n",
      "epoch 14; iter: 0; batch classifier loss: 0.392474; batch adversarial loss: 0.608270\n",
      "epoch 14; iter: 200; batch classifier loss: 0.298365; batch adversarial loss: 0.653337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471500; batch adversarial loss: 0.690944\n",
      "epoch 15; iter: 200; batch classifier loss: 0.570608; batch adversarial loss: 0.620625\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350769; batch adversarial loss: 0.601758\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304364; batch adversarial loss: 0.644121\n",
      "epoch 17; iter: 0; batch classifier loss: 0.354492; batch adversarial loss: 0.594088\n",
      "epoch 17; iter: 200; batch classifier loss: 0.374300; batch adversarial loss: 0.568261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468982; batch adversarial loss: 0.647723\n",
      "epoch 18; iter: 200; batch classifier loss: 0.621001; batch adversarial loss: 0.654583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.646437; batch adversarial loss: 0.643903\n",
      "epoch 19; iter: 200; batch classifier loss: 0.290945; batch adversarial loss: 0.626021\n",
      "epoch 20; iter: 0; batch classifier loss: 0.291650; batch adversarial loss: 0.620637\n",
      "epoch 20; iter: 200; batch classifier loss: 0.277556; batch adversarial loss: 0.598875\n",
      "epoch 21; iter: 0; batch classifier loss: 0.314896; batch adversarial loss: 0.601673\n",
      "epoch 21; iter: 200; batch classifier loss: 0.346560; batch adversarial loss: 0.655924\n",
      "epoch 22; iter: 0; batch classifier loss: 0.324710; batch adversarial loss: 0.619805\n",
      "epoch 22; iter: 200; batch classifier loss: 0.349407; batch adversarial loss: 0.560175\n",
      "epoch 23; iter: 0; batch classifier loss: 0.408921; batch adversarial loss: 0.629570\n",
      "epoch 23; iter: 200; batch classifier loss: 0.349664; batch adversarial loss: 0.617525\n",
      "epoch 24; iter: 0; batch classifier loss: 0.256369; batch adversarial loss: 0.687180\n",
      "epoch 24; iter: 200; batch classifier loss: 0.403833; batch adversarial loss: 0.602559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.292295; batch adversarial loss: 0.615906\n",
      "epoch 25; iter: 200; batch classifier loss: 0.358987; batch adversarial loss: 0.647546\n",
      "epoch 26; iter: 0; batch classifier loss: 0.312204; batch adversarial loss: 0.628948\n",
      "epoch 26; iter: 200; batch classifier loss: 0.238444; batch adversarial loss: 0.677402\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330254; batch adversarial loss: 0.588383\n",
      "epoch 27; iter: 200; batch classifier loss: 0.346428; batch adversarial loss: 0.571551\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437094; batch adversarial loss: 0.710056\n",
      "epoch 28; iter: 200; batch classifier loss: 0.415858; batch adversarial loss: 0.584786\n",
      "epoch 29; iter: 0; batch classifier loss: 0.314713; batch adversarial loss: 0.578565\n",
      "epoch 29; iter: 200; batch classifier loss: 0.273252; batch adversarial loss: 0.613710\n",
      "epoch 30; iter: 0; batch classifier loss: 0.339163; batch adversarial loss: 0.609688\n",
      "epoch 30; iter: 200; batch classifier loss: 0.438606; batch adversarial loss: 0.604111\n",
      "epoch 31; iter: 0; batch classifier loss: 0.317335; batch adversarial loss: 0.614836\n",
      "epoch 31; iter: 200; batch classifier loss: 0.510237; batch adversarial loss: 0.631616\n",
      "epoch 32; iter: 0; batch classifier loss: 0.341043; batch adversarial loss: 0.629638\n",
      "epoch 32; iter: 200; batch classifier loss: 0.383695; batch adversarial loss: 0.562046\n",
      "epoch 33; iter: 0; batch classifier loss: 0.285866; batch adversarial loss: 0.615720\n",
      "epoch 33; iter: 200; batch classifier loss: 0.312871; batch adversarial loss: 0.608050\n",
      "epoch 34; iter: 0; batch classifier loss: 0.634369; batch adversarial loss: 0.637303\n",
      "epoch 34; iter: 200; batch classifier loss: 0.266423; batch adversarial loss: 0.640687\n",
      "epoch 35; iter: 0; batch classifier loss: 0.453388; batch adversarial loss: 0.631755\n",
      "epoch 35; iter: 200; batch classifier loss: 0.416752; batch adversarial loss: 0.592892\n",
      "epoch 36; iter: 0; batch classifier loss: 0.300150; batch adversarial loss: 0.629259\n",
      "epoch 36; iter: 200; batch classifier loss: 0.536252; batch adversarial loss: 0.599250\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442125; batch adversarial loss: 0.599151\n",
      "epoch 37; iter: 200; batch classifier loss: 0.340230; batch adversarial loss: 0.552974\n",
      "epoch 38; iter: 0; batch classifier loss: 0.342474; batch adversarial loss: 0.644775\n",
      "epoch 38; iter: 200; batch classifier loss: 0.686298; batch adversarial loss: 0.637083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362581; batch adversarial loss: 0.618738\n",
      "epoch 39; iter: 200; batch classifier loss: 0.342896; batch adversarial loss: 0.606061\n",
      "epoch 40; iter: 0; batch classifier loss: 0.379550; batch adversarial loss: 0.668479\n",
      "epoch 40; iter: 200; batch classifier loss: 0.300427; batch adversarial loss: 0.632299\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388641; batch adversarial loss: 0.633648\n",
      "epoch 41; iter: 200; batch classifier loss: 0.294275; batch adversarial loss: 0.678904\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299132; batch adversarial loss: 0.617346\n",
      "epoch 42; iter: 200; batch classifier loss: 0.312147; batch adversarial loss: 0.679304\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482702; batch adversarial loss: 0.612190\n",
      "epoch 43; iter: 200; batch classifier loss: 0.574813; batch adversarial loss: 0.643348\n",
      "epoch 44; iter: 0; batch classifier loss: 0.296577; batch adversarial loss: 0.670012\n",
      "epoch 44; iter: 200; batch classifier loss: 0.334160; batch adversarial loss: 0.637600\n",
      "epoch 45; iter: 0; batch classifier loss: 0.710826; batch adversarial loss: 0.614310\n",
      "epoch 45; iter: 200; batch classifier loss: 0.330396; batch adversarial loss: 0.637219\n",
      "epoch 46; iter: 0; batch classifier loss: 0.515400; batch adversarial loss: 0.644966\n",
      "epoch 46; iter: 200; batch classifier loss: 0.425778; batch adversarial loss: 0.663718\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431067; batch adversarial loss: 0.604588\n",
      "epoch 47; iter: 200; batch classifier loss: 0.444141; batch adversarial loss: 0.669239\n",
      "epoch 48; iter: 0; batch classifier loss: 0.243410; batch adversarial loss: 0.608772\n",
      "epoch 48; iter: 200; batch classifier loss: 0.371371; batch adversarial loss: 0.648129\n",
      "epoch 49; iter: 0; batch classifier loss: 0.574846; batch adversarial loss: 0.574747\n",
      "epoch 49; iter: 200; batch classifier loss: 0.453338; batch adversarial loss: 0.602821\n",
      "epoch 0; iter: 0; batch classifier loss: 154.967590; batch adversarial loss: 0.741848\n",
      "epoch 0; iter: 200; batch classifier loss: 7.871423; batch adversarial loss: 0.680879\n",
      "epoch 1; iter: 0; batch classifier loss: 3.831079; batch adversarial loss: 0.653019\n",
      "epoch 1; iter: 200; batch classifier loss: 3.862933; batch adversarial loss: 0.661759\n",
      "epoch 2; iter: 0; batch classifier loss: 5.146238; batch adversarial loss: 0.674080\n",
      "epoch 2; iter: 200; batch classifier loss: 7.688386; batch adversarial loss: 0.634201\n",
      "epoch 3; iter: 0; batch classifier loss: 2.576942; batch adversarial loss: 0.637443\n",
      "epoch 3; iter: 200; batch classifier loss: 0.588592; batch adversarial loss: 0.655420\n",
      "epoch 4; iter: 0; batch classifier loss: 1.341090; batch adversarial loss: 0.649315\n",
      "epoch 4; iter: 200; batch classifier loss: 0.795834; batch adversarial loss: 0.605903\n",
      "epoch 5; iter: 0; batch classifier loss: 1.208732; batch adversarial loss: 0.652453\n",
      "epoch 5; iter: 200; batch classifier loss: 1.214698; batch adversarial loss: 0.690166\n",
      "epoch 6; iter: 0; batch classifier loss: 2.600124; batch adversarial loss: 0.720002\n",
      "epoch 6; iter: 200; batch classifier loss: 0.506337; batch adversarial loss: 0.692839\n",
      "epoch 7; iter: 0; batch classifier loss: 0.674420; batch adversarial loss: 0.610578\n",
      "epoch 7; iter: 200; batch classifier loss: 0.968755; batch adversarial loss: 0.615362\n",
      "epoch 8; iter: 0; batch classifier loss: 7.919637; batch adversarial loss: 0.588082\n",
      "epoch 8; iter: 200; batch classifier loss: 0.485111; batch adversarial loss: 0.610216\n",
      "epoch 9; iter: 0; batch classifier loss: 1.381219; batch adversarial loss: 0.650828\n",
      "epoch 9; iter: 200; batch classifier loss: 0.361727; batch adversarial loss: 0.615958\n",
      "epoch 10; iter: 0; batch classifier loss: 0.303642; batch adversarial loss: 0.642532\n",
      "epoch 10; iter: 200; batch classifier loss: 0.441089; batch adversarial loss: 0.603844\n",
      "epoch 11; iter: 0; batch classifier loss: 0.767983; batch adversarial loss: 0.607956\n",
      "epoch 11; iter: 200; batch classifier loss: 0.961172; batch adversarial loss: 0.591409\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470939; batch adversarial loss: 0.611231\n",
      "epoch 12; iter: 200; batch classifier loss: 0.467364; batch adversarial loss: 0.624469\n",
      "epoch 13; iter: 0; batch classifier loss: 0.359167; batch adversarial loss: 0.645585\n",
      "epoch 13; iter: 200; batch classifier loss: 0.311696; batch adversarial loss: 0.656611\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491487; batch adversarial loss: 0.665047\n",
      "epoch 14; iter: 200; batch classifier loss: 0.407159; batch adversarial loss: 0.660116\n",
      "epoch 15; iter: 0; batch classifier loss: 0.445529; batch adversarial loss: 0.611633\n",
      "epoch 15; iter: 200; batch classifier loss: 0.325458; batch adversarial loss: 0.578821\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454826; batch adversarial loss: 0.633021\n",
      "epoch 16; iter: 200; batch classifier loss: 0.301447; batch adversarial loss: 0.623450\n",
      "epoch 17; iter: 0; batch classifier loss: 0.351440; batch adversarial loss: 0.611948\n",
      "epoch 17; iter: 200; batch classifier loss: 0.439928; batch adversarial loss: 0.623661\n",
      "epoch 18; iter: 0; batch classifier loss: 0.405437; batch adversarial loss: 0.623066\n",
      "epoch 18; iter: 200; batch classifier loss: 0.360479; batch adversarial loss: 0.634990\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463886; batch adversarial loss: 0.677380\n",
      "epoch 19; iter: 200; batch classifier loss: 0.368699; batch adversarial loss: 0.640086\n",
      "epoch 20; iter: 0; batch classifier loss: 0.277151; batch adversarial loss: 0.666208\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379408; batch adversarial loss: 0.696854\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355295; batch adversarial loss: 0.670482\n",
      "epoch 21; iter: 200; batch classifier loss: 0.356613; batch adversarial loss: 0.620487\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331299; batch adversarial loss: 0.624182\n",
      "epoch 22; iter: 200; batch classifier loss: 0.378354; batch adversarial loss: 0.659814\n",
      "epoch 23; iter: 0; batch classifier loss: 0.435172; batch adversarial loss: 0.664481\n",
      "epoch 23; iter: 200; batch classifier loss: 0.308374; batch adversarial loss: 0.592811\n",
      "epoch 24; iter: 0; batch classifier loss: 0.615380; batch adversarial loss: 0.581137\n",
      "epoch 24; iter: 200; batch classifier loss: 0.357884; batch adversarial loss: 0.646900\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326110; batch adversarial loss: 0.629434\n",
      "epoch 25; iter: 200; batch classifier loss: 0.319844; batch adversarial loss: 0.603376\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356754; batch adversarial loss: 0.583846\n",
      "epoch 26; iter: 200; batch classifier loss: 0.419990; batch adversarial loss: 0.624475\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362783; batch adversarial loss: 0.631358\n",
      "epoch 27; iter: 200; batch classifier loss: 0.353853; batch adversarial loss: 0.647633\n",
      "epoch 28; iter: 0; batch classifier loss: 0.297145; batch adversarial loss: 0.625129\n",
      "epoch 28; iter: 200; batch classifier loss: 0.300385; batch adversarial loss: 0.684885\n",
      "epoch 29; iter: 0; batch classifier loss: 0.341773; batch adversarial loss: 0.659153\n",
      "epoch 29; iter: 200; batch classifier loss: 0.403219; batch adversarial loss: 0.618010\n",
      "epoch 30; iter: 0; batch classifier loss: 0.433999; batch adversarial loss: 0.589572\n",
      "epoch 30; iter: 200; batch classifier loss: 0.377312; batch adversarial loss: 0.603060\n",
      "epoch 31; iter: 0; batch classifier loss: 0.437304; batch adversarial loss: 0.619693\n",
      "epoch 31; iter: 200; batch classifier loss: 0.361412; batch adversarial loss: 0.554426\n",
      "epoch 32; iter: 0; batch classifier loss: 0.372407; batch adversarial loss: 0.606180\n",
      "epoch 32; iter: 200; batch classifier loss: 0.380116; batch adversarial loss: 0.625054\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484938; batch adversarial loss: 0.539217\n",
      "epoch 33; iter: 200; batch classifier loss: 0.386966; batch adversarial loss: 0.613261\n",
      "epoch 34; iter: 0; batch classifier loss: 0.374372; batch adversarial loss: 0.596462\n",
      "epoch 34; iter: 200; batch classifier loss: 0.372952; batch adversarial loss: 0.681603\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484566; batch adversarial loss: 0.619926\n",
      "epoch 35; iter: 200; batch classifier loss: 0.330928; batch adversarial loss: 0.546369\n",
      "epoch 36; iter: 0; batch classifier loss: 0.338753; batch adversarial loss: 0.602847\n",
      "epoch 36; iter: 200; batch classifier loss: 0.613115; batch adversarial loss: 0.668882\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378644; batch adversarial loss: 0.636795\n",
      "epoch 37; iter: 200; batch classifier loss: 0.395696; batch adversarial loss: 0.598567\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435757; batch adversarial loss: 0.626292\n",
      "epoch 38; iter: 200; batch classifier loss: 0.305468; batch adversarial loss: 0.622989\n",
      "epoch 39; iter: 0; batch classifier loss: 0.372025; batch adversarial loss: 0.543360\n",
      "epoch 39; iter: 200; batch classifier loss: 0.381386; batch adversarial loss: 0.575893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.380802; batch adversarial loss: 0.571445\n",
      "epoch 40; iter: 200; batch classifier loss: 0.521196; batch adversarial loss: 0.596554\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396490; batch adversarial loss: 0.641012\n",
      "epoch 41; iter: 200; batch classifier loss: 0.352423; batch adversarial loss: 0.645308\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299889; batch adversarial loss: 0.604351\n",
      "epoch 42; iter: 200; batch classifier loss: 0.337760; batch adversarial loss: 0.591768\n",
      "epoch 43; iter: 0; batch classifier loss: 0.491154; batch adversarial loss: 0.583951\n",
      "epoch 43; iter: 200; batch classifier loss: 0.287775; batch adversarial loss: 0.637730\n",
      "epoch 44; iter: 0; batch classifier loss: 0.330434; batch adversarial loss: 0.673903\n",
      "epoch 44; iter: 200; batch classifier loss: 0.372772; batch adversarial loss: 0.555899\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502314; batch adversarial loss: 0.663972\n",
      "epoch 45; iter: 200; batch classifier loss: 0.424284; batch adversarial loss: 0.669670\n",
      "epoch 46; iter: 0; batch classifier loss: 0.440948; batch adversarial loss: 0.625432\n",
      "epoch 46; iter: 200; batch classifier loss: 0.431794; batch adversarial loss: 0.607233\n",
      "epoch 47; iter: 0; batch classifier loss: 0.193008; batch adversarial loss: 0.627188\n",
      "epoch 47; iter: 200; batch classifier loss: 0.344754; batch adversarial loss: 0.603975\n",
      "epoch 48; iter: 0; batch classifier loss: 0.317488; batch adversarial loss: 0.577565\n",
      "epoch 48; iter: 200; batch classifier loss: 0.385322; batch adversarial loss: 0.586671\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401340; batch adversarial loss: 0.580715\n",
      "epoch 49; iter: 200; batch classifier loss: 0.397053; batch adversarial loss: 0.653133\n",
      "epoch 0; iter: 0; batch classifier loss: 6.592462; batch adversarial loss: 0.674489\n",
      "epoch 0; iter: 200; batch classifier loss: 10.050957; batch adversarial loss: 0.651010\n",
      "epoch 1; iter: 0; batch classifier loss: 9.326611; batch adversarial loss: 0.636492\n",
      "epoch 1; iter: 200; batch classifier loss: 3.558164; batch adversarial loss: 0.663962\n",
      "epoch 2; iter: 0; batch classifier loss: 8.776837; batch adversarial loss: 0.649608\n",
      "epoch 2; iter: 200; batch classifier loss: 2.782364; batch adversarial loss: 0.605242\n",
      "epoch 3; iter: 0; batch classifier loss: 4.568459; batch adversarial loss: 0.614145\n",
      "epoch 3; iter: 200; batch classifier loss: 0.642412; batch adversarial loss: 0.627792\n",
      "epoch 4; iter: 0; batch classifier loss: 2.399185; batch adversarial loss: 0.610676\n",
      "epoch 4; iter: 200; batch classifier loss: 0.983120; batch adversarial loss: 0.559918\n",
      "epoch 5; iter: 0; batch classifier loss: 2.135869; batch adversarial loss: 0.613895\n",
      "epoch 5; iter: 200; batch classifier loss: 1.557018; batch adversarial loss: 0.625660\n",
      "epoch 6; iter: 0; batch classifier loss: 2.033226; batch adversarial loss: 0.629256\n",
      "epoch 6; iter: 200; batch classifier loss: 1.924786; batch adversarial loss: 0.609177\n",
      "epoch 7; iter: 0; batch classifier loss: 0.863948; batch adversarial loss: 0.565062\n",
      "epoch 7; iter: 200; batch classifier loss: 0.759867; batch adversarial loss: 0.576299\n",
      "epoch 8; iter: 0; batch classifier loss: 1.954713; batch adversarial loss: 0.606612\n",
      "epoch 8; iter: 200; batch classifier loss: 0.617014; batch adversarial loss: 0.622192\n",
      "epoch 9; iter: 0; batch classifier loss: 0.844739; batch adversarial loss: 0.641675\n",
      "epoch 9; iter: 200; batch classifier loss: 0.580505; batch adversarial loss: 0.622260\n",
      "epoch 10; iter: 0; batch classifier loss: 0.418606; batch adversarial loss: 0.613048\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420835; batch adversarial loss: 0.632627\n",
      "epoch 11; iter: 0; batch classifier loss: 0.395074; batch adversarial loss: 0.624000\n",
      "epoch 11; iter: 200; batch classifier loss: 0.341967; batch adversarial loss: 0.622373\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368276; batch adversarial loss: 0.618936\n",
      "epoch 12; iter: 200; batch classifier loss: 0.976782; batch adversarial loss: 0.619721\n",
      "epoch 13; iter: 0; batch classifier loss: 0.446426; batch adversarial loss: 0.640213\n",
      "epoch 13; iter: 200; batch classifier loss: 0.469443; batch adversarial loss: 0.647063\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331081; batch adversarial loss: 0.641411\n",
      "epoch 14; iter: 200; batch classifier loss: 0.431725; batch adversarial loss: 0.594461\n",
      "epoch 15; iter: 0; batch classifier loss: 0.408150; batch adversarial loss: 0.633445\n",
      "epoch 15; iter: 200; batch classifier loss: 0.335094; batch adversarial loss: 0.621794\n",
      "epoch 16; iter: 0; batch classifier loss: 0.703827; batch adversarial loss: 0.575793\n",
      "epoch 16; iter: 200; batch classifier loss: 0.271143; batch adversarial loss: 0.599264\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356266; batch adversarial loss: 0.630944\n",
      "epoch 17; iter: 200; batch classifier loss: 0.284953; batch adversarial loss: 0.622491\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429132; batch adversarial loss: 0.651927\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371172; batch adversarial loss: 0.637335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.391525; batch adversarial loss: 0.614021\n",
      "epoch 19; iter: 200; batch classifier loss: 0.390539; batch adversarial loss: 0.604624\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356346; batch adversarial loss: 0.627625\n",
      "epoch 20; iter: 200; batch classifier loss: 0.430656; batch adversarial loss: 0.610288\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305016; batch adversarial loss: 0.675580\n",
      "epoch 21; iter: 200; batch classifier loss: 0.676398; batch adversarial loss: 0.609690\n",
      "epoch 22; iter: 0; batch classifier loss: 0.456966; batch adversarial loss: 0.618360\n",
      "epoch 22; iter: 200; batch classifier loss: 0.335973; batch adversarial loss: 0.672600\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379996; batch adversarial loss: 0.633082\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371728; batch adversarial loss: 0.616590\n",
      "epoch 24; iter: 0; batch classifier loss: 0.596123; batch adversarial loss: 0.613428\n",
      "epoch 24; iter: 200; batch classifier loss: 0.380890; batch adversarial loss: 0.588251\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432585; batch adversarial loss: 0.625212\n",
      "epoch 25; iter: 200; batch classifier loss: 0.426448; batch adversarial loss: 0.564573\n",
      "epoch 26; iter: 0; batch classifier loss: 0.241442; batch adversarial loss: 0.607492\n",
      "epoch 26; iter: 200; batch classifier loss: 0.299641; batch adversarial loss: 0.594925\n",
      "epoch 27; iter: 0; batch classifier loss: 0.287416; batch adversarial loss: 0.664621\n",
      "epoch 27; iter: 200; batch classifier loss: 0.358172; batch adversarial loss: 0.630241\n",
      "epoch 28; iter: 0; batch classifier loss: 0.378930; batch adversarial loss: 0.590131\n",
      "epoch 28; iter: 200; batch classifier loss: 0.267432; batch adversarial loss: 0.627400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435913; batch adversarial loss: 0.594080\n",
      "epoch 29; iter: 200; batch classifier loss: 0.269329; batch adversarial loss: 0.586332\n",
      "epoch 30; iter: 0; batch classifier loss: 0.519578; batch adversarial loss: 0.567530\n",
      "epoch 30; iter: 200; batch classifier loss: 0.385072; batch adversarial loss: 0.644716\n",
      "epoch 31; iter: 0; batch classifier loss: 0.317538; batch adversarial loss: 0.628886\n",
      "epoch 31; iter: 200; batch classifier loss: 0.304250; batch adversarial loss: 0.634415\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430471; batch adversarial loss: 0.601640\n",
      "epoch 32; iter: 200; batch classifier loss: 0.402599; batch adversarial loss: 0.632231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388009; batch adversarial loss: 0.646069\n",
      "epoch 33; iter: 200; batch classifier loss: 0.339282; batch adversarial loss: 0.583322\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331828; batch adversarial loss: 0.611228\n",
      "epoch 34; iter: 200; batch classifier loss: 0.296458; batch adversarial loss: 0.655694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458853; batch adversarial loss: 0.661997\n",
      "epoch 35; iter: 200; batch classifier loss: 0.376289; batch adversarial loss: 0.668978\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347601; batch adversarial loss: 0.554126\n",
      "epoch 36; iter: 200; batch classifier loss: 0.392880; batch adversarial loss: 0.623302\n",
      "epoch 37; iter: 0; batch classifier loss: 0.324392; batch adversarial loss: 0.646270\n",
      "epoch 37; iter: 200; batch classifier loss: 0.464803; batch adversarial loss: 0.646789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.319833; batch adversarial loss: 0.629035\n",
      "epoch 38; iter: 200; batch classifier loss: 0.443828; batch adversarial loss: 0.639709\n",
      "epoch 39; iter: 0; batch classifier loss: 0.346337; batch adversarial loss: 0.646453\n",
      "epoch 39; iter: 200; batch classifier loss: 0.410584; batch adversarial loss: 0.650294\n",
      "epoch 40; iter: 0; batch classifier loss: 0.533191; batch adversarial loss: 0.590859\n",
      "epoch 40; iter: 200; batch classifier loss: 0.582175; batch adversarial loss: 0.631026\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395597; batch adversarial loss: 0.662587\n",
      "epoch 41; iter: 200; batch classifier loss: 0.482056; batch adversarial loss: 0.656194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.476156; batch adversarial loss: 0.629636\n",
      "epoch 42; iter: 200; batch classifier loss: 0.472022; batch adversarial loss: 0.606053\n",
      "epoch 43; iter: 0; batch classifier loss: 0.589218; batch adversarial loss: 0.590089\n",
      "epoch 43; iter: 200; batch classifier loss: 0.371608; batch adversarial loss: 0.647984\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375754; batch adversarial loss: 0.635584\n",
      "epoch 44; iter: 200; batch classifier loss: 0.452901; batch adversarial loss: 0.630865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473491; batch adversarial loss: 0.637125\n",
      "epoch 45; iter: 200; batch classifier loss: 0.417212; batch adversarial loss: 0.683396\n",
      "epoch 46; iter: 0; batch classifier loss: 0.340193; batch adversarial loss: 0.729156\n",
      "epoch 46; iter: 200; batch classifier loss: 0.474495; batch adversarial loss: 0.626467\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384848; batch adversarial loss: 0.587968\n",
      "epoch 47; iter: 200; batch classifier loss: 0.448870; batch adversarial loss: 0.583011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420865; batch adversarial loss: 0.599196\n",
      "epoch 48; iter: 200; batch classifier loss: 0.351307; batch adversarial loss: 0.600126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.458458; batch adversarial loss: 0.635910\n",
      "epoch 49; iter: 200; batch classifier loss: 0.404673; batch adversarial loss: 0.631162\n",
      "epoch 0; iter: 0; batch classifier loss: 5.881947; batch adversarial loss: 0.862645\n",
      "epoch 0; iter: 200; batch classifier loss: 8.050597; batch adversarial loss: 0.745535\n",
      "epoch 1; iter: 0; batch classifier loss: 2.479838; batch adversarial loss: 0.714373\n",
      "epoch 1; iter: 200; batch classifier loss: 10.876261; batch adversarial loss: 0.680795\n",
      "epoch 2; iter: 0; batch classifier loss: 5.131482; batch adversarial loss: 0.653771\n",
      "epoch 2; iter: 200; batch classifier loss: 4.278824; batch adversarial loss: 0.652976\n",
      "epoch 3; iter: 0; batch classifier loss: 2.542154; batch adversarial loss: 0.611619\n",
      "epoch 3; iter: 200; batch classifier loss: 3.185984; batch adversarial loss: 0.685031\n",
      "epoch 4; iter: 0; batch classifier loss: 3.554785; batch adversarial loss: 0.661351\n",
      "epoch 4; iter: 200; batch classifier loss: 1.141863; batch adversarial loss: 0.660906\n",
      "epoch 5; iter: 0; batch classifier loss: 0.983925; batch adversarial loss: 0.651842\n",
      "epoch 5; iter: 200; batch classifier loss: 1.659726; batch adversarial loss: 0.600785\n",
      "epoch 6; iter: 0; batch classifier loss: 0.439801; batch adversarial loss: 0.646382\n",
      "epoch 6; iter: 200; batch classifier loss: 0.546448; batch adversarial loss: 0.645552\n",
      "epoch 7; iter: 0; batch classifier loss: 1.178368; batch adversarial loss: 0.667728\n",
      "epoch 7; iter: 200; batch classifier loss: 0.403858; batch adversarial loss: 0.629878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.918974; batch adversarial loss: 0.617811\n",
      "epoch 8; iter: 200; batch classifier loss: 0.477070; batch adversarial loss: 0.625178\n",
      "epoch 9; iter: 0; batch classifier loss: 8.032204; batch adversarial loss: 0.619307\n",
      "epoch 9; iter: 200; batch classifier loss: 0.368216; batch adversarial loss: 0.620248\n",
      "epoch 10; iter: 0; batch classifier loss: 0.683872; batch adversarial loss: 0.568675\n",
      "epoch 10; iter: 200; batch classifier loss: 0.486538; batch adversarial loss: 0.577943\n",
      "epoch 11; iter: 0; batch classifier loss: 0.384299; batch adversarial loss: 0.589111\n",
      "epoch 11; iter: 200; batch classifier loss: 0.380826; batch adversarial loss: 0.663209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491481; batch adversarial loss: 0.683801\n",
      "epoch 12; iter: 200; batch classifier loss: 0.426708; batch adversarial loss: 0.649031\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418893; batch adversarial loss: 0.622564\n",
      "epoch 13; iter: 200; batch classifier loss: 0.356254; batch adversarial loss: 0.636509\n",
      "epoch 14; iter: 0; batch classifier loss: 0.405615; batch adversarial loss: 0.647362\n",
      "epoch 14; iter: 200; batch classifier loss: 0.407956; batch adversarial loss: 0.670643\n",
      "epoch 15; iter: 0; batch classifier loss: 0.400808; batch adversarial loss: 0.627074\n",
      "epoch 15; iter: 200; batch classifier loss: 0.417444; batch adversarial loss: 0.645600\n",
      "epoch 16; iter: 0; batch classifier loss: 0.511956; batch adversarial loss: 0.627077\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342563; batch adversarial loss: 0.653734\n",
      "epoch 17; iter: 0; batch classifier loss: 0.407411; batch adversarial loss: 0.628146\n",
      "epoch 17; iter: 200; batch classifier loss: 0.375885; batch adversarial loss: 0.649475\n",
      "epoch 18; iter: 0; batch classifier loss: 0.921134; batch adversarial loss: 0.660705\n",
      "epoch 18; iter: 200; batch classifier loss: 0.538426; batch adversarial loss: 0.604523\n",
      "epoch 19; iter: 0; batch classifier loss: 0.472797; batch adversarial loss: 0.572883\n",
      "epoch 19; iter: 200; batch classifier loss: 0.529420; batch adversarial loss: 0.640042\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385078; batch adversarial loss: 0.624944\n",
      "epoch 20; iter: 200; batch classifier loss: 0.890347; batch adversarial loss: 0.654981\n",
      "epoch 21; iter: 0; batch classifier loss: 0.370651; batch adversarial loss: 0.665255\n",
      "epoch 21; iter: 200; batch classifier loss: 0.553322; batch adversarial loss: 0.645140\n",
      "epoch 22; iter: 0; batch classifier loss: 0.332479; batch adversarial loss: 0.677618\n",
      "epoch 22; iter: 200; batch classifier loss: 0.349084; batch adversarial loss: 0.626189\n",
      "epoch 23; iter: 0; batch classifier loss: 0.362132; batch adversarial loss: 0.589723\n",
      "epoch 23; iter: 200; batch classifier loss: 0.351874; batch adversarial loss: 0.606509\n",
      "epoch 24; iter: 0; batch classifier loss: 0.376990; batch adversarial loss: 0.581174\n",
      "epoch 24; iter: 200; batch classifier loss: 0.430284; batch adversarial loss: 0.643458\n",
      "epoch 25; iter: 0; batch classifier loss: 0.361426; batch adversarial loss: 0.650344\n",
      "epoch 25; iter: 200; batch classifier loss: 0.394307; batch adversarial loss: 0.612080\n",
      "epoch 26; iter: 0; batch classifier loss: 0.390028; batch adversarial loss: 0.631197\n",
      "epoch 26; iter: 200; batch classifier loss: 0.297598; batch adversarial loss: 0.671238\n",
      "epoch 27; iter: 0; batch classifier loss: 0.353580; batch adversarial loss: 0.629926\n",
      "epoch 27; iter: 200; batch classifier loss: 0.323444; batch adversarial loss: 0.617945\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362518; batch adversarial loss: 0.610322\n",
      "epoch 28; iter: 200; batch classifier loss: 0.317874; batch adversarial loss: 0.574402\n",
      "epoch 29; iter: 0; batch classifier loss: 0.353965; batch adversarial loss: 0.626381\n",
      "epoch 29; iter: 200; batch classifier loss: 0.300174; batch adversarial loss: 0.645545\n",
      "epoch 30; iter: 0; batch classifier loss: 0.355174; batch adversarial loss: 0.691903\n",
      "epoch 30; iter: 200; batch classifier loss: 0.375299; batch adversarial loss: 0.586928\n",
      "epoch 31; iter: 0; batch classifier loss: 0.344361; batch adversarial loss: 0.591425\n",
      "epoch 31; iter: 200; batch classifier loss: 0.272077; batch adversarial loss: 0.650912\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467944; batch adversarial loss: 0.639207\n",
      "epoch 32; iter: 200; batch classifier loss: 0.380817; batch adversarial loss: 0.624288\n",
      "epoch 33; iter: 0; batch classifier loss: 0.329556; batch adversarial loss: 0.566457\n",
      "epoch 33; iter: 200; batch classifier loss: 0.330638; batch adversarial loss: 0.662087\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418941; batch adversarial loss: 0.628052\n",
      "epoch 34; iter: 200; batch classifier loss: 0.366678; batch adversarial loss: 0.578490\n",
      "epoch 35; iter: 0; batch classifier loss: 0.401147; batch adversarial loss: 0.655515\n",
      "epoch 35; iter: 200; batch classifier loss: 0.381999; batch adversarial loss: 0.662102\n",
      "epoch 36; iter: 0; batch classifier loss: 0.378799; batch adversarial loss: 0.638140\n",
      "epoch 36; iter: 200; batch classifier loss: 0.341161; batch adversarial loss: 0.660654\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343313; batch adversarial loss: 0.657531\n",
      "epoch 37; iter: 200; batch classifier loss: 0.364994; batch adversarial loss: 0.652568\n",
      "epoch 38; iter: 0; batch classifier loss: 0.313117; batch adversarial loss: 0.627830\n",
      "epoch 38; iter: 200; batch classifier loss: 0.312545; batch adversarial loss: 0.587862\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427366; batch adversarial loss: 0.668710\n",
      "epoch 39; iter: 200; batch classifier loss: 0.326005; batch adversarial loss: 0.641833\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442043; batch adversarial loss: 0.621252\n",
      "epoch 40; iter: 200; batch classifier loss: 0.347693; batch adversarial loss: 0.616128\n",
      "epoch 41; iter: 0; batch classifier loss: 0.361149; batch adversarial loss: 0.609389\n",
      "epoch 41; iter: 200; batch classifier loss: 0.389914; batch adversarial loss: 0.613503\n",
      "epoch 42; iter: 0; batch classifier loss: 0.366038; batch adversarial loss: 0.655212\n",
      "epoch 42; iter: 200; batch classifier loss: 0.321623; batch adversarial loss: 0.634044\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384017; batch adversarial loss: 0.630028\n",
      "epoch 43; iter: 200; batch classifier loss: 0.319198; batch adversarial loss: 0.649050\n",
      "epoch 44; iter: 0; batch classifier loss: 0.541718; batch adversarial loss: 0.636471\n",
      "epoch 44; iter: 200; batch classifier loss: 0.421333; batch adversarial loss: 0.604985\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421880; batch adversarial loss: 0.591286\n",
      "epoch 45; iter: 200; batch classifier loss: 0.373801; batch adversarial loss: 0.670444\n",
      "epoch 46; iter: 0; batch classifier loss: 0.384530; batch adversarial loss: 0.591739\n",
      "epoch 46; iter: 200; batch classifier loss: 0.395166; batch adversarial loss: 0.624259\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389579; batch adversarial loss: 0.651564\n",
      "epoch 47; iter: 200; batch classifier loss: 0.336353; batch adversarial loss: 0.667676\n",
      "epoch 48; iter: 0; batch classifier loss: 0.436704; batch adversarial loss: 0.602533\n",
      "epoch 48; iter: 200; batch classifier loss: 0.478002; batch adversarial loss: 0.686202\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428710; batch adversarial loss: 0.561592\n",
      "epoch 49; iter: 200; batch classifier loss: 0.335696; batch adversarial loss: 0.627753\n",
      "epoch 0; iter: 0; batch classifier loss: 25.696327; batch adversarial loss: 1.025304\n",
      "epoch 0; iter: 200; batch classifier loss: 9.495037; batch adversarial loss: 1.047192\n",
      "epoch 1; iter: 0; batch classifier loss: 3.543792; batch adversarial loss: 0.827566\n",
      "epoch 1; iter: 200; batch classifier loss: 7.345741; batch adversarial loss: 0.785866\n",
      "epoch 2; iter: 0; batch classifier loss: 6.773405; batch adversarial loss: 0.670423\n",
      "epoch 2; iter: 200; batch classifier loss: 3.236577; batch adversarial loss: 0.644577\n",
      "epoch 3; iter: 0; batch classifier loss: 9.332830; batch adversarial loss: 0.661610\n",
      "epoch 3; iter: 200; batch classifier loss: 1.370032; batch adversarial loss: 0.662264\n",
      "epoch 4; iter: 0; batch classifier loss: 2.001432; batch adversarial loss: 0.629996\n",
      "epoch 4; iter: 200; batch classifier loss: 1.061466; batch adversarial loss: 0.655542\n",
      "epoch 5; iter: 0; batch classifier loss: 2.367949; batch adversarial loss: 0.646132\n",
      "epoch 5; iter: 200; batch classifier loss: 2.334632; batch adversarial loss: 0.652928\n",
      "epoch 6; iter: 0; batch classifier loss: 2.957339; batch adversarial loss: 0.616676\n",
      "epoch 6; iter: 200; batch classifier loss: 1.142684; batch adversarial loss: 0.644641\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465441; batch adversarial loss: 0.612647\n",
      "epoch 7; iter: 200; batch classifier loss: 0.598560; batch adversarial loss: 0.604779\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567223; batch adversarial loss: 0.665231\n",
      "epoch 8; iter: 200; batch classifier loss: 0.440655; batch adversarial loss: 0.642945\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437762; batch adversarial loss: 0.575389\n",
      "epoch 9; iter: 200; batch classifier loss: 0.538661; batch adversarial loss: 0.611580\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507067; batch adversarial loss: 0.697905\n",
      "epoch 10; iter: 200; batch classifier loss: 0.359165; batch adversarial loss: 0.595845\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343543; batch adversarial loss: 0.692160\n",
      "epoch 11; iter: 200; batch classifier loss: 0.431283; batch adversarial loss: 0.592519\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441179; batch adversarial loss: 0.584134\n",
      "epoch 12; iter: 200; batch classifier loss: 0.373660; batch adversarial loss: 0.635345\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324867; batch adversarial loss: 0.605063\n",
      "epoch 13; iter: 200; batch classifier loss: 0.387803; batch adversarial loss: 0.589326\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387338; batch adversarial loss: 0.569684\n",
      "epoch 14; iter: 200; batch classifier loss: 0.391552; batch adversarial loss: 0.645407\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415731; batch adversarial loss: 0.652067\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380228; batch adversarial loss: 0.635699\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450165; batch adversarial loss: 0.599941\n",
      "epoch 16; iter: 200; batch classifier loss: 0.394835; batch adversarial loss: 0.627988\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397175; batch adversarial loss: 0.650396\n",
      "epoch 17; iter: 200; batch classifier loss: 0.391037; batch adversarial loss: 0.683392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.405841; batch adversarial loss: 0.660695\n",
      "epoch 18; iter: 200; batch classifier loss: 0.402358; batch adversarial loss: 0.665519\n",
      "epoch 19; iter: 0; batch classifier loss: 0.345063; batch adversarial loss: 0.671791\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372498; batch adversarial loss: 0.634902\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338156; batch adversarial loss: 0.626187\n",
      "epoch 20; iter: 200; batch classifier loss: 0.391283; batch adversarial loss: 0.657978\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387120; batch adversarial loss: 0.610096\n",
      "epoch 21; iter: 200; batch classifier loss: 0.328276; batch adversarial loss: 0.640914\n",
      "epoch 22; iter: 0; batch classifier loss: 0.302703; batch adversarial loss: 0.612653\n",
      "epoch 22; iter: 200; batch classifier loss: 0.351270; batch adversarial loss: 0.606181\n",
      "epoch 23; iter: 0; batch classifier loss: 0.353983; batch adversarial loss: 0.627127\n",
      "epoch 23; iter: 200; batch classifier loss: 0.247064; batch adversarial loss: 0.655584\n",
      "epoch 24; iter: 0; batch classifier loss: 0.390824; batch adversarial loss: 0.594466\n",
      "epoch 24; iter: 200; batch classifier loss: 0.346473; batch adversarial loss: 0.572829\n",
      "epoch 25; iter: 0; batch classifier loss: 0.290939; batch adversarial loss: 0.565931\n",
      "epoch 25; iter: 200; batch classifier loss: 0.358153; batch adversarial loss: 0.626716\n",
      "epoch 26; iter: 0; batch classifier loss: 0.259004; batch adversarial loss: 0.661013\n",
      "epoch 26; iter: 200; batch classifier loss: 0.302529; batch adversarial loss: 0.646931\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321379; batch adversarial loss: 0.637757\n",
      "epoch 27; iter: 200; batch classifier loss: 0.396793; batch adversarial loss: 0.624052\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402730; batch adversarial loss: 0.613997\n",
      "epoch 28; iter: 200; batch classifier loss: 0.423901; batch adversarial loss: 0.583194\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406046; batch adversarial loss: 0.620064\n",
      "epoch 29; iter: 200; batch classifier loss: 0.239050; batch adversarial loss: 0.697998\n",
      "epoch 30; iter: 0; batch classifier loss: 0.318994; batch adversarial loss: 0.656543\n",
      "epoch 30; iter: 200; batch classifier loss: 0.273496; batch adversarial loss: 0.642715\n",
      "epoch 31; iter: 0; batch classifier loss: 0.381853; batch adversarial loss: 0.650582\n",
      "epoch 31; iter: 200; batch classifier loss: 0.331593; batch adversarial loss: 0.600746\n",
      "epoch 32; iter: 0; batch classifier loss: 0.551840; batch adversarial loss: 0.585220\n",
      "epoch 32; iter: 200; batch classifier loss: 0.332573; batch adversarial loss: 0.630295\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272564; batch adversarial loss: 0.610866\n",
      "epoch 33; iter: 200; batch classifier loss: 0.393766; batch adversarial loss: 0.685100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.388015; batch adversarial loss: 0.640271\n",
      "epoch 34; iter: 200; batch classifier loss: 0.376215; batch adversarial loss: 0.603964\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424164; batch adversarial loss: 0.624456\n",
      "epoch 35; iter: 200; batch classifier loss: 0.282341; batch adversarial loss: 0.655991\n",
      "epoch 36; iter: 0; batch classifier loss: 0.458202; batch adversarial loss: 0.645844\n",
      "epoch 36; iter: 200; batch classifier loss: 0.432383; batch adversarial loss: 0.654826\n",
      "epoch 37; iter: 0; batch classifier loss: 0.483119; batch adversarial loss: 0.576168\n",
      "epoch 37; iter: 200; batch classifier loss: 0.289121; batch adversarial loss: 0.656597\n",
      "epoch 38; iter: 0; batch classifier loss: 0.332131; batch adversarial loss: 0.700256\n",
      "epoch 38; iter: 200; batch classifier loss: 0.419233; batch adversarial loss: 0.612221\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513631; batch adversarial loss: 0.696486\n",
      "epoch 39; iter: 200; batch classifier loss: 0.377437; batch adversarial loss: 0.653675\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411065; batch adversarial loss: 0.625781\n",
      "epoch 40; iter: 200; batch classifier loss: 0.424434; batch adversarial loss: 0.663305\n",
      "epoch 41; iter: 0; batch classifier loss: 0.308369; batch adversarial loss: 0.656950\n",
      "epoch 41; iter: 200; batch classifier loss: 0.452904; batch adversarial loss: 0.641100\n",
      "epoch 42; iter: 0; batch classifier loss: 0.438555; batch adversarial loss: 0.600400\n",
      "epoch 42; iter: 200; batch classifier loss: 0.318127; batch adversarial loss: 0.616863\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469001; batch adversarial loss: 0.627011\n",
      "epoch 43; iter: 200; batch classifier loss: 0.451128; batch adversarial loss: 0.632293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.361121; batch adversarial loss: 0.589073\n",
      "epoch 44; iter: 200; batch classifier loss: 0.286835; batch adversarial loss: 0.620698\n",
      "epoch 45; iter: 0; batch classifier loss: 0.359053; batch adversarial loss: 0.639319\n",
      "epoch 45; iter: 200; batch classifier loss: 0.354889; batch adversarial loss: 0.613079\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402061; batch adversarial loss: 0.593343\n",
      "epoch 46; iter: 200; batch classifier loss: 0.364038; batch adversarial loss: 0.621224\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393123; batch adversarial loss: 0.639025\n",
      "epoch 47; iter: 200; batch classifier loss: 0.519698; batch adversarial loss: 0.685325\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386521; batch adversarial loss: 0.598648\n",
      "epoch 48; iter: 200; batch classifier loss: 0.392144; batch adversarial loss: 0.649177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.310650; batch adversarial loss: 0.586167\n",
      "epoch 49; iter: 200; batch classifier loss: 0.542605; batch adversarial loss: 0.616404\n",
      "epoch 0; iter: 0; batch classifier loss: 45.609333; batch adversarial loss: 0.874395\n",
      "epoch 0; iter: 200; batch classifier loss: 6.037939; batch adversarial loss: 0.771632\n",
      "epoch 1; iter: 0; batch classifier loss: 2.128470; batch adversarial loss: 0.729202\n",
      "epoch 1; iter: 200; batch classifier loss: 5.619980; batch adversarial loss: 0.673680\n",
      "epoch 2; iter: 0; batch classifier loss: 1.987354; batch adversarial loss: 0.694260\n",
      "epoch 2; iter: 200; batch classifier loss: 0.895959; batch adversarial loss: 0.649640\n",
      "epoch 3; iter: 0; batch classifier loss: 1.679085; batch adversarial loss: 0.670287\n",
      "epoch 3; iter: 200; batch classifier loss: 1.403880; batch adversarial loss: 0.680764\n",
      "epoch 4; iter: 0; batch classifier loss: 1.214742; batch adversarial loss: 0.686461\n",
      "epoch 4; iter: 200; batch classifier loss: 1.909978; batch adversarial loss: 0.633188\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483243; batch adversarial loss: 0.626515\n",
      "epoch 5; iter: 200; batch classifier loss: 0.299517; batch adversarial loss: 0.652727\n",
      "epoch 6; iter: 0; batch classifier loss: 0.781770; batch adversarial loss: 0.621329\n",
      "epoch 6; iter: 200; batch classifier loss: 0.410946; batch adversarial loss: 0.625160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.333380; batch adversarial loss: 0.573380\n",
      "epoch 7; iter: 200; batch classifier loss: 0.370701; batch adversarial loss: 0.630098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555095; batch adversarial loss: 0.627411\n",
      "epoch 8; iter: 200; batch classifier loss: 0.392233; batch adversarial loss: 0.619439\n",
      "epoch 9; iter: 0; batch classifier loss: 0.314498; batch adversarial loss: 0.665095\n",
      "epoch 9; iter: 200; batch classifier loss: 0.593375; batch adversarial loss: 0.617244\n",
      "epoch 10; iter: 0; batch classifier loss: 0.473191; batch adversarial loss: 0.633464\n",
      "epoch 10; iter: 200; batch classifier loss: 0.431628; batch adversarial loss: 0.593333\n",
      "epoch 11; iter: 0; batch classifier loss: 0.482331; batch adversarial loss: 0.636809\n",
      "epoch 11; iter: 200; batch classifier loss: 0.448136; batch adversarial loss: 0.647475\n",
      "epoch 12; iter: 0; batch classifier loss: 0.363921; batch adversarial loss: 0.636792\n",
      "epoch 12; iter: 200; batch classifier loss: 0.465985; batch adversarial loss: 0.638464\n",
      "epoch 13; iter: 0; batch classifier loss: 0.351674; batch adversarial loss: 0.592621\n",
      "epoch 13; iter: 200; batch classifier loss: 0.489630; batch adversarial loss: 0.657152\n",
      "epoch 14; iter: 0; batch classifier loss: 0.403538; batch adversarial loss: 0.654059\n",
      "epoch 14; iter: 200; batch classifier loss: 0.560505; batch adversarial loss: 0.669014\n",
      "epoch 15; iter: 0; batch classifier loss: 0.425869; batch adversarial loss: 0.649037\n",
      "epoch 15; iter: 200; batch classifier loss: 0.361692; batch adversarial loss: 0.624523\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408473; batch adversarial loss: 0.584428\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380977; batch adversarial loss: 0.668829\n",
      "epoch 17; iter: 0; batch classifier loss: 0.413318; batch adversarial loss: 0.654182\n",
      "epoch 17; iter: 200; batch classifier loss: 0.446543; batch adversarial loss: 0.600537\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438028; batch adversarial loss: 0.588721\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373659; batch adversarial loss: 0.636342\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425962; batch adversarial loss: 0.648458\n",
      "epoch 19; iter: 200; batch classifier loss: 0.334523; batch adversarial loss: 0.655583\n",
      "epoch 20; iter: 0; batch classifier loss: 0.419069; batch adversarial loss: 0.585020\n",
      "epoch 20; iter: 200; batch classifier loss: 0.361388; batch adversarial loss: 0.670821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306232; batch adversarial loss: 0.613758\n",
      "epoch 21; iter: 200; batch classifier loss: 0.335106; batch adversarial loss: 0.672094\n",
      "epoch 22; iter: 0; batch classifier loss: 0.365664; batch adversarial loss: 0.679873\n",
      "epoch 22; iter: 200; batch classifier loss: 0.323054; batch adversarial loss: 0.615524\n",
      "epoch 23; iter: 0; batch classifier loss: 0.354637; batch adversarial loss: 0.624293\n",
      "epoch 23; iter: 200; batch classifier loss: 0.373102; batch adversarial loss: 0.619968\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362501; batch adversarial loss: 0.601075\n",
      "epoch 24; iter: 200; batch classifier loss: 0.293778; batch adversarial loss: 0.634875\n",
      "epoch 25; iter: 0; batch classifier loss: 0.422885; batch adversarial loss: 0.610795\n",
      "epoch 25; iter: 200; batch classifier loss: 0.276572; batch adversarial loss: 0.624454\n",
      "epoch 26; iter: 0; batch classifier loss: 0.258977; batch adversarial loss: 0.613766\n",
      "epoch 26; iter: 200; batch classifier loss: 0.334450; batch adversarial loss: 0.680944\n",
      "epoch 27; iter: 0; batch classifier loss: 0.550040; batch adversarial loss: 0.581609\n",
      "epoch 27; iter: 200; batch classifier loss: 0.389728; batch adversarial loss: 0.603999\n",
      "epoch 28; iter: 0; batch classifier loss: 0.306796; batch adversarial loss: 0.593551\n",
      "epoch 28; iter: 200; batch classifier loss: 0.465344; batch adversarial loss: 0.544683\n",
      "epoch 29; iter: 0; batch classifier loss: 0.348704; batch adversarial loss: 0.677734\n",
      "epoch 29; iter: 200; batch classifier loss: 0.283444; batch adversarial loss: 0.634016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.330474; batch adversarial loss: 0.634170\n",
      "epoch 30; iter: 200; batch classifier loss: 0.347819; batch adversarial loss: 0.619685\n",
      "epoch 31; iter: 0; batch classifier loss: 0.396062; batch adversarial loss: 0.608433\n",
      "epoch 31; iter: 200; batch classifier loss: 0.412002; batch adversarial loss: 0.684194\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478975; batch adversarial loss: 0.574337\n",
      "epoch 32; iter: 200; batch classifier loss: 0.375688; batch adversarial loss: 0.629276\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408976; batch adversarial loss: 0.558273\n",
      "epoch 33; iter: 200; batch classifier loss: 0.344909; batch adversarial loss: 0.623925\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478327; batch adversarial loss: 0.607343\n",
      "epoch 34; iter: 200; batch classifier loss: 0.326105; batch adversarial loss: 0.582050\n",
      "epoch 35; iter: 0; batch classifier loss: 0.351608; batch adversarial loss: 0.612520\n",
      "epoch 35; iter: 200; batch classifier loss: 0.345160; batch adversarial loss: 0.691850\n",
      "epoch 36; iter: 0; batch classifier loss: 0.297760; batch adversarial loss: 0.630417\n",
      "epoch 36; iter: 200; batch classifier loss: 0.429725; batch adversarial loss: 0.651608\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381542; batch adversarial loss: 0.644655\n",
      "epoch 37; iter: 200; batch classifier loss: 0.335800; batch adversarial loss: 0.586731\n",
      "epoch 38; iter: 0; batch classifier loss: 0.325502; batch adversarial loss: 0.634248\n",
      "epoch 38; iter: 200; batch classifier loss: 0.405075; batch adversarial loss: 0.675469\n",
      "epoch 39; iter: 0; batch classifier loss: 0.339939; batch adversarial loss: 0.645551\n",
      "epoch 39; iter: 200; batch classifier loss: 0.509394; batch adversarial loss: 0.581444\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361856; batch adversarial loss: 0.631116\n",
      "epoch 40; iter: 200; batch classifier loss: 0.391996; batch adversarial loss: 0.635174\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423597; batch adversarial loss: 0.629183\n",
      "epoch 41; iter: 200; batch classifier loss: 0.489338; batch adversarial loss: 0.628569\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408832; batch adversarial loss: 0.643333\n",
      "epoch 42; iter: 200; batch classifier loss: 0.473200; batch adversarial loss: 0.581842\n",
      "epoch 43; iter: 0; batch classifier loss: 0.393904; batch adversarial loss: 0.603611\n",
      "epoch 43; iter: 200; batch classifier loss: 0.738998; batch adversarial loss: 0.633554\n",
      "epoch 44; iter: 0; batch classifier loss: 0.378897; batch adversarial loss: 0.626050\n",
      "epoch 44; iter: 200; batch classifier loss: 0.502753; batch adversarial loss: 0.601952\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442503; batch adversarial loss: 0.611637\n",
      "epoch 45; iter: 200; batch classifier loss: 0.390154; batch adversarial loss: 0.631645\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317055; batch adversarial loss: 0.661787\n",
      "epoch 46; iter: 200; batch classifier loss: 0.295236; batch adversarial loss: 0.597020\n",
      "epoch 47; iter: 0; batch classifier loss: 0.447300; batch adversarial loss: 0.630670\n",
      "epoch 47; iter: 200; batch classifier loss: 0.335622; batch adversarial loss: 0.617378\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413133; batch adversarial loss: 0.622370\n",
      "epoch 48; iter: 200; batch classifier loss: 0.480050; batch adversarial loss: 0.545558\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419310; batch adversarial loss: 0.626946\n",
      "epoch 49; iter: 200; batch classifier loss: 0.285965; batch adversarial loss: 0.691321\n",
      "epoch 0; iter: 0; batch classifier loss: 39.328598; batch adversarial loss: 0.675451\n",
      "epoch 0; iter: 200; batch classifier loss: 5.377722; batch adversarial loss: 0.664230\n",
      "epoch 1; iter: 0; batch classifier loss: 2.981437; batch adversarial loss: 0.656714\n",
      "epoch 1; iter: 200; batch classifier loss: 1.587294; batch adversarial loss: 0.608469\n",
      "epoch 2; iter: 0; batch classifier loss: 4.081314; batch adversarial loss: 0.622262\n",
      "epoch 2; iter: 200; batch classifier loss: 1.888026; batch adversarial loss: 0.665973\n",
      "epoch 3; iter: 0; batch classifier loss: 1.707482; batch adversarial loss: 0.584662\n",
      "epoch 3; iter: 200; batch classifier loss: 0.896537; batch adversarial loss: 0.624767\n",
      "epoch 4; iter: 0; batch classifier loss: 5.209196; batch adversarial loss: 0.603696\n",
      "epoch 4; iter: 200; batch classifier loss: 1.667805; batch adversarial loss: 0.734472\n",
      "epoch 5; iter: 0; batch classifier loss: 1.795802; batch adversarial loss: 0.618640\n",
      "epoch 5; iter: 200; batch classifier loss: 0.647456; batch adversarial loss: 0.634909\n",
      "epoch 6; iter: 0; batch classifier loss: 1.190687; batch adversarial loss: 0.635618\n",
      "epoch 6; iter: 200; batch classifier loss: 0.702124; batch adversarial loss: 0.613252\n",
      "epoch 7; iter: 0; batch classifier loss: 0.664009; batch adversarial loss: 0.641004\n",
      "epoch 7; iter: 200; batch classifier loss: 0.500315; batch adversarial loss: 0.575144\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556706; batch adversarial loss: 0.593449\n",
      "epoch 8; iter: 200; batch classifier loss: 0.587179; batch adversarial loss: 0.580507\n",
      "epoch 9; iter: 0; batch classifier loss: 0.441602; batch adversarial loss: 0.633213\n",
      "epoch 9; iter: 200; batch classifier loss: 0.395603; batch adversarial loss: 0.619646\n",
      "epoch 10; iter: 0; batch classifier loss: 0.356565; batch adversarial loss: 0.609787\n",
      "epoch 10; iter: 200; batch classifier loss: 0.436203; batch adversarial loss: 0.632555\n",
      "epoch 11; iter: 0; batch classifier loss: 0.251693; batch adversarial loss: 0.694345\n",
      "epoch 11; iter: 200; batch classifier loss: 0.416253; batch adversarial loss: 0.632047\n",
      "epoch 12; iter: 0; batch classifier loss: 0.322703; batch adversarial loss: 0.639859\n",
      "epoch 12; iter: 200; batch classifier loss: 0.384362; batch adversarial loss: 0.576989\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515627; batch adversarial loss: 0.642419\n",
      "epoch 13; iter: 200; batch classifier loss: 0.391804; batch adversarial loss: 0.661977\n",
      "epoch 14; iter: 0; batch classifier loss: 0.382845; batch adversarial loss: 0.556665\n",
      "epoch 14; iter: 200; batch classifier loss: 0.482826; batch adversarial loss: 0.570347\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458556; batch adversarial loss: 0.640045\n",
      "epoch 15; iter: 200; batch classifier loss: 0.427044; batch adversarial loss: 0.657181\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319310; batch adversarial loss: 0.634299\n",
      "epoch 16; iter: 200; batch classifier loss: 0.308092; batch adversarial loss: 0.646390\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420310; batch adversarial loss: 0.655577\n",
      "epoch 17; iter: 200; batch classifier loss: 0.389647; batch adversarial loss: 0.624510\n",
      "epoch 18; iter: 0; batch classifier loss: 0.376124; batch adversarial loss: 0.570880\n",
      "epoch 18; iter: 200; batch classifier loss: 0.324286; batch adversarial loss: 0.656547\n",
      "epoch 19; iter: 0; batch classifier loss: 0.523573; batch adversarial loss: 0.635100\n",
      "epoch 19; iter: 200; batch classifier loss: 0.432402; batch adversarial loss: 0.614255\n",
      "epoch 20; iter: 0; batch classifier loss: 0.382076; batch adversarial loss: 0.669572\n",
      "epoch 20; iter: 200; batch classifier loss: 0.400888; batch adversarial loss: 0.622907\n",
      "epoch 21; iter: 0; batch classifier loss: 0.383557; batch adversarial loss: 0.602029\n",
      "epoch 21; iter: 200; batch classifier loss: 0.443858; batch adversarial loss: 0.598672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.326538; batch adversarial loss: 0.603484\n",
      "epoch 22; iter: 200; batch classifier loss: 0.542696; batch adversarial loss: 0.627150\n",
      "epoch 23; iter: 0; batch classifier loss: 0.369959; batch adversarial loss: 0.622346\n",
      "epoch 23; iter: 200; batch classifier loss: 0.413083; batch adversarial loss: 0.647754\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421317; batch adversarial loss: 0.598165\n",
      "epoch 24; iter: 200; batch classifier loss: 0.369442; batch adversarial loss: 0.629090\n",
      "epoch 25; iter: 0; batch classifier loss: 0.309245; batch adversarial loss: 0.635198\n",
      "epoch 25; iter: 200; batch classifier loss: 0.337912; batch adversarial loss: 0.612379\n",
      "epoch 26; iter: 0; batch classifier loss: 0.347102; batch adversarial loss: 0.611620\n",
      "epoch 26; iter: 200; batch classifier loss: 0.263184; batch adversarial loss: 0.627196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.366203; batch adversarial loss: 0.633090\n",
      "epoch 27; iter: 200; batch classifier loss: 0.350820; batch adversarial loss: 0.615841\n",
      "epoch 28; iter: 0; batch classifier loss: 0.409393; batch adversarial loss: 0.614796\n",
      "epoch 28; iter: 200; batch classifier loss: 0.345521; batch adversarial loss: 0.625095\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259885; batch adversarial loss: 0.612727\n",
      "epoch 29; iter: 200; batch classifier loss: 0.326572; batch adversarial loss: 0.627412\n",
      "epoch 30; iter: 0; batch classifier loss: 0.297078; batch adversarial loss: 0.586433\n",
      "epoch 30; iter: 200; batch classifier loss: 0.398795; batch adversarial loss: 0.643260\n",
      "epoch 31; iter: 0; batch classifier loss: 0.483604; batch adversarial loss: 0.644443\n",
      "epoch 31; iter: 200; batch classifier loss: 0.292456; batch adversarial loss: 0.620638\n",
      "epoch 32; iter: 0; batch classifier loss: 0.363520; batch adversarial loss: 0.662769\n",
      "epoch 32; iter: 200; batch classifier loss: 0.359301; batch adversarial loss: 0.633083\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401393; batch adversarial loss: 0.636401\n",
      "epoch 33; iter: 200; batch classifier loss: 0.405163; batch adversarial loss: 0.638487\n",
      "epoch 34; iter: 0; batch classifier loss: 0.482172; batch adversarial loss: 0.622484\n",
      "epoch 34; iter: 200; batch classifier loss: 0.331907; batch adversarial loss: 0.633842\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471210; batch adversarial loss: 0.607290\n",
      "epoch 35; iter: 200; batch classifier loss: 0.485312; batch adversarial loss: 0.616575\n",
      "epoch 36; iter: 0; batch classifier loss: 0.344828; batch adversarial loss: 0.640703\n",
      "epoch 36; iter: 200; batch classifier loss: 0.309008; batch adversarial loss: 0.602411\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404951; batch adversarial loss: 0.628919\n",
      "epoch 37; iter: 200; batch classifier loss: 0.365421; batch adversarial loss: 0.630350\n",
      "epoch 38; iter: 0; batch classifier loss: 0.341314; batch adversarial loss: 0.624015\n",
      "epoch 38; iter: 200; batch classifier loss: 0.462795; batch adversarial loss: 0.640318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.366721; batch adversarial loss: 0.676064\n",
      "epoch 39; iter: 200; batch classifier loss: 0.442709; batch adversarial loss: 0.658307\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390490; batch adversarial loss: 0.602645\n",
      "epoch 40; iter: 200; batch classifier loss: 0.389107; batch adversarial loss: 0.672717\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410034; batch adversarial loss: 0.622960\n",
      "epoch 41; iter: 200; batch classifier loss: 0.438495; batch adversarial loss: 0.618797\n",
      "epoch 42; iter: 0; batch classifier loss: 0.373415; batch adversarial loss: 0.634301\n",
      "epoch 42; iter: 200; batch classifier loss: 0.409206; batch adversarial loss: 0.626029\n",
      "epoch 43; iter: 0; batch classifier loss: 0.752359; batch adversarial loss: 0.581605\n",
      "epoch 43; iter: 200; batch classifier loss: 0.355732; batch adversarial loss: 0.642083\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457186; batch adversarial loss: 0.565014\n",
      "epoch 44; iter: 200; batch classifier loss: 0.362467; batch adversarial loss: 0.631403\n",
      "epoch 45; iter: 0; batch classifier loss: 0.296531; batch adversarial loss: 0.656656\n",
      "epoch 45; iter: 200; batch classifier loss: 0.359416; batch adversarial loss: 0.622740\n",
      "epoch 46; iter: 0; batch classifier loss: 0.361817; batch adversarial loss: 0.592789\n",
      "epoch 46; iter: 200; batch classifier loss: 0.280715; batch adversarial loss: 0.608496\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446578; batch adversarial loss: 0.663412\n",
      "epoch 47; iter: 200; batch classifier loss: 0.368132; batch adversarial loss: 0.639474\n",
      "epoch 48; iter: 0; batch classifier loss: 0.327715; batch adversarial loss: 0.645751\n",
      "epoch 48; iter: 200; batch classifier loss: 0.366563; batch adversarial loss: 0.685331\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400741; batch adversarial loss: 0.634438\n",
      "epoch 49; iter: 200; batch classifier loss: 0.369028; batch adversarial loss: 0.599838\n",
      "epoch 0; iter: 0; batch classifier loss: 28.046398; batch adversarial loss: 0.663626\n",
      "epoch 0; iter: 200; batch classifier loss: 5.523405; batch adversarial loss: 0.667945\n",
      "epoch 1; iter: 0; batch classifier loss: 4.704677; batch adversarial loss: 0.613457\n",
      "epoch 1; iter: 200; batch classifier loss: 6.703541; batch adversarial loss: 0.654574\n",
      "epoch 2; iter: 0; batch classifier loss: 3.927468; batch adversarial loss: 0.652180\n",
      "epoch 2; iter: 200; batch classifier loss: 6.516219; batch adversarial loss: 0.615953\n",
      "epoch 3; iter: 0; batch classifier loss: 13.601868; batch adversarial loss: 0.642855\n",
      "epoch 3; iter: 200; batch classifier loss: 1.444009; batch adversarial loss: 0.683980\n",
      "epoch 4; iter: 0; batch classifier loss: 0.461162; batch adversarial loss: 0.555920\n",
      "epoch 4; iter: 200; batch classifier loss: 0.619143; batch adversarial loss: 0.619190\n",
      "epoch 5; iter: 0; batch classifier loss: 1.893480; batch adversarial loss: 0.636131\n",
      "epoch 5; iter: 200; batch classifier loss: 0.940451; batch adversarial loss: 0.644796\n",
      "epoch 6; iter: 0; batch classifier loss: 2.126278; batch adversarial loss: 0.631788\n",
      "epoch 6; iter: 200; batch classifier loss: 0.640403; batch adversarial loss: 0.590728\n",
      "epoch 7; iter: 0; batch classifier loss: 0.776132; batch adversarial loss: 0.639925\n",
      "epoch 7; iter: 200; batch classifier loss: 0.406877; batch adversarial loss: 0.648947\n",
      "epoch 8; iter: 0; batch classifier loss: 0.650496; batch adversarial loss: 0.672355\n",
      "epoch 8; iter: 200; batch classifier loss: 0.288664; batch adversarial loss: 0.612669\n",
      "epoch 9; iter: 0; batch classifier loss: 0.290526; batch adversarial loss: 0.621301\n",
      "epoch 9; iter: 200; batch classifier loss: 0.410459; batch adversarial loss: 0.577338\n",
      "epoch 10; iter: 0; batch classifier loss: 0.746318; batch adversarial loss: 0.613039\n",
      "epoch 10; iter: 200; batch classifier loss: 0.469104; batch adversarial loss: 0.651178\n",
      "epoch 11; iter: 0; batch classifier loss: 0.940450; batch adversarial loss: 0.620035\n",
      "epoch 11; iter: 200; batch classifier loss: 0.574317; batch adversarial loss: 0.650586\n",
      "epoch 12; iter: 0; batch classifier loss: 0.297671; batch adversarial loss: 0.630234\n",
      "epoch 12; iter: 200; batch classifier loss: 0.569141; batch adversarial loss: 0.632457\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518964; batch adversarial loss: 0.600673\n",
      "epoch 13; iter: 200; batch classifier loss: 0.526709; batch adversarial loss: 0.633959\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290983; batch adversarial loss: 0.692943\n",
      "epoch 14; iter: 200; batch classifier loss: 0.290858; batch adversarial loss: 0.626039\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395193; batch adversarial loss: 0.622665\n",
      "epoch 15; iter: 200; batch classifier loss: 0.393456; batch adversarial loss: 0.679105\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387546; batch adversarial loss: 0.609668\n",
      "epoch 16; iter: 200; batch classifier loss: 0.349899; batch adversarial loss: 0.695995\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327306; batch adversarial loss: 0.573112\n",
      "epoch 17; iter: 200; batch classifier loss: 0.495298; batch adversarial loss: 0.609594\n",
      "epoch 18; iter: 0; batch classifier loss: 0.400948; batch adversarial loss: 0.599762\n",
      "epoch 18; iter: 200; batch classifier loss: 0.486782; batch adversarial loss: 0.639009\n",
      "epoch 19; iter: 0; batch classifier loss: 0.304736; batch adversarial loss: 0.645618\n",
      "epoch 19; iter: 200; batch classifier loss: 0.417721; batch adversarial loss: 0.600085\n",
      "epoch 20; iter: 0; batch classifier loss: 0.458615; batch adversarial loss: 0.615050\n",
      "epoch 20; iter: 200; batch classifier loss: 0.430382; batch adversarial loss: 0.617849\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450383; batch adversarial loss: 0.605946\n",
      "epoch 21; iter: 200; batch classifier loss: 0.401375; batch adversarial loss: 0.621533\n",
      "epoch 22; iter: 0; batch classifier loss: 0.357869; batch adversarial loss: 0.644853\n",
      "epoch 22; iter: 200; batch classifier loss: 0.381486; batch adversarial loss: 0.590200\n",
      "epoch 23; iter: 0; batch classifier loss: 0.323699; batch adversarial loss: 0.633709\n",
      "epoch 23; iter: 200; batch classifier loss: 0.317895; batch adversarial loss: 0.647298\n",
      "epoch 24; iter: 0; batch classifier loss: 0.385546; batch adversarial loss: 0.620342\n",
      "epoch 24; iter: 200; batch classifier loss: 0.343958; batch adversarial loss: 0.618942\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271719; batch adversarial loss: 0.600446\n",
      "epoch 25; iter: 200; batch classifier loss: 0.285539; batch adversarial loss: 0.684827\n",
      "epoch 26; iter: 0; batch classifier loss: 0.377361; batch adversarial loss: 0.603021\n",
      "epoch 26; iter: 200; batch classifier loss: 0.316451; batch adversarial loss: 0.635090\n",
      "epoch 27; iter: 0; batch classifier loss: 0.293872; batch adversarial loss: 0.625489\n",
      "epoch 27; iter: 200; batch classifier loss: 0.313738; batch adversarial loss: 0.624325\n",
      "epoch 28; iter: 0; batch classifier loss: 0.392888; batch adversarial loss: 0.563819\n",
      "epoch 28; iter: 200; batch classifier loss: 0.364343; batch adversarial loss: 0.627195\n",
      "epoch 29; iter: 0; batch classifier loss: 0.255590; batch adversarial loss: 0.667311\n",
      "epoch 29; iter: 200; batch classifier loss: 0.412989; batch adversarial loss: 0.612582\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422476; batch adversarial loss: 0.659044\n",
      "epoch 30; iter: 200; batch classifier loss: 0.309990; batch adversarial loss: 0.583204\n",
      "epoch 31; iter: 0; batch classifier loss: 0.293837; batch adversarial loss: 0.628618\n",
      "epoch 31; iter: 200; batch classifier loss: 0.413570; batch adversarial loss: 0.599412\n",
      "epoch 32; iter: 0; batch classifier loss: 0.359777; batch adversarial loss: 0.616578\n",
      "epoch 32; iter: 200; batch classifier loss: 0.413798; batch adversarial loss: 0.621689\n",
      "epoch 33; iter: 0; batch classifier loss: 0.353748; batch adversarial loss: 0.585871\n",
      "epoch 33; iter: 200; batch classifier loss: 0.533493; batch adversarial loss: 0.570877\n",
      "epoch 34; iter: 0; batch classifier loss: 0.341035; batch adversarial loss: 0.591447\n",
      "epoch 34; iter: 200; batch classifier loss: 0.343944; batch adversarial loss: 0.627912\n",
      "epoch 35; iter: 0; batch classifier loss: 0.373630; batch adversarial loss: 0.582970\n",
      "epoch 35; iter: 200; batch classifier loss: 0.249470; batch adversarial loss: 0.614824\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434246; batch adversarial loss: 0.581833\n",
      "epoch 36; iter: 200; batch classifier loss: 0.320652; batch adversarial loss: 0.609349\n",
      "epoch 37; iter: 0; batch classifier loss: 0.336537; batch adversarial loss: 0.679440\n",
      "epoch 37; iter: 200; batch classifier loss: 0.335662; batch adversarial loss: 0.622128\n",
      "epoch 38; iter: 0; batch classifier loss: 0.377205; batch adversarial loss: 0.614175\n",
      "epoch 38; iter: 200; batch classifier loss: 0.381372; batch adversarial loss: 0.615788\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422918; batch adversarial loss: 0.654254\n",
      "epoch 39; iter: 200; batch classifier loss: 0.336166; batch adversarial loss: 0.616347\n",
      "epoch 40; iter: 0; batch classifier loss: 0.404553; batch adversarial loss: 0.600550\n",
      "epoch 40; iter: 200; batch classifier loss: 0.388354; batch adversarial loss: 0.626483\n",
      "epoch 41; iter: 0; batch classifier loss: 0.306690; batch adversarial loss: 0.614333\n",
      "epoch 41; iter: 200; batch classifier loss: 0.643844; batch adversarial loss: 0.611999\n",
      "epoch 42; iter: 0; batch classifier loss: 0.322407; batch adversarial loss: 0.627292\n",
      "epoch 42; iter: 200; batch classifier loss: 0.344149; batch adversarial loss: 0.656503\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432946; batch adversarial loss: 0.623039\n",
      "epoch 43; iter: 200; batch classifier loss: 0.305241; batch adversarial loss: 0.572448\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386378; batch adversarial loss: 0.611459\n",
      "epoch 44; iter: 200; batch classifier loss: 0.397027; batch adversarial loss: 0.676489\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376669; batch adversarial loss: 0.667171\n",
      "epoch 45; iter: 200; batch classifier loss: 0.338722; batch adversarial loss: 0.639243\n",
      "epoch 46; iter: 0; batch classifier loss: 0.316235; batch adversarial loss: 0.635098\n",
      "epoch 46; iter: 200; batch classifier loss: 0.251628; batch adversarial loss: 0.643207\n",
      "epoch 47; iter: 0; batch classifier loss: 0.355522; batch adversarial loss: 0.608677\n",
      "epoch 47; iter: 200; batch classifier loss: 0.283594; batch adversarial loss: 0.700218\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306725; batch adversarial loss: 0.561904\n",
      "epoch 48; iter: 200; batch classifier loss: 0.328555; batch adversarial loss: 0.593476\n",
      "epoch 49; iter: 0; batch classifier loss: 0.360281; batch adversarial loss: 0.609160\n",
      "epoch 49; iter: 200; batch classifier loss: 0.492167; batch adversarial loss: 0.619744\n",
      "epoch 0; iter: 0; batch classifier loss: 22.956945; batch adversarial loss: 0.688562\n",
      "epoch 0; iter: 200; batch classifier loss: 10.443532; batch adversarial loss: 0.660607\n",
      "epoch 1; iter: 0; batch classifier loss: 17.710243; batch adversarial loss: 0.658189\n",
      "epoch 1; iter: 200; batch classifier loss: 8.704371; batch adversarial loss: 0.612695\n",
      "epoch 2; iter: 0; batch classifier loss: 8.304892; batch adversarial loss: 0.645082\n",
      "epoch 2; iter: 200; batch classifier loss: 2.850574; batch adversarial loss: 0.659424\n",
      "epoch 3; iter: 0; batch classifier loss: 2.318109; batch adversarial loss: 0.654047\n",
      "epoch 3; iter: 200; batch classifier loss: 1.405662; batch adversarial loss: 0.619515\n",
      "epoch 4; iter: 0; batch classifier loss: 8.035599; batch adversarial loss: 0.608035\n",
      "epoch 4; iter: 200; batch classifier loss: 1.505340; batch adversarial loss: 0.613002\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595599; batch adversarial loss: 0.606041\n",
      "epoch 5; iter: 200; batch classifier loss: 2.337844; batch adversarial loss: 0.627698\n",
      "epoch 6; iter: 0; batch classifier loss: 1.656382; batch adversarial loss: 0.611359\n",
      "epoch 6; iter: 200; batch classifier loss: 1.200359; batch adversarial loss: 0.570409\n",
      "epoch 7; iter: 0; batch classifier loss: 13.938650; batch adversarial loss: 0.643089\n",
      "epoch 7; iter: 200; batch classifier loss: 0.462263; batch adversarial loss: 0.593639\n",
      "epoch 8; iter: 0; batch classifier loss: 0.448087; batch adversarial loss: 0.655855\n",
      "epoch 8; iter: 200; batch classifier loss: 1.085258; batch adversarial loss: 0.674898\n",
      "epoch 9; iter: 0; batch classifier loss: 0.636186; batch adversarial loss: 0.583801\n",
      "epoch 9; iter: 200; batch classifier loss: 0.567319; batch adversarial loss: 0.613042\n",
      "epoch 10; iter: 0; batch classifier loss: 0.829431; batch adversarial loss: 0.605550\n",
      "epoch 10; iter: 200; batch classifier loss: 0.550436; batch adversarial loss: 0.670635\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470710; batch adversarial loss: 0.623254\n",
      "epoch 11; iter: 200; batch classifier loss: 0.446097; batch adversarial loss: 0.627254\n",
      "epoch 12; iter: 0; batch classifier loss: 0.307575; batch adversarial loss: 0.611374\n",
      "epoch 12; iter: 200; batch classifier loss: 0.328802; batch adversarial loss: 0.683037\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339982; batch adversarial loss: 0.649281\n",
      "epoch 13; iter: 200; batch classifier loss: 0.387417; batch adversarial loss: 0.633220\n",
      "epoch 14; iter: 0; batch classifier loss: 0.337758; batch adversarial loss: 0.641328\n",
      "epoch 14; iter: 200; batch classifier loss: 0.673868; batch adversarial loss: 0.672500\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395441; batch adversarial loss: 0.660965\n",
      "epoch 15; iter: 200; batch classifier loss: 0.558431; batch adversarial loss: 0.619358\n",
      "epoch 16; iter: 0; batch classifier loss: 0.441878; batch adversarial loss: 0.675849\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388053; batch adversarial loss: 0.619671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.912967; batch adversarial loss: 0.637334\n",
      "epoch 17; iter: 200; batch classifier loss: 0.539802; batch adversarial loss: 0.632333\n",
      "epoch 18; iter: 0; batch classifier loss: 0.411916; batch adversarial loss: 0.527065\n",
      "epoch 18; iter: 200; batch classifier loss: 0.374560; batch adversarial loss: 0.607678\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374980; batch adversarial loss: 0.637100\n",
      "epoch 19; iter: 200; batch classifier loss: 0.465797; batch adversarial loss: 0.667028\n",
      "epoch 20; iter: 0; batch classifier loss: 0.390574; batch adversarial loss: 0.556301\n",
      "epoch 20; iter: 200; batch classifier loss: 0.375958; batch adversarial loss: 0.606873\n",
      "epoch 21; iter: 0; batch classifier loss: 0.365439; batch adversarial loss: 0.619588\n",
      "epoch 21; iter: 200; batch classifier loss: 0.449556; batch adversarial loss: 0.631368\n",
      "epoch 22; iter: 0; batch classifier loss: 0.374679; batch adversarial loss: 0.647537\n",
      "epoch 22; iter: 200; batch classifier loss: 0.461569; batch adversarial loss: 0.567620\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379026; batch adversarial loss: 0.626924\n",
      "epoch 23; iter: 200; batch classifier loss: 0.413156; batch adversarial loss: 0.592562\n",
      "epoch 24; iter: 0; batch classifier loss: 0.372260; batch adversarial loss: 0.648498\n",
      "epoch 24; iter: 200; batch classifier loss: 0.276618; batch adversarial loss: 0.633043\n",
      "epoch 25; iter: 0; batch classifier loss: 0.280656; batch adversarial loss: 0.588325\n",
      "epoch 25; iter: 200; batch classifier loss: 0.426953; batch adversarial loss: 0.564053\n",
      "epoch 26; iter: 0; batch classifier loss: 0.380612; batch adversarial loss: 0.672151\n",
      "epoch 26; iter: 200; batch classifier loss: 0.395036; batch adversarial loss: 0.593509\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337349; batch adversarial loss: 0.633606\n",
      "epoch 27; iter: 200; batch classifier loss: 0.304039; batch adversarial loss: 0.590127\n",
      "epoch 28; iter: 0; batch classifier loss: 0.357157; batch adversarial loss: 0.624831\n",
      "epoch 28; iter: 200; batch classifier loss: 0.421040; batch adversarial loss: 0.644303\n",
      "epoch 29; iter: 0; batch classifier loss: 0.362601; batch adversarial loss: 0.593209\n",
      "epoch 29; iter: 200; batch classifier loss: 0.409674; batch adversarial loss: 0.584752\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456991; batch adversarial loss: 0.630829\n",
      "epoch 30; iter: 200; batch classifier loss: 0.357732; batch adversarial loss: 0.593563\n",
      "epoch 31; iter: 0; batch classifier loss: 0.287641; batch adversarial loss: 0.597287\n",
      "epoch 31; iter: 200; batch classifier loss: 0.276227; batch adversarial loss: 0.642065\n",
      "epoch 32; iter: 0; batch classifier loss: 0.371702; batch adversarial loss: 0.631041\n",
      "epoch 32; iter: 200; batch classifier loss: 0.370730; batch adversarial loss: 0.602574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450942; batch adversarial loss: 0.614478\n",
      "epoch 33; iter: 200; batch classifier loss: 0.429473; batch adversarial loss: 0.604232\n",
      "epoch 34; iter: 0; batch classifier loss: 0.311976; batch adversarial loss: 0.606849\n",
      "epoch 34; iter: 200; batch classifier loss: 0.460769; batch adversarial loss: 0.602664\n",
      "epoch 35; iter: 0; batch classifier loss: 0.340034; batch adversarial loss: 0.632703\n",
      "epoch 35; iter: 200; batch classifier loss: 0.354155; batch adversarial loss: 0.611497\n",
      "epoch 36; iter: 0; batch classifier loss: 0.374395; batch adversarial loss: 0.613301\n",
      "epoch 36; iter: 200; batch classifier loss: 0.330700; batch adversarial loss: 0.630306\n",
      "epoch 37; iter: 0; batch classifier loss: 0.329485; batch adversarial loss: 0.683100\n",
      "epoch 37; iter: 200; batch classifier loss: 0.401625; batch adversarial loss: 0.621761\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373432; batch adversarial loss: 0.589961\n",
      "epoch 38; iter: 200; batch classifier loss: 0.286523; batch adversarial loss: 0.592947\n",
      "epoch 39; iter: 0; batch classifier loss: 0.380344; batch adversarial loss: 0.621925\n",
      "epoch 39; iter: 200; batch classifier loss: 0.350737; batch adversarial loss: 0.619525\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367226; batch adversarial loss: 0.630232\n",
      "epoch 40; iter: 200; batch classifier loss: 0.275157; batch adversarial loss: 0.640352\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449295; batch adversarial loss: 0.642365\n",
      "epoch 41; iter: 200; batch classifier loss: 0.402245; batch adversarial loss: 0.602579\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457946; batch adversarial loss: 0.621740\n",
      "epoch 42; iter: 200; batch classifier loss: 0.513120; batch adversarial loss: 0.582280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.307476; batch adversarial loss: 0.617257\n",
      "epoch 43; iter: 200; batch classifier loss: 0.463886; batch adversarial loss: 0.618623\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481399; batch adversarial loss: 0.610164\n",
      "epoch 44; iter: 200; batch classifier loss: 0.400405; batch adversarial loss: 0.595137\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413425; batch adversarial loss: 0.615731\n",
      "epoch 45; iter: 200; batch classifier loss: 0.335411; batch adversarial loss: 0.587288\n",
      "epoch 46; iter: 0; batch classifier loss: 0.434468; batch adversarial loss: 0.619944\n",
      "epoch 46; iter: 200; batch classifier loss: 0.409917; batch adversarial loss: 0.574116\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484620; batch adversarial loss: 0.591105\n",
      "epoch 47; iter: 200; batch classifier loss: 0.443321; batch adversarial loss: 0.694432\n",
      "epoch 48; iter: 0; batch classifier loss: 0.359691; batch adversarial loss: 0.592915\n",
      "epoch 48; iter: 200; batch classifier loss: 0.404648; batch adversarial loss: 0.592871\n",
      "epoch 49; iter: 0; batch classifier loss: 0.498350; batch adversarial loss: 0.590726\n",
      "epoch 49; iter: 200; batch classifier loss: 0.324271; batch adversarial loss: 0.639292\n",
      "Best parameters: adversary_loss_weight     1.000000\n",
      "batch_size               64.000000\n",
      "num_epochs               10.000000\n",
      "acc_mean                  0.815601\n",
      "acc_std                   0.013747\n",
      "f1_mean                   0.480061\n",
      "f1_std                    0.078158\n",
      "SPD_mean                 -0.009022\n",
      "SPD_std                   0.028017\n",
      "DI_mean                   0.996947\n",
      "DI_std                    0.258184\n",
      "EOD_mean                  0.259476\n",
      "EOD_std                   0.061979\n",
      "AOD_mean                  0.140337\n",
      "AOD_std                   0.035708\n",
      "fairness_score            0.012075\n",
      "Name: 6, dtype: float64\n",
      "epoch 0; iter: 0; batch classifier loss: 126.045380; batch adversarial loss: 0.735191\n",
      "epoch 0; iter: 200; batch classifier loss: 4.576407; batch adversarial loss: 0.855656\n",
      "epoch 0; iter: 400; batch classifier loss: 7.697418; batch adversarial loss: 0.662871\n",
      "epoch 0; iter: 600; batch classifier loss: 7.276422; batch adversarial loss: 0.702428\n",
      "epoch 1; iter: 0; batch classifier loss: 3.919177; batch adversarial loss: 0.622631\n",
      "epoch 1; iter: 200; batch classifier loss: 0.907643; batch adversarial loss: 0.654465\n",
      "epoch 1; iter: 400; batch classifier loss: 6.960036; batch adversarial loss: 0.659616\n",
      "epoch 1; iter: 600; batch classifier loss: 1.940778; batch adversarial loss: 0.686515\n",
      "epoch 2; iter: 0; batch classifier loss: 3.085787; batch adversarial loss: 0.569073\n",
      "epoch 2; iter: 200; batch classifier loss: 1.026730; batch adversarial loss: 0.651632\n",
      "epoch 2; iter: 400; batch classifier loss: 0.417821; batch adversarial loss: 0.612116\n",
      "epoch 2; iter: 600; batch classifier loss: 1.240677; batch adversarial loss: 0.635826\n",
      "epoch 3; iter: 0; batch classifier loss: 3.623370; batch adversarial loss: 0.631544\n",
      "epoch 3; iter: 200; batch classifier loss: 0.957471; batch adversarial loss: 0.649944\n",
      "epoch 3; iter: 400; batch classifier loss: 0.641213; batch adversarial loss: 0.571298\n",
      "epoch 3; iter: 600; batch classifier loss: 0.433806; batch adversarial loss: 0.643232\n",
      "epoch 4; iter: 0; batch classifier loss: 0.381229; batch adversarial loss: 0.635939\n",
      "epoch 4; iter: 200; batch classifier loss: 0.421368; batch adversarial loss: 0.622783\n",
      "epoch 4; iter: 400; batch classifier loss: 0.504244; batch adversarial loss: 0.666437\n",
      "epoch 4; iter: 600; batch classifier loss: 0.478324; batch adversarial loss: 0.681723\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322352; batch adversarial loss: 0.689016\n",
      "epoch 5; iter: 200; batch classifier loss: 0.277141; batch adversarial loss: 0.611480\n",
      "epoch 5; iter: 400; batch classifier loss: 0.338567; batch adversarial loss: 0.608984\n",
      "epoch 5; iter: 600; batch classifier loss: 0.334530; batch adversarial loss: 0.677011\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586514; batch adversarial loss: 0.625681\n",
      "epoch 6; iter: 200; batch classifier loss: 0.443666; batch adversarial loss: 0.655520\n",
      "epoch 6; iter: 400; batch classifier loss: 0.570615; batch adversarial loss: 0.606619\n",
      "epoch 6; iter: 600; batch classifier loss: 0.411775; batch adversarial loss: 0.540344\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494113; batch adversarial loss: 0.616876\n",
      "epoch 7; iter: 200; batch classifier loss: 0.313759; batch adversarial loss: 0.637106\n",
      "epoch 7; iter: 400; batch classifier loss: 0.359064; batch adversarial loss: 0.669624\n",
      "epoch 7; iter: 600; batch classifier loss: 0.355670; batch adversarial loss: 0.606800\n",
      "epoch 8; iter: 0; batch classifier loss: 0.298611; batch adversarial loss: 0.623131\n",
      "epoch 8; iter: 200; batch classifier loss: 0.447908; batch adversarial loss: 0.598724\n",
      "epoch 8; iter: 400; batch classifier loss: 0.552904; batch adversarial loss: 0.580194\n",
      "epoch 8; iter: 600; batch classifier loss: 0.424856; batch adversarial loss: 0.697386\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504715; batch adversarial loss: 0.744378\n",
      "epoch 9; iter: 200; batch classifier loss: 0.391715; batch adversarial loss: 0.640106\n",
      "epoch 9; iter: 400; batch classifier loss: 0.394850; batch adversarial loss: 0.617211\n",
      "epoch 9; iter: 600; batch classifier loss: 0.328429; batch adversarial loss: 0.630921\n",
      "epoch 0; iter: 0; batch classifier loss: 5.603682; batch adversarial loss: 0.517180\n",
      "epoch 0; iter: 200; batch classifier loss: 8.779080; batch adversarial loss: 0.692684\n",
      "epoch 0; iter: 400; batch classifier loss: 16.659840; batch adversarial loss: 0.681960\n",
      "epoch 0; iter: 600; batch classifier loss: 14.122592; batch adversarial loss: 0.700412\n",
      "epoch 1; iter: 0; batch classifier loss: 5.673231; batch adversarial loss: 0.588303\n",
      "epoch 1; iter: 200; batch classifier loss: 3.122101; batch adversarial loss: 0.548718\n",
      "epoch 1; iter: 400; batch classifier loss: 3.462370; batch adversarial loss: 0.699306\n",
      "epoch 1; iter: 600; batch classifier loss: 4.558926; batch adversarial loss: 0.588955\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600545; batch adversarial loss: 0.686381\n",
      "epoch 2; iter: 200; batch classifier loss: 0.578982; batch adversarial loss: 0.583914\n",
      "epoch 2; iter: 400; batch classifier loss: 0.320403; batch adversarial loss: 0.578477\n",
      "epoch 2; iter: 600; batch classifier loss: 0.488499; batch adversarial loss: 0.586662\n",
      "epoch 3; iter: 0; batch classifier loss: 0.354227; batch adversarial loss: 0.649425\n",
      "epoch 3; iter: 200; batch classifier loss: 1.341463; batch adversarial loss: 0.539912\n",
      "epoch 3; iter: 400; batch classifier loss: 0.369014; batch adversarial loss: 0.588313\n",
      "epoch 3; iter: 600; batch classifier loss: 0.809735; batch adversarial loss: 0.602919\n",
      "epoch 4; iter: 0; batch classifier loss: 0.230681; batch adversarial loss: 0.603481\n",
      "epoch 4; iter: 200; batch classifier loss: 0.575697; batch adversarial loss: 0.673347\n",
      "epoch 4; iter: 400; batch classifier loss: 0.369695; batch adversarial loss: 0.631505\n",
      "epoch 4; iter: 600; batch classifier loss: 0.552944; batch adversarial loss: 0.575698\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524960; batch adversarial loss: 0.631723\n",
      "epoch 5; iter: 200; batch classifier loss: 0.377840; batch adversarial loss: 0.647636\n",
      "epoch 5; iter: 400; batch classifier loss: 0.324161; batch adversarial loss: 0.622483\n",
      "epoch 5; iter: 600; batch classifier loss: 0.311255; batch adversarial loss: 0.625388\n",
      "epoch 6; iter: 0; batch classifier loss: 0.429240; batch adversarial loss: 0.636504\n",
      "epoch 6; iter: 200; batch classifier loss: 0.435327; batch adversarial loss: 0.581465\n",
      "epoch 6; iter: 400; batch classifier loss: 0.350289; batch adversarial loss: 0.544338\n",
      "epoch 6; iter: 600; batch classifier loss: 0.320412; batch adversarial loss: 0.626077\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471529; batch adversarial loss: 0.639728\n",
      "epoch 7; iter: 200; batch classifier loss: 0.449905; batch adversarial loss: 0.692383\n",
      "epoch 7; iter: 400; batch classifier loss: 0.539779; batch adversarial loss: 0.661210\n",
      "epoch 7; iter: 600; batch classifier loss: 0.302289; batch adversarial loss: 0.672725\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390211; batch adversarial loss: 0.586228\n",
      "epoch 8; iter: 200; batch classifier loss: 0.345277; batch adversarial loss: 0.581722\n",
      "epoch 8; iter: 400; batch classifier loss: 0.382076; batch adversarial loss: 0.633564\n",
      "epoch 8; iter: 600; batch classifier loss: 0.455516; batch adversarial loss: 0.586283\n",
      "epoch 9; iter: 0; batch classifier loss: 0.267369; batch adversarial loss: 0.635176\n",
      "epoch 9; iter: 200; batch classifier loss: 0.240557; batch adversarial loss: 0.613876\n",
      "epoch 9; iter: 400; batch classifier loss: 0.373186; batch adversarial loss: 0.626357\n",
      "epoch 9; iter: 600; batch classifier loss: 0.323529; batch adversarial loss: 0.636490\n",
      "epoch 0; iter: 0; batch classifier loss: 16.866817; batch adversarial loss: 0.725913\n",
      "epoch 0; iter: 200; batch classifier loss: 26.598351; batch adversarial loss: 0.724644\n",
      "epoch 0; iter: 400; batch classifier loss: 6.256588; batch adversarial loss: 0.666656\n",
      "epoch 0; iter: 600; batch classifier loss: 7.855285; batch adversarial loss: 0.592386\n",
      "epoch 1; iter: 0; batch classifier loss: 2.997996; batch adversarial loss: 0.662261\n",
      "epoch 1; iter: 200; batch classifier loss: 2.421677; batch adversarial loss: 0.605093\n",
      "epoch 1; iter: 400; batch classifier loss: 0.945910; batch adversarial loss: 0.531124\n",
      "epoch 1; iter: 600; batch classifier loss: 1.925144; batch adversarial loss: 0.615825\n",
      "epoch 2; iter: 0; batch classifier loss: 2.995094; batch adversarial loss: 0.697758\n",
      "epoch 2; iter: 200; batch classifier loss: 1.131564; batch adversarial loss: 0.630929\n",
      "epoch 2; iter: 400; batch classifier loss: 0.289795; batch adversarial loss: 0.608773\n",
      "epoch 2; iter: 600; batch classifier loss: 0.816849; batch adversarial loss: 0.683022\n",
      "epoch 3; iter: 0; batch classifier loss: 0.587753; batch adversarial loss: 0.558292\n",
      "epoch 3; iter: 200; batch classifier loss: 2.372876; batch adversarial loss: 0.628062\n",
      "epoch 3; iter: 400; batch classifier loss: 0.386848; batch adversarial loss: 0.547407\n",
      "epoch 3; iter: 600; batch classifier loss: 1.067256; batch adversarial loss: 0.601840\n",
      "epoch 4; iter: 0; batch classifier loss: 0.664698; batch adversarial loss: 0.585771\n",
      "epoch 4; iter: 200; batch classifier loss: 0.488628; batch adversarial loss: 0.667228\n",
      "epoch 4; iter: 400; batch classifier loss: 0.734504; batch adversarial loss: 0.657904\n",
      "epoch 4; iter: 600; batch classifier loss: 0.419784; batch adversarial loss: 0.588929\n",
      "epoch 5; iter: 0; batch classifier loss: 0.610598; batch adversarial loss: 0.668481\n",
      "epoch 5; iter: 200; batch classifier loss: 0.751886; batch adversarial loss: 0.632167\n",
      "epoch 5; iter: 400; batch classifier loss: 0.358868; batch adversarial loss: 0.676388\n",
      "epoch 5; iter: 600; batch classifier loss: 0.430385; batch adversarial loss: 0.691500\n",
      "epoch 6; iter: 0; batch classifier loss: 0.394100; batch adversarial loss: 0.611958\n",
      "epoch 6; iter: 200; batch classifier loss: 0.435553; batch adversarial loss: 0.556104\n",
      "epoch 6; iter: 400; batch classifier loss: 0.388422; batch adversarial loss: 0.561474\n",
      "epoch 6; iter: 600; batch classifier loss: 0.319340; batch adversarial loss: 0.736277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332737; batch adversarial loss: 0.610467\n",
      "epoch 7; iter: 200; batch classifier loss: 0.328101; batch adversarial loss: 0.654298\n",
      "epoch 7; iter: 400; batch classifier loss: 0.497695; batch adversarial loss: 0.586714\n",
      "epoch 7; iter: 600; batch classifier loss: 0.522862; batch adversarial loss: 0.580910\n",
      "epoch 8; iter: 0; batch classifier loss: 0.266122; batch adversarial loss: 0.698370\n",
      "epoch 8; iter: 200; batch classifier loss: 0.450908; batch adversarial loss: 0.621222\n",
      "epoch 8; iter: 400; batch classifier loss: 0.432332; batch adversarial loss: 0.669828\n",
      "epoch 8; iter: 600; batch classifier loss: 0.371755; batch adversarial loss: 0.651142\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311679; batch adversarial loss: 0.696024\n",
      "epoch 9; iter: 200; batch classifier loss: 0.439187; batch adversarial loss: 0.691497\n",
      "epoch 9; iter: 400; batch classifier loss: 0.385824; batch adversarial loss: 0.637770\n",
      "epoch 9; iter: 600; batch classifier loss: 0.287397; batch adversarial loss: 0.600315\n",
      "epoch 0; iter: 0; batch classifier loss: 5.822628; batch adversarial loss: 0.697196\n",
      "epoch 0; iter: 200; batch classifier loss: 4.251689; batch adversarial loss: 0.634205\n",
      "epoch 0; iter: 400; batch classifier loss: 8.259608; batch adversarial loss: 0.657228\n",
      "epoch 0; iter: 600; batch classifier loss: 2.583130; batch adversarial loss: 0.621813\n",
      "epoch 1; iter: 0; batch classifier loss: 4.682671; batch adversarial loss: 0.675701\n",
      "epoch 1; iter: 200; batch classifier loss: 4.330762; batch adversarial loss: 0.583855\n",
      "epoch 1; iter: 400; batch classifier loss: 3.854700; batch adversarial loss: 0.707092\n",
      "epoch 1; iter: 600; batch classifier loss: 2.652690; batch adversarial loss: 0.623064\n",
      "epoch 2; iter: 0; batch classifier loss: 1.257136; batch adversarial loss: 0.701044\n",
      "epoch 2; iter: 200; batch classifier loss: 1.815541; batch adversarial loss: 0.722885\n",
      "epoch 2; iter: 400; batch classifier loss: 2.075414; batch adversarial loss: 0.581134\n",
      "epoch 2; iter: 600; batch classifier loss: 0.517749; batch adversarial loss: 0.603263\n",
      "epoch 3; iter: 0; batch classifier loss: 1.533793; batch adversarial loss: 0.637937\n",
      "epoch 3; iter: 200; batch classifier loss: 0.636022; batch adversarial loss: 0.626703\n",
      "epoch 3; iter: 400; batch classifier loss: 0.463914; batch adversarial loss: 0.624510\n",
      "epoch 3; iter: 600; batch classifier loss: 0.359057; batch adversarial loss: 0.627544\n",
      "epoch 4; iter: 0; batch classifier loss: 1.035574; batch adversarial loss: 0.682557\n",
      "epoch 4; iter: 200; batch classifier loss: 0.683331; batch adversarial loss: 0.636042\n",
      "epoch 4; iter: 400; batch classifier loss: 0.387044; batch adversarial loss: 0.648064\n",
      "epoch 4; iter: 600; batch classifier loss: 0.592201; batch adversarial loss: 0.573445\n",
      "epoch 5; iter: 0; batch classifier loss: 0.305159; batch adversarial loss: 0.603147\n",
      "epoch 5; iter: 200; batch classifier loss: 0.312980; batch adversarial loss: 0.547521\n",
      "epoch 5; iter: 400; batch classifier loss: 0.446835; batch adversarial loss: 0.690979\n",
      "epoch 5; iter: 600; batch classifier loss: 0.460226; batch adversarial loss: 0.613323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583860; batch adversarial loss: 0.630453\n",
      "epoch 6; iter: 200; batch classifier loss: 0.331900; batch adversarial loss: 0.609573\n",
      "epoch 6; iter: 400; batch classifier loss: 0.368360; batch adversarial loss: 0.602794\n",
      "epoch 6; iter: 600; batch classifier loss: 0.327641; batch adversarial loss: 0.652434\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385472; batch adversarial loss: 0.643610\n",
      "epoch 7; iter: 200; batch classifier loss: 0.460015; batch adversarial loss: 0.571591\n",
      "epoch 7; iter: 400; batch classifier loss: 0.412892; batch adversarial loss: 0.641136\n",
      "epoch 7; iter: 600; batch classifier loss: 0.342549; batch adversarial loss: 0.558082\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453998; batch adversarial loss: 0.655367\n",
      "epoch 8; iter: 200; batch classifier loss: 0.538147; batch adversarial loss: 0.691459\n",
      "epoch 8; iter: 400; batch classifier loss: 0.421091; batch adversarial loss: 0.610656\n",
      "epoch 8; iter: 600; batch classifier loss: 0.221329; batch adversarial loss: 0.685177\n",
      "epoch 9; iter: 0; batch classifier loss: 0.405860; batch adversarial loss: 0.641486\n",
      "epoch 9; iter: 200; batch classifier loss: 0.398077; batch adversarial loss: 0.635458\n",
      "epoch 9; iter: 400; batch classifier loss: 0.373694; batch adversarial loss: 0.606190\n",
      "epoch 9; iter: 600; batch classifier loss: 0.435286; batch adversarial loss: 0.624454\n",
      "epoch 0; iter: 0; batch classifier loss: 1.918144; batch adversarial loss: 0.681891\n",
      "epoch 0; iter: 200; batch classifier loss: 1.923386; batch adversarial loss: 0.852734\n",
      "epoch 0; iter: 400; batch classifier loss: 8.446803; batch adversarial loss: 0.771028\n",
      "epoch 0; iter: 600; batch classifier loss: 0.816586; batch adversarial loss: 0.682139\n",
      "epoch 1; iter: 0; batch classifier loss: 6.476830; batch adversarial loss: 0.677055\n",
      "epoch 1; iter: 200; batch classifier loss: 0.721325; batch adversarial loss: 0.628804\n",
      "epoch 1; iter: 400; batch classifier loss: 3.989705; batch adversarial loss: 0.638169\n",
      "epoch 1; iter: 600; batch classifier loss: 3.404044; batch adversarial loss: 0.641566\n",
      "epoch 2; iter: 0; batch classifier loss: 0.981118; batch adversarial loss: 0.574833\n",
      "epoch 2; iter: 200; batch classifier loss: 1.902495; batch adversarial loss: 0.689343\n",
      "epoch 2; iter: 400; batch classifier loss: 7.937874; batch adversarial loss: 0.591627\n",
      "epoch 2; iter: 600; batch classifier loss: 1.698356; batch adversarial loss: 0.575028\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602165; batch adversarial loss: 0.683826\n",
      "epoch 3; iter: 200; batch classifier loss: 2.147920; batch adversarial loss: 0.714280\n",
      "epoch 3; iter: 400; batch classifier loss: 0.535461; batch adversarial loss: 0.604092\n",
      "epoch 3; iter: 600; batch classifier loss: 0.636343; batch adversarial loss: 0.631269\n",
      "epoch 4; iter: 0; batch classifier loss: 0.288321; batch adversarial loss: 0.640402\n",
      "epoch 4; iter: 200; batch classifier loss: 0.428218; batch adversarial loss: 0.631479\n",
      "epoch 4; iter: 400; batch classifier loss: 0.408172; batch adversarial loss: 0.618473\n",
      "epoch 4; iter: 600; batch classifier loss: 0.603207; batch adversarial loss: 0.619232\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651848; batch adversarial loss: 0.569447\n",
      "epoch 5; iter: 200; batch classifier loss: 0.384811; batch adversarial loss: 0.591805\n",
      "epoch 5; iter: 400; batch classifier loss: 0.401955; batch adversarial loss: 0.638458\n",
      "epoch 5; iter: 600; batch classifier loss: 0.568128; batch adversarial loss: 0.643884\n",
      "epoch 6; iter: 0; batch classifier loss: 0.294256; batch adversarial loss: 0.622105\n",
      "epoch 6; iter: 200; batch classifier loss: 0.445322; batch adversarial loss: 0.534720\n",
      "epoch 6; iter: 400; batch classifier loss: 0.486971; batch adversarial loss: 0.660057\n",
      "epoch 6; iter: 600; batch classifier loss: 0.392333; batch adversarial loss: 0.581804\n",
      "epoch 7; iter: 0; batch classifier loss: 0.367759; batch adversarial loss: 0.726038\n",
      "epoch 7; iter: 200; batch classifier loss: 0.447101; batch adversarial loss: 0.590439\n",
      "epoch 7; iter: 400; batch classifier loss: 0.476119; batch adversarial loss: 0.616394\n",
      "epoch 7; iter: 600; batch classifier loss: 0.419290; batch adversarial loss: 0.656699\n",
      "epoch 8; iter: 0; batch classifier loss: 0.612532; batch adversarial loss: 0.619966\n",
      "epoch 8; iter: 200; batch classifier loss: 0.412350; batch adversarial loss: 0.593258\n",
      "epoch 8; iter: 400; batch classifier loss: 0.276461; batch adversarial loss: 0.579421\n",
      "epoch 8; iter: 600; batch classifier loss: 0.524227; batch adversarial loss: 0.646370\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347663; batch adversarial loss: 0.597221\n",
      "epoch 9; iter: 200; batch classifier loss: 0.228369; batch adversarial loss: 0.716423\n",
      "epoch 9; iter: 400; batch classifier loss: 0.340452; batch adversarial loss: 0.592985\n",
      "epoch 9; iter: 600; batch classifier loss: 0.238553; batch adversarial loss: 0.615551\n",
      "epoch 0; iter: 0; batch classifier loss: 26.638256; batch adversarial loss: 0.693242\n",
      "epoch 0; iter: 200; batch classifier loss: 3.935902; batch adversarial loss: 0.663063\n",
      "epoch 0; iter: 400; batch classifier loss: 8.335955; batch adversarial loss: 0.635481\n",
      "epoch 0; iter: 600; batch classifier loss: 11.634476; batch adversarial loss: 0.670295\n",
      "epoch 1; iter: 0; batch classifier loss: 8.609191; batch adversarial loss: 0.594342\n",
      "epoch 1; iter: 200; batch classifier loss: 3.223136; batch adversarial loss: 0.620783\n",
      "epoch 1; iter: 400; batch classifier loss: 7.575892; batch adversarial loss: 0.680522\n",
      "epoch 1; iter: 600; batch classifier loss: 3.506618; batch adversarial loss: 0.588261\n",
      "epoch 2; iter: 0; batch classifier loss: 6.240894; batch adversarial loss: 0.588525\n",
      "epoch 2; iter: 200; batch classifier loss: 1.018998; batch adversarial loss: 0.621820\n",
      "epoch 2; iter: 400; batch classifier loss: 2.459913; batch adversarial loss: 0.613764\n",
      "epoch 2; iter: 600; batch classifier loss: 4.027711; batch adversarial loss: 0.574696\n",
      "epoch 3; iter: 0; batch classifier loss: 0.560870; batch adversarial loss: 0.707269\n",
      "epoch 3; iter: 200; batch classifier loss: 0.651054; batch adversarial loss: 0.575282\n",
      "epoch 3; iter: 400; batch classifier loss: 0.973041; batch adversarial loss: 0.647428\n",
      "epoch 3; iter: 600; batch classifier loss: 0.316424; batch adversarial loss: 0.754710\n",
      "epoch 4; iter: 0; batch classifier loss: 0.750459; batch adversarial loss: 0.650563\n",
      "epoch 4; iter: 200; batch classifier loss: 1.216693; batch adversarial loss: 0.558814\n",
      "epoch 4; iter: 400; batch classifier loss: 0.413269; batch adversarial loss: 0.576376\n",
      "epoch 4; iter: 600; batch classifier loss: 0.870990; batch adversarial loss: 0.587376\n",
      "epoch 5; iter: 0; batch classifier loss: 0.281406; batch adversarial loss: 0.658240\n",
      "epoch 5; iter: 200; batch classifier loss: 0.397964; batch adversarial loss: 0.587982\n",
      "epoch 5; iter: 400; batch classifier loss: 0.325548; batch adversarial loss: 0.608622\n",
      "epoch 5; iter: 600; batch classifier loss: 0.336532; batch adversarial loss: 0.604228\n",
      "epoch 6; iter: 0; batch classifier loss: 0.488330; batch adversarial loss: 0.541638\n",
      "epoch 6; iter: 200; batch classifier loss: 0.375359; batch adversarial loss: 0.660387\n",
      "epoch 6; iter: 400; batch classifier loss: 0.315169; batch adversarial loss: 0.688350\n",
      "epoch 6; iter: 600; batch classifier loss: 0.325124; batch adversarial loss: 0.619447\n",
      "epoch 7; iter: 0; batch classifier loss: 0.476616; batch adversarial loss: 0.602831\n",
      "epoch 7; iter: 200; batch classifier loss: 0.301883; batch adversarial loss: 0.659295\n",
      "epoch 7; iter: 400; batch classifier loss: 0.304124; batch adversarial loss: 0.682597\n",
      "epoch 7; iter: 600; batch classifier loss: 0.270651; batch adversarial loss: 0.653293\n",
      "epoch 8; iter: 0; batch classifier loss: 0.348595; batch adversarial loss: 0.620125\n",
      "epoch 8; iter: 200; batch classifier loss: 0.297331; batch adversarial loss: 0.670720\n",
      "epoch 8; iter: 400; batch classifier loss: 0.489754; batch adversarial loss: 0.629610\n",
      "epoch 8; iter: 600; batch classifier loss: 0.512718; batch adversarial loss: 0.626161\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361287; batch adversarial loss: 0.626915\n",
      "epoch 9; iter: 200; batch classifier loss: 0.470514; batch adversarial loss: 0.653839\n",
      "epoch 9; iter: 400; batch classifier loss: 0.402442; batch adversarial loss: 0.652033\n",
      "epoch 9; iter: 600; batch classifier loss: 0.305133; batch adversarial loss: 0.603006\n",
      "epoch 0; iter: 0; batch classifier loss: 5.777101; batch adversarial loss: 0.657145\n",
      "epoch 0; iter: 200; batch classifier loss: 5.746096; batch adversarial loss: 0.690237\n",
      "epoch 0; iter: 400; batch classifier loss: 1.784078; batch adversarial loss: 0.638581\n",
      "epoch 0; iter: 600; batch classifier loss: 11.157231; batch adversarial loss: 0.668247\n",
      "epoch 1; iter: 0; batch classifier loss: 1.310888; batch adversarial loss: 0.620063\n",
      "epoch 1; iter: 200; batch classifier loss: 2.019778; batch adversarial loss: 0.599989\n",
      "epoch 1; iter: 400; batch classifier loss: 2.359733; batch adversarial loss: 0.611475\n",
      "epoch 1; iter: 600; batch classifier loss: 3.077788; batch adversarial loss: 0.665997\n",
      "epoch 2; iter: 0; batch classifier loss: 1.444980; batch adversarial loss: 0.583778\n",
      "epoch 2; iter: 200; batch classifier loss: 0.459206; batch adversarial loss: 0.669948\n",
      "epoch 2; iter: 400; batch classifier loss: 0.374760; batch adversarial loss: 0.629112\n",
      "epoch 2; iter: 600; batch classifier loss: 0.428220; batch adversarial loss: 0.603633\n",
      "epoch 3; iter: 0; batch classifier loss: 2.039576; batch adversarial loss: 0.641663\n",
      "epoch 3; iter: 200; batch classifier loss: 1.167111; batch adversarial loss: 0.714688\n",
      "epoch 3; iter: 400; batch classifier loss: 0.440657; batch adversarial loss: 0.598366\n",
      "epoch 3; iter: 600; batch classifier loss: 3.140300; batch adversarial loss: 0.616177\n",
      "epoch 4; iter: 0; batch classifier loss: 0.411209; batch adversarial loss: 0.632384\n",
      "epoch 4; iter: 200; batch classifier loss: 0.394199; batch adversarial loss: 0.620002\n",
      "epoch 4; iter: 400; batch classifier loss: 0.476894; batch adversarial loss: 0.700078\n",
      "epoch 4; iter: 600; batch classifier loss: 0.370582; batch adversarial loss: 0.647873\n",
      "epoch 5; iter: 0; batch classifier loss: 0.668707; batch adversarial loss: 0.640507\n",
      "epoch 5; iter: 200; batch classifier loss: 0.361054; batch adversarial loss: 0.686037\n",
      "epoch 5; iter: 400; batch classifier loss: 0.426589; batch adversarial loss: 0.609251\n",
      "epoch 5; iter: 600; batch classifier loss: 0.387347; batch adversarial loss: 0.663821\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322133; batch adversarial loss: 0.612002\n",
      "epoch 6; iter: 200; batch classifier loss: 0.449935; batch adversarial loss: 0.557411\n",
      "epoch 6; iter: 400; batch classifier loss: 0.457092; batch adversarial loss: 0.614993\n",
      "epoch 6; iter: 600; batch classifier loss: 0.565997; batch adversarial loss: 0.602842\n",
      "epoch 7; iter: 0; batch classifier loss: 0.590598; batch adversarial loss: 0.653004\n",
      "epoch 7; iter: 200; batch classifier loss: 0.476143; batch adversarial loss: 0.530130\n",
      "epoch 7; iter: 400; batch classifier loss: 0.317679; batch adversarial loss: 0.614956\n",
      "epoch 7; iter: 600; batch classifier loss: 0.374607; batch adversarial loss: 0.619864\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421771; batch adversarial loss: 0.577543\n",
      "epoch 8; iter: 200; batch classifier loss: 0.306679; batch adversarial loss: 0.629487\n",
      "epoch 8; iter: 400; batch classifier loss: 0.369824; batch adversarial loss: 0.631234\n",
      "epoch 8; iter: 600; batch classifier loss: 0.323648; batch adversarial loss: 0.620330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549688; batch adversarial loss: 0.651235\n",
      "epoch 9; iter: 200; batch classifier loss: 0.245328; batch adversarial loss: 0.561344\n",
      "epoch 9; iter: 400; batch classifier loss: 0.323950; batch adversarial loss: 0.593307\n",
      "epoch 9; iter: 600; batch classifier loss: 0.313482; batch adversarial loss: 0.646626\n",
      "epoch 0; iter: 0; batch classifier loss: 29.688267; batch adversarial loss: 0.673484\n",
      "epoch 0; iter: 200; batch classifier loss: 9.463080; batch adversarial loss: 0.622137\n",
      "epoch 0; iter: 400; batch classifier loss: 10.602682; batch adversarial loss: 0.706347\n",
      "epoch 0; iter: 600; batch classifier loss: 2.175245; batch adversarial loss: 0.576380\n",
      "epoch 1; iter: 0; batch classifier loss: 7.274592; batch adversarial loss: 0.660320\n",
      "epoch 1; iter: 200; batch classifier loss: 0.720216; batch adversarial loss: 0.707367\n",
      "epoch 1; iter: 400; batch classifier loss: 1.463689; batch adversarial loss: 0.694114\n",
      "epoch 1; iter: 600; batch classifier loss: 1.347455; batch adversarial loss: 0.697596\n",
      "epoch 2; iter: 0; batch classifier loss: 23.133522; batch adversarial loss: 0.644892\n",
      "epoch 2; iter: 200; batch classifier loss: 1.869883; batch adversarial loss: 0.606916\n",
      "epoch 2; iter: 400; batch classifier loss: 0.383355; batch adversarial loss: 0.588800\n",
      "epoch 2; iter: 600; batch classifier loss: 2.681756; batch adversarial loss: 0.604526\n",
      "epoch 3; iter: 0; batch classifier loss: 0.974155; batch adversarial loss: 0.590071\n",
      "epoch 3; iter: 200; batch classifier loss: 1.660857; batch adversarial loss: 0.602966\n",
      "epoch 3; iter: 400; batch classifier loss: 0.366087; batch adversarial loss: 0.692970\n",
      "epoch 3; iter: 600; batch classifier loss: 0.512030; batch adversarial loss: 0.581083\n",
      "epoch 4; iter: 0; batch classifier loss: 0.500783; batch adversarial loss: 0.590693\n",
      "epoch 4; iter: 200; batch classifier loss: 0.703428; batch adversarial loss: 0.647700\n",
      "epoch 4; iter: 400; batch classifier loss: 0.390191; batch adversarial loss: 0.659547\n",
      "epoch 4; iter: 600; batch classifier loss: 0.425656; batch adversarial loss: 0.632527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.264943; batch adversarial loss: 0.631460\n",
      "epoch 5; iter: 200; batch classifier loss: 0.391121; batch adversarial loss: 0.630459\n",
      "epoch 5; iter: 400; batch classifier loss: 0.342866; batch adversarial loss: 0.686867\n",
      "epoch 5; iter: 600; batch classifier loss: 0.386803; batch adversarial loss: 0.694461\n",
      "epoch 6; iter: 0; batch classifier loss: 0.581792; batch adversarial loss: 0.680375\n",
      "epoch 6; iter: 200; batch classifier loss: 0.471524; batch adversarial loss: 0.687151\n",
      "epoch 6; iter: 400; batch classifier loss: 0.996623; batch adversarial loss: 0.544014\n",
      "epoch 6; iter: 600; batch classifier loss: 0.477775; batch adversarial loss: 0.615368\n",
      "epoch 7; iter: 0; batch classifier loss: 1.100365; batch adversarial loss: 0.704282\n",
      "epoch 7; iter: 200; batch classifier loss: 0.387724; batch adversarial loss: 0.624610\n",
      "epoch 7; iter: 400; batch classifier loss: 0.393457; batch adversarial loss: 0.626876\n",
      "epoch 7; iter: 600; batch classifier loss: 0.480989; batch adversarial loss: 0.583741\n",
      "epoch 8; iter: 0; batch classifier loss: 0.348022; batch adversarial loss: 0.639367\n",
      "epoch 8; iter: 200; batch classifier loss: 0.402844; batch adversarial loss: 0.680970\n",
      "epoch 8; iter: 400; batch classifier loss: 0.440399; batch adversarial loss: 0.581171\n",
      "epoch 8; iter: 600; batch classifier loss: 0.277203; batch adversarial loss: 0.549133\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367081; batch adversarial loss: 0.596594\n",
      "epoch 9; iter: 200; batch classifier loss: 0.613359; batch adversarial loss: 0.599650\n",
      "epoch 9; iter: 400; batch classifier loss: 0.236729; batch adversarial loss: 0.625248\n",
      "epoch 9; iter: 600; batch classifier loss: 0.379289; batch adversarial loss: 0.577105\n",
      "epoch 0; iter: 0; batch classifier loss: 70.142822; batch adversarial loss: 0.688795\n",
      "epoch 0; iter: 200; batch classifier loss: 6.750278; batch adversarial loss: 0.653540\n",
      "epoch 0; iter: 400; batch classifier loss: 4.069534; batch adversarial loss: 0.640869\n",
      "epoch 0; iter: 600; batch classifier loss: 11.436566; batch adversarial loss: 0.633243\n",
      "epoch 1; iter: 0; batch classifier loss: 2.428610; batch adversarial loss: 0.673465\n",
      "epoch 1; iter: 200; batch classifier loss: 2.290790; batch adversarial loss: 0.687140\n",
      "epoch 1; iter: 400; batch classifier loss: 0.550110; batch adversarial loss: 0.640250\n",
      "epoch 1; iter: 600; batch classifier loss: 1.142679; batch adversarial loss: 0.572461\n",
      "epoch 2; iter: 0; batch classifier loss: 5.404198; batch adversarial loss: 0.678157\n",
      "epoch 2; iter: 200; batch classifier loss: 0.458933; batch adversarial loss: 0.702113\n",
      "epoch 2; iter: 400; batch classifier loss: 4.518238; batch adversarial loss: 0.630154\n",
      "epoch 2; iter: 600; batch classifier loss: 0.748630; batch adversarial loss: 0.582415\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641697; batch adversarial loss: 0.670539\n",
      "epoch 3; iter: 200; batch classifier loss: 1.829592; batch adversarial loss: 0.619419\n",
      "epoch 3; iter: 400; batch classifier loss: 1.811800; batch adversarial loss: 0.630825\n",
      "epoch 3; iter: 600; batch classifier loss: 0.574160; batch adversarial loss: 0.645346\n",
      "epoch 4; iter: 0; batch classifier loss: 0.940904; batch adversarial loss: 0.587015\n",
      "epoch 4; iter: 200; batch classifier loss: 1.074088; batch adversarial loss: 0.632291\n",
      "epoch 4; iter: 400; batch classifier loss: 0.428640; batch adversarial loss: 0.583686\n",
      "epoch 4; iter: 600; batch classifier loss: 0.409520; batch adversarial loss: 0.578591\n",
      "epoch 5; iter: 0; batch classifier loss: 0.298917; batch adversarial loss: 0.609560\n",
      "epoch 5; iter: 200; batch classifier loss: 0.460519; batch adversarial loss: 0.593406\n",
      "epoch 5; iter: 400; batch classifier loss: 0.798163; batch adversarial loss: 0.700106\n",
      "epoch 5; iter: 600; batch classifier loss: 0.595843; batch adversarial loss: 0.616787\n",
      "epoch 6; iter: 0; batch classifier loss: 0.305840; batch adversarial loss: 0.686732\n",
      "epoch 6; iter: 200; batch classifier loss: 0.600926; batch adversarial loss: 0.670195\n",
      "epoch 6; iter: 400; batch classifier loss: 0.381666; batch adversarial loss: 0.731456\n",
      "epoch 6; iter: 600; batch classifier loss: 1.684457; batch adversarial loss: 0.720012\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342924; batch adversarial loss: 0.651084\n",
      "epoch 7; iter: 200; batch classifier loss: 0.311116; batch adversarial loss: 0.626625\n",
      "epoch 7; iter: 400; batch classifier loss: 0.406759; batch adversarial loss: 0.611678\n",
      "epoch 7; iter: 600; batch classifier loss: 0.445742; batch adversarial loss: 0.688350\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451961; batch adversarial loss: 0.576713\n",
      "epoch 8; iter: 200; batch classifier loss: 0.343351; batch adversarial loss: 0.691786\n",
      "epoch 8; iter: 400; batch classifier loss: 0.495909; batch adversarial loss: 0.700136\n",
      "epoch 8; iter: 600; batch classifier loss: 0.298211; batch adversarial loss: 0.613217\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462643; batch adversarial loss: 0.642723\n",
      "epoch 9; iter: 200; batch classifier loss: 0.403622; batch adversarial loss: 0.636992\n",
      "epoch 9; iter: 400; batch classifier loss: 0.430381; batch adversarial loss: 0.600720\n",
      "epoch 9; iter: 600; batch classifier loss: 0.667475; batch adversarial loss: 0.551632\n",
      "epoch 0; iter: 0; batch classifier loss: 18.181087; batch adversarial loss: 0.666162\n",
      "epoch 0; iter: 200; batch classifier loss: 3.922832; batch adversarial loss: 0.690639\n",
      "epoch 0; iter: 400; batch classifier loss: 13.069283; batch adversarial loss: 0.664177\n",
      "epoch 0; iter: 600; batch classifier loss: 0.619785; batch adversarial loss: 0.689912\n",
      "epoch 1; iter: 0; batch classifier loss: 3.823034; batch adversarial loss: 0.619328\n",
      "epoch 1; iter: 200; batch classifier loss: 4.258724; batch adversarial loss: 0.707406\n",
      "epoch 1; iter: 400; batch classifier loss: 1.009939; batch adversarial loss: 0.639565\n",
      "epoch 1; iter: 600; batch classifier loss: 1.192082; batch adversarial loss: 0.588014\n",
      "epoch 2; iter: 0; batch classifier loss: 4.923417; batch adversarial loss: 0.635094\n",
      "epoch 2; iter: 200; batch classifier loss: 0.281669; batch adversarial loss: 0.609697\n",
      "epoch 2; iter: 400; batch classifier loss: 0.396033; batch adversarial loss: 0.584014\n",
      "epoch 2; iter: 600; batch classifier loss: 1.727756; batch adversarial loss: 0.579434\n",
      "epoch 3; iter: 0; batch classifier loss: 0.416969; batch adversarial loss: 0.626805\n",
      "epoch 3; iter: 200; batch classifier loss: 0.770754; batch adversarial loss: 0.635747\n",
      "epoch 3; iter: 400; batch classifier loss: 2.032826; batch adversarial loss: 0.596870\n",
      "epoch 3; iter: 600; batch classifier loss: 0.485491; batch adversarial loss: 0.636348\n",
      "epoch 4; iter: 0; batch classifier loss: 0.430685; batch adversarial loss: 0.609226\n",
      "epoch 4; iter: 200; batch classifier loss: 0.774235; batch adversarial loss: 0.569806\n",
      "epoch 4; iter: 400; batch classifier loss: 0.695972; batch adversarial loss: 0.688472\n",
      "epoch 4; iter: 600; batch classifier loss: 0.578110; batch adversarial loss: 0.591928\n",
      "epoch 5; iter: 0; batch classifier loss: 0.304483; batch adversarial loss: 0.635299\n",
      "epoch 5; iter: 200; batch classifier loss: 0.328494; batch adversarial loss: 0.609551\n",
      "epoch 5; iter: 400; batch classifier loss: 0.455172; batch adversarial loss: 0.571365\n",
      "epoch 5; iter: 600; batch classifier loss: 0.437252; batch adversarial loss: 0.692416\n",
      "epoch 6; iter: 0; batch classifier loss: 0.293178; batch adversarial loss: 0.678461\n",
      "epoch 6; iter: 200; batch classifier loss: 0.225304; batch adversarial loss: 0.572431\n",
      "epoch 6; iter: 400; batch classifier loss: 0.457127; batch adversarial loss: 0.656943\n",
      "epoch 6; iter: 600; batch classifier loss: 0.470470; batch adversarial loss: 0.604940\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411132; batch adversarial loss: 0.571752\n",
      "epoch 7; iter: 200; batch classifier loss: 0.467034; batch adversarial loss: 0.598167\n",
      "epoch 7; iter: 400; batch classifier loss: 0.328322; batch adversarial loss: 0.651602\n",
      "epoch 7; iter: 600; batch classifier loss: 0.486628; batch adversarial loss: 0.648416\n",
      "epoch 8; iter: 0; batch classifier loss: 0.358681; batch adversarial loss: 0.613171\n",
      "epoch 8; iter: 200; batch classifier loss: 0.423314; batch adversarial loss: 0.629247\n",
      "epoch 8; iter: 400; batch classifier loss: 0.223927; batch adversarial loss: 0.624318\n",
      "epoch 8; iter: 600; batch classifier loss: 0.319940; batch adversarial loss: 0.552762\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549103; batch adversarial loss: 0.618031\n",
      "epoch 9; iter: 200; batch classifier loss: 0.447220; batch adversarial loss: 0.642958\n",
      "epoch 9; iter: 400; batch classifier loss: 0.291917; batch adversarial loss: 0.570165\n",
      "epoch 9; iter: 600; batch classifier loss: 0.414431; batch adversarial loss: 0.642473\n",
      "epoch 0; iter: 0; batch classifier loss: 8.152227; batch adversarial loss: 0.696483\n",
      "epoch 0; iter: 200; batch classifier loss: 28.046289; batch adversarial loss: 0.687103\n",
      "epoch 0; iter: 400; batch classifier loss: 1.236772; batch adversarial loss: 0.632842\n",
      "epoch 0; iter: 600; batch classifier loss: 10.625962; batch adversarial loss: 0.627761\n",
      "epoch 1; iter: 0; batch classifier loss: 4.450437; batch adversarial loss: 0.589831\n",
      "epoch 1; iter: 200; batch classifier loss: 5.818359; batch adversarial loss: 0.595977\n",
      "epoch 1; iter: 400; batch classifier loss: 2.912077; batch adversarial loss: 0.661826\n",
      "epoch 1; iter: 600; batch classifier loss: 0.364767; batch adversarial loss: 0.666952\n",
      "epoch 2; iter: 0; batch classifier loss: 1.414154; batch adversarial loss: 0.613111\n",
      "epoch 2; iter: 200; batch classifier loss: 1.467466; batch adversarial loss: 0.568171\n",
      "epoch 2; iter: 400; batch classifier loss: 0.933059; batch adversarial loss: 0.677112\n",
      "epoch 2; iter: 600; batch classifier loss: 0.549091; batch adversarial loss: 0.611113\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540053; batch adversarial loss: 0.629861\n",
      "epoch 3; iter: 200; batch classifier loss: 0.470397; batch adversarial loss: 0.620382\n",
      "epoch 3; iter: 400; batch classifier loss: 0.666137; batch adversarial loss: 0.617327\n",
      "epoch 3; iter: 600; batch classifier loss: 0.562637; batch adversarial loss: 0.646980\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469546; batch adversarial loss: 0.606833\n",
      "epoch 4; iter: 200; batch classifier loss: 0.396204; batch adversarial loss: 0.566639\n",
      "epoch 4; iter: 400; batch classifier loss: 0.226965; batch adversarial loss: 0.600485\n",
      "epoch 4; iter: 600; batch classifier loss: 0.315256; batch adversarial loss: 0.634553\n",
      "epoch 5; iter: 0; batch classifier loss: 0.334457; batch adversarial loss: 0.670285\n",
      "epoch 5; iter: 200; batch classifier loss: 0.354987; batch adversarial loss: 0.579301\n",
      "epoch 5; iter: 400; batch classifier loss: 0.592079; batch adversarial loss: 0.599415\n",
      "epoch 5; iter: 600; batch classifier loss: 0.296064; batch adversarial loss: 0.626082\n",
      "epoch 6; iter: 0; batch classifier loss: 0.362344; batch adversarial loss: 0.582289\n",
      "epoch 6; iter: 200; batch classifier loss: 0.306127; batch adversarial loss: 0.696599\n",
      "epoch 6; iter: 400; batch classifier loss: 0.410561; batch adversarial loss: 0.628243\n",
      "epoch 6; iter: 600; batch classifier loss: 0.296487; batch adversarial loss: 0.627341\n",
      "epoch 7; iter: 0; batch classifier loss: 0.375083; batch adversarial loss: 0.705365\n",
      "epoch 7; iter: 200; batch classifier loss: 0.362440; batch adversarial loss: 0.635661\n",
      "epoch 7; iter: 400; batch classifier loss: 0.580489; batch adversarial loss: 0.603179\n",
      "epoch 7; iter: 600; batch classifier loss: 0.325383; batch adversarial loss: 0.589295\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359041; batch adversarial loss: 0.616986\n",
      "epoch 8; iter: 200; batch classifier loss: 0.366248; batch adversarial loss: 0.620801\n",
      "epoch 8; iter: 400; batch classifier loss: 0.328184; batch adversarial loss: 0.694777\n",
      "epoch 8; iter: 600; batch classifier loss: 0.467577; batch adversarial loss: 0.596092\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384566; batch adversarial loss: 0.662810\n",
      "epoch 9; iter: 200; batch classifier loss: 0.348041; batch adversarial loss: 0.635790\n",
      "epoch 9; iter: 400; batch classifier loss: 0.266323; batch adversarial loss: 0.675769\n",
      "epoch 9; iter: 600; batch classifier loss: 0.213441; batch adversarial loss: 0.658309\n",
      "epoch 0; iter: 0; batch classifier loss: 5.976104; batch adversarial loss: 0.709803\n",
      "epoch 0; iter: 200; batch classifier loss: 16.961506; batch adversarial loss: 0.679719\n",
      "epoch 0; iter: 400; batch classifier loss: 3.496746; batch adversarial loss: 0.623741\n",
      "epoch 0; iter: 600; batch classifier loss: 3.752429; batch adversarial loss: 0.649462\n",
      "epoch 1; iter: 0; batch classifier loss: 3.812741; batch adversarial loss: 0.628009\n",
      "epoch 1; iter: 200; batch classifier loss: 0.937881; batch adversarial loss: 0.648252\n",
      "epoch 1; iter: 400; batch classifier loss: 0.721351; batch adversarial loss: 0.618903\n",
      "epoch 1; iter: 600; batch classifier loss: 0.522743; batch adversarial loss: 0.691248\n",
      "epoch 2; iter: 0; batch classifier loss: 1.466378; batch adversarial loss: 0.670140\n",
      "epoch 2; iter: 200; batch classifier loss: 0.799003; batch adversarial loss: 0.595359\n",
      "epoch 2; iter: 400; batch classifier loss: 1.204706; batch adversarial loss: 0.585609\n",
      "epoch 2; iter: 600; batch classifier loss: 1.035115; batch adversarial loss: 0.683920\n",
      "epoch 3; iter: 0; batch classifier loss: 1.145462; batch adversarial loss: 0.690629\n",
      "epoch 3; iter: 200; batch classifier loss: 0.442006; batch adversarial loss: 0.626817\n",
      "epoch 3; iter: 400; batch classifier loss: 0.814130; batch adversarial loss: 0.592958\n",
      "epoch 3; iter: 600; batch classifier loss: 0.328975; batch adversarial loss: 0.655303\n",
      "epoch 4; iter: 0; batch classifier loss: 0.662007; batch adversarial loss: 0.576520\n",
      "epoch 4; iter: 200; batch classifier loss: 1.708625; batch adversarial loss: 0.622464\n",
      "epoch 4; iter: 400; batch classifier loss: 0.555257; batch adversarial loss: 0.688657\n",
      "epoch 4; iter: 600; batch classifier loss: 0.423838; batch adversarial loss: 0.648390\n",
      "epoch 5; iter: 0; batch classifier loss: 1.081583; batch adversarial loss: 0.662035\n",
      "epoch 5; iter: 200; batch classifier loss: 0.641574; batch adversarial loss: 0.612083\n",
      "epoch 5; iter: 400; batch classifier loss: 0.488625; batch adversarial loss: 0.617741\n",
      "epoch 5; iter: 600; batch classifier loss: 0.438319; batch adversarial loss: 0.607959\n",
      "epoch 6; iter: 0; batch classifier loss: 0.371408; batch adversarial loss: 0.586552\n",
      "epoch 6; iter: 200; batch classifier loss: 0.470475; batch adversarial loss: 0.562209\n",
      "epoch 6; iter: 400; batch classifier loss: 0.510278; batch adversarial loss: 0.596931\n",
      "epoch 6; iter: 600; batch classifier loss: 0.348535; batch adversarial loss: 0.638420\n",
      "epoch 7; iter: 0; batch classifier loss: 0.386437; batch adversarial loss: 0.600477\n",
      "epoch 7; iter: 200; batch classifier loss: 0.546498; batch adversarial loss: 0.624320\n",
      "epoch 7; iter: 400; batch classifier loss: 0.344010; batch adversarial loss: 0.608367\n",
      "epoch 7; iter: 600; batch classifier loss: 0.425050; batch adversarial loss: 0.675536\n",
      "epoch 8; iter: 0; batch classifier loss: 0.687676; batch adversarial loss: 0.634232\n",
      "epoch 8; iter: 200; batch classifier loss: 0.470028; batch adversarial loss: 0.618221\n",
      "epoch 8; iter: 400; batch classifier loss: 0.458820; batch adversarial loss: 0.624773\n",
      "epoch 8; iter: 600; batch classifier loss: 0.482269; batch adversarial loss: 0.610564\n",
      "epoch 9; iter: 0; batch classifier loss: 1.027372; batch adversarial loss: 0.585037\n",
      "epoch 9; iter: 200; batch classifier loss: 0.530498; batch adversarial loss: 0.612301\n",
      "epoch 9; iter: 400; batch classifier loss: 0.424033; batch adversarial loss: 0.615703\n",
      "epoch 9; iter: 600; batch classifier loss: 0.522518; batch adversarial loss: 0.651573\n",
      "epoch 0; iter: 0; batch classifier loss: 8.001112; batch adversarial loss: 0.634771\n",
      "epoch 0; iter: 200; batch classifier loss: 10.243369; batch adversarial loss: 0.593118\n",
      "epoch 0; iter: 400; batch classifier loss: 3.070457; batch adversarial loss: 0.624984\n",
      "epoch 0; iter: 600; batch classifier loss: 6.794067; batch adversarial loss: 0.657489\n",
      "epoch 1; iter: 0; batch classifier loss: 5.600574; batch adversarial loss: 0.649459\n",
      "epoch 1; iter: 200; batch classifier loss: 0.580913; batch adversarial loss: 0.581014\n",
      "epoch 1; iter: 400; batch classifier loss: 0.692270; batch adversarial loss: 0.685233\n",
      "epoch 1; iter: 600; batch classifier loss: 1.635135; batch adversarial loss: 0.614428\n",
      "epoch 2; iter: 0; batch classifier loss: 0.775985; batch adversarial loss: 0.608166\n",
      "epoch 2; iter: 200; batch classifier loss: 3.555596; batch adversarial loss: 0.664744\n",
      "epoch 2; iter: 400; batch classifier loss: 1.103458; batch adversarial loss: 0.682250\n",
      "epoch 2; iter: 600; batch classifier loss: 0.377602; batch adversarial loss: 0.585600\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572684; batch adversarial loss: 0.671600\n",
      "epoch 3; iter: 200; batch classifier loss: 1.590654; batch adversarial loss: 0.634276\n",
      "epoch 3; iter: 400; batch classifier loss: 0.451503; batch adversarial loss: 0.569146\n",
      "epoch 3; iter: 600; batch classifier loss: 1.194442; batch adversarial loss: 0.595768\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469222; batch adversarial loss: 0.653835\n",
      "epoch 4; iter: 200; batch classifier loss: 0.616056; batch adversarial loss: 0.595111\n",
      "epoch 4; iter: 400; batch classifier loss: 0.757184; batch adversarial loss: 0.531432\n",
      "epoch 4; iter: 600; batch classifier loss: 0.721029; batch adversarial loss: 0.653462\n",
      "epoch 5; iter: 0; batch classifier loss: 0.252717; batch adversarial loss: 0.660889\n",
      "epoch 5; iter: 200; batch classifier loss: 0.336489; batch adversarial loss: 0.682285\n",
      "epoch 5; iter: 400; batch classifier loss: 0.348736; batch adversarial loss: 0.584917\n",
      "epoch 5; iter: 600; batch classifier loss: 0.368981; batch adversarial loss: 0.658194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.415303; batch adversarial loss: 0.669570\n",
      "epoch 6; iter: 200; batch classifier loss: 0.187154; batch adversarial loss: 0.668457\n",
      "epoch 6; iter: 400; batch classifier loss: 0.389490; batch adversarial loss: 0.555540\n",
      "epoch 6; iter: 600; batch classifier loss: 0.390278; batch adversarial loss: 0.690261\n",
      "epoch 7; iter: 0; batch classifier loss: 0.350602; batch adversarial loss: 0.624236\n",
      "epoch 7; iter: 200; batch classifier loss: 0.397168; batch adversarial loss: 0.553126\n",
      "epoch 7; iter: 400; batch classifier loss: 0.498358; batch adversarial loss: 0.587450\n",
      "epoch 7; iter: 600; batch classifier loss: 0.424105; batch adversarial loss: 0.672417\n",
      "epoch 8; iter: 0; batch classifier loss: 0.433387; batch adversarial loss: 0.664703\n",
      "epoch 8; iter: 200; batch classifier loss: 0.388688; batch adversarial loss: 0.618884\n",
      "epoch 8; iter: 400; batch classifier loss: 0.484236; batch adversarial loss: 0.613964\n",
      "epoch 8; iter: 600; batch classifier loss: 0.292253; batch adversarial loss: 0.558091\n",
      "epoch 9; iter: 0; batch classifier loss: 0.242867; batch adversarial loss: 0.690999\n",
      "epoch 9; iter: 200; batch classifier loss: 0.374619; batch adversarial loss: 0.622018\n",
      "epoch 9; iter: 400; batch classifier loss: 0.309677; batch adversarial loss: 0.629850\n",
      "epoch 9; iter: 600; batch classifier loss: 0.433205; batch adversarial loss: 0.669564\n",
      "epoch 0; iter: 0; batch classifier loss: 10.688132; batch adversarial loss: 0.722177\n",
      "epoch 0; iter: 200; batch classifier loss: 3.618894; batch adversarial loss: 0.775912\n",
      "epoch 0; iter: 400; batch classifier loss: 4.677806; batch adversarial loss: 0.797287\n",
      "epoch 0; iter: 600; batch classifier loss: 2.426969; batch adversarial loss: 0.652537\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591223; batch adversarial loss: 0.665837\n",
      "epoch 1; iter: 200; batch classifier loss: 6.201397; batch adversarial loss: 0.611452\n",
      "epoch 1; iter: 400; batch classifier loss: 2.162517; batch adversarial loss: 0.642984\n",
      "epoch 1; iter: 600; batch classifier loss: 2.201219; batch adversarial loss: 0.648284\n",
      "epoch 2; iter: 0; batch classifier loss: 4.830642; batch adversarial loss: 0.612865\n",
      "epoch 2; iter: 200; batch classifier loss: 0.909379; batch adversarial loss: 0.608578\n",
      "epoch 2; iter: 400; batch classifier loss: 2.035254; batch adversarial loss: 0.587830\n",
      "epoch 2; iter: 600; batch classifier loss: 1.749362; batch adversarial loss: 0.679391\n",
      "epoch 3; iter: 0; batch classifier loss: 0.660779; batch adversarial loss: 0.627433\n",
      "epoch 3; iter: 200; batch classifier loss: 1.723464; batch adversarial loss: 0.647832\n",
      "epoch 3; iter: 400; batch classifier loss: 0.398918; batch adversarial loss: 0.609487\n",
      "epoch 3; iter: 600; batch classifier loss: 0.313105; batch adversarial loss: 0.637573\n",
      "epoch 4; iter: 0; batch classifier loss: 0.318109; batch adversarial loss: 0.666778\n",
      "epoch 4; iter: 200; batch classifier loss: 0.618063; batch adversarial loss: 0.582511\n",
      "epoch 4; iter: 400; batch classifier loss: 0.307287; batch adversarial loss: 0.542400\n",
      "epoch 4; iter: 600; batch classifier loss: 0.640779; batch adversarial loss: 0.626463\n",
      "epoch 5; iter: 0; batch classifier loss: 0.747396; batch adversarial loss: 0.617543\n",
      "epoch 5; iter: 200; batch classifier loss: 0.527084; batch adversarial loss: 0.563471\n",
      "epoch 5; iter: 400; batch classifier loss: 0.447298; batch adversarial loss: 0.638948\n",
      "epoch 5; iter: 600; batch classifier loss: 0.376570; batch adversarial loss: 0.596393\n",
      "epoch 6; iter: 0; batch classifier loss: 0.351644; batch adversarial loss: 0.566702\n",
      "epoch 6; iter: 200; batch classifier loss: 0.596772; batch adversarial loss: 0.632357\n",
      "epoch 6; iter: 400; batch classifier loss: 0.481849; batch adversarial loss: 0.629404\n",
      "epoch 6; iter: 600; batch classifier loss: 0.530409; batch adversarial loss: 0.585521\n",
      "epoch 7; iter: 0; batch classifier loss: 0.324490; batch adversarial loss: 0.638688\n",
      "epoch 7; iter: 200; batch classifier loss: 0.397441; batch adversarial loss: 0.634164\n",
      "epoch 7; iter: 400; batch classifier loss: 0.322335; batch adversarial loss: 0.624243\n",
      "epoch 7; iter: 600; batch classifier loss: 0.360312; batch adversarial loss: 0.634730\n",
      "epoch 8; iter: 0; batch classifier loss: 0.430695; batch adversarial loss: 0.641068\n",
      "epoch 8; iter: 200; batch classifier loss: 0.435905; batch adversarial loss: 0.599954\n",
      "epoch 8; iter: 400; batch classifier loss: 0.425116; batch adversarial loss: 0.695107\n",
      "epoch 8; iter: 600; batch classifier loss: 0.412165; batch adversarial loss: 0.595338\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484195; batch adversarial loss: 0.642428\n",
      "epoch 9; iter: 200; batch classifier loss: 0.274425; batch adversarial loss: 0.618930\n",
      "epoch 9; iter: 400; batch classifier loss: 0.427590; batch adversarial loss: 0.665693\n",
      "epoch 9; iter: 600; batch classifier loss: 0.316302; batch adversarial loss: 0.581093\n",
      "epoch 0; iter: 0; batch classifier loss: 7.502588; batch adversarial loss: 0.740835\n",
      "epoch 0; iter: 200; batch classifier loss: 1.777458; batch adversarial loss: 0.663278\n",
      "epoch 0; iter: 400; batch classifier loss: 11.096980; batch adversarial loss: 0.611187\n",
      "epoch 0; iter: 600; batch classifier loss: 1.423288; batch adversarial loss: 0.645820\n",
      "epoch 1; iter: 0; batch classifier loss: 5.345958; batch adversarial loss: 0.623816\n",
      "epoch 1; iter: 200; batch classifier loss: 6.547100; batch adversarial loss: 0.687747\n",
      "epoch 1; iter: 400; batch classifier loss: 2.739769; batch adversarial loss: 0.704897\n",
      "epoch 1; iter: 600; batch classifier loss: 2.191323; batch adversarial loss: 0.654897\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446683; batch adversarial loss: 0.643373\n",
      "epoch 2; iter: 200; batch classifier loss: 1.614059; batch adversarial loss: 0.630800\n",
      "epoch 2; iter: 400; batch classifier loss: 0.921827; batch adversarial loss: 0.634921\n",
      "epoch 2; iter: 600; batch classifier loss: 1.173185; batch adversarial loss: 0.574218\n",
      "epoch 3; iter: 0; batch classifier loss: 0.905981; batch adversarial loss: 0.628319\n",
      "epoch 3; iter: 200; batch classifier loss: 0.539203; batch adversarial loss: 0.656035\n",
      "epoch 3; iter: 400; batch classifier loss: 0.790220; batch adversarial loss: 0.668345\n",
      "epoch 3; iter: 600; batch classifier loss: 0.725654; batch adversarial loss: 0.662035\n",
      "epoch 4; iter: 0; batch classifier loss: 0.653072; batch adversarial loss: 0.622369\n",
      "epoch 4; iter: 200; batch classifier loss: 0.449914; batch adversarial loss: 0.647062\n",
      "epoch 4; iter: 400; batch classifier loss: 0.389072; batch adversarial loss: 0.651646\n",
      "epoch 4; iter: 600; batch classifier loss: 0.591842; batch adversarial loss: 0.644626\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418207; batch adversarial loss: 0.636549\n",
      "epoch 5; iter: 200; batch classifier loss: 0.444852; batch adversarial loss: 0.636362\n",
      "epoch 5; iter: 400; batch classifier loss: 0.368746; batch adversarial loss: 0.639076\n",
      "epoch 5; iter: 600; batch classifier loss: 0.339147; batch adversarial loss: 0.628048\n",
      "epoch 6; iter: 0; batch classifier loss: 0.844035; batch adversarial loss: 0.570042\n",
      "epoch 6; iter: 200; batch classifier loss: 0.555424; batch adversarial loss: 0.575881\n",
      "epoch 6; iter: 400; batch classifier loss: 0.400746; batch adversarial loss: 0.633404\n",
      "epoch 6; iter: 600; batch classifier loss: 0.695327; batch adversarial loss: 0.629000\n",
      "epoch 7; iter: 0; batch classifier loss: 0.433318; batch adversarial loss: 0.613226\n",
      "epoch 7; iter: 200; batch classifier loss: 0.341332; batch adversarial loss: 0.607877\n",
      "epoch 7; iter: 400; batch classifier loss: 0.352736; batch adversarial loss: 0.607954\n",
      "epoch 7; iter: 600; batch classifier loss: 0.353198; batch adversarial loss: 0.629234\n",
      "epoch 8; iter: 0; batch classifier loss: 0.273469; batch adversarial loss: 0.593356\n",
      "epoch 8; iter: 200; batch classifier loss: 0.243901; batch adversarial loss: 0.581375\n",
      "epoch 8; iter: 400; batch classifier loss: 0.371603; batch adversarial loss: 0.595824\n",
      "epoch 8; iter: 600; batch classifier loss: 0.376108; batch adversarial loss: 0.612189\n",
      "epoch 9; iter: 0; batch classifier loss: 0.468518; batch adversarial loss: 0.625919\n",
      "epoch 9; iter: 200; batch classifier loss: 0.417531; batch adversarial loss: 0.686556\n",
      "epoch 9; iter: 400; batch classifier loss: 0.420577; batch adversarial loss: 0.609960\n",
      "epoch 9; iter: 600; batch classifier loss: 0.369095; batch adversarial loss: 0.678406\n",
      "epoch 0; iter: 0; batch classifier loss: 14.901382; batch adversarial loss: 0.670410\n",
      "epoch 0; iter: 200; batch classifier loss: 3.186471; batch adversarial loss: 0.545950\n",
      "epoch 0; iter: 400; batch classifier loss: 0.671394; batch adversarial loss: 0.600334\n",
      "epoch 0; iter: 600; batch classifier loss: 1.846129; batch adversarial loss: 0.653412\n",
      "epoch 1; iter: 0; batch classifier loss: 5.628500; batch adversarial loss: 0.688405\n",
      "epoch 1; iter: 200; batch classifier loss: 4.351659; batch adversarial loss: 0.634435\n",
      "epoch 1; iter: 400; batch classifier loss: 2.812568; batch adversarial loss: 0.666515\n",
      "epoch 1; iter: 600; batch classifier loss: 1.298257; batch adversarial loss: 0.699268\n",
      "epoch 2; iter: 0; batch classifier loss: 4.072346; batch adversarial loss: 0.643898\n",
      "epoch 2; iter: 200; batch classifier loss: 0.487423; batch adversarial loss: 0.638659\n",
      "epoch 2; iter: 400; batch classifier loss: 0.445201; batch adversarial loss: 0.593765\n",
      "epoch 2; iter: 600; batch classifier loss: 0.517847; batch adversarial loss: 0.617397\n",
      "epoch 3; iter: 0; batch classifier loss: 2.778816; batch adversarial loss: 0.591330\n",
      "epoch 3; iter: 200; batch classifier loss: 0.294207; batch adversarial loss: 0.567277\n",
      "epoch 3; iter: 400; batch classifier loss: 0.297133; batch adversarial loss: 0.598583\n",
      "epoch 3; iter: 600; batch classifier loss: 0.616836; batch adversarial loss: 0.572318\n",
      "epoch 4; iter: 0; batch classifier loss: 0.984637; batch adversarial loss: 0.581853\n",
      "epoch 4; iter: 200; batch classifier loss: 0.496507; batch adversarial loss: 0.577624\n",
      "epoch 4; iter: 400; batch classifier loss: 0.412361; batch adversarial loss: 0.551880\n",
      "epoch 4; iter: 600; batch classifier loss: 0.733319; batch adversarial loss: 0.612529\n",
      "epoch 5; iter: 0; batch classifier loss: 0.423839; batch adversarial loss: 0.586941\n",
      "epoch 5; iter: 200; batch classifier loss: 0.845583; batch adversarial loss: 0.651624\n",
      "epoch 5; iter: 400; batch classifier loss: 0.339977; batch adversarial loss: 0.622312\n",
      "epoch 5; iter: 600; batch classifier loss: 0.340502; batch adversarial loss: 0.643580\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402870; batch adversarial loss: 0.582847\n",
      "epoch 6; iter: 200; batch classifier loss: 0.407952; batch adversarial loss: 0.678115\n",
      "epoch 6; iter: 400; batch classifier loss: 0.424981; batch adversarial loss: 0.582739\n",
      "epoch 6; iter: 600; batch classifier loss: 0.430074; batch adversarial loss: 0.603569\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335780; batch adversarial loss: 0.668232\n",
      "epoch 7; iter: 200; batch classifier loss: 0.434756; batch adversarial loss: 0.571719\n",
      "epoch 7; iter: 400; batch classifier loss: 0.470625; batch adversarial loss: 0.596216\n",
      "epoch 7; iter: 600; batch classifier loss: 0.477525; batch adversarial loss: 0.624397\n",
      "epoch 8; iter: 0; batch classifier loss: 0.269349; batch adversarial loss: 0.705631\n",
      "epoch 8; iter: 200; batch classifier loss: 0.374665; batch adversarial loss: 0.699550\n",
      "epoch 8; iter: 400; batch classifier loss: 0.343686; batch adversarial loss: 0.617836\n",
      "epoch 8; iter: 600; batch classifier loss: 0.285886; batch adversarial loss: 0.638337\n",
      "epoch 9; iter: 0; batch classifier loss: 0.308760; batch adversarial loss: 0.603237\n",
      "epoch 9; iter: 200; batch classifier loss: 0.424746; batch adversarial loss: 0.586739\n",
      "epoch 9; iter: 400; batch classifier loss: 0.405013; batch adversarial loss: 0.640226\n",
      "epoch 9; iter: 600; batch classifier loss: 0.358941; batch adversarial loss: 0.712905\n",
      "epoch 0; iter: 0; batch classifier loss: 65.192352; batch adversarial loss: 0.743601\n",
      "epoch 0; iter: 200; batch classifier loss: 2.262399; batch adversarial loss: 0.699093\n",
      "epoch 0; iter: 400; batch classifier loss: 1.633317; batch adversarial loss: 0.732843\n",
      "epoch 0; iter: 600; batch classifier loss: 4.753675; batch adversarial loss: 0.672803\n",
      "epoch 1; iter: 0; batch classifier loss: 12.757448; batch adversarial loss: 0.604315\n",
      "epoch 1; iter: 200; batch classifier loss: 17.284117; batch adversarial loss: 0.674469\n",
      "epoch 1; iter: 400; batch classifier loss: 11.089302; batch adversarial loss: 0.571090\n",
      "epoch 1; iter: 600; batch classifier loss: 1.151320; batch adversarial loss: 0.612704\n",
      "epoch 2; iter: 0; batch classifier loss: 1.029982; batch adversarial loss: 0.622415\n",
      "epoch 2; iter: 200; batch classifier loss: 0.339991; batch adversarial loss: 0.633243\n",
      "epoch 2; iter: 400; batch classifier loss: 2.492360; batch adversarial loss: 0.686719\n",
      "epoch 2; iter: 600; batch classifier loss: 1.239828; batch adversarial loss: 0.681799\n",
      "epoch 3; iter: 0; batch classifier loss: 0.857574; batch adversarial loss: 0.603094\n",
      "epoch 3; iter: 200; batch classifier loss: 0.365248; batch adversarial loss: 0.643313\n",
      "epoch 3; iter: 400; batch classifier loss: 0.369915; batch adversarial loss: 0.672264\n",
      "epoch 3; iter: 600; batch classifier loss: 0.432912; batch adversarial loss: 0.628372\n",
      "epoch 4; iter: 0; batch classifier loss: 0.449401; batch adversarial loss: 0.659339\n",
      "epoch 4; iter: 200; batch classifier loss: 0.418144; batch adversarial loss: 0.617424\n",
      "epoch 4; iter: 400; batch classifier loss: 0.396812; batch adversarial loss: 0.577912\n",
      "epoch 4; iter: 600; batch classifier loss: 0.438815; batch adversarial loss: 0.643038\n",
      "epoch 5; iter: 0; batch classifier loss: 0.369005; batch adversarial loss: 0.625509\n",
      "epoch 5; iter: 200; batch classifier loss: 0.676164; batch adversarial loss: 0.581668\n",
      "epoch 5; iter: 400; batch classifier loss: 0.305840; batch adversarial loss: 0.551045\n",
      "epoch 5; iter: 600; batch classifier loss: 0.767278; batch adversarial loss: 0.637476\n",
      "epoch 6; iter: 0; batch classifier loss: 0.673387; batch adversarial loss: 0.617620\n",
      "epoch 6; iter: 200; batch classifier loss: 0.317693; batch adversarial loss: 0.645240\n",
      "epoch 6; iter: 400; batch classifier loss: 0.567271; batch adversarial loss: 0.711093\n",
      "epoch 6; iter: 600; batch classifier loss: 0.496045; batch adversarial loss: 0.652532\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416802; batch adversarial loss: 0.597808\n",
      "epoch 7; iter: 200; batch classifier loss: 0.351768; batch adversarial loss: 0.616879\n",
      "epoch 7; iter: 400; batch classifier loss: 0.310528; batch adversarial loss: 0.692430\n",
      "epoch 7; iter: 600; batch classifier loss: 0.407400; batch adversarial loss: 0.633794\n",
      "epoch 8; iter: 0; batch classifier loss: 0.392331; batch adversarial loss: 0.565957\n",
      "epoch 8; iter: 200; batch classifier loss: 0.407295; batch adversarial loss: 0.646613\n",
      "epoch 8; iter: 400; batch classifier loss: 0.523375; batch adversarial loss: 0.641035\n",
      "epoch 8; iter: 600; batch classifier loss: 0.353109; batch adversarial loss: 0.649591\n",
      "epoch 9; iter: 0; batch classifier loss: 0.359849; batch adversarial loss: 0.598589\n",
      "epoch 9; iter: 200; batch classifier loss: 0.323016; batch adversarial loss: 0.604169\n",
      "epoch 9; iter: 400; batch classifier loss: 0.549565; batch adversarial loss: 0.625014\n",
      "epoch 9; iter: 600; batch classifier loss: 0.411019; batch adversarial loss: 0.595029\n",
      "epoch 0; iter: 0; batch classifier loss: 230.929520; batch adversarial loss: 0.772016\n",
      "epoch 0; iter: 200; batch classifier loss: 9.106042; batch adversarial loss: 0.712759\n",
      "epoch 0; iter: 400; batch classifier loss: 4.256500; batch adversarial loss: 0.668179\n",
      "epoch 0; iter: 600; batch classifier loss: 4.453731; batch adversarial loss: 0.665517\n",
      "epoch 1; iter: 0; batch classifier loss: 4.114297; batch adversarial loss: 0.641869\n",
      "epoch 1; iter: 200; batch classifier loss: 4.949102; batch adversarial loss: 0.662421\n",
      "epoch 1; iter: 400; batch classifier loss: 0.520455; batch adversarial loss: 0.544448\n",
      "epoch 1; iter: 600; batch classifier loss: 0.660542; batch adversarial loss: 0.594273\n",
      "epoch 2; iter: 0; batch classifier loss: 0.461501; batch adversarial loss: 0.633738\n",
      "epoch 2; iter: 200; batch classifier loss: 3.292245; batch adversarial loss: 0.561100\n",
      "epoch 2; iter: 400; batch classifier loss: 21.252136; batch adversarial loss: 0.624060\n",
      "epoch 2; iter: 600; batch classifier loss: 3.776309; batch adversarial loss: 0.697120\n",
      "epoch 3; iter: 0; batch classifier loss: 0.262480; batch adversarial loss: 0.572057\n",
      "epoch 3; iter: 200; batch classifier loss: 0.919977; batch adversarial loss: 0.634387\n",
      "epoch 3; iter: 400; batch classifier loss: 0.527466; batch adversarial loss: 0.677139\n",
      "epoch 3; iter: 600; batch classifier loss: 6.448313; batch adversarial loss: 0.579747\n",
      "epoch 4; iter: 0; batch classifier loss: 1.921439; batch adversarial loss: 0.628505\n",
      "epoch 4; iter: 200; batch classifier loss: 0.362119; batch adversarial loss: 0.663984\n",
      "epoch 4; iter: 400; batch classifier loss: 0.389984; batch adversarial loss: 0.635955\n",
      "epoch 4; iter: 600; batch classifier loss: 0.434074; batch adversarial loss: 0.700006\n",
      "epoch 5; iter: 0; batch classifier loss: 5.421489; batch adversarial loss: 0.600413\n",
      "epoch 5; iter: 200; batch classifier loss: 0.597493; batch adversarial loss: 0.668762\n",
      "epoch 5; iter: 400; batch classifier loss: 0.406963; batch adversarial loss: 0.656885\n",
      "epoch 5; iter: 600; batch classifier loss: 0.408005; batch adversarial loss: 0.664207\n",
      "epoch 6; iter: 0; batch classifier loss: 0.792142; batch adversarial loss: 0.580960\n",
      "epoch 6; iter: 200; batch classifier loss: 0.299588; batch adversarial loss: 0.648823\n",
      "epoch 6; iter: 400; batch classifier loss: 0.466159; batch adversarial loss: 0.652323\n",
      "epoch 6; iter: 600; batch classifier loss: 0.463394; batch adversarial loss: 0.641429\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503660; batch adversarial loss: 0.594470\n",
      "epoch 7; iter: 200; batch classifier loss: 0.342690; batch adversarial loss: 0.704899\n",
      "epoch 7; iter: 400; batch classifier loss: 0.419802; batch adversarial loss: 0.620597\n",
      "epoch 7; iter: 600; batch classifier loss: 0.279708; batch adversarial loss: 0.674853\n",
      "epoch 8; iter: 0; batch classifier loss: 0.374509; batch adversarial loss: 0.646338\n",
      "epoch 8; iter: 200; batch classifier loss: 0.408245; batch adversarial loss: 0.562152\n",
      "epoch 8; iter: 400; batch classifier loss: 0.512280; batch adversarial loss: 0.620921\n",
      "epoch 8; iter: 600; batch classifier loss: 0.434098; batch adversarial loss: 0.483197\n",
      "epoch 9; iter: 0; batch classifier loss: 0.275383; batch adversarial loss: 0.600603\n",
      "epoch 9; iter: 200; batch classifier loss: 0.309403; batch adversarial loss: 0.686696\n",
      "epoch 9; iter: 400; batch classifier loss: 0.342457; batch adversarial loss: 0.638604\n",
      "epoch 9; iter: 600; batch classifier loss: 0.458867; batch adversarial loss: 0.605560\n",
      "epoch 0; iter: 0; batch classifier loss: 197.532532; batch adversarial loss: 0.898153\n",
      "epoch 0; iter: 200; batch classifier loss: 5.831563; batch adversarial loss: 0.816383\n",
      "epoch 0; iter: 400; batch classifier loss: 6.994434; batch adversarial loss: 0.719491\n",
      "epoch 0; iter: 600; batch classifier loss: 8.199991; batch adversarial loss: 0.619074\n",
      "epoch 1; iter: 0; batch classifier loss: 5.428852; batch adversarial loss: 0.648064\n",
      "epoch 1; iter: 200; batch classifier loss: 0.564652; batch adversarial loss: 0.565959\n",
      "epoch 1; iter: 400; batch classifier loss: 11.191751; batch adversarial loss: 0.669677\n",
      "epoch 1; iter: 600; batch classifier loss: 2.244794; batch adversarial loss: 0.609196\n",
      "epoch 2; iter: 0; batch classifier loss: 10.108214; batch adversarial loss: 0.643842\n",
      "epoch 2; iter: 200; batch classifier loss: 0.402476; batch adversarial loss: 0.582857\n",
      "epoch 2; iter: 400; batch classifier loss: 0.655982; batch adversarial loss: 0.605056\n",
      "epoch 2; iter: 600; batch classifier loss: 1.670272; batch adversarial loss: 0.560295\n",
      "epoch 3; iter: 0; batch classifier loss: 16.756941; batch adversarial loss: 0.615703\n",
      "epoch 3; iter: 200; batch classifier loss: 1.897994; batch adversarial loss: 0.641030\n",
      "epoch 3; iter: 400; batch classifier loss: 0.402440; batch adversarial loss: 0.662502\n",
      "epoch 3; iter: 600; batch classifier loss: 0.827697; batch adversarial loss: 0.624233\n",
      "epoch 4; iter: 0; batch classifier loss: 0.365468; batch adversarial loss: 0.669234\n",
      "epoch 4; iter: 200; batch classifier loss: 0.924461; batch adversarial loss: 0.594118\n",
      "epoch 4; iter: 400; batch classifier loss: 0.546931; batch adversarial loss: 0.665287\n",
      "epoch 4; iter: 600; batch classifier loss: 0.795941; batch adversarial loss: 0.621585\n",
      "epoch 5; iter: 0; batch classifier loss: 3.598727; batch adversarial loss: 0.693336\n",
      "epoch 5; iter: 200; batch classifier loss: 0.634599; batch adversarial loss: 0.731638\n",
      "epoch 5; iter: 400; batch classifier loss: 0.337441; batch adversarial loss: 0.589020\n",
      "epoch 5; iter: 600; batch classifier loss: 0.538314; batch adversarial loss: 0.626172\n",
      "epoch 6; iter: 0; batch classifier loss: 0.326995; batch adversarial loss: 0.603287\n",
      "epoch 6; iter: 200; batch classifier loss: 0.435353; batch adversarial loss: 0.758742\n",
      "epoch 6; iter: 400; batch classifier loss: 0.601861; batch adversarial loss: 0.613014\n",
      "epoch 6; iter: 600; batch classifier loss: 0.363787; batch adversarial loss: 0.676995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.402216; batch adversarial loss: 0.561723\n",
      "epoch 7; iter: 200; batch classifier loss: 0.341654; batch adversarial loss: 0.626548\n",
      "epoch 7; iter: 400; batch classifier loss: 0.239000; batch adversarial loss: 0.621719\n",
      "epoch 7; iter: 600; batch classifier loss: 0.399274; batch adversarial loss: 0.650430\n",
      "epoch 8; iter: 0; batch classifier loss: 0.299257; batch adversarial loss: 0.671075\n",
      "epoch 8; iter: 200; batch classifier loss: 0.395288; batch adversarial loss: 0.686861\n",
      "epoch 8; iter: 400; batch classifier loss: 0.401587; batch adversarial loss: 0.631111\n",
      "epoch 8; iter: 600; batch classifier loss: 0.397107; batch adversarial loss: 0.596372\n",
      "epoch 9; iter: 0; batch classifier loss: 0.321676; batch adversarial loss: 0.649646\n",
      "epoch 9; iter: 200; batch classifier loss: 0.351221; batch adversarial loss: 0.625708\n",
      "epoch 9; iter: 400; batch classifier loss: 0.430834; batch adversarial loss: 0.604281\n",
      "epoch 9; iter: 600; batch classifier loss: 0.355448; batch adversarial loss: 0.611311\n",
      "epoch 0; iter: 0; batch classifier loss: 6.241957; batch adversarial loss: 0.779055\n",
      "epoch 0; iter: 200; batch classifier loss: 4.240728; batch adversarial loss: 0.678567\n",
      "epoch 0; iter: 400; batch classifier loss: 5.821810; batch adversarial loss: 0.655692\n",
      "epoch 0; iter: 600; batch classifier loss: 2.167020; batch adversarial loss: 0.583482\n",
      "epoch 1; iter: 0; batch classifier loss: 1.507184; batch adversarial loss: 0.587436\n",
      "epoch 1; iter: 200; batch classifier loss: 0.814582; batch adversarial loss: 0.646459\n",
      "epoch 1; iter: 400; batch classifier loss: 5.179959; batch adversarial loss: 0.613202\n",
      "epoch 1; iter: 600; batch classifier loss: 0.319207; batch adversarial loss: 0.661699\n",
      "epoch 2; iter: 0; batch classifier loss: 6.307561; batch adversarial loss: 0.599059\n",
      "epoch 2; iter: 200; batch classifier loss: 2.884994; batch adversarial loss: 0.582064\n",
      "epoch 2; iter: 400; batch classifier loss: 0.513729; batch adversarial loss: 0.591339\n",
      "epoch 2; iter: 600; batch classifier loss: 0.314098; batch adversarial loss: 0.623612\n",
      "epoch 3; iter: 0; batch classifier loss: 0.891209; batch adversarial loss: 0.657419\n",
      "epoch 3; iter: 200; batch classifier loss: 0.791658; batch adversarial loss: 0.602890\n",
      "epoch 3; iter: 400; batch classifier loss: 1.412438; batch adversarial loss: 0.658649\n",
      "epoch 3; iter: 600; batch classifier loss: 0.363856; batch adversarial loss: 0.669961\n",
      "epoch 4; iter: 0; batch classifier loss: 0.353703; batch adversarial loss: 0.668071\n",
      "epoch 4; iter: 200; batch classifier loss: 0.781298; batch adversarial loss: 0.639224\n",
      "epoch 4; iter: 400; batch classifier loss: 0.335002; batch adversarial loss: 0.613597\n",
      "epoch 4; iter: 600; batch classifier loss: 0.643561; batch adversarial loss: 0.605551\n",
      "epoch 5; iter: 0; batch classifier loss: 0.287519; batch adversarial loss: 0.655458\n",
      "epoch 5; iter: 200; batch classifier loss: 0.592997; batch adversarial loss: 0.661326\n",
      "epoch 5; iter: 400; batch classifier loss: 0.917815; batch adversarial loss: 0.619215\n",
      "epoch 5; iter: 600; batch classifier loss: 0.574512; batch adversarial loss: 0.628822\n",
      "epoch 6; iter: 0; batch classifier loss: 0.456650; batch adversarial loss: 0.580939\n",
      "epoch 6; iter: 200; batch classifier loss: 0.590189; batch adversarial loss: 0.538416\n",
      "epoch 6; iter: 400; batch classifier loss: 0.320192; batch adversarial loss: 0.648396\n",
      "epoch 6; iter: 600; batch classifier loss: 0.341610; batch adversarial loss: 0.589040\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565570; batch adversarial loss: 0.643774\n",
      "epoch 7; iter: 200; batch classifier loss: 0.625527; batch adversarial loss: 0.615171\n",
      "epoch 7; iter: 400; batch classifier loss: 0.283805; batch adversarial loss: 0.630075\n",
      "epoch 7; iter: 600; batch classifier loss: 0.397681; batch adversarial loss: 0.631720\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455169; batch adversarial loss: 0.675154\n",
      "epoch 8; iter: 200; batch classifier loss: 0.431917; batch adversarial loss: 0.675843\n",
      "epoch 8; iter: 400; batch classifier loss: 0.432752; batch adversarial loss: 0.665470\n",
      "epoch 8; iter: 600; batch classifier loss: 0.305703; batch adversarial loss: 0.653171\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349804; batch adversarial loss: 0.626255\n",
      "epoch 9; iter: 200; batch classifier loss: 0.382805; batch adversarial loss: 0.549887\n",
      "epoch 9; iter: 400; batch classifier loss: 0.303305; batch adversarial loss: 0.679596\n",
      "epoch 9; iter: 600; batch classifier loss: 0.447157; batch adversarial loss: 0.606516\n",
      "epoch 0; iter: 0; batch classifier loss: 12.374174; batch adversarial loss: 0.721513\n",
      "epoch 0; iter: 200; batch classifier loss: 10.497304; batch adversarial loss: 0.683971\n",
      "epoch 0; iter: 400; batch classifier loss: 9.294057; batch adversarial loss: 0.654167\n",
      "epoch 0; iter: 600; batch classifier loss: 4.382606; batch adversarial loss: 0.599178\n",
      "epoch 1; iter: 0; batch classifier loss: 4.201761; batch adversarial loss: 0.658962\n",
      "epoch 1; iter: 200; batch classifier loss: 1.251940; batch adversarial loss: 0.649484\n",
      "epoch 1; iter: 400; batch classifier loss: 1.200679; batch adversarial loss: 0.651965\n",
      "epoch 1; iter: 600; batch classifier loss: 4.708943; batch adversarial loss: 0.670431\n",
      "epoch 2; iter: 0; batch classifier loss: 2.845984; batch adversarial loss: 0.650499\n",
      "epoch 2; iter: 200; batch classifier loss: 1.902153; batch adversarial loss: 0.617807\n",
      "epoch 2; iter: 400; batch classifier loss: 2.235988; batch adversarial loss: 0.698503\n",
      "epoch 2; iter: 600; batch classifier loss: 1.950091; batch adversarial loss: 0.610632\n",
      "epoch 3; iter: 0; batch classifier loss: 1.285312; batch adversarial loss: 0.558013\n",
      "epoch 3; iter: 200; batch classifier loss: 0.523583; batch adversarial loss: 0.620331\n",
      "epoch 3; iter: 400; batch classifier loss: 0.496886; batch adversarial loss: 0.596847\n",
      "epoch 3; iter: 600; batch classifier loss: 0.364909; batch adversarial loss: 0.677261\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521357; batch adversarial loss: 0.604873\n",
      "epoch 4; iter: 200; batch classifier loss: 0.328676; batch adversarial loss: 0.619297\n",
      "epoch 4; iter: 400; batch classifier loss: 0.348017; batch adversarial loss: 0.586794\n",
      "epoch 4; iter: 600; batch classifier loss: 0.513583; batch adversarial loss: 0.645166\n",
      "epoch 5; iter: 0; batch classifier loss: 0.317122; batch adversarial loss: 0.612545\n",
      "epoch 5; iter: 200; batch classifier loss: 0.539284; batch adversarial loss: 0.647698\n",
      "epoch 5; iter: 400; batch classifier loss: 0.366764; batch adversarial loss: 0.625717\n",
      "epoch 5; iter: 600; batch classifier loss: 0.426145; batch adversarial loss: 0.561780\n",
      "epoch 6; iter: 0; batch classifier loss: 0.343338; batch adversarial loss: 0.665018\n",
      "epoch 6; iter: 200; batch classifier loss: 0.358336; batch adversarial loss: 0.566644\n",
      "epoch 6; iter: 400; batch classifier loss: 0.330845; batch adversarial loss: 0.568107\n",
      "epoch 6; iter: 600; batch classifier loss: 0.426781; batch adversarial loss: 0.647550\n",
      "epoch 7; iter: 0; batch classifier loss: 0.322862; batch adversarial loss: 0.674321\n",
      "epoch 7; iter: 200; batch classifier loss: 0.435991; batch adversarial loss: 0.628615\n",
      "epoch 7; iter: 400; batch classifier loss: 0.608328; batch adversarial loss: 0.624081\n",
      "epoch 7; iter: 600; batch classifier loss: 0.451214; batch adversarial loss: 0.651541\n",
      "epoch 8; iter: 0; batch classifier loss: 0.424387; batch adversarial loss: 0.672478\n",
      "epoch 8; iter: 200; batch classifier loss: 0.409807; batch adversarial loss: 0.635572\n",
      "epoch 8; iter: 400; batch classifier loss: 0.502933; batch adversarial loss: 0.648267\n",
      "epoch 8; iter: 600; batch classifier loss: 0.306288; batch adversarial loss: 0.660568\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471824; batch adversarial loss: 0.653200\n",
      "epoch 9; iter: 200; batch classifier loss: 0.336834; batch adversarial loss: 0.633615\n",
      "epoch 9; iter: 400; batch classifier loss: 0.334806; batch adversarial loss: 0.637953\n",
      "epoch 9; iter: 600; batch classifier loss: 0.378538; batch adversarial loss: 0.623268\n",
      "epoch 0; iter: 0; batch classifier loss: 7.825775; batch adversarial loss: 0.817231\n",
      "epoch 0; iter: 200; batch classifier loss: 4.542046; batch adversarial loss: 0.718158\n",
      "epoch 0; iter: 400; batch classifier loss: 15.225298; batch adversarial loss: 0.695112\n",
      "epoch 0; iter: 600; batch classifier loss: 12.591795; batch adversarial loss: 0.734535\n",
      "epoch 1; iter: 0; batch classifier loss: 2.376528; batch adversarial loss: 0.679342\n",
      "epoch 1; iter: 200; batch classifier loss: 2.466756; batch adversarial loss: 0.649719\n",
      "epoch 1; iter: 400; batch classifier loss: 4.119330; batch adversarial loss: 0.637896\n",
      "epoch 1; iter: 600; batch classifier loss: 2.144065; batch adversarial loss: 0.621945\n",
      "epoch 2; iter: 0; batch classifier loss: 2.298004; batch adversarial loss: 0.642523\n",
      "epoch 2; iter: 200; batch classifier loss: 0.675696; batch adversarial loss: 0.689760\n",
      "epoch 2; iter: 400; batch classifier loss: 0.812712; batch adversarial loss: 0.631837\n",
      "epoch 2; iter: 600; batch classifier loss: 1.972554; batch adversarial loss: 0.654924\n",
      "epoch 3; iter: 0; batch classifier loss: 0.805760; batch adversarial loss: 0.663127\n",
      "epoch 3; iter: 200; batch classifier loss: 1.632928; batch adversarial loss: 0.612637\n",
      "epoch 3; iter: 400; batch classifier loss: 0.723650; batch adversarial loss: 0.711103\n",
      "epoch 3; iter: 600; batch classifier loss: 0.880636; batch adversarial loss: 0.650226\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513573; batch adversarial loss: 0.565884\n",
      "epoch 4; iter: 200; batch classifier loss: 0.408065; batch adversarial loss: 0.692689\n",
      "epoch 4; iter: 400; batch classifier loss: 0.394648; batch adversarial loss: 0.688292\n",
      "epoch 4; iter: 600; batch classifier loss: 0.401752; batch adversarial loss: 0.597382\n",
      "epoch 5; iter: 0; batch classifier loss: 0.662519; batch adversarial loss: 0.654543\n",
      "epoch 5; iter: 200; batch classifier loss: 0.339799; batch adversarial loss: 0.641181\n",
      "epoch 5; iter: 400; batch classifier loss: 0.337332; batch adversarial loss: 0.599329\n",
      "epoch 5; iter: 600; batch classifier loss: 0.374975; batch adversarial loss: 0.651034\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484082; batch adversarial loss: 0.693173\n",
      "epoch 6; iter: 200; batch classifier loss: 0.428023; batch adversarial loss: 0.621225\n",
      "epoch 6; iter: 400; batch classifier loss: 0.370649; batch adversarial loss: 0.679366\n",
      "epoch 6; iter: 600; batch classifier loss: 0.366585; batch adversarial loss: 0.636441\n",
      "epoch 7; iter: 0; batch classifier loss: 0.383698; batch adversarial loss: 0.606379\n",
      "epoch 7; iter: 200; batch classifier loss: 0.326073; batch adversarial loss: 0.548748\n",
      "epoch 7; iter: 400; batch classifier loss: 0.388440; batch adversarial loss: 0.617216\n",
      "epoch 7; iter: 600; batch classifier loss: 0.482021; batch adversarial loss: 0.562846\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400779; batch adversarial loss: 0.689998\n",
      "epoch 8; iter: 200; batch classifier loss: 1.086004; batch adversarial loss: 0.560400\n",
      "epoch 8; iter: 400; batch classifier loss: 0.434485; batch adversarial loss: 0.642496\n",
      "epoch 8; iter: 600; batch classifier loss: 0.309051; batch adversarial loss: 0.757481\n",
      "epoch 9; iter: 0; batch classifier loss: 0.510798; batch adversarial loss: 0.615229\n",
      "epoch 9; iter: 200; batch classifier loss: 0.390387; batch adversarial loss: 0.714323\n",
      "epoch 9; iter: 400; batch classifier loss: 0.348478; batch adversarial loss: 0.588962\n",
      "epoch 9; iter: 600; batch classifier loss: 0.272318; batch adversarial loss: 0.677058\n",
      "epoch 0; iter: 0; batch classifier loss: 10.042405; batch adversarial loss: 0.923373\n",
      "epoch 0; iter: 200; batch classifier loss: 11.165759; batch adversarial loss: 0.713349\n",
      "epoch 0; iter: 400; batch classifier loss: 8.235175; batch adversarial loss: 0.658082\n",
      "epoch 0; iter: 600; batch classifier loss: 3.653694; batch adversarial loss: 0.678367\n",
      "epoch 1; iter: 0; batch classifier loss: 1.884810; batch adversarial loss: 0.640999\n",
      "epoch 1; iter: 200; batch classifier loss: 4.518868; batch adversarial loss: 0.653648\n",
      "epoch 1; iter: 400; batch classifier loss: 5.362094; batch adversarial loss: 0.586379\n",
      "epoch 1; iter: 600; batch classifier loss: 1.391636; batch adversarial loss: 0.571217\n",
      "epoch 2; iter: 0; batch classifier loss: 1.062996; batch adversarial loss: 0.562567\n",
      "epoch 2; iter: 200; batch classifier loss: 0.425712; batch adversarial loss: 0.663943\n",
      "epoch 2; iter: 400; batch classifier loss: 1.806075; batch adversarial loss: 0.574735\n",
      "epoch 2; iter: 600; batch classifier loss: 2.147365; batch adversarial loss: 0.612044\n",
      "epoch 3; iter: 0; batch classifier loss: 0.432357; batch adversarial loss: 0.604602\n",
      "epoch 3; iter: 200; batch classifier loss: 1.758421; batch adversarial loss: 0.633716\n",
      "epoch 3; iter: 400; batch classifier loss: 1.073587; batch adversarial loss: 0.617418\n",
      "epoch 3; iter: 600; batch classifier loss: 0.956926; batch adversarial loss: 0.568974\n",
      "epoch 4; iter: 0; batch classifier loss: 0.435004; batch adversarial loss: 0.659147\n",
      "epoch 4; iter: 200; batch classifier loss: 0.737625; batch adversarial loss: 0.601315\n",
      "epoch 4; iter: 400; batch classifier loss: 0.605002; batch adversarial loss: 0.593310\n",
      "epoch 4; iter: 600; batch classifier loss: 0.719056; batch adversarial loss: 0.695140\n",
      "epoch 5; iter: 0; batch classifier loss: 2.013171; batch adversarial loss: 0.567779\n",
      "epoch 5; iter: 200; batch classifier loss: 0.372166; batch adversarial loss: 0.624788\n",
      "epoch 5; iter: 400; batch classifier loss: 0.363458; batch adversarial loss: 0.618126\n",
      "epoch 5; iter: 600; batch classifier loss: 0.330881; batch adversarial loss: 0.691158\n",
      "epoch 6; iter: 0; batch classifier loss: 0.459520; batch adversarial loss: 0.607923\n",
      "epoch 6; iter: 200; batch classifier loss: 0.680009; batch adversarial loss: 0.595996\n",
      "epoch 6; iter: 400; batch classifier loss: 0.285096; batch adversarial loss: 0.588670\n",
      "epoch 6; iter: 600; batch classifier loss: 0.337773; batch adversarial loss: 0.589094\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485352; batch adversarial loss: 0.630337\n",
      "epoch 7; iter: 200; batch classifier loss: 0.373779; batch adversarial loss: 0.655569\n",
      "epoch 7; iter: 400; batch classifier loss: 0.291236; batch adversarial loss: 0.682321\n",
      "epoch 7; iter: 600; batch classifier loss: 0.342543; batch adversarial loss: 0.658655\n",
      "epoch 8; iter: 0; batch classifier loss: 0.444378; batch adversarial loss: 0.592519\n",
      "epoch 8; iter: 200; batch classifier loss: 0.556125; batch adversarial loss: 0.571999\n",
      "epoch 8; iter: 400; batch classifier loss: 0.349931; batch adversarial loss: 0.603413\n",
      "epoch 8; iter: 600; batch classifier loss: 0.450964; batch adversarial loss: 0.609987\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332302; batch adversarial loss: 0.592588\n",
      "epoch 9; iter: 200; batch classifier loss: 0.271144; batch adversarial loss: 0.659816\n",
      "epoch 9; iter: 400; batch classifier loss: 0.188880; batch adversarial loss: 0.665763\n",
      "epoch 9; iter: 600; batch classifier loss: 0.355472; batch adversarial loss: 0.631518\n",
      "epoch 0; iter: 0; batch classifier loss: 71.685478; batch adversarial loss: 0.689078\n",
      "epoch 0; iter: 200; batch classifier loss: 35.575783; batch adversarial loss: 0.662687\n",
      "epoch 0; iter: 400; batch classifier loss: 11.140180; batch adversarial loss: 0.648485\n",
      "epoch 0; iter: 600; batch classifier loss: 5.155218; batch adversarial loss: 0.652700\n",
      "epoch 1; iter: 0; batch classifier loss: 5.174418; batch adversarial loss: 0.645974\n",
      "epoch 1; iter: 200; batch classifier loss: 1.528993; batch adversarial loss: 0.603973\n",
      "epoch 1; iter: 400; batch classifier loss: 2.665493; batch adversarial loss: 0.678475\n",
      "epoch 1; iter: 600; batch classifier loss: 2.704923; batch adversarial loss: 0.601736\n",
      "epoch 2; iter: 0; batch classifier loss: 6.839361; batch adversarial loss: 0.644511\n",
      "epoch 2; iter: 200; batch classifier loss: 5.849341; batch adversarial loss: 0.737001\n",
      "epoch 2; iter: 400; batch classifier loss: 0.442490; batch adversarial loss: 0.634811\n",
      "epoch 2; iter: 600; batch classifier loss: 1.209536; batch adversarial loss: 0.646362\n",
      "epoch 3; iter: 0; batch classifier loss: 0.826292; batch adversarial loss: 0.600839\n",
      "epoch 3; iter: 200; batch classifier loss: 1.498107; batch adversarial loss: 0.597821\n",
      "epoch 3; iter: 400; batch classifier loss: 0.397534; batch adversarial loss: 0.613624\n",
      "epoch 3; iter: 600; batch classifier loss: 0.384471; batch adversarial loss: 0.625175\n",
      "epoch 4; iter: 0; batch classifier loss: 0.344631; batch adversarial loss: 0.574397\n",
      "epoch 4; iter: 200; batch classifier loss: 0.543907; batch adversarial loss: 0.664565\n",
      "epoch 4; iter: 400; batch classifier loss: 0.428493; batch adversarial loss: 0.653722\n",
      "epoch 4; iter: 600; batch classifier loss: 0.493677; batch adversarial loss: 0.617242\n",
      "epoch 5; iter: 0; batch classifier loss: 0.936799; batch adversarial loss: 0.592066\n",
      "epoch 5; iter: 200; batch classifier loss: 0.667387; batch adversarial loss: 0.573751\n",
      "epoch 5; iter: 400; batch classifier loss: 0.578698; batch adversarial loss: 0.601547\n",
      "epoch 5; iter: 600; batch classifier loss: 0.435432; batch adversarial loss: 0.619334\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598490; batch adversarial loss: 0.532915\n",
      "epoch 6; iter: 200; batch classifier loss: 0.457122; batch adversarial loss: 0.566625\n",
      "epoch 6; iter: 400; batch classifier loss: 0.408432; batch adversarial loss: 0.640986\n",
      "epoch 6; iter: 600; batch classifier loss: 0.553019; batch adversarial loss: 0.580483\n",
      "epoch 7; iter: 0; batch classifier loss: 0.438090; batch adversarial loss: 0.768069\n",
      "epoch 7; iter: 200; batch classifier loss: 0.399016; batch adversarial loss: 0.688650\n",
      "epoch 7; iter: 400; batch classifier loss: 0.456848; batch adversarial loss: 0.603639\n",
      "epoch 7; iter: 600; batch classifier loss: 0.362206; batch adversarial loss: 0.699296\n",
      "epoch 8; iter: 0; batch classifier loss: 0.306993; batch adversarial loss: 0.677651\n",
      "epoch 8; iter: 200; batch classifier loss: 0.502274; batch adversarial loss: 0.619835\n",
      "epoch 8; iter: 400; batch classifier loss: 0.441486; batch adversarial loss: 0.619108\n",
      "epoch 8; iter: 600; batch classifier loss: 0.300216; batch adversarial loss: 0.592018\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421607; batch adversarial loss: 0.631874\n",
      "epoch 9; iter: 200; batch classifier loss: 0.476831; batch adversarial loss: 0.651342\n",
      "epoch 9; iter: 400; batch classifier loss: 0.471059; batch adversarial loss: 0.580460\n",
      "epoch 9; iter: 600; batch classifier loss: 0.300205; batch adversarial loss: 0.679442\n",
      "epoch 0; iter: 0; batch classifier loss: 29.585035; batch adversarial loss: 1.044372\n",
      "epoch 0; iter: 200; batch classifier loss: 12.503940; batch adversarial loss: 0.835436\n",
      "epoch 0; iter: 400; batch classifier loss: 6.828284; batch adversarial loss: 0.716461\n",
      "epoch 0; iter: 600; batch classifier loss: 7.316171; batch adversarial loss: 0.689987\n",
      "epoch 1; iter: 0; batch classifier loss: 1.486392; batch adversarial loss: 0.636856\n",
      "epoch 1; iter: 200; batch classifier loss: 3.609535; batch adversarial loss: 0.706259\n",
      "epoch 1; iter: 400; batch classifier loss: 6.017668; batch adversarial loss: 0.568296\n",
      "epoch 1; iter: 600; batch classifier loss: 1.730225; batch adversarial loss: 0.573767\n",
      "epoch 2; iter: 0; batch classifier loss: 1.683590; batch adversarial loss: 0.615218\n",
      "epoch 2; iter: 200; batch classifier loss: 0.466585; batch adversarial loss: 0.647703\n",
      "epoch 2; iter: 400; batch classifier loss: 2.146430; batch adversarial loss: 0.627610\n",
      "epoch 2; iter: 600; batch classifier loss: 0.583235; batch adversarial loss: 0.589375\n",
      "epoch 3; iter: 0; batch classifier loss: 1.238609; batch adversarial loss: 0.517110\n",
      "epoch 3; iter: 200; batch classifier loss: 1.145699; batch adversarial loss: 0.609082\n",
      "epoch 3; iter: 400; batch classifier loss: 1.065283; batch adversarial loss: 0.576783\n",
      "epoch 3; iter: 600; batch classifier loss: 0.788187; batch adversarial loss: 0.628151\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532194; batch adversarial loss: 0.621662\n",
      "epoch 4; iter: 200; batch classifier loss: 0.890119; batch adversarial loss: 0.528063\n",
      "epoch 4; iter: 400; batch classifier loss: 0.591022; batch adversarial loss: 0.657941\n",
      "epoch 4; iter: 600; batch classifier loss: 0.288743; batch adversarial loss: 0.619589\n",
      "epoch 5; iter: 0; batch classifier loss: 0.366978; batch adversarial loss: 0.639639\n",
      "epoch 5; iter: 200; batch classifier loss: 0.518353; batch adversarial loss: 0.620905\n",
      "epoch 5; iter: 400; batch classifier loss: 0.358874; batch adversarial loss: 0.625702\n",
      "epoch 5; iter: 600; batch classifier loss: 0.579607; batch adversarial loss: 0.615551\n",
      "epoch 6; iter: 0; batch classifier loss: 0.297862; batch adversarial loss: 0.619587\n",
      "epoch 6; iter: 200; batch classifier loss: 0.385281; batch adversarial loss: 0.585838\n",
      "epoch 6; iter: 400; batch classifier loss: 0.406410; batch adversarial loss: 0.599531\n",
      "epoch 6; iter: 600; batch classifier loss: 0.355100; batch adversarial loss: 0.662960\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376973; batch adversarial loss: 0.545511\n",
      "epoch 7; iter: 200; batch classifier loss: 0.435052; batch adversarial loss: 0.577110\n",
      "epoch 7; iter: 400; batch classifier loss: 0.390327; batch adversarial loss: 0.555770\n",
      "epoch 7; iter: 600; batch classifier loss: 0.673637; batch adversarial loss: 0.583268\n",
      "epoch 8; iter: 0; batch classifier loss: 0.235710; batch adversarial loss: 0.676405\n",
      "epoch 8; iter: 200; batch classifier loss: 0.373412; batch adversarial loss: 0.699943\n",
      "epoch 8; iter: 400; batch classifier loss: 0.435536; batch adversarial loss: 0.588736\n",
      "epoch 8; iter: 600; batch classifier loss: 0.304111; batch adversarial loss: 0.645728\n",
      "epoch 9; iter: 0; batch classifier loss: 0.284339; batch adversarial loss: 0.618479\n",
      "epoch 9; iter: 200; batch classifier loss: 0.367865; batch adversarial loss: 0.614313\n",
      "epoch 9; iter: 400; batch classifier loss: 0.332301; batch adversarial loss: 0.691421\n",
      "epoch 9; iter: 600; batch classifier loss: 0.357394; batch adversarial loss: 0.628483\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.825252  0.523353 -0.029469  0.982186  0.212425  0.114293\n",
      "std   0.015477  0.105330  0.029749  0.857478  0.083782  0.045684\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedShuffleSplit, StratifiedKFold\n",
    "from src.metrics import best_hyperparameter_advdeb\n",
    "\n",
    "# 1) Retrieve data\n",
    "protected           = 'sex'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','sex')]\n",
    "\n",
    "# 2) Hyperparameter Search\n",
    "param_grid = {\n",
    "    'adversary_loss_weight': [0.5, 1.0],\n",
    "    'num_epochs':            [10, 20, 50],\n",
    "    'batch_size':            [64, 128]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "grid_results = []\n",
    "# Perform hyperparameter search with 15 stratified shuffle splits\n",
    "for params in grid:\n",
    "    print(f\"Testing config: {params}\")\n",
    "    fold_metrics = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=15, test_size=0.3, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            privileged_groups, unprivileged_groups,\n",
    "            scope_name='adv',\n",
    "            num_epochs=params['num_epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            adversary_loss_weight=params['adversary_loss_weight']\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "    \n",
    "    df_fm = pd.DataFrame(fold_metrics)\n",
    "    agg = df_fm.agg(['mean', 'std'])\n",
    "\n",
    "    grid_results.append({\n",
    "        **params,\n",
    "        'acc_mean':   agg.loc['mean', 'accuracy'],\n",
    "        'acc_std':    agg.loc['std',  'accuracy'],\n",
    "        'f1_mean':    agg.loc['mean', 'f1_score'],\n",
    "        'f1_std':     agg.loc['std',  'f1_score'],\n",
    "        'SPD_mean':   agg.loc['mean', 'SPD'],\n",
    "        'SPD_std':    agg.loc['std',  'SPD'],\n",
    "        'DI_mean':    agg.loc['mean', 'DI'],\n",
    "        'DI_std':     agg.loc['std',  'DI'],\n",
    "        'EOD_mean':   agg.loc['mean', 'EOD'],\n",
    "        'EOD_std':    agg.loc['std',  'EOD'],\n",
    "        'AOD_mean':   agg.loc['mean', 'AOD'],\n",
    "        'AOD_std':    agg.loc['std',  'AOD'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Hyperparameter Selection\n",
    "best_param = best_hyperparameter_advdeb(results_df)\n",
    "print(f\"Best parameters: {best_param}\")\n",
    "\n",
    "# Final evaluation with StratifiedKFold\n",
    "loss_weight = best_param['adversary_loss_weight']\n",
    "n_epochs    = int(best_param['num_epochs'])\n",
    "batch_sz    = int(best_param['batch_size'])\n",
    "\n",
    "# 4) Run experiment, Evaluate\n",
    "results = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        privileged_groups, unprivileged_groups,\n",
    "        scope_name='adv',\n",
    "        num_epochs=n_epochs,\n",
    "        batch_size=batch_sz,\n",
    "        adversary_loss_weight=loss_weight\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 5) Aggregate results\n",
    "adult_sex_metrics       = pd.DataFrame(results)\n",
    "adult_sex_metrics_agg   = adult_sex_metrics.agg(['mean','std'])\n",
    "print(adult_sex_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2435e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', 'Hyperparametertuned Adversial Debiasing Adult: Baseline - Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d97e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
