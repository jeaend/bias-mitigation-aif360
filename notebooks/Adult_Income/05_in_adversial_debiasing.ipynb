{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53b8bcc",
   "metadata": {},
   "source": [
    "## Inprocessing - Adversial Debiasing  -  Compas Model\n",
    "- for 'sex' and 'race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a779c2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import reset_default_graph\n",
    "import pandas as pd\n",
    "from src.data_loading import load_adult_sex, load_adult_race\n",
    "from src.modeling import adversial_debiasing_train_and_predict\n",
    "from src.metrics import compute_metrics, compare_viz_metrics_2x3\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e287ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_race_agg = pd.read_csv('../../reports/baseline_agg/adult_race_metrics_agg.csv', index_col=0)\n",
    "baseline_sex_agg = pd.read_csv('../../reports/baseline_agg/adult_sex_metrics_agg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec69a2",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785d3da",
   "metadata": {},
   "source": [
    "## default adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efb8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 21:32:46.427504: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 16.681690; batch adversarial loss: 0.900612\n",
      "epoch 0; iter: 200; batch classifier loss: 2.634743; batch adversarial loss: 0.750224\n",
      "epoch 1; iter: 0; batch classifier loss: 5.411049; batch adversarial loss: 0.725157\n",
      "epoch 1; iter: 200; batch classifier loss: 2.225876; batch adversarial loss: 0.618025\n",
      "epoch 2; iter: 0; batch classifier loss: 1.619228; batch adversarial loss: 0.592903\n",
      "epoch 2; iter: 200; batch classifier loss: 3.601415; batch adversarial loss: 0.512157\n",
      "epoch 3; iter: 0; batch classifier loss: 2.465281; batch adversarial loss: 0.510030\n",
      "epoch 3; iter: 200; batch classifier loss: 0.663907; batch adversarial loss: 0.492371\n",
      "epoch 4; iter: 0; batch classifier loss: 2.034355; batch adversarial loss: 0.519680\n",
      "epoch 4; iter: 200; batch classifier loss: 1.923033; batch adversarial loss: 0.507665\n",
      "epoch 5; iter: 0; batch classifier loss: 1.307237; batch adversarial loss: 0.410921\n",
      "epoch 5; iter: 200; batch classifier loss: 1.132911; batch adversarial loss: 0.504795\n",
      "epoch 6; iter: 0; batch classifier loss: 0.831949; batch adversarial loss: 0.483430\n",
      "epoch 6; iter: 200; batch classifier loss: 1.748787; batch adversarial loss: 0.391698\n",
      "epoch 7; iter: 0; batch classifier loss: 0.412534; batch adversarial loss: 0.356514\n",
      "epoch 7; iter: 200; batch classifier loss: 0.519256; batch adversarial loss: 0.427870\n",
      "epoch 8; iter: 0; batch classifier loss: 0.411044; batch adversarial loss: 0.334553\n",
      "epoch 8; iter: 200; batch classifier loss: 0.578410; batch adversarial loss: 0.327218\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381506; batch adversarial loss: 0.380652\n",
      "epoch 9; iter: 200; batch classifier loss: 0.455886; batch adversarial loss: 0.366257\n",
      "epoch 10; iter: 0; batch classifier loss: 0.630338; batch adversarial loss: 0.414442\n",
      "epoch 10; iter: 200; batch classifier loss: 0.486617; batch adversarial loss: 0.457335\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424447; batch adversarial loss: 0.458598\n",
      "epoch 11; iter: 200; batch classifier loss: 0.393068; batch adversarial loss: 0.469583\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407040; batch adversarial loss: 0.351286\n",
      "epoch 12; iter: 200; batch classifier loss: 0.706690; batch adversarial loss: 0.384774\n",
      "epoch 13; iter: 0; batch classifier loss: 0.393826; batch adversarial loss: 0.372022\n",
      "epoch 13; iter: 200; batch classifier loss: 0.328190; batch adversarial loss: 0.343322\n",
      "epoch 14; iter: 0; batch classifier loss: 0.464287; batch adversarial loss: 0.465731\n",
      "epoch 14; iter: 200; batch classifier loss: 0.321298; batch adversarial loss: 0.393239\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362652; batch adversarial loss: 0.389208\n",
      "epoch 15; iter: 200; batch classifier loss: 0.412998; batch adversarial loss: 0.398093\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379274; batch adversarial loss: 0.400867\n",
      "epoch 16; iter: 200; batch classifier loss: 0.351012; batch adversarial loss: 0.299663\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409841; batch adversarial loss: 0.333656\n",
      "epoch 17; iter: 200; batch classifier loss: 0.256250; batch adversarial loss: 0.388015\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354539; batch adversarial loss: 0.373220\n",
      "epoch 18; iter: 200; batch classifier loss: 0.343222; batch adversarial loss: 0.465141\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322311; batch adversarial loss: 0.374961\n",
      "epoch 19; iter: 200; batch classifier loss: 0.300987; batch adversarial loss: 0.420186\n",
      "epoch 20; iter: 0; batch classifier loss: 0.377985; batch adversarial loss: 0.402230\n",
      "epoch 20; iter: 200; batch classifier loss: 0.425795; batch adversarial loss: 0.371728\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388896; batch adversarial loss: 0.393964\n",
      "epoch 21; iter: 200; batch classifier loss: 0.367648; batch adversarial loss: 0.316076\n",
      "epoch 22; iter: 0; batch classifier loss: 0.257779; batch adversarial loss: 0.502873\n",
      "epoch 22; iter: 200; batch classifier loss: 0.277631; batch adversarial loss: 0.378454\n",
      "epoch 23; iter: 0; batch classifier loss: 0.307926; batch adversarial loss: 0.433727\n",
      "epoch 23; iter: 200; batch classifier loss: 0.296119; batch adversarial loss: 0.431290\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303270; batch adversarial loss: 0.464866\n",
      "epoch 24; iter: 200; batch classifier loss: 0.328110; batch adversarial loss: 0.446012\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311207; batch adversarial loss: 0.457944\n",
      "epoch 25; iter: 200; batch classifier loss: 0.396162; batch adversarial loss: 0.414511\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338562; batch adversarial loss: 0.388737\n",
      "epoch 26; iter: 200; batch classifier loss: 0.329018; batch adversarial loss: 0.461254\n",
      "epoch 27; iter: 0; batch classifier loss: 0.365139; batch adversarial loss: 0.412401\n",
      "epoch 27; iter: 200; batch classifier loss: 0.336755; batch adversarial loss: 0.351738\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352131; batch adversarial loss: 0.388606\n",
      "epoch 28; iter: 200; batch classifier loss: 0.343863; batch adversarial loss: 0.491360\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320812; batch adversarial loss: 0.503632\n",
      "epoch 29; iter: 200; batch classifier loss: 0.289848; batch adversarial loss: 0.417219\n",
      "epoch 30; iter: 0; batch classifier loss: 0.385427; batch adversarial loss: 0.349030\n",
      "epoch 30; iter: 200; batch classifier loss: 0.284767; batch adversarial loss: 0.349092\n",
      "epoch 31; iter: 0; batch classifier loss: 0.392968; batch adversarial loss: 0.383026\n",
      "epoch 31; iter: 200; batch classifier loss: 0.414943; batch adversarial loss: 0.552805\n",
      "epoch 32; iter: 0; batch classifier loss: 0.334083; batch adversarial loss: 0.435776\n",
      "epoch 32; iter: 200; batch classifier loss: 0.352824; batch adversarial loss: 0.474715\n",
      "epoch 33; iter: 0; batch classifier loss: 0.268301; batch adversarial loss: 0.371038\n",
      "epoch 33; iter: 200; batch classifier loss: 0.392112; batch adversarial loss: 0.392703\n",
      "epoch 34; iter: 0; batch classifier loss: 0.351122; batch adversarial loss: 0.483282\n",
      "epoch 34; iter: 200; batch classifier loss: 0.377723; batch adversarial loss: 0.461472\n",
      "epoch 35; iter: 0; batch classifier loss: 0.391908; batch adversarial loss: 0.432608\n",
      "epoch 35; iter: 200; batch classifier loss: 0.367477; batch adversarial loss: 0.506712\n",
      "epoch 36; iter: 0; batch classifier loss: 0.273572; batch adversarial loss: 0.283718\n",
      "epoch 36; iter: 200; batch classifier loss: 0.379849; batch adversarial loss: 0.448086\n",
      "epoch 37; iter: 0; batch classifier loss: 0.354407; batch adversarial loss: 0.403570\n",
      "epoch 37; iter: 200; batch classifier loss: 0.275577; batch adversarial loss: 0.418773\n",
      "epoch 38; iter: 0; batch classifier loss: 0.336309; batch adversarial loss: 0.454737\n",
      "epoch 38; iter: 200; batch classifier loss: 0.327179; batch adversarial loss: 0.441831\n",
      "epoch 39; iter: 0; batch classifier loss: 0.301463; batch adversarial loss: 0.425230\n",
      "epoch 39; iter: 200; batch classifier loss: 0.277123; batch adversarial loss: 0.410207\n",
      "epoch 40; iter: 0; batch classifier loss: 0.472716; batch adversarial loss: 0.409344\n",
      "epoch 40; iter: 200; batch classifier loss: 0.328634; batch adversarial loss: 0.402699\n",
      "epoch 41; iter: 0; batch classifier loss: 0.319221; batch adversarial loss: 0.387206\n",
      "epoch 41; iter: 200; batch classifier loss: 0.368068; batch adversarial loss: 0.441570\n",
      "epoch 42; iter: 0; batch classifier loss: 0.312268; batch adversarial loss: 0.517196\n",
      "epoch 42; iter: 200; batch classifier loss: 0.250341; batch adversarial loss: 0.391110\n",
      "epoch 43; iter: 0; batch classifier loss: 0.349907; batch adversarial loss: 0.306263\n",
      "epoch 43; iter: 200; batch classifier loss: 0.300431; batch adversarial loss: 0.407357\n",
      "epoch 44; iter: 0; batch classifier loss: 0.315360; batch adversarial loss: 0.368016\n",
      "epoch 44; iter: 200; batch classifier loss: 0.320241; batch adversarial loss: 0.465670\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383761; batch adversarial loss: 0.454393\n",
      "epoch 45; iter: 200; batch classifier loss: 0.320751; batch adversarial loss: 0.401463\n",
      "epoch 46; iter: 0; batch classifier loss: 0.264333; batch adversarial loss: 0.514792\n",
      "epoch 46; iter: 200; batch classifier loss: 0.249365; batch adversarial loss: 0.430325\n",
      "epoch 47; iter: 0; batch classifier loss: 0.344770; batch adversarial loss: 0.279122\n",
      "epoch 47; iter: 200; batch classifier loss: 0.266092; batch adversarial loss: 0.553452\n",
      "epoch 48; iter: 0; batch classifier loss: 0.389797; batch adversarial loss: 0.329837\n",
      "epoch 48; iter: 200; batch classifier loss: 0.305630; batch adversarial loss: 0.540040\n",
      "epoch 49; iter: 0; batch classifier loss: 0.229381; batch adversarial loss: 0.385461\n",
      "epoch 49; iter: 200; batch classifier loss: 0.305960; batch adversarial loss: 0.340672\n",
      "epoch 0; iter: 0; batch classifier loss: 28.907257; batch adversarial loss: 0.473624\n",
      "epoch 0; iter: 200; batch classifier loss: 6.169736; batch adversarial loss: 0.536582\n",
      "epoch 1; iter: 0; batch classifier loss: 5.615822; batch adversarial loss: 0.514274\n",
      "epoch 1; iter: 200; batch classifier loss: 5.266359; batch adversarial loss: 0.547842\n",
      "epoch 2; iter: 0; batch classifier loss: 6.860864; batch adversarial loss: 0.477683\n",
      "epoch 2; iter: 200; batch classifier loss: 5.076104; batch adversarial loss: 0.490859\n",
      "epoch 3; iter: 0; batch classifier loss: 1.932605; batch adversarial loss: 0.455293\n",
      "epoch 3; iter: 200; batch classifier loss: 4.952918; batch adversarial loss: 0.436367\n",
      "epoch 4; iter: 0; batch classifier loss: 6.554148; batch adversarial loss: 0.410378\n",
      "epoch 4; iter: 200; batch classifier loss: 1.790512; batch adversarial loss: 0.432476\n",
      "epoch 5; iter: 0; batch classifier loss: 0.879523; batch adversarial loss: 0.432796\n",
      "epoch 5; iter: 200; batch classifier loss: 1.042341; batch adversarial loss: 0.427338\n",
      "epoch 6; iter: 0; batch classifier loss: 3.938960; batch adversarial loss: 0.533420\n",
      "epoch 6; iter: 200; batch classifier loss: 1.194947; batch adversarial loss: 0.365603\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563952; batch adversarial loss: 0.379672\n",
      "epoch 7; iter: 200; batch classifier loss: 0.488938; batch adversarial loss: 0.497204\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558924; batch adversarial loss: 0.420368\n",
      "epoch 8; iter: 200; batch classifier loss: 0.428094; batch adversarial loss: 0.499192\n",
      "epoch 9; iter: 0; batch classifier loss: 0.578883; batch adversarial loss: 0.383766\n",
      "epoch 9; iter: 200; batch classifier loss: 0.449782; batch adversarial loss: 0.389411\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516580; batch adversarial loss: 0.474820\n",
      "epoch 10; iter: 200; batch classifier loss: 0.354805; batch adversarial loss: 0.384394\n",
      "epoch 11; iter: 0; batch classifier loss: 0.795518; batch adversarial loss: 0.307143\n",
      "epoch 11; iter: 200; batch classifier loss: 0.357426; batch adversarial loss: 0.431906\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390160; batch adversarial loss: 0.461986\n",
      "epoch 12; iter: 200; batch classifier loss: 0.316563; batch adversarial loss: 0.349620\n",
      "epoch 13; iter: 0; batch classifier loss: 0.433642; batch adversarial loss: 0.334509\n",
      "epoch 13; iter: 200; batch classifier loss: 0.269634; batch adversarial loss: 0.431724\n",
      "epoch 14; iter: 0; batch classifier loss: 0.287691; batch adversarial loss: 0.438638\n",
      "epoch 14; iter: 200; batch classifier loss: 0.339136; batch adversarial loss: 0.407642\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268967; batch adversarial loss: 0.487070\n",
      "epoch 15; iter: 200; batch classifier loss: 0.364928; batch adversarial loss: 0.526223\n",
      "epoch 16; iter: 0; batch classifier loss: 0.360513; batch adversarial loss: 0.472161\n",
      "epoch 16; iter: 200; batch classifier loss: 0.375761; batch adversarial loss: 0.362359\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317249; batch adversarial loss: 0.444850\n",
      "epoch 17; iter: 200; batch classifier loss: 0.412533; batch adversarial loss: 0.412185\n",
      "epoch 18; iter: 0; batch classifier loss: 0.407459; batch adversarial loss: 0.402947\n",
      "epoch 18; iter: 200; batch classifier loss: 0.335941; batch adversarial loss: 0.442849\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355935; batch adversarial loss: 0.456919\n",
      "epoch 19; iter: 200; batch classifier loss: 0.368667; batch adversarial loss: 0.399639\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387935; batch adversarial loss: 0.398726\n",
      "epoch 20; iter: 200; batch classifier loss: 0.326232; batch adversarial loss: 0.500991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311514; batch adversarial loss: 0.296855\n",
      "epoch 21; iter: 200; batch classifier loss: 0.255884; batch adversarial loss: 0.402777\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305408; batch adversarial loss: 0.514168\n",
      "epoch 22; iter: 200; batch classifier loss: 0.312900; batch adversarial loss: 0.371936\n",
      "epoch 23; iter: 0; batch classifier loss: 0.366491; batch adversarial loss: 0.392532\n",
      "epoch 23; iter: 200; batch classifier loss: 0.319414; batch adversarial loss: 0.349399\n",
      "epoch 24; iter: 0; batch classifier loss: 0.358555; batch adversarial loss: 0.384390\n",
      "epoch 24; iter: 200; batch classifier loss: 0.315934; batch adversarial loss: 0.455042\n",
      "epoch 25; iter: 0; batch classifier loss: 0.350342; batch adversarial loss: 0.364984\n",
      "epoch 25; iter: 200; batch classifier loss: 0.324192; batch adversarial loss: 0.368110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.379203; batch adversarial loss: 0.436602\n",
      "epoch 26; iter: 200; batch classifier loss: 0.274637; batch adversarial loss: 0.464835\n",
      "epoch 27; iter: 0; batch classifier loss: 0.289365; batch adversarial loss: 0.565957\n",
      "epoch 27; iter: 200; batch classifier loss: 0.398873; batch adversarial loss: 0.398777\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267669; batch adversarial loss: 0.369083\n",
      "epoch 28; iter: 200; batch classifier loss: 0.348579; batch adversarial loss: 0.381132\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419596; batch adversarial loss: 0.395470\n",
      "epoch 29; iter: 200; batch classifier loss: 0.354715; batch adversarial loss: 0.361846\n",
      "epoch 30; iter: 0; batch classifier loss: 0.301736; batch adversarial loss: 0.341330\n",
      "epoch 30; iter: 200; batch classifier loss: 0.343011; batch adversarial loss: 0.376679\n",
      "epoch 31; iter: 0; batch classifier loss: 0.478166; batch adversarial loss: 0.409029\n",
      "epoch 31; iter: 200; batch classifier loss: 0.287801; batch adversarial loss: 0.441109\n",
      "epoch 32; iter: 0; batch classifier loss: 0.389226; batch adversarial loss: 0.409810\n",
      "epoch 32; iter: 200; batch classifier loss: 0.275018; batch adversarial loss: 0.414433\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355909; batch adversarial loss: 0.400316\n",
      "epoch 33; iter: 200; batch classifier loss: 0.320434; batch adversarial loss: 0.518946\n",
      "epoch 34; iter: 0; batch classifier loss: 0.397577; batch adversarial loss: 0.433603\n",
      "epoch 34; iter: 200; batch classifier loss: 0.385879; batch adversarial loss: 0.458483\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392589; batch adversarial loss: 0.343971\n",
      "epoch 35; iter: 200; batch classifier loss: 0.425384; batch adversarial loss: 0.546185\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368180; batch adversarial loss: 0.405333\n",
      "epoch 36; iter: 200; batch classifier loss: 0.517995; batch adversarial loss: 0.350447\n",
      "epoch 37; iter: 0; batch classifier loss: 0.308660; batch adversarial loss: 0.426941\n",
      "epoch 37; iter: 200; batch classifier loss: 0.376882; batch adversarial loss: 0.561165\n",
      "epoch 38; iter: 0; batch classifier loss: 0.374194; batch adversarial loss: 0.486287\n",
      "epoch 38; iter: 200; batch classifier loss: 0.492893; batch adversarial loss: 0.305683\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455338; batch adversarial loss: 0.437028\n",
      "epoch 39; iter: 200; batch classifier loss: 0.325032; batch adversarial loss: 0.334309\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411135; batch adversarial loss: 0.328201\n",
      "epoch 40; iter: 200; batch classifier loss: 0.574583; batch adversarial loss: 0.431708\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407095; batch adversarial loss: 0.433487\n",
      "epoch 41; iter: 200; batch classifier loss: 0.439796; batch adversarial loss: 0.390548\n",
      "epoch 42; iter: 0; batch classifier loss: 0.345722; batch adversarial loss: 0.321894\n",
      "epoch 42; iter: 200; batch classifier loss: 0.431983; batch adversarial loss: 0.452612\n",
      "epoch 43; iter: 0; batch classifier loss: 0.368571; batch adversarial loss: 0.438820\n",
      "epoch 43; iter: 200; batch classifier loss: 0.423620; batch adversarial loss: 0.469586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474221; batch adversarial loss: 0.430306\n",
      "epoch 44; iter: 200; batch classifier loss: 0.469389; batch adversarial loss: 0.321376\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479246; batch adversarial loss: 0.403474\n",
      "epoch 45; iter: 200; batch classifier loss: 0.474669; batch adversarial loss: 0.405467\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401486; batch adversarial loss: 0.459515\n",
      "epoch 46; iter: 200; batch classifier loss: 0.470023; batch adversarial loss: 0.472853\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522782; batch adversarial loss: 0.350420\n",
      "epoch 47; iter: 200; batch classifier loss: 0.369436; batch adversarial loss: 0.435734\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427914; batch adversarial loss: 0.430764\n",
      "epoch 48; iter: 200; batch classifier loss: 0.420541; batch adversarial loss: 0.397126\n",
      "epoch 49; iter: 0; batch classifier loss: 0.427933; batch adversarial loss: 0.373837\n",
      "epoch 49; iter: 200; batch classifier loss: 0.452086; batch adversarial loss: 0.371530\n",
      "epoch 0; iter: 0; batch classifier loss: 63.428314; batch adversarial loss: 0.757680\n",
      "epoch 0; iter: 200; batch classifier loss: 7.804418; batch adversarial loss: 0.653453\n",
      "epoch 1; iter: 0; batch classifier loss: 1.046862; batch adversarial loss: 0.625299\n",
      "epoch 1; iter: 200; batch classifier loss: 6.868276; batch adversarial loss: 0.569598\n",
      "epoch 2; iter: 0; batch classifier loss: 10.714100; batch adversarial loss: 0.566526\n",
      "epoch 2; iter: 200; batch classifier loss: 8.243145; batch adversarial loss: 0.517242\n",
      "epoch 3; iter: 0; batch classifier loss: 7.163853; batch adversarial loss: 0.507161\n",
      "epoch 3; iter: 200; batch classifier loss: 3.143012; batch adversarial loss: 0.442790\n",
      "epoch 4; iter: 0; batch classifier loss: 2.869006; batch adversarial loss: 0.471130\n",
      "epoch 4; iter: 200; batch classifier loss: 1.633284; batch adversarial loss: 0.459743\n",
      "epoch 5; iter: 0; batch classifier loss: 0.919198; batch adversarial loss: 0.427047\n",
      "epoch 5; iter: 200; batch classifier loss: 1.256111; batch adversarial loss: 0.476792\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641916; batch adversarial loss: 0.388294\n",
      "epoch 6; iter: 200; batch classifier loss: 1.873243; batch adversarial loss: 0.459763\n",
      "epoch 7; iter: 0; batch classifier loss: 0.879998; batch adversarial loss: 0.456301\n",
      "epoch 7; iter: 200; batch classifier loss: 0.439321; batch adversarial loss: 0.495508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491223; batch adversarial loss: 0.373516\n",
      "epoch 8; iter: 200; batch classifier loss: 0.523713; batch adversarial loss: 0.382438\n",
      "epoch 9; iter: 0; batch classifier loss: 0.953493; batch adversarial loss: 0.350158\n",
      "epoch 9; iter: 200; batch classifier loss: 0.430401; batch adversarial loss: 0.404976\n",
      "epoch 10; iter: 0; batch classifier loss: 0.475568; batch adversarial loss: 0.357312\n",
      "epoch 10; iter: 200; batch classifier loss: 0.332722; batch adversarial loss: 0.413215\n",
      "epoch 11; iter: 0; batch classifier loss: 1.312874; batch adversarial loss: 0.341474\n",
      "epoch 11; iter: 200; batch classifier loss: 0.364960; batch adversarial loss: 0.395734\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356166; batch adversarial loss: 0.348017\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432659; batch adversarial loss: 0.392751\n",
      "epoch 13; iter: 0; batch classifier loss: 0.415405; batch adversarial loss: 0.508846\n",
      "epoch 13; iter: 200; batch classifier loss: 0.325944; batch adversarial loss: 0.455059\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297218; batch adversarial loss: 0.452343\n",
      "epoch 14; iter: 200; batch classifier loss: 0.298654; batch adversarial loss: 0.414000\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363441; batch adversarial loss: 0.343964\n",
      "epoch 15; iter: 200; batch classifier loss: 0.372086; batch adversarial loss: 0.357809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.717923; batch adversarial loss: 0.495954\n",
      "epoch 16; iter: 200; batch classifier loss: 0.397679; batch adversarial loss: 0.432242\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377742; batch adversarial loss: 0.288559\n",
      "epoch 17; iter: 200; batch classifier loss: 0.340401; batch adversarial loss: 0.476047\n",
      "epoch 18; iter: 0; batch classifier loss: 0.425183; batch adversarial loss: 0.422997\n",
      "epoch 18; iter: 200; batch classifier loss: 0.348679; batch adversarial loss: 0.400281\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337333; batch adversarial loss: 0.411624\n",
      "epoch 19; iter: 200; batch classifier loss: 0.275482; batch adversarial loss: 0.356892\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446572; batch adversarial loss: 0.445596\n",
      "epoch 20; iter: 200; batch classifier loss: 0.381001; batch adversarial loss: 0.359637\n",
      "epoch 21; iter: 0; batch classifier loss: 0.337890; batch adversarial loss: 0.334266\n",
      "epoch 21; iter: 200; batch classifier loss: 0.340285; batch adversarial loss: 0.368556\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305704; batch adversarial loss: 0.507083\n",
      "epoch 22; iter: 200; batch classifier loss: 0.380168; batch adversarial loss: 0.429268\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381132; batch adversarial loss: 0.431598\n",
      "epoch 23; iter: 200; batch classifier loss: 0.276680; batch adversarial loss: 0.343731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.295293; batch adversarial loss: 0.388529\n",
      "epoch 24; iter: 200; batch classifier loss: 0.359785; batch adversarial loss: 0.390048\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270827; batch adversarial loss: 0.499268\n",
      "epoch 25; iter: 200; batch classifier loss: 0.330726; batch adversarial loss: 0.399096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.291119; batch adversarial loss: 0.400968\n",
      "epoch 26; iter: 200; batch classifier loss: 0.287865; batch adversarial loss: 0.424078\n",
      "epoch 27; iter: 0; batch classifier loss: 0.353227; batch adversarial loss: 0.333138\n",
      "epoch 27; iter: 200; batch classifier loss: 0.292621; batch adversarial loss: 0.384798\n",
      "epoch 28; iter: 0; batch classifier loss: 0.261182; batch adversarial loss: 0.517530\n",
      "epoch 28; iter: 200; batch classifier loss: 0.375164; batch adversarial loss: 0.380191\n",
      "epoch 29; iter: 0; batch classifier loss: 0.352311; batch adversarial loss: 0.442041\n",
      "epoch 29; iter: 200; batch classifier loss: 0.429858; batch adversarial loss: 0.459376\n",
      "epoch 30; iter: 0; batch classifier loss: 0.339516; batch adversarial loss: 0.426357\n",
      "epoch 30; iter: 200; batch classifier loss: 0.355912; batch adversarial loss: 0.459177\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433016; batch adversarial loss: 0.398577\n",
      "epoch 31; iter: 200; batch classifier loss: 0.250639; batch adversarial loss: 0.400725\n",
      "epoch 32; iter: 0; batch classifier loss: 0.380275; batch adversarial loss: 0.419814\n",
      "epoch 32; iter: 200; batch classifier loss: 0.295001; batch adversarial loss: 0.366096\n",
      "epoch 33; iter: 0; batch classifier loss: 0.322264; batch adversarial loss: 0.456763\n",
      "epoch 33; iter: 200; batch classifier loss: 0.334422; batch adversarial loss: 0.390935\n",
      "epoch 34; iter: 0; batch classifier loss: 0.337625; batch adversarial loss: 0.405798\n",
      "epoch 34; iter: 200; batch classifier loss: 0.294158; batch adversarial loss: 0.436561\n",
      "epoch 35; iter: 0; batch classifier loss: 0.353865; batch adversarial loss: 0.444234\n",
      "epoch 35; iter: 200; batch classifier loss: 0.324802; batch adversarial loss: 0.407727\n",
      "epoch 36; iter: 0; batch classifier loss: 0.409146; batch adversarial loss: 0.393859\n",
      "epoch 36; iter: 200; batch classifier loss: 0.302575; batch adversarial loss: 0.402444\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383806; batch adversarial loss: 0.361812\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341932; batch adversarial loss: 0.497674\n",
      "epoch 38; iter: 0; batch classifier loss: 0.324689; batch adversarial loss: 0.345279\n",
      "epoch 38; iter: 200; batch classifier loss: 0.355492; batch adversarial loss: 0.342428\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421343; batch adversarial loss: 0.414829\n",
      "epoch 39; iter: 200; batch classifier loss: 0.308877; batch adversarial loss: 0.409316\n",
      "epoch 40; iter: 0; batch classifier loss: 0.316406; batch adversarial loss: 0.429168\n",
      "epoch 40; iter: 200; batch classifier loss: 0.370079; batch adversarial loss: 0.441605\n",
      "epoch 41; iter: 0; batch classifier loss: 0.353760; batch adversarial loss: 0.354055\n",
      "epoch 41; iter: 200; batch classifier loss: 0.350448; batch adversarial loss: 0.357185\n",
      "epoch 42; iter: 0; batch classifier loss: 0.318269; batch adversarial loss: 0.509434\n",
      "epoch 42; iter: 200; batch classifier loss: 0.365829; batch adversarial loss: 0.432055\n",
      "epoch 43; iter: 0; batch classifier loss: 0.251741; batch adversarial loss: 0.460767\n",
      "epoch 43; iter: 200; batch classifier loss: 0.295531; batch adversarial loss: 0.442448\n",
      "epoch 44; iter: 0; batch classifier loss: 0.346359; batch adversarial loss: 0.375743\n",
      "epoch 44; iter: 200; batch classifier loss: 0.316572; batch adversarial loss: 0.403726\n",
      "epoch 45; iter: 0; batch classifier loss: 0.308785; batch adversarial loss: 0.398222\n",
      "epoch 45; iter: 200; batch classifier loss: 0.405071; batch adversarial loss: 0.327996\n",
      "epoch 46; iter: 0; batch classifier loss: 0.399063; batch adversarial loss: 0.358793\n",
      "epoch 46; iter: 200; batch classifier loss: 0.307956; batch adversarial loss: 0.446975\n",
      "epoch 47; iter: 0; batch classifier loss: 0.558523; batch adversarial loss: 0.453891\n",
      "epoch 47; iter: 200; batch classifier loss: 0.378873; batch adversarial loss: 0.395446\n",
      "epoch 48; iter: 0; batch classifier loss: 0.310019; batch adversarial loss: 0.412018\n",
      "epoch 48; iter: 200; batch classifier loss: 0.505657; batch adversarial loss: 0.436317\n",
      "epoch 49; iter: 0; batch classifier loss: 0.362872; batch adversarial loss: 0.420961\n",
      "epoch 49; iter: 200; batch classifier loss: 0.412800; batch adversarial loss: 0.405920\n",
      "epoch 0; iter: 0; batch classifier loss: 169.685471; batch adversarial loss: 0.683419\n",
      "epoch 0; iter: 200; batch classifier loss: 5.623796; batch adversarial loss: 0.618860\n",
      "epoch 1; iter: 0; batch classifier loss: 19.067780; batch adversarial loss: 0.565405\n",
      "epoch 1; iter: 200; batch classifier loss: 3.584317; batch adversarial loss: 0.517251\n",
      "epoch 2; iter: 0; batch classifier loss: 3.054520; batch adversarial loss: 0.562136\n",
      "epoch 2; iter: 200; batch classifier loss: 4.734926; batch adversarial loss: 0.478031\n",
      "epoch 3; iter: 0; batch classifier loss: 4.547232; batch adversarial loss: 0.482984\n",
      "epoch 3; iter: 200; batch classifier loss: 2.998507; batch adversarial loss: 0.464999\n",
      "epoch 4; iter: 0; batch classifier loss: 3.675810; batch adversarial loss: 0.424082\n",
      "epoch 4; iter: 200; batch classifier loss: 1.513412; batch adversarial loss: 0.410161\n",
      "epoch 5; iter: 0; batch classifier loss: 4.151396; batch adversarial loss: 0.386381\n",
      "epoch 5; iter: 200; batch classifier loss: 2.257125; batch adversarial loss: 0.358577\n",
      "epoch 6; iter: 0; batch classifier loss: 1.750065; batch adversarial loss: 0.340950\n",
      "epoch 6; iter: 200; batch classifier loss: 1.098645; batch adversarial loss: 0.413817\n",
      "epoch 7; iter: 0; batch classifier loss: 0.722698; batch adversarial loss: 0.439553\n",
      "epoch 7; iter: 200; batch classifier loss: 0.985722; batch adversarial loss: 0.334968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500799; batch adversarial loss: 0.459052\n",
      "epoch 8; iter: 200; batch classifier loss: 0.552183; batch adversarial loss: 0.317007\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458468; batch adversarial loss: 0.465543\n",
      "epoch 9; iter: 200; batch classifier loss: 0.392587; batch adversarial loss: 0.364760\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422345; batch adversarial loss: 0.434543\n",
      "epoch 10; iter: 200; batch classifier loss: 0.348372; batch adversarial loss: 0.419311\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459991; batch adversarial loss: 0.467414\n",
      "epoch 11; iter: 200; batch classifier loss: 0.463471; batch adversarial loss: 0.402862\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329200; batch adversarial loss: 0.485834\n",
      "epoch 12; iter: 200; batch classifier loss: 0.371010; batch adversarial loss: 0.468531\n",
      "epoch 13; iter: 0; batch classifier loss: 0.310801; batch adversarial loss: 0.461467\n",
      "epoch 13; iter: 200; batch classifier loss: 0.369443; batch adversarial loss: 0.475035\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265014; batch adversarial loss: 0.359893\n",
      "epoch 14; iter: 200; batch classifier loss: 0.373761; batch adversarial loss: 0.577405\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363987; batch adversarial loss: 0.410459\n",
      "epoch 15; iter: 200; batch classifier loss: 0.377596; batch adversarial loss: 0.465355\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382339; batch adversarial loss: 0.464911\n",
      "epoch 16; iter: 200; batch classifier loss: 0.410163; batch adversarial loss: 0.399209\n",
      "epoch 17; iter: 0; batch classifier loss: 0.307515; batch adversarial loss: 0.478585\n",
      "epoch 17; iter: 200; batch classifier loss: 0.316311; batch adversarial loss: 0.352326\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323727; batch adversarial loss: 0.460422\n",
      "epoch 18; iter: 200; batch classifier loss: 0.299944; batch adversarial loss: 0.467649\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307992; batch adversarial loss: 0.489498\n",
      "epoch 19; iter: 200; batch classifier loss: 0.405353; batch adversarial loss: 0.383940\n",
      "epoch 20; iter: 0; batch classifier loss: 0.319567; batch adversarial loss: 0.415153\n",
      "epoch 20; iter: 200; batch classifier loss: 0.362750; batch adversarial loss: 0.377908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387028; batch adversarial loss: 0.432315\n",
      "epoch 21; iter: 200; batch classifier loss: 0.405000; batch adversarial loss: 0.420103\n",
      "epoch 22; iter: 0; batch classifier loss: 0.424508; batch adversarial loss: 0.438977\n",
      "epoch 22; iter: 200; batch classifier loss: 0.341809; batch adversarial loss: 0.359919\n",
      "epoch 23; iter: 0; batch classifier loss: 0.357356; batch adversarial loss: 0.343180\n",
      "epoch 23; iter: 200; batch classifier loss: 0.260612; batch adversarial loss: 0.405332\n",
      "epoch 24; iter: 0; batch classifier loss: 0.326633; batch adversarial loss: 0.449000\n",
      "epoch 24; iter: 200; batch classifier loss: 0.377038; batch adversarial loss: 0.454547\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271191; batch adversarial loss: 0.404644\n",
      "epoch 25; iter: 200; batch classifier loss: 0.365888; batch adversarial loss: 0.440526\n",
      "epoch 26; iter: 0; batch classifier loss: 0.354015; batch adversarial loss: 0.455728\n",
      "epoch 26; iter: 200; batch classifier loss: 0.395939; batch adversarial loss: 0.547196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.283507; batch adversarial loss: 0.375778\n",
      "epoch 27; iter: 200; batch classifier loss: 0.359420; batch adversarial loss: 0.385749\n",
      "epoch 28; iter: 0; batch classifier loss: 0.423281; batch adversarial loss: 0.520104\n",
      "epoch 28; iter: 200; batch classifier loss: 0.347216; batch adversarial loss: 0.549431\n",
      "epoch 29; iter: 0; batch classifier loss: 0.342503; batch adversarial loss: 0.320683\n",
      "epoch 29; iter: 200; batch classifier loss: 0.329559; batch adversarial loss: 0.425535\n",
      "epoch 30; iter: 0; batch classifier loss: 0.373560; batch adversarial loss: 0.455170\n",
      "epoch 30; iter: 200; batch classifier loss: 0.403029; batch adversarial loss: 0.370919\n",
      "epoch 31; iter: 0; batch classifier loss: 0.357610; batch adversarial loss: 0.417983\n",
      "epoch 31; iter: 200; batch classifier loss: 0.246026; batch adversarial loss: 0.364773\n",
      "epoch 32; iter: 0; batch classifier loss: 0.359331; batch adversarial loss: 0.406501\n",
      "epoch 32; iter: 200; batch classifier loss: 0.468063; batch adversarial loss: 0.308343\n",
      "epoch 33; iter: 0; batch classifier loss: 0.349501; batch adversarial loss: 0.463149\n",
      "epoch 33; iter: 200; batch classifier loss: 0.269394; batch adversarial loss: 0.495676\n",
      "epoch 34; iter: 0; batch classifier loss: 0.287123; batch adversarial loss: 0.446522\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338384; batch adversarial loss: 0.461190\n",
      "epoch 35; iter: 0; batch classifier loss: 0.329818; batch adversarial loss: 0.312573\n",
      "epoch 35; iter: 200; batch classifier loss: 0.350781; batch adversarial loss: 0.450091\n",
      "epoch 36; iter: 0; batch classifier loss: 0.305542; batch adversarial loss: 0.440496\n",
      "epoch 36; iter: 200; batch classifier loss: 0.245742; batch adversarial loss: 0.381014\n",
      "epoch 37; iter: 0; batch classifier loss: 0.312506; batch adversarial loss: 0.456774\n",
      "epoch 37; iter: 200; batch classifier loss: 0.334423; batch adversarial loss: 0.487561\n",
      "epoch 38; iter: 0; batch classifier loss: 0.368245; batch adversarial loss: 0.363597\n",
      "epoch 38; iter: 200; batch classifier loss: 0.303749; batch adversarial loss: 0.347848\n",
      "epoch 39; iter: 0; batch classifier loss: 0.269618; batch adversarial loss: 0.427535\n",
      "epoch 39; iter: 200; batch classifier loss: 0.367150; batch adversarial loss: 0.420455\n",
      "epoch 40; iter: 0; batch classifier loss: 0.321990; batch adversarial loss: 0.417194\n",
      "epoch 40; iter: 200; batch classifier loss: 0.294414; batch adversarial loss: 0.404938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.307985; batch adversarial loss: 0.351300\n",
      "epoch 41; iter: 200; batch classifier loss: 0.401532; batch adversarial loss: 0.362632\n",
      "epoch 42; iter: 0; batch classifier loss: 0.342900; batch adversarial loss: 0.423981\n",
      "epoch 42; iter: 200; batch classifier loss: 0.295261; batch adversarial loss: 0.438276\n",
      "epoch 43; iter: 0; batch classifier loss: 0.343331; batch adversarial loss: 0.528467\n",
      "epoch 43; iter: 200; batch classifier loss: 0.420031; batch adversarial loss: 0.302801\n",
      "epoch 44; iter: 0; batch classifier loss: 0.367615; batch adversarial loss: 0.391913\n",
      "epoch 44; iter: 200; batch classifier loss: 0.336559; batch adversarial loss: 0.456011\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502938; batch adversarial loss: 0.458541\n",
      "epoch 45; iter: 200; batch classifier loss: 0.342509; batch adversarial loss: 0.322832\n",
      "epoch 46; iter: 0; batch classifier loss: 0.224714; batch adversarial loss: 0.423829\n",
      "epoch 46; iter: 200; batch classifier loss: 0.361169; batch adversarial loss: 0.395008\n",
      "epoch 47; iter: 0; batch classifier loss: 0.405693; batch adversarial loss: 0.352440\n",
      "epoch 47; iter: 200; batch classifier loss: 0.371096; batch adversarial loss: 0.307926\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335232; batch adversarial loss: 0.425488\n",
      "epoch 48; iter: 200; batch classifier loss: 0.300528; batch adversarial loss: 0.423896\n",
      "epoch 49; iter: 0; batch classifier loss: 0.340734; batch adversarial loss: 0.410253\n",
      "epoch 49; iter: 200; batch classifier loss: 0.393535; batch adversarial loss: 0.392086\n",
      "epoch 0; iter: 0; batch classifier loss: 17.527477; batch adversarial loss: 0.907705\n",
      "epoch 0; iter: 200; batch classifier loss: 4.669049; batch adversarial loss: 0.732172\n",
      "epoch 1; iter: 0; batch classifier loss: 5.348983; batch adversarial loss: 0.655927\n",
      "epoch 1; iter: 200; batch classifier loss: 9.484139; batch adversarial loss: 0.531329\n",
      "epoch 2; iter: 0; batch classifier loss: 6.522523; batch adversarial loss: 0.482380\n",
      "epoch 2; iter: 200; batch classifier loss: 2.772640; batch adversarial loss: 0.514070\n",
      "epoch 3; iter: 0; batch classifier loss: 1.330101; batch adversarial loss: 0.491603\n",
      "epoch 3; iter: 200; batch classifier loss: 0.712100; batch adversarial loss: 0.491111\n",
      "epoch 4; iter: 0; batch classifier loss: 4.512729; batch adversarial loss: 0.487548\n",
      "epoch 4; iter: 200; batch classifier loss: 16.098858; batch adversarial loss: 0.416278\n",
      "epoch 5; iter: 0; batch classifier loss: 1.162896; batch adversarial loss: 0.424529\n",
      "epoch 5; iter: 200; batch classifier loss: 3.703656; batch adversarial loss: 0.414036\n",
      "epoch 6; iter: 0; batch classifier loss: 0.452614; batch adversarial loss: 0.422684\n",
      "epoch 6; iter: 200; batch classifier loss: 2.413858; batch adversarial loss: 0.490894\n",
      "epoch 7; iter: 0; batch classifier loss: 0.716465; batch adversarial loss: 0.477617\n",
      "epoch 7; iter: 200; batch classifier loss: 0.555713; batch adversarial loss: 0.366176\n",
      "epoch 8; iter: 0; batch classifier loss: 0.987205; batch adversarial loss: 0.375403\n",
      "epoch 8; iter: 200; batch classifier loss: 0.463338; batch adversarial loss: 0.396976\n",
      "epoch 9; iter: 0; batch classifier loss: 0.397805; batch adversarial loss: 0.440893\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383442; batch adversarial loss: 0.392089\n",
      "epoch 10; iter: 0; batch classifier loss: 0.423835; batch adversarial loss: 0.430943\n",
      "epoch 10; iter: 200; batch classifier loss: 0.409887; batch adversarial loss: 0.493463\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514598; batch adversarial loss: 0.296208\n",
      "epoch 11; iter: 200; batch classifier loss: 0.469158; batch adversarial loss: 0.373297\n",
      "epoch 12; iter: 0; batch classifier loss: 0.366344; batch adversarial loss: 0.534655\n",
      "epoch 12; iter: 200; batch classifier loss: 0.341280; batch adversarial loss: 0.459417\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501584; batch adversarial loss: 0.451873\n",
      "epoch 13; iter: 200; batch classifier loss: 0.427239; batch adversarial loss: 0.383029\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376030; batch adversarial loss: 0.425928\n",
      "epoch 14; iter: 200; batch classifier loss: 0.311153; batch adversarial loss: 0.520077\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362227; batch adversarial loss: 0.495228\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392802; batch adversarial loss: 0.432726\n",
      "epoch 16; iter: 0; batch classifier loss: 0.325849; batch adversarial loss: 0.363759\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352104; batch adversarial loss: 0.311382\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459137; batch adversarial loss: 0.453446\n",
      "epoch 17; iter: 200; batch classifier loss: 0.335599; batch adversarial loss: 0.346577\n",
      "epoch 18; iter: 0; batch classifier loss: 0.260553; batch adversarial loss: 0.436428\n",
      "epoch 18; iter: 200; batch classifier loss: 0.375893; batch adversarial loss: 0.354444\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340646; batch adversarial loss: 0.365242\n",
      "epoch 19; iter: 200; batch classifier loss: 0.300911; batch adversarial loss: 0.461623\n",
      "epoch 20; iter: 0; batch classifier loss: 0.470115; batch adversarial loss: 0.362456\n",
      "epoch 20; iter: 200; batch classifier loss: 0.360637; batch adversarial loss: 0.358937\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352876; batch adversarial loss: 0.274044\n",
      "epoch 21; iter: 200; batch classifier loss: 0.434717; batch adversarial loss: 0.435012\n",
      "epoch 22; iter: 0; batch classifier loss: 0.369839; batch adversarial loss: 0.402129\n",
      "epoch 22; iter: 200; batch classifier loss: 0.380063; batch adversarial loss: 0.329949\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379966; batch adversarial loss: 0.483392\n",
      "epoch 23; iter: 200; batch classifier loss: 0.363252; batch adversarial loss: 0.398122\n",
      "epoch 24; iter: 0; batch classifier loss: 0.266405; batch adversarial loss: 0.362916\n",
      "epoch 24; iter: 200; batch classifier loss: 0.320711; batch adversarial loss: 0.394284\n",
      "epoch 25; iter: 0; batch classifier loss: 0.345143; batch adversarial loss: 0.406220\n",
      "epoch 25; iter: 200; batch classifier loss: 0.332393; batch adversarial loss: 0.341376\n",
      "epoch 26; iter: 0; batch classifier loss: 0.383761; batch adversarial loss: 0.486515\n",
      "epoch 26; iter: 200; batch classifier loss: 0.324920; batch adversarial loss: 0.372890\n",
      "epoch 27; iter: 0; batch classifier loss: 0.381831; batch adversarial loss: 0.461727\n",
      "epoch 27; iter: 200; batch classifier loss: 0.261019; batch adversarial loss: 0.442948\n",
      "epoch 28; iter: 0; batch classifier loss: 0.295489; batch adversarial loss: 0.473264\n",
      "epoch 28; iter: 200; batch classifier loss: 0.303054; batch adversarial loss: 0.301617\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303934; batch adversarial loss: 0.528770\n",
      "epoch 29; iter: 200; batch classifier loss: 0.271993; batch adversarial loss: 0.470272\n",
      "epoch 30; iter: 0; batch classifier loss: 0.349424; batch adversarial loss: 0.413997\n",
      "epoch 30; iter: 200; batch classifier loss: 0.319004; batch adversarial loss: 0.439048\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334015; batch adversarial loss: 0.395843\n",
      "epoch 31; iter: 200; batch classifier loss: 0.416547; batch adversarial loss: 0.521631\n",
      "epoch 32; iter: 0; batch classifier loss: 0.254160; batch adversarial loss: 0.362269\n",
      "epoch 32; iter: 200; batch classifier loss: 0.318098; batch adversarial loss: 0.401260\n",
      "epoch 33; iter: 0; batch classifier loss: 0.366012; batch adversarial loss: 0.374802\n",
      "epoch 33; iter: 200; batch classifier loss: 0.486548; batch adversarial loss: 0.383017\n",
      "epoch 34; iter: 0; batch classifier loss: 0.381172; batch adversarial loss: 0.385142\n",
      "epoch 34; iter: 200; batch classifier loss: 0.356879; batch adversarial loss: 0.484889\n",
      "epoch 35; iter: 0; batch classifier loss: 0.457935; batch adversarial loss: 0.412461\n",
      "epoch 35; iter: 200; batch classifier loss: 0.452491; batch adversarial loss: 0.332334\n",
      "epoch 36; iter: 0; batch classifier loss: 0.402644; batch adversarial loss: 0.474895\n",
      "epoch 36; iter: 200; batch classifier loss: 0.336686; batch adversarial loss: 0.333799\n",
      "epoch 37; iter: 0; batch classifier loss: 0.517752; batch adversarial loss: 0.283825\n",
      "epoch 37; iter: 200; batch classifier loss: 0.387851; batch adversarial loss: 0.539928\n",
      "epoch 38; iter: 0; batch classifier loss: 0.415815; batch adversarial loss: 0.414121\n",
      "epoch 38; iter: 200; batch classifier loss: 0.460861; batch adversarial loss: 0.503619\n",
      "epoch 39; iter: 0; batch classifier loss: 0.453004; batch adversarial loss: 0.384922\n",
      "epoch 39; iter: 200; batch classifier loss: 0.411955; batch adversarial loss: 0.348744\n",
      "epoch 40; iter: 0; batch classifier loss: 0.368150; batch adversarial loss: 0.358948\n",
      "epoch 40; iter: 200; batch classifier loss: 0.510913; batch adversarial loss: 0.380174\n",
      "epoch 41; iter: 0; batch classifier loss: 0.358553; batch adversarial loss: 0.436419\n",
      "epoch 41; iter: 200; batch classifier loss: 0.488743; batch adversarial loss: 0.408645\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374306; batch adversarial loss: 0.512277\n",
      "epoch 42; iter: 200; batch classifier loss: 0.391005; batch adversarial loss: 0.406047\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390620; batch adversarial loss: 0.431100\n",
      "epoch 43; iter: 200; batch classifier loss: 0.361659; batch adversarial loss: 0.403684\n",
      "epoch 44; iter: 0; batch classifier loss: 0.508264; batch adversarial loss: 0.391284\n",
      "epoch 44; iter: 200; batch classifier loss: 0.473444; batch adversarial loss: 0.373580\n",
      "epoch 45; iter: 0; batch classifier loss: 0.547970; batch adversarial loss: 0.361084\n",
      "epoch 45; iter: 200; batch classifier loss: 0.458540; batch adversarial loss: 0.474074\n",
      "epoch 46; iter: 0; batch classifier loss: 0.468599; batch adversarial loss: 0.417339\n",
      "epoch 46; iter: 200; batch classifier loss: 0.386267; batch adversarial loss: 0.434406\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520753; batch adversarial loss: 0.430551\n",
      "epoch 47; iter: 200; batch classifier loss: 0.448392; batch adversarial loss: 0.335140\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452981; batch adversarial loss: 0.413891\n",
      "epoch 48; iter: 200; batch classifier loss: 0.312719; batch adversarial loss: 0.389317\n",
      "epoch 49; iter: 0; batch classifier loss: 0.560159; batch adversarial loss: 0.404181\n",
      "epoch 49; iter: 200; batch classifier loss: 0.376369; batch adversarial loss: 0.389790\n",
      "epoch 0; iter: 0; batch classifier loss: 54.628838; batch adversarial loss: 0.511320\n",
      "epoch 0; iter: 200; batch classifier loss: 6.374729; batch adversarial loss: 0.484015\n",
      "epoch 1; iter: 0; batch classifier loss: 4.137969; batch adversarial loss: 0.479615\n",
      "epoch 1; iter: 200; batch classifier loss: 1.502880; batch adversarial loss: 0.424156\n",
      "epoch 2; iter: 0; batch classifier loss: 3.244056; batch adversarial loss: 0.477209\n",
      "epoch 2; iter: 200; batch classifier loss: 7.931383; batch adversarial loss: 0.413126\n",
      "epoch 3; iter: 0; batch classifier loss: 1.987709; batch adversarial loss: 0.434773\n",
      "epoch 3; iter: 200; batch classifier loss: 4.710624; batch adversarial loss: 0.399215\n",
      "epoch 4; iter: 0; batch classifier loss: 1.516504; batch adversarial loss: 0.402071\n",
      "epoch 4; iter: 200; batch classifier loss: 4.449527; batch adversarial loss: 0.450944\n",
      "epoch 5; iter: 0; batch classifier loss: 3.277458; batch adversarial loss: 0.488263\n",
      "epoch 5; iter: 200; batch classifier loss: 1.563306; batch adversarial loss: 0.349604\n",
      "epoch 6; iter: 0; batch classifier loss: 0.667381; batch adversarial loss: 0.468870\n",
      "epoch 6; iter: 200; batch classifier loss: 1.101438; batch adversarial loss: 0.461807\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497294; batch adversarial loss: 0.347578\n",
      "epoch 7; iter: 200; batch classifier loss: 1.181572; batch adversarial loss: 0.475985\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432672; batch adversarial loss: 0.419145\n",
      "epoch 8; iter: 200; batch classifier loss: 0.491633; batch adversarial loss: 0.525881\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590935; batch adversarial loss: 0.367874\n",
      "epoch 9; iter: 200; batch classifier loss: 0.467023; batch adversarial loss: 0.402219\n",
      "epoch 10; iter: 0; batch classifier loss: 0.825510; batch adversarial loss: 0.438362\n",
      "epoch 10; iter: 200; batch classifier loss: 0.737397; batch adversarial loss: 0.397287\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456746; batch adversarial loss: 0.329192\n",
      "epoch 11; iter: 200; batch classifier loss: 0.458822; batch adversarial loss: 0.467385\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410332; batch adversarial loss: 0.349516\n",
      "epoch 12; iter: 200; batch classifier loss: 0.490643; batch adversarial loss: 0.312997\n",
      "epoch 13; iter: 0; batch classifier loss: 0.691045; batch adversarial loss: 0.362931\n",
      "epoch 13; iter: 200; batch classifier loss: 0.325188; batch adversarial loss: 0.337522\n",
      "epoch 14; iter: 0; batch classifier loss: 0.422119; batch adversarial loss: 0.348278\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379956; batch adversarial loss: 0.351667\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334915; batch adversarial loss: 0.469041\n",
      "epoch 15; iter: 200; batch classifier loss: 0.350939; batch adversarial loss: 0.429056\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306376; batch adversarial loss: 0.435551\n",
      "epoch 16; iter: 200; batch classifier loss: 0.393442; batch adversarial loss: 0.504994\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420054; batch adversarial loss: 0.365792\n",
      "epoch 17; iter: 200; batch classifier loss: 0.309571; batch adversarial loss: 0.466143\n",
      "epoch 18; iter: 0; batch classifier loss: 0.251760; batch adversarial loss: 0.398734\n",
      "epoch 18; iter: 200; batch classifier loss: 0.368556; batch adversarial loss: 0.357534\n",
      "epoch 19; iter: 0; batch classifier loss: 0.323094; batch adversarial loss: 0.376125\n",
      "epoch 19; iter: 200; batch classifier loss: 0.457827; batch adversarial loss: 0.385651\n",
      "epoch 20; iter: 0; batch classifier loss: 0.309909; batch adversarial loss: 0.443073\n",
      "epoch 20; iter: 200; batch classifier loss: 0.378033; batch adversarial loss: 0.343007\n",
      "epoch 21; iter: 0; batch classifier loss: 0.296402; batch adversarial loss: 0.477257\n",
      "epoch 21; iter: 200; batch classifier loss: 0.373005; batch adversarial loss: 0.369964\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361445; batch adversarial loss: 0.394901\n",
      "epoch 22; iter: 200; batch classifier loss: 0.416018; batch adversarial loss: 0.355244\n",
      "epoch 23; iter: 0; batch classifier loss: 0.302205; batch adversarial loss: 0.364061\n",
      "epoch 23; iter: 200; batch classifier loss: 0.279194; batch adversarial loss: 0.348558\n",
      "epoch 24; iter: 0; batch classifier loss: 0.274128; batch adversarial loss: 0.479998\n",
      "epoch 24; iter: 200; batch classifier loss: 0.343195; batch adversarial loss: 0.399514\n",
      "epoch 25; iter: 0; batch classifier loss: 0.316631; batch adversarial loss: 0.314492\n",
      "epoch 25; iter: 200; batch classifier loss: 0.325742; batch adversarial loss: 0.380814\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340404; batch adversarial loss: 0.375268\n",
      "epoch 26; iter: 200; batch classifier loss: 0.376956; batch adversarial loss: 0.424587\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389886; batch adversarial loss: 0.441491\n",
      "epoch 27; iter: 200; batch classifier loss: 0.378818; batch adversarial loss: 0.325742\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458958; batch adversarial loss: 0.414369\n",
      "epoch 28; iter: 200; batch classifier loss: 0.487222; batch adversarial loss: 0.336274\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281378; batch adversarial loss: 0.444826\n",
      "epoch 29; iter: 200; batch classifier loss: 0.302684; batch adversarial loss: 0.418919\n",
      "epoch 30; iter: 0; batch classifier loss: 0.304403; batch adversarial loss: 0.399185\n",
      "epoch 30; iter: 200; batch classifier loss: 0.232142; batch adversarial loss: 0.449397\n",
      "epoch 31; iter: 0; batch classifier loss: 0.295710; batch adversarial loss: 0.483646\n",
      "epoch 31; iter: 200; batch classifier loss: 0.372779; batch adversarial loss: 0.449864\n",
      "epoch 32; iter: 0; batch classifier loss: 0.308653; batch adversarial loss: 0.458059\n",
      "epoch 32; iter: 200; batch classifier loss: 0.333616; batch adversarial loss: 0.365673\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355094; batch adversarial loss: 0.457987\n",
      "epoch 33; iter: 200; batch classifier loss: 0.415378; batch adversarial loss: 0.488646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.339229; batch adversarial loss: 0.389215\n",
      "epoch 34; iter: 200; batch classifier loss: 0.335074; batch adversarial loss: 0.418353\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470744; batch adversarial loss: 0.351085\n",
      "epoch 35; iter: 200; batch classifier loss: 0.373181; batch adversarial loss: 0.445335\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424013; batch adversarial loss: 0.408815\n",
      "epoch 36; iter: 200; batch classifier loss: 0.349559; batch adversarial loss: 0.320771\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378495; batch adversarial loss: 0.388938\n",
      "epoch 37; iter: 200; batch classifier loss: 0.481006; batch adversarial loss: 0.427212\n",
      "epoch 38; iter: 0; batch classifier loss: 0.435493; batch adversarial loss: 0.442292\n",
      "epoch 38; iter: 200; batch classifier loss: 0.379611; batch adversarial loss: 0.409484\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443960; batch adversarial loss: 0.459606\n",
      "epoch 39; iter: 200; batch classifier loss: 0.435710; batch adversarial loss: 0.487839\n",
      "epoch 40; iter: 0; batch classifier loss: 0.329423; batch adversarial loss: 0.416454\n",
      "epoch 40; iter: 200; batch classifier loss: 0.503549; batch adversarial loss: 0.453964\n",
      "epoch 41; iter: 0; batch classifier loss: 0.499624; batch adversarial loss: 0.358499\n",
      "epoch 41; iter: 200; batch classifier loss: 0.421273; batch adversarial loss: 0.395916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.413640; batch adversarial loss: 0.419229\n",
      "epoch 42; iter: 200; batch classifier loss: 0.361328; batch adversarial loss: 0.379563\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407338; batch adversarial loss: 0.402402\n",
      "epoch 43; iter: 200; batch classifier loss: 0.439322; batch adversarial loss: 0.376063\n",
      "epoch 44; iter: 0; batch classifier loss: 0.485789; batch adversarial loss: 0.370839\n",
      "epoch 44; iter: 200; batch classifier loss: 0.303605; batch adversarial loss: 0.446647\n",
      "epoch 45; iter: 0; batch classifier loss: 0.617373; batch adversarial loss: 0.447882\n",
      "epoch 45; iter: 200; batch classifier loss: 0.435861; batch adversarial loss: 0.403071\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469267; batch adversarial loss: 0.409427\n",
      "epoch 46; iter: 200; batch classifier loss: 0.437525; batch adversarial loss: 0.347836\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462203; batch adversarial loss: 0.371924\n",
      "epoch 47; iter: 200; batch classifier loss: 0.408606; batch adversarial loss: 0.467332\n",
      "epoch 48; iter: 0; batch classifier loss: 0.500569; batch adversarial loss: 0.393900\n",
      "epoch 48; iter: 200; batch classifier loss: 0.449837; batch adversarial loss: 0.345610\n",
      "epoch 49; iter: 0; batch classifier loss: 0.370676; batch adversarial loss: 0.393376\n",
      "epoch 49; iter: 200; batch classifier loss: 0.325495; batch adversarial loss: 0.475714\n",
      "epoch 0; iter: 0; batch classifier loss: 21.936329; batch adversarial loss: 0.595441\n",
      "epoch 0; iter: 200; batch classifier loss: 6.284925; batch adversarial loss: 0.585101\n",
      "epoch 1; iter: 0; batch classifier loss: 5.922019; batch adversarial loss: 0.571480\n",
      "epoch 1; iter: 200; batch classifier loss: 7.458178; batch adversarial loss: 0.516840\n",
      "epoch 2; iter: 0; batch classifier loss: 2.785740; batch adversarial loss: 0.519939\n",
      "epoch 2; iter: 200; batch classifier loss: 1.453816; batch adversarial loss: 0.462731\n",
      "epoch 3; iter: 0; batch classifier loss: 18.930862; batch adversarial loss: 0.525970\n",
      "epoch 3; iter: 200; batch classifier loss: 1.398497; batch adversarial loss: 0.499096\n",
      "epoch 4; iter: 0; batch classifier loss: 2.338834; batch adversarial loss: 0.472446\n",
      "epoch 4; iter: 200; batch classifier loss: 1.019880; batch adversarial loss: 0.447015\n",
      "epoch 5; iter: 0; batch classifier loss: 0.785454; batch adversarial loss: 0.460932\n",
      "epoch 5; iter: 200; batch classifier loss: 0.587231; batch adversarial loss: 0.414760\n",
      "epoch 6; iter: 0; batch classifier loss: 1.118995; batch adversarial loss: 0.504589\n",
      "epoch 6; iter: 200; batch classifier loss: 0.927408; batch adversarial loss: 0.490995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.767521; batch adversarial loss: 0.520497\n",
      "epoch 7; iter: 200; batch classifier loss: 0.887324; batch adversarial loss: 0.472924\n",
      "epoch 8; iter: 0; batch classifier loss: 1.535500; batch adversarial loss: 0.426928\n",
      "epoch 8; iter: 200; batch classifier loss: 0.555737; batch adversarial loss: 0.396423\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513128; batch adversarial loss: 0.412548\n",
      "epoch 9; iter: 200; batch classifier loss: 0.515126; batch adversarial loss: 0.466017\n",
      "epoch 10; iter: 0; batch classifier loss: 0.781782; batch adversarial loss: 0.443073\n",
      "epoch 10; iter: 200; batch classifier loss: 0.406125; batch adversarial loss: 0.316328\n",
      "epoch 11; iter: 0; batch classifier loss: 0.347051; batch adversarial loss: 0.361885\n",
      "epoch 11; iter: 200; batch classifier loss: 0.519672; batch adversarial loss: 0.356070\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341859; batch adversarial loss: 0.355283\n",
      "epoch 12; iter: 200; batch classifier loss: 0.490029; batch adversarial loss: 0.347527\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477584; batch adversarial loss: 0.360746\n",
      "epoch 13; iter: 200; batch classifier loss: 0.359858; batch adversarial loss: 0.474998\n",
      "epoch 14; iter: 0; batch classifier loss: 0.380740; batch adversarial loss: 0.362521\n",
      "epoch 14; iter: 200; batch classifier loss: 0.427946; batch adversarial loss: 0.392943\n",
      "epoch 15; iter: 0; batch classifier loss: 0.367836; batch adversarial loss: 0.481938\n",
      "epoch 15; iter: 200; batch classifier loss: 0.316036; batch adversarial loss: 0.400216\n",
      "epoch 16; iter: 0; batch classifier loss: 0.416205; batch adversarial loss: 0.432880\n",
      "epoch 16; iter: 200; batch classifier loss: 0.339010; batch adversarial loss: 0.449809\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532664; batch adversarial loss: 0.439079\n",
      "epoch 17; iter: 200; batch classifier loss: 0.318621; batch adversarial loss: 0.321847\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335248; batch adversarial loss: 0.418415\n",
      "epoch 18; iter: 200; batch classifier loss: 0.355079; batch adversarial loss: 0.374781\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352600; batch adversarial loss: 0.359787\n",
      "epoch 19; iter: 200; batch classifier loss: 0.438890; batch adversarial loss: 0.411105\n",
      "epoch 20; iter: 0; batch classifier loss: 0.365754; batch adversarial loss: 0.360542\n",
      "epoch 20; iter: 200; batch classifier loss: 0.331273; batch adversarial loss: 0.325027\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319771; batch adversarial loss: 0.420590\n",
      "epoch 21; iter: 200; batch classifier loss: 0.390973; batch adversarial loss: 0.377382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294957; batch adversarial loss: 0.356559\n",
      "epoch 22; iter: 200; batch classifier loss: 0.408432; batch adversarial loss: 0.403745\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380734; batch adversarial loss: 0.358983\n",
      "epoch 23; iter: 200; batch classifier loss: 0.331864; batch adversarial loss: 0.389879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362265; batch adversarial loss: 0.529431\n",
      "epoch 24; iter: 200; batch classifier loss: 0.276106; batch adversarial loss: 0.432945\n",
      "epoch 25; iter: 0; batch classifier loss: 0.356732; batch adversarial loss: 0.336831\n",
      "epoch 25; iter: 200; batch classifier loss: 0.351620; batch adversarial loss: 0.406862\n",
      "epoch 26; iter: 0; batch classifier loss: 0.318455; batch adversarial loss: 0.465135\n",
      "epoch 26; iter: 200; batch classifier loss: 0.392775; batch adversarial loss: 0.325568\n",
      "epoch 27; iter: 0; batch classifier loss: 0.393998; batch adversarial loss: 0.361113\n",
      "epoch 27; iter: 200; batch classifier loss: 0.407603; batch adversarial loss: 0.483585\n",
      "epoch 28; iter: 0; batch classifier loss: 0.245076; batch adversarial loss: 0.383354\n",
      "epoch 28; iter: 200; batch classifier loss: 0.331095; batch adversarial loss: 0.388436\n",
      "epoch 29; iter: 0; batch classifier loss: 0.341440; batch adversarial loss: 0.400076\n",
      "epoch 29; iter: 200; batch classifier loss: 0.382809; batch adversarial loss: 0.380499\n",
      "epoch 30; iter: 0; batch classifier loss: 0.341815; batch adversarial loss: 0.368630\n",
      "epoch 30; iter: 200; batch classifier loss: 0.386401; batch adversarial loss: 0.359431\n",
      "epoch 31; iter: 0; batch classifier loss: 0.382396; batch adversarial loss: 0.465518\n",
      "epoch 31; iter: 200; batch classifier loss: 0.344975; batch adversarial loss: 0.331712\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409368; batch adversarial loss: 0.458161\n",
      "epoch 32; iter: 200; batch classifier loss: 0.367361; batch adversarial loss: 0.419076\n",
      "epoch 33; iter: 0; batch classifier loss: 0.291346; batch adversarial loss: 0.461213\n",
      "epoch 33; iter: 200; batch classifier loss: 0.371575; batch adversarial loss: 0.445063\n",
      "epoch 34; iter: 0; batch classifier loss: 0.413174; batch adversarial loss: 0.536358\n",
      "epoch 34; iter: 200; batch classifier loss: 0.355053; batch adversarial loss: 0.464582\n",
      "epoch 35; iter: 0; batch classifier loss: 0.385978; batch adversarial loss: 0.461675\n",
      "epoch 35; iter: 200; batch classifier loss: 0.409162; batch adversarial loss: 0.433863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357530; batch adversarial loss: 0.341332\n",
      "epoch 36; iter: 200; batch classifier loss: 0.337059; batch adversarial loss: 0.464618\n",
      "epoch 37; iter: 0; batch classifier loss: 0.312632; batch adversarial loss: 0.450384\n",
      "epoch 37; iter: 200; batch classifier loss: 0.311940; batch adversarial loss: 0.334928\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392690; batch adversarial loss: 0.370917\n",
      "epoch 38; iter: 200; batch classifier loss: 0.375489; batch adversarial loss: 0.428429\n",
      "epoch 39; iter: 0; batch classifier loss: 0.341571; batch adversarial loss: 0.494327\n",
      "epoch 39; iter: 200; batch classifier loss: 0.296829; batch adversarial loss: 0.334682\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409818; batch adversarial loss: 0.397824\n",
      "epoch 40; iter: 200; batch classifier loss: 0.453386; batch adversarial loss: 0.317011\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446047; batch adversarial loss: 0.366100\n",
      "epoch 41; iter: 200; batch classifier loss: 0.347819; batch adversarial loss: 0.392065\n",
      "epoch 42; iter: 0; batch classifier loss: 0.317042; batch adversarial loss: 0.485673\n",
      "epoch 42; iter: 200; batch classifier loss: 0.355108; batch adversarial loss: 0.426983\n",
      "epoch 43; iter: 0; batch classifier loss: 0.367757; batch adversarial loss: 0.389648\n",
      "epoch 43; iter: 200; batch classifier loss: 0.304458; batch adversarial loss: 0.350073\n",
      "epoch 44; iter: 0; batch classifier loss: 0.351488; batch adversarial loss: 0.477142\n",
      "epoch 44; iter: 200; batch classifier loss: 0.486952; batch adversarial loss: 0.434278\n",
      "epoch 45; iter: 0; batch classifier loss: 0.514761; batch adversarial loss: 0.411406\n",
      "epoch 45; iter: 200; batch classifier loss: 0.550800; batch adversarial loss: 0.513693\n",
      "epoch 46; iter: 0; batch classifier loss: 0.366898; batch adversarial loss: 0.375139\n",
      "epoch 46; iter: 200; batch classifier loss: 0.449321; batch adversarial loss: 0.381607\n",
      "epoch 47; iter: 0; batch classifier loss: 0.513326; batch adversarial loss: 0.336032\n",
      "epoch 47; iter: 200; batch classifier loss: 0.445578; batch adversarial loss: 0.442221\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461948; batch adversarial loss: 0.421179\n",
      "epoch 48; iter: 200; batch classifier loss: 0.464031; batch adversarial loss: 0.364017\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487298; batch adversarial loss: 0.402616\n",
      "epoch 49; iter: 200; batch classifier loss: 0.437029; batch adversarial loss: 0.459401\n",
      "epoch 0; iter: 0; batch classifier loss: 187.683868; batch adversarial loss: 1.159472\n",
      "epoch 0; iter: 200; batch classifier loss: 8.114880; batch adversarial loss: 0.752979\n",
      "epoch 1; iter: 0; batch classifier loss: 12.070951; batch adversarial loss: 0.705974\n",
      "epoch 1; iter: 200; batch classifier loss: 6.699275; batch adversarial loss: 0.605207\n",
      "epoch 2; iter: 0; batch classifier loss: 4.682028; batch adversarial loss: 0.585973\n",
      "epoch 2; iter: 200; batch classifier loss: 9.457137; batch adversarial loss: 0.535112\n",
      "epoch 3; iter: 0; batch classifier loss: 1.849328; batch adversarial loss: 0.539637\n",
      "epoch 3; iter: 200; batch classifier loss: 0.646171; batch adversarial loss: 0.496529\n",
      "epoch 4; iter: 0; batch classifier loss: 1.197560; batch adversarial loss: 0.480614\n",
      "epoch 4; iter: 200; batch classifier loss: 2.791821; batch adversarial loss: 0.454393\n",
      "epoch 5; iter: 0; batch classifier loss: 1.738397; batch adversarial loss: 0.430648\n",
      "epoch 5; iter: 200; batch classifier loss: 2.919463; batch adversarial loss: 0.479879\n",
      "epoch 6; iter: 0; batch classifier loss: 0.409028; batch adversarial loss: 0.441249\n",
      "epoch 6; iter: 200; batch classifier loss: 0.648253; batch adversarial loss: 0.456645\n",
      "epoch 7; iter: 0; batch classifier loss: 0.370556; batch adversarial loss: 0.506971\n",
      "epoch 7; iter: 200; batch classifier loss: 0.363214; batch adversarial loss: 0.462315\n",
      "epoch 8; iter: 0; batch classifier loss: 0.686023; batch adversarial loss: 0.366646\n",
      "epoch 8; iter: 200; batch classifier loss: 0.495197; batch adversarial loss: 0.387832\n",
      "epoch 9; iter: 0; batch classifier loss: 0.451626; batch adversarial loss: 0.456160\n",
      "epoch 9; iter: 200; batch classifier loss: 0.457983; batch adversarial loss: 0.458703\n",
      "epoch 10; iter: 0; batch classifier loss: 0.790570; batch adversarial loss: 0.428101\n",
      "epoch 10; iter: 200; batch classifier loss: 0.419495; batch adversarial loss: 0.400465\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508822; batch adversarial loss: 0.349932\n",
      "epoch 11; iter: 200; batch classifier loss: 0.377284; batch adversarial loss: 0.394695\n",
      "epoch 12; iter: 0; batch classifier loss: 0.432023; batch adversarial loss: 0.454163\n",
      "epoch 12; iter: 200; batch classifier loss: 0.357950; batch adversarial loss: 0.402274\n",
      "epoch 13; iter: 0; batch classifier loss: 0.360234; batch adversarial loss: 0.395390\n",
      "epoch 13; iter: 200; batch classifier loss: 0.321450; batch adversarial loss: 0.347857\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315988; batch adversarial loss: 0.326996\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352223; batch adversarial loss: 0.353187\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518489; batch adversarial loss: 0.340896\n",
      "epoch 15; iter: 200; batch classifier loss: 0.319919; batch adversarial loss: 0.392682\n",
      "epoch 16; iter: 0; batch classifier loss: 0.338685; batch adversarial loss: 0.349265\n",
      "epoch 16; iter: 200; batch classifier loss: 0.337327; batch adversarial loss: 0.330539\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347167; batch adversarial loss: 0.550808\n",
      "epoch 17; iter: 200; batch classifier loss: 0.329123; batch adversarial loss: 0.455641\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513499; batch adversarial loss: 0.414820\n",
      "epoch 18; iter: 200; batch classifier loss: 0.426625; batch adversarial loss: 0.442468\n",
      "epoch 19; iter: 0; batch classifier loss: 0.358601; batch adversarial loss: 0.417760\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347279; batch adversarial loss: 0.398641\n",
      "epoch 20; iter: 0; batch classifier loss: 0.287048; batch adversarial loss: 0.370182\n",
      "epoch 20; iter: 200; batch classifier loss: 0.327798; batch adversarial loss: 0.477972\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355962; batch adversarial loss: 0.441151\n",
      "epoch 21; iter: 200; batch classifier loss: 0.431889; batch adversarial loss: 0.374929\n",
      "epoch 22; iter: 0; batch classifier loss: 0.334708; batch adversarial loss: 0.509414\n",
      "epoch 22; iter: 200; batch classifier loss: 0.339380; batch adversarial loss: 0.437397\n",
      "epoch 23; iter: 0; batch classifier loss: 0.358555; batch adversarial loss: 0.496098\n",
      "epoch 23; iter: 200; batch classifier loss: 0.459726; batch adversarial loss: 0.385545\n",
      "epoch 24; iter: 0; batch classifier loss: 0.348839; batch adversarial loss: 0.327811\n",
      "epoch 24; iter: 200; batch classifier loss: 0.319853; batch adversarial loss: 0.379683\n",
      "epoch 25; iter: 0; batch classifier loss: 0.346607; batch adversarial loss: 0.512420\n",
      "epoch 25; iter: 200; batch classifier loss: 0.354695; batch adversarial loss: 0.342793\n",
      "epoch 26; iter: 0; batch classifier loss: 0.362599; batch adversarial loss: 0.358915\n",
      "epoch 26; iter: 200; batch classifier loss: 0.371925; batch adversarial loss: 0.464330\n",
      "epoch 27; iter: 0; batch classifier loss: 0.416854; batch adversarial loss: 0.258312\n",
      "epoch 27; iter: 200; batch classifier loss: 0.337374; batch adversarial loss: 0.504404\n",
      "epoch 28; iter: 0; batch classifier loss: 0.323677; batch adversarial loss: 0.510566\n",
      "epoch 28; iter: 200; batch classifier loss: 0.353837; batch adversarial loss: 0.439717\n",
      "epoch 29; iter: 0; batch classifier loss: 0.281603; batch adversarial loss: 0.498946\n",
      "epoch 29; iter: 200; batch classifier loss: 0.305138; batch adversarial loss: 0.325589\n",
      "epoch 30; iter: 0; batch classifier loss: 0.350711; batch adversarial loss: 0.429000\n",
      "epoch 30; iter: 200; batch classifier loss: 0.343516; batch adversarial loss: 0.410399\n",
      "epoch 31; iter: 0; batch classifier loss: 0.283038; batch adversarial loss: 0.371064\n",
      "epoch 31; iter: 200; batch classifier loss: 0.263940; batch adversarial loss: 0.360498\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512524; batch adversarial loss: 0.339561\n",
      "epoch 32; iter: 200; batch classifier loss: 0.333557; batch adversarial loss: 0.344846\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318143; batch adversarial loss: 0.399530\n",
      "epoch 33; iter: 200; batch classifier loss: 0.329815; batch adversarial loss: 0.469887\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389377; batch adversarial loss: 0.322411\n",
      "epoch 34; iter: 200; batch classifier loss: 0.254391; batch adversarial loss: 0.435698\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400440; batch adversarial loss: 0.513992\n",
      "epoch 35; iter: 200; batch classifier loss: 0.321296; batch adversarial loss: 0.550084\n",
      "epoch 36; iter: 0; batch classifier loss: 0.346562; batch adversarial loss: 0.442873\n",
      "epoch 36; iter: 200; batch classifier loss: 0.329774; batch adversarial loss: 0.424248\n",
      "epoch 37; iter: 0; batch classifier loss: 0.369146; batch adversarial loss: 0.396805\n",
      "epoch 37; iter: 200; batch classifier loss: 0.328129; batch adversarial loss: 0.381183\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359285; batch adversarial loss: 0.435088\n",
      "epoch 38; iter: 200; batch classifier loss: 0.373389; batch adversarial loss: 0.483565\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315225; batch adversarial loss: 0.356654\n",
      "epoch 39; iter: 200; batch classifier loss: 0.389561; batch adversarial loss: 0.339480\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401423; batch adversarial loss: 0.357311\n",
      "epoch 40; iter: 200; batch classifier loss: 0.289947; batch adversarial loss: 0.406564\n",
      "epoch 41; iter: 0; batch classifier loss: 0.300297; batch adversarial loss: 0.391410\n",
      "epoch 41; iter: 200; batch classifier loss: 0.389198; batch adversarial loss: 0.404039\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462875; batch adversarial loss: 0.415132\n",
      "epoch 42; iter: 200; batch classifier loss: 0.307874; batch adversarial loss: 0.334424\n",
      "epoch 43; iter: 0; batch classifier loss: 0.338484; batch adversarial loss: 0.352457\n",
      "epoch 43; iter: 200; batch classifier loss: 0.367525; batch adversarial loss: 0.338118\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400544; batch adversarial loss: 0.329195\n",
      "epoch 44; iter: 200; batch classifier loss: 0.338358; batch adversarial loss: 0.426832\n",
      "epoch 45; iter: 0; batch classifier loss: 0.308553; batch adversarial loss: 0.395563\n",
      "epoch 45; iter: 200; batch classifier loss: 0.414387; batch adversarial loss: 0.418633\n",
      "epoch 46; iter: 0; batch classifier loss: 0.476850; batch adversarial loss: 0.356418\n",
      "epoch 46; iter: 200; batch classifier loss: 0.453128; batch adversarial loss: 0.397603\n",
      "epoch 47; iter: 0; batch classifier loss: 0.358842; batch adversarial loss: 0.418349\n",
      "epoch 47; iter: 200; batch classifier loss: 0.439365; batch adversarial loss: 0.420219\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404251; batch adversarial loss: 0.445928\n",
      "epoch 48; iter: 200; batch classifier loss: 0.444309; batch adversarial loss: 0.389222\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366903; batch adversarial loss: 0.501578\n",
      "epoch 49; iter: 200; batch classifier loss: 0.392011; batch adversarial loss: 0.337211\n",
      "epoch 0; iter: 0; batch classifier loss: 10.681117; batch adversarial loss: 0.758597\n",
      "epoch 0; iter: 200; batch classifier loss: 2.079583; batch adversarial loss: 0.646181\n",
      "epoch 1; iter: 0; batch classifier loss: 8.249435; batch adversarial loss: 0.611730\n",
      "epoch 1; iter: 200; batch classifier loss: 4.832401; batch adversarial loss: 0.477809\n",
      "epoch 2; iter: 0; batch classifier loss: 21.208094; batch adversarial loss: 0.481908\n",
      "epoch 2; iter: 200; batch classifier loss: 5.830268; batch adversarial loss: 0.440128\n",
      "epoch 3; iter: 0; batch classifier loss: 6.416782; batch adversarial loss: 0.451695\n",
      "epoch 3; iter: 200; batch classifier loss: 2.247424; batch adversarial loss: 0.466495\n",
      "epoch 4; iter: 0; batch classifier loss: 0.732110; batch adversarial loss: 0.401204\n",
      "epoch 4; iter: 200; batch classifier loss: 3.515406; batch adversarial loss: 0.446764\n",
      "epoch 5; iter: 0; batch classifier loss: 1.481952; batch adversarial loss: 0.427573\n",
      "epoch 5; iter: 200; batch classifier loss: 1.159925; batch adversarial loss: 0.381846\n",
      "epoch 6; iter: 0; batch classifier loss: 1.176915; batch adversarial loss: 0.410246\n",
      "epoch 6; iter: 200; batch classifier loss: 1.083698; batch adversarial loss: 0.475919\n",
      "epoch 7; iter: 0; batch classifier loss: 2.548259; batch adversarial loss: 0.492305\n",
      "epoch 7; iter: 200; batch classifier loss: 0.532191; batch adversarial loss: 0.357017\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557305; batch adversarial loss: 0.417422\n",
      "epoch 8; iter: 200; batch classifier loss: 0.336694; batch adversarial loss: 0.370781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.365764; batch adversarial loss: 0.414050\n",
      "epoch 9; iter: 200; batch classifier loss: 0.379533; batch adversarial loss: 0.468165\n",
      "epoch 10; iter: 0; batch classifier loss: 0.334559; batch adversarial loss: 0.499717\n",
      "epoch 10; iter: 200; batch classifier loss: 0.384199; batch adversarial loss: 0.343533\n",
      "epoch 11; iter: 0; batch classifier loss: 0.433548; batch adversarial loss: 0.390180\n",
      "epoch 11; iter: 200; batch classifier loss: 0.335062; batch adversarial loss: 0.411809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.918325; batch adversarial loss: 0.440776\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432629; batch adversarial loss: 0.384808\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338821; batch adversarial loss: 0.404782\n",
      "epoch 13; iter: 200; batch classifier loss: 0.375693; batch adversarial loss: 0.370552\n",
      "epoch 14; iter: 0; batch classifier loss: 0.329797; batch adversarial loss: 0.429651\n",
      "epoch 14; iter: 200; batch classifier loss: 0.309892; batch adversarial loss: 0.325224\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381922; batch adversarial loss: 0.465946\n",
      "epoch 15; iter: 200; batch classifier loss: 0.399685; batch adversarial loss: 0.468678\n",
      "epoch 16; iter: 0; batch classifier loss: 0.427766; batch adversarial loss: 0.444215\n",
      "epoch 16; iter: 200; batch classifier loss: 0.290261; batch adversarial loss: 0.406686\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470386; batch adversarial loss: 0.313183\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321628; batch adversarial loss: 0.353280\n",
      "epoch 18; iter: 0; batch classifier loss: 0.253804; batch adversarial loss: 0.447153\n",
      "epoch 18; iter: 200; batch classifier loss: 0.334267; batch adversarial loss: 0.399059\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307782; batch adversarial loss: 0.428397\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342999; batch adversarial loss: 0.555500\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385194; batch adversarial loss: 0.403983\n",
      "epoch 20; iter: 200; batch classifier loss: 0.420427; batch adversarial loss: 0.434467\n",
      "epoch 21; iter: 0; batch classifier loss: 0.267793; batch adversarial loss: 0.448374\n",
      "epoch 21; iter: 200; batch classifier loss: 0.346763; batch adversarial loss: 0.420814\n",
      "epoch 22; iter: 0; batch classifier loss: 0.313301; batch adversarial loss: 0.437479\n",
      "epoch 22; iter: 200; batch classifier loss: 0.307417; batch adversarial loss: 0.411449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.340078; batch adversarial loss: 0.357850\n",
      "epoch 23; iter: 200; batch classifier loss: 0.405446; batch adversarial loss: 0.371019\n",
      "epoch 24; iter: 0; batch classifier loss: 0.313176; batch adversarial loss: 0.402291\n",
      "epoch 24; iter: 200; batch classifier loss: 0.359449; batch adversarial loss: 0.293555\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321458; batch adversarial loss: 0.425700\n",
      "epoch 25; iter: 200; batch classifier loss: 0.324327; batch adversarial loss: 0.422259\n",
      "epoch 26; iter: 0; batch classifier loss: 0.322963; batch adversarial loss: 0.466003\n",
      "epoch 26; iter: 200; batch classifier loss: 0.327707; batch adversarial loss: 0.426494\n",
      "epoch 27; iter: 0; batch classifier loss: 0.309153; batch adversarial loss: 0.366761\n",
      "epoch 27; iter: 200; batch classifier loss: 0.331669; batch adversarial loss: 0.390925\n",
      "epoch 28; iter: 0; batch classifier loss: 0.269309; batch adversarial loss: 0.458914\n",
      "epoch 28; iter: 200; batch classifier loss: 0.293203; batch adversarial loss: 0.337499\n",
      "epoch 29; iter: 0; batch classifier loss: 0.328888; batch adversarial loss: 0.395345\n",
      "epoch 29; iter: 200; batch classifier loss: 0.319532; batch adversarial loss: 0.435067\n",
      "epoch 30; iter: 0; batch classifier loss: 0.308963; batch adversarial loss: 0.372504\n",
      "epoch 30; iter: 200; batch classifier loss: 0.403274; batch adversarial loss: 0.400537\n",
      "epoch 31; iter: 0; batch classifier loss: 0.352421; batch adversarial loss: 0.381287\n",
      "epoch 31; iter: 200; batch classifier loss: 0.347004; batch adversarial loss: 0.396243\n",
      "epoch 32; iter: 0; batch classifier loss: 0.291876; batch adversarial loss: 0.496169\n",
      "epoch 32; iter: 200; batch classifier loss: 0.330376; batch adversarial loss: 0.303444\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404428; batch adversarial loss: 0.389085\n",
      "epoch 33; iter: 200; batch classifier loss: 0.303405; batch adversarial loss: 0.415167\n",
      "epoch 34; iter: 0; batch classifier loss: 0.352334; batch adversarial loss: 0.355854\n",
      "epoch 34; iter: 200; batch classifier loss: 0.225595; batch adversarial loss: 0.369141\n",
      "epoch 35; iter: 0; batch classifier loss: 0.302963; batch adversarial loss: 0.591797\n",
      "epoch 35; iter: 200; batch classifier loss: 0.297364; batch adversarial loss: 0.466800\n",
      "epoch 36; iter: 0; batch classifier loss: 0.259363; batch adversarial loss: 0.413229\n",
      "epoch 36; iter: 200; batch classifier loss: 0.336480; batch adversarial loss: 0.326845\n",
      "epoch 37; iter: 0; batch classifier loss: 0.287035; batch adversarial loss: 0.408080\n",
      "epoch 37; iter: 200; batch classifier loss: 0.252308; batch adversarial loss: 0.425704\n",
      "epoch 38; iter: 0; batch classifier loss: 0.393124; batch adversarial loss: 0.417127\n",
      "epoch 38; iter: 200; batch classifier loss: 0.289683; batch adversarial loss: 0.388342\n",
      "epoch 39; iter: 0; batch classifier loss: 0.373790; batch adversarial loss: 0.438986\n",
      "epoch 39; iter: 200; batch classifier loss: 0.329825; batch adversarial loss: 0.472366\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403603; batch adversarial loss: 0.378908\n",
      "epoch 40; iter: 200; batch classifier loss: 0.316481; batch adversarial loss: 0.439371\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407169; batch adversarial loss: 0.557630\n",
      "epoch 41; iter: 200; batch classifier loss: 0.232328; batch adversarial loss: 0.320826\n",
      "epoch 42; iter: 0; batch classifier loss: 0.309841; batch adversarial loss: 0.379775\n",
      "epoch 42; iter: 200; batch classifier loss: 0.357225; batch adversarial loss: 0.395282\n",
      "epoch 43; iter: 0; batch classifier loss: 0.343087; batch adversarial loss: 0.379532\n",
      "epoch 43; iter: 200; batch classifier loss: 0.327144; batch adversarial loss: 0.405389\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388430; batch adversarial loss: 0.380009\n",
      "epoch 44; iter: 200; batch classifier loss: 0.343656; batch adversarial loss: 0.429438\n",
      "epoch 45; iter: 0; batch classifier loss: 0.340666; batch adversarial loss: 0.322379\n",
      "epoch 45; iter: 200; batch classifier loss: 0.364687; batch adversarial loss: 0.331718\n",
      "epoch 46; iter: 0; batch classifier loss: 0.265750; batch adversarial loss: 0.472048\n",
      "epoch 46; iter: 200; batch classifier loss: 0.331428; batch adversarial loss: 0.494459\n",
      "epoch 47; iter: 0; batch classifier loss: 0.304036; batch adversarial loss: 0.433733\n",
      "epoch 47; iter: 200; batch classifier loss: 0.350223; batch adversarial loss: 0.479361\n",
      "epoch 48; iter: 0; batch classifier loss: 0.415247; batch adversarial loss: 0.462183\n",
      "epoch 48; iter: 200; batch classifier loss: 0.347012; batch adversarial loss: 0.434180\n",
      "epoch 49; iter: 0; batch classifier loss: 0.375905; batch adversarial loss: 0.320194\n",
      "epoch 49; iter: 200; batch classifier loss: 0.263968; batch adversarial loss: 0.428284\n",
      "epoch 0; iter: 0; batch classifier loss: 11.400124; batch adversarial loss: 0.606852\n",
      "epoch 0; iter: 200; batch classifier loss: 8.587157; batch adversarial loss: 0.549841\n",
      "epoch 1; iter: 0; batch classifier loss: 20.852615; batch adversarial loss: 0.501706\n",
      "epoch 1; iter: 200; batch classifier loss: 5.180904; batch adversarial loss: 0.512469\n",
      "epoch 2; iter: 0; batch classifier loss: 3.714892; batch adversarial loss: 0.504609\n",
      "epoch 2; iter: 200; batch classifier loss: 1.821535; batch adversarial loss: 0.442017\n",
      "epoch 3; iter: 0; batch classifier loss: 7.354608; batch adversarial loss: 0.449574\n",
      "epoch 3; iter: 200; batch classifier loss: 1.234404; batch adversarial loss: 0.463841\n",
      "epoch 4; iter: 0; batch classifier loss: 3.446686; batch adversarial loss: 0.435154\n",
      "epoch 4; iter: 200; batch classifier loss: 1.616634; batch adversarial loss: 0.489271\n",
      "epoch 5; iter: 0; batch classifier loss: 1.730672; batch adversarial loss: 0.452816\n",
      "epoch 5; iter: 200; batch classifier loss: 1.893865; batch adversarial loss: 0.518408\n",
      "epoch 6; iter: 0; batch classifier loss: 1.280059; batch adversarial loss: 0.441980\n",
      "epoch 6; iter: 200; batch classifier loss: 0.480062; batch adversarial loss: 0.441975\n",
      "epoch 7; iter: 0; batch classifier loss: 0.757153; batch adversarial loss: 0.440799\n",
      "epoch 7; iter: 200; batch classifier loss: 0.407609; batch adversarial loss: 0.546316\n",
      "epoch 8; iter: 0; batch classifier loss: 0.727782; batch adversarial loss: 0.414053\n",
      "epoch 8; iter: 200; batch classifier loss: 0.504408; batch adversarial loss: 0.390221\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364972; batch adversarial loss: 0.399321\n",
      "epoch 9; iter: 200; batch classifier loss: 0.531822; batch adversarial loss: 0.433689\n",
      "epoch 10; iter: 0; batch classifier loss: 0.420212; batch adversarial loss: 0.430538\n",
      "epoch 10; iter: 200; batch classifier loss: 0.429620; batch adversarial loss: 0.355201\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313774; batch adversarial loss: 0.421090\n",
      "epoch 11; iter: 200; batch classifier loss: 0.634353; batch adversarial loss: 0.478937\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341562; batch adversarial loss: 0.322418\n",
      "epoch 12; iter: 200; batch classifier loss: 0.426682; batch adversarial loss: 0.379972\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372218; batch adversarial loss: 0.418546\n",
      "epoch 13; iter: 200; batch classifier loss: 0.357802; batch adversarial loss: 0.402900\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396139; batch adversarial loss: 0.355249\n",
      "epoch 14; iter: 200; batch classifier loss: 0.428942; batch adversarial loss: 0.498135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361278; batch adversarial loss: 0.347855\n",
      "epoch 15; iter: 200; batch classifier loss: 0.429847; batch adversarial loss: 0.419879\n",
      "epoch 16; iter: 0; batch classifier loss: 0.290192; batch adversarial loss: 0.534099\n",
      "epoch 16; iter: 200; batch classifier loss: 0.340121; batch adversarial loss: 0.497636\n",
      "epoch 17; iter: 0; batch classifier loss: 0.318682; batch adversarial loss: 0.365453\n",
      "epoch 17; iter: 200; batch classifier loss: 0.287410; batch adversarial loss: 0.365732\n",
      "epoch 18; iter: 0; batch classifier loss: 0.346928; batch adversarial loss: 0.460317\n",
      "epoch 18; iter: 200; batch classifier loss: 0.344276; batch adversarial loss: 0.354606\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280184; batch adversarial loss: 0.449188\n",
      "epoch 19; iter: 200; batch classifier loss: 0.391244; batch adversarial loss: 0.350225\n",
      "epoch 20; iter: 0; batch classifier loss: 0.311718; batch adversarial loss: 0.403646\n",
      "epoch 20; iter: 200; batch classifier loss: 0.335093; batch adversarial loss: 0.497563\n",
      "epoch 21; iter: 0; batch classifier loss: 0.347660; batch adversarial loss: 0.357910\n",
      "epoch 21; iter: 200; batch classifier loss: 0.268141; batch adversarial loss: 0.447413\n",
      "epoch 22; iter: 0; batch classifier loss: 0.398512; batch adversarial loss: 0.434053\n",
      "epoch 22; iter: 200; batch classifier loss: 0.315856; batch adversarial loss: 0.362335\n",
      "epoch 23; iter: 0; batch classifier loss: 0.267341; batch adversarial loss: 0.498189\n",
      "epoch 23; iter: 200; batch classifier loss: 0.415148; batch adversarial loss: 0.320897\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329373; batch adversarial loss: 0.420547\n",
      "epoch 24; iter: 200; batch classifier loss: 0.364924; batch adversarial loss: 0.485956\n",
      "epoch 25; iter: 0; batch classifier loss: 0.308306; batch adversarial loss: 0.515959\n",
      "epoch 25; iter: 200; batch classifier loss: 0.358717; batch adversarial loss: 0.331602\n",
      "epoch 26; iter: 0; batch classifier loss: 0.354801; batch adversarial loss: 0.448894\n",
      "epoch 26; iter: 200; batch classifier loss: 0.311674; batch adversarial loss: 0.375061\n",
      "epoch 27; iter: 0; batch classifier loss: 0.273551; batch adversarial loss: 0.408029\n",
      "epoch 27; iter: 200; batch classifier loss: 0.324212; batch adversarial loss: 0.481546\n",
      "epoch 28; iter: 0; batch classifier loss: 0.283525; batch adversarial loss: 0.438023\n",
      "epoch 28; iter: 200; batch classifier loss: 0.308036; batch adversarial loss: 0.336396\n",
      "epoch 29; iter: 0; batch classifier loss: 0.344797; batch adversarial loss: 0.341738\n",
      "epoch 29; iter: 200; batch classifier loss: 0.353077; batch adversarial loss: 0.416472\n",
      "epoch 30; iter: 0; batch classifier loss: 0.287282; batch adversarial loss: 0.406863\n",
      "epoch 30; iter: 200; batch classifier loss: 0.345774; batch adversarial loss: 0.444891\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315106; batch adversarial loss: 0.399681\n",
      "epoch 31; iter: 200; batch classifier loss: 0.294696; batch adversarial loss: 0.457795\n",
      "epoch 32; iter: 0; batch classifier loss: 0.342019; batch adversarial loss: 0.349853\n",
      "epoch 32; iter: 200; batch classifier loss: 0.384433; batch adversarial loss: 0.378080\n",
      "epoch 33; iter: 0; batch classifier loss: 0.296448; batch adversarial loss: 0.390252\n",
      "epoch 33; iter: 200; batch classifier loss: 0.438307; batch adversarial loss: 0.508105\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419061; batch adversarial loss: 0.418041\n",
      "epoch 34; iter: 200; batch classifier loss: 0.361576; batch adversarial loss: 0.470204\n",
      "epoch 35; iter: 0; batch classifier loss: 0.479165; batch adversarial loss: 0.450907\n",
      "epoch 35; iter: 200; batch classifier loss: 0.466592; batch adversarial loss: 0.429279\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480742; batch adversarial loss: 0.397257\n",
      "epoch 36; iter: 200; batch classifier loss: 0.327184; batch adversarial loss: 0.444482\n",
      "epoch 37; iter: 0; batch classifier loss: 0.495038; batch adversarial loss: 0.294299\n",
      "epoch 37; iter: 200; batch classifier loss: 0.409999; batch adversarial loss: 0.396548\n",
      "epoch 38; iter: 0; batch classifier loss: 0.512894; batch adversarial loss: 0.443780\n",
      "epoch 38; iter: 200; batch classifier loss: 0.390891; batch adversarial loss: 0.408020\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377896; batch adversarial loss: 0.377115\n",
      "epoch 39; iter: 200; batch classifier loss: 0.472149; batch adversarial loss: 0.333020\n",
      "epoch 40; iter: 0; batch classifier loss: 0.382300; batch adversarial loss: 0.431991\n",
      "epoch 40; iter: 200; batch classifier loss: 0.419229; batch adversarial loss: 0.382522\n",
      "epoch 41; iter: 0; batch classifier loss: 0.618379; batch adversarial loss: 0.463454\n",
      "epoch 41; iter: 200; batch classifier loss: 0.527474; batch adversarial loss: 0.461437\n",
      "epoch 42; iter: 0; batch classifier loss: 0.543550; batch adversarial loss: 0.466757\n",
      "epoch 42; iter: 200; batch classifier loss: 0.638408; batch adversarial loss: 0.416636\n",
      "epoch 43; iter: 0; batch classifier loss: 0.594585; batch adversarial loss: 0.418895\n",
      "epoch 43; iter: 200; batch classifier loss: 0.341951; batch adversarial loss: 0.404104\n",
      "epoch 44; iter: 0; batch classifier loss: 0.540663; batch adversarial loss: 0.346913\n",
      "epoch 44; iter: 200; batch classifier loss: 0.546598; batch adversarial loss: 0.402767\n",
      "epoch 45; iter: 0; batch classifier loss: 0.502889; batch adversarial loss: 0.462808\n",
      "epoch 45; iter: 200; batch classifier loss: 0.555924; batch adversarial loss: 0.429460\n",
      "epoch 46; iter: 0; batch classifier loss: 0.690905; batch adversarial loss: 0.513857\n",
      "epoch 46; iter: 200; batch classifier loss: 0.517029; batch adversarial loss: 0.417540\n",
      "epoch 47; iter: 0; batch classifier loss: 0.556189; batch adversarial loss: 0.475380\n",
      "epoch 47; iter: 200; batch classifier loss: 0.432578; batch adversarial loss: 0.419896\n",
      "epoch 48; iter: 0; batch classifier loss: 0.501700; batch adversarial loss: 0.374874\n",
      "epoch 48; iter: 200; batch classifier loss: 0.490294; batch adversarial loss: 0.457252\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451003; batch adversarial loss: 0.468292\n",
      "epoch 49; iter: 200; batch classifier loss: 0.454549; batch adversarial loss: 0.380963\n",
      "epoch 0; iter: 0; batch classifier loss: 27.722263; batch adversarial loss: 0.643777\n",
      "epoch 0; iter: 200; batch classifier loss: 4.127804; batch adversarial loss: 0.566155\n",
      "epoch 1; iter: 0; batch classifier loss: 7.240281; batch adversarial loss: 0.538554\n",
      "epoch 1; iter: 200; batch classifier loss: 4.711095; batch adversarial loss: 0.541745\n",
      "epoch 2; iter: 0; batch classifier loss: 0.941558; batch adversarial loss: 0.512154\n",
      "epoch 2; iter: 200; batch classifier loss: 5.006497; batch adversarial loss: 0.511179\n",
      "epoch 3; iter: 0; batch classifier loss: 4.442160; batch adversarial loss: 0.460156\n",
      "epoch 3; iter: 200; batch classifier loss: 5.020552; batch adversarial loss: 0.500592\n",
      "epoch 4; iter: 0; batch classifier loss: 0.564504; batch adversarial loss: 0.437452\n",
      "epoch 4; iter: 200; batch classifier loss: 2.618207; batch adversarial loss: 0.436883\n",
      "epoch 5; iter: 0; batch classifier loss: 1.118010; batch adversarial loss: 0.412851\n",
      "epoch 5; iter: 200; batch classifier loss: 1.003277; batch adversarial loss: 0.467981\n",
      "epoch 6; iter: 0; batch classifier loss: 0.857604; batch adversarial loss: 0.397536\n",
      "epoch 6; iter: 200; batch classifier loss: 0.735656; batch adversarial loss: 0.503829\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619596; batch adversarial loss: 0.379866\n",
      "epoch 7; iter: 200; batch classifier loss: 2.093954; batch adversarial loss: 0.421057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555463; batch adversarial loss: 0.388580\n",
      "epoch 8; iter: 200; batch classifier loss: 0.451106; batch adversarial loss: 0.383719\n",
      "epoch 9; iter: 0; batch classifier loss: 1.210152; batch adversarial loss: 0.355056\n",
      "epoch 9; iter: 200; batch classifier loss: 0.285570; batch adversarial loss: 0.431081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.451196; batch adversarial loss: 0.373070\n",
      "epoch 10; iter: 200; batch classifier loss: 0.458281; batch adversarial loss: 0.419404\n",
      "epoch 11; iter: 0; batch classifier loss: 0.905588; batch adversarial loss: 0.467030\n",
      "epoch 11; iter: 200; batch classifier loss: 0.394462; batch adversarial loss: 0.409168\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556680; batch adversarial loss: 0.461825\n",
      "epoch 12; iter: 200; batch classifier loss: 0.435624; batch adversarial loss: 0.431602\n",
      "epoch 13; iter: 0; batch classifier loss: 0.357442; batch adversarial loss: 0.382896\n",
      "epoch 13; iter: 200; batch classifier loss: 0.351805; batch adversarial loss: 0.429826\n",
      "epoch 14; iter: 0; batch classifier loss: 0.434061; batch adversarial loss: 0.412069\n",
      "epoch 14; iter: 200; batch classifier loss: 0.370281; batch adversarial loss: 0.340316\n",
      "epoch 15; iter: 0; batch classifier loss: 0.420137; batch adversarial loss: 0.373162\n",
      "epoch 15; iter: 200; batch classifier loss: 0.347204; batch adversarial loss: 0.376788\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371280; batch adversarial loss: 0.342294\n",
      "epoch 16; iter: 200; batch classifier loss: 0.387990; batch adversarial loss: 0.430196\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363333; batch adversarial loss: 0.345378\n",
      "epoch 17; iter: 200; batch classifier loss: 0.334800; batch adversarial loss: 0.424334\n",
      "epoch 18; iter: 0; batch classifier loss: 0.386042; batch adversarial loss: 0.407062\n",
      "epoch 18; iter: 200; batch classifier loss: 0.325575; batch adversarial loss: 0.515354\n",
      "epoch 19; iter: 0; batch classifier loss: 0.333566; batch adversarial loss: 0.442209\n",
      "epoch 19; iter: 200; batch classifier loss: 0.406628; batch adversarial loss: 0.413910\n",
      "epoch 20; iter: 0; batch classifier loss: 0.353948; batch adversarial loss: 0.405862\n",
      "epoch 20; iter: 200; batch classifier loss: 0.307658; batch adversarial loss: 0.405646\n",
      "epoch 21; iter: 0; batch classifier loss: 0.409260; batch adversarial loss: 0.391102\n",
      "epoch 21; iter: 200; batch classifier loss: 0.393783; batch adversarial loss: 0.415325\n",
      "epoch 22; iter: 0; batch classifier loss: 0.224469; batch adversarial loss: 0.449808\n",
      "epoch 22; iter: 200; batch classifier loss: 0.396065; batch adversarial loss: 0.294008\n",
      "epoch 23; iter: 0; batch classifier loss: 0.399772; batch adversarial loss: 0.418685\n",
      "epoch 23; iter: 200; batch classifier loss: 0.312585; batch adversarial loss: 0.412053\n",
      "epoch 24; iter: 0; batch classifier loss: 0.414552; batch adversarial loss: 0.335394\n",
      "epoch 24; iter: 200; batch classifier loss: 0.308891; batch adversarial loss: 0.406716\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311427; batch adversarial loss: 0.410456\n",
      "epoch 25; iter: 200; batch classifier loss: 0.373055; batch adversarial loss: 0.363880\n",
      "epoch 26; iter: 0; batch classifier loss: 0.307129; batch adversarial loss: 0.382172\n",
      "epoch 26; iter: 200; batch classifier loss: 0.332157; batch adversarial loss: 0.449965\n",
      "epoch 27; iter: 0; batch classifier loss: 0.254632; batch adversarial loss: 0.508894\n",
      "epoch 27; iter: 200; batch classifier loss: 0.388046; batch adversarial loss: 0.421724\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375578; batch adversarial loss: 0.429797\n",
      "epoch 28; iter: 200; batch classifier loss: 0.426732; batch adversarial loss: 0.413925\n",
      "epoch 29; iter: 0; batch classifier loss: 0.367977; batch adversarial loss: 0.333081\n",
      "epoch 29; iter: 200; batch classifier loss: 0.302677; batch adversarial loss: 0.357927\n",
      "epoch 30; iter: 0; batch classifier loss: 0.306464; batch adversarial loss: 0.478835\n",
      "epoch 30; iter: 200; batch classifier loss: 0.346835; batch adversarial loss: 0.348205\n",
      "epoch 31; iter: 0; batch classifier loss: 0.351025; batch adversarial loss: 0.482957\n",
      "epoch 31; iter: 200; batch classifier loss: 0.368449; batch adversarial loss: 0.450481\n",
      "epoch 32; iter: 0; batch classifier loss: 0.331197; batch adversarial loss: 0.364936\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397733; batch adversarial loss: 0.402871\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363768; batch adversarial loss: 0.459318\n",
      "epoch 33; iter: 200; batch classifier loss: 0.359261; batch adversarial loss: 0.399179\n",
      "epoch 34; iter: 0; batch classifier loss: 0.353491; batch adversarial loss: 0.350733\n",
      "epoch 34; iter: 200; batch classifier loss: 0.337167; batch adversarial loss: 0.378631\n",
      "epoch 35; iter: 0; batch classifier loss: 0.295569; batch adversarial loss: 0.467425\n",
      "epoch 35; iter: 200; batch classifier loss: 0.275475; batch adversarial loss: 0.353879\n",
      "epoch 36; iter: 0; batch classifier loss: 0.297367; batch adversarial loss: 0.305552\n",
      "epoch 36; iter: 200; batch classifier loss: 0.297710; batch adversarial loss: 0.429297\n",
      "epoch 37; iter: 0; batch classifier loss: 0.441676; batch adversarial loss: 0.384650\n",
      "epoch 37; iter: 200; batch classifier loss: 0.392483; batch adversarial loss: 0.361236\n",
      "epoch 38; iter: 0; batch classifier loss: 0.353064; batch adversarial loss: 0.347920\n",
      "epoch 38; iter: 200; batch classifier loss: 0.301938; batch adversarial loss: 0.465684\n",
      "epoch 39; iter: 0; batch classifier loss: 0.455673; batch adversarial loss: 0.342086\n",
      "epoch 39; iter: 200; batch classifier loss: 0.394851; batch adversarial loss: 0.527439\n",
      "epoch 40; iter: 0; batch classifier loss: 0.258326; batch adversarial loss: 0.364239\n",
      "epoch 40; iter: 200; batch classifier loss: 0.239829; batch adversarial loss: 0.445255\n",
      "epoch 41; iter: 0; batch classifier loss: 0.345599; batch adversarial loss: 0.342760\n",
      "epoch 41; iter: 200; batch classifier loss: 0.301609; batch adversarial loss: 0.416632\n",
      "epoch 42; iter: 0; batch classifier loss: 0.393299; batch adversarial loss: 0.516347\n",
      "epoch 42; iter: 200; batch classifier loss: 0.334335; batch adversarial loss: 0.403872\n",
      "epoch 43; iter: 0; batch classifier loss: 0.547455; batch adversarial loss: 0.475796\n",
      "epoch 43; iter: 200; batch classifier loss: 0.294775; batch adversarial loss: 0.449954\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336206; batch adversarial loss: 0.415107\n",
      "epoch 44; iter: 200; batch classifier loss: 0.354728; batch adversarial loss: 0.377605\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419689; batch adversarial loss: 0.428183\n",
      "epoch 45; iter: 200; batch classifier loss: 0.315539; batch adversarial loss: 0.454163\n",
      "epoch 46; iter: 0; batch classifier loss: 0.347049; batch adversarial loss: 0.372868\n",
      "epoch 46; iter: 200; batch classifier loss: 0.337267; batch adversarial loss: 0.364446\n",
      "epoch 47; iter: 0; batch classifier loss: 0.324092; batch adversarial loss: 0.377312\n",
      "epoch 47; iter: 200; batch classifier loss: 0.339554; batch adversarial loss: 0.316392\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375943; batch adversarial loss: 0.390687\n",
      "epoch 48; iter: 200; batch classifier loss: 0.501378; batch adversarial loss: 0.405737\n",
      "epoch 49; iter: 0; batch classifier loss: 0.294821; batch adversarial loss: 0.318950\n",
      "epoch 49; iter: 200; batch classifier loss: 0.373833; batch adversarial loss: 0.376005\n",
      "epoch 0; iter: 0; batch classifier loss: 19.804810; batch adversarial loss: 0.564502\n",
      "epoch 0; iter: 200; batch classifier loss: 4.201657; batch adversarial loss: 0.505311\n",
      "epoch 1; iter: 0; batch classifier loss: 6.838667; batch adversarial loss: 0.487711\n",
      "epoch 1; iter: 200; batch classifier loss: 8.255946; batch adversarial loss: 0.502593\n",
      "epoch 2; iter: 0; batch classifier loss: 5.153356; batch adversarial loss: 0.483761\n",
      "epoch 2; iter: 200; batch classifier loss: 1.855884; batch adversarial loss: 0.473066\n",
      "epoch 3; iter: 0; batch classifier loss: 3.578714; batch adversarial loss: 0.400619\n",
      "epoch 3; iter: 200; batch classifier loss: 1.147834; batch adversarial loss: 0.450167\n",
      "epoch 4; iter: 0; batch classifier loss: 2.500780; batch adversarial loss: 0.464889\n",
      "epoch 4; iter: 200; batch classifier loss: 1.246658; batch adversarial loss: 0.484820\n",
      "epoch 5; iter: 0; batch classifier loss: 1.379058; batch adversarial loss: 0.443639\n",
      "epoch 5; iter: 200; batch classifier loss: 0.682149; batch adversarial loss: 0.405722\n",
      "epoch 6; iter: 0; batch classifier loss: 2.002187; batch adversarial loss: 0.545995\n",
      "epoch 6; iter: 200; batch classifier loss: 0.481706; batch adversarial loss: 0.403972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517088; batch adversarial loss: 0.440394\n",
      "epoch 7; iter: 200; batch classifier loss: 0.841345; batch adversarial loss: 0.388919\n",
      "epoch 8; iter: 0; batch classifier loss: 0.755137; batch adversarial loss: 0.456464\n",
      "epoch 8; iter: 200; batch classifier loss: 0.490618; batch adversarial loss: 0.472685\n",
      "epoch 9; iter: 0; batch classifier loss: 0.362114; batch adversarial loss: 0.499847\n",
      "epoch 9; iter: 200; batch classifier loss: 0.843096; batch adversarial loss: 0.445604\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493341; batch adversarial loss: 0.386692\n",
      "epoch 10; iter: 200; batch classifier loss: 0.388305; batch adversarial loss: 0.379079\n",
      "epoch 11; iter: 0; batch classifier loss: 0.439250; batch adversarial loss: 0.369785\n",
      "epoch 11; iter: 200; batch classifier loss: 0.405270; batch adversarial loss: 0.357723\n",
      "epoch 12; iter: 0; batch classifier loss: 0.440574; batch adversarial loss: 0.464256\n",
      "epoch 12; iter: 200; batch classifier loss: 0.406348; batch adversarial loss: 0.487380\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372800; batch adversarial loss: 0.431824\n",
      "epoch 13; iter: 200; batch classifier loss: 0.411256; batch adversarial loss: 0.366176\n",
      "epoch 14; iter: 0; batch classifier loss: 0.359773; batch adversarial loss: 0.451920\n",
      "epoch 14; iter: 200; batch classifier loss: 0.370063; batch adversarial loss: 0.365436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.437044; batch adversarial loss: 0.518377\n",
      "epoch 15; iter: 200; batch classifier loss: 0.488354; batch adversarial loss: 0.355116\n",
      "epoch 16; iter: 0; batch classifier loss: 0.422555; batch adversarial loss: 0.339680\n",
      "epoch 16; iter: 200; batch classifier loss: 0.405005; batch adversarial loss: 0.357551\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374209; batch adversarial loss: 0.476825\n",
      "epoch 17; iter: 200; batch classifier loss: 0.324511; batch adversarial loss: 0.441367\n",
      "epoch 18; iter: 0; batch classifier loss: 0.583515; batch adversarial loss: 0.351395\n",
      "epoch 18; iter: 200; batch classifier loss: 0.433900; batch adversarial loss: 0.392594\n",
      "epoch 19; iter: 0; batch classifier loss: 0.341924; batch adversarial loss: 0.511043\n",
      "epoch 19; iter: 200; batch classifier loss: 0.364693; batch adversarial loss: 0.371065\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434541; batch adversarial loss: 0.464070\n",
      "epoch 20; iter: 200; batch classifier loss: 0.332984; batch adversarial loss: 0.420338\n",
      "epoch 21; iter: 0; batch classifier loss: 0.281072; batch adversarial loss: 0.495765\n",
      "epoch 21; iter: 200; batch classifier loss: 0.371737; batch adversarial loss: 0.422636\n",
      "epoch 22; iter: 0; batch classifier loss: 0.325953; batch adversarial loss: 0.406600\n",
      "epoch 22; iter: 200; batch classifier loss: 0.300334; batch adversarial loss: 0.372684\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400583; batch adversarial loss: 0.360650\n",
      "epoch 23; iter: 200; batch classifier loss: 0.377776; batch adversarial loss: 0.407580\n",
      "epoch 24; iter: 0; batch classifier loss: 0.398304; batch adversarial loss: 0.452989\n",
      "epoch 24; iter: 200; batch classifier loss: 0.316268; batch adversarial loss: 0.451667\n",
      "epoch 25; iter: 0; batch classifier loss: 0.332004; batch adversarial loss: 0.489245\n",
      "epoch 25; iter: 200; batch classifier loss: 0.316024; batch adversarial loss: 0.440666\n",
      "epoch 26; iter: 0; batch classifier loss: 0.337473; batch adversarial loss: 0.416678\n",
      "epoch 26; iter: 200; batch classifier loss: 0.341641; batch adversarial loss: 0.497834\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272247; batch adversarial loss: 0.451210\n",
      "epoch 27; iter: 200; batch classifier loss: 0.268304; batch adversarial loss: 0.386930\n",
      "epoch 28; iter: 0; batch classifier loss: 0.306786; batch adversarial loss: 0.438684\n",
      "epoch 28; iter: 200; batch classifier loss: 0.399896; batch adversarial loss: 0.439003\n",
      "epoch 29; iter: 0; batch classifier loss: 0.308030; batch adversarial loss: 0.413140\n",
      "epoch 29; iter: 200; batch classifier loss: 0.330611; batch adversarial loss: 0.447586\n",
      "epoch 30; iter: 0; batch classifier loss: 0.291656; batch adversarial loss: 0.442402\n",
      "epoch 30; iter: 200; batch classifier loss: 0.423912; batch adversarial loss: 0.347034\n",
      "epoch 31; iter: 0; batch classifier loss: 0.303863; batch adversarial loss: 0.362602\n",
      "epoch 31; iter: 200; batch classifier loss: 0.327296; batch adversarial loss: 0.333456\n",
      "epoch 32; iter: 0; batch classifier loss: 0.282044; batch adversarial loss: 0.343002\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397829; batch adversarial loss: 0.401604\n",
      "epoch 33; iter: 0; batch classifier loss: 0.361150; batch adversarial loss: 0.388303\n",
      "epoch 33; iter: 200; batch classifier loss: 0.331060; batch adversarial loss: 0.477046\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276396; batch adversarial loss: 0.470587\n",
      "epoch 34; iter: 200; batch classifier loss: 0.310228; batch adversarial loss: 0.368167\n",
      "epoch 35; iter: 0; batch classifier loss: 0.307551; batch adversarial loss: 0.430103\n",
      "epoch 35; iter: 200; batch classifier loss: 0.299258; batch adversarial loss: 0.467354\n",
      "epoch 36; iter: 0; batch classifier loss: 0.335552; batch adversarial loss: 0.396800\n",
      "epoch 36; iter: 200; batch classifier loss: 0.260227; batch adversarial loss: 0.421723\n",
      "epoch 37; iter: 0; batch classifier loss: 0.292177; batch adversarial loss: 0.485234\n",
      "epoch 37; iter: 200; batch classifier loss: 0.333034; batch adversarial loss: 0.406769\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340470; batch adversarial loss: 0.402595\n",
      "epoch 38; iter: 200; batch classifier loss: 0.279786; batch adversarial loss: 0.500406\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382235; batch adversarial loss: 0.371614\n",
      "epoch 39; iter: 200; batch classifier loss: 0.331793; batch adversarial loss: 0.424278\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409719; batch adversarial loss: 0.432049\n",
      "epoch 40; iter: 200; batch classifier loss: 0.360252; batch adversarial loss: 0.387858\n",
      "epoch 41; iter: 0; batch classifier loss: 0.339008; batch adversarial loss: 0.400928\n",
      "epoch 41; iter: 200; batch classifier loss: 0.240084; batch adversarial loss: 0.299376\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299159; batch adversarial loss: 0.420540\n",
      "epoch 42; iter: 200; batch classifier loss: 0.431270; batch adversarial loss: 0.461021\n",
      "epoch 43; iter: 0; batch classifier loss: 0.333390; batch adversarial loss: 0.403599\n",
      "epoch 43; iter: 200; batch classifier loss: 0.453051; batch adversarial loss: 0.406449\n",
      "epoch 44; iter: 0; batch classifier loss: 0.307844; batch adversarial loss: 0.451967\n",
      "epoch 44; iter: 200; batch classifier loss: 0.339844; batch adversarial loss: 0.293689\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382982; batch adversarial loss: 0.467135\n",
      "epoch 45; iter: 200; batch classifier loss: 0.354063; batch adversarial loss: 0.518038\n",
      "epoch 46; iter: 0; batch classifier loss: 0.256777; batch adversarial loss: 0.519371\n",
      "epoch 46; iter: 200; batch classifier loss: 0.302452; batch adversarial loss: 0.449570\n",
      "epoch 47; iter: 0; batch classifier loss: 0.287528; batch adversarial loss: 0.373580\n",
      "epoch 47; iter: 200; batch classifier loss: 0.324030; batch adversarial loss: 0.347594\n",
      "epoch 48; iter: 0; batch classifier loss: 0.315603; batch adversarial loss: 0.321093\n",
      "epoch 48; iter: 200; batch classifier loss: 0.311450; batch adversarial loss: 0.499083\n",
      "epoch 49; iter: 0; batch classifier loss: 0.354452; batch adversarial loss: 0.370861\n",
      "epoch 49; iter: 200; batch classifier loss: 0.357790; batch adversarial loss: 0.381097\n",
      "epoch 0; iter: 0; batch classifier loss: 7.523965; batch adversarial loss: 0.826894\n",
      "epoch 0; iter: 200; batch classifier loss: 7.755952; batch adversarial loss: 0.662675\n",
      "epoch 1; iter: 0; batch classifier loss: 9.573572; batch adversarial loss: 0.625520\n",
      "epoch 1; iter: 200; batch classifier loss: 5.867647; batch adversarial loss: 0.516902\n",
      "epoch 2; iter: 0; batch classifier loss: 5.656657; batch adversarial loss: 0.520369\n",
      "epoch 2; iter: 200; batch classifier loss: 5.918747; batch adversarial loss: 0.509015\n",
      "epoch 3; iter: 0; batch classifier loss: 4.057066; batch adversarial loss: 0.468646\n",
      "epoch 3; iter: 200; batch classifier loss: 4.932476; batch adversarial loss: 0.458929\n",
      "epoch 4; iter: 0; batch classifier loss: 1.333984; batch adversarial loss: 0.439000\n",
      "epoch 4; iter: 200; batch classifier loss: 3.682876; batch adversarial loss: 0.396378\n",
      "epoch 5; iter: 0; batch classifier loss: 3.751225; batch adversarial loss: 0.433673\n",
      "epoch 5; iter: 200; batch classifier loss: 7.967951; batch adversarial loss: 0.365459\n",
      "epoch 6; iter: 0; batch classifier loss: 1.067861; batch adversarial loss: 0.452724\n",
      "epoch 6; iter: 200; batch classifier loss: 0.965335; batch adversarial loss: 0.355564\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535547; batch adversarial loss: 0.389171\n",
      "epoch 7; iter: 200; batch classifier loss: 0.724261; batch adversarial loss: 0.402953\n",
      "epoch 8; iter: 0; batch classifier loss: 0.441837; batch adversarial loss: 0.455715\n",
      "epoch 8; iter: 200; batch classifier loss: 0.723672; batch adversarial loss: 0.474591\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512038; batch adversarial loss: 0.519646\n",
      "epoch 9; iter: 200; batch classifier loss: 0.433632; batch adversarial loss: 0.484152\n",
      "epoch 10; iter: 0; batch classifier loss: 0.544862; batch adversarial loss: 0.347167\n",
      "epoch 10; iter: 200; batch classifier loss: 0.534534; batch adversarial loss: 0.357644\n",
      "epoch 11; iter: 0; batch classifier loss: 0.380146; batch adversarial loss: 0.376575\n",
      "epoch 11; iter: 200; batch classifier loss: 0.456916; batch adversarial loss: 0.422830\n",
      "epoch 12; iter: 0; batch classifier loss: 0.436672; batch adversarial loss: 0.433055\n",
      "epoch 12; iter: 200; batch classifier loss: 0.583620; batch adversarial loss: 0.379069\n",
      "epoch 13; iter: 0; batch classifier loss: 0.397247; batch adversarial loss: 0.368967\n",
      "epoch 13; iter: 200; batch classifier loss: 0.453843; batch adversarial loss: 0.551426\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384042; batch adversarial loss: 0.392432\n",
      "epoch 14; iter: 200; batch classifier loss: 0.485646; batch adversarial loss: 0.404409\n",
      "epoch 15; iter: 0; batch classifier loss: 0.416658; batch adversarial loss: 0.391348\n",
      "epoch 15; iter: 200; batch classifier loss: 0.349362; batch adversarial loss: 0.420660\n",
      "epoch 16; iter: 0; batch classifier loss: 0.433157; batch adversarial loss: 0.376765\n",
      "epoch 16; iter: 200; batch classifier loss: 0.374846; batch adversarial loss: 0.367294\n",
      "epoch 17; iter: 0; batch classifier loss: 0.405711; batch adversarial loss: 0.429260\n",
      "epoch 17; iter: 200; batch classifier loss: 0.426988; batch adversarial loss: 0.402965\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333207; batch adversarial loss: 0.414195\n",
      "epoch 18; iter: 200; batch classifier loss: 0.318902; batch adversarial loss: 0.430468\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355059; batch adversarial loss: 0.318470\n",
      "epoch 19; iter: 200; batch classifier loss: 0.336346; batch adversarial loss: 0.430677\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295018; batch adversarial loss: 0.327281\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379156; batch adversarial loss: 0.460960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369554; batch adversarial loss: 0.532696\n",
      "epoch 21; iter: 200; batch classifier loss: 0.364223; batch adversarial loss: 0.477920\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331060; batch adversarial loss: 0.536770\n",
      "epoch 22; iter: 200; batch classifier loss: 0.368274; batch adversarial loss: 0.400604\n",
      "epoch 23; iter: 0; batch classifier loss: 0.319251; batch adversarial loss: 0.442574\n",
      "epoch 23; iter: 200; batch classifier loss: 0.320854; batch adversarial loss: 0.400720\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361805; batch adversarial loss: 0.463774\n",
      "epoch 24; iter: 200; batch classifier loss: 0.377725; batch adversarial loss: 0.405846\n",
      "epoch 25; iter: 0; batch classifier loss: 0.342283; batch adversarial loss: 0.413995\n",
      "epoch 25; iter: 200; batch classifier loss: 0.334897; batch adversarial loss: 0.508312\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426235; batch adversarial loss: 0.419573\n",
      "epoch 26; iter: 200; batch classifier loss: 0.311473; batch adversarial loss: 0.492443\n",
      "epoch 27; iter: 0; batch classifier loss: 0.347429; batch adversarial loss: 0.407972\n",
      "epoch 27; iter: 200; batch classifier loss: 0.329958; batch adversarial loss: 0.465328\n",
      "epoch 28; iter: 0; batch classifier loss: 0.347277; batch adversarial loss: 0.313386\n",
      "epoch 28; iter: 200; batch classifier loss: 0.334521; batch adversarial loss: 0.337184\n",
      "epoch 29; iter: 0; batch classifier loss: 0.309256; batch adversarial loss: 0.479953\n",
      "epoch 29; iter: 200; batch classifier loss: 0.386783; batch adversarial loss: 0.406831\n",
      "epoch 30; iter: 0; batch classifier loss: 0.326112; batch adversarial loss: 0.540236\n",
      "epoch 30; iter: 200; batch classifier loss: 0.311882; batch adversarial loss: 0.434913\n",
      "epoch 31; iter: 0; batch classifier loss: 0.309561; batch adversarial loss: 0.478966\n",
      "epoch 31; iter: 200; batch classifier loss: 0.306464; batch adversarial loss: 0.438747\n",
      "epoch 32; iter: 0; batch classifier loss: 0.338899; batch adversarial loss: 0.324499\n",
      "epoch 32; iter: 200; batch classifier loss: 0.416304; batch adversarial loss: 0.388968\n",
      "epoch 33; iter: 0; batch classifier loss: 0.304286; batch adversarial loss: 0.446495\n",
      "epoch 33; iter: 200; batch classifier loss: 0.323717; batch adversarial loss: 0.407338\n",
      "epoch 34; iter: 0; batch classifier loss: 0.339024; batch adversarial loss: 0.462355\n",
      "epoch 34; iter: 200; batch classifier loss: 0.337534; batch adversarial loss: 0.339852\n",
      "epoch 35; iter: 0; batch classifier loss: 0.312766; batch adversarial loss: 0.395452\n",
      "epoch 35; iter: 200; batch classifier loss: 0.370804; batch adversarial loss: 0.402463\n",
      "epoch 36; iter: 0; batch classifier loss: 0.325110; batch adversarial loss: 0.417300\n",
      "epoch 36; iter: 200; batch classifier loss: 0.326767; batch adversarial loss: 0.358310\n",
      "epoch 37; iter: 0; batch classifier loss: 0.270131; batch adversarial loss: 0.373737\n",
      "epoch 37; iter: 200; batch classifier loss: 0.320640; batch adversarial loss: 0.385434\n",
      "epoch 38; iter: 0; batch classifier loss: 0.385289; batch adversarial loss: 0.528242\n",
      "epoch 38; iter: 200; batch classifier loss: 0.311919; batch adversarial loss: 0.406919\n",
      "epoch 39; iter: 0; batch classifier loss: 0.298664; batch adversarial loss: 0.406016\n",
      "epoch 39; iter: 200; batch classifier loss: 0.436158; batch adversarial loss: 0.419215\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507579; batch adversarial loss: 0.436140\n",
      "epoch 40; iter: 200; batch classifier loss: 0.416460; batch adversarial loss: 0.484490\n",
      "epoch 41; iter: 0; batch classifier loss: 0.300226; batch adversarial loss: 0.319118\n",
      "epoch 41; iter: 200; batch classifier loss: 0.475709; batch adversarial loss: 0.384463\n",
      "epoch 42; iter: 0; batch classifier loss: 0.482203; batch adversarial loss: 0.387841\n",
      "epoch 42; iter: 200; batch classifier loss: 0.510158; batch adversarial loss: 0.303907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.416538; batch adversarial loss: 0.426082\n",
      "epoch 43; iter: 200; batch classifier loss: 0.503893; batch adversarial loss: 0.374092\n",
      "epoch 44; iter: 0; batch classifier loss: 0.362758; batch adversarial loss: 0.319561\n",
      "epoch 44; iter: 200; batch classifier loss: 0.496616; batch adversarial loss: 0.501784\n",
      "epoch 45; iter: 0; batch classifier loss: 0.452860; batch adversarial loss: 0.430488\n",
      "epoch 45; iter: 200; batch classifier loss: 0.507208; batch adversarial loss: 0.301176\n",
      "epoch 46; iter: 0; batch classifier loss: 0.333397; batch adversarial loss: 0.435977\n",
      "epoch 46; iter: 200; batch classifier loss: 0.458500; batch adversarial loss: 0.423449\n",
      "epoch 47; iter: 0; batch classifier loss: 0.592666; batch adversarial loss: 0.416284\n",
      "epoch 47; iter: 200; batch classifier loss: 0.459749; batch adversarial loss: 0.399031\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429524; batch adversarial loss: 0.341764\n",
      "epoch 48; iter: 200; batch classifier loss: 0.421866; batch adversarial loss: 0.373185\n",
      "epoch 49; iter: 0; batch classifier loss: 0.431351; batch adversarial loss: 0.548993\n",
      "epoch 49; iter: 200; batch classifier loss: 0.364424; batch adversarial loss: 0.402704\n",
      "epoch 0; iter: 0; batch classifier loss: 58.705219; batch adversarial loss: 0.491138\n",
      "epoch 0; iter: 200; batch classifier loss: 2.056562; batch adversarial loss: 0.546318\n",
      "epoch 1; iter: 0; batch classifier loss: 7.364254; batch adversarial loss: 0.475722\n",
      "epoch 1; iter: 200; batch classifier loss: 24.836653; batch adversarial loss: 0.489915\n",
      "epoch 2; iter: 0; batch classifier loss: 4.258118; batch adversarial loss: 0.480268\n",
      "epoch 2; iter: 200; batch classifier loss: 4.515805; batch adversarial loss: 0.506210\n",
      "epoch 3; iter: 0; batch classifier loss: 3.608070; batch adversarial loss: 0.437762\n",
      "epoch 3; iter: 200; batch classifier loss: 2.058998; batch adversarial loss: 0.461992\n",
      "epoch 4; iter: 0; batch classifier loss: 2.499497; batch adversarial loss: 0.429794\n",
      "epoch 4; iter: 200; batch classifier loss: 2.484217; batch adversarial loss: 0.615897\n",
      "epoch 5; iter: 0; batch classifier loss: 1.422660; batch adversarial loss: 0.463437\n",
      "epoch 5; iter: 200; batch classifier loss: 1.122913; batch adversarial loss: 0.453964\n",
      "epoch 6; iter: 0; batch classifier loss: 1.011214; batch adversarial loss: 0.583865\n",
      "epoch 6; iter: 200; batch classifier loss: 0.861340; batch adversarial loss: 0.544859\n",
      "epoch 7; iter: 0; batch classifier loss: 1.504633; batch adversarial loss: 0.522718\n",
      "epoch 7; iter: 200; batch classifier loss: 0.628445; batch adversarial loss: 0.462522\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634806; batch adversarial loss: 0.340733\n",
      "epoch 8; iter: 200; batch classifier loss: 0.489058; batch adversarial loss: 0.479193\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465841; batch adversarial loss: 0.370939\n",
      "epoch 9; iter: 200; batch classifier loss: 0.465244; batch adversarial loss: 0.419338\n",
      "epoch 10; iter: 0; batch classifier loss: 0.437209; batch adversarial loss: 0.399410\n",
      "epoch 10; iter: 200; batch classifier loss: 0.465702; batch adversarial loss: 0.428210\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490523; batch adversarial loss: 0.430409\n",
      "epoch 11; iter: 200; batch classifier loss: 0.431756; batch adversarial loss: 0.336960\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398336; batch adversarial loss: 0.388191\n",
      "epoch 12; iter: 200; batch classifier loss: 0.550493; batch adversarial loss: 0.460913\n",
      "epoch 13; iter: 0; batch classifier loss: 0.461783; batch adversarial loss: 0.409678\n",
      "epoch 13; iter: 200; batch classifier loss: 0.410322; batch adversarial loss: 0.470871\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339025; batch adversarial loss: 0.470186\n",
      "epoch 14; iter: 200; batch classifier loss: 1.024813; batch adversarial loss: 0.473641\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364821; batch adversarial loss: 0.414372\n",
      "epoch 15; iter: 200; batch classifier loss: 0.552648; batch adversarial loss: 0.308921\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423184; batch adversarial loss: 0.349515\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342253; batch adversarial loss: 0.360601\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348481; batch adversarial loss: 0.499402\n",
      "epoch 17; iter: 200; batch classifier loss: 0.388009; batch adversarial loss: 0.345857\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323669; batch adversarial loss: 0.408743\n",
      "epoch 18; iter: 200; batch classifier loss: 0.303257; batch adversarial loss: 0.411426\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343876; batch adversarial loss: 0.402392\n",
      "epoch 19; iter: 200; batch classifier loss: 0.378436; batch adversarial loss: 0.320013\n",
      "epoch 20; iter: 0; batch classifier loss: 0.372506; batch adversarial loss: 0.529667\n",
      "epoch 20; iter: 200; batch classifier loss: 0.307142; batch adversarial loss: 0.444648\n",
      "epoch 21; iter: 0; batch classifier loss: 0.349279; batch adversarial loss: 0.520921\n",
      "epoch 21; iter: 200; batch classifier loss: 0.313171; batch adversarial loss: 0.372552\n",
      "epoch 22; iter: 0; batch classifier loss: 0.320538; batch adversarial loss: 0.388975\n",
      "epoch 22; iter: 200; batch classifier loss: 0.318313; batch adversarial loss: 0.423866\n",
      "epoch 23; iter: 0; batch classifier loss: 0.352831; batch adversarial loss: 0.385327\n",
      "epoch 23; iter: 200; batch classifier loss: 0.284089; batch adversarial loss: 0.454708\n",
      "epoch 24; iter: 0; batch classifier loss: 0.383932; batch adversarial loss: 0.452297\n",
      "epoch 24; iter: 200; batch classifier loss: 0.419705; batch adversarial loss: 0.350828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.406768; batch adversarial loss: 0.381912\n",
      "epoch 25; iter: 200; batch classifier loss: 0.324117; batch adversarial loss: 0.456328\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338740; batch adversarial loss: 0.421058\n",
      "epoch 26; iter: 200; batch classifier loss: 0.349022; batch adversarial loss: 0.367502\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327792; batch adversarial loss: 0.476081\n",
      "epoch 27; iter: 200; batch classifier loss: 0.389032; batch adversarial loss: 0.408401\n",
      "epoch 28; iter: 0; batch classifier loss: 0.340262; batch adversarial loss: 0.425146\n",
      "epoch 28; iter: 200; batch classifier loss: 0.320160; batch adversarial loss: 0.480122\n",
      "epoch 29; iter: 0; batch classifier loss: 0.356614; batch adversarial loss: 0.306584\n",
      "epoch 29; iter: 200; batch classifier loss: 0.283748; batch adversarial loss: 0.424328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.345743; batch adversarial loss: 0.311643\n",
      "epoch 30; iter: 200; batch classifier loss: 0.303045; batch adversarial loss: 0.319309\n",
      "epoch 31; iter: 0; batch classifier loss: 0.371376; batch adversarial loss: 0.368209\n",
      "epoch 31; iter: 200; batch classifier loss: 0.281982; batch adversarial loss: 0.407586\n",
      "epoch 32; iter: 0; batch classifier loss: 0.546044; batch adversarial loss: 0.439327\n",
      "epoch 32; iter: 200; batch classifier loss: 0.340069; batch adversarial loss: 0.406660\n",
      "epoch 33; iter: 0; batch classifier loss: 0.265916; batch adversarial loss: 0.428843\n",
      "epoch 33; iter: 200; batch classifier loss: 0.431313; batch adversarial loss: 0.358700\n",
      "epoch 34; iter: 0; batch classifier loss: 0.319770; batch adversarial loss: 0.401258\n",
      "epoch 34; iter: 200; batch classifier loss: 0.319022; batch adversarial loss: 0.418181\n",
      "epoch 35; iter: 0; batch classifier loss: 0.237906; batch adversarial loss: 0.452632\n",
      "epoch 35; iter: 200; batch classifier loss: 0.302194; batch adversarial loss: 0.427573\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280035; batch adversarial loss: 0.380640\n",
      "epoch 36; iter: 200; batch classifier loss: 0.407993; batch adversarial loss: 0.482693\n",
      "epoch 37; iter: 0; batch classifier loss: 0.289802; batch adversarial loss: 0.391966\n",
      "epoch 37; iter: 200; batch classifier loss: 0.251645; batch adversarial loss: 0.476594\n",
      "epoch 38; iter: 0; batch classifier loss: 0.356176; batch adversarial loss: 0.400177\n",
      "epoch 38; iter: 200; batch classifier loss: 0.349945; batch adversarial loss: 0.372073\n",
      "epoch 39; iter: 0; batch classifier loss: 0.377363; batch adversarial loss: 0.407813\n",
      "epoch 39; iter: 200; batch classifier loss: 0.363880; batch adversarial loss: 0.467176\n",
      "epoch 40; iter: 0; batch classifier loss: 0.359843; batch adversarial loss: 0.440683\n",
      "epoch 40; iter: 200; batch classifier loss: 0.335218; batch adversarial loss: 0.366520\n",
      "epoch 41; iter: 0; batch classifier loss: 0.321207; batch adversarial loss: 0.292827\n",
      "epoch 41; iter: 200; batch classifier loss: 0.376888; batch adversarial loss: 0.383758\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385387; batch adversarial loss: 0.386954\n",
      "epoch 42; iter: 200; batch classifier loss: 0.401853; batch adversarial loss: 0.507564\n",
      "epoch 43; iter: 0; batch classifier loss: 0.312309; batch adversarial loss: 0.375934\n",
      "epoch 43; iter: 200; batch classifier loss: 0.309472; batch adversarial loss: 0.323736\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397144; batch adversarial loss: 0.391768\n",
      "epoch 44; iter: 200; batch classifier loss: 0.227419; batch adversarial loss: 0.422066\n",
      "epoch 45; iter: 0; batch classifier loss: 0.293501; batch adversarial loss: 0.453198\n",
      "epoch 45; iter: 200; batch classifier loss: 0.315075; batch adversarial loss: 0.328904\n",
      "epoch 46; iter: 0; batch classifier loss: 0.355901; batch adversarial loss: 0.363403\n",
      "epoch 46; iter: 200; batch classifier loss: 0.395054; batch adversarial loss: 0.379034\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371431; batch adversarial loss: 0.393534\n",
      "epoch 47; iter: 200; batch classifier loss: 0.348277; batch adversarial loss: 0.441310\n",
      "epoch 48; iter: 0; batch classifier loss: 0.311359; batch adversarial loss: 0.389801\n",
      "epoch 48; iter: 200; batch classifier loss: 0.390890; batch adversarial loss: 0.414282\n",
      "epoch 49; iter: 0; batch classifier loss: 0.346750; batch adversarial loss: 0.411107\n",
      "epoch 49; iter: 200; batch classifier loss: 0.359968; batch adversarial loss: 0.413400\n",
      "epoch 0; iter: 0; batch classifier loss: 15.241349; batch adversarial loss: 0.667527\n",
      "epoch 0; iter: 200; batch classifier loss: 9.083570; batch adversarial loss: 0.602020\n",
      "epoch 1; iter: 0; batch classifier loss: 7.154338; batch adversarial loss: 0.570509\n",
      "epoch 1; iter: 200; batch classifier loss: 3.062832; batch adversarial loss: 0.486546\n",
      "epoch 2; iter: 0; batch classifier loss: 3.541367; batch adversarial loss: 0.527286\n",
      "epoch 2; iter: 200; batch classifier loss: 3.854880; batch adversarial loss: 0.449826\n",
      "epoch 3; iter: 0; batch classifier loss: 2.735010; batch adversarial loss: 0.458245\n",
      "epoch 3; iter: 200; batch classifier loss: 1.092513; batch adversarial loss: 0.528509\n",
      "epoch 4; iter: 0; batch classifier loss: 1.583673; batch adversarial loss: 0.507655\n",
      "epoch 4; iter: 200; batch classifier loss: 1.550871; batch adversarial loss: 0.472298\n",
      "epoch 5; iter: 0; batch classifier loss: 0.900361; batch adversarial loss: 0.490738\n",
      "epoch 5; iter: 200; batch classifier loss: 1.210306; batch adversarial loss: 0.387199\n",
      "epoch 6; iter: 0; batch classifier loss: 0.824597; batch adversarial loss: 0.461156\n",
      "epoch 6; iter: 200; batch classifier loss: 0.562685; batch adversarial loss: 0.450359\n",
      "epoch 7; iter: 0; batch classifier loss: 0.739637; batch adversarial loss: 0.423973\n",
      "epoch 7; iter: 200; batch classifier loss: 0.472218; batch adversarial loss: 0.447259\n",
      "epoch 8; iter: 0; batch classifier loss: 0.398471; batch adversarial loss: 0.464768\n",
      "epoch 8; iter: 200; batch classifier loss: 0.429687; batch adversarial loss: 0.360062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.497246; batch adversarial loss: 0.411981\n",
      "epoch 9; iter: 200; batch classifier loss: 0.420048; batch adversarial loss: 0.315840\n",
      "epoch 10; iter: 0; batch classifier loss: 0.349812; batch adversarial loss: 0.332820\n",
      "epoch 10; iter: 200; batch classifier loss: 0.350951; batch adversarial loss: 0.328873\n",
      "epoch 11; iter: 0; batch classifier loss: 0.395032; batch adversarial loss: 0.333559\n",
      "epoch 11; iter: 200; batch classifier loss: 0.337364; batch adversarial loss: 0.398571\n",
      "epoch 12; iter: 0; batch classifier loss: 0.297987; batch adversarial loss: 0.446416\n",
      "epoch 12; iter: 200; batch classifier loss: 0.347410; batch adversarial loss: 0.414077\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342774; batch adversarial loss: 0.293212\n",
      "epoch 13; iter: 200; batch classifier loss: 0.383101; batch adversarial loss: 0.380603\n",
      "epoch 14; iter: 0; batch classifier loss: 0.288195; batch adversarial loss: 0.333786\n",
      "epoch 14; iter: 200; batch classifier loss: 0.374008; batch adversarial loss: 0.415324\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463970; batch adversarial loss: 0.440328\n",
      "epoch 15; iter: 200; batch classifier loss: 0.482997; batch adversarial loss: 0.464151\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379378; batch adversarial loss: 0.384058\n",
      "epoch 16; iter: 200; batch classifier loss: 0.400757; batch adversarial loss: 0.382582\n",
      "epoch 17; iter: 0; batch classifier loss: 0.458750; batch adversarial loss: 0.489470\n",
      "epoch 17; iter: 200; batch classifier loss: 0.269902; batch adversarial loss: 0.316011\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257671; batch adversarial loss: 0.340662\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336254; batch adversarial loss: 0.440066\n",
      "epoch 19; iter: 0; batch classifier loss: 0.326874; batch adversarial loss: 0.511430\n",
      "epoch 19; iter: 200; batch classifier loss: 0.321619; batch adversarial loss: 0.357827\n",
      "epoch 20; iter: 0; batch classifier loss: 0.308930; batch adversarial loss: 0.401982\n",
      "epoch 20; iter: 200; batch classifier loss: 0.292459; batch adversarial loss: 0.482293\n",
      "epoch 21; iter: 0; batch classifier loss: 0.356027; batch adversarial loss: 0.461615\n",
      "epoch 21; iter: 200; batch classifier loss: 0.366760; batch adversarial loss: 0.289980\n",
      "epoch 22; iter: 0; batch classifier loss: 0.340679; batch adversarial loss: 0.446594\n",
      "epoch 22; iter: 200; batch classifier loss: 0.383043; batch adversarial loss: 0.452415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313246; batch adversarial loss: 0.441267\n",
      "epoch 23; iter: 200; batch classifier loss: 0.328786; batch adversarial loss: 0.406245\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361964; batch adversarial loss: 0.451906\n",
      "epoch 24; iter: 200; batch classifier loss: 0.202608; batch adversarial loss: 0.390504\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303288; batch adversarial loss: 0.505703\n",
      "epoch 25; iter: 200; batch classifier loss: 0.320192; batch adversarial loss: 0.469156\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460760; batch adversarial loss: 0.425685\n",
      "epoch 26; iter: 200; batch classifier loss: 0.261115; batch adversarial loss: 0.504089\n",
      "epoch 27; iter: 0; batch classifier loss: 0.418462; batch adversarial loss: 0.480143\n",
      "epoch 27; iter: 200; batch classifier loss: 0.240734; batch adversarial loss: 0.432524\n",
      "epoch 28; iter: 0; batch classifier loss: 0.358830; batch adversarial loss: 0.279408\n",
      "epoch 28; iter: 200; batch classifier loss: 0.322983; batch adversarial loss: 0.335639\n",
      "epoch 29; iter: 0; batch classifier loss: 0.369351; batch adversarial loss: 0.324725\n",
      "epoch 29; iter: 200; batch classifier loss: 0.372262; batch adversarial loss: 0.347745\n",
      "epoch 30; iter: 0; batch classifier loss: 0.380958; batch adversarial loss: 0.391909\n",
      "epoch 30; iter: 200; batch classifier loss: 0.305665; batch adversarial loss: 0.470571\n",
      "epoch 31; iter: 0; batch classifier loss: 0.314486; batch adversarial loss: 0.556055\n",
      "epoch 31; iter: 200; batch classifier loss: 0.375151; batch adversarial loss: 0.424473\n",
      "epoch 32; iter: 0; batch classifier loss: 0.273504; batch adversarial loss: 0.361757\n",
      "epoch 32; iter: 200; batch classifier loss: 0.269560; batch adversarial loss: 0.433874\n",
      "epoch 33; iter: 0; batch classifier loss: 0.343795; batch adversarial loss: 0.438499\n",
      "epoch 33; iter: 200; batch classifier loss: 0.293598; batch adversarial loss: 0.301249\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445354; batch adversarial loss: 0.428805\n",
      "epoch 34; iter: 200; batch classifier loss: 0.469640; batch adversarial loss: 0.380080\n",
      "epoch 35; iter: 0; batch classifier loss: 0.319789; batch adversarial loss: 0.411286\n",
      "epoch 35; iter: 200; batch classifier loss: 0.333539; batch adversarial loss: 0.375136\n",
      "epoch 36; iter: 0; batch classifier loss: 0.298909; batch adversarial loss: 0.492008\n",
      "epoch 36; iter: 200; batch classifier loss: 0.288959; batch adversarial loss: 0.466822\n",
      "epoch 37; iter: 0; batch classifier loss: 0.261321; batch adversarial loss: 0.394746\n",
      "epoch 37; iter: 200; batch classifier loss: 0.234240; batch adversarial loss: 0.326279\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340316; batch adversarial loss: 0.441999\n",
      "epoch 38; iter: 200; batch classifier loss: 0.357135; batch adversarial loss: 0.415275\n",
      "epoch 39; iter: 0; batch classifier loss: 0.281937; batch adversarial loss: 0.332549\n",
      "epoch 39; iter: 200; batch classifier loss: 0.345404; batch adversarial loss: 0.454895\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351847; batch adversarial loss: 0.378601\n",
      "epoch 40; iter: 200; batch classifier loss: 0.265348; batch adversarial loss: 0.373702\n",
      "epoch 41; iter: 0; batch classifier loss: 0.301253; batch adversarial loss: 0.358405\n",
      "epoch 41; iter: 200; batch classifier loss: 0.335998; batch adversarial loss: 0.426355\n",
      "epoch 42; iter: 0; batch classifier loss: 0.336027; batch adversarial loss: 0.326651\n",
      "epoch 42; iter: 200; batch classifier loss: 0.614120; batch adversarial loss: 0.446062\n",
      "epoch 43; iter: 0; batch classifier loss: 0.231439; batch adversarial loss: 0.569968\n",
      "epoch 43; iter: 200; batch classifier loss: 0.348076; batch adversarial loss: 0.393013\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375711; batch adversarial loss: 0.477781\n",
      "epoch 44; iter: 200; batch classifier loss: 0.335729; batch adversarial loss: 0.403618\n",
      "epoch 45; iter: 0; batch classifier loss: 0.405961; batch adversarial loss: 0.317997\n",
      "epoch 45; iter: 200; batch classifier loss: 0.322392; batch adversarial loss: 0.320781\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398523; batch adversarial loss: 0.419732\n",
      "epoch 46; iter: 200; batch classifier loss: 0.380100; batch adversarial loss: 0.351790\n",
      "epoch 47; iter: 0; batch classifier loss: 0.298202; batch adversarial loss: 0.454716\n",
      "epoch 47; iter: 200; batch classifier loss: 0.578101; batch adversarial loss: 0.312219\n",
      "epoch 48; iter: 0; batch classifier loss: 0.315025; batch adversarial loss: 0.445181\n",
      "epoch 48; iter: 200; batch classifier loss: 0.306600; batch adversarial loss: 0.454532\n",
      "epoch 49; iter: 0; batch classifier loss: 0.240900; batch adversarial loss: 0.433126\n",
      "epoch 49; iter: 200; batch classifier loss: 0.436796; batch adversarial loss: 0.413449\n",
      "epoch 0; iter: 0; batch classifier loss: 55.366806; batch adversarial loss: 0.694033\n",
      "epoch 0; iter: 200; batch classifier loss: 28.493252; batch adversarial loss: 0.602547\n",
      "epoch 1; iter: 0; batch classifier loss: 7.555454; batch adversarial loss: 0.587602\n",
      "epoch 1; iter: 200; batch classifier loss: 4.460537; batch adversarial loss: 0.510580\n",
      "epoch 2; iter: 0; batch classifier loss: 3.377009; batch adversarial loss: 0.474868\n",
      "epoch 2; iter: 200; batch classifier loss: 6.634889; batch adversarial loss: 0.474284\n",
      "epoch 3; iter: 0; batch classifier loss: 1.820308; batch adversarial loss: 0.494753\n",
      "epoch 3; iter: 200; batch classifier loss: 2.458386; batch adversarial loss: 0.495765\n",
      "epoch 4; iter: 0; batch classifier loss: 4.531780; batch adversarial loss: 0.423077\n",
      "epoch 4; iter: 200; batch classifier loss: 2.298500; batch adversarial loss: 0.498081\n",
      "epoch 5; iter: 0; batch classifier loss: 1.621739; batch adversarial loss: 0.477120\n",
      "epoch 5; iter: 200; batch classifier loss: 1.559909; batch adversarial loss: 0.521486\n",
      "epoch 6; iter: 0; batch classifier loss: 3.352220; batch adversarial loss: 0.421309\n",
      "epoch 6; iter: 200; batch classifier loss: 0.884206; batch adversarial loss: 0.368384\n",
      "epoch 7; iter: 0; batch classifier loss: 1.078984; batch adversarial loss: 0.434627\n",
      "epoch 7; iter: 200; batch classifier loss: 0.513083; batch adversarial loss: 0.473889\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538988; batch adversarial loss: 0.345503\n",
      "epoch 8; iter: 200; batch classifier loss: 0.508545; batch adversarial loss: 0.517764\n",
      "epoch 9; iter: 0; batch classifier loss: 0.399482; batch adversarial loss: 0.392423\n",
      "epoch 9; iter: 200; batch classifier loss: 0.521816; batch adversarial loss: 0.407156\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400675; batch adversarial loss: 0.377203\n",
      "epoch 10; iter: 200; batch classifier loss: 0.364459; batch adversarial loss: 0.473607\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555810; batch adversarial loss: 0.406143\n",
      "epoch 11; iter: 200; batch classifier loss: 0.317565; batch adversarial loss: 0.492485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405171; batch adversarial loss: 0.376049\n",
      "epoch 12; iter: 200; batch classifier loss: 0.451066; batch adversarial loss: 0.342379\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431940; batch adversarial loss: 0.312803\n",
      "epoch 13; iter: 200; batch classifier loss: 0.570218; batch adversarial loss: 0.384613\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354592; batch adversarial loss: 0.393136\n",
      "epoch 14; iter: 200; batch classifier loss: 0.369005; batch adversarial loss: 0.428721\n",
      "epoch 15; iter: 0; batch classifier loss: 0.367674; batch adversarial loss: 0.417753\n",
      "epoch 15; iter: 200; batch classifier loss: 0.395917; batch adversarial loss: 0.453544\n",
      "epoch 16; iter: 0; batch classifier loss: 0.395490; batch adversarial loss: 0.469447\n",
      "epoch 16; iter: 200; batch classifier loss: 0.349952; batch adversarial loss: 0.351197\n",
      "epoch 17; iter: 0; batch classifier loss: 0.394105; batch adversarial loss: 0.420845\n",
      "epoch 17; iter: 200; batch classifier loss: 0.306452; batch adversarial loss: 0.383444\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398302; batch adversarial loss: 0.284208\n",
      "epoch 18; iter: 200; batch classifier loss: 0.319195; batch adversarial loss: 0.378037\n",
      "epoch 19; iter: 0; batch classifier loss: 0.407401; batch adversarial loss: 0.356243\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387389; batch adversarial loss: 0.387736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.321695; batch adversarial loss: 0.433014\n",
      "epoch 20; iter: 200; batch classifier loss: 0.303993; batch adversarial loss: 0.458162\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369059; batch adversarial loss: 0.386216\n",
      "epoch 21; iter: 200; batch classifier loss: 0.427842; batch adversarial loss: 0.393905\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354746; batch adversarial loss: 0.506129\n",
      "epoch 22; iter: 200; batch classifier loss: 0.307791; batch adversarial loss: 0.407690\n",
      "epoch 23; iter: 0; batch classifier loss: 0.361778; batch adversarial loss: 0.507977\n",
      "epoch 23; iter: 200; batch classifier loss: 0.342409; batch adversarial loss: 0.432360\n",
      "epoch 24; iter: 0; batch classifier loss: 0.344386; batch adversarial loss: 0.374084\n",
      "epoch 24; iter: 200; batch classifier loss: 0.308310; batch adversarial loss: 0.399459\n",
      "epoch 25; iter: 0; batch classifier loss: 0.354680; batch adversarial loss: 0.407474\n",
      "epoch 25; iter: 200; batch classifier loss: 0.358771; batch adversarial loss: 0.466776\n",
      "epoch 26; iter: 0; batch classifier loss: 0.335461; batch adversarial loss: 0.573878\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336689; batch adversarial loss: 0.435591\n",
      "epoch 27; iter: 0; batch classifier loss: 0.393238; batch adversarial loss: 0.358712\n",
      "epoch 27; iter: 200; batch classifier loss: 0.340366; batch adversarial loss: 0.444496\n",
      "epoch 28; iter: 0; batch classifier loss: 0.334196; batch adversarial loss: 0.401310\n",
      "epoch 28; iter: 200; batch classifier loss: 0.348817; batch adversarial loss: 0.280159\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322061; batch adversarial loss: 0.377086\n",
      "epoch 29; iter: 200; batch classifier loss: 0.273800; batch adversarial loss: 0.481031\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265409; batch adversarial loss: 0.457905\n",
      "epoch 30; iter: 200; batch classifier loss: 0.278588; batch adversarial loss: 0.405840\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432280; batch adversarial loss: 0.461692\n",
      "epoch 31; iter: 200; batch classifier loss: 0.315738; batch adversarial loss: 0.339571\n",
      "epoch 32; iter: 0; batch classifier loss: 0.273559; batch adversarial loss: 0.435968\n",
      "epoch 32; iter: 200; batch classifier loss: 0.293714; batch adversarial loss: 0.421846\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447410; batch adversarial loss: 0.344515\n",
      "epoch 33; iter: 200; batch classifier loss: 0.350485; batch adversarial loss: 0.397672\n",
      "epoch 34; iter: 0; batch classifier loss: 0.296349; batch adversarial loss: 0.528112\n",
      "epoch 34; iter: 200; batch classifier loss: 0.426527; batch adversarial loss: 0.410279\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410503; batch adversarial loss: 0.380457\n",
      "epoch 35; iter: 200; batch classifier loss: 0.382985; batch adversarial loss: 0.533608\n",
      "epoch 36; iter: 0; batch classifier loss: 0.323249; batch adversarial loss: 0.424284\n",
      "epoch 36; iter: 200; batch classifier loss: 0.344421; batch adversarial loss: 0.383142\n",
      "epoch 37; iter: 0; batch classifier loss: 0.391713; batch adversarial loss: 0.316235\n",
      "epoch 37; iter: 200; batch classifier loss: 0.269289; batch adversarial loss: 0.413522\n",
      "epoch 38; iter: 0; batch classifier loss: 0.325254; batch adversarial loss: 0.373428\n",
      "epoch 38; iter: 200; batch classifier loss: 0.368782; batch adversarial loss: 0.446158\n",
      "epoch 39; iter: 0; batch classifier loss: 0.321351; batch adversarial loss: 0.496779\n",
      "epoch 39; iter: 200; batch classifier loss: 0.377689; batch adversarial loss: 0.468365\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441726; batch adversarial loss: 0.483312\n",
      "epoch 40; iter: 200; batch classifier loss: 0.348487; batch adversarial loss: 0.409498\n",
      "epoch 41; iter: 0; batch classifier loss: 0.296503; batch adversarial loss: 0.426523\n",
      "epoch 41; iter: 200; batch classifier loss: 0.323539; batch adversarial loss: 0.412916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.258911; batch adversarial loss: 0.476559\n",
      "epoch 42; iter: 200; batch classifier loss: 0.257526; batch adversarial loss: 0.511100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.252871; batch adversarial loss: 0.359059\n",
      "epoch 43; iter: 200; batch classifier loss: 0.369355; batch adversarial loss: 0.478844\n",
      "epoch 44; iter: 0; batch classifier loss: 0.285134; batch adversarial loss: 0.386564\n",
      "epoch 44; iter: 200; batch classifier loss: 0.359324; batch adversarial loss: 0.397802\n",
      "epoch 45; iter: 0; batch classifier loss: 0.311077; batch adversarial loss: 0.373828\n",
      "epoch 45; iter: 200; batch classifier loss: 0.310909; batch adversarial loss: 0.365453\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381354; batch adversarial loss: 0.490899\n",
      "epoch 46; iter: 200; batch classifier loss: 0.311790; batch adversarial loss: 0.390938\n",
      "epoch 47; iter: 0; batch classifier loss: 0.334714; batch adversarial loss: 0.307613\n",
      "epoch 47; iter: 200; batch classifier loss: 0.306046; batch adversarial loss: 0.478257\n",
      "epoch 48; iter: 0; batch classifier loss: 0.280292; batch adversarial loss: 0.428082\n",
      "epoch 48; iter: 200; batch classifier loss: 0.305372; batch adversarial loss: 0.403555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417020; batch adversarial loss: 0.355411\n",
      "epoch 49; iter: 200; batch classifier loss: 0.363081; batch adversarial loss: 0.468362\n",
      "epoch 0; iter: 0; batch classifier loss: 77.543121; batch adversarial loss: 0.541485\n",
      "epoch 0; iter: 200; batch classifier loss: 7.350858; batch adversarial loss: 0.529230\n",
      "epoch 1; iter: 0; batch classifier loss: 5.728646; batch adversarial loss: 0.560879\n",
      "epoch 1; iter: 200; batch classifier loss: 11.590070; batch adversarial loss: 0.469237\n",
      "epoch 2; iter: 0; batch classifier loss: 7.201838; batch adversarial loss: 0.495660\n",
      "epoch 2; iter: 200; batch classifier loss: 1.876955; batch adversarial loss: 0.516756\n",
      "epoch 3; iter: 0; batch classifier loss: 9.982447; batch adversarial loss: 0.500399\n",
      "epoch 3; iter: 200; batch classifier loss: 5.762837; batch adversarial loss: 0.422113\n",
      "epoch 4; iter: 0; batch classifier loss: 5.647481; batch adversarial loss: 0.503785\n",
      "epoch 4; iter: 200; batch classifier loss: 3.515815; batch adversarial loss: 0.397944\n",
      "epoch 5; iter: 0; batch classifier loss: 2.418166; batch adversarial loss: 0.331596\n",
      "epoch 5; iter: 200; batch classifier loss: 2.293289; batch adversarial loss: 0.482124\n",
      "epoch 6; iter: 0; batch classifier loss: 3.181710; batch adversarial loss: 0.410907\n",
      "epoch 6; iter: 200; batch classifier loss: 2.424304; batch adversarial loss: 0.346593\n",
      "epoch 7; iter: 0; batch classifier loss: 1.562103; batch adversarial loss: 0.326170\n",
      "epoch 7; iter: 200; batch classifier loss: 0.514896; batch adversarial loss: 0.515542\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465306; batch adversarial loss: 0.452263\n",
      "epoch 8; iter: 200; batch classifier loss: 0.519268; batch adversarial loss: 0.369018\n",
      "epoch 9; iter: 0; batch classifier loss: 0.413781; batch adversarial loss: 0.491393\n",
      "epoch 9; iter: 200; batch classifier loss: 0.889613; batch adversarial loss: 0.444286\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368241; batch adversarial loss: 0.405655\n",
      "epoch 10; iter: 200; batch classifier loss: 0.337220; batch adversarial loss: 0.388240\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495911; batch adversarial loss: 0.377032\n",
      "epoch 11; iter: 200; batch classifier loss: 0.507848; batch adversarial loss: 0.462792\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522381; batch adversarial loss: 0.438001\n",
      "epoch 12; iter: 200; batch classifier loss: 0.408132; batch adversarial loss: 0.272960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308208; batch adversarial loss: 0.426357\n",
      "epoch 13; iter: 200; batch classifier loss: 0.327223; batch adversarial loss: 0.458578\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488929; batch adversarial loss: 0.451395\n",
      "epoch 14; iter: 200; batch classifier loss: 0.321696; batch adversarial loss: 0.422136\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347482; batch adversarial loss: 0.499316\n",
      "epoch 15; iter: 200; batch classifier loss: 0.451581; batch adversarial loss: 0.328497\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414535; batch adversarial loss: 0.345439\n",
      "epoch 16; iter: 200; batch classifier loss: 0.338407; batch adversarial loss: 0.435158\n",
      "epoch 17; iter: 0; batch classifier loss: 0.359963; batch adversarial loss: 0.431511\n",
      "epoch 17; iter: 200; batch classifier loss: 0.283326; batch adversarial loss: 0.458281\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367048; batch adversarial loss: 0.318742\n",
      "epoch 18; iter: 200; batch classifier loss: 0.282700; batch adversarial loss: 0.442463\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352980; batch adversarial loss: 0.353126\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372720; batch adversarial loss: 0.362179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.358362; batch adversarial loss: 0.473079\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379898; batch adversarial loss: 0.505957\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338008; batch adversarial loss: 0.455489\n",
      "epoch 21; iter: 200; batch classifier loss: 0.500167; batch adversarial loss: 0.375275\n",
      "epoch 22; iter: 0; batch classifier loss: 0.373341; batch adversarial loss: 0.425713\n",
      "epoch 22; iter: 200; batch classifier loss: 0.348559; batch adversarial loss: 0.493211\n",
      "epoch 23; iter: 0; batch classifier loss: 0.355758; batch adversarial loss: 0.355623\n",
      "epoch 23; iter: 200; batch classifier loss: 0.295968; batch adversarial loss: 0.357224\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361400; batch adversarial loss: 0.404846\n",
      "epoch 24; iter: 200; batch classifier loss: 0.340746; batch adversarial loss: 0.357905\n",
      "epoch 25; iter: 0; batch classifier loss: 0.320492; batch adversarial loss: 0.359199\n",
      "epoch 25; iter: 200; batch classifier loss: 0.436838; batch adversarial loss: 0.441524\n",
      "epoch 26; iter: 0; batch classifier loss: 0.342700; batch adversarial loss: 0.324654\n",
      "epoch 26; iter: 200; batch classifier loss: 0.381086; batch adversarial loss: 0.398287\n",
      "epoch 27; iter: 0; batch classifier loss: 0.384898; batch adversarial loss: 0.467897\n",
      "epoch 27; iter: 200; batch classifier loss: 0.367945; batch adversarial loss: 0.479675\n",
      "epoch 28; iter: 0; batch classifier loss: 0.334434; batch adversarial loss: 0.375076\n",
      "epoch 28; iter: 200; batch classifier loss: 0.372284; batch adversarial loss: 0.305797\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358779; batch adversarial loss: 0.363007\n",
      "epoch 29; iter: 200; batch classifier loss: 0.269588; batch adversarial loss: 0.408678\n",
      "epoch 30; iter: 0; batch classifier loss: 0.371756; batch adversarial loss: 0.292663\n",
      "epoch 30; iter: 200; batch classifier loss: 0.466616; batch adversarial loss: 0.457480\n",
      "epoch 31; iter: 0; batch classifier loss: 0.394597; batch adversarial loss: 0.407133\n",
      "epoch 31; iter: 200; batch classifier loss: 0.369395; batch adversarial loss: 0.455159\n",
      "epoch 32; iter: 0; batch classifier loss: 0.315454; batch adversarial loss: 0.490065\n",
      "epoch 32; iter: 200; batch classifier loss: 0.365702; batch adversarial loss: 0.389802\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412206; batch adversarial loss: 0.355406\n",
      "epoch 33; iter: 200; batch classifier loss: 0.344024; batch adversarial loss: 0.390661\n",
      "epoch 34; iter: 0; batch classifier loss: 0.326788; batch adversarial loss: 0.314119\n",
      "epoch 34; iter: 200; batch classifier loss: 0.358889; batch adversarial loss: 0.352019\n",
      "epoch 35; iter: 0; batch classifier loss: 0.395835; batch adversarial loss: 0.426294\n",
      "epoch 35; iter: 200; batch classifier loss: 0.309234; batch adversarial loss: 0.437772\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410955; batch adversarial loss: 0.411909\n",
      "epoch 36; iter: 200; batch classifier loss: 0.389499; batch adversarial loss: 0.559802\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378930; batch adversarial loss: 0.463822\n",
      "epoch 37; iter: 200; batch classifier loss: 0.418241; batch adversarial loss: 0.382234\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261379; batch adversarial loss: 0.399574\n",
      "epoch 38; iter: 200; batch classifier loss: 0.257677; batch adversarial loss: 0.393151\n",
      "epoch 39; iter: 0; batch classifier loss: 0.313304; batch adversarial loss: 0.366382\n",
      "epoch 39; iter: 200; batch classifier loss: 0.305542; batch adversarial loss: 0.466965\n",
      "epoch 40; iter: 0; batch classifier loss: 0.416291; batch adversarial loss: 0.485187\n",
      "epoch 40; iter: 200; batch classifier loss: 0.383597; batch adversarial loss: 0.423106\n",
      "epoch 41; iter: 0; batch classifier loss: 0.320609; batch adversarial loss: 0.415245\n",
      "epoch 41; iter: 200; batch classifier loss: 0.283176; batch adversarial loss: 0.416875\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420800; batch adversarial loss: 0.387149\n",
      "epoch 42; iter: 200; batch classifier loss: 0.438553; batch adversarial loss: 0.455280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365602; batch adversarial loss: 0.330148\n",
      "epoch 43; iter: 200; batch classifier loss: 0.352316; batch adversarial loss: 0.354326\n",
      "epoch 44; iter: 0; batch classifier loss: 0.346106; batch adversarial loss: 0.393594\n",
      "epoch 44; iter: 200; batch classifier loss: 0.298934; batch adversarial loss: 0.557151\n",
      "epoch 45; iter: 0; batch classifier loss: 0.241102; batch adversarial loss: 0.416304\n",
      "epoch 45; iter: 200; batch classifier loss: 0.360026; batch adversarial loss: 0.377850\n",
      "epoch 46; iter: 0; batch classifier loss: 0.327017; batch adversarial loss: 0.418639\n",
      "epoch 46; iter: 200; batch classifier loss: 0.373359; batch adversarial loss: 0.340733\n",
      "epoch 47; iter: 0; batch classifier loss: 0.274479; batch adversarial loss: 0.353122\n",
      "epoch 47; iter: 200; batch classifier loss: 0.390924; batch adversarial loss: 0.486884\n",
      "epoch 48; iter: 0; batch classifier loss: 0.311867; batch adversarial loss: 0.459623\n",
      "epoch 48; iter: 200; batch classifier loss: 0.293876; batch adversarial loss: 0.364484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399966; batch adversarial loss: 0.398195\n",
      "epoch 49; iter: 200; batch classifier loss: 0.287084; batch adversarial loss: 0.412555\n",
      "epoch 0; iter: 0; batch classifier loss: 13.209939; batch adversarial loss: 0.568348\n",
      "epoch 0; iter: 200; batch classifier loss: 9.895437; batch adversarial loss: 0.577378\n",
      "epoch 1; iter: 0; batch classifier loss: 3.588457; batch adversarial loss: 0.531745\n",
      "epoch 1; iter: 200; batch classifier loss: 1.443135; batch adversarial loss: 0.529423\n",
      "epoch 2; iter: 0; batch classifier loss: 3.495393; batch adversarial loss: 0.537550\n",
      "epoch 2; iter: 200; batch classifier loss: 4.479418; batch adversarial loss: 0.522060\n",
      "epoch 3; iter: 0; batch classifier loss: 10.144331; batch adversarial loss: 0.446228\n",
      "epoch 3; iter: 200; batch classifier loss: 3.282499; batch adversarial loss: 0.460208\n",
      "epoch 4; iter: 0; batch classifier loss: 1.383883; batch adversarial loss: 0.457324\n",
      "epoch 4; iter: 200; batch classifier loss: 1.559710; batch adversarial loss: 0.527470\n",
      "epoch 5; iter: 0; batch classifier loss: 1.677442; batch adversarial loss: 0.464112\n",
      "epoch 5; iter: 200; batch classifier loss: 0.438465; batch adversarial loss: 0.374510\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570555; batch adversarial loss: 0.452235\n",
      "epoch 6; iter: 200; batch classifier loss: 0.811217; batch adversarial loss: 0.490947\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522664; batch adversarial loss: 0.474043\n",
      "epoch 7; iter: 200; batch classifier loss: 0.771479; batch adversarial loss: 0.364349\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550997; batch adversarial loss: 0.424095\n",
      "epoch 8; iter: 200; batch classifier loss: 0.356348; batch adversarial loss: 0.414925\n",
      "epoch 9; iter: 0; batch classifier loss: 0.406792; batch adversarial loss: 0.334650\n",
      "epoch 9; iter: 200; batch classifier loss: 0.395180; batch adversarial loss: 0.378257\n",
      "epoch 10; iter: 0; batch classifier loss: 0.350009; batch adversarial loss: 0.430787\n",
      "epoch 10; iter: 200; batch classifier loss: 0.494694; batch adversarial loss: 0.371966\n",
      "epoch 11; iter: 0; batch classifier loss: 0.438277; batch adversarial loss: 0.482201\n",
      "epoch 11; iter: 200; batch classifier loss: 0.342454; batch adversarial loss: 0.474720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.725746; batch adversarial loss: 0.390471\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420329; batch adversarial loss: 0.523623\n",
      "epoch 13; iter: 0; batch classifier loss: 0.523422; batch adversarial loss: 0.464372\n",
      "epoch 13; iter: 200; batch classifier loss: 0.356026; batch adversarial loss: 0.434462\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348180; batch adversarial loss: 0.412888\n",
      "epoch 14; iter: 200; batch classifier loss: 0.392569; batch adversarial loss: 0.319282\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373125; batch adversarial loss: 0.435134\n",
      "epoch 15; iter: 200; batch classifier loss: 0.410065; batch adversarial loss: 0.364172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402567; batch adversarial loss: 0.499701\n",
      "epoch 16; iter: 200; batch classifier loss: 0.333918; batch adversarial loss: 0.429589\n",
      "epoch 17; iter: 0; batch classifier loss: 0.427247; batch adversarial loss: 0.446926\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339540; batch adversarial loss: 0.433775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331485; batch adversarial loss: 0.358622\n",
      "epoch 18; iter: 200; batch classifier loss: 0.286449; batch adversarial loss: 0.460334\n",
      "epoch 19; iter: 0; batch classifier loss: 0.370823; batch adversarial loss: 0.497835\n",
      "epoch 19; iter: 200; batch classifier loss: 0.313128; batch adversarial loss: 0.462202\n",
      "epoch 20; iter: 0; batch classifier loss: 0.424252; batch adversarial loss: 0.437391\n",
      "epoch 20; iter: 200; batch classifier loss: 0.238820; batch adversarial loss: 0.420003\n",
      "epoch 21; iter: 0; batch classifier loss: 0.329448; batch adversarial loss: 0.443430\n",
      "epoch 21; iter: 200; batch classifier loss: 0.326877; batch adversarial loss: 0.447521\n",
      "epoch 22; iter: 0; batch classifier loss: 0.289081; batch adversarial loss: 0.353421\n",
      "epoch 22; iter: 200; batch classifier loss: 0.328796; batch adversarial loss: 0.441271\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438719; batch adversarial loss: 0.444269\n",
      "epoch 23; iter: 200; batch classifier loss: 0.260488; batch adversarial loss: 0.371621\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340057; batch adversarial loss: 0.382276\n",
      "epoch 24; iter: 200; batch classifier loss: 0.287250; batch adversarial loss: 0.361828\n",
      "epoch 25; iter: 0; batch classifier loss: 0.294936; batch adversarial loss: 0.399423\n",
      "epoch 25; iter: 200; batch classifier loss: 0.293732; batch adversarial loss: 0.533937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.370012; batch adversarial loss: 0.346983\n",
      "epoch 26; iter: 200; batch classifier loss: 0.377895; batch adversarial loss: 0.376835\n",
      "epoch 27; iter: 0; batch classifier loss: 0.351896; batch adversarial loss: 0.459312\n",
      "epoch 27; iter: 200; batch classifier loss: 0.379291; batch adversarial loss: 0.378191\n",
      "epoch 28; iter: 0; batch classifier loss: 0.371901; batch adversarial loss: 0.373958\n",
      "epoch 28; iter: 200; batch classifier loss: 0.359766; batch adversarial loss: 0.405618\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313812; batch adversarial loss: 0.438925\n",
      "epoch 29; iter: 200; batch classifier loss: 0.433149; batch adversarial loss: 0.472107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.303223; batch adversarial loss: 0.361715\n",
      "epoch 30; iter: 200; batch classifier loss: 0.374256; batch adversarial loss: 0.401894\n",
      "epoch 31; iter: 0; batch classifier loss: 0.314540; batch adversarial loss: 0.442757\n",
      "epoch 31; iter: 200; batch classifier loss: 0.298377; batch adversarial loss: 0.476282\n",
      "epoch 32; iter: 0; batch classifier loss: 0.307517; batch adversarial loss: 0.415237\n",
      "epoch 32; iter: 200; batch classifier loss: 0.332166; batch adversarial loss: 0.456766\n",
      "epoch 33; iter: 0; batch classifier loss: 0.414984; batch adversarial loss: 0.429596\n",
      "epoch 33; iter: 200; batch classifier loss: 0.352266; batch adversarial loss: 0.359816\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419468; batch adversarial loss: 0.462920\n",
      "epoch 34; iter: 200; batch classifier loss: 0.322432; batch adversarial loss: 0.371042\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464392; batch adversarial loss: 0.317832\n",
      "epoch 35; iter: 200; batch classifier loss: 0.388667; batch adversarial loss: 0.403794\n",
      "epoch 36; iter: 0; batch classifier loss: 0.377806; batch adversarial loss: 0.424108\n",
      "epoch 36; iter: 200; batch classifier loss: 0.362670; batch adversarial loss: 0.520530\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385928; batch adversarial loss: 0.411710\n",
      "epoch 37; iter: 200; batch classifier loss: 0.458733; batch adversarial loss: 0.429005\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373671; batch adversarial loss: 0.500832\n",
      "epoch 38; iter: 200; batch classifier loss: 0.347784; batch adversarial loss: 0.467492\n",
      "epoch 39; iter: 0; batch classifier loss: 0.374884; batch adversarial loss: 0.331744\n",
      "epoch 39; iter: 200; batch classifier loss: 0.288334; batch adversarial loss: 0.457886\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246113; batch adversarial loss: 0.405758\n",
      "epoch 40; iter: 200; batch classifier loss: 0.297404; batch adversarial loss: 0.466160\n",
      "epoch 41; iter: 0; batch classifier loss: 0.366697; batch adversarial loss: 0.349425\n",
      "epoch 41; iter: 200; batch classifier loss: 0.342240; batch adversarial loss: 0.404766\n",
      "epoch 42; iter: 0; batch classifier loss: 0.234870; batch adversarial loss: 0.254019\n",
      "epoch 42; iter: 200; batch classifier loss: 0.529353; batch adversarial loss: 0.347754\n",
      "epoch 43; iter: 0; batch classifier loss: 0.504922; batch adversarial loss: 0.365671\n",
      "epoch 43; iter: 200; batch classifier loss: 0.339804; batch adversarial loss: 0.513406\n",
      "epoch 44; iter: 0; batch classifier loss: 0.346586; batch adversarial loss: 0.323241\n",
      "epoch 44; iter: 200; batch classifier loss: 0.524979; batch adversarial loss: 0.454396\n",
      "epoch 45; iter: 0; batch classifier loss: 0.583827; batch adversarial loss: 0.472070\n",
      "epoch 45; iter: 200; batch classifier loss: 0.476328; batch adversarial loss: 0.451976\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469947; batch adversarial loss: 0.375923\n",
      "epoch 46; iter: 200; batch classifier loss: 0.552206; batch adversarial loss: 0.368516\n",
      "epoch 47; iter: 0; batch classifier loss: 0.485018; batch adversarial loss: 0.436871\n",
      "epoch 47; iter: 200; batch classifier loss: 0.507897; batch adversarial loss: 0.403242\n",
      "epoch 48; iter: 0; batch classifier loss: 0.444996; batch adversarial loss: 0.379311\n",
      "epoch 48; iter: 200; batch classifier loss: 0.428508; batch adversarial loss: 0.424751\n",
      "epoch 49; iter: 0; batch classifier loss: 0.546978; batch adversarial loss: 0.414119\n",
      "epoch 49; iter: 200; batch classifier loss: 0.402065; batch adversarial loss: 0.505253\n",
      "epoch 0; iter: 0; batch classifier loss: 41.989731; batch adversarial loss: 0.797777\n",
      "epoch 0; iter: 200; batch classifier loss: 7.242632; batch adversarial loss: 0.680173\n",
      "epoch 1; iter: 0; batch classifier loss: 5.500189; batch adversarial loss: 0.624868\n",
      "epoch 1; iter: 200; batch classifier loss: 9.963737; batch adversarial loss: 0.569235\n",
      "epoch 2; iter: 0; batch classifier loss: 5.311703; batch adversarial loss: 0.508476\n",
      "epoch 2; iter: 200; batch classifier loss: 8.503037; batch adversarial loss: 0.480818\n",
      "epoch 3; iter: 0; batch classifier loss: 8.155931; batch adversarial loss: 0.469325\n",
      "epoch 3; iter: 200; batch classifier loss: 1.414871; batch adversarial loss: 0.431003\n",
      "epoch 4; iter: 0; batch classifier loss: 2.731702; batch adversarial loss: 0.483936\n",
      "epoch 4; iter: 200; batch classifier loss: 2.756722; batch adversarial loss: 0.421723\n",
      "epoch 5; iter: 0; batch classifier loss: 1.757911; batch adversarial loss: 0.448501\n",
      "epoch 5; iter: 200; batch classifier loss: 1.978274; batch adversarial loss: 0.534947\n",
      "epoch 6; iter: 0; batch classifier loss: 3.388227; batch adversarial loss: 0.395514\n",
      "epoch 6; iter: 200; batch classifier loss: 1.107805; batch adversarial loss: 0.401007\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549303; batch adversarial loss: 0.460373\n",
      "epoch 7; iter: 200; batch classifier loss: 0.538310; batch adversarial loss: 0.437074\n",
      "epoch 8; iter: 0; batch classifier loss: 0.447609; batch adversarial loss: 0.384601\n",
      "epoch 8; iter: 200; batch classifier loss: 0.569654; batch adversarial loss: 0.447351\n",
      "epoch 9; iter: 0; batch classifier loss: 0.682944; batch adversarial loss: 0.390643\n",
      "epoch 9; iter: 200; batch classifier loss: 0.570608; batch adversarial loss: 0.396446\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547893; batch adversarial loss: 0.452864\n",
      "epoch 10; iter: 200; batch classifier loss: 0.459525; batch adversarial loss: 0.420499\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440500; batch adversarial loss: 0.374290\n",
      "epoch 11; iter: 200; batch classifier loss: 0.388281; batch adversarial loss: 0.402810\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356775; batch adversarial loss: 0.488662\n",
      "epoch 12; iter: 200; batch classifier loss: 0.404531; batch adversarial loss: 0.385068\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382147; batch adversarial loss: 0.330217\n",
      "epoch 13; iter: 200; batch classifier loss: 0.381474; batch adversarial loss: 0.424291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.451917; batch adversarial loss: 0.388064\n",
      "epoch 14; iter: 200; batch classifier loss: 0.263548; batch adversarial loss: 0.455690\n",
      "epoch 15; iter: 0; batch classifier loss: 0.407787; batch adversarial loss: 0.501227\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366003; batch adversarial loss: 0.351520\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467878; batch adversarial loss: 0.519357\n",
      "epoch 16; iter: 200; batch classifier loss: 0.339505; batch adversarial loss: 0.395799\n",
      "epoch 17; iter: 0; batch classifier loss: 0.355516; batch adversarial loss: 0.437033\n",
      "epoch 17; iter: 200; batch classifier loss: 0.317843; batch adversarial loss: 0.449780\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371811; batch adversarial loss: 0.376608\n",
      "epoch 18; iter: 200; batch classifier loss: 0.396038; batch adversarial loss: 0.444121\n",
      "epoch 19; iter: 0; batch classifier loss: 0.322295; batch adversarial loss: 0.339879\n",
      "epoch 19; iter: 200; batch classifier loss: 0.327880; batch adversarial loss: 0.431396\n",
      "epoch 20; iter: 0; batch classifier loss: 0.388552; batch adversarial loss: 0.407363\n",
      "epoch 20; iter: 200; batch classifier loss: 0.370649; batch adversarial loss: 0.308097\n",
      "epoch 21; iter: 0; batch classifier loss: 0.334373; batch adversarial loss: 0.409507\n",
      "epoch 21; iter: 200; batch classifier loss: 0.359672; batch adversarial loss: 0.406104\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378271; batch adversarial loss: 0.336451\n",
      "epoch 22; iter: 200; batch classifier loss: 0.374357; batch adversarial loss: 0.357631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.295645; batch adversarial loss: 0.441062\n",
      "epoch 23; iter: 200; batch classifier loss: 0.304849; batch adversarial loss: 0.382189\n",
      "epoch 24; iter: 0; batch classifier loss: 0.294601; batch adversarial loss: 0.374895\n",
      "epoch 24; iter: 200; batch classifier loss: 0.390155; batch adversarial loss: 0.376940\n",
      "epoch 25; iter: 0; batch classifier loss: 0.409620; batch adversarial loss: 0.346168\n",
      "epoch 25; iter: 200; batch classifier loss: 0.365675; batch adversarial loss: 0.408081\n",
      "epoch 26; iter: 0; batch classifier loss: 0.365863; batch adversarial loss: 0.447128\n",
      "epoch 26; iter: 200; batch classifier loss: 0.444011; batch adversarial loss: 0.328007\n",
      "epoch 27; iter: 0; batch classifier loss: 0.351897; batch adversarial loss: 0.484791\n",
      "epoch 27; iter: 200; batch classifier loss: 0.346370; batch adversarial loss: 0.403327\n",
      "epoch 28; iter: 0; batch classifier loss: 0.367334; batch adversarial loss: 0.532165\n",
      "epoch 28; iter: 200; batch classifier loss: 0.325675; batch adversarial loss: 0.399679\n",
      "epoch 29; iter: 0; batch classifier loss: 0.293079; batch adversarial loss: 0.425252\n",
      "epoch 29; iter: 200; batch classifier loss: 0.318318; batch adversarial loss: 0.404244\n",
      "epoch 30; iter: 0; batch classifier loss: 0.327335; batch adversarial loss: 0.401641\n",
      "epoch 30; iter: 200; batch classifier loss: 0.284682; batch adversarial loss: 0.342829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.374269; batch adversarial loss: 0.395022\n",
      "epoch 31; iter: 200; batch classifier loss: 0.450953; batch adversarial loss: 0.459397\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434717; batch adversarial loss: 0.372292\n",
      "epoch 32; iter: 200; batch classifier loss: 0.353555; batch adversarial loss: 0.378665\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344663; batch adversarial loss: 0.408831\n",
      "epoch 33; iter: 200; batch classifier loss: 0.294797; batch adversarial loss: 0.412274\n",
      "epoch 34; iter: 0; batch classifier loss: 0.425495; batch adversarial loss: 0.390358\n",
      "epoch 34; iter: 200; batch classifier loss: 0.354284; batch adversarial loss: 0.480557\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341141; batch adversarial loss: 0.464498\n",
      "epoch 35; iter: 200; batch classifier loss: 0.492280; batch adversarial loss: 0.390333\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465939; batch adversarial loss: 0.437737\n",
      "epoch 36; iter: 200; batch classifier loss: 0.417905; batch adversarial loss: 0.433077\n",
      "epoch 37; iter: 0; batch classifier loss: 0.382919; batch adversarial loss: 0.473501\n",
      "epoch 37; iter: 200; batch classifier loss: 0.478148; batch adversarial loss: 0.345771\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392423; batch adversarial loss: 0.465419\n",
      "epoch 38; iter: 200; batch classifier loss: 0.346639; batch adversarial loss: 0.499405\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466617; batch adversarial loss: 0.380991\n",
      "epoch 39; iter: 200; batch classifier loss: 0.265236; batch adversarial loss: 0.364858\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412611; batch adversarial loss: 0.387248\n",
      "epoch 40; iter: 200; batch classifier loss: 0.404716; batch adversarial loss: 0.335046\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397564; batch adversarial loss: 0.405786\n",
      "epoch 41; iter: 200; batch classifier loss: 0.509142; batch adversarial loss: 0.310037\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462887; batch adversarial loss: 0.373421\n",
      "epoch 42; iter: 200; batch classifier loss: 0.513036; batch adversarial loss: 0.496893\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434143; batch adversarial loss: 0.334014\n",
      "epoch 43; iter: 200; batch classifier loss: 0.496102; batch adversarial loss: 0.426218\n",
      "epoch 44; iter: 0; batch classifier loss: 0.306087; batch adversarial loss: 0.453610\n",
      "epoch 44; iter: 200; batch classifier loss: 0.405260; batch adversarial loss: 0.450696\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414601; batch adversarial loss: 0.403824\n",
      "epoch 45; iter: 200; batch classifier loss: 0.425290; batch adversarial loss: 0.307617\n",
      "epoch 46; iter: 0; batch classifier loss: 0.410941; batch adversarial loss: 0.375474\n",
      "epoch 46; iter: 200; batch classifier loss: 0.565496; batch adversarial loss: 0.375960\n",
      "epoch 47; iter: 0; batch classifier loss: 0.542374; batch adversarial loss: 0.414611\n",
      "epoch 47; iter: 200; batch classifier loss: 0.391126; batch adversarial loss: 0.444667\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495235; batch adversarial loss: 0.479084\n",
      "epoch 48; iter: 200; batch classifier loss: 0.539790; batch adversarial loss: 0.463281\n",
      "epoch 49; iter: 0; batch classifier loss: 0.421226; batch adversarial loss: 0.352172\n",
      "epoch 49; iter: 200; batch classifier loss: 0.489649; batch adversarial loss: 0.443913\n",
      "epoch 0; iter: 0; batch classifier loss: 46.035820; batch adversarial loss: 0.678300\n",
      "epoch 0; iter: 200; batch classifier loss: 4.387743; batch adversarial loss: 0.582793\n",
      "epoch 1; iter: 0; batch classifier loss: 6.362162; batch adversarial loss: 0.581531\n",
      "epoch 1; iter: 200; batch classifier loss: 4.230170; batch adversarial loss: 0.493166\n",
      "epoch 2; iter: 0; batch classifier loss: 4.139259; batch adversarial loss: 0.542432\n",
      "epoch 2; iter: 200; batch classifier loss: 3.405853; batch adversarial loss: 0.438247\n",
      "epoch 3; iter: 0; batch classifier loss: 3.529287; batch adversarial loss: 0.448528\n",
      "epoch 3; iter: 200; batch classifier loss: 2.859819; batch adversarial loss: 0.465231\n",
      "epoch 4; iter: 0; batch classifier loss: 1.633551; batch adversarial loss: 0.390913\n",
      "epoch 4; iter: 200; batch classifier loss: 5.697249; batch adversarial loss: 0.450431\n",
      "epoch 5; iter: 0; batch classifier loss: 1.411957; batch adversarial loss: 0.405513\n",
      "epoch 5; iter: 200; batch classifier loss: 1.374502; batch adversarial loss: 0.447230\n",
      "epoch 6; iter: 0; batch classifier loss: 1.345019; batch adversarial loss: 0.517911\n",
      "epoch 6; iter: 200; batch classifier loss: 0.553989; batch adversarial loss: 0.406548\n",
      "epoch 7; iter: 0; batch classifier loss: 0.637506; batch adversarial loss: 0.441424\n",
      "epoch 7; iter: 200; batch classifier loss: 0.749962; batch adversarial loss: 0.467931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542286; batch adversarial loss: 0.417440\n",
      "epoch 8; iter: 200; batch classifier loss: 0.394969; batch adversarial loss: 0.423885\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407608; batch adversarial loss: 0.413206\n",
      "epoch 9; iter: 200; batch classifier loss: 0.582638; batch adversarial loss: 0.424548\n",
      "epoch 10; iter: 0; batch classifier loss: 0.423616; batch adversarial loss: 0.387401\n",
      "epoch 10; iter: 200; batch classifier loss: 0.380610; batch adversarial loss: 0.499722\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368281; batch adversarial loss: 0.385919\n",
      "epoch 11; iter: 200; batch classifier loss: 0.262701; batch adversarial loss: 0.398516\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341182; batch adversarial loss: 0.418561\n",
      "epoch 12; iter: 200; batch classifier loss: 0.376545; batch adversarial loss: 0.398362\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407901; batch adversarial loss: 0.394436\n",
      "epoch 13; iter: 200; batch classifier loss: 0.355921; batch adversarial loss: 0.316103\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348233; batch adversarial loss: 0.333501\n",
      "epoch 14; iter: 200; batch classifier loss: 0.395450; batch adversarial loss: 0.362159\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358532; batch adversarial loss: 0.368543\n",
      "epoch 15; iter: 200; batch classifier loss: 0.516556; batch adversarial loss: 0.471159\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362746; batch adversarial loss: 0.432727\n",
      "epoch 16; iter: 200; batch classifier loss: 0.465087; batch adversarial loss: 0.400667\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337846; batch adversarial loss: 0.367292\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343293; batch adversarial loss: 0.441437\n",
      "epoch 18; iter: 0; batch classifier loss: 0.385652; batch adversarial loss: 0.319345\n",
      "epoch 18; iter: 200; batch classifier loss: 0.422667; batch adversarial loss: 0.504838\n",
      "epoch 19; iter: 0; batch classifier loss: 0.258208; batch adversarial loss: 0.454091\n",
      "epoch 19; iter: 200; batch classifier loss: 0.348939; batch adversarial loss: 0.345092\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385650; batch adversarial loss: 0.355906\n",
      "epoch 20; iter: 200; batch classifier loss: 0.351906; batch adversarial loss: 0.435382\n",
      "epoch 21; iter: 0; batch classifier loss: 0.343715; batch adversarial loss: 0.349744\n",
      "epoch 21; iter: 200; batch classifier loss: 0.271172; batch adversarial loss: 0.450777\n",
      "epoch 22; iter: 0; batch classifier loss: 0.341234; batch adversarial loss: 0.456384\n",
      "epoch 22; iter: 200; batch classifier loss: 0.269507; batch adversarial loss: 0.500095\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313279; batch adversarial loss: 0.438737\n",
      "epoch 23; iter: 200; batch classifier loss: 0.258659; batch adversarial loss: 0.363833\n",
      "epoch 24; iter: 0; batch classifier loss: 0.296424; batch adversarial loss: 0.449861\n",
      "epoch 24; iter: 200; batch classifier loss: 0.416202; batch adversarial loss: 0.454698\n",
      "epoch 25; iter: 0; batch classifier loss: 0.265756; batch adversarial loss: 0.524516\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360861; batch adversarial loss: 0.323925\n",
      "epoch 26; iter: 0; batch classifier loss: 0.358915; batch adversarial loss: 0.429144\n",
      "epoch 26; iter: 200; batch classifier loss: 0.415701; batch adversarial loss: 0.367797\n",
      "epoch 27; iter: 0; batch classifier loss: 0.319162; batch adversarial loss: 0.479011\n",
      "epoch 27; iter: 200; batch classifier loss: 0.256780; batch adversarial loss: 0.418781\n",
      "epoch 28; iter: 0; batch classifier loss: 0.318157; batch adversarial loss: 0.437317\n",
      "epoch 28; iter: 200; batch classifier loss: 0.305291; batch adversarial loss: 0.422373\n",
      "epoch 29; iter: 0; batch classifier loss: 0.373783; batch adversarial loss: 0.342492\n",
      "epoch 29; iter: 200; batch classifier loss: 0.369816; batch adversarial loss: 0.384555\n",
      "epoch 30; iter: 0; batch classifier loss: 0.330912; batch adversarial loss: 0.424909\n",
      "epoch 30; iter: 200; batch classifier loss: 0.257562; batch adversarial loss: 0.366197\n",
      "epoch 31; iter: 0; batch classifier loss: 0.277189; batch adversarial loss: 0.432722\n",
      "epoch 31; iter: 200; batch classifier loss: 0.403497; batch adversarial loss: 0.394827\n",
      "epoch 32; iter: 0; batch classifier loss: 0.340497; batch adversarial loss: 0.469744\n",
      "epoch 32; iter: 200; batch classifier loss: 0.287809; batch adversarial loss: 0.367206\n",
      "epoch 33; iter: 0; batch classifier loss: 0.333282; batch adversarial loss: 0.437762\n",
      "epoch 33; iter: 200; batch classifier loss: 0.372183; batch adversarial loss: 0.376160\n",
      "epoch 34; iter: 0; batch classifier loss: 0.250949; batch adversarial loss: 0.441306\n",
      "epoch 34; iter: 200; batch classifier loss: 0.354992; batch adversarial loss: 0.449451\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416373; batch adversarial loss: 0.428337\n",
      "epoch 35; iter: 200; batch classifier loss: 0.295748; batch adversarial loss: 0.476663\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365331; batch adversarial loss: 0.383344\n",
      "epoch 36; iter: 200; batch classifier loss: 0.300784; batch adversarial loss: 0.508769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383548; batch adversarial loss: 0.399203\n",
      "epoch 37; iter: 200; batch classifier loss: 0.319869; batch adversarial loss: 0.401756\n",
      "epoch 38; iter: 0; batch classifier loss: 0.378110; batch adversarial loss: 0.363109\n",
      "epoch 38; iter: 200; batch classifier loss: 0.309102; batch adversarial loss: 0.460294\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422825; batch adversarial loss: 0.453881\n",
      "epoch 39; iter: 200; batch classifier loss: 0.368482; batch adversarial loss: 0.402314\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419788; batch adversarial loss: 0.395394\n",
      "epoch 40; iter: 200; batch classifier loss: 0.364306; batch adversarial loss: 0.424421\n",
      "epoch 41; iter: 0; batch classifier loss: 0.606932; batch adversarial loss: 0.435298\n",
      "epoch 41; iter: 200; batch classifier loss: 0.507943; batch adversarial loss: 0.414512\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409202; batch adversarial loss: 0.419781\n",
      "epoch 42; iter: 200; batch classifier loss: 0.593942; batch adversarial loss: 0.365917\n",
      "epoch 43; iter: 0; batch classifier loss: 0.409464; batch adversarial loss: 0.387914\n",
      "epoch 43; iter: 200; batch classifier loss: 0.453918; batch adversarial loss: 0.484706\n",
      "epoch 44; iter: 0; batch classifier loss: 0.558897; batch adversarial loss: 0.391492\n",
      "epoch 44; iter: 200; batch classifier loss: 0.537235; batch adversarial loss: 0.385649\n",
      "epoch 45; iter: 0; batch classifier loss: 0.518489; batch adversarial loss: 0.390326\n",
      "epoch 45; iter: 200; batch classifier loss: 0.509801; batch adversarial loss: 0.368254\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448835; batch adversarial loss: 0.383323\n",
      "epoch 46; iter: 200; batch classifier loss: 0.510901; batch adversarial loss: 0.369059\n",
      "epoch 47; iter: 0; batch classifier loss: 0.486150; batch adversarial loss: 0.310537\n",
      "epoch 47; iter: 200; batch classifier loss: 0.496802; batch adversarial loss: 0.511712\n",
      "epoch 48; iter: 0; batch classifier loss: 0.469038; batch adversarial loss: 0.317710\n",
      "epoch 48; iter: 200; batch classifier loss: 0.464948; batch adversarial loss: 0.319440\n",
      "epoch 49; iter: 0; batch classifier loss: 0.434391; batch adversarial loss: 0.525518\n",
      "epoch 49; iter: 200; batch classifier loss: 0.612462; batch adversarial loss: 0.375006\n",
      "epoch 0; iter: 0; batch classifier loss: 177.538467; batch adversarial loss: 0.818470\n",
      "epoch 0; iter: 200; batch classifier loss: 2.422713; batch adversarial loss: 0.681787\n",
      "epoch 1; iter: 0; batch classifier loss: 11.809323; batch adversarial loss: 0.604875\n",
      "epoch 1; iter: 200; batch classifier loss: 1.020234; batch adversarial loss: 0.529373\n",
      "epoch 2; iter: 0; batch classifier loss: 8.438570; batch adversarial loss: 0.487622\n",
      "epoch 2; iter: 200; batch classifier loss: 7.090746; batch adversarial loss: 0.532937\n",
      "epoch 3; iter: 0; batch classifier loss: 2.263949; batch adversarial loss: 0.510234\n",
      "epoch 3; iter: 200; batch classifier loss: 2.436297; batch adversarial loss: 0.465211\n",
      "epoch 4; iter: 0; batch classifier loss: 2.169534; batch adversarial loss: 0.413215\n",
      "epoch 4; iter: 200; batch classifier loss: 0.978310; batch adversarial loss: 0.419703\n",
      "epoch 5; iter: 0; batch classifier loss: 1.305160; batch adversarial loss: 0.428156\n",
      "epoch 5; iter: 200; batch classifier loss: 2.145722; batch adversarial loss: 0.450851\n",
      "epoch 6; iter: 0; batch classifier loss: 1.011236; batch adversarial loss: 0.485703\n",
      "epoch 6; iter: 200; batch classifier loss: 0.727104; batch adversarial loss: 0.428896\n",
      "epoch 7; iter: 0; batch classifier loss: 0.658364; batch adversarial loss: 0.520485\n",
      "epoch 7; iter: 200; batch classifier loss: 0.464348; batch adversarial loss: 0.492935\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555520; batch adversarial loss: 0.398656\n",
      "epoch 8; iter: 200; batch classifier loss: 0.382798; batch adversarial loss: 0.428535\n",
      "epoch 9; iter: 0; batch classifier loss: 0.477338; batch adversarial loss: 0.485662\n",
      "epoch 9; iter: 200; batch classifier loss: 0.440489; batch adversarial loss: 0.384177\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446683; batch adversarial loss: 0.309807\n",
      "epoch 10; iter: 200; batch classifier loss: 0.692215; batch adversarial loss: 0.402680\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543910; batch adversarial loss: 0.373151\n",
      "epoch 11; iter: 200; batch classifier loss: 0.454567; batch adversarial loss: 0.372559\n",
      "epoch 12; iter: 0; batch classifier loss: 0.442615; batch adversarial loss: 0.415040\n",
      "epoch 12; iter: 200; batch classifier loss: 0.377779; batch adversarial loss: 0.464781\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338826; batch adversarial loss: 0.401614\n",
      "epoch 13; iter: 200; batch classifier loss: 0.423476; batch adversarial loss: 0.414941\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369747; batch adversarial loss: 0.408414\n",
      "epoch 14; iter: 200; batch classifier loss: 0.404739; batch adversarial loss: 0.343864\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350579; batch adversarial loss: 0.451391\n",
      "epoch 15; iter: 200; batch classifier loss: 0.355624; batch adversarial loss: 0.446045\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370020; batch adversarial loss: 0.393570\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388161; batch adversarial loss: 0.512139\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474430; batch adversarial loss: 0.386758\n",
      "epoch 17; iter: 200; batch classifier loss: 0.293574; batch adversarial loss: 0.343329\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320891; batch adversarial loss: 0.290682\n",
      "epoch 18; iter: 200; batch classifier loss: 0.461083; batch adversarial loss: 0.437389\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295767; batch adversarial loss: 0.522298\n",
      "epoch 19; iter: 200; batch classifier loss: 0.562323; batch adversarial loss: 0.394036\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325229; batch adversarial loss: 0.420118\n",
      "epoch 20; iter: 200; batch classifier loss: 0.328778; batch adversarial loss: 0.441574\n",
      "epoch 21; iter: 0; batch classifier loss: 0.384479; batch adversarial loss: 0.330090\n",
      "epoch 21; iter: 200; batch classifier loss: 0.279272; batch adversarial loss: 0.470912\n",
      "epoch 22; iter: 0; batch classifier loss: 0.344427; batch adversarial loss: 0.501916\n",
      "epoch 22; iter: 200; batch classifier loss: 0.315730; batch adversarial loss: 0.429179\n",
      "epoch 23; iter: 0; batch classifier loss: 0.305916; batch adversarial loss: 0.305787\n",
      "epoch 23; iter: 200; batch classifier loss: 0.358575; batch adversarial loss: 0.475189\n",
      "epoch 24; iter: 0; batch classifier loss: 0.268219; batch adversarial loss: 0.450362\n",
      "epoch 24; iter: 200; batch classifier loss: 0.326358; batch adversarial loss: 0.328543\n",
      "epoch 25; iter: 0; batch classifier loss: 0.363472; batch adversarial loss: 0.354056\n",
      "epoch 25; iter: 200; batch classifier loss: 0.270655; batch adversarial loss: 0.417789\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343389; batch adversarial loss: 0.443920\n",
      "epoch 26; iter: 200; batch classifier loss: 0.335381; batch adversarial loss: 0.312013\n",
      "epoch 27; iter: 0; batch classifier loss: 0.344936; batch adversarial loss: 0.443511\n",
      "epoch 27; iter: 200; batch classifier loss: 0.355042; batch adversarial loss: 0.320527\n",
      "epoch 28; iter: 0; batch classifier loss: 0.302311; batch adversarial loss: 0.276322\n",
      "epoch 28; iter: 200; batch classifier loss: 0.253905; batch adversarial loss: 0.468529\n",
      "epoch 29; iter: 0; batch classifier loss: 0.298341; batch adversarial loss: 0.523209\n",
      "epoch 29; iter: 200; batch classifier loss: 0.390004; batch adversarial loss: 0.397283\n",
      "epoch 30; iter: 0; batch classifier loss: 0.312833; batch adversarial loss: 0.346280\n",
      "epoch 30; iter: 200; batch classifier loss: 0.290262; batch adversarial loss: 0.424592\n",
      "epoch 31; iter: 0; batch classifier loss: 0.369815; batch adversarial loss: 0.402388\n",
      "epoch 31; iter: 200; batch classifier loss: 0.242930; batch adversarial loss: 0.420503\n",
      "epoch 32; iter: 0; batch classifier loss: 0.286042; batch adversarial loss: 0.403699\n",
      "epoch 32; iter: 200; batch classifier loss: 0.377352; batch adversarial loss: 0.405499\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370393; batch adversarial loss: 0.455439\n",
      "epoch 33; iter: 200; batch classifier loss: 0.298872; batch adversarial loss: 0.377860\n",
      "epoch 34; iter: 0; batch classifier loss: 0.396978; batch adversarial loss: 0.296286\n",
      "epoch 34; iter: 200; batch classifier loss: 0.435776; batch adversarial loss: 0.477509\n",
      "epoch 35; iter: 0; batch classifier loss: 0.408062; batch adversarial loss: 0.450384\n",
      "epoch 35; iter: 200; batch classifier loss: 0.323116; batch adversarial loss: 0.487490\n",
      "epoch 36; iter: 0; batch classifier loss: 0.383621; batch adversarial loss: 0.404276\n",
      "epoch 36; iter: 200; batch classifier loss: 0.524885; batch adversarial loss: 0.365629\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420179; batch adversarial loss: 0.312161\n",
      "epoch 37; iter: 200; batch classifier loss: 0.436511; batch adversarial loss: 0.331170\n",
      "epoch 38; iter: 0; batch classifier loss: 0.490343; batch adversarial loss: 0.428436\n",
      "epoch 38; iter: 200; batch classifier loss: 0.314689; batch adversarial loss: 0.360723\n",
      "epoch 39; iter: 0; batch classifier loss: 0.520060; batch adversarial loss: 0.346991\n",
      "epoch 39; iter: 200; batch classifier loss: 0.341419; batch adversarial loss: 0.325522\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465800; batch adversarial loss: 0.417316\n",
      "epoch 40; iter: 200; batch classifier loss: 0.519418; batch adversarial loss: 0.362748\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424073; batch adversarial loss: 0.331397\n",
      "epoch 41; iter: 200; batch classifier loss: 0.497231; batch adversarial loss: 0.448390\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431481; batch adversarial loss: 0.481255\n",
      "epoch 42; iter: 200; batch classifier loss: 0.471071; batch adversarial loss: 0.502787\n",
      "epoch 43; iter: 0; batch classifier loss: 0.477365; batch adversarial loss: 0.463071\n",
      "epoch 43; iter: 200; batch classifier loss: 0.524701; batch adversarial loss: 0.383283\n",
      "epoch 44; iter: 0; batch classifier loss: 0.571068; batch adversarial loss: 0.474160\n",
      "epoch 44; iter: 200; batch classifier loss: 0.580638; batch adversarial loss: 0.335278\n",
      "epoch 45; iter: 0; batch classifier loss: 0.491782; batch adversarial loss: 0.379167\n",
      "epoch 45; iter: 200; batch classifier loss: 0.553787; batch adversarial loss: 0.437808\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496631; batch adversarial loss: 0.410591\n",
      "epoch 46; iter: 200; batch classifier loss: 0.656349; batch adversarial loss: 0.414938\n",
      "epoch 47; iter: 0; batch classifier loss: 0.495811; batch adversarial loss: 0.382545\n",
      "epoch 47; iter: 200; batch classifier loss: 0.369965; batch adversarial loss: 0.352785\n",
      "epoch 48; iter: 0; batch classifier loss: 0.476779; batch adversarial loss: 0.430072\n",
      "epoch 48; iter: 200; batch classifier loss: 0.429765; batch adversarial loss: 0.431325\n",
      "epoch 49; iter: 0; batch classifier loss: 0.460367; batch adversarial loss: 0.474422\n",
      "epoch 49; iter: 200; batch classifier loss: 0.588790; batch adversarial loss: 0.525651\n",
      "epoch 0; iter: 0; batch classifier loss: 4.366328; batch adversarial loss: 1.213627\n",
      "epoch 0; iter: 200; batch classifier loss: 5.708585; batch adversarial loss: 0.908231\n",
      "epoch 1; iter: 0; batch classifier loss: 10.870260; batch adversarial loss: 0.924768\n",
      "epoch 1; iter: 200; batch classifier loss: 9.523203; batch adversarial loss: 0.679624\n",
      "epoch 2; iter: 0; batch classifier loss: 6.395181; batch adversarial loss: 0.642846\n",
      "epoch 2; iter: 200; batch classifier loss: 2.490717; batch adversarial loss: 0.519392\n",
      "epoch 3; iter: 0; batch classifier loss: 11.456348; batch adversarial loss: 0.489117\n",
      "epoch 3; iter: 200; batch classifier loss: 2.215945; batch adversarial loss: 0.478746\n",
      "epoch 4; iter: 0; batch classifier loss: 2.067342; batch adversarial loss: 0.419806\n",
      "epoch 4; iter: 200; batch classifier loss: 1.403689; batch adversarial loss: 0.491551\n",
      "epoch 5; iter: 0; batch classifier loss: 2.648811; batch adversarial loss: 0.463066\n",
      "epoch 5; iter: 200; batch classifier loss: 1.434878; batch adversarial loss: 0.463743\n",
      "epoch 6; iter: 0; batch classifier loss: 1.350327; batch adversarial loss: 0.434797\n",
      "epoch 6; iter: 200; batch classifier loss: 2.046126; batch adversarial loss: 0.474278\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534849; batch adversarial loss: 0.483502\n",
      "epoch 7; iter: 200; batch classifier loss: 0.726621; batch adversarial loss: 0.439292\n",
      "epoch 8; iter: 0; batch classifier loss: 0.801325; batch adversarial loss: 0.351310\n",
      "epoch 8; iter: 200; batch classifier loss: 0.591354; batch adversarial loss: 0.413442\n",
      "epoch 9; iter: 0; batch classifier loss: 0.482071; batch adversarial loss: 0.367069\n",
      "epoch 9; iter: 200; batch classifier loss: 0.670361; batch adversarial loss: 0.437303\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501471; batch adversarial loss: 0.433151\n",
      "epoch 10; iter: 200; batch classifier loss: 0.434164; batch adversarial loss: 0.399274\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549216; batch adversarial loss: 0.368858\n",
      "epoch 11; iter: 200; batch classifier loss: 0.441722; batch adversarial loss: 0.349551\n",
      "epoch 12; iter: 0; batch classifier loss: 0.425651; batch adversarial loss: 0.327438\n",
      "epoch 12; iter: 200; batch classifier loss: 0.748378; batch adversarial loss: 0.513677\n",
      "epoch 13; iter: 0; batch classifier loss: 0.371218; batch adversarial loss: 0.395825\n",
      "epoch 13; iter: 200; batch classifier loss: 0.537160; batch adversarial loss: 0.389450\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459243; batch adversarial loss: 0.374308\n",
      "epoch 14; iter: 200; batch classifier loss: 0.367057; batch adversarial loss: 0.342328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343157; batch adversarial loss: 0.372957\n",
      "epoch 15; iter: 200; batch classifier loss: 0.403019; batch adversarial loss: 0.345303\n",
      "epoch 16; iter: 0; batch classifier loss: 0.390588; batch adversarial loss: 0.400149\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399231; batch adversarial loss: 0.365251\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409502; batch adversarial loss: 0.431520\n",
      "epoch 17; iter: 200; batch classifier loss: 0.314577; batch adversarial loss: 0.342964\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286127; batch adversarial loss: 0.424251\n",
      "epoch 18; iter: 200; batch classifier loss: 0.352638; batch adversarial loss: 0.397847\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385463; batch adversarial loss: 0.363381\n",
      "epoch 19; iter: 200; batch classifier loss: 0.451008; batch adversarial loss: 0.364581\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387864; batch adversarial loss: 0.389595\n",
      "epoch 20; iter: 200; batch classifier loss: 0.435673; batch adversarial loss: 0.371677\n",
      "epoch 21; iter: 0; batch classifier loss: 0.298455; batch adversarial loss: 0.399897\n",
      "epoch 21; iter: 200; batch classifier loss: 0.352989; batch adversarial loss: 0.438459\n",
      "epoch 22; iter: 0; batch classifier loss: 0.499871; batch adversarial loss: 0.493024\n",
      "epoch 22; iter: 200; batch classifier loss: 0.339048; batch adversarial loss: 0.361649\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378045; batch adversarial loss: 0.409184\n",
      "epoch 23; iter: 200; batch classifier loss: 0.308891; batch adversarial loss: 0.457347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.499449; batch adversarial loss: 0.485514\n",
      "epoch 24; iter: 200; batch classifier loss: 0.441200; batch adversarial loss: 0.318601\n",
      "epoch 25; iter: 0; batch classifier loss: 0.309644; batch adversarial loss: 0.387786\n",
      "epoch 25; iter: 200; batch classifier loss: 0.357362; batch adversarial loss: 0.392864\n",
      "epoch 26; iter: 0; batch classifier loss: 0.341257; batch adversarial loss: 0.378155\n",
      "epoch 26; iter: 200; batch classifier loss: 0.305527; batch adversarial loss: 0.441680\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394100; batch adversarial loss: 0.388987\n",
      "epoch 27; iter: 200; batch classifier loss: 0.364249; batch adversarial loss: 0.414871\n",
      "epoch 28; iter: 0; batch classifier loss: 0.364780; batch adversarial loss: 0.420785\n",
      "epoch 28; iter: 200; batch classifier loss: 0.361697; batch adversarial loss: 0.376984\n",
      "epoch 29; iter: 0; batch classifier loss: 0.344126; batch adversarial loss: 0.405867\n",
      "epoch 29; iter: 200; batch classifier loss: 0.289369; batch adversarial loss: 0.394868\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329124; batch adversarial loss: 0.329965\n",
      "epoch 30; iter: 200; batch classifier loss: 0.301335; batch adversarial loss: 0.346263\n",
      "epoch 31; iter: 0; batch classifier loss: 0.363037; batch adversarial loss: 0.410554\n",
      "epoch 31; iter: 200; batch classifier loss: 0.391004; batch adversarial loss: 0.440498\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428846; batch adversarial loss: 0.359964\n",
      "epoch 32; iter: 200; batch classifier loss: 0.410758; batch adversarial loss: 0.391302\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400602; batch adversarial loss: 0.415963\n",
      "epoch 33; iter: 200; batch classifier loss: 0.337196; batch adversarial loss: 0.426263\n",
      "epoch 34; iter: 0; batch classifier loss: 0.300304; batch adversarial loss: 0.408601\n",
      "epoch 34; iter: 200; batch classifier loss: 0.399237; batch adversarial loss: 0.373886\n",
      "epoch 35; iter: 0; batch classifier loss: 0.347982; batch adversarial loss: 0.356024\n",
      "epoch 35; iter: 200; batch classifier loss: 0.361397; batch adversarial loss: 0.342265\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397972; batch adversarial loss: 0.470380\n",
      "epoch 36; iter: 200; batch classifier loss: 0.354055; batch adversarial loss: 0.370151\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445019; batch adversarial loss: 0.387613\n",
      "epoch 37; iter: 200; batch classifier loss: 0.344224; batch adversarial loss: 0.360921\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392541; batch adversarial loss: 0.399852\n",
      "epoch 38; iter: 200; batch classifier loss: 0.294409; batch adversarial loss: 0.416978\n",
      "epoch 39; iter: 0; batch classifier loss: 0.358128; batch adversarial loss: 0.409319\n",
      "epoch 39; iter: 200; batch classifier loss: 0.338602; batch adversarial loss: 0.402572\n",
      "epoch 40; iter: 0; batch classifier loss: 0.323710; batch adversarial loss: 0.398496\n",
      "epoch 40; iter: 200; batch classifier loss: 0.424130; batch adversarial loss: 0.372264\n",
      "epoch 41; iter: 0; batch classifier loss: 0.304059; batch adversarial loss: 0.347579\n",
      "epoch 41; iter: 200; batch classifier loss: 0.358087; batch adversarial loss: 0.441504\n",
      "epoch 42; iter: 0; batch classifier loss: 0.347933; batch adversarial loss: 0.505510\n",
      "epoch 42; iter: 200; batch classifier loss: 0.388835; batch adversarial loss: 0.468020\n",
      "epoch 43; iter: 0; batch classifier loss: 0.538314; batch adversarial loss: 0.428594\n",
      "epoch 43; iter: 200; batch classifier loss: 0.332525; batch adversarial loss: 0.399064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.370190; batch adversarial loss: 0.383134\n",
      "epoch 44; iter: 200; batch classifier loss: 0.497765; batch adversarial loss: 0.357232\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419218; batch adversarial loss: 0.441856\n",
      "epoch 45; iter: 200; batch classifier loss: 0.329985; batch adversarial loss: 0.509733\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407560; batch adversarial loss: 0.465396\n",
      "epoch 46; iter: 200; batch classifier loss: 0.390587; batch adversarial loss: 0.416279\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437385; batch adversarial loss: 0.417798\n",
      "epoch 47; iter: 200; batch classifier loss: 0.322229; batch adversarial loss: 0.425177\n",
      "epoch 48; iter: 0; batch classifier loss: 0.513850; batch adversarial loss: 0.373732\n",
      "epoch 48; iter: 200; batch classifier loss: 0.380208; batch adversarial loss: 0.391441\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478057; batch adversarial loss: 0.475462\n",
      "epoch 49; iter: 200; batch classifier loss: 0.403070; batch adversarial loss: 0.385487\n",
      "epoch 0; iter: 0; batch classifier loss: 24.307774; batch adversarial loss: 1.052056\n",
      "epoch 0; iter: 200; batch classifier loss: 11.709839; batch adversarial loss: 0.778339\n",
      "epoch 1; iter: 0; batch classifier loss: 11.388564; batch adversarial loss: 0.719654\n",
      "epoch 1; iter: 200; batch classifier loss: 2.587757; batch adversarial loss: 0.608058\n",
      "epoch 2; iter: 0; batch classifier loss: 5.085759; batch adversarial loss: 0.550893\n",
      "epoch 2; iter: 200; batch classifier loss: 0.808008; batch adversarial loss: 0.509433\n",
      "epoch 3; iter: 0; batch classifier loss: 3.226687; batch adversarial loss: 0.478429\n",
      "epoch 3; iter: 200; batch classifier loss: 2.937553; batch adversarial loss: 0.464156\n",
      "epoch 4; iter: 0; batch classifier loss: 2.589259; batch adversarial loss: 0.493893\n",
      "epoch 4; iter: 200; batch classifier loss: 1.231299; batch adversarial loss: 0.465430\n",
      "epoch 5; iter: 0; batch classifier loss: 1.904053; batch adversarial loss: 0.426849\n",
      "epoch 5; iter: 200; batch classifier loss: 4.591445; batch adversarial loss: 0.537162\n",
      "epoch 6; iter: 0; batch classifier loss: 1.119055; batch adversarial loss: 0.417207\n",
      "epoch 6; iter: 200; batch classifier loss: 1.217523; batch adversarial loss: 0.389402\n",
      "epoch 7; iter: 0; batch classifier loss: 1.056524; batch adversarial loss: 0.405992\n",
      "epoch 7; iter: 200; batch classifier loss: 1.150334; batch adversarial loss: 0.458363\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527465; batch adversarial loss: 0.450654\n",
      "epoch 8; iter: 200; batch classifier loss: 0.650453; batch adversarial loss: 0.372535\n",
      "epoch 9; iter: 0; batch classifier loss: 0.837415; batch adversarial loss: 0.464876\n",
      "epoch 9; iter: 200; batch classifier loss: 0.529947; batch adversarial loss: 0.395271\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460718; batch adversarial loss: 0.429862\n",
      "epoch 10; iter: 200; batch classifier loss: 0.590221; batch adversarial loss: 0.447045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465741; batch adversarial loss: 0.346799\n",
      "epoch 11; iter: 200; batch classifier loss: 0.465305; batch adversarial loss: 0.458485\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503883; batch adversarial loss: 0.341043\n",
      "epoch 12; iter: 200; batch classifier loss: 0.559911; batch adversarial loss: 0.414859\n",
      "epoch 13; iter: 0; batch classifier loss: 0.509939; batch adversarial loss: 0.416998\n",
      "epoch 13; iter: 200; batch classifier loss: 0.411146; batch adversarial loss: 0.412574\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473171; batch adversarial loss: 0.423053\n",
      "epoch 14; iter: 200; batch classifier loss: 0.597858; batch adversarial loss: 0.331510\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386717; batch adversarial loss: 0.413597\n",
      "epoch 15; iter: 200; batch classifier loss: 0.423127; batch adversarial loss: 0.372522\n",
      "epoch 16; iter: 0; batch classifier loss: 0.422714; batch adversarial loss: 0.457095\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399359; batch adversarial loss: 0.329157\n",
      "epoch 17; iter: 0; batch classifier loss: 0.414299; batch adversarial loss: 0.378392\n",
      "epoch 17; iter: 200; batch classifier loss: 0.338719; batch adversarial loss: 0.428860\n",
      "epoch 18; iter: 0; batch classifier loss: 0.327699; batch adversarial loss: 0.374193\n",
      "epoch 18; iter: 200; batch classifier loss: 0.368436; batch adversarial loss: 0.425007\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250995; batch adversarial loss: 0.399316\n",
      "epoch 19; iter: 200; batch classifier loss: 0.362910; batch adversarial loss: 0.455029\n",
      "epoch 20; iter: 0; batch classifier loss: 0.389571; batch adversarial loss: 0.423605\n",
      "epoch 20; iter: 200; batch classifier loss: 0.373918; batch adversarial loss: 0.463574\n",
      "epoch 21; iter: 0; batch classifier loss: 0.333493; batch adversarial loss: 0.367314\n",
      "epoch 21; iter: 200; batch classifier loss: 0.367561; batch adversarial loss: 0.409659\n",
      "epoch 22; iter: 0; batch classifier loss: 0.367816; batch adversarial loss: 0.351971\n",
      "epoch 22; iter: 200; batch classifier loss: 0.388407; batch adversarial loss: 0.485438\n",
      "epoch 23; iter: 0; batch classifier loss: 0.386745; batch adversarial loss: 0.475044\n",
      "epoch 23; iter: 200; batch classifier loss: 0.313774; batch adversarial loss: 0.469454\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329602; batch adversarial loss: 0.448183\n",
      "epoch 24; iter: 200; batch classifier loss: 0.339157; batch adversarial loss: 0.408259\n",
      "epoch 25; iter: 0; batch classifier loss: 0.359423; batch adversarial loss: 0.421419\n",
      "epoch 25; iter: 200; batch classifier loss: 0.259172; batch adversarial loss: 0.390435\n",
      "epoch 26; iter: 0; batch classifier loss: 0.306012; batch adversarial loss: 0.492268\n",
      "epoch 26; iter: 200; batch classifier loss: 0.418687; batch adversarial loss: 0.402825\n",
      "epoch 27; iter: 0; batch classifier loss: 0.309312; batch adversarial loss: 0.367646\n",
      "epoch 27; iter: 200; batch classifier loss: 0.435049; batch adversarial loss: 0.351946\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352537; batch adversarial loss: 0.359888\n",
      "epoch 28; iter: 200; batch classifier loss: 0.386226; batch adversarial loss: 0.478711\n",
      "epoch 29; iter: 0; batch classifier loss: 0.336842; batch adversarial loss: 0.354825\n",
      "epoch 29; iter: 200; batch classifier loss: 0.492505; batch adversarial loss: 0.346264\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397876; batch adversarial loss: 0.384502\n",
      "epoch 30; iter: 200; batch classifier loss: 0.300506; batch adversarial loss: 0.350782\n",
      "epoch 31; iter: 0; batch classifier loss: 0.384371; batch adversarial loss: 0.414409\n",
      "epoch 31; iter: 200; batch classifier loss: 0.356362; batch adversarial loss: 0.390672\n",
      "epoch 32; iter: 0; batch classifier loss: 0.307323; batch adversarial loss: 0.394386\n",
      "epoch 32; iter: 200; batch classifier loss: 0.338236; batch adversarial loss: 0.433609\n",
      "epoch 33; iter: 0; batch classifier loss: 0.317451; batch adversarial loss: 0.357084\n",
      "epoch 33; iter: 200; batch classifier loss: 0.348784; batch adversarial loss: 0.451640\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279555; batch adversarial loss: 0.410490\n",
      "epoch 34; iter: 200; batch classifier loss: 0.386617; batch adversarial loss: 0.359373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.331897; batch adversarial loss: 0.396500\n",
      "epoch 35; iter: 200; batch classifier loss: 0.367785; batch adversarial loss: 0.453370\n",
      "epoch 36; iter: 0; batch classifier loss: 0.382043; batch adversarial loss: 0.359641\n",
      "epoch 36; iter: 200; batch classifier loss: 0.383491; batch adversarial loss: 0.386496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404013; batch adversarial loss: 0.478308\n",
      "epoch 37; iter: 200; batch classifier loss: 0.275579; batch adversarial loss: 0.470583\n",
      "epoch 38; iter: 0; batch classifier loss: 0.498225; batch adversarial loss: 0.393009\n",
      "epoch 38; iter: 200; batch classifier loss: 0.414186; batch adversarial loss: 0.320163\n",
      "epoch 39; iter: 0; batch classifier loss: 0.304771; batch adversarial loss: 0.409524\n",
      "epoch 39; iter: 200; batch classifier loss: 0.361438; batch adversarial loss: 0.415750\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420123; batch adversarial loss: 0.474225\n",
      "epoch 40; iter: 200; batch classifier loss: 0.296275; batch adversarial loss: 0.471419\n",
      "epoch 41; iter: 0; batch classifier loss: 0.367130; batch adversarial loss: 0.479326\n",
      "epoch 41; iter: 200; batch classifier loss: 0.337312; batch adversarial loss: 0.388534\n",
      "epoch 42; iter: 0; batch classifier loss: 0.295345; batch adversarial loss: 0.426330\n",
      "epoch 42; iter: 200; batch classifier loss: 0.311153; batch adversarial loss: 0.421681\n",
      "epoch 43; iter: 0; batch classifier loss: 0.243789; batch adversarial loss: 0.542759\n",
      "epoch 43; iter: 200; batch classifier loss: 0.340730; batch adversarial loss: 0.396742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.303409; batch adversarial loss: 0.357035\n",
      "epoch 44; iter: 200; batch classifier loss: 0.266267; batch adversarial loss: 0.344770\n",
      "epoch 45; iter: 0; batch classifier loss: 0.311123; batch adversarial loss: 0.418003\n",
      "epoch 45; iter: 200; batch classifier loss: 0.277395; batch adversarial loss: 0.373918\n",
      "epoch 46; iter: 0; batch classifier loss: 0.407377; batch adversarial loss: 0.432460\n",
      "epoch 46; iter: 200; batch classifier loss: 0.326195; batch adversarial loss: 0.362422\n",
      "epoch 47; iter: 0; batch classifier loss: 0.404743; batch adversarial loss: 0.404660\n",
      "epoch 47; iter: 200; batch classifier loss: 0.348476; batch adversarial loss: 0.470161\n",
      "epoch 48; iter: 0; batch classifier loss: 0.248442; batch adversarial loss: 0.430673\n",
      "epoch 48; iter: 200; batch classifier loss: 0.266938; batch adversarial loss: 0.355147\n",
      "epoch 49; iter: 0; batch classifier loss: 0.304008; batch adversarial loss: 0.550508\n",
      "epoch 49; iter: 200; batch classifier loss: 0.299919; batch adversarial loss: 0.448715\n",
      "epoch 0; iter: 0; batch classifier loss: 15.599275; batch adversarial loss: 0.773342\n",
      "epoch 0; iter: 200; batch classifier loss: 4.396772; batch adversarial loss: 0.688587\n",
      "epoch 1; iter: 0; batch classifier loss: 4.413856; batch adversarial loss: 0.602369\n",
      "epoch 1; iter: 200; batch classifier loss: 1.766722; batch adversarial loss: 0.568385\n",
      "epoch 2; iter: 0; batch classifier loss: 1.475304; batch adversarial loss: 0.498712\n",
      "epoch 2; iter: 200; batch classifier loss: 4.990630; batch adversarial loss: 0.509958\n",
      "epoch 3; iter: 0; batch classifier loss: 2.934096; batch adversarial loss: 0.484997\n",
      "epoch 3; iter: 200; batch classifier loss: 1.843285; batch adversarial loss: 0.464847\n",
      "epoch 4; iter: 0; batch classifier loss: 1.638555; batch adversarial loss: 0.440011\n",
      "epoch 4; iter: 200; batch classifier loss: 0.775851; batch adversarial loss: 0.513625\n",
      "epoch 5; iter: 0; batch classifier loss: 2.019801; batch adversarial loss: 0.422436\n",
      "epoch 5; iter: 200; batch classifier loss: 1.607170; batch adversarial loss: 0.420554\n",
      "epoch 6; iter: 0; batch classifier loss: 0.943452; batch adversarial loss: 0.407839\n",
      "epoch 6; iter: 200; batch classifier loss: 1.047742; batch adversarial loss: 0.353327\n",
      "epoch 7; iter: 0; batch classifier loss: 0.870095; batch adversarial loss: 0.380782\n",
      "epoch 7; iter: 200; batch classifier loss: 0.392000; batch adversarial loss: 0.408819\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596112; batch adversarial loss: 0.401272\n",
      "epoch 8; iter: 200; batch classifier loss: 0.527583; batch adversarial loss: 0.405919\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539107; batch adversarial loss: 0.438010\n",
      "epoch 9; iter: 200; batch classifier loss: 0.388310; batch adversarial loss: 0.421010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.408690; batch adversarial loss: 0.415119\n",
      "epoch 10; iter: 200; batch classifier loss: 0.454900; batch adversarial loss: 0.424768\n",
      "epoch 11; iter: 0; batch classifier loss: 0.576379; batch adversarial loss: 0.422523\n",
      "epoch 11; iter: 200; batch classifier loss: 0.376651; batch adversarial loss: 0.400001\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391981; batch adversarial loss: 0.423927\n",
      "epoch 12; iter: 200; batch classifier loss: 0.342237; batch adversarial loss: 0.380304\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412474; batch adversarial loss: 0.453959\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353247; batch adversarial loss: 0.403701\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376756; batch adversarial loss: 0.384985\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379106; batch adversarial loss: 0.453845\n",
      "epoch 15; iter: 0; batch classifier loss: 0.335703; batch adversarial loss: 0.449019\n",
      "epoch 15; iter: 200; batch classifier loss: 0.356818; batch adversarial loss: 0.452141\n",
      "epoch 16; iter: 0; batch classifier loss: 0.462918; batch adversarial loss: 0.438437\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352369; batch adversarial loss: 0.441859\n",
      "epoch 17; iter: 0; batch classifier loss: 0.344117; batch adversarial loss: 0.390448\n",
      "epoch 17; iter: 200; batch classifier loss: 0.486218; batch adversarial loss: 0.369860\n",
      "epoch 18; iter: 0; batch classifier loss: 0.402186; batch adversarial loss: 0.481813\n",
      "epoch 18; iter: 200; batch classifier loss: 0.366857; batch adversarial loss: 0.467866\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458869; batch adversarial loss: 0.447483\n",
      "epoch 19; iter: 200; batch classifier loss: 0.250520; batch adversarial loss: 0.429267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299761; batch adversarial loss: 0.418348\n",
      "epoch 20; iter: 200; batch classifier loss: 0.353267; batch adversarial loss: 0.374275\n",
      "epoch 21; iter: 0; batch classifier loss: 0.413619; batch adversarial loss: 0.461635\n",
      "epoch 21; iter: 200; batch classifier loss: 0.354790; batch adversarial loss: 0.421273\n",
      "epoch 22; iter: 0; batch classifier loss: 0.302603; batch adversarial loss: 0.419749\n",
      "epoch 22; iter: 200; batch classifier loss: 0.341218; batch adversarial loss: 0.391500\n",
      "epoch 23; iter: 0; batch classifier loss: 0.432387; batch adversarial loss: 0.342764\n",
      "epoch 23; iter: 200; batch classifier loss: 0.296805; batch adversarial loss: 0.450321\n",
      "epoch 24; iter: 0; batch classifier loss: 0.286217; batch adversarial loss: 0.392462\n",
      "epoch 24; iter: 200; batch classifier loss: 0.339770; batch adversarial loss: 0.448008\n",
      "epoch 25; iter: 0; batch classifier loss: 0.367261; batch adversarial loss: 0.302464\n",
      "epoch 25; iter: 200; batch classifier loss: 0.321314; batch adversarial loss: 0.393360\n",
      "epoch 26; iter: 0; batch classifier loss: 0.285828; batch adversarial loss: 0.409277\n",
      "epoch 26; iter: 200; batch classifier loss: 0.338559; batch adversarial loss: 0.325739\n",
      "epoch 27; iter: 0; batch classifier loss: 0.320304; batch adversarial loss: 0.415754\n",
      "epoch 27; iter: 200; batch classifier loss: 0.378773; batch adversarial loss: 0.410506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433418; batch adversarial loss: 0.487034\n",
      "epoch 28; iter: 200; batch classifier loss: 0.381862; batch adversarial loss: 0.345988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.328292; batch adversarial loss: 0.444003\n",
      "epoch 29; iter: 200; batch classifier loss: 0.342688; batch adversarial loss: 0.427971\n",
      "epoch 30; iter: 0; batch classifier loss: 0.282588; batch adversarial loss: 0.393108\n",
      "epoch 30; iter: 200; batch classifier loss: 0.376703; batch adversarial loss: 0.352520\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398279; batch adversarial loss: 0.470853\n",
      "epoch 31; iter: 200; batch classifier loss: 0.354506; batch adversarial loss: 0.472664\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423898; batch adversarial loss: 0.570165\n",
      "epoch 32; iter: 200; batch classifier loss: 0.555000; batch adversarial loss: 0.364742\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346977; batch adversarial loss: 0.456310\n",
      "epoch 33; iter: 200; batch classifier loss: 0.324418; batch adversarial loss: 0.564206\n",
      "epoch 34; iter: 0; batch classifier loss: 0.295669; batch adversarial loss: 0.428528\n",
      "epoch 34; iter: 200; batch classifier loss: 0.403762; batch adversarial loss: 0.423539\n",
      "epoch 35; iter: 0; batch classifier loss: 0.231549; batch adversarial loss: 0.402440\n",
      "epoch 35; iter: 200; batch classifier loss: 0.454016; batch adversarial loss: 0.436071\n",
      "epoch 36; iter: 0; batch classifier loss: 0.330251; batch adversarial loss: 0.331530\n",
      "epoch 36; iter: 200; batch classifier loss: 0.310956; batch adversarial loss: 0.381962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400669; batch adversarial loss: 0.433414\n",
      "epoch 37; iter: 200; batch classifier loss: 0.381552; batch adversarial loss: 0.365657\n",
      "epoch 38; iter: 0; batch classifier loss: 0.351628; batch adversarial loss: 0.394085\n",
      "epoch 38; iter: 200; batch classifier loss: 0.391205; batch adversarial loss: 0.375508\n",
      "epoch 39; iter: 0; batch classifier loss: 0.355212; batch adversarial loss: 0.250360\n",
      "epoch 39; iter: 200; batch classifier loss: 0.280873; batch adversarial loss: 0.472288\n",
      "epoch 40; iter: 0; batch classifier loss: 0.385877; batch adversarial loss: 0.498785\n",
      "epoch 40; iter: 200; batch classifier loss: 0.353965; batch adversarial loss: 0.404120\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402574; batch adversarial loss: 0.399354\n",
      "epoch 41; iter: 200; batch classifier loss: 0.258416; batch adversarial loss: 0.447044\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467697; batch adversarial loss: 0.296760\n",
      "epoch 42; iter: 200; batch classifier loss: 0.315019; batch adversarial loss: 0.422721\n",
      "epoch 43; iter: 0; batch classifier loss: 0.319662; batch adversarial loss: 0.382572\n",
      "epoch 43; iter: 200; batch classifier loss: 0.345597; batch adversarial loss: 0.304281\n",
      "epoch 44; iter: 0; batch classifier loss: 0.315516; batch adversarial loss: 0.426796\n",
      "epoch 44; iter: 200; batch classifier loss: 0.380741; batch adversarial loss: 0.384280\n",
      "epoch 45; iter: 0; batch classifier loss: 0.358790; batch adversarial loss: 0.431586\n",
      "epoch 45; iter: 200; batch classifier loss: 0.301680; batch adversarial loss: 0.389313\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511073; batch adversarial loss: 0.444207\n",
      "epoch 46; iter: 200; batch classifier loss: 0.372441; batch adversarial loss: 0.358762\n",
      "epoch 47; iter: 0; batch classifier loss: 0.323723; batch adversarial loss: 0.319523\n",
      "epoch 47; iter: 200; batch classifier loss: 0.402098; batch adversarial loss: 0.364148\n",
      "epoch 48; iter: 0; batch classifier loss: 0.340003; batch adversarial loss: 0.439492\n",
      "epoch 48; iter: 200; batch classifier loss: 0.372230; batch adversarial loss: 0.511229\n",
      "epoch 49; iter: 0; batch classifier loss: 0.349577; batch adversarial loss: 0.450234\n",
      "epoch 49; iter: 200; batch classifier loss: 0.394527; batch adversarial loss: 0.385816\n",
      "epoch 0; iter: 0; batch classifier loss: 3.662322; batch adversarial loss: 0.488392\n",
      "epoch 0; iter: 200; batch classifier loss: 5.614930; batch adversarial loss: 0.548178\n",
      "epoch 1; iter: 0; batch classifier loss: 5.381765; batch adversarial loss: 0.526520\n",
      "epoch 1; iter: 200; batch classifier loss: 6.661067; batch adversarial loss: 0.443172\n",
      "epoch 2; iter: 0; batch classifier loss: 5.331053; batch adversarial loss: 0.469328\n",
      "epoch 2; iter: 200; batch classifier loss: 4.264350; batch adversarial loss: 0.436530\n",
      "epoch 3; iter: 0; batch classifier loss: 2.067183; batch adversarial loss: 0.474405\n",
      "epoch 3; iter: 200; batch classifier loss: 1.925651; batch adversarial loss: 0.420731\n",
      "epoch 4; iter: 0; batch classifier loss: 3.145390; batch adversarial loss: 0.466804\n",
      "epoch 4; iter: 200; batch classifier loss: 1.267015; batch adversarial loss: 0.496907\n",
      "epoch 5; iter: 0; batch classifier loss: 2.088912; batch adversarial loss: 0.401154\n",
      "epoch 5; iter: 200; batch classifier loss: 0.640061; batch adversarial loss: 0.362817\n",
      "epoch 6; iter: 0; batch classifier loss: 0.406983; batch adversarial loss: 0.423607\n",
      "epoch 6; iter: 200; batch classifier loss: 0.610802; batch adversarial loss: 0.496079\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503825; batch adversarial loss: 0.324879\n",
      "epoch 7; iter: 200; batch classifier loss: 0.639204; batch adversarial loss: 0.586938\n",
      "epoch 8; iter: 0; batch classifier loss: 0.502031; batch adversarial loss: 0.400458\n",
      "epoch 8; iter: 200; batch classifier loss: 0.550530; batch adversarial loss: 0.418063\n",
      "epoch 9; iter: 0; batch classifier loss: 0.439616; batch adversarial loss: 0.482571\n",
      "epoch 9; iter: 200; batch classifier loss: 0.484084; batch adversarial loss: 0.487327\n",
      "epoch 10; iter: 0; batch classifier loss: 0.465317; batch adversarial loss: 0.424509\n",
      "epoch 10; iter: 200; batch classifier loss: 0.712220; batch adversarial loss: 0.467358\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392929; batch adversarial loss: 0.485733\n",
      "epoch 11; iter: 200; batch classifier loss: 0.341682; batch adversarial loss: 0.412154\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455498; batch adversarial loss: 0.439738\n",
      "epoch 12; iter: 200; batch classifier loss: 0.403322; batch adversarial loss: 0.349747\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347575; batch adversarial loss: 0.362855\n",
      "epoch 13; iter: 200; batch classifier loss: 0.324687; batch adversarial loss: 0.269611\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349062; batch adversarial loss: 0.367083\n",
      "epoch 14; iter: 200; batch classifier loss: 0.446256; batch adversarial loss: 0.443195\n",
      "epoch 15; iter: 0; batch classifier loss: 0.342732; batch adversarial loss: 0.294139\n",
      "epoch 15; iter: 200; batch classifier loss: 0.352395; batch adversarial loss: 0.396548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.400037; batch adversarial loss: 0.400152\n",
      "epoch 16; iter: 200; batch classifier loss: 0.351175; batch adversarial loss: 0.481966\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312753; batch adversarial loss: 0.429951\n",
      "epoch 17; iter: 200; batch classifier loss: 0.399147; batch adversarial loss: 0.408146\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419467; batch adversarial loss: 0.421320\n",
      "epoch 18; iter: 200; batch classifier loss: 0.324474; batch adversarial loss: 0.406371\n",
      "epoch 19; iter: 0; batch classifier loss: 0.342882; batch adversarial loss: 0.360884\n",
      "epoch 19; iter: 200; batch classifier loss: 0.326123; batch adversarial loss: 0.485361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.431740; batch adversarial loss: 0.384390\n",
      "epoch 20; iter: 200; batch classifier loss: 0.287177; batch adversarial loss: 0.424380\n",
      "epoch 21; iter: 0; batch classifier loss: 0.368747; batch adversarial loss: 0.536421\n",
      "epoch 21; iter: 200; batch classifier loss: 0.419137; batch adversarial loss: 0.260110\n",
      "epoch 22; iter: 0; batch classifier loss: 0.373824; batch adversarial loss: 0.334679\n",
      "epoch 22; iter: 200; batch classifier loss: 0.344553; batch adversarial loss: 0.382236\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333199; batch adversarial loss: 0.442740\n",
      "epoch 23; iter: 200; batch classifier loss: 0.324082; batch adversarial loss: 0.392288\n",
      "epoch 24; iter: 0; batch classifier loss: 0.377156; batch adversarial loss: 0.548738\n",
      "epoch 24; iter: 200; batch classifier loss: 0.311583; batch adversarial loss: 0.490848\n",
      "epoch 25; iter: 0; batch classifier loss: 0.399483; batch adversarial loss: 0.413569\n",
      "epoch 25; iter: 200; batch classifier loss: 0.520277; batch adversarial loss: 0.520325\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438687; batch adversarial loss: 0.368277\n",
      "epoch 26; iter: 200; batch classifier loss: 0.270346; batch adversarial loss: 0.382546\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460123; batch adversarial loss: 0.367498\n",
      "epoch 27; iter: 200; batch classifier loss: 0.391368; batch adversarial loss: 0.408774\n",
      "epoch 28; iter: 0; batch classifier loss: 0.419448; batch adversarial loss: 0.366254\n",
      "epoch 28; iter: 200; batch classifier loss: 0.421663; batch adversarial loss: 0.398193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324699; batch adversarial loss: 0.363004\n",
      "epoch 29; iter: 200; batch classifier loss: 0.392469; batch adversarial loss: 0.361815\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416965; batch adversarial loss: 0.493413\n",
      "epoch 30; iter: 200; batch classifier loss: 0.447758; batch adversarial loss: 0.419217\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436617; batch adversarial loss: 0.477888\n",
      "epoch 31; iter: 200; batch classifier loss: 0.370768; batch adversarial loss: 0.480974\n",
      "epoch 32; iter: 0; batch classifier loss: 0.398230; batch adversarial loss: 0.438696\n",
      "epoch 32; iter: 200; batch classifier loss: 0.459296; batch adversarial loss: 0.443679\n",
      "epoch 33; iter: 0; batch classifier loss: 0.409869; batch adversarial loss: 0.445071\n",
      "epoch 33; iter: 200; batch classifier loss: 0.515404; batch adversarial loss: 0.345998\n",
      "epoch 34; iter: 0; batch classifier loss: 0.377842; batch adversarial loss: 0.420083\n",
      "epoch 34; iter: 200; batch classifier loss: 0.337178; batch adversarial loss: 0.401105\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473293; batch adversarial loss: 0.419723\n",
      "epoch 35; iter: 200; batch classifier loss: 0.521731; batch adversarial loss: 0.345971\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453215; batch adversarial loss: 0.416351\n",
      "epoch 36; iter: 200; batch classifier loss: 0.525778; batch adversarial loss: 0.320711\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402571; batch adversarial loss: 0.518144\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341023; batch adversarial loss: 0.372038\n",
      "epoch 38; iter: 0; batch classifier loss: 0.423716; batch adversarial loss: 0.391299\n",
      "epoch 38; iter: 200; batch classifier loss: 0.469448; batch adversarial loss: 0.389503\n",
      "epoch 39; iter: 0; batch classifier loss: 0.364565; batch adversarial loss: 0.431827\n",
      "epoch 39; iter: 200; batch classifier loss: 0.570530; batch adversarial loss: 0.456448\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461569; batch adversarial loss: 0.313597\n",
      "epoch 40; iter: 200; batch classifier loss: 0.513161; batch adversarial loss: 0.431774\n",
      "epoch 41; iter: 0; batch classifier loss: 0.403492; batch adversarial loss: 0.407980\n",
      "epoch 41; iter: 200; batch classifier loss: 0.476216; batch adversarial loss: 0.385140\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407544; batch adversarial loss: 0.442838\n",
      "epoch 42; iter: 200; batch classifier loss: 0.362461; batch adversarial loss: 0.441419\n",
      "epoch 43; iter: 0; batch classifier loss: 0.411359; batch adversarial loss: 0.408166\n",
      "epoch 43; iter: 200; batch classifier loss: 0.561227; batch adversarial loss: 0.385108\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472972; batch adversarial loss: 0.433109\n",
      "epoch 44; iter: 200; batch classifier loss: 0.348588; batch adversarial loss: 0.391397\n",
      "epoch 45; iter: 0; batch classifier loss: 0.532234; batch adversarial loss: 0.377946\n",
      "epoch 45; iter: 200; batch classifier loss: 0.476967; batch adversarial loss: 0.443892\n",
      "epoch 46; iter: 0; batch classifier loss: 0.416861; batch adversarial loss: 0.420230\n",
      "epoch 46; iter: 200; batch classifier loss: 0.572974; batch adversarial loss: 0.361198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.625774; batch adversarial loss: 0.401842\n",
      "epoch 47; iter: 200; batch classifier loss: 0.548423; batch adversarial loss: 0.416036\n",
      "epoch 48; iter: 0; batch classifier loss: 0.602737; batch adversarial loss: 0.433830\n",
      "epoch 48; iter: 200; batch classifier loss: 0.280139; batch adversarial loss: 0.483645\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450336; batch adversarial loss: 0.359177\n",
      "epoch 49; iter: 200; batch classifier loss: 0.422439; batch adversarial loss: 0.431056\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.819928  0.518741  0.005795  1.061475  0.136122  0.080246\n",
      "std   0.022347  0.087100  0.026959  0.209031  0.068521  0.041824\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    "    scope_name='adv',           \n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.1)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate\n",
    "adult_race_metrics = pd.DataFrame(results)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62585541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', 'Default Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fce3f2",
   "metadata": {},
   "source": [
    "## default adversial debiaser, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d433b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 10.719220; batch adversarial loss: 0.653934\n",
      "epoch 0; iter: 200; batch classifier loss: 5.535931; batch adversarial loss: 0.674039\n",
      "epoch 1; iter: 0; batch classifier loss: 9.397532; batch adversarial loss: 0.657341\n",
      "epoch 1; iter: 200; batch classifier loss: 4.852560; batch adversarial loss: 0.654549\n",
      "epoch 2; iter: 0; batch classifier loss: 11.071877; batch adversarial loss: 0.697256\n",
      "epoch 2; iter: 200; batch classifier loss: 1.763735; batch adversarial loss: 0.647708\n",
      "epoch 3; iter: 0; batch classifier loss: 4.819965; batch adversarial loss: 0.601127\n",
      "epoch 3; iter: 200; batch classifier loss: 3.276618; batch adversarial loss: 0.682499\n",
      "epoch 4; iter: 0; batch classifier loss: 2.981311; batch adversarial loss: 0.626493\n",
      "epoch 4; iter: 200; batch classifier loss: 5.110703; batch adversarial loss: 0.663583\n",
      "epoch 5; iter: 0; batch classifier loss: 1.047821; batch adversarial loss: 0.575429\n",
      "epoch 5; iter: 200; batch classifier loss: 1.263878; batch adversarial loss: 0.641364\n",
      "epoch 6; iter: 0; batch classifier loss: 1.163029; batch adversarial loss: 0.627569\n",
      "epoch 6; iter: 200; batch classifier loss: 0.835266; batch adversarial loss: 0.632021\n",
      "epoch 7; iter: 0; batch classifier loss: 0.477453; batch adversarial loss: 0.621247\n",
      "epoch 7; iter: 200; batch classifier loss: 0.563499; batch adversarial loss: 0.707367\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549604; batch adversarial loss: 0.641796\n",
      "epoch 8; iter: 200; batch classifier loss: 0.430388; batch adversarial loss: 0.590956\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414105; batch adversarial loss: 0.646755\n",
      "epoch 9; iter: 200; batch classifier loss: 0.322366; batch adversarial loss: 0.628904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398922; batch adversarial loss: 0.594671\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420172; batch adversarial loss: 0.656040\n",
      "epoch 11; iter: 0; batch classifier loss: 0.382218; batch adversarial loss: 0.617495\n",
      "epoch 11; iter: 200; batch classifier loss: 0.393084; batch adversarial loss: 0.599085\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367973; batch adversarial loss: 0.659820\n",
      "epoch 12; iter: 200; batch classifier loss: 0.433614; batch adversarial loss: 0.579408\n",
      "epoch 13; iter: 0; batch classifier loss: 0.398186; batch adversarial loss: 0.656557\n",
      "epoch 13; iter: 200; batch classifier loss: 0.327745; batch adversarial loss: 0.658145\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352129; batch adversarial loss: 0.663936\n",
      "epoch 14; iter: 200; batch classifier loss: 0.360046; batch adversarial loss: 0.595385\n",
      "epoch 15; iter: 0; batch classifier loss: 0.470607; batch adversarial loss: 0.588145\n",
      "epoch 15; iter: 200; batch classifier loss: 0.292689; batch adversarial loss: 0.678927\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377114; batch adversarial loss: 0.609836\n",
      "epoch 16; iter: 200; batch classifier loss: 0.431147; batch adversarial loss: 0.621054\n",
      "epoch 17; iter: 0; batch classifier loss: 0.381189; batch adversarial loss: 0.605325\n",
      "epoch 17; iter: 200; batch classifier loss: 0.331500; batch adversarial loss: 0.631218\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398948; batch adversarial loss: 0.638993\n",
      "epoch 18; iter: 200; batch classifier loss: 0.355169; batch adversarial loss: 0.581180\n",
      "epoch 19; iter: 0; batch classifier loss: 0.359585; batch adversarial loss: 0.592259\n",
      "epoch 19; iter: 200; batch classifier loss: 0.493308; batch adversarial loss: 0.646087\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406312; batch adversarial loss: 0.593431\n",
      "epoch 20; iter: 200; batch classifier loss: 0.326485; batch adversarial loss: 0.582394\n",
      "epoch 21; iter: 0; batch classifier loss: 0.385272; batch adversarial loss: 0.552985\n",
      "epoch 21; iter: 200; batch classifier loss: 0.310546; batch adversarial loss: 0.551561\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457221; batch adversarial loss: 0.605152\n",
      "epoch 22; iter: 200; batch classifier loss: 0.373409; batch adversarial loss: 0.608833\n",
      "epoch 23; iter: 0; batch classifier loss: 0.306804; batch adversarial loss: 0.598135\n",
      "epoch 23; iter: 200; batch classifier loss: 0.355392; batch adversarial loss: 0.710125\n",
      "epoch 24; iter: 0; batch classifier loss: 0.296992; batch adversarial loss: 0.597219\n",
      "epoch 24; iter: 200; batch classifier loss: 0.386267; batch adversarial loss: 0.585891\n",
      "epoch 25; iter: 0; batch classifier loss: 0.398157; batch adversarial loss: 0.606773\n",
      "epoch 25; iter: 200; batch classifier loss: 0.332254; batch adversarial loss: 0.666639\n",
      "epoch 26; iter: 0; batch classifier loss: 0.328770; batch adversarial loss: 0.645036\n",
      "epoch 26; iter: 200; batch classifier loss: 0.267684; batch adversarial loss: 0.584020\n",
      "epoch 27; iter: 0; batch classifier loss: 0.296344; batch adversarial loss: 0.580883\n",
      "epoch 27; iter: 200; batch classifier loss: 0.318013; batch adversarial loss: 0.591188\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421045; batch adversarial loss: 0.586795\n",
      "epoch 28; iter: 200; batch classifier loss: 0.333796; batch adversarial loss: 0.640069\n",
      "epoch 29; iter: 0; batch classifier loss: 0.334189; batch adversarial loss: 0.599665\n",
      "epoch 29; iter: 200; batch classifier loss: 0.378247; batch adversarial loss: 0.655031\n",
      "epoch 30; iter: 0; batch classifier loss: 0.379183; batch adversarial loss: 0.579076\n",
      "epoch 30; iter: 200; batch classifier loss: 0.347149; batch adversarial loss: 0.547468\n",
      "epoch 31; iter: 0; batch classifier loss: 0.339412; batch adversarial loss: 0.597413\n",
      "epoch 31; iter: 200; batch classifier loss: 0.257607; batch adversarial loss: 0.647470\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432851; batch adversarial loss: 0.624094\n",
      "epoch 32; iter: 200; batch classifier loss: 0.392761; batch adversarial loss: 0.619796\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460166; batch adversarial loss: 0.620308\n",
      "epoch 33; iter: 200; batch classifier loss: 0.393938; batch adversarial loss: 0.634328\n",
      "epoch 34; iter: 0; batch classifier loss: 0.319916; batch adversarial loss: 0.632989\n",
      "epoch 34; iter: 200; batch classifier loss: 0.749218; batch adversarial loss: 0.616125\n",
      "epoch 35; iter: 0; batch classifier loss: 0.243683; batch adversarial loss: 0.644261\n",
      "epoch 35; iter: 200; batch classifier loss: 0.533771; batch adversarial loss: 0.659479\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425163; batch adversarial loss: 0.565409\n",
      "epoch 36; iter: 200; batch classifier loss: 0.408690; batch adversarial loss: 0.659453\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386801; batch adversarial loss: 0.570005\n",
      "epoch 37; iter: 200; batch classifier loss: 0.294748; batch adversarial loss: 0.600842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.265234; batch adversarial loss: 0.636802\n",
      "epoch 38; iter: 200; batch classifier loss: 0.361949; batch adversarial loss: 0.656470\n",
      "epoch 39; iter: 0; batch classifier loss: 0.441604; batch adversarial loss: 0.651534\n",
      "epoch 39; iter: 200; batch classifier loss: 0.327169; batch adversarial loss: 0.610372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389202; batch adversarial loss: 0.642131\n",
      "epoch 40; iter: 200; batch classifier loss: 0.312110; batch adversarial loss: 0.631020\n",
      "epoch 41; iter: 0; batch classifier loss: 0.545759; batch adversarial loss: 0.646314\n",
      "epoch 41; iter: 200; batch classifier loss: 0.287192; batch adversarial loss: 0.706381\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410301; batch adversarial loss: 0.587460\n",
      "epoch 42; iter: 200; batch classifier loss: 0.279526; batch adversarial loss: 0.609031\n",
      "epoch 43; iter: 0; batch classifier loss: 0.336106; batch adversarial loss: 0.680283\n",
      "epoch 43; iter: 200; batch classifier loss: 0.300771; batch adversarial loss: 0.658399\n",
      "epoch 44; iter: 0; batch classifier loss: 0.354933; batch adversarial loss: 0.658485\n",
      "epoch 44; iter: 200; batch classifier loss: 0.353823; batch adversarial loss: 0.598265\n",
      "epoch 45; iter: 0; batch classifier loss: 0.293530; batch adversarial loss: 0.606288\n",
      "epoch 45; iter: 200; batch classifier loss: 0.402519; batch adversarial loss: 0.592811\n",
      "epoch 46; iter: 0; batch classifier loss: 0.351829; batch adversarial loss: 0.576849\n",
      "epoch 46; iter: 200; batch classifier loss: 0.348087; batch adversarial loss: 0.627747\n",
      "epoch 47; iter: 0; batch classifier loss: 0.265210; batch adversarial loss: 0.606858\n",
      "epoch 47; iter: 200; batch classifier loss: 0.391799; batch adversarial loss: 0.645162\n",
      "epoch 48; iter: 0; batch classifier loss: 0.273145; batch adversarial loss: 0.655990\n",
      "epoch 48; iter: 200; batch classifier loss: 0.385057; batch adversarial loss: 0.611242\n",
      "epoch 49; iter: 0; batch classifier loss: 0.295901; batch adversarial loss: 0.677938\n",
      "epoch 49; iter: 200; batch classifier loss: 0.389951; batch adversarial loss: 0.615796\n",
      "epoch 0; iter: 0; batch classifier loss: 60.680641; batch adversarial loss: 0.675974\n",
      "epoch 0; iter: 200; batch classifier loss: 14.792019; batch adversarial loss: 0.670482\n",
      "epoch 1; iter: 0; batch classifier loss: 7.296554; batch adversarial loss: 0.672810\n",
      "epoch 1; iter: 200; batch classifier loss: 17.897791; batch adversarial loss: 0.693042\n",
      "epoch 2; iter: 0; batch classifier loss: 7.423687; batch adversarial loss: 0.701953\n",
      "epoch 2; iter: 200; batch classifier loss: 9.010990; batch adversarial loss: 0.654657\n",
      "epoch 3; iter: 0; batch classifier loss: 2.254957; batch adversarial loss: 0.614911\n",
      "epoch 3; iter: 200; batch classifier loss: 3.560355; batch adversarial loss: 0.604710\n",
      "epoch 4; iter: 0; batch classifier loss: 2.848828; batch adversarial loss: 0.580709\n",
      "epoch 4; iter: 200; batch classifier loss: 4.816368; batch adversarial loss: 0.557254\n",
      "epoch 5; iter: 0; batch classifier loss: 1.268970; batch adversarial loss: 0.561976\n",
      "epoch 5; iter: 200; batch classifier loss: 0.832868; batch adversarial loss: 0.596437\n",
      "epoch 6; iter: 0; batch classifier loss: 1.044611; batch adversarial loss: 0.600786\n",
      "epoch 6; iter: 200; batch classifier loss: 0.561089; batch adversarial loss: 0.600244\n",
      "epoch 7; iter: 0; batch classifier loss: 1.878418; batch adversarial loss: 0.625912\n",
      "epoch 7; iter: 200; batch classifier loss: 0.663369; batch adversarial loss: 0.566150\n",
      "epoch 8; iter: 0; batch classifier loss: 0.505748; batch adversarial loss: 0.615619\n",
      "epoch 8; iter: 200; batch classifier loss: 0.535999; batch adversarial loss: 0.594379\n",
      "epoch 9; iter: 0; batch classifier loss: 0.400996; batch adversarial loss: 0.649203\n",
      "epoch 9; iter: 200; batch classifier loss: 0.515271; batch adversarial loss: 0.620740\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426867; batch adversarial loss: 0.612448\n",
      "epoch 10; iter: 200; batch classifier loss: 0.494777; batch adversarial loss: 0.606829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448786; batch adversarial loss: 0.576829\n",
      "epoch 11; iter: 200; batch classifier loss: 0.459304; batch adversarial loss: 0.622196\n",
      "epoch 12; iter: 0; batch classifier loss: 0.698323; batch adversarial loss: 0.649309\n",
      "epoch 12; iter: 200; batch classifier loss: 0.453551; batch adversarial loss: 0.597418\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512940; batch adversarial loss: 0.606730\n",
      "epoch 13; iter: 200; batch classifier loss: 0.395591; batch adversarial loss: 0.558429\n",
      "epoch 14; iter: 0; batch classifier loss: 0.500675; batch adversarial loss: 0.640544\n",
      "epoch 14; iter: 200; batch classifier loss: 0.361173; batch adversarial loss: 0.600529\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336302; batch adversarial loss: 0.641423\n",
      "epoch 15; iter: 200; batch classifier loss: 0.443310; batch adversarial loss: 0.586753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318478; batch adversarial loss: 0.578828\n",
      "epoch 16; iter: 200; batch classifier loss: 0.435952; batch adversarial loss: 0.613232\n",
      "epoch 17; iter: 0; batch classifier loss: 0.331889; batch adversarial loss: 0.557202\n",
      "epoch 17; iter: 200; batch classifier loss: 0.389058; batch adversarial loss: 0.573984\n",
      "epoch 18; iter: 0; batch classifier loss: 0.395838; batch adversarial loss: 0.597078\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326479; batch adversarial loss: 0.665797\n",
      "epoch 19; iter: 0; batch classifier loss: 0.480114; batch adversarial loss: 0.678440\n",
      "epoch 19; iter: 200; batch classifier loss: 0.314739; batch adversarial loss: 0.568895\n",
      "epoch 20; iter: 0; batch classifier loss: 0.348393; batch adversarial loss: 0.585818\n",
      "epoch 20; iter: 200; batch classifier loss: 0.327134; batch adversarial loss: 0.641992\n",
      "epoch 21; iter: 0; batch classifier loss: 0.296439; batch adversarial loss: 0.632095\n",
      "epoch 21; iter: 200; batch classifier loss: 0.450079; batch adversarial loss: 0.610572\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354036; batch adversarial loss: 0.640081\n",
      "epoch 22; iter: 200; batch classifier loss: 0.333793; batch adversarial loss: 0.649870\n",
      "epoch 23; iter: 0; batch classifier loss: 0.321657; batch adversarial loss: 0.644352\n",
      "epoch 23; iter: 200; batch classifier loss: 0.316267; batch adversarial loss: 0.585048\n",
      "epoch 24; iter: 0; batch classifier loss: 0.276775; batch adversarial loss: 0.647391\n",
      "epoch 24; iter: 200; batch classifier loss: 0.286124; batch adversarial loss: 0.580869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279802; batch adversarial loss: 0.622655\n",
      "epoch 25; iter: 200; batch classifier loss: 0.317682; batch adversarial loss: 0.551962\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343175; batch adversarial loss: 0.633014\n",
      "epoch 26; iter: 200; batch classifier loss: 0.254168; batch adversarial loss: 0.617342\n",
      "epoch 27; iter: 0; batch classifier loss: 0.332612; batch adversarial loss: 0.650723\n",
      "epoch 27; iter: 200; batch classifier loss: 0.459858; batch adversarial loss: 0.621820\n",
      "epoch 28; iter: 0; batch classifier loss: 0.360703; batch adversarial loss: 0.531307\n",
      "epoch 28; iter: 200; batch classifier loss: 0.576243; batch adversarial loss: 0.670565\n",
      "epoch 29; iter: 0; batch classifier loss: 0.332254; batch adversarial loss: 0.582865\n",
      "epoch 29; iter: 200; batch classifier loss: 0.320187; batch adversarial loss: 0.608102\n",
      "epoch 30; iter: 0; batch classifier loss: 0.314368; batch adversarial loss: 0.647806\n",
      "epoch 30; iter: 200; batch classifier loss: 0.374809; batch adversarial loss: 0.621035\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471492; batch adversarial loss: 0.708120\n",
      "epoch 31; iter: 200; batch classifier loss: 0.398101; batch adversarial loss: 0.629565\n",
      "epoch 32; iter: 0; batch classifier loss: 0.384423; batch adversarial loss: 0.627018\n",
      "epoch 32; iter: 200; batch classifier loss: 0.387141; batch adversarial loss: 0.636063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.329835; batch adversarial loss: 0.617654\n",
      "epoch 33; iter: 200; batch classifier loss: 0.350903; batch adversarial loss: 0.608504\n",
      "epoch 34; iter: 0; batch classifier loss: 0.313137; batch adversarial loss: 0.548577\n",
      "epoch 34; iter: 200; batch classifier loss: 0.440706; batch adversarial loss: 0.664862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.346392; batch adversarial loss: 0.637302\n",
      "epoch 35; iter: 200; batch classifier loss: 0.374914; batch adversarial loss: 0.659699\n",
      "epoch 36; iter: 0; batch classifier loss: 0.352716; batch adversarial loss: 0.589960\n",
      "epoch 36; iter: 200; batch classifier loss: 0.293093; batch adversarial loss: 0.630460\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395174; batch adversarial loss: 0.613517\n",
      "epoch 37; iter: 200; batch classifier loss: 0.368284; batch adversarial loss: 0.618955\n",
      "epoch 38; iter: 0; batch classifier loss: 0.312330; batch adversarial loss: 0.616994\n",
      "epoch 38; iter: 200; batch classifier loss: 0.291711; batch adversarial loss: 0.597672\n",
      "epoch 39; iter: 0; batch classifier loss: 0.339359; batch adversarial loss: 0.621217\n",
      "epoch 39; iter: 200; batch classifier loss: 0.308142; batch adversarial loss: 0.603880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.371960; batch adversarial loss: 0.673982\n",
      "epoch 40; iter: 200; batch classifier loss: 0.401933; batch adversarial loss: 0.575157\n",
      "epoch 41; iter: 0; batch classifier loss: 0.413057; batch adversarial loss: 0.559889\n",
      "epoch 41; iter: 200; batch classifier loss: 0.437509; batch adversarial loss: 0.639231\n",
      "epoch 42; iter: 0; batch classifier loss: 0.330948; batch adversarial loss: 0.601998\n",
      "epoch 42; iter: 200; batch classifier loss: 0.331835; batch adversarial loss: 0.668439\n",
      "epoch 43; iter: 0; batch classifier loss: 0.377129; batch adversarial loss: 0.638477\n",
      "epoch 43; iter: 200; batch classifier loss: 0.234809; batch adversarial loss: 0.569745\n",
      "epoch 44; iter: 0; batch classifier loss: 0.314132; batch adversarial loss: 0.631147\n",
      "epoch 44; iter: 200; batch classifier loss: 0.405732; batch adversarial loss: 0.624913\n",
      "epoch 45; iter: 0; batch classifier loss: 0.357750; batch adversarial loss: 0.611457\n",
      "epoch 45; iter: 200; batch classifier loss: 0.271330; batch adversarial loss: 0.635236\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431034; batch adversarial loss: 0.590509\n",
      "epoch 46; iter: 200; batch classifier loss: 0.371649; batch adversarial loss: 0.675320\n",
      "epoch 47; iter: 0; batch classifier loss: 0.302805; batch adversarial loss: 0.654729\n",
      "epoch 47; iter: 200; batch classifier loss: 0.361528; batch adversarial loss: 0.621058\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470854; batch adversarial loss: 0.629901\n",
      "epoch 48; iter: 200; batch classifier loss: 0.350070; batch adversarial loss: 0.623434\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379378; batch adversarial loss: 0.636211\n",
      "epoch 49; iter: 200; batch classifier loss: 0.458975; batch adversarial loss: 0.594853\n",
      "epoch 0; iter: 0; batch classifier loss: 31.171930; batch adversarial loss: 0.633184\n",
      "epoch 0; iter: 200; batch classifier loss: 7.960083; batch adversarial loss: 0.663315\n",
      "epoch 1; iter: 0; batch classifier loss: 20.307777; batch adversarial loss: 0.601013\n",
      "epoch 1; iter: 200; batch classifier loss: 4.169371; batch adversarial loss: 0.586020\n",
      "epoch 2; iter: 0; batch classifier loss: 3.760082; batch adversarial loss: 0.657383\n",
      "epoch 2; iter: 200; batch classifier loss: 3.426084; batch adversarial loss: 0.687289\n",
      "epoch 3; iter: 0; batch classifier loss: 11.716976; batch adversarial loss: 0.616819\n",
      "epoch 3; iter: 200; batch classifier loss: 7.371699; batch adversarial loss: 0.570226\n",
      "epoch 4; iter: 0; batch classifier loss: 2.593703; batch adversarial loss: 0.675159\n",
      "epoch 4; iter: 200; batch classifier loss: 0.653435; batch adversarial loss: 0.677025\n",
      "epoch 5; iter: 0; batch classifier loss: 1.773391; batch adversarial loss: 0.622490\n",
      "epoch 5; iter: 200; batch classifier loss: 0.528048; batch adversarial loss: 0.632907\n",
      "epoch 6; iter: 0; batch classifier loss: 2.808067; batch adversarial loss: 0.621371\n",
      "epoch 6; iter: 200; batch classifier loss: 0.765033; batch adversarial loss: 0.618183\n",
      "epoch 7; iter: 0; batch classifier loss: 0.644083; batch adversarial loss: 0.648329\n",
      "epoch 7; iter: 200; batch classifier loss: 0.624359; batch adversarial loss: 0.678390\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525454; batch adversarial loss: 0.597817\n",
      "epoch 8; iter: 200; batch classifier loss: 0.488640; batch adversarial loss: 0.638868\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527803; batch adversarial loss: 0.578006\n",
      "epoch 9; iter: 200; batch classifier loss: 0.464406; batch adversarial loss: 0.580889\n",
      "epoch 10; iter: 0; batch classifier loss: 0.427797; batch adversarial loss: 0.628731\n",
      "epoch 10; iter: 200; batch classifier loss: 0.316477; batch adversarial loss: 0.674053\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381496; batch adversarial loss: 0.607438\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412113; batch adversarial loss: 0.604407\n",
      "epoch 12; iter: 0; batch classifier loss: 0.671438; batch adversarial loss: 0.630608\n",
      "epoch 12; iter: 200; batch classifier loss: 0.407685; batch adversarial loss: 0.646373\n",
      "epoch 13; iter: 0; batch classifier loss: 0.427843; batch adversarial loss: 0.558248\n",
      "epoch 13; iter: 200; batch classifier loss: 0.351374; batch adversarial loss: 0.579609\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261368; batch adversarial loss: 0.699560\n",
      "epoch 14; iter: 200; batch classifier loss: 0.358826; batch adversarial loss: 0.592295\n",
      "epoch 15; iter: 0; batch classifier loss: 0.299324; batch adversarial loss: 0.615802\n",
      "epoch 15; iter: 200; batch classifier loss: 0.411715; batch adversarial loss: 0.618078\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323673; batch adversarial loss: 0.589570\n",
      "epoch 16; iter: 200; batch classifier loss: 0.321823; batch adversarial loss: 0.585034\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356065; batch adversarial loss: 0.544683\n",
      "epoch 17; iter: 200; batch classifier loss: 0.333052; batch adversarial loss: 0.567647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366282; batch adversarial loss: 0.570664\n",
      "epoch 18; iter: 200; batch classifier loss: 0.262547; batch adversarial loss: 0.588889\n",
      "epoch 19; iter: 0; batch classifier loss: 0.295282; batch adversarial loss: 0.606936\n",
      "epoch 19; iter: 200; batch classifier loss: 0.241357; batch adversarial loss: 0.613518\n",
      "epoch 20; iter: 0; batch classifier loss: 0.340474; batch adversarial loss: 0.594521\n",
      "epoch 20; iter: 200; batch classifier loss: 0.393650; batch adversarial loss: 0.661301\n",
      "epoch 21; iter: 0; batch classifier loss: 0.352159; batch adversarial loss: 0.636930\n",
      "epoch 21; iter: 200; batch classifier loss: 0.386628; batch adversarial loss: 0.594188\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291254; batch adversarial loss: 0.657071\n",
      "epoch 22; iter: 200; batch classifier loss: 0.276716; batch adversarial loss: 0.656054\n",
      "epoch 23; iter: 0; batch classifier loss: 0.350039; batch adversarial loss: 0.586294\n",
      "epoch 23; iter: 200; batch classifier loss: 0.393362; batch adversarial loss: 0.637232\n",
      "epoch 24; iter: 0; batch classifier loss: 0.356188; batch adversarial loss: 0.591060\n",
      "epoch 24; iter: 200; batch classifier loss: 0.341290; batch adversarial loss: 0.623227\n",
      "epoch 25; iter: 0; batch classifier loss: 0.331342; batch adversarial loss: 0.659153\n",
      "epoch 25; iter: 200; batch classifier loss: 0.329323; batch adversarial loss: 0.643115\n",
      "epoch 26; iter: 0; batch classifier loss: 0.280519; batch adversarial loss: 0.610815\n",
      "epoch 26; iter: 200; batch classifier loss: 0.462996; batch adversarial loss: 0.638276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.313296; batch adversarial loss: 0.645696\n",
      "epoch 27; iter: 200; batch classifier loss: 0.266222; batch adversarial loss: 0.618002\n",
      "epoch 28; iter: 0; batch classifier loss: 0.321283; batch adversarial loss: 0.589251\n",
      "epoch 28; iter: 200; batch classifier loss: 0.371427; batch adversarial loss: 0.603758\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394543; batch adversarial loss: 0.619183\n",
      "epoch 29; iter: 200; batch classifier loss: 0.253759; batch adversarial loss: 0.648906\n",
      "epoch 30; iter: 0; batch classifier loss: 0.297395; batch adversarial loss: 0.631682\n",
      "epoch 30; iter: 200; batch classifier loss: 0.273827; batch adversarial loss: 0.583583\n",
      "epoch 31; iter: 0; batch classifier loss: 0.281276; batch adversarial loss: 0.619310\n",
      "epoch 31; iter: 200; batch classifier loss: 0.766155; batch adversarial loss: 0.621932\n",
      "epoch 32; iter: 0; batch classifier loss: 0.365378; batch adversarial loss: 0.615827\n",
      "epoch 32; iter: 200; batch classifier loss: 0.294277; batch adversarial loss: 0.623570\n",
      "epoch 33; iter: 0; batch classifier loss: 0.273785; batch adversarial loss: 0.591297\n",
      "epoch 33; iter: 200; batch classifier loss: 0.420794; batch adversarial loss: 0.638062\n",
      "epoch 34; iter: 0; batch classifier loss: 0.234834; batch adversarial loss: 0.643332\n",
      "epoch 34; iter: 200; batch classifier loss: 0.325679; batch adversarial loss: 0.618712\n",
      "epoch 35; iter: 0; batch classifier loss: 0.310837; batch adversarial loss: 0.579232\n",
      "epoch 35; iter: 200; batch classifier loss: 0.443572; batch adversarial loss: 0.637670\n",
      "epoch 36; iter: 0; batch classifier loss: 0.310843; batch adversarial loss: 0.680684\n",
      "epoch 36; iter: 200; batch classifier loss: 0.288654; batch adversarial loss: 0.607006\n",
      "epoch 37; iter: 0; batch classifier loss: 0.429210; batch adversarial loss: 0.581356\n",
      "epoch 37; iter: 200; batch classifier loss: 0.262009; batch adversarial loss: 0.600819\n",
      "epoch 38; iter: 0; batch classifier loss: 0.358336; batch adversarial loss: 0.605416\n",
      "epoch 38; iter: 200; batch classifier loss: 0.332817; batch adversarial loss: 0.643346\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417364; batch adversarial loss: 0.658251\n",
      "epoch 39; iter: 200; batch classifier loss: 0.323630; batch adversarial loss: 0.627964\n",
      "epoch 40; iter: 0; batch classifier loss: 0.331833; batch adversarial loss: 0.633412\n",
      "epoch 40; iter: 200; batch classifier loss: 0.420858; batch adversarial loss: 0.668108\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410669; batch adversarial loss: 0.581524\n",
      "epoch 41; iter: 200; batch classifier loss: 0.348726; batch adversarial loss: 0.591107\n",
      "epoch 42; iter: 0; batch classifier loss: 0.295574; batch adversarial loss: 0.574808\n",
      "epoch 42; iter: 200; batch classifier loss: 0.297777; batch adversarial loss: 0.597864\n",
      "epoch 43; iter: 0; batch classifier loss: 0.402569; batch adversarial loss: 0.640982\n",
      "epoch 43; iter: 200; batch classifier loss: 0.402131; batch adversarial loss: 0.624211\n",
      "epoch 44; iter: 0; batch classifier loss: 0.481131; batch adversarial loss: 0.556224\n",
      "epoch 44; iter: 200; batch classifier loss: 0.361155; batch adversarial loss: 0.617817\n",
      "epoch 45; iter: 0; batch classifier loss: 0.226537; batch adversarial loss: 0.582365\n",
      "epoch 45; iter: 200; batch classifier loss: 0.360946; batch adversarial loss: 0.644618\n",
      "epoch 46; iter: 0; batch classifier loss: 0.431983; batch adversarial loss: 0.653966\n",
      "epoch 46; iter: 200; batch classifier loss: 0.374105; batch adversarial loss: 0.582997\n",
      "epoch 47; iter: 0; batch classifier loss: 0.320454; batch adversarial loss: 0.588874\n",
      "epoch 47; iter: 200; batch classifier loss: 0.328972; batch adversarial loss: 0.618857\n",
      "epoch 48; iter: 0; batch classifier loss: 0.301955; batch adversarial loss: 0.633015\n",
      "epoch 48; iter: 200; batch classifier loss: 0.366230; batch adversarial loss: 0.621898\n",
      "epoch 49; iter: 0; batch classifier loss: 0.392603; batch adversarial loss: 0.614096\n",
      "epoch 49; iter: 200; batch classifier loss: 0.297891; batch adversarial loss: 0.626850\n",
      "epoch 0; iter: 0; batch classifier loss: 24.294155; batch adversarial loss: 0.791497\n",
      "epoch 0; iter: 200; batch classifier loss: 5.472917; batch adversarial loss: 0.728420\n",
      "epoch 1; iter: 0; batch classifier loss: 20.029369; batch adversarial loss: 0.686268\n",
      "epoch 1; iter: 200; batch classifier loss: 5.865479; batch adversarial loss: 0.634183\n",
      "epoch 2; iter: 0; batch classifier loss: 4.885656; batch adversarial loss: 0.650217\n",
      "epoch 2; iter: 200; batch classifier loss: 3.056077; batch adversarial loss: 0.655295\n",
      "epoch 3; iter: 0; batch classifier loss: 4.737490; batch adversarial loss: 0.621108\n",
      "epoch 3; iter: 200; batch classifier loss: 4.822556; batch adversarial loss: 0.658423\n",
      "epoch 4; iter: 0; batch classifier loss: 2.223966; batch adversarial loss: 0.635218\n",
      "epoch 4; iter: 200; batch classifier loss: 3.746507; batch adversarial loss: 0.649887\n",
      "epoch 5; iter: 0; batch classifier loss: 1.582853; batch adversarial loss: 0.574324\n",
      "epoch 5; iter: 200; batch classifier loss: 2.974034; batch adversarial loss: 0.616010\n",
      "epoch 6; iter: 0; batch classifier loss: 0.781480; batch adversarial loss: 0.626673\n",
      "epoch 6; iter: 200; batch classifier loss: 1.022157; batch adversarial loss: 0.591357\n",
      "epoch 7; iter: 0; batch classifier loss: 0.804492; batch adversarial loss: 0.645754\n",
      "epoch 7; iter: 200; batch classifier loss: 0.597490; batch adversarial loss: 0.582530\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421652; batch adversarial loss: 0.616332\n",
      "epoch 8; iter: 200; batch classifier loss: 0.445558; batch adversarial loss: 0.605673\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530088; batch adversarial loss: 0.594663\n",
      "epoch 9; iter: 200; batch classifier loss: 0.546491; batch adversarial loss: 0.651142\n",
      "epoch 10; iter: 0; batch classifier loss: 1.036205; batch adversarial loss: 0.660564\n",
      "epoch 10; iter: 200; batch classifier loss: 0.528671; batch adversarial loss: 0.632129\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366808; batch adversarial loss: 0.579934\n",
      "epoch 11; iter: 200; batch classifier loss: 0.608840; batch adversarial loss: 0.611305\n",
      "epoch 12; iter: 0; batch classifier loss: 0.268954; batch adversarial loss: 0.626127\n",
      "epoch 12; iter: 200; batch classifier loss: 0.441179; batch adversarial loss: 0.586257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.425503; batch adversarial loss: 0.611979\n",
      "epoch 13; iter: 200; batch classifier loss: 0.478979; batch adversarial loss: 0.627859\n",
      "epoch 14; iter: 0; batch classifier loss: 0.419533; batch adversarial loss: 0.665070\n",
      "epoch 14; iter: 200; batch classifier loss: 0.396457; batch adversarial loss: 0.638328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374005; batch adversarial loss: 0.610178\n",
      "epoch 15; iter: 200; batch classifier loss: 0.358290; batch adversarial loss: 0.607072\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363133; batch adversarial loss: 0.634768\n",
      "epoch 16; iter: 200; batch classifier loss: 0.314653; batch adversarial loss: 0.586681\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363303; batch adversarial loss: 0.574748\n",
      "epoch 17; iter: 200; batch classifier loss: 0.379527; batch adversarial loss: 0.571342\n",
      "epoch 18; iter: 0; batch classifier loss: 0.357246; batch adversarial loss: 0.598300\n",
      "epoch 18; iter: 200; batch classifier loss: 0.446567; batch adversarial loss: 0.557895\n",
      "epoch 19; iter: 0; batch classifier loss: 0.423529; batch adversarial loss: 0.580182\n",
      "epoch 19; iter: 200; batch classifier loss: 0.314122; batch adversarial loss: 0.572330\n",
      "epoch 20; iter: 0; batch classifier loss: 0.345196; batch adversarial loss: 0.623476\n",
      "epoch 20; iter: 200; batch classifier loss: 0.319979; batch adversarial loss: 0.605198\n",
      "epoch 21; iter: 0; batch classifier loss: 0.396570; batch adversarial loss: 0.687142\n",
      "epoch 21; iter: 200; batch classifier loss: 0.368602; batch adversarial loss: 0.594010\n",
      "epoch 22; iter: 0; batch classifier loss: 0.305236; batch adversarial loss: 0.733141\n",
      "epoch 22; iter: 200; batch classifier loss: 0.306106; batch adversarial loss: 0.620075\n",
      "epoch 23; iter: 0; batch classifier loss: 0.359432; batch adversarial loss: 0.565808\n",
      "epoch 23; iter: 200; batch classifier loss: 0.270523; batch adversarial loss: 0.623692\n",
      "epoch 24; iter: 0; batch classifier loss: 0.301296; batch adversarial loss: 0.650308\n",
      "epoch 24; iter: 200; batch classifier loss: 0.268305; batch adversarial loss: 0.639005\n",
      "epoch 25; iter: 0; batch classifier loss: 0.379529; batch adversarial loss: 0.559130\n",
      "epoch 25; iter: 200; batch classifier loss: 0.304810; batch adversarial loss: 0.559752\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356945; batch adversarial loss: 0.632849\n",
      "epoch 26; iter: 200; batch classifier loss: 0.290626; batch adversarial loss: 0.677407\n",
      "epoch 27; iter: 0; batch classifier loss: 0.346285; batch adversarial loss: 0.578297\n",
      "epoch 27; iter: 200; batch classifier loss: 0.357125; batch adversarial loss: 0.645639\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267170; batch adversarial loss: 0.599616\n",
      "epoch 28; iter: 200; batch classifier loss: 0.409854; batch adversarial loss: 0.652786\n",
      "epoch 29; iter: 0; batch classifier loss: 0.351289; batch adversarial loss: 0.634432\n",
      "epoch 29; iter: 200; batch classifier loss: 0.364768; batch adversarial loss: 0.583258\n",
      "epoch 30; iter: 0; batch classifier loss: 0.356672; batch adversarial loss: 0.602538\n",
      "epoch 30; iter: 200; batch classifier loss: 0.371762; batch adversarial loss: 0.696857\n",
      "epoch 31; iter: 0; batch classifier loss: 0.285446; batch adversarial loss: 0.632204\n",
      "epoch 31; iter: 200; batch classifier loss: 0.339420; batch adversarial loss: 0.624282\n",
      "epoch 32; iter: 0; batch classifier loss: 0.286662; batch adversarial loss: 0.606500\n",
      "epoch 32; iter: 200; batch classifier loss: 0.266439; batch adversarial loss: 0.605907\n",
      "epoch 33; iter: 0; batch classifier loss: 0.435130; batch adversarial loss: 0.537140\n",
      "epoch 33; iter: 200; batch classifier loss: 0.330120; batch adversarial loss: 0.624364\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310123; batch adversarial loss: 0.668567\n",
      "epoch 34; iter: 200; batch classifier loss: 0.516362; batch adversarial loss: 0.627821\n",
      "epoch 35; iter: 0; batch classifier loss: 0.360466; batch adversarial loss: 0.656891\n",
      "epoch 35; iter: 200; batch classifier loss: 0.287587; batch adversarial loss: 0.666998\n",
      "epoch 36; iter: 0; batch classifier loss: 0.355498; batch adversarial loss: 0.583228\n",
      "epoch 36; iter: 200; batch classifier loss: 0.391152; batch adversarial loss: 0.614538\n",
      "epoch 37; iter: 0; batch classifier loss: 0.373272; batch adversarial loss: 0.669004\n",
      "epoch 37; iter: 200; batch classifier loss: 0.360111; batch adversarial loss: 0.632347\n",
      "epoch 38; iter: 0; batch classifier loss: 0.292030; batch adversarial loss: 0.647921\n",
      "epoch 38; iter: 200; batch classifier loss: 0.454969; batch adversarial loss: 0.654997\n",
      "epoch 39; iter: 0; batch classifier loss: 0.319694; batch adversarial loss: 0.597248\n",
      "epoch 39; iter: 200; batch classifier loss: 0.346671; batch adversarial loss: 0.640904\n",
      "epoch 40; iter: 0; batch classifier loss: 0.301049; batch adversarial loss: 0.601316\n",
      "epoch 40; iter: 200; batch classifier loss: 0.341463; batch adversarial loss: 0.586079\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448373; batch adversarial loss: 0.630015\n",
      "epoch 41; iter: 200; batch classifier loss: 0.442299; batch adversarial loss: 0.605214\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443110; batch adversarial loss: 0.662179\n",
      "epoch 42; iter: 200; batch classifier loss: 0.330410; batch adversarial loss: 0.591219\n",
      "epoch 43; iter: 0; batch classifier loss: 0.266931; batch adversarial loss: 0.637984\n",
      "epoch 43; iter: 200; batch classifier loss: 0.339344; batch adversarial loss: 0.652869\n",
      "epoch 44; iter: 0; batch classifier loss: 0.343243; batch adversarial loss: 0.696713\n",
      "epoch 44; iter: 200; batch classifier loss: 0.369536; batch adversarial loss: 0.608423\n",
      "epoch 45; iter: 0; batch classifier loss: 0.302230; batch adversarial loss: 0.704684\n",
      "epoch 45; iter: 200; batch classifier loss: 0.278152; batch adversarial loss: 0.647478\n",
      "epoch 46; iter: 0; batch classifier loss: 0.309442; batch adversarial loss: 0.659532\n",
      "epoch 46; iter: 200; batch classifier loss: 0.315129; batch adversarial loss: 0.657713\n",
      "epoch 47; iter: 0; batch classifier loss: 0.425106; batch adversarial loss: 0.572782\n",
      "epoch 47; iter: 200; batch classifier loss: 0.309872; batch adversarial loss: 0.620196\n",
      "epoch 48; iter: 0; batch classifier loss: 0.289311; batch adversarial loss: 0.619524\n",
      "epoch 48; iter: 200; batch classifier loss: 0.344375; batch adversarial loss: 0.566833\n",
      "epoch 49; iter: 0; batch classifier loss: 0.320426; batch adversarial loss: 0.636650\n",
      "epoch 49; iter: 200; batch classifier loss: 0.411723; batch adversarial loss: 0.619601\n",
      "epoch 0; iter: 0; batch classifier loss: 13.669546; batch adversarial loss: 0.659907\n",
      "epoch 0; iter: 200; batch classifier loss: 10.127052; batch adversarial loss: 0.598436\n",
      "epoch 1; iter: 0; batch classifier loss: 3.378011; batch adversarial loss: 0.596080\n",
      "epoch 1; iter: 200; batch classifier loss: 3.509831; batch adversarial loss: 0.592106\n",
      "epoch 2; iter: 0; batch classifier loss: 1.252413; batch adversarial loss: 0.629493\n",
      "epoch 2; iter: 200; batch classifier loss: 1.798709; batch adversarial loss: 0.610145\n",
      "epoch 3; iter: 0; batch classifier loss: 2.933485; batch adversarial loss: 0.692429\n",
      "epoch 3; iter: 200; batch classifier loss: 2.111766; batch adversarial loss: 0.623546\n",
      "epoch 4; iter: 0; batch classifier loss: 1.426164; batch adversarial loss: 0.638874\n",
      "epoch 4; iter: 200; batch classifier loss: 3.753306; batch adversarial loss: 0.565370\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447337; batch adversarial loss: 0.633059\n",
      "epoch 5; iter: 200; batch classifier loss: 1.525439; batch adversarial loss: 0.625441\n",
      "epoch 6; iter: 0; batch classifier loss: 1.005841; batch adversarial loss: 0.670357\n",
      "epoch 6; iter: 200; batch classifier loss: 0.642912; batch adversarial loss: 0.661012\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563788; batch adversarial loss: 0.556378\n",
      "epoch 7; iter: 200; batch classifier loss: 0.522171; batch adversarial loss: 0.634253\n",
      "epoch 8; iter: 0; batch classifier loss: 0.584864; batch adversarial loss: 0.596427\n",
      "epoch 8; iter: 200; batch classifier loss: 0.594485; batch adversarial loss: 0.595088\n",
      "epoch 9; iter: 0; batch classifier loss: 0.485628; batch adversarial loss: 0.595133\n",
      "epoch 9; iter: 200; batch classifier loss: 0.561527; batch adversarial loss: 0.619503\n",
      "epoch 10; iter: 0; batch classifier loss: 0.506452; batch adversarial loss: 0.643042\n",
      "epoch 10; iter: 200; batch classifier loss: 0.435086; batch adversarial loss: 0.596229\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404343; batch adversarial loss: 0.683593\n",
      "epoch 11; iter: 200; batch classifier loss: 0.463994; batch adversarial loss: 0.543539\n",
      "epoch 12; iter: 0; batch classifier loss: 0.394270; batch adversarial loss: 0.646314\n",
      "epoch 12; iter: 200; batch classifier loss: 0.464076; batch adversarial loss: 0.635772\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349880; batch adversarial loss: 0.615096\n",
      "epoch 13; iter: 200; batch classifier loss: 0.401085; batch adversarial loss: 0.667710\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358717; batch adversarial loss: 0.583790\n",
      "epoch 14; iter: 200; batch classifier loss: 0.346925; batch adversarial loss: 0.655240\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331295; batch adversarial loss: 0.585509\n",
      "epoch 15; iter: 200; batch classifier loss: 0.323203; batch adversarial loss: 0.623615\n",
      "epoch 16; iter: 0; batch classifier loss: 0.263552; batch adversarial loss: 0.637750\n",
      "epoch 16; iter: 200; batch classifier loss: 0.358814; batch adversarial loss: 0.624004\n",
      "epoch 17; iter: 0; batch classifier loss: 0.402530; batch adversarial loss: 0.588654\n",
      "epoch 17; iter: 200; batch classifier loss: 0.363104; batch adversarial loss: 0.626392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.314612; batch adversarial loss: 0.619641\n",
      "epoch 18; iter: 200; batch classifier loss: 0.435694; batch adversarial loss: 0.640331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.332543; batch adversarial loss: 0.564006\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342286; batch adversarial loss: 0.612709\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523199; batch adversarial loss: 0.557503\n",
      "epoch 20; iter: 200; batch classifier loss: 0.284608; batch adversarial loss: 0.599955\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291726; batch adversarial loss: 0.602376\n",
      "epoch 21; iter: 200; batch classifier loss: 0.351006; batch adversarial loss: 0.580617\n",
      "epoch 22; iter: 0; batch classifier loss: 0.342312; batch adversarial loss: 0.629576\n",
      "epoch 22; iter: 200; batch classifier loss: 0.320546; batch adversarial loss: 0.614674\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344711; batch adversarial loss: 0.621987\n",
      "epoch 23; iter: 200; batch classifier loss: 0.454687; batch adversarial loss: 0.579524\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467124; batch adversarial loss: 0.578181\n",
      "epoch 24; iter: 200; batch classifier loss: 0.250610; batch adversarial loss: 0.653747\n",
      "epoch 25; iter: 0; batch classifier loss: 0.327867; batch adversarial loss: 0.576857\n",
      "epoch 25; iter: 200; batch classifier loss: 0.293739; batch adversarial loss: 0.653276\n",
      "epoch 26; iter: 0; batch classifier loss: 0.401439; batch adversarial loss: 0.642723\n",
      "epoch 26; iter: 200; batch classifier loss: 0.281716; batch adversarial loss: 0.587945\n",
      "epoch 27; iter: 0; batch classifier loss: 0.313803; batch adversarial loss: 0.621986\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310842; batch adversarial loss: 0.612618\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538998; batch adversarial loss: 0.578177\n",
      "epoch 28; iter: 200; batch classifier loss: 0.446391; batch adversarial loss: 0.648465\n",
      "epoch 29; iter: 0; batch classifier loss: 0.357003; batch adversarial loss: 0.575188\n",
      "epoch 29; iter: 200; batch classifier loss: 0.428178; batch adversarial loss: 0.593108\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453307; batch adversarial loss: 0.607597\n",
      "epoch 30; iter: 200; batch classifier loss: 0.471307; batch adversarial loss: 0.650432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402900; batch adversarial loss: 0.603677\n",
      "epoch 31; iter: 200; batch classifier loss: 0.322219; batch adversarial loss: 0.697235\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364250; batch adversarial loss: 0.611387\n",
      "epoch 32; iter: 200; batch classifier loss: 0.340199; batch adversarial loss: 0.587881\n",
      "epoch 33; iter: 0; batch classifier loss: 0.376327; batch adversarial loss: 0.597561\n",
      "epoch 33; iter: 200; batch classifier loss: 0.335457; batch adversarial loss: 0.668286\n",
      "epoch 34; iter: 0; batch classifier loss: 0.313717; batch adversarial loss: 0.654813\n",
      "epoch 34; iter: 200; batch classifier loss: 0.389181; batch adversarial loss: 0.614842\n",
      "epoch 35; iter: 0; batch classifier loss: 0.311130; batch adversarial loss: 0.663343\n",
      "epoch 35; iter: 200; batch classifier loss: 0.309820; batch adversarial loss: 0.579028\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357161; batch adversarial loss: 0.656324\n",
      "epoch 36; iter: 200; batch classifier loss: 0.344264; batch adversarial loss: 0.678408\n",
      "epoch 37; iter: 0; batch classifier loss: 0.309210; batch adversarial loss: 0.628960\n",
      "epoch 37; iter: 200; batch classifier loss: 0.310916; batch adversarial loss: 0.609331\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404487; batch adversarial loss: 0.638532\n",
      "epoch 38; iter: 200; batch classifier loss: 0.324051; batch adversarial loss: 0.654515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.375916; batch adversarial loss: 0.627694\n",
      "epoch 39; iter: 200; batch classifier loss: 0.296752; batch adversarial loss: 0.647442\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398968; batch adversarial loss: 0.661169\n",
      "epoch 40; iter: 200; batch classifier loss: 0.435752; batch adversarial loss: 0.679858\n",
      "epoch 41; iter: 0; batch classifier loss: 0.392857; batch adversarial loss: 0.605773\n",
      "epoch 41; iter: 200; batch classifier loss: 0.404442; batch adversarial loss: 0.671103\n",
      "epoch 42; iter: 0; batch classifier loss: 0.345619; batch adversarial loss: 0.659016\n",
      "epoch 42; iter: 200; batch classifier loss: 0.285503; batch adversarial loss: 0.637408\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414739; batch adversarial loss: 0.676982\n",
      "epoch 43; iter: 200; batch classifier loss: 0.289354; batch adversarial loss: 0.618455\n",
      "epoch 44; iter: 0; batch classifier loss: 0.355378; batch adversarial loss: 0.612189\n",
      "epoch 44; iter: 200; batch classifier loss: 0.434630; batch adversarial loss: 0.664142\n",
      "epoch 45; iter: 0; batch classifier loss: 0.432333; batch adversarial loss: 0.606723\n",
      "epoch 45; iter: 200; batch classifier loss: 0.394919; batch adversarial loss: 0.579795\n",
      "epoch 46; iter: 0; batch classifier loss: 0.363997; batch adversarial loss: 0.642653\n",
      "epoch 46; iter: 200; batch classifier loss: 0.286189; batch adversarial loss: 0.613456\n",
      "epoch 47; iter: 0; batch classifier loss: 0.312553; batch adversarial loss: 0.592386\n",
      "epoch 47; iter: 200; batch classifier loss: 0.472438; batch adversarial loss: 0.667802\n",
      "epoch 48; iter: 0; batch classifier loss: 0.351053; batch adversarial loss: 0.564199\n",
      "epoch 48; iter: 200; batch classifier loss: 0.458808; batch adversarial loss: 0.632481\n",
      "epoch 49; iter: 0; batch classifier loss: 0.335595; batch adversarial loss: 0.549538\n",
      "epoch 49; iter: 200; batch classifier loss: 0.332073; batch adversarial loss: 0.614576\n",
      "epoch 0; iter: 0; batch classifier loss: 50.626099; batch adversarial loss: 0.647967\n",
      "epoch 0; iter: 200; batch classifier loss: 5.912543; batch adversarial loss: 0.687526\n",
      "epoch 1; iter: 0; batch classifier loss: 6.795421; batch adversarial loss: 0.651808\n",
      "epoch 1; iter: 200; batch classifier loss: 8.632184; batch adversarial loss: 0.653179\n",
      "epoch 2; iter: 0; batch classifier loss: 2.788144; batch adversarial loss: 0.621207\n",
      "epoch 2; iter: 200; batch classifier loss: 5.682897; batch adversarial loss: 0.682514\n",
      "epoch 3; iter: 0; batch classifier loss: 2.933345; batch adversarial loss: 0.637054\n",
      "epoch 3; iter: 200; batch classifier loss: 1.848097; batch adversarial loss: 0.616395\n",
      "epoch 4; iter: 0; batch classifier loss: 1.557416; batch adversarial loss: 0.625874\n",
      "epoch 4; iter: 200; batch classifier loss: 1.250326; batch adversarial loss: 0.645344\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532625; batch adversarial loss: 0.643624\n",
      "epoch 5; iter: 200; batch classifier loss: 0.862620; batch adversarial loss: 0.598413\n",
      "epoch 6; iter: 0; batch classifier loss: 1.287914; batch adversarial loss: 0.633916\n",
      "epoch 6; iter: 200; batch classifier loss: 0.448765; batch adversarial loss: 0.633958\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611097; batch adversarial loss: 0.593522\n",
      "epoch 7; iter: 200; batch classifier loss: 0.566993; batch adversarial loss: 0.592845\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511754; batch adversarial loss: 0.680788\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387838; batch adversarial loss: 0.653235\n",
      "epoch 9; iter: 0; batch classifier loss: 0.412128; batch adversarial loss: 0.610992\n",
      "epoch 9; iter: 200; batch classifier loss: 0.397071; batch adversarial loss: 0.620837\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494479; batch adversarial loss: 0.539898\n",
      "epoch 10; iter: 200; batch classifier loss: 0.553727; batch adversarial loss: 0.594267\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535242; batch adversarial loss: 0.610440\n",
      "epoch 11; iter: 200; batch classifier loss: 0.576761; batch adversarial loss: 0.584363\n",
      "epoch 12; iter: 0; batch classifier loss: 0.386762; batch adversarial loss: 0.609701\n",
      "epoch 12; iter: 200; batch classifier loss: 0.423562; batch adversarial loss: 0.646110\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399894; batch adversarial loss: 0.548262\n",
      "epoch 13; iter: 200; batch classifier loss: 0.434892; batch adversarial loss: 0.631738\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406247; batch adversarial loss: 0.617697\n",
      "epoch 14; iter: 200; batch classifier loss: 0.338693; batch adversarial loss: 0.657872\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390683; batch adversarial loss: 0.649401\n",
      "epoch 15; iter: 200; batch classifier loss: 0.434425; batch adversarial loss: 0.552587\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356773; batch adversarial loss: 0.584799\n",
      "epoch 16; iter: 200; batch classifier loss: 0.392110; batch adversarial loss: 0.702933\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382361; batch adversarial loss: 0.614012\n",
      "epoch 17; iter: 200; batch classifier loss: 0.311505; batch adversarial loss: 0.630685\n",
      "epoch 18; iter: 0; batch classifier loss: 0.330679; batch adversarial loss: 0.546130\n",
      "epoch 18; iter: 200; batch classifier loss: 0.409373; batch adversarial loss: 0.618834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.373412; batch adversarial loss: 0.587684\n",
      "epoch 19; iter: 200; batch classifier loss: 0.302543; batch adversarial loss: 0.632115\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256732; batch adversarial loss: 0.693427\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368646; batch adversarial loss: 0.555398\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336199; batch adversarial loss: 0.711004\n",
      "epoch 21; iter: 200; batch classifier loss: 0.456252; batch adversarial loss: 0.626106\n",
      "epoch 22; iter: 0; batch classifier loss: 0.369715; batch adversarial loss: 0.614449\n",
      "epoch 22; iter: 200; batch classifier loss: 0.407812; batch adversarial loss: 0.610861\n",
      "epoch 23; iter: 0; batch classifier loss: 0.399758; batch adversarial loss: 0.579599\n",
      "epoch 23; iter: 200; batch classifier loss: 0.449643; batch adversarial loss: 0.603506\n",
      "epoch 24; iter: 0; batch classifier loss: 0.418329; batch adversarial loss: 0.587685\n",
      "epoch 24; iter: 200; batch classifier loss: 0.350065; batch adversarial loss: 0.621812\n",
      "epoch 25; iter: 0; batch classifier loss: 0.244866; batch adversarial loss: 0.641426\n",
      "epoch 25; iter: 200; batch classifier loss: 0.307500; batch adversarial loss: 0.632108\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489288; batch adversarial loss: 0.648520\n",
      "epoch 26; iter: 200; batch classifier loss: 0.370577; batch adversarial loss: 0.628091\n",
      "epoch 27; iter: 0; batch classifier loss: 0.261787; batch adversarial loss: 0.618388\n",
      "epoch 27; iter: 200; batch classifier loss: 0.261450; batch adversarial loss: 0.682402\n",
      "epoch 28; iter: 0; batch classifier loss: 0.383056; batch adversarial loss: 0.644771\n",
      "epoch 28; iter: 200; batch classifier loss: 0.363010; batch adversarial loss: 0.631819\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322155; batch adversarial loss: 0.633793\n",
      "epoch 29; iter: 200; batch classifier loss: 0.344131; batch adversarial loss: 0.599825\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283193; batch adversarial loss: 0.591735\n",
      "epoch 30; iter: 200; batch classifier loss: 0.372197; batch adversarial loss: 0.657670\n",
      "epoch 31; iter: 0; batch classifier loss: 0.391553; batch adversarial loss: 0.609869\n",
      "epoch 31; iter: 200; batch classifier loss: 0.317852; batch adversarial loss: 0.639623\n",
      "epoch 32; iter: 0; batch classifier loss: 0.371349; batch adversarial loss: 0.624642\n",
      "epoch 32; iter: 200; batch classifier loss: 0.257748; batch adversarial loss: 0.663759\n",
      "epoch 33; iter: 0; batch classifier loss: 0.271778; batch adversarial loss: 0.625551\n",
      "epoch 33; iter: 200; batch classifier loss: 0.382869; batch adversarial loss: 0.625224\n",
      "epoch 34; iter: 0; batch classifier loss: 0.629286; batch adversarial loss: 0.648834\n",
      "epoch 34; iter: 200; batch classifier loss: 0.273942; batch adversarial loss: 0.584752\n",
      "epoch 35; iter: 0; batch classifier loss: 0.281076; batch adversarial loss: 0.652565\n",
      "epoch 35; iter: 200; batch classifier loss: 0.325314; batch adversarial loss: 0.583628\n",
      "epoch 36; iter: 0; batch classifier loss: 0.316715; batch adversarial loss: 0.647704\n",
      "epoch 36; iter: 200; batch classifier loss: 0.401798; batch adversarial loss: 0.619182\n",
      "epoch 37; iter: 0; batch classifier loss: 0.305381; batch adversarial loss: 0.633793\n",
      "epoch 37; iter: 200; batch classifier loss: 0.321333; batch adversarial loss: 0.624273\n",
      "epoch 38; iter: 0; batch classifier loss: 0.282251; batch adversarial loss: 0.636917\n",
      "epoch 38; iter: 200; batch classifier loss: 0.326311; batch adversarial loss: 0.615583\n",
      "epoch 39; iter: 0; batch classifier loss: 0.713194; batch adversarial loss: 0.634966\n",
      "epoch 39; iter: 200; batch classifier loss: 0.301053; batch adversarial loss: 0.616183\n",
      "epoch 40; iter: 0; batch classifier loss: 0.356430; batch adversarial loss: 0.633991\n",
      "epoch 40; iter: 200; batch classifier loss: 0.304120; batch adversarial loss: 0.644854\n",
      "epoch 41; iter: 0; batch classifier loss: 0.358604; batch adversarial loss: 0.598554\n",
      "epoch 41; iter: 200; batch classifier loss: 0.321715; batch adversarial loss: 0.637006\n",
      "epoch 42; iter: 0; batch classifier loss: 0.330395; batch adversarial loss: 0.640784\n",
      "epoch 42; iter: 200; batch classifier loss: 0.320056; batch adversarial loss: 0.674551\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415000; batch adversarial loss: 0.630337\n",
      "epoch 43; iter: 200; batch classifier loss: 0.422159; batch adversarial loss: 0.657861\n",
      "epoch 44; iter: 0; batch classifier loss: 0.384210; batch adversarial loss: 0.645897\n",
      "epoch 44; iter: 200; batch classifier loss: 0.397173; batch adversarial loss: 0.586399\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371226; batch adversarial loss: 0.589789\n",
      "epoch 45; iter: 200; batch classifier loss: 0.280212; batch adversarial loss: 0.726609\n",
      "epoch 46; iter: 0; batch classifier loss: 0.322698; batch adversarial loss: 0.647768\n",
      "epoch 46; iter: 200; batch classifier loss: 0.337857; batch adversarial loss: 0.590541\n",
      "epoch 47; iter: 0; batch classifier loss: 0.300984; batch adversarial loss: 0.614677\n",
      "epoch 47; iter: 200; batch classifier loss: 0.437377; batch adversarial loss: 0.648295\n",
      "epoch 48; iter: 0; batch classifier loss: 0.351971; batch adversarial loss: 0.618171\n",
      "epoch 48; iter: 200; batch classifier loss: 0.309601; batch adversarial loss: 0.635921\n",
      "epoch 49; iter: 0; batch classifier loss: 0.525170; batch adversarial loss: 0.662794\n",
      "epoch 49; iter: 200; batch classifier loss: 0.464306; batch adversarial loss: 0.644517\n",
      "epoch 0; iter: 0; batch classifier loss: 104.829842; batch adversarial loss: 0.816977\n",
      "epoch 0; iter: 200; batch classifier loss: 10.132327; batch adversarial loss: 0.687123\n",
      "epoch 1; iter: 0; batch classifier loss: 7.907237; batch adversarial loss: 0.656596\n",
      "epoch 1; iter: 200; batch classifier loss: 3.477649; batch adversarial loss: 0.668436\n",
      "epoch 2; iter: 0; batch classifier loss: 7.823654; batch adversarial loss: 0.615377\n",
      "epoch 2; iter: 200; batch classifier loss: 4.191381; batch adversarial loss: 0.662440\n",
      "epoch 3; iter: 0; batch classifier loss: 22.239243; batch adversarial loss: 0.659212\n",
      "epoch 3; iter: 200; batch classifier loss: 5.202416; batch adversarial loss: 0.625567\n",
      "epoch 4; iter: 0; batch classifier loss: 3.714746; batch adversarial loss: 0.658574\n",
      "epoch 4; iter: 200; batch classifier loss: 0.790371; batch adversarial loss: 0.589110\n",
      "epoch 5; iter: 0; batch classifier loss: 2.267555; batch adversarial loss: 0.639667\n",
      "epoch 5; iter: 200; batch classifier loss: 1.662256; batch adversarial loss: 0.639849\n",
      "epoch 6; iter: 0; batch classifier loss: 4.491195; batch adversarial loss: 0.603869\n",
      "epoch 6; iter: 200; batch classifier loss: 1.737791; batch adversarial loss: 0.625666\n",
      "epoch 7; iter: 0; batch classifier loss: 0.975107; batch adversarial loss: 0.627349\n",
      "epoch 7; iter: 200; batch classifier loss: 0.525553; batch adversarial loss: 0.620535\n",
      "epoch 8; iter: 0; batch classifier loss: 2.917282; batch adversarial loss: 0.591540\n",
      "epoch 8; iter: 200; batch classifier loss: 0.828093; batch adversarial loss: 0.567226\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536547; batch adversarial loss: 0.685604\n",
      "epoch 9; iter: 200; batch classifier loss: 0.389645; batch adversarial loss: 0.601496\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454321; batch adversarial loss: 0.615991\n",
      "epoch 10; iter: 200; batch classifier loss: 0.467376; batch adversarial loss: 0.615385\n",
      "epoch 11; iter: 0; batch classifier loss: 0.460141; batch adversarial loss: 0.652568\n",
      "epoch 11; iter: 200; batch classifier loss: 0.365533; batch adversarial loss: 0.641052\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457830; batch adversarial loss: 0.603955\n",
      "epoch 12; iter: 200; batch classifier loss: 0.481136; batch adversarial loss: 0.605185\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457243; batch adversarial loss: 0.619707\n",
      "epoch 13; iter: 200; batch classifier loss: 0.440630; batch adversarial loss: 0.603931\n",
      "epoch 14; iter: 0; batch classifier loss: 0.401964; batch adversarial loss: 0.669716\n",
      "epoch 14; iter: 200; batch classifier loss: 0.396394; batch adversarial loss: 0.634872\n",
      "epoch 15; iter: 0; batch classifier loss: 0.438541; batch adversarial loss: 0.591390\n",
      "epoch 15; iter: 200; batch classifier loss: 0.309712; batch adversarial loss: 0.616732\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394544; batch adversarial loss: 0.613954\n",
      "epoch 16; iter: 200; batch classifier loss: 0.350024; batch adversarial loss: 0.592727\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435260; batch adversarial loss: 0.623017\n",
      "epoch 17; iter: 200; batch classifier loss: 0.322928; batch adversarial loss: 0.577397\n",
      "epoch 18; iter: 0; batch classifier loss: 0.383020; batch adversarial loss: 0.617784\n",
      "epoch 18; iter: 200; batch classifier loss: 0.434952; batch adversarial loss: 0.549497\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382754; batch adversarial loss: 0.560752\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385866; batch adversarial loss: 0.552109\n",
      "epoch 20; iter: 0; batch classifier loss: 0.454503; batch adversarial loss: 0.674037\n",
      "epoch 20; iter: 200; batch classifier loss: 0.371350; batch adversarial loss: 0.617967\n",
      "epoch 21; iter: 0; batch classifier loss: 0.374222; batch adversarial loss: 0.662823\n",
      "epoch 21; iter: 200; batch classifier loss: 0.425328; batch adversarial loss: 0.612858\n",
      "epoch 22; iter: 0; batch classifier loss: 0.281993; batch adversarial loss: 0.611347\n",
      "epoch 22; iter: 200; batch classifier loss: 0.418073; batch adversarial loss: 0.590865\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483334; batch adversarial loss: 0.555402\n",
      "epoch 23; iter: 200; batch classifier loss: 0.339588; batch adversarial loss: 0.617533\n",
      "epoch 24; iter: 0; batch classifier loss: 0.419341; batch adversarial loss: 0.604720\n",
      "epoch 24; iter: 200; batch classifier loss: 0.551404; batch adversarial loss: 0.662669\n",
      "epoch 25; iter: 0; batch classifier loss: 0.413452; batch adversarial loss: 0.599184\n",
      "epoch 25; iter: 200; batch classifier loss: 0.483749; batch adversarial loss: 0.620641\n",
      "epoch 26; iter: 0; batch classifier loss: 0.344745; batch adversarial loss: 0.650979\n",
      "epoch 26; iter: 200; batch classifier loss: 0.313505; batch adversarial loss: 0.592557\n",
      "epoch 27; iter: 0; batch classifier loss: 0.470127; batch adversarial loss: 0.610083\n",
      "epoch 27; iter: 200; batch classifier loss: 0.420663; batch adversarial loss: 0.576307\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362463; batch adversarial loss: 0.590936\n",
      "epoch 28; iter: 200; batch classifier loss: 0.294069; batch adversarial loss: 0.664973\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446587; batch adversarial loss: 0.573273\n",
      "epoch 29; iter: 200; batch classifier loss: 0.389834; batch adversarial loss: 0.646838\n",
      "epoch 30; iter: 0; batch classifier loss: 0.316324; batch adversarial loss: 0.675552\n",
      "epoch 30; iter: 200; batch classifier loss: 0.457039; batch adversarial loss: 0.556606\n",
      "epoch 31; iter: 0; batch classifier loss: 0.406670; batch adversarial loss: 0.664221\n",
      "epoch 31; iter: 200; batch classifier loss: 0.296447; batch adversarial loss: 0.665607\n",
      "epoch 32; iter: 0; batch classifier loss: 0.388270; batch adversarial loss: 0.650255\n",
      "epoch 32; iter: 200; batch classifier loss: 0.315371; batch adversarial loss: 0.615345\n",
      "epoch 33; iter: 0; batch classifier loss: 0.333363; batch adversarial loss: 0.627548\n",
      "epoch 33; iter: 200; batch classifier loss: 0.356627; batch adversarial loss: 0.614978\n",
      "epoch 34; iter: 0; batch classifier loss: 0.340950; batch adversarial loss: 0.597882\n",
      "epoch 34; iter: 200; batch classifier loss: 0.255870; batch adversarial loss: 0.590778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.298783; batch adversarial loss: 0.589163\n",
      "epoch 35; iter: 200; batch classifier loss: 0.322095; batch adversarial loss: 0.625341\n",
      "epoch 36; iter: 0; batch classifier loss: 0.370579; batch adversarial loss: 0.570122\n",
      "epoch 36; iter: 200; batch classifier loss: 0.385254; batch adversarial loss: 0.566170\n",
      "epoch 37; iter: 0; batch classifier loss: 0.351985; batch adversarial loss: 0.560967\n",
      "epoch 37; iter: 200; batch classifier loss: 0.287497; batch adversarial loss: 0.578797\n",
      "epoch 38; iter: 0; batch classifier loss: 0.429948; batch adversarial loss: 0.645777\n",
      "epoch 38; iter: 200; batch classifier loss: 0.324391; batch adversarial loss: 0.594181\n",
      "epoch 39; iter: 0; batch classifier loss: 0.387497; batch adversarial loss: 0.630537\n",
      "epoch 39; iter: 200; batch classifier loss: 0.392593; batch adversarial loss: 0.615216\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493251; batch adversarial loss: 0.580009\n",
      "epoch 40; iter: 200; batch classifier loss: 0.422564; batch adversarial loss: 0.557899\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415039; batch adversarial loss: 0.603264\n",
      "epoch 41; iter: 200; batch classifier loss: 0.384216; batch adversarial loss: 0.619894\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378868; batch adversarial loss: 0.592021\n",
      "epoch 42; iter: 200; batch classifier loss: 0.290405; batch adversarial loss: 0.645123\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395445; batch adversarial loss: 0.570559\n",
      "epoch 43; iter: 200; batch classifier loss: 0.388645; batch adversarial loss: 0.672180\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385307; batch adversarial loss: 0.559797\n",
      "epoch 44; iter: 200; batch classifier loss: 0.391486; batch adversarial loss: 0.606394\n",
      "epoch 45; iter: 0; batch classifier loss: 0.386036; batch adversarial loss: 0.587677\n",
      "epoch 45; iter: 200; batch classifier loss: 0.341441; batch adversarial loss: 0.624350\n",
      "epoch 46; iter: 0; batch classifier loss: 0.325856; batch adversarial loss: 0.592666\n",
      "epoch 46; iter: 200; batch classifier loss: 0.340029; batch adversarial loss: 0.609207\n",
      "epoch 47; iter: 0; batch classifier loss: 0.321830; batch adversarial loss: 0.645978\n",
      "epoch 47; iter: 200; batch classifier loss: 0.415451; batch adversarial loss: 0.582120\n",
      "epoch 48; iter: 0; batch classifier loss: 0.341170; batch adversarial loss: 0.603742\n",
      "epoch 48; iter: 200; batch classifier loss: 0.267994; batch adversarial loss: 0.640332\n",
      "epoch 49; iter: 0; batch classifier loss: 0.290873; batch adversarial loss: 0.608589\n",
      "epoch 49; iter: 200; batch classifier loss: 0.418314; batch adversarial loss: 0.627236\n",
      "epoch 0; iter: 0; batch classifier loss: 17.945133; batch adversarial loss: 0.896244\n",
      "epoch 0; iter: 200; batch classifier loss: 8.411427; batch adversarial loss: 0.800166\n",
      "epoch 1; iter: 0; batch classifier loss: 9.712110; batch adversarial loss: 0.775213\n",
      "epoch 1; iter: 200; batch classifier loss: 9.754385; batch adversarial loss: 0.726164\n",
      "epoch 2; iter: 0; batch classifier loss: 3.240406; batch adversarial loss: 0.685156\n",
      "epoch 2; iter: 200; batch classifier loss: 4.076973; batch adversarial loss: 0.643237\n",
      "epoch 3; iter: 0; batch classifier loss: 3.652008; batch adversarial loss: 0.650167\n",
      "epoch 3; iter: 200; batch classifier loss: 3.302829; batch adversarial loss: 0.586192\n",
      "epoch 4; iter: 0; batch classifier loss: 4.076658; batch adversarial loss: 0.612373\n",
      "epoch 4; iter: 200; batch classifier loss: 2.112600; batch adversarial loss: 0.641049\n",
      "epoch 5; iter: 0; batch classifier loss: 1.400694; batch adversarial loss: 0.632946\n",
      "epoch 5; iter: 200; batch classifier loss: 1.199532; batch adversarial loss: 0.628774\n",
      "epoch 6; iter: 0; batch classifier loss: 0.536266; batch adversarial loss: 0.620800\n",
      "epoch 6; iter: 200; batch classifier loss: 0.850334; batch adversarial loss: 0.624792\n",
      "epoch 7; iter: 0; batch classifier loss: 1.452093; batch adversarial loss: 0.617921\n",
      "epoch 7; iter: 200; batch classifier loss: 0.544815; batch adversarial loss: 0.581425\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595629; batch adversarial loss: 0.624661\n",
      "epoch 8; iter: 200; batch classifier loss: 0.610340; batch adversarial loss: 0.644215\n",
      "epoch 9; iter: 0; batch classifier loss: 0.950211; batch adversarial loss: 0.624809\n",
      "epoch 9; iter: 200; batch classifier loss: 0.491791; batch adversarial loss: 0.599284\n",
      "epoch 10; iter: 0; batch classifier loss: 0.715002; batch adversarial loss: 0.616252\n",
      "epoch 10; iter: 200; batch classifier loss: 0.397132; batch adversarial loss: 0.671225\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398540; batch adversarial loss: 0.616346\n",
      "epoch 11; iter: 200; batch classifier loss: 0.489519; batch adversarial loss: 0.631993\n",
      "epoch 12; iter: 0; batch classifier loss: 0.422447; batch adversarial loss: 0.617573\n",
      "epoch 12; iter: 200; batch classifier loss: 0.344448; batch adversarial loss: 0.652779\n",
      "epoch 13; iter: 0; batch classifier loss: 0.522835; batch adversarial loss: 0.606120\n",
      "epoch 13; iter: 200; batch classifier loss: 0.318742; batch adversarial loss: 0.649393\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340003; batch adversarial loss: 0.607147\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351885; batch adversarial loss: 0.652617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395710; batch adversarial loss: 0.550976\n",
      "epoch 15; iter: 200; batch classifier loss: 0.337928; batch adversarial loss: 0.649142\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377299; batch adversarial loss: 0.554442\n",
      "epoch 16; iter: 200; batch classifier loss: 0.386395; batch adversarial loss: 0.654230\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319408; batch adversarial loss: 0.608646\n",
      "epoch 17; iter: 200; batch classifier loss: 0.391071; batch adversarial loss: 0.604902\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384588; batch adversarial loss: 0.611447\n",
      "epoch 18; iter: 200; batch classifier loss: 0.302975; batch adversarial loss: 0.635494\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408599; batch adversarial loss: 0.575120\n",
      "epoch 19; iter: 200; batch classifier loss: 0.472219; batch adversarial loss: 0.583461\n",
      "epoch 20; iter: 0; batch classifier loss: 0.363813; batch adversarial loss: 0.576742\n",
      "epoch 20; iter: 200; batch classifier loss: 0.508749; batch adversarial loss: 0.595928\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369928; batch adversarial loss: 0.598143\n",
      "epoch 21; iter: 200; batch classifier loss: 0.303957; batch adversarial loss: 0.560232\n",
      "epoch 22; iter: 0; batch classifier loss: 0.444943; batch adversarial loss: 0.542475\n",
      "epoch 22; iter: 200; batch classifier loss: 0.328346; batch adversarial loss: 0.605647\n",
      "epoch 23; iter: 0; batch classifier loss: 0.349508; batch adversarial loss: 0.578947\n",
      "epoch 23; iter: 200; batch classifier loss: 0.246378; batch adversarial loss: 0.579313\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498297; batch adversarial loss: 0.608065\n",
      "epoch 24; iter: 200; batch classifier loss: 0.324722; batch adversarial loss: 0.590512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.351823; batch adversarial loss: 0.577110\n",
      "epoch 25; iter: 200; batch classifier loss: 0.329700; batch adversarial loss: 0.564835\n",
      "epoch 26; iter: 0; batch classifier loss: 0.302866; batch adversarial loss: 0.645181\n",
      "epoch 26; iter: 200; batch classifier loss: 0.259766; batch adversarial loss: 0.646732\n",
      "epoch 27; iter: 0; batch classifier loss: 0.328454; batch adversarial loss: 0.580038\n",
      "epoch 27; iter: 200; batch classifier loss: 0.487450; batch adversarial loss: 0.605980\n",
      "epoch 28; iter: 0; batch classifier loss: 0.340052; batch adversarial loss: 0.650026\n",
      "epoch 28; iter: 200; batch classifier loss: 0.292013; batch adversarial loss: 0.655160\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376492; batch adversarial loss: 0.609523\n",
      "epoch 29; iter: 200; batch classifier loss: 0.225723; batch adversarial loss: 0.604020\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404870; batch adversarial loss: 0.601940\n",
      "epoch 30; iter: 200; batch classifier loss: 0.335749; batch adversarial loss: 0.573443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.313895; batch adversarial loss: 0.599196\n",
      "epoch 31; iter: 200; batch classifier loss: 0.332060; batch adversarial loss: 0.570812\n",
      "epoch 32; iter: 0; batch classifier loss: 0.346820; batch adversarial loss: 0.676090\n",
      "epoch 32; iter: 200; batch classifier loss: 0.280749; batch adversarial loss: 0.602422\n",
      "epoch 33; iter: 0; batch classifier loss: 0.357856; batch adversarial loss: 0.633528\n",
      "epoch 33; iter: 200; batch classifier loss: 0.515092; batch adversarial loss: 0.668880\n",
      "epoch 34; iter: 0; batch classifier loss: 0.342568; batch adversarial loss: 0.533419\n",
      "epoch 34; iter: 200; batch classifier loss: 0.354849; batch adversarial loss: 0.572916\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427106; batch adversarial loss: 0.618827\n",
      "epoch 35; iter: 200; batch classifier loss: 0.385585; batch adversarial loss: 0.596661\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368210; batch adversarial loss: 0.566258\n",
      "epoch 36; iter: 200; batch classifier loss: 0.410707; batch adversarial loss: 0.587237\n",
      "epoch 37; iter: 0; batch classifier loss: 0.345528; batch adversarial loss: 0.714330\n",
      "epoch 37; iter: 200; batch classifier loss: 0.378356; batch adversarial loss: 0.621490\n",
      "epoch 38; iter: 0; batch classifier loss: 0.323406; batch adversarial loss: 0.662665\n",
      "epoch 38; iter: 200; batch classifier loss: 0.261559; batch adversarial loss: 0.569401\n",
      "epoch 39; iter: 0; batch classifier loss: 0.398048; batch adversarial loss: 0.668477\n",
      "epoch 39; iter: 200; batch classifier loss: 0.352457; batch adversarial loss: 0.633634\n",
      "epoch 40; iter: 0; batch classifier loss: 0.455235; batch adversarial loss: 0.628995\n",
      "epoch 40; iter: 200; batch classifier loss: 0.306278; batch adversarial loss: 0.605582\n",
      "epoch 41; iter: 0; batch classifier loss: 0.572114; batch adversarial loss: 0.610176\n",
      "epoch 41; iter: 200; batch classifier loss: 0.343623; batch adversarial loss: 0.625391\n",
      "epoch 42; iter: 0; batch classifier loss: 0.368066; batch adversarial loss: 0.653572\n",
      "epoch 42; iter: 200; batch classifier loss: 0.409078; batch adversarial loss: 0.607243\n",
      "epoch 43; iter: 0; batch classifier loss: 0.350227; batch adversarial loss: 0.617536\n",
      "epoch 43; iter: 200; batch classifier loss: 0.392919; batch adversarial loss: 0.675321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358258; batch adversarial loss: 0.610411\n",
      "epoch 44; iter: 200; batch classifier loss: 0.280756; batch adversarial loss: 0.604904\n",
      "epoch 45; iter: 0; batch classifier loss: 0.278464; batch adversarial loss: 0.647242\n",
      "epoch 45; iter: 200; batch classifier loss: 0.328102; batch adversarial loss: 0.631402\n",
      "epoch 46; iter: 0; batch classifier loss: 0.346503; batch adversarial loss: 0.608980\n",
      "epoch 46; iter: 200; batch classifier loss: 0.316162; batch adversarial loss: 0.613298\n",
      "epoch 47; iter: 0; batch classifier loss: 0.330437; batch adversarial loss: 0.660580\n",
      "epoch 47; iter: 200; batch classifier loss: 0.415757; batch adversarial loss: 0.583587\n",
      "epoch 48; iter: 0; batch classifier loss: 0.328477; batch adversarial loss: 0.592809\n",
      "epoch 48; iter: 200; batch classifier loss: 0.356532; batch adversarial loss: 0.662405\n",
      "epoch 49; iter: 0; batch classifier loss: 0.209760; batch adversarial loss: 0.648927\n",
      "epoch 49; iter: 200; batch classifier loss: 0.334383; batch adversarial loss: 0.602826\n",
      "epoch 0; iter: 0; batch classifier loss: 17.179129; batch adversarial loss: 0.950479\n",
      "epoch 0; iter: 200; batch classifier loss: 7.235621; batch adversarial loss: 0.783765\n",
      "epoch 1; iter: 0; batch classifier loss: 5.147871; batch adversarial loss: 0.706591\n",
      "epoch 1; iter: 200; batch classifier loss: 3.248533; batch adversarial loss: 0.686011\n",
      "epoch 2; iter: 0; batch classifier loss: 6.443099; batch adversarial loss: 0.650410\n",
      "epoch 2; iter: 200; batch classifier loss: 1.813340; batch adversarial loss: 0.669644\n",
      "epoch 3; iter: 0; batch classifier loss: 4.489344; batch adversarial loss: 0.655891\n",
      "epoch 3; iter: 200; batch classifier loss: 2.565640; batch adversarial loss: 0.668707\n",
      "epoch 4; iter: 0; batch classifier loss: 2.051301; batch adversarial loss: 0.664422\n",
      "epoch 4; iter: 200; batch classifier loss: 4.552727; batch adversarial loss: 0.602482\n",
      "epoch 5; iter: 0; batch classifier loss: 1.148799; batch adversarial loss: 0.621085\n",
      "epoch 5; iter: 200; batch classifier loss: 0.920395; batch adversarial loss: 0.652399\n",
      "epoch 6; iter: 0; batch classifier loss: 1.023405; batch adversarial loss: 0.629856\n",
      "epoch 6; iter: 200; batch classifier loss: 1.486344; batch adversarial loss: 0.666110\n",
      "epoch 7; iter: 0; batch classifier loss: 0.646912; batch adversarial loss: 0.614003\n",
      "epoch 7; iter: 200; batch classifier loss: 1.329335; batch adversarial loss: 0.628945\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535689; batch adversarial loss: 0.638128\n",
      "epoch 8; iter: 200; batch classifier loss: 0.457896; batch adversarial loss: 0.593854\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553439; batch adversarial loss: 0.619101\n",
      "epoch 9; iter: 200; batch classifier loss: 0.585029; batch adversarial loss: 0.597108\n",
      "epoch 10; iter: 0; batch classifier loss: 0.494220; batch adversarial loss: 0.582522\n",
      "epoch 10; iter: 200; batch classifier loss: 0.364404; batch adversarial loss: 0.601904\n",
      "epoch 11; iter: 0; batch classifier loss: 0.411385; batch adversarial loss: 0.627069\n",
      "epoch 11; iter: 200; batch classifier loss: 0.416098; batch adversarial loss: 0.615074\n",
      "epoch 12; iter: 0; batch classifier loss: 0.378795; batch adversarial loss: 0.688722\n",
      "epoch 12; iter: 200; batch classifier loss: 0.376168; batch adversarial loss: 0.659547\n",
      "epoch 13; iter: 0; batch classifier loss: 0.351365; batch adversarial loss: 0.640159\n",
      "epoch 13; iter: 200; batch classifier loss: 0.471965; batch adversarial loss: 0.612742\n",
      "epoch 14; iter: 0; batch classifier loss: 0.516699; batch adversarial loss: 0.622678\n",
      "epoch 14; iter: 200; batch classifier loss: 0.413022; batch adversarial loss: 0.576662\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334445; batch adversarial loss: 0.616551\n",
      "epoch 15; iter: 200; batch classifier loss: 0.338735; batch adversarial loss: 0.618931\n",
      "epoch 16; iter: 0; batch classifier loss: 0.280631; batch adversarial loss: 0.637411\n",
      "epoch 16; iter: 200; batch classifier loss: 0.423643; batch adversarial loss: 0.581452\n",
      "epoch 17; iter: 0; batch classifier loss: 0.312192; batch adversarial loss: 0.613647\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345077; batch adversarial loss: 0.554908\n",
      "epoch 18; iter: 0; batch classifier loss: 0.403944; batch adversarial loss: 0.625129\n",
      "epoch 18; iter: 200; batch classifier loss: 0.363081; batch adversarial loss: 0.653728\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310580; batch adversarial loss: 0.611532\n",
      "epoch 19; iter: 200; batch classifier loss: 0.468512; batch adversarial loss: 0.612222\n",
      "epoch 20; iter: 0; batch classifier loss: 0.316644; batch adversarial loss: 0.619047\n",
      "epoch 20; iter: 200; batch classifier loss: 0.341923; batch adversarial loss: 0.593372\n",
      "epoch 21; iter: 0; batch classifier loss: 0.384635; batch adversarial loss: 0.597295\n",
      "epoch 21; iter: 200; batch classifier loss: 0.288922; batch adversarial loss: 0.641268\n",
      "epoch 22; iter: 0; batch classifier loss: 0.388021; batch adversarial loss: 0.593429\n",
      "epoch 22; iter: 200; batch classifier loss: 0.353754; batch adversarial loss: 0.596684\n",
      "epoch 23; iter: 0; batch classifier loss: 0.406281; batch adversarial loss: 0.547993\n",
      "epoch 23; iter: 200; batch classifier loss: 0.386858; batch adversarial loss: 0.591743\n",
      "epoch 24; iter: 0; batch classifier loss: 0.314265; batch adversarial loss: 0.596423\n",
      "epoch 24; iter: 200; batch classifier loss: 0.488597; batch adversarial loss: 0.657232\n",
      "epoch 25; iter: 0; batch classifier loss: 0.286498; batch adversarial loss: 0.627803\n",
      "epoch 25; iter: 200; batch classifier loss: 0.376391; batch adversarial loss: 0.581329\n",
      "epoch 26; iter: 0; batch classifier loss: 0.355979; batch adversarial loss: 0.610314\n",
      "epoch 26; iter: 200; batch classifier loss: 0.348939; batch adversarial loss: 0.612622\n",
      "epoch 27; iter: 0; batch classifier loss: 0.290722; batch adversarial loss: 0.625772\n",
      "epoch 27; iter: 200; batch classifier loss: 0.453831; batch adversarial loss: 0.579802\n",
      "epoch 28; iter: 0; batch classifier loss: 0.324691; batch adversarial loss: 0.635160\n",
      "epoch 28; iter: 200; batch classifier loss: 0.317005; batch adversarial loss: 0.580792\n",
      "epoch 29; iter: 0; batch classifier loss: 0.309746; batch adversarial loss: 0.580575\n",
      "epoch 29; iter: 200; batch classifier loss: 0.261018; batch adversarial loss: 0.628005\n",
      "epoch 30; iter: 0; batch classifier loss: 0.374017; batch adversarial loss: 0.668375\n",
      "epoch 30; iter: 200; batch classifier loss: 0.352892; batch adversarial loss: 0.602627\n",
      "epoch 31; iter: 0; batch classifier loss: 0.330515; batch adversarial loss: 0.640843\n",
      "epoch 31; iter: 200; batch classifier loss: 0.357417; batch adversarial loss: 0.624168\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318753; batch adversarial loss: 0.660755\n",
      "epoch 32; iter: 200; batch classifier loss: 0.512980; batch adversarial loss: 0.601993\n",
      "epoch 33; iter: 0; batch classifier loss: 0.399445; batch adversarial loss: 0.602913\n",
      "epoch 33; iter: 200; batch classifier loss: 0.420808; batch adversarial loss: 0.637305\n",
      "epoch 34; iter: 0; batch classifier loss: 0.302300; batch adversarial loss: 0.655720\n",
      "epoch 34; iter: 200; batch classifier loss: 0.454814; batch adversarial loss: 0.661679\n",
      "epoch 35; iter: 0; batch classifier loss: 0.413061; batch adversarial loss: 0.653527\n",
      "epoch 35; iter: 200; batch classifier loss: 0.361145; batch adversarial loss: 0.640031\n",
      "epoch 36; iter: 0; batch classifier loss: 0.469220; batch adversarial loss: 0.637496\n",
      "epoch 36; iter: 200; batch classifier loss: 0.405561; batch adversarial loss: 0.622548\n",
      "epoch 37; iter: 0; batch classifier loss: 0.365587; batch adversarial loss: 0.607155\n",
      "epoch 37; iter: 200; batch classifier loss: 0.382246; batch adversarial loss: 0.612166\n",
      "epoch 38; iter: 0; batch classifier loss: 0.221165; batch adversarial loss: 0.606601\n",
      "epoch 38; iter: 200; batch classifier loss: 0.327857; batch adversarial loss: 0.613364\n",
      "epoch 39; iter: 0; batch classifier loss: 0.428688; batch adversarial loss: 0.668015\n",
      "epoch 39; iter: 200; batch classifier loss: 0.350659; batch adversarial loss: 0.588181\n",
      "epoch 40; iter: 0; batch classifier loss: 0.384066; batch adversarial loss: 0.633799\n",
      "epoch 40; iter: 200; batch classifier loss: 0.563167; batch adversarial loss: 0.594853\n",
      "epoch 41; iter: 0; batch classifier loss: 0.352657; batch adversarial loss: 0.642285\n",
      "epoch 41; iter: 200; batch classifier loss: 0.450559; batch adversarial loss: 0.566569\n",
      "epoch 42; iter: 0; batch classifier loss: 0.470254; batch adversarial loss: 0.591346\n",
      "epoch 42; iter: 200; batch classifier loss: 0.326534; batch adversarial loss: 0.631280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407117; batch adversarial loss: 0.593611\n",
      "epoch 43; iter: 200; batch classifier loss: 0.369461; batch adversarial loss: 0.649797\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499349; batch adversarial loss: 0.641420\n",
      "epoch 44; iter: 200; batch classifier loss: 0.527505; batch adversarial loss: 0.573121\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398978; batch adversarial loss: 0.651020\n",
      "epoch 45; iter: 200; batch classifier loss: 0.401801; batch adversarial loss: 0.651587\n",
      "epoch 46; iter: 0; batch classifier loss: 0.254074; batch adversarial loss: 0.632985\n",
      "epoch 46; iter: 200; batch classifier loss: 0.381559; batch adversarial loss: 0.651232\n",
      "epoch 47; iter: 0; batch classifier loss: 0.328367; batch adversarial loss: 0.603421\n",
      "epoch 47; iter: 200; batch classifier loss: 0.294272; batch adversarial loss: 0.547147\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397132; batch adversarial loss: 0.676067\n",
      "epoch 48; iter: 200; batch classifier loss: 0.437754; batch adversarial loss: 0.668945\n",
      "epoch 49; iter: 0; batch classifier loss: 0.410971; batch adversarial loss: 0.568581\n",
      "epoch 49; iter: 200; batch classifier loss: 0.424576; batch adversarial loss: 0.640152\n",
      "epoch 0; iter: 0; batch classifier loss: 26.957432; batch adversarial loss: 0.761640\n",
      "epoch 0; iter: 200; batch classifier loss: 3.992325; batch adversarial loss: 0.728704\n",
      "epoch 1; iter: 0; batch classifier loss: 6.774056; batch adversarial loss: 0.691760\n",
      "epoch 1; iter: 200; batch classifier loss: 9.855885; batch adversarial loss: 0.652235\n",
      "epoch 2; iter: 0; batch classifier loss: 4.353052; batch adversarial loss: 0.646944\n",
      "epoch 2; iter: 200; batch classifier loss: 3.824771; batch adversarial loss: 0.626553\n",
      "epoch 3; iter: 0; batch classifier loss: 4.007410; batch adversarial loss: 0.634146\n",
      "epoch 3; iter: 200; batch classifier loss: 4.434039; batch adversarial loss: 0.598727\n",
      "epoch 4; iter: 0; batch classifier loss: 2.144991; batch adversarial loss: 0.631420\n",
      "epoch 4; iter: 200; batch classifier loss: 1.423875; batch adversarial loss: 0.573529\n",
      "epoch 5; iter: 0; batch classifier loss: 1.265353; batch adversarial loss: 0.641709\n",
      "epoch 5; iter: 200; batch classifier loss: 1.252916; batch adversarial loss: 0.618702\n",
      "epoch 6; iter: 0; batch classifier loss: 2.493507; batch adversarial loss: 0.589642\n",
      "epoch 6; iter: 200; batch classifier loss: 0.735561; batch adversarial loss: 0.631115\n",
      "epoch 7; iter: 0; batch classifier loss: 0.857326; batch adversarial loss: 0.660290\n",
      "epoch 7; iter: 200; batch classifier loss: 0.512335; batch adversarial loss: 0.689950\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634192; batch adversarial loss: 0.613934\n",
      "epoch 8; iter: 200; batch classifier loss: 1.401720; batch adversarial loss: 0.623966\n",
      "epoch 9; iter: 0; batch classifier loss: 0.447792; batch adversarial loss: 0.679992\n",
      "epoch 9; iter: 200; batch classifier loss: 0.500557; batch adversarial loss: 0.630244\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397352; batch adversarial loss: 0.561860\n",
      "epoch 10; iter: 200; batch classifier loss: 0.481506; batch adversarial loss: 0.600078\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480050; batch adversarial loss: 0.582205\n",
      "epoch 11; iter: 200; batch classifier loss: 0.448849; batch adversarial loss: 0.667535\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343222; batch adversarial loss: 0.614147\n",
      "epoch 12; iter: 200; batch classifier loss: 0.358822; batch adversarial loss: 0.597456\n",
      "epoch 13; iter: 0; batch classifier loss: 0.249639; batch adversarial loss: 0.676458\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326545; batch adversarial loss: 0.605963\n",
      "epoch 14; iter: 0; batch classifier loss: 0.428197; batch adversarial loss: 0.610453\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378435; batch adversarial loss: 0.576830\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310892; batch adversarial loss: 0.646973\n",
      "epoch 15; iter: 200; batch classifier loss: 0.324307; batch adversarial loss: 0.546591\n",
      "epoch 16; iter: 0; batch classifier loss: 0.411276; batch adversarial loss: 0.585905\n",
      "epoch 16; iter: 200; batch classifier loss: 0.332181; batch adversarial loss: 0.598247\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366554; batch adversarial loss: 0.652682\n",
      "epoch 17; iter: 200; batch classifier loss: 0.421057; batch adversarial loss: 0.577847\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326268; batch adversarial loss: 0.571520\n",
      "epoch 18; iter: 200; batch classifier loss: 0.416004; batch adversarial loss: 0.644417\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379626; batch adversarial loss: 0.612498\n",
      "epoch 19; iter: 200; batch classifier loss: 0.452710; batch adversarial loss: 0.577067\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428582; batch adversarial loss: 0.595782\n",
      "epoch 20; iter: 200; batch classifier loss: 0.377627; batch adversarial loss: 0.613848\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319168; batch adversarial loss: 0.607621\n",
      "epoch 21; iter: 200; batch classifier loss: 0.343387; batch adversarial loss: 0.565502\n",
      "epoch 22; iter: 0; batch classifier loss: 0.377786; batch adversarial loss: 0.577599\n",
      "epoch 22; iter: 200; batch classifier loss: 0.392268; batch adversarial loss: 0.577100\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450195; batch adversarial loss: 0.592106\n",
      "epoch 23; iter: 200; batch classifier loss: 0.325480; batch adversarial loss: 0.668395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.358132; batch adversarial loss: 0.548178\n",
      "epoch 24; iter: 200; batch classifier loss: 0.373944; batch adversarial loss: 0.576553\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360736; batch adversarial loss: 0.666537\n",
      "epoch 25; iter: 200; batch classifier loss: 0.359438; batch adversarial loss: 0.611459\n",
      "epoch 26; iter: 0; batch classifier loss: 0.350050; batch adversarial loss: 0.587624\n",
      "epoch 26; iter: 200; batch classifier loss: 0.312693; batch adversarial loss: 0.596850\n",
      "epoch 27; iter: 0; batch classifier loss: 0.369121; batch adversarial loss: 0.640776\n",
      "epoch 27; iter: 200; batch classifier loss: 0.280772; batch adversarial loss: 0.567896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.344449; batch adversarial loss: 0.616161\n",
      "epoch 28; iter: 200; batch classifier loss: 0.250603; batch adversarial loss: 0.688580\n",
      "epoch 29; iter: 0; batch classifier loss: 0.282400; batch adversarial loss: 0.692749\n",
      "epoch 29; iter: 200; batch classifier loss: 0.305139; batch adversarial loss: 0.604825\n",
      "epoch 30; iter: 0; batch classifier loss: 0.265617; batch adversarial loss: 0.661414\n",
      "epoch 30; iter: 200; batch classifier loss: 0.319170; batch adversarial loss: 0.552471\n",
      "epoch 31; iter: 0; batch classifier loss: 0.307193; batch adversarial loss: 0.636872\n",
      "epoch 31; iter: 200; batch classifier loss: 0.350844; batch adversarial loss: 0.665725\n",
      "epoch 32; iter: 0; batch classifier loss: 0.424053; batch adversarial loss: 0.614382\n",
      "epoch 32; iter: 200; batch classifier loss: 0.394513; batch adversarial loss: 0.617056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344383; batch adversarial loss: 0.624465\n",
      "epoch 33; iter: 200; batch classifier loss: 0.386434; batch adversarial loss: 0.571367\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392941; batch adversarial loss: 0.649583\n",
      "epoch 34; iter: 200; batch classifier loss: 0.352382; batch adversarial loss: 0.602065\n",
      "epoch 35; iter: 0; batch classifier loss: 0.357486; batch adversarial loss: 0.601305\n",
      "epoch 35; iter: 200; batch classifier loss: 0.289077; batch adversarial loss: 0.671939\n",
      "epoch 36; iter: 0; batch classifier loss: 0.395625; batch adversarial loss: 0.603750\n",
      "epoch 36; iter: 200; batch classifier loss: 0.328687; batch adversarial loss: 0.596743\n",
      "epoch 37; iter: 0; batch classifier loss: 0.329539; batch adversarial loss: 0.611920\n",
      "epoch 37; iter: 200; batch classifier loss: 0.390933; batch adversarial loss: 0.590604\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340511; batch adversarial loss: 0.656698\n",
      "epoch 38; iter: 200; batch classifier loss: 0.289540; batch adversarial loss: 0.662432\n",
      "epoch 39; iter: 0; batch classifier loss: 0.373003; batch adversarial loss: 0.611713\n",
      "epoch 39; iter: 200; batch classifier loss: 0.327270; batch adversarial loss: 0.707301\n",
      "epoch 40; iter: 0; batch classifier loss: 0.292684; batch adversarial loss: 0.598160\n",
      "epoch 40; iter: 200; batch classifier loss: 0.386987; batch adversarial loss: 0.603267\n",
      "epoch 41; iter: 0; batch classifier loss: 0.405092; batch adversarial loss: 0.617464\n",
      "epoch 41; iter: 200; batch classifier loss: 0.267759; batch adversarial loss: 0.610238\n",
      "epoch 42; iter: 0; batch classifier loss: 0.308485; batch adversarial loss: 0.668222\n",
      "epoch 42; iter: 200; batch classifier loss: 0.350859; batch adversarial loss: 0.625241\n",
      "epoch 43; iter: 0; batch classifier loss: 0.494391; batch adversarial loss: 0.618073\n",
      "epoch 43; iter: 200; batch classifier loss: 0.407683; batch adversarial loss: 0.633644\n",
      "epoch 44; iter: 0; batch classifier loss: 0.357271; batch adversarial loss: 0.615233\n",
      "epoch 44; iter: 200; batch classifier loss: 0.330673; batch adversarial loss: 0.606362\n",
      "epoch 45; iter: 0; batch classifier loss: 0.276129; batch adversarial loss: 0.641645\n",
      "epoch 45; iter: 200; batch classifier loss: 0.353868; batch adversarial loss: 0.601916\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383136; batch adversarial loss: 0.635152\n",
      "epoch 46; iter: 200; batch classifier loss: 0.375006; batch adversarial loss: 0.574244\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325087; batch adversarial loss: 0.670731\n",
      "epoch 47; iter: 200; batch classifier loss: 0.301049; batch adversarial loss: 0.688563\n",
      "epoch 48; iter: 0; batch classifier loss: 0.743805; batch adversarial loss: 0.650353\n",
      "epoch 48; iter: 200; batch classifier loss: 0.314250; batch adversarial loss: 0.618083\n",
      "epoch 49; iter: 0; batch classifier loss: 0.455492; batch adversarial loss: 0.627781\n",
      "epoch 49; iter: 200; batch classifier loss: 0.387520; batch adversarial loss: 0.643690\n",
      "epoch 0; iter: 0; batch classifier loss: 15.516527; batch adversarial loss: 0.690894\n",
      "epoch 0; iter: 200; batch classifier loss: 11.306540; batch adversarial loss: 0.714765\n",
      "epoch 1; iter: 0; batch classifier loss: 8.168571; batch adversarial loss: 0.642796\n",
      "epoch 1; iter: 200; batch classifier loss: 7.791544; batch adversarial loss: 0.681878\n",
      "epoch 2; iter: 0; batch classifier loss: 8.815902; batch adversarial loss: 0.639226\n",
      "epoch 2; iter: 200; batch classifier loss: 4.948448; batch adversarial loss: 0.610477\n",
      "epoch 3; iter: 0; batch classifier loss: 2.479026; batch adversarial loss: 0.671645\n",
      "epoch 3; iter: 200; batch classifier loss: 2.781274; batch adversarial loss: 0.598123\n",
      "epoch 4; iter: 0; batch classifier loss: 1.778082; batch adversarial loss: 0.648033\n",
      "epoch 4; iter: 200; batch classifier loss: 2.823330; batch adversarial loss: 0.567803\n",
      "epoch 5; iter: 0; batch classifier loss: 1.251448; batch adversarial loss: 0.609582\n",
      "epoch 5; iter: 200; batch classifier loss: 0.742144; batch adversarial loss: 0.629488\n",
      "epoch 6; iter: 0; batch classifier loss: 0.756130; batch adversarial loss: 0.598286\n",
      "epoch 6; iter: 200; batch classifier loss: 0.705681; batch adversarial loss: 0.606714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.623625; batch adversarial loss: 0.679040\n",
      "epoch 7; iter: 200; batch classifier loss: 0.522972; batch adversarial loss: 0.592491\n",
      "epoch 8; iter: 0; batch classifier loss: 0.831948; batch adversarial loss: 0.656500\n",
      "epoch 8; iter: 200; batch classifier loss: 0.626950; batch adversarial loss: 0.568372\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533174; batch adversarial loss: 0.636525\n",
      "epoch 9; iter: 200; batch classifier loss: 0.631351; batch adversarial loss: 0.634828\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375269; batch adversarial loss: 0.581364\n",
      "epoch 10; iter: 200; batch classifier loss: 0.473205; batch adversarial loss: 0.601560\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413221; batch adversarial loss: 0.631396\n",
      "epoch 11; iter: 200; batch classifier loss: 0.472063; batch adversarial loss: 0.681333\n",
      "epoch 12; iter: 0; batch classifier loss: 0.432924; batch adversarial loss: 0.580249\n",
      "epoch 12; iter: 200; batch classifier loss: 0.856784; batch adversarial loss: 0.575167\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346192; batch adversarial loss: 0.664562\n",
      "epoch 13; iter: 200; batch classifier loss: 0.281322; batch adversarial loss: 0.593788\n",
      "epoch 14; iter: 0; batch classifier loss: 0.326341; batch adversarial loss: 0.594431\n",
      "epoch 14; iter: 200; batch classifier loss: 0.551031; batch adversarial loss: 0.583797\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359372; batch adversarial loss: 0.593929\n",
      "epoch 15; iter: 200; batch classifier loss: 0.347625; batch adversarial loss: 0.578220\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518681; batch adversarial loss: 0.655030\n",
      "epoch 16; iter: 200; batch classifier loss: 0.333771; batch adversarial loss: 0.581535\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328042; batch adversarial loss: 0.630111\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343112; batch adversarial loss: 0.694423\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342096; batch adversarial loss: 0.625107\n",
      "epoch 18; iter: 200; batch classifier loss: 0.338685; batch adversarial loss: 0.608599\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253917; batch adversarial loss: 0.677340\n",
      "epoch 19; iter: 200; batch classifier loss: 0.395621; batch adversarial loss: 0.560089\n",
      "epoch 20; iter: 0; batch classifier loss: 0.363884; batch adversarial loss: 0.621744\n",
      "epoch 20; iter: 200; batch classifier loss: 0.254860; batch adversarial loss: 0.584902\n",
      "epoch 21; iter: 0; batch classifier loss: 0.417549; batch adversarial loss: 0.647275\n",
      "epoch 21; iter: 200; batch classifier loss: 0.347432; batch adversarial loss: 0.583677\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354685; batch adversarial loss: 0.604318\n",
      "epoch 22; iter: 200; batch classifier loss: 0.263488; batch adversarial loss: 0.614856\n",
      "epoch 23; iter: 0; batch classifier loss: 0.345666; batch adversarial loss: 0.688169\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371841; batch adversarial loss: 0.597398\n",
      "epoch 24; iter: 0; batch classifier loss: 0.346590; batch adversarial loss: 0.578615\n",
      "epoch 24; iter: 200; batch classifier loss: 0.279038; batch adversarial loss: 0.615909\n",
      "epoch 25; iter: 0; batch classifier loss: 0.312546; batch adversarial loss: 0.572345\n",
      "epoch 25; iter: 200; batch classifier loss: 0.356526; batch adversarial loss: 0.570816\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297634; batch adversarial loss: 0.631392\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343574; batch adversarial loss: 0.648214\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337312; batch adversarial loss: 0.650753\n",
      "epoch 27; iter: 200; batch classifier loss: 0.244572; batch adversarial loss: 0.653093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.511157; batch adversarial loss: 0.595764\n",
      "epoch 28; iter: 200; batch classifier loss: 0.334631; batch adversarial loss: 0.587030\n",
      "epoch 29; iter: 0; batch classifier loss: 0.299185; batch adversarial loss: 0.566504\n",
      "epoch 29; iter: 200; batch classifier loss: 0.393990; batch adversarial loss: 0.551705\n",
      "epoch 30; iter: 0; batch classifier loss: 0.380687; batch adversarial loss: 0.587937\n",
      "epoch 30; iter: 200; batch classifier loss: 0.376243; batch adversarial loss: 0.677764\n",
      "epoch 31; iter: 0; batch classifier loss: 0.357877; batch adversarial loss: 0.602742\n",
      "epoch 31; iter: 200; batch classifier loss: 0.365164; batch adversarial loss: 0.610340\n",
      "epoch 32; iter: 0; batch classifier loss: 0.316153; batch adversarial loss: 0.586923\n",
      "epoch 32; iter: 200; batch classifier loss: 0.434041; batch adversarial loss: 0.621392\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433642; batch adversarial loss: 0.602319\n",
      "epoch 33; iter: 200; batch classifier loss: 0.656649; batch adversarial loss: 0.589926\n",
      "epoch 34; iter: 0; batch classifier loss: 0.280551; batch adversarial loss: 0.639249\n",
      "epoch 34; iter: 200; batch classifier loss: 0.389202; batch adversarial loss: 0.641071\n",
      "epoch 35; iter: 0; batch classifier loss: 0.349258; batch adversarial loss: 0.621765\n",
      "epoch 35; iter: 200; batch classifier loss: 0.308939; batch adversarial loss: 0.649151\n",
      "epoch 36; iter: 0; batch classifier loss: 0.398930; batch adversarial loss: 0.576776\n",
      "epoch 36; iter: 200; batch classifier loss: 0.387190; batch adversarial loss: 0.588082\n",
      "epoch 37; iter: 0; batch classifier loss: 0.329701; batch adversarial loss: 0.661414\n",
      "epoch 37; iter: 200; batch classifier loss: 0.299427; batch adversarial loss: 0.626005\n",
      "epoch 38; iter: 0; batch classifier loss: 0.319465; batch adversarial loss: 0.591079\n",
      "epoch 38; iter: 200; batch classifier loss: 0.366695; batch adversarial loss: 0.609557\n",
      "epoch 39; iter: 0; batch classifier loss: 0.371628; batch adversarial loss: 0.594695\n",
      "epoch 39; iter: 200; batch classifier loss: 0.340794; batch adversarial loss: 0.653304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.372736; batch adversarial loss: 0.613232\n",
      "epoch 40; iter: 200; batch classifier loss: 0.383706; batch adversarial loss: 0.626485\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382757; batch adversarial loss: 0.610372\n",
      "epoch 41; iter: 200; batch classifier loss: 0.251692; batch adversarial loss: 0.617179\n",
      "epoch 42; iter: 0; batch classifier loss: 0.423140; batch adversarial loss: 0.657705\n",
      "epoch 42; iter: 200; batch classifier loss: 0.321405; batch adversarial loss: 0.603362\n",
      "epoch 43; iter: 0; batch classifier loss: 0.455926; batch adversarial loss: 0.585537\n",
      "epoch 43; iter: 200; batch classifier loss: 0.305897; batch adversarial loss: 0.602162\n",
      "epoch 44; iter: 0; batch classifier loss: 0.330265; batch adversarial loss: 0.606328\n",
      "epoch 44; iter: 200; batch classifier loss: 0.373838; batch adversarial loss: 0.568416\n",
      "epoch 45; iter: 0; batch classifier loss: 0.329775; batch adversarial loss: 0.645232\n",
      "epoch 45; iter: 200; batch classifier loss: 0.370436; batch adversarial loss: 0.638709\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370327; batch adversarial loss: 0.652430\n",
      "epoch 46; iter: 200; batch classifier loss: 0.397398; batch adversarial loss: 0.585150\n",
      "epoch 47; iter: 0; batch classifier loss: 0.352035; batch adversarial loss: 0.575119\n",
      "epoch 47; iter: 200; batch classifier loss: 0.629262; batch adversarial loss: 0.608343\n",
      "epoch 48; iter: 0; batch classifier loss: 0.408333; batch adversarial loss: 0.622547\n",
      "epoch 48; iter: 200; batch classifier loss: 0.303452; batch adversarial loss: 0.556770\n",
      "epoch 49; iter: 0; batch classifier loss: 0.484522; batch adversarial loss: 0.675434\n",
      "epoch 49; iter: 200; batch classifier loss: 0.453703; batch adversarial loss: 0.643801\n",
      "epoch 0; iter: 0; batch classifier loss: 7.464818; batch adversarial loss: 0.895954\n",
      "epoch 0; iter: 200; batch classifier loss: 3.682414; batch adversarial loss: 0.717655\n",
      "epoch 1; iter: 0; batch classifier loss: 4.190465; batch adversarial loss: 0.697196\n",
      "epoch 1; iter: 200; batch classifier loss: 7.100444; batch adversarial loss: 0.648605\n",
      "epoch 2; iter: 0; batch classifier loss: 3.483790; batch adversarial loss: 0.640491\n",
      "epoch 2; iter: 200; batch classifier loss: 3.707605; batch adversarial loss: 0.622284\n",
      "epoch 3; iter: 0; batch classifier loss: 4.358785; batch adversarial loss: 0.668998\n",
      "epoch 3; iter: 200; batch classifier loss: 3.845519; batch adversarial loss: 0.654392\n",
      "epoch 4; iter: 0; batch classifier loss: 2.548397; batch adversarial loss: 0.625641\n",
      "epoch 4; iter: 200; batch classifier loss: 2.640566; batch adversarial loss: 0.618912\n",
      "epoch 5; iter: 0; batch classifier loss: 2.017452; batch adversarial loss: 0.649979\n",
      "epoch 5; iter: 200; batch classifier loss: 1.045443; batch adversarial loss: 0.680016\n",
      "epoch 6; iter: 0; batch classifier loss: 6.932703; batch adversarial loss: 0.605578\n",
      "epoch 6; iter: 200; batch classifier loss: 1.165377; batch adversarial loss: 0.693915\n",
      "epoch 7; iter: 0; batch classifier loss: 1.121705; batch adversarial loss: 0.657627\n",
      "epoch 7; iter: 200; batch classifier loss: 0.534999; batch adversarial loss: 0.667877\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601874; batch adversarial loss: 0.629464\n",
      "epoch 8; iter: 200; batch classifier loss: 0.635585; batch adversarial loss: 0.575934\n",
      "epoch 9; iter: 0; batch classifier loss: 0.737158; batch adversarial loss: 0.601148\n",
      "epoch 9; iter: 200; batch classifier loss: 0.554537; batch adversarial loss: 0.587919\n",
      "epoch 10; iter: 0; batch classifier loss: 0.653270; batch adversarial loss: 0.615055\n",
      "epoch 10; iter: 200; batch classifier loss: 0.534103; batch adversarial loss: 0.602658\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464643; batch adversarial loss: 0.584693\n",
      "epoch 11; iter: 200; batch classifier loss: 0.382794; batch adversarial loss: 0.634935\n",
      "epoch 12; iter: 0; batch classifier loss: 0.351354; batch adversarial loss: 0.601371\n",
      "epoch 12; iter: 200; batch classifier loss: 0.333537; batch adversarial loss: 0.591682\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530093; batch adversarial loss: 0.616750\n",
      "epoch 13; iter: 200; batch classifier loss: 0.476062; batch adversarial loss: 0.684874\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488042; batch adversarial loss: 0.653361\n",
      "epoch 14; iter: 200; batch classifier loss: 0.409370; batch adversarial loss: 0.601372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.503121; batch adversarial loss: 0.638039\n",
      "epoch 15; iter: 200; batch classifier loss: 0.352291; batch adversarial loss: 0.602838\n",
      "epoch 16; iter: 0; batch classifier loss: 0.464131; batch adversarial loss: 0.626630\n",
      "epoch 16; iter: 200; batch classifier loss: 0.434844; batch adversarial loss: 0.675522\n",
      "epoch 17; iter: 0; batch classifier loss: 0.342584; batch adversarial loss: 0.641251\n",
      "epoch 17; iter: 200; batch classifier loss: 0.420876; batch adversarial loss: 0.636086\n",
      "epoch 18; iter: 0; batch classifier loss: 0.336553; batch adversarial loss: 0.596208\n",
      "epoch 18; iter: 200; batch classifier loss: 0.313506; batch adversarial loss: 0.615289\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335425; batch adversarial loss: 0.606061\n",
      "epoch 19; iter: 200; batch classifier loss: 0.441312; batch adversarial loss: 0.567110\n",
      "epoch 20; iter: 0; batch classifier loss: 0.374380; batch adversarial loss: 0.563152\n",
      "epoch 20; iter: 200; batch classifier loss: 0.321048; batch adversarial loss: 0.566115\n",
      "epoch 21; iter: 0; batch classifier loss: 0.351663; batch adversarial loss: 0.590596\n",
      "epoch 21; iter: 200; batch classifier loss: 0.327323; batch adversarial loss: 0.581958\n",
      "epoch 22; iter: 0; batch classifier loss: 0.283793; batch adversarial loss: 0.586923\n",
      "epoch 22; iter: 200; batch classifier loss: 0.286446; batch adversarial loss: 0.614414\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426710; batch adversarial loss: 0.584918\n",
      "epoch 23; iter: 200; batch classifier loss: 0.553863; batch adversarial loss: 0.622432\n",
      "epoch 24; iter: 0; batch classifier loss: 0.335910; batch adversarial loss: 0.529263\n",
      "epoch 24; iter: 200; batch classifier loss: 0.382604; batch adversarial loss: 0.650252\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291003; batch adversarial loss: 0.576781\n",
      "epoch 25; iter: 200; batch classifier loss: 0.298390; batch adversarial loss: 0.591117\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366312; batch adversarial loss: 0.598269\n",
      "epoch 26; iter: 200; batch classifier loss: 0.407432; batch adversarial loss: 0.534897\n",
      "epoch 27; iter: 0; batch classifier loss: 0.305385; batch adversarial loss: 0.687846\n",
      "epoch 27; iter: 200; batch classifier loss: 0.371256; batch adversarial loss: 0.611456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.400775; batch adversarial loss: 0.553855\n",
      "epoch 28; iter: 200; batch classifier loss: 0.312096; batch adversarial loss: 0.616694\n",
      "epoch 29; iter: 0; batch classifier loss: 0.317644; batch adversarial loss: 0.706605\n",
      "epoch 29; iter: 200; batch classifier loss: 0.346486; batch adversarial loss: 0.595601\n",
      "epoch 30; iter: 0; batch classifier loss: 0.375560; batch adversarial loss: 0.658024\n",
      "epoch 30; iter: 200; batch classifier loss: 0.362011; batch adversarial loss: 0.637534\n",
      "epoch 31; iter: 0; batch classifier loss: 0.272292; batch adversarial loss: 0.600306\n",
      "epoch 31; iter: 200; batch classifier loss: 0.339270; batch adversarial loss: 0.639137\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329224; batch adversarial loss: 0.600400\n",
      "epoch 32; iter: 200; batch classifier loss: 0.585210; batch adversarial loss: 0.634011\n",
      "epoch 33; iter: 0; batch classifier loss: 0.213999; batch adversarial loss: 0.598944\n",
      "epoch 33; iter: 200; batch classifier loss: 0.416467; batch adversarial loss: 0.646555\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411618; batch adversarial loss: 0.626890\n",
      "epoch 34; iter: 200; batch classifier loss: 0.352119; batch adversarial loss: 0.580442\n",
      "epoch 35; iter: 0; batch classifier loss: 0.282218; batch adversarial loss: 0.604641\n",
      "epoch 35; iter: 200; batch classifier loss: 0.336825; batch adversarial loss: 0.611755\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272718; batch adversarial loss: 0.625084\n",
      "epoch 36; iter: 200; batch classifier loss: 0.578514; batch adversarial loss: 0.579140\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378453; batch adversarial loss: 0.579779\n",
      "epoch 37; iter: 200; batch classifier loss: 0.318611; batch adversarial loss: 0.617979\n",
      "epoch 38; iter: 0; batch classifier loss: 0.363151; batch adversarial loss: 0.587237\n",
      "epoch 38; iter: 200; batch classifier loss: 0.351861; batch adversarial loss: 0.641485\n",
      "epoch 39; iter: 0; batch classifier loss: 0.388481; batch adversarial loss: 0.619951\n",
      "epoch 39; iter: 200; batch classifier loss: 0.389695; batch adversarial loss: 0.627580\n",
      "epoch 40; iter: 0; batch classifier loss: 0.307864; batch adversarial loss: 0.649190\n",
      "epoch 40; iter: 200; batch classifier loss: 0.402851; batch adversarial loss: 0.562878\n",
      "epoch 41; iter: 0; batch classifier loss: 0.419486; batch adversarial loss: 0.630582\n",
      "epoch 41; iter: 200; batch classifier loss: 0.305719; batch adversarial loss: 0.619594\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389827; batch adversarial loss: 0.635358\n",
      "epoch 42; iter: 200; batch classifier loss: 0.512649; batch adversarial loss: 0.619810\n",
      "epoch 43; iter: 0; batch classifier loss: 0.344659; batch adversarial loss: 0.649611\n",
      "epoch 43; iter: 200; batch classifier loss: 0.381607; batch adversarial loss: 0.594439\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383509; batch adversarial loss: 0.632235\n",
      "epoch 44; iter: 200; batch classifier loss: 0.312303; batch adversarial loss: 0.622110\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407019; batch adversarial loss: 0.641428\n",
      "epoch 45; iter: 200; batch classifier loss: 0.449035; batch adversarial loss: 0.665283\n",
      "epoch 46; iter: 0; batch classifier loss: 0.384037; batch adversarial loss: 0.597014\n",
      "epoch 46; iter: 200; batch classifier loss: 0.396854; batch adversarial loss: 0.597551\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408754; batch adversarial loss: 0.583978\n",
      "epoch 47; iter: 200; batch classifier loss: 0.351863; batch adversarial loss: 0.600099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.305880; batch adversarial loss: 0.684616\n",
      "epoch 48; iter: 200; batch classifier loss: 0.434956; batch adversarial loss: 0.575641\n",
      "epoch 49; iter: 0; batch classifier loss: 0.626297; batch adversarial loss: 0.618178\n",
      "epoch 49; iter: 200; batch classifier loss: 0.348477; batch adversarial loss: 0.600024\n",
      "epoch 0; iter: 0; batch classifier loss: 45.668571; batch adversarial loss: 0.797155\n",
      "epoch 0; iter: 200; batch classifier loss: 11.216939; batch adversarial loss: 0.750622\n",
      "epoch 1; iter: 0; batch classifier loss: 25.805948; batch adversarial loss: 0.752701\n",
      "epoch 1; iter: 200; batch classifier loss: 3.610185; batch adversarial loss: 0.710353\n",
      "epoch 2; iter: 0; batch classifier loss: 3.282161; batch adversarial loss: 0.674727\n",
      "epoch 2; iter: 200; batch classifier loss: 8.653408; batch adversarial loss: 0.682225\n",
      "epoch 3; iter: 0; batch classifier loss: 8.405248; batch adversarial loss: 0.610649\n",
      "epoch 3; iter: 200; batch classifier loss: 0.752740; batch adversarial loss: 0.614165\n",
      "epoch 4; iter: 0; batch classifier loss: 3.382071; batch adversarial loss: 0.655060\n",
      "epoch 4; iter: 200; batch classifier loss: 1.935090; batch adversarial loss: 0.613550\n",
      "epoch 5; iter: 0; batch classifier loss: 2.872869; batch adversarial loss: 0.616055\n",
      "epoch 5; iter: 200; batch classifier loss: 1.428783; batch adversarial loss: 0.636418\n",
      "epoch 6; iter: 0; batch classifier loss: 0.825053; batch adversarial loss: 0.540889\n",
      "epoch 6; iter: 200; batch classifier loss: 0.590354; batch adversarial loss: 0.653276\n",
      "epoch 7; iter: 0; batch classifier loss: 0.742916; batch adversarial loss: 0.644713\n",
      "epoch 7; iter: 200; batch classifier loss: 0.669873; batch adversarial loss: 0.653345\n",
      "epoch 8; iter: 0; batch classifier loss: 0.784836; batch adversarial loss: 0.637621\n",
      "epoch 8; iter: 200; batch classifier loss: 0.667817; batch adversarial loss: 0.673810\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470246; batch adversarial loss: 0.672498\n",
      "epoch 9; iter: 200; batch classifier loss: 0.695394; batch adversarial loss: 0.595170\n",
      "epoch 10; iter: 0; batch classifier loss: 0.441750; batch adversarial loss: 0.629934\n",
      "epoch 10; iter: 200; batch classifier loss: 0.546041; batch adversarial loss: 0.598750\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524491; batch adversarial loss: 0.633080\n",
      "epoch 11; iter: 200; batch classifier loss: 0.565874; batch adversarial loss: 0.588048\n",
      "epoch 12; iter: 0; batch classifier loss: 0.380053; batch adversarial loss: 0.664291\n",
      "epoch 12; iter: 200; batch classifier loss: 0.356626; batch adversarial loss: 0.694034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.440718; batch adversarial loss: 0.618133\n",
      "epoch 13; iter: 200; batch classifier loss: 0.466902; batch adversarial loss: 0.600412\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442602; batch adversarial loss: 0.586753\n",
      "epoch 14; iter: 200; batch classifier loss: 0.414763; batch adversarial loss: 0.640097\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310561; batch adversarial loss: 0.639997\n",
      "epoch 15; iter: 200; batch classifier loss: 0.292452; batch adversarial loss: 0.627086\n",
      "epoch 16; iter: 0; batch classifier loss: 0.417278; batch adversarial loss: 0.586562\n",
      "epoch 16; iter: 200; batch classifier loss: 0.478069; batch adversarial loss: 0.623902\n",
      "epoch 17; iter: 0; batch classifier loss: 0.361489; batch adversarial loss: 0.634327\n",
      "epoch 17; iter: 200; batch classifier loss: 0.414951; batch adversarial loss: 0.596375\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331693; batch adversarial loss: 0.608215\n",
      "epoch 18; iter: 200; batch classifier loss: 0.290922; batch adversarial loss: 0.598213\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382295; batch adversarial loss: 0.602049\n",
      "epoch 19; iter: 200; batch classifier loss: 0.335482; batch adversarial loss: 0.592710\n",
      "epoch 20; iter: 0; batch classifier loss: 0.374263; batch adversarial loss: 0.584838\n",
      "epoch 20; iter: 200; batch classifier loss: 0.337762; batch adversarial loss: 0.656581\n",
      "epoch 21; iter: 0; batch classifier loss: 0.395057; batch adversarial loss: 0.642771\n",
      "epoch 21; iter: 200; batch classifier loss: 0.353305; batch adversarial loss: 0.568921\n",
      "epoch 22; iter: 0; batch classifier loss: 0.297143; batch adversarial loss: 0.618899\n",
      "epoch 22; iter: 200; batch classifier loss: 0.351451; batch adversarial loss: 0.556876\n",
      "epoch 23; iter: 0; batch classifier loss: 0.431680; batch adversarial loss: 0.597519\n",
      "epoch 23; iter: 200; batch classifier loss: 0.358761; batch adversarial loss: 0.593962\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307698; batch adversarial loss: 0.644676\n",
      "epoch 24; iter: 200; batch classifier loss: 0.337343; batch adversarial loss: 0.575282\n",
      "epoch 25; iter: 0; batch classifier loss: 0.423327; batch adversarial loss: 0.529305\n",
      "epoch 25; iter: 200; batch classifier loss: 0.293456; batch adversarial loss: 0.592711\n",
      "epoch 26; iter: 0; batch classifier loss: 0.353995; batch adversarial loss: 0.592190\n",
      "epoch 26; iter: 200; batch classifier loss: 0.387648; batch adversarial loss: 0.626978\n",
      "epoch 27; iter: 0; batch classifier loss: 0.310191; batch adversarial loss: 0.565577\n",
      "epoch 27; iter: 200; batch classifier loss: 0.400163; batch adversarial loss: 0.601615\n",
      "epoch 28; iter: 0; batch classifier loss: 0.384333; batch adversarial loss: 0.596803\n",
      "epoch 28; iter: 200; batch classifier loss: 0.394497; batch adversarial loss: 0.676636\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324375; batch adversarial loss: 0.554794\n",
      "epoch 29; iter: 200; batch classifier loss: 0.358659; batch adversarial loss: 0.656863\n",
      "epoch 30; iter: 0; batch classifier loss: 0.343414; batch adversarial loss: 0.626688\n",
      "epoch 30; iter: 200; batch classifier loss: 0.324192; batch adversarial loss: 0.625150\n",
      "epoch 31; iter: 0; batch classifier loss: 0.260863; batch adversarial loss: 0.592265\n",
      "epoch 31; iter: 200; batch classifier loss: 0.357077; batch adversarial loss: 0.617619\n",
      "epoch 32; iter: 0; batch classifier loss: 0.300695; batch adversarial loss: 0.544043\n",
      "epoch 32; iter: 200; batch classifier loss: 0.414259; batch adversarial loss: 0.590739\n",
      "epoch 33; iter: 0; batch classifier loss: 0.356557; batch adversarial loss: 0.623664\n",
      "epoch 33; iter: 200; batch classifier loss: 0.301795; batch adversarial loss: 0.584867\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390128; batch adversarial loss: 0.597611\n",
      "epoch 34; iter: 200; batch classifier loss: 0.325406; batch adversarial loss: 0.638496\n",
      "epoch 35; iter: 0; batch classifier loss: 0.344742; batch adversarial loss: 0.602642\n",
      "epoch 35; iter: 200; batch classifier loss: 0.329384; batch adversarial loss: 0.566967\n",
      "epoch 36; iter: 0; batch classifier loss: 0.479975; batch adversarial loss: 0.652236\n",
      "epoch 36; iter: 200; batch classifier loss: 0.323103; batch adversarial loss: 0.613600\n",
      "epoch 37; iter: 0; batch classifier loss: 0.322986; batch adversarial loss: 0.594509\n",
      "epoch 37; iter: 200; batch classifier loss: 0.394992; batch adversarial loss: 0.610161\n",
      "epoch 38; iter: 0; batch classifier loss: 0.320119; batch adversarial loss: 0.537787\n",
      "epoch 38; iter: 200; batch classifier loss: 0.314500; batch adversarial loss: 0.607231\n",
      "epoch 39; iter: 0; batch classifier loss: 0.318234; batch adversarial loss: 0.635385\n",
      "epoch 39; iter: 200; batch classifier loss: 0.440755; batch adversarial loss: 0.668605\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411291; batch adversarial loss: 0.687152\n",
      "epoch 40; iter: 200; batch classifier loss: 0.403580; batch adversarial loss: 0.610467\n",
      "epoch 41; iter: 0; batch classifier loss: 0.320125; batch adversarial loss: 0.640074\n",
      "epoch 41; iter: 200; batch classifier loss: 0.312948; batch adversarial loss: 0.641352\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378891; batch adversarial loss: 0.649154\n",
      "epoch 42; iter: 200; batch classifier loss: 0.335640; batch adversarial loss: 0.595355\n",
      "epoch 43; iter: 0; batch classifier loss: 0.372293; batch adversarial loss: 0.652398\n",
      "epoch 43; iter: 200; batch classifier loss: 0.377567; batch adversarial loss: 0.562999\n",
      "epoch 44; iter: 0; batch classifier loss: 0.458040; batch adversarial loss: 0.612157\n",
      "epoch 44; iter: 200; batch classifier loss: 0.337565; batch adversarial loss: 0.621022\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458971; batch adversarial loss: 0.618248\n",
      "epoch 45; iter: 200; batch classifier loss: 0.354273; batch adversarial loss: 0.653200\n",
      "epoch 46; iter: 0; batch classifier loss: 0.363024; batch adversarial loss: 0.629655\n",
      "epoch 46; iter: 200; batch classifier loss: 0.470328; batch adversarial loss: 0.579782\n",
      "epoch 47; iter: 0; batch classifier loss: 0.300109; batch adversarial loss: 0.632472\n",
      "epoch 47; iter: 200; batch classifier loss: 0.272921; batch adversarial loss: 0.644139\n",
      "epoch 48; iter: 0; batch classifier loss: 0.362617; batch adversarial loss: 0.600023\n",
      "epoch 48; iter: 200; batch classifier loss: 0.340153; batch adversarial loss: 0.639106\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390771; batch adversarial loss: 0.626128\n",
      "epoch 49; iter: 200; batch classifier loss: 0.332596; batch adversarial loss: 0.669065\n",
      "epoch 0; iter: 0; batch classifier loss: 6.034610; batch adversarial loss: 0.702524\n",
      "epoch 0; iter: 200; batch classifier loss: 7.040916; batch adversarial loss: 0.664197\n",
      "epoch 1; iter: 0; batch classifier loss: 4.417579; batch adversarial loss: 0.642307\n",
      "epoch 1; iter: 200; batch classifier loss: 8.898146; batch adversarial loss: 0.620335\n",
      "epoch 2; iter: 0; batch classifier loss: 8.217255; batch adversarial loss: 0.661771\n",
      "epoch 2; iter: 200; batch classifier loss: 2.075399; batch adversarial loss: 0.610059\n",
      "epoch 3; iter: 0; batch classifier loss: 11.551323; batch adversarial loss: 0.596368\n",
      "epoch 3; iter: 200; batch classifier loss: 4.074569; batch adversarial loss: 0.608817\n",
      "epoch 4; iter: 0; batch classifier loss: 0.754265; batch adversarial loss: 0.616806\n",
      "epoch 4; iter: 200; batch classifier loss: 2.394451; batch adversarial loss: 0.628748\n",
      "epoch 5; iter: 0; batch classifier loss: 1.369578; batch adversarial loss: 0.658916\n",
      "epoch 5; iter: 200; batch classifier loss: 1.083203; batch adversarial loss: 0.698677\n",
      "epoch 6; iter: 0; batch classifier loss: 5.758257; batch adversarial loss: 0.659124\n",
      "epoch 6; iter: 200; batch classifier loss: 1.527354; batch adversarial loss: 0.568186\n",
      "epoch 7; iter: 0; batch classifier loss: 0.588384; batch adversarial loss: 0.590189\n",
      "epoch 7; iter: 200; batch classifier loss: 0.578191; batch adversarial loss: 0.650639\n",
      "epoch 8; iter: 0; batch classifier loss: 0.666193; batch adversarial loss: 0.623019\n",
      "epoch 8; iter: 200; batch classifier loss: 0.456687; batch adversarial loss: 0.637569\n",
      "epoch 9; iter: 0; batch classifier loss: 1.317822; batch adversarial loss: 0.663048\n",
      "epoch 9; iter: 200; batch classifier loss: 0.628345; batch adversarial loss: 0.648120\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443186; batch adversarial loss: 0.641827\n",
      "epoch 10; iter: 200; batch classifier loss: 0.426362; batch adversarial loss: 0.645381\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555354; batch adversarial loss: 0.636773\n",
      "epoch 11; iter: 200; batch classifier loss: 0.436841; batch adversarial loss: 0.674845\n",
      "epoch 12; iter: 0; batch classifier loss: 0.597478; batch adversarial loss: 0.624982\n",
      "epoch 12; iter: 200; batch classifier loss: 0.384718; batch adversarial loss: 0.580866\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381511; batch adversarial loss: 0.589542\n",
      "epoch 13; iter: 200; batch classifier loss: 0.371941; batch adversarial loss: 0.614321\n",
      "epoch 14; iter: 0; batch classifier loss: 0.377852; batch adversarial loss: 0.614030\n",
      "epoch 14; iter: 200; batch classifier loss: 0.315345; batch adversarial loss: 0.640683\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334755; batch adversarial loss: 0.608844\n",
      "epoch 15; iter: 200; batch classifier loss: 0.306749; batch adversarial loss: 0.612937\n",
      "epoch 16; iter: 0; batch classifier loss: 0.351992; batch adversarial loss: 0.658554\n",
      "epoch 16; iter: 200; batch classifier loss: 0.293654; batch adversarial loss: 0.629596\n",
      "epoch 17; iter: 0; batch classifier loss: 0.334449; batch adversarial loss: 0.626604\n",
      "epoch 17; iter: 200; batch classifier loss: 0.316658; batch adversarial loss: 0.596341\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387773; batch adversarial loss: 0.571251\n",
      "epoch 18; iter: 200; batch classifier loss: 0.360680; batch adversarial loss: 0.629000\n",
      "epoch 19; iter: 0; batch classifier loss: 0.413081; batch adversarial loss: 0.568313\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376858; batch adversarial loss: 0.582993\n",
      "epoch 20; iter: 0; batch classifier loss: 0.592265; batch adversarial loss: 0.652768\n",
      "epoch 20; iter: 200; batch classifier loss: 0.339292; batch adversarial loss: 0.643736\n",
      "epoch 21; iter: 0; batch classifier loss: 0.378668; batch adversarial loss: 0.642099\n",
      "epoch 21; iter: 200; batch classifier loss: 0.403242; batch adversarial loss: 0.627385\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372365; batch adversarial loss: 0.640196\n",
      "epoch 22; iter: 200; batch classifier loss: 0.334640; batch adversarial loss: 0.622328\n",
      "epoch 23; iter: 0; batch classifier loss: 0.279426; batch adversarial loss: 0.603037\n",
      "epoch 23; iter: 200; batch classifier loss: 0.372282; batch adversarial loss: 0.582729\n",
      "epoch 24; iter: 0; batch classifier loss: 0.363128; batch adversarial loss: 0.617027\n",
      "epoch 24; iter: 200; batch classifier loss: 0.340137; batch adversarial loss: 0.631028\n",
      "epoch 25; iter: 0; batch classifier loss: 0.323389; batch adversarial loss: 0.596179\n",
      "epoch 25; iter: 200; batch classifier loss: 0.392075; batch adversarial loss: 0.614084\n",
      "epoch 26; iter: 0; batch classifier loss: 0.386209; batch adversarial loss: 0.568949\n",
      "epoch 26; iter: 200; batch classifier loss: 0.379019; batch adversarial loss: 0.584842\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325086; batch adversarial loss: 0.638899\n",
      "epoch 27; iter: 200; batch classifier loss: 0.367090; batch adversarial loss: 0.559782\n",
      "epoch 28; iter: 0; batch classifier loss: 0.576566; batch adversarial loss: 0.653803\n",
      "epoch 28; iter: 200; batch classifier loss: 0.406476; batch adversarial loss: 0.583961\n",
      "epoch 29; iter: 0; batch classifier loss: 0.314521; batch adversarial loss: 0.549794\n",
      "epoch 29; iter: 200; batch classifier loss: 0.328145; batch adversarial loss: 0.633810\n",
      "epoch 30; iter: 0; batch classifier loss: 0.412602; batch adversarial loss: 0.586929\n",
      "epoch 30; iter: 200; batch classifier loss: 0.308611; batch adversarial loss: 0.621498\n",
      "epoch 31; iter: 0; batch classifier loss: 0.277412; batch adversarial loss: 0.603789\n",
      "epoch 31; iter: 200; batch classifier loss: 0.380246; batch adversarial loss: 0.602604\n",
      "epoch 32; iter: 0; batch classifier loss: 0.289782; batch adversarial loss: 0.635477\n",
      "epoch 32; iter: 200; batch classifier loss: 0.335103; batch adversarial loss: 0.612985\n",
      "epoch 33; iter: 0; batch classifier loss: 0.265550; batch adversarial loss: 0.614752\n",
      "epoch 33; iter: 200; batch classifier loss: 0.302452; batch adversarial loss: 0.594356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.348461; batch adversarial loss: 0.643708\n",
      "epoch 34; iter: 200; batch classifier loss: 0.273653; batch adversarial loss: 0.549763\n",
      "epoch 35; iter: 0; batch classifier loss: 0.368429; batch adversarial loss: 0.665802\n",
      "epoch 35; iter: 200; batch classifier loss: 0.362580; batch adversarial loss: 0.591581\n",
      "epoch 36; iter: 0; batch classifier loss: 0.314373; batch adversarial loss: 0.648351\n",
      "epoch 36; iter: 200; batch classifier loss: 0.342124; batch adversarial loss: 0.622035\n",
      "epoch 37; iter: 0; batch classifier loss: 0.338520; batch adversarial loss: 0.592154\n",
      "epoch 37; iter: 200; batch classifier loss: 0.382147; batch adversarial loss: 0.649286\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409022; batch adversarial loss: 0.622731\n",
      "epoch 38; iter: 200; batch classifier loss: 0.392902; batch adversarial loss: 0.663896\n",
      "epoch 39; iter: 0; batch classifier loss: 0.348011; batch adversarial loss: 0.593475\n",
      "epoch 39; iter: 200; batch classifier loss: 0.331333; batch adversarial loss: 0.652839\n",
      "epoch 40; iter: 0; batch classifier loss: 0.314930; batch adversarial loss: 0.594645\n",
      "epoch 40; iter: 200; batch classifier loss: 0.347517; batch adversarial loss: 0.622797\n",
      "epoch 41; iter: 0; batch classifier loss: 0.317659; batch adversarial loss: 0.589356\n",
      "epoch 41; iter: 200; batch classifier loss: 0.409027; batch adversarial loss: 0.576720\n",
      "epoch 42; iter: 0; batch classifier loss: 0.309333; batch adversarial loss: 0.638426\n",
      "epoch 42; iter: 200; batch classifier loss: 0.348611; batch adversarial loss: 0.652543\n",
      "epoch 43; iter: 0; batch classifier loss: 0.353882; batch adversarial loss: 0.626133\n",
      "epoch 43; iter: 200; batch classifier loss: 0.341274; batch adversarial loss: 0.582345\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358133; batch adversarial loss: 0.652696\n",
      "epoch 44; iter: 200; batch classifier loss: 0.389582; batch adversarial loss: 0.601638\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373248; batch adversarial loss: 0.591978\n",
      "epoch 45; iter: 200; batch classifier loss: 0.387753; batch adversarial loss: 0.633694\n",
      "epoch 46; iter: 0; batch classifier loss: 0.295120; batch adversarial loss: 0.626335\n",
      "epoch 46; iter: 200; batch classifier loss: 0.294912; batch adversarial loss: 0.598646\n",
      "epoch 47; iter: 0; batch classifier loss: 0.390352; batch adversarial loss: 0.650222\n",
      "epoch 47; iter: 200; batch classifier loss: 0.449364; batch adversarial loss: 0.603177\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481696; batch adversarial loss: 0.628709\n",
      "epoch 48; iter: 200; batch classifier loss: 0.356263; batch adversarial loss: 0.644516\n",
      "epoch 49; iter: 0; batch classifier loss: 0.323812; batch adversarial loss: 0.640434\n",
      "epoch 49; iter: 200; batch classifier loss: 0.374018; batch adversarial loss: 0.609470\n",
      "epoch 0; iter: 0; batch classifier loss: 8.853869; batch adversarial loss: 0.780458\n",
      "epoch 0; iter: 200; batch classifier loss: 13.317039; batch adversarial loss: 0.680423\n",
      "epoch 1; iter: 0; batch classifier loss: 1.640455; batch adversarial loss: 0.673288\n",
      "epoch 1; iter: 200; batch classifier loss: 5.696013; batch adversarial loss: 0.623804\n",
      "epoch 2; iter: 0; batch classifier loss: 2.720170; batch adversarial loss: 0.630187\n",
      "epoch 2; iter: 200; batch classifier loss: 3.775700; batch adversarial loss: 0.644837\n",
      "epoch 3; iter: 0; batch classifier loss: 5.948210; batch adversarial loss: 0.633734\n",
      "epoch 3; iter: 200; batch classifier loss: 3.756555; batch adversarial loss: 0.620198\n",
      "epoch 4; iter: 0; batch classifier loss: 4.082039; batch adversarial loss: 0.641025\n",
      "epoch 4; iter: 200; batch classifier loss: 3.507489; batch adversarial loss: 0.649032\n",
      "epoch 5; iter: 0; batch classifier loss: 2.114785; batch adversarial loss: 0.662296\n",
      "epoch 5; iter: 200; batch classifier loss: 0.915633; batch adversarial loss: 0.598478\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582745; batch adversarial loss: 0.667025\n",
      "epoch 6; iter: 200; batch classifier loss: 1.029826; batch adversarial loss: 0.667819\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595835; batch adversarial loss: 0.619545\n",
      "epoch 7; iter: 200; batch classifier loss: 0.635712; batch adversarial loss: 0.637164\n",
      "epoch 8; iter: 0; batch classifier loss: 0.856976; batch adversarial loss: 0.639242\n",
      "epoch 8; iter: 200; batch classifier loss: 0.504986; batch adversarial loss: 0.578094\n",
      "epoch 9; iter: 0; batch classifier loss: 0.428775; batch adversarial loss: 0.659679\n",
      "epoch 9; iter: 200; batch classifier loss: 0.464833; batch adversarial loss: 0.659275\n",
      "epoch 10; iter: 0; batch classifier loss: 0.383536; batch adversarial loss: 0.609224\n",
      "epoch 10; iter: 200; batch classifier loss: 0.451005; batch adversarial loss: 0.615377\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407024; batch adversarial loss: 0.620947\n",
      "epoch 11; iter: 200; batch classifier loss: 0.360747; batch adversarial loss: 0.616484\n",
      "epoch 12; iter: 0; batch classifier loss: 0.320714; batch adversarial loss: 0.640048\n",
      "epoch 12; iter: 200; batch classifier loss: 0.314451; batch adversarial loss: 0.610379\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494728; batch adversarial loss: 0.625354\n",
      "epoch 13; iter: 200; batch classifier loss: 0.452333; batch adversarial loss: 0.601240\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390447; batch adversarial loss: 0.617023\n",
      "epoch 14; iter: 200; batch classifier loss: 0.335422; batch adversarial loss: 0.634889\n",
      "epoch 15; iter: 0; batch classifier loss: 0.354318; batch adversarial loss: 0.588304\n",
      "epoch 15; iter: 200; batch classifier loss: 0.299857; batch adversarial loss: 0.608331\n",
      "epoch 16; iter: 0; batch classifier loss: 0.421455; batch adversarial loss: 0.610735\n",
      "epoch 16; iter: 200; batch classifier loss: 0.427803; batch adversarial loss: 0.643805\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373816; batch adversarial loss: 0.575916\n",
      "epoch 17; iter: 200; batch classifier loss: 0.350432; batch adversarial loss: 0.638770\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359821; batch adversarial loss: 0.676472\n",
      "epoch 18; iter: 200; batch classifier loss: 0.437650; batch adversarial loss: 0.681077\n",
      "epoch 19; iter: 0; batch classifier loss: 0.293488; batch adversarial loss: 0.589445\n",
      "epoch 19; iter: 200; batch classifier loss: 0.373111; batch adversarial loss: 0.634580\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447642; batch adversarial loss: 0.612745\n",
      "epoch 20; iter: 200; batch classifier loss: 0.405767; batch adversarial loss: 0.618225\n",
      "epoch 21; iter: 0; batch classifier loss: 0.380129; batch adversarial loss: 0.600501\n",
      "epoch 21; iter: 200; batch classifier loss: 0.361494; batch adversarial loss: 0.607424\n",
      "epoch 22; iter: 0; batch classifier loss: 0.287748; batch adversarial loss: 0.586262\n",
      "epoch 22; iter: 200; batch classifier loss: 0.434332; batch adversarial loss: 0.586160\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379839; batch adversarial loss: 0.667972\n",
      "epoch 23; iter: 200; batch classifier loss: 0.369526; batch adversarial loss: 0.658869\n",
      "epoch 24; iter: 0; batch classifier loss: 0.339842; batch adversarial loss: 0.612689\n",
      "epoch 24; iter: 200; batch classifier loss: 0.307284; batch adversarial loss: 0.581860\n",
      "epoch 25; iter: 0; batch classifier loss: 0.366379; batch adversarial loss: 0.618653\n",
      "epoch 25; iter: 200; batch classifier loss: 0.307133; batch adversarial loss: 0.597621\n",
      "epoch 26; iter: 0; batch classifier loss: 0.369252; batch adversarial loss: 0.604583\n",
      "epoch 26; iter: 200; batch classifier loss: 0.550111; batch adversarial loss: 0.644252\n",
      "epoch 27; iter: 0; batch classifier loss: 0.407846; batch adversarial loss: 0.619403\n",
      "epoch 27; iter: 200; batch classifier loss: 0.364348; batch adversarial loss: 0.647073\n",
      "epoch 28; iter: 0; batch classifier loss: 0.309592; batch adversarial loss: 0.616467\n",
      "epoch 28; iter: 200; batch classifier loss: 0.389639; batch adversarial loss: 0.613382\n",
      "epoch 29; iter: 0; batch classifier loss: 0.300046; batch adversarial loss: 0.675644\n",
      "epoch 29; iter: 200; batch classifier loss: 0.349748; batch adversarial loss: 0.621525\n",
      "epoch 30; iter: 0; batch classifier loss: 0.366729; batch adversarial loss: 0.656619\n",
      "epoch 30; iter: 200; batch classifier loss: 0.447061; batch adversarial loss: 0.609016\n",
      "epoch 31; iter: 0; batch classifier loss: 0.329900; batch adversarial loss: 0.597711\n",
      "epoch 31; iter: 200; batch classifier loss: 0.426592; batch adversarial loss: 0.669329\n",
      "epoch 32; iter: 0; batch classifier loss: 0.530833; batch adversarial loss: 0.611014\n",
      "epoch 32; iter: 200; batch classifier loss: 0.351421; batch adversarial loss: 0.663655\n",
      "epoch 33; iter: 0; batch classifier loss: 0.258002; batch adversarial loss: 0.605895\n",
      "epoch 33; iter: 200; batch classifier loss: 0.339431; batch adversarial loss: 0.665793\n",
      "epoch 34; iter: 0; batch classifier loss: 0.334564; batch adversarial loss: 0.572288\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338998; batch adversarial loss: 0.602493\n",
      "epoch 35; iter: 0; batch classifier loss: 0.300650; batch adversarial loss: 0.577108\n",
      "epoch 35; iter: 200; batch classifier loss: 0.397768; batch adversarial loss: 0.671054\n",
      "epoch 36; iter: 0; batch classifier loss: 0.297118; batch adversarial loss: 0.615136\n",
      "epoch 36; iter: 200; batch classifier loss: 0.430898; batch adversarial loss: 0.574457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.345297; batch adversarial loss: 0.662922\n",
      "epoch 37; iter: 200; batch classifier loss: 0.354720; batch adversarial loss: 0.636355\n",
      "epoch 38; iter: 0; batch classifier loss: 0.375189; batch adversarial loss: 0.614826\n",
      "epoch 38; iter: 200; batch classifier loss: 0.355920; batch adversarial loss: 0.637024\n",
      "epoch 39; iter: 0; batch classifier loss: 0.302120; batch adversarial loss: 0.619628\n",
      "epoch 39; iter: 200; batch classifier loss: 0.184680; batch adversarial loss: 0.683842\n",
      "epoch 40; iter: 0; batch classifier loss: 0.331700; batch adversarial loss: 0.626882\n",
      "epoch 40; iter: 200; batch classifier loss: 0.377516; batch adversarial loss: 0.638817\n",
      "epoch 41; iter: 0; batch classifier loss: 0.423750; batch adversarial loss: 0.564941\n",
      "epoch 41; iter: 200; batch classifier loss: 0.296130; batch adversarial loss: 0.590132\n",
      "epoch 42; iter: 0; batch classifier loss: 0.370747; batch adversarial loss: 0.604833\n",
      "epoch 42; iter: 200; batch classifier loss: 0.331183; batch adversarial loss: 0.597797\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401472; batch adversarial loss: 0.660559\n",
      "epoch 43; iter: 200; batch classifier loss: 0.467411; batch adversarial loss: 0.586560\n",
      "epoch 44; iter: 0; batch classifier loss: 0.324318; batch adversarial loss: 0.578856\n",
      "epoch 44; iter: 200; batch classifier loss: 0.384633; batch adversarial loss: 0.649253\n",
      "epoch 45; iter: 0; batch classifier loss: 0.294084; batch adversarial loss: 0.632471\n",
      "epoch 45; iter: 200; batch classifier loss: 0.395230; batch adversarial loss: 0.652119\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371528; batch adversarial loss: 0.686667\n",
      "epoch 46; iter: 200; batch classifier loss: 0.409640; batch adversarial loss: 0.605786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.270768; batch adversarial loss: 0.665796\n",
      "epoch 47; iter: 200; batch classifier loss: 0.424418; batch adversarial loss: 0.670443\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386385; batch adversarial loss: 0.629010\n",
      "epoch 48; iter: 200; batch classifier loss: 0.413998; batch adversarial loss: 0.601582\n",
      "epoch 49; iter: 0; batch classifier loss: 0.345018; batch adversarial loss: 0.631324\n",
      "epoch 49; iter: 200; batch classifier loss: 0.369252; batch adversarial loss: 0.625571\n",
      "epoch 0; iter: 0; batch classifier loss: 22.128653; batch adversarial loss: 0.850073\n",
      "epoch 0; iter: 200; batch classifier loss: 5.123835; batch adversarial loss: 0.725081\n",
      "epoch 1; iter: 0; batch classifier loss: 9.951148; batch adversarial loss: 0.699892\n",
      "epoch 1; iter: 200; batch classifier loss: 34.568371; batch adversarial loss: 0.662636\n",
      "epoch 2; iter: 0; batch classifier loss: 26.988659; batch adversarial loss: 0.666186\n",
      "epoch 2; iter: 200; batch classifier loss: 4.724097; batch adversarial loss: 0.624382\n",
      "epoch 3; iter: 0; batch classifier loss: 1.438948; batch adversarial loss: 0.635313\n",
      "epoch 3; iter: 200; batch classifier loss: 4.209723; batch adversarial loss: 0.603008\n",
      "epoch 4; iter: 0; batch classifier loss: 1.761887; batch adversarial loss: 0.654553\n",
      "epoch 4; iter: 200; batch classifier loss: 1.635648; batch adversarial loss: 0.599212\n",
      "epoch 5; iter: 0; batch classifier loss: 3.423108; batch adversarial loss: 0.659448\n",
      "epoch 5; iter: 200; batch classifier loss: 0.525848; batch adversarial loss: 0.663540\n",
      "epoch 6; iter: 0; batch classifier loss: 1.167136; batch adversarial loss: 0.614219\n",
      "epoch 6; iter: 200; batch classifier loss: 0.750781; batch adversarial loss: 0.650749\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493886; batch adversarial loss: 0.647765\n",
      "epoch 7; iter: 200; batch classifier loss: 0.520577; batch adversarial loss: 0.566758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.418912; batch adversarial loss: 0.652262\n",
      "epoch 8; iter: 200; batch classifier loss: 0.411917; batch adversarial loss: 0.581603\n",
      "epoch 9; iter: 0; batch classifier loss: 0.477911; batch adversarial loss: 0.605347\n",
      "epoch 9; iter: 200; batch classifier loss: 0.848491; batch adversarial loss: 0.591252\n",
      "epoch 10; iter: 0; batch classifier loss: 0.981226; batch adversarial loss: 0.663640\n",
      "epoch 10; iter: 200; batch classifier loss: 0.356754; batch adversarial loss: 0.673486\n",
      "epoch 11; iter: 0; batch classifier loss: 0.395671; batch adversarial loss: 0.588714\n",
      "epoch 11; iter: 200; batch classifier loss: 0.414472; batch adversarial loss: 0.588550\n",
      "epoch 12; iter: 0; batch classifier loss: 0.416402; batch adversarial loss: 0.659708\n",
      "epoch 12; iter: 200; batch classifier loss: 0.405874; batch adversarial loss: 0.581281\n",
      "epoch 13; iter: 0; batch classifier loss: 0.401517; batch adversarial loss: 0.554065\n",
      "epoch 13; iter: 200; batch classifier loss: 0.389897; batch adversarial loss: 0.661169\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331396; batch adversarial loss: 0.613316\n",
      "epoch 14; iter: 200; batch classifier loss: 0.496903; batch adversarial loss: 0.615105\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318024; batch adversarial loss: 0.641083\n",
      "epoch 15; iter: 200; batch classifier loss: 0.347014; batch adversarial loss: 0.636382\n",
      "epoch 16; iter: 0; batch classifier loss: 0.574947; batch adversarial loss: 0.636724\n",
      "epoch 16; iter: 200; batch classifier loss: 0.354421; batch adversarial loss: 0.648959\n",
      "epoch 17; iter: 0; batch classifier loss: 0.369139; batch adversarial loss: 0.595371\n",
      "epoch 17; iter: 200; batch classifier loss: 0.329149; batch adversarial loss: 0.581707\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471856; batch adversarial loss: 0.564848\n",
      "epoch 18; iter: 200; batch classifier loss: 0.347313; batch adversarial loss: 0.608720\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501765; batch adversarial loss: 0.643368\n",
      "epoch 19; iter: 200; batch classifier loss: 0.331350; batch adversarial loss: 0.625931\n",
      "epoch 20; iter: 0; batch classifier loss: 0.314470; batch adversarial loss: 0.630326\n",
      "epoch 20; iter: 200; batch classifier loss: 0.340012; batch adversarial loss: 0.578507\n",
      "epoch 21; iter: 0; batch classifier loss: 0.357087; batch adversarial loss: 0.588633\n",
      "epoch 21; iter: 200; batch classifier loss: 0.352000; batch adversarial loss: 0.652592\n",
      "epoch 22; iter: 0; batch classifier loss: 0.293048; batch adversarial loss: 0.579649\n",
      "epoch 22; iter: 200; batch classifier loss: 0.420818; batch adversarial loss: 0.590653\n",
      "epoch 23; iter: 0; batch classifier loss: 0.312665; batch adversarial loss: 0.596822\n",
      "epoch 23; iter: 200; batch classifier loss: 0.287774; batch adversarial loss: 0.626816\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452176; batch adversarial loss: 0.611822\n",
      "epoch 24; iter: 200; batch classifier loss: 0.322209; batch adversarial loss: 0.655374\n",
      "epoch 25; iter: 0; batch classifier loss: 0.346641; batch adversarial loss: 0.614491\n",
      "epoch 25; iter: 200; batch classifier loss: 0.398010; batch adversarial loss: 0.596566\n",
      "epoch 26; iter: 0; batch classifier loss: 0.336140; batch adversarial loss: 0.625426\n",
      "epoch 26; iter: 200; batch classifier loss: 0.399452; batch adversarial loss: 0.588403\n",
      "epoch 27; iter: 0; batch classifier loss: 0.317643; batch adversarial loss: 0.632554\n",
      "epoch 27; iter: 200; batch classifier loss: 0.317114; batch adversarial loss: 0.613967\n",
      "epoch 28; iter: 0; batch classifier loss: 0.326220; batch adversarial loss: 0.686317\n",
      "epoch 28; iter: 200; batch classifier loss: 0.374774; batch adversarial loss: 0.632892\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386752; batch adversarial loss: 0.641537\n",
      "epoch 29; iter: 200; batch classifier loss: 0.335489; batch adversarial loss: 0.635189\n",
      "epoch 30; iter: 0; batch classifier loss: 0.341366; batch adversarial loss: 0.649822\n",
      "epoch 30; iter: 200; batch classifier loss: 0.306381; batch adversarial loss: 0.636900\n",
      "epoch 31; iter: 0; batch classifier loss: 0.296985; batch adversarial loss: 0.656911\n",
      "epoch 31; iter: 200; batch classifier loss: 0.487736; batch adversarial loss: 0.622307\n",
      "epoch 32; iter: 0; batch classifier loss: 0.312956; batch adversarial loss: 0.611737\n",
      "epoch 32; iter: 200; batch classifier loss: 0.275950; batch adversarial loss: 0.617393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.402543; batch adversarial loss: 0.597617\n",
      "epoch 33; iter: 200; batch classifier loss: 0.358015; batch adversarial loss: 0.579599\n",
      "epoch 34; iter: 0; batch classifier loss: 0.343469; batch adversarial loss: 0.638464\n",
      "epoch 34; iter: 200; batch classifier loss: 0.314129; batch adversarial loss: 0.640961\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372664; batch adversarial loss: 0.568898\n",
      "epoch 35; iter: 200; batch classifier loss: 0.366541; batch adversarial loss: 0.598646\n",
      "epoch 36; iter: 0; batch classifier loss: 0.328477; batch adversarial loss: 0.606204\n",
      "epoch 36; iter: 200; batch classifier loss: 0.267860; batch adversarial loss: 0.646723\n",
      "epoch 37; iter: 0; batch classifier loss: 0.469576; batch adversarial loss: 0.621174\n",
      "epoch 37; iter: 200; batch classifier loss: 0.238466; batch adversarial loss: 0.689146\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386195; batch adversarial loss: 0.646285\n",
      "epoch 38; iter: 200; batch classifier loss: 0.307513; batch adversarial loss: 0.548395\n",
      "epoch 39; iter: 0; batch classifier loss: 0.341590; batch adversarial loss: 0.595654\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349519; batch adversarial loss: 0.601020\n",
      "epoch 40; iter: 0; batch classifier loss: 0.363900; batch adversarial loss: 0.650589\n",
      "epoch 40; iter: 200; batch classifier loss: 0.337367; batch adversarial loss: 0.625974\n",
      "epoch 41; iter: 0; batch classifier loss: 0.275610; batch adversarial loss: 0.621770\n",
      "epoch 41; iter: 200; batch classifier loss: 0.257218; batch adversarial loss: 0.654644\n",
      "epoch 42; iter: 0; batch classifier loss: 0.350711; batch adversarial loss: 0.568240\n",
      "epoch 42; iter: 200; batch classifier loss: 0.267766; batch adversarial loss: 0.664095\n",
      "epoch 43; iter: 0; batch classifier loss: 0.323764; batch adversarial loss: 0.645244\n",
      "epoch 43; iter: 200; batch classifier loss: 0.368308; batch adversarial loss: 0.582180\n",
      "epoch 44; iter: 0; batch classifier loss: 0.350165; batch adversarial loss: 0.620369\n",
      "epoch 44; iter: 200; batch classifier loss: 0.586595; batch adversarial loss: 0.593818\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382358; batch adversarial loss: 0.596922\n",
      "epoch 45; iter: 200; batch classifier loss: 0.464256; batch adversarial loss: 0.645535\n",
      "epoch 46; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.638108\n",
      "epoch 46; iter: 200; batch classifier loss: 0.452866; batch adversarial loss: 0.614712\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420790; batch adversarial loss: 0.642589\n",
      "epoch 47; iter: 200; batch classifier loss: 0.363461; batch adversarial loss: 0.560003\n",
      "epoch 48; iter: 0; batch classifier loss: 0.395944; batch adversarial loss: 0.593752\n",
      "epoch 48; iter: 200; batch classifier loss: 0.287440; batch adversarial loss: 0.639154\n",
      "epoch 49; iter: 0; batch classifier loss: 0.370348; batch adversarial loss: 0.644696\n",
      "epoch 49; iter: 200; batch classifier loss: 0.332732; batch adversarial loss: 0.594231\n",
      "epoch 0; iter: 0; batch classifier loss: 7.363085; batch adversarial loss: 0.737133\n",
      "epoch 0; iter: 200; batch classifier loss: 4.306316; batch adversarial loss: 0.673500\n",
      "epoch 1; iter: 0; batch classifier loss: 43.486374; batch adversarial loss: 0.626860\n",
      "epoch 1; iter: 200; batch classifier loss: 5.631352; batch adversarial loss: 0.615205\n",
      "epoch 2; iter: 0; batch classifier loss: 6.299661; batch adversarial loss: 0.668754\n",
      "epoch 2; iter: 200; batch classifier loss: 2.578898; batch adversarial loss: 0.619627\n",
      "epoch 3; iter: 0; batch classifier loss: 4.041401; batch adversarial loss: 0.608424\n",
      "epoch 3; iter: 200; batch classifier loss: 4.772581; batch adversarial loss: 0.566193\n",
      "epoch 4; iter: 0; batch classifier loss: 0.717219; batch adversarial loss: 0.650685\n",
      "epoch 4; iter: 200; batch classifier loss: 2.586345; batch adversarial loss: 0.629479\n",
      "epoch 5; iter: 0; batch classifier loss: 4.187283; batch adversarial loss: 0.663877\n",
      "epoch 5; iter: 200; batch classifier loss: 1.595342; batch adversarial loss: 0.576850\n",
      "epoch 6; iter: 0; batch classifier loss: 2.111250; batch adversarial loss: 0.625511\n",
      "epoch 6; iter: 200; batch classifier loss: 1.840671; batch adversarial loss: 0.631766\n",
      "epoch 7; iter: 0; batch classifier loss: 0.622796; batch adversarial loss: 0.592878\n",
      "epoch 7; iter: 200; batch classifier loss: 0.895326; batch adversarial loss: 0.629281\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438167; batch adversarial loss: 0.638689\n",
      "epoch 8; iter: 200; batch classifier loss: 0.460573; batch adversarial loss: 0.634868\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575715; batch adversarial loss: 0.580109\n",
      "epoch 9; iter: 200; batch classifier loss: 0.474382; batch adversarial loss: 0.639009\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572302; batch adversarial loss: 0.639296\n",
      "epoch 10; iter: 200; batch classifier loss: 0.383641; batch adversarial loss: 0.624399\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448333; batch adversarial loss: 0.617607\n",
      "epoch 11; iter: 200; batch classifier loss: 0.440007; batch adversarial loss: 0.588657\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463601; batch adversarial loss: 0.622689\n",
      "epoch 12; iter: 200; batch classifier loss: 0.334492; batch adversarial loss: 0.614468\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330542; batch adversarial loss: 0.639328\n",
      "epoch 13; iter: 200; batch classifier loss: 0.388133; batch adversarial loss: 0.688812\n",
      "epoch 14; iter: 0; batch classifier loss: 0.346151; batch adversarial loss: 0.646118\n",
      "epoch 14; iter: 200; batch classifier loss: 0.330710; batch adversarial loss: 0.576728\n",
      "epoch 15; iter: 0; batch classifier loss: 0.308544; batch adversarial loss: 0.681354\n",
      "epoch 15; iter: 200; batch classifier loss: 0.406309; batch adversarial loss: 0.633967\n",
      "epoch 16; iter: 0; batch classifier loss: 0.274277; batch adversarial loss: 0.607131\n",
      "epoch 16; iter: 200; batch classifier loss: 0.327579; batch adversarial loss: 0.617474\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310835; batch adversarial loss: 0.659116\n",
      "epoch 17; iter: 200; batch classifier loss: 0.368128; batch adversarial loss: 0.563604\n",
      "epoch 18; iter: 0; batch classifier loss: 0.321568; batch adversarial loss: 0.599663\n",
      "epoch 18; iter: 200; batch classifier loss: 0.398182; batch adversarial loss: 0.634079\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378445; batch adversarial loss: 0.594162\n",
      "epoch 19; iter: 200; batch classifier loss: 0.328568; batch adversarial loss: 0.631127\n",
      "epoch 20; iter: 0; batch classifier loss: 0.377928; batch adversarial loss: 0.632558\n",
      "epoch 20; iter: 200; batch classifier loss: 0.341693; batch adversarial loss: 0.539530\n",
      "epoch 21; iter: 0; batch classifier loss: 0.294789; batch adversarial loss: 0.673972\n",
      "epoch 21; iter: 200; batch classifier loss: 0.468443; batch adversarial loss: 0.628478\n",
      "epoch 22; iter: 0; batch classifier loss: 0.319029; batch adversarial loss: 0.648855\n",
      "epoch 22; iter: 200; batch classifier loss: 0.302462; batch adversarial loss: 0.632801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426387; batch adversarial loss: 0.622253\n",
      "epoch 23; iter: 200; batch classifier loss: 0.392531; batch adversarial loss: 0.645226\n",
      "epoch 24; iter: 0; batch classifier loss: 0.377232; batch adversarial loss: 0.641244\n",
      "epoch 24; iter: 200; batch classifier loss: 0.284167; batch adversarial loss: 0.671986\n",
      "epoch 25; iter: 0; batch classifier loss: 0.578062; batch adversarial loss: 0.603688\n",
      "epoch 25; iter: 200; batch classifier loss: 0.406263; batch adversarial loss: 0.615653\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366282; batch adversarial loss: 0.612662\n",
      "epoch 26; iter: 200; batch classifier loss: 0.333167; batch adversarial loss: 0.612331\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461943; batch adversarial loss: 0.635154\n",
      "epoch 27; iter: 200; batch classifier loss: 0.392808; batch adversarial loss: 0.615569\n",
      "epoch 28; iter: 0; batch classifier loss: 0.310364; batch adversarial loss: 0.654082\n",
      "epoch 28; iter: 200; batch classifier loss: 0.327930; batch adversarial loss: 0.597200\n",
      "epoch 29; iter: 0; batch classifier loss: 0.375744; batch adversarial loss: 0.603027\n",
      "epoch 29; iter: 200; batch classifier loss: 0.380634; batch adversarial loss: 0.595557\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390525; batch adversarial loss: 0.626962\n",
      "epoch 30; iter: 200; batch classifier loss: 0.494419; batch adversarial loss: 0.603330\n",
      "epoch 31; iter: 0; batch classifier loss: 0.335590; batch adversarial loss: 0.642003\n",
      "epoch 31; iter: 200; batch classifier loss: 0.303055; batch adversarial loss: 0.595373\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381195; batch adversarial loss: 0.619146\n",
      "epoch 32; iter: 200; batch classifier loss: 0.320938; batch adversarial loss: 0.597160\n",
      "epoch 33; iter: 0; batch classifier loss: 0.289777; batch adversarial loss: 0.649606\n",
      "epoch 33; iter: 200; batch classifier loss: 0.367302; batch adversarial loss: 0.595100\n",
      "epoch 34; iter: 0; batch classifier loss: 0.377366; batch adversarial loss: 0.597708\n",
      "epoch 34; iter: 200; batch classifier loss: 0.358352; batch adversarial loss: 0.553730\n",
      "epoch 35; iter: 0; batch classifier loss: 0.363852; batch adversarial loss: 0.692454\n",
      "epoch 35; iter: 200; batch classifier loss: 0.327915; batch adversarial loss: 0.615928\n",
      "epoch 36; iter: 0; batch classifier loss: 0.327475; batch adversarial loss: 0.610969\n",
      "epoch 36; iter: 200; batch classifier loss: 0.300432; batch adversarial loss: 0.606994\n",
      "epoch 37; iter: 0; batch classifier loss: 0.375704; batch adversarial loss: 0.680502\n",
      "epoch 37; iter: 200; batch classifier loss: 0.397744; batch adversarial loss: 0.603483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.365615; batch adversarial loss: 0.599908\n",
      "epoch 38; iter: 200; batch classifier loss: 0.317955; batch adversarial loss: 0.611598\n",
      "epoch 39; iter: 0; batch classifier loss: 0.278615; batch adversarial loss: 0.620651\n",
      "epoch 39; iter: 200; batch classifier loss: 0.446465; batch adversarial loss: 0.691776\n",
      "epoch 40; iter: 0; batch classifier loss: 0.299789; batch adversarial loss: 0.617375\n",
      "epoch 40; iter: 200; batch classifier loss: 0.358295; batch adversarial loss: 0.607083\n",
      "epoch 41; iter: 0; batch classifier loss: 0.350910; batch adversarial loss: 0.611665\n",
      "epoch 41; iter: 200; batch classifier loss: 0.306190; batch adversarial loss: 0.656070\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414922; batch adversarial loss: 0.574562\n",
      "epoch 42; iter: 200; batch classifier loss: 0.364442; batch adversarial loss: 0.573591\n",
      "epoch 43; iter: 0; batch classifier loss: 0.454854; batch adversarial loss: 0.611285\n",
      "epoch 43; iter: 200; batch classifier loss: 0.372977; batch adversarial loss: 0.639116\n",
      "epoch 44; iter: 0; batch classifier loss: 0.284780; batch adversarial loss: 0.664033\n",
      "epoch 44; iter: 200; batch classifier loss: 0.331397; batch adversarial loss: 0.627531\n",
      "epoch 45; iter: 0; batch classifier loss: 0.210550; batch adversarial loss: 0.608342\n",
      "epoch 45; iter: 200; batch classifier loss: 0.361536; batch adversarial loss: 0.595938\n",
      "epoch 46; iter: 0; batch classifier loss: 0.375513; batch adversarial loss: 0.624631\n",
      "epoch 46; iter: 200; batch classifier loss: 0.304991; batch adversarial loss: 0.596245\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357357; batch adversarial loss: 0.623391\n",
      "epoch 47; iter: 200; batch classifier loss: 0.401404; batch adversarial loss: 0.644366\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438355; batch adversarial loss: 0.647430\n",
      "epoch 48; iter: 200; batch classifier loss: 0.421824; batch adversarial loss: 0.601165\n",
      "epoch 49; iter: 0; batch classifier loss: 0.653009; batch adversarial loss: 0.591455\n",
      "epoch 49; iter: 200; batch classifier loss: 0.421213; batch adversarial loss: 0.680728\n",
      "epoch 0; iter: 0; batch classifier loss: 12.660600; batch adversarial loss: 0.669260\n",
      "epoch 0; iter: 200; batch classifier loss: 7.512349; batch adversarial loss: 0.683740\n",
      "epoch 1; iter: 0; batch classifier loss: 3.911484; batch adversarial loss: 0.641428\n",
      "epoch 1; iter: 200; batch classifier loss: 9.043929; batch adversarial loss: 0.628905\n",
      "epoch 2; iter: 0; batch classifier loss: 6.815174; batch adversarial loss: 0.625893\n",
      "epoch 2; iter: 200; batch classifier loss: 4.279675; batch adversarial loss: 0.632508\n",
      "epoch 3; iter: 0; batch classifier loss: 6.638335; batch adversarial loss: 0.657288\n",
      "epoch 3; iter: 200; batch classifier loss: 2.816319; batch adversarial loss: 0.650446\n",
      "epoch 4; iter: 0; batch classifier loss: 2.689198; batch adversarial loss: 0.646508\n",
      "epoch 4; iter: 200; batch classifier loss: 1.125812; batch adversarial loss: 0.677580\n",
      "epoch 5; iter: 0; batch classifier loss: 1.802442; batch adversarial loss: 0.630390\n",
      "epoch 5; iter: 200; batch classifier loss: 1.877421; batch adversarial loss: 0.664215\n",
      "epoch 6; iter: 0; batch classifier loss: 1.187865; batch adversarial loss: 0.665832\n",
      "epoch 6; iter: 200; batch classifier loss: 0.547328; batch adversarial loss: 0.633043\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586479; batch adversarial loss: 0.621002\n",
      "epoch 7; iter: 200; batch classifier loss: 0.881159; batch adversarial loss: 0.577998\n",
      "epoch 8; iter: 0; batch classifier loss: 0.787340; batch adversarial loss: 0.623869\n",
      "epoch 8; iter: 200; batch classifier loss: 0.626490; batch adversarial loss: 0.633874\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548526; batch adversarial loss: 0.609898\n",
      "epoch 9; iter: 200; batch classifier loss: 0.472538; batch adversarial loss: 0.628086\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481423; batch adversarial loss: 0.649077\n",
      "epoch 10; iter: 200; batch classifier loss: 0.663544; batch adversarial loss: 0.596689\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424824; batch adversarial loss: 0.663699\n",
      "epoch 11; iter: 200; batch classifier loss: 0.444640; batch adversarial loss: 0.635309\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478702; batch adversarial loss: 0.628974\n",
      "epoch 12; iter: 200; batch classifier loss: 0.470315; batch adversarial loss: 0.667247\n",
      "epoch 13; iter: 0; batch classifier loss: 0.423912; batch adversarial loss: 0.600750\n",
      "epoch 13; iter: 200; batch classifier loss: 0.443816; batch adversarial loss: 0.586954\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525860; batch adversarial loss: 0.680359\n",
      "epoch 14; iter: 200; batch classifier loss: 0.500781; batch adversarial loss: 0.578081\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323175; batch adversarial loss: 0.648439\n",
      "epoch 15; iter: 200; batch classifier loss: 0.288046; batch adversarial loss: 0.561322\n",
      "epoch 16; iter: 0; batch classifier loss: 0.316334; batch adversarial loss: 0.646845\n",
      "epoch 16; iter: 200; batch classifier loss: 0.382507; batch adversarial loss: 0.560144\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.529972\n",
      "epoch 17; iter: 200; batch classifier loss: 0.281448; batch adversarial loss: 0.633668\n",
      "epoch 18; iter: 0; batch classifier loss: 0.346426; batch adversarial loss: 0.579878\n",
      "epoch 18; iter: 200; batch classifier loss: 0.351532; batch adversarial loss: 0.606304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.371154; batch adversarial loss: 0.650196\n",
      "epoch 19; iter: 200; batch classifier loss: 0.348444; batch adversarial loss: 0.630233\n",
      "epoch 20; iter: 0; batch classifier loss: 0.343832; batch adversarial loss: 0.600275\n",
      "epoch 20; iter: 200; batch classifier loss: 0.346763; batch adversarial loss: 0.594567\n",
      "epoch 21; iter: 0; batch classifier loss: 0.357769; batch adversarial loss: 0.646042\n",
      "epoch 21; iter: 200; batch classifier loss: 0.319686; batch adversarial loss: 0.647242\n",
      "epoch 22; iter: 0; batch classifier loss: 0.304808; batch adversarial loss: 0.626598\n",
      "epoch 22; iter: 200; batch classifier loss: 0.344785; batch adversarial loss: 0.638772\n",
      "epoch 23; iter: 0; batch classifier loss: 0.276528; batch adversarial loss: 0.649257\n",
      "epoch 23; iter: 200; batch classifier loss: 0.292162; batch adversarial loss: 0.625829\n",
      "epoch 24; iter: 0; batch classifier loss: 0.304992; batch adversarial loss: 0.644569\n",
      "epoch 24; iter: 200; batch classifier loss: 0.361399; batch adversarial loss: 0.613593\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311451; batch adversarial loss: 0.595766\n",
      "epoch 25; iter: 200; batch classifier loss: 0.327957; batch adversarial loss: 0.586420\n",
      "epoch 26; iter: 0; batch classifier loss: 0.364932; batch adversarial loss: 0.559485\n",
      "epoch 26; iter: 200; batch classifier loss: 0.330480; batch adversarial loss: 0.639774\n",
      "epoch 27; iter: 0; batch classifier loss: 0.336031; batch adversarial loss: 0.623720\n",
      "epoch 27; iter: 200; batch classifier loss: 0.344641; batch adversarial loss: 0.625095\n",
      "epoch 28; iter: 0; batch classifier loss: 0.331453; batch adversarial loss: 0.571950\n",
      "epoch 28; iter: 200; batch classifier loss: 0.310741; batch adversarial loss: 0.595375\n",
      "epoch 29; iter: 0; batch classifier loss: 0.298113; batch adversarial loss: 0.607383\n",
      "epoch 29; iter: 200; batch classifier loss: 0.284271; batch adversarial loss: 0.566205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.348330; batch adversarial loss: 0.650869\n",
      "epoch 30; iter: 200; batch classifier loss: 0.418888; batch adversarial loss: 0.639526\n",
      "epoch 31; iter: 0; batch classifier loss: 0.279504; batch adversarial loss: 0.578187\n",
      "epoch 31; iter: 200; batch classifier loss: 0.375563; batch adversarial loss: 0.592447\n",
      "epoch 32; iter: 0; batch classifier loss: 0.350127; batch adversarial loss: 0.633281\n",
      "epoch 32; iter: 200; batch classifier loss: 0.455034; batch adversarial loss: 0.594800\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471672; batch adversarial loss: 0.639617\n",
      "epoch 33; iter: 200; batch classifier loss: 0.358964; batch adversarial loss: 0.593846\n",
      "epoch 34; iter: 0; batch classifier loss: 0.352352; batch adversarial loss: 0.583631\n",
      "epoch 34; iter: 200; batch classifier loss: 0.273427; batch adversarial loss: 0.585615\n",
      "epoch 35; iter: 0; batch classifier loss: 0.237899; batch adversarial loss: 0.659773\n",
      "epoch 35; iter: 200; batch classifier loss: 0.372201; batch adversarial loss: 0.595765\n",
      "epoch 36; iter: 0; batch classifier loss: 0.382286; batch adversarial loss: 0.618671\n",
      "epoch 36; iter: 200; batch classifier loss: 0.291171; batch adversarial loss: 0.644154\n",
      "epoch 37; iter: 0; batch classifier loss: 0.288038; batch adversarial loss: 0.622718\n",
      "epoch 37; iter: 200; batch classifier loss: 0.401359; batch adversarial loss: 0.636303\n",
      "epoch 38; iter: 0; batch classifier loss: 0.321178; batch adversarial loss: 0.608587\n",
      "epoch 38; iter: 200; batch classifier loss: 0.337474; batch adversarial loss: 0.664079\n",
      "epoch 39; iter: 0; batch classifier loss: 0.246333; batch adversarial loss: 0.597357\n",
      "epoch 39; iter: 200; batch classifier loss: 0.331164; batch adversarial loss: 0.628998\n",
      "epoch 40; iter: 0; batch classifier loss: 0.332384; batch adversarial loss: 0.663508\n",
      "epoch 40; iter: 200; batch classifier loss: 0.309049; batch adversarial loss: 0.635087\n",
      "epoch 41; iter: 0; batch classifier loss: 0.298944; batch adversarial loss: 0.613039\n",
      "epoch 41; iter: 200; batch classifier loss: 0.417804; batch adversarial loss: 0.607191\n",
      "epoch 42; iter: 0; batch classifier loss: 0.322472; batch adversarial loss: 0.630538\n",
      "epoch 42; iter: 200; batch classifier loss: 0.351277; batch adversarial loss: 0.631159\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390662; batch adversarial loss: 0.620652\n",
      "epoch 43; iter: 200; batch classifier loss: 0.349688; batch adversarial loss: 0.633743\n",
      "epoch 44; iter: 0; batch classifier loss: 0.334271; batch adversarial loss: 0.545665\n",
      "epoch 44; iter: 200; batch classifier loss: 0.453013; batch adversarial loss: 0.642701\n",
      "epoch 45; iter: 0; batch classifier loss: 0.349063; batch adversarial loss: 0.618325\n",
      "epoch 45; iter: 200; batch classifier loss: 0.295101; batch adversarial loss: 0.666466\n",
      "epoch 46; iter: 0; batch classifier loss: 0.437093; batch adversarial loss: 0.616591\n",
      "epoch 46; iter: 200; batch classifier loss: 0.467092; batch adversarial loss: 0.621741\n",
      "epoch 47; iter: 0; batch classifier loss: 0.389967; batch adversarial loss: 0.675944\n",
      "epoch 47; iter: 200; batch classifier loss: 0.375110; batch adversarial loss: 0.609578\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409363; batch adversarial loss: 0.596584\n",
      "epoch 48; iter: 200; batch classifier loss: 0.318850; batch adversarial loss: 0.653411\n",
      "epoch 49; iter: 0; batch classifier loss: 0.359546; batch adversarial loss: 0.622028\n",
      "epoch 49; iter: 200; batch classifier loss: 0.338450; batch adversarial loss: 0.658017\n",
      "epoch 0; iter: 0; batch classifier loss: 40.810947; batch adversarial loss: 0.638045\n",
      "epoch 0; iter: 200; batch classifier loss: 2.211429; batch adversarial loss: 0.652588\n",
      "epoch 1; iter: 0; batch classifier loss: 10.901037; batch adversarial loss: 0.630127\n",
      "epoch 1; iter: 200; batch classifier loss: 7.063746; batch adversarial loss: 0.618524\n",
      "epoch 2; iter: 0; batch classifier loss: 5.824645; batch adversarial loss: 0.683425\n",
      "epoch 2; iter: 200; batch classifier loss: 4.127569; batch adversarial loss: 0.605093\n",
      "epoch 3; iter: 0; batch classifier loss: 4.725232; batch adversarial loss: 0.629498\n",
      "epoch 3; iter: 200; batch classifier loss: 11.286118; batch adversarial loss: 0.626121\n",
      "epoch 4; iter: 0; batch classifier loss: 2.583114; batch adversarial loss: 0.631061\n",
      "epoch 4; iter: 200; batch classifier loss: 1.311152; batch adversarial loss: 0.642640\n",
      "epoch 5; iter: 0; batch classifier loss: 1.724232; batch adversarial loss: 0.595718\n",
      "epoch 5; iter: 200; batch classifier loss: 1.571405; batch adversarial loss: 0.639516\n",
      "epoch 6; iter: 0; batch classifier loss: 0.745271; batch adversarial loss: 0.598362\n",
      "epoch 6; iter: 200; batch classifier loss: 0.983589; batch adversarial loss: 0.619662\n",
      "epoch 7; iter: 0; batch classifier loss: 0.809994; batch adversarial loss: 0.625206\n",
      "epoch 7; iter: 200; batch classifier loss: 0.530639; batch adversarial loss: 0.654691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497469; batch adversarial loss: 0.635950\n",
      "epoch 8; iter: 200; batch classifier loss: 0.403762; batch adversarial loss: 0.621972\n",
      "epoch 9; iter: 0; batch classifier loss: 0.468003; batch adversarial loss: 0.626283\n",
      "epoch 9; iter: 200; batch classifier loss: 0.498340; batch adversarial loss: 0.646923\n",
      "epoch 10; iter: 0; batch classifier loss: 0.467607; batch adversarial loss: 0.630345\n",
      "epoch 10; iter: 200; batch classifier loss: 0.524380; batch adversarial loss: 0.593407\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480413; batch adversarial loss: 0.573459\n",
      "epoch 11; iter: 200; batch classifier loss: 0.492469; batch adversarial loss: 0.573209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.429720; batch adversarial loss: 0.639599\n",
      "epoch 12; iter: 200; batch classifier loss: 0.307297; batch adversarial loss: 0.638065\n",
      "epoch 13; iter: 0; batch classifier loss: 0.447205; batch adversarial loss: 0.665859\n",
      "epoch 13; iter: 200; batch classifier loss: 0.489498; batch adversarial loss: 0.643762\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390634; batch adversarial loss: 0.641429\n",
      "epoch 14; iter: 200; batch classifier loss: 0.465061; batch adversarial loss: 0.571232\n",
      "epoch 15; iter: 0; batch classifier loss: 0.666164; batch adversarial loss: 0.574202\n",
      "epoch 15; iter: 200; batch classifier loss: 0.497072; batch adversarial loss: 0.609928\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385817; batch adversarial loss: 0.632610\n",
      "epoch 16; iter: 200; batch classifier loss: 0.403284; batch adversarial loss: 0.599214\n",
      "epoch 17; iter: 0; batch classifier loss: 0.407099; batch adversarial loss: 0.613261\n",
      "epoch 17; iter: 200; batch classifier loss: 0.311609; batch adversarial loss: 0.651735\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343750; batch adversarial loss: 0.627966\n",
      "epoch 18; iter: 200; batch classifier loss: 0.484230; batch adversarial loss: 0.613167\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340636; batch adversarial loss: 0.582508\n",
      "epoch 19; iter: 200; batch classifier loss: 0.412488; batch adversarial loss: 0.623034\n",
      "epoch 20; iter: 0; batch classifier loss: 0.443254; batch adversarial loss: 0.564783\n",
      "epoch 20; iter: 200; batch classifier loss: 0.382672; batch adversarial loss: 0.616287\n",
      "epoch 21; iter: 0; batch classifier loss: 0.360623; batch adversarial loss: 0.526206\n",
      "epoch 21; iter: 200; batch classifier loss: 0.346161; batch adversarial loss: 0.620948\n",
      "epoch 22; iter: 0; batch classifier loss: 0.397702; batch adversarial loss: 0.595385\n",
      "epoch 22; iter: 200; batch classifier loss: 0.402008; batch adversarial loss: 0.639948\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351902; batch adversarial loss: 0.592904\n",
      "epoch 23; iter: 200; batch classifier loss: 0.412968; batch adversarial loss: 0.610893\n",
      "epoch 24; iter: 0; batch classifier loss: 0.305676; batch adversarial loss: 0.616658\n",
      "epoch 24; iter: 200; batch classifier loss: 0.360924; batch adversarial loss: 0.617455\n",
      "epoch 25; iter: 0; batch classifier loss: 0.515819; batch adversarial loss: 0.699489\n",
      "epoch 25; iter: 200; batch classifier loss: 0.373819; batch adversarial loss: 0.576386\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413849; batch adversarial loss: 0.590680\n",
      "epoch 26; iter: 200; batch classifier loss: 0.357626; batch adversarial loss: 0.638525\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327371; batch adversarial loss: 0.574095\n",
      "epoch 27; iter: 200; batch classifier loss: 0.413576; batch adversarial loss: 0.621734\n",
      "epoch 28; iter: 0; batch classifier loss: 0.239246; batch adversarial loss: 0.590247\n",
      "epoch 28; iter: 200; batch classifier loss: 0.336013; batch adversarial loss: 0.656894\n",
      "epoch 29; iter: 0; batch classifier loss: 0.387735; batch adversarial loss: 0.543285\n",
      "epoch 29; iter: 200; batch classifier loss: 0.437992; batch adversarial loss: 0.624795\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425915; batch adversarial loss: 0.616500\n",
      "epoch 30; iter: 200; batch classifier loss: 0.326874; batch adversarial loss: 0.629136\n",
      "epoch 31; iter: 0; batch classifier loss: 0.365921; batch adversarial loss: 0.614088\n",
      "epoch 31; iter: 200; batch classifier loss: 0.348503; batch adversarial loss: 0.626118\n",
      "epoch 32; iter: 0; batch classifier loss: 0.301795; batch adversarial loss: 0.637875\n",
      "epoch 32; iter: 200; batch classifier loss: 0.544972; batch adversarial loss: 0.566849\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425632; batch adversarial loss: 0.608675\n",
      "epoch 33; iter: 200; batch classifier loss: 0.341990; batch adversarial loss: 0.611370\n",
      "epoch 34; iter: 0; batch classifier loss: 0.664541; batch adversarial loss: 0.588765\n",
      "epoch 34; iter: 200; batch classifier loss: 0.359923; batch adversarial loss: 0.639459\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376915; batch adversarial loss: 0.591964\n",
      "epoch 35; iter: 200; batch classifier loss: 0.293375; batch adversarial loss: 0.587467\n",
      "epoch 36; iter: 0; batch classifier loss: 0.359851; batch adversarial loss: 0.624693\n",
      "epoch 36; iter: 200; batch classifier loss: 0.429203; batch adversarial loss: 0.632348\n",
      "epoch 37; iter: 0; batch classifier loss: 0.328498; batch adversarial loss: 0.611227\n",
      "epoch 37; iter: 200; batch classifier loss: 0.388699; batch adversarial loss: 0.577292\n",
      "epoch 38; iter: 0; batch classifier loss: 0.287978; batch adversarial loss: 0.701210\n",
      "epoch 38; iter: 200; batch classifier loss: 0.325864; batch adversarial loss: 0.598552\n",
      "epoch 39; iter: 0; batch classifier loss: 0.361833; batch adversarial loss: 0.671026\n",
      "epoch 39; iter: 200; batch classifier loss: 0.382014; batch adversarial loss: 0.611165\n",
      "epoch 40; iter: 0; batch classifier loss: 0.344396; batch adversarial loss: 0.593085\n",
      "epoch 40; iter: 200; batch classifier loss: 0.371491; batch adversarial loss: 0.595857\n",
      "epoch 41; iter: 0; batch classifier loss: 0.489335; batch adversarial loss: 0.655619\n",
      "epoch 41; iter: 200; batch classifier loss: 0.320834; batch adversarial loss: 0.624801\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378423; batch adversarial loss: 0.582012\n",
      "epoch 42; iter: 200; batch classifier loss: 0.383391; batch adversarial loss: 0.670104\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386800; batch adversarial loss: 0.664280\n",
      "epoch 43; iter: 200; batch classifier loss: 0.409928; batch adversarial loss: 0.639165\n",
      "epoch 44; iter: 0; batch classifier loss: 0.319488; batch adversarial loss: 0.565529\n",
      "epoch 44; iter: 200; batch classifier loss: 0.261235; batch adversarial loss: 0.572458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399222; batch adversarial loss: 0.620023\n",
      "epoch 45; iter: 200; batch classifier loss: 0.387923; batch adversarial loss: 0.601129\n",
      "epoch 46; iter: 0; batch classifier loss: 0.244169; batch adversarial loss: 0.659792\n",
      "epoch 46; iter: 200; batch classifier loss: 0.369625; batch adversarial loss: 0.565082\n",
      "epoch 47; iter: 0; batch classifier loss: 0.606199; batch adversarial loss: 0.640755\n",
      "epoch 47; iter: 200; batch classifier loss: 0.384362; batch adversarial loss: 0.619555\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366613; batch adversarial loss: 0.608793\n",
      "epoch 48; iter: 200; batch classifier loss: 0.420708; batch adversarial loss: 0.587540\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416181; batch adversarial loss: 0.598409\n",
      "epoch 49; iter: 200; batch classifier loss: 0.382404; batch adversarial loss: 0.585147\n",
      "epoch 0; iter: 0; batch classifier loss: 13.035395; batch adversarial loss: 0.721671\n",
      "epoch 0; iter: 200; batch classifier loss: 9.362294; batch adversarial loss: 0.662033\n",
      "epoch 1; iter: 0; batch classifier loss: 10.966476; batch adversarial loss: 0.658666\n",
      "epoch 1; iter: 200; batch classifier loss: 4.578113; batch adversarial loss: 0.655507\n",
      "epoch 2; iter: 0; batch classifier loss: 6.879086; batch adversarial loss: 0.671131\n",
      "epoch 2; iter: 200; batch classifier loss: 2.083513; batch adversarial loss: 0.670276\n",
      "epoch 3; iter: 0; batch classifier loss: 5.633524; batch adversarial loss: 0.623217\n",
      "epoch 3; iter: 200; batch classifier loss: 2.298383; batch adversarial loss: 0.613852\n",
      "epoch 4; iter: 0; batch classifier loss: 2.870193; batch adversarial loss: 0.634334\n",
      "epoch 4; iter: 200; batch classifier loss: 5.611553; batch adversarial loss: 0.651715\n",
      "epoch 5; iter: 0; batch classifier loss: 1.390114; batch adversarial loss: 0.597537\n",
      "epoch 5; iter: 200; batch classifier loss: 0.953832; batch adversarial loss: 0.616506\n",
      "epoch 6; iter: 0; batch classifier loss: 0.684830; batch adversarial loss: 0.652446\n",
      "epoch 6; iter: 200; batch classifier loss: 0.742175; batch adversarial loss: 0.607922\n",
      "epoch 7; iter: 0; batch classifier loss: 0.708697; batch adversarial loss: 0.646751\n",
      "epoch 7; iter: 200; batch classifier loss: 0.445764; batch adversarial loss: 0.666414\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546358; batch adversarial loss: 0.578859\n",
      "epoch 8; iter: 200; batch classifier loss: 0.476934; batch adversarial loss: 0.587048\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479260; batch adversarial loss: 0.648362\n",
      "epoch 9; iter: 200; batch classifier loss: 0.477002; batch adversarial loss: 0.616593\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400556; batch adversarial loss: 0.594389\n",
      "epoch 10; iter: 200; batch classifier loss: 0.417436; batch adversarial loss: 0.632939\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353969; batch adversarial loss: 0.604145\n",
      "epoch 11; iter: 200; batch classifier loss: 0.487376; batch adversarial loss: 0.620970\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377221; batch adversarial loss: 0.668900\n",
      "epoch 12; iter: 200; batch classifier loss: 0.439576; batch adversarial loss: 0.668332\n",
      "epoch 13; iter: 0; batch classifier loss: 0.323046; batch adversarial loss: 0.615633\n",
      "epoch 13; iter: 200; batch classifier loss: 0.299824; batch adversarial loss: 0.620142\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528908; batch adversarial loss: 0.600713\n",
      "epoch 14; iter: 200; batch classifier loss: 0.303560; batch adversarial loss: 0.593548\n",
      "epoch 15; iter: 0; batch classifier loss: 0.403526; batch adversarial loss: 0.622166\n",
      "epoch 15; iter: 200; batch classifier loss: 0.373308; batch adversarial loss: 0.685549\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387159; batch adversarial loss: 0.646176\n",
      "epoch 16; iter: 200; batch classifier loss: 0.359777; batch adversarial loss: 0.571782\n",
      "epoch 17; iter: 0; batch classifier loss: 0.385340; batch adversarial loss: 0.583262\n",
      "epoch 17; iter: 200; batch classifier loss: 0.441039; batch adversarial loss: 0.643587\n",
      "epoch 18; iter: 0; batch classifier loss: 0.363755; batch adversarial loss: 0.612642\n",
      "epoch 18; iter: 200; batch classifier loss: 0.283485; batch adversarial loss: 0.571497\n",
      "epoch 19; iter: 0; batch classifier loss: 0.274017; batch adversarial loss: 0.645720\n",
      "epoch 19; iter: 200; batch classifier loss: 0.340721; batch adversarial loss: 0.601667\n",
      "epoch 20; iter: 0; batch classifier loss: 0.407735; batch adversarial loss: 0.544322\n",
      "epoch 20; iter: 200; batch classifier loss: 0.353316; batch adversarial loss: 0.578766\n",
      "epoch 21; iter: 0; batch classifier loss: 0.385033; batch adversarial loss: 0.606517\n",
      "epoch 21; iter: 200; batch classifier loss: 0.354337; batch adversarial loss: 0.597385\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458411; batch adversarial loss: 0.647831\n",
      "epoch 22; iter: 200; batch classifier loss: 0.308561; batch adversarial loss: 0.595493\n",
      "epoch 23; iter: 0; batch classifier loss: 0.369341; batch adversarial loss: 0.595522\n",
      "epoch 23; iter: 200; batch classifier loss: 0.360179; batch adversarial loss: 0.616839\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364560; batch adversarial loss: 0.596767\n",
      "epoch 24; iter: 200; batch classifier loss: 0.254101; batch adversarial loss: 0.585979\n",
      "epoch 25; iter: 0; batch classifier loss: 0.302619; batch adversarial loss: 0.533077\n",
      "epoch 25; iter: 200; batch classifier loss: 0.404946; batch adversarial loss: 0.651250\n",
      "epoch 26; iter: 0; batch classifier loss: 0.360481; batch adversarial loss: 0.607778\n",
      "epoch 26; iter: 200; batch classifier loss: 0.404762; batch adversarial loss: 0.627731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.323064; batch adversarial loss: 0.602641\n",
      "epoch 27; iter: 200; batch classifier loss: 0.383991; batch adversarial loss: 0.588706\n",
      "epoch 28; iter: 0; batch classifier loss: 0.370641; batch adversarial loss: 0.584419\n",
      "epoch 28; iter: 200; batch classifier loss: 0.452476; batch adversarial loss: 0.539688\n",
      "epoch 29; iter: 0; batch classifier loss: 0.276780; batch adversarial loss: 0.617149\n",
      "epoch 29; iter: 200; batch classifier loss: 0.291495; batch adversarial loss: 0.619868\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320508; batch adversarial loss: 0.657801\n",
      "epoch 30; iter: 200; batch classifier loss: 0.433011; batch adversarial loss: 0.607767\n",
      "epoch 31; iter: 0; batch classifier loss: 0.262330; batch adversarial loss: 0.631600\n",
      "epoch 31; iter: 200; batch classifier loss: 0.316136; batch adversarial loss: 0.621819\n",
      "epoch 32; iter: 0; batch classifier loss: 0.370804; batch adversarial loss: 0.575330\n",
      "epoch 32; iter: 200; batch classifier loss: 0.364935; batch adversarial loss: 0.671274\n",
      "epoch 33; iter: 0; batch classifier loss: 0.338474; batch adversarial loss: 0.617683\n",
      "epoch 33; iter: 200; batch classifier loss: 0.314033; batch adversarial loss: 0.630654\n",
      "epoch 34; iter: 0; batch classifier loss: 0.314561; batch adversarial loss: 0.707756\n",
      "epoch 34; iter: 200; batch classifier loss: 0.380572; batch adversarial loss: 0.606679\n",
      "epoch 35; iter: 0; batch classifier loss: 0.332158; batch adversarial loss: 0.576975\n",
      "epoch 35; iter: 200; batch classifier loss: 0.282586; batch adversarial loss: 0.653624\n",
      "epoch 36; iter: 0; batch classifier loss: 0.376980; batch adversarial loss: 0.571579\n",
      "epoch 36; iter: 200; batch classifier loss: 0.406283; batch adversarial loss: 0.616578\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421476; batch adversarial loss: 0.621059\n",
      "epoch 37; iter: 200; batch classifier loss: 0.330515; batch adversarial loss: 0.610811\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392494; batch adversarial loss: 0.673198\n",
      "epoch 38; iter: 200; batch classifier loss: 0.451120; batch adversarial loss: 0.659650\n",
      "epoch 39; iter: 0; batch classifier loss: 0.360518; batch adversarial loss: 0.623214\n",
      "epoch 39; iter: 200; batch classifier loss: 0.353440; batch adversarial loss: 0.660311\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389549; batch adversarial loss: 0.625021\n",
      "epoch 40; iter: 200; batch classifier loss: 0.323117; batch adversarial loss: 0.635199\n",
      "epoch 41; iter: 0; batch classifier loss: 0.361190; batch adversarial loss: 0.641361\n",
      "epoch 41; iter: 200; batch classifier loss: 0.304940; batch adversarial loss: 0.671931\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406362; batch adversarial loss: 0.591319\n",
      "epoch 42; iter: 200; batch classifier loss: 0.342323; batch adversarial loss: 0.667833\n",
      "epoch 43; iter: 0; batch classifier loss: 0.274607; batch adversarial loss: 0.560967\n",
      "epoch 43; iter: 200; batch classifier loss: 0.300919; batch adversarial loss: 0.655700\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401402; batch adversarial loss: 0.600383\n",
      "epoch 44; iter: 200; batch classifier loss: 0.326897; batch adversarial loss: 0.672044\n",
      "epoch 45; iter: 0; batch classifier loss: 0.322174; batch adversarial loss: 0.635480\n",
      "epoch 45; iter: 200; batch classifier loss: 0.592202; batch adversarial loss: 0.699141\n",
      "epoch 46; iter: 0; batch classifier loss: 0.210227; batch adversarial loss: 0.678264\n",
      "epoch 46; iter: 200; batch classifier loss: 0.342200; batch adversarial loss: 0.589037\n",
      "epoch 47; iter: 0; batch classifier loss: 0.320817; batch adversarial loss: 0.639373\n",
      "epoch 47; iter: 200; batch classifier loss: 0.444300; batch adversarial loss: 0.642607\n",
      "epoch 48; iter: 0; batch classifier loss: 0.328832; batch adversarial loss: 0.535115\n",
      "epoch 48; iter: 200; batch classifier loss: 0.388513; batch adversarial loss: 0.626331\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382170; batch adversarial loss: 0.610127\n",
      "epoch 49; iter: 200; batch classifier loss: 0.270627; batch adversarial loss: 0.619267\n",
      "epoch 0; iter: 0; batch classifier loss: 532.214783; batch adversarial loss: 0.663798\n",
      "epoch 0; iter: 200; batch classifier loss: 2.911255; batch adversarial loss: 0.639603\n",
      "epoch 1; iter: 0; batch classifier loss: 6.731716; batch adversarial loss: 0.621315\n",
      "epoch 1; iter: 200; batch classifier loss: 3.732283; batch adversarial loss: 0.620664\n",
      "epoch 2; iter: 0; batch classifier loss: 15.807917; batch adversarial loss: 0.649694\n",
      "epoch 2; iter: 200; batch classifier loss: 3.467700; batch adversarial loss: 0.669919\n",
      "epoch 3; iter: 0; batch classifier loss: 4.536171; batch adversarial loss: 0.737504\n",
      "epoch 3; iter: 200; batch classifier loss: 3.609376; batch adversarial loss: 0.666742\n",
      "epoch 4; iter: 0; batch classifier loss: 1.558991; batch adversarial loss: 0.664356\n",
      "epoch 4; iter: 200; batch classifier loss: 1.778307; batch adversarial loss: 0.648078\n",
      "epoch 5; iter: 0; batch classifier loss: 3.576465; batch adversarial loss: 0.640063\n",
      "epoch 5; iter: 200; batch classifier loss: 2.001249; batch adversarial loss: 0.622162\n",
      "epoch 6; iter: 0; batch classifier loss: 1.369764; batch adversarial loss: 0.633552\n",
      "epoch 6; iter: 200; batch classifier loss: 1.037560; batch adversarial loss: 0.608358\n",
      "epoch 7; iter: 0; batch classifier loss: 1.608343; batch adversarial loss: 0.600085\n",
      "epoch 7; iter: 200; batch classifier loss: 0.640723; batch adversarial loss: 0.603079\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578642; batch adversarial loss: 0.646556\n",
      "epoch 8; iter: 200; batch classifier loss: 0.545318; batch adversarial loss: 0.596985\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349336; batch adversarial loss: 0.637264\n",
      "epoch 9; iter: 200; batch classifier loss: 0.482235; batch adversarial loss: 0.590026\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493586; batch adversarial loss: 0.628148\n",
      "epoch 10; iter: 200; batch classifier loss: 0.584690; batch adversarial loss: 0.638987\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494933; batch adversarial loss: 0.613701\n",
      "epoch 11; iter: 200; batch classifier loss: 0.407853; batch adversarial loss: 0.606442\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441262; batch adversarial loss: 0.614981\n",
      "epoch 12; iter: 200; batch classifier loss: 0.401642; batch adversarial loss: 0.587398\n",
      "epoch 13; iter: 0; batch classifier loss: 0.434945; batch adversarial loss: 0.544401\n",
      "epoch 13; iter: 200; batch classifier loss: 0.397248; batch adversarial loss: 0.615379\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394442; batch adversarial loss: 0.639517\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352867; batch adversarial loss: 0.621399\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372173; batch adversarial loss: 0.650834\n",
      "epoch 15; iter: 200; batch classifier loss: 0.506745; batch adversarial loss: 0.630309\n",
      "epoch 16; iter: 0; batch classifier loss: 0.322594; batch adversarial loss: 0.600336\n",
      "epoch 16; iter: 200; batch classifier loss: 0.358276; batch adversarial loss: 0.547050\n",
      "epoch 17; iter: 0; batch classifier loss: 0.434042; batch adversarial loss: 0.626850\n",
      "epoch 17; iter: 200; batch classifier loss: 0.355866; batch adversarial loss: 0.630622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.389586; batch adversarial loss: 0.565162\n",
      "epoch 18; iter: 200; batch classifier loss: 0.422691; batch adversarial loss: 0.604482\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324668; batch adversarial loss: 0.612718\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350673; batch adversarial loss: 0.652817\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337243; batch adversarial loss: 0.597810\n",
      "epoch 20; iter: 200; batch classifier loss: 0.362286; batch adversarial loss: 0.619577\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372233; batch adversarial loss: 0.615260\n",
      "epoch 21; iter: 200; batch classifier loss: 0.382823; batch adversarial loss: 0.593988\n",
      "epoch 22; iter: 0; batch classifier loss: 0.357786; batch adversarial loss: 0.586913\n",
      "epoch 22; iter: 200; batch classifier loss: 0.369448; batch adversarial loss: 0.637490\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344724; batch adversarial loss: 0.676557\n",
      "epoch 23; iter: 200; batch classifier loss: 0.381220; batch adversarial loss: 0.574033\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292793; batch adversarial loss: 0.580656\n",
      "epoch 24; iter: 200; batch classifier loss: 0.229507; batch adversarial loss: 0.647609\n",
      "epoch 25; iter: 0; batch classifier loss: 0.274259; batch adversarial loss: 0.695080\n",
      "epoch 25; iter: 200; batch classifier loss: 0.368409; batch adversarial loss: 0.603976\n",
      "epoch 26; iter: 0; batch classifier loss: 0.384860; batch adversarial loss: 0.612032\n",
      "epoch 26; iter: 200; batch classifier loss: 0.358845; batch adversarial loss: 0.617934\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278188; batch adversarial loss: 0.654763\n",
      "epoch 27; iter: 200; batch classifier loss: 0.333949; batch adversarial loss: 0.657248\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315066; batch adversarial loss: 0.638385\n",
      "epoch 28; iter: 200; batch classifier loss: 0.347076; batch adversarial loss: 0.657966\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258836; batch adversarial loss: 0.670993\n",
      "epoch 29; iter: 200; batch classifier loss: 0.362655; batch adversarial loss: 0.682301\n",
      "epoch 30; iter: 0; batch classifier loss: 0.409382; batch adversarial loss: 0.621050\n",
      "epoch 30; iter: 200; batch classifier loss: 0.445919; batch adversarial loss: 0.590735\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416350; batch adversarial loss: 0.578441\n",
      "epoch 31; iter: 200; batch classifier loss: 0.246652; batch adversarial loss: 0.580122\n",
      "epoch 32; iter: 0; batch classifier loss: 0.355367; batch adversarial loss: 0.629281\n",
      "epoch 32; iter: 200; batch classifier loss: 0.293439; batch adversarial loss: 0.646727\n",
      "epoch 33; iter: 0; batch classifier loss: 0.387580; batch adversarial loss: 0.621040\n",
      "epoch 33; iter: 200; batch classifier loss: 0.367732; batch adversarial loss: 0.636627\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418889; batch adversarial loss: 0.614969\n",
      "epoch 34; iter: 200; batch classifier loss: 0.327032; batch adversarial loss: 0.645289\n",
      "epoch 35; iter: 0; batch classifier loss: 0.375703; batch adversarial loss: 0.655168\n",
      "epoch 35; iter: 200; batch classifier loss: 0.352787; batch adversarial loss: 0.640112\n",
      "epoch 36; iter: 0; batch classifier loss: 0.392950; batch adversarial loss: 0.680660\n",
      "epoch 36; iter: 200; batch classifier loss: 0.401468; batch adversarial loss: 0.620012\n",
      "epoch 37; iter: 0; batch classifier loss: 0.319318; batch adversarial loss: 0.639585\n",
      "epoch 37; iter: 200; batch classifier loss: 0.350270; batch adversarial loss: 0.604722\n",
      "epoch 38; iter: 0; batch classifier loss: 0.324336; batch adversarial loss: 0.598819\n",
      "epoch 38; iter: 200; batch classifier loss: 0.483876; batch adversarial loss: 0.611272\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386125; batch adversarial loss: 0.625664\n",
      "epoch 39; iter: 200; batch classifier loss: 0.399376; batch adversarial loss: 0.674071\n",
      "epoch 40; iter: 0; batch classifier loss: 0.287136; batch adversarial loss: 0.631917\n",
      "epoch 40; iter: 200; batch classifier loss: 0.349167; batch adversarial loss: 0.604463\n",
      "epoch 41; iter: 0; batch classifier loss: 0.364671; batch adversarial loss: 0.687795\n",
      "epoch 41; iter: 200; batch classifier loss: 0.613996; batch adversarial loss: 0.546801\n",
      "epoch 42; iter: 0; batch classifier loss: 0.291272; batch adversarial loss: 0.646141\n",
      "epoch 42; iter: 200; batch classifier loss: 0.397207; batch adversarial loss: 0.625640\n",
      "epoch 43; iter: 0; batch classifier loss: 0.311107; batch adversarial loss: 0.623850\n",
      "epoch 43; iter: 200; batch classifier loss: 0.407584; batch adversarial loss: 0.648882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401235; batch adversarial loss: 0.637402\n",
      "epoch 44; iter: 200; batch classifier loss: 0.397890; batch adversarial loss: 0.654311\n",
      "epoch 45; iter: 0; batch classifier loss: 0.333508; batch adversarial loss: 0.567928\n",
      "epoch 45; iter: 200; batch classifier loss: 0.374643; batch adversarial loss: 0.613727\n",
      "epoch 46; iter: 0; batch classifier loss: 0.342612; batch adversarial loss: 0.605079\n",
      "epoch 46; iter: 200; batch classifier loss: 0.441542; batch adversarial loss: 0.624265\n",
      "epoch 47; iter: 0; batch classifier loss: 0.631584; batch adversarial loss: 0.642893\n",
      "epoch 47; iter: 200; batch classifier loss: 0.305292; batch adversarial loss: 0.641604\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347130; batch adversarial loss: 0.690901\n",
      "epoch 48; iter: 200; batch classifier loss: 0.318457; batch adversarial loss: 0.641432\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438264; batch adversarial loss: 0.574650\n",
      "epoch 49; iter: 200; batch classifier loss: 0.371990; batch adversarial loss: 0.638878\n",
      "epoch 0; iter: 0; batch classifier loss: 7.207137; batch adversarial loss: 0.802663\n",
      "epoch 0; iter: 200; batch classifier loss: 15.009626; batch adversarial loss: 0.789803\n",
      "epoch 1; iter: 0; batch classifier loss: 7.016886; batch adversarial loss: 0.827636\n",
      "epoch 1; iter: 200; batch classifier loss: 6.514084; batch adversarial loss: 0.726686\n",
      "epoch 2; iter: 0; batch classifier loss: 2.496981; batch adversarial loss: 0.683453\n",
      "epoch 2; iter: 200; batch classifier loss: 3.196881; batch adversarial loss: 0.686894\n",
      "epoch 3; iter: 0; batch classifier loss: 5.770755; batch adversarial loss: 0.628325\n",
      "epoch 3; iter: 200; batch classifier loss: 1.153466; batch adversarial loss: 0.611015\n",
      "epoch 4; iter: 0; batch classifier loss: 1.335401; batch adversarial loss: 0.597524\n",
      "epoch 4; iter: 200; batch classifier loss: 1.146567; batch adversarial loss: 0.604345\n",
      "epoch 5; iter: 0; batch classifier loss: 0.993087; batch adversarial loss: 0.577543\n",
      "epoch 5; iter: 200; batch classifier loss: 1.383134; batch adversarial loss: 0.607071\n",
      "epoch 6; iter: 0; batch classifier loss: 0.723087; batch adversarial loss: 0.663476\n",
      "epoch 6; iter: 200; batch classifier loss: 0.582961; batch adversarial loss: 0.612015\n",
      "epoch 7; iter: 0; batch classifier loss: 0.788715; batch adversarial loss: 0.659365\n",
      "epoch 7; iter: 200; batch classifier loss: 0.611884; batch adversarial loss: 0.576328\n",
      "epoch 8; iter: 0; batch classifier loss: 0.605818; batch adversarial loss: 0.582461\n",
      "epoch 8; iter: 200; batch classifier loss: 0.631802; batch adversarial loss: 0.578392\n",
      "epoch 9; iter: 0; batch classifier loss: 0.868405; batch adversarial loss: 0.575372\n",
      "epoch 9; iter: 200; batch classifier loss: 0.526856; batch adversarial loss: 0.612666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414671; batch adversarial loss: 0.643690\n",
      "epoch 10; iter: 200; batch classifier loss: 0.447548; batch adversarial loss: 0.594255\n",
      "epoch 11; iter: 0; batch classifier loss: 0.427627; batch adversarial loss: 0.632849\n",
      "epoch 11; iter: 200; batch classifier loss: 0.494996; batch adversarial loss: 0.600997\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360672; batch adversarial loss: 0.609228\n",
      "epoch 12; iter: 200; batch classifier loss: 0.500096; batch adversarial loss: 0.556883\n",
      "epoch 13; iter: 0; batch classifier loss: 0.385220; batch adversarial loss: 0.579849\n",
      "epoch 13; iter: 200; batch classifier loss: 0.316998; batch adversarial loss: 0.631177\n",
      "epoch 14; iter: 0; batch classifier loss: 0.375784; batch adversarial loss: 0.611796\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352232; batch adversarial loss: 0.621026\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364087; batch adversarial loss: 0.652096\n",
      "epoch 15; iter: 200; batch classifier loss: 0.367420; batch adversarial loss: 0.596431\n",
      "epoch 16; iter: 0; batch classifier loss: 0.338230; batch adversarial loss: 0.635721\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304876; batch adversarial loss: 0.617864\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356693; batch adversarial loss: 0.617001\n",
      "epoch 17; iter: 200; batch classifier loss: 0.394780; batch adversarial loss: 0.591912\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367717; batch adversarial loss: 0.604601\n",
      "epoch 18; iter: 200; batch classifier loss: 0.438167; batch adversarial loss: 0.674365\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355711; batch adversarial loss: 0.582674\n",
      "epoch 19; iter: 200; batch classifier loss: 0.386455; batch adversarial loss: 0.476201\n",
      "epoch 20; iter: 0; batch classifier loss: 0.328492; batch adversarial loss: 0.579458\n",
      "epoch 20; iter: 200; batch classifier loss: 0.311570; batch adversarial loss: 0.590945\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287279; batch adversarial loss: 0.652074\n",
      "epoch 21; iter: 200; batch classifier loss: 0.342884; batch adversarial loss: 0.637520\n",
      "epoch 22; iter: 0; batch classifier loss: 0.496595; batch adversarial loss: 0.575150\n",
      "epoch 22; iter: 200; batch classifier loss: 0.367223; batch adversarial loss: 0.656250\n",
      "epoch 23; iter: 0; batch classifier loss: 0.328955; batch adversarial loss: 0.557541\n",
      "epoch 23; iter: 200; batch classifier loss: 0.360562; batch adversarial loss: 0.669934\n",
      "epoch 24; iter: 0; batch classifier loss: 0.297704; batch adversarial loss: 0.584269\n",
      "epoch 24; iter: 200; batch classifier loss: 0.439966; batch adversarial loss: 0.594048\n",
      "epoch 25; iter: 0; batch classifier loss: 0.332436; batch adversarial loss: 0.571332\n",
      "epoch 25; iter: 200; batch classifier loss: 0.330923; batch adversarial loss: 0.538256\n",
      "epoch 26; iter: 0; batch classifier loss: 0.437941; batch adversarial loss: 0.638576\n",
      "epoch 26; iter: 200; batch classifier loss: 0.304396; batch adversarial loss: 0.626769\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274128; batch adversarial loss: 0.643060\n",
      "epoch 27; iter: 200; batch classifier loss: 0.289710; batch adversarial loss: 0.538951\n",
      "epoch 28; iter: 0; batch classifier loss: 0.391291; batch adversarial loss: 0.635650\n",
      "epoch 28; iter: 200; batch classifier loss: 0.388376; batch adversarial loss: 0.600958\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411931; batch adversarial loss: 0.560091\n",
      "epoch 29; iter: 200; batch classifier loss: 0.445557; batch adversarial loss: 0.627580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.295533; batch adversarial loss: 0.613052\n",
      "epoch 30; iter: 200; batch classifier loss: 0.380718; batch adversarial loss: 0.605567\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269008; batch adversarial loss: 0.625391\n",
      "epoch 31; iter: 200; batch classifier loss: 0.281921; batch adversarial loss: 0.639613\n",
      "epoch 32; iter: 0; batch classifier loss: 0.359039; batch adversarial loss: 0.584969\n",
      "epoch 32; iter: 200; batch classifier loss: 0.279200; batch adversarial loss: 0.613741\n",
      "epoch 33; iter: 0; batch classifier loss: 0.273106; batch adversarial loss: 0.641667\n",
      "epoch 33; iter: 200; batch classifier loss: 0.367308; batch adversarial loss: 0.678925\n",
      "epoch 34; iter: 0; batch classifier loss: 0.361543; batch adversarial loss: 0.603503\n",
      "epoch 34; iter: 200; batch classifier loss: 0.336978; batch adversarial loss: 0.646298\n",
      "epoch 35; iter: 0; batch classifier loss: 0.329237; batch adversarial loss: 0.681473\n",
      "epoch 35; iter: 200; batch classifier loss: 0.367979; batch adversarial loss: 0.638320\n",
      "epoch 36; iter: 0; batch classifier loss: 0.364314; batch adversarial loss: 0.593858\n",
      "epoch 36; iter: 200; batch classifier loss: 0.337295; batch adversarial loss: 0.585339\n",
      "epoch 37; iter: 0; batch classifier loss: 0.344323; batch adversarial loss: 0.684281\n",
      "epoch 37; iter: 200; batch classifier loss: 0.290465; batch adversarial loss: 0.658238\n",
      "epoch 38; iter: 0; batch classifier loss: 0.296828; batch adversarial loss: 0.581108\n",
      "epoch 38; iter: 200; batch classifier loss: 0.483794; batch adversarial loss: 0.642357\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382265; batch adversarial loss: 0.621579\n",
      "epoch 39; iter: 200; batch classifier loss: 0.378868; batch adversarial loss: 0.618886\n",
      "epoch 40; iter: 0; batch classifier loss: 0.359928; batch adversarial loss: 0.660345\n",
      "epoch 40; iter: 200; batch classifier loss: 0.305424; batch adversarial loss: 0.688734\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461576; batch adversarial loss: 0.633716\n",
      "epoch 41; iter: 200; batch classifier loss: 0.360130; batch adversarial loss: 0.699209\n",
      "epoch 42; iter: 0; batch classifier loss: 0.368524; batch adversarial loss: 0.618685\n",
      "epoch 42; iter: 200; batch classifier loss: 0.279186; batch adversarial loss: 0.651783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.405451; batch adversarial loss: 0.620723\n",
      "epoch 43; iter: 200; batch classifier loss: 0.387866; batch adversarial loss: 0.548738\n",
      "epoch 44; iter: 0; batch classifier loss: 0.351495; batch adversarial loss: 0.608236\n",
      "epoch 44; iter: 200; batch classifier loss: 0.359056; batch adversarial loss: 0.623727\n",
      "epoch 45; iter: 0; batch classifier loss: 0.303890; batch adversarial loss: 0.613227\n",
      "epoch 45; iter: 200; batch classifier loss: 0.275399; batch adversarial loss: 0.681021\n",
      "epoch 46; iter: 0; batch classifier loss: 0.202041; batch adversarial loss: 0.632745\n",
      "epoch 46; iter: 200; batch classifier loss: 0.374109; batch adversarial loss: 0.629464\n",
      "epoch 47; iter: 0; batch classifier loss: 0.315121; batch adversarial loss: 0.648415\n",
      "epoch 47; iter: 200; batch classifier loss: 0.321280; batch adversarial loss: 0.599740\n",
      "epoch 48; iter: 0; batch classifier loss: 0.383082; batch adversarial loss: 0.621072\n",
      "epoch 48; iter: 200; batch classifier loss: 0.340429; batch adversarial loss: 0.636886\n",
      "epoch 49; iter: 0; batch classifier loss: 0.352861; batch adversarial loss: 0.635253\n",
      "epoch 49; iter: 200; batch classifier loss: 0.338105; batch adversarial loss: 0.642442\n",
      "epoch 0; iter: 0; batch classifier loss: 17.420431; batch adversarial loss: 0.841391\n",
      "epoch 0; iter: 200; batch classifier loss: 4.900207; batch adversarial loss: 0.682376\n",
      "epoch 1; iter: 0; batch classifier loss: 11.943739; batch adversarial loss: 0.665999\n",
      "epoch 1; iter: 200; batch classifier loss: 9.842163; batch adversarial loss: 0.658283\n",
      "epoch 2; iter: 0; batch classifier loss: 17.746752; batch adversarial loss: 0.625355\n",
      "epoch 2; iter: 200; batch classifier loss: 2.233479; batch adversarial loss: 0.614156\n",
      "epoch 3; iter: 0; batch classifier loss: 2.796149; batch adversarial loss: 0.618940\n",
      "epoch 3; iter: 200; batch classifier loss: 1.124482; batch adversarial loss: 0.639747\n",
      "epoch 4; iter: 0; batch classifier loss: 6.147566; batch adversarial loss: 0.603361\n",
      "epoch 4; iter: 200; batch classifier loss: 1.520927; batch adversarial loss: 0.642576\n",
      "epoch 5; iter: 0; batch classifier loss: 1.536080; batch adversarial loss: 0.628225\n",
      "epoch 5; iter: 200; batch classifier loss: 0.557936; batch adversarial loss: 0.618018\n",
      "epoch 6; iter: 0; batch classifier loss: 0.493083; batch adversarial loss: 0.576413\n",
      "epoch 6; iter: 200; batch classifier loss: 0.430262; batch adversarial loss: 0.668864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523399; batch adversarial loss: 0.628627\n",
      "epoch 7; iter: 200; batch classifier loss: 0.446693; batch adversarial loss: 0.623055\n",
      "epoch 8; iter: 0; batch classifier loss: 1.042532; batch adversarial loss: 0.666095\n",
      "epoch 8; iter: 200; batch classifier loss: 0.474370; batch adversarial loss: 0.618376\n",
      "epoch 9; iter: 0; batch classifier loss: 0.613412; batch adversarial loss: 0.580357\n",
      "epoch 9; iter: 200; batch classifier loss: 0.446028; batch adversarial loss: 0.628787\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487520; batch adversarial loss: 0.607641\n",
      "epoch 10; iter: 200; batch classifier loss: 0.540527; batch adversarial loss: 0.639440\n",
      "epoch 11; iter: 0; batch classifier loss: 0.367976; batch adversarial loss: 0.679422\n",
      "epoch 11; iter: 200; batch classifier loss: 0.458869; batch adversarial loss: 0.634910\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500229; batch adversarial loss: 0.630065\n",
      "epoch 12; iter: 200; batch classifier loss: 0.520038; batch adversarial loss: 0.630706\n",
      "epoch 13; iter: 0; batch classifier loss: 0.373070; batch adversarial loss: 0.615766\n",
      "epoch 13; iter: 200; batch classifier loss: 0.576752; batch adversarial loss: 0.602667\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350045; batch adversarial loss: 0.574104\n",
      "epoch 14; iter: 200; batch classifier loss: 0.303405; batch adversarial loss: 0.635300\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401453; batch adversarial loss: 0.616245\n",
      "epoch 15; iter: 200; batch classifier loss: 0.426505; batch adversarial loss: 0.658497\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327400; batch adversarial loss: 0.621658\n",
      "epoch 16; iter: 200; batch classifier loss: 0.329469; batch adversarial loss: 0.613186\n",
      "epoch 17; iter: 0; batch classifier loss: 0.311187; batch adversarial loss: 0.559572\n",
      "epoch 17; iter: 200; batch classifier loss: 0.272169; batch adversarial loss: 0.621843\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437625; batch adversarial loss: 0.594762\n",
      "epoch 18; iter: 200; batch classifier loss: 0.229423; batch adversarial loss: 0.617975\n",
      "epoch 19; iter: 0; batch classifier loss: 0.314320; batch adversarial loss: 0.641739\n",
      "epoch 19; iter: 200; batch classifier loss: 0.336013; batch adversarial loss: 0.654188\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281205; batch adversarial loss: 0.606454\n",
      "epoch 20; iter: 200; batch classifier loss: 0.338164; batch adversarial loss: 0.583377\n",
      "epoch 21; iter: 0; batch classifier loss: 0.334581; batch adversarial loss: 0.567111\n",
      "epoch 21; iter: 200; batch classifier loss: 0.457148; batch adversarial loss: 0.615877\n",
      "epoch 22; iter: 0; batch classifier loss: 0.399667; batch adversarial loss: 0.573789\n",
      "epoch 22; iter: 200; batch classifier loss: 0.285073; batch adversarial loss: 0.565385\n",
      "epoch 23; iter: 0; batch classifier loss: 0.319389; batch adversarial loss: 0.663925\n",
      "epoch 23; iter: 200; batch classifier loss: 0.375039; batch adversarial loss: 0.603184\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340477; batch adversarial loss: 0.588062\n",
      "epoch 24; iter: 200; batch classifier loss: 0.282600; batch adversarial loss: 0.662085\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321986; batch adversarial loss: 0.637821\n",
      "epoch 25; iter: 200; batch classifier loss: 0.353577; batch adversarial loss: 0.690357\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296010; batch adversarial loss: 0.615445\n",
      "epoch 26; iter: 200; batch classifier loss: 0.286542; batch adversarial loss: 0.575487\n",
      "epoch 27; iter: 0; batch classifier loss: 0.305206; batch adversarial loss: 0.632226\n",
      "epoch 27; iter: 200; batch classifier loss: 0.384309; batch adversarial loss: 0.623402\n",
      "epoch 28; iter: 0; batch classifier loss: 0.255959; batch adversarial loss: 0.676543\n",
      "epoch 28; iter: 200; batch classifier loss: 0.360222; batch adversarial loss: 0.568990\n",
      "epoch 29; iter: 0; batch classifier loss: 0.307840; batch adversarial loss: 0.663036\n",
      "epoch 29; iter: 200; batch classifier loss: 0.411875; batch adversarial loss: 0.616958\n",
      "epoch 30; iter: 0; batch classifier loss: 0.289507; batch adversarial loss: 0.673362\n",
      "epoch 30; iter: 200; batch classifier loss: 0.351139; batch adversarial loss: 0.620917\n",
      "epoch 31; iter: 0; batch classifier loss: 0.306448; batch adversarial loss: 0.595676\n",
      "epoch 31; iter: 200; batch classifier loss: 0.315585; batch adversarial loss: 0.651942\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238571; batch adversarial loss: 0.608576\n",
      "epoch 32; iter: 200; batch classifier loss: 0.310685; batch adversarial loss: 0.592817\n",
      "epoch 33; iter: 0; batch classifier loss: 0.326783; batch adversarial loss: 0.614401\n",
      "epoch 33; iter: 200; batch classifier loss: 0.334005; batch adversarial loss: 0.612530\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252745; batch adversarial loss: 0.616431\n",
      "epoch 34; iter: 200; batch classifier loss: 0.307936; batch adversarial loss: 0.572408\n",
      "epoch 35; iter: 0; batch classifier loss: 0.278101; batch adversarial loss: 0.708459\n",
      "epoch 35; iter: 200; batch classifier loss: 0.337125; batch adversarial loss: 0.655665\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357039; batch adversarial loss: 0.676506\n",
      "epoch 36; iter: 200; batch classifier loss: 0.287400; batch adversarial loss: 0.579617\n",
      "epoch 37; iter: 0; batch classifier loss: 0.391918; batch adversarial loss: 0.581376\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341785; batch adversarial loss: 0.679968\n",
      "epoch 38; iter: 0; batch classifier loss: 0.345165; batch adversarial loss: 0.633088\n",
      "epoch 38; iter: 200; batch classifier loss: 0.375151; batch adversarial loss: 0.682299\n",
      "epoch 39; iter: 0; batch classifier loss: 0.393119; batch adversarial loss: 0.617428\n",
      "epoch 39; iter: 200; batch classifier loss: 0.252939; batch adversarial loss: 0.665673\n",
      "epoch 40; iter: 0; batch classifier loss: 0.376733; batch adversarial loss: 0.560752\n",
      "epoch 40; iter: 200; batch classifier loss: 0.341959; batch adversarial loss: 0.615764\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436104; batch adversarial loss: 0.650101\n",
      "epoch 41; iter: 200; batch classifier loss: 0.321948; batch adversarial loss: 0.698905\n",
      "epoch 42; iter: 0; batch classifier loss: 0.315777; batch adversarial loss: 0.603101\n",
      "epoch 42; iter: 200; batch classifier loss: 0.533912; batch adversarial loss: 0.675914\n",
      "epoch 43; iter: 0; batch classifier loss: 0.287726; batch adversarial loss: 0.592367\n",
      "epoch 43; iter: 200; batch classifier loss: 0.404951; batch adversarial loss: 0.633849\n",
      "epoch 44; iter: 0; batch classifier loss: 0.350922; batch adversarial loss: 0.601267\n",
      "epoch 44; iter: 200; batch classifier loss: 0.292758; batch adversarial loss: 0.630069\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434281; batch adversarial loss: 0.658415\n",
      "epoch 45; iter: 200; batch classifier loss: 0.403390; batch adversarial loss: 0.644988\n",
      "epoch 46; iter: 0; batch classifier loss: 0.273639; batch adversarial loss: 0.617409\n",
      "epoch 46; iter: 200; batch classifier loss: 0.298622; batch adversarial loss: 0.697680\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348356; batch adversarial loss: 0.655635\n",
      "epoch 47; iter: 200; batch classifier loss: 0.308405; batch adversarial loss: 0.580112\n",
      "epoch 48; iter: 0; batch classifier loss: 0.348964; batch adversarial loss: 0.588024\n",
      "epoch 48; iter: 200; batch classifier loss: 0.410241; batch adversarial loss: 0.594169\n",
      "epoch 49; iter: 0; batch classifier loss: 0.787003; batch adversarial loss: 0.629285\n",
      "epoch 49; iter: 200; batch classifier loss: 0.374388; batch adversarial loss: 0.641909\n",
      "epoch 0; iter: 0; batch classifier loss: 177.749069; batch adversarial loss: 0.738059\n",
      "epoch 0; iter: 200; batch classifier loss: 6.528188; batch adversarial loss: 0.667915\n",
      "epoch 1; iter: 0; batch classifier loss: 7.679792; batch adversarial loss: 0.641993\n",
      "epoch 1; iter: 200; batch classifier loss: 5.655957; batch adversarial loss: 0.656522\n",
      "epoch 2; iter: 0; batch classifier loss: 5.626473; batch adversarial loss: 0.615225\n",
      "epoch 2; iter: 200; batch classifier loss: 13.906877; batch adversarial loss: 0.636298\n",
      "epoch 3; iter: 0; batch classifier loss: 5.611698; batch adversarial loss: 0.623341\n",
      "epoch 3; iter: 200; batch classifier loss: 2.143428; batch adversarial loss: 0.653974\n",
      "epoch 4; iter: 0; batch classifier loss: 1.290687; batch adversarial loss: 0.646937\n",
      "epoch 4; iter: 200; batch classifier loss: 3.113389; batch adversarial loss: 0.583060\n",
      "epoch 5; iter: 0; batch classifier loss: 1.955333; batch adversarial loss: 0.631960\n",
      "epoch 5; iter: 200; batch classifier loss: 1.728664; batch adversarial loss: 0.638305\n",
      "epoch 6; iter: 0; batch classifier loss: 1.729345; batch adversarial loss: 0.605826\n",
      "epoch 6; iter: 200; batch classifier loss: 1.524784; batch adversarial loss: 0.592157\n",
      "epoch 7; iter: 0; batch classifier loss: 0.699271; batch adversarial loss: 0.693134\n",
      "epoch 7; iter: 200; batch classifier loss: 1.439721; batch adversarial loss: 0.619329\n",
      "epoch 8; iter: 0; batch classifier loss: 0.859515; batch adversarial loss: 0.650779\n",
      "epoch 8; iter: 200; batch classifier loss: 0.486174; batch adversarial loss: 0.645991\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517846; batch adversarial loss: 0.580812\n",
      "epoch 9; iter: 200; batch classifier loss: 0.509305; batch adversarial loss: 0.588516\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503198; batch adversarial loss: 0.613421\n",
      "epoch 10; iter: 200; batch classifier loss: 0.445041; batch adversarial loss: 0.633912\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492805; batch adversarial loss: 0.616028\n",
      "epoch 11; iter: 200; batch classifier loss: 0.360637; batch adversarial loss: 0.656479\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517300; batch adversarial loss: 0.612174\n",
      "epoch 12; iter: 200; batch classifier loss: 0.584567; batch adversarial loss: 0.686519\n",
      "epoch 13; iter: 0; batch classifier loss: 0.388286; batch adversarial loss: 0.672653\n",
      "epoch 13; iter: 200; batch classifier loss: 0.386826; batch adversarial loss: 0.575800\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345188; batch adversarial loss: 0.638020\n",
      "epoch 14; iter: 200; batch classifier loss: 0.345042; batch adversarial loss: 0.606076\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435414; batch adversarial loss: 0.612232\n",
      "epoch 15; iter: 200; batch classifier loss: 0.325046; batch adversarial loss: 0.540762\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371411; batch adversarial loss: 0.618871\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357563; batch adversarial loss: 0.616673\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382742; batch adversarial loss: 0.642846\n",
      "epoch 17; iter: 200; batch classifier loss: 0.319961; batch adversarial loss: 0.560955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308808; batch adversarial loss: 0.595296\n",
      "epoch 18; iter: 200; batch classifier loss: 0.353166; batch adversarial loss: 0.617684\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352930; batch adversarial loss: 0.570502\n",
      "epoch 19; iter: 200; batch classifier loss: 0.290812; batch adversarial loss: 0.578593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347595; batch adversarial loss: 0.585559\n",
      "epoch 20; iter: 200; batch classifier loss: 0.308106; batch adversarial loss: 0.622021\n",
      "epoch 21; iter: 0; batch classifier loss: 0.335858; batch adversarial loss: 0.604554\n",
      "epoch 21; iter: 200; batch classifier loss: 0.290231; batch adversarial loss: 0.583891\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411489; batch adversarial loss: 0.639924\n",
      "epoch 22; iter: 200; batch classifier loss: 0.354631; batch adversarial loss: 0.569093\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275964; batch adversarial loss: 0.682314\n",
      "epoch 23; iter: 200; batch classifier loss: 0.424995; batch adversarial loss: 0.647272\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329992; batch adversarial loss: 0.628633\n",
      "epoch 24; iter: 200; batch classifier loss: 0.367107; batch adversarial loss: 0.657009\n",
      "epoch 25; iter: 0; batch classifier loss: 0.336076; batch adversarial loss: 0.608339\n",
      "epoch 25; iter: 200; batch classifier loss: 0.435767; batch adversarial loss: 0.554467\n",
      "epoch 26; iter: 0; batch classifier loss: 0.365597; batch adversarial loss: 0.653519\n",
      "epoch 26; iter: 200; batch classifier loss: 0.303535; batch adversarial loss: 0.638608\n",
      "epoch 27; iter: 0; batch classifier loss: 0.319220; batch adversarial loss: 0.594238\n",
      "epoch 27; iter: 200; batch classifier loss: 0.390113; batch adversarial loss: 0.643012\n",
      "epoch 28; iter: 0; batch classifier loss: 0.268175; batch adversarial loss: 0.692916\n",
      "epoch 28; iter: 200; batch classifier loss: 0.398551; batch adversarial loss: 0.627115\n",
      "epoch 29; iter: 0; batch classifier loss: 0.329618; batch adversarial loss: 0.662945\n",
      "epoch 29; iter: 200; batch classifier loss: 0.325623; batch adversarial loss: 0.703366\n",
      "epoch 30; iter: 0; batch classifier loss: 0.302150; batch adversarial loss: 0.642384\n",
      "epoch 30; iter: 200; batch classifier loss: 0.393908; batch adversarial loss: 0.601605\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467223; batch adversarial loss: 0.635480\n",
      "epoch 31; iter: 200; batch classifier loss: 0.391273; batch adversarial loss: 0.599140\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318805; batch adversarial loss: 0.607776\n",
      "epoch 32; iter: 200; batch classifier loss: 0.326425; batch adversarial loss: 0.602773\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346229; batch adversarial loss: 0.622189\n",
      "epoch 33; iter: 200; batch classifier loss: 0.275602; batch adversarial loss: 0.629124\n",
      "epoch 34; iter: 0; batch classifier loss: 0.376857; batch adversarial loss: 0.588462\n",
      "epoch 34; iter: 200; batch classifier loss: 0.382922; batch adversarial loss: 0.686787\n",
      "epoch 35; iter: 0; batch classifier loss: 0.272679; batch adversarial loss: 0.616396\n",
      "epoch 35; iter: 200; batch classifier loss: 0.331844; batch adversarial loss: 0.626810\n",
      "epoch 36; iter: 0; batch classifier loss: 0.346661; batch adversarial loss: 0.565909\n",
      "epoch 36; iter: 200; batch classifier loss: 0.408545; batch adversarial loss: 0.583747\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421022; batch adversarial loss: 0.615299\n",
      "epoch 37; iter: 200; batch classifier loss: 0.362688; batch adversarial loss: 0.618341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440887; batch adversarial loss: 0.595680\n",
      "epoch 38; iter: 200; batch classifier loss: 0.336885; batch adversarial loss: 0.569542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.317009; batch adversarial loss: 0.557718\n",
      "epoch 39; iter: 200; batch classifier loss: 0.339303; batch adversarial loss: 0.624337\n",
      "epoch 40; iter: 0; batch classifier loss: 0.330852; batch adversarial loss: 0.643841\n",
      "epoch 40; iter: 200; batch classifier loss: 0.357623; batch adversarial loss: 0.671068\n",
      "epoch 41; iter: 0; batch classifier loss: 0.346523; batch adversarial loss: 0.650935\n",
      "epoch 41; iter: 200; batch classifier loss: 0.421852; batch adversarial loss: 0.636494\n",
      "epoch 42; iter: 0; batch classifier loss: 0.360164; batch adversarial loss: 0.644702\n",
      "epoch 42; iter: 200; batch classifier loss: 0.305530; batch adversarial loss: 0.623439\n",
      "epoch 43; iter: 0; batch classifier loss: 0.781512; batch adversarial loss: 0.630961\n",
      "epoch 43; iter: 200; batch classifier loss: 0.305274; batch adversarial loss: 0.615600\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267830; batch adversarial loss: 0.630963\n",
      "epoch 44; iter: 200; batch classifier loss: 0.307851; batch adversarial loss: 0.615952\n",
      "epoch 45; iter: 0; batch classifier loss: 0.416916; batch adversarial loss: 0.595863\n",
      "epoch 45; iter: 200; batch classifier loss: 0.405635; batch adversarial loss: 0.600875\n",
      "epoch 46; iter: 0; batch classifier loss: 0.323807; batch adversarial loss: 0.581665\n",
      "epoch 46; iter: 200; batch classifier loss: 0.367910; batch adversarial loss: 0.575501\n",
      "epoch 47; iter: 0; batch classifier loss: 0.321500; batch adversarial loss: 0.587692\n",
      "epoch 47; iter: 200; batch classifier loss: 0.389813; batch adversarial loss: 0.577658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.266826; batch adversarial loss: 0.593259\n",
      "epoch 48; iter: 200; batch classifier loss: 0.404360; batch adversarial loss: 0.677651\n",
      "epoch 49; iter: 0; batch classifier loss: 0.322566; batch adversarial loss: 0.664375\n",
      "epoch 49; iter: 200; batch classifier loss: 0.239445; batch adversarial loss: 0.649986\n",
      "epoch 0; iter: 0; batch classifier loss: 72.177780; batch adversarial loss: 0.680360\n",
      "epoch 0; iter: 200; batch classifier loss: 5.880959; batch adversarial loss: 0.649038\n",
      "epoch 1; iter: 0; batch classifier loss: 1.765370; batch adversarial loss: 0.585755\n",
      "epoch 1; iter: 200; batch classifier loss: 7.170951; batch adversarial loss: 0.635577\n",
      "epoch 2; iter: 0; batch classifier loss: 4.001846; batch adversarial loss: 0.671966\n",
      "epoch 2; iter: 200; batch classifier loss: 3.168310; batch adversarial loss: 0.605720\n",
      "epoch 3; iter: 0; batch classifier loss: 4.328062; batch adversarial loss: 0.670594\n",
      "epoch 3; iter: 200; batch classifier loss: 6.778654; batch adversarial loss: 0.639153\n",
      "epoch 4; iter: 0; batch classifier loss: 1.747769; batch adversarial loss: 0.636033\n",
      "epoch 4; iter: 200; batch classifier loss: 1.264459; batch adversarial loss: 0.563619\n",
      "epoch 5; iter: 0; batch classifier loss: 1.202755; batch adversarial loss: 0.612432\n",
      "epoch 5; iter: 200; batch classifier loss: 1.166186; batch adversarial loss: 0.647491\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487919; batch adversarial loss: 0.591582\n",
      "epoch 6; iter: 200; batch classifier loss: 0.659579; batch adversarial loss: 0.638834\n",
      "epoch 7; iter: 0; batch classifier loss: 1.192234; batch adversarial loss: 0.560683\n",
      "epoch 7; iter: 200; batch classifier loss: 0.427590; batch adversarial loss: 0.589703\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527876; batch adversarial loss: 0.549226\n",
      "epoch 8; iter: 200; batch classifier loss: 0.350537; batch adversarial loss: 0.633602\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407271; batch adversarial loss: 0.581574\n",
      "epoch 9; iter: 200; batch classifier loss: 0.870417; batch adversarial loss: 0.590374\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372730; batch adversarial loss: 0.635268\n",
      "epoch 10; iter: 200; batch classifier loss: 0.442609; batch adversarial loss: 0.644139\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430284; batch adversarial loss: 0.599253\n",
      "epoch 11; iter: 200; batch classifier loss: 0.324593; batch adversarial loss: 0.591426\n",
      "epoch 12; iter: 0; batch classifier loss: 0.278903; batch adversarial loss: 0.617679\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432753; batch adversarial loss: 0.613047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.286148; batch adversarial loss: 0.694804\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352431; batch adversarial loss: 0.584238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311321; batch adversarial loss: 0.626496\n",
      "epoch 14; iter: 200; batch classifier loss: 0.458426; batch adversarial loss: 0.616063\n",
      "epoch 15; iter: 0; batch classifier loss: 0.360588; batch adversarial loss: 0.640880\n",
      "epoch 15; iter: 200; batch classifier loss: 0.338712; batch adversarial loss: 0.575790\n",
      "epoch 16; iter: 0; batch classifier loss: 0.275293; batch adversarial loss: 0.594011\n",
      "epoch 16; iter: 200; batch classifier loss: 0.367431; batch adversarial loss: 0.653031\n",
      "epoch 17; iter: 0; batch classifier loss: 0.341052; batch adversarial loss: 0.589373\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343814; batch adversarial loss: 0.626280\n",
      "epoch 18; iter: 0; batch classifier loss: 0.392080; batch adversarial loss: 0.597291\n",
      "epoch 18; iter: 200; batch classifier loss: 0.307613; batch adversarial loss: 0.611638\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352375; batch adversarial loss: 0.639501\n",
      "epoch 19; iter: 200; batch classifier loss: 0.278283; batch adversarial loss: 0.648213\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333146; batch adversarial loss: 0.654568\n",
      "epoch 20; iter: 200; batch classifier loss: 0.264770; batch adversarial loss: 0.630486\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311164; batch adversarial loss: 0.600552\n",
      "epoch 21; iter: 200; batch classifier loss: 0.386469; batch adversarial loss: 0.606199\n",
      "epoch 22; iter: 0; batch classifier loss: 0.399588; batch adversarial loss: 0.568786\n",
      "epoch 22; iter: 200; batch classifier loss: 0.323291; batch adversarial loss: 0.617662\n",
      "epoch 23; iter: 0; batch classifier loss: 0.340457; batch adversarial loss: 0.579622\n",
      "epoch 23; iter: 200; batch classifier loss: 0.404421; batch adversarial loss: 0.561239\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329269; batch adversarial loss: 0.632986\n",
      "epoch 24; iter: 200; batch classifier loss: 0.495518; batch adversarial loss: 0.577928\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396362; batch adversarial loss: 0.576846\n",
      "epoch 25; iter: 200; batch classifier loss: 0.358172; batch adversarial loss: 0.628192\n",
      "epoch 26; iter: 0; batch classifier loss: 0.364428; batch adversarial loss: 0.612651\n",
      "epoch 26; iter: 200; batch classifier loss: 0.421063; batch adversarial loss: 0.514248\n",
      "epoch 27; iter: 0; batch classifier loss: 0.339818; batch adversarial loss: 0.628372\n",
      "epoch 27; iter: 200; batch classifier loss: 0.471617; batch adversarial loss: 0.620858\n",
      "epoch 28; iter: 0; batch classifier loss: 0.287631; batch adversarial loss: 0.603765\n",
      "epoch 28; iter: 200; batch classifier loss: 0.361036; batch adversarial loss: 0.661592\n",
      "epoch 29; iter: 0; batch classifier loss: 0.370583; batch adversarial loss: 0.651458\n",
      "epoch 29; iter: 200; batch classifier loss: 0.282712; batch adversarial loss: 0.636891\n",
      "epoch 30; iter: 0; batch classifier loss: 0.341639; batch adversarial loss: 0.627277\n",
      "epoch 30; iter: 200; batch classifier loss: 0.511652; batch adversarial loss: 0.577649\n",
      "epoch 31; iter: 0; batch classifier loss: 0.306365; batch adversarial loss: 0.644511\n",
      "epoch 31; iter: 200; batch classifier loss: 0.363436; batch adversarial loss: 0.667631\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309736; batch adversarial loss: 0.583561\n",
      "epoch 32; iter: 200; batch classifier loss: 0.362707; batch adversarial loss: 0.647367\n",
      "epoch 33; iter: 0; batch classifier loss: 0.302428; batch adversarial loss: 0.684820\n",
      "epoch 33; iter: 200; batch classifier loss: 0.373716; batch adversarial loss: 0.567726\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412069; batch adversarial loss: 0.618674\n",
      "epoch 34; iter: 200; batch classifier loss: 0.336041; batch adversarial loss: 0.571541\n",
      "epoch 35; iter: 0; batch classifier loss: 0.297362; batch adversarial loss: 0.656968\n",
      "epoch 35; iter: 200; batch classifier loss: 0.363283; batch adversarial loss: 0.678056\n",
      "epoch 36; iter: 0; batch classifier loss: 0.307257; batch adversarial loss: 0.628565\n",
      "epoch 36; iter: 200; batch classifier loss: 0.629995; batch adversarial loss: 0.668069\n",
      "epoch 37; iter: 0; batch classifier loss: 0.372593; batch adversarial loss: 0.588088\n",
      "epoch 37; iter: 200; batch classifier loss: 0.312172; batch adversarial loss: 0.613370\n",
      "epoch 38; iter: 0; batch classifier loss: 0.311721; batch adversarial loss: 0.675126\n",
      "epoch 38; iter: 200; batch classifier loss: 0.252172; batch adversarial loss: 0.639561\n",
      "epoch 39; iter: 0; batch classifier loss: 0.246190; batch adversarial loss: 0.652261\n",
      "epoch 39; iter: 200; batch classifier loss: 0.322973; batch adversarial loss: 0.680846\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390260; batch adversarial loss: 0.700168\n",
      "epoch 40; iter: 200; batch classifier loss: 0.229562; batch adversarial loss: 0.628494\n",
      "epoch 41; iter: 0; batch classifier loss: 0.275652; batch adversarial loss: 0.636871\n",
      "epoch 41; iter: 200; batch classifier loss: 0.404532; batch adversarial loss: 0.620490\n",
      "epoch 42; iter: 0; batch classifier loss: 0.248286; batch adversarial loss: 0.640605\n",
      "epoch 42; iter: 200; batch classifier loss: 0.302758; batch adversarial loss: 0.646014\n",
      "epoch 43; iter: 0; batch classifier loss: 0.349391; batch adversarial loss: 0.598163\n",
      "epoch 43; iter: 200; batch classifier loss: 0.329770; batch adversarial loss: 0.595635\n",
      "epoch 44; iter: 0; batch classifier loss: 0.296334; batch adversarial loss: 0.606389\n",
      "epoch 44; iter: 200; batch classifier loss: 0.366375; batch adversarial loss: 0.622742\n",
      "epoch 45; iter: 0; batch classifier loss: 0.439083; batch adversarial loss: 0.669196\n",
      "epoch 45; iter: 200; batch classifier loss: 0.337696; batch adversarial loss: 0.655889\n",
      "epoch 46; iter: 0; batch classifier loss: 0.359500; batch adversarial loss: 0.589019\n",
      "epoch 46; iter: 200; batch classifier loss: 0.368720; batch adversarial loss: 0.599156\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398995; batch adversarial loss: 0.598531\n",
      "epoch 47; iter: 200; batch classifier loss: 0.423958; batch adversarial loss: 0.630067\n",
      "epoch 48; iter: 0; batch classifier loss: 0.365827; batch adversarial loss: 0.578917\n",
      "epoch 48; iter: 200; batch classifier loss: 0.497943; batch adversarial loss: 0.596089\n",
      "epoch 49; iter: 0; batch classifier loss: 0.328501; batch adversarial loss: 0.644786\n",
      "epoch 49; iter: 200; batch classifier loss: 0.372899; batch adversarial loss: 0.592610\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.819928  0.518741  0.005795  1.061475  0.136122  0.080246\n",
      "std   0.022347  0.087100  0.026959  0.209031  0.068521  0.041824\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'sex'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','sex')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    "    scope_name='adv',           \n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.1)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate\n",
    "adult_sex_metrics = pd.DataFrame(results)\n",
    "adult_sex_metrics_agg = adult_sex_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae1c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', 'Default Adversial Debiasing Adult: Baseline - Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a28cb",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6be3258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 11.202388; batch adversarial loss: 0.645773\n",
      "epoch 0; iter: 200; batch classifier loss: 3.869604; batch adversarial loss: 0.546782\n",
      "epoch 0; iter: 400; batch classifier loss: 8.335328; batch adversarial loss: 0.527901\n",
      "epoch 0; iter: 600; batch classifier loss: 14.498314; batch adversarial loss: 0.507898\n",
      "epoch 1; iter: 0; batch classifier loss: 0.397023; batch adversarial loss: 0.491184\n",
      "epoch 1; iter: 200; batch classifier loss: 1.533347; batch adversarial loss: 0.438787\n",
      "epoch 1; iter: 400; batch classifier loss: 5.130083; batch adversarial loss: 0.422949\n",
      "epoch 1; iter: 600; batch classifier loss: 0.733338; batch adversarial loss: 0.467993\n",
      "epoch 2; iter: 0; batch classifier loss: 0.524937; batch adversarial loss: 0.401172\n",
      "epoch 2; iter: 200; batch classifier loss: 2.750088; batch adversarial loss: 0.440327\n",
      "epoch 2; iter: 400; batch classifier loss: 0.718974; batch adversarial loss: 0.468103\n",
      "epoch 2; iter: 600; batch classifier loss: 1.609058; batch adversarial loss: 0.350126\n",
      "epoch 3; iter: 0; batch classifier loss: 0.895206; batch adversarial loss: 0.402586\n",
      "epoch 3; iter: 200; batch classifier loss: 1.664740; batch adversarial loss: 0.328561\n",
      "epoch 3; iter: 400; batch classifier loss: 1.628411; batch adversarial loss: 0.396854\n",
      "epoch 3; iter: 600; batch classifier loss: 0.783436; batch adversarial loss: 0.328172\n",
      "epoch 4; iter: 0; batch classifier loss: 1.509154; batch adversarial loss: 0.353572\n",
      "epoch 4; iter: 200; batch classifier loss: 0.473428; batch adversarial loss: 0.282693\n",
      "epoch 4; iter: 400; batch classifier loss: 0.476567; batch adversarial loss: 0.395184\n",
      "epoch 4; iter: 600; batch classifier loss: 0.578521; batch adversarial loss: 0.329949\n",
      "epoch 5; iter: 0; batch classifier loss: 0.674226; batch adversarial loss: 0.397913\n",
      "epoch 5; iter: 200; batch classifier loss: 1.888179; batch adversarial loss: 0.422157\n",
      "epoch 5; iter: 400; batch classifier loss: 0.432531; batch adversarial loss: 0.498471\n",
      "epoch 5; iter: 600; batch classifier loss: 0.655451; batch adversarial loss: 0.439663\n",
      "epoch 6; iter: 0; batch classifier loss: 0.655646; batch adversarial loss: 0.432008\n",
      "epoch 6; iter: 200; batch classifier loss: 0.345146; batch adversarial loss: 0.522771\n",
      "epoch 6; iter: 400; batch classifier loss: 0.415495; batch adversarial loss: 0.413664\n",
      "epoch 6; iter: 600; batch classifier loss: 0.397327; batch adversarial loss: 0.552447\n",
      "epoch 7; iter: 0; batch classifier loss: 0.703845; batch adversarial loss: 0.484833\n",
      "epoch 7; iter: 200; batch classifier loss: 0.383288; batch adversarial loss: 0.386377\n",
      "epoch 7; iter: 400; batch classifier loss: 0.432538; batch adversarial loss: 0.408023\n",
      "epoch 7; iter: 600; batch classifier loss: 0.338659; batch adversarial loss: 0.385985\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552395; batch adversarial loss: 0.366501\n",
      "epoch 8; iter: 200; batch classifier loss: 0.592490; batch adversarial loss: 0.376578\n",
      "epoch 8; iter: 400; batch classifier loss: 0.370771; batch adversarial loss: 0.371764\n",
      "epoch 8; iter: 600; batch classifier loss: 0.273933; batch adversarial loss: 0.611392\n",
      "epoch 9; iter: 0; batch classifier loss: 0.282466; batch adversarial loss: 0.424310\n",
      "epoch 9; iter: 200; batch classifier loss: 0.327208; batch adversarial loss: 0.421898\n",
      "epoch 9; iter: 400; batch classifier loss: 0.515052; batch adversarial loss: 0.295983\n",
      "epoch 9; iter: 600; batch classifier loss: 0.305483; batch adversarial loss: 0.299180\n",
      "epoch 0; iter: 0; batch classifier loss: 10.356456; batch adversarial loss: 1.173660\n",
      "epoch 0; iter: 200; batch classifier loss: 13.932728; batch adversarial loss: 1.224287\n",
      "epoch 0; iter: 400; batch classifier loss: 3.677385; batch adversarial loss: 0.892081\n",
      "epoch 0; iter: 600; batch classifier loss: 5.276794; batch adversarial loss: 0.775017\n",
      "epoch 1; iter: 0; batch classifier loss: 2.932602; batch adversarial loss: 0.754992\n",
      "epoch 1; iter: 200; batch classifier loss: 3.305998; batch adversarial loss: 0.600417\n",
      "epoch 1; iter: 400; batch classifier loss: 5.415356; batch adversarial loss: 0.514119\n",
      "epoch 1; iter: 600; batch classifier loss: 5.153255; batch adversarial loss: 0.409999\n",
      "epoch 2; iter: 0; batch classifier loss: 1.713558; batch adversarial loss: 0.499026\n",
      "epoch 2; iter: 200; batch classifier loss: 1.222705; batch adversarial loss: 0.380857\n",
      "epoch 2; iter: 400; batch classifier loss: 3.468271; batch adversarial loss: 0.425287\n",
      "epoch 2; iter: 600; batch classifier loss: 2.424002; batch adversarial loss: 0.388297\n",
      "epoch 3; iter: 0; batch classifier loss: 1.433036; batch adversarial loss: 0.425839\n",
      "epoch 3; iter: 200; batch classifier loss: 16.568924; batch adversarial loss: 0.560103\n",
      "epoch 3; iter: 400; batch classifier loss: 3.931080; batch adversarial loss: 0.345862\n",
      "epoch 3; iter: 600; batch classifier loss: 0.592123; batch adversarial loss: 0.353981\n",
      "epoch 4; iter: 0; batch classifier loss: 0.720266; batch adversarial loss: 0.404444\n",
      "epoch 4; iter: 200; batch classifier loss: 1.107886; batch adversarial loss: 0.401826\n",
      "epoch 4; iter: 400; batch classifier loss: 1.471988; batch adversarial loss: 0.429301\n",
      "epoch 4; iter: 600; batch classifier loss: 0.636632; batch adversarial loss: 0.393073\n",
      "epoch 5; iter: 0; batch classifier loss: 0.787231; batch adversarial loss: 0.330263\n",
      "epoch 5; iter: 200; batch classifier loss: 0.573482; batch adversarial loss: 0.418973\n",
      "epoch 5; iter: 400; batch classifier loss: 1.082388; batch adversarial loss: 0.455425\n",
      "epoch 5; iter: 600; batch classifier loss: 1.150051; batch adversarial loss: 0.420920\n",
      "epoch 6; iter: 0; batch classifier loss: 0.517845; batch adversarial loss: 0.368132\n",
      "epoch 6; iter: 200; batch classifier loss: 0.870409; batch adversarial loss: 0.398757\n",
      "epoch 6; iter: 400; batch classifier loss: 0.434876; batch adversarial loss: 0.513451\n",
      "epoch 6; iter: 600; batch classifier loss: 0.464537; batch adversarial loss: 0.329431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489672; batch adversarial loss: 0.306893\n",
      "epoch 7; iter: 200; batch classifier loss: 0.308986; batch adversarial loss: 0.343758\n",
      "epoch 7; iter: 400; batch classifier loss: 1.279012; batch adversarial loss: 0.395874\n",
      "epoch 7; iter: 600; batch classifier loss: 0.538082; batch adversarial loss: 0.336036\n",
      "epoch 8; iter: 0; batch classifier loss: 0.413144; batch adversarial loss: 0.328896\n",
      "epoch 8; iter: 200; batch classifier loss: 0.429640; batch adversarial loss: 0.507754\n",
      "epoch 8; iter: 400; batch classifier loss: 0.334216; batch adversarial loss: 0.313356\n",
      "epoch 8; iter: 600; batch classifier loss: 0.310382; batch adversarial loss: 0.428084\n",
      "epoch 9; iter: 0; batch classifier loss: 0.360872; batch adversarial loss: 0.370454\n",
      "epoch 9; iter: 200; batch classifier loss: 0.481900; batch adversarial loss: 0.330034\n",
      "epoch 9; iter: 400; batch classifier loss: 0.327058; batch adversarial loss: 0.471651\n",
      "epoch 9; iter: 600; batch classifier loss: 0.543190; batch adversarial loss: 0.392468\n",
      "epoch 0; iter: 0; batch classifier loss: 3.489647; batch adversarial loss: 0.619461\n",
      "epoch 0; iter: 200; batch classifier loss: 39.005867; batch adversarial loss: 0.458706\n",
      "epoch 0; iter: 400; batch classifier loss: 27.201092; batch adversarial loss: 0.493249\n",
      "epoch 0; iter: 600; batch classifier loss: 15.741760; batch adversarial loss: 0.375446\n",
      "epoch 1; iter: 0; batch classifier loss: 1.151639; batch adversarial loss: 0.438039\n",
      "epoch 1; iter: 200; batch classifier loss: 16.466677; batch adversarial loss: 0.557653\n",
      "epoch 1; iter: 400; batch classifier loss: 10.466095; batch adversarial loss: 0.431173\n",
      "epoch 1; iter: 600; batch classifier loss: 3.226599; batch adversarial loss: 0.487313\n",
      "epoch 2; iter: 0; batch classifier loss: 11.309504; batch adversarial loss: 0.519873\n",
      "epoch 2; iter: 200; batch classifier loss: 11.412778; batch adversarial loss: 0.387536\n",
      "epoch 2; iter: 400; batch classifier loss: 6.692966; batch adversarial loss: 0.405343\n",
      "epoch 2; iter: 600; batch classifier loss: 0.981630; batch adversarial loss: 0.401585\n",
      "epoch 3; iter: 0; batch classifier loss: 1.812552; batch adversarial loss: 0.450764\n",
      "epoch 3; iter: 200; batch classifier loss: 3.704670; batch adversarial loss: 0.558057\n",
      "epoch 3; iter: 400; batch classifier loss: 1.790077; batch adversarial loss: 0.330228\n",
      "epoch 3; iter: 600; batch classifier loss: 0.370985; batch adversarial loss: 0.376437\n",
      "epoch 4; iter: 0; batch classifier loss: 0.563671; batch adversarial loss: 0.379021\n",
      "epoch 4; iter: 200; batch classifier loss: 1.595493; batch adversarial loss: 0.441206\n",
      "epoch 4; iter: 400; batch classifier loss: 0.832612; batch adversarial loss: 0.447494\n",
      "epoch 4; iter: 600; batch classifier loss: 0.457645; batch adversarial loss: 0.414577\n",
      "epoch 5; iter: 0; batch classifier loss: 0.885111; batch adversarial loss: 0.439393\n",
      "epoch 5; iter: 200; batch classifier loss: 0.488629; batch adversarial loss: 0.291874\n",
      "epoch 5; iter: 400; batch classifier loss: 0.669425; batch adversarial loss: 0.455695\n",
      "epoch 5; iter: 600; batch classifier loss: 0.354969; batch adversarial loss: 0.361652\n",
      "epoch 6; iter: 0; batch classifier loss: 0.773130; batch adversarial loss: 0.400938\n",
      "epoch 6; iter: 200; batch classifier loss: 0.252705; batch adversarial loss: 0.465233\n",
      "epoch 6; iter: 400; batch classifier loss: 0.457631; batch adversarial loss: 0.402673\n",
      "epoch 6; iter: 600; batch classifier loss: 0.270451; batch adversarial loss: 0.512815\n",
      "epoch 7; iter: 0; batch classifier loss: 0.475394; batch adversarial loss: 0.307486\n",
      "epoch 7; iter: 200; batch classifier loss: 0.399270; batch adversarial loss: 0.473573\n",
      "epoch 7; iter: 400; batch classifier loss: 0.432198; batch adversarial loss: 0.516030\n",
      "epoch 7; iter: 600; batch classifier loss: 0.356289; batch adversarial loss: 0.430732\n",
      "epoch 8; iter: 0; batch classifier loss: 0.369132; batch adversarial loss: 0.364489\n",
      "epoch 8; iter: 200; batch classifier loss: 0.462543; batch adversarial loss: 0.441818\n",
      "epoch 8; iter: 400; batch classifier loss: 0.429025; batch adversarial loss: 0.441532\n",
      "epoch 8; iter: 600; batch classifier loss: 0.358191; batch adversarial loss: 0.463025\n",
      "epoch 9; iter: 0; batch classifier loss: 0.310728; batch adversarial loss: 0.272780\n",
      "epoch 9; iter: 200; batch classifier loss: 0.359738; batch adversarial loss: 0.449021\n",
      "epoch 9; iter: 400; batch classifier loss: 0.319414; batch adversarial loss: 0.406049\n",
      "epoch 9; iter: 600; batch classifier loss: 0.364599; batch adversarial loss: 0.492076\n",
      "epoch 0; iter: 0; batch classifier loss: 11.580147; batch adversarial loss: 0.573259\n",
      "epoch 0; iter: 200; batch classifier loss: 0.722412; batch adversarial loss: 0.530641\n",
      "epoch 0; iter: 400; batch classifier loss: 1.931614; batch adversarial loss: 0.535484\n",
      "epoch 0; iter: 600; batch classifier loss: 9.136814; batch adversarial loss: 0.539299\n",
      "epoch 1; iter: 0; batch classifier loss: 8.242588; batch adversarial loss: 0.476699\n",
      "epoch 1; iter: 200; batch classifier loss: 0.403641; batch adversarial loss: 0.461405\n",
      "epoch 1; iter: 400; batch classifier loss: 3.769832; batch adversarial loss: 0.449870\n",
      "epoch 1; iter: 600; batch classifier loss: 0.848625; batch adversarial loss: 0.402909\n",
      "epoch 2; iter: 0; batch classifier loss: 0.944480; batch adversarial loss: 0.376830\n",
      "epoch 2; iter: 200; batch classifier loss: 5.145797; batch adversarial loss: 0.337831\n",
      "epoch 2; iter: 400; batch classifier loss: 0.621913; batch adversarial loss: 0.523602\n",
      "epoch 2; iter: 600; batch classifier loss: 1.520891; batch adversarial loss: 0.388937\n",
      "epoch 3; iter: 0; batch classifier loss: 1.127582; batch adversarial loss: 0.521801\n",
      "epoch 3; iter: 200; batch classifier loss: 2.228079; batch adversarial loss: 0.508364\n",
      "epoch 3; iter: 400; batch classifier loss: 0.533264; batch adversarial loss: 0.381356\n",
      "epoch 3; iter: 600; batch classifier loss: 0.662605; batch adversarial loss: 0.471644\n",
      "epoch 4; iter: 0; batch classifier loss: 0.799837; batch adversarial loss: 0.470497\n",
      "epoch 4; iter: 200; batch classifier loss: 0.847807; batch adversarial loss: 0.371454\n",
      "epoch 4; iter: 400; batch classifier loss: 0.668687; batch adversarial loss: 0.406062\n",
      "epoch 4; iter: 600; batch classifier loss: 0.451154; batch adversarial loss: 0.562536\n",
      "epoch 5; iter: 0; batch classifier loss: 0.972928; batch adversarial loss: 0.459962\n",
      "epoch 5; iter: 200; batch classifier loss: 0.289475; batch adversarial loss: 0.441444\n",
      "epoch 5; iter: 400; batch classifier loss: 0.679979; batch adversarial loss: 0.451916\n",
      "epoch 5; iter: 600; batch classifier loss: 0.608802; batch adversarial loss: 0.371824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584373; batch adversarial loss: 0.490239\n",
      "epoch 6; iter: 200; batch classifier loss: 0.564445; batch adversarial loss: 0.351836\n",
      "epoch 6; iter: 400; batch classifier loss: 0.490741; batch adversarial loss: 0.644054\n",
      "epoch 6; iter: 600; batch classifier loss: 0.492310; batch adversarial loss: 0.319189\n",
      "epoch 7; iter: 0; batch classifier loss: 0.315530; batch adversarial loss: 0.366503\n",
      "epoch 7; iter: 200; batch classifier loss: 0.395519; batch adversarial loss: 0.394099\n",
      "epoch 7; iter: 400; batch classifier loss: 0.363002; batch adversarial loss: 0.394563\n",
      "epoch 7; iter: 600; batch classifier loss: 0.448731; batch adversarial loss: 0.411634\n",
      "epoch 8; iter: 0; batch classifier loss: 0.405972; batch adversarial loss: 0.463120\n",
      "epoch 8; iter: 200; batch classifier loss: 0.286289; batch adversarial loss: 0.445288\n",
      "epoch 8; iter: 400; batch classifier loss: 0.511141; batch adversarial loss: 0.508559\n",
      "epoch 8; iter: 600; batch classifier loss: 0.352875; batch adversarial loss: 0.426577\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436162; batch adversarial loss: 0.514533\n",
      "epoch 9; iter: 200; batch classifier loss: 0.229925; batch adversarial loss: 0.399873\n",
      "epoch 9; iter: 400; batch classifier loss: 0.347732; batch adversarial loss: 0.376237\n",
      "epoch 9; iter: 600; batch classifier loss: 0.355453; batch adversarial loss: 0.455608\n",
      "epoch 0; iter: 0; batch classifier loss: 351.661774; batch adversarial loss: 0.613963\n",
      "epoch 0; iter: 200; batch classifier loss: 13.307378; batch adversarial loss: 0.602613\n",
      "epoch 0; iter: 400; batch classifier loss: 1.187641; batch adversarial loss: 0.546327\n",
      "epoch 0; iter: 600; batch classifier loss: 12.114004; batch adversarial loss: 0.476251\n",
      "epoch 1; iter: 0; batch classifier loss: 7.157213; batch adversarial loss: 0.437029\n",
      "epoch 1; iter: 200; batch classifier loss: 1.494517; batch adversarial loss: 0.506352\n",
      "epoch 1; iter: 400; batch classifier loss: 2.229463; batch adversarial loss: 0.533893\n",
      "epoch 1; iter: 600; batch classifier loss: 2.915258; batch adversarial loss: 0.481578\n",
      "epoch 2; iter: 0; batch classifier loss: 8.759470; batch adversarial loss: 0.452429\n",
      "epoch 2; iter: 200; batch classifier loss: 0.471675; batch adversarial loss: 0.480960\n",
      "epoch 2; iter: 400; batch classifier loss: 3.246279; batch adversarial loss: 0.472090\n",
      "epoch 2; iter: 600; batch classifier loss: 2.299001; batch adversarial loss: 0.380626\n",
      "epoch 3; iter: 0; batch classifier loss: 1.362383; batch adversarial loss: 0.453390\n",
      "epoch 3; iter: 200; batch classifier loss: 0.638581; batch adversarial loss: 0.371933\n",
      "epoch 3; iter: 400; batch classifier loss: 1.438080; batch adversarial loss: 0.318546\n",
      "epoch 3; iter: 600; batch classifier loss: 1.813081; batch adversarial loss: 0.409061\n",
      "epoch 4; iter: 0; batch classifier loss: 2.704803; batch adversarial loss: 0.431619\n",
      "epoch 4; iter: 200; batch classifier loss: 0.696766; batch adversarial loss: 0.432654\n",
      "epoch 4; iter: 400; batch classifier loss: 0.919480; batch adversarial loss: 0.353141\n",
      "epoch 4; iter: 600; batch classifier loss: 0.378910; batch adversarial loss: 0.357063\n",
      "epoch 5; iter: 0; batch classifier loss: 0.679849; batch adversarial loss: 0.517087\n",
      "epoch 5; iter: 200; batch classifier loss: 0.542406; batch adversarial loss: 0.396609\n",
      "epoch 5; iter: 400; batch classifier loss: 1.036442; batch adversarial loss: 0.341514\n",
      "epoch 5; iter: 600; batch classifier loss: 0.423915; batch adversarial loss: 0.412647\n",
      "epoch 6; iter: 0; batch classifier loss: 0.711319; batch adversarial loss: 0.447776\n",
      "epoch 6; iter: 200; batch classifier loss: 0.652829; batch adversarial loss: 0.454858\n",
      "epoch 6; iter: 400; batch classifier loss: 0.491930; batch adversarial loss: 0.483575\n",
      "epoch 6; iter: 600; batch classifier loss: 0.383771; batch adversarial loss: 0.387975\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574054; batch adversarial loss: 0.436798\n",
      "epoch 7; iter: 200; batch classifier loss: 0.441819; batch adversarial loss: 0.391218\n",
      "epoch 7; iter: 400; batch classifier loss: 0.434897; batch adversarial loss: 0.519861\n",
      "epoch 7; iter: 600; batch classifier loss: 0.446353; batch adversarial loss: 0.419637\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579399; batch adversarial loss: 0.287464\n",
      "epoch 8; iter: 200; batch classifier loss: 0.369505; batch adversarial loss: 0.445673\n",
      "epoch 8; iter: 400; batch classifier loss: 0.406159; batch adversarial loss: 0.266312\n",
      "epoch 8; iter: 600; batch classifier loss: 0.337890; batch adversarial loss: 0.471224\n",
      "epoch 9; iter: 0; batch classifier loss: 0.352794; batch adversarial loss: 0.408568\n",
      "epoch 9; iter: 200; batch classifier loss: 0.371038; batch adversarial loss: 0.457549\n",
      "epoch 9; iter: 400; batch classifier loss: 0.222897; batch adversarial loss: 0.404231\n",
      "epoch 9; iter: 600; batch classifier loss: 0.382748; batch adversarial loss: 0.398272\n",
      "epoch 0; iter: 0; batch classifier loss: 25.467381; batch adversarial loss: 0.560094\n",
      "epoch 0; iter: 200; batch classifier loss: 3.793617; batch adversarial loss: 0.602879\n",
      "epoch 0; iter: 400; batch classifier loss: 2.459343; batch adversarial loss: 0.570338\n",
      "epoch 0; iter: 600; batch classifier loss: 3.523593; batch adversarial loss: 0.500968\n",
      "epoch 1; iter: 0; batch classifier loss: 1.345726; batch adversarial loss: 0.556064\n",
      "epoch 1; iter: 200; batch classifier loss: 4.840116; batch adversarial loss: 0.473296\n",
      "epoch 1; iter: 400; batch classifier loss: 9.429445; batch adversarial loss: 0.394506\n",
      "epoch 1; iter: 600; batch classifier loss: 2.285051; batch adversarial loss: 0.408547\n",
      "epoch 2; iter: 0; batch classifier loss: 5.945952; batch adversarial loss: 0.421866\n",
      "epoch 2; iter: 200; batch classifier loss: 4.944756; batch adversarial loss: 0.404422\n",
      "epoch 2; iter: 400; batch classifier loss: 1.523691; batch adversarial loss: 0.424315\n",
      "epoch 2; iter: 600; batch classifier loss: 0.386706; batch adversarial loss: 0.362309\n",
      "epoch 3; iter: 0; batch classifier loss: 2.186903; batch adversarial loss: 0.390361\n",
      "epoch 3; iter: 200; batch classifier loss: 5.876063; batch adversarial loss: 0.332008\n",
      "epoch 3; iter: 400; batch classifier loss: 2.385482; batch adversarial loss: 0.468218\n",
      "epoch 3; iter: 600; batch classifier loss: 0.920262; batch adversarial loss: 0.484162\n",
      "epoch 4; iter: 0; batch classifier loss: 6.371510; batch adversarial loss: 0.333888\n",
      "epoch 4; iter: 200; batch classifier loss: 2.295195; batch adversarial loss: 0.501489\n",
      "epoch 4; iter: 400; batch classifier loss: 1.141241; batch adversarial loss: 0.526314\n",
      "epoch 4; iter: 600; batch classifier loss: 0.749129; batch adversarial loss: 0.482838\n",
      "epoch 5; iter: 0; batch classifier loss: 0.503870; batch adversarial loss: 0.358657\n",
      "epoch 5; iter: 200; batch classifier loss: 5.278937; batch adversarial loss: 0.475310\n",
      "epoch 5; iter: 400; batch classifier loss: 0.444470; batch adversarial loss: 0.420794\n",
      "epoch 5; iter: 600; batch classifier loss: 0.485998; batch adversarial loss: 0.389614\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563340; batch adversarial loss: 0.562231\n",
      "epoch 6; iter: 200; batch classifier loss: 0.524387; batch adversarial loss: 0.478607\n",
      "epoch 6; iter: 400; batch classifier loss: 0.363375; batch adversarial loss: 0.417347\n",
      "epoch 6; iter: 600; batch classifier loss: 0.473886; batch adversarial loss: 0.379890\n",
      "epoch 7; iter: 0; batch classifier loss: 0.685012; batch adversarial loss: 0.404390\n",
      "epoch 7; iter: 200; batch classifier loss: 0.520461; batch adversarial loss: 0.358463\n",
      "epoch 7; iter: 400; batch classifier loss: 0.490882; batch adversarial loss: 0.407932\n",
      "epoch 7; iter: 600; batch classifier loss: 0.359222; batch adversarial loss: 0.401609\n",
      "epoch 8; iter: 0; batch classifier loss: 0.359626; batch adversarial loss: 0.210507\n",
      "epoch 8; iter: 200; batch classifier loss: 0.266907; batch adversarial loss: 0.352414\n",
      "epoch 8; iter: 400; batch classifier loss: 0.346999; batch adversarial loss: 0.419603\n",
      "epoch 8; iter: 600; batch classifier loss: 0.502794; batch adversarial loss: 0.293438\n",
      "epoch 9; iter: 0; batch classifier loss: 0.655951; batch adversarial loss: 0.349206\n",
      "epoch 9; iter: 200; batch classifier loss: 0.332867; batch adversarial loss: 0.412731\n",
      "epoch 9; iter: 400; batch classifier loss: 0.313648; batch adversarial loss: 0.549432\n",
      "epoch 9; iter: 600; batch classifier loss: 0.329227; batch adversarial loss: 0.429692\n",
      "epoch 0; iter: 0; batch classifier loss: 19.974159; batch adversarial loss: 0.846554\n",
      "epoch 0; iter: 200; batch classifier loss: 8.066474; batch adversarial loss: 0.727417\n",
      "epoch 0; iter: 400; batch classifier loss: 3.201744; batch adversarial loss: 0.557132\n",
      "epoch 0; iter: 600; batch classifier loss: 3.143005; batch adversarial loss: 0.535374\n",
      "epoch 1; iter: 0; batch classifier loss: 1.594782; batch adversarial loss: 0.539323\n",
      "epoch 1; iter: 200; batch classifier loss: 0.875142; batch adversarial loss: 0.446123\n",
      "epoch 1; iter: 400; batch classifier loss: 4.680376; batch adversarial loss: 0.441670\n",
      "epoch 1; iter: 600; batch classifier loss: 2.046624; batch adversarial loss: 0.486445\n",
      "epoch 2; iter: 0; batch classifier loss: 1.410022; batch adversarial loss: 0.463736\n",
      "epoch 2; iter: 200; batch classifier loss: 0.460011; batch adversarial loss: 0.508886\n",
      "epoch 2; iter: 400; batch classifier loss: 1.884626; batch adversarial loss: 0.412576\n",
      "epoch 2; iter: 600; batch classifier loss: 1.779576; batch adversarial loss: 0.504864\n",
      "epoch 3; iter: 0; batch classifier loss: 1.402772; batch adversarial loss: 0.477222\n",
      "epoch 3; iter: 200; batch classifier loss: 1.103804; batch adversarial loss: 0.477127\n",
      "epoch 3; iter: 400; batch classifier loss: 1.103922; batch adversarial loss: 0.505349\n",
      "epoch 3; iter: 600; batch classifier loss: 0.571643; batch adversarial loss: 0.483135\n",
      "epoch 4; iter: 0; batch classifier loss: 3.740425; batch adversarial loss: 0.373127\n",
      "epoch 4; iter: 200; batch classifier loss: 2.428296; batch adversarial loss: 0.575221\n",
      "epoch 4; iter: 400; batch classifier loss: 0.512727; batch adversarial loss: 0.601672\n",
      "epoch 4; iter: 600; batch classifier loss: 0.497351; batch adversarial loss: 0.682371\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489644; batch adversarial loss: 0.328024\n",
      "epoch 5; iter: 200; batch classifier loss: 0.536614; batch adversarial loss: 0.558279\n",
      "epoch 5; iter: 400; batch classifier loss: 0.466409; batch adversarial loss: 0.379387\n",
      "epoch 5; iter: 600; batch classifier loss: 0.454410; batch adversarial loss: 0.376245\n",
      "epoch 6; iter: 0; batch classifier loss: 0.415086; batch adversarial loss: 0.329085\n",
      "epoch 6; iter: 200; batch classifier loss: 0.528397; batch adversarial loss: 0.507779\n",
      "epoch 6; iter: 400; batch classifier loss: 0.486794; batch adversarial loss: 0.488597\n",
      "epoch 6; iter: 600; batch classifier loss: 0.397197; batch adversarial loss: 0.353071\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581998; batch adversarial loss: 0.446039\n",
      "epoch 7; iter: 200; batch classifier loss: 0.507505; batch adversarial loss: 0.476190\n",
      "epoch 7; iter: 400; batch classifier loss: 0.318817; batch adversarial loss: 0.432916\n",
      "epoch 7; iter: 600; batch classifier loss: 0.418268; batch adversarial loss: 0.440395\n",
      "epoch 8; iter: 0; batch classifier loss: 0.395194; batch adversarial loss: 0.366335\n",
      "epoch 8; iter: 200; batch classifier loss: 0.342584; batch adversarial loss: 0.589857\n",
      "epoch 8; iter: 400; batch classifier loss: 0.352521; batch adversarial loss: 0.378856\n",
      "epoch 8; iter: 600; batch classifier loss: 0.292998; batch adversarial loss: 0.510220\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383369; batch adversarial loss: 0.432451\n",
      "epoch 9; iter: 200; batch classifier loss: 0.360110; batch adversarial loss: 0.351041\n",
      "epoch 9; iter: 400; batch classifier loss: 0.373598; batch adversarial loss: 0.461857\n",
      "epoch 9; iter: 600; batch classifier loss: 0.326537; batch adversarial loss: 0.372277\n",
      "epoch 0; iter: 0; batch classifier loss: 158.133545; batch adversarial loss: 0.579714\n",
      "epoch 0; iter: 200; batch classifier loss: 1.770334; batch adversarial loss: 0.632461\n",
      "epoch 0; iter: 400; batch classifier loss: 9.256865; batch adversarial loss: 0.547716\n",
      "epoch 0; iter: 600; batch classifier loss: 1.735544; batch adversarial loss: 0.510599\n",
      "epoch 1; iter: 0; batch classifier loss: 4.139011; batch adversarial loss: 0.471861\n",
      "epoch 1; iter: 200; batch classifier loss: 10.070330; batch adversarial loss: 0.523886\n",
      "epoch 1; iter: 400; batch classifier loss: 4.564511; batch adversarial loss: 0.487970\n",
      "epoch 1; iter: 600; batch classifier loss: 10.953654; batch adversarial loss: 0.447230\n",
      "epoch 2; iter: 0; batch classifier loss: 0.535966; batch adversarial loss: 0.393374\n",
      "epoch 2; iter: 200; batch classifier loss: 5.262248; batch adversarial loss: 0.370705\n",
      "epoch 2; iter: 400; batch classifier loss: 1.301414; batch adversarial loss: 0.491776\n",
      "epoch 2; iter: 600; batch classifier loss: 3.698399; batch adversarial loss: 0.527299\n",
      "epoch 3; iter: 0; batch classifier loss: 1.955823; batch adversarial loss: 0.388858\n",
      "epoch 3; iter: 200; batch classifier loss: 2.645100; batch adversarial loss: 0.460755\n",
      "epoch 3; iter: 400; batch classifier loss: 1.569754; batch adversarial loss: 0.375361\n",
      "epoch 3; iter: 600; batch classifier loss: 1.329419; batch adversarial loss: 0.418786\n",
      "epoch 4; iter: 0; batch classifier loss: 1.012314; batch adversarial loss: 0.280694\n",
      "epoch 4; iter: 200; batch classifier loss: 0.318071; batch adversarial loss: 0.437114\n",
      "epoch 4; iter: 400; batch classifier loss: 0.365853; batch adversarial loss: 0.426166\n",
      "epoch 4; iter: 600; batch classifier loss: 0.548825; batch adversarial loss: 0.513169\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515538; batch adversarial loss: 0.433764\n",
      "epoch 5; iter: 200; batch classifier loss: 0.375945; batch adversarial loss: 0.338629\n",
      "epoch 5; iter: 400; batch classifier loss: 0.572066; batch adversarial loss: 0.314881\n",
      "epoch 5; iter: 600; batch classifier loss: 0.467710; batch adversarial loss: 0.460741\n",
      "epoch 6; iter: 0; batch classifier loss: 0.479360; batch adversarial loss: 0.381284\n",
      "epoch 6; iter: 200; batch classifier loss: 0.375178; batch adversarial loss: 0.292416\n",
      "epoch 6; iter: 400; batch classifier loss: 0.433668; batch adversarial loss: 0.251552\n",
      "epoch 6; iter: 600; batch classifier loss: 0.431165; batch adversarial loss: 0.436880\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405926; batch adversarial loss: 0.294692\n",
      "epoch 7; iter: 200; batch classifier loss: 0.396742; batch adversarial loss: 0.394721\n",
      "epoch 7; iter: 400; batch classifier loss: 0.325421; batch adversarial loss: 0.305314\n",
      "epoch 7; iter: 600; batch classifier loss: 0.280063; batch adversarial loss: 0.338264\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479542; batch adversarial loss: 0.432221\n",
      "epoch 8; iter: 200; batch classifier loss: 0.349013; batch adversarial loss: 0.398705\n",
      "epoch 8; iter: 400; batch classifier loss: 0.381441; batch adversarial loss: 0.446476\n",
      "epoch 8; iter: 600; batch classifier loss: 0.418464; batch adversarial loss: 0.448667\n",
      "epoch 9; iter: 0; batch classifier loss: 0.413564; batch adversarial loss: 0.322871\n",
      "epoch 9; iter: 200; batch classifier loss: 0.316717; batch adversarial loss: 0.398378\n",
      "epoch 9; iter: 400; batch classifier loss: 0.316236; batch adversarial loss: 0.455883\n",
      "epoch 9; iter: 600; batch classifier loss: 0.387063; batch adversarial loss: 0.417548\n",
      "epoch 0; iter: 0; batch classifier loss: 5.665215; batch adversarial loss: 0.548522\n",
      "epoch 0; iter: 200; batch classifier loss: 31.717550; batch adversarial loss: 0.603523\n",
      "epoch 0; iter: 400; batch classifier loss: 12.742768; batch adversarial loss: 0.508581\n",
      "epoch 0; iter: 600; batch classifier loss: 4.182702; batch adversarial loss: 0.478169\n",
      "epoch 1; iter: 0; batch classifier loss: 6.260979; batch adversarial loss: 0.484692\n",
      "epoch 1; iter: 200; batch classifier loss: 5.279236; batch adversarial loss: 0.595452\n",
      "epoch 1; iter: 400; batch classifier loss: 6.920543; batch adversarial loss: 0.432239\n",
      "epoch 1; iter: 600; batch classifier loss: 1.373560; batch adversarial loss: 0.536181\n",
      "epoch 2; iter: 0; batch classifier loss: 1.351946; batch adversarial loss: 0.438801\n",
      "epoch 2; iter: 200; batch classifier loss: 5.360441; batch adversarial loss: 0.468163\n",
      "epoch 2; iter: 400; batch classifier loss: 2.044693; batch adversarial loss: 0.449331\n",
      "epoch 2; iter: 600; batch classifier loss: 0.871180; batch adversarial loss: 0.429614\n",
      "epoch 3; iter: 0; batch classifier loss: 1.874155; batch adversarial loss: 0.449238\n",
      "epoch 3; iter: 200; batch classifier loss: 1.613759; batch adversarial loss: 0.353293\n",
      "epoch 3; iter: 400; batch classifier loss: 2.061743; batch adversarial loss: 0.567116\n",
      "epoch 3; iter: 600; batch classifier loss: 0.286425; batch adversarial loss: 0.421038\n",
      "epoch 4; iter: 0; batch classifier loss: 1.291213; batch adversarial loss: 0.459765\n",
      "epoch 4; iter: 200; batch classifier loss: 0.785046; batch adversarial loss: 0.375590\n",
      "epoch 4; iter: 400; batch classifier loss: 1.690163; batch adversarial loss: 0.304688\n",
      "epoch 4; iter: 600; batch classifier loss: 0.592903; batch adversarial loss: 0.378137\n",
      "epoch 5; iter: 0; batch classifier loss: 0.408278; batch adversarial loss: 0.486342\n",
      "epoch 5; iter: 200; batch classifier loss: 0.521826; batch adversarial loss: 0.472658\n",
      "epoch 5; iter: 400; batch classifier loss: 0.790376; batch adversarial loss: 0.408304\n",
      "epoch 5; iter: 600; batch classifier loss: 0.354941; batch adversarial loss: 0.486873\n",
      "epoch 6; iter: 0; batch classifier loss: 0.442479; batch adversarial loss: 0.407863\n",
      "epoch 6; iter: 200; batch classifier loss: 0.471067; batch adversarial loss: 0.419303\n",
      "epoch 6; iter: 400; batch classifier loss: 0.487795; batch adversarial loss: 0.381139\n",
      "epoch 6; iter: 600; batch classifier loss: 0.801902; batch adversarial loss: 0.480656\n",
      "epoch 7; iter: 0; batch classifier loss: 0.396164; batch adversarial loss: 0.434107\n",
      "epoch 7; iter: 200; batch classifier loss: 0.372564; batch adversarial loss: 0.462553\n",
      "epoch 7; iter: 400; batch classifier loss: 0.332582; batch adversarial loss: 0.579499\n",
      "epoch 7; iter: 600; batch classifier loss: 0.469363; batch adversarial loss: 0.388875\n",
      "epoch 8; iter: 0; batch classifier loss: 0.341340; batch adversarial loss: 0.384726\n",
      "epoch 8; iter: 200; batch classifier loss: 0.334149; batch adversarial loss: 0.549172\n",
      "epoch 8; iter: 400; batch classifier loss: 0.356811; batch adversarial loss: 0.350874\n",
      "epoch 8; iter: 600; batch classifier loss: 0.486669; batch adversarial loss: 0.278242\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354254; batch adversarial loss: 0.606426\n",
      "epoch 9; iter: 200; batch classifier loss: 0.285263; batch adversarial loss: 0.267133\n",
      "epoch 9; iter: 400; batch classifier loss: 0.277399; batch adversarial loss: 0.348042\n",
      "epoch 9; iter: 600; batch classifier loss: 0.384479; batch adversarial loss: 0.450026\n",
      "epoch 0; iter: 0; batch classifier loss: 230.057663; batch adversarial loss: 0.767614\n",
      "epoch 0; iter: 200; batch classifier loss: 14.175022; batch adversarial loss: 0.683049\n",
      "epoch 0; iter: 400; batch classifier loss: 3.767056; batch adversarial loss: 0.659725\n",
      "epoch 0; iter: 600; batch classifier loss: 6.724542; batch adversarial loss: 0.608545\n",
      "epoch 1; iter: 0; batch classifier loss: 1.504582; batch adversarial loss: 0.537101\n",
      "epoch 1; iter: 200; batch classifier loss: 0.973211; batch adversarial loss: 0.479833\n",
      "epoch 1; iter: 400; batch classifier loss: 1.806441; batch adversarial loss: 0.519621\n",
      "epoch 1; iter: 600; batch classifier loss: 1.414623; batch adversarial loss: 0.516659\n",
      "epoch 2; iter: 0; batch classifier loss: 11.993877; batch adversarial loss: 0.492874\n",
      "epoch 2; iter: 200; batch classifier loss: 0.726388; batch adversarial loss: 0.400374\n",
      "epoch 2; iter: 400; batch classifier loss: 4.325091; batch adversarial loss: 0.454090\n",
      "epoch 2; iter: 600; batch classifier loss: 1.264648; batch adversarial loss: 0.377084\n",
      "epoch 3; iter: 0; batch classifier loss: 2.430027; batch adversarial loss: 0.467262\n",
      "epoch 3; iter: 200; batch classifier loss: 0.344746; batch adversarial loss: 0.503359\n",
      "epoch 3; iter: 400; batch classifier loss: 2.332938; batch adversarial loss: 0.449712\n",
      "epoch 3; iter: 600; batch classifier loss: 1.374036; batch adversarial loss: 0.385437\n",
      "epoch 4; iter: 0; batch classifier loss: 0.825421; batch adversarial loss: 0.515630\n",
      "epoch 4; iter: 200; batch classifier loss: 0.907303; batch adversarial loss: 0.427642\n",
      "epoch 4; iter: 400; batch classifier loss: 1.142259; batch adversarial loss: 0.466475\n",
      "epoch 4; iter: 600; batch classifier loss: 0.559897; batch adversarial loss: 0.493102\n",
      "epoch 5; iter: 0; batch classifier loss: 0.765545; batch adversarial loss: 0.491418\n",
      "epoch 5; iter: 200; batch classifier loss: 0.437076; batch adversarial loss: 0.519289\n",
      "epoch 5; iter: 400; batch classifier loss: 0.548401; batch adversarial loss: 0.529561\n",
      "epoch 5; iter: 600; batch classifier loss: 0.551204; batch adversarial loss: 0.414342\n",
      "epoch 6; iter: 0; batch classifier loss: 0.832159; batch adversarial loss: 0.355168\n",
      "epoch 6; iter: 200; batch classifier loss: 0.414551; batch adversarial loss: 0.411138\n",
      "epoch 6; iter: 400; batch classifier loss: 0.376257; batch adversarial loss: 0.462883\n",
      "epoch 6; iter: 600; batch classifier loss: 0.483378; batch adversarial loss: 0.455647\n",
      "epoch 7; iter: 0; batch classifier loss: 0.380411; batch adversarial loss: 0.380639\n",
      "epoch 7; iter: 200; batch classifier loss: 1.174494; batch adversarial loss: 0.422096\n",
      "epoch 7; iter: 400; batch classifier loss: 0.377760; batch adversarial loss: 0.331962\n",
      "epoch 7; iter: 600; batch classifier loss: 2.798002; batch adversarial loss: 0.355878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.860559; batch adversarial loss: 0.339824\n",
      "epoch 8; iter: 200; batch classifier loss: 0.419217; batch adversarial loss: 0.432473\n",
      "epoch 8; iter: 400; batch classifier loss: 0.502294; batch adversarial loss: 0.393932\n",
      "epoch 8; iter: 600; batch classifier loss: 0.425295; batch adversarial loss: 0.287291\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386143; batch adversarial loss: 0.345784\n",
      "epoch 9; iter: 200; batch classifier loss: 0.402792; batch adversarial loss: 0.507297\n",
      "epoch 9; iter: 400; batch classifier loss: 0.349528; batch adversarial loss: 0.400237\n",
      "epoch 9; iter: 600; batch classifier loss: 0.465180; batch adversarial loss: 0.469150\n",
      "epoch 0; iter: 0; batch classifier loss: 12.836866; batch adversarial loss: 0.969225\n",
      "epoch 0; iter: 200; batch classifier loss: 2.001308; batch adversarial loss: 1.057887\n",
      "epoch 0; iter: 400; batch classifier loss: 3.923306; batch adversarial loss: 0.730314\n",
      "epoch 0; iter: 600; batch classifier loss: 3.647011; batch adversarial loss: 0.629389\n",
      "epoch 1; iter: 0; batch classifier loss: 6.045813; batch adversarial loss: 0.680559\n",
      "epoch 1; iter: 200; batch classifier loss: 8.851315; batch adversarial loss: 0.498683\n",
      "epoch 1; iter: 400; batch classifier loss: 3.798731; batch adversarial loss: 0.468446\n",
      "epoch 1; iter: 600; batch classifier loss: 1.080709; batch adversarial loss: 0.392494\n",
      "epoch 2; iter: 0; batch classifier loss: 1.216272; batch adversarial loss: 0.430002\n",
      "epoch 2; iter: 200; batch classifier loss: 3.970442; batch adversarial loss: 0.426621\n",
      "epoch 2; iter: 400; batch classifier loss: 5.816916; batch adversarial loss: 0.407476\n",
      "epoch 2; iter: 600; batch classifier loss: 4.185163; batch adversarial loss: 0.446314\n",
      "epoch 3; iter: 0; batch classifier loss: 0.804623; batch adversarial loss: 0.567689\n",
      "epoch 3; iter: 200; batch classifier loss: 2.913291; batch adversarial loss: 0.426972\n",
      "epoch 3; iter: 400; batch classifier loss: 2.948909; batch adversarial loss: 0.340868\n",
      "epoch 3; iter: 600; batch classifier loss: 1.398913; batch adversarial loss: 0.369898\n",
      "epoch 4; iter: 0; batch classifier loss: 0.405098; batch adversarial loss: 0.427309\n",
      "epoch 4; iter: 200; batch classifier loss: 3.296737; batch adversarial loss: 0.435116\n",
      "epoch 4; iter: 400; batch classifier loss: 0.824530; batch adversarial loss: 0.331885\n",
      "epoch 4; iter: 600; batch classifier loss: 1.309745; batch adversarial loss: 0.429890\n",
      "epoch 5; iter: 0; batch classifier loss: 0.344309; batch adversarial loss: 0.375315\n",
      "epoch 5; iter: 200; batch classifier loss: 0.593954; batch adversarial loss: 0.421199\n",
      "epoch 5; iter: 400; batch classifier loss: 0.704839; batch adversarial loss: 0.461433\n",
      "epoch 5; iter: 600; batch classifier loss: 0.506424; batch adversarial loss: 0.376190\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639599; batch adversarial loss: 0.451677\n",
      "epoch 6; iter: 200; batch classifier loss: 0.381645; batch adversarial loss: 0.573363\n",
      "epoch 6; iter: 400; batch classifier loss: 0.679883; batch adversarial loss: 0.398207\n",
      "epoch 6; iter: 600; batch classifier loss: 0.549407; batch adversarial loss: 0.450366\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496637; batch adversarial loss: 0.390845\n",
      "epoch 7; iter: 200; batch classifier loss: 0.509759; batch adversarial loss: 0.386890\n",
      "epoch 7; iter: 400; batch classifier loss: 0.495730; batch adversarial loss: 0.322497\n",
      "epoch 7; iter: 600; batch classifier loss: 0.448270; batch adversarial loss: 0.398984\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394141; batch adversarial loss: 0.439818\n",
      "epoch 8; iter: 200; batch classifier loss: 0.292575; batch adversarial loss: 0.374215\n",
      "epoch 8; iter: 400; batch classifier loss: 0.474469; batch adversarial loss: 0.282603\n",
      "epoch 8; iter: 600; batch classifier loss: 0.462753; batch adversarial loss: 0.502055\n",
      "epoch 9; iter: 0; batch classifier loss: 0.283954; batch adversarial loss: 0.343901\n",
      "epoch 9; iter: 200; batch classifier loss: 0.431863; batch adversarial loss: 0.362786\n",
      "epoch 9; iter: 400; batch classifier loss: 0.428315; batch adversarial loss: 0.412251\n",
      "epoch 9; iter: 600; batch classifier loss: 0.349047; batch adversarial loss: 0.296972\n",
      "epoch 0; iter: 0; batch classifier loss: 6.757521; batch adversarial loss: 1.196412\n",
      "epoch 0; iter: 200; batch classifier loss: 4.458808; batch adversarial loss: 1.073620\n",
      "epoch 0; iter: 400; batch classifier loss: 12.475402; batch adversarial loss: 0.909452\n",
      "epoch 0; iter: 600; batch classifier loss: 7.977529; batch adversarial loss: 0.690588\n",
      "epoch 1; iter: 0; batch classifier loss: 0.818049; batch adversarial loss: 0.658565\n",
      "epoch 1; iter: 200; batch classifier loss: 3.125714; batch adversarial loss: 0.550849\n",
      "epoch 1; iter: 400; batch classifier loss: 6.356375; batch adversarial loss: 0.558772\n",
      "epoch 1; iter: 600; batch classifier loss: 4.513230; batch adversarial loss: 0.423687\n",
      "epoch 2; iter: 0; batch classifier loss: 7.913612; batch adversarial loss: 0.462994\n",
      "epoch 2; iter: 200; batch classifier loss: 1.743971; batch adversarial loss: 0.485192\n",
      "epoch 2; iter: 400; batch classifier loss: 4.337347; batch adversarial loss: 0.544506\n",
      "epoch 2; iter: 600; batch classifier loss: 2.759798; batch adversarial loss: 0.452610\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629327; batch adversarial loss: 0.443977\n",
      "epoch 3; iter: 200; batch classifier loss: 1.308194; batch adversarial loss: 0.369441\n",
      "epoch 3; iter: 400; batch classifier loss: 0.841037; batch adversarial loss: 0.384177\n",
      "epoch 3; iter: 600; batch classifier loss: 0.799625; batch adversarial loss: 0.569741\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535847; batch adversarial loss: 0.464288\n",
      "epoch 4; iter: 200; batch classifier loss: 0.986258; batch adversarial loss: 0.365536\n",
      "epoch 4; iter: 400; batch classifier loss: 0.476223; batch adversarial loss: 0.407873\n",
      "epoch 4; iter: 600; batch classifier loss: 0.502897; batch adversarial loss: 0.503588\n",
      "epoch 5; iter: 0; batch classifier loss: 0.611489; batch adversarial loss: 0.408841\n",
      "epoch 5; iter: 200; batch classifier loss: 0.776958; batch adversarial loss: 0.377292\n",
      "epoch 5; iter: 400; batch classifier loss: 0.650933; batch adversarial loss: 0.474008\n",
      "epoch 5; iter: 600; batch classifier loss: 0.332362; batch adversarial loss: 0.292025\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565361; batch adversarial loss: 0.449914\n",
      "epoch 6; iter: 200; batch classifier loss: 0.361638; batch adversarial loss: 0.360685\n",
      "epoch 6; iter: 400; batch classifier loss: 0.567665; batch adversarial loss: 0.441195\n",
      "epoch 6; iter: 600; batch classifier loss: 0.524020; batch adversarial loss: 0.403075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.382942; batch adversarial loss: 0.502935\n",
      "epoch 7; iter: 200; batch classifier loss: 0.502384; batch adversarial loss: 0.349226\n",
      "epoch 7; iter: 400; batch classifier loss: 0.338077; batch adversarial loss: 0.497619\n",
      "epoch 7; iter: 600; batch classifier loss: 1.134987; batch adversarial loss: 0.321241\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520386; batch adversarial loss: 0.380457\n",
      "epoch 8; iter: 200; batch classifier loss: 0.470867; batch adversarial loss: 0.449798\n",
      "epoch 8; iter: 400; batch classifier loss: 0.426939; batch adversarial loss: 0.537247\n",
      "epoch 8; iter: 600; batch classifier loss: 0.309299; batch adversarial loss: 0.587839\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553331; batch adversarial loss: 0.389100\n",
      "epoch 9; iter: 200; batch classifier loss: 0.363310; batch adversarial loss: 0.397575\n",
      "epoch 9; iter: 400; batch classifier loss: 0.392694; batch adversarial loss: 0.368371\n",
      "epoch 9; iter: 600; batch classifier loss: 0.514783; batch adversarial loss: 0.401674\n",
      "epoch 0; iter: 0; batch classifier loss: 89.895012; batch adversarial loss: 0.550478\n",
      "epoch 0; iter: 200; batch classifier loss: 4.282495; batch adversarial loss: 0.571803\n",
      "epoch 0; iter: 400; batch classifier loss: 10.198162; batch adversarial loss: 0.416313\n",
      "epoch 0; iter: 600; batch classifier loss: 5.905105; batch adversarial loss: 0.568172\n",
      "epoch 1; iter: 0; batch classifier loss: 9.353428; batch adversarial loss: 0.452202\n",
      "epoch 1; iter: 200; batch classifier loss: 0.377276; batch adversarial loss: 0.525657\n",
      "epoch 1; iter: 400; batch classifier loss: 2.321834; batch adversarial loss: 0.485408\n",
      "epoch 1; iter: 600; batch classifier loss: 5.658134; batch adversarial loss: 0.395774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624918; batch adversarial loss: 0.547220\n",
      "epoch 2; iter: 200; batch classifier loss: 6.246961; batch adversarial loss: 0.523679\n",
      "epoch 2; iter: 400; batch classifier loss: 3.490800; batch adversarial loss: 0.485346\n",
      "epoch 2; iter: 600; batch classifier loss: 2.660167; batch adversarial loss: 0.443623\n",
      "epoch 3; iter: 0; batch classifier loss: 1.349720; batch adversarial loss: 0.401161\n",
      "epoch 3; iter: 200; batch classifier loss: 0.913116; batch adversarial loss: 0.534979\n",
      "epoch 3; iter: 400; batch classifier loss: 1.878222; batch adversarial loss: 0.446864\n",
      "epoch 3; iter: 600; batch classifier loss: 3.041694; batch adversarial loss: 0.480170\n",
      "epoch 4; iter: 0; batch classifier loss: 1.503120; batch adversarial loss: 0.402366\n",
      "epoch 4; iter: 200; batch classifier loss: 1.220290; batch adversarial loss: 0.426503\n",
      "epoch 4; iter: 400; batch classifier loss: 0.958552; batch adversarial loss: 0.423207\n",
      "epoch 4; iter: 600; batch classifier loss: 0.357676; batch adversarial loss: 0.406563\n",
      "epoch 5; iter: 0; batch classifier loss: 0.685683; batch adversarial loss: 0.398068\n",
      "epoch 5; iter: 200; batch classifier loss: 0.726455; batch adversarial loss: 0.364529\n",
      "epoch 5; iter: 400; batch classifier loss: 0.591757; batch adversarial loss: 0.380621\n",
      "epoch 5; iter: 600; batch classifier loss: 1.284974; batch adversarial loss: 0.397256\n",
      "epoch 6; iter: 0; batch classifier loss: 0.503162; batch adversarial loss: 0.504585\n",
      "epoch 6; iter: 200; batch classifier loss: 0.501627; batch adversarial loss: 0.406032\n",
      "epoch 6; iter: 400; batch classifier loss: 0.583611; batch adversarial loss: 0.493243\n",
      "epoch 6; iter: 600; batch classifier loss: 0.514243; batch adversarial loss: 0.420756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.651894; batch adversarial loss: 0.411271\n",
      "epoch 7; iter: 200; batch classifier loss: 0.519725; batch adversarial loss: 0.413665\n",
      "epoch 7; iter: 400; batch classifier loss: 0.338796; batch adversarial loss: 0.393190\n",
      "epoch 7; iter: 600; batch classifier loss: 0.464301; batch adversarial loss: 0.336532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292382; batch adversarial loss: 0.538089\n",
      "epoch 8; iter: 200; batch classifier loss: 0.437295; batch adversarial loss: 0.458797\n",
      "epoch 8; iter: 400; batch classifier loss: 0.358270; batch adversarial loss: 0.528872\n",
      "epoch 8; iter: 600; batch classifier loss: 0.267331; batch adversarial loss: 0.396055\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402014; batch adversarial loss: 0.399001\n",
      "epoch 9; iter: 200; batch classifier loss: 0.422816; batch adversarial loss: 0.268918\n",
      "epoch 9; iter: 400; batch classifier loss: 0.385772; batch adversarial loss: 0.341183\n",
      "epoch 9; iter: 600; batch classifier loss: 0.412833; batch adversarial loss: 0.449159\n",
      "epoch 0; iter: 0; batch classifier loss: 29.325735; batch adversarial loss: 0.585857\n",
      "epoch 0; iter: 200; batch classifier loss: 3.736350; batch adversarial loss: 0.479417\n",
      "epoch 0; iter: 400; batch classifier loss: 3.236508; batch adversarial loss: 0.497546\n",
      "epoch 0; iter: 600; batch classifier loss: 3.146475; batch adversarial loss: 0.601560\n",
      "epoch 1; iter: 0; batch classifier loss: 6.260929; batch adversarial loss: 0.515597\n",
      "epoch 1; iter: 200; batch classifier loss: 1.250081; batch adversarial loss: 0.565169\n",
      "epoch 1; iter: 400; batch classifier loss: 7.226672; batch adversarial loss: 0.416653\n",
      "epoch 1; iter: 600; batch classifier loss: 3.386514; batch adversarial loss: 0.529807\n",
      "epoch 2; iter: 0; batch classifier loss: 3.802684; batch adversarial loss: 0.452002\n",
      "epoch 2; iter: 200; batch classifier loss: 20.807264; batch adversarial loss: 0.463688\n",
      "epoch 2; iter: 400; batch classifier loss: 15.270697; batch adversarial loss: 0.278629\n",
      "epoch 2; iter: 600; batch classifier loss: 1.295637; batch adversarial loss: 0.343751\n",
      "epoch 3; iter: 0; batch classifier loss: 3.741650; batch adversarial loss: 0.457216\n",
      "epoch 3; iter: 200; batch classifier loss: 1.014537; batch adversarial loss: 0.364570\n",
      "epoch 3; iter: 400; batch classifier loss: 2.981706; batch adversarial loss: 0.520322\n",
      "epoch 3; iter: 600; batch classifier loss: 1.226526; batch adversarial loss: 0.389067\n",
      "epoch 4; iter: 0; batch classifier loss: 1.790746; batch adversarial loss: 0.525099\n",
      "epoch 4; iter: 200; batch classifier loss: 0.444268; batch adversarial loss: 0.325561\n",
      "epoch 4; iter: 400; batch classifier loss: 1.127370; batch adversarial loss: 0.402016\n",
      "epoch 4; iter: 600; batch classifier loss: 0.542841; batch adversarial loss: 0.344372\n",
      "epoch 5; iter: 0; batch classifier loss: 0.797672; batch adversarial loss: 0.567385\n",
      "epoch 5; iter: 200; batch classifier loss: 0.626889; batch adversarial loss: 0.379932\n",
      "epoch 5; iter: 400; batch classifier loss: 0.697259; batch adversarial loss: 0.492159\n",
      "epoch 5; iter: 600; batch classifier loss: 0.508671; batch adversarial loss: 0.387504\n",
      "epoch 6; iter: 0; batch classifier loss: 0.656325; batch adversarial loss: 0.456718\n",
      "epoch 6; iter: 200; batch classifier loss: 0.404846; batch adversarial loss: 0.467947\n",
      "epoch 6; iter: 400; batch classifier loss: 0.422111; batch adversarial loss: 0.399410\n",
      "epoch 6; iter: 600; batch classifier loss: 0.641044; batch adversarial loss: 0.436101\n",
      "epoch 7; iter: 0; batch classifier loss: 0.783202; batch adversarial loss: 0.321895\n",
      "epoch 7; iter: 200; batch classifier loss: 0.396592; batch adversarial loss: 0.475611\n",
      "epoch 7; iter: 400; batch classifier loss: 0.349018; batch adversarial loss: 0.424936\n",
      "epoch 7; iter: 600; batch classifier loss: 0.377635; batch adversarial loss: 0.312233\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478011; batch adversarial loss: 0.361065\n",
      "epoch 8; iter: 200; batch classifier loss: 0.300109; batch adversarial loss: 0.446842\n",
      "epoch 8; iter: 400; batch classifier loss: 0.350544; batch adversarial loss: 0.535426\n",
      "epoch 8; iter: 600; batch classifier loss: 0.260453; batch adversarial loss: 0.516692\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480087; batch adversarial loss: 0.523135\n",
      "epoch 9; iter: 200; batch classifier loss: 0.373441; batch adversarial loss: 0.266053\n",
      "epoch 9; iter: 400; batch classifier loss: 0.299114; batch adversarial loss: 0.447324\n",
      "epoch 9; iter: 600; batch classifier loss: 0.403985; batch adversarial loss: 0.530332\n",
      "epoch 0; iter: 0; batch classifier loss: 5.445262; batch adversarial loss: 0.736389\n",
      "epoch 0; iter: 200; batch classifier loss: 19.448061; batch adversarial loss: 0.629551\n",
      "epoch 0; iter: 400; batch classifier loss: 21.263502; batch adversarial loss: 0.527503\n",
      "epoch 0; iter: 600; batch classifier loss: 3.741242; batch adversarial loss: 0.527241\n",
      "epoch 1; iter: 0; batch classifier loss: 12.482635; batch adversarial loss: 0.464022\n",
      "epoch 1; iter: 200; batch classifier loss: 11.475527; batch adversarial loss: 0.460921\n",
      "epoch 1; iter: 400; batch classifier loss: 4.647764; batch adversarial loss: 0.424324\n",
      "epoch 1; iter: 600; batch classifier loss: 3.256059; batch adversarial loss: 0.474147\n",
      "epoch 2; iter: 0; batch classifier loss: 1.282405; batch adversarial loss: 0.474396\n",
      "epoch 2; iter: 200; batch classifier loss: 2.131366; batch adversarial loss: 0.439582\n",
      "epoch 2; iter: 400; batch classifier loss: 3.779977; batch adversarial loss: 0.382500\n",
      "epoch 2; iter: 600; batch classifier loss: 2.276798; batch adversarial loss: 0.485882\n",
      "epoch 3; iter: 0; batch classifier loss: 2.847573; batch adversarial loss: 0.370058\n",
      "epoch 3; iter: 200; batch classifier loss: 4.666678; batch adversarial loss: 0.435694\n",
      "epoch 3; iter: 400; batch classifier loss: 9.171513; batch adversarial loss: 0.339202\n",
      "epoch 3; iter: 600; batch classifier loss: 0.866372; batch adversarial loss: 0.258823\n",
      "epoch 4; iter: 0; batch classifier loss: 1.079432; batch adversarial loss: 0.429891\n",
      "epoch 4; iter: 200; batch classifier loss: 3.517483; batch adversarial loss: 0.518992\n",
      "epoch 4; iter: 400; batch classifier loss: 0.884397; batch adversarial loss: 0.285160\n",
      "epoch 4; iter: 600; batch classifier loss: 2.178166; batch adversarial loss: 0.384717\n",
      "epoch 5; iter: 0; batch classifier loss: 0.970244; batch adversarial loss: 0.383698\n",
      "epoch 5; iter: 200; batch classifier loss: 0.341324; batch adversarial loss: 0.295136\n",
      "epoch 5; iter: 400; batch classifier loss: 0.321964; batch adversarial loss: 0.489484\n",
      "epoch 5; iter: 600; batch classifier loss: 0.379028; batch adversarial loss: 0.426004\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553539; batch adversarial loss: 0.409533\n",
      "epoch 6; iter: 200; batch classifier loss: 0.421962; batch adversarial loss: 0.404962\n",
      "epoch 6; iter: 400; batch classifier loss: 0.411505; batch adversarial loss: 0.489836\n",
      "epoch 6; iter: 600; batch classifier loss: 0.357010; batch adversarial loss: 0.545240\n",
      "epoch 7; iter: 0; batch classifier loss: 0.359151; batch adversarial loss: 0.308192\n",
      "epoch 7; iter: 200; batch classifier loss: 0.363920; batch adversarial loss: 0.434903\n",
      "epoch 7; iter: 400; batch classifier loss: 0.414019; batch adversarial loss: 0.409729\n",
      "epoch 7; iter: 600; batch classifier loss: 0.560288; batch adversarial loss: 0.237623\n",
      "epoch 8; iter: 0; batch classifier loss: 0.335268; batch adversarial loss: 0.549327\n",
      "epoch 8; iter: 200; batch classifier loss: 0.445264; batch adversarial loss: 0.398729\n",
      "epoch 8; iter: 400; batch classifier loss: 0.445334; batch adversarial loss: 0.220536\n",
      "epoch 8; iter: 600; batch classifier loss: 0.348603; batch adversarial loss: 0.455781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363236; batch adversarial loss: 0.456621\n",
      "epoch 9; iter: 200; batch classifier loss: 0.385880; batch adversarial loss: 0.553123\n",
      "epoch 9; iter: 400; batch classifier loss: 0.373792; batch adversarial loss: 0.368953\n",
      "epoch 9; iter: 600; batch classifier loss: 0.322495; batch adversarial loss: 0.405124\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 8.922720; batch adversarial loss: 0.687437\n",
      "epoch 0; iter: 200; batch classifier loss: 0.780192; batch adversarial loss: 0.612202\n",
      "epoch 0; iter: 400; batch classifier loss: 0.978636; batch adversarial loss: 0.559539\n",
      "epoch 0; iter: 600; batch classifier loss: 9.153783; batch adversarial loss: 0.540244\n",
      "epoch 1; iter: 0; batch classifier loss: 5.076581; batch adversarial loss: 0.512815\n",
      "epoch 1; iter: 200; batch classifier loss: 6.344346; batch adversarial loss: 0.528483\n",
      "epoch 1; iter: 400; batch classifier loss: 5.584642; batch adversarial loss: 0.439610\n",
      "epoch 1; iter: 600; batch classifier loss: 6.658807; batch adversarial loss: 0.428013\n",
      "epoch 2; iter: 0; batch classifier loss: 3.359363; batch adversarial loss: 0.441481\n",
      "epoch 2; iter: 200; batch classifier loss: 34.253773; batch adversarial loss: 0.421056\n",
      "epoch 2; iter: 400; batch classifier loss: 1.547177; batch adversarial loss: 0.558012\n",
      "epoch 2; iter: 600; batch classifier loss: 2.316591; batch adversarial loss: 0.307525\n",
      "epoch 3; iter: 0; batch classifier loss: 2.740197; batch adversarial loss: 0.368087\n",
      "epoch 3; iter: 200; batch classifier loss: 0.764638; batch adversarial loss: 0.367110\n",
      "epoch 3; iter: 400; batch classifier loss: 4.286318; batch adversarial loss: 0.413505\n",
      "epoch 3; iter: 600; batch classifier loss: 3.152603; batch adversarial loss: 0.403646\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595452; batch adversarial loss: 0.413329\n",
      "epoch 4; iter: 200; batch classifier loss: 0.506032; batch adversarial loss: 0.328668\n",
      "epoch 4; iter: 400; batch classifier loss: 0.855057; batch adversarial loss: 0.380458\n",
      "epoch 4; iter: 600; batch classifier loss: 0.664297; batch adversarial loss: 0.444660\n",
      "epoch 5; iter: 0; batch classifier loss: 0.620423; batch adversarial loss: 0.419602\n",
      "epoch 5; iter: 200; batch classifier loss: 0.572764; batch adversarial loss: 0.489411\n",
      "epoch 5; iter: 400; batch classifier loss: 0.497431; batch adversarial loss: 0.511256\n",
      "epoch 5; iter: 600; batch classifier loss: 0.679285; batch adversarial loss: 0.477187\n",
      "epoch 6; iter: 0; batch classifier loss: 2.134733; batch adversarial loss: 0.492130\n",
      "epoch 6; iter: 200; batch classifier loss: 0.665964; batch adversarial loss: 0.293609\n",
      "epoch 6; iter: 400; batch classifier loss: 0.501182; batch adversarial loss: 0.515538\n",
      "epoch 6; iter: 600; batch classifier loss: 0.608076; batch adversarial loss: 0.301681\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420943; batch adversarial loss: 0.420816\n",
      "epoch 7; iter: 200; batch classifier loss: 0.511796; batch adversarial loss: 0.328425\n",
      "epoch 7; iter: 400; batch classifier loss: 0.495666; batch adversarial loss: 0.408399\n",
      "epoch 7; iter: 600; batch classifier loss: 0.448134; batch adversarial loss: 0.403071\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572265; batch adversarial loss: 0.299426\n",
      "epoch 8; iter: 200; batch classifier loss: 1.399573; batch adversarial loss: 0.453155\n",
      "epoch 8; iter: 400; batch classifier loss: 0.323642; batch adversarial loss: 0.379845\n",
      "epoch 8; iter: 600; batch classifier loss: 0.456258; batch adversarial loss: 0.371450\n",
      "epoch 9; iter: 0; batch classifier loss: 0.431530; batch adversarial loss: 0.295433\n",
      "epoch 9; iter: 200; batch classifier loss: 0.444928; batch adversarial loss: 0.446872\n",
      "epoch 9; iter: 400; batch classifier loss: 0.366361; batch adversarial loss: 0.292154\n",
      "epoch 9; iter: 600; batch classifier loss: 0.468468; batch adversarial loss: 0.459212\n",
      "epoch 10; iter: 0; batch classifier loss: 0.437403; batch adversarial loss: 0.429472\n",
      "epoch 10; iter: 200; batch classifier loss: 0.463011; batch adversarial loss: 0.232962\n",
      "epoch 10; iter: 400; batch classifier loss: 0.294218; batch adversarial loss: 0.381879\n",
      "epoch 10; iter: 600; batch classifier loss: 0.291162; batch adversarial loss: 0.434308\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393102; batch adversarial loss: 0.431617\n",
      "epoch 11; iter: 200; batch classifier loss: 0.303544; batch adversarial loss: 0.478550\n",
      "epoch 11; iter: 400; batch classifier loss: 0.345232; batch adversarial loss: 0.370248\n",
      "epoch 11; iter: 600; batch classifier loss: 0.286333; batch adversarial loss: 0.360038\n",
      "epoch 12; iter: 0; batch classifier loss: 0.431478; batch adversarial loss: 0.431644\n",
      "epoch 12; iter: 200; batch classifier loss: 0.261285; batch adversarial loss: 0.408637\n",
      "epoch 12; iter: 400; batch classifier loss: 0.404581; batch adversarial loss: 0.337098\n",
      "epoch 12; iter: 600; batch classifier loss: 0.481124; batch adversarial loss: 0.427725\n",
      "epoch 13; iter: 0; batch classifier loss: 0.449660; batch adversarial loss: 0.440040\n",
      "epoch 13; iter: 200; batch classifier loss: 0.356157; batch adversarial loss: 0.433612\n",
      "epoch 13; iter: 400; batch classifier loss: 0.432531; batch adversarial loss: 0.481183\n",
      "epoch 13; iter: 600; batch classifier loss: 0.361269; batch adversarial loss: 0.315768\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265021; batch adversarial loss: 0.366453\n",
      "epoch 14; iter: 200; batch classifier loss: 0.358246; batch adversarial loss: 0.561891\n",
      "epoch 14; iter: 400; batch classifier loss: 0.401374; batch adversarial loss: 0.337000\n",
      "epoch 14; iter: 600; batch classifier loss: 0.476133; batch adversarial loss: 0.391690\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287417; batch adversarial loss: 0.426792\n",
      "epoch 15; iter: 200; batch classifier loss: 0.356905; batch adversarial loss: 0.358919\n",
      "epoch 15; iter: 400; batch classifier loss: 0.323419; batch adversarial loss: 0.366317\n",
      "epoch 15; iter: 600; batch classifier loss: 0.364962; batch adversarial loss: 0.434473\n",
      "epoch 16; iter: 0; batch classifier loss: 0.410338; batch adversarial loss: 0.510273\n",
      "epoch 16; iter: 200; batch classifier loss: 0.259011; batch adversarial loss: 0.287449\n",
      "epoch 16; iter: 400; batch classifier loss: 0.219300; batch adversarial loss: 0.404795\n",
      "epoch 16; iter: 600; batch classifier loss: 0.239625; batch adversarial loss: 0.409081\n",
      "epoch 17; iter: 0; batch classifier loss: 0.295053; batch adversarial loss: 0.382341\n",
      "epoch 17; iter: 200; batch classifier loss: 0.365208; batch adversarial loss: 0.342984\n",
      "epoch 17; iter: 400; batch classifier loss: 0.282760; batch adversarial loss: 0.434221\n",
      "epoch 17; iter: 600; batch classifier loss: 0.311465; batch adversarial loss: 0.616121\n",
      "epoch 18; iter: 0; batch classifier loss: 0.255302; batch adversarial loss: 0.459140\n",
      "epoch 18; iter: 200; batch classifier loss: 0.359187; batch adversarial loss: 0.417682\n",
      "epoch 18; iter: 400; batch classifier loss: 0.270754; batch adversarial loss: 0.395544\n",
      "epoch 18; iter: 600; batch classifier loss: 0.351348; batch adversarial loss: 0.442882\n",
      "epoch 19; iter: 0; batch classifier loss: 0.390493; batch adversarial loss: 0.354535\n",
      "epoch 19; iter: 200; batch classifier loss: 0.338364; batch adversarial loss: 0.555285\n",
      "epoch 19; iter: 400; batch classifier loss: 0.466568; batch adversarial loss: 0.600936\n",
      "epoch 19; iter: 600; batch classifier loss: 0.270692; batch adversarial loss: 0.410109\n",
      "epoch 0; iter: 0; batch classifier loss: 393.460571; batch adversarial loss: 0.758113\n",
      "epoch 0; iter: 200; batch classifier loss: 7.183283; batch adversarial loss: 0.656270\n",
      "epoch 0; iter: 400; batch classifier loss: 7.406337; batch adversarial loss: 0.661478\n",
      "epoch 0; iter: 600; batch classifier loss: 20.013542; batch adversarial loss: 0.562468\n",
      "epoch 1; iter: 0; batch classifier loss: 16.920586; batch adversarial loss: 0.556229\n",
      "epoch 1; iter: 200; batch classifier loss: 11.223832; batch adversarial loss: 0.496827\n",
      "epoch 1; iter: 400; batch classifier loss: 1.282548; batch adversarial loss: 0.456597\n",
      "epoch 1; iter: 600; batch classifier loss: 6.799198; batch adversarial loss: 0.546451\n",
      "epoch 2; iter: 0; batch classifier loss: 1.830809; batch adversarial loss: 0.473779\n",
      "epoch 2; iter: 200; batch classifier loss: 10.651848; batch adversarial loss: 0.537337\n",
      "epoch 2; iter: 400; batch classifier loss: 18.690554; batch adversarial loss: 0.364217\n",
      "epoch 2; iter: 600; batch classifier loss: 4.085201; batch adversarial loss: 0.436201\n",
      "epoch 3; iter: 0; batch classifier loss: 3.044180; batch adversarial loss: 0.313618\n",
      "epoch 3; iter: 200; batch classifier loss: 3.270640; batch adversarial loss: 0.355564\n",
      "epoch 3; iter: 400; batch classifier loss: 1.597196; batch adversarial loss: 0.317566\n",
      "epoch 3; iter: 600; batch classifier loss: 1.868402; batch adversarial loss: 0.376471\n",
      "epoch 4; iter: 0; batch classifier loss: 2.510331; batch adversarial loss: 0.299184\n",
      "epoch 4; iter: 200; batch classifier loss: 3.079872; batch adversarial loss: 0.230349\n",
      "epoch 4; iter: 400; batch classifier loss: 0.680096; batch adversarial loss: 0.448877\n",
      "epoch 4; iter: 600; batch classifier loss: 0.603828; batch adversarial loss: 0.577158\n",
      "epoch 5; iter: 0; batch classifier loss: 2.015407; batch adversarial loss: 0.415111\n",
      "epoch 5; iter: 200; batch classifier loss: 1.104735; batch adversarial loss: 0.454833\n",
      "epoch 5; iter: 400; batch classifier loss: 0.907075; batch adversarial loss: 0.515556\n",
      "epoch 5; iter: 600; batch classifier loss: 0.474320; batch adversarial loss: 0.390008\n",
      "epoch 6; iter: 0; batch classifier loss: 0.945536; batch adversarial loss: 0.422373\n",
      "epoch 6; iter: 200; batch classifier loss: 0.476671; batch adversarial loss: 0.392015\n",
      "epoch 6; iter: 400; batch classifier loss: 0.446906; batch adversarial loss: 0.467342\n",
      "epoch 6; iter: 600; batch classifier loss: 0.496598; batch adversarial loss: 0.304622\n",
      "epoch 7; iter: 0; batch classifier loss: 0.356553; batch adversarial loss: 0.493027\n",
      "epoch 7; iter: 200; batch classifier loss: 0.452016; batch adversarial loss: 0.635297\n",
      "epoch 7; iter: 400; batch classifier loss: 0.379132; batch adversarial loss: 0.411923\n",
      "epoch 7; iter: 600; batch classifier loss: 0.449474; batch adversarial loss: 0.335368\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396112; batch adversarial loss: 0.323451\n",
      "epoch 8; iter: 200; batch classifier loss: 0.608064; batch adversarial loss: 0.494222\n",
      "epoch 8; iter: 400; batch classifier loss: 0.384730; batch adversarial loss: 0.518792\n",
      "epoch 8; iter: 600; batch classifier loss: 0.318152; batch adversarial loss: 0.465477\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481966; batch adversarial loss: 0.372331\n",
      "epoch 9; iter: 200; batch classifier loss: 0.398881; batch adversarial loss: 0.454009\n",
      "epoch 9; iter: 400; batch classifier loss: 0.430104; batch adversarial loss: 0.429196\n",
      "epoch 9; iter: 600; batch classifier loss: 0.339015; batch adversarial loss: 0.515973\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445321; batch adversarial loss: 0.524478\n",
      "epoch 10; iter: 200; batch classifier loss: 0.358634; batch adversarial loss: 0.371072\n",
      "epoch 10; iter: 400; batch classifier loss: 0.332249; batch adversarial loss: 0.357385\n",
      "epoch 10; iter: 600; batch classifier loss: 0.412612; batch adversarial loss: 0.421566\n",
      "epoch 11; iter: 0; batch classifier loss: 0.223381; batch adversarial loss: 0.447330\n",
      "epoch 11; iter: 200; batch classifier loss: 0.615490; batch adversarial loss: 0.470056\n",
      "epoch 11; iter: 400; batch classifier loss: 0.382551; batch adversarial loss: 0.298839\n",
      "epoch 11; iter: 600; batch classifier loss: 0.442483; batch adversarial loss: 0.288283\n",
      "epoch 12; iter: 0; batch classifier loss: 0.280155; batch adversarial loss: 0.432563\n",
      "epoch 12; iter: 200; batch classifier loss: 0.548456; batch adversarial loss: 0.462378\n",
      "epoch 12; iter: 400; batch classifier loss: 0.375465; batch adversarial loss: 0.493822\n",
      "epoch 12; iter: 600; batch classifier loss: 0.284061; batch adversarial loss: 0.419938\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336658; batch adversarial loss: 0.341195\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404793; batch adversarial loss: 0.323766\n",
      "epoch 13; iter: 400; batch classifier loss: 0.327349; batch adversarial loss: 0.337495\n",
      "epoch 13; iter: 600; batch classifier loss: 0.429816; batch adversarial loss: 0.480771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339914; batch adversarial loss: 0.431968\n",
      "epoch 14; iter: 200; batch classifier loss: 0.458868; batch adversarial loss: 0.447655\n",
      "epoch 14; iter: 400; batch classifier loss: 0.281836; batch adversarial loss: 0.419359\n",
      "epoch 14; iter: 600; batch classifier loss: 0.372652; batch adversarial loss: 0.313624\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433893; batch adversarial loss: 0.312245\n",
      "epoch 15; iter: 200; batch classifier loss: 0.359443; batch adversarial loss: 0.344289\n",
      "epoch 15; iter: 400; batch classifier loss: 0.494349; batch adversarial loss: 0.349076\n",
      "epoch 15; iter: 600; batch classifier loss: 0.449464; batch adversarial loss: 0.505671\n",
      "epoch 16; iter: 0; batch classifier loss: 0.287096; batch adversarial loss: 0.351785\n",
      "epoch 16; iter: 200; batch classifier loss: 0.348155; batch adversarial loss: 0.452946\n",
      "epoch 16; iter: 400; batch classifier loss: 0.355243; batch adversarial loss: 0.437237\n",
      "epoch 16; iter: 600; batch classifier loss: 0.428281; batch adversarial loss: 0.483017\n",
      "epoch 17; iter: 0; batch classifier loss: 0.246537; batch adversarial loss: 0.502426\n",
      "epoch 17; iter: 200; batch classifier loss: 0.483725; batch adversarial loss: 0.314686\n",
      "epoch 17; iter: 400; batch classifier loss: 0.318879; batch adversarial loss: 0.398515\n",
      "epoch 17; iter: 600; batch classifier loss: 0.308789; batch adversarial loss: 0.419939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.385668; batch adversarial loss: 0.427421\n",
      "epoch 18; iter: 200; batch classifier loss: 0.352792; batch adversarial loss: 0.535787\n",
      "epoch 18; iter: 400; batch classifier loss: 0.390531; batch adversarial loss: 0.516403\n",
      "epoch 18; iter: 600; batch classifier loss: 0.405153; batch adversarial loss: 0.598537\n",
      "epoch 19; iter: 0; batch classifier loss: 0.419098; batch adversarial loss: 0.450708\n",
      "epoch 19; iter: 200; batch classifier loss: 0.435906; batch adversarial loss: 0.461269\n",
      "epoch 19; iter: 400; batch classifier loss: 0.310109; batch adversarial loss: 0.399150\n",
      "epoch 19; iter: 600; batch classifier loss: 0.334475; batch adversarial loss: 0.319783\n",
      "epoch 0; iter: 0; batch classifier loss: 5.540159; batch adversarial loss: 0.958210\n",
      "epoch 0; iter: 200; batch classifier loss: 9.711923; batch adversarial loss: 0.858037\n",
      "epoch 0; iter: 400; batch classifier loss: 4.983170; batch adversarial loss: 0.679783\n",
      "epoch 0; iter: 600; batch classifier loss: 12.029820; batch adversarial loss: 0.597046\n",
      "epoch 1; iter: 0; batch classifier loss: 3.889323; batch adversarial loss: 0.575230\n",
      "epoch 1; iter: 200; batch classifier loss: 7.086114; batch adversarial loss: 0.476610\n",
      "epoch 1; iter: 400; batch classifier loss: 1.825364; batch adversarial loss: 0.476964\n",
      "epoch 1; iter: 600; batch classifier loss: 9.397636; batch adversarial loss: 0.457902\n",
      "epoch 2; iter: 0; batch classifier loss: 6.193501; batch adversarial loss: 0.455188\n",
      "epoch 2; iter: 200; batch classifier loss: 1.690943; batch adversarial loss: 0.576134\n",
      "epoch 2; iter: 400; batch classifier loss: 1.020253; batch adversarial loss: 0.446761\n",
      "epoch 2; iter: 600; batch classifier loss: 2.853656; batch adversarial loss: 0.418150\n",
      "epoch 3; iter: 0; batch classifier loss: 3.656401; batch adversarial loss: 0.425033\n",
      "epoch 3; iter: 200; batch classifier loss: 3.179669; batch adversarial loss: 0.466084\n",
      "epoch 3; iter: 400; batch classifier loss: 0.707874; batch adversarial loss: 0.492425\n",
      "epoch 3; iter: 600; batch classifier loss: 1.342462; batch adversarial loss: 0.482672\n",
      "epoch 4; iter: 0; batch classifier loss: 1.199499; batch adversarial loss: 0.416249\n",
      "epoch 4; iter: 200; batch classifier loss: 0.804000; batch adversarial loss: 0.571045\n",
      "epoch 4; iter: 400; batch classifier loss: 0.463144; batch adversarial loss: 0.400786\n",
      "epoch 4; iter: 600; batch classifier loss: 0.486404; batch adversarial loss: 0.357153\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566668; batch adversarial loss: 0.362617\n",
      "epoch 5; iter: 200; batch classifier loss: 0.605928; batch adversarial loss: 0.429521\n",
      "epoch 5; iter: 400; batch classifier loss: 0.848216; batch adversarial loss: 0.428042\n",
      "epoch 5; iter: 600; batch classifier loss: 0.554639; batch adversarial loss: 0.487578\n",
      "epoch 6; iter: 0; batch classifier loss: 0.746280; batch adversarial loss: 0.280788\n",
      "epoch 6; iter: 200; batch classifier loss: 0.466741; batch adversarial loss: 0.357240\n",
      "epoch 6; iter: 400; batch classifier loss: 0.583667; batch adversarial loss: 0.525805\n",
      "epoch 6; iter: 600; batch classifier loss: 0.592280; batch adversarial loss: 0.479254\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377259; batch adversarial loss: 0.482376\n",
      "epoch 7; iter: 200; batch classifier loss: 0.417301; batch adversarial loss: 0.452563\n",
      "epoch 7; iter: 400; batch classifier loss: 0.999479; batch adversarial loss: 0.408818\n",
      "epoch 7; iter: 600; batch classifier loss: 0.345058; batch adversarial loss: 0.373293\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499722; batch adversarial loss: 0.348629\n",
      "epoch 8; iter: 200; batch classifier loss: 0.386083; batch adversarial loss: 0.422614\n",
      "epoch 8; iter: 400; batch classifier loss: 0.388565; batch adversarial loss: 0.612068\n",
      "epoch 8; iter: 600; batch classifier loss: 0.393704; batch adversarial loss: 0.503344\n",
      "epoch 9; iter: 0; batch classifier loss: 0.388191; batch adversarial loss: 0.379986\n",
      "epoch 9; iter: 200; batch classifier loss: 0.277097; batch adversarial loss: 0.367708\n",
      "epoch 9; iter: 400; batch classifier loss: 0.434872; batch adversarial loss: 0.368397\n",
      "epoch 9; iter: 600; batch classifier loss: 0.290829; batch adversarial loss: 0.488408\n",
      "epoch 10; iter: 0; batch classifier loss: 0.294384; batch adversarial loss: 0.447366\n",
      "epoch 10; iter: 200; batch classifier loss: 0.531211; batch adversarial loss: 0.436077\n",
      "epoch 10; iter: 400; batch classifier loss: 0.397379; batch adversarial loss: 0.320540\n",
      "epoch 10; iter: 600; batch classifier loss: 0.298009; batch adversarial loss: 0.418874\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404468; batch adversarial loss: 0.339162\n",
      "epoch 11; iter: 200; batch classifier loss: 0.416540; batch adversarial loss: 0.429673\n",
      "epoch 11; iter: 400; batch classifier loss: 0.372284; batch adversarial loss: 0.351935\n",
      "epoch 11; iter: 600; batch classifier loss: 0.512648; batch adversarial loss: 0.455642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470418; batch adversarial loss: 0.320827\n",
      "epoch 12; iter: 200; batch classifier loss: 0.323062; batch adversarial loss: 0.354826\n",
      "epoch 12; iter: 400; batch classifier loss: 0.287903; batch adversarial loss: 0.459491\n",
      "epoch 12; iter: 600; batch classifier loss: 0.366301; batch adversarial loss: 0.413410\n",
      "epoch 13; iter: 0; batch classifier loss: 0.304911; batch adversarial loss: 0.596901\n",
      "epoch 13; iter: 200; batch classifier loss: 0.287232; batch adversarial loss: 0.545159\n",
      "epoch 13; iter: 400; batch classifier loss: 0.520039; batch adversarial loss: 0.347948\n",
      "epoch 13; iter: 600; batch classifier loss: 0.402793; batch adversarial loss: 0.494815\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279235; batch adversarial loss: 0.499076\n",
      "epoch 14; iter: 200; batch classifier loss: 0.264365; batch adversarial loss: 0.372223\n",
      "epoch 14; iter: 400; batch classifier loss: 0.279933; batch adversarial loss: 0.448703\n",
      "epoch 14; iter: 600; batch classifier loss: 0.388348; batch adversarial loss: 0.297956\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391796; batch adversarial loss: 0.376892\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392744; batch adversarial loss: 0.517899\n",
      "epoch 15; iter: 400; batch classifier loss: 0.173521; batch adversarial loss: 0.618581\n",
      "epoch 15; iter: 600; batch classifier loss: 0.471626; batch adversarial loss: 0.394617\n",
      "epoch 16; iter: 0; batch classifier loss: 0.390365; batch adversarial loss: 0.326357\n",
      "epoch 16; iter: 200; batch classifier loss: 0.397994; batch adversarial loss: 0.391911\n",
      "epoch 16; iter: 400; batch classifier loss: 0.412777; batch adversarial loss: 0.449931\n",
      "epoch 16; iter: 600; batch classifier loss: 0.305347; batch adversarial loss: 0.423897\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317991; batch adversarial loss: 0.456519\n",
      "epoch 17; iter: 200; batch classifier loss: 0.425875; batch adversarial loss: 0.396633\n",
      "epoch 17; iter: 400; batch classifier loss: 0.332944; batch adversarial loss: 0.459700\n",
      "epoch 17; iter: 600; batch classifier loss: 0.491619; batch adversarial loss: 0.534341\n",
      "epoch 18; iter: 0; batch classifier loss: 0.407765; batch adversarial loss: 0.319301\n",
      "epoch 18; iter: 200; batch classifier loss: 0.310799; batch adversarial loss: 0.428790\n",
      "epoch 18; iter: 400; batch classifier loss: 0.422198; batch adversarial loss: 0.443670\n",
      "epoch 18; iter: 600; batch classifier loss: 0.360242; batch adversarial loss: 0.349604\n",
      "epoch 19; iter: 0; batch classifier loss: 0.359376; batch adversarial loss: 0.468024\n",
      "epoch 19; iter: 200; batch classifier loss: 0.499521; batch adversarial loss: 0.482975\n",
      "epoch 19; iter: 400; batch classifier loss: 0.351087; batch adversarial loss: 0.320522\n",
      "epoch 19; iter: 600; batch classifier loss: 0.464302; batch adversarial loss: 0.371217\n",
      "epoch 0; iter: 0; batch classifier loss: 0.749311; batch adversarial loss: 1.144908\n",
      "epoch 0; iter: 200; batch classifier loss: 6.803846; batch adversarial loss: 0.951809\n",
      "epoch 0; iter: 400; batch classifier loss: 50.510838; batch adversarial loss: 0.795686\n",
      "epoch 0; iter: 600; batch classifier loss: 11.773471; batch adversarial loss: 0.646390\n",
      "epoch 1; iter: 0; batch classifier loss: 5.106622; batch adversarial loss: 0.637239\n",
      "epoch 1; iter: 200; batch classifier loss: 1.141876; batch adversarial loss: 0.484036\n",
      "epoch 1; iter: 400; batch classifier loss: 4.973239; batch adversarial loss: 0.465537\n",
      "epoch 1; iter: 600; batch classifier loss: 3.513221; batch adversarial loss: 0.515893\n",
      "epoch 2; iter: 0; batch classifier loss: 12.516075; batch adversarial loss: 0.516776\n",
      "epoch 2; iter: 200; batch classifier loss: 2.292329; batch adversarial loss: 0.402338\n",
      "epoch 2; iter: 400; batch classifier loss: 2.883045; batch adversarial loss: 0.477771\n",
      "epoch 2; iter: 600; batch classifier loss: 0.732147; batch adversarial loss: 0.404107\n",
      "epoch 3; iter: 0; batch classifier loss: 4.441207; batch adversarial loss: 0.505726\n",
      "epoch 3; iter: 200; batch classifier loss: 1.960067; batch adversarial loss: 0.448439\n",
      "epoch 3; iter: 400; batch classifier loss: 3.947815; batch adversarial loss: 0.457995\n",
      "epoch 3; iter: 600; batch classifier loss: 1.269867; batch adversarial loss: 0.417534\n",
      "epoch 4; iter: 0; batch classifier loss: 0.416118; batch adversarial loss: 0.421860\n",
      "epoch 4; iter: 200; batch classifier loss: 0.382595; batch adversarial loss: 0.388382\n",
      "epoch 4; iter: 400; batch classifier loss: 0.479755; batch adversarial loss: 0.502835\n",
      "epoch 4; iter: 600; batch classifier loss: 1.602314; batch adversarial loss: 0.406957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.739007; batch adversarial loss: 0.310290\n",
      "epoch 5; iter: 200; batch classifier loss: 0.621976; batch adversarial loss: 0.478546\n",
      "epoch 5; iter: 400; batch classifier loss: 0.411239; batch adversarial loss: 0.381895\n",
      "epoch 5; iter: 600; batch classifier loss: 0.463517; batch adversarial loss: 0.507394\n",
      "epoch 6; iter: 0; batch classifier loss: 0.450084; batch adversarial loss: 0.520049\n",
      "epoch 6; iter: 200; batch classifier loss: 0.643981; batch adversarial loss: 0.303247\n",
      "epoch 6; iter: 400; batch classifier loss: 0.560678; batch adversarial loss: 0.528722\n",
      "epoch 6; iter: 600; batch classifier loss: 0.358161; batch adversarial loss: 0.404010\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559851; batch adversarial loss: 0.404942\n",
      "epoch 7; iter: 200; batch classifier loss: 0.613481; batch adversarial loss: 0.403185\n",
      "epoch 7; iter: 400; batch classifier loss: 0.641123; batch adversarial loss: 0.432283\n",
      "epoch 7; iter: 600; batch classifier loss: 0.469379; batch adversarial loss: 0.372656\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340943; batch adversarial loss: 0.454869\n",
      "epoch 8; iter: 200; batch classifier loss: 0.286339; batch adversarial loss: 0.455041\n",
      "epoch 8; iter: 400; batch classifier loss: 0.418138; batch adversarial loss: 0.342248\n",
      "epoch 8; iter: 600; batch classifier loss: 0.379412; batch adversarial loss: 0.299058\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420793; batch adversarial loss: 0.321475\n",
      "epoch 9; iter: 200; batch classifier loss: 0.346078; batch adversarial loss: 0.531143\n",
      "epoch 9; iter: 400; batch classifier loss: 0.414838; batch adversarial loss: 0.411570\n",
      "epoch 9; iter: 600; batch classifier loss: 0.432945; batch adversarial loss: 0.494524\n",
      "epoch 10; iter: 0; batch classifier loss: 0.671330; batch adversarial loss: 0.540076\n",
      "epoch 10; iter: 200; batch classifier loss: 0.451539; batch adversarial loss: 0.321040\n",
      "epoch 10; iter: 400; batch classifier loss: 0.306490; batch adversarial loss: 0.410860\n",
      "epoch 10; iter: 600; batch classifier loss: 0.382406; batch adversarial loss: 0.469034\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447172; batch adversarial loss: 0.511897\n",
      "epoch 11; iter: 200; batch classifier loss: 0.240694; batch adversarial loss: 0.355244\n",
      "epoch 11; iter: 400; batch classifier loss: 0.321262; batch adversarial loss: 0.439230\n",
      "epoch 11; iter: 600; batch classifier loss: 0.328727; batch adversarial loss: 0.356664\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361786; batch adversarial loss: 0.488574\n",
      "epoch 12; iter: 200; batch classifier loss: 0.339468; batch adversarial loss: 0.423890\n",
      "epoch 12; iter: 400; batch classifier loss: 0.397558; batch adversarial loss: 0.372284\n",
      "epoch 12; iter: 600; batch classifier loss: 0.419557; batch adversarial loss: 0.384050\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383473; batch adversarial loss: 0.404488\n",
      "epoch 13; iter: 200; batch classifier loss: 0.420034; batch adversarial loss: 0.563882\n",
      "epoch 13; iter: 400; batch classifier loss: 0.332516; batch adversarial loss: 0.469651\n",
      "epoch 13; iter: 600; batch classifier loss: 0.307280; batch adversarial loss: 0.233888\n",
      "epoch 14; iter: 0; batch classifier loss: 0.323920; batch adversarial loss: 0.587655\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378651; batch adversarial loss: 0.460333\n",
      "epoch 14; iter: 400; batch classifier loss: 0.397086; batch adversarial loss: 0.396746\n",
      "epoch 14; iter: 600; batch classifier loss: 0.286209; batch adversarial loss: 0.480420\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349116; batch adversarial loss: 0.431492\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392740; batch adversarial loss: 0.508836\n",
      "epoch 15; iter: 400; batch classifier loss: 0.459036; batch adversarial loss: 0.398885\n",
      "epoch 15; iter: 600; batch classifier loss: 0.355606; batch adversarial loss: 0.401942\n",
      "epoch 16; iter: 0; batch classifier loss: 0.321758; batch adversarial loss: 0.557257\n",
      "epoch 16; iter: 200; batch classifier loss: 0.334052; batch adversarial loss: 0.421120\n",
      "epoch 16; iter: 400; batch classifier loss: 0.323529; batch adversarial loss: 0.463311\n",
      "epoch 16; iter: 600; batch classifier loss: 0.431247; batch adversarial loss: 0.395818\n",
      "epoch 17; iter: 0; batch classifier loss: 0.415547; batch adversarial loss: 0.376796\n",
      "epoch 17; iter: 200; batch classifier loss: 0.405399; batch adversarial loss: 0.365107\n",
      "epoch 17; iter: 400; batch classifier loss: 0.397530; batch adversarial loss: 0.368964\n",
      "epoch 17; iter: 600; batch classifier loss: 0.458934; batch adversarial loss: 0.549887\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328006; batch adversarial loss: 0.348305\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382312; batch adversarial loss: 0.429633\n",
      "epoch 18; iter: 400; batch classifier loss: 0.283040; batch adversarial loss: 0.448564\n",
      "epoch 18; iter: 600; batch classifier loss: 0.340094; batch adversarial loss: 0.592250\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451279; batch adversarial loss: 0.323144\n",
      "epoch 19; iter: 200; batch classifier loss: 0.340811; batch adversarial loss: 0.426089\n",
      "epoch 19; iter: 400; batch classifier loss: 0.330130; batch adversarial loss: 0.386001\n",
      "epoch 19; iter: 600; batch classifier loss: 0.428495; batch adversarial loss: 0.370183\n",
      "epoch 0; iter: 0; batch classifier loss: 12.149324; batch adversarial loss: 0.530988\n",
      "epoch 0; iter: 200; batch classifier loss: 9.971982; batch adversarial loss: 0.594521\n",
      "epoch 0; iter: 400; batch classifier loss: 29.975790; batch adversarial loss: 0.548719\n",
      "epoch 0; iter: 600; batch classifier loss: 12.456512; batch adversarial loss: 0.430013\n",
      "epoch 1; iter: 0; batch classifier loss: 4.496045; batch adversarial loss: 0.561666\n",
      "epoch 1; iter: 200; batch classifier loss: 1.072896; batch adversarial loss: 0.478930\n",
      "epoch 1; iter: 400; batch classifier loss: 1.263496; batch adversarial loss: 0.544088\n",
      "epoch 1; iter: 600; batch classifier loss: 3.167034; batch adversarial loss: 0.500320\n",
      "epoch 2; iter: 0; batch classifier loss: 7.009200; batch adversarial loss: 0.429847\n",
      "epoch 2; iter: 200; batch classifier loss: 5.854292; batch adversarial loss: 0.397151\n",
      "epoch 2; iter: 400; batch classifier loss: 0.704613; batch adversarial loss: 0.443588\n",
      "epoch 2; iter: 600; batch classifier loss: 7.630583; batch adversarial loss: 0.301355\n",
      "epoch 3; iter: 0; batch classifier loss: 3.688427; batch adversarial loss: 0.324477\n",
      "epoch 3; iter: 200; batch classifier loss: 1.144390; batch adversarial loss: 0.448300\n",
      "epoch 3; iter: 400; batch classifier loss: 1.784392; batch adversarial loss: 0.370865\n",
      "epoch 3; iter: 600; batch classifier loss: 1.237082; batch adversarial loss: 0.427501\n",
      "epoch 4; iter: 0; batch classifier loss: 1.160069; batch adversarial loss: 0.396351\n",
      "epoch 4; iter: 200; batch classifier loss: 0.746552; batch adversarial loss: 0.320791\n",
      "epoch 4; iter: 400; batch classifier loss: 0.765775; batch adversarial loss: 0.432979\n",
      "epoch 4; iter: 600; batch classifier loss: 0.482345; batch adversarial loss: 0.411585\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506810; batch adversarial loss: 0.511549\n",
      "epoch 5; iter: 200; batch classifier loss: 0.363804; batch adversarial loss: 0.536288\n",
      "epoch 5; iter: 400; batch classifier loss: 0.451909; batch adversarial loss: 0.353209\n",
      "epoch 5; iter: 600; batch classifier loss: 0.355482; batch adversarial loss: 0.460996\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480608; batch adversarial loss: 0.323504\n",
      "epoch 6; iter: 200; batch classifier loss: 0.380451; batch adversarial loss: 0.590736\n",
      "epoch 6; iter: 400; batch classifier loss: 0.420499; batch adversarial loss: 0.538709\n",
      "epoch 6; iter: 600; batch classifier loss: 0.393989; batch adversarial loss: 0.349999\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587488; batch adversarial loss: 0.421405\n",
      "epoch 7; iter: 200; batch classifier loss: 0.467405; batch adversarial loss: 0.387188\n",
      "epoch 7; iter: 400; batch classifier loss: 0.357838; batch adversarial loss: 0.438874\n",
      "epoch 7; iter: 600; batch classifier loss: 0.469591; batch adversarial loss: 0.421925\n",
      "epoch 8; iter: 0; batch classifier loss: 0.552992; batch adversarial loss: 0.344486\n",
      "epoch 8; iter: 200; batch classifier loss: 0.435477; batch adversarial loss: 0.371074\n",
      "epoch 8; iter: 400; batch classifier loss: 0.396690; batch adversarial loss: 0.430513\n",
      "epoch 8; iter: 600; batch classifier loss: 0.299114; batch adversarial loss: 0.321605\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475758; batch adversarial loss: 0.380567\n",
      "epoch 9; iter: 200; batch classifier loss: 0.505845; batch adversarial loss: 0.350865\n",
      "epoch 9; iter: 400; batch classifier loss: 0.415415; batch adversarial loss: 0.297110\n",
      "epoch 9; iter: 600; batch classifier loss: 0.208807; batch adversarial loss: 0.548914\n",
      "epoch 10; iter: 0; batch classifier loss: 0.395509; batch adversarial loss: 0.379348\n",
      "epoch 10; iter: 200; batch classifier loss: 0.407329; batch adversarial loss: 0.380063\n",
      "epoch 10; iter: 400; batch classifier loss: 0.474848; batch adversarial loss: 0.330284\n",
      "epoch 10; iter: 600; batch classifier loss: 0.368826; batch adversarial loss: 0.340007\n",
      "epoch 11; iter: 0; batch classifier loss: 0.338068; batch adversarial loss: 0.475507\n",
      "epoch 11; iter: 200; batch classifier loss: 0.331538; batch adversarial loss: 0.405146\n",
      "epoch 11; iter: 400; batch classifier loss: 0.363672; batch adversarial loss: 0.317028\n",
      "epoch 11; iter: 600; batch classifier loss: 0.262255; batch adversarial loss: 0.410782\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496626; batch adversarial loss: 0.439329\n",
      "epoch 12; iter: 200; batch classifier loss: 0.487806; batch adversarial loss: 0.379417\n",
      "epoch 12; iter: 400; batch classifier loss: 0.282923; batch adversarial loss: 0.485116\n",
      "epoch 12; iter: 600; batch classifier loss: 0.367403; batch adversarial loss: 0.600537\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301627; batch adversarial loss: 0.425810\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352751; batch adversarial loss: 0.495464\n",
      "epoch 13; iter: 400; batch classifier loss: 0.339393; batch adversarial loss: 0.396059\n",
      "epoch 13; iter: 600; batch classifier loss: 0.337168; batch adversarial loss: 0.405268\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299924; batch adversarial loss: 0.238937\n",
      "epoch 14; iter: 200; batch classifier loss: 0.309595; batch adversarial loss: 0.428925\n",
      "epoch 14; iter: 400; batch classifier loss: 0.234882; batch adversarial loss: 0.497102\n",
      "epoch 14; iter: 600; batch classifier loss: 0.332373; batch adversarial loss: 0.393584\n",
      "epoch 15; iter: 0; batch classifier loss: 0.456816; batch adversarial loss: 0.432905\n",
      "epoch 15; iter: 200; batch classifier loss: 0.309577; batch adversarial loss: 0.451822\n",
      "epoch 15; iter: 400; batch classifier loss: 0.381872; batch adversarial loss: 0.458002\n",
      "epoch 15; iter: 600; batch classifier loss: 0.395752; batch adversarial loss: 0.406193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442640; batch adversarial loss: 0.569170\n",
      "epoch 16; iter: 200; batch classifier loss: 0.323776; batch adversarial loss: 0.547458\n",
      "epoch 16; iter: 400; batch classifier loss: 0.280651; batch adversarial loss: 0.319253\n",
      "epoch 16; iter: 600; batch classifier loss: 0.453376; batch adversarial loss: 0.420521\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314719; batch adversarial loss: 0.514610\n",
      "epoch 17; iter: 200; batch classifier loss: 0.352471; batch adversarial loss: 0.349951\n",
      "epoch 17; iter: 400; batch classifier loss: 0.485118; batch adversarial loss: 0.456405\n",
      "epoch 17; iter: 600; batch classifier loss: 0.380608; batch adversarial loss: 0.489035\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438569; batch adversarial loss: 0.432515\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341178; batch adversarial loss: 0.487140\n",
      "epoch 18; iter: 400; batch classifier loss: 0.287954; batch adversarial loss: 0.300392\n",
      "epoch 18; iter: 600; batch classifier loss: 0.301176; batch adversarial loss: 0.329160\n",
      "epoch 19; iter: 0; batch classifier loss: 0.281215; batch adversarial loss: 0.393769\n",
      "epoch 19; iter: 200; batch classifier loss: 0.364786; batch adversarial loss: 0.497498\n",
      "epoch 19; iter: 400; batch classifier loss: 0.370728; batch adversarial loss: 0.445430\n",
      "epoch 19; iter: 600; batch classifier loss: 0.348120; batch adversarial loss: 0.323949\n",
      "epoch 0; iter: 0; batch classifier loss: 0.616872; batch adversarial loss: 0.858760\n",
      "epoch 0; iter: 200; batch classifier loss: 18.816755; batch adversarial loss: 0.785068\n",
      "epoch 0; iter: 400; batch classifier loss: 6.563374; batch adversarial loss: 0.636198\n",
      "epoch 0; iter: 600; batch classifier loss: 17.466896; batch adversarial loss: 0.546712\n",
      "epoch 1; iter: 0; batch classifier loss: 7.090049; batch adversarial loss: 0.511430\n",
      "epoch 1; iter: 200; batch classifier loss: 0.935310; batch adversarial loss: 0.482241\n",
      "epoch 1; iter: 400; batch classifier loss: 5.650272; batch adversarial loss: 0.498480\n",
      "epoch 1; iter: 600; batch classifier loss: 1.297894; batch adversarial loss: 0.376174\n",
      "epoch 2; iter: 0; batch classifier loss: 0.925532; batch adversarial loss: 0.382336\n",
      "epoch 2; iter: 200; batch classifier loss: 0.825624; batch adversarial loss: 0.399112\n",
      "epoch 2; iter: 400; batch classifier loss: 5.929470; batch adversarial loss: 0.364486\n",
      "epoch 2; iter: 600; batch classifier loss: 2.362996; batch adversarial loss: 0.504853\n",
      "epoch 3; iter: 0; batch classifier loss: 0.361053; batch adversarial loss: 0.430084\n",
      "epoch 3; iter: 200; batch classifier loss: 3.860406; batch adversarial loss: 0.394808\n",
      "epoch 3; iter: 400; batch classifier loss: 0.432586; batch adversarial loss: 0.480935\n",
      "epoch 3; iter: 600; batch classifier loss: 0.773291; batch adversarial loss: 0.505035\n",
      "epoch 4; iter: 0; batch classifier loss: 1.349707; batch adversarial loss: 0.428134\n",
      "epoch 4; iter: 200; batch classifier loss: 1.191305; batch adversarial loss: 0.363005\n",
      "epoch 4; iter: 400; batch classifier loss: 0.745766; batch adversarial loss: 0.458875\n",
      "epoch 4; iter: 600; batch classifier loss: 0.440393; batch adversarial loss: 0.377019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483720; batch adversarial loss: 0.523287\n",
      "epoch 5; iter: 200; batch classifier loss: 0.416277; batch adversarial loss: 0.530122\n",
      "epoch 5; iter: 400; batch classifier loss: 1.154398; batch adversarial loss: 0.476288\n",
      "epoch 5; iter: 600; batch classifier loss: 0.620767; batch adversarial loss: 0.364892\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473392; batch adversarial loss: 0.331618\n",
      "epoch 6; iter: 200; batch classifier loss: 0.690542; batch adversarial loss: 0.416179\n",
      "epoch 6; iter: 400; batch classifier loss: 0.486734; batch adversarial loss: 0.295429\n",
      "epoch 6; iter: 600; batch classifier loss: 0.511059; batch adversarial loss: 0.518963\n",
      "epoch 7; iter: 0; batch classifier loss: 0.375987; batch adversarial loss: 0.400068\n",
      "epoch 7; iter: 200; batch classifier loss: 0.333603; batch adversarial loss: 0.628142\n",
      "epoch 7; iter: 400; batch classifier loss: 0.348663; batch adversarial loss: 0.501429\n",
      "epoch 7; iter: 600; batch classifier loss: 0.346825; batch adversarial loss: 0.294570\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381827; batch adversarial loss: 0.502807\n",
      "epoch 8; iter: 200; batch classifier loss: 0.519237; batch adversarial loss: 0.468538\n",
      "epoch 8; iter: 400; batch classifier loss: 0.360630; batch adversarial loss: 0.440369\n",
      "epoch 8; iter: 600; batch classifier loss: 0.360444; batch adversarial loss: 0.345932\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517663; batch adversarial loss: 0.383200\n",
      "epoch 9; iter: 200; batch classifier loss: 0.353373; batch adversarial loss: 0.416355\n",
      "epoch 9; iter: 400; batch classifier loss: 0.378500; batch adversarial loss: 0.401667\n",
      "epoch 9; iter: 600; batch classifier loss: 0.380084; batch adversarial loss: 0.436828\n",
      "epoch 10; iter: 0; batch classifier loss: 0.409526; batch adversarial loss: 0.357962\n",
      "epoch 10; iter: 200; batch classifier loss: 0.328416; batch adversarial loss: 0.327958\n",
      "epoch 10; iter: 400; batch classifier loss: 0.453419; batch adversarial loss: 0.481642\n",
      "epoch 10; iter: 600; batch classifier loss: 0.462819; batch adversarial loss: 0.466636\n",
      "epoch 11; iter: 0; batch classifier loss: 0.462288; batch adversarial loss: 0.564024\n",
      "epoch 11; iter: 200; batch classifier loss: 0.344245; batch adversarial loss: 0.447628\n",
      "epoch 11; iter: 400; batch classifier loss: 0.378531; batch adversarial loss: 0.380866\n",
      "epoch 11; iter: 600; batch classifier loss: 0.335912; batch adversarial loss: 0.380178\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365369; batch adversarial loss: 0.472052\n",
      "epoch 12; iter: 200; batch classifier loss: 0.397075; batch adversarial loss: 0.415580\n",
      "epoch 12; iter: 400; batch classifier loss: 0.288963; batch adversarial loss: 0.427548\n",
      "epoch 12; iter: 600; batch classifier loss: 0.357405; batch adversarial loss: 0.402936\n",
      "epoch 13; iter: 0; batch classifier loss: 0.334862; batch adversarial loss: 0.425021\n",
      "epoch 13; iter: 200; batch classifier loss: 0.361692; batch adversarial loss: 0.318019\n",
      "epoch 13; iter: 400; batch classifier loss: 0.350796; batch adversarial loss: 0.617543\n",
      "epoch 13; iter: 600; batch classifier loss: 0.527318; batch adversarial loss: 0.470977\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368035; batch adversarial loss: 0.369956\n",
      "epoch 14; iter: 200; batch classifier loss: 0.450518; batch adversarial loss: 0.615478\n",
      "epoch 14; iter: 400; batch classifier loss: 0.443551; batch adversarial loss: 0.342844\n",
      "epoch 14; iter: 600; batch classifier loss: 0.386212; batch adversarial loss: 0.407746\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507762; batch adversarial loss: 0.381116\n",
      "epoch 15; iter: 200; batch classifier loss: 0.431629; batch adversarial loss: 0.382568\n",
      "epoch 15; iter: 400; batch classifier loss: 0.397933; batch adversarial loss: 0.453269\n",
      "epoch 15; iter: 600; batch classifier loss: 0.418799; batch adversarial loss: 0.467635\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382173; batch adversarial loss: 0.448185\n",
      "epoch 16; iter: 200; batch classifier loss: 0.496444; batch adversarial loss: 0.377720\n",
      "epoch 16; iter: 400; batch classifier loss: 0.405895; batch adversarial loss: 0.403192\n",
      "epoch 16; iter: 600; batch classifier loss: 0.314018; batch adversarial loss: 0.479930\n",
      "epoch 17; iter: 0; batch classifier loss: 0.311905; batch adversarial loss: 0.295838\n",
      "epoch 17; iter: 200; batch classifier loss: 0.401743; batch adversarial loss: 0.392052\n",
      "epoch 17; iter: 400; batch classifier loss: 0.396518; batch adversarial loss: 0.392413\n",
      "epoch 17; iter: 600; batch classifier loss: 0.483839; batch adversarial loss: 0.456193\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370118; batch adversarial loss: 0.537752\n",
      "epoch 18; iter: 200; batch classifier loss: 0.449907; batch adversarial loss: 0.375159\n",
      "epoch 18; iter: 400; batch classifier loss: 0.318574; batch adversarial loss: 0.370963\n",
      "epoch 18; iter: 600; batch classifier loss: 0.297265; batch adversarial loss: 0.417887\n",
      "epoch 19; iter: 0; batch classifier loss: 0.381857; batch adversarial loss: 0.431720\n",
      "epoch 19; iter: 200; batch classifier loss: 0.326827; batch adversarial loss: 0.368642\n",
      "epoch 19; iter: 400; batch classifier loss: 0.296410; batch adversarial loss: 0.400322\n",
      "epoch 19; iter: 600; batch classifier loss: 0.356237; batch adversarial loss: 0.323587\n",
      "epoch 0; iter: 0; batch classifier loss: 15.521159; batch adversarial loss: 0.523474\n",
      "epoch 0; iter: 200; batch classifier loss: 3.532052; batch adversarial loss: 0.549787\n",
      "epoch 0; iter: 400; batch classifier loss: 12.508842; batch adversarial loss: 0.475806\n",
      "epoch 0; iter: 600; batch classifier loss: 11.160376; batch adversarial loss: 0.482576\n",
      "epoch 1; iter: 0; batch classifier loss: 21.996395; batch adversarial loss: 0.431837\n",
      "epoch 1; iter: 200; batch classifier loss: 13.730813; batch adversarial loss: 0.464692\n",
      "epoch 1; iter: 400; batch classifier loss: 1.684511; batch adversarial loss: 0.467506\n",
      "epoch 1; iter: 600; batch classifier loss: 1.434629; batch adversarial loss: 0.472983\n",
      "epoch 2; iter: 0; batch classifier loss: 3.547058; batch adversarial loss: 0.419184\n",
      "epoch 2; iter: 200; batch classifier loss: 4.743614; batch adversarial loss: 0.371734\n",
      "epoch 2; iter: 400; batch classifier loss: 1.130120; batch adversarial loss: 0.430101\n",
      "epoch 2; iter: 600; batch classifier loss: 2.318692; batch adversarial loss: 0.373654\n",
      "epoch 3; iter: 0; batch classifier loss: 1.469537; batch adversarial loss: 0.501473\n",
      "epoch 3; iter: 200; batch classifier loss: 2.103145; batch adversarial loss: 0.409721\n",
      "epoch 3; iter: 400; batch classifier loss: 2.562493; batch adversarial loss: 0.394187\n",
      "epoch 3; iter: 600; batch classifier loss: 1.819014; batch adversarial loss: 0.352613\n",
      "epoch 4; iter: 0; batch classifier loss: 1.723960; batch adversarial loss: 0.427327\n",
      "epoch 4; iter: 200; batch classifier loss: 1.464521; batch adversarial loss: 0.447014\n",
      "epoch 4; iter: 400; batch classifier loss: 0.878787; batch adversarial loss: 0.364964\n",
      "epoch 4; iter: 600; batch classifier loss: 0.644389; batch adversarial loss: 0.279228\n",
      "epoch 5; iter: 0; batch classifier loss: 0.819035; batch adversarial loss: 0.576609\n",
      "epoch 5; iter: 200; batch classifier loss: 0.387554; batch adversarial loss: 0.400888\n",
      "epoch 5; iter: 400; batch classifier loss: 0.496797; batch adversarial loss: 0.510514\n",
      "epoch 5; iter: 600; batch classifier loss: 0.500722; batch adversarial loss: 0.332116\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414326; batch adversarial loss: 0.329832\n",
      "epoch 6; iter: 200; batch classifier loss: 0.510761; batch adversarial loss: 0.342316\n",
      "epoch 6; iter: 400; batch classifier loss: 0.280360; batch adversarial loss: 0.409850\n",
      "epoch 6; iter: 600; batch classifier loss: 0.441574; batch adversarial loss: 0.546496\n",
      "epoch 7; iter: 0; batch classifier loss: 0.355610; batch adversarial loss: 0.399561\n",
      "epoch 7; iter: 200; batch classifier loss: 0.343033; batch adversarial loss: 0.619283\n",
      "epoch 7; iter: 400; batch classifier loss: 0.393937; batch adversarial loss: 0.388705\n",
      "epoch 7; iter: 600; batch classifier loss: 0.565523; batch adversarial loss: 0.450712\n",
      "epoch 8; iter: 0; batch classifier loss: 0.365317; batch adversarial loss: 0.315085\n",
      "epoch 8; iter: 200; batch classifier loss: 0.307468; batch adversarial loss: 0.357355\n",
      "epoch 8; iter: 400; batch classifier loss: 0.348219; batch adversarial loss: 0.429958\n",
      "epoch 8; iter: 600; batch classifier loss: 0.249047; batch adversarial loss: 0.342613\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436665; batch adversarial loss: 0.516645\n",
      "epoch 9; iter: 200; batch classifier loss: 0.365517; batch adversarial loss: 0.455461\n",
      "epoch 9; iter: 400; batch classifier loss: 0.378778; batch adversarial loss: 0.469982\n",
      "epoch 9; iter: 600; batch classifier loss: 0.311182; batch adversarial loss: 0.349618\n",
      "epoch 10; iter: 0; batch classifier loss: 0.330797; batch adversarial loss: 0.457822\n",
      "epoch 10; iter: 200; batch classifier loss: 0.508764; batch adversarial loss: 0.314666\n",
      "epoch 10; iter: 400; batch classifier loss: 0.297944; batch adversarial loss: 0.531971\n",
      "epoch 10; iter: 600; batch classifier loss: 0.269309; batch adversarial loss: 0.385195\n",
      "epoch 11; iter: 0; batch classifier loss: 0.280674; batch adversarial loss: 0.522308\n",
      "epoch 11; iter: 200; batch classifier loss: 0.400379; batch adversarial loss: 0.402770\n",
      "epoch 11; iter: 400; batch classifier loss: 0.321502; batch adversarial loss: 0.383502\n",
      "epoch 11; iter: 600; batch classifier loss: 0.439218; batch adversarial loss: 0.377746\n",
      "epoch 12; iter: 0; batch classifier loss: 0.423017; batch adversarial loss: 0.462265\n",
      "epoch 12; iter: 200; batch classifier loss: 0.357137; batch adversarial loss: 0.453253\n",
      "epoch 12; iter: 400; batch classifier loss: 0.418248; batch adversarial loss: 0.463239\n",
      "epoch 12; iter: 600; batch classifier loss: 0.390260; batch adversarial loss: 0.510057\n",
      "epoch 13; iter: 0; batch classifier loss: 0.426504; batch adversarial loss: 0.337651\n",
      "epoch 13; iter: 200; batch classifier loss: 0.386414; batch adversarial loss: 0.609916\n",
      "epoch 13; iter: 400; batch classifier loss: 0.287703; batch adversarial loss: 0.484216\n",
      "epoch 13; iter: 600; batch classifier loss: 0.308150; batch adversarial loss: 0.364079\n",
      "epoch 14; iter: 0; batch classifier loss: 0.317108; batch adversarial loss: 0.471014\n",
      "epoch 14; iter: 200; batch classifier loss: 0.329105; batch adversarial loss: 0.507405\n",
      "epoch 14; iter: 400; batch classifier loss: 0.332133; batch adversarial loss: 0.397629\n",
      "epoch 14; iter: 600; batch classifier loss: 0.362339; batch adversarial loss: 0.441907\n",
      "epoch 15; iter: 0; batch classifier loss: 0.319915; batch adversarial loss: 0.606730\n",
      "epoch 15; iter: 200; batch classifier loss: 0.302807; batch adversarial loss: 0.342520\n",
      "epoch 15; iter: 400; batch classifier loss: 0.349135; batch adversarial loss: 0.390705\n",
      "epoch 15; iter: 600; batch classifier loss: 0.426478; batch adversarial loss: 0.517753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.194980; batch adversarial loss: 0.475751\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342117; batch adversarial loss: 0.557544\n",
      "epoch 16; iter: 400; batch classifier loss: 0.267566; batch adversarial loss: 0.402004\n",
      "epoch 16; iter: 600; batch classifier loss: 0.437962; batch adversarial loss: 0.360882\n",
      "epoch 17; iter: 0; batch classifier loss: 0.314545; batch adversarial loss: 0.239518\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349451; batch adversarial loss: 0.409693\n",
      "epoch 17; iter: 400; batch classifier loss: 0.250830; batch adversarial loss: 0.554700\n",
      "epoch 17; iter: 600; batch classifier loss: 0.299526; batch adversarial loss: 0.382663\n",
      "epoch 18; iter: 0; batch classifier loss: 0.353679; batch adversarial loss: 0.466710\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373227; batch adversarial loss: 0.405631\n",
      "epoch 18; iter: 400; batch classifier loss: 0.351527; batch adversarial loss: 0.407870\n",
      "epoch 18; iter: 600; batch classifier loss: 0.376541; batch adversarial loss: 0.443711\n",
      "epoch 19; iter: 0; batch classifier loss: 0.372275; batch adversarial loss: 0.349125\n",
      "epoch 19; iter: 200; batch classifier loss: 0.217642; batch adversarial loss: 0.364575\n",
      "epoch 19; iter: 400; batch classifier loss: 0.323516; batch adversarial loss: 0.470326\n",
      "epoch 19; iter: 600; batch classifier loss: 0.376307; batch adversarial loss: 0.490280\n",
      "epoch 0; iter: 0; batch classifier loss: 99.544533; batch adversarial loss: 0.819730\n",
      "epoch 0; iter: 200; batch classifier loss: 6.583233; batch adversarial loss: 0.685778\n",
      "epoch 0; iter: 400; batch classifier loss: 4.566684; batch adversarial loss: 0.592918\n",
      "epoch 0; iter: 600; batch classifier loss: 4.941728; batch adversarial loss: 0.507423\n",
      "epoch 1; iter: 0; batch classifier loss: 2.901049; batch adversarial loss: 0.528963\n",
      "epoch 1; iter: 200; batch classifier loss: 13.426882; batch adversarial loss: 0.473380\n",
      "epoch 1; iter: 400; batch classifier loss: 6.823519; batch adversarial loss: 0.412153\n",
      "epoch 1; iter: 600; batch classifier loss: 2.556267; batch adversarial loss: 0.458751\n",
      "epoch 2; iter: 0; batch classifier loss: 20.762438; batch adversarial loss: 0.469356\n",
      "epoch 2; iter: 200; batch classifier loss: 1.109913; batch adversarial loss: 0.438044\n",
      "epoch 2; iter: 400; batch classifier loss: 2.667304; batch adversarial loss: 0.584570\n",
      "epoch 2; iter: 600; batch classifier loss: 1.003129; batch adversarial loss: 0.398072\n",
      "epoch 3; iter: 0; batch classifier loss: 2.632233; batch adversarial loss: 0.438248\n",
      "epoch 3; iter: 200; batch classifier loss: 2.448552; batch adversarial loss: 0.495028\n",
      "epoch 3; iter: 400; batch classifier loss: 3.303940; batch adversarial loss: 0.541568\n",
      "epoch 3; iter: 600; batch classifier loss: 0.552803; batch adversarial loss: 0.307195\n",
      "epoch 4; iter: 0; batch classifier loss: 0.444468; batch adversarial loss: 0.424844\n",
      "epoch 4; iter: 200; batch classifier loss: 0.522413; batch adversarial loss: 0.424978\n",
      "epoch 4; iter: 400; batch classifier loss: 0.694413; batch adversarial loss: 0.397619\n",
      "epoch 4; iter: 600; batch classifier loss: 2.058105; batch adversarial loss: 0.358460\n",
      "epoch 5; iter: 0; batch classifier loss: 0.501125; batch adversarial loss: 0.430062\n",
      "epoch 5; iter: 200; batch classifier loss: 0.508801; batch adversarial loss: 0.318833\n",
      "epoch 5; iter: 400; batch classifier loss: 1.152390; batch adversarial loss: 0.407788\n",
      "epoch 5; iter: 600; batch classifier loss: 1.055951; batch adversarial loss: 0.420986\n",
      "epoch 6; iter: 0; batch classifier loss: 0.462918; batch adversarial loss: 0.261562\n",
      "epoch 6; iter: 200; batch classifier loss: 0.366559; batch adversarial loss: 0.352228\n",
      "epoch 6; iter: 400; batch classifier loss: 0.433476; batch adversarial loss: 0.423226\n",
      "epoch 6; iter: 600; batch classifier loss: 0.624941; batch adversarial loss: 0.460885\n",
      "epoch 7; iter: 0; batch classifier loss: 0.487267; batch adversarial loss: 0.381460\n",
      "epoch 7; iter: 200; batch classifier loss: 0.320755; batch adversarial loss: 0.451649\n",
      "epoch 7; iter: 400; batch classifier loss: 0.385657; batch adversarial loss: 0.342534\n",
      "epoch 7; iter: 600; batch classifier loss: 0.341302; batch adversarial loss: 0.389182\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360424; batch adversarial loss: 0.282932\n",
      "epoch 8; iter: 200; batch classifier loss: 0.526933; batch adversarial loss: 0.356352\n",
      "epoch 8; iter: 400; batch classifier loss: 0.458563; batch adversarial loss: 0.342157\n",
      "epoch 8; iter: 600; batch classifier loss: 0.465096; batch adversarial loss: 0.263115\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341255; batch adversarial loss: 0.475295\n",
      "epoch 9; iter: 200; batch classifier loss: 0.405038; batch adversarial loss: 0.255812\n",
      "epoch 9; iter: 400; batch classifier loss: 0.350064; batch adversarial loss: 0.385599\n",
      "epoch 9; iter: 600; batch classifier loss: 0.354761; batch adversarial loss: 0.309729\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302758; batch adversarial loss: 0.448949\n",
      "epoch 10; iter: 200; batch classifier loss: 0.265271; batch adversarial loss: 0.465355\n",
      "epoch 10; iter: 400; batch classifier loss: 0.420544; batch adversarial loss: 0.369635\n",
      "epoch 10; iter: 600; batch classifier loss: 0.372807; batch adversarial loss: 0.414975\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364628; batch adversarial loss: 0.345996\n",
      "epoch 11; iter: 200; batch classifier loss: 0.464295; batch adversarial loss: 0.506730\n",
      "epoch 11; iter: 400; batch classifier loss: 0.328918; batch adversarial loss: 0.464752\n",
      "epoch 11; iter: 600; batch classifier loss: 0.424507; batch adversarial loss: 0.451319\n",
      "epoch 12; iter: 0; batch classifier loss: 0.322603; batch adversarial loss: 0.337171\n",
      "epoch 12; iter: 200; batch classifier loss: 0.344645; batch adversarial loss: 0.304437\n",
      "epoch 12; iter: 400; batch classifier loss: 0.383065; batch adversarial loss: 0.310171\n",
      "epoch 12; iter: 600; batch classifier loss: 0.299736; batch adversarial loss: 0.384724\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321511; batch adversarial loss: 0.417957\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396080; batch adversarial loss: 0.327747\n",
      "epoch 13; iter: 400; batch classifier loss: 0.405420; batch adversarial loss: 0.515627\n",
      "epoch 13; iter: 600; batch classifier loss: 0.224253; batch adversarial loss: 0.431978\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299336; batch adversarial loss: 0.519263\n",
      "epoch 14; iter: 200; batch classifier loss: 0.245729; batch adversarial loss: 0.588095\n",
      "epoch 14; iter: 400; batch classifier loss: 0.385924; batch adversarial loss: 0.537649\n",
      "epoch 14; iter: 600; batch classifier loss: 0.352661; batch adversarial loss: 0.310983\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273853; batch adversarial loss: 0.425441\n",
      "epoch 15; iter: 200; batch classifier loss: 0.275842; batch adversarial loss: 0.420432\n",
      "epoch 15; iter: 400; batch classifier loss: 0.270058; batch adversarial loss: 0.399412\n",
      "epoch 15; iter: 600; batch classifier loss: 0.288253; batch adversarial loss: 0.537603\n",
      "epoch 16; iter: 0; batch classifier loss: 0.303215; batch adversarial loss: 0.515950\n",
      "epoch 16; iter: 200; batch classifier loss: 0.334248; batch adversarial loss: 0.625364\n",
      "epoch 16; iter: 400; batch classifier loss: 0.322153; batch adversarial loss: 0.364851\n",
      "epoch 16; iter: 600; batch classifier loss: 0.363481; batch adversarial loss: 0.269135\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336139; batch adversarial loss: 0.315302\n",
      "epoch 17; iter: 200; batch classifier loss: 0.301063; batch adversarial loss: 0.520984\n",
      "epoch 17; iter: 400; batch classifier loss: 0.327987; batch adversarial loss: 0.540882\n",
      "epoch 17; iter: 600; batch classifier loss: 0.335035; batch adversarial loss: 0.407878\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371637; batch adversarial loss: 0.599364\n",
      "epoch 18; iter: 200; batch classifier loss: 0.484410; batch adversarial loss: 0.459768\n",
      "epoch 18; iter: 400; batch classifier loss: 0.302548; batch adversarial loss: 0.387673\n",
      "epoch 18; iter: 600; batch classifier loss: 0.331974; batch adversarial loss: 0.351783\n",
      "epoch 19; iter: 0; batch classifier loss: 0.404180; batch adversarial loss: 0.394074\n",
      "epoch 19; iter: 200; batch classifier loss: 0.461999; batch adversarial loss: 0.370727\n",
      "epoch 19; iter: 400; batch classifier loss: 0.422059; batch adversarial loss: 0.448994\n",
      "epoch 19; iter: 600; batch classifier loss: 0.351088; batch adversarial loss: 0.347681\n",
      "epoch 0; iter: 0; batch classifier loss: 14.723616; batch adversarial loss: 0.707316\n",
      "epoch 0; iter: 200; batch classifier loss: 5.930481; batch adversarial loss: 0.634621\n",
      "epoch 0; iter: 400; batch classifier loss: 11.914028; batch adversarial loss: 0.547029\n",
      "epoch 0; iter: 600; batch classifier loss: 10.590975; batch adversarial loss: 0.493917\n",
      "epoch 1; iter: 0; batch classifier loss: 24.473507; batch adversarial loss: 0.494692\n",
      "epoch 1; iter: 200; batch classifier loss: 5.243958; batch adversarial loss: 0.523712\n",
      "epoch 1; iter: 400; batch classifier loss: 1.809106; batch adversarial loss: 0.494879\n",
      "epoch 1; iter: 600; batch classifier loss: 0.895089; batch adversarial loss: 0.439447\n",
      "epoch 2; iter: 0; batch classifier loss: 1.902626; batch adversarial loss: 0.502271\n",
      "epoch 2; iter: 200; batch classifier loss: 8.770264; batch adversarial loss: 0.550953\n",
      "epoch 2; iter: 400; batch classifier loss: 1.501261; batch adversarial loss: 0.430294\n",
      "epoch 2; iter: 600; batch classifier loss: 0.687235; batch adversarial loss: 0.396848\n",
      "epoch 3; iter: 0; batch classifier loss: 0.388370; batch adversarial loss: 0.466949\n",
      "epoch 3; iter: 200; batch classifier loss: 2.606922; batch adversarial loss: 0.315789\n",
      "epoch 3; iter: 400; batch classifier loss: 2.949388; batch adversarial loss: 0.327526\n",
      "epoch 3; iter: 600; batch classifier loss: 0.562951; batch adversarial loss: 0.538248\n",
      "epoch 4; iter: 0; batch classifier loss: 0.945076; batch adversarial loss: 0.432876\n",
      "epoch 4; iter: 200; batch classifier loss: 2.739645; batch adversarial loss: 0.513137\n",
      "epoch 4; iter: 400; batch classifier loss: 0.973483; batch adversarial loss: 0.353184\n",
      "epoch 4; iter: 600; batch classifier loss: 0.414729; batch adversarial loss: 0.395133\n",
      "epoch 5; iter: 0; batch classifier loss: 0.823856; batch adversarial loss: 0.458022\n",
      "epoch 5; iter: 200; batch classifier loss: 0.436105; batch adversarial loss: 0.363797\n",
      "epoch 5; iter: 400; batch classifier loss: 0.709910; batch adversarial loss: 0.337042\n",
      "epoch 5; iter: 600; batch classifier loss: 0.409572; batch adversarial loss: 0.391455\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550477; batch adversarial loss: 0.432967\n",
      "epoch 6; iter: 200; batch classifier loss: 0.490853; batch adversarial loss: 0.325066\n",
      "epoch 6; iter: 400; batch classifier loss: 0.619700; batch adversarial loss: 0.306843\n",
      "epoch 6; iter: 600; batch classifier loss: 0.364056; batch adversarial loss: 0.522593\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518925; batch adversarial loss: 0.424592\n",
      "epoch 7; iter: 200; batch classifier loss: 0.402462; batch adversarial loss: 0.528849\n",
      "epoch 7; iter: 400; batch classifier loss: 0.380593; batch adversarial loss: 0.379626\n",
      "epoch 7; iter: 600; batch classifier loss: 0.408184; batch adversarial loss: 0.389374\n",
      "epoch 8; iter: 0; batch classifier loss: 0.384784; batch adversarial loss: 0.508635\n",
      "epoch 8; iter: 200; batch classifier loss: 0.476618; batch adversarial loss: 0.291254\n",
      "epoch 8; iter: 400; batch classifier loss: 0.421004; batch adversarial loss: 0.476787\n",
      "epoch 8; iter: 600; batch classifier loss: 0.330416; batch adversarial loss: 0.456667\n",
      "epoch 9; iter: 0; batch classifier loss: 0.378909; batch adversarial loss: 0.421235\n",
      "epoch 9; iter: 200; batch classifier loss: 0.470868; batch adversarial loss: 0.230286\n",
      "epoch 9; iter: 400; batch classifier loss: 0.304146; batch adversarial loss: 0.518649\n",
      "epoch 9; iter: 600; batch classifier loss: 0.221257; batch adversarial loss: 0.432721\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405223; batch adversarial loss: 0.434139\n",
      "epoch 10; iter: 200; batch classifier loss: 0.336055; batch adversarial loss: 0.402911\n",
      "epoch 10; iter: 400; batch classifier loss: 0.280647; batch adversarial loss: 0.427606\n",
      "epoch 10; iter: 600; batch classifier loss: 0.334115; batch adversarial loss: 0.367245\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373806; batch adversarial loss: 0.342848\n",
      "epoch 11; iter: 200; batch classifier loss: 0.212559; batch adversarial loss: 0.295510\n",
      "epoch 11; iter: 400; batch classifier loss: 0.333196; batch adversarial loss: 0.339207\n",
      "epoch 11; iter: 600; batch classifier loss: 0.428397; batch adversarial loss: 0.364575\n",
      "epoch 12; iter: 0; batch classifier loss: 0.424328; batch adversarial loss: 0.260843\n",
      "epoch 12; iter: 200; batch classifier loss: 0.316499; batch adversarial loss: 0.522243\n",
      "epoch 12; iter: 400; batch classifier loss: 0.235125; batch adversarial loss: 0.372928\n",
      "epoch 12; iter: 600; batch classifier loss: 0.434443; batch adversarial loss: 0.475527\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350125; batch adversarial loss: 0.442991\n",
      "epoch 13; iter: 200; batch classifier loss: 0.322433; batch adversarial loss: 0.345248\n",
      "epoch 13; iter: 400; batch classifier loss: 0.366050; batch adversarial loss: 0.419311\n",
      "epoch 13; iter: 600; batch classifier loss: 0.423549; batch adversarial loss: 0.350887\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285840; batch adversarial loss: 0.396419\n",
      "epoch 14; iter: 200; batch classifier loss: 0.282724; batch adversarial loss: 0.461559\n",
      "epoch 14; iter: 400; batch classifier loss: 0.359195; batch adversarial loss: 0.366115\n",
      "epoch 14; iter: 600; batch classifier loss: 0.372773; batch adversarial loss: 0.471991\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428675; batch adversarial loss: 0.487832\n",
      "epoch 15; iter: 200; batch classifier loss: 0.322593; batch adversarial loss: 0.272593\n",
      "epoch 15; iter: 400; batch classifier loss: 0.213067; batch adversarial loss: 0.504752\n",
      "epoch 15; iter: 600; batch classifier loss: 0.381233; batch adversarial loss: 0.431186\n",
      "epoch 16; iter: 0; batch classifier loss: 0.278073; batch adversarial loss: 0.396169\n",
      "epoch 16; iter: 200; batch classifier loss: 0.360174; batch adversarial loss: 0.541361\n",
      "epoch 16; iter: 400; batch classifier loss: 0.530873; batch adversarial loss: 0.376735\n",
      "epoch 16; iter: 600; batch classifier loss: 0.448524; batch adversarial loss: 0.360334\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409008; batch adversarial loss: 0.413599\n",
      "epoch 17; iter: 200; batch classifier loss: 0.379538; batch adversarial loss: 0.418424\n",
      "epoch 17; iter: 400; batch classifier loss: 0.412055; batch adversarial loss: 0.322286\n",
      "epoch 17; iter: 600; batch classifier loss: 0.417940; batch adversarial loss: 0.431458\n",
      "epoch 18; iter: 0; batch classifier loss: 0.421507; batch adversarial loss: 0.465121\n",
      "epoch 18; iter: 200; batch classifier loss: 0.338551; batch adversarial loss: 0.376808\n",
      "epoch 18; iter: 400; batch classifier loss: 0.415953; batch adversarial loss: 0.408667\n",
      "epoch 18; iter: 600; batch classifier loss: 0.516820; batch adversarial loss: 0.451888\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337328; batch adversarial loss: 0.357196\n",
      "epoch 19; iter: 200; batch classifier loss: 0.425230; batch adversarial loss: 0.359312\n",
      "epoch 19; iter: 400; batch classifier loss: 0.407048; batch adversarial loss: 0.402721\n",
      "epoch 19; iter: 600; batch classifier loss: 0.340917; batch adversarial loss: 0.485508\n",
      "epoch 0; iter: 0; batch classifier loss: 196.240875; batch adversarial loss: 0.749216\n",
      "epoch 0; iter: 200; batch classifier loss: 3.334866; batch adversarial loss: 0.650517\n",
      "epoch 0; iter: 400; batch classifier loss: 10.194007; batch adversarial loss: 0.601931\n",
      "epoch 0; iter: 600; batch classifier loss: 7.344034; batch adversarial loss: 0.481668\n",
      "epoch 1; iter: 0; batch classifier loss: 1.040040; batch adversarial loss: 0.496777\n",
      "epoch 1; iter: 200; batch classifier loss: 3.171027; batch adversarial loss: 0.499998\n",
      "epoch 1; iter: 400; batch classifier loss: 4.199001; batch adversarial loss: 0.455338\n",
      "epoch 1; iter: 600; batch classifier loss: 7.646236; batch adversarial loss: 0.531184\n",
      "epoch 2; iter: 0; batch classifier loss: 6.897628; batch adversarial loss: 0.435583\n",
      "epoch 2; iter: 200; batch classifier loss: 0.753647; batch adversarial loss: 0.516488\n",
      "epoch 2; iter: 400; batch classifier loss: 2.381735; batch adversarial loss: 0.441961\n",
      "epoch 2; iter: 600; batch classifier loss: 1.195970; batch adversarial loss: 0.353815\n",
      "epoch 3; iter: 0; batch classifier loss: 4.772338; batch adversarial loss: 0.473772\n",
      "epoch 3; iter: 200; batch classifier loss: 1.991220; batch adversarial loss: 0.445991\n",
      "epoch 3; iter: 400; batch classifier loss: 2.217364; batch adversarial loss: 0.544750\n",
      "epoch 3; iter: 600; batch classifier loss: 0.917743; batch adversarial loss: 0.379992\n",
      "epoch 4; iter: 0; batch classifier loss: 0.736389; batch adversarial loss: 0.399204\n",
      "epoch 4; iter: 200; batch classifier loss: 0.683282; batch adversarial loss: 0.390603\n",
      "epoch 4; iter: 400; batch classifier loss: 0.406989; batch adversarial loss: 0.627929\n",
      "epoch 4; iter: 600; batch classifier loss: 0.712674; batch adversarial loss: 0.438180\n",
      "epoch 5; iter: 0; batch classifier loss: 1.265859; batch adversarial loss: 0.386400\n",
      "epoch 5; iter: 200; batch classifier loss: 0.596045; batch adversarial loss: 0.413171\n",
      "epoch 5; iter: 400; batch classifier loss: 0.585829; batch adversarial loss: 0.459319\n",
      "epoch 5; iter: 600; batch classifier loss: 0.388423; batch adversarial loss: 0.462956\n",
      "epoch 6; iter: 0; batch classifier loss: 1.116359; batch adversarial loss: 0.404979\n",
      "epoch 6; iter: 200; batch classifier loss: 0.584396; batch adversarial loss: 0.429905\n",
      "epoch 6; iter: 400; batch classifier loss: 0.458617; batch adversarial loss: 0.384509\n",
      "epoch 6; iter: 600; batch classifier loss: 0.505567; batch adversarial loss: 0.413187\n",
      "epoch 7; iter: 0; batch classifier loss: 0.413172; batch adversarial loss: 0.407448\n",
      "epoch 7; iter: 200; batch classifier loss: 0.342191; batch adversarial loss: 0.417771\n",
      "epoch 7; iter: 400; batch classifier loss: 0.293053; batch adversarial loss: 0.425123\n",
      "epoch 7; iter: 600; batch classifier loss: 0.371621; batch adversarial loss: 0.438114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334733; batch adversarial loss: 0.320016\n",
      "epoch 8; iter: 200; batch classifier loss: 0.312989; batch adversarial loss: 0.437512\n",
      "epoch 8; iter: 400; batch classifier loss: 0.402361; batch adversarial loss: 0.390979\n",
      "epoch 8; iter: 600; batch classifier loss: 0.872156; batch adversarial loss: 0.356817\n",
      "epoch 9; iter: 0; batch classifier loss: 0.506382; batch adversarial loss: 0.369077\n",
      "epoch 9; iter: 200; batch classifier loss: 0.264768; batch adversarial loss: 0.376452\n",
      "epoch 9; iter: 400; batch classifier loss: 0.440614; batch adversarial loss: 0.388486\n",
      "epoch 9; iter: 600; batch classifier loss: 0.367949; batch adversarial loss: 0.321645\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316608; batch adversarial loss: 0.400665\n",
      "epoch 10; iter: 200; batch classifier loss: 0.524990; batch adversarial loss: 0.350689\n",
      "epoch 10; iter: 400; batch classifier loss: 0.333563; batch adversarial loss: 0.404964\n",
      "epoch 10; iter: 600; batch classifier loss: 0.353485; batch adversarial loss: 0.428552\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339618; batch adversarial loss: 0.394409\n",
      "epoch 11; iter: 200; batch classifier loss: 0.307377; batch adversarial loss: 0.362805\n",
      "epoch 11; iter: 400; batch classifier loss: 0.292569; batch adversarial loss: 0.347327\n",
      "epoch 11; iter: 600; batch classifier loss: 0.357808; batch adversarial loss: 0.353806\n",
      "epoch 12; iter: 0; batch classifier loss: 0.324384; batch adversarial loss: 0.507476\n",
      "epoch 12; iter: 200; batch classifier loss: 0.341620; batch adversarial loss: 0.475158\n",
      "epoch 12; iter: 400; batch classifier loss: 0.323744; batch adversarial loss: 0.347728\n",
      "epoch 12; iter: 600; batch classifier loss: 0.357636; batch adversarial loss: 0.460813\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342362; batch adversarial loss: 0.498242\n",
      "epoch 13; iter: 200; batch classifier loss: 0.296284; batch adversarial loss: 0.585068\n",
      "epoch 13; iter: 400; batch classifier loss: 0.369523; batch adversarial loss: 0.434028\n",
      "epoch 13; iter: 600; batch classifier loss: 0.338978; batch adversarial loss: 0.237601\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502282; batch adversarial loss: 0.374162\n",
      "epoch 14; iter: 200; batch classifier loss: 0.394141; batch adversarial loss: 0.400760\n",
      "epoch 14; iter: 400; batch classifier loss: 0.383166; batch adversarial loss: 0.455112\n",
      "epoch 14; iter: 600; batch classifier loss: 0.300642; batch adversarial loss: 0.434425\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362177; batch adversarial loss: 0.350684\n",
      "epoch 15; iter: 200; batch classifier loss: 0.256148; batch adversarial loss: 0.426653\n",
      "epoch 15; iter: 400; batch classifier loss: 0.331968; batch adversarial loss: 0.340061\n",
      "epoch 15; iter: 600; batch classifier loss: 0.345372; batch adversarial loss: 0.344342\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336300; batch adversarial loss: 0.445417\n",
      "epoch 16; iter: 200; batch classifier loss: 0.343344; batch adversarial loss: 0.291904\n",
      "epoch 16; iter: 400; batch classifier loss: 0.400832; batch adversarial loss: 0.379809\n",
      "epoch 16; iter: 600; batch classifier loss: 0.387112; batch adversarial loss: 0.300476\n",
      "epoch 17; iter: 0; batch classifier loss: 0.403803; batch adversarial loss: 0.497838\n",
      "epoch 17; iter: 200; batch classifier loss: 0.326762; batch adversarial loss: 0.408254\n",
      "epoch 17; iter: 400; batch classifier loss: 0.349942; batch adversarial loss: 0.453390\n",
      "epoch 17; iter: 600; batch classifier loss: 0.489416; batch adversarial loss: 0.456663\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419855; batch adversarial loss: 0.406937\n",
      "epoch 18; iter: 200; batch classifier loss: 0.532501; batch adversarial loss: 0.343714\n",
      "epoch 18; iter: 400; batch classifier loss: 0.642736; batch adversarial loss: 0.404098\n",
      "epoch 18; iter: 600; batch classifier loss: 0.376430; batch adversarial loss: 0.573890\n",
      "epoch 19; iter: 0; batch classifier loss: 0.608148; batch adversarial loss: 0.349929\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372384; batch adversarial loss: 0.347639\n",
      "epoch 19; iter: 400; batch classifier loss: 0.363668; batch adversarial loss: 0.376132\n",
      "epoch 19; iter: 600; batch classifier loss: 0.544560; batch adversarial loss: 0.319990\n",
      "epoch 0; iter: 0; batch classifier loss: 167.171738; batch adversarial loss: 0.590880\n",
      "epoch 0; iter: 200; batch classifier loss: 10.602389; batch adversarial loss: 0.564121\n",
      "epoch 0; iter: 400; batch classifier loss: 8.753700; batch adversarial loss: 0.506885\n",
      "epoch 0; iter: 600; batch classifier loss: 7.159801; batch adversarial loss: 0.518199\n",
      "epoch 1; iter: 0; batch classifier loss: 14.048955; batch adversarial loss: 0.500381\n",
      "epoch 1; iter: 200; batch classifier loss: 1.880683; batch adversarial loss: 0.524028\n",
      "epoch 1; iter: 400; batch classifier loss: 5.812331; batch adversarial loss: 0.515749\n",
      "epoch 1; iter: 600; batch classifier loss: 5.497490; batch adversarial loss: 0.518058\n",
      "epoch 2; iter: 0; batch classifier loss: 3.136561; batch adversarial loss: 0.471094\n",
      "epoch 2; iter: 200; batch classifier loss: 1.950149; batch adversarial loss: 0.443191\n",
      "epoch 2; iter: 400; batch classifier loss: 6.739691; batch adversarial loss: 0.419224\n",
      "epoch 2; iter: 600; batch classifier loss: 1.716026; batch adversarial loss: 0.348791\n",
      "epoch 3; iter: 0; batch classifier loss: 4.713602; batch adversarial loss: 0.394325\n",
      "epoch 3; iter: 200; batch classifier loss: 3.175015; batch adversarial loss: 0.431459\n",
      "epoch 3; iter: 400; batch classifier loss: 0.671128; batch adversarial loss: 0.431780\n",
      "epoch 3; iter: 600; batch classifier loss: 0.712905; batch adversarial loss: 0.423456\n",
      "epoch 4; iter: 0; batch classifier loss: 0.648657; batch adversarial loss: 0.529978\n",
      "epoch 4; iter: 200; batch classifier loss: 2.457365; batch adversarial loss: 0.423874\n",
      "epoch 4; iter: 400; batch classifier loss: 0.497554; batch adversarial loss: 0.396000\n",
      "epoch 4; iter: 600; batch classifier loss: 0.784411; batch adversarial loss: 0.425178\n",
      "epoch 5; iter: 0; batch classifier loss: 1.319466; batch adversarial loss: 0.352443\n",
      "epoch 5; iter: 200; batch classifier loss: 0.672186; batch adversarial loss: 0.547579\n",
      "epoch 5; iter: 400; batch classifier loss: 0.464243; batch adversarial loss: 0.513221\n",
      "epoch 5; iter: 600; batch classifier loss: 0.806746; batch adversarial loss: 0.545796\n",
      "epoch 6; iter: 0; batch classifier loss: 1.407355; batch adversarial loss: 0.312354\n",
      "epoch 6; iter: 200; batch classifier loss: 0.324625; batch adversarial loss: 0.329607\n",
      "epoch 6; iter: 400; batch classifier loss: 0.329819; batch adversarial loss: 0.359032\n",
      "epoch 6; iter: 600; batch classifier loss: 0.430879; batch adversarial loss: 0.388005\n",
      "epoch 7; iter: 0; batch classifier loss: 0.310936; batch adversarial loss: 0.425985\n",
      "epoch 7; iter: 200; batch classifier loss: 0.377586; batch adversarial loss: 0.465590\n",
      "epoch 7; iter: 400; batch classifier loss: 0.503922; batch adversarial loss: 0.343953\n",
      "epoch 7; iter: 600; batch classifier loss: 0.355342; batch adversarial loss: 0.298205\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356143; batch adversarial loss: 0.416347\n",
      "epoch 8; iter: 200; batch classifier loss: 0.297963; batch adversarial loss: 0.281347\n",
      "epoch 8; iter: 400; batch classifier loss: 0.579102; batch adversarial loss: 0.434519\n",
      "epoch 8; iter: 600; batch classifier loss: 0.282011; batch adversarial loss: 0.463496\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398621; batch adversarial loss: 0.372096\n",
      "epoch 9; iter: 200; batch classifier loss: 0.633899; batch adversarial loss: 0.516069\n",
      "epoch 9; iter: 400; batch classifier loss: 0.404364; batch adversarial loss: 0.481771\n",
      "epoch 9; iter: 600; batch classifier loss: 0.358954; batch adversarial loss: 0.318670\n",
      "epoch 10; iter: 0; batch classifier loss: 0.308940; batch adversarial loss: 0.461677\n",
      "epoch 10; iter: 200; batch classifier loss: 0.347618; batch adversarial loss: 0.404958\n",
      "epoch 10; iter: 400; batch classifier loss: 0.597675; batch adversarial loss: 0.392172\n",
      "epoch 10; iter: 600; batch classifier loss: 0.492147; batch adversarial loss: 0.452472\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428477; batch adversarial loss: 0.369134\n",
      "epoch 11; iter: 200; batch classifier loss: 0.331644; batch adversarial loss: 0.438456\n",
      "epoch 11; iter: 400; batch classifier loss: 0.376337; batch adversarial loss: 0.453474\n",
      "epoch 11; iter: 600; batch classifier loss: 0.587283; batch adversarial loss: 0.375767\n",
      "epoch 12; iter: 0; batch classifier loss: 0.408295; batch adversarial loss: 0.308711\n",
      "epoch 12; iter: 200; batch classifier loss: 0.344959; batch adversarial loss: 0.556486\n",
      "epoch 12; iter: 400; batch classifier loss: 0.341290; batch adversarial loss: 0.396145\n",
      "epoch 12; iter: 600; batch classifier loss: 0.389538; batch adversarial loss: 0.429379\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389565; batch adversarial loss: 0.369346\n",
      "epoch 13; iter: 200; batch classifier loss: 0.390803; batch adversarial loss: 0.339134\n",
      "epoch 13; iter: 400; batch classifier loss: 0.322561; batch adversarial loss: 0.345233\n",
      "epoch 13; iter: 600; batch classifier loss: 0.458525; batch adversarial loss: 0.315427\n",
      "epoch 14; iter: 0; batch classifier loss: 0.293055; batch adversarial loss: 0.473694\n",
      "epoch 14; iter: 200; batch classifier loss: 0.303269; batch adversarial loss: 0.287796\n",
      "epoch 14; iter: 400; batch classifier loss: 0.387123; batch adversarial loss: 0.414722\n",
      "epoch 14; iter: 600; batch classifier loss: 0.200158; batch adversarial loss: 0.451200\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481102; batch adversarial loss: 0.497945\n",
      "epoch 15; iter: 200; batch classifier loss: 0.269557; batch adversarial loss: 0.518645\n",
      "epoch 15; iter: 400; batch classifier loss: 0.350331; batch adversarial loss: 0.267605\n",
      "epoch 15; iter: 600; batch classifier loss: 0.313075; batch adversarial loss: 0.394367\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336253; batch adversarial loss: 0.352453\n",
      "epoch 16; iter: 200; batch classifier loss: 0.324556; batch adversarial loss: 0.356352\n",
      "epoch 16; iter: 400; batch classifier loss: 0.393830; batch adversarial loss: 0.433722\n",
      "epoch 16; iter: 600; batch classifier loss: 0.263698; batch adversarial loss: 0.395982\n",
      "epoch 17; iter: 0; batch classifier loss: 0.422829; batch adversarial loss: 0.437805\n",
      "epoch 17; iter: 200; batch classifier loss: 0.264921; batch adversarial loss: 0.422945\n",
      "epoch 17; iter: 400; batch classifier loss: 0.308062; batch adversarial loss: 0.295472\n",
      "epoch 17; iter: 600; batch classifier loss: 0.375425; batch adversarial loss: 0.430800\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313498; batch adversarial loss: 0.343843\n",
      "epoch 18; iter: 200; batch classifier loss: 0.369931; batch adversarial loss: 0.454500\n",
      "epoch 18; iter: 400; batch classifier loss: 0.505678; batch adversarial loss: 0.311952\n",
      "epoch 18; iter: 600; batch classifier loss: 0.535175; batch adversarial loss: 0.326164\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379884; batch adversarial loss: 0.505842\n",
      "epoch 19; iter: 200; batch classifier loss: 0.351704; batch adversarial loss: 0.401995\n",
      "epoch 19; iter: 400; batch classifier loss: 0.487318; batch adversarial loss: 0.451638\n",
      "epoch 19; iter: 600; batch classifier loss: 0.551830; batch adversarial loss: 0.400658\n",
      "epoch 0; iter: 0; batch classifier loss: 13.280214; batch adversarial loss: 0.556295\n",
      "epoch 0; iter: 200; batch classifier loss: 4.313284; batch adversarial loss: 0.565626\n",
      "epoch 0; iter: 400; batch classifier loss: 9.870874; batch adversarial loss: 0.572798\n",
      "epoch 0; iter: 600; batch classifier loss: 11.360495; batch adversarial loss: 0.520113\n",
      "epoch 1; iter: 0; batch classifier loss: 2.836726; batch adversarial loss: 0.534364\n",
      "epoch 1; iter: 200; batch classifier loss: 17.137745; batch adversarial loss: 0.496943\n",
      "epoch 1; iter: 400; batch classifier loss: 1.739181; batch adversarial loss: 0.481161\n",
      "epoch 1; iter: 600; batch classifier loss: 5.978850; batch adversarial loss: 0.518328\n",
      "epoch 2; iter: 0; batch classifier loss: 20.499580; batch adversarial loss: 0.539330\n",
      "epoch 2; iter: 200; batch classifier loss: 3.783794; batch adversarial loss: 0.505492\n",
      "epoch 2; iter: 400; batch classifier loss: 0.385041; batch adversarial loss: 0.311317\n",
      "epoch 2; iter: 600; batch classifier loss: 0.610712; batch adversarial loss: 0.375191\n",
      "epoch 3; iter: 0; batch classifier loss: 0.473155; batch adversarial loss: 0.472828\n",
      "epoch 3; iter: 200; batch classifier loss: 2.322071; batch adversarial loss: 0.406363\n",
      "epoch 3; iter: 400; batch classifier loss: 0.586425; batch adversarial loss: 0.443235\n",
      "epoch 3; iter: 600; batch classifier loss: 0.883349; batch adversarial loss: 0.343880\n",
      "epoch 4; iter: 0; batch classifier loss: 4.894646; batch adversarial loss: 0.373861\n",
      "epoch 4; iter: 200; batch classifier loss: 0.983484; batch adversarial loss: 0.380157\n",
      "epoch 4; iter: 400; batch classifier loss: 3.281971; batch adversarial loss: 0.562823\n",
      "epoch 4; iter: 600; batch classifier loss: 0.633367; batch adversarial loss: 0.519801\n",
      "epoch 5; iter: 0; batch classifier loss: 0.705960; batch adversarial loss: 0.340163\n",
      "epoch 5; iter: 200; batch classifier loss: 0.473242; batch adversarial loss: 0.316080\n",
      "epoch 5; iter: 400; batch classifier loss: 0.639398; batch adversarial loss: 0.364792\n",
      "epoch 5; iter: 600; batch classifier loss: 0.476313; batch adversarial loss: 0.540838\n",
      "epoch 6; iter: 0; batch classifier loss: 0.320913; batch adversarial loss: 0.316727\n",
      "epoch 6; iter: 200; batch classifier loss: 0.450515; batch adversarial loss: 0.380687\n",
      "epoch 6; iter: 400; batch classifier loss: 0.744362; batch adversarial loss: 0.438127\n",
      "epoch 6; iter: 600; batch classifier loss: 0.606839; batch adversarial loss: 0.432168\n",
      "epoch 7; iter: 0; batch classifier loss: 0.323709; batch adversarial loss: 0.478481\n",
      "epoch 7; iter: 200; batch classifier loss: 0.490889; batch adversarial loss: 0.426265\n",
      "epoch 7; iter: 400; batch classifier loss: 0.437184; batch adversarial loss: 0.457559\n",
      "epoch 7; iter: 600; batch classifier loss: 0.416367; batch adversarial loss: 0.354260\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537831; batch adversarial loss: 0.576654\n",
      "epoch 8; iter: 200; batch classifier loss: 0.456950; batch adversarial loss: 0.433743\n",
      "epoch 8; iter: 400; batch classifier loss: 0.390897; batch adversarial loss: 0.288792\n",
      "epoch 8; iter: 600; batch classifier loss: 0.297805; batch adversarial loss: 0.384801\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390953; batch adversarial loss: 0.466710\n",
      "epoch 9; iter: 200; batch classifier loss: 0.338975; batch adversarial loss: 0.342558\n",
      "epoch 9; iter: 400; batch classifier loss: 0.377491; batch adversarial loss: 0.445913\n",
      "epoch 9; iter: 600; batch classifier loss: 0.450261; batch adversarial loss: 0.399561\n",
      "epoch 10; iter: 0; batch classifier loss: 0.289942; batch adversarial loss: 0.447078\n",
      "epoch 10; iter: 200; batch classifier loss: 0.350421; batch adversarial loss: 0.321530\n",
      "epoch 10; iter: 400; batch classifier loss: 0.305629; batch adversarial loss: 0.471109\n",
      "epoch 10; iter: 600; batch classifier loss: 0.303963; batch adversarial loss: 0.401337\n",
      "epoch 11; iter: 0; batch classifier loss: 0.333950; batch adversarial loss: 0.293919\n",
      "epoch 11; iter: 200; batch classifier loss: 0.260997; batch adversarial loss: 0.320930\n",
      "epoch 11; iter: 400; batch classifier loss: 0.347458; batch adversarial loss: 0.395006\n",
      "epoch 11; iter: 600; batch classifier loss: 0.358690; batch adversarial loss: 0.527482\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329949; batch adversarial loss: 0.268055\n",
      "epoch 12; iter: 200; batch classifier loss: 0.301887; batch adversarial loss: 0.340483\n",
      "epoch 12; iter: 400; batch classifier loss: 0.440747; batch adversarial loss: 0.352530\n",
      "epoch 12; iter: 600; batch classifier loss: 0.319343; batch adversarial loss: 0.340097\n",
      "epoch 13; iter: 0; batch classifier loss: 0.353700; batch adversarial loss: 0.451157\n",
      "epoch 13; iter: 200; batch classifier loss: 0.316957; batch adversarial loss: 0.465696\n",
      "epoch 13; iter: 400; batch classifier loss: 0.356063; batch adversarial loss: 0.421122\n",
      "epoch 13; iter: 600; batch classifier loss: 0.386390; batch adversarial loss: 0.337451\n",
      "epoch 14; iter: 0; batch classifier loss: 0.321037; batch adversarial loss: 0.519687\n",
      "epoch 14; iter: 200; batch classifier loss: 0.460222; batch adversarial loss: 0.382342\n",
      "epoch 14; iter: 400; batch classifier loss: 0.287308; batch adversarial loss: 0.452265\n",
      "epoch 14; iter: 600; batch classifier loss: 0.257522; batch adversarial loss: 0.430415\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440711; batch adversarial loss: 0.346688\n",
      "epoch 15; iter: 200; batch classifier loss: 0.254097; batch adversarial loss: 0.301460\n",
      "epoch 15; iter: 400; batch classifier loss: 0.410161; batch adversarial loss: 0.295654\n",
      "epoch 15; iter: 600; batch classifier loss: 0.427720; batch adversarial loss: 0.323279\n",
      "epoch 16; iter: 0; batch classifier loss: 0.325879; batch adversarial loss: 0.498232\n",
      "epoch 16; iter: 200; batch classifier loss: 0.331753; batch adversarial loss: 0.295485\n",
      "epoch 16; iter: 400; batch classifier loss: 0.413269; batch adversarial loss: 0.350086\n",
      "epoch 16; iter: 600; batch classifier loss: 0.435908; batch adversarial loss: 0.413484\n",
      "epoch 17; iter: 0; batch classifier loss: 0.350023; batch adversarial loss: 0.478858\n",
      "epoch 17; iter: 200; batch classifier loss: 0.650832; batch adversarial loss: 0.544735\n",
      "epoch 17; iter: 400; batch classifier loss: 0.420897; batch adversarial loss: 0.348445\n",
      "epoch 17; iter: 600; batch classifier loss: 0.346062; batch adversarial loss: 0.339081\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303564; batch adversarial loss: 0.511120\n",
      "epoch 18; iter: 200; batch classifier loss: 0.567958; batch adversarial loss: 0.267233\n",
      "epoch 18; iter: 400; batch classifier loss: 0.370032; batch adversarial loss: 0.349145\n",
      "epoch 18; iter: 600; batch classifier loss: 0.429852; batch adversarial loss: 0.584696\n",
      "epoch 19; iter: 0; batch classifier loss: 0.392553; batch adversarial loss: 0.408078\n",
      "epoch 19; iter: 200; batch classifier loss: 0.583408; batch adversarial loss: 0.486447\n",
      "epoch 19; iter: 400; batch classifier loss: 0.355268; batch adversarial loss: 0.565234\n",
      "epoch 19; iter: 600; batch classifier loss: 0.466326; batch adversarial loss: 0.320896\n",
      "epoch 0; iter: 0; batch classifier loss: 11.574441; batch adversarial loss: 0.579656\n",
      "epoch 0; iter: 200; batch classifier loss: 0.449844; batch adversarial loss: 0.576182\n",
      "epoch 0; iter: 400; batch classifier loss: 7.583571; batch adversarial loss: 0.511668\n",
      "epoch 0; iter: 600; batch classifier loss: 2.937867; batch adversarial loss: 0.480346\n",
      "epoch 1; iter: 0; batch classifier loss: 9.747525; batch adversarial loss: 0.569331\n",
      "epoch 1; iter: 200; batch classifier loss: 8.004389; batch adversarial loss: 0.522615\n",
      "epoch 1; iter: 400; batch classifier loss: 3.457151; batch adversarial loss: 0.520067\n",
      "epoch 1; iter: 600; batch classifier loss: 2.674518; batch adversarial loss: 0.624313\n",
      "epoch 2; iter: 0; batch classifier loss: 1.757282; batch adversarial loss: 0.416355\n",
      "epoch 2; iter: 200; batch classifier loss: 4.195868; batch adversarial loss: 0.360793\n",
      "epoch 2; iter: 400; batch classifier loss: 2.615613; batch adversarial loss: 0.557441\n",
      "epoch 2; iter: 600; batch classifier loss: 2.572144; batch adversarial loss: 0.462379\n",
      "epoch 3; iter: 0; batch classifier loss: 4.297173; batch adversarial loss: 0.301720\n",
      "epoch 3; iter: 200; batch classifier loss: 2.296795; batch adversarial loss: 0.401720\n",
      "epoch 3; iter: 400; batch classifier loss: 0.627854; batch adversarial loss: 0.499330\n",
      "epoch 3; iter: 600; batch classifier loss: 0.751436; batch adversarial loss: 0.523033\n",
      "epoch 4; iter: 0; batch classifier loss: 1.345346; batch adversarial loss: 0.394849\n",
      "epoch 4; iter: 200; batch classifier loss: 0.919580; batch adversarial loss: 0.409982\n",
      "epoch 4; iter: 400; batch classifier loss: 0.914302; batch adversarial loss: 0.479506\n",
      "epoch 4; iter: 600; batch classifier loss: 1.309321; batch adversarial loss: 0.430441\n",
      "epoch 5; iter: 0; batch classifier loss: 0.793242; batch adversarial loss: 0.463413\n",
      "epoch 5; iter: 200; batch classifier loss: 0.691698; batch adversarial loss: 0.471954\n",
      "epoch 5; iter: 400; batch classifier loss: 0.823423; batch adversarial loss: 0.421252\n",
      "epoch 5; iter: 600; batch classifier loss: 0.275028; batch adversarial loss: 0.404055\n",
      "epoch 6; iter: 0; batch classifier loss: 0.472717; batch adversarial loss: 0.346295\n",
      "epoch 6; iter: 200; batch classifier loss: 0.336933; batch adversarial loss: 0.372027\n",
      "epoch 6; iter: 400; batch classifier loss: 0.567146; batch adversarial loss: 0.379240\n",
      "epoch 6; iter: 600; batch classifier loss: 0.306184; batch adversarial loss: 0.512821\n",
      "epoch 7; iter: 0; batch classifier loss: 0.749320; batch adversarial loss: 0.510038\n",
      "epoch 7; iter: 200; batch classifier loss: 0.444616; batch adversarial loss: 0.389131\n",
      "epoch 7; iter: 400; batch classifier loss: 0.464687; batch adversarial loss: 0.392775\n",
      "epoch 7; iter: 600; batch classifier loss: 0.595244; batch adversarial loss: 0.328073\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537422; batch adversarial loss: 0.325935\n",
      "epoch 8; iter: 200; batch classifier loss: 0.554597; batch adversarial loss: 0.430985\n",
      "epoch 8; iter: 400; batch classifier loss: 0.366301; batch adversarial loss: 0.454849\n",
      "epoch 8; iter: 600; batch classifier loss: 0.354660; batch adversarial loss: 0.328717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341517; batch adversarial loss: 0.539274\n",
      "epoch 9; iter: 200; batch classifier loss: 0.313851; batch adversarial loss: 0.356343\n",
      "epoch 9; iter: 400; batch classifier loss: 0.390228; batch adversarial loss: 0.408868\n",
      "epoch 9; iter: 600; batch classifier loss: 0.482991; batch adversarial loss: 0.483756\n",
      "epoch 10; iter: 0; batch classifier loss: 0.315595; batch adversarial loss: 0.505251\n",
      "epoch 10; iter: 200; batch classifier loss: 0.346022; batch adversarial loss: 0.420700\n",
      "epoch 10; iter: 400; batch classifier loss: 0.291074; batch adversarial loss: 0.338018\n",
      "epoch 10; iter: 600; batch classifier loss: 0.379122; batch adversarial loss: 0.452699\n",
      "epoch 11; iter: 0; batch classifier loss: 0.330462; batch adversarial loss: 0.342400\n",
      "epoch 11; iter: 200; batch classifier loss: 0.362887; batch adversarial loss: 0.319453\n",
      "epoch 11; iter: 400; batch classifier loss: 0.371758; batch adversarial loss: 0.365195\n",
      "epoch 11; iter: 600; batch classifier loss: 0.292539; batch adversarial loss: 0.338222\n",
      "epoch 12; iter: 0; batch classifier loss: 0.285013; batch adversarial loss: 0.298452\n",
      "epoch 12; iter: 200; batch classifier loss: 0.256447; batch adversarial loss: 0.492098\n",
      "epoch 12; iter: 400; batch classifier loss: 0.339731; batch adversarial loss: 0.352200\n",
      "epoch 12; iter: 600; batch classifier loss: 0.385580; batch adversarial loss: 0.287434\n",
      "epoch 13; iter: 0; batch classifier loss: 0.353060; batch adversarial loss: 0.373608\n",
      "epoch 13; iter: 200; batch classifier loss: 0.266424; batch adversarial loss: 0.429544\n",
      "epoch 13; iter: 400; batch classifier loss: 0.356209; batch adversarial loss: 0.338680\n",
      "epoch 13; iter: 600; batch classifier loss: 0.328486; batch adversarial loss: 0.379113\n",
      "epoch 14; iter: 0; batch classifier loss: 0.414525; batch adversarial loss: 0.350455\n",
      "epoch 14; iter: 200; batch classifier loss: 0.299876; batch adversarial loss: 0.393235\n",
      "epoch 14; iter: 400; batch classifier loss: 0.316247; batch adversarial loss: 0.597180\n",
      "epoch 14; iter: 600; batch classifier loss: 0.282672; batch adversarial loss: 0.461708\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322963; batch adversarial loss: 0.396828\n",
      "epoch 15; iter: 200; batch classifier loss: 0.395563; batch adversarial loss: 0.394690\n",
      "epoch 15; iter: 400; batch classifier loss: 0.325804; batch adversarial loss: 0.312302\n",
      "epoch 15; iter: 600; batch classifier loss: 0.282485; batch adversarial loss: 0.412020\n",
      "epoch 16; iter: 0; batch classifier loss: 0.171706; batch adversarial loss: 0.421435\n",
      "epoch 16; iter: 200; batch classifier loss: 0.282999; batch adversarial loss: 0.450993\n",
      "epoch 16; iter: 400; batch classifier loss: 0.472981; batch adversarial loss: 0.457950\n",
      "epoch 16; iter: 600; batch classifier loss: 0.366062; batch adversarial loss: 0.405782\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320406; batch adversarial loss: 0.549539\n",
      "epoch 17; iter: 200; batch classifier loss: 0.283602; batch adversarial loss: 0.377998\n",
      "epoch 17; iter: 400; batch classifier loss: 0.440846; batch adversarial loss: 0.458031\n",
      "epoch 17; iter: 600; batch classifier loss: 0.410493; batch adversarial loss: 0.465394\n",
      "epoch 18; iter: 0; batch classifier loss: 0.616858; batch adversarial loss: 0.354677\n",
      "epoch 18; iter: 200; batch classifier loss: 0.412963; batch adversarial loss: 0.514342\n",
      "epoch 18; iter: 400; batch classifier loss: 0.574021; batch adversarial loss: 0.379587\n",
      "epoch 18; iter: 600; batch classifier loss: 0.517282; batch adversarial loss: 0.315773\n",
      "epoch 19; iter: 0; batch classifier loss: 0.446116; batch adversarial loss: 0.380688\n",
      "epoch 19; iter: 200; batch classifier loss: 0.416494; batch adversarial loss: 0.587648\n",
      "epoch 19; iter: 400; batch classifier loss: 0.559239; batch adversarial loss: 0.345390\n",
      "epoch 19; iter: 600; batch classifier loss: 0.604060; batch adversarial loss: 0.355783\n",
      "epoch 0; iter: 0; batch classifier loss: 53.344055; batch adversarial loss: 0.648898\n",
      "epoch 0; iter: 200; batch classifier loss: 2.613255; batch adversarial loss: 0.597982\n",
      "epoch 0; iter: 400; batch classifier loss: 3.320626; batch adversarial loss: 0.528187\n",
      "epoch 0; iter: 600; batch classifier loss: 2.420227; batch adversarial loss: 0.445956\n",
      "epoch 1; iter: 0; batch classifier loss: 6.597304; batch adversarial loss: 0.520135\n",
      "epoch 1; iter: 200; batch classifier loss: 2.551391; batch adversarial loss: 0.497623\n",
      "epoch 1; iter: 400; batch classifier loss: 1.065641; batch adversarial loss: 0.425359\n",
      "epoch 1; iter: 600; batch classifier loss: 1.642448; batch adversarial loss: 0.523616\n",
      "epoch 2; iter: 0; batch classifier loss: 5.302985; batch adversarial loss: 0.349624\n",
      "epoch 2; iter: 200; batch classifier loss: 3.753370; batch adversarial loss: 0.558028\n",
      "epoch 2; iter: 400; batch classifier loss: 5.125484; batch adversarial loss: 0.436624\n",
      "epoch 2; iter: 600; batch classifier loss: 3.198184; batch adversarial loss: 0.538994\n",
      "epoch 3; iter: 0; batch classifier loss: 1.216730; batch adversarial loss: 0.321933\n",
      "epoch 3; iter: 200; batch classifier loss: 1.434742; batch adversarial loss: 0.471317\n",
      "epoch 3; iter: 400; batch classifier loss: 1.104536; batch adversarial loss: 0.554114\n",
      "epoch 3; iter: 600; batch classifier loss: 2.194428; batch adversarial loss: 0.408749\n",
      "epoch 4; iter: 0; batch classifier loss: 0.832569; batch adversarial loss: 0.392597\n",
      "epoch 4; iter: 200; batch classifier loss: 0.669428; batch adversarial loss: 0.441965\n",
      "epoch 4; iter: 400; batch classifier loss: 1.013645; batch adversarial loss: 0.512334\n",
      "epoch 4; iter: 600; batch classifier loss: 0.591869; batch adversarial loss: 0.577294\n",
      "epoch 5; iter: 0; batch classifier loss: 0.420807; batch adversarial loss: 0.562975\n",
      "epoch 5; iter: 200; batch classifier loss: 3.608688; batch adversarial loss: 0.448282\n",
      "epoch 5; iter: 400; batch classifier loss: 0.698932; batch adversarial loss: 0.457141\n",
      "epoch 5; iter: 600; batch classifier loss: 0.463858; batch adversarial loss: 0.323037\n",
      "epoch 6; iter: 0; batch classifier loss: 0.271517; batch adversarial loss: 0.410845\n",
      "epoch 6; iter: 200; batch classifier loss: 0.322268; batch adversarial loss: 0.415507\n",
      "epoch 6; iter: 400; batch classifier loss: 0.347781; batch adversarial loss: 0.570593\n",
      "epoch 6; iter: 600; batch classifier loss: 0.519974; batch adversarial loss: 0.401555\n",
      "epoch 7; iter: 0; batch classifier loss: 0.387845; batch adversarial loss: 0.453568\n",
      "epoch 7; iter: 200; batch classifier loss: 0.389563; batch adversarial loss: 0.281340\n",
      "epoch 7; iter: 400; batch classifier loss: 0.310491; batch adversarial loss: 0.419565\n",
      "epoch 7; iter: 600; batch classifier loss: 0.455830; batch adversarial loss: 0.391406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506100; batch adversarial loss: 0.506379\n",
      "epoch 8; iter: 200; batch classifier loss: 0.407105; batch adversarial loss: 0.302288\n",
      "epoch 8; iter: 400; batch classifier loss: 0.334585; batch adversarial loss: 0.408841\n",
      "epoch 8; iter: 600; batch classifier loss: 0.311379; batch adversarial loss: 0.483724\n",
      "epoch 9; iter: 0; batch classifier loss: 0.244647; batch adversarial loss: 0.490881\n",
      "epoch 9; iter: 200; batch classifier loss: 0.309469; batch adversarial loss: 0.466800\n",
      "epoch 9; iter: 400; batch classifier loss: 0.309983; batch adversarial loss: 0.411991\n",
      "epoch 9; iter: 600; batch classifier loss: 0.402921; batch adversarial loss: 0.363142\n",
      "epoch 10; iter: 0; batch classifier loss: 0.395583; batch adversarial loss: 0.407356\n",
      "epoch 10; iter: 200; batch classifier loss: 0.481241; batch adversarial loss: 0.435802\n",
      "epoch 10; iter: 400; batch classifier loss: 0.273615; batch adversarial loss: 0.421102\n",
      "epoch 10; iter: 600; batch classifier loss: 0.354101; batch adversarial loss: 0.503093\n",
      "epoch 11; iter: 0; batch classifier loss: 0.287091; batch adversarial loss: 0.391913\n",
      "epoch 11; iter: 200; batch classifier loss: 0.289101; batch adversarial loss: 0.399334\n",
      "epoch 11; iter: 400; batch classifier loss: 0.301174; batch adversarial loss: 0.446711\n",
      "epoch 11; iter: 600; batch classifier loss: 0.349552; batch adversarial loss: 0.425012\n",
      "epoch 12; iter: 0; batch classifier loss: 0.371076; batch adversarial loss: 0.405106\n",
      "epoch 12; iter: 200; batch classifier loss: 0.239428; batch adversarial loss: 0.360099\n",
      "epoch 12; iter: 400; batch classifier loss: 0.522178; batch adversarial loss: 0.374529\n",
      "epoch 12; iter: 600; batch classifier loss: 0.327648; batch adversarial loss: 0.379384\n",
      "epoch 13; iter: 0; batch classifier loss: 0.272208; batch adversarial loss: 0.436148\n",
      "epoch 13; iter: 200; batch classifier loss: 0.510348; batch adversarial loss: 0.345116\n",
      "epoch 13; iter: 400; batch classifier loss: 0.356925; batch adversarial loss: 0.443267\n",
      "epoch 13; iter: 600; batch classifier loss: 0.340860; batch adversarial loss: 0.310516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.407469; batch adversarial loss: 0.368170\n",
      "epoch 14; iter: 200; batch classifier loss: 0.393743; batch adversarial loss: 0.291082\n",
      "epoch 14; iter: 400; batch classifier loss: 0.368149; batch adversarial loss: 0.393357\n",
      "epoch 14; iter: 600; batch classifier loss: 0.306908; batch adversarial loss: 0.378420\n",
      "epoch 15; iter: 0; batch classifier loss: 0.328541; batch adversarial loss: 0.344151\n",
      "epoch 15; iter: 200; batch classifier loss: 0.292083; batch adversarial loss: 0.563578\n",
      "epoch 15; iter: 400; batch classifier loss: 0.439780; batch adversarial loss: 0.331846\n",
      "epoch 15; iter: 600; batch classifier loss: 0.266615; batch adversarial loss: 0.433151\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378074; batch adversarial loss: 0.322964\n",
      "epoch 16; iter: 200; batch classifier loss: 0.470477; batch adversarial loss: 0.349088\n",
      "epoch 16; iter: 400; batch classifier loss: 0.369086; batch adversarial loss: 0.440602\n",
      "epoch 16; iter: 600; batch classifier loss: 0.305969; batch adversarial loss: 0.479413\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269249; batch adversarial loss: 0.491728\n",
      "epoch 17; iter: 200; batch classifier loss: 0.344871; batch adversarial loss: 0.538735\n",
      "epoch 17; iter: 400; batch classifier loss: 0.317456; batch adversarial loss: 0.694939\n",
      "epoch 17; iter: 600; batch classifier loss: 0.463785; batch adversarial loss: 0.325951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.238530; batch adversarial loss: 0.431887\n",
      "epoch 18; iter: 200; batch classifier loss: 0.304357; batch adversarial loss: 0.529340\n",
      "epoch 18; iter: 400; batch classifier loss: 0.330362; batch adversarial loss: 0.472456\n",
      "epoch 18; iter: 600; batch classifier loss: 0.305039; batch adversarial loss: 0.451223\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262998; batch adversarial loss: 0.384965\n",
      "epoch 19; iter: 200; batch classifier loss: 0.369986; batch adversarial loss: 0.378233\n",
      "epoch 19; iter: 400; batch classifier loss: 0.267390; batch adversarial loss: 0.369683\n",
      "epoch 19; iter: 600; batch classifier loss: 0.392878; batch adversarial loss: 0.526786\n",
      "epoch 0; iter: 0; batch classifier loss: 14.178195; batch adversarial loss: 0.686001\n",
      "epoch 0; iter: 200; batch classifier loss: 7.133458; batch adversarial loss: 0.614181\n",
      "epoch 0; iter: 400; batch classifier loss: 8.521585; batch adversarial loss: 0.537919\n",
      "epoch 0; iter: 600; batch classifier loss: 4.642460; batch adversarial loss: 0.489440\n",
      "epoch 1; iter: 0; batch classifier loss: 4.423530; batch adversarial loss: 0.506299\n",
      "epoch 1; iter: 200; batch classifier loss: 8.714896; batch adversarial loss: 0.443040\n",
      "epoch 1; iter: 400; batch classifier loss: 1.089067; batch adversarial loss: 0.460001\n",
      "epoch 1; iter: 600; batch classifier loss: 3.441121; batch adversarial loss: 0.499380\n",
      "epoch 2; iter: 0; batch classifier loss: 6.498725; batch adversarial loss: 0.399659\n",
      "epoch 2; iter: 200; batch classifier loss: 1.675737; batch adversarial loss: 0.448182\n",
      "epoch 2; iter: 400; batch classifier loss: 1.117931; batch adversarial loss: 0.429613\n",
      "epoch 2; iter: 600; batch classifier loss: 1.525577; batch adversarial loss: 0.436502\n",
      "epoch 3; iter: 0; batch classifier loss: 1.647106; batch adversarial loss: 0.478087\n",
      "epoch 3; iter: 200; batch classifier loss: 1.800230; batch adversarial loss: 0.448569\n",
      "epoch 3; iter: 400; batch classifier loss: 0.735783; batch adversarial loss: 0.384237\n",
      "epoch 3; iter: 600; batch classifier loss: 1.074064; batch adversarial loss: 0.394430\n",
      "epoch 4; iter: 0; batch classifier loss: 2.404939; batch adversarial loss: 0.373699\n",
      "epoch 4; iter: 200; batch classifier loss: 0.928787; batch adversarial loss: 0.453380\n",
      "epoch 4; iter: 400; batch classifier loss: 0.576382; batch adversarial loss: 0.364859\n",
      "epoch 4; iter: 600; batch classifier loss: 0.446228; batch adversarial loss: 0.426989\n",
      "epoch 5; iter: 0; batch classifier loss: 0.461100; batch adversarial loss: 0.459217\n",
      "epoch 5; iter: 200; batch classifier loss: 0.474828; batch adversarial loss: 0.416605\n",
      "epoch 5; iter: 400; batch classifier loss: 0.405906; batch adversarial loss: 0.302984\n",
      "epoch 5; iter: 600; batch classifier loss: 0.430746; batch adversarial loss: 0.446038\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502951; batch adversarial loss: 0.375364\n",
      "epoch 6; iter: 200; batch classifier loss: 0.435811; batch adversarial loss: 0.450012\n",
      "epoch 6; iter: 400; batch classifier loss: 0.422083; batch adversarial loss: 0.339908\n",
      "epoch 6; iter: 600; batch classifier loss: 0.329758; batch adversarial loss: 0.432520\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332924; batch adversarial loss: 0.394018\n",
      "epoch 7; iter: 200; batch classifier loss: 0.485599; batch adversarial loss: 0.260087\n",
      "epoch 7; iter: 400; batch classifier loss: 0.466601; batch adversarial loss: 0.463202\n",
      "epoch 7; iter: 600; batch classifier loss: 0.437475; batch adversarial loss: 0.262023\n",
      "epoch 8; iter: 0; batch classifier loss: 0.279945; batch adversarial loss: 0.394651\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387335; batch adversarial loss: 0.418098\n",
      "epoch 8; iter: 400; batch classifier loss: 0.286272; batch adversarial loss: 0.303696\n",
      "epoch 8; iter: 600; batch classifier loss: 0.316583; batch adversarial loss: 0.393398\n",
      "epoch 9; iter: 0; batch classifier loss: 0.327550; batch adversarial loss: 0.328398\n",
      "epoch 9; iter: 200; batch classifier loss: 0.347106; batch adversarial loss: 0.444932\n",
      "epoch 9; iter: 400; batch classifier loss: 0.378062; batch adversarial loss: 0.404278\n",
      "epoch 9; iter: 600; batch classifier loss: 0.389450; batch adversarial loss: 0.296587\n",
      "epoch 10; iter: 0; batch classifier loss: 0.282083; batch adversarial loss: 0.480395\n",
      "epoch 10; iter: 200; batch classifier loss: 0.373962; batch adversarial loss: 0.333059\n",
      "epoch 10; iter: 400; batch classifier loss: 0.413230; batch adversarial loss: 0.372527\n",
      "epoch 10; iter: 600; batch classifier loss: 0.204656; batch adversarial loss: 0.425872\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416328; batch adversarial loss: 0.400668\n",
      "epoch 11; iter: 200; batch classifier loss: 0.344487; batch adversarial loss: 0.433331\n",
      "epoch 11; iter: 400; batch classifier loss: 0.701525; batch adversarial loss: 0.390352\n",
      "epoch 11; iter: 600; batch classifier loss: 0.345963; batch adversarial loss: 0.293952\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359989; batch adversarial loss: 0.370835\n",
      "epoch 12; iter: 200; batch classifier loss: 0.247501; batch adversarial loss: 0.298680\n",
      "epoch 12; iter: 400; batch classifier loss: 0.351688; batch adversarial loss: 0.554675\n",
      "epoch 12; iter: 600; batch classifier loss: 0.505152; batch adversarial loss: 0.619928\n",
      "epoch 13; iter: 0; batch classifier loss: 0.395436; batch adversarial loss: 0.454314\n",
      "epoch 13; iter: 200; batch classifier loss: 0.366117; batch adversarial loss: 0.341375\n",
      "epoch 13; iter: 400; batch classifier loss: 0.315193; batch adversarial loss: 0.373431\n",
      "epoch 13; iter: 600; batch classifier loss: 0.432723; batch adversarial loss: 0.450958\n",
      "epoch 14; iter: 0; batch classifier loss: 0.278756; batch adversarial loss: 0.471587\n",
      "epoch 14; iter: 200; batch classifier loss: 0.293220; batch adversarial loss: 0.427909\n",
      "epoch 14; iter: 400; batch classifier loss: 0.287505; batch adversarial loss: 0.419888\n",
      "epoch 14; iter: 600; batch classifier loss: 0.346165; batch adversarial loss: 0.439168\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337177; batch adversarial loss: 0.428411\n",
      "epoch 15; iter: 200; batch classifier loss: 0.358030; batch adversarial loss: 0.357778\n",
      "epoch 15; iter: 400; batch classifier loss: 0.405731; batch adversarial loss: 0.374706\n",
      "epoch 15; iter: 600; batch classifier loss: 0.615844; batch adversarial loss: 0.474296\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489258; batch adversarial loss: 0.560806\n",
      "epoch 16; iter: 200; batch classifier loss: 0.270340; batch adversarial loss: 0.389738\n",
      "epoch 16; iter: 400; batch classifier loss: 0.732835; batch adversarial loss: 0.455506\n",
      "epoch 16; iter: 600; batch classifier loss: 0.399212; batch adversarial loss: 0.313820\n",
      "epoch 17; iter: 0; batch classifier loss: 0.378255; batch adversarial loss: 0.475636\n",
      "epoch 17; iter: 200; batch classifier loss: 0.289958; batch adversarial loss: 0.425986\n",
      "epoch 17; iter: 400; batch classifier loss: 0.533518; batch adversarial loss: 0.239296\n",
      "epoch 17; iter: 600; batch classifier loss: 0.254211; batch adversarial loss: 0.421169\n",
      "epoch 18; iter: 0; batch classifier loss: 0.424934; batch adversarial loss: 0.473786\n",
      "epoch 18; iter: 200; batch classifier loss: 0.295562; batch adversarial loss: 0.289937\n",
      "epoch 18; iter: 400; batch classifier loss: 0.276569; batch adversarial loss: 0.421860\n",
      "epoch 18; iter: 600; batch classifier loss: 0.254974; batch adversarial loss: 0.348923\n",
      "epoch 19; iter: 0; batch classifier loss: 0.323656; batch adversarial loss: 0.346357\n",
      "epoch 19; iter: 200; batch classifier loss: 0.404910; batch adversarial loss: 0.532428\n",
      "epoch 19; iter: 400; batch classifier loss: 0.389082; batch adversarial loss: 0.352999\n",
      "epoch 19; iter: 600; batch classifier loss: 0.378952; batch adversarial loss: 0.353737\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 12.132196; batch adversarial loss: 1.110523\n",
      "epoch 0; iter: 200; batch classifier loss: 3.426633; batch adversarial loss: 1.053488\n",
      "epoch 0; iter: 400; batch classifier loss: 5.142054; batch adversarial loss: 0.835820\n",
      "epoch 0; iter: 600; batch classifier loss: 1.343586; batch adversarial loss: 0.689575\n",
      "epoch 1; iter: 0; batch classifier loss: 4.179070; batch adversarial loss: 0.666167\n",
      "epoch 1; iter: 200; batch classifier loss: 5.671936; batch adversarial loss: 0.488376\n",
      "epoch 1; iter: 400; batch classifier loss: 3.473013; batch adversarial loss: 0.467113\n",
      "epoch 1; iter: 600; batch classifier loss: 3.770780; batch adversarial loss: 0.464753\n",
      "epoch 2; iter: 0; batch classifier loss: 7.523229; batch adversarial loss: 0.529196\n",
      "epoch 2; iter: 200; batch classifier loss: 4.322602; batch adversarial loss: 0.429998\n",
      "epoch 2; iter: 400; batch classifier loss: 0.683853; batch adversarial loss: 0.401392\n",
      "epoch 2; iter: 600; batch classifier loss: 5.159576; batch adversarial loss: 0.454154\n",
      "epoch 3; iter: 0; batch classifier loss: 2.052404; batch adversarial loss: 0.462030\n",
      "epoch 3; iter: 200; batch classifier loss: 1.294976; batch adversarial loss: 0.421793\n",
      "epoch 3; iter: 400; batch classifier loss: 1.976541; batch adversarial loss: 0.416052\n",
      "epoch 3; iter: 600; batch classifier loss: 0.754902; batch adversarial loss: 0.562171\n",
      "epoch 4; iter: 0; batch classifier loss: 0.932495; batch adversarial loss: 0.459728\n",
      "epoch 4; iter: 200; batch classifier loss: 2.079243; batch adversarial loss: 0.433638\n",
      "epoch 4; iter: 400; batch classifier loss: 1.997415; batch adversarial loss: 0.430138\n",
      "epoch 4; iter: 600; batch classifier loss: 0.362012; batch adversarial loss: 0.401891\n",
      "epoch 5; iter: 0; batch classifier loss: 0.770178; batch adversarial loss: 0.352770\n",
      "epoch 5; iter: 200; batch classifier loss: 0.457040; batch adversarial loss: 0.321010\n",
      "epoch 5; iter: 400; batch classifier loss: 0.669763; batch adversarial loss: 0.515312\n",
      "epoch 5; iter: 600; batch classifier loss: 0.452268; batch adversarial loss: 0.457417\n",
      "epoch 6; iter: 0; batch classifier loss: 0.617251; batch adversarial loss: 0.343163\n",
      "epoch 6; iter: 200; batch classifier loss: 0.567670; batch adversarial loss: 0.403640\n",
      "epoch 6; iter: 400; batch classifier loss: 0.496975; batch adversarial loss: 0.369040\n",
      "epoch 6; iter: 600; batch classifier loss: 0.427562; batch adversarial loss: 0.276948\n",
      "epoch 7; iter: 0; batch classifier loss: 0.413242; batch adversarial loss: 0.381269\n",
      "epoch 7; iter: 200; batch classifier loss: 0.513381; batch adversarial loss: 0.275556\n",
      "epoch 7; iter: 400; batch classifier loss: 0.397606; batch adversarial loss: 0.479665\n",
      "epoch 7; iter: 600; batch classifier loss: 0.538428; batch adversarial loss: 0.351306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465645; batch adversarial loss: 0.342352\n",
      "epoch 8; iter: 200; batch classifier loss: 0.482313; batch adversarial loss: 0.451226\n",
      "epoch 8; iter: 400; batch classifier loss: 0.324800; batch adversarial loss: 0.400625\n",
      "epoch 8; iter: 600; batch classifier loss: 0.531791; batch adversarial loss: 0.542832\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390557; batch adversarial loss: 0.413459\n",
      "epoch 9; iter: 200; batch classifier loss: 0.441143; batch adversarial loss: 0.234645\n",
      "epoch 9; iter: 400; batch classifier loss: 0.390287; batch adversarial loss: 0.478496\n",
      "epoch 9; iter: 600; batch classifier loss: 0.367817; batch adversarial loss: 0.382623\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338416; batch adversarial loss: 0.373678\n",
      "epoch 10; iter: 200; batch classifier loss: 0.472739; batch adversarial loss: 0.410230\n",
      "epoch 10; iter: 400; batch classifier loss: 0.402027; batch adversarial loss: 0.416354\n",
      "epoch 10; iter: 600; batch classifier loss: 0.404678; batch adversarial loss: 0.392317\n",
      "epoch 11; iter: 0; batch classifier loss: 0.352956; batch adversarial loss: 0.427131\n",
      "epoch 11; iter: 200; batch classifier loss: 0.302999; batch adversarial loss: 0.405682\n",
      "epoch 11; iter: 400; batch classifier loss: 0.368364; batch adversarial loss: 0.402355\n",
      "epoch 11; iter: 600; batch classifier loss: 0.366478; batch adversarial loss: 0.380505\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270815; batch adversarial loss: 0.542864\n",
      "epoch 12; iter: 200; batch classifier loss: 0.394885; batch adversarial loss: 0.272098\n",
      "epoch 12; iter: 400; batch classifier loss: 0.285063; batch adversarial loss: 0.434809\n",
      "epoch 12; iter: 600; batch classifier loss: 0.347788; batch adversarial loss: 0.366083\n",
      "epoch 13; iter: 0; batch classifier loss: 0.324028; batch adversarial loss: 0.425931\n",
      "epoch 13; iter: 200; batch classifier loss: 0.423177; batch adversarial loss: 0.586229\n",
      "epoch 13; iter: 400; batch classifier loss: 0.367379; batch adversarial loss: 0.406676\n",
      "epoch 13; iter: 600; batch classifier loss: 0.403010; batch adversarial loss: 0.491920\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336098; batch adversarial loss: 0.380198\n",
      "epoch 14; iter: 200; batch classifier loss: 0.487460; batch adversarial loss: 0.430385\n",
      "epoch 14; iter: 400; batch classifier loss: 0.343776; batch adversarial loss: 0.374071\n",
      "epoch 14; iter: 600; batch classifier loss: 0.448118; batch adversarial loss: 0.380372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330552; batch adversarial loss: 0.506529\n",
      "epoch 15; iter: 200; batch classifier loss: 0.336561; batch adversarial loss: 0.434739\n",
      "epoch 15; iter: 400; batch classifier loss: 0.447939; batch adversarial loss: 0.483187\n",
      "epoch 15; iter: 600; batch classifier loss: 0.256984; batch adversarial loss: 0.370193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.342115; batch adversarial loss: 0.349650\n",
      "epoch 16; iter: 200; batch classifier loss: 0.333589; batch adversarial loss: 0.367583\n",
      "epoch 16; iter: 400; batch classifier loss: 0.428494; batch adversarial loss: 0.454972\n",
      "epoch 16; iter: 600; batch classifier loss: 0.268912; batch adversarial loss: 0.460595\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453383; batch adversarial loss: 0.455097\n",
      "epoch 17; iter: 200; batch classifier loss: 0.421316; batch adversarial loss: 0.470876\n",
      "epoch 17; iter: 400; batch classifier loss: 0.425110; batch adversarial loss: 0.462719\n",
      "epoch 17; iter: 600; batch classifier loss: 0.389162; batch adversarial loss: 0.469476\n",
      "epoch 18; iter: 0; batch classifier loss: 0.372145; batch adversarial loss: 0.323367\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399595; batch adversarial loss: 0.402529\n",
      "epoch 18; iter: 400; batch classifier loss: 0.469619; batch adversarial loss: 0.344741\n",
      "epoch 18; iter: 600; batch classifier loss: 0.425385; batch adversarial loss: 0.461161\n",
      "epoch 19; iter: 0; batch classifier loss: 0.300053; batch adversarial loss: 0.319874\n",
      "epoch 19; iter: 200; batch classifier loss: 0.398908; batch adversarial loss: 0.400510\n",
      "epoch 19; iter: 400; batch classifier loss: 0.373515; batch adversarial loss: 0.350130\n",
      "epoch 19; iter: 600; batch classifier loss: 0.560758; batch adversarial loss: 0.456121\n",
      "epoch 20; iter: 0; batch classifier loss: 0.489340; batch adversarial loss: 0.364954\n",
      "epoch 20; iter: 200; batch classifier loss: 0.389141; batch adversarial loss: 0.406856\n",
      "epoch 20; iter: 400; batch classifier loss: 0.302532; batch adversarial loss: 0.460829\n",
      "epoch 20; iter: 600; batch classifier loss: 0.528208; batch adversarial loss: 0.313604\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526247; batch adversarial loss: 0.401310\n",
      "epoch 21; iter: 200; batch classifier loss: 0.379359; batch adversarial loss: 0.371246\n",
      "epoch 21; iter: 400; batch classifier loss: 0.351569; batch adversarial loss: 0.416358\n",
      "epoch 21; iter: 600; batch classifier loss: 0.433697; batch adversarial loss: 0.313834\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476934; batch adversarial loss: 0.453188\n",
      "epoch 22; iter: 200; batch classifier loss: 0.485321; batch adversarial loss: 0.487353\n",
      "epoch 22; iter: 400; batch classifier loss: 0.471811; batch adversarial loss: 0.380988\n",
      "epoch 22; iter: 600; batch classifier loss: 0.369697; batch adversarial loss: 0.624609\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426672; batch adversarial loss: 0.454177\n",
      "epoch 23; iter: 200; batch classifier loss: 0.469490; batch adversarial loss: 0.435871\n",
      "epoch 23; iter: 400; batch classifier loss: 0.419155; batch adversarial loss: 0.487411\n",
      "epoch 23; iter: 600; batch classifier loss: 0.517744; batch adversarial loss: 0.371878\n",
      "epoch 24; iter: 0; batch classifier loss: 0.330742; batch adversarial loss: 0.403595\n",
      "epoch 24; iter: 200; batch classifier loss: 0.353330; batch adversarial loss: 0.411431\n",
      "epoch 24; iter: 400; batch classifier loss: 0.472745; batch adversarial loss: 0.318125\n",
      "epoch 24; iter: 600; batch classifier loss: 0.524843; batch adversarial loss: 0.313295\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429222; batch adversarial loss: 0.316898\n",
      "epoch 25; iter: 200; batch classifier loss: 0.422578; batch adversarial loss: 0.295637\n",
      "epoch 25; iter: 400; batch classifier loss: 0.471236; batch adversarial loss: 0.442765\n",
      "epoch 25; iter: 600; batch classifier loss: 0.472519; batch adversarial loss: 0.507753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.369839; batch adversarial loss: 0.562917\n",
      "epoch 26; iter: 200; batch classifier loss: 0.454016; batch adversarial loss: 0.398653\n",
      "epoch 26; iter: 400; batch classifier loss: 0.532177; batch adversarial loss: 0.406116\n",
      "epoch 26; iter: 600; batch classifier loss: 0.477580; batch adversarial loss: 0.290369\n",
      "epoch 27; iter: 0; batch classifier loss: 0.564295; batch adversarial loss: 0.327473\n",
      "epoch 27; iter: 200; batch classifier loss: 0.459960; batch adversarial loss: 0.513139\n",
      "epoch 27; iter: 400; batch classifier loss: 0.479812; batch adversarial loss: 0.409896\n",
      "epoch 27; iter: 600; batch classifier loss: 0.409609; batch adversarial loss: 0.333536\n",
      "epoch 28; iter: 0; batch classifier loss: 0.493357; batch adversarial loss: 0.378151\n",
      "epoch 28; iter: 200; batch classifier loss: 0.435472; batch adversarial loss: 0.292859\n",
      "epoch 28; iter: 400; batch classifier loss: 0.338709; batch adversarial loss: 0.402775\n",
      "epoch 28; iter: 600; batch classifier loss: 0.625583; batch adversarial loss: 0.354514\n",
      "epoch 29; iter: 0; batch classifier loss: 0.284861; batch adversarial loss: 0.428026\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338382; batch adversarial loss: 0.485589\n",
      "epoch 29; iter: 400; batch classifier loss: 0.284596; batch adversarial loss: 0.464358\n",
      "epoch 29; iter: 600; batch classifier loss: 0.489361; batch adversarial loss: 0.543811\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436731; batch adversarial loss: 0.410569\n",
      "epoch 30; iter: 200; batch classifier loss: 0.225007; batch adversarial loss: 0.436365\n",
      "epoch 30; iter: 400; batch classifier loss: 0.403063; batch adversarial loss: 0.292492\n",
      "epoch 30; iter: 600; batch classifier loss: 0.543422; batch adversarial loss: 0.270222\n",
      "epoch 31; iter: 0; batch classifier loss: 0.405238; batch adversarial loss: 0.350998\n",
      "epoch 31; iter: 200; batch classifier loss: 0.482759; batch adversarial loss: 0.348025\n",
      "epoch 31; iter: 400; batch classifier loss: 0.415630; batch adversarial loss: 0.511375\n",
      "epoch 31; iter: 600; batch classifier loss: 0.565298; batch adversarial loss: 0.382082\n",
      "epoch 32; iter: 0; batch classifier loss: 0.411390; batch adversarial loss: 0.406880\n",
      "epoch 32; iter: 200; batch classifier loss: 0.346259; batch adversarial loss: 0.317222\n",
      "epoch 32; iter: 400; batch classifier loss: 0.394519; batch adversarial loss: 0.264054\n",
      "epoch 32; iter: 600; batch classifier loss: 0.516989; batch adversarial loss: 0.373869\n",
      "epoch 33; iter: 0; batch classifier loss: 0.534999; batch adversarial loss: 0.489019\n",
      "epoch 33; iter: 200; batch classifier loss: 0.449746; batch adversarial loss: 0.346751\n",
      "epoch 33; iter: 400; batch classifier loss: 0.378290; batch adversarial loss: 0.491951\n",
      "epoch 33; iter: 600; batch classifier loss: 0.583638; batch adversarial loss: 0.468336\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411663; batch adversarial loss: 0.405906\n",
      "epoch 34; iter: 200; batch classifier loss: 0.522442; batch adversarial loss: 0.357888\n",
      "epoch 34; iter: 400; batch classifier loss: 0.449675; batch adversarial loss: 0.425030\n",
      "epoch 34; iter: 600; batch classifier loss: 0.521329; batch adversarial loss: 0.513488\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376640; batch adversarial loss: 0.400782\n",
      "epoch 35; iter: 200; batch classifier loss: 0.492473; batch adversarial loss: 0.459974\n",
      "epoch 35; iter: 400; batch classifier loss: 0.832081; batch adversarial loss: 0.402921\n",
      "epoch 35; iter: 600; batch classifier loss: 0.526693; batch adversarial loss: 0.318602\n",
      "epoch 36; iter: 0; batch classifier loss: 0.345357; batch adversarial loss: 0.471305\n",
      "epoch 36; iter: 200; batch classifier loss: 0.493752; batch adversarial loss: 0.407348\n",
      "epoch 36; iter: 400; batch classifier loss: 0.668151; batch adversarial loss: 0.456032\n",
      "epoch 36; iter: 600; batch classifier loss: 0.697689; batch adversarial loss: 0.373018\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460240; batch adversarial loss: 0.362487\n",
      "epoch 37; iter: 200; batch classifier loss: 0.414861; batch adversarial loss: 0.373184\n",
      "epoch 37; iter: 400; batch classifier loss: 0.515424; batch adversarial loss: 0.381688\n",
      "epoch 37; iter: 600; batch classifier loss: 0.346384; batch adversarial loss: 0.373141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.560498; batch adversarial loss: 0.509556\n",
      "epoch 38; iter: 200; batch classifier loss: 0.483076; batch adversarial loss: 0.324244\n",
      "epoch 38; iter: 400; batch classifier loss: 0.392025; batch adversarial loss: 0.434381\n",
      "epoch 38; iter: 600; batch classifier loss: 0.396381; batch adversarial loss: 0.318832\n",
      "epoch 39; iter: 0; batch classifier loss: 0.627493; batch adversarial loss: 0.319905\n",
      "epoch 39; iter: 200; batch classifier loss: 0.381175; batch adversarial loss: 0.548287\n",
      "epoch 39; iter: 400; batch classifier loss: 0.447625; batch adversarial loss: 0.427199\n",
      "epoch 39; iter: 600; batch classifier loss: 0.514920; batch adversarial loss: 0.346402\n",
      "epoch 40; iter: 0; batch classifier loss: 0.488711; batch adversarial loss: 0.327691\n",
      "epoch 40; iter: 200; batch classifier loss: 0.401106; batch adversarial loss: 0.322407\n",
      "epoch 40; iter: 400; batch classifier loss: 0.521091; batch adversarial loss: 0.545176\n",
      "epoch 40; iter: 600; batch classifier loss: 0.482089; batch adversarial loss: 0.515153\n",
      "epoch 41; iter: 0; batch classifier loss: 0.361434; batch adversarial loss: 0.358980\n",
      "epoch 41; iter: 200; batch classifier loss: 0.570152; batch adversarial loss: 0.402124\n",
      "epoch 41; iter: 400; batch classifier loss: 0.537960; batch adversarial loss: 0.343129\n",
      "epoch 41; iter: 600; batch classifier loss: 0.463825; batch adversarial loss: 0.485114\n",
      "epoch 42; iter: 0; batch classifier loss: 0.519069; batch adversarial loss: 0.410039\n",
      "epoch 42; iter: 200; batch classifier loss: 0.653450; batch adversarial loss: 0.483867\n",
      "epoch 42; iter: 400; batch classifier loss: 0.567647; batch adversarial loss: 0.405941\n",
      "epoch 42; iter: 600; batch classifier loss: 0.550136; batch adversarial loss: 0.379900\n",
      "epoch 43; iter: 0; batch classifier loss: 0.578055; batch adversarial loss: 0.373964\n",
      "epoch 43; iter: 200; batch classifier loss: 0.514721; batch adversarial loss: 0.317683\n",
      "epoch 43; iter: 400; batch classifier loss: 0.684337; batch adversarial loss: 0.239537\n",
      "epoch 43; iter: 600; batch classifier loss: 0.376922; batch adversarial loss: 0.379738\n",
      "epoch 44; iter: 0; batch classifier loss: 0.796291; batch adversarial loss: 0.320855\n",
      "epoch 44; iter: 200; batch classifier loss: 0.429604; batch adversarial loss: 0.506756\n",
      "epoch 44; iter: 400; batch classifier loss: 0.343771; batch adversarial loss: 0.453441\n",
      "epoch 44; iter: 600; batch classifier loss: 0.400927; batch adversarial loss: 0.436389\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420577; batch adversarial loss: 0.420222\n",
      "epoch 45; iter: 200; batch classifier loss: 0.564277; batch adversarial loss: 0.435139\n",
      "epoch 45; iter: 400; batch classifier loss: 0.453360; batch adversarial loss: 0.514111\n",
      "epoch 45; iter: 600; batch classifier loss: 0.516384; batch adversarial loss: 0.467381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.585123; batch adversarial loss: 0.440530\n",
      "epoch 46; iter: 200; batch classifier loss: 0.577372; batch adversarial loss: 0.461088\n",
      "epoch 46; iter: 400; batch classifier loss: 0.458873; batch adversarial loss: 0.405676\n",
      "epoch 46; iter: 600; batch classifier loss: 0.459975; batch adversarial loss: 0.430715\n",
      "epoch 47; iter: 0; batch classifier loss: 0.595246; batch adversarial loss: 0.381097\n",
      "epoch 47; iter: 200; batch classifier loss: 0.779772; batch adversarial loss: 0.354398\n",
      "epoch 47; iter: 400; batch classifier loss: 0.885983; batch adversarial loss: 0.375733\n",
      "epoch 47; iter: 600; batch classifier loss: 0.384849; batch adversarial loss: 0.372211\n",
      "epoch 48; iter: 0; batch classifier loss: 0.693697; batch adversarial loss: 0.271524\n",
      "epoch 48; iter: 200; batch classifier loss: 0.515292; batch adversarial loss: 0.290913\n",
      "epoch 48; iter: 400; batch classifier loss: 0.595739; batch adversarial loss: 0.347464\n",
      "epoch 48; iter: 600; batch classifier loss: 0.521013; batch adversarial loss: 0.328886\n",
      "epoch 49; iter: 0; batch classifier loss: 0.546401; batch adversarial loss: 0.300884\n",
      "epoch 49; iter: 200; batch classifier loss: 0.424592; batch adversarial loss: 0.408385\n",
      "epoch 49; iter: 400; batch classifier loss: 0.848269; batch adversarial loss: 0.403856\n",
      "epoch 49; iter: 600; batch classifier loss: 0.592559; batch adversarial loss: 0.432328\n",
      "epoch 0; iter: 0; batch classifier loss: 16.561216; batch adversarial loss: 0.470755\n",
      "epoch 0; iter: 200; batch classifier loss: 6.195895; batch adversarial loss: 0.541276\n",
      "epoch 0; iter: 400; batch classifier loss: 21.577034; batch adversarial loss: 0.519332\n",
      "epoch 0; iter: 600; batch classifier loss: 4.663852; batch adversarial loss: 0.533379\n",
      "epoch 1; iter: 0; batch classifier loss: 15.352374; batch adversarial loss: 0.533289\n",
      "epoch 1; iter: 200; batch classifier loss: 0.866608; batch adversarial loss: 0.493184\n",
      "epoch 1; iter: 400; batch classifier loss: 8.975863; batch adversarial loss: 0.466690\n",
      "epoch 1; iter: 600; batch classifier loss: 0.339114; batch adversarial loss: 0.441333\n",
      "epoch 2; iter: 0; batch classifier loss: 2.420683; batch adversarial loss: 0.377324\n",
      "epoch 2; iter: 200; batch classifier loss: 9.344584; batch adversarial loss: 0.479931\n",
      "epoch 2; iter: 400; batch classifier loss: 2.646217; batch adversarial loss: 0.510918\n",
      "epoch 2; iter: 600; batch classifier loss: 1.611923; batch adversarial loss: 0.498423\n",
      "epoch 3; iter: 0; batch classifier loss: 4.641938; batch adversarial loss: 0.456519\n",
      "epoch 3; iter: 200; batch classifier loss: 1.906062; batch adversarial loss: 0.442345\n",
      "epoch 3; iter: 400; batch classifier loss: 4.926996; batch adversarial loss: 0.415713\n",
      "epoch 3; iter: 600; batch classifier loss: 0.850548; batch adversarial loss: 0.451192\n",
      "epoch 4; iter: 0; batch classifier loss: 1.676024; batch adversarial loss: 0.455413\n",
      "epoch 4; iter: 200; batch classifier loss: 0.558728; batch adversarial loss: 0.307872\n",
      "epoch 4; iter: 400; batch classifier loss: 4.521836; batch adversarial loss: 0.403068\n",
      "epoch 4; iter: 600; batch classifier loss: 1.708973; batch adversarial loss: 0.362019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.778855; batch adversarial loss: 0.393035\n",
      "epoch 5; iter: 200; batch classifier loss: 0.422034; batch adversarial loss: 0.430213\n",
      "epoch 5; iter: 400; batch classifier loss: 0.508849; batch adversarial loss: 0.278715\n",
      "epoch 5; iter: 600; batch classifier loss: 0.407030; batch adversarial loss: 0.423047\n",
      "epoch 6; iter: 0; batch classifier loss: 0.777193; batch adversarial loss: 0.341377\n",
      "epoch 6; iter: 200; batch classifier loss: 0.423502; batch adversarial loss: 0.332040\n",
      "epoch 6; iter: 400; batch classifier loss: 0.475241; batch adversarial loss: 0.452312\n",
      "epoch 6; iter: 600; batch classifier loss: 0.414154; batch adversarial loss: 0.443897\n",
      "epoch 7; iter: 0; batch classifier loss: 0.508829; batch adversarial loss: 0.437313\n",
      "epoch 7; iter: 200; batch classifier loss: 0.645200; batch adversarial loss: 0.310483\n",
      "epoch 7; iter: 400; batch classifier loss: 0.307419; batch adversarial loss: 0.294850\n",
      "epoch 7; iter: 600; batch classifier loss: 0.558751; batch adversarial loss: 0.399976\n",
      "epoch 8; iter: 0; batch classifier loss: 0.558058; batch adversarial loss: 0.294565\n",
      "epoch 8; iter: 200; batch classifier loss: 0.490490; batch adversarial loss: 0.436754\n",
      "epoch 8; iter: 400; batch classifier loss: 0.377979; batch adversarial loss: 0.510292\n",
      "epoch 8; iter: 600; batch classifier loss: 0.589705; batch adversarial loss: 0.405080\n",
      "epoch 9; iter: 0; batch classifier loss: 0.377431; batch adversarial loss: 0.371592\n",
      "epoch 9; iter: 200; batch classifier loss: 0.370358; batch adversarial loss: 0.423116\n",
      "epoch 9; iter: 400; batch classifier loss: 0.479412; batch adversarial loss: 0.238824\n",
      "epoch 9; iter: 600; batch classifier loss: 0.472059; batch adversarial loss: 0.484072\n",
      "epoch 10; iter: 0; batch classifier loss: 0.345793; batch adversarial loss: 0.393149\n",
      "epoch 10; iter: 200; batch classifier loss: 0.372187; batch adversarial loss: 0.435239\n",
      "epoch 10; iter: 400; batch classifier loss: 0.361613; batch adversarial loss: 0.368563\n",
      "epoch 10; iter: 600; batch classifier loss: 0.423976; batch adversarial loss: 0.353102\n",
      "epoch 11; iter: 0; batch classifier loss: 0.270352; batch adversarial loss: 0.493429\n",
      "epoch 11; iter: 200; batch classifier loss: 0.332978; batch adversarial loss: 0.379391\n",
      "epoch 11; iter: 400; batch classifier loss: 0.412401; batch adversarial loss: 0.439447\n",
      "epoch 11; iter: 600; batch classifier loss: 0.305881; batch adversarial loss: 0.399896\n",
      "epoch 12; iter: 0; batch classifier loss: 0.249667; batch adversarial loss: 0.614308\n",
      "epoch 12; iter: 200; batch classifier loss: 0.279049; batch adversarial loss: 0.566806\n",
      "epoch 12; iter: 400; batch classifier loss: 0.305668; batch adversarial loss: 0.473666\n",
      "epoch 12; iter: 600; batch classifier loss: 0.409693; batch adversarial loss: 0.321329\n",
      "epoch 13; iter: 0; batch classifier loss: 0.395555; batch adversarial loss: 0.392960\n",
      "epoch 13; iter: 200; batch classifier loss: 0.552415; batch adversarial loss: 0.280096\n",
      "epoch 13; iter: 400; batch classifier loss: 0.388188; batch adversarial loss: 0.446039\n",
      "epoch 13; iter: 600; batch classifier loss: 0.319875; batch adversarial loss: 0.381060\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342683; batch adversarial loss: 0.389853\n",
      "epoch 14; iter: 200; batch classifier loss: 0.330860; batch adversarial loss: 0.401049\n",
      "epoch 14; iter: 400; batch classifier loss: 0.353088; batch adversarial loss: 0.382004\n",
      "epoch 14; iter: 600; batch classifier loss: 0.349735; batch adversarial loss: 0.433209\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270062; batch adversarial loss: 0.389817\n",
      "epoch 15; iter: 200; batch classifier loss: 0.449783; batch adversarial loss: 0.468862\n",
      "epoch 15; iter: 400; batch classifier loss: 0.321062; batch adversarial loss: 0.564447\n",
      "epoch 15; iter: 600; batch classifier loss: 0.295015; batch adversarial loss: 0.587189\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382208; batch adversarial loss: 0.370456\n",
      "epoch 16; iter: 200; batch classifier loss: 0.523905; batch adversarial loss: 0.405757\n",
      "epoch 16; iter: 400; batch classifier loss: 0.372896; batch adversarial loss: 0.440660\n",
      "epoch 16; iter: 600; batch classifier loss: 0.232811; batch adversarial loss: 0.495667\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327409; batch adversarial loss: 0.445917\n",
      "epoch 17; iter: 200; batch classifier loss: 0.362282; batch adversarial loss: 0.236357\n",
      "epoch 17; iter: 400; batch classifier loss: 0.328963; batch adversarial loss: 0.401809\n",
      "epoch 17; iter: 600; batch classifier loss: 0.301166; batch adversarial loss: 0.372605\n",
      "epoch 18; iter: 0; batch classifier loss: 0.330841; batch adversarial loss: 0.537728\n",
      "epoch 18; iter: 200; batch classifier loss: 0.486234; batch adversarial loss: 0.402638\n",
      "epoch 18; iter: 400; batch classifier loss: 0.527349; batch adversarial loss: 0.613548\n",
      "epoch 18; iter: 600; batch classifier loss: 0.482004; batch adversarial loss: 0.454524\n",
      "epoch 19; iter: 0; batch classifier loss: 0.662347; batch adversarial loss: 0.479458\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429517; batch adversarial loss: 0.379774\n",
      "epoch 19; iter: 400; batch classifier loss: 0.254229; batch adversarial loss: 0.439830\n",
      "epoch 19; iter: 600; batch classifier loss: 0.568905; batch adversarial loss: 0.345239\n",
      "epoch 20; iter: 0; batch classifier loss: 0.380401; batch adversarial loss: 0.509178\n",
      "epoch 20; iter: 200; batch classifier loss: 0.447347; batch adversarial loss: 0.400228\n",
      "epoch 20; iter: 400; batch classifier loss: 0.268137; batch adversarial loss: 0.577932\n",
      "epoch 20; iter: 600; batch classifier loss: 0.377387; batch adversarial loss: 0.318767\n",
      "epoch 21; iter: 0; batch classifier loss: 0.447094; batch adversarial loss: 0.293466\n",
      "epoch 21; iter: 200; batch classifier loss: 0.315971; batch adversarial loss: 0.508757\n",
      "epoch 21; iter: 400; batch classifier loss: 0.397940; batch adversarial loss: 0.527424\n",
      "epoch 21; iter: 600; batch classifier loss: 0.382837; batch adversarial loss: 0.512459\n",
      "epoch 22; iter: 0; batch classifier loss: 0.339381; batch adversarial loss: 0.547924\n",
      "epoch 22; iter: 200; batch classifier loss: 0.302308; batch adversarial loss: 0.427300\n",
      "epoch 22; iter: 400; batch classifier loss: 0.577105; batch adversarial loss: 0.434270\n",
      "epoch 22; iter: 600; batch classifier loss: 0.446423; batch adversarial loss: 0.323475\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380607; batch adversarial loss: 0.453851\n",
      "epoch 23; iter: 200; batch classifier loss: 0.628372; batch adversarial loss: 0.397977\n",
      "epoch 23; iter: 400; batch classifier loss: 0.548271; batch adversarial loss: 0.317480\n",
      "epoch 23; iter: 600; batch classifier loss: 0.523960; batch adversarial loss: 0.347651\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533190; batch adversarial loss: 0.407931\n",
      "epoch 24; iter: 200; batch classifier loss: 0.405323; batch adversarial loss: 0.482492\n",
      "epoch 24; iter: 400; batch classifier loss: 0.507852; batch adversarial loss: 0.375550\n",
      "epoch 24; iter: 600; batch classifier loss: 0.668807; batch adversarial loss: 0.372145\n",
      "epoch 25; iter: 0; batch classifier loss: 0.692529; batch adversarial loss: 0.373975\n",
      "epoch 25; iter: 200; batch classifier loss: 0.536567; batch adversarial loss: 0.386730\n",
      "epoch 25; iter: 400; batch classifier loss: 0.577564; batch adversarial loss: 0.406696\n",
      "epoch 25; iter: 600; batch classifier loss: 0.402983; batch adversarial loss: 0.359142\n",
      "epoch 26; iter: 0; batch classifier loss: 0.456698; batch adversarial loss: 0.376473\n",
      "epoch 26; iter: 200; batch classifier loss: 0.363879; batch adversarial loss: 0.293809\n",
      "epoch 26; iter: 400; batch classifier loss: 0.440388; batch adversarial loss: 0.433627\n",
      "epoch 26; iter: 600; batch classifier loss: 0.740849; batch adversarial loss: 0.508675\n",
      "epoch 27; iter: 0; batch classifier loss: 0.502053; batch adversarial loss: 0.370714\n",
      "epoch 27; iter: 200; batch classifier loss: 0.554195; batch adversarial loss: 0.403481\n",
      "epoch 27; iter: 400; batch classifier loss: 0.382177; batch adversarial loss: 0.350156\n",
      "epoch 27; iter: 600; batch classifier loss: 0.562186; batch adversarial loss: 0.320838\n",
      "epoch 28; iter: 0; batch classifier loss: 0.597107; batch adversarial loss: 0.403092\n",
      "epoch 28; iter: 200; batch classifier loss: 0.508364; batch adversarial loss: 0.351291\n",
      "epoch 28; iter: 400; batch classifier loss: 0.605777; batch adversarial loss: 0.461492\n",
      "epoch 28; iter: 600; batch classifier loss: 0.519567; batch adversarial loss: 0.489542\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524607; batch adversarial loss: 0.295447\n",
      "epoch 29; iter: 200; batch classifier loss: 0.494498; batch adversarial loss: 0.405316\n",
      "epoch 29; iter: 400; batch classifier loss: 0.529383; batch adversarial loss: 0.323152\n",
      "epoch 29; iter: 600; batch classifier loss: 0.310273; batch adversarial loss: 0.320128\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538954; batch adversarial loss: 0.463263\n",
      "epoch 30; iter: 200; batch classifier loss: 0.670920; batch adversarial loss: 0.374393\n",
      "epoch 30; iter: 400; batch classifier loss: 0.506287; batch adversarial loss: 0.483086\n",
      "epoch 30; iter: 600; batch classifier loss: 0.621720; batch adversarial loss: 0.354781\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459420; batch adversarial loss: 0.295440\n",
      "epoch 31; iter: 200; batch classifier loss: 0.589625; batch adversarial loss: 0.320985\n",
      "epoch 31; iter: 400; batch classifier loss: 0.579715; batch adversarial loss: 0.401154\n",
      "epoch 31; iter: 600; batch classifier loss: 0.370932; batch adversarial loss: 0.386865\n",
      "epoch 32; iter: 0; batch classifier loss: 0.396832; batch adversarial loss: 0.434352\n",
      "epoch 32; iter: 200; batch classifier loss: 0.354636; batch adversarial loss: 0.411546\n",
      "epoch 32; iter: 400; batch classifier loss: 0.399513; batch adversarial loss: 0.416446\n",
      "epoch 32; iter: 600; batch classifier loss: 0.370408; batch adversarial loss: 0.327187\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509993; batch adversarial loss: 0.347108\n",
      "epoch 33; iter: 200; batch classifier loss: 0.429578; batch adversarial loss: 0.488193\n",
      "epoch 33; iter: 400; batch classifier loss: 0.536454; batch adversarial loss: 0.376098\n",
      "epoch 33; iter: 600; batch classifier loss: 0.501927; batch adversarial loss: 0.460541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.547227; batch adversarial loss: 0.350497\n",
      "epoch 34; iter: 200; batch classifier loss: 0.787816; batch adversarial loss: 0.431863\n",
      "epoch 34; iter: 400; batch classifier loss: 0.352475; batch adversarial loss: 0.435595\n",
      "epoch 34; iter: 600; batch classifier loss: 0.443745; batch adversarial loss: 0.403072\n",
      "epoch 35; iter: 0; batch classifier loss: 0.322822; batch adversarial loss: 0.493223\n",
      "epoch 35; iter: 200; batch classifier loss: 0.460574; batch adversarial loss: 0.376555\n",
      "epoch 35; iter: 400; batch classifier loss: 0.555046; batch adversarial loss: 0.460939\n",
      "epoch 35; iter: 600; batch classifier loss: 0.551367; batch adversarial loss: 0.430868\n",
      "epoch 36; iter: 0; batch classifier loss: 0.324862; batch adversarial loss: 0.432658\n",
      "epoch 36; iter: 200; batch classifier loss: 0.858398; batch adversarial loss: 0.429462\n",
      "epoch 36; iter: 400; batch classifier loss: 0.533788; batch adversarial loss: 0.356594\n",
      "epoch 36; iter: 600; batch classifier loss: 0.421782; batch adversarial loss: 0.596300\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452898; batch adversarial loss: 0.376303\n",
      "epoch 37; iter: 200; batch classifier loss: 0.555834; batch adversarial loss: 0.322387\n",
      "epoch 37; iter: 400; batch classifier loss: 0.468766; batch adversarial loss: 0.550922\n",
      "epoch 37; iter: 600; batch classifier loss: 0.544058; batch adversarial loss: 0.405136\n",
      "epoch 38; iter: 0; batch classifier loss: 0.504665; batch adversarial loss: 0.461806\n",
      "epoch 38; iter: 200; batch classifier loss: 0.494463; batch adversarial loss: 0.605217\n",
      "epoch 38; iter: 400; batch classifier loss: 0.495512; batch adversarial loss: 0.381588\n",
      "epoch 38; iter: 600; batch classifier loss: 0.551107; batch adversarial loss: 0.294084\n",
      "epoch 39; iter: 0; batch classifier loss: 0.722155; batch adversarial loss: 0.430103\n",
      "epoch 39; iter: 200; batch classifier loss: 0.559235; batch adversarial loss: 0.430795\n",
      "epoch 39; iter: 400; batch classifier loss: 0.551623; batch adversarial loss: 0.436009\n",
      "epoch 39; iter: 600; batch classifier loss: 0.710273; batch adversarial loss: 0.350196\n",
      "epoch 40; iter: 0; batch classifier loss: 0.554626; batch adversarial loss: 0.349160\n",
      "epoch 40; iter: 200; batch classifier loss: 0.725685; batch adversarial loss: 0.515362\n",
      "epoch 40; iter: 400; batch classifier loss: 0.476998; batch adversarial loss: 0.381291\n",
      "epoch 40; iter: 600; batch classifier loss: 0.707132; batch adversarial loss: 0.295193\n",
      "epoch 41; iter: 0; batch classifier loss: 0.358492; batch adversarial loss: 0.323125\n",
      "epoch 41; iter: 200; batch classifier loss: 0.516542; batch adversarial loss: 0.432807\n",
      "epoch 41; iter: 400; batch classifier loss: 0.875749; batch adversarial loss: 0.322327\n",
      "epoch 41; iter: 600; batch classifier loss: 0.523301; batch adversarial loss: 0.488081\n",
      "epoch 42; iter: 0; batch classifier loss: 0.392072; batch adversarial loss: 0.516133\n",
      "epoch 42; iter: 200; batch classifier loss: 0.403334; batch adversarial loss: 0.379655\n",
      "epoch 42; iter: 400; batch classifier loss: 0.731442; batch adversarial loss: 0.382512\n",
      "epoch 42; iter: 600; batch classifier loss: 0.734846; batch adversarial loss: 0.322121\n",
      "epoch 43; iter: 0; batch classifier loss: 0.498599; batch adversarial loss: 0.322091\n",
      "epoch 43; iter: 200; batch classifier loss: 0.617916; batch adversarial loss: 0.349963\n",
      "epoch 43; iter: 400; batch classifier loss: 0.686122; batch adversarial loss: 0.572120\n",
      "epoch 43; iter: 600; batch classifier loss: 0.499372; batch adversarial loss: 0.460834\n",
      "epoch 44; iter: 0; batch classifier loss: 0.677695; batch adversarial loss: 0.378067\n",
      "epoch 44; iter: 200; batch classifier loss: 0.569597; batch adversarial loss: 0.462034\n",
      "epoch 44; iter: 400; batch classifier loss: 0.598553; batch adversarial loss: 0.378414\n",
      "epoch 44; iter: 600; batch classifier loss: 0.495100; batch adversarial loss: 0.491150\n",
      "epoch 45; iter: 0; batch classifier loss: 0.307580; batch adversarial loss: 0.379391\n",
      "epoch 45; iter: 200; batch classifier loss: 0.636557; batch adversarial loss: 0.461348\n",
      "epoch 45; iter: 400; batch classifier loss: 0.389399; batch adversarial loss: 0.517774\n",
      "epoch 45; iter: 600; batch classifier loss: 0.486687; batch adversarial loss: 0.571836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.562621; batch adversarial loss: 0.488671\n",
      "epoch 46; iter: 200; batch classifier loss: 0.522506; batch adversarial loss: 0.350069\n",
      "epoch 46; iter: 400; batch classifier loss: 0.562756; batch adversarial loss: 0.378040\n",
      "epoch 46; iter: 600; batch classifier loss: 0.627219; batch adversarial loss: 0.573160\n",
      "epoch 47; iter: 0; batch classifier loss: 0.916440; batch adversarial loss: 0.433728\n",
      "epoch 47; iter: 200; batch classifier loss: 0.650633; batch adversarial loss: 0.295532\n",
      "epoch 47; iter: 400; batch classifier loss: 0.786654; batch adversarial loss: 0.544519\n",
      "epoch 47; iter: 600; batch classifier loss: 0.697444; batch adversarial loss: 0.378505\n",
      "epoch 48; iter: 0; batch classifier loss: 0.733862; batch adversarial loss: 0.406040\n",
      "epoch 48; iter: 200; batch classifier loss: 0.720050; batch adversarial loss: 0.434031\n",
      "epoch 48; iter: 400; batch classifier loss: 0.542352; batch adversarial loss: 0.350759\n",
      "epoch 48; iter: 600; batch classifier loss: 0.666245; batch adversarial loss: 0.544927\n",
      "epoch 49; iter: 0; batch classifier loss: 0.703267; batch adversarial loss: 0.434833\n",
      "epoch 49; iter: 200; batch classifier loss: 0.745539; batch adversarial loss: 0.322160\n",
      "epoch 49; iter: 400; batch classifier loss: 0.400268; batch adversarial loss: 0.461896\n",
      "epoch 49; iter: 600; batch classifier loss: 0.686743; batch adversarial loss: 0.379479\n",
      "epoch 0; iter: 0; batch classifier loss: 28.322119; batch adversarial loss: 0.915930\n",
      "epoch 0; iter: 200; batch classifier loss: 8.766626; batch adversarial loss: 0.849925\n",
      "epoch 0; iter: 400; batch classifier loss: 3.810182; batch adversarial loss: 0.650414\n",
      "epoch 0; iter: 600; batch classifier loss: 3.460626; batch adversarial loss: 0.555771\n",
      "epoch 1; iter: 0; batch classifier loss: 8.816778; batch adversarial loss: 0.560298\n",
      "epoch 1; iter: 200; batch classifier loss: 1.269988; batch adversarial loss: 0.544636\n",
      "epoch 1; iter: 400; batch classifier loss: 0.506096; batch adversarial loss: 0.512963\n",
      "epoch 1; iter: 600; batch classifier loss: 12.119243; batch adversarial loss: 0.468757\n",
      "epoch 2; iter: 0; batch classifier loss: 7.751721; batch adversarial loss: 0.369863\n",
      "epoch 2; iter: 200; batch classifier loss: 0.757410; batch adversarial loss: 0.460965\n",
      "epoch 2; iter: 400; batch classifier loss: 0.891326; batch adversarial loss: 0.487278\n",
      "epoch 2; iter: 600; batch classifier loss: 0.918277; batch adversarial loss: 0.393292\n",
      "epoch 3; iter: 0; batch classifier loss: 1.671981; batch adversarial loss: 0.389051\n",
      "epoch 3; iter: 200; batch classifier loss: 7.620226; batch adversarial loss: 0.439688\n",
      "epoch 3; iter: 400; batch classifier loss: 0.466365; batch adversarial loss: 0.454579\n",
      "epoch 3; iter: 600; batch classifier loss: 3.328217; batch adversarial loss: 0.493428\n",
      "epoch 4; iter: 0; batch classifier loss: 8.115701; batch adversarial loss: 0.472063\n",
      "epoch 4; iter: 200; batch classifier loss: 0.602794; batch adversarial loss: 0.281964\n",
      "epoch 4; iter: 400; batch classifier loss: 2.883646; batch adversarial loss: 0.407411\n",
      "epoch 4; iter: 600; batch classifier loss: 1.145211; batch adversarial loss: 0.436073\n",
      "epoch 5; iter: 0; batch classifier loss: 0.828919; batch adversarial loss: 0.446008\n",
      "epoch 5; iter: 200; batch classifier loss: 0.664585; batch adversarial loss: 0.428796\n",
      "epoch 5; iter: 400; batch classifier loss: 1.395048; batch adversarial loss: 0.389682\n",
      "epoch 5; iter: 600; batch classifier loss: 0.298634; batch adversarial loss: 0.367260\n",
      "epoch 6; iter: 0; batch classifier loss: 0.409972; batch adversarial loss: 0.487589\n",
      "epoch 6; iter: 200; batch classifier loss: 0.590557; batch adversarial loss: 0.357819\n",
      "epoch 6; iter: 400; batch classifier loss: 0.786768; batch adversarial loss: 0.545671\n",
      "epoch 6; iter: 600; batch classifier loss: 0.525507; batch adversarial loss: 0.432631\n",
      "epoch 7; iter: 0; batch classifier loss: 0.684019; batch adversarial loss: 0.328126\n",
      "epoch 7; iter: 200; batch classifier loss: 0.286705; batch adversarial loss: 0.405957\n",
      "epoch 7; iter: 400; batch classifier loss: 0.745275; batch adversarial loss: 0.414177\n",
      "epoch 7; iter: 600; batch classifier loss: 0.361606; batch adversarial loss: 0.398340\n",
      "epoch 8; iter: 0; batch classifier loss: 0.367116; batch adversarial loss: 0.469217\n",
      "epoch 8; iter: 200; batch classifier loss: 0.510092; batch adversarial loss: 0.316608\n",
      "epoch 8; iter: 400; batch classifier loss: 0.343624; batch adversarial loss: 0.369911\n",
      "epoch 8; iter: 600; batch classifier loss: 0.385070; batch adversarial loss: 0.419328\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465309; batch adversarial loss: 0.286375\n",
      "epoch 9; iter: 200; batch classifier loss: 0.303550; batch adversarial loss: 0.531628\n",
      "epoch 9; iter: 400; batch classifier loss: 0.296815; batch adversarial loss: 0.277145\n",
      "epoch 9; iter: 600; batch classifier loss: 0.442329; batch adversarial loss: 0.281653\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346134; batch adversarial loss: 0.534091\n",
      "epoch 10; iter: 200; batch classifier loss: 0.389407; batch adversarial loss: 0.510173\n",
      "epoch 10; iter: 400; batch classifier loss: 0.393105; batch adversarial loss: 0.391265\n",
      "epoch 10; iter: 600; batch classifier loss: 0.354019; batch adversarial loss: 0.404234\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346741; batch adversarial loss: 0.450483\n",
      "epoch 11; iter: 200; batch classifier loss: 0.348828; batch adversarial loss: 0.396000\n",
      "epoch 11; iter: 400; batch classifier loss: 0.367580; batch adversarial loss: 0.295463\n",
      "epoch 11; iter: 600; batch classifier loss: 0.424734; batch adversarial loss: 0.342191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329180; batch adversarial loss: 0.504498\n",
      "epoch 12; iter: 200; batch classifier loss: 0.314190; batch adversarial loss: 0.523671\n",
      "epoch 12; iter: 400; batch classifier loss: 0.288313; batch adversarial loss: 0.316397\n",
      "epoch 12; iter: 600; batch classifier loss: 0.338500; batch adversarial loss: 0.366017\n",
      "epoch 13; iter: 0; batch classifier loss: 0.362801; batch adversarial loss: 0.353766\n",
      "epoch 13; iter: 200; batch classifier loss: 0.344680; batch adversarial loss: 0.417421\n",
      "epoch 13; iter: 400; batch classifier loss: 0.279987; batch adversarial loss: 0.414209\n",
      "epoch 13; iter: 600; batch classifier loss: 0.504363; batch adversarial loss: 0.312176\n",
      "epoch 14; iter: 0; batch classifier loss: 0.222762; batch adversarial loss: 0.518654\n",
      "epoch 14; iter: 200; batch classifier loss: 0.258235; batch adversarial loss: 0.330363\n",
      "epoch 14; iter: 400; batch classifier loss: 0.305021; batch adversarial loss: 0.540756\n",
      "epoch 14; iter: 600; batch classifier loss: 0.364742; batch adversarial loss: 0.543544\n",
      "epoch 15; iter: 0; batch classifier loss: 0.270005; batch adversarial loss: 0.419737\n",
      "epoch 15; iter: 200; batch classifier loss: 0.343597; batch adversarial loss: 0.467803\n",
      "epoch 15; iter: 400; batch classifier loss: 0.374402; batch adversarial loss: 0.444605\n",
      "epoch 15; iter: 600; batch classifier loss: 0.422389; batch adversarial loss: 0.346446\n",
      "epoch 16; iter: 0; batch classifier loss: 0.353987; batch adversarial loss: 0.377552\n",
      "epoch 16; iter: 200; batch classifier loss: 0.387153; batch adversarial loss: 0.378547\n",
      "epoch 16; iter: 400; batch classifier loss: 0.267042; batch adversarial loss: 0.487322\n",
      "epoch 16; iter: 600; batch classifier loss: 0.419499; batch adversarial loss: 0.407864\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375926; batch adversarial loss: 0.388431\n",
      "epoch 17; iter: 200; batch classifier loss: 0.368877; batch adversarial loss: 0.295278\n",
      "epoch 17; iter: 400; batch classifier loss: 0.311709; batch adversarial loss: 0.302318\n",
      "epoch 17; iter: 600; batch classifier loss: 0.384653; batch adversarial loss: 0.474141\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301200; batch adversarial loss: 0.432786\n",
      "epoch 18; iter: 200; batch classifier loss: 0.270639; batch adversarial loss: 0.461630\n",
      "epoch 18; iter: 400; batch classifier loss: 0.457877; batch adversarial loss: 0.464944\n",
      "epoch 18; iter: 600; batch classifier loss: 0.355847; batch adversarial loss: 0.402163\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408936; batch adversarial loss: 0.322742\n",
      "epoch 19; iter: 200; batch classifier loss: 0.354625; batch adversarial loss: 0.395783\n",
      "epoch 19; iter: 400; batch classifier loss: 0.529034; batch adversarial loss: 0.434224\n",
      "epoch 19; iter: 600; batch classifier loss: 0.441301; batch adversarial loss: 0.267923\n",
      "epoch 20; iter: 0; batch classifier loss: 0.484467; batch adversarial loss: 0.381963\n",
      "epoch 20; iter: 200; batch classifier loss: 0.339853; batch adversarial loss: 0.349976\n",
      "epoch 20; iter: 400; batch classifier loss: 0.381049; batch adversarial loss: 0.518406\n",
      "epoch 20; iter: 600; batch classifier loss: 0.462273; batch adversarial loss: 0.344379\n",
      "epoch 21; iter: 0; batch classifier loss: 0.399024; batch adversarial loss: 0.340687\n",
      "epoch 21; iter: 200; batch classifier loss: 0.335863; batch adversarial loss: 0.456511\n",
      "epoch 21; iter: 400; batch classifier loss: 0.469889; batch adversarial loss: 0.372513\n",
      "epoch 21; iter: 600; batch classifier loss: 0.476058; batch adversarial loss: 0.304094\n",
      "epoch 22; iter: 0; batch classifier loss: 0.400135; batch adversarial loss: 0.480261\n",
      "epoch 22; iter: 200; batch classifier loss: 0.466667; batch adversarial loss: 0.448235\n",
      "epoch 22; iter: 400; batch classifier loss: 0.464631; batch adversarial loss: 0.459640\n",
      "epoch 22; iter: 600; batch classifier loss: 0.429988; batch adversarial loss: 0.402918\n",
      "epoch 23; iter: 0; batch classifier loss: 0.441102; batch adversarial loss: 0.433707\n",
      "epoch 23; iter: 200; batch classifier loss: 0.390409; batch adversarial loss: 0.427103\n",
      "epoch 23; iter: 400; batch classifier loss: 0.451256; batch adversarial loss: 0.380039\n",
      "epoch 23; iter: 600; batch classifier loss: 0.313069; batch adversarial loss: 0.556850\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387096; batch adversarial loss: 0.460016\n",
      "epoch 24; iter: 200; batch classifier loss: 0.469961; batch adversarial loss: 0.585453\n",
      "epoch 24; iter: 400; batch classifier loss: 0.444774; batch adversarial loss: 0.352331\n",
      "epoch 24; iter: 600; batch classifier loss: 0.493293; batch adversarial loss: 0.381808\n",
      "epoch 25; iter: 0; batch classifier loss: 0.430915; batch adversarial loss: 0.327557\n",
      "epoch 25; iter: 200; batch classifier loss: 0.694790; batch adversarial loss: 0.288955\n",
      "epoch 25; iter: 400; batch classifier loss: 0.336448; batch adversarial loss: 0.456467\n",
      "epoch 25; iter: 600; batch classifier loss: 0.481578; batch adversarial loss: 0.518152\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532963; batch adversarial loss: 0.522349\n",
      "epoch 26; iter: 200; batch classifier loss: 0.398375; batch adversarial loss: 0.424486\n",
      "epoch 26; iter: 400; batch classifier loss: 0.475432; batch adversarial loss: 0.394879\n",
      "epoch 26; iter: 600; batch classifier loss: 0.410334; batch adversarial loss: 0.481321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.397952; batch adversarial loss: 0.458359\n",
      "epoch 27; iter: 200; batch classifier loss: 0.417930; batch adversarial loss: 0.328541\n",
      "epoch 27; iter: 400; batch classifier loss: 0.346684; batch adversarial loss: 0.380276\n",
      "epoch 27; iter: 600; batch classifier loss: 0.500540; batch adversarial loss: 0.267497\n",
      "epoch 28; iter: 0; batch classifier loss: 0.427942; batch adversarial loss: 0.397929\n",
      "epoch 28; iter: 200; batch classifier loss: 0.449611; batch adversarial loss: 0.349076\n",
      "epoch 28; iter: 400; batch classifier loss: 0.327694; batch adversarial loss: 0.269628\n",
      "epoch 28; iter: 600; batch classifier loss: 0.516124; batch adversarial loss: 0.371660\n",
      "epoch 29; iter: 0; batch classifier loss: 0.508839; batch adversarial loss: 0.368930\n",
      "epoch 29; iter: 200; batch classifier loss: 0.461340; batch adversarial loss: 0.281544\n",
      "epoch 29; iter: 400; batch classifier loss: 0.449161; batch adversarial loss: 0.323617\n",
      "epoch 29; iter: 600; batch classifier loss: 0.453157; batch adversarial loss: 0.408818\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489059; batch adversarial loss: 0.491053\n",
      "epoch 30; iter: 200; batch classifier loss: 0.451003; batch adversarial loss: 0.358480\n",
      "epoch 30; iter: 400; batch classifier loss: 0.366364; batch adversarial loss: 0.452870\n",
      "epoch 30; iter: 600; batch classifier loss: 0.449536; batch adversarial loss: 0.375058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464593; batch adversarial loss: 0.480467\n",
      "epoch 31; iter: 200; batch classifier loss: 0.377839; batch adversarial loss: 0.384046\n",
      "epoch 31; iter: 400; batch classifier loss: 0.370402; batch adversarial loss: 0.505429\n",
      "epoch 31; iter: 600; batch classifier loss: 0.405585; batch adversarial loss: 0.387451\n",
      "epoch 32; iter: 0; batch classifier loss: 0.624801; batch adversarial loss: 0.429312\n",
      "epoch 32; iter: 200; batch classifier loss: 0.474259; batch adversarial loss: 0.436412\n",
      "epoch 32; iter: 400; batch classifier loss: 0.516737; batch adversarial loss: 0.562703\n",
      "epoch 32; iter: 600; batch classifier loss: 0.549011; batch adversarial loss: 0.429695\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473448; batch adversarial loss: 0.507710\n",
      "epoch 33; iter: 200; batch classifier loss: 0.451542; batch adversarial loss: 0.505391\n",
      "epoch 33; iter: 400; batch classifier loss: 0.444731; batch adversarial loss: 0.348829\n",
      "epoch 33; iter: 600; batch classifier loss: 0.456488; batch adversarial loss: 0.325490\n",
      "epoch 34; iter: 0; batch classifier loss: 0.679826; batch adversarial loss: 0.290772\n",
      "epoch 34; iter: 200; batch classifier loss: 0.348438; batch adversarial loss: 0.382055\n",
      "epoch 34; iter: 400; batch classifier loss: 0.660493; batch adversarial loss: 0.347883\n",
      "epoch 34; iter: 600; batch classifier loss: 0.773689; batch adversarial loss: 0.368032\n",
      "epoch 35; iter: 0; batch classifier loss: 0.283900; batch adversarial loss: 0.409960\n",
      "epoch 35; iter: 200; batch classifier loss: 0.288315; batch adversarial loss: 0.346426\n",
      "epoch 35; iter: 400; batch classifier loss: 0.480450; batch adversarial loss: 0.384412\n",
      "epoch 35; iter: 600; batch classifier loss: 0.718576; batch adversarial loss: 0.456457\n",
      "epoch 36; iter: 0; batch classifier loss: 0.485471; batch adversarial loss: 0.428588\n",
      "epoch 36; iter: 200; batch classifier loss: 0.634870; batch adversarial loss: 0.602807\n",
      "epoch 36; iter: 400; batch classifier loss: 0.640314; batch adversarial loss: 0.382470\n",
      "epoch 36; iter: 600; batch classifier loss: 0.558584; batch adversarial loss: 0.259339\n",
      "epoch 37; iter: 0; batch classifier loss: 0.694836; batch adversarial loss: 0.373457\n",
      "epoch 37; iter: 200; batch classifier loss: 0.380987; batch adversarial loss: 0.315000\n",
      "epoch 37; iter: 400; batch classifier loss: 0.618475; batch adversarial loss: 0.347853\n",
      "epoch 37; iter: 600; batch classifier loss: 0.695157; batch adversarial loss: 0.458786\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441613; batch adversarial loss: 0.416615\n",
      "epoch 38; iter: 200; batch classifier loss: 0.421760; batch adversarial loss: 0.401315\n",
      "epoch 38; iter: 400; batch classifier loss: 0.424553; batch adversarial loss: 0.372502\n",
      "epoch 38; iter: 600; batch classifier loss: 0.395173; batch adversarial loss: 0.378411\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483974; batch adversarial loss: 0.459564\n",
      "epoch 39; iter: 200; batch classifier loss: 0.671112; batch adversarial loss: 0.401466\n",
      "epoch 39; iter: 400; batch classifier loss: 0.341957; batch adversarial loss: 0.407813\n",
      "epoch 39; iter: 600; batch classifier loss: 0.451896; batch adversarial loss: 0.295154\n",
      "epoch 40; iter: 0; batch classifier loss: 0.565957; batch adversarial loss: 0.466125\n",
      "epoch 40; iter: 200; batch classifier loss: 0.396160; batch adversarial loss: 0.294003\n",
      "epoch 40; iter: 400; batch classifier loss: 0.680949; batch adversarial loss: 0.430926\n",
      "epoch 40; iter: 600; batch classifier loss: 0.447346; batch adversarial loss: 0.399352\n",
      "epoch 41; iter: 0; batch classifier loss: 0.360702; batch adversarial loss: 0.461910\n",
      "epoch 41; iter: 200; batch classifier loss: 0.506480; batch adversarial loss: 0.356331\n",
      "epoch 41; iter: 400; batch classifier loss: 0.684218; batch adversarial loss: 0.359653\n",
      "epoch 41; iter: 600; batch classifier loss: 0.655554; batch adversarial loss: 0.332879\n",
      "epoch 42; iter: 0; batch classifier loss: 0.677850; batch adversarial loss: 0.386398\n",
      "epoch 42; iter: 200; batch classifier loss: 0.566635; batch adversarial loss: 0.350692\n",
      "epoch 42; iter: 400; batch classifier loss: 0.432719; batch adversarial loss: 0.459888\n",
      "epoch 42; iter: 600; batch classifier loss: 0.645310; batch adversarial loss: 0.389379\n",
      "epoch 43; iter: 0; batch classifier loss: 0.844968; batch adversarial loss: 0.318585\n",
      "epoch 43; iter: 200; batch classifier loss: 0.466077; batch adversarial loss: 0.493468\n",
      "epoch 43; iter: 400; batch classifier loss: 0.529158; batch adversarial loss: 0.320836\n",
      "epoch 43; iter: 600; batch classifier loss: 0.408157; batch adversarial loss: 0.463873\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470089; batch adversarial loss: 0.569968\n",
      "epoch 44; iter: 200; batch classifier loss: 0.625267; batch adversarial loss: 0.507430\n",
      "epoch 44; iter: 400; batch classifier loss: 0.401961; batch adversarial loss: 0.344388\n",
      "epoch 44; iter: 600; batch classifier loss: 0.592522; batch adversarial loss: 0.350835\n",
      "epoch 45; iter: 0; batch classifier loss: 0.370563; batch adversarial loss: 0.599476\n",
      "epoch 45; iter: 200; batch classifier loss: 0.379518; batch adversarial loss: 0.299953\n",
      "epoch 45; iter: 400; batch classifier loss: 0.588987; batch adversarial loss: 0.379350\n",
      "epoch 45; iter: 600; batch classifier loss: 0.479801; batch adversarial loss: 0.325494\n",
      "epoch 46; iter: 0; batch classifier loss: 0.492830; batch adversarial loss: 0.434528\n",
      "epoch 46; iter: 200; batch classifier loss: 0.393040; batch adversarial loss: 0.349732\n",
      "epoch 46; iter: 400; batch classifier loss: 0.516642; batch adversarial loss: 0.455329\n",
      "epoch 46; iter: 600; batch classifier loss: 0.537066; batch adversarial loss: 0.460693\n",
      "epoch 47; iter: 0; batch classifier loss: 0.365424; batch adversarial loss: 0.488213\n",
      "epoch 47; iter: 200; batch classifier loss: 0.467695; batch adversarial loss: 0.512609\n",
      "epoch 47; iter: 400; batch classifier loss: 0.598694; batch adversarial loss: 0.356100\n",
      "epoch 47; iter: 600; batch classifier loss: 0.429961; batch adversarial loss: 0.433538\n",
      "epoch 48; iter: 0; batch classifier loss: 0.616946; batch adversarial loss: 0.432686\n",
      "epoch 48; iter: 200; batch classifier loss: 0.423979; batch adversarial loss: 0.216013\n",
      "epoch 48; iter: 400; batch classifier loss: 0.616994; batch adversarial loss: 0.571182\n",
      "epoch 48; iter: 600; batch classifier loss: 0.498554; batch adversarial loss: 0.484342\n",
      "epoch 49; iter: 0; batch classifier loss: 0.705170; batch adversarial loss: 0.484481\n",
      "epoch 49; iter: 200; batch classifier loss: 0.533108; batch adversarial loss: 0.399825\n",
      "epoch 49; iter: 400; batch classifier loss: 0.808611; batch adversarial loss: 0.479372\n",
      "epoch 49; iter: 600; batch classifier loss: 0.440077; batch adversarial loss: 0.345739\n",
      "epoch 0; iter: 0; batch classifier loss: 42.772488; batch adversarial loss: 0.897150\n",
      "epoch 0; iter: 200; batch classifier loss: 13.424028; batch adversarial loss: 0.875105\n",
      "epoch 0; iter: 400; batch classifier loss: 11.529007; batch adversarial loss: 0.672314\n",
      "epoch 0; iter: 600; batch classifier loss: 11.448997; batch adversarial loss: 0.577059\n",
      "epoch 1; iter: 0; batch classifier loss: 4.823367; batch adversarial loss: 0.558570\n",
      "epoch 1; iter: 200; batch classifier loss: 2.939929; batch adversarial loss: 0.528402\n",
      "epoch 1; iter: 400; batch classifier loss: 0.484544; batch adversarial loss: 0.534421\n",
      "epoch 1; iter: 600; batch classifier loss: 4.061262; batch adversarial loss: 0.414612\n",
      "epoch 2; iter: 0; batch classifier loss: 26.701183; batch adversarial loss: 0.489682\n",
      "epoch 2; iter: 200; batch classifier loss: 7.232296; batch adversarial loss: 0.418424\n",
      "epoch 2; iter: 400; batch classifier loss: 0.763146; batch adversarial loss: 0.413317\n",
      "epoch 2; iter: 600; batch classifier loss: 3.099344; batch adversarial loss: 0.419269\n",
      "epoch 3; iter: 0; batch classifier loss: 1.303145; batch adversarial loss: 0.426233\n",
      "epoch 3; iter: 200; batch classifier loss: 1.903706; batch adversarial loss: 0.473354\n",
      "epoch 3; iter: 400; batch classifier loss: 1.193147; batch adversarial loss: 0.350155\n",
      "epoch 3; iter: 600; batch classifier loss: 0.610734; batch adversarial loss: 0.322001\n",
      "epoch 4; iter: 0; batch classifier loss: 2.834093; batch adversarial loss: 0.428658\n",
      "epoch 4; iter: 200; batch classifier loss: 0.544951; batch adversarial loss: 0.391403\n",
      "epoch 4; iter: 400; batch classifier loss: 2.316234; batch adversarial loss: 0.475574\n",
      "epoch 4; iter: 600; batch classifier loss: 1.286824; batch adversarial loss: 0.422408\n",
      "epoch 5; iter: 0; batch classifier loss: 0.709226; batch adversarial loss: 0.316033\n",
      "epoch 5; iter: 200; batch classifier loss: 1.025822; batch adversarial loss: 0.308648\n",
      "epoch 5; iter: 400; batch classifier loss: 0.466721; batch adversarial loss: 0.374604\n",
      "epoch 5; iter: 600; batch classifier loss: 0.526550; batch adversarial loss: 0.381374\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579804; batch adversarial loss: 0.428727\n",
      "epoch 6; iter: 200; batch classifier loss: 0.482551; batch adversarial loss: 0.525030\n",
      "epoch 6; iter: 400; batch classifier loss: 0.540773; batch adversarial loss: 0.464724\n",
      "epoch 6; iter: 600; batch classifier loss: 0.447114; batch adversarial loss: 0.383674\n",
      "epoch 7; iter: 0; batch classifier loss: 0.365136; batch adversarial loss: 0.404494\n",
      "epoch 7; iter: 200; batch classifier loss: 0.357217; batch adversarial loss: 0.332021\n",
      "epoch 7; iter: 400; batch classifier loss: 0.581411; batch adversarial loss: 0.327181\n",
      "epoch 7; iter: 600; batch classifier loss: 0.392871; batch adversarial loss: 0.320237\n",
      "epoch 8; iter: 0; batch classifier loss: 0.445225; batch adversarial loss: 0.324293\n",
      "epoch 8; iter: 200; batch classifier loss: 0.342017; batch adversarial loss: 0.399745\n",
      "epoch 8; iter: 400; batch classifier loss: 0.408183; batch adversarial loss: 0.453573\n",
      "epoch 8; iter: 600; batch classifier loss: 0.263312; batch adversarial loss: 0.422231\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386632; batch adversarial loss: 0.508211\n",
      "epoch 9; iter: 200; batch classifier loss: 0.381122; batch adversarial loss: 0.349416\n",
      "epoch 9; iter: 400; batch classifier loss: 0.321197; batch adversarial loss: 0.419645\n",
      "epoch 9; iter: 600; batch classifier loss: 0.349382; batch adversarial loss: 0.519062\n",
      "epoch 10; iter: 0; batch classifier loss: 0.279133; batch adversarial loss: 0.476423\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420283; batch adversarial loss: 0.344763\n",
      "epoch 10; iter: 400; batch classifier loss: 0.366518; batch adversarial loss: 0.461182\n",
      "epoch 10; iter: 600; batch classifier loss: 0.338186; batch adversarial loss: 0.346038\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430720; batch adversarial loss: 0.512909\n",
      "epoch 11; iter: 200; batch classifier loss: 0.328122; batch adversarial loss: 0.442526\n",
      "epoch 11; iter: 400; batch classifier loss: 0.432721; batch adversarial loss: 0.351103\n",
      "epoch 11; iter: 600; batch classifier loss: 0.508145; batch adversarial loss: 0.427653\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398478; batch adversarial loss: 0.514343\n",
      "epoch 12; iter: 200; batch classifier loss: 0.342177; batch adversarial loss: 0.367831\n",
      "epoch 12; iter: 400; batch classifier loss: 0.269657; batch adversarial loss: 0.343415\n",
      "epoch 12; iter: 600; batch classifier loss: 0.319722; batch adversarial loss: 0.368232\n",
      "epoch 13; iter: 0; batch classifier loss: 0.386324; batch adversarial loss: 0.510933\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353007; batch adversarial loss: 0.453528\n",
      "epoch 13; iter: 400; batch classifier loss: 0.379509; batch adversarial loss: 0.513531\n",
      "epoch 13; iter: 600; batch classifier loss: 0.424771; batch adversarial loss: 0.349523\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470389; batch adversarial loss: 0.398935\n",
      "epoch 14; iter: 200; batch classifier loss: 0.434228; batch adversarial loss: 0.443868\n",
      "epoch 14; iter: 400; batch classifier loss: 0.304608; batch adversarial loss: 0.337072\n",
      "epoch 14; iter: 600; batch classifier loss: 0.351093; batch adversarial loss: 0.323172\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409749; batch adversarial loss: 0.374311\n",
      "epoch 15; iter: 200; batch classifier loss: 0.336027; batch adversarial loss: 0.399364\n",
      "epoch 15; iter: 400; batch classifier loss: 0.261561; batch adversarial loss: 0.419071\n",
      "epoch 15; iter: 600; batch classifier loss: 0.389524; batch adversarial loss: 0.342074\n",
      "epoch 16; iter: 0; batch classifier loss: 0.202450; batch adversarial loss: 0.422295\n",
      "epoch 16; iter: 200; batch classifier loss: 0.303033; batch adversarial loss: 0.376803\n",
      "epoch 16; iter: 400; batch classifier loss: 0.448137; batch adversarial loss: 0.507408\n",
      "epoch 16; iter: 600; batch classifier loss: 0.268077; batch adversarial loss: 0.431367\n",
      "epoch 17; iter: 0; batch classifier loss: 0.381707; batch adversarial loss: 0.374104\n",
      "epoch 17; iter: 200; batch classifier loss: 0.404352; batch adversarial loss: 0.486825\n",
      "epoch 17; iter: 400; batch classifier loss: 0.275171; batch adversarial loss: 0.312278\n",
      "epoch 17; iter: 600; batch classifier loss: 0.429744; batch adversarial loss: 0.411757\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333653; batch adversarial loss: 0.426517\n",
      "epoch 18; iter: 200; batch classifier loss: 0.329867; batch adversarial loss: 0.374747\n",
      "epoch 18; iter: 400; batch classifier loss: 0.482698; batch adversarial loss: 0.509101\n",
      "epoch 18; iter: 600; batch classifier loss: 0.365033; batch adversarial loss: 0.352573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.390807; batch adversarial loss: 0.424333\n",
      "epoch 19; iter: 200; batch classifier loss: 0.401510; batch adversarial loss: 0.354211\n",
      "epoch 19; iter: 400; batch classifier loss: 0.304270; batch adversarial loss: 0.557266\n",
      "epoch 19; iter: 600; batch classifier loss: 0.439135; batch adversarial loss: 0.269195\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294446; batch adversarial loss: 0.484617\n",
      "epoch 20; iter: 200; batch classifier loss: 0.254681; batch adversarial loss: 0.361305\n",
      "epoch 20; iter: 400; batch classifier loss: 0.274943; batch adversarial loss: 0.401183\n",
      "epoch 20; iter: 600; batch classifier loss: 0.637234; batch adversarial loss: 0.428566\n",
      "epoch 21; iter: 0; batch classifier loss: 0.390701; batch adversarial loss: 0.429503\n",
      "epoch 21; iter: 200; batch classifier loss: 0.387501; batch adversarial loss: 0.436864\n",
      "epoch 21; iter: 400; batch classifier loss: 0.366033; batch adversarial loss: 0.493345\n",
      "epoch 21; iter: 600; batch classifier loss: 0.369358; batch adversarial loss: 0.464147\n",
      "epoch 22; iter: 0; batch classifier loss: 0.368863; batch adversarial loss: 0.407553\n",
      "epoch 22; iter: 200; batch classifier loss: 0.375327; batch adversarial loss: 0.377303\n",
      "epoch 22; iter: 400; batch classifier loss: 0.444325; batch adversarial loss: 0.432979\n",
      "epoch 22; iter: 600; batch classifier loss: 0.238749; batch adversarial loss: 0.438164\n",
      "epoch 23; iter: 0; batch classifier loss: 0.394000; batch adversarial loss: 0.441793\n",
      "epoch 23; iter: 200; batch classifier loss: 0.351624; batch adversarial loss: 0.374757\n",
      "epoch 23; iter: 400; batch classifier loss: 0.373505; batch adversarial loss: 0.399323\n",
      "epoch 23; iter: 600; batch classifier loss: 0.326998; batch adversarial loss: 0.293711\n",
      "epoch 24; iter: 0; batch classifier loss: 0.383901; batch adversarial loss: 0.353831\n",
      "epoch 24; iter: 200; batch classifier loss: 0.318730; batch adversarial loss: 0.459212\n",
      "epoch 24; iter: 400; batch classifier loss: 0.399274; batch adversarial loss: 0.492349\n",
      "epoch 24; iter: 600; batch classifier loss: 0.557312; batch adversarial loss: 0.397385\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396402; batch adversarial loss: 0.458639\n",
      "epoch 25; iter: 200; batch classifier loss: 0.410962; batch adversarial loss: 0.461716\n",
      "epoch 25; iter: 400; batch classifier loss: 0.361956; batch adversarial loss: 0.452295\n",
      "epoch 25; iter: 600; batch classifier loss: 0.412094; batch adversarial loss: 0.378677\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387861; batch adversarial loss: 0.421155\n",
      "epoch 26; iter: 200; batch classifier loss: 0.320095; batch adversarial loss: 0.372674\n",
      "epoch 26; iter: 400; batch classifier loss: 0.389575; batch adversarial loss: 0.265517\n",
      "epoch 26; iter: 600; batch classifier loss: 0.308403; batch adversarial loss: 0.319512\n",
      "epoch 27; iter: 0; batch classifier loss: 0.344838; batch adversarial loss: 0.400614\n",
      "epoch 27; iter: 200; batch classifier loss: 0.452359; batch adversarial loss: 0.466117\n",
      "epoch 27; iter: 400; batch classifier loss: 0.426475; batch adversarial loss: 0.377015\n",
      "epoch 27; iter: 600; batch classifier loss: 0.541295; batch adversarial loss: 0.411337\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351609; batch adversarial loss: 0.485515\n",
      "epoch 28; iter: 200; batch classifier loss: 0.544943; batch adversarial loss: 0.539794\n",
      "epoch 28; iter: 400; batch classifier loss: 0.368367; batch adversarial loss: 0.342933\n",
      "epoch 28; iter: 600; batch classifier loss: 0.439878; batch adversarial loss: 0.431284\n",
      "epoch 29; iter: 0; batch classifier loss: 0.391483; batch adversarial loss: 0.385074\n",
      "epoch 29; iter: 200; batch classifier loss: 0.499987; batch adversarial loss: 0.344488\n",
      "epoch 29; iter: 400; batch classifier loss: 0.563452; batch adversarial loss: 0.516795\n",
      "epoch 29; iter: 600; batch classifier loss: 0.579787; batch adversarial loss: 0.405541\n",
      "epoch 30; iter: 0; batch classifier loss: 0.429565; batch adversarial loss: 0.351156\n",
      "epoch 30; iter: 200; batch classifier loss: 0.386309; batch adversarial loss: 0.459923\n",
      "epoch 30; iter: 400; batch classifier loss: 0.403683; batch adversarial loss: 0.409106\n",
      "epoch 30; iter: 600; batch classifier loss: 0.310585; batch adversarial loss: 0.542373\n",
      "epoch 31; iter: 0; batch classifier loss: 0.520327; batch adversarial loss: 0.299576\n",
      "epoch 31; iter: 200; batch classifier loss: 0.363429; batch adversarial loss: 0.294915\n",
      "epoch 31; iter: 400; batch classifier loss: 0.312944; batch adversarial loss: 0.377460\n",
      "epoch 31; iter: 600; batch classifier loss: 0.408637; batch adversarial loss: 0.363738\n",
      "epoch 32; iter: 0; batch classifier loss: 0.488090; batch adversarial loss: 0.268255\n",
      "epoch 32; iter: 200; batch classifier loss: 0.556797; batch adversarial loss: 0.410135\n",
      "epoch 32; iter: 400; batch classifier loss: 0.338671; batch adversarial loss: 0.266363\n",
      "epoch 32; iter: 600; batch classifier loss: 0.386048; batch adversarial loss: 0.506626\n",
      "epoch 33; iter: 0; batch classifier loss: 0.570717; batch adversarial loss: 0.454565\n",
      "epoch 33; iter: 200; batch classifier loss: 0.296131; batch adversarial loss: 0.419625\n",
      "epoch 33; iter: 400; batch classifier loss: 0.506504; batch adversarial loss: 0.515381\n",
      "epoch 33; iter: 600; batch classifier loss: 0.383780; batch adversarial loss: 0.488787\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480708; batch adversarial loss: 0.266743\n",
      "epoch 34; iter: 200; batch classifier loss: 0.669397; batch adversarial loss: 0.454370\n",
      "epoch 34; iter: 400; batch classifier loss: 0.501806; batch adversarial loss: 0.506458\n",
      "epoch 34; iter: 600; batch classifier loss: 0.308483; batch adversarial loss: 0.407206\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478322; batch adversarial loss: 0.376932\n",
      "epoch 35; iter: 200; batch classifier loss: 0.538245; batch adversarial loss: 0.320507\n",
      "epoch 35; iter: 400; batch classifier loss: 0.513194; batch adversarial loss: 0.375178\n",
      "epoch 35; iter: 600; batch classifier loss: 0.628842; batch adversarial loss: 0.266232\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467819; batch adversarial loss: 0.346932\n",
      "epoch 36; iter: 200; batch classifier loss: 0.316439; batch adversarial loss: 0.318719\n",
      "epoch 36; iter: 400; batch classifier loss: 0.482138; batch adversarial loss: 0.432405\n",
      "epoch 36; iter: 600; batch classifier loss: 0.434910; batch adversarial loss: 0.463422\n",
      "epoch 37; iter: 0; batch classifier loss: 0.505856; batch adversarial loss: 0.319750\n",
      "epoch 37; iter: 200; batch classifier loss: 0.547351; batch adversarial loss: 0.428866\n",
      "epoch 37; iter: 400; batch classifier loss: 0.702184; batch adversarial loss: 0.382108\n",
      "epoch 37; iter: 600; batch classifier loss: 0.383779; batch adversarial loss: 0.459404\n",
      "epoch 38; iter: 0; batch classifier loss: 0.550614; batch adversarial loss: 0.346821\n",
      "epoch 38; iter: 200; batch classifier loss: 0.542016; batch adversarial loss: 0.597836\n",
      "epoch 38; iter: 400; batch classifier loss: 0.552915; batch adversarial loss: 0.266657\n",
      "epoch 38; iter: 600; batch classifier loss: 0.626968; batch adversarial loss: 0.488501\n",
      "epoch 39; iter: 0; batch classifier loss: 0.466283; batch adversarial loss: 0.408799\n",
      "epoch 39; iter: 200; batch classifier loss: 0.564391; batch adversarial loss: 0.319380\n",
      "epoch 39; iter: 400; batch classifier loss: 0.338708; batch adversarial loss: 0.377444\n",
      "epoch 39; iter: 600; batch classifier loss: 0.517905; batch adversarial loss: 0.373041\n",
      "epoch 40; iter: 0; batch classifier loss: 0.769518; batch adversarial loss: 0.440682\n",
      "epoch 40; iter: 200; batch classifier loss: 0.535328; batch adversarial loss: 0.463149\n",
      "epoch 40; iter: 400; batch classifier loss: 0.457230; batch adversarial loss: 0.238986\n",
      "epoch 40; iter: 600; batch classifier loss: 0.356936; batch adversarial loss: 0.444698\n",
      "epoch 41; iter: 0; batch classifier loss: 0.640489; batch adversarial loss: 0.374994\n",
      "epoch 41; iter: 200; batch classifier loss: 0.706015; batch adversarial loss: 0.435107\n",
      "epoch 41; iter: 400; batch classifier loss: 0.594070; batch adversarial loss: 0.506269\n",
      "epoch 41; iter: 600; batch classifier loss: 0.401544; batch adversarial loss: 0.376696\n",
      "epoch 42; iter: 0; batch classifier loss: 0.661762; batch adversarial loss: 0.372452\n",
      "epoch 42; iter: 200; batch classifier loss: 0.389274; batch adversarial loss: 0.405897\n",
      "epoch 42; iter: 400; batch classifier loss: 0.516017; batch adversarial loss: 0.438672\n",
      "epoch 42; iter: 600; batch classifier loss: 0.648113; batch adversarial loss: 0.468355\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478469; batch adversarial loss: 0.402554\n",
      "epoch 43; iter: 200; batch classifier loss: 0.504252; batch adversarial loss: 0.439607\n",
      "epoch 43; iter: 400; batch classifier loss: 0.498044; batch adversarial loss: 0.488097\n",
      "epoch 43; iter: 600; batch classifier loss: 0.599005; batch adversarial loss: 0.379584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.629990; batch adversarial loss: 0.322499\n",
      "epoch 44; iter: 200; batch classifier loss: 0.505756; batch adversarial loss: 0.460898\n",
      "epoch 44; iter: 400; batch classifier loss: 0.636607; batch adversarial loss: 0.436675\n",
      "epoch 44; iter: 600; batch classifier loss: 0.393643; batch adversarial loss: 0.354291\n",
      "epoch 45; iter: 0; batch classifier loss: 0.591307; batch adversarial loss: 0.414849\n",
      "epoch 45; iter: 200; batch classifier loss: 0.529145; batch adversarial loss: 0.431957\n",
      "epoch 45; iter: 400; batch classifier loss: 0.629710; batch adversarial loss: 0.435050\n",
      "epoch 45; iter: 600; batch classifier loss: 0.831110; batch adversarial loss: 0.489252\n",
      "epoch 46; iter: 0; batch classifier loss: 0.583879; batch adversarial loss: 0.463110\n",
      "epoch 46; iter: 200; batch classifier loss: 0.649801; batch adversarial loss: 0.430415\n",
      "epoch 46; iter: 400; batch classifier loss: 0.421424; batch adversarial loss: 0.623067\n",
      "epoch 46; iter: 600; batch classifier loss: 0.431176; batch adversarial loss: 0.353721\n",
      "epoch 47; iter: 0; batch classifier loss: 0.752998; batch adversarial loss: 0.320802\n",
      "epoch 47; iter: 200; batch classifier loss: 0.797489; batch adversarial loss: 0.375847\n",
      "epoch 47; iter: 400; batch classifier loss: 0.318857; batch adversarial loss: 0.299158\n",
      "epoch 47; iter: 600; batch classifier loss: 0.298396; batch adversarial loss: 0.465541\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468461; batch adversarial loss: 0.319761\n",
      "epoch 48; iter: 200; batch classifier loss: 0.691287; batch adversarial loss: 0.402221\n",
      "epoch 48; iter: 400; batch classifier loss: 0.494241; batch adversarial loss: 0.356129\n",
      "epoch 48; iter: 600; batch classifier loss: 0.770331; batch adversarial loss: 0.458192\n",
      "epoch 49; iter: 0; batch classifier loss: 0.669037; batch adversarial loss: 0.353982\n",
      "epoch 49; iter: 200; batch classifier loss: 0.575001; batch adversarial loss: 0.492894\n",
      "epoch 49; iter: 400; batch classifier loss: 0.842440; batch adversarial loss: 0.512919\n",
      "epoch 49; iter: 600; batch classifier loss: 0.804813; batch adversarial loss: 0.430625\n",
      "epoch 0; iter: 0; batch classifier loss: 11.476760; batch adversarial loss: 1.085753\n",
      "epoch 0; iter: 200; batch classifier loss: 15.845140; batch adversarial loss: 1.028788\n",
      "epoch 0; iter: 400; batch classifier loss: 2.042552; batch adversarial loss: 0.823992\n",
      "epoch 0; iter: 600; batch classifier loss: 3.883463; batch adversarial loss: 0.626945\n",
      "epoch 1; iter: 0; batch classifier loss: 4.142289; batch adversarial loss: 0.660053\n",
      "epoch 1; iter: 200; batch classifier loss: 6.166230; batch adversarial loss: 0.577179\n",
      "epoch 1; iter: 400; batch classifier loss: 1.459950; batch adversarial loss: 0.458395\n",
      "epoch 1; iter: 600; batch classifier loss: 8.842403; batch adversarial loss: 0.503749\n",
      "epoch 2; iter: 0; batch classifier loss: 3.879374; batch adversarial loss: 0.527800\n",
      "epoch 2; iter: 200; batch classifier loss: 2.171761; batch adversarial loss: 0.472108\n",
      "epoch 2; iter: 400; batch classifier loss: 2.998399; batch adversarial loss: 0.374597\n",
      "epoch 2; iter: 600; batch classifier loss: 0.750765; batch adversarial loss: 0.492483\n",
      "epoch 3; iter: 0; batch classifier loss: 1.023684; batch adversarial loss: 0.549431\n",
      "epoch 3; iter: 200; batch classifier loss: 1.081121; batch adversarial loss: 0.537606\n",
      "epoch 3; iter: 400; batch classifier loss: 0.928997; batch adversarial loss: 0.481922\n",
      "epoch 3; iter: 600; batch classifier loss: 0.585304; batch adversarial loss: 0.330851\n",
      "epoch 4; iter: 0; batch classifier loss: 1.437370; batch adversarial loss: 0.462183\n",
      "epoch 4; iter: 200; batch classifier loss: 1.706661; batch adversarial loss: 0.409734\n",
      "epoch 4; iter: 400; batch classifier loss: 0.779488; batch adversarial loss: 0.406958\n",
      "epoch 4; iter: 600; batch classifier loss: 0.533385; batch adversarial loss: 0.429016\n",
      "epoch 5; iter: 0; batch classifier loss: 0.717872; batch adversarial loss: 0.338232\n",
      "epoch 5; iter: 200; batch classifier loss: 0.660710; batch adversarial loss: 0.395305\n",
      "epoch 5; iter: 400; batch classifier loss: 0.528288; batch adversarial loss: 0.430582\n",
      "epoch 5; iter: 600; batch classifier loss: 0.418946; batch adversarial loss: 0.441215\n",
      "epoch 6; iter: 0; batch classifier loss: 0.912285; batch adversarial loss: 0.358240\n",
      "epoch 6; iter: 200; batch classifier loss: 0.367407; batch adversarial loss: 0.323005\n",
      "epoch 6; iter: 400; batch classifier loss: 3.288971; batch adversarial loss: 0.421000\n",
      "epoch 6; iter: 600; batch classifier loss: 0.684366; batch adversarial loss: 0.501661\n",
      "epoch 7; iter: 0; batch classifier loss: 0.284668; batch adversarial loss: 0.374539\n",
      "epoch 7; iter: 200; batch classifier loss: 1.143757; batch adversarial loss: 0.350556\n",
      "epoch 7; iter: 400; batch classifier loss: 0.440029; batch adversarial loss: 0.369252\n",
      "epoch 7; iter: 600; batch classifier loss: 0.463807; batch adversarial loss: 0.602147\n",
      "epoch 8; iter: 0; batch classifier loss: 0.388885; batch adversarial loss: 0.427605\n",
      "epoch 8; iter: 200; batch classifier loss: 0.436730; batch adversarial loss: 0.474855\n",
      "epoch 8; iter: 400; batch classifier loss: 0.407644; batch adversarial loss: 0.319333\n",
      "epoch 8; iter: 600; batch classifier loss: 0.486104; batch adversarial loss: 0.230460\n",
      "epoch 9; iter: 0; batch classifier loss: 0.413849; batch adversarial loss: 0.427817\n",
      "epoch 9; iter: 200; batch classifier loss: 0.518988; batch adversarial loss: 0.289115\n",
      "epoch 9; iter: 400; batch classifier loss: 0.326710; batch adversarial loss: 0.355362\n",
      "epoch 9; iter: 600; batch classifier loss: 0.252029; batch adversarial loss: 0.760455\n",
      "epoch 10; iter: 0; batch classifier loss: 0.383217; batch adversarial loss: 0.440144\n",
      "epoch 10; iter: 200; batch classifier loss: 0.354442; batch adversarial loss: 0.455747\n",
      "epoch 10; iter: 400; batch classifier loss: 0.253391; batch adversarial loss: 0.236479\n",
      "epoch 10; iter: 600; batch classifier loss: 0.435198; batch adversarial loss: 0.515505\n",
      "epoch 11; iter: 0; batch classifier loss: 0.308137; batch adversarial loss: 0.436812\n",
      "epoch 11; iter: 200; batch classifier loss: 0.425153; batch adversarial loss: 0.575951\n",
      "epoch 11; iter: 400; batch classifier loss: 0.312478; batch adversarial loss: 0.494689\n",
      "epoch 11; iter: 600; batch classifier loss: 0.437981; batch adversarial loss: 0.428022\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504345; batch adversarial loss: 0.493046\n",
      "epoch 12; iter: 200; batch classifier loss: 0.380764; batch adversarial loss: 0.375632\n",
      "epoch 12; iter: 400; batch classifier loss: 0.309401; batch adversarial loss: 0.382860\n",
      "epoch 12; iter: 600; batch classifier loss: 0.335184; batch adversarial loss: 0.375814\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329097; batch adversarial loss: 0.337776\n",
      "epoch 13; iter: 200; batch classifier loss: 0.310861; batch adversarial loss: 0.498656\n",
      "epoch 13; iter: 400; batch classifier loss: 0.373701; batch adversarial loss: 0.309750\n",
      "epoch 13; iter: 600; batch classifier loss: 0.436565; batch adversarial loss: 0.384048\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342411; batch adversarial loss: 0.332989\n",
      "epoch 14; iter: 200; batch classifier loss: 0.246769; batch adversarial loss: 0.442654\n",
      "epoch 14; iter: 400; batch classifier loss: 0.272988; batch adversarial loss: 0.379158\n",
      "epoch 14; iter: 600; batch classifier loss: 0.406827; batch adversarial loss: 0.396234\n",
      "epoch 15; iter: 0; batch classifier loss: 0.355716; batch adversarial loss: 0.402954\n",
      "epoch 15; iter: 200; batch classifier loss: 0.431502; batch adversarial loss: 0.326411\n",
      "epoch 15; iter: 400; batch classifier loss: 0.319622; batch adversarial loss: 0.270668\n",
      "epoch 15; iter: 600; batch classifier loss: 0.362295; batch adversarial loss: 0.434367\n",
      "epoch 16; iter: 0; batch classifier loss: 0.369917; batch adversarial loss: 0.234579\n",
      "epoch 16; iter: 200; batch classifier loss: 0.686045; batch adversarial loss: 0.393541\n",
      "epoch 16; iter: 400; batch classifier loss: 0.369906; batch adversarial loss: 0.354848\n",
      "epoch 16; iter: 600; batch classifier loss: 0.338352; batch adversarial loss: 0.495588\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430863; batch adversarial loss: 0.509820\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339739; batch adversarial loss: 0.517398\n",
      "epoch 17; iter: 400; batch classifier loss: 0.520203; batch adversarial loss: 0.470961\n",
      "epoch 17; iter: 600; batch classifier loss: 0.372889; batch adversarial loss: 0.304312\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325998; batch adversarial loss: 0.325164\n",
      "epoch 18; iter: 200; batch classifier loss: 0.388915; batch adversarial loss: 0.408097\n",
      "epoch 18; iter: 400; batch classifier loss: 0.268693; batch adversarial loss: 0.299984\n",
      "epoch 18; iter: 600; batch classifier loss: 0.434774; batch adversarial loss: 0.408147\n",
      "epoch 19; iter: 0; batch classifier loss: 0.300559; batch adversarial loss: 0.448639\n",
      "epoch 19; iter: 200; batch classifier loss: 0.366716; batch adversarial loss: 0.385341\n",
      "epoch 19; iter: 400; batch classifier loss: 0.282955; batch adversarial loss: 0.319366\n",
      "epoch 19; iter: 600; batch classifier loss: 0.338592; batch adversarial loss: 0.301513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.357901; batch adversarial loss: 0.468493\n",
      "epoch 20; iter: 200; batch classifier loss: 0.337318; batch adversarial loss: 0.359242\n",
      "epoch 20; iter: 400; batch classifier loss: 0.304918; batch adversarial loss: 0.494756\n",
      "epoch 20; iter: 600; batch classifier loss: 0.357601; batch adversarial loss: 0.410517\n",
      "epoch 21; iter: 0; batch classifier loss: 0.390158; batch adversarial loss: 0.461059\n",
      "epoch 21; iter: 200; batch classifier loss: 0.315442; batch adversarial loss: 0.599835\n",
      "epoch 21; iter: 400; batch classifier loss: 0.263965; batch adversarial loss: 0.468388\n",
      "epoch 21; iter: 600; batch classifier loss: 0.338903; batch adversarial loss: 0.373353\n",
      "epoch 22; iter: 0; batch classifier loss: 0.363204; batch adversarial loss: 0.403098\n",
      "epoch 22; iter: 200; batch classifier loss: 0.458796; batch adversarial loss: 0.491448\n",
      "epoch 22; iter: 400; batch classifier loss: 0.538164; batch adversarial loss: 0.400746\n",
      "epoch 22; iter: 600; batch classifier loss: 0.468811; batch adversarial loss: 0.341291\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458361; batch adversarial loss: 0.317959\n",
      "epoch 23; iter: 200; batch classifier loss: 0.421750; batch adversarial loss: 0.455313\n",
      "epoch 23; iter: 400; batch classifier loss: 0.516253; batch adversarial loss: 0.443909\n",
      "epoch 23; iter: 600; batch classifier loss: 0.432187; batch adversarial loss: 0.428803\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293244; batch adversarial loss: 0.518299\n",
      "epoch 24; iter: 200; batch classifier loss: 0.380007; batch adversarial loss: 0.373746\n",
      "epoch 24; iter: 400; batch classifier loss: 0.463323; batch adversarial loss: 0.534032\n",
      "epoch 24; iter: 600; batch classifier loss: 0.380064; batch adversarial loss: 0.429779\n",
      "epoch 25; iter: 0; batch classifier loss: 0.390418; batch adversarial loss: 0.371149\n",
      "epoch 25; iter: 200; batch classifier loss: 0.384895; batch adversarial loss: 0.356533\n",
      "epoch 25; iter: 400; batch classifier loss: 0.409559; batch adversarial loss: 0.412787\n",
      "epoch 25; iter: 600; batch classifier loss: 0.398152; batch adversarial loss: 0.386654\n",
      "epoch 26; iter: 0; batch classifier loss: 0.349381; batch adversarial loss: 0.432115\n",
      "epoch 26; iter: 200; batch classifier loss: 0.421390; batch adversarial loss: 0.482839\n",
      "epoch 26; iter: 400; batch classifier loss: 0.379427; batch adversarial loss: 0.301724\n",
      "epoch 26; iter: 600; batch classifier loss: 0.475784; batch adversarial loss: 0.384453\n",
      "epoch 27; iter: 0; batch classifier loss: 0.463679; batch adversarial loss: 0.345857\n",
      "epoch 27; iter: 200; batch classifier loss: 0.301414; batch adversarial loss: 0.400560\n",
      "epoch 27; iter: 400; batch classifier loss: 0.479225; batch adversarial loss: 0.403043\n",
      "epoch 27; iter: 600; batch classifier loss: 0.343010; batch adversarial loss: 0.413373\n",
      "epoch 28; iter: 0; batch classifier loss: 0.336180; batch adversarial loss: 0.321555\n",
      "epoch 28; iter: 200; batch classifier loss: 0.375781; batch adversarial loss: 0.321139\n",
      "epoch 28; iter: 400; batch classifier loss: 0.452543; batch adversarial loss: 0.470570\n",
      "epoch 28; iter: 600; batch classifier loss: 0.376001; batch adversarial loss: 0.409139\n",
      "epoch 29; iter: 0; batch classifier loss: 0.299525; batch adversarial loss: 0.408949\n",
      "epoch 29; iter: 200; batch classifier loss: 0.592751; batch adversarial loss: 0.320012\n",
      "epoch 29; iter: 400; batch classifier loss: 0.322626; batch adversarial loss: 0.443990\n",
      "epoch 29; iter: 600; batch classifier loss: 0.356430; batch adversarial loss: 0.323997\n",
      "epoch 30; iter: 0; batch classifier loss: 0.465709; batch adversarial loss: 0.422020\n",
      "epoch 30; iter: 200; batch classifier loss: 0.433799; batch adversarial loss: 0.370720\n",
      "epoch 30; iter: 400; batch classifier loss: 0.396054; batch adversarial loss: 0.598412\n",
      "epoch 30; iter: 600; batch classifier loss: 0.467119; batch adversarial loss: 0.348863\n",
      "epoch 31; iter: 0; batch classifier loss: 0.298659; batch adversarial loss: 0.510688\n",
      "epoch 31; iter: 200; batch classifier loss: 0.435692; batch adversarial loss: 0.455834\n",
      "epoch 31; iter: 400; batch classifier loss: 0.467274; batch adversarial loss: 0.270197\n",
      "epoch 31; iter: 600; batch classifier loss: 0.355096; batch adversarial loss: 0.429818\n",
      "epoch 32; iter: 0; batch classifier loss: 0.280907; batch adversarial loss: 0.347029\n",
      "epoch 32; iter: 200; batch classifier loss: 0.725988; batch adversarial loss: 0.430168\n",
      "epoch 32; iter: 400; batch classifier loss: 0.294282; batch adversarial loss: 0.433412\n",
      "epoch 32; iter: 600; batch classifier loss: 0.541929; batch adversarial loss: 0.296118\n",
      "epoch 33; iter: 0; batch classifier loss: 0.516681; batch adversarial loss: 0.347666\n",
      "epoch 33; iter: 200; batch classifier loss: 0.361861; batch adversarial loss: 0.421136\n",
      "epoch 33; iter: 400; batch classifier loss: 0.434221; batch adversarial loss: 0.374453\n",
      "epoch 33; iter: 600; batch classifier loss: 0.473165; batch adversarial loss: 0.431174\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499419; batch adversarial loss: 0.382892\n",
      "epoch 34; iter: 200; batch classifier loss: 0.495073; batch adversarial loss: 0.445284\n",
      "epoch 34; iter: 400; batch classifier loss: 0.441516; batch adversarial loss: 0.487015\n",
      "epoch 34; iter: 600; batch classifier loss: 0.352245; batch adversarial loss: 0.348509\n",
      "epoch 35; iter: 0; batch classifier loss: 0.359346; batch adversarial loss: 0.495077\n",
      "epoch 35; iter: 200; batch classifier loss: 0.609534; batch adversarial loss: 0.293626\n",
      "epoch 35; iter: 400; batch classifier loss: 0.697270; batch adversarial loss: 0.429632\n",
      "epoch 35; iter: 600; batch classifier loss: 0.604941; batch adversarial loss: 0.330696\n",
      "epoch 36; iter: 0; batch classifier loss: 0.381895; batch adversarial loss: 0.381362\n",
      "epoch 36; iter: 200; batch classifier loss: 0.555626; batch adversarial loss: 0.454596\n",
      "epoch 36; iter: 400; batch classifier loss: 0.414363; batch adversarial loss: 0.442083\n",
      "epoch 36; iter: 600; batch classifier loss: 0.733683; batch adversarial loss: 0.481398\n",
      "epoch 37; iter: 0; batch classifier loss: 0.560823; batch adversarial loss: 0.273188\n",
      "epoch 37; iter: 200; batch classifier loss: 0.436920; batch adversarial loss: 0.456766\n",
      "epoch 37; iter: 400; batch classifier loss: 0.420199; batch adversarial loss: 0.406730\n",
      "epoch 37; iter: 600; batch classifier loss: 0.427419; batch adversarial loss: 0.375679\n",
      "epoch 38; iter: 0; batch classifier loss: 0.597982; batch adversarial loss: 0.297145\n",
      "epoch 38; iter: 200; batch classifier loss: 0.358459; batch adversarial loss: 0.404018\n",
      "epoch 38; iter: 400; batch classifier loss: 0.666150; batch adversarial loss: 0.378289\n",
      "epoch 38; iter: 600; batch classifier loss: 0.435681; batch adversarial loss: 0.495653\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490219; batch adversarial loss: 0.386058\n",
      "epoch 39; iter: 200; batch classifier loss: 0.650197; batch adversarial loss: 0.292818\n",
      "epoch 39; iter: 400; batch classifier loss: 0.611983; batch adversarial loss: 0.375616\n",
      "epoch 39; iter: 600; batch classifier loss: 0.528772; batch adversarial loss: 0.484030\n",
      "epoch 40; iter: 0; batch classifier loss: 0.740743; batch adversarial loss: 0.357520\n",
      "epoch 40; iter: 200; batch classifier loss: 0.499559; batch adversarial loss: 0.617278\n",
      "epoch 40; iter: 400; batch classifier loss: 0.647152; batch adversarial loss: 0.349120\n",
      "epoch 40; iter: 600; batch classifier loss: 0.695830; batch adversarial loss: 0.435913\n",
      "epoch 41; iter: 0; batch classifier loss: 0.762999; batch adversarial loss: 0.347928\n",
      "epoch 41; iter: 200; batch classifier loss: 0.525901; batch adversarial loss: 0.427387\n",
      "epoch 41; iter: 400; batch classifier loss: 0.633744; batch adversarial loss: 0.378355\n",
      "epoch 41; iter: 600; batch classifier loss: 0.636875; batch adversarial loss: 0.436530\n",
      "epoch 42; iter: 0; batch classifier loss: 0.456030; batch adversarial loss: 0.431643\n",
      "epoch 42; iter: 200; batch classifier loss: 0.695404; batch adversarial loss: 0.268042\n",
      "epoch 42; iter: 400; batch classifier loss: 0.566358; batch adversarial loss: 0.493721\n",
      "epoch 42; iter: 600; batch classifier loss: 0.258489; batch adversarial loss: 0.517178\n",
      "epoch 43; iter: 0; batch classifier loss: 0.597640; batch adversarial loss: 0.464230\n",
      "epoch 43; iter: 200; batch classifier loss: 0.404114; batch adversarial loss: 0.462445\n",
      "epoch 43; iter: 400; batch classifier loss: 0.323285; batch adversarial loss: 0.462110\n",
      "epoch 43; iter: 600; batch classifier loss: 0.729032; batch adversarial loss: 0.433649\n",
      "epoch 44; iter: 0; batch classifier loss: 0.620271; batch adversarial loss: 0.321841\n",
      "epoch 44; iter: 200; batch classifier loss: 0.408726; batch adversarial loss: 0.513101\n",
      "epoch 44; iter: 400; batch classifier loss: 0.589919; batch adversarial loss: 0.237767\n",
      "epoch 44; iter: 600; batch classifier loss: 0.489166; batch adversarial loss: 0.515690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.549650; batch adversarial loss: 0.484984\n",
      "epoch 45; iter: 200; batch classifier loss: 0.456764; batch adversarial loss: 0.331080\n",
      "epoch 45; iter: 400; batch classifier loss: 0.365940; batch adversarial loss: 0.518435\n",
      "epoch 45; iter: 600; batch classifier loss: 0.500553; batch adversarial loss: 0.436890\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331572; batch adversarial loss: 0.375658\n",
      "epoch 46; iter: 200; batch classifier loss: 0.472394; batch adversarial loss: 0.351299\n",
      "epoch 46; iter: 400; batch classifier loss: 0.590559; batch adversarial loss: 0.404925\n",
      "epoch 46; iter: 600; batch classifier loss: 0.505435; batch adversarial loss: 0.379450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.507400; batch adversarial loss: 0.510885\n",
      "epoch 47; iter: 200; batch classifier loss: 0.403268; batch adversarial loss: 0.513282\n",
      "epoch 47; iter: 400; batch classifier loss: 0.406497; batch adversarial loss: 0.470154\n",
      "epoch 47; iter: 600; batch classifier loss: 0.612516; batch adversarial loss: 0.381153\n",
      "epoch 48; iter: 0; batch classifier loss: 0.608846; batch adversarial loss: 0.435000\n",
      "epoch 48; iter: 200; batch classifier loss: 0.729653; batch adversarial loss: 0.392164\n",
      "epoch 48; iter: 400; batch classifier loss: 0.515096; batch adversarial loss: 0.510845\n",
      "epoch 48; iter: 600; batch classifier loss: 0.598725; batch adversarial loss: 0.326177\n",
      "epoch 49; iter: 0; batch classifier loss: 0.579823; batch adversarial loss: 0.375644\n",
      "epoch 49; iter: 200; batch classifier loss: 0.437870; batch adversarial loss: 0.349540\n",
      "epoch 49; iter: 400; batch classifier loss: 0.648693; batch adversarial loss: 0.496623\n",
      "epoch 49; iter: 600; batch classifier loss: 0.597969; batch adversarial loss: 0.381678\n",
      "epoch 0; iter: 0; batch classifier loss: 3.927936; batch adversarial loss: 1.056241\n",
      "epoch 0; iter: 200; batch classifier loss: 10.854200; batch adversarial loss: 0.922401\n",
      "epoch 0; iter: 400; batch classifier loss: 12.279051; batch adversarial loss: 0.740966\n",
      "epoch 0; iter: 600; batch classifier loss: 7.329416; batch adversarial loss: 0.579931\n",
      "epoch 1; iter: 0; batch classifier loss: 2.314045; batch adversarial loss: 0.631886\n",
      "epoch 1; iter: 200; batch classifier loss: 3.011387; batch adversarial loss: 0.477684\n",
      "epoch 1; iter: 400; batch classifier loss: 16.118975; batch adversarial loss: 0.458334\n",
      "epoch 1; iter: 600; batch classifier loss: 7.825664; batch adversarial loss: 0.466642\n",
      "epoch 2; iter: 0; batch classifier loss: 1.294726; batch adversarial loss: 0.437614\n",
      "epoch 2; iter: 200; batch classifier loss: 3.760989; batch adversarial loss: 0.433600\n",
      "epoch 2; iter: 400; batch classifier loss: 3.203764; batch adversarial loss: 0.478490\n",
      "epoch 2; iter: 600; batch classifier loss: 0.580001; batch adversarial loss: 0.423974\n",
      "epoch 3; iter: 0; batch classifier loss: 2.425735; batch adversarial loss: 0.377005\n",
      "epoch 3; iter: 200; batch classifier loss: 3.425062; batch adversarial loss: 0.395895\n",
      "epoch 3; iter: 400; batch classifier loss: 4.736249; batch adversarial loss: 0.472500\n",
      "epoch 3; iter: 600; batch classifier loss: 1.980767; batch adversarial loss: 0.360801\n",
      "epoch 4; iter: 0; batch classifier loss: 1.646577; batch adversarial loss: 0.370602\n",
      "epoch 4; iter: 200; batch classifier loss: 0.599206; batch adversarial loss: 0.509129\n",
      "epoch 4; iter: 400; batch classifier loss: 0.979970; batch adversarial loss: 0.448210\n",
      "epoch 4; iter: 600; batch classifier loss: 0.975315; batch adversarial loss: 0.373256\n",
      "epoch 5; iter: 0; batch classifier loss: 0.993087; batch adversarial loss: 0.398271\n",
      "epoch 5; iter: 200; batch classifier loss: 0.507734; batch adversarial loss: 0.356835\n",
      "epoch 5; iter: 400; batch classifier loss: 0.518286; batch adversarial loss: 0.288487\n",
      "epoch 5; iter: 600; batch classifier loss: 0.732984; batch adversarial loss: 0.273098\n",
      "epoch 6; iter: 0; batch classifier loss: 0.447981; batch adversarial loss: 0.331534\n",
      "epoch 6; iter: 200; batch classifier loss: 0.689409; batch adversarial loss: 0.356146\n",
      "epoch 6; iter: 400; batch classifier loss: 0.737296; batch adversarial loss: 0.527024\n",
      "epoch 6; iter: 600; batch classifier loss: 0.475213; batch adversarial loss: 0.394498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.689211; batch adversarial loss: 0.538875\n",
      "epoch 7; iter: 200; batch classifier loss: 0.576114; batch adversarial loss: 0.370810\n",
      "epoch 7; iter: 400; batch classifier loss: 0.792584; batch adversarial loss: 0.438302\n",
      "epoch 7; iter: 600; batch classifier loss: 0.646308; batch adversarial loss: 0.401979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453142; batch adversarial loss: 0.422370\n",
      "epoch 8; iter: 200; batch classifier loss: 0.571863; batch adversarial loss: 0.384351\n",
      "epoch 8; iter: 400; batch classifier loss: 0.547799; batch adversarial loss: 0.531930\n",
      "epoch 8; iter: 600; batch classifier loss: 0.319077; batch adversarial loss: 0.430870\n",
      "epoch 9; iter: 0; batch classifier loss: 0.324970; batch adversarial loss: 0.336818\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383430; batch adversarial loss: 0.356999\n",
      "epoch 9; iter: 400; batch classifier loss: 0.438117; batch adversarial loss: 0.395754\n",
      "epoch 9; iter: 600; batch classifier loss: 0.454242; batch adversarial loss: 0.528620\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405109; batch adversarial loss: 0.418689\n",
      "epoch 10; iter: 200; batch classifier loss: 0.356077; batch adversarial loss: 0.323176\n",
      "epoch 10; iter: 400; batch classifier loss: 0.390463; batch adversarial loss: 0.507851\n",
      "epoch 10; iter: 600; batch classifier loss: 0.514546; batch adversarial loss: 0.538773\n",
      "epoch 11; iter: 0; batch classifier loss: 0.359778; batch adversarial loss: 0.407960\n",
      "epoch 11; iter: 200; batch classifier loss: 0.237622; batch adversarial loss: 0.360498\n",
      "epoch 11; iter: 400; batch classifier loss: 0.461424; batch adversarial loss: 0.411023\n",
      "epoch 11; iter: 600; batch classifier loss: 0.435012; batch adversarial loss: 0.537833\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329598; batch adversarial loss: 0.414610\n",
      "epoch 12; iter: 200; batch classifier loss: 0.434358; batch adversarial loss: 0.368250\n",
      "epoch 12; iter: 400; batch classifier loss: 0.277848; batch adversarial loss: 0.345899\n",
      "epoch 12; iter: 600; batch classifier loss: 0.416953; batch adversarial loss: 0.400717\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399168; batch adversarial loss: 0.369267\n",
      "epoch 13; iter: 200; batch classifier loss: 0.312530; batch adversarial loss: 0.497420\n",
      "epoch 13; iter: 400; batch classifier loss: 0.320775; batch adversarial loss: 0.437856\n",
      "epoch 13; iter: 600; batch classifier loss: 0.262116; batch adversarial loss: 0.484920\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310482; batch adversarial loss: 0.499089\n",
      "epoch 14; iter: 200; batch classifier loss: 0.292806; batch adversarial loss: 0.452464\n",
      "epoch 14; iter: 400; batch classifier loss: 0.349800; batch adversarial loss: 0.370730\n",
      "epoch 14; iter: 600; batch classifier loss: 0.265352; batch adversarial loss: 0.516556\n",
      "epoch 15; iter: 0; batch classifier loss: 0.321255; batch adversarial loss: 0.485126\n",
      "epoch 15; iter: 200; batch classifier loss: 0.348813; batch adversarial loss: 0.589816\n",
      "epoch 15; iter: 400; batch classifier loss: 0.350697; batch adversarial loss: 0.455154\n",
      "epoch 15; iter: 600; batch classifier loss: 0.387435; batch adversarial loss: 0.468971\n",
      "epoch 16; iter: 0; batch classifier loss: 0.368229; batch adversarial loss: 0.380862\n",
      "epoch 16; iter: 200; batch classifier loss: 0.423747; batch adversarial loss: 0.342658\n",
      "epoch 16; iter: 400; batch classifier loss: 0.388482; batch adversarial loss: 0.558837\n",
      "epoch 16; iter: 600; batch classifier loss: 0.385270; batch adversarial loss: 0.327214\n",
      "epoch 17; iter: 0; batch classifier loss: 0.379619; batch adversarial loss: 0.453360\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321608; batch adversarial loss: 0.405882\n",
      "epoch 17; iter: 400; batch classifier loss: 0.212297; batch adversarial loss: 0.458101\n",
      "epoch 17; iter: 600; batch classifier loss: 0.322711; batch adversarial loss: 0.353481\n",
      "epoch 18; iter: 0; batch classifier loss: 0.352623; batch adversarial loss: 0.596096\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399158; batch adversarial loss: 0.728001\n",
      "epoch 18; iter: 400; batch classifier loss: 0.326125; batch adversarial loss: 0.401246\n",
      "epoch 18; iter: 600; batch classifier loss: 0.335221; batch adversarial loss: 0.393252\n",
      "epoch 19; iter: 0; batch classifier loss: 0.410586; batch adversarial loss: 0.369442\n",
      "epoch 19; iter: 200; batch classifier loss: 0.344283; batch adversarial loss: 0.379841\n",
      "epoch 19; iter: 400; batch classifier loss: 0.288729; batch adversarial loss: 0.596272\n",
      "epoch 19; iter: 600; batch classifier loss: 0.551961; batch adversarial loss: 0.285176\n",
      "epoch 20; iter: 0; batch classifier loss: 0.340841; batch adversarial loss: 0.428256\n",
      "epoch 20; iter: 200; batch classifier loss: 0.376311; batch adversarial loss: 0.328753\n",
      "epoch 20; iter: 400; batch classifier loss: 0.369891; batch adversarial loss: 0.287332\n",
      "epoch 20; iter: 600; batch classifier loss: 0.405541; batch adversarial loss: 0.264796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.263672; batch adversarial loss: 0.401819\n",
      "epoch 21; iter: 200; batch classifier loss: 0.454189; batch adversarial loss: 0.319425\n",
      "epoch 21; iter: 400; batch classifier loss: 0.421744; batch adversarial loss: 0.429752\n",
      "epoch 21; iter: 600; batch classifier loss: 0.228585; batch adversarial loss: 0.412813\n",
      "epoch 22; iter: 0; batch classifier loss: 0.444357; batch adversarial loss: 0.461357\n",
      "epoch 22; iter: 200; batch classifier loss: 0.465026; batch adversarial loss: 0.321357\n",
      "epoch 22; iter: 400; batch classifier loss: 0.501621; batch adversarial loss: 0.399520\n",
      "epoch 22; iter: 600; batch classifier loss: 0.467038; batch adversarial loss: 0.470164\n",
      "epoch 23; iter: 0; batch classifier loss: 0.419639; batch adversarial loss: 0.450805\n",
      "epoch 23; iter: 200; batch classifier loss: 0.349423; batch adversarial loss: 0.464273\n",
      "epoch 23; iter: 400; batch classifier loss: 0.392865; batch adversarial loss: 0.315813\n",
      "epoch 23; iter: 600; batch classifier loss: 0.372875; batch adversarial loss: 0.401552\n",
      "epoch 24; iter: 0; batch classifier loss: 0.359585; batch adversarial loss: 0.356267\n",
      "epoch 24; iter: 200; batch classifier loss: 0.378133; batch adversarial loss: 0.509074\n",
      "epoch 24; iter: 400; batch classifier loss: 0.335085; batch adversarial loss: 0.429520\n",
      "epoch 24; iter: 600; batch classifier loss: 0.484935; batch adversarial loss: 0.467089\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446830; batch adversarial loss: 0.412834\n",
      "epoch 25; iter: 200; batch classifier loss: 0.356598; batch adversarial loss: 0.397358\n",
      "epoch 25; iter: 400; batch classifier loss: 0.417135; batch adversarial loss: 0.486303\n",
      "epoch 25; iter: 600; batch classifier loss: 0.538420; batch adversarial loss: 0.363739\n",
      "epoch 26; iter: 0; batch classifier loss: 0.277923; batch adversarial loss: 0.504265\n",
      "epoch 26; iter: 200; batch classifier loss: 0.332366; batch adversarial loss: 0.409969\n",
      "epoch 26; iter: 400; batch classifier loss: 0.326477; batch adversarial loss: 0.486423\n",
      "epoch 26; iter: 600; batch classifier loss: 0.427427; batch adversarial loss: 0.404360\n",
      "epoch 27; iter: 0; batch classifier loss: 0.369881; batch adversarial loss: 0.485105\n",
      "epoch 27; iter: 200; batch classifier loss: 0.564793; batch adversarial loss: 0.495032\n",
      "epoch 27; iter: 400; batch classifier loss: 0.324877; batch adversarial loss: 0.417450\n",
      "epoch 27; iter: 600; batch classifier loss: 0.362706; batch adversarial loss: 0.262737\n",
      "epoch 28; iter: 0; batch classifier loss: 0.373504; batch adversarial loss: 0.518622\n",
      "epoch 28; iter: 200; batch classifier loss: 0.496760; batch adversarial loss: 0.344587\n",
      "epoch 28; iter: 400; batch classifier loss: 0.410862; batch adversarial loss: 0.403234\n",
      "epoch 28; iter: 600; batch classifier loss: 0.533758; batch adversarial loss: 0.518606\n",
      "epoch 29; iter: 0; batch classifier loss: 0.339618; batch adversarial loss: 0.580292\n",
      "epoch 29; iter: 200; batch classifier loss: 0.415909; batch adversarial loss: 0.429577\n",
      "epoch 29; iter: 400; batch classifier loss: 0.467701; batch adversarial loss: 0.484626\n",
      "epoch 29; iter: 600; batch classifier loss: 0.429385; batch adversarial loss: 0.370429\n",
      "epoch 30; iter: 0; batch classifier loss: 0.337195; batch adversarial loss: 0.373587\n",
      "epoch 30; iter: 200; batch classifier loss: 0.487030; batch adversarial loss: 0.323677\n",
      "epoch 30; iter: 400; batch classifier loss: 0.467413; batch adversarial loss: 0.243690\n",
      "epoch 30; iter: 600; batch classifier loss: 0.369241; batch adversarial loss: 0.361324\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550178; batch adversarial loss: 0.267587\n",
      "epoch 31; iter: 200; batch classifier loss: 0.304423; batch adversarial loss: 0.376189\n",
      "epoch 31; iter: 400; batch classifier loss: 0.405325; batch adversarial loss: 0.376063\n",
      "epoch 31; iter: 600; batch classifier loss: 0.357194; batch adversarial loss: 0.511715\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499897; batch adversarial loss: 0.380840\n",
      "epoch 32; iter: 200; batch classifier loss: 0.372232; batch adversarial loss: 0.386725\n",
      "epoch 32; iter: 400; batch classifier loss: 0.474185; batch adversarial loss: 0.401815\n",
      "epoch 32; iter: 600; batch classifier loss: 0.444690; batch adversarial loss: 0.266349\n",
      "epoch 33; iter: 0; batch classifier loss: 0.351932; batch adversarial loss: 0.487258\n",
      "epoch 33; iter: 200; batch classifier loss: 0.236996; batch adversarial loss: 0.374441\n",
      "epoch 33; iter: 400; batch classifier loss: 0.595489; batch adversarial loss: 0.409769\n",
      "epoch 33; iter: 600; batch classifier loss: 0.463380; batch adversarial loss: 0.350800\n",
      "epoch 34; iter: 0; batch classifier loss: 0.499722; batch adversarial loss: 0.491463\n",
      "epoch 34; iter: 200; batch classifier loss: 0.428810; batch adversarial loss: 0.354398\n",
      "epoch 34; iter: 400; batch classifier loss: 0.383848; batch adversarial loss: 0.289749\n",
      "epoch 34; iter: 600; batch classifier loss: 0.344851; batch adversarial loss: 0.375632\n",
      "epoch 35; iter: 0; batch classifier loss: 0.476471; batch adversarial loss: 0.432254\n",
      "epoch 35; iter: 200; batch classifier loss: 0.518709; batch adversarial loss: 0.522043\n",
      "epoch 35; iter: 400; batch classifier loss: 0.404178; batch adversarial loss: 0.404259\n",
      "epoch 35; iter: 600; batch classifier loss: 0.483047; batch adversarial loss: 0.343739\n",
      "epoch 36; iter: 0; batch classifier loss: 0.516127; batch adversarial loss: 0.433115\n",
      "epoch 36; iter: 200; batch classifier loss: 0.410121; batch adversarial loss: 0.508490\n",
      "epoch 36; iter: 400; batch classifier loss: 0.496233; batch adversarial loss: 0.428085\n",
      "epoch 36; iter: 600; batch classifier loss: 0.468964; batch adversarial loss: 0.375225\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423455; batch adversarial loss: 0.374709\n",
      "epoch 37; iter: 200; batch classifier loss: 0.575103; batch adversarial loss: 0.343027\n",
      "epoch 37; iter: 400; batch classifier loss: 0.671633; batch adversarial loss: 0.398344\n",
      "epoch 37; iter: 600; batch classifier loss: 0.544957; batch adversarial loss: 0.378981\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408649; batch adversarial loss: 0.381308\n",
      "epoch 38; iter: 200; batch classifier loss: 0.542751; batch adversarial loss: 0.267961\n",
      "epoch 38; iter: 400; batch classifier loss: 0.483831; batch adversarial loss: 0.264053\n",
      "epoch 38; iter: 600; batch classifier loss: 0.370632; batch adversarial loss: 0.372978\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410203; batch adversarial loss: 0.331222\n",
      "epoch 39; iter: 200; batch classifier loss: 0.671793; batch adversarial loss: 0.358452\n",
      "epoch 39; iter: 400; batch classifier loss: 0.306464; batch adversarial loss: 0.294103\n",
      "epoch 39; iter: 600; batch classifier loss: 0.389427; batch adversarial loss: 0.411059\n",
      "epoch 40; iter: 0; batch classifier loss: 0.475453; batch adversarial loss: 0.566887\n",
      "epoch 40; iter: 200; batch classifier loss: 0.571745; batch adversarial loss: 0.432569\n",
      "epoch 40; iter: 400; batch classifier loss: 0.338806; batch adversarial loss: 0.374220\n",
      "epoch 40; iter: 600; batch classifier loss: 0.456853; batch adversarial loss: 0.401611\n",
      "epoch 41; iter: 0; batch classifier loss: 0.405068; batch adversarial loss: 0.545990\n",
      "epoch 41; iter: 200; batch classifier loss: 0.438065; batch adversarial loss: 0.512942\n",
      "epoch 41; iter: 400; batch classifier loss: 0.455113; batch adversarial loss: 0.401979\n",
      "epoch 41; iter: 600; batch classifier loss: 0.359221; batch adversarial loss: 0.432546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.694198; batch adversarial loss: 0.346502\n",
      "epoch 42; iter: 200; batch classifier loss: 0.486387; batch adversarial loss: 0.566684\n",
      "epoch 42; iter: 400; batch classifier loss: 0.482871; batch adversarial loss: 0.374372\n",
      "epoch 42; iter: 600; batch classifier loss: 0.390796; batch adversarial loss: 0.375759\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375677; batch adversarial loss: 0.403062\n",
      "epoch 43; iter: 200; batch classifier loss: 0.579203; batch adversarial loss: 0.559339\n",
      "epoch 43; iter: 400; batch classifier loss: 0.573734; batch adversarial loss: 0.292256\n",
      "epoch 43; iter: 600; batch classifier loss: 0.265453; batch adversarial loss: 0.513565\n",
      "epoch 44; iter: 0; batch classifier loss: 0.563978; batch adversarial loss: 0.454444\n",
      "epoch 44; iter: 200; batch classifier loss: 0.531606; batch adversarial loss: 0.413444\n",
      "epoch 44; iter: 400; batch classifier loss: 0.326820; batch adversarial loss: 0.364866\n",
      "epoch 44; iter: 600; batch classifier loss: 0.356103; batch adversarial loss: 0.406955\n",
      "epoch 45; iter: 0; batch classifier loss: 0.549961; batch adversarial loss: 0.470186\n",
      "epoch 45; iter: 200; batch classifier loss: 0.316681; batch adversarial loss: 0.381779\n",
      "epoch 45; iter: 400; batch classifier loss: 0.312197; batch adversarial loss: 0.427935\n",
      "epoch 45; iter: 600; batch classifier loss: 0.397239; batch adversarial loss: 0.405502\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482495; batch adversarial loss: 0.383057\n",
      "epoch 46; iter: 200; batch classifier loss: 0.443545; batch adversarial loss: 0.380515\n",
      "epoch 46; iter: 400; batch classifier loss: 0.672633; batch adversarial loss: 0.378937\n",
      "epoch 46; iter: 600; batch classifier loss: 0.665866; batch adversarial loss: 0.373955\n",
      "epoch 47; iter: 0; batch classifier loss: 0.565883; batch adversarial loss: 0.296452\n",
      "epoch 47; iter: 200; batch classifier loss: 0.485269; batch adversarial loss: 0.462289\n",
      "epoch 47; iter: 400; batch classifier loss: 0.643573; batch adversarial loss: 0.374011\n",
      "epoch 47; iter: 600; batch classifier loss: 0.448514; batch adversarial loss: 0.412048\n",
      "epoch 48; iter: 0; batch classifier loss: 0.630960; batch adversarial loss: 0.373525\n",
      "epoch 48; iter: 200; batch classifier loss: 0.365715; batch adversarial loss: 0.348446\n",
      "epoch 48; iter: 400; batch classifier loss: 0.490200; batch adversarial loss: 0.456694\n",
      "epoch 48; iter: 600; batch classifier loss: 0.610190; batch adversarial loss: 0.373654\n",
      "epoch 49; iter: 0; batch classifier loss: 0.351687; batch adversarial loss: 0.514153\n",
      "epoch 49; iter: 200; batch classifier loss: 0.326099; batch adversarial loss: 0.322882\n",
      "epoch 49; iter: 400; batch classifier loss: 0.466946; batch adversarial loss: 0.513261\n",
      "epoch 49; iter: 600; batch classifier loss: 0.555584; batch adversarial loss: 0.489234\n",
      "epoch 0; iter: 0; batch classifier loss: 14.067223; batch adversarial loss: 0.789615\n",
      "epoch 0; iter: 200; batch classifier loss: 0.417106; batch adversarial loss: 0.703972\n",
      "epoch 0; iter: 400; batch classifier loss: 12.793104; batch adversarial loss: 0.591119\n",
      "epoch 0; iter: 600; batch classifier loss: 9.484597; batch adversarial loss: 0.562808\n",
      "epoch 1; iter: 0; batch classifier loss: 3.610178; batch adversarial loss: 0.550611\n",
      "epoch 1; iter: 200; batch classifier loss: 0.504832; batch adversarial loss: 0.549657\n",
      "epoch 1; iter: 400; batch classifier loss: 2.558617; batch adversarial loss: 0.540820\n",
      "epoch 1; iter: 600; batch classifier loss: 1.872793; batch adversarial loss: 0.435109\n",
      "epoch 2; iter: 0; batch classifier loss: 4.854920; batch adversarial loss: 0.402387\n",
      "epoch 2; iter: 200; batch classifier loss: 3.964429; batch adversarial loss: 0.450602\n",
      "epoch 2; iter: 400; batch classifier loss: 6.946233; batch adversarial loss: 0.482340\n",
      "epoch 2; iter: 600; batch classifier loss: 10.079045; batch adversarial loss: 0.517339\n",
      "epoch 3; iter: 0; batch classifier loss: 2.841654; batch adversarial loss: 0.475672\n",
      "epoch 3; iter: 200; batch classifier loss: 1.901417; batch adversarial loss: 0.383650\n",
      "epoch 3; iter: 400; batch classifier loss: 0.731010; batch adversarial loss: 0.443536\n",
      "epoch 3; iter: 600; batch classifier loss: 1.901907; batch adversarial loss: 0.407816\n",
      "epoch 4; iter: 0; batch classifier loss: 1.010266; batch adversarial loss: 0.500831\n",
      "epoch 4; iter: 200; batch classifier loss: 0.527832; batch adversarial loss: 0.545733\n",
      "epoch 4; iter: 400; batch classifier loss: 0.559330; batch adversarial loss: 0.379455\n",
      "epoch 4; iter: 600; batch classifier loss: 0.555760; batch adversarial loss: 0.404841\n",
      "epoch 5; iter: 0; batch classifier loss: 0.762582; batch adversarial loss: 0.544098\n",
      "epoch 5; iter: 200; batch classifier loss: 0.733817; batch adversarial loss: 0.502186\n",
      "epoch 5; iter: 400; batch classifier loss: 0.432559; batch adversarial loss: 0.456199\n",
      "epoch 5; iter: 600; batch classifier loss: 0.815240; batch adversarial loss: 0.486436\n",
      "epoch 6; iter: 0; batch classifier loss: 0.664504; batch adversarial loss: 0.363360\n",
      "epoch 6; iter: 200; batch classifier loss: 0.414146; batch adversarial loss: 0.376593\n",
      "epoch 6; iter: 400; batch classifier loss: 0.403617; batch adversarial loss: 0.299110\n",
      "epoch 6; iter: 600; batch classifier loss: 0.483033; batch adversarial loss: 0.392953\n",
      "epoch 7; iter: 0; batch classifier loss: 0.467566; batch adversarial loss: 0.372919\n",
      "epoch 7; iter: 200; batch classifier loss: 0.398944; batch adversarial loss: 0.463769\n",
      "epoch 7; iter: 400; batch classifier loss: 0.377733; batch adversarial loss: 0.314860\n",
      "epoch 7; iter: 600; batch classifier loss: 0.373971; batch adversarial loss: 0.372359\n",
      "epoch 8; iter: 0; batch classifier loss: 0.775744; batch adversarial loss: 0.367789\n",
      "epoch 8; iter: 200; batch classifier loss: 0.334347; batch adversarial loss: 0.443075\n",
      "epoch 8; iter: 400; batch classifier loss: 0.355007; batch adversarial loss: 0.357586\n",
      "epoch 8; iter: 600; batch classifier loss: 0.328659; batch adversarial loss: 0.301461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.391780; batch adversarial loss: 0.381506\n",
      "epoch 9; iter: 200; batch classifier loss: 0.391315; batch adversarial loss: 0.340609\n",
      "epoch 9; iter: 400; batch classifier loss: 0.289806; batch adversarial loss: 0.456869\n",
      "epoch 9; iter: 600; batch classifier loss: 0.319606; batch adversarial loss: 0.445991\n",
      "epoch 10; iter: 0; batch classifier loss: 0.274868; batch adversarial loss: 0.345293\n",
      "epoch 10; iter: 200; batch classifier loss: 0.381522; batch adversarial loss: 0.371355\n",
      "epoch 10; iter: 400; batch classifier loss: 0.331358; batch adversarial loss: 0.396035\n",
      "epoch 10; iter: 600; batch classifier loss: 0.373386; batch adversarial loss: 0.491252\n",
      "epoch 11; iter: 0; batch classifier loss: 0.559290; batch adversarial loss: 0.301465\n",
      "epoch 11; iter: 200; batch classifier loss: 0.392908; batch adversarial loss: 0.371449\n",
      "epoch 11; iter: 400; batch classifier loss: 0.281924; batch adversarial loss: 0.420871\n",
      "epoch 11; iter: 600; batch classifier loss: 0.263726; batch adversarial loss: 0.490424\n",
      "epoch 12; iter: 0; batch classifier loss: 0.387217; batch adversarial loss: 0.470918\n",
      "epoch 12; iter: 200; batch classifier loss: 0.310030; batch adversarial loss: 0.378877\n",
      "epoch 12; iter: 400; batch classifier loss: 0.310949; batch adversarial loss: 0.283116\n",
      "epoch 12; iter: 600; batch classifier loss: 0.266516; batch adversarial loss: 0.344371\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394333; batch adversarial loss: 0.444837\n",
      "epoch 13; iter: 200; batch classifier loss: 0.276913; batch adversarial loss: 0.436330\n",
      "epoch 13; iter: 400; batch classifier loss: 0.418131; batch adversarial loss: 0.417727\n",
      "epoch 13; iter: 600; batch classifier loss: 0.349989; batch adversarial loss: 0.450244\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340530; batch adversarial loss: 0.472167\n",
      "epoch 14; iter: 200; batch classifier loss: 0.221987; batch adversarial loss: 0.404394\n",
      "epoch 14; iter: 400; batch classifier loss: 0.392111; batch adversarial loss: 0.395827\n",
      "epoch 14; iter: 600; batch classifier loss: 0.423771; batch adversarial loss: 0.368364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.383259; batch adversarial loss: 0.414142\n",
      "epoch 15; iter: 200; batch classifier loss: 0.336107; batch adversarial loss: 0.432090\n",
      "epoch 15; iter: 400; batch classifier loss: 0.399677; batch adversarial loss: 0.471570\n",
      "epoch 15; iter: 600; batch classifier loss: 0.406652; batch adversarial loss: 0.374638\n",
      "epoch 16; iter: 0; batch classifier loss: 0.305186; batch adversarial loss: 0.295130\n",
      "epoch 16; iter: 200; batch classifier loss: 0.363867; batch adversarial loss: 0.433392\n",
      "epoch 16; iter: 400; batch classifier loss: 0.342501; batch adversarial loss: 0.420207\n",
      "epoch 16; iter: 600; batch classifier loss: 0.431911; batch adversarial loss: 0.264537\n",
      "epoch 17; iter: 0; batch classifier loss: 0.468838; batch adversarial loss: 0.219352\n",
      "epoch 17; iter: 200; batch classifier loss: 0.385641; batch adversarial loss: 0.338640\n",
      "epoch 17; iter: 400; batch classifier loss: 0.302827; batch adversarial loss: 0.593890\n",
      "epoch 17; iter: 600; batch classifier loss: 0.385802; batch adversarial loss: 0.454853\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339843; batch adversarial loss: 0.344594\n",
      "epoch 18; iter: 200; batch classifier loss: 0.477618; batch adversarial loss: 0.319991\n",
      "epoch 18; iter: 400; batch classifier loss: 0.442735; batch adversarial loss: 0.487990\n",
      "epoch 18; iter: 600; batch classifier loss: 0.408269; batch adversarial loss: 0.400551\n",
      "epoch 19; iter: 0; batch classifier loss: 0.524292; batch adversarial loss: 0.349966\n",
      "epoch 19; iter: 200; batch classifier loss: 0.507845; batch adversarial loss: 0.469657\n",
      "epoch 19; iter: 400; batch classifier loss: 0.362122; batch adversarial loss: 0.382749\n",
      "epoch 19; iter: 600; batch classifier loss: 0.346916; batch adversarial loss: 0.408022\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436452; batch adversarial loss: 0.300451\n",
      "epoch 20; iter: 200; batch classifier loss: 0.474451; batch adversarial loss: 0.321375\n",
      "epoch 20; iter: 400; batch classifier loss: 0.393166; batch adversarial loss: 0.506447\n",
      "epoch 20; iter: 600; batch classifier loss: 0.468697; batch adversarial loss: 0.428630\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456115; batch adversarial loss: 0.430066\n",
      "epoch 21; iter: 200; batch classifier loss: 0.323595; batch adversarial loss: 0.405809\n",
      "epoch 21; iter: 400; batch classifier loss: 0.476010; batch adversarial loss: 0.410378\n",
      "epoch 21; iter: 600; batch classifier loss: 0.370894; batch adversarial loss: 0.414116\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378645; batch adversarial loss: 0.430979\n",
      "epoch 22; iter: 200; batch classifier loss: 0.437604; batch adversarial loss: 0.408408\n",
      "epoch 22; iter: 400; batch classifier loss: 0.500320; batch adversarial loss: 0.514745\n",
      "epoch 22; iter: 600; batch classifier loss: 0.531346; batch adversarial loss: 0.584625\n",
      "epoch 23; iter: 0; batch classifier loss: 0.550490; batch adversarial loss: 0.315081\n",
      "epoch 23; iter: 200; batch classifier loss: 0.457492; batch adversarial loss: 0.475648\n",
      "epoch 23; iter: 400; batch classifier loss: 0.409099; batch adversarial loss: 0.427180\n",
      "epoch 23; iter: 600; batch classifier loss: 0.485671; batch adversarial loss: 0.320263\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456066; batch adversarial loss: 0.494201\n",
      "epoch 24; iter: 200; batch classifier loss: 0.408524; batch adversarial loss: 0.322197\n",
      "epoch 24; iter: 400; batch classifier loss: 0.374073; batch adversarial loss: 0.435845\n",
      "epoch 24; iter: 600; batch classifier loss: 0.400914; batch adversarial loss: 0.316994\n",
      "epoch 25; iter: 0; batch classifier loss: 0.395688; batch adversarial loss: 0.321771\n",
      "epoch 25; iter: 200; batch classifier loss: 0.446576; batch adversarial loss: 0.277851\n",
      "epoch 25; iter: 400; batch classifier loss: 0.393449; batch adversarial loss: 0.399484\n",
      "epoch 25; iter: 600; batch classifier loss: 0.606230; batch adversarial loss: 0.479623\n",
      "epoch 26; iter: 0; batch classifier loss: 0.526842; batch adversarial loss: 0.492796\n",
      "epoch 26; iter: 200; batch classifier loss: 0.352279; batch adversarial loss: 0.354882\n",
      "epoch 26; iter: 400; batch classifier loss: 0.497122; batch adversarial loss: 0.346004\n",
      "epoch 26; iter: 600; batch classifier loss: 0.369088; batch adversarial loss: 0.409834\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513647; batch adversarial loss: 0.480348\n",
      "epoch 27; iter: 200; batch classifier loss: 0.545314; batch adversarial loss: 0.415883\n",
      "epoch 27; iter: 400; batch classifier loss: 0.536029; batch adversarial loss: 0.289863\n",
      "epoch 27; iter: 600; batch classifier loss: 0.550257; batch adversarial loss: 0.485018\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514539; batch adversarial loss: 0.510844\n",
      "epoch 28; iter: 200; batch classifier loss: 0.408422; batch adversarial loss: 0.375960\n",
      "epoch 28; iter: 400; batch classifier loss: 0.341944; batch adversarial loss: 0.453035\n",
      "epoch 28; iter: 600; batch classifier loss: 0.438210; batch adversarial loss: 0.568467\n",
      "epoch 29; iter: 0; batch classifier loss: 0.597597; batch adversarial loss: 0.485071\n",
      "epoch 29; iter: 200; batch classifier loss: 0.424480; batch adversarial loss: 0.429907\n",
      "epoch 29; iter: 400; batch classifier loss: 0.391111; batch adversarial loss: 0.455739\n",
      "epoch 29; iter: 600; batch classifier loss: 0.336161; batch adversarial loss: 0.235367\n",
      "epoch 30; iter: 0; batch classifier loss: 0.708942; batch adversarial loss: 0.483255\n",
      "epoch 30; iter: 200; batch classifier loss: 0.467116; batch adversarial loss: 0.347234\n",
      "epoch 30; iter: 400; batch classifier loss: 0.492425; batch adversarial loss: 0.399171\n",
      "epoch 30; iter: 600; batch classifier loss: 0.584435; batch adversarial loss: 0.346881\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507469; batch adversarial loss: 0.355638\n",
      "epoch 31; iter: 200; batch classifier loss: 0.555971; batch adversarial loss: 0.405848\n",
      "epoch 31; iter: 400; batch classifier loss: 0.450883; batch adversarial loss: 0.481938\n",
      "epoch 31; iter: 600; batch classifier loss: 0.417931; batch adversarial loss: 0.416030\n",
      "epoch 32; iter: 0; batch classifier loss: 0.625373; batch adversarial loss: 0.430224\n",
      "epoch 32; iter: 200; batch classifier loss: 0.437377; batch adversarial loss: 0.469592\n",
      "epoch 32; iter: 400; batch classifier loss: 0.485848; batch adversarial loss: 0.349128\n",
      "epoch 32; iter: 600; batch classifier loss: 0.503091; batch adversarial loss: 0.325350\n",
      "epoch 33; iter: 0; batch classifier loss: 0.525705; batch adversarial loss: 0.326217\n",
      "epoch 33; iter: 200; batch classifier loss: 0.515468; batch adversarial loss: 0.407721\n",
      "epoch 33; iter: 400; batch classifier loss: 0.474521; batch adversarial loss: 0.488403\n",
      "epoch 33; iter: 600; batch classifier loss: 0.498953; batch adversarial loss: 0.544999\n",
      "epoch 34; iter: 0; batch classifier loss: 0.477848; batch adversarial loss: 0.518946\n",
      "epoch 34; iter: 200; batch classifier loss: 0.455542; batch adversarial loss: 0.404375\n",
      "epoch 34; iter: 400; batch classifier loss: 0.610337; batch adversarial loss: 0.404462\n",
      "epoch 34; iter: 600; batch classifier loss: 0.567406; batch adversarial loss: 0.559658\n",
      "epoch 35; iter: 0; batch classifier loss: 0.497292; batch adversarial loss: 0.317999\n",
      "epoch 35; iter: 200; batch classifier loss: 0.506393; batch adversarial loss: 0.510599\n",
      "epoch 35; iter: 400; batch classifier loss: 0.530984; batch adversarial loss: 0.461620\n",
      "epoch 35; iter: 600; batch classifier loss: 0.687342; batch adversarial loss: 0.427193\n",
      "epoch 36; iter: 0; batch classifier loss: 0.573286; batch adversarial loss: 0.428663\n",
      "epoch 36; iter: 200; batch classifier loss: 0.418459; batch adversarial loss: 0.404413\n",
      "epoch 36; iter: 400; batch classifier loss: 0.607248; batch adversarial loss: 0.435388\n",
      "epoch 36; iter: 600; batch classifier loss: 0.551766; batch adversarial loss: 0.373970\n",
      "epoch 37; iter: 0; batch classifier loss: 0.568261; batch adversarial loss: 0.296167\n",
      "epoch 37; iter: 200; batch classifier loss: 0.315528; batch adversarial loss: 0.430366\n",
      "epoch 37; iter: 400; batch classifier loss: 0.711077; batch adversarial loss: 0.401800\n",
      "epoch 37; iter: 600; batch classifier loss: 0.712300; batch adversarial loss: 0.408388\n",
      "epoch 38; iter: 0; batch classifier loss: 0.755278; batch adversarial loss: 0.346175\n",
      "epoch 38; iter: 200; batch classifier loss: 0.581073; batch adversarial loss: 0.298086\n",
      "epoch 38; iter: 400; batch classifier loss: 0.701288; batch adversarial loss: 0.210447\n",
      "epoch 38; iter: 600; batch classifier loss: 0.854996; batch adversarial loss: 0.240726\n",
      "epoch 39; iter: 0; batch classifier loss: 0.877808; batch adversarial loss: 0.377551\n",
      "epoch 39; iter: 200; batch classifier loss: 0.918831; batch adversarial loss: 0.357376\n",
      "epoch 39; iter: 400; batch classifier loss: 0.522521; batch adversarial loss: 0.400517\n",
      "epoch 39; iter: 600; batch classifier loss: 0.481262; batch adversarial loss: 0.400468\n",
      "epoch 40; iter: 0; batch classifier loss: 0.793822; batch adversarial loss: 0.404131\n",
      "epoch 40; iter: 200; batch classifier loss: 0.583557; batch adversarial loss: 0.460701\n",
      "epoch 40; iter: 400; batch classifier loss: 0.824986; batch adversarial loss: 0.353555\n",
      "epoch 40; iter: 600; batch classifier loss: 0.391028; batch adversarial loss: 0.428706\n",
      "epoch 41; iter: 0; batch classifier loss: 0.519824; batch adversarial loss: 0.430252\n",
      "epoch 41; iter: 200; batch classifier loss: 0.645091; batch adversarial loss: 0.346255\n",
      "epoch 41; iter: 400; batch classifier loss: 0.626198; batch adversarial loss: 0.373063\n",
      "epoch 41; iter: 600; batch classifier loss: 0.700461; batch adversarial loss: 0.373483\n",
      "epoch 42; iter: 0; batch classifier loss: 0.467312; batch adversarial loss: 0.409148\n",
      "epoch 42; iter: 200; batch classifier loss: 0.856236; batch adversarial loss: 0.433587\n",
      "epoch 42; iter: 400; batch classifier loss: 0.477837; batch adversarial loss: 0.488589\n",
      "epoch 42; iter: 600; batch classifier loss: 0.615651; batch adversarial loss: 0.371493\n",
      "epoch 43; iter: 0; batch classifier loss: 0.692147; batch adversarial loss: 0.509514\n",
      "epoch 43; iter: 200; batch classifier loss: 0.759068; batch adversarial loss: 0.379487\n",
      "epoch 43; iter: 400; batch classifier loss: 0.617124; batch adversarial loss: 0.426009\n",
      "epoch 43; iter: 600; batch classifier loss: 0.325198; batch adversarial loss: 0.516418\n",
      "epoch 44; iter: 0; batch classifier loss: 0.680798; batch adversarial loss: 0.496248\n",
      "epoch 44; iter: 200; batch classifier loss: 0.398400; batch adversarial loss: 0.347573\n",
      "epoch 44; iter: 400; batch classifier loss: 0.795992; batch adversarial loss: 0.351677\n",
      "epoch 44; iter: 600; batch classifier loss: 0.904193; batch adversarial loss: 0.493890\n",
      "epoch 45; iter: 0; batch classifier loss: 0.472182; batch adversarial loss: 0.401186\n",
      "epoch 45; iter: 200; batch classifier loss: 0.511205; batch adversarial loss: 0.321367\n",
      "epoch 45; iter: 400; batch classifier loss: 0.667587; batch adversarial loss: 0.349439\n",
      "epoch 45; iter: 600; batch classifier loss: 0.609865; batch adversarial loss: 0.377912\n",
      "epoch 46; iter: 0; batch classifier loss: 0.653154; batch adversarial loss: 0.408608\n",
      "epoch 46; iter: 200; batch classifier loss: 0.686922; batch adversarial loss: 0.324033\n",
      "epoch 46; iter: 400; batch classifier loss: 0.463749; batch adversarial loss: 0.482235\n",
      "epoch 46; iter: 600; batch classifier loss: 0.600049; batch adversarial loss: 0.325236\n",
      "epoch 47; iter: 0; batch classifier loss: 0.553492; batch adversarial loss: 0.354736\n",
      "epoch 47; iter: 200; batch classifier loss: 0.747874; batch adversarial loss: 0.427928\n",
      "epoch 47; iter: 400; batch classifier loss: 0.591512; batch adversarial loss: 0.299490\n",
      "epoch 47; iter: 600; batch classifier loss: 0.510762; batch adversarial loss: 0.511913\n",
      "epoch 48; iter: 0; batch classifier loss: 0.585795; batch adversarial loss: 0.457025\n",
      "epoch 48; iter: 200; batch classifier loss: 0.758682; batch adversarial loss: 0.322029\n",
      "epoch 48; iter: 400; batch classifier loss: 0.656923; batch adversarial loss: 0.292640\n",
      "epoch 48; iter: 600; batch classifier loss: 0.479625; batch adversarial loss: 0.354299\n",
      "epoch 49; iter: 0; batch classifier loss: 0.591941; batch adversarial loss: 0.404013\n",
      "epoch 49; iter: 200; batch classifier loss: 0.640349; batch adversarial loss: 0.157484\n",
      "epoch 49; iter: 400; batch classifier loss: 0.466705; batch adversarial loss: 0.486596\n",
      "epoch 49; iter: 600; batch classifier loss: 0.657182; batch adversarial loss: 0.676894\n",
      "epoch 0; iter: 0; batch classifier loss: 50.247467; batch adversarial loss: 0.884246\n",
      "epoch 0; iter: 200; batch classifier loss: 9.310294; batch adversarial loss: 0.938458\n",
      "epoch 0; iter: 400; batch classifier loss: 5.427210; batch adversarial loss: 0.775062\n",
      "epoch 0; iter: 600; batch classifier loss: 6.298917; batch adversarial loss: 0.608092\n",
      "epoch 1; iter: 0; batch classifier loss: 5.383246; batch adversarial loss: 0.601524\n",
      "epoch 1; iter: 200; batch classifier loss: 4.175486; batch adversarial loss: 0.518982\n",
      "epoch 1; iter: 400; batch classifier loss: 6.239390; batch adversarial loss: 0.524326\n",
      "epoch 1; iter: 600; batch classifier loss: 1.095972; batch adversarial loss: 0.399425\n",
      "epoch 2; iter: 0; batch classifier loss: 4.908919; batch adversarial loss: 0.446665\n",
      "epoch 2; iter: 200; batch classifier loss: 3.348960; batch adversarial loss: 0.486898\n",
      "epoch 2; iter: 400; batch classifier loss: 11.815012; batch adversarial loss: 0.416216\n",
      "epoch 2; iter: 600; batch classifier loss: 3.816827; batch adversarial loss: 0.479975\n",
      "epoch 3; iter: 0; batch classifier loss: 0.964059; batch adversarial loss: 0.387864\n",
      "epoch 3; iter: 200; batch classifier loss: 0.777818; batch adversarial loss: 0.368320\n",
      "epoch 3; iter: 400; batch classifier loss: 5.850355; batch adversarial loss: 0.375817\n",
      "epoch 3; iter: 600; batch classifier loss: 2.036452; batch adversarial loss: 0.419518\n",
      "epoch 4; iter: 0; batch classifier loss: 1.083793; batch adversarial loss: 0.325212\n",
      "epoch 4; iter: 200; batch classifier loss: 1.216181; batch adversarial loss: 0.473912\n",
      "epoch 4; iter: 400; batch classifier loss: 1.085908; batch adversarial loss: 0.523149\n",
      "epoch 4; iter: 600; batch classifier loss: 0.794937; batch adversarial loss: 0.534404\n",
      "epoch 5; iter: 0; batch classifier loss: 1.023386; batch adversarial loss: 0.411381\n",
      "epoch 5; iter: 200; batch classifier loss: 0.811981; batch adversarial loss: 0.249925\n",
      "epoch 5; iter: 400; batch classifier loss: 1.407389; batch adversarial loss: 0.421311\n",
      "epoch 5; iter: 600; batch classifier loss: 0.429308; batch adversarial loss: 0.528715\n",
      "epoch 6; iter: 0; batch classifier loss: 0.461030; batch adversarial loss: 0.514305\n",
      "epoch 6; iter: 200; batch classifier loss: 0.484016; batch adversarial loss: 0.416796\n",
      "epoch 6; iter: 400; batch classifier loss: 0.541506; batch adversarial loss: 0.467750\n",
      "epoch 6; iter: 600; batch classifier loss: 0.339844; batch adversarial loss: 0.241356\n",
      "epoch 7; iter: 0; batch classifier loss: 0.440846; batch adversarial loss: 0.472054\n",
      "epoch 7; iter: 200; batch classifier loss: 0.363987; batch adversarial loss: 0.414980\n",
      "epoch 7; iter: 400; batch classifier loss: 0.352490; batch adversarial loss: 0.321729\n",
      "epoch 7; iter: 600; batch classifier loss: 0.598585; batch adversarial loss: 0.332623\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489613; batch adversarial loss: 0.457179\n",
      "epoch 8; iter: 200; batch classifier loss: 0.327350; batch adversarial loss: 0.432245\n",
      "epoch 8; iter: 400; batch classifier loss: 0.461052; batch adversarial loss: 0.264235\n",
      "epoch 8; iter: 600; batch classifier loss: 0.481518; batch adversarial loss: 0.407073\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335011; batch adversarial loss: 0.510657\n",
      "epoch 9; iter: 200; batch classifier loss: 0.318103; batch adversarial loss: 0.288946\n",
      "epoch 9; iter: 400; batch classifier loss: 0.385100; batch adversarial loss: 0.373233\n",
      "epoch 9; iter: 600; batch classifier loss: 0.377943; batch adversarial loss: 0.364989\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388759; batch adversarial loss: 0.276933\n",
      "epoch 10; iter: 200; batch classifier loss: 0.355573; batch adversarial loss: 0.338485\n",
      "epoch 10; iter: 400; batch classifier loss: 0.518524; batch adversarial loss: 0.393459\n",
      "epoch 10; iter: 600; batch classifier loss: 0.293165; batch adversarial loss: 0.534677\n",
      "epoch 11; iter: 0; batch classifier loss: 0.233374; batch adversarial loss: 0.512268\n",
      "epoch 11; iter: 200; batch classifier loss: 0.441197; batch adversarial loss: 0.576825\n",
      "epoch 11; iter: 400; batch classifier loss: 0.331716; batch adversarial loss: 0.496125\n",
      "epoch 11; iter: 600; batch classifier loss: 0.357039; batch adversarial loss: 0.299005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.545410; batch adversarial loss: 0.413671\n",
      "epoch 12; iter: 200; batch classifier loss: 0.473413; batch adversarial loss: 0.323698\n",
      "epoch 12; iter: 400; batch classifier loss: 0.259038; batch adversarial loss: 0.379238\n",
      "epoch 12; iter: 600; batch classifier loss: 0.337073; batch adversarial loss: 0.359114\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302014; batch adversarial loss: 0.434555\n",
      "epoch 13; iter: 200; batch classifier loss: 0.259646; batch adversarial loss: 0.453701\n",
      "epoch 13; iter: 400; batch classifier loss: 0.363799; batch adversarial loss: 0.461144\n",
      "epoch 13; iter: 600; batch classifier loss: 0.369325; batch adversarial loss: 0.330696\n",
      "epoch 14; iter: 0; batch classifier loss: 0.274357; batch adversarial loss: 0.372062\n",
      "epoch 14; iter: 200; batch classifier loss: 0.281697; batch adversarial loss: 0.405392\n",
      "epoch 14; iter: 400; batch classifier loss: 0.462793; batch adversarial loss: 0.451970\n",
      "epoch 14; iter: 600; batch classifier loss: 0.507266; batch adversarial loss: 0.345194\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349676; batch adversarial loss: 0.398588\n",
      "epoch 15; iter: 200; batch classifier loss: 0.321538; batch adversarial loss: 0.330934\n",
      "epoch 15; iter: 400; batch classifier loss: 0.331420; batch adversarial loss: 0.353409\n",
      "epoch 15; iter: 600; batch classifier loss: 0.280161; batch adversarial loss: 0.517369\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404678; batch adversarial loss: 0.404413\n",
      "epoch 16; iter: 200; batch classifier loss: 0.402291; batch adversarial loss: 0.475984\n",
      "epoch 16; iter: 400; batch classifier loss: 0.496597; batch adversarial loss: 0.446011\n",
      "epoch 16; iter: 600; batch classifier loss: 0.266772; batch adversarial loss: 0.431458\n",
      "epoch 17; iter: 0; batch classifier loss: 0.402593; batch adversarial loss: 0.541788\n",
      "epoch 17; iter: 200; batch classifier loss: 0.452906; batch adversarial loss: 0.332558\n",
      "epoch 17; iter: 400; batch classifier loss: 0.401059; batch adversarial loss: 0.375911\n",
      "epoch 17; iter: 600; batch classifier loss: 0.326475; batch adversarial loss: 0.487736\n",
      "epoch 18; iter: 0; batch classifier loss: 0.305180; batch adversarial loss: 0.402065\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382404; batch adversarial loss: 0.604029\n",
      "epoch 18; iter: 400; batch classifier loss: 1.308684; batch adversarial loss: 0.573018\n",
      "epoch 18; iter: 600; batch classifier loss: 0.298761; batch adversarial loss: 0.561744\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376309; batch adversarial loss: 0.405472\n",
      "epoch 19; iter: 200; batch classifier loss: 0.402065; batch adversarial loss: 0.397126\n",
      "epoch 19; iter: 400; batch classifier loss: 0.255967; batch adversarial loss: 0.369071\n",
      "epoch 19; iter: 600; batch classifier loss: 0.406266; batch adversarial loss: 0.329660\n",
      "epoch 20; iter: 0; batch classifier loss: 0.445125; batch adversarial loss: 0.353184\n",
      "epoch 20; iter: 200; batch classifier loss: 0.336108; batch adversarial loss: 0.482689\n",
      "epoch 20; iter: 400; batch classifier loss: 0.374663; batch adversarial loss: 0.571296\n",
      "epoch 20; iter: 600; batch classifier loss: 0.476760; batch adversarial loss: 0.518358\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338287; batch adversarial loss: 0.419627\n",
      "epoch 21; iter: 200; batch classifier loss: 0.436103; batch adversarial loss: 0.338299\n",
      "epoch 21; iter: 400; batch classifier loss: 0.443113; batch adversarial loss: 0.396995\n",
      "epoch 21; iter: 600; batch classifier loss: 0.479431; batch adversarial loss: 0.369327\n",
      "epoch 22; iter: 0; batch classifier loss: 0.244469; batch adversarial loss: 0.303837\n",
      "epoch 22; iter: 200; batch classifier loss: 0.376731; batch adversarial loss: 0.434473\n",
      "epoch 22; iter: 400; batch classifier loss: 0.501730; batch adversarial loss: 0.400075\n",
      "epoch 22; iter: 600; batch classifier loss: 0.441924; batch adversarial loss: 0.373353\n",
      "epoch 23; iter: 0; batch classifier loss: 0.413112; batch adversarial loss: 0.472747\n",
      "epoch 23; iter: 200; batch classifier loss: 0.410923; batch adversarial loss: 0.537423\n",
      "epoch 23; iter: 400; batch classifier loss: 0.305792; batch adversarial loss: 0.406384\n",
      "epoch 23; iter: 600; batch classifier loss: 0.253772; batch adversarial loss: 0.423212\n",
      "epoch 24; iter: 0; batch classifier loss: 0.394495; batch adversarial loss: 0.380752\n",
      "epoch 24; iter: 200; batch classifier loss: 0.359011; batch adversarial loss: 0.510600\n",
      "epoch 24; iter: 400; batch classifier loss: 0.460963; batch adversarial loss: 0.478131\n",
      "epoch 24; iter: 600; batch classifier loss: 0.537105; batch adversarial loss: 0.456905\n",
      "epoch 25; iter: 0; batch classifier loss: 0.355511; batch adversarial loss: 0.454926\n",
      "epoch 25; iter: 200; batch classifier loss: 0.339071; batch adversarial loss: 0.453251\n",
      "epoch 25; iter: 400; batch classifier loss: 0.567711; batch adversarial loss: 0.315585\n",
      "epoch 25; iter: 600; batch classifier loss: 0.434480; batch adversarial loss: 0.478813\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432412; batch adversarial loss: 0.300822\n",
      "epoch 26; iter: 200; batch classifier loss: 0.391619; batch adversarial loss: 0.381307\n",
      "epoch 26; iter: 400; batch classifier loss: 0.262240; batch adversarial loss: 0.318588\n",
      "epoch 26; iter: 600; batch classifier loss: 0.413773; batch adversarial loss: 0.547392\n",
      "epoch 27; iter: 0; batch classifier loss: 0.346382; batch adversarial loss: 0.342059\n",
      "epoch 27; iter: 200; batch classifier loss: 0.477172; batch adversarial loss: 0.345231\n",
      "epoch 27; iter: 400; batch classifier loss: 0.430990; batch adversarial loss: 0.455754\n",
      "epoch 27; iter: 600; batch classifier loss: 0.452471; batch adversarial loss: 0.376120\n",
      "epoch 28; iter: 0; batch classifier loss: 0.388801; batch adversarial loss: 0.506508\n",
      "epoch 28; iter: 200; batch classifier loss: 0.484280; batch adversarial loss: 0.527067\n",
      "epoch 28; iter: 400; batch classifier loss: 0.515410; batch adversarial loss: 0.408648\n",
      "epoch 28; iter: 600; batch classifier loss: 0.390075; batch adversarial loss: 0.429643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.532383; batch adversarial loss: 0.394450\n",
      "epoch 29; iter: 200; batch classifier loss: 0.386539; batch adversarial loss: 0.408452\n",
      "epoch 29; iter: 400; batch classifier loss: 0.384373; batch adversarial loss: 0.400133\n",
      "epoch 29; iter: 600; batch classifier loss: 0.430973; batch adversarial loss: 0.419747\n",
      "epoch 30; iter: 0; batch classifier loss: 0.595040; batch adversarial loss: 0.318640\n",
      "epoch 30; iter: 200; batch classifier loss: 0.453681; batch adversarial loss: 0.492124\n",
      "epoch 30; iter: 400; batch classifier loss: 0.392769; batch adversarial loss: 0.603447\n",
      "epoch 30; iter: 600; batch classifier loss: 0.522528; batch adversarial loss: 0.292532\n",
      "epoch 31; iter: 0; batch classifier loss: 0.623402; batch adversarial loss: 0.591317\n",
      "epoch 31; iter: 200; batch classifier loss: 0.479306; batch adversarial loss: 0.460962\n",
      "epoch 31; iter: 400; batch classifier loss: 0.537317; batch adversarial loss: 0.496172\n",
      "epoch 31; iter: 600; batch classifier loss: 0.327078; batch adversarial loss: 0.483957\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443766; batch adversarial loss: 0.436662\n",
      "epoch 32; iter: 200; batch classifier loss: 0.725649; batch adversarial loss: 0.348033\n",
      "epoch 32; iter: 400; batch classifier loss: 0.580711; batch adversarial loss: 0.384306\n",
      "epoch 32; iter: 600; batch classifier loss: 0.355635; batch adversarial loss: 0.606722\n",
      "epoch 33; iter: 0; batch classifier loss: 0.417158; batch adversarial loss: 0.379350\n",
      "epoch 33; iter: 200; batch classifier loss: 0.412714; batch adversarial loss: 0.378055\n",
      "epoch 33; iter: 400; batch classifier loss: 0.472917; batch adversarial loss: 0.573095\n",
      "epoch 33; iter: 600; batch classifier loss: 0.521057; batch adversarial loss: 0.353181\n",
      "epoch 34; iter: 0; batch classifier loss: 0.512968; batch adversarial loss: 0.481311\n",
      "epoch 34; iter: 200; batch classifier loss: 0.561409; batch adversarial loss: 0.324128\n",
      "epoch 34; iter: 400; batch classifier loss: 0.513258; batch adversarial loss: 0.333560\n",
      "epoch 34; iter: 600; batch classifier loss: 0.418333; batch adversarial loss: 0.406200\n",
      "epoch 35; iter: 0; batch classifier loss: 0.537532; batch adversarial loss: 0.377639\n",
      "epoch 35; iter: 200; batch classifier loss: 0.390095; batch adversarial loss: 0.464014\n",
      "epoch 35; iter: 400; batch classifier loss: 0.519478; batch adversarial loss: 0.436285\n",
      "epoch 35; iter: 600; batch classifier loss: 0.501132; batch adversarial loss: 0.431330\n",
      "epoch 36; iter: 0; batch classifier loss: 0.217768; batch adversarial loss: 0.371810\n",
      "epoch 36; iter: 200; batch classifier loss: 0.444931; batch adversarial loss: 0.320859\n",
      "epoch 36; iter: 400; batch classifier loss: 0.372839; batch adversarial loss: 0.370445\n",
      "epoch 36; iter: 600; batch classifier loss: 0.847007; batch adversarial loss: 0.290305\n",
      "epoch 37; iter: 0; batch classifier loss: 0.649214; batch adversarial loss: 0.293285\n",
      "epoch 37; iter: 200; batch classifier loss: 0.519457; batch adversarial loss: 0.372213\n",
      "epoch 37; iter: 400; batch classifier loss: 0.425263; batch adversarial loss: 0.271579\n",
      "epoch 37; iter: 600; batch classifier loss: 0.357345; batch adversarial loss: 0.408226\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400534; batch adversarial loss: 0.410002\n",
      "epoch 38; iter: 200; batch classifier loss: 0.405587; batch adversarial loss: 0.400864\n",
      "epoch 38; iter: 400; batch classifier loss: 0.545832; batch adversarial loss: 0.321133\n",
      "epoch 38; iter: 600; batch classifier loss: 0.540192; batch adversarial loss: 0.433010\n",
      "epoch 39; iter: 0; batch classifier loss: 0.611718; batch adversarial loss: 0.293334\n",
      "epoch 39; iter: 200; batch classifier loss: 0.706371; batch adversarial loss: 0.429076\n",
      "epoch 39; iter: 400; batch classifier loss: 0.526359; batch adversarial loss: 0.408432\n",
      "epoch 39; iter: 600; batch classifier loss: 0.699744; batch adversarial loss: 0.374304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436079; batch adversarial loss: 0.349693\n",
      "epoch 40; iter: 200; batch classifier loss: 0.820500; batch adversarial loss: 0.576871\n",
      "epoch 40; iter: 400; batch classifier loss: 0.610849; batch adversarial loss: 0.464666\n",
      "epoch 40; iter: 600; batch classifier loss: 0.601565; batch adversarial loss: 0.455001\n",
      "epoch 41; iter: 0; batch classifier loss: 0.617684; batch adversarial loss: 0.466515\n",
      "epoch 41; iter: 200; batch classifier loss: 0.528496; batch adversarial loss: 0.519225\n",
      "epoch 41; iter: 400; batch classifier loss: 0.457029; batch adversarial loss: 0.457575\n",
      "epoch 41; iter: 600; batch classifier loss: 0.519474; batch adversarial loss: 0.466621\n",
      "epoch 42; iter: 0; batch classifier loss: 0.466423; batch adversarial loss: 0.236561\n",
      "epoch 42; iter: 200; batch classifier loss: 0.409626; batch adversarial loss: 0.409581\n",
      "epoch 42; iter: 400; batch classifier loss: 0.522279; batch adversarial loss: 0.470029\n",
      "epoch 42; iter: 600; batch classifier loss: 0.339917; batch adversarial loss: 0.349495\n",
      "epoch 43; iter: 0; batch classifier loss: 0.565382; batch adversarial loss: 0.465562\n",
      "epoch 43; iter: 200; batch classifier loss: 0.596113; batch adversarial loss: 0.510036\n",
      "epoch 43; iter: 400; batch classifier loss: 0.533351; batch adversarial loss: 0.537178\n",
      "epoch 43; iter: 600; batch classifier loss: 0.779703; batch adversarial loss: 0.455286\n",
      "epoch 44; iter: 0; batch classifier loss: 0.703334; batch adversarial loss: 0.432251\n",
      "epoch 44; iter: 200; batch classifier loss: 0.744595; batch adversarial loss: 0.427920\n",
      "epoch 44; iter: 400; batch classifier loss: 0.655318; batch adversarial loss: 0.481167\n",
      "epoch 44; iter: 600; batch classifier loss: 0.681314; batch adversarial loss: 0.482998\n",
      "epoch 45; iter: 0; batch classifier loss: 0.593356; batch adversarial loss: 0.291305\n",
      "epoch 45; iter: 200; batch classifier loss: 0.555384; batch adversarial loss: 0.375675\n",
      "epoch 45; iter: 400; batch classifier loss: 0.470175; batch adversarial loss: 0.456251\n",
      "epoch 45; iter: 600; batch classifier loss: 0.540212; batch adversarial loss: 0.437795\n",
      "epoch 46; iter: 0; batch classifier loss: 0.592872; batch adversarial loss: 0.399841\n",
      "epoch 46; iter: 200; batch classifier loss: 0.330019; batch adversarial loss: 0.511334\n",
      "epoch 46; iter: 400; batch classifier loss: 0.631863; batch adversarial loss: 0.620515\n",
      "epoch 46; iter: 600; batch classifier loss: 0.760589; batch adversarial loss: 0.434118\n",
      "epoch 47; iter: 0; batch classifier loss: 0.574833; batch adversarial loss: 0.376119\n",
      "epoch 47; iter: 200; batch classifier loss: 0.397314; batch adversarial loss: 0.434952\n",
      "epoch 47; iter: 400; batch classifier loss: 0.619034; batch adversarial loss: 0.320487\n",
      "epoch 47; iter: 600; batch classifier loss: 0.657388; batch adversarial loss: 0.238758\n",
      "epoch 48; iter: 0; batch classifier loss: 0.451441; batch adversarial loss: 0.458122\n",
      "epoch 48; iter: 200; batch classifier loss: 0.736113; batch adversarial loss: 0.409356\n",
      "epoch 48; iter: 400; batch classifier loss: 0.270815; batch adversarial loss: 0.435733\n",
      "epoch 48; iter: 600; batch classifier loss: 0.732659; batch adversarial loss: 0.374200\n",
      "epoch 49; iter: 0; batch classifier loss: 0.349388; batch adversarial loss: 0.456120\n",
      "epoch 49; iter: 200; batch classifier loss: 0.750830; batch adversarial loss: 0.320117\n",
      "epoch 49; iter: 400; batch classifier loss: 0.745908; batch adversarial loss: 0.329105\n",
      "epoch 49; iter: 600; batch classifier loss: 0.523775; batch adversarial loss: 0.573036\n",
      "epoch 0; iter: 0; batch classifier loss: 19.017969; batch adversarial loss: 0.567402\n",
      "epoch 0; iter: 200; batch classifier loss: 10.349988; batch adversarial loss: 0.533214\n",
      "epoch 0; iter: 400; batch classifier loss: 7.579627; batch adversarial loss: 0.582204\n",
      "epoch 0; iter: 600; batch classifier loss: 0.926701; batch adversarial loss: 0.526697\n",
      "epoch 1; iter: 0; batch classifier loss: 8.194132; batch adversarial loss: 0.462190\n",
      "epoch 1; iter: 200; batch classifier loss: 2.243687; batch adversarial loss: 0.478810\n",
      "epoch 1; iter: 400; batch classifier loss: 12.149619; batch adversarial loss: 0.404207\n",
      "epoch 1; iter: 600; batch classifier loss: 4.725077; batch adversarial loss: 0.549707\n",
      "epoch 2; iter: 0; batch classifier loss: 1.725972; batch adversarial loss: 0.395919\n",
      "epoch 2; iter: 200; batch classifier loss: 3.034485; batch adversarial loss: 0.474556\n",
      "epoch 2; iter: 400; batch classifier loss: 5.139003; batch adversarial loss: 0.535826\n",
      "epoch 2; iter: 600; batch classifier loss: 2.941993; batch adversarial loss: 0.408186\n",
      "epoch 3; iter: 0; batch classifier loss: 4.806442; batch adversarial loss: 0.345624\n",
      "epoch 3; iter: 200; batch classifier loss: 1.377428; batch adversarial loss: 0.545483\n",
      "epoch 3; iter: 400; batch classifier loss: 0.461836; batch adversarial loss: 0.440854\n",
      "epoch 3; iter: 600; batch classifier loss: 0.501757; batch adversarial loss: 0.507307\n",
      "epoch 4; iter: 0; batch classifier loss: 3.018850; batch adversarial loss: 0.476352\n",
      "epoch 4; iter: 200; batch classifier loss: 0.851397; batch adversarial loss: 0.465883\n",
      "epoch 4; iter: 400; batch classifier loss: 0.569933; batch adversarial loss: 0.308313\n",
      "epoch 4; iter: 600; batch classifier loss: 0.580031; batch adversarial loss: 0.443761\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521647; batch adversarial loss: 0.385139\n",
      "epoch 5; iter: 200; batch classifier loss: 0.354759; batch adversarial loss: 0.345840\n",
      "epoch 5; iter: 400; batch classifier loss: 0.420763; batch adversarial loss: 0.439004\n",
      "epoch 5; iter: 600; batch classifier loss: 2.701092; batch adversarial loss: 0.428392\n",
      "epoch 6; iter: 0; batch classifier loss: 0.701755; batch adversarial loss: 0.384650\n",
      "epoch 6; iter: 200; batch classifier loss: 0.527619; batch adversarial loss: 0.366991\n",
      "epoch 6; iter: 400; batch classifier loss: 0.417606; batch adversarial loss: 0.426087\n",
      "epoch 6; iter: 600; batch classifier loss: 0.418944; batch adversarial loss: 0.294353\n",
      "epoch 7; iter: 0; batch classifier loss: 0.301305; batch adversarial loss: 0.479908\n",
      "epoch 7; iter: 200; batch classifier loss: 0.593679; batch adversarial loss: 0.293939\n",
      "epoch 7; iter: 400; batch classifier loss: 0.459195; batch adversarial loss: 0.395367\n",
      "epoch 7; iter: 600; batch classifier loss: 0.591477; batch adversarial loss: 0.439146\n",
      "epoch 8; iter: 0; batch classifier loss: 0.753634; batch adversarial loss: 0.484644\n",
      "epoch 8; iter: 200; batch classifier loss: 0.433688; batch adversarial loss: 0.295148\n",
      "epoch 8; iter: 400; batch classifier loss: 0.452163; batch adversarial loss: 0.475949\n",
      "epoch 8; iter: 600; batch classifier loss: 0.367316; batch adversarial loss: 0.430419\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480849; batch adversarial loss: 0.452563\n",
      "epoch 9; iter: 200; batch classifier loss: 0.261773; batch adversarial loss: 0.463211\n",
      "epoch 9; iter: 400; batch classifier loss: 0.412934; batch adversarial loss: 0.370379\n",
      "epoch 9; iter: 600; batch classifier loss: 0.315641; batch adversarial loss: 0.405763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307587; batch adversarial loss: 0.489370\n",
      "epoch 10; iter: 200; batch classifier loss: 0.353858; batch adversarial loss: 0.341891\n",
      "epoch 10; iter: 400; batch classifier loss: 0.493027; batch adversarial loss: 0.355416\n",
      "epoch 10; iter: 600; batch classifier loss: 0.477896; batch adversarial loss: 0.487213\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345581; batch adversarial loss: 0.371070\n",
      "epoch 11; iter: 200; batch classifier loss: 0.462029; batch adversarial loss: 0.268703\n",
      "epoch 11; iter: 400; batch classifier loss: 0.157171; batch adversarial loss: 0.466820\n",
      "epoch 11; iter: 600; batch classifier loss: 0.287777; batch adversarial loss: 0.370847\n",
      "epoch 12; iter: 0; batch classifier loss: 0.336034; batch adversarial loss: 0.477174\n",
      "epoch 12; iter: 200; batch classifier loss: 0.320130; batch adversarial loss: 0.349310\n",
      "epoch 12; iter: 400; batch classifier loss: 0.286592; batch adversarial loss: 0.374786\n",
      "epoch 12; iter: 600; batch classifier loss: 0.327609; batch adversarial loss: 0.480612\n",
      "epoch 13; iter: 0; batch classifier loss: 0.282906; batch adversarial loss: 0.427105\n",
      "epoch 13; iter: 200; batch classifier loss: 0.362575; batch adversarial loss: 0.339542\n",
      "epoch 13; iter: 400; batch classifier loss: 0.349738; batch adversarial loss: 0.557921\n",
      "epoch 13; iter: 600; batch classifier loss: 0.391849; batch adversarial loss: 0.365846\n",
      "epoch 14; iter: 0; batch classifier loss: 0.398871; batch adversarial loss: 0.267801\n",
      "epoch 14; iter: 200; batch classifier loss: 0.308030; batch adversarial loss: 0.290201\n",
      "epoch 14; iter: 400; batch classifier loss: 0.320030; batch adversarial loss: 0.344716\n",
      "epoch 14; iter: 600; batch classifier loss: 0.346003; batch adversarial loss: 0.397880\n",
      "epoch 15; iter: 0; batch classifier loss: 0.450479; batch adversarial loss: 0.501593\n",
      "epoch 15; iter: 200; batch classifier loss: 0.297946; batch adversarial loss: 0.342559\n",
      "epoch 15; iter: 400; batch classifier loss: 0.317204; batch adversarial loss: 0.503758\n",
      "epoch 15; iter: 600; batch classifier loss: 0.266843; batch adversarial loss: 0.452538\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387083; batch adversarial loss: 0.375607\n",
      "epoch 16; iter: 200; batch classifier loss: 0.359648; batch adversarial loss: 0.548065\n",
      "epoch 16; iter: 400; batch classifier loss: 0.489973; batch adversarial loss: 0.363517\n",
      "epoch 16; iter: 600; batch classifier loss: 0.407965; batch adversarial loss: 0.472840\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451132; batch adversarial loss: 0.380780\n",
      "epoch 17; iter: 200; batch classifier loss: 0.378387; batch adversarial loss: 0.379730\n",
      "epoch 17; iter: 400; batch classifier loss: 0.496685; batch adversarial loss: 0.275753\n",
      "epoch 17; iter: 600; batch classifier loss: 0.309453; batch adversarial loss: 0.430379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.447644; batch adversarial loss: 0.459224\n",
      "epoch 18; iter: 200; batch classifier loss: 0.375126; batch adversarial loss: 0.518234\n",
      "epoch 18; iter: 400; batch classifier loss: 0.577941; batch adversarial loss: 0.491560\n",
      "epoch 18; iter: 600; batch classifier loss: 0.452283; batch adversarial loss: 0.459324\n",
      "epoch 19; iter: 0; batch classifier loss: 0.431848; batch adversarial loss: 0.294858\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342492; batch adversarial loss: 0.344989\n",
      "epoch 19; iter: 400; batch classifier loss: 0.460849; batch adversarial loss: 0.492911\n",
      "epoch 19; iter: 600; batch classifier loss: 0.421637; batch adversarial loss: 0.371957\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324566; batch adversarial loss: 0.327622\n",
      "epoch 20; iter: 200; batch classifier loss: 0.504123; batch adversarial loss: 0.403556\n",
      "epoch 20; iter: 400; batch classifier loss: 0.325391; batch adversarial loss: 0.412917\n",
      "epoch 20; iter: 600; batch classifier loss: 0.527775; batch adversarial loss: 0.293738\n",
      "epoch 21; iter: 0; batch classifier loss: 0.587454; batch adversarial loss: 0.542789\n",
      "epoch 21; iter: 200; batch classifier loss: 0.353031; batch adversarial loss: 0.354572\n",
      "epoch 21; iter: 400; batch classifier loss: 0.331012; batch adversarial loss: 0.568476\n",
      "epoch 21; iter: 600; batch classifier loss: 0.451899; batch adversarial loss: 0.238855\n",
      "epoch 22; iter: 0; batch classifier loss: 0.318068; batch adversarial loss: 0.507731\n",
      "epoch 22; iter: 200; batch classifier loss: 0.465413; batch adversarial loss: 0.492314\n",
      "epoch 22; iter: 400; batch classifier loss: 0.291316; batch adversarial loss: 0.492667\n",
      "epoch 22; iter: 600; batch classifier loss: 0.350356; batch adversarial loss: 0.364787\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504191; batch adversarial loss: 0.460437\n",
      "epoch 23; iter: 200; batch classifier loss: 0.624178; batch adversarial loss: 0.363711\n",
      "epoch 23; iter: 400; batch classifier loss: 0.576516; batch adversarial loss: 0.328504\n",
      "epoch 23; iter: 600; batch classifier loss: 0.460348; batch adversarial loss: 0.512469\n",
      "epoch 24; iter: 0; batch classifier loss: 0.353103; batch adversarial loss: 0.550662\n",
      "epoch 24; iter: 200; batch classifier loss: 0.332544; batch adversarial loss: 0.373768\n",
      "epoch 24; iter: 400; batch classifier loss: 0.382998; batch adversarial loss: 0.404214\n",
      "epoch 24; iter: 600; batch classifier loss: 0.364423; batch adversarial loss: 0.508397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517829; batch adversarial loss: 0.519588\n",
      "epoch 25; iter: 200; batch classifier loss: 0.438000; batch adversarial loss: 0.508841\n",
      "epoch 25; iter: 400; batch classifier loss: 0.302012; batch adversarial loss: 0.348088\n",
      "epoch 25; iter: 600; batch classifier loss: 0.444804; batch adversarial loss: 0.440067\n",
      "epoch 26; iter: 0; batch classifier loss: 0.403521; batch adversarial loss: 0.345024\n",
      "epoch 26; iter: 200; batch classifier loss: 0.405320; batch adversarial loss: 0.459093\n",
      "epoch 26; iter: 400; batch classifier loss: 0.645205; batch adversarial loss: 0.349739\n",
      "epoch 26; iter: 600; batch classifier loss: 0.473078; batch adversarial loss: 0.464728\n",
      "epoch 27; iter: 0; batch classifier loss: 0.471829; batch adversarial loss: 0.399823\n",
      "epoch 27; iter: 200; batch classifier loss: 0.913912; batch adversarial loss: 0.373911\n",
      "epoch 27; iter: 400; batch classifier loss: 0.327623; batch adversarial loss: 0.320008\n",
      "epoch 27; iter: 600; batch classifier loss: 0.432725; batch adversarial loss: 0.442675\n",
      "epoch 28; iter: 0; batch classifier loss: 0.531162; batch adversarial loss: 0.492484\n",
      "epoch 28; iter: 200; batch classifier loss: 0.644101; batch adversarial loss: 0.299841\n",
      "epoch 28; iter: 400; batch classifier loss: 0.445010; batch adversarial loss: 0.430130\n",
      "epoch 28; iter: 600; batch classifier loss: 0.410582; batch adversarial loss: 0.432022\n",
      "epoch 29; iter: 0; batch classifier loss: 0.581693; batch adversarial loss: 0.373230\n",
      "epoch 29; iter: 200; batch classifier loss: 0.517050; batch adversarial loss: 0.521710\n",
      "epoch 29; iter: 400; batch classifier loss: 0.532566; batch adversarial loss: 0.596744\n",
      "epoch 29; iter: 600; batch classifier loss: 0.515920; batch adversarial loss: 0.346770\n",
      "epoch 30; iter: 0; batch classifier loss: 0.338456; batch adversarial loss: 0.362354\n",
      "epoch 30; iter: 200; batch classifier loss: 0.402931; batch adversarial loss: 0.453196\n",
      "epoch 30; iter: 400; batch classifier loss: 0.596850; batch adversarial loss: 0.351613\n",
      "epoch 30; iter: 600; batch classifier loss: 0.599549; batch adversarial loss: 0.457348\n",
      "epoch 31; iter: 0; batch classifier loss: 0.531332; batch adversarial loss: 0.293291\n",
      "epoch 31; iter: 200; batch classifier loss: 0.438461; batch adversarial loss: 0.374770\n",
      "epoch 31; iter: 400; batch classifier loss: 0.526764; batch adversarial loss: 0.459805\n",
      "epoch 31; iter: 600; batch classifier loss: 0.494238; batch adversarial loss: 0.519401\n",
      "epoch 32; iter: 0; batch classifier loss: 0.482369; batch adversarial loss: 0.455877\n",
      "epoch 32; iter: 200; batch classifier loss: 0.566665; batch adversarial loss: 0.493174\n",
      "epoch 32; iter: 400; batch classifier loss: 0.524759; batch adversarial loss: 0.293757\n",
      "epoch 32; iter: 600; batch classifier loss: 0.362633; batch adversarial loss: 0.431496\n",
      "epoch 33; iter: 0; batch classifier loss: 0.393711; batch adversarial loss: 0.555615\n",
      "epoch 33; iter: 200; batch classifier loss: 0.531338; batch adversarial loss: 0.237615\n",
      "epoch 33; iter: 400; batch classifier loss: 0.613381; batch adversarial loss: 0.348642\n",
      "epoch 33; iter: 600; batch classifier loss: 0.370608; batch adversarial loss: 0.353752\n",
      "epoch 34; iter: 0; batch classifier loss: 0.559193; batch adversarial loss: 0.263135\n",
      "epoch 34; iter: 200; batch classifier loss: 0.328832; batch adversarial loss: 0.320803\n",
      "epoch 34; iter: 400; batch classifier loss: 0.842700; batch adversarial loss: 0.429961\n",
      "epoch 34; iter: 600; batch classifier loss: 0.437455; batch adversarial loss: 0.455145\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397208; batch adversarial loss: 0.318266\n",
      "epoch 35; iter: 200; batch classifier loss: 0.598191; batch adversarial loss: 0.518975\n",
      "epoch 35; iter: 400; batch classifier loss: 0.726633; batch adversarial loss: 0.455558\n",
      "epoch 35; iter: 600; batch classifier loss: 0.786653; batch adversarial loss: 0.404466\n",
      "epoch 36; iter: 0; batch classifier loss: 0.561445; batch adversarial loss: 0.538237\n",
      "epoch 36; iter: 200; batch classifier loss: 0.513693; batch adversarial loss: 0.521830\n",
      "epoch 36; iter: 400; batch classifier loss: 0.713698; batch adversarial loss: 0.379123\n",
      "epoch 36; iter: 600; batch classifier loss: 0.684811; batch adversarial loss: 0.492793\n",
      "epoch 37; iter: 0; batch classifier loss: 0.581629; batch adversarial loss: 0.240672\n",
      "epoch 37; iter: 200; batch classifier loss: 0.745486; batch adversarial loss: 0.436494\n",
      "epoch 37; iter: 400; batch classifier loss: 0.534082; batch adversarial loss: 0.504219\n",
      "epoch 37; iter: 600; batch classifier loss: 0.456144; batch adversarial loss: 0.652607\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389243; batch adversarial loss: 0.507557\n",
      "epoch 38; iter: 200; batch classifier loss: 0.548788; batch adversarial loss: 0.432622\n",
      "epoch 38; iter: 400; batch classifier loss: 0.479285; batch adversarial loss: 0.427671\n",
      "epoch 38; iter: 600; batch classifier loss: 0.588514; batch adversarial loss: 0.438835\n",
      "epoch 39; iter: 0; batch classifier loss: 0.582866; batch adversarial loss: 0.380215\n",
      "epoch 39; iter: 200; batch classifier loss: 0.321221; batch adversarial loss: 0.459607\n",
      "epoch 39; iter: 400; batch classifier loss: 0.424401; batch adversarial loss: 0.484389\n",
      "epoch 39; iter: 600; batch classifier loss: 0.699828; batch adversarial loss: 0.374180\n",
      "epoch 40; iter: 0; batch classifier loss: 0.741633; batch adversarial loss: 0.323153\n",
      "epoch 40; iter: 200; batch classifier loss: 0.608123; batch adversarial loss: 0.439799\n",
      "epoch 40; iter: 400; batch classifier loss: 0.758480; batch adversarial loss: 0.296552\n",
      "epoch 40; iter: 600; batch classifier loss: 0.306318; batch adversarial loss: 0.443450\n",
      "epoch 41; iter: 0; batch classifier loss: 0.670052; batch adversarial loss: 0.466293\n",
      "epoch 41; iter: 200; batch classifier loss: 0.396944; batch adversarial loss: 0.411712\n",
      "epoch 41; iter: 400; batch classifier loss: 0.558159; batch adversarial loss: 0.465254\n",
      "epoch 41; iter: 600; batch classifier loss: 0.467012; batch adversarial loss: 0.527867\n",
      "epoch 42; iter: 0; batch classifier loss: 0.483321; batch adversarial loss: 0.430987\n",
      "epoch 42; iter: 200; batch classifier loss: 0.602954; batch adversarial loss: 0.598681\n",
      "epoch 42; iter: 400; batch classifier loss: 0.902259; batch adversarial loss: 0.510397\n",
      "epoch 42; iter: 600; batch classifier loss: 0.290001; batch adversarial loss: 0.402705\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442817; batch adversarial loss: 0.321034\n",
      "epoch 43; iter: 200; batch classifier loss: 0.407679; batch adversarial loss: 0.551224\n",
      "epoch 43; iter: 400; batch classifier loss: 0.907639; batch adversarial loss: 0.374029\n",
      "epoch 43; iter: 600; batch classifier loss: 0.503438; batch adversarial loss: 0.318366\n",
      "epoch 44; iter: 0; batch classifier loss: 0.681214; batch adversarial loss: 0.487683\n",
      "epoch 44; iter: 200; batch classifier loss: 0.479663; batch adversarial loss: 0.489740\n",
      "epoch 44; iter: 400; batch classifier loss: 0.667672; batch adversarial loss: 0.370617\n",
      "epoch 44; iter: 600; batch classifier loss: 0.448951; batch adversarial loss: 0.428273\n",
      "epoch 45; iter: 0; batch classifier loss: 0.574037; batch adversarial loss: 0.428144\n",
      "epoch 45; iter: 200; batch classifier loss: 0.597066; batch adversarial loss: 0.434000\n",
      "epoch 45; iter: 400; batch classifier loss: 0.526731; batch adversarial loss: 0.291210\n",
      "epoch 45; iter: 600; batch classifier loss: 0.477731; batch adversarial loss: 0.460635\n",
      "epoch 46; iter: 0; batch classifier loss: 0.667898; batch adversarial loss: 0.416006\n",
      "epoch 46; iter: 200; batch classifier loss: 0.612868; batch adversarial loss: 0.375244\n",
      "epoch 46; iter: 400; batch classifier loss: 0.335952; batch adversarial loss: 0.401515\n",
      "epoch 46; iter: 600; batch classifier loss: 0.729786; batch adversarial loss: 0.374530\n",
      "epoch 47; iter: 0; batch classifier loss: 0.594350; batch adversarial loss: 0.402104\n",
      "epoch 47; iter: 200; batch classifier loss: 0.398651; batch adversarial loss: 0.435942\n",
      "epoch 47; iter: 400; batch classifier loss: 0.429908; batch adversarial loss: 0.401845\n",
      "epoch 47; iter: 600; batch classifier loss: 0.774159; batch adversarial loss: 0.408058\n",
      "epoch 48; iter: 0; batch classifier loss: 0.455657; batch adversarial loss: 0.403610\n",
      "epoch 48; iter: 200; batch classifier loss: 0.738101; batch adversarial loss: 0.346468\n",
      "epoch 48; iter: 400; batch classifier loss: 0.799455; batch adversarial loss: 0.413247\n",
      "epoch 48; iter: 600; batch classifier loss: 0.634203; batch adversarial loss: 0.409247\n",
      "epoch 49; iter: 0; batch classifier loss: 0.828758; batch adversarial loss: 0.270559\n",
      "epoch 49; iter: 200; batch classifier loss: 0.645372; batch adversarial loss: 0.388074\n",
      "epoch 49; iter: 400; batch classifier loss: 0.563181; batch adversarial loss: 0.268216\n",
      "epoch 49; iter: 600; batch classifier loss: 0.769969; batch adversarial loss: 0.392397\n",
      "epoch 0; iter: 0; batch classifier loss: 32.204010; batch adversarial loss: 0.914756\n",
      "epoch 0; iter: 200; batch classifier loss: 9.042953; batch adversarial loss: 0.754206\n",
      "epoch 0; iter: 400; batch classifier loss: 7.151097; batch adversarial loss: 0.595339\n",
      "epoch 0; iter: 600; batch classifier loss: 4.340129; batch adversarial loss: 0.491973\n",
      "epoch 1; iter: 0; batch classifier loss: 15.143532; batch adversarial loss: 0.517677\n",
      "epoch 1; iter: 200; batch classifier loss: 2.506612; batch adversarial loss: 0.449115\n",
      "epoch 1; iter: 400; batch classifier loss: 4.471521; batch adversarial loss: 0.435350\n",
      "epoch 1; iter: 600; batch classifier loss: 1.587922; batch adversarial loss: 0.407600\n",
      "epoch 2; iter: 0; batch classifier loss: 3.590330; batch adversarial loss: 0.479525\n",
      "epoch 2; iter: 200; batch classifier loss: 1.601898; batch adversarial loss: 0.464594\n",
      "epoch 2; iter: 400; batch classifier loss: 0.960103; batch adversarial loss: 0.386748\n",
      "epoch 2; iter: 600; batch classifier loss: 3.217901; batch adversarial loss: 0.443585\n",
      "epoch 3; iter: 0; batch classifier loss: 7.091089; batch adversarial loss: 0.363660\n",
      "epoch 3; iter: 200; batch classifier loss: 1.622950; batch adversarial loss: 0.366238\n",
      "epoch 3; iter: 400; batch classifier loss: 1.610024; batch adversarial loss: 0.336429\n",
      "epoch 3; iter: 600; batch classifier loss: 1.433264; batch adversarial loss: 0.482105\n",
      "epoch 4; iter: 0; batch classifier loss: 0.477325; batch adversarial loss: 0.334604\n",
      "epoch 4; iter: 200; batch classifier loss: 0.838723; batch adversarial loss: 0.373974\n",
      "epoch 4; iter: 400; batch classifier loss: 1.135272; batch adversarial loss: 0.309014\n",
      "epoch 4; iter: 600; batch classifier loss: 1.435093; batch adversarial loss: 0.244442\n",
      "epoch 5; iter: 0; batch classifier loss: 1.283999; batch adversarial loss: 0.482984\n",
      "epoch 5; iter: 200; batch classifier loss: 1.351737; batch adversarial loss: 0.424417\n",
      "epoch 5; iter: 400; batch classifier loss: 0.679732; batch adversarial loss: 0.474271\n",
      "epoch 5; iter: 600; batch classifier loss: 0.418707; batch adversarial loss: 0.365906\n",
      "epoch 6; iter: 0; batch classifier loss: 0.638550; batch adversarial loss: 0.420357\n",
      "epoch 6; iter: 200; batch classifier loss: 0.460490; batch adversarial loss: 0.394327\n",
      "epoch 6; iter: 400; batch classifier loss: 0.577891; batch adversarial loss: 0.369115\n",
      "epoch 6; iter: 600; batch classifier loss: 0.349680; batch adversarial loss: 0.465325\n",
      "epoch 7; iter: 0; batch classifier loss: 0.457734; batch adversarial loss: 0.304675\n",
      "epoch 7; iter: 200; batch classifier loss: 0.379543; batch adversarial loss: 0.376334\n",
      "epoch 7; iter: 400; batch classifier loss: 0.385994; batch adversarial loss: 0.562315\n",
      "epoch 7; iter: 600; batch classifier loss: 0.399918; batch adversarial loss: 0.458408\n",
      "epoch 8; iter: 0; batch classifier loss: 0.405104; batch adversarial loss: 0.521965\n",
      "epoch 8; iter: 200; batch classifier loss: 0.443262; batch adversarial loss: 0.291845\n",
      "epoch 8; iter: 400; batch classifier loss: 0.291961; batch adversarial loss: 0.385758\n",
      "epoch 8; iter: 600; batch classifier loss: 0.443745; batch adversarial loss: 0.372090\n",
      "epoch 9; iter: 0; batch classifier loss: 0.380955; batch adversarial loss: 0.437078\n",
      "epoch 9; iter: 200; batch classifier loss: 0.333258; batch adversarial loss: 0.299345\n",
      "epoch 9; iter: 400; batch classifier loss: 0.325035; batch adversarial loss: 0.334416\n",
      "epoch 9; iter: 600; batch classifier loss: 0.380637; batch adversarial loss: 0.611599\n",
      "epoch 10; iter: 0; batch classifier loss: 0.435268; batch adversarial loss: 0.409294\n",
      "epoch 10; iter: 200; batch classifier loss: 0.342922; batch adversarial loss: 0.528501\n",
      "epoch 10; iter: 400; batch classifier loss: 0.407429; batch adversarial loss: 0.314252\n",
      "epoch 10; iter: 600; batch classifier loss: 0.312384; batch adversarial loss: 0.411208\n",
      "epoch 11; iter: 0; batch classifier loss: 0.471562; batch adversarial loss: 0.385769\n",
      "epoch 11; iter: 200; batch classifier loss: 0.418138; batch adversarial loss: 0.347630\n",
      "epoch 11; iter: 400; batch classifier loss: 0.485065; batch adversarial loss: 0.407741\n",
      "epoch 11; iter: 600; batch classifier loss: 0.291291; batch adversarial loss: 0.366322\n",
      "epoch 12; iter: 0; batch classifier loss: 0.288696; batch adversarial loss: 0.501074\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391500; batch adversarial loss: 0.265061\n",
      "epoch 12; iter: 400; batch classifier loss: 0.353374; batch adversarial loss: 0.343874\n",
      "epoch 12; iter: 600; batch classifier loss: 0.224062; batch adversarial loss: 0.379144\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350065; batch adversarial loss: 0.455950\n",
      "epoch 13; iter: 200; batch classifier loss: 0.418756; batch adversarial loss: 0.493394\n",
      "epoch 13; iter: 400; batch classifier loss: 0.382847; batch adversarial loss: 0.339171\n",
      "epoch 13; iter: 600; batch classifier loss: 0.430758; batch adversarial loss: 0.424762\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290006; batch adversarial loss: 0.373564\n",
      "epoch 14; iter: 200; batch classifier loss: 0.302812; batch adversarial loss: 0.398253\n",
      "epoch 14; iter: 400; batch classifier loss: 0.509326; batch adversarial loss: 0.454641\n",
      "epoch 14; iter: 600; batch classifier loss: 0.446248; batch adversarial loss: 0.330266\n",
      "epoch 15; iter: 0; batch classifier loss: 0.388817; batch adversarial loss: 0.482700\n",
      "epoch 15; iter: 200; batch classifier loss: 0.481284; batch adversarial loss: 0.382830\n",
      "epoch 15; iter: 400; batch classifier loss: 0.441960; batch adversarial loss: 0.430944\n",
      "epoch 15; iter: 600; batch classifier loss: 0.399484; batch adversarial loss: 0.521814\n",
      "epoch 16; iter: 0; batch classifier loss: 0.398496; batch adversarial loss: 0.447630\n",
      "epoch 16; iter: 200; batch classifier loss: 0.501616; batch adversarial loss: 0.331492\n",
      "epoch 16; iter: 400; batch classifier loss: 0.449811; batch adversarial loss: 0.484275\n",
      "epoch 16; iter: 600; batch classifier loss: 0.300109; batch adversarial loss: 0.454104\n",
      "epoch 17; iter: 0; batch classifier loss: 0.403045; batch adversarial loss: 0.412156\n",
      "epoch 17; iter: 200; batch classifier loss: 0.258009; batch adversarial loss: 0.519942\n",
      "epoch 17; iter: 400; batch classifier loss: 0.344970; batch adversarial loss: 0.411074\n",
      "epoch 17; iter: 600; batch classifier loss: 0.333548; batch adversarial loss: 0.384760\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334832; batch adversarial loss: 0.402819\n",
      "epoch 18; iter: 200; batch classifier loss: 0.541869; batch adversarial loss: 0.400810\n",
      "epoch 18; iter: 400; batch classifier loss: 0.370718; batch adversarial loss: 0.356487\n",
      "epoch 18; iter: 600; batch classifier loss: 0.437707; batch adversarial loss: 0.345904\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310947; batch adversarial loss: 0.514162\n",
      "epoch 19; iter: 200; batch classifier loss: 0.482987; batch adversarial loss: 0.429239\n",
      "epoch 19; iter: 400; batch classifier loss: 0.490789; batch adversarial loss: 0.406361\n",
      "epoch 19; iter: 600; batch classifier loss: 0.471239; batch adversarial loss: 0.532756\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347134; batch adversarial loss: 0.293639\n",
      "epoch 20; iter: 200; batch classifier loss: 0.461271; batch adversarial loss: 0.377500\n",
      "epoch 20; iter: 400; batch classifier loss: 0.319662; batch adversarial loss: 0.481440\n",
      "epoch 20; iter: 600; batch classifier loss: 0.326365; batch adversarial loss: 0.517941\n",
      "epoch 21; iter: 0; batch classifier loss: 0.464395; batch adversarial loss: 0.429431\n",
      "epoch 21; iter: 200; batch classifier loss: 0.333101; batch adversarial loss: 0.488972\n",
      "epoch 21; iter: 400; batch classifier loss: 0.458041; batch adversarial loss: 0.458300\n",
      "epoch 21; iter: 600; batch classifier loss: 0.630765; batch adversarial loss: 0.429940\n",
      "epoch 22; iter: 0; batch classifier loss: 0.439356; batch adversarial loss: 0.431387\n",
      "epoch 22; iter: 200; batch classifier loss: 0.447666; batch adversarial loss: 0.317764\n",
      "epoch 22; iter: 400; batch classifier loss: 0.481493; batch adversarial loss: 0.293314\n",
      "epoch 22; iter: 600; batch classifier loss: 0.292640; batch adversarial loss: 0.379218\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517620; batch adversarial loss: 0.374661\n",
      "epoch 23; iter: 200; batch classifier loss: 0.240963; batch adversarial loss: 0.540821\n",
      "epoch 23; iter: 400; batch classifier loss: 0.406291; batch adversarial loss: 0.545055\n",
      "epoch 23; iter: 600; batch classifier loss: 0.441518; batch adversarial loss: 0.317788\n",
      "epoch 24; iter: 0; batch classifier loss: 0.543737; batch adversarial loss: 0.354459\n",
      "epoch 24; iter: 200; batch classifier loss: 0.344894; batch adversarial loss: 0.430587\n",
      "epoch 24; iter: 400; batch classifier loss: 0.427289; batch adversarial loss: 0.551335\n",
      "epoch 24; iter: 600; batch classifier loss: 0.581728; batch adversarial loss: 0.348866\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455860; batch adversarial loss: 0.401760\n",
      "epoch 25; iter: 200; batch classifier loss: 0.629489; batch adversarial loss: 0.486609\n",
      "epoch 25; iter: 400; batch classifier loss: 0.393482; batch adversarial loss: 0.410024\n",
      "epoch 25; iter: 600; batch classifier loss: 0.520475; batch adversarial loss: 0.353218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434928; batch adversarial loss: 0.344640\n",
      "epoch 26; iter: 200; batch classifier loss: 0.393541; batch adversarial loss: 0.465952\n",
      "epoch 26; iter: 400; batch classifier loss: 0.696587; batch adversarial loss: 0.400414\n",
      "epoch 26; iter: 600; batch classifier loss: 0.461640; batch adversarial loss: 0.345033\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458209; batch adversarial loss: 0.457715\n",
      "epoch 27; iter: 200; batch classifier loss: 0.622132; batch adversarial loss: 0.490780\n",
      "epoch 27; iter: 400; batch classifier loss: 0.415386; batch adversarial loss: 0.544499\n",
      "epoch 27; iter: 600; batch classifier loss: 0.384956; batch adversarial loss: 0.412586\n",
      "epoch 28; iter: 0; batch classifier loss: 0.389427; batch adversarial loss: 0.297648\n",
      "epoch 28; iter: 200; batch classifier loss: 0.544258; batch adversarial loss: 0.594741\n",
      "epoch 28; iter: 400; batch classifier loss: 0.536643; batch adversarial loss: 0.353493\n",
      "epoch 28; iter: 600; batch classifier loss: 0.569357; batch adversarial loss: 0.461459\n",
      "epoch 29; iter: 0; batch classifier loss: 0.488409; batch adversarial loss: 0.511139\n",
      "epoch 29; iter: 200; batch classifier loss: 0.432967; batch adversarial loss: 0.428295\n",
      "epoch 29; iter: 400; batch classifier loss: 0.456442; batch adversarial loss: 0.431235\n",
      "epoch 29; iter: 600; batch classifier loss: 0.433709; batch adversarial loss: 0.374941\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484651; batch adversarial loss: 0.488128\n",
      "epoch 30; iter: 200; batch classifier loss: 0.438831; batch adversarial loss: 0.412342\n",
      "epoch 30; iter: 400; batch classifier loss: 0.387120; batch adversarial loss: 0.488663\n",
      "epoch 30; iter: 600; batch classifier loss: 0.386380; batch adversarial loss: 0.408852\n",
      "epoch 31; iter: 0; batch classifier loss: 0.375164; batch adversarial loss: 0.429617\n",
      "epoch 31; iter: 200; batch classifier loss: 0.409860; batch adversarial loss: 0.348544\n",
      "epoch 31; iter: 400; batch classifier loss: 0.394201; batch adversarial loss: 0.320994\n",
      "epoch 31; iter: 600; batch classifier loss: 0.345106; batch adversarial loss: 0.352932\n",
      "epoch 32; iter: 0; batch classifier loss: 0.575648; batch adversarial loss: 0.409228\n",
      "epoch 32; iter: 200; batch classifier loss: 0.524779; batch adversarial loss: 0.376673\n",
      "epoch 32; iter: 400; batch classifier loss: 0.509998; batch adversarial loss: 0.320445\n",
      "epoch 32; iter: 600; batch classifier loss: 0.376301; batch adversarial loss: 0.346861\n",
      "epoch 33; iter: 0; batch classifier loss: 0.542459; batch adversarial loss: 0.407041\n",
      "epoch 33; iter: 200; batch classifier loss: 0.744898; batch adversarial loss: 0.270406\n",
      "epoch 33; iter: 400; batch classifier loss: 0.427999; batch adversarial loss: 0.480845\n",
      "epoch 33; iter: 600; batch classifier loss: 0.293022; batch adversarial loss: 0.400909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466071; batch adversarial loss: 0.443216\n",
      "epoch 34; iter: 200; batch classifier loss: 0.332923; batch adversarial loss: 0.408298\n",
      "epoch 34; iter: 400; batch classifier loss: 0.357108; batch adversarial loss: 0.400313\n",
      "epoch 34; iter: 600; batch classifier loss: 0.250184; batch adversarial loss: 0.494769\n",
      "epoch 35; iter: 0; batch classifier loss: 0.360410; batch adversarial loss: 0.460223\n",
      "epoch 35; iter: 200; batch classifier loss: 0.518514; batch adversarial loss: 0.408050\n",
      "epoch 35; iter: 400; batch classifier loss: 0.297533; batch adversarial loss: 0.487829\n",
      "epoch 35; iter: 600; batch classifier loss: 0.503371; batch adversarial loss: 0.456564\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404768; batch adversarial loss: 0.323118\n",
      "epoch 36; iter: 200; batch classifier loss: 0.319094; batch adversarial loss: 0.410856\n",
      "epoch 36; iter: 400; batch classifier loss: 0.507519; batch adversarial loss: 0.324402\n",
      "epoch 36; iter: 600; batch classifier loss: 0.411805; batch adversarial loss: 0.354260\n",
      "epoch 37; iter: 0; batch classifier loss: 0.259672; batch adversarial loss: 0.326797\n",
      "epoch 37; iter: 200; batch classifier loss: 0.393646; batch adversarial loss: 0.445748\n",
      "epoch 37; iter: 400; batch classifier loss: 0.585160; batch adversarial loss: 0.402914\n",
      "epoch 37; iter: 600; batch classifier loss: 0.403104; batch adversarial loss: 0.406512\n",
      "epoch 38; iter: 0; batch classifier loss: 0.432098; batch adversarial loss: 0.403982\n",
      "epoch 38; iter: 200; batch classifier loss: 0.663587; batch adversarial loss: 0.409468\n",
      "epoch 38; iter: 400; batch classifier loss: 0.416370; batch adversarial loss: 0.324116\n",
      "epoch 38; iter: 600; batch classifier loss: 0.487477; batch adversarial loss: 0.321971\n",
      "epoch 39; iter: 0; batch classifier loss: 0.576693; batch adversarial loss: 0.350349\n",
      "epoch 39; iter: 200; batch classifier loss: 0.599139; batch adversarial loss: 0.483484\n",
      "epoch 39; iter: 400; batch classifier loss: 0.489759; batch adversarial loss: 0.484520\n",
      "epoch 39; iter: 600; batch classifier loss: 0.681687; batch adversarial loss: 0.376280\n",
      "epoch 40; iter: 0; batch classifier loss: 0.642615; batch adversarial loss: 0.437477\n",
      "epoch 40; iter: 200; batch classifier loss: 0.502293; batch adversarial loss: 0.462281\n",
      "epoch 40; iter: 400; batch classifier loss: 0.677971; batch adversarial loss: 0.432815\n",
      "epoch 40; iter: 600; batch classifier loss: 0.556321; batch adversarial loss: 0.350832\n",
      "epoch 41; iter: 0; batch classifier loss: 0.497039; batch adversarial loss: 0.436447\n",
      "epoch 41; iter: 200; batch classifier loss: 0.319125; batch adversarial loss: 0.462354\n",
      "epoch 41; iter: 400; batch classifier loss: 0.568971; batch adversarial loss: 0.297930\n",
      "epoch 41; iter: 600; batch classifier loss: 0.410997; batch adversarial loss: 0.409365\n",
      "epoch 42; iter: 0; batch classifier loss: 0.490801; batch adversarial loss: 0.402880\n",
      "epoch 42; iter: 200; batch classifier loss: 0.563213; batch adversarial loss: 0.349079\n",
      "epoch 42; iter: 400; batch classifier loss: 0.489722; batch adversarial loss: 0.431840\n",
      "epoch 42; iter: 600; batch classifier loss: 0.424593; batch adversarial loss: 0.376907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.298951; batch adversarial loss: 0.490319\n",
      "epoch 43; iter: 200; batch classifier loss: 0.607999; batch adversarial loss: 0.402619\n",
      "epoch 43; iter: 400; batch classifier loss: 0.664912; batch adversarial loss: 0.377492\n",
      "epoch 43; iter: 600; batch classifier loss: 0.519492; batch adversarial loss: 0.322840\n",
      "epoch 44; iter: 0; batch classifier loss: 0.564406; batch adversarial loss: 0.547150\n",
      "epoch 44; iter: 200; batch classifier loss: 0.402510; batch adversarial loss: 0.376339\n",
      "epoch 44; iter: 400; batch classifier loss: 0.662528; batch adversarial loss: 0.459643\n",
      "epoch 44; iter: 600; batch classifier loss: 0.552706; batch adversarial loss: 0.378485\n",
      "epoch 45; iter: 0; batch classifier loss: 0.357358; batch adversarial loss: 0.630118\n",
      "epoch 45; iter: 200; batch classifier loss: 0.468671; batch adversarial loss: 0.440680\n",
      "epoch 45; iter: 400; batch classifier loss: 0.599306; batch adversarial loss: 0.599031\n",
      "epoch 45; iter: 600; batch classifier loss: 0.457210; batch adversarial loss: 0.459836\n",
      "epoch 46; iter: 0; batch classifier loss: 0.876457; batch adversarial loss: 0.485523\n",
      "epoch 46; iter: 200; batch classifier loss: 0.480095; batch adversarial loss: 0.294695\n",
      "epoch 46; iter: 400; batch classifier loss: 0.702993; batch adversarial loss: 0.514620\n",
      "epoch 46; iter: 600; batch classifier loss: 0.799098; batch adversarial loss: 0.512588\n",
      "epoch 47; iter: 0; batch classifier loss: 0.457592; batch adversarial loss: 0.463788\n",
      "epoch 47; iter: 200; batch classifier loss: 0.718672; batch adversarial loss: 0.431324\n",
      "epoch 47; iter: 400; batch classifier loss: 0.622056; batch adversarial loss: 0.349355\n",
      "epoch 47; iter: 600; batch classifier loss: 0.694500; batch adversarial loss: 0.427492\n",
      "epoch 48; iter: 0; batch classifier loss: 0.559171; batch adversarial loss: 0.349393\n",
      "epoch 48; iter: 200; batch classifier loss: 0.702876; batch adversarial loss: 0.320636\n",
      "epoch 48; iter: 400; batch classifier loss: 0.544355; batch adversarial loss: 0.292195\n",
      "epoch 48; iter: 600; batch classifier loss: 0.320653; batch adversarial loss: 0.322956\n",
      "epoch 49; iter: 0; batch classifier loss: 0.573225; batch adversarial loss: 0.378215\n",
      "epoch 49; iter: 200; batch classifier loss: 0.605517; batch adversarial loss: 0.461686\n",
      "epoch 49; iter: 400; batch classifier loss: 0.555106; batch adversarial loss: 0.243704\n",
      "epoch 49; iter: 600; batch classifier loss: 0.387267; batch adversarial loss: 0.513592\n",
      "epoch 0; iter: 0; batch classifier loss: 3.556456; batch adversarial loss: 0.572522\n",
      "epoch 0; iter: 200; batch classifier loss: 8.120037; batch adversarial loss: 0.578185\n",
      "epoch 0; iter: 400; batch classifier loss: 3.744135; batch adversarial loss: 0.542558\n",
      "epoch 0; iter: 600; batch classifier loss: 12.737722; batch adversarial loss: 0.461222\n",
      "epoch 1; iter: 0; batch classifier loss: 5.033350; batch adversarial loss: 0.498945\n",
      "epoch 1; iter: 200; batch classifier loss: 4.856799; batch adversarial loss: 0.396144\n",
      "epoch 1; iter: 400; batch classifier loss: 11.077446; batch adversarial loss: 0.462557\n",
      "epoch 1; iter: 600; batch classifier loss: 7.962305; batch adversarial loss: 0.453415\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613686; batch adversarial loss: 0.443195\n",
      "epoch 2; iter: 200; batch classifier loss: 2.914480; batch adversarial loss: 0.463702\n",
      "epoch 2; iter: 400; batch classifier loss: 2.412549; batch adversarial loss: 0.338554\n",
      "epoch 2; iter: 600; batch classifier loss: 4.067779; batch adversarial loss: 0.546455\n",
      "epoch 3; iter: 0; batch classifier loss: 0.432650; batch adversarial loss: 0.422894\n",
      "epoch 3; iter: 200; batch classifier loss: 0.717548; batch adversarial loss: 0.386882\n",
      "epoch 3; iter: 400; batch classifier loss: 0.729206; batch adversarial loss: 0.490670\n",
      "epoch 3; iter: 600; batch classifier loss: 0.367169; batch adversarial loss: 0.427041\n",
      "epoch 4; iter: 0; batch classifier loss: 1.415607; batch adversarial loss: 0.425715\n",
      "epoch 4; iter: 200; batch classifier loss: 1.057205; batch adversarial loss: 0.370741\n",
      "epoch 4; iter: 400; batch classifier loss: 0.613311; batch adversarial loss: 0.347075\n",
      "epoch 4; iter: 600; batch classifier loss: 0.593815; batch adversarial loss: 0.327285\n",
      "epoch 5; iter: 0; batch classifier loss: 0.465214; batch adversarial loss: 0.490958\n",
      "epoch 5; iter: 200; batch classifier loss: 0.445206; batch adversarial loss: 0.403783\n",
      "epoch 5; iter: 400; batch classifier loss: 0.483856; batch adversarial loss: 0.322157\n",
      "epoch 5; iter: 600; batch classifier loss: 0.432535; batch adversarial loss: 0.498465\n",
      "epoch 6; iter: 0; batch classifier loss: 0.702057; batch adversarial loss: 0.423120\n",
      "epoch 6; iter: 200; batch classifier loss: 0.908101; batch adversarial loss: 0.428660\n",
      "epoch 6; iter: 400; batch classifier loss: 0.340969; batch adversarial loss: 0.473413\n",
      "epoch 6; iter: 600; batch classifier loss: 0.403053; batch adversarial loss: 0.490321\n",
      "epoch 7; iter: 0; batch classifier loss: 0.281858; batch adversarial loss: 0.373522\n",
      "epoch 7; iter: 200; batch classifier loss: 0.494888; batch adversarial loss: 0.247406\n",
      "epoch 7; iter: 400; batch classifier loss: 0.391365; batch adversarial loss: 0.450760\n",
      "epoch 7; iter: 600; batch classifier loss: 0.458682; batch adversarial loss: 0.414790\n",
      "epoch 8; iter: 0; batch classifier loss: 0.326121; batch adversarial loss: 0.383659\n",
      "epoch 8; iter: 200; batch classifier loss: 0.334478; batch adversarial loss: 0.481091\n",
      "epoch 8; iter: 400; batch classifier loss: 0.604951; batch adversarial loss: 0.310659\n",
      "epoch 8; iter: 600; batch classifier loss: 0.464003; batch adversarial loss: 0.450013\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426604; batch adversarial loss: 0.430430\n",
      "epoch 9; iter: 200; batch classifier loss: 0.252154; batch adversarial loss: 0.330886\n",
      "epoch 9; iter: 400; batch classifier loss: 0.560255; batch adversarial loss: 0.406357\n",
      "epoch 9; iter: 600; batch classifier loss: 0.340263; batch adversarial loss: 0.427715\n",
      "epoch 10; iter: 0; batch classifier loss: 0.267606; batch adversarial loss: 0.319577\n",
      "epoch 10; iter: 200; batch classifier loss: 0.324843; batch adversarial loss: 0.317932\n",
      "epoch 10; iter: 400; batch classifier loss: 0.329583; batch adversarial loss: 0.443941\n",
      "epoch 10; iter: 600; batch classifier loss: 0.277238; batch adversarial loss: 0.371337\n",
      "epoch 11; iter: 0; batch classifier loss: 0.338235; batch adversarial loss: 0.321319\n",
      "epoch 11; iter: 200; batch classifier loss: 0.353623; batch adversarial loss: 0.369992\n",
      "epoch 11; iter: 400; batch classifier loss: 0.335258; batch adversarial loss: 0.401545\n",
      "epoch 11; iter: 600; batch classifier loss: 0.351694; batch adversarial loss: 0.370302\n",
      "epoch 12; iter: 0; batch classifier loss: 0.374159; batch adversarial loss: 0.449824\n",
      "epoch 12; iter: 200; batch classifier loss: 0.402894; batch adversarial loss: 0.431757\n",
      "epoch 12; iter: 400; batch classifier loss: 0.361838; batch adversarial loss: 0.444177\n",
      "epoch 12; iter: 600; batch classifier loss: 0.452994; batch adversarial loss: 0.357801\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382511; batch adversarial loss: 0.554935\n",
      "epoch 13; iter: 200; batch classifier loss: 0.279156; batch adversarial loss: 0.343036\n",
      "epoch 13; iter: 400; batch classifier loss: 0.425084; batch adversarial loss: 0.450147\n",
      "epoch 13; iter: 600; batch classifier loss: 0.308967; batch adversarial loss: 0.459114\n",
      "epoch 14; iter: 0; batch classifier loss: 0.453290; batch adversarial loss: 0.444462\n",
      "epoch 14; iter: 200; batch classifier loss: 0.356802; batch adversarial loss: 0.409164\n",
      "epoch 14; iter: 400; batch classifier loss: 0.417804; batch adversarial loss: 0.319550\n",
      "epoch 14; iter: 600; batch classifier loss: 0.371007; batch adversarial loss: 0.566023\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475648; batch adversarial loss: 0.542537\n",
      "epoch 15; iter: 200; batch classifier loss: 0.261524; batch adversarial loss: 0.556606\n",
      "epoch 15; iter: 400; batch classifier loss: 0.299495; batch adversarial loss: 0.346709\n",
      "epoch 15; iter: 600; batch classifier loss: 0.296333; batch adversarial loss: 0.291669\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347548; batch adversarial loss: 0.637994\n",
      "epoch 16; iter: 200; batch classifier loss: 0.367515; batch adversarial loss: 0.347713\n",
      "epoch 16; iter: 400; batch classifier loss: 0.268983; batch adversarial loss: 0.566304\n",
      "epoch 16; iter: 600; batch classifier loss: 0.452611; batch adversarial loss: 0.403005\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367924; batch adversarial loss: 0.429515\n",
      "epoch 17; iter: 200; batch classifier loss: 0.383954; batch adversarial loss: 0.326070\n",
      "epoch 17; iter: 400; batch classifier loss: 0.387443; batch adversarial loss: 0.386610\n",
      "epoch 17; iter: 600; batch classifier loss: 0.341076; batch adversarial loss: 0.601785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339980; batch adversarial loss: 0.294123\n",
      "epoch 18; iter: 200; batch classifier loss: 0.228538; batch adversarial loss: 0.354814\n",
      "epoch 18; iter: 400; batch classifier loss: 0.453527; batch adversarial loss: 0.437368\n",
      "epoch 18; iter: 600; batch classifier loss: 0.436437; batch adversarial loss: 0.451425\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317734; batch adversarial loss: 0.289946\n",
      "epoch 19; iter: 200; batch classifier loss: 0.335299; batch adversarial loss: 0.400604\n",
      "epoch 19; iter: 400; batch classifier loss: 0.318284; batch adversarial loss: 0.428339\n",
      "epoch 19; iter: 600; batch classifier loss: 0.369621; batch adversarial loss: 0.385195\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514588; batch adversarial loss: 0.514637\n",
      "epoch 20; iter: 200; batch classifier loss: 0.662663; batch adversarial loss: 0.560431\n",
      "epoch 20; iter: 400; batch classifier loss: 0.597743; batch adversarial loss: 0.446579\n",
      "epoch 20; iter: 600; batch classifier loss: 0.413386; batch adversarial loss: 0.425745\n",
      "epoch 21; iter: 0; batch classifier loss: 0.492661; batch adversarial loss: 0.519527\n",
      "epoch 21; iter: 200; batch classifier loss: 0.445896; batch adversarial loss: 0.484136\n",
      "epoch 21; iter: 400; batch classifier loss: 0.210991; batch adversarial loss: 0.349987\n",
      "epoch 21; iter: 600; batch classifier loss: 0.379403; batch adversarial loss: 0.432194\n",
      "epoch 22; iter: 0; batch classifier loss: 0.543507; batch adversarial loss: 0.399905\n",
      "epoch 22; iter: 200; batch classifier loss: 0.233873; batch adversarial loss: 0.383496\n",
      "epoch 22; iter: 400; batch classifier loss: 0.467783; batch adversarial loss: 0.432462\n",
      "epoch 22; iter: 600; batch classifier loss: 0.406165; batch adversarial loss: 0.381487\n",
      "epoch 23; iter: 0; batch classifier loss: 0.365919; batch adversarial loss: 0.427448\n",
      "epoch 23; iter: 200; batch classifier loss: 0.392510; batch adversarial loss: 0.377083\n",
      "epoch 23; iter: 400; batch classifier loss: 0.512018; batch adversarial loss: 0.419007\n",
      "epoch 23; iter: 600; batch classifier loss: 0.343281; batch adversarial loss: 0.289834\n",
      "epoch 24; iter: 0; batch classifier loss: 0.523427; batch adversarial loss: 0.376348\n",
      "epoch 24; iter: 200; batch classifier loss: 0.396786; batch adversarial loss: 0.425864\n",
      "epoch 24; iter: 400; batch classifier loss: 0.433534; batch adversarial loss: 0.503626\n",
      "epoch 24; iter: 600; batch classifier loss: 0.436298; batch adversarial loss: 0.349558\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490412; batch adversarial loss: 0.412929\n",
      "epoch 25; iter: 200; batch classifier loss: 0.488724; batch adversarial loss: 0.468461\n",
      "epoch 25; iter: 400; batch classifier loss: 0.407376; batch adversarial loss: 0.375883\n",
      "epoch 25; iter: 600; batch classifier loss: 0.323260; batch adversarial loss: 0.350046\n",
      "epoch 26; iter: 0; batch classifier loss: 0.384622; batch adversarial loss: 0.518537\n",
      "epoch 26; iter: 200; batch classifier loss: 0.511992; batch adversarial loss: 0.469905\n",
      "epoch 26; iter: 400; batch classifier loss: 0.376141; batch adversarial loss: 0.534519\n",
      "epoch 26; iter: 600; batch classifier loss: 0.586651; batch adversarial loss: 0.488979\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424530; batch adversarial loss: 0.428101\n",
      "epoch 27; iter: 200; batch classifier loss: 0.563432; batch adversarial loss: 0.445437\n",
      "epoch 27; iter: 400; batch classifier loss: 0.415846; batch adversarial loss: 0.408987\n",
      "epoch 27; iter: 600; batch classifier loss: 0.438946; batch adversarial loss: 0.376054\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418537; batch adversarial loss: 0.496681\n",
      "epoch 28; iter: 200; batch classifier loss: 0.548582; batch adversarial loss: 0.433731\n",
      "epoch 28; iter: 400; batch classifier loss: 0.484762; batch adversarial loss: 0.455510\n",
      "epoch 28; iter: 600; batch classifier loss: 0.464522; batch adversarial loss: 0.395897\n",
      "epoch 29; iter: 0; batch classifier loss: 0.479718; batch adversarial loss: 0.349055\n",
      "epoch 29; iter: 200; batch classifier loss: 0.315891; batch adversarial loss: 0.602388\n",
      "epoch 29; iter: 400; batch classifier loss: 0.388189; batch adversarial loss: 0.465549\n",
      "epoch 29; iter: 600; batch classifier loss: 0.427422; batch adversarial loss: 0.465121\n",
      "epoch 30; iter: 0; batch classifier loss: 0.367522; batch adversarial loss: 0.517786\n",
      "epoch 30; iter: 200; batch classifier loss: 0.439890; batch adversarial loss: 0.466755\n",
      "epoch 30; iter: 400; batch classifier loss: 0.607136; batch adversarial loss: 0.498626\n",
      "epoch 30; iter: 600; batch classifier loss: 0.571509; batch adversarial loss: 0.493125\n",
      "epoch 31; iter: 0; batch classifier loss: 0.666633; batch adversarial loss: 0.346805\n",
      "epoch 31; iter: 200; batch classifier loss: 0.470532; batch adversarial loss: 0.429977\n",
      "epoch 31; iter: 400; batch classifier loss: 0.415327; batch adversarial loss: 0.492550\n",
      "epoch 31; iter: 600; batch classifier loss: 0.367143; batch adversarial loss: 0.438811\n",
      "epoch 32; iter: 0; batch classifier loss: 0.652226; batch adversarial loss: 0.408320\n",
      "epoch 32; iter: 200; batch classifier loss: 0.619613; batch adversarial loss: 0.435275\n",
      "epoch 32; iter: 400; batch classifier loss: 0.490155; batch adversarial loss: 0.345613\n",
      "epoch 32; iter: 600; batch classifier loss: 0.463277; batch adversarial loss: 0.320819\n",
      "epoch 33; iter: 0; batch classifier loss: 0.467078; batch adversarial loss: 0.369318\n",
      "epoch 33; iter: 200; batch classifier loss: 0.764615; batch adversarial loss: 0.404266\n",
      "epoch 33; iter: 400; batch classifier loss: 0.607096; batch adversarial loss: 0.495666\n",
      "epoch 33; iter: 600; batch classifier loss: 0.410593; batch adversarial loss: 0.264789\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502960; batch adversarial loss: 0.516186\n",
      "epoch 34; iter: 200; batch classifier loss: 0.307472; batch adversarial loss: 0.404951\n",
      "epoch 34; iter: 400; batch classifier loss: 0.301322; batch adversarial loss: 0.438179\n",
      "epoch 34; iter: 600; batch classifier loss: 0.445715; batch adversarial loss: 0.407918\n",
      "epoch 35; iter: 0; batch classifier loss: 0.541437; batch adversarial loss: 0.373641\n",
      "epoch 35; iter: 200; batch classifier loss: 0.429414; batch adversarial loss: 0.555833\n",
      "epoch 35; iter: 400; batch classifier loss: 0.619535; batch adversarial loss: 0.428720\n",
      "epoch 35; iter: 600; batch classifier loss: 0.622858; batch adversarial loss: 0.348557\n",
      "epoch 36; iter: 0; batch classifier loss: 0.478508; batch adversarial loss: 0.459008\n",
      "epoch 36; iter: 200; batch classifier loss: 0.507384; batch adversarial loss: 0.354497\n",
      "epoch 36; iter: 400; batch classifier loss: 0.288886; batch adversarial loss: 0.348076\n",
      "epoch 36; iter: 600; batch classifier loss: 0.317172; batch adversarial loss: 0.293780\n",
      "epoch 37; iter: 0; batch classifier loss: 0.424724; batch adversarial loss: 0.388477\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341980; batch adversarial loss: 0.428697\n",
      "epoch 37; iter: 400; batch classifier loss: 0.497562; batch adversarial loss: 0.410804\n",
      "epoch 37; iter: 600; batch classifier loss: 0.387244; batch adversarial loss: 0.650483\n",
      "epoch 38; iter: 0; batch classifier loss: 0.521921; batch adversarial loss: 0.499039\n",
      "epoch 38; iter: 200; batch classifier loss: 0.548710; batch adversarial loss: 0.380010\n",
      "epoch 38; iter: 400; batch classifier loss: 0.684262; batch adversarial loss: 0.239859\n",
      "epoch 38; iter: 600; batch classifier loss: 0.348583; batch adversarial loss: 0.428634\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386969; batch adversarial loss: 0.401923\n",
      "epoch 39; iter: 200; batch classifier loss: 0.554857; batch adversarial loss: 0.654329\n",
      "epoch 39; iter: 400; batch classifier loss: 0.470679; batch adversarial loss: 0.486212\n",
      "epoch 39; iter: 600; batch classifier loss: 0.924509; batch adversarial loss: 0.511954\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410159; batch adversarial loss: 0.510542\n",
      "epoch 40; iter: 200; batch classifier loss: 0.598385; batch adversarial loss: 0.327219\n",
      "epoch 40; iter: 400; batch classifier loss: 0.445092; batch adversarial loss: 0.430322\n",
      "epoch 40; iter: 600; batch classifier loss: 0.606639; batch adversarial loss: 0.467912\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445484; batch adversarial loss: 0.410549\n",
      "epoch 41; iter: 200; batch classifier loss: 0.649070; batch adversarial loss: 0.385927\n",
      "epoch 41; iter: 400; batch classifier loss: 0.655753; batch adversarial loss: 0.378191\n",
      "epoch 41; iter: 600; batch classifier loss: 0.618025; batch adversarial loss: 0.436781\n",
      "epoch 42; iter: 0; batch classifier loss: 0.534977; batch adversarial loss: 0.618639\n",
      "epoch 42; iter: 200; batch classifier loss: 0.356321; batch adversarial loss: 0.353394\n",
      "epoch 42; iter: 400; batch classifier loss: 0.616059; batch adversarial loss: 0.405754\n",
      "epoch 42; iter: 600; batch classifier loss: 0.556789; batch adversarial loss: 0.461314\n",
      "epoch 43; iter: 0; batch classifier loss: 0.584865; batch adversarial loss: 0.458208\n",
      "epoch 43; iter: 200; batch classifier loss: 0.715916; batch adversarial loss: 0.485964\n",
      "epoch 43; iter: 400; batch classifier loss: 0.515065; batch adversarial loss: 0.545222\n",
      "epoch 43; iter: 600; batch classifier loss: 0.503663; batch adversarial loss: 0.376094\n",
      "epoch 44; iter: 0; batch classifier loss: 0.553643; batch adversarial loss: 0.265387\n",
      "epoch 44; iter: 200; batch classifier loss: 0.472025; batch adversarial loss: 0.379922\n",
      "epoch 44; iter: 400; batch classifier loss: 0.469362; batch adversarial loss: 0.566773\n",
      "epoch 44; iter: 600; batch classifier loss: 0.513409; batch adversarial loss: 0.405478\n",
      "epoch 45; iter: 0; batch classifier loss: 0.626925; batch adversarial loss: 0.488873\n",
      "epoch 45; iter: 200; batch classifier loss: 0.557897; batch adversarial loss: 0.546966\n",
      "epoch 45; iter: 400; batch classifier loss: 0.473698; batch adversarial loss: 0.433386\n",
      "epoch 45; iter: 600; batch classifier loss: 0.408859; batch adversarial loss: 0.412928\n",
      "epoch 46; iter: 0; batch classifier loss: 0.631880; batch adversarial loss: 0.482305\n",
      "epoch 46; iter: 200; batch classifier loss: 0.446474; batch adversarial loss: 0.348029\n",
      "epoch 46; iter: 400; batch classifier loss: 0.637093; batch adversarial loss: 0.295627\n",
      "epoch 46; iter: 600; batch classifier loss: 0.745142; batch adversarial loss: 0.298823\n",
      "epoch 47; iter: 0; batch classifier loss: 0.737066; batch adversarial loss: 0.576923\n",
      "epoch 47; iter: 200; batch classifier loss: 0.372354; batch adversarial loss: 0.267063\n",
      "epoch 47; iter: 400; batch classifier loss: 0.353947; batch adversarial loss: 0.373883\n",
      "epoch 47; iter: 600; batch classifier loss: 0.687483; batch adversarial loss: 0.486848\n",
      "epoch 48; iter: 0; batch classifier loss: 0.548363; batch adversarial loss: 0.484537\n",
      "epoch 48; iter: 200; batch classifier loss: 0.823443; batch adversarial loss: 0.406056\n",
      "epoch 48; iter: 400; batch classifier loss: 0.655638; batch adversarial loss: 0.427090\n",
      "epoch 48; iter: 600; batch classifier loss: 0.534335; batch adversarial loss: 0.374850\n",
      "epoch 49; iter: 0; batch classifier loss: 0.599267; batch adversarial loss: 0.428979\n",
      "epoch 49; iter: 200; batch classifier loss: 0.446225; batch adversarial loss: 0.579335\n",
      "epoch 49; iter: 400; batch classifier loss: 0.677795; batch adversarial loss: 0.295129\n",
      "epoch 49; iter: 600; batch classifier loss: 0.511407; batch adversarial loss: 0.483998\n",
      "epoch 0; iter: 0; batch classifier loss: 26.337841; batch adversarial loss: 0.682933\n",
      "epoch 0; iter: 200; batch classifier loss: 6.262156; batch adversarial loss: 0.612822\n",
      "epoch 0; iter: 400; batch classifier loss: 8.054912; batch adversarial loss: 0.512985\n",
      "epoch 0; iter: 600; batch classifier loss: 0.474471; batch adversarial loss: 0.502118\n",
      "epoch 1; iter: 0; batch classifier loss: 4.489324; batch adversarial loss: 0.474775\n",
      "epoch 1; iter: 200; batch classifier loss: 2.553087; batch adversarial loss: 0.448389\n",
      "epoch 1; iter: 400; batch classifier loss: 1.729564; batch adversarial loss: 0.579878\n",
      "epoch 1; iter: 600; batch classifier loss: 9.162605; batch adversarial loss: 0.441612\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572593; batch adversarial loss: 0.367251\n",
      "epoch 2; iter: 200; batch classifier loss: 2.347143; batch adversarial loss: 0.541227\n",
      "epoch 2; iter: 400; batch classifier loss: 2.792167; batch adversarial loss: 0.429420\n",
      "epoch 2; iter: 600; batch classifier loss: 0.909238; batch adversarial loss: 0.578685\n",
      "epoch 3; iter: 0; batch classifier loss: 1.846450; batch adversarial loss: 0.500684\n",
      "epoch 3; iter: 200; batch classifier loss: 9.951940; batch adversarial loss: 0.479828\n",
      "epoch 3; iter: 400; batch classifier loss: 1.408583; batch adversarial loss: 0.351987\n",
      "epoch 3; iter: 600; batch classifier loss: 1.427548; batch adversarial loss: 0.375893\n",
      "epoch 4; iter: 0; batch classifier loss: 1.079551; batch adversarial loss: 0.397477\n",
      "epoch 4; iter: 200; batch classifier loss: 0.413946; batch adversarial loss: 0.464973\n",
      "epoch 4; iter: 400; batch classifier loss: 0.483368; batch adversarial loss: 0.359431\n",
      "epoch 4; iter: 600; batch classifier loss: 1.656794; batch adversarial loss: 0.476856\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572274; batch adversarial loss: 0.505500\n",
      "epoch 5; iter: 200; batch classifier loss: 0.359301; batch adversarial loss: 0.439765\n",
      "epoch 5; iter: 400; batch classifier loss: 0.634440; batch adversarial loss: 0.471614\n",
      "epoch 5; iter: 600; batch classifier loss: 0.711972; batch adversarial loss: 0.427862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515893; batch adversarial loss: 0.436073\n",
      "epoch 6; iter: 200; batch classifier loss: 0.438508; batch adversarial loss: 0.350653\n",
      "epoch 6; iter: 400; batch classifier loss: 0.325643; batch adversarial loss: 0.443511\n",
      "epoch 6; iter: 600; batch classifier loss: 0.544562; batch adversarial loss: 0.401054\n",
      "epoch 7; iter: 0; batch classifier loss: 0.230309; batch adversarial loss: 0.451605\n",
      "epoch 7; iter: 200; batch classifier loss: 0.402135; batch adversarial loss: 0.389209\n",
      "epoch 7; iter: 400; batch classifier loss: 0.460181; batch adversarial loss: 0.541974\n",
      "epoch 7; iter: 600; batch classifier loss: 0.322333; batch adversarial loss: 0.345732\n",
      "epoch 8; iter: 0; batch classifier loss: 0.605889; batch adversarial loss: 0.540655\n",
      "epoch 8; iter: 200; batch classifier loss: 0.312159; batch adversarial loss: 0.564694\n",
      "epoch 8; iter: 400; batch classifier loss: 0.436726; batch adversarial loss: 0.371883\n",
      "epoch 8; iter: 600; batch classifier loss: 0.317249; batch adversarial loss: 0.349731\n",
      "epoch 9; iter: 0; batch classifier loss: 0.355533; batch adversarial loss: 0.289341\n",
      "epoch 9; iter: 200; batch classifier loss: 0.390372; batch adversarial loss: 0.275599\n",
      "epoch 9; iter: 400; batch classifier loss: 0.300263; batch adversarial loss: 0.457930\n",
      "epoch 9; iter: 600; batch classifier loss: 0.298483; batch adversarial loss: 0.469400\n",
      "epoch 10; iter: 0; batch classifier loss: 0.377011; batch adversarial loss: 0.527203\n",
      "epoch 10; iter: 200; batch classifier loss: 0.402882; batch adversarial loss: 0.376647\n",
      "epoch 10; iter: 400; batch classifier loss: 0.301125; batch adversarial loss: 0.483137\n",
      "epoch 10; iter: 600; batch classifier loss: 0.303323; batch adversarial loss: 0.339487\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339137; batch adversarial loss: 0.406848\n",
      "epoch 11; iter: 200; batch classifier loss: 0.445311; batch adversarial loss: 0.425537\n",
      "epoch 11; iter: 400; batch classifier loss: 0.352506; batch adversarial loss: 0.478742\n",
      "epoch 11; iter: 600; batch classifier loss: 0.380578; batch adversarial loss: 0.324180\n",
      "epoch 12; iter: 0; batch classifier loss: 0.339859; batch adversarial loss: 0.367906\n",
      "epoch 12; iter: 200; batch classifier loss: 0.318789; batch adversarial loss: 0.372082\n",
      "epoch 12; iter: 400; batch classifier loss: 0.293083; batch adversarial loss: 0.490335\n",
      "epoch 12; iter: 600; batch classifier loss: 0.364436; batch adversarial loss: 0.258664\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301928; batch adversarial loss: 0.507731\n",
      "epoch 13; iter: 200; batch classifier loss: 0.276116; batch adversarial loss: 0.433667\n",
      "epoch 13; iter: 400; batch classifier loss: 0.258072; batch adversarial loss: 0.381106\n",
      "epoch 13; iter: 600; batch classifier loss: 0.371674; batch adversarial loss: 0.381589\n",
      "epoch 14; iter: 0; batch classifier loss: 0.355783; batch adversarial loss: 0.323227\n",
      "epoch 14; iter: 200; batch classifier loss: 0.302502; batch adversarial loss: 0.464623\n",
      "epoch 14; iter: 400; batch classifier loss: 0.271108; batch adversarial loss: 0.424102\n",
      "epoch 14; iter: 600; batch classifier loss: 0.361437; batch adversarial loss: 0.597151\n",
      "epoch 15; iter: 0; batch classifier loss: 0.357308; batch adversarial loss: 0.473159\n",
      "epoch 15; iter: 200; batch classifier loss: 0.411092; batch adversarial loss: 0.479232\n",
      "epoch 15; iter: 400; batch classifier loss: 0.375102; batch adversarial loss: 0.427156\n",
      "epoch 15; iter: 600; batch classifier loss: 0.351119; batch adversarial loss: 0.392265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450289; batch adversarial loss: 0.481451\n",
      "epoch 16; iter: 200; batch classifier loss: 0.330789; batch adversarial loss: 0.419979\n",
      "epoch 16; iter: 400; batch classifier loss: 0.410742; batch adversarial loss: 0.484363\n",
      "epoch 16; iter: 600; batch classifier loss: 0.332717; batch adversarial loss: 0.368688\n",
      "epoch 17; iter: 0; batch classifier loss: 0.393967; batch adversarial loss: 0.406624\n",
      "epoch 17; iter: 200; batch classifier loss: 0.404859; batch adversarial loss: 0.344206\n",
      "epoch 17; iter: 400; batch classifier loss: 0.354339; batch adversarial loss: 0.323442\n",
      "epoch 17; iter: 600; batch classifier loss: 0.284230; batch adversarial loss: 0.457517\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328843; batch adversarial loss: 0.394970\n",
      "epoch 18; iter: 200; batch classifier loss: 0.367202; batch adversarial loss: 0.371325\n",
      "epoch 18; iter: 400; batch classifier loss: 0.272128; batch adversarial loss: 0.433005\n",
      "epoch 18; iter: 600; batch classifier loss: 0.355775; batch adversarial loss: 0.361621\n",
      "epoch 19; iter: 0; batch classifier loss: 0.532026; batch adversarial loss: 0.366962\n",
      "epoch 19; iter: 200; batch classifier loss: 0.262462; batch adversarial loss: 0.520409\n",
      "epoch 19; iter: 400; batch classifier loss: 0.467894; batch adversarial loss: 0.407945\n",
      "epoch 19; iter: 600; batch classifier loss: 0.404064; batch adversarial loss: 0.451466\n",
      "epoch 20; iter: 0; batch classifier loss: 0.329409; batch adversarial loss: 0.567072\n",
      "epoch 20; iter: 200; batch classifier loss: 0.423773; batch adversarial loss: 0.542238\n",
      "epoch 20; iter: 400; batch classifier loss: 0.392641; batch adversarial loss: 0.671767\n",
      "epoch 20; iter: 600; batch classifier loss: 0.250933; batch adversarial loss: 0.547477\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295112; batch adversarial loss: 0.396212\n",
      "epoch 21; iter: 200; batch classifier loss: 0.295092; batch adversarial loss: 0.389360\n",
      "epoch 21; iter: 400; batch classifier loss: 0.317853; batch adversarial loss: 0.403420\n",
      "epoch 21; iter: 600; batch classifier loss: 0.372507; batch adversarial loss: 0.431580\n",
      "epoch 22; iter: 0; batch classifier loss: 0.424105; batch adversarial loss: 0.424886\n",
      "epoch 22; iter: 200; batch classifier loss: 0.439013; batch adversarial loss: 0.408481\n",
      "epoch 22; iter: 400; batch classifier loss: 0.453361; batch adversarial loss: 0.412859\n",
      "epoch 22; iter: 600; batch classifier loss: 0.728639; batch adversarial loss: 0.376826\n",
      "epoch 23; iter: 0; batch classifier loss: 0.692464; batch adversarial loss: 0.457503\n",
      "epoch 23; iter: 200; batch classifier loss: 0.503695; batch adversarial loss: 0.355867\n",
      "epoch 23; iter: 400; batch classifier loss: 0.517507; batch adversarial loss: 0.402055\n",
      "epoch 23; iter: 600; batch classifier loss: 0.364124; batch adversarial loss: 0.484292\n",
      "epoch 24; iter: 0; batch classifier loss: 0.511698; batch adversarial loss: 0.462294\n",
      "epoch 24; iter: 200; batch classifier loss: 0.437751; batch adversarial loss: 0.358113\n",
      "epoch 24; iter: 400; batch classifier loss: 0.733924; batch adversarial loss: 0.372508\n",
      "epoch 24; iter: 600; batch classifier loss: 0.510090; batch adversarial loss: 0.320485\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487151; batch adversarial loss: 0.499285\n",
      "epoch 25; iter: 200; batch classifier loss: 0.401229; batch adversarial loss: 0.322639\n",
      "epoch 25; iter: 400; batch classifier loss: 0.595814; batch adversarial loss: 0.492284\n",
      "epoch 25; iter: 600; batch classifier loss: 0.514429; batch adversarial loss: 0.435294\n",
      "epoch 26; iter: 0; batch classifier loss: 0.554804; batch adversarial loss: 0.412866\n",
      "epoch 26; iter: 200; batch classifier loss: 0.508048; batch adversarial loss: 0.355848\n",
      "epoch 26; iter: 400; batch classifier loss: 0.643740; batch adversarial loss: 0.535948\n",
      "epoch 26; iter: 600; batch classifier loss: 0.309187; batch adversarial loss: 0.351177\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458905; batch adversarial loss: 0.486542\n",
      "epoch 27; iter: 200; batch classifier loss: 0.395131; batch adversarial loss: 0.462315\n",
      "epoch 27; iter: 400; batch classifier loss: 0.457548; batch adversarial loss: 0.361433\n",
      "epoch 27; iter: 600; batch classifier loss: 0.549266; batch adversarial loss: 0.405779\n",
      "epoch 28; iter: 0; batch classifier loss: 0.568618; batch adversarial loss: 0.352733\n",
      "epoch 28; iter: 200; batch classifier loss: 0.383599; batch adversarial loss: 0.295346\n",
      "epoch 28; iter: 400; batch classifier loss: 0.778664; batch adversarial loss: 0.428863\n",
      "epoch 28; iter: 600; batch classifier loss: 0.749829; batch adversarial loss: 0.408429\n",
      "epoch 29; iter: 0; batch classifier loss: 0.371732; batch adversarial loss: 0.375331\n",
      "epoch 29; iter: 200; batch classifier loss: 0.488278; batch adversarial loss: 0.433920\n",
      "epoch 29; iter: 400; batch classifier loss: 0.394195; batch adversarial loss: 0.326733\n",
      "epoch 29; iter: 600; batch classifier loss: 0.420600; batch adversarial loss: 0.409847\n",
      "epoch 30; iter: 0; batch classifier loss: 0.637697; batch adversarial loss: 0.347833\n",
      "epoch 30; iter: 200; batch classifier loss: 0.650528; batch adversarial loss: 0.460407\n",
      "epoch 30; iter: 400; batch classifier loss: 0.713333; batch adversarial loss: 0.487314\n",
      "epoch 30; iter: 600; batch classifier loss: 0.454936; batch adversarial loss: 0.296600\n",
      "epoch 31; iter: 0; batch classifier loss: 0.575361; batch adversarial loss: 0.377400\n",
      "epoch 31; iter: 200; batch classifier loss: 0.376652; batch adversarial loss: 0.372331\n",
      "epoch 31; iter: 400; batch classifier loss: 0.544520; batch adversarial loss: 0.430894\n",
      "epoch 31; iter: 600; batch classifier loss: 0.709133; batch adversarial loss: 0.323022\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419379; batch adversarial loss: 0.295060\n",
      "epoch 32; iter: 200; batch classifier loss: 0.338266; batch adversarial loss: 0.522924\n",
      "epoch 32; iter: 400; batch classifier loss: 0.581691; batch adversarial loss: 0.483966\n",
      "epoch 32; iter: 600; batch classifier loss: 0.631356; batch adversarial loss: 0.439154\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355004; batch adversarial loss: 0.502018\n",
      "epoch 33; iter: 200; batch classifier loss: 0.740967; batch adversarial loss: 0.592222\n",
      "epoch 33; iter: 400; batch classifier loss: 0.423803; batch adversarial loss: 0.410344\n",
      "epoch 33; iter: 600; batch classifier loss: 0.590820; batch adversarial loss: 0.485392\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533750; batch adversarial loss: 0.438445\n",
      "epoch 34; iter: 200; batch classifier loss: 0.323188; batch adversarial loss: 0.577031\n",
      "epoch 34; iter: 400; batch classifier loss: 0.408429; batch adversarial loss: 0.348271\n",
      "epoch 34; iter: 600; batch classifier loss: 0.701869; batch adversarial loss: 0.384252\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404789; batch adversarial loss: 0.488415\n",
      "epoch 35; iter: 200; batch classifier loss: 0.562572; batch adversarial loss: 0.402553\n",
      "epoch 35; iter: 400; batch classifier loss: 0.602580; batch adversarial loss: 0.487491\n",
      "epoch 35; iter: 600; batch classifier loss: 0.635478; batch adversarial loss: 0.571651\n",
      "epoch 36; iter: 0; batch classifier loss: 0.663401; batch adversarial loss: 0.377815\n",
      "epoch 36; iter: 200; batch classifier loss: 0.591618; batch adversarial loss: 0.491114\n",
      "epoch 36; iter: 400; batch classifier loss: 0.623542; batch adversarial loss: 0.434894\n",
      "epoch 36; iter: 600; batch classifier loss: 0.634241; batch adversarial loss: 0.407216\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473927; batch adversarial loss: 0.456447\n",
      "epoch 37; iter: 200; batch classifier loss: 0.580285; batch adversarial loss: 0.463584\n",
      "epoch 37; iter: 400; batch classifier loss: 0.532794; batch adversarial loss: 0.432268\n",
      "epoch 37; iter: 600; batch classifier loss: 0.429516; batch adversarial loss: 0.484940\n",
      "epoch 38; iter: 0; batch classifier loss: 0.313672; batch adversarial loss: 0.491681\n",
      "epoch 38; iter: 200; batch classifier loss: 0.493441; batch adversarial loss: 0.456972\n",
      "epoch 38; iter: 400; batch classifier loss: 0.484600; batch adversarial loss: 0.514250\n",
      "epoch 38; iter: 600; batch classifier loss: 0.424164; batch adversarial loss: 0.458488\n",
      "epoch 39; iter: 0; batch classifier loss: 0.364704; batch adversarial loss: 0.376970\n",
      "epoch 39; iter: 200; batch classifier loss: 0.565333; batch adversarial loss: 0.379336\n",
      "epoch 39; iter: 400; batch classifier loss: 0.548570; batch adversarial loss: 0.352451\n",
      "epoch 39; iter: 600; batch classifier loss: 0.546882; batch adversarial loss: 0.489988\n",
      "epoch 40; iter: 0; batch classifier loss: 0.658990; batch adversarial loss: 0.348662\n",
      "epoch 40; iter: 200; batch classifier loss: 0.799914; batch adversarial loss: 0.381357\n",
      "epoch 40; iter: 400; batch classifier loss: 0.760801; batch adversarial loss: 0.488570\n",
      "epoch 40; iter: 600; batch classifier loss: 0.493248; batch adversarial loss: 0.431582\n",
      "epoch 41; iter: 0; batch classifier loss: 0.454368; batch adversarial loss: 0.488560\n",
      "epoch 41; iter: 200; batch classifier loss: 0.598733; batch adversarial loss: 0.269164\n",
      "epoch 41; iter: 400; batch classifier loss: 0.509848; batch adversarial loss: 0.378031\n",
      "epoch 41; iter: 600; batch classifier loss: 0.690668; batch adversarial loss: 0.488433\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449001; batch adversarial loss: 0.431813\n",
      "epoch 42; iter: 200; batch classifier loss: 0.612733; batch adversarial loss: 0.430691\n",
      "epoch 42; iter: 400; batch classifier loss: 0.669116; batch adversarial loss: 0.350944\n",
      "epoch 42; iter: 600; batch classifier loss: 0.787616; batch adversarial loss: 0.404637\n",
      "epoch 43; iter: 0; batch classifier loss: 0.513470; batch adversarial loss: 0.380318\n",
      "epoch 43; iter: 200; batch classifier loss: 0.791133; batch adversarial loss: 0.351018\n",
      "epoch 43; iter: 400; batch classifier loss: 0.699959; batch adversarial loss: 0.413500\n",
      "epoch 43; iter: 600; batch classifier loss: 0.847556; batch adversarial loss: 0.406533\n",
      "epoch 44; iter: 0; batch classifier loss: 0.777963; batch adversarial loss: 0.518009\n",
      "epoch 44; iter: 200; batch classifier loss: 0.361994; batch adversarial loss: 0.466261\n",
      "epoch 44; iter: 400; batch classifier loss: 0.596167; batch adversarial loss: 0.488865\n",
      "epoch 44; iter: 600; batch classifier loss: 0.358821; batch adversarial loss: 0.442996\n",
      "epoch 45; iter: 0; batch classifier loss: 0.933811; batch adversarial loss: 0.381177\n",
      "epoch 45; iter: 200; batch classifier loss: 0.446461; batch adversarial loss: 0.435159\n",
      "epoch 45; iter: 400; batch classifier loss: 0.852004; batch adversarial loss: 0.320158\n",
      "epoch 45; iter: 600; batch classifier loss: 0.802883; batch adversarial loss: 0.407760\n",
      "epoch 46; iter: 0; batch classifier loss: 0.485458; batch adversarial loss: 0.349648\n",
      "epoch 46; iter: 200; batch classifier loss: 0.691014; batch adversarial loss: 0.403845\n",
      "epoch 46; iter: 400; batch classifier loss: 0.905898; batch adversarial loss: 0.265126\n",
      "epoch 46; iter: 600; batch classifier loss: 0.572247; batch adversarial loss: 0.349576\n",
      "epoch 47; iter: 0; batch classifier loss: 0.661738; batch adversarial loss: 0.462957\n",
      "epoch 47; iter: 200; batch classifier loss: 0.773851; batch adversarial loss: 0.405733\n",
      "epoch 47; iter: 400; batch classifier loss: 0.624328; batch adversarial loss: 0.350958\n",
      "epoch 47; iter: 600; batch classifier loss: 0.713617; batch adversarial loss: 0.485062\n",
      "epoch 48; iter: 0; batch classifier loss: 0.787748; batch adversarial loss: 0.571837\n",
      "epoch 48; iter: 200; batch classifier loss: 0.830340; batch adversarial loss: 0.513613\n",
      "epoch 48; iter: 400; batch classifier loss: 0.926483; batch adversarial loss: 0.596999\n",
      "epoch 48; iter: 600; batch classifier loss: 0.606966; batch adversarial loss: 0.547278\n",
      "epoch 49; iter: 0; batch classifier loss: 0.362273; batch adversarial loss: 0.325075\n",
      "epoch 49; iter: 200; batch classifier loss: 0.956311; batch adversarial loss: 0.461207\n",
      "epoch 49; iter: 400; batch classifier loss: 0.988664; batch adversarial loss: 0.351268\n",
      "epoch 49; iter: 600; batch classifier loss: 0.537591; batch adversarial loss: 0.406083\n",
      "epoch 0; iter: 0; batch classifier loss: 5.551591; batch adversarial loss: 0.576244\n",
      "epoch 0; iter: 200; batch classifier loss: 10.816532; batch adversarial loss: 0.531114\n",
      "epoch 0; iter: 400; batch classifier loss: 5.719311; batch adversarial loss: 0.518666\n",
      "epoch 0; iter: 600; batch classifier loss: 4.235312; batch adversarial loss: 0.484445\n",
      "epoch 1; iter: 0; batch classifier loss: 3.775830; batch adversarial loss: 0.490467\n",
      "epoch 1; iter: 200; batch classifier loss: 4.308573; batch adversarial loss: 0.515347\n",
      "epoch 1; iter: 400; batch classifier loss: 5.962234; batch adversarial loss: 0.560899\n",
      "epoch 1; iter: 600; batch classifier loss: 6.841218; batch adversarial loss: 0.559702\n",
      "epoch 2; iter: 0; batch classifier loss: 3.894177; batch adversarial loss: 0.395488\n",
      "epoch 2; iter: 200; batch classifier loss: 8.942171; batch adversarial loss: 0.506976\n",
      "epoch 2; iter: 400; batch classifier loss: 21.968361; batch adversarial loss: 0.485567\n",
      "epoch 2; iter: 600; batch classifier loss: 2.752917; batch adversarial loss: 0.449578\n",
      "epoch 3; iter: 0; batch classifier loss: 1.650483; batch adversarial loss: 0.417474\n",
      "epoch 3; iter: 200; batch classifier loss: 2.860295; batch adversarial loss: 0.390809\n",
      "epoch 3; iter: 400; batch classifier loss: 2.963598; batch adversarial loss: 0.353147\n",
      "epoch 3; iter: 600; batch classifier loss: 4.149858; batch adversarial loss: 0.290137\n",
      "epoch 4; iter: 0; batch classifier loss: 1.295506; batch adversarial loss: 0.328137\n",
      "epoch 4; iter: 200; batch classifier loss: 0.518894; batch adversarial loss: 0.424893\n",
      "epoch 4; iter: 400; batch classifier loss: 1.569355; batch adversarial loss: 0.485730\n",
      "epoch 4; iter: 600; batch classifier loss: 0.450308; batch adversarial loss: 0.478358\n",
      "epoch 5; iter: 0; batch classifier loss: 0.805355; batch adversarial loss: 0.460585\n",
      "epoch 5; iter: 200; batch classifier loss: 1.008655; batch adversarial loss: 0.293075\n",
      "epoch 5; iter: 400; batch classifier loss: 1.666169; batch adversarial loss: 0.491016\n",
      "epoch 5; iter: 600; batch classifier loss: 0.757594; batch adversarial loss: 0.365718\n",
      "epoch 6; iter: 0; batch classifier loss: 0.873225; batch adversarial loss: 0.359462\n",
      "epoch 6; iter: 200; batch classifier loss: 0.531073; batch adversarial loss: 0.377511\n",
      "epoch 6; iter: 400; batch classifier loss: 0.533817; batch adversarial loss: 0.356432\n",
      "epoch 6; iter: 600; batch classifier loss: 0.483437; batch adversarial loss: 0.355314\n",
      "epoch 7; iter: 0; batch classifier loss: 0.448872; batch adversarial loss: 0.441818\n",
      "epoch 7; iter: 200; batch classifier loss: 0.329030; batch adversarial loss: 0.438676\n",
      "epoch 7; iter: 400; batch classifier loss: 0.603213; batch adversarial loss: 0.543010\n",
      "epoch 7; iter: 600; batch classifier loss: 0.367775; batch adversarial loss: 0.237616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.385690; batch adversarial loss: 0.376450\n",
      "epoch 8; iter: 200; batch classifier loss: 0.256457; batch adversarial loss: 0.447018\n",
      "epoch 8; iter: 400; batch classifier loss: 0.463426; batch adversarial loss: 0.418405\n",
      "epoch 8; iter: 600; batch classifier loss: 0.549145; batch adversarial loss: 0.322700\n",
      "epoch 9; iter: 0; batch classifier loss: 0.448063; batch adversarial loss: 0.357484\n",
      "epoch 9; iter: 200; batch classifier loss: 0.349278; batch adversarial loss: 0.355260\n",
      "epoch 9; iter: 400; batch classifier loss: 0.327628; batch adversarial loss: 0.351035\n",
      "epoch 9; iter: 600; batch classifier loss: 0.372381; batch adversarial loss: 0.285164\n",
      "epoch 10; iter: 0; batch classifier loss: 0.322774; batch adversarial loss: 0.522634\n",
      "epoch 10; iter: 200; batch classifier loss: 0.382506; batch adversarial loss: 0.454296\n",
      "epoch 10; iter: 400; batch classifier loss: 0.442484; batch adversarial loss: 0.469161\n",
      "epoch 10; iter: 600; batch classifier loss: 0.397540; batch adversarial loss: 0.429919\n",
      "epoch 11; iter: 0; batch classifier loss: 0.264576; batch adversarial loss: 0.391189\n",
      "epoch 11; iter: 200; batch classifier loss: 0.308377; batch adversarial loss: 0.387795\n",
      "epoch 11; iter: 400; batch classifier loss: 0.434242; batch adversarial loss: 0.315480\n",
      "epoch 11; iter: 600; batch classifier loss: 0.410411; batch adversarial loss: 0.340115\n",
      "epoch 12; iter: 0; batch classifier loss: 0.365995; batch adversarial loss: 0.451644\n",
      "epoch 12; iter: 200; batch classifier loss: 0.442533; batch adversarial loss: 0.451210\n",
      "epoch 12; iter: 400; batch classifier loss: 0.414984; batch adversarial loss: 0.309669\n",
      "epoch 12; iter: 600; batch classifier loss: 0.549256; batch adversarial loss: 0.363364\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279114; batch adversarial loss: 0.416751\n",
      "epoch 13; iter: 200; batch classifier loss: 0.346768; batch adversarial loss: 0.389890\n",
      "epoch 13; iter: 400; batch classifier loss: 0.215049; batch adversarial loss: 0.320836\n",
      "epoch 13; iter: 600; batch classifier loss: 0.361978; batch adversarial loss: 0.372416\n",
      "epoch 14; iter: 0; batch classifier loss: 0.377520; batch adversarial loss: 0.604504\n",
      "epoch 14; iter: 200; batch classifier loss: 0.307268; batch adversarial loss: 0.351144\n",
      "epoch 14; iter: 400; batch classifier loss: 0.376064; batch adversarial loss: 0.481495\n",
      "epoch 14; iter: 600; batch classifier loss: 0.311456; batch adversarial loss: 0.477455\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371762; batch adversarial loss: 0.342508\n",
      "epoch 15; iter: 200; batch classifier loss: 0.335965; batch adversarial loss: 0.545085\n",
      "epoch 15; iter: 400; batch classifier loss: 0.399938; batch adversarial loss: 0.316061\n",
      "epoch 15; iter: 600; batch classifier loss: 0.401224; batch adversarial loss: 0.369339\n",
      "epoch 16; iter: 0; batch classifier loss: 0.299866; batch adversarial loss: 0.262627\n",
      "epoch 16; iter: 200; batch classifier loss: 0.261982; batch adversarial loss: 0.468633\n",
      "epoch 16; iter: 400; batch classifier loss: 0.363635; batch adversarial loss: 0.284178\n",
      "epoch 16; iter: 600; batch classifier loss: 0.323421; batch adversarial loss: 0.380115\n",
      "epoch 17; iter: 0; batch classifier loss: 0.405217; batch adversarial loss: 0.435133\n",
      "epoch 17; iter: 200; batch classifier loss: 0.298421; batch adversarial loss: 0.416721\n",
      "epoch 17; iter: 400; batch classifier loss: 0.371641; batch adversarial loss: 0.453421\n",
      "epoch 17; iter: 600; batch classifier loss: 0.330276; batch adversarial loss: 0.427945\n",
      "epoch 18; iter: 0; batch classifier loss: 0.236119; batch adversarial loss: 0.343945\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321100; batch adversarial loss: 0.479714\n",
      "epoch 18; iter: 400; batch classifier loss: 0.364576; batch adversarial loss: 0.450409\n",
      "epoch 18; iter: 600; batch classifier loss: 0.290777; batch adversarial loss: 0.214250\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264785; batch adversarial loss: 0.368327\n",
      "epoch 19; iter: 200; batch classifier loss: 0.319559; batch adversarial loss: 0.504797\n",
      "epoch 19; iter: 400; batch classifier loss: 0.264862; batch adversarial loss: 0.467254\n",
      "epoch 19; iter: 600; batch classifier loss: 0.281408; batch adversarial loss: 0.297527\n",
      "epoch 20; iter: 0; batch classifier loss: 0.373770; batch adversarial loss: 0.458053\n",
      "epoch 20; iter: 200; batch classifier loss: 0.219647; batch adversarial loss: 0.371695\n",
      "epoch 20; iter: 400; batch classifier loss: 0.338810; batch adversarial loss: 0.533340\n",
      "epoch 20; iter: 600; batch classifier loss: 0.464202; batch adversarial loss: 0.390296\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355081; batch adversarial loss: 0.423968\n",
      "epoch 21; iter: 200; batch classifier loss: 0.215563; batch adversarial loss: 0.379112\n",
      "epoch 21; iter: 400; batch classifier loss: 0.328569; batch adversarial loss: 0.372802\n",
      "epoch 21; iter: 600; batch classifier loss: 0.275416; batch adversarial loss: 0.409625\n",
      "epoch 22; iter: 0; batch classifier loss: 0.236657; batch adversarial loss: 0.344191\n",
      "epoch 22; iter: 200; batch classifier loss: 0.397639; batch adversarial loss: 0.458210\n",
      "epoch 22; iter: 400; batch classifier loss: 0.299810; batch adversarial loss: 0.407743\n",
      "epoch 22; iter: 600; batch classifier loss: 0.337569; batch adversarial loss: 0.389701\n",
      "epoch 23; iter: 0; batch classifier loss: 0.367232; batch adversarial loss: 0.369325\n",
      "epoch 23; iter: 200; batch classifier loss: 0.312681; batch adversarial loss: 0.463826\n",
      "epoch 23; iter: 400; batch classifier loss: 0.375441; batch adversarial loss: 0.512680\n",
      "epoch 23; iter: 600; batch classifier loss: 0.361685; batch adversarial loss: 0.573038\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427052; batch adversarial loss: 0.391017\n",
      "epoch 24; iter: 200; batch classifier loss: 0.529330; batch adversarial loss: 0.434175\n",
      "epoch 24; iter: 400; batch classifier loss: 0.473209; batch adversarial loss: 0.410254\n",
      "epoch 24; iter: 600; batch classifier loss: 0.307174; batch adversarial loss: 0.616859\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279913; batch adversarial loss: 0.349023\n",
      "epoch 25; iter: 200; batch classifier loss: 0.287355; batch adversarial loss: 0.384845\n",
      "epoch 25; iter: 400; batch classifier loss: 0.346557; batch adversarial loss: 0.396367\n",
      "epoch 25; iter: 600; batch classifier loss: 0.396505; batch adversarial loss: 0.492959\n",
      "epoch 26; iter: 0; batch classifier loss: 0.564627; batch adversarial loss: 0.347192\n",
      "epoch 26; iter: 200; batch classifier loss: 0.337724; batch adversarial loss: 0.397135\n",
      "epoch 26; iter: 400; batch classifier loss: 0.398543; batch adversarial loss: 0.377424\n",
      "epoch 26; iter: 600; batch classifier loss: 0.300856; batch adversarial loss: 0.480242\n",
      "epoch 27; iter: 0; batch classifier loss: 0.453153; batch adversarial loss: 0.449591\n",
      "epoch 27; iter: 200; batch classifier loss: 0.335504; batch adversarial loss: 0.376055\n",
      "epoch 27; iter: 400; batch classifier loss: 0.244682; batch adversarial loss: 0.541587\n",
      "epoch 27; iter: 600; batch classifier loss: 0.282780; batch adversarial loss: 0.410668\n",
      "epoch 28; iter: 0; batch classifier loss: 0.302802; batch adversarial loss: 0.431496\n",
      "epoch 28; iter: 200; batch classifier loss: 0.449269; batch adversarial loss: 0.369245\n",
      "epoch 28; iter: 400; batch classifier loss: 0.423784; batch adversarial loss: 0.370211\n",
      "epoch 28; iter: 600; batch classifier loss: 0.450986; batch adversarial loss: 0.401041\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455064; batch adversarial loss: 0.353811\n",
      "epoch 29; iter: 200; batch classifier loss: 0.331483; batch adversarial loss: 0.319813\n",
      "epoch 29; iter: 400; batch classifier loss: 0.305812; batch adversarial loss: 0.470694\n",
      "epoch 29; iter: 600; batch classifier loss: 0.345639; batch adversarial loss: 0.296514\n",
      "epoch 30; iter: 0; batch classifier loss: 0.314240; batch adversarial loss: 0.429382\n",
      "epoch 30; iter: 200; batch classifier loss: 0.559399; batch adversarial loss: 0.429132\n",
      "epoch 30; iter: 400; batch classifier loss: 0.363807; batch adversarial loss: 0.455004\n",
      "epoch 30; iter: 600; batch classifier loss: 0.398135; batch adversarial loss: 0.516705\n",
      "epoch 31; iter: 0; batch classifier loss: 0.424493; batch adversarial loss: 0.512085\n",
      "epoch 31; iter: 200; batch classifier loss: 0.447382; batch adversarial loss: 0.400747\n",
      "epoch 31; iter: 400; batch classifier loss: 0.246585; batch adversarial loss: 0.430140\n",
      "epoch 31; iter: 600; batch classifier loss: 0.413183; batch adversarial loss: 0.461643\n",
      "epoch 32; iter: 0; batch classifier loss: 0.464374; batch adversarial loss: 0.407267\n",
      "epoch 32; iter: 200; batch classifier loss: 0.486422; batch adversarial loss: 0.381701\n",
      "epoch 32; iter: 400; batch classifier loss: 0.531426; batch adversarial loss: 0.349215\n",
      "epoch 32; iter: 600; batch classifier loss: 0.340236; batch adversarial loss: 0.487965\n",
      "epoch 33; iter: 0; batch classifier loss: 0.345395; batch adversarial loss: 0.403103\n",
      "epoch 33; iter: 200; batch classifier loss: 0.268360; batch adversarial loss: 0.484191\n",
      "epoch 33; iter: 400; batch classifier loss: 0.563331; batch adversarial loss: 0.455776\n",
      "epoch 33; iter: 600; batch classifier loss: 0.344185; batch adversarial loss: 0.523944\n",
      "epoch 34; iter: 0; batch classifier loss: 0.416647; batch adversarial loss: 0.406806\n",
      "epoch 34; iter: 200; batch classifier loss: 0.376529; batch adversarial loss: 0.460580\n",
      "epoch 34; iter: 400; batch classifier loss: 0.565037; batch adversarial loss: 0.495975\n",
      "epoch 34; iter: 600; batch classifier loss: 0.443590; batch adversarial loss: 0.373953\n",
      "epoch 35; iter: 0; batch classifier loss: 0.312655; batch adversarial loss: 0.458889\n",
      "epoch 35; iter: 200; batch classifier loss: 0.313190; batch adversarial loss: 0.349508\n",
      "epoch 35; iter: 400; batch classifier loss: 0.404271; batch adversarial loss: 0.545613\n",
      "epoch 35; iter: 600; batch classifier loss: 0.509677; batch adversarial loss: 0.544399\n",
      "epoch 36; iter: 0; batch classifier loss: 0.411421; batch adversarial loss: 0.401785\n",
      "epoch 36; iter: 200; batch classifier loss: 0.398461; batch adversarial loss: 0.404204\n",
      "epoch 36; iter: 400; batch classifier loss: 0.595273; batch adversarial loss: 0.518966\n",
      "epoch 36; iter: 600; batch classifier loss: 0.539488; batch adversarial loss: 0.409460\n",
      "epoch 37; iter: 0; batch classifier loss: 0.553888; batch adversarial loss: 0.316441\n",
      "epoch 37; iter: 200; batch classifier loss: 0.307340; batch adversarial loss: 0.570357\n",
      "epoch 37; iter: 400; batch classifier loss: 0.352710; batch adversarial loss: 0.378114\n",
      "epoch 37; iter: 600; batch classifier loss: 0.350940; batch adversarial loss: 0.430680\n",
      "epoch 38; iter: 0; batch classifier loss: 0.585449; batch adversarial loss: 0.379219\n",
      "epoch 38; iter: 200; batch classifier loss: 0.408558; batch adversarial loss: 0.406353\n",
      "epoch 38; iter: 400; batch classifier loss: 0.648932; batch adversarial loss: 0.489913\n",
      "epoch 38; iter: 600; batch classifier loss: 0.339142; batch adversarial loss: 0.375123\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436925; batch adversarial loss: 0.428984\n",
      "epoch 39; iter: 200; batch classifier loss: 0.410282; batch adversarial loss: 0.379090\n",
      "epoch 39; iter: 400; batch classifier loss: 0.481574; batch adversarial loss: 0.524224\n",
      "epoch 39; iter: 600; batch classifier loss: 0.544454; batch adversarial loss: 0.296652\n",
      "epoch 40; iter: 0; batch classifier loss: 0.358726; batch adversarial loss: 0.410482\n",
      "epoch 40; iter: 200; batch classifier loss: 0.334065; batch adversarial loss: 0.321437\n",
      "epoch 40; iter: 400; batch classifier loss: 0.346138; batch adversarial loss: 0.347836\n",
      "epoch 40; iter: 600; batch classifier loss: 0.623493; batch adversarial loss: 0.483521\n",
      "epoch 41; iter: 0; batch classifier loss: 0.503794; batch adversarial loss: 0.550077\n",
      "epoch 41; iter: 200; batch classifier loss: 0.438126; batch adversarial loss: 0.462265\n",
      "epoch 41; iter: 400; batch classifier loss: 0.301546; batch adversarial loss: 0.404274\n",
      "epoch 41; iter: 600; batch classifier loss: 0.312810; batch adversarial loss: 0.516048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.547723; batch adversarial loss: 0.321114\n",
      "epoch 42; iter: 200; batch classifier loss: 0.479094; batch adversarial loss: 0.541923\n",
      "epoch 42; iter: 400; batch classifier loss: 0.414418; batch adversarial loss: 0.461051\n",
      "epoch 42; iter: 600; batch classifier loss: 0.461916; batch adversarial loss: 0.406383\n",
      "epoch 43; iter: 0; batch classifier loss: 0.340593; batch adversarial loss: 0.442166\n",
      "epoch 43; iter: 200; batch classifier loss: 0.320565; batch adversarial loss: 0.379616\n",
      "epoch 43; iter: 400; batch classifier loss: 0.389559; batch adversarial loss: 0.515829\n",
      "epoch 43; iter: 600; batch classifier loss: 0.470875; batch adversarial loss: 0.376705\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444527; batch adversarial loss: 0.402083\n",
      "epoch 44; iter: 200; batch classifier loss: 0.510047; batch adversarial loss: 0.434614\n",
      "epoch 44; iter: 400; batch classifier loss: 0.515527; batch adversarial loss: 0.468231\n",
      "epoch 44; iter: 600; batch classifier loss: 0.318736; batch adversarial loss: 0.488515\n",
      "epoch 45; iter: 0; batch classifier loss: 0.485253; batch adversarial loss: 0.379791\n",
      "epoch 45; iter: 200; batch classifier loss: 0.392427; batch adversarial loss: 0.610206\n",
      "epoch 45; iter: 400; batch classifier loss: 0.420217; batch adversarial loss: 0.349654\n",
      "epoch 45; iter: 600; batch classifier loss: 0.467162; batch adversarial loss: 0.349869\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331137; batch adversarial loss: 0.406256\n",
      "epoch 46; iter: 200; batch classifier loss: 0.299856; batch adversarial loss: 0.349012\n",
      "epoch 46; iter: 400; batch classifier loss: 0.480933; batch adversarial loss: 0.322126\n",
      "epoch 46; iter: 600; batch classifier loss: 0.534929; batch adversarial loss: 0.602306\n",
      "epoch 47; iter: 0; batch classifier loss: 0.342475; batch adversarial loss: 0.487410\n",
      "epoch 47; iter: 200; batch classifier loss: 0.403568; batch adversarial loss: 0.430997\n",
      "epoch 47; iter: 400; batch classifier loss: 0.408846; batch adversarial loss: 0.486050\n",
      "epoch 47; iter: 600; batch classifier loss: 0.407702; batch adversarial loss: 0.461027\n",
      "epoch 48; iter: 0; batch classifier loss: 0.286183; batch adversarial loss: 0.436894\n",
      "epoch 48; iter: 200; batch classifier loss: 0.416377; batch adversarial loss: 0.377894\n",
      "epoch 48; iter: 400; batch classifier loss: 0.534656; batch adversarial loss: 0.459643\n",
      "epoch 48; iter: 600; batch classifier loss: 0.330710; batch adversarial loss: 0.405960\n",
      "epoch 49; iter: 0; batch classifier loss: 0.420410; batch adversarial loss: 0.461738\n",
      "epoch 49; iter: 200; batch classifier loss: 0.272094; batch adversarial loss: 0.325635\n",
      "epoch 49; iter: 400; batch classifier loss: 0.784924; batch adversarial loss: 0.460924\n",
      "epoch 49; iter: 600; batch classifier loss: 0.643124; batch adversarial loss: 0.347548\n",
      "epoch 0; iter: 0; batch classifier loss: 40.156204; batch adversarial loss: 0.760618\n",
      "epoch 0; iter: 200; batch classifier loss: 11.434597; batch adversarial loss: 0.636229\n",
      "epoch 0; iter: 400; batch classifier loss: 13.233858; batch adversarial loss: 0.603319\n",
      "epoch 0; iter: 600; batch classifier loss: 2.144441; batch adversarial loss: 0.537019\n",
      "epoch 1; iter: 0; batch classifier loss: 8.989926; batch adversarial loss: 0.540470\n",
      "epoch 1; iter: 200; batch classifier loss: 7.100118; batch adversarial loss: 0.467722\n",
      "epoch 1; iter: 400; batch classifier loss: 2.139743; batch adversarial loss: 0.530713\n",
      "epoch 1; iter: 600; batch classifier loss: 8.862834; batch adversarial loss: 0.453050\n",
      "epoch 2; iter: 0; batch classifier loss: 4.647151; batch adversarial loss: 0.449142\n",
      "epoch 2; iter: 200; batch classifier loss: 4.658117; batch adversarial loss: 0.395626\n",
      "epoch 2; iter: 400; batch classifier loss: 1.643077; batch adversarial loss: 0.338096\n",
      "epoch 2; iter: 600; batch classifier loss: 5.330180; batch adversarial loss: 0.577073\n",
      "epoch 3; iter: 0; batch classifier loss: 3.270908; batch adversarial loss: 0.370875\n",
      "epoch 3; iter: 200; batch classifier loss: 2.024144; batch adversarial loss: 0.419140\n",
      "epoch 3; iter: 400; batch classifier loss: 2.520645; batch adversarial loss: 0.493862\n",
      "epoch 3; iter: 600; batch classifier loss: 3.787575; batch adversarial loss: 0.340575\n",
      "epoch 4; iter: 0; batch classifier loss: 3.211840; batch adversarial loss: 0.496665\n",
      "epoch 4; iter: 200; batch classifier loss: 2.678176; batch adversarial loss: 0.504712\n",
      "epoch 4; iter: 400; batch classifier loss: 0.345850; batch adversarial loss: 0.510594\n",
      "epoch 4; iter: 600; batch classifier loss: 1.665540; batch adversarial loss: 0.408688\n",
      "epoch 5; iter: 0; batch classifier loss: 0.353317; batch adversarial loss: 0.512316\n",
      "epoch 5; iter: 200; batch classifier loss: 1.731249; batch adversarial loss: 0.410855\n",
      "epoch 5; iter: 400; batch classifier loss: 0.805362; batch adversarial loss: 0.387479\n",
      "epoch 5; iter: 600; batch classifier loss: 0.405484; batch adversarial loss: 0.360471\n",
      "epoch 6; iter: 0; batch classifier loss: 0.394590; batch adversarial loss: 0.426784\n",
      "epoch 6; iter: 200; batch classifier loss: 0.729571; batch adversarial loss: 0.353912\n",
      "epoch 6; iter: 400; batch classifier loss: 0.886006; batch adversarial loss: 0.501587\n",
      "epoch 6; iter: 600; batch classifier loss: 1.474684; batch adversarial loss: 0.445792\n",
      "epoch 7; iter: 0; batch classifier loss: 0.397359; batch adversarial loss: 0.507707\n",
      "epoch 7; iter: 200; batch classifier loss: 0.404577; batch adversarial loss: 0.371461\n",
      "epoch 7; iter: 400; batch classifier loss: 0.381175; batch adversarial loss: 0.429049\n",
      "epoch 7; iter: 600; batch classifier loss: 0.386149; batch adversarial loss: 0.400933\n",
      "epoch 8; iter: 0; batch classifier loss: 0.424447; batch adversarial loss: 0.433172\n",
      "epoch 8; iter: 200; batch classifier loss: 0.318696; batch adversarial loss: 0.325915\n",
      "epoch 8; iter: 400; batch classifier loss: 0.522091; batch adversarial loss: 0.386765\n",
      "epoch 8; iter: 600; batch classifier loss: 0.403012; batch adversarial loss: 0.409940\n",
      "epoch 9; iter: 0; batch classifier loss: 0.366332; batch adversarial loss: 0.515004\n",
      "epoch 9; iter: 200; batch classifier loss: 0.453259; batch adversarial loss: 0.322037\n",
      "epoch 9; iter: 400; batch classifier loss: 0.461156; batch adversarial loss: 0.373405\n",
      "epoch 9; iter: 600; batch classifier loss: 0.383633; batch adversarial loss: 0.374216\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434445; batch adversarial loss: 0.428123\n",
      "epoch 10; iter: 200; batch classifier loss: 0.288274; batch adversarial loss: 0.406091\n",
      "epoch 10; iter: 400; batch classifier loss: 0.368587; batch adversarial loss: 0.443961\n",
      "epoch 10; iter: 600; batch classifier loss: 0.350180; batch adversarial loss: 0.257646\n",
      "epoch 11; iter: 0; batch classifier loss: 0.288483; batch adversarial loss: 0.379286\n",
      "epoch 11; iter: 200; batch classifier loss: 0.354492; batch adversarial loss: 0.287840\n",
      "epoch 11; iter: 400; batch classifier loss: 0.371309; batch adversarial loss: 0.281394\n",
      "epoch 11; iter: 600; batch classifier loss: 0.327445; batch adversarial loss: 0.426390\n",
      "epoch 12; iter: 0; batch classifier loss: 0.320875; batch adversarial loss: 0.448153\n",
      "epoch 12; iter: 200; batch classifier loss: 0.318627; batch adversarial loss: 0.625933\n",
      "epoch 12; iter: 400; batch classifier loss: 0.298279; batch adversarial loss: 0.320688\n",
      "epoch 12; iter: 600; batch classifier loss: 0.363769; batch adversarial loss: 0.386145\n",
      "epoch 13; iter: 0; batch classifier loss: 0.276877; batch adversarial loss: 0.481616\n",
      "epoch 13; iter: 200; batch classifier loss: 0.302702; batch adversarial loss: 0.395276\n",
      "epoch 13; iter: 400; batch classifier loss: 0.294979; batch adversarial loss: 0.505086\n",
      "epoch 13; iter: 600; batch classifier loss: 0.243436; batch adversarial loss: 0.450402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.328835; batch adversarial loss: 0.590414\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388823; batch adversarial loss: 0.373164\n",
      "epoch 14; iter: 400; batch classifier loss: 0.251719; batch adversarial loss: 0.343626\n",
      "epoch 14; iter: 600; batch classifier loss: 0.342983; batch adversarial loss: 0.478243\n",
      "epoch 15; iter: 0; batch classifier loss: 0.380153; batch adversarial loss: 0.408957\n",
      "epoch 15; iter: 200; batch classifier loss: 0.307091; batch adversarial loss: 0.466502\n",
      "epoch 15; iter: 400; batch classifier loss: 0.369206; batch adversarial loss: 0.425646\n",
      "epoch 15; iter: 600; batch classifier loss: 0.384316; batch adversarial loss: 0.265265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330340; batch adversarial loss: 0.453073\n",
      "epoch 16; iter: 200; batch classifier loss: 0.306669; batch adversarial loss: 0.399404\n",
      "epoch 16; iter: 400; batch classifier loss: 0.223611; batch adversarial loss: 0.401042\n",
      "epoch 16; iter: 600; batch classifier loss: 0.386865; batch adversarial loss: 0.403489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.280291; batch adversarial loss: 0.381714\n",
      "epoch 17; iter: 200; batch classifier loss: 0.434882; batch adversarial loss: 0.326221\n",
      "epoch 17; iter: 400; batch classifier loss: 0.266641; batch adversarial loss: 0.318163\n",
      "epoch 17; iter: 600; batch classifier loss: 0.492462; batch adversarial loss: 0.434410\n",
      "epoch 18; iter: 0; batch classifier loss: 0.747972; batch adversarial loss: 0.289922\n",
      "epoch 18; iter: 200; batch classifier loss: 0.495923; batch adversarial loss: 0.300941\n",
      "epoch 18; iter: 400; batch classifier loss: 0.344301; batch adversarial loss: 0.479569\n",
      "epoch 18; iter: 600; batch classifier loss: 0.474551; batch adversarial loss: 0.406323\n",
      "epoch 19; iter: 0; batch classifier loss: 0.499930; batch adversarial loss: 0.524159\n",
      "epoch 19; iter: 200; batch classifier loss: 0.311528; batch adversarial loss: 0.354995\n",
      "epoch 19; iter: 400; batch classifier loss: 0.536475; batch adversarial loss: 0.466426\n",
      "epoch 19; iter: 600; batch classifier loss: 0.465272; batch adversarial loss: 0.352527\n",
      "epoch 20; iter: 0; batch classifier loss: 0.334940; batch adversarial loss: 0.468056\n",
      "epoch 20; iter: 200; batch classifier loss: 0.447692; batch adversarial loss: 0.401816\n",
      "epoch 20; iter: 400; batch classifier loss: 0.265857; batch adversarial loss: 0.382764\n",
      "epoch 20; iter: 600; batch classifier loss: 0.596619; batch adversarial loss: 0.372464\n",
      "epoch 21; iter: 0; batch classifier loss: 0.457045; batch adversarial loss: 0.398218\n",
      "epoch 21; iter: 200; batch classifier loss: 0.311900; batch adversarial loss: 0.487316\n",
      "epoch 21; iter: 400; batch classifier loss: 0.618883; batch adversarial loss: 0.325772\n",
      "epoch 21; iter: 600; batch classifier loss: 0.497140; batch adversarial loss: 0.272090\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451834; batch adversarial loss: 0.350271\n",
      "epoch 22; iter: 200; batch classifier loss: 0.382710; batch adversarial loss: 0.320376\n",
      "epoch 22; iter: 400; batch classifier loss: 0.400845; batch adversarial loss: 0.320623\n",
      "epoch 22; iter: 600; batch classifier loss: 0.605754; batch adversarial loss: 0.422802\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339619; batch adversarial loss: 0.346972\n",
      "epoch 23; iter: 200; batch classifier loss: 0.471479; batch adversarial loss: 0.376762\n",
      "epoch 23; iter: 400; batch classifier loss: 0.456244; batch adversarial loss: 0.355312\n",
      "epoch 23; iter: 600; batch classifier loss: 0.508226; batch adversarial loss: 0.460694\n",
      "epoch 24; iter: 0; batch classifier loss: 0.638875; batch adversarial loss: 0.463322\n",
      "epoch 24; iter: 200; batch classifier loss: 0.581944; batch adversarial loss: 0.382938\n",
      "epoch 24; iter: 400; batch classifier loss: 0.444462; batch adversarial loss: 0.354375\n",
      "epoch 24; iter: 600; batch classifier loss: 0.467286; batch adversarial loss: 0.299863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432442; batch adversarial loss: 0.372660\n",
      "epoch 25; iter: 200; batch classifier loss: 0.362247; batch adversarial loss: 0.379107\n",
      "epoch 25; iter: 400; batch classifier loss: 0.393823; batch adversarial loss: 0.385484\n",
      "epoch 25; iter: 600; batch classifier loss: 0.496260; batch adversarial loss: 0.487180\n",
      "epoch 26; iter: 0; batch classifier loss: 0.588050; batch adversarial loss: 0.483765\n",
      "epoch 26; iter: 200; batch classifier loss: 0.503575; batch adversarial loss: 0.442493\n",
      "epoch 26; iter: 400; batch classifier loss: 0.514216; batch adversarial loss: 0.542414\n",
      "epoch 26; iter: 600; batch classifier loss: 0.500647; batch adversarial loss: 0.365679\n",
      "epoch 27; iter: 0; batch classifier loss: 0.574310; batch adversarial loss: 0.374222\n",
      "epoch 27; iter: 200; batch classifier loss: 0.494821; batch adversarial loss: 0.405420\n",
      "epoch 27; iter: 400; batch classifier loss: 0.390420; batch adversarial loss: 0.405745\n",
      "epoch 27; iter: 600; batch classifier loss: 0.701344; batch adversarial loss: 0.406936\n",
      "epoch 28; iter: 0; batch classifier loss: 0.295648; batch adversarial loss: 0.460721\n",
      "epoch 28; iter: 200; batch classifier loss: 0.581224; batch adversarial loss: 0.493659\n",
      "epoch 28; iter: 400; batch classifier loss: 0.615083; batch adversarial loss: 0.459521\n",
      "epoch 28; iter: 600; batch classifier loss: 0.472043; batch adversarial loss: 0.403561\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491801; batch adversarial loss: 0.375538\n",
      "epoch 29; iter: 200; batch classifier loss: 0.546144; batch adversarial loss: 0.488396\n",
      "epoch 29; iter: 400; batch classifier loss: 0.553423; batch adversarial loss: 0.462806\n",
      "epoch 29; iter: 600; batch classifier loss: 0.645684; batch adversarial loss: 0.264696\n",
      "epoch 30; iter: 0; batch classifier loss: 0.351217; batch adversarial loss: 0.408175\n",
      "epoch 30; iter: 200; batch classifier loss: 0.452429; batch adversarial loss: 0.409812\n",
      "epoch 30; iter: 400; batch classifier loss: 0.551915; batch adversarial loss: 0.322049\n",
      "epoch 30; iter: 600; batch classifier loss: 0.478439; batch adversarial loss: 0.434848\n",
      "epoch 31; iter: 0; batch classifier loss: 0.331155; batch adversarial loss: 0.601229\n",
      "epoch 31; iter: 200; batch classifier loss: 0.519623; batch adversarial loss: 0.426272\n",
      "epoch 31; iter: 400; batch classifier loss: 0.553412; batch adversarial loss: 0.461509\n",
      "epoch 31; iter: 600; batch classifier loss: 0.553267; batch adversarial loss: 0.514954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.511434; batch adversarial loss: 0.353511\n",
      "epoch 32; iter: 200; batch classifier loss: 0.589733; batch adversarial loss: 0.461520\n",
      "epoch 32; iter: 400; batch classifier loss: 0.694570; batch adversarial loss: 0.298147\n",
      "epoch 32; iter: 600; batch classifier loss: 0.551199; batch adversarial loss: 0.459850\n",
      "epoch 33; iter: 0; batch classifier loss: 0.521625; batch adversarial loss: 0.434445\n",
      "epoch 33; iter: 200; batch classifier loss: 0.404463; batch adversarial loss: 0.300158\n",
      "epoch 33; iter: 400; batch classifier loss: 0.468448; batch adversarial loss: 0.659980\n",
      "epoch 33; iter: 600; batch classifier loss: 0.389966; batch adversarial loss: 0.430556\n",
      "epoch 34; iter: 0; batch classifier loss: 0.659812; batch adversarial loss: 0.329621\n",
      "epoch 34; iter: 200; batch classifier loss: 0.463464; batch adversarial loss: 0.456390\n",
      "epoch 34; iter: 400; batch classifier loss: 0.599234; batch adversarial loss: 0.510945\n",
      "epoch 34; iter: 600; batch classifier loss: 0.506925; batch adversarial loss: 0.407236\n",
      "epoch 35; iter: 0; batch classifier loss: 0.548191; batch adversarial loss: 0.435664\n",
      "epoch 35; iter: 200; batch classifier loss: 0.679474; batch adversarial loss: 0.326374\n",
      "epoch 35; iter: 400; batch classifier loss: 0.621162; batch adversarial loss: 0.291266\n",
      "epoch 35; iter: 600; batch classifier loss: 0.429970; batch adversarial loss: 0.412066\n",
      "epoch 36; iter: 0; batch classifier loss: 0.630888; batch adversarial loss: 0.303343\n",
      "epoch 36; iter: 200; batch classifier loss: 0.509928; batch adversarial loss: 0.350569\n",
      "epoch 36; iter: 400; batch classifier loss: 0.602953; batch adversarial loss: 0.240529\n",
      "epoch 36; iter: 600; batch classifier loss: 0.499544; batch adversarial loss: 0.456730\n",
      "epoch 37; iter: 0; batch classifier loss: 0.618383; batch adversarial loss: 0.294539\n",
      "epoch 37; iter: 200; batch classifier loss: 0.440749; batch adversarial loss: 0.377738\n",
      "epoch 37; iter: 400; batch classifier loss: 0.371406; batch adversarial loss: 0.346507\n",
      "epoch 37; iter: 600; batch classifier loss: 0.670661; batch adversarial loss: 0.431134\n",
      "epoch 38; iter: 0; batch classifier loss: 0.934995; batch adversarial loss: 0.514395\n",
      "epoch 38; iter: 200; batch classifier loss: 0.837093; batch adversarial loss: 0.463714\n",
      "epoch 38; iter: 400; batch classifier loss: 0.723803; batch adversarial loss: 0.401163\n",
      "epoch 38; iter: 600; batch classifier loss: 0.557495; batch adversarial loss: 0.403729\n",
      "epoch 39; iter: 0; batch classifier loss: 0.570219; batch adversarial loss: 0.546228\n",
      "epoch 39; iter: 200; batch classifier loss: 0.465758; batch adversarial loss: 0.378823\n",
      "epoch 39; iter: 400; batch classifier loss: 0.617095; batch adversarial loss: 0.295623\n",
      "epoch 39; iter: 600; batch classifier loss: 0.536028; batch adversarial loss: 0.462031\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520338; batch adversarial loss: 0.511033\n",
      "epoch 40; iter: 200; batch classifier loss: 0.576796; batch adversarial loss: 0.484456\n",
      "epoch 40; iter: 400; batch classifier loss: 0.458117; batch adversarial loss: 0.321964\n",
      "epoch 40; iter: 600; batch classifier loss: 0.595036; batch adversarial loss: 0.344905\n",
      "epoch 41; iter: 0; batch classifier loss: 0.308500; batch adversarial loss: 0.402123\n",
      "epoch 41; iter: 200; batch classifier loss: 0.731065; batch adversarial loss: 0.488875\n",
      "epoch 41; iter: 400; batch classifier loss: 0.569437; batch adversarial loss: 0.416560\n",
      "epoch 41; iter: 600; batch classifier loss: 0.678891; batch adversarial loss: 0.408646\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440794; batch adversarial loss: 0.433986\n",
      "epoch 42; iter: 200; batch classifier loss: 0.423848; batch adversarial loss: 0.353590\n",
      "epoch 42; iter: 400; batch classifier loss: 0.547836; batch adversarial loss: 0.411996\n",
      "epoch 42; iter: 600; batch classifier loss: 0.594605; batch adversarial loss: 0.294060\n",
      "epoch 43; iter: 0; batch classifier loss: 0.522518; batch adversarial loss: 0.379415\n",
      "epoch 43; iter: 200; batch classifier loss: 0.426235; batch adversarial loss: 0.426987\n",
      "epoch 43; iter: 400; batch classifier loss: 0.615908; batch adversarial loss: 0.460197\n",
      "epoch 43; iter: 600; batch classifier loss: 0.637767; batch adversarial loss: 0.459780\n",
      "epoch 44; iter: 0; batch classifier loss: 0.742288; batch adversarial loss: 0.320799\n",
      "epoch 44; iter: 200; batch classifier loss: 0.725590; batch adversarial loss: 0.409337\n",
      "epoch 44; iter: 400; batch classifier loss: 0.703599; batch adversarial loss: 0.292956\n",
      "epoch 44; iter: 600; batch classifier loss: 0.375785; batch adversarial loss: 0.568322\n",
      "epoch 45; iter: 0; batch classifier loss: 0.516013; batch adversarial loss: 0.429580\n",
      "epoch 45; iter: 200; batch classifier loss: 0.726906; batch adversarial loss: 0.485432\n",
      "epoch 45; iter: 400; batch classifier loss: 0.574977; batch adversarial loss: 0.348447\n",
      "epoch 45; iter: 600; batch classifier loss: 0.353791; batch adversarial loss: 0.488934\n",
      "epoch 46; iter: 0; batch classifier loss: 0.267295; batch adversarial loss: 0.508647\n",
      "epoch 46; iter: 200; batch classifier loss: 0.487386; batch adversarial loss: 0.378086\n",
      "epoch 46; iter: 400; batch classifier loss: 0.415894; batch adversarial loss: 0.520061\n",
      "epoch 46; iter: 600; batch classifier loss: 0.449382; batch adversarial loss: 0.409761\n",
      "epoch 47; iter: 0; batch classifier loss: 0.656620; batch adversarial loss: 0.433292\n",
      "epoch 47; iter: 200; batch classifier loss: 0.570428; batch adversarial loss: 0.355734\n",
      "epoch 47; iter: 400; batch classifier loss: 0.567032; batch adversarial loss: 0.352158\n",
      "epoch 47; iter: 600; batch classifier loss: 0.586603; batch adversarial loss: 0.294424\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418034; batch adversarial loss: 0.434702\n",
      "epoch 48; iter: 200; batch classifier loss: 0.848996; batch adversarial loss: 0.539840\n",
      "epoch 48; iter: 400; batch classifier loss: 1.079196; batch adversarial loss: 0.524146\n",
      "epoch 48; iter: 600; batch classifier loss: 0.685018; batch adversarial loss: 0.438547\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463336; batch adversarial loss: 0.452791\n",
      "epoch 49; iter: 200; batch classifier loss: 0.769352; batch adversarial loss: 0.347471\n",
      "epoch 49; iter: 400; batch classifier loss: 0.489878; batch adversarial loss: 0.433574\n",
      "epoch 49; iter: 600; batch classifier loss: 0.301527; batch adversarial loss: 0.353117\n",
      "epoch 0; iter: 0; batch classifier loss: 16.774338; batch adversarial loss: 0.469046\n",
      "epoch 0; iter: 200; batch classifier loss: 0.557990; batch adversarial loss: 0.574547\n",
      "epoch 0; iter: 400; batch classifier loss: 4.296859; batch adversarial loss: 0.509276\n",
      "epoch 0; iter: 600; batch classifier loss: 12.273428; batch adversarial loss: 0.472676\n",
      "epoch 1; iter: 0; batch classifier loss: 3.201404; batch adversarial loss: 0.508449\n",
      "epoch 1; iter: 200; batch classifier loss: 6.543946; batch adversarial loss: 0.478018\n",
      "epoch 1; iter: 400; batch classifier loss: 14.940454; batch adversarial loss: 0.490427\n",
      "epoch 1; iter: 600; batch classifier loss: 0.854672; batch adversarial loss: 0.430248\n",
      "epoch 2; iter: 0; batch classifier loss: 3.658091; batch adversarial loss: 0.309617\n",
      "epoch 2; iter: 200; batch classifier loss: 3.258182; batch adversarial loss: 0.392641\n",
      "epoch 2; iter: 400; batch classifier loss: 2.187474; batch adversarial loss: 0.354091\n",
      "epoch 2; iter: 600; batch classifier loss: 4.871968; batch adversarial loss: 0.475882\n",
      "epoch 3; iter: 0; batch classifier loss: 0.501344; batch adversarial loss: 0.463616\n",
      "epoch 3; iter: 200; batch classifier loss: 2.243340; batch adversarial loss: 0.584105\n",
      "epoch 3; iter: 400; batch classifier loss: 2.378263; batch adversarial loss: 0.521143\n",
      "epoch 3; iter: 600; batch classifier loss: 0.446284; batch adversarial loss: 0.467447\n",
      "epoch 4; iter: 0; batch classifier loss: 1.465279; batch adversarial loss: 0.395471\n",
      "epoch 4; iter: 200; batch classifier loss: 0.480040; batch adversarial loss: 0.288712\n",
      "epoch 4; iter: 400; batch classifier loss: 0.462445; batch adversarial loss: 0.462355\n",
      "epoch 4; iter: 600; batch classifier loss: 1.049897; batch adversarial loss: 0.416397\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548806; batch adversarial loss: 0.411878\n",
      "epoch 5; iter: 200; batch classifier loss: 0.696858; batch adversarial loss: 0.435485\n",
      "epoch 5; iter: 400; batch classifier loss: 0.557269; batch adversarial loss: 0.519517\n",
      "epoch 5; iter: 600; batch classifier loss: 1.988130; batch adversarial loss: 0.431408\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502353; batch adversarial loss: 0.277967\n",
      "epoch 6; iter: 200; batch classifier loss: 0.538337; batch adversarial loss: 0.462254\n",
      "epoch 6; iter: 400; batch classifier loss: 0.859046; batch adversarial loss: 0.535088\n",
      "epoch 6; iter: 600; batch classifier loss: 0.391557; batch adversarial loss: 0.348266\n",
      "epoch 7; iter: 0; batch classifier loss: 0.384693; batch adversarial loss: 0.483650\n",
      "epoch 7; iter: 200; batch classifier loss: 0.498211; batch adversarial loss: 0.432780\n",
      "epoch 7; iter: 400; batch classifier loss: 0.551284; batch adversarial loss: 0.405915\n",
      "epoch 7; iter: 600; batch classifier loss: 0.457547; batch adversarial loss: 0.491547\n",
      "epoch 8; iter: 0; batch classifier loss: 0.353186; batch adversarial loss: 0.373283\n",
      "epoch 8; iter: 200; batch classifier loss: 0.721940; batch adversarial loss: 0.269454\n",
      "epoch 8; iter: 400; batch classifier loss: 0.385735; batch adversarial loss: 0.426985\n",
      "epoch 8; iter: 600; batch classifier loss: 0.423134; batch adversarial loss: 0.538096\n",
      "epoch 9; iter: 0; batch classifier loss: 0.413516; batch adversarial loss: 0.458397\n",
      "epoch 9; iter: 200; batch classifier loss: 0.313314; batch adversarial loss: 0.451201\n",
      "epoch 9; iter: 400; batch classifier loss: 0.577285; batch adversarial loss: 0.449762\n",
      "epoch 9; iter: 600; batch classifier loss: 0.255296; batch adversarial loss: 0.563424\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288651; batch adversarial loss: 0.349947\n",
      "epoch 10; iter: 200; batch classifier loss: 0.453129; batch adversarial loss: 0.476354\n",
      "epoch 10; iter: 400; batch classifier loss: 0.356705; batch adversarial loss: 0.321835\n",
      "epoch 10; iter: 600; batch classifier loss: 0.473701; batch adversarial loss: 0.427040\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373826; batch adversarial loss: 0.445529\n",
      "epoch 11; iter: 200; batch classifier loss: 0.363165; batch adversarial loss: 0.426120\n",
      "epoch 11; iter: 400; batch classifier loss: 0.393415; batch adversarial loss: 0.368592\n",
      "epoch 11; iter: 600; batch classifier loss: 0.341452; batch adversarial loss: 0.425136\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299857; batch adversarial loss: 0.505202\n",
      "epoch 12; iter: 200; batch classifier loss: 0.338682; batch adversarial loss: 0.462433\n",
      "epoch 12; iter: 400; batch classifier loss: 0.407940; batch adversarial loss: 0.399347\n",
      "epoch 12; iter: 600; batch classifier loss: 0.266583; batch adversarial loss: 0.372668\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341419; batch adversarial loss: 0.520958\n",
      "epoch 13; iter: 200; batch classifier loss: 0.389244; batch adversarial loss: 0.376316\n",
      "epoch 13; iter: 400; batch classifier loss: 0.433437; batch adversarial loss: 0.479518\n",
      "epoch 13; iter: 600; batch classifier loss: 0.269395; batch adversarial loss: 0.420854\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387876; batch adversarial loss: 0.298829\n",
      "epoch 14; iter: 200; batch classifier loss: 0.333359; batch adversarial loss: 0.431258\n",
      "epoch 14; iter: 400; batch classifier loss: 0.334624; batch adversarial loss: 0.492587\n",
      "epoch 14; iter: 600; batch classifier loss: 0.462483; batch adversarial loss: 0.405460\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372875; batch adversarial loss: 0.506573\n",
      "epoch 15; iter: 200; batch classifier loss: 0.400740; batch adversarial loss: 0.319270\n",
      "epoch 15; iter: 400; batch classifier loss: 0.307631; batch adversarial loss: 0.264463\n",
      "epoch 15; iter: 600; batch classifier loss: 0.421585; batch adversarial loss: 0.401320\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346739; batch adversarial loss: 0.384490\n",
      "epoch 16; iter: 200; batch classifier loss: 0.299327; batch adversarial loss: 0.512448\n",
      "epoch 16; iter: 400; batch classifier loss: 0.434162; batch adversarial loss: 0.345739\n",
      "epoch 16; iter: 600; batch classifier loss: 0.308938; batch adversarial loss: 0.337981\n",
      "epoch 17; iter: 0; batch classifier loss: 0.417422; batch adversarial loss: 0.479712\n",
      "epoch 17; iter: 200; batch classifier loss: 0.302372; batch adversarial loss: 0.371248\n",
      "epoch 17; iter: 400; batch classifier loss: 0.295424; batch adversarial loss: 0.481439\n",
      "epoch 17; iter: 600; batch classifier loss: 0.292570; batch adversarial loss: 0.433117\n",
      "epoch 18; iter: 0; batch classifier loss: 0.363498; batch adversarial loss: 0.454012\n",
      "epoch 18; iter: 200; batch classifier loss: 0.316072; batch adversarial loss: 0.468222\n",
      "epoch 18; iter: 400; batch classifier loss: 0.431859; batch adversarial loss: 0.240543\n",
      "epoch 18; iter: 600; batch classifier loss: 0.293863; batch adversarial loss: 0.457048\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543808; batch adversarial loss: 0.380908\n",
      "epoch 19; iter: 200; batch classifier loss: 0.363976; batch adversarial loss: 0.409429\n",
      "epoch 19; iter: 400; batch classifier loss: 0.388190; batch adversarial loss: 0.461221\n",
      "epoch 19; iter: 600; batch classifier loss: 0.436191; batch adversarial loss: 0.434028\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288322; batch adversarial loss: 0.357255\n",
      "epoch 20; iter: 200; batch classifier loss: 0.527609; batch adversarial loss: 0.350617\n",
      "epoch 20; iter: 400; batch classifier loss: 0.530127; batch adversarial loss: 0.400000\n",
      "epoch 20; iter: 600; batch classifier loss: 0.437318; batch adversarial loss: 0.469543\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535553; batch adversarial loss: 0.525394\n",
      "epoch 21; iter: 200; batch classifier loss: 0.381304; batch adversarial loss: 0.541543\n",
      "epoch 21; iter: 400; batch classifier loss: 0.338339; batch adversarial loss: 0.479563\n",
      "epoch 21; iter: 600; batch classifier loss: 0.726953; batch adversarial loss: 0.438686\n",
      "epoch 22; iter: 0; batch classifier loss: 0.278800; batch adversarial loss: 0.428892\n",
      "epoch 22; iter: 200; batch classifier loss: 0.363704; batch adversarial loss: 0.214499\n",
      "epoch 22; iter: 400; batch classifier loss: 0.428067; batch adversarial loss: 0.512239\n",
      "epoch 22; iter: 600; batch classifier loss: 0.349591; batch adversarial loss: 0.460356\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452193; batch adversarial loss: 0.519065\n",
      "epoch 23; iter: 200; batch classifier loss: 0.465882; batch adversarial loss: 0.340358\n",
      "epoch 23; iter: 400; batch classifier loss: 0.516793; batch adversarial loss: 0.498639\n",
      "epoch 23; iter: 600; batch classifier loss: 0.364097; batch adversarial loss: 0.454622\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505886; batch adversarial loss: 0.461377\n",
      "epoch 24; iter: 200; batch classifier loss: 0.375045; batch adversarial loss: 0.353499\n",
      "epoch 24; iter: 400; batch classifier loss: 0.476448; batch adversarial loss: 0.485913\n",
      "epoch 24; iter: 600; batch classifier loss: 0.402678; batch adversarial loss: 0.374023\n",
      "epoch 25; iter: 0; batch classifier loss: 0.392330; batch adversarial loss: 0.398641\n",
      "epoch 25; iter: 200; batch classifier loss: 0.348000; batch adversarial loss: 0.569380\n",
      "epoch 25; iter: 400; batch classifier loss: 0.503996; batch adversarial loss: 0.407726\n",
      "epoch 25; iter: 600; batch classifier loss: 0.514404; batch adversarial loss: 0.369393\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356774; batch adversarial loss: 0.355419\n",
      "epoch 26; iter: 200; batch classifier loss: 0.436815; batch adversarial loss: 0.291651\n",
      "epoch 26; iter: 400; batch classifier loss: 0.500459; batch adversarial loss: 0.347641\n",
      "epoch 26; iter: 600; batch classifier loss: 0.372082; batch adversarial loss: 0.410866\n",
      "epoch 27; iter: 0; batch classifier loss: 0.659240; batch adversarial loss: 0.401664\n",
      "epoch 27; iter: 200; batch classifier loss: 0.516784; batch adversarial loss: 0.349688\n",
      "epoch 27; iter: 400; batch classifier loss: 0.532918; batch adversarial loss: 0.451808\n",
      "epoch 27; iter: 600; batch classifier loss: 0.443078; batch adversarial loss: 0.372487\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510384; batch adversarial loss: 0.399488\n",
      "epoch 28; iter: 200; batch classifier loss: 0.395012; batch adversarial loss: 0.483899\n",
      "epoch 28; iter: 400; batch classifier loss: 0.716250; batch adversarial loss: 0.493879\n",
      "epoch 28; iter: 600; batch classifier loss: 0.541957; batch adversarial loss: 0.319353\n",
      "epoch 29; iter: 0; batch classifier loss: 0.356053; batch adversarial loss: 0.349997\n",
      "epoch 29; iter: 200; batch classifier loss: 0.472068; batch adversarial loss: 0.384606\n",
      "epoch 29; iter: 400; batch classifier loss: 0.506747; batch adversarial loss: 0.438386\n",
      "epoch 29; iter: 600; batch classifier loss: 0.430921; batch adversarial loss: 0.429468\n",
      "epoch 30; iter: 0; batch classifier loss: 0.294400; batch adversarial loss: 0.616793\n",
      "epoch 30; iter: 200; batch classifier loss: 0.406468; batch adversarial loss: 0.398340\n",
      "epoch 30; iter: 400; batch classifier loss: 0.338048; batch adversarial loss: 0.355518\n",
      "epoch 30; iter: 600; batch classifier loss: 0.614664; batch adversarial loss: 0.437319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.368713; batch adversarial loss: 0.432655\n",
      "epoch 31; iter: 200; batch classifier loss: 0.443801; batch adversarial loss: 0.377675\n",
      "epoch 31; iter: 400; batch classifier loss: 0.428154; batch adversarial loss: 0.401679\n",
      "epoch 31; iter: 600; batch classifier loss: 0.325990; batch adversarial loss: 0.553717\n",
      "epoch 32; iter: 0; batch classifier loss: 0.592342; batch adversarial loss: 0.537784\n",
      "epoch 32; iter: 200; batch classifier loss: 0.466058; batch adversarial loss: 0.380558\n",
      "epoch 32; iter: 400; batch classifier loss: 0.495293; batch adversarial loss: 0.432386\n",
      "epoch 32; iter: 600; batch classifier loss: 0.527202; batch adversarial loss: 0.570775\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445818; batch adversarial loss: 0.400946\n",
      "epoch 33; iter: 200; batch classifier loss: 0.295508; batch adversarial loss: 0.414029\n",
      "epoch 33; iter: 400; batch classifier loss: 0.408912; batch adversarial loss: 0.319104\n",
      "epoch 33; iter: 600; batch classifier loss: 0.363702; batch adversarial loss: 0.460136\n",
      "epoch 34; iter: 0; batch classifier loss: 0.417628; batch adversarial loss: 0.432135\n",
      "epoch 34; iter: 200; batch classifier loss: 0.500300; batch adversarial loss: 0.383633\n",
      "epoch 34; iter: 400; batch classifier loss: 0.477024; batch adversarial loss: 0.317565\n",
      "epoch 34; iter: 600; batch classifier loss: 0.475271; batch adversarial loss: 0.387047\n",
      "epoch 35; iter: 0; batch classifier loss: 0.349250; batch adversarial loss: 0.496072\n",
      "epoch 35; iter: 200; batch classifier loss: 0.623262; batch adversarial loss: 0.317789\n",
      "epoch 35; iter: 400; batch classifier loss: 0.541660; batch adversarial loss: 0.345634\n",
      "epoch 35; iter: 600; batch classifier loss: 0.701264; batch adversarial loss: 0.348076\n",
      "epoch 36; iter: 0; batch classifier loss: 0.446806; batch adversarial loss: 0.268267\n",
      "epoch 36; iter: 200; batch classifier loss: 0.373989; batch adversarial loss: 0.383028\n",
      "epoch 36; iter: 400; batch classifier loss: 0.543184; batch adversarial loss: 0.436468\n",
      "epoch 36; iter: 600; batch classifier loss: 0.664268; batch adversarial loss: 0.465438\n",
      "epoch 37; iter: 0; batch classifier loss: 0.446344; batch adversarial loss: 0.410645\n",
      "epoch 37; iter: 200; batch classifier loss: 0.585016; batch adversarial loss: 0.346648\n",
      "epoch 37; iter: 400; batch classifier loss: 0.374433; batch adversarial loss: 0.321006\n",
      "epoch 37; iter: 600; batch classifier loss: 0.314185; batch adversarial loss: 0.406213\n",
      "epoch 38; iter: 0; batch classifier loss: 0.373680; batch adversarial loss: 0.320855\n",
      "epoch 38; iter: 200; batch classifier loss: 0.526015; batch adversarial loss: 0.404608\n",
      "epoch 38; iter: 400; batch classifier loss: 0.416643; batch adversarial loss: 0.515198\n",
      "epoch 38; iter: 600; batch classifier loss: 0.604319; batch adversarial loss: 0.334375\n",
      "epoch 39; iter: 0; batch classifier loss: 0.482010; batch adversarial loss: 0.373271\n",
      "epoch 39; iter: 200; batch classifier loss: 0.519650; batch adversarial loss: 0.355765\n",
      "epoch 39; iter: 400; batch classifier loss: 0.518175; batch adversarial loss: 0.451647\n",
      "epoch 39; iter: 600; batch classifier loss: 0.790857; batch adversarial loss: 0.401506\n",
      "epoch 40; iter: 0; batch classifier loss: 0.550214; batch adversarial loss: 0.471816\n",
      "epoch 40; iter: 200; batch classifier loss: 0.485824; batch adversarial loss: 0.409299\n",
      "epoch 40; iter: 400; batch classifier loss: 0.229438; batch adversarial loss: 0.509742\n",
      "epoch 40; iter: 600; batch classifier loss: 0.430739; batch adversarial loss: 0.543597\n",
      "epoch 41; iter: 0; batch classifier loss: 0.386811; batch adversarial loss: 0.274807\n",
      "epoch 41; iter: 200; batch classifier loss: 0.279339; batch adversarial loss: 0.399119\n",
      "epoch 41; iter: 400; batch classifier loss: 0.422769; batch adversarial loss: 0.404043\n",
      "epoch 41; iter: 600; batch classifier loss: 0.446306; batch adversarial loss: 0.437597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.406767; batch adversarial loss: 0.467755\n",
      "epoch 42; iter: 200; batch classifier loss: 0.336665; batch adversarial loss: 0.408583\n",
      "epoch 42; iter: 400; batch classifier loss: 0.691696; batch adversarial loss: 0.425201\n",
      "epoch 42; iter: 600; batch classifier loss: 0.376565; batch adversarial loss: 0.401247\n",
      "epoch 43; iter: 0; batch classifier loss: 0.429368; batch adversarial loss: 0.416176\n",
      "epoch 43; iter: 200; batch classifier loss: 0.469298; batch adversarial loss: 0.405472\n",
      "epoch 43; iter: 400; batch classifier loss: 0.610708; batch adversarial loss: 0.455410\n",
      "epoch 43; iter: 600; batch classifier loss: 0.522790; batch adversarial loss: 0.462480\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398260; batch adversarial loss: 0.464119\n",
      "epoch 44; iter: 200; batch classifier loss: 0.732573; batch adversarial loss: 0.457946\n",
      "epoch 44; iter: 400; batch classifier loss: 0.523236; batch adversarial loss: 0.237219\n",
      "epoch 44; iter: 600; batch classifier loss: 0.421149; batch adversarial loss: 0.427997\n",
      "epoch 45; iter: 0; batch classifier loss: 0.500781; batch adversarial loss: 0.432126\n",
      "epoch 45; iter: 200; batch classifier loss: 0.593745; batch adversarial loss: 0.321130\n",
      "epoch 45; iter: 400; batch classifier loss: 0.589801; batch adversarial loss: 0.345763\n",
      "epoch 45; iter: 600; batch classifier loss: 0.548702; batch adversarial loss: 0.386911\n",
      "epoch 46; iter: 0; batch classifier loss: 0.444221; batch adversarial loss: 0.464206\n",
      "epoch 46; iter: 200; batch classifier loss: 0.477202; batch adversarial loss: 0.469769\n",
      "epoch 46; iter: 400; batch classifier loss: 0.648597; batch adversarial loss: 0.345598\n",
      "epoch 46; iter: 600; batch classifier loss: 0.416542; batch adversarial loss: 0.414471\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366744; batch adversarial loss: 0.486343\n",
      "epoch 47; iter: 200; batch classifier loss: 0.507254; batch adversarial loss: 0.516143\n",
      "epoch 47; iter: 400; batch classifier loss: 0.573254; batch adversarial loss: 0.388147\n",
      "epoch 47; iter: 600; batch classifier loss: 0.480462; batch adversarial loss: 0.375037\n",
      "epoch 48; iter: 0; batch classifier loss: 0.581081; batch adversarial loss: 0.458074\n",
      "epoch 48; iter: 200; batch classifier loss: 0.346928; batch adversarial loss: 0.431821\n",
      "epoch 48; iter: 400; batch classifier loss: 0.594735; batch adversarial loss: 0.385021\n",
      "epoch 48; iter: 600; batch classifier loss: 0.740943; batch adversarial loss: 0.404223\n",
      "epoch 49; iter: 0; batch classifier loss: 0.843591; batch adversarial loss: 0.440849\n",
      "epoch 49; iter: 200; batch classifier loss: 0.436495; batch adversarial loss: 0.551641\n",
      "epoch 49; iter: 400; batch classifier loss: 0.513446; batch adversarial loss: 0.384538\n",
      "epoch 49; iter: 600; batch classifier loss: 0.406521; batch adversarial loss: 0.326823\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 59.017250; batch adversarial loss: 0.605981\n",
      "epoch 0; iter: 200; batch classifier loss: 10.425096; batch adversarial loss: 0.608077\n",
      "epoch 1; iter: 0; batch classifier loss: 5.324236; batch adversarial loss: 0.558530\n",
      "epoch 1; iter: 200; batch classifier loss: 4.930835; batch adversarial loss: 0.514276\n",
      "epoch 2; iter: 0; batch classifier loss: 6.671131; batch adversarial loss: 0.536972\n",
      "epoch 2; iter: 200; batch classifier loss: 6.026134; batch adversarial loss: 0.446249\n",
      "epoch 3; iter: 0; batch classifier loss: 0.879547; batch adversarial loss: 0.507050\n",
      "epoch 3; iter: 200; batch classifier loss: 4.139832; batch adversarial loss: 0.435470\n",
      "epoch 4; iter: 0; batch classifier loss: 12.912018; batch adversarial loss: 0.434238\n",
      "epoch 4; iter: 200; batch classifier loss: 0.805692; batch adversarial loss: 0.467100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489587; batch adversarial loss: 0.424425\n",
      "epoch 5; iter: 200; batch classifier loss: 0.644980; batch adversarial loss: 0.417702\n",
      "epoch 6; iter: 0; batch classifier loss: 0.848674; batch adversarial loss: 0.468385\n",
      "epoch 6; iter: 200; batch classifier loss: 0.560657; batch adversarial loss: 0.427402\n",
      "epoch 7; iter: 0; batch classifier loss: 2.019725; batch adversarial loss: 0.433865\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416471; batch adversarial loss: 0.495145\n",
      "epoch 8; iter: 0; batch classifier loss: 0.380802; batch adversarial loss: 0.461440\n",
      "epoch 8; iter: 200; batch classifier loss: 0.534947; batch adversarial loss: 0.372360\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536473; batch adversarial loss: 0.439114\n",
      "epoch 9; iter: 200; batch classifier loss: 0.489576; batch adversarial loss: 0.460514\n",
      "epoch 0; iter: 0; batch classifier loss: 10.894247; batch adversarial loss: 0.805704\n",
      "epoch 0; iter: 200; batch classifier loss: 11.668999; batch adversarial loss: 0.648680\n",
      "epoch 1; iter: 0; batch classifier loss: 6.909188; batch adversarial loss: 0.585009\n",
      "epoch 1; iter: 200; batch classifier loss: 2.183736; batch adversarial loss: 0.567489\n",
      "epoch 2; iter: 0; batch classifier loss: 3.984785; batch adversarial loss: 0.568333\n",
      "epoch 2; iter: 200; batch classifier loss: 2.196747; batch adversarial loss: 0.532338\n",
      "epoch 3; iter: 0; batch classifier loss: 2.595204; batch adversarial loss: 0.459575\n",
      "epoch 3; iter: 200; batch classifier loss: 2.480618; batch adversarial loss: 0.431991\n",
      "epoch 4; iter: 0; batch classifier loss: 1.621935; batch adversarial loss: 0.473292\n",
      "epoch 4; iter: 200; batch classifier loss: 0.992852; batch adversarial loss: 0.485668\n",
      "epoch 5; iter: 0; batch classifier loss: 1.627193; batch adversarial loss: 0.409644\n",
      "epoch 5; iter: 200; batch classifier loss: 1.849961; batch adversarial loss: 0.389184\n",
      "epoch 6; iter: 0; batch classifier loss: 1.296364; batch adversarial loss: 0.486461\n",
      "epoch 6; iter: 200; batch classifier loss: 0.631362; batch adversarial loss: 0.392549\n",
      "epoch 7; iter: 0; batch classifier loss: 0.444934; batch adversarial loss: 0.382429\n",
      "epoch 7; iter: 200; batch classifier loss: 0.560701; batch adversarial loss: 0.449224\n",
      "epoch 8; iter: 0; batch classifier loss: 0.656420; batch adversarial loss: 0.434370\n",
      "epoch 8; iter: 200; batch classifier loss: 0.539080; batch adversarial loss: 0.453639\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472386; batch adversarial loss: 0.472839\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426253; batch adversarial loss: 0.380362\n",
      "epoch 0; iter: 0; batch classifier loss: 29.203051; batch adversarial loss: 0.936616\n",
      "epoch 0; iter: 200; batch classifier loss: 4.971752; batch adversarial loss: 0.877151\n",
      "epoch 1; iter: 0; batch classifier loss: 9.955149; batch adversarial loss: 0.763641\n",
      "epoch 1; iter: 200; batch classifier loss: 11.677639; batch adversarial loss: 0.606232\n",
      "epoch 2; iter: 0; batch classifier loss: 18.996593; batch adversarial loss: 0.555383\n",
      "epoch 2; iter: 200; batch classifier loss: 1.218775; batch adversarial loss: 0.489584\n",
      "epoch 3; iter: 0; batch classifier loss: 4.933919; batch adversarial loss: 0.473232\n",
      "epoch 3; iter: 200; batch classifier loss: 2.396389; batch adversarial loss: 0.472686\n",
      "epoch 4; iter: 0; batch classifier loss: 4.382219; batch adversarial loss: 0.518258\n",
      "epoch 4; iter: 200; batch classifier loss: 3.416312; batch adversarial loss: 0.428008\n",
      "epoch 5; iter: 0; batch classifier loss: 2.517426; batch adversarial loss: 0.453284\n",
      "epoch 5; iter: 200; batch classifier loss: 1.835170; batch adversarial loss: 0.487760\n",
      "epoch 6; iter: 0; batch classifier loss: 3.666688; batch adversarial loss: 0.456399\n",
      "epoch 6; iter: 200; batch classifier loss: 0.806364; batch adversarial loss: 0.399148\n",
      "epoch 7; iter: 0; batch classifier loss: 0.841048; batch adversarial loss: 0.398633\n",
      "epoch 7; iter: 200; batch classifier loss: 0.849073; batch adversarial loss: 0.415460\n",
      "epoch 8; iter: 0; batch classifier loss: 0.594888; batch adversarial loss: 0.390041\n",
      "epoch 8; iter: 200; batch classifier loss: 0.802028; batch adversarial loss: 0.398452\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570272; batch adversarial loss: 0.434312\n",
      "epoch 9; iter: 200; batch classifier loss: 0.463355; batch adversarial loss: 0.464723\n",
      "epoch 0; iter: 0; batch classifier loss: 14.231126; batch adversarial loss: 0.720670\n",
      "epoch 0; iter: 200; batch classifier loss: 7.842965; batch adversarial loss: 0.601206\n",
      "epoch 1; iter: 0; batch classifier loss: 5.466518; batch adversarial loss: 0.564444\n",
      "epoch 1; iter: 200; batch classifier loss: 4.444839; batch adversarial loss: 0.574544\n",
      "epoch 2; iter: 0; batch classifier loss: 5.639014; batch adversarial loss: 0.516429\n",
      "epoch 2; iter: 200; batch classifier loss: 0.669162; batch adversarial loss: 0.453302\n",
      "epoch 3; iter: 0; batch classifier loss: 3.479067; batch adversarial loss: 0.463413\n",
      "epoch 3; iter: 200; batch classifier loss: 1.458724; batch adversarial loss: 0.465632\n",
      "epoch 4; iter: 0; batch classifier loss: 3.319929; batch adversarial loss: 0.468462\n",
      "epoch 4; iter: 200; batch classifier loss: 0.868734; batch adversarial loss: 0.505802\n",
      "epoch 5; iter: 0; batch classifier loss: 2.159789; batch adversarial loss: 0.370821\n",
      "epoch 5; iter: 200; batch classifier loss: 2.205308; batch adversarial loss: 0.424622\n",
      "epoch 6; iter: 0; batch classifier loss: 0.752384; batch adversarial loss: 0.393189\n",
      "epoch 6; iter: 200; batch classifier loss: 0.916703; batch adversarial loss: 0.421738\n",
      "epoch 7; iter: 0; batch classifier loss: 1.168687; batch adversarial loss: 0.447616\n",
      "epoch 7; iter: 200; batch classifier loss: 0.480833; batch adversarial loss: 0.503424\n",
      "epoch 8; iter: 0; batch classifier loss: 0.753698; batch adversarial loss: 0.423022\n",
      "epoch 8; iter: 200; batch classifier loss: 0.363131; batch adversarial loss: 0.408517\n",
      "epoch 9; iter: 0; batch classifier loss: 0.408956; batch adversarial loss: 0.313437\n",
      "epoch 9; iter: 200; batch classifier loss: 0.795002; batch adversarial loss: 0.324740\n",
      "epoch 0; iter: 0; batch classifier loss: 81.804504; batch adversarial loss: 0.745405\n",
      "epoch 0; iter: 200; batch classifier loss: 8.169717; batch adversarial loss: 0.610281\n",
      "epoch 1; iter: 0; batch classifier loss: 7.651573; batch adversarial loss: 0.597295\n",
      "epoch 1; iter: 200; batch classifier loss: 5.932385; batch adversarial loss: 0.555675\n",
      "epoch 2; iter: 0; batch classifier loss: 13.537893; batch adversarial loss: 0.532108\n",
      "epoch 2; iter: 200; batch classifier loss: 6.778393; batch adversarial loss: 0.494450\n",
      "epoch 3; iter: 0; batch classifier loss: 1.886468; batch adversarial loss: 0.470211\n",
      "epoch 3; iter: 200; batch classifier loss: 4.368420; batch adversarial loss: 0.456092\n",
      "epoch 4; iter: 0; batch classifier loss: 0.472382; batch adversarial loss: 0.491774\n",
      "epoch 4; iter: 200; batch classifier loss: 2.282383; batch adversarial loss: 0.410647\n",
      "epoch 5; iter: 0; batch classifier loss: 1.099172; batch adversarial loss: 0.388406\n",
      "epoch 5; iter: 200; batch classifier loss: 5.660153; batch adversarial loss: 0.502790\n",
      "epoch 6; iter: 0; batch classifier loss: 1.622418; batch adversarial loss: 0.518059\n",
      "epoch 6; iter: 200; batch classifier loss: 1.342875; batch adversarial loss: 0.453526\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549408; batch adversarial loss: 0.421386\n",
      "epoch 7; iter: 200; batch classifier loss: 1.017080; batch adversarial loss: 0.470047\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611066; batch adversarial loss: 0.359153\n",
      "epoch 8; iter: 200; batch classifier loss: 0.480039; batch adversarial loss: 0.348974\n",
      "epoch 9; iter: 0; batch classifier loss: 0.387723; batch adversarial loss: 0.378997\n",
      "epoch 9; iter: 200; batch classifier loss: 0.483813; batch adversarial loss: 0.371001\n",
      "epoch 0; iter: 0; batch classifier loss: 11.568108; batch adversarial loss: 0.713945\n",
      "epoch 0; iter: 200; batch classifier loss: 4.745995; batch adversarial loss: 0.631663\n",
      "epoch 1; iter: 0; batch classifier loss: 14.440420; batch adversarial loss: 0.572642\n",
      "epoch 1; iter: 200; batch classifier loss: 3.898622; batch adversarial loss: 0.535127\n",
      "epoch 2; iter: 0; batch classifier loss: 35.771202; batch adversarial loss: 0.502230\n",
      "epoch 2; iter: 200; batch classifier loss: 9.399001; batch adversarial loss: 0.523395\n",
      "epoch 3; iter: 0; batch classifier loss: 3.876409; batch adversarial loss: 0.487070\n",
      "epoch 3; iter: 200; batch classifier loss: 2.278082; batch adversarial loss: 0.435624\n",
      "epoch 4; iter: 0; batch classifier loss: 3.410756; batch adversarial loss: 0.448418\n",
      "epoch 4; iter: 200; batch classifier loss: 1.971577; batch adversarial loss: 0.420725\n",
      "epoch 5; iter: 0; batch classifier loss: 1.480050; batch adversarial loss: 0.437707\n",
      "epoch 5; iter: 200; batch classifier loss: 4.760655; batch adversarial loss: 0.532749\n",
      "epoch 6; iter: 0; batch classifier loss: 2.949034; batch adversarial loss: 0.561222\n",
      "epoch 6; iter: 200; batch classifier loss: 2.380275; batch adversarial loss: 0.363652\n",
      "epoch 7; iter: 0; batch classifier loss: 4.057517; batch adversarial loss: 0.456453\n",
      "epoch 7; iter: 200; batch classifier loss: 1.051622; batch adversarial loss: 0.384715\n",
      "epoch 8; iter: 0; batch classifier loss: 1.058851; batch adversarial loss: 0.526492\n",
      "epoch 8; iter: 200; batch classifier loss: 0.736287; batch adversarial loss: 0.385630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458746; batch adversarial loss: 0.367105\n",
      "epoch 9; iter: 200; batch classifier loss: 0.626584; batch adversarial loss: 0.436290\n",
      "epoch 0; iter: 0; batch classifier loss: 167.662048; batch adversarial loss: 0.759120\n",
      "epoch 0; iter: 200; batch classifier loss: 4.151186; batch adversarial loss: 0.639235\n",
      "epoch 1; iter: 0; batch classifier loss: 4.045625; batch adversarial loss: 0.591101\n",
      "epoch 1; iter: 200; batch classifier loss: 5.207500; batch adversarial loss: 0.559506\n",
      "epoch 2; iter: 0; batch classifier loss: 3.345740; batch adversarial loss: 0.525349\n",
      "epoch 2; iter: 200; batch classifier loss: 3.600939; batch adversarial loss: 0.453887\n",
      "epoch 3; iter: 0; batch classifier loss: 12.431158; batch adversarial loss: 0.495419\n",
      "epoch 3; iter: 200; batch classifier loss: 2.070198; batch adversarial loss: 0.453184\n",
      "epoch 4; iter: 0; batch classifier loss: 7.792041; batch adversarial loss: 0.468886\n",
      "epoch 4; iter: 200; batch classifier loss: 2.139978; batch adversarial loss: 0.489391\n",
      "epoch 5; iter: 0; batch classifier loss: 2.715928; batch adversarial loss: 0.446572\n",
      "epoch 5; iter: 200; batch classifier loss: 1.322625; batch adversarial loss: 0.464803\n",
      "epoch 6; iter: 0; batch classifier loss: 2.529102; batch adversarial loss: 0.429370\n",
      "epoch 6; iter: 200; batch classifier loss: 0.891939; batch adversarial loss: 0.404369\n",
      "epoch 7; iter: 0; batch classifier loss: 1.142741; batch adversarial loss: 0.464543\n",
      "epoch 7; iter: 200; batch classifier loss: 0.808015; batch adversarial loss: 0.366740\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525043; batch adversarial loss: 0.417651\n",
      "epoch 8; iter: 200; batch classifier loss: 0.414758; batch adversarial loss: 0.368770\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364318; batch adversarial loss: 0.342011\n",
      "epoch 9; iter: 200; batch classifier loss: 0.389154; batch adversarial loss: 0.393509\n",
      "epoch 0; iter: 0; batch classifier loss: 82.584610; batch adversarial loss: 0.564780\n",
      "epoch 0; iter: 200; batch classifier loss: 11.816406; batch adversarial loss: 0.603634\n",
      "epoch 1; iter: 0; batch classifier loss: 6.252686; batch adversarial loss: 0.567761\n",
      "epoch 1; iter: 200; batch classifier loss: 6.368636; batch adversarial loss: 0.556643\n",
      "epoch 2; iter: 0; batch classifier loss: 5.058837; batch adversarial loss: 0.546713\n",
      "epoch 2; iter: 200; batch classifier loss: 2.523094; batch adversarial loss: 0.473746\n",
      "epoch 3; iter: 0; batch classifier loss: 5.072287; batch adversarial loss: 0.516753\n",
      "epoch 3; iter: 200; batch classifier loss: 1.537462; batch adversarial loss: 0.497356\n",
      "epoch 4; iter: 0; batch classifier loss: 2.480405; batch adversarial loss: 0.452904\n",
      "epoch 4; iter: 200; batch classifier loss: 2.314965; batch adversarial loss: 0.397442\n",
      "epoch 5; iter: 0; batch classifier loss: 1.577729; batch adversarial loss: 0.433491\n",
      "epoch 5; iter: 200; batch classifier loss: 1.069005; batch adversarial loss: 0.485390\n",
      "epoch 6; iter: 0; batch classifier loss: 0.926442; batch adversarial loss: 0.402385\n",
      "epoch 6; iter: 200; batch classifier loss: 0.993348; batch adversarial loss: 0.483546\n",
      "epoch 7; iter: 0; batch classifier loss: 0.609645; batch adversarial loss: 0.391192\n",
      "epoch 7; iter: 200; batch classifier loss: 1.166158; batch adversarial loss: 0.522651\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564916; batch adversarial loss: 0.490142\n",
      "epoch 8; iter: 200; batch classifier loss: 0.417292; batch adversarial loss: 0.394269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507744; batch adversarial loss: 0.535920\n",
      "epoch 9; iter: 200; batch classifier loss: 0.618612; batch adversarial loss: 0.420183\n",
      "epoch 0; iter: 0; batch classifier loss: 30.100815; batch adversarial loss: 0.585948\n",
      "epoch 0; iter: 200; batch classifier loss: 13.749883; batch adversarial loss: 0.609528\n",
      "epoch 1; iter: 0; batch classifier loss: 7.525543; batch adversarial loss: 0.568997\n",
      "epoch 1; iter: 200; batch classifier loss: 2.442263; batch adversarial loss: 0.618577\n",
      "epoch 2; iter: 0; batch classifier loss: 5.646505; batch adversarial loss: 0.517175\n",
      "epoch 2; iter: 200; batch classifier loss: 15.095813; batch adversarial loss: 0.566539\n",
      "epoch 3; iter: 0; batch classifier loss: 3.901931; batch adversarial loss: 0.493110\n",
      "epoch 3; iter: 200; batch classifier loss: 2.862528; batch adversarial loss: 0.506794\n",
      "epoch 4; iter: 0; batch classifier loss: 3.682939; batch adversarial loss: 0.547980\n",
      "epoch 4; iter: 200; batch classifier loss: 2.783560; batch adversarial loss: 0.485499\n",
      "epoch 5; iter: 0; batch classifier loss: 1.913019; batch adversarial loss: 0.463429\n",
      "epoch 5; iter: 200; batch classifier loss: 0.610075; batch adversarial loss: 0.404015\n",
      "epoch 6; iter: 0; batch classifier loss: 1.105315; batch adversarial loss: 0.417247\n",
      "epoch 6; iter: 200; batch classifier loss: 0.643087; batch adversarial loss: 0.412816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595922; batch adversarial loss: 0.494960\n",
      "epoch 7; iter: 200; batch classifier loss: 0.583190; batch adversarial loss: 0.544013\n",
      "epoch 8; iter: 0; batch classifier loss: 0.452573; batch adversarial loss: 0.391635\n",
      "epoch 8; iter: 200; batch classifier loss: 0.472325; batch adversarial loss: 0.463342\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538150; batch adversarial loss: 0.390866\n",
      "epoch 9; iter: 200; batch classifier loss: 0.550131; batch adversarial loss: 0.401369\n",
      "epoch 0; iter: 0; batch classifier loss: 40.047298; batch adversarial loss: 0.637081\n",
      "epoch 0; iter: 200; batch classifier loss: 9.372723; batch adversarial loss: 0.576042\n",
      "epoch 1; iter: 0; batch classifier loss: 2.537149; batch adversarial loss: 0.516492\n",
      "epoch 1; iter: 200; batch classifier loss: 9.352820; batch adversarial loss: 0.517752\n",
      "epoch 2; iter: 0; batch classifier loss: 2.040986; batch adversarial loss: 0.451947\n",
      "epoch 2; iter: 200; batch classifier loss: 4.623560; batch adversarial loss: 0.479636\n",
      "epoch 3; iter: 0; batch classifier loss: 1.338400; batch adversarial loss: 0.468420\n",
      "epoch 3; iter: 200; batch classifier loss: 3.118717; batch adversarial loss: 0.497411\n",
      "epoch 4; iter: 0; batch classifier loss: 1.632873; batch adversarial loss: 0.463715\n",
      "epoch 4; iter: 200; batch classifier loss: 2.417797; batch adversarial loss: 0.455213\n",
      "epoch 5; iter: 0; batch classifier loss: 1.283960; batch adversarial loss: 0.461578\n",
      "epoch 5; iter: 200; batch classifier loss: 1.065032; batch adversarial loss: 0.499531\n",
      "epoch 6; iter: 0; batch classifier loss: 0.844915; batch adversarial loss: 0.439723\n",
      "epoch 6; iter: 200; batch classifier loss: 0.767185; batch adversarial loss: 0.449870\n",
      "epoch 7; iter: 0; batch classifier loss: 0.700301; batch adversarial loss: 0.429157\n",
      "epoch 7; iter: 200; batch classifier loss: 1.640085; batch adversarial loss: 0.443714\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585093; batch adversarial loss: 0.399620\n",
      "epoch 8; iter: 200; batch classifier loss: 0.760626; batch adversarial loss: 0.503405\n",
      "epoch 9; iter: 0; batch classifier loss: 0.753229; batch adversarial loss: 0.323977\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426504; batch adversarial loss: 0.484805\n",
      "epoch 0; iter: 0; batch classifier loss: 17.795528; batch adversarial loss: 0.998773\n",
      "epoch 0; iter: 200; batch classifier loss: 5.898123; batch adversarial loss: 0.820368\n",
      "epoch 1; iter: 0; batch classifier loss: 7.616666; batch adversarial loss: 0.729346\n",
      "epoch 1; iter: 200; batch classifier loss: 2.022365; batch adversarial loss: 0.600168\n",
      "epoch 2; iter: 0; batch classifier loss: 2.742090; batch adversarial loss: 0.548993\n",
      "epoch 2; iter: 200; batch classifier loss: 5.213241; batch adversarial loss: 0.509413\n",
      "epoch 3; iter: 0; batch classifier loss: 5.856247; batch adversarial loss: 0.437007\n",
      "epoch 3; iter: 200; batch classifier loss: 2.419916; batch adversarial loss: 0.479639\n",
      "epoch 4; iter: 0; batch classifier loss: 1.421955; batch adversarial loss: 0.427812\n",
      "epoch 4; iter: 200; batch classifier loss: 0.826952; batch adversarial loss: 0.448151\n",
      "epoch 5; iter: 0; batch classifier loss: 1.349172; batch adversarial loss: 0.438715\n",
      "epoch 5; iter: 200; batch classifier loss: 1.009172; batch adversarial loss: 0.383145\n",
      "epoch 6; iter: 0; batch classifier loss: 0.659929; batch adversarial loss: 0.445440\n",
      "epoch 6; iter: 200; batch classifier loss: 0.438170; batch adversarial loss: 0.409396\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606525; batch adversarial loss: 0.417456\n",
      "epoch 7; iter: 200; batch classifier loss: 0.972453; batch adversarial loss: 0.430701\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514793; batch adversarial loss: 0.416382\n",
      "epoch 8; iter: 200; batch classifier loss: 1.028347; batch adversarial loss: 0.364484\n",
      "epoch 9; iter: 0; batch classifier loss: 0.624666; batch adversarial loss: 0.408232\n",
      "epoch 9; iter: 200; batch classifier loss: 0.494025; batch adversarial loss: 0.340756\n",
      "epoch 0; iter: 0; batch classifier loss: 3.505445; batch adversarial loss: 1.100948\n",
      "epoch 0; iter: 200; batch classifier loss: 12.381842; batch adversarial loss: 1.078899\n",
      "epoch 1; iter: 0; batch classifier loss: 3.512627; batch adversarial loss: 0.971831\n",
      "epoch 1; iter: 200; batch classifier loss: 6.230432; batch adversarial loss: 0.721351\n",
      "epoch 2; iter: 0; batch classifier loss: 6.815980; batch adversarial loss: 0.657572\n",
      "epoch 2; iter: 200; batch classifier loss: 7.335609; batch adversarial loss: 0.557173\n",
      "epoch 3; iter: 0; batch classifier loss: 4.884944; batch adversarial loss: 0.500853\n",
      "epoch 3; iter: 200; batch classifier loss: 3.923729; batch adversarial loss: 0.504888\n",
      "epoch 4; iter: 0; batch classifier loss: 1.164291; batch adversarial loss: 0.482590\n",
      "epoch 4; iter: 200; batch classifier loss: 1.212640; batch adversarial loss: 0.427920\n",
      "epoch 5; iter: 0; batch classifier loss: 0.770925; batch adversarial loss: 0.441692\n",
      "epoch 5; iter: 200; batch classifier loss: 0.908595; batch adversarial loss: 0.432893\n",
      "epoch 6; iter: 0; batch classifier loss: 1.867038; batch adversarial loss: 0.377202\n",
      "epoch 6; iter: 200; batch classifier loss: 1.288805; batch adversarial loss: 0.469908\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582031; batch adversarial loss: 0.410261\n",
      "epoch 7; iter: 200; batch classifier loss: 0.458303; batch adversarial loss: 0.402551\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569149; batch adversarial loss: 0.407293\n",
      "epoch 8; iter: 200; batch classifier loss: 0.682659; batch adversarial loss: 0.449619\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544504; batch adversarial loss: 0.446934\n",
      "epoch 9; iter: 200; batch classifier loss: 0.435464; batch adversarial loss: 0.336786\n",
      "epoch 0; iter: 0; batch classifier loss: 28.931282; batch adversarial loss: 0.537442\n",
      "epoch 0; iter: 200; batch classifier loss: 10.507328; batch adversarial loss: 0.600302\n",
      "epoch 1; iter: 0; batch classifier loss: 2.613697; batch adversarial loss: 0.615979\n",
      "epoch 1; iter: 200; batch classifier loss: 4.492382; batch adversarial loss: 0.434024\n",
      "epoch 2; iter: 0; batch classifier loss: 23.621016; batch adversarial loss: 0.508288\n",
      "epoch 2; iter: 200; batch classifier loss: 3.607459; batch adversarial loss: 0.468922\n",
      "epoch 3; iter: 0; batch classifier loss: 1.291630; batch adversarial loss: 0.478447\n",
      "epoch 3; iter: 200; batch classifier loss: 2.697604; batch adversarial loss: 0.399539\n",
      "epoch 4; iter: 0; batch classifier loss: 5.688337; batch adversarial loss: 0.435846\n",
      "epoch 4; iter: 200; batch classifier loss: 0.760969; batch adversarial loss: 0.478749\n",
      "epoch 5; iter: 0; batch classifier loss: 1.498241; batch adversarial loss: 0.471317\n",
      "epoch 5; iter: 200; batch classifier loss: 1.535729; batch adversarial loss: 0.478043\n",
      "epoch 6; iter: 0; batch classifier loss: 1.006612; batch adversarial loss: 0.442084\n",
      "epoch 6; iter: 200; batch classifier loss: 0.646157; batch adversarial loss: 0.447896\n",
      "epoch 7; iter: 0; batch classifier loss: 0.884774; batch adversarial loss: 0.364192\n",
      "epoch 7; iter: 200; batch classifier loss: 0.491736; batch adversarial loss: 0.488060\n",
      "epoch 8; iter: 0; batch classifier loss: 0.607560; batch adversarial loss: 0.429767\n",
      "epoch 8; iter: 200; batch classifier loss: 0.579548; batch adversarial loss: 0.376017\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490461; batch adversarial loss: 0.469095\n",
      "epoch 9; iter: 200; batch classifier loss: 0.397925; batch adversarial loss: 0.476172\n",
      "epoch 0; iter: 0; batch classifier loss: 6.945112; batch adversarial loss: 0.820673\n",
      "epoch 0; iter: 200; batch classifier loss: 13.410393; batch adversarial loss: 0.714549\n",
      "epoch 1; iter: 0; batch classifier loss: 4.443528; batch adversarial loss: 0.612136\n",
      "epoch 1; iter: 200; batch classifier loss: 4.913885; batch adversarial loss: 0.535949\n",
      "epoch 2; iter: 0; batch classifier loss: 4.860319; batch adversarial loss: 0.524844\n",
      "epoch 2; iter: 200; batch classifier loss: 3.695049; batch adversarial loss: 0.511026\n",
      "epoch 3; iter: 0; batch classifier loss: 5.253662; batch adversarial loss: 0.507569\n",
      "epoch 3; iter: 200; batch classifier loss: 1.428016; batch adversarial loss: 0.444720\n",
      "epoch 4; iter: 0; batch classifier loss: 1.084334; batch adversarial loss: 0.456911\n",
      "epoch 4; iter: 200; batch classifier loss: 2.376778; batch adversarial loss: 0.470075\n",
      "epoch 5; iter: 0; batch classifier loss: 1.182710; batch adversarial loss: 0.435733\n",
      "epoch 5; iter: 200; batch classifier loss: 1.039223; batch adversarial loss: 0.398797\n",
      "epoch 6; iter: 0; batch classifier loss: 1.128564; batch adversarial loss: 0.446761\n",
      "epoch 6; iter: 200; batch classifier loss: 0.931072; batch adversarial loss: 0.417629\n",
      "epoch 7; iter: 0; batch classifier loss: 0.785429; batch adversarial loss: 0.484262\n",
      "epoch 7; iter: 200; batch classifier loss: 0.832454; batch adversarial loss: 0.434935\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526753; batch adversarial loss: 0.437520\n",
      "epoch 8; iter: 200; batch classifier loss: 0.527670; batch adversarial loss: 0.453344\n",
      "epoch 9; iter: 0; batch classifier loss: 0.463519; batch adversarial loss: 0.395723\n",
      "epoch 9; iter: 200; batch classifier loss: 0.410142; batch adversarial loss: 0.336375\n",
      "epoch 0; iter: 0; batch classifier loss: 110.388199; batch adversarial loss: 0.774965\n",
      "epoch 0; iter: 200; batch classifier loss: 4.951813; batch adversarial loss: 0.764907\n",
      "epoch 1; iter: 0; batch classifier loss: 3.314180; batch adversarial loss: 0.608153\n",
      "epoch 1; iter: 200; batch classifier loss: 8.365852; batch adversarial loss: 0.542411\n",
      "epoch 2; iter: 0; batch classifier loss: 2.982595; batch adversarial loss: 0.545193\n",
      "epoch 2; iter: 200; batch classifier loss: 4.250937; batch adversarial loss: 0.443472\n",
      "epoch 3; iter: 0; batch classifier loss: 3.009391; batch adversarial loss: 0.465182\n",
      "epoch 3; iter: 200; batch classifier loss: 5.340198; batch adversarial loss: 0.476622\n",
      "epoch 4; iter: 0; batch classifier loss: 1.823493; batch adversarial loss: 0.477101\n",
      "epoch 4; iter: 200; batch classifier loss: 1.498925; batch adversarial loss: 0.456068\n",
      "epoch 5; iter: 0; batch classifier loss: 1.676307; batch adversarial loss: 0.433308\n",
      "epoch 5; iter: 200; batch classifier loss: 2.340841; batch adversarial loss: 0.404229\n",
      "epoch 6; iter: 0; batch classifier loss: 1.039539; batch adversarial loss: 0.396665\n",
      "epoch 6; iter: 200; batch classifier loss: 1.095924; batch adversarial loss: 0.364032\n",
      "epoch 7; iter: 0; batch classifier loss: 0.589119; batch adversarial loss: 0.480897\n",
      "epoch 7; iter: 200; batch classifier loss: 0.833709; batch adversarial loss: 0.485914\n",
      "epoch 8; iter: 0; batch classifier loss: 1.015532; batch adversarial loss: 0.372598\n",
      "epoch 8; iter: 200; batch classifier loss: 0.612049; batch adversarial loss: 0.441394\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471717; batch adversarial loss: 0.365670\n",
      "epoch 9; iter: 200; batch classifier loss: 0.497480; batch adversarial loss: 0.407830\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 6.770554; batch adversarial loss: 1.124213\n",
      "epoch 0; iter: 200; batch classifier loss: 21.297779; batch adversarial loss: 1.120998\n",
      "epoch 1; iter: 0; batch classifier loss: 15.745147; batch adversarial loss: 0.902016\n",
      "epoch 1; iter: 200; batch classifier loss: 4.189391; batch adversarial loss: 0.736897\n",
      "epoch 2; iter: 0; batch classifier loss: 8.263187; batch adversarial loss: 0.649821\n",
      "epoch 2; iter: 200; batch classifier loss: 6.327110; batch adversarial loss: 0.597596\n",
      "epoch 3; iter: 0; batch classifier loss: 1.720464; batch adversarial loss: 0.531419\n",
      "epoch 3; iter: 200; batch classifier loss: 7.530402; batch adversarial loss: 0.483445\n",
      "epoch 4; iter: 0; batch classifier loss: 2.121979; batch adversarial loss: 0.509762\n",
      "epoch 4; iter: 200; batch classifier loss: 4.789531; batch adversarial loss: 0.467319\n",
      "epoch 5; iter: 0; batch classifier loss: 3.984444; batch adversarial loss: 0.495446\n",
      "epoch 5; iter: 200; batch classifier loss: 2.479240; batch adversarial loss: 0.394263\n",
      "epoch 6; iter: 0; batch classifier loss: 5.827898; batch adversarial loss: 0.409825\n",
      "epoch 6; iter: 200; batch classifier loss: 1.294262; batch adversarial loss: 0.459079\n",
      "epoch 7; iter: 0; batch classifier loss: 2.829577; batch adversarial loss: 0.374881\n",
      "epoch 7; iter: 200; batch classifier loss: 0.811344; batch adversarial loss: 0.405199\n",
      "epoch 8; iter: 0; batch classifier loss: 0.749639; batch adversarial loss: 0.434079\n",
      "epoch 8; iter: 200; batch classifier loss: 0.703051; batch adversarial loss: 0.419113\n",
      "epoch 9; iter: 0; batch classifier loss: 0.693188; batch adversarial loss: 0.457376\n",
      "epoch 9; iter: 200; batch classifier loss: 0.560588; batch adversarial loss: 0.471154\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594692; batch adversarial loss: 0.378037\n",
      "epoch 10; iter: 200; batch classifier loss: 0.524713; batch adversarial loss: 0.427369\n",
      "epoch 11; iter: 0; batch classifier loss: 0.731800; batch adversarial loss: 0.480885\n",
      "epoch 11; iter: 200; batch classifier loss: 0.453445; batch adversarial loss: 0.382517\n",
      "epoch 12; iter: 0; batch classifier loss: 0.541495; batch adversarial loss: 0.481955\n",
      "epoch 12; iter: 200; batch classifier loss: 0.475542; batch adversarial loss: 0.360636\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383888; batch adversarial loss: 0.354358\n",
      "epoch 13; iter: 200; batch classifier loss: 0.463192; batch adversarial loss: 0.279502\n",
      "epoch 14; iter: 0; batch classifier loss: 0.507763; batch adversarial loss: 0.373810\n",
      "epoch 14; iter: 200; batch classifier loss: 0.501574; batch adversarial loss: 0.365357\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409131; batch adversarial loss: 0.474815\n",
      "epoch 15; iter: 200; batch classifier loss: 0.486108; batch adversarial loss: 0.401592\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488966; batch adversarial loss: 0.389222\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383788; batch adversarial loss: 0.372628\n",
      "epoch 17; iter: 0; batch classifier loss: 0.447498; batch adversarial loss: 0.427926\n",
      "epoch 17; iter: 200; batch classifier loss: 0.348549; batch adversarial loss: 0.402398\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348046; batch adversarial loss: 0.429706\n",
      "epoch 18; iter: 200; batch classifier loss: 0.372346; batch adversarial loss: 0.364181\n",
      "epoch 19; iter: 0; batch classifier loss: 0.466829; batch adversarial loss: 0.442744\n",
      "epoch 19; iter: 200; batch classifier loss: 0.415715; batch adversarial loss: 0.407099\n",
      "epoch 0; iter: 0; batch classifier loss: 226.215500; batch adversarial loss: 0.563829\n",
      "epoch 0; iter: 200; batch classifier loss: 14.735237; batch adversarial loss: 0.550245\n",
      "epoch 1; iter: 0; batch classifier loss: 6.366586; batch adversarial loss: 0.561125\n",
      "epoch 1; iter: 200; batch classifier loss: 4.957675; batch adversarial loss: 0.583951\n",
      "epoch 2; iter: 0; batch classifier loss: 1.735380; batch adversarial loss: 0.507834\n",
      "epoch 2; iter: 200; batch classifier loss: 5.984123; batch adversarial loss: 0.402348\n",
      "epoch 3; iter: 0; batch classifier loss: 2.474181; batch adversarial loss: 0.433829\n",
      "epoch 3; iter: 200; batch classifier loss: 1.355236; batch adversarial loss: 0.450010\n",
      "epoch 4; iter: 0; batch classifier loss: 7.268674; batch adversarial loss: 0.484898\n",
      "epoch 4; iter: 200; batch classifier loss: 7.783781; batch adversarial loss: 0.548526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.977530; batch adversarial loss: 0.434314\n",
      "epoch 5; iter: 200; batch classifier loss: 1.729500; batch adversarial loss: 0.392777\n",
      "epoch 6; iter: 0; batch classifier loss: 2.493146; batch adversarial loss: 0.461654\n",
      "epoch 6; iter: 200; batch classifier loss: 0.374213; batch adversarial loss: 0.435498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.953859; batch adversarial loss: 0.443978\n",
      "epoch 7; iter: 200; batch classifier loss: 0.477285; batch adversarial loss: 0.357023\n",
      "epoch 8; iter: 0; batch classifier loss: 0.625497; batch adversarial loss: 0.313171\n",
      "epoch 8; iter: 200; batch classifier loss: 0.450982; batch adversarial loss: 0.487086\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535295; batch adversarial loss: 0.350833\n",
      "epoch 9; iter: 200; batch classifier loss: 0.498584; batch adversarial loss: 0.454263\n",
      "epoch 10; iter: 0; batch classifier loss: 0.340116; batch adversarial loss: 0.345843\n",
      "epoch 10; iter: 200; batch classifier loss: 0.424786; batch adversarial loss: 0.457272\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568159; batch adversarial loss: 0.567749\n",
      "epoch 11; iter: 200; batch classifier loss: 0.517654; batch adversarial loss: 0.365402\n",
      "epoch 12; iter: 0; batch classifier loss: 0.704003; batch adversarial loss: 0.399408\n",
      "epoch 12; iter: 200; batch classifier loss: 0.438978; batch adversarial loss: 0.345241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.836370; batch adversarial loss: 0.351492\n",
      "epoch 13; iter: 200; batch classifier loss: 0.398793; batch adversarial loss: 0.394385\n",
      "epoch 14; iter: 0; batch classifier loss: 0.678541; batch adversarial loss: 0.301506\n",
      "epoch 14; iter: 200; batch classifier loss: 0.430424; batch adversarial loss: 0.448233\n",
      "epoch 15; iter: 0; batch classifier loss: 0.333469; batch adversarial loss: 0.427066\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430619; batch adversarial loss: 0.470125\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377417; batch adversarial loss: 0.393867\n",
      "epoch 16; iter: 200; batch classifier loss: 0.376769; batch adversarial loss: 0.569872\n",
      "epoch 17; iter: 0; batch classifier loss: 0.256247; batch adversarial loss: 0.478094\n",
      "epoch 17; iter: 200; batch classifier loss: 0.363638; batch adversarial loss: 0.357691\n",
      "epoch 18; iter: 0; batch classifier loss: 0.732563; batch adversarial loss: 0.389405\n",
      "epoch 18; iter: 200; batch classifier loss: 0.441946; batch adversarial loss: 0.517597\n",
      "epoch 19; iter: 0; batch classifier loss: 0.403964; batch adversarial loss: 0.424073\n",
      "epoch 19; iter: 200; batch classifier loss: 0.363614; batch adversarial loss: 0.384402\n",
      "epoch 0; iter: 0; batch classifier loss: 8.517628; batch adversarial loss: 1.062059\n",
      "epoch 0; iter: 200; batch classifier loss: 8.671497; batch adversarial loss: 0.873229\n",
      "epoch 1; iter: 0; batch classifier loss: 6.085550; batch adversarial loss: 0.781473\n",
      "epoch 1; iter: 200; batch classifier loss: 1.952515; batch adversarial loss: 0.638608\n",
      "epoch 2; iter: 0; batch classifier loss: 4.153052; batch adversarial loss: 0.596807\n",
      "epoch 2; iter: 200; batch classifier loss: 2.999968; batch adversarial loss: 0.504494\n",
      "epoch 3; iter: 0; batch classifier loss: 4.685852; batch adversarial loss: 0.513857\n",
      "epoch 3; iter: 200; batch classifier loss: 1.709709; batch adversarial loss: 0.469911\n",
      "epoch 4; iter: 0; batch classifier loss: 1.380993; batch adversarial loss: 0.503695\n",
      "epoch 4; iter: 200; batch classifier loss: 1.115393; batch adversarial loss: 0.505487\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515760; batch adversarial loss: 0.439906\n",
      "epoch 5; iter: 200; batch classifier loss: 0.540054; batch adversarial loss: 0.469696\n",
      "epoch 6; iter: 0; batch classifier loss: 0.988511; batch adversarial loss: 0.449779\n",
      "epoch 6; iter: 200; batch classifier loss: 0.559189; batch adversarial loss: 0.435992\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616079; batch adversarial loss: 0.472983\n",
      "epoch 7; iter: 200; batch classifier loss: 0.524712; batch adversarial loss: 0.442124\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466834; batch adversarial loss: 0.414996\n",
      "epoch 8; iter: 200; batch classifier loss: 0.442012; batch adversarial loss: 0.345421\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432698; batch adversarial loss: 0.369002\n",
      "epoch 9; iter: 200; batch classifier loss: 0.504930; batch adversarial loss: 0.510146\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557038; batch adversarial loss: 0.428196\n",
      "epoch 10; iter: 200; batch classifier loss: 0.416229; batch adversarial loss: 0.494219\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400351; batch adversarial loss: 0.409304\n",
      "epoch 11; iter: 200; batch classifier loss: 0.491538; batch adversarial loss: 0.387185\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492047; batch adversarial loss: 0.453642\n",
      "epoch 12; iter: 200; batch classifier loss: 0.597422; batch adversarial loss: 0.394012\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429283; batch adversarial loss: 0.353060\n",
      "epoch 13; iter: 200; batch classifier loss: 0.377485; batch adversarial loss: 0.431253\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395718; batch adversarial loss: 0.392315\n",
      "epoch 14; iter: 200; batch classifier loss: 0.421134; batch adversarial loss: 0.424605\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370443; batch adversarial loss: 0.410615\n",
      "epoch 15; iter: 200; batch classifier loss: 0.290513; batch adversarial loss: 0.420777\n",
      "epoch 16; iter: 0; batch classifier loss: 0.398649; batch adversarial loss: 0.373669\n",
      "epoch 16; iter: 200; batch classifier loss: 0.331106; batch adversarial loss: 0.386260\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377381; batch adversarial loss: 0.462243\n",
      "epoch 17; iter: 200; batch classifier loss: 0.370443; batch adversarial loss: 0.290562\n",
      "epoch 18; iter: 0; batch classifier loss: 0.423072; batch adversarial loss: 0.442635\n",
      "epoch 18; iter: 200; batch classifier loss: 0.301923; batch adversarial loss: 0.320740\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307928; batch adversarial loss: 0.376645\n",
      "epoch 19; iter: 200; batch classifier loss: 0.327692; batch adversarial loss: 0.320165\n",
      "epoch 0; iter: 0; batch classifier loss: 6.861811; batch adversarial loss: 0.601875\n",
      "epoch 0; iter: 200; batch classifier loss: 3.258414; batch adversarial loss: 0.600383\n",
      "epoch 1; iter: 0; batch classifier loss: 3.822420; batch adversarial loss: 0.562652\n",
      "epoch 1; iter: 200; batch classifier loss: 4.659654; batch adversarial loss: 0.532314\n",
      "epoch 2; iter: 0; batch classifier loss: 6.026299; batch adversarial loss: 0.515516\n",
      "epoch 2; iter: 200; batch classifier loss: 2.163220; batch adversarial loss: 0.456622\n",
      "epoch 3; iter: 0; batch classifier loss: 2.844646; batch adversarial loss: 0.443663\n",
      "epoch 3; iter: 200; batch classifier loss: 8.790372; batch adversarial loss: 0.415129\n",
      "epoch 4; iter: 0; batch classifier loss: 1.759663; batch adversarial loss: 0.488587\n",
      "epoch 4; iter: 200; batch classifier loss: 1.971213; batch adversarial loss: 0.455142\n",
      "epoch 5; iter: 0; batch classifier loss: 1.427257; batch adversarial loss: 0.416896\n",
      "epoch 5; iter: 200; batch classifier loss: 0.624260; batch adversarial loss: 0.427697\n",
      "epoch 6; iter: 0; batch classifier loss: 0.723595; batch adversarial loss: 0.410795\n",
      "epoch 6; iter: 200; batch classifier loss: 0.701014; batch adversarial loss: 0.416387\n",
      "epoch 7; iter: 0; batch classifier loss: 0.375101; batch adversarial loss: 0.341412\n",
      "epoch 7; iter: 200; batch classifier loss: 0.461850; batch adversarial loss: 0.400116\n",
      "epoch 8; iter: 0; batch classifier loss: 0.440847; batch adversarial loss: 0.393518\n",
      "epoch 8; iter: 200; batch classifier loss: 0.414837; batch adversarial loss: 0.421088\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599439; batch adversarial loss: 0.527754\n",
      "epoch 9; iter: 200; batch classifier loss: 0.467943; batch adversarial loss: 0.397121\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546209; batch adversarial loss: 0.414978\n",
      "epoch 10; iter: 200; batch classifier loss: 0.371763; batch adversarial loss: 0.444359\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426819; batch adversarial loss: 0.443219\n",
      "epoch 11; iter: 200; batch classifier loss: 0.388691; batch adversarial loss: 0.438345\n",
      "epoch 12; iter: 0; batch classifier loss: 0.394984; batch adversarial loss: 0.436881\n",
      "epoch 12; iter: 200; batch classifier loss: 0.414012; batch adversarial loss: 0.473021\n",
      "epoch 13; iter: 0; batch classifier loss: 0.362932; batch adversarial loss: 0.435399\n",
      "epoch 13; iter: 200; batch classifier loss: 0.480910; batch adversarial loss: 0.382708\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413658; batch adversarial loss: 0.433412\n",
      "epoch 14; iter: 200; batch classifier loss: 0.358667; batch adversarial loss: 0.436998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.352695; batch adversarial loss: 0.483001\n",
      "epoch 15; iter: 200; batch classifier loss: 0.406740; batch adversarial loss: 0.288196\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349120; batch adversarial loss: 0.373122\n",
      "epoch 16; iter: 200; batch classifier loss: 0.333024; batch adversarial loss: 0.529083\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316419; batch adversarial loss: 0.574099\n",
      "epoch 17; iter: 200; batch classifier loss: 0.314201; batch adversarial loss: 0.429258\n",
      "epoch 18; iter: 0; batch classifier loss: 0.351285; batch adversarial loss: 0.427879\n",
      "epoch 18; iter: 200; batch classifier loss: 0.381005; batch adversarial loss: 0.418244\n",
      "epoch 19; iter: 0; batch classifier loss: 0.405717; batch adversarial loss: 0.444079\n",
      "epoch 19; iter: 200; batch classifier loss: 0.294272; batch adversarial loss: 0.332130\n",
      "epoch 0; iter: 0; batch classifier loss: 8.067635; batch adversarial loss: 0.690874\n",
      "epoch 0; iter: 200; batch classifier loss: 9.198256; batch adversarial loss: 0.593227\n",
      "epoch 1; iter: 0; batch classifier loss: 6.020275; batch adversarial loss: 0.576991\n",
      "epoch 1; iter: 200; batch classifier loss: 3.720520; batch adversarial loss: 0.572097\n",
      "epoch 2; iter: 0; batch classifier loss: 3.658540; batch adversarial loss: 0.533760\n",
      "epoch 2; iter: 200; batch classifier loss: 3.760616; batch adversarial loss: 0.477790\n",
      "epoch 3; iter: 0; batch classifier loss: 3.552379; batch adversarial loss: 0.446004\n",
      "epoch 3; iter: 200; batch classifier loss: 1.614381; batch adversarial loss: 0.463088\n",
      "epoch 4; iter: 0; batch classifier loss: 3.213289; batch adversarial loss: 0.422180\n",
      "epoch 4; iter: 200; batch classifier loss: 2.881751; batch adversarial loss: 0.439044\n",
      "epoch 5; iter: 0; batch classifier loss: 1.897596; batch adversarial loss: 0.391617\n",
      "epoch 5; iter: 200; batch classifier loss: 0.430258; batch adversarial loss: 0.423176\n",
      "epoch 6; iter: 0; batch classifier loss: 1.040520; batch adversarial loss: 0.448812\n",
      "epoch 6; iter: 200; batch classifier loss: 0.517774; batch adversarial loss: 0.359616\n",
      "epoch 7; iter: 0; batch classifier loss: 0.451297; batch adversarial loss: 0.358321\n",
      "epoch 7; iter: 200; batch classifier loss: 0.460475; batch adversarial loss: 0.467809\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479039; batch adversarial loss: 0.391753\n",
      "epoch 8; iter: 200; batch classifier loss: 0.469162; batch adversarial loss: 0.486497\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445742; batch adversarial loss: 0.424213\n",
      "epoch 9; iter: 200; batch classifier loss: 0.412446; batch adversarial loss: 0.418246\n",
      "epoch 10; iter: 0; batch classifier loss: 0.348302; batch adversarial loss: 0.401525\n",
      "epoch 10; iter: 200; batch classifier loss: 0.416417; batch adversarial loss: 0.474332\n",
      "epoch 11; iter: 0; batch classifier loss: 0.358261; batch adversarial loss: 0.334060\n",
      "epoch 11; iter: 200; batch classifier loss: 0.342528; batch adversarial loss: 0.421034\n",
      "epoch 12; iter: 0; batch classifier loss: 0.519655; batch adversarial loss: 0.370635\n",
      "epoch 12; iter: 200; batch classifier loss: 0.409297; batch adversarial loss: 0.339676\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374606; batch adversarial loss: 0.437799\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404056; batch adversarial loss: 0.367332\n",
      "epoch 14; iter: 0; batch classifier loss: 0.322692; batch adversarial loss: 0.418382\n",
      "epoch 14; iter: 200; batch classifier loss: 0.349947; batch adversarial loss: 0.374286\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307147; batch adversarial loss: 0.411918\n",
      "epoch 15; iter: 200; batch classifier loss: 0.394631; batch adversarial loss: 0.347749\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336551; batch adversarial loss: 0.531156\n",
      "epoch 16; iter: 200; batch classifier loss: 0.339317; batch adversarial loss: 0.339778\n",
      "epoch 17; iter: 0; batch classifier loss: 0.376432; batch adversarial loss: 0.336897\n",
      "epoch 17; iter: 200; batch classifier loss: 0.390962; batch adversarial loss: 0.452426\n",
      "epoch 18; iter: 0; batch classifier loss: 0.386637; batch adversarial loss: 0.345494\n",
      "epoch 18; iter: 200; batch classifier loss: 0.370200; batch adversarial loss: 0.263950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.418307; batch adversarial loss: 0.415502\n",
      "epoch 19; iter: 200; batch classifier loss: 0.336345; batch adversarial loss: 0.441123\n",
      "epoch 0; iter: 0; batch classifier loss: 24.852486; batch adversarial loss: 0.955931\n",
      "epoch 0; iter: 200; batch classifier loss: 7.107195; batch adversarial loss: 0.996568\n",
      "epoch 1; iter: 0; batch classifier loss: 5.172942; batch adversarial loss: 0.890150\n",
      "epoch 1; iter: 200; batch classifier loss: 35.608582; batch adversarial loss: 0.696131\n",
      "epoch 2; iter: 0; batch classifier loss: 5.481790; batch adversarial loss: 0.600716\n",
      "epoch 2; iter: 200; batch classifier loss: 3.321906; batch adversarial loss: 0.551426\n",
      "epoch 3; iter: 0; batch classifier loss: 4.893132; batch adversarial loss: 0.559570\n",
      "epoch 3; iter: 200; batch classifier loss: 6.004107; batch adversarial loss: 0.495049\n",
      "epoch 4; iter: 0; batch classifier loss: 3.898353; batch adversarial loss: 0.466675\n",
      "epoch 4; iter: 200; batch classifier loss: 1.037426; batch adversarial loss: 0.442441\n",
      "epoch 5; iter: 0; batch classifier loss: 0.866880; batch adversarial loss: 0.442078\n",
      "epoch 5; iter: 200; batch classifier loss: 1.525281; batch adversarial loss: 0.461279\n",
      "epoch 6; iter: 0; batch classifier loss: 1.261604; batch adversarial loss: 0.446648\n",
      "epoch 6; iter: 200; batch classifier loss: 1.145092; batch adversarial loss: 0.490707\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493427; batch adversarial loss: 0.426805\n",
      "epoch 7; iter: 200; batch classifier loss: 0.539357; batch adversarial loss: 0.500461\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504720; batch adversarial loss: 0.480665\n",
      "epoch 8; iter: 200; batch classifier loss: 0.518201; batch adversarial loss: 0.403789\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529957; batch adversarial loss: 0.421388\n",
      "epoch 9; iter: 200; batch classifier loss: 0.456395; batch adversarial loss: 0.446270\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531456; batch adversarial loss: 0.391056\n",
      "epoch 10; iter: 200; batch classifier loss: 0.912586; batch adversarial loss: 0.348322\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501012; batch adversarial loss: 0.479107\n",
      "epoch 11; iter: 200; batch classifier loss: 0.712119; batch adversarial loss: 0.400955\n",
      "epoch 12; iter: 0; batch classifier loss: 0.411466; batch adversarial loss: 0.382549\n",
      "epoch 12; iter: 200; batch classifier loss: 0.413972; batch adversarial loss: 0.389422\n",
      "epoch 13; iter: 0; batch classifier loss: 0.387587; batch adversarial loss: 0.373275\n",
      "epoch 13; iter: 200; batch classifier loss: 0.357115; batch adversarial loss: 0.280751\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371692; batch adversarial loss: 0.348393\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351777; batch adversarial loss: 0.327689\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374548; batch adversarial loss: 0.412500\n",
      "epoch 15; iter: 200; batch classifier loss: 0.417829; batch adversarial loss: 0.339695\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366674; batch adversarial loss: 0.291767\n",
      "epoch 16; iter: 200; batch classifier loss: 0.291736; batch adversarial loss: 0.411124\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337034; batch adversarial loss: 0.343470\n",
      "epoch 17; iter: 200; batch classifier loss: 0.374623; batch adversarial loss: 0.460321\n",
      "epoch 18; iter: 0; batch classifier loss: 0.355028; batch adversarial loss: 0.301736\n",
      "epoch 18; iter: 200; batch classifier loss: 0.358574; batch adversarial loss: 0.397235\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344615; batch adversarial loss: 0.283510\n",
      "epoch 19; iter: 200; batch classifier loss: 0.369872; batch adversarial loss: 0.334890\n",
      "epoch 0; iter: 0; batch classifier loss: 117.916908; batch adversarial loss: 0.656981\n",
      "epoch 0; iter: 200; batch classifier loss: 15.850458; batch adversarial loss: 0.594793\n",
      "epoch 1; iter: 0; batch classifier loss: 6.534096; batch adversarial loss: 0.582733\n",
      "epoch 1; iter: 200; batch classifier loss: 2.412316; batch adversarial loss: 0.565318\n",
      "epoch 2; iter: 0; batch classifier loss: 1.998393; batch adversarial loss: 0.528765\n",
      "epoch 2; iter: 200; batch classifier loss: 5.060322; batch adversarial loss: 0.458929\n",
      "epoch 3; iter: 0; batch classifier loss: 2.777722; batch adversarial loss: 0.508559\n",
      "epoch 3; iter: 200; batch classifier loss: 6.283653; batch adversarial loss: 0.522630\n",
      "epoch 4; iter: 0; batch classifier loss: 4.236687; batch adversarial loss: 0.410696\n",
      "epoch 4; iter: 200; batch classifier loss: 2.948381; batch adversarial loss: 0.483639\n",
      "epoch 5; iter: 0; batch classifier loss: 3.086921; batch adversarial loss: 0.400228\n",
      "epoch 5; iter: 200; batch classifier loss: 0.933532; batch adversarial loss: 0.417959\n",
      "epoch 6; iter: 0; batch classifier loss: 0.459988; batch adversarial loss: 0.480239\n",
      "epoch 6; iter: 200; batch classifier loss: 1.642899; batch adversarial loss: 0.464907\n",
      "epoch 7; iter: 0; batch classifier loss: 1.581713; batch adversarial loss: 0.457795\n",
      "epoch 7; iter: 200; batch classifier loss: 0.725527; batch adversarial loss: 0.411711\n",
      "epoch 8; iter: 0; batch classifier loss: 0.689928; batch adversarial loss: 0.370611\n",
      "epoch 8; iter: 200; batch classifier loss: 0.517214; batch adversarial loss: 0.441891\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555688; batch adversarial loss: 0.448779\n",
      "epoch 9; iter: 200; batch classifier loss: 0.452991; batch adversarial loss: 0.494553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.401816; batch adversarial loss: 0.405264\n",
      "epoch 10; iter: 200; batch classifier loss: 0.382918; batch adversarial loss: 0.401185\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472338; batch adversarial loss: 0.384616\n",
      "epoch 11; iter: 200; batch classifier loss: 0.493988; batch adversarial loss: 0.393335\n",
      "epoch 12; iter: 0; batch classifier loss: 0.456157; batch adversarial loss: 0.362212\n",
      "epoch 12; iter: 200; batch classifier loss: 0.366363; batch adversarial loss: 0.469959\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356540; batch adversarial loss: 0.284810\n",
      "epoch 13; iter: 200; batch classifier loss: 0.369008; batch adversarial loss: 0.417709\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308945; batch adversarial loss: 0.477767\n",
      "epoch 14; iter: 200; batch classifier loss: 0.382605; batch adversarial loss: 0.431880\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510410; batch adversarial loss: 0.429606\n",
      "epoch 15; iter: 200; batch classifier loss: 0.505339; batch adversarial loss: 0.341828\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358842; batch adversarial loss: 0.487181\n",
      "epoch 16; iter: 200; batch classifier loss: 0.421031; batch adversarial loss: 0.415196\n",
      "epoch 17; iter: 0; batch classifier loss: 0.362663; batch adversarial loss: 0.490192\n",
      "epoch 17; iter: 200; batch classifier loss: 0.295493; batch adversarial loss: 0.478631\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329024; batch adversarial loss: 0.421333\n",
      "epoch 18; iter: 200; batch classifier loss: 0.403010; batch adversarial loss: 0.410803\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396706; batch adversarial loss: 0.427545\n",
      "epoch 19; iter: 200; batch classifier loss: 0.326583; batch adversarial loss: 0.433057\n",
      "epoch 0; iter: 0; batch classifier loss: 6.171701; batch adversarial loss: 0.742412\n",
      "epoch 0; iter: 200; batch classifier loss: 16.948212; batch adversarial loss: 0.671491\n",
      "epoch 1; iter: 0; batch classifier loss: 6.923634; batch adversarial loss: 0.620596\n",
      "epoch 1; iter: 200; batch classifier loss: 4.918965; batch adversarial loss: 0.553670\n",
      "epoch 2; iter: 0; batch classifier loss: 6.254264; batch adversarial loss: 0.566875\n",
      "epoch 2; iter: 200; batch classifier loss: 5.124430; batch adversarial loss: 0.540454\n",
      "epoch 3; iter: 0; batch classifier loss: 9.387753; batch adversarial loss: 0.493830\n",
      "epoch 3; iter: 200; batch classifier loss: 1.113203; batch adversarial loss: 0.493357\n",
      "epoch 4; iter: 0; batch classifier loss: 6.615865; batch adversarial loss: 0.435360\n",
      "epoch 4; iter: 200; batch classifier loss: 2.690080; batch adversarial loss: 0.385265\n",
      "epoch 5; iter: 0; batch classifier loss: 1.580044; batch adversarial loss: 0.448893\n",
      "epoch 5; iter: 200; batch classifier loss: 2.164893; batch adversarial loss: 0.447615\n",
      "epoch 6; iter: 0; batch classifier loss: 1.586455; batch adversarial loss: 0.425402\n",
      "epoch 6; iter: 200; batch classifier loss: 1.539163; batch adversarial loss: 0.412935\n",
      "epoch 7; iter: 0; batch classifier loss: 1.048421; batch adversarial loss: 0.444162\n",
      "epoch 7; iter: 200; batch classifier loss: 0.506661; batch adversarial loss: 0.340095\n",
      "epoch 8; iter: 0; batch classifier loss: 0.974472; batch adversarial loss: 0.427487\n",
      "epoch 8; iter: 200; batch classifier loss: 0.607931; batch adversarial loss: 0.366600\n",
      "epoch 9; iter: 0; batch classifier loss: 0.393312; batch adversarial loss: 0.436556\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383017; batch adversarial loss: 0.469436\n",
      "epoch 10; iter: 0; batch classifier loss: 0.512745; batch adversarial loss: 0.393416\n",
      "epoch 10; iter: 200; batch classifier loss: 0.410980; batch adversarial loss: 0.377021\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515090; batch adversarial loss: 0.439124\n",
      "epoch 11; iter: 200; batch classifier loss: 0.510048; batch adversarial loss: 0.311095\n",
      "epoch 12; iter: 0; batch classifier loss: 0.373017; batch adversarial loss: 0.329015\n",
      "epoch 12; iter: 200; batch classifier loss: 0.406356; batch adversarial loss: 0.432246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.376218; batch adversarial loss: 0.402377\n",
      "epoch 13; iter: 200; batch classifier loss: 0.471246; batch adversarial loss: 0.376572\n",
      "epoch 14; iter: 0; batch classifier loss: 0.346927; batch adversarial loss: 0.369154\n",
      "epoch 14; iter: 200; batch classifier loss: 0.382427; batch adversarial loss: 0.314773\n",
      "epoch 15; iter: 0; batch classifier loss: 0.404100; batch adversarial loss: 0.393130\n",
      "epoch 15; iter: 200; batch classifier loss: 0.354899; batch adversarial loss: 0.498912\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403727; batch adversarial loss: 0.368489\n",
      "epoch 16; iter: 200; batch classifier loss: 0.440465; batch adversarial loss: 0.386275\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289213; batch adversarial loss: 0.435895\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345880; batch adversarial loss: 0.344333\n",
      "epoch 18; iter: 0; batch classifier loss: 0.390186; batch adversarial loss: 0.412462\n",
      "epoch 18; iter: 200; batch classifier loss: 0.346609; batch adversarial loss: 0.362946\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311204; batch adversarial loss: 0.459579\n",
      "epoch 19; iter: 200; batch classifier loss: 0.369933; batch adversarial loss: 0.411071\n",
      "epoch 0; iter: 0; batch classifier loss: 40.158108; batch adversarial loss: 0.591904\n",
      "epoch 0; iter: 200; batch classifier loss: 6.516524; batch adversarial loss: 0.603950\n",
      "epoch 1; iter: 0; batch classifier loss: 5.030178; batch adversarial loss: 0.571252\n",
      "epoch 1; iter: 200; batch classifier loss: 3.094493; batch adversarial loss: 0.507653\n",
      "epoch 2; iter: 0; batch classifier loss: 3.643145; batch adversarial loss: 0.524277\n",
      "epoch 2; iter: 200; batch classifier loss: 1.235413; batch adversarial loss: 0.499626\n",
      "epoch 3; iter: 0; batch classifier loss: 6.649612; batch adversarial loss: 0.501786\n",
      "epoch 3; iter: 200; batch classifier loss: 5.635520; batch adversarial loss: 0.430677\n",
      "epoch 4; iter: 0; batch classifier loss: 5.148739; batch adversarial loss: 0.409815\n",
      "epoch 4; iter: 200; batch classifier loss: 5.455225; batch adversarial loss: 0.445697\n",
      "epoch 5; iter: 0; batch classifier loss: 2.570751; batch adversarial loss: 0.487960\n",
      "epoch 5; iter: 200; batch classifier loss: 3.004570; batch adversarial loss: 0.470023\n",
      "epoch 6; iter: 0; batch classifier loss: 0.825320; batch adversarial loss: 0.448359\n",
      "epoch 6; iter: 200; batch classifier loss: 1.942072; batch adversarial loss: 0.486076\n",
      "epoch 7; iter: 0; batch classifier loss: 0.891659; batch adversarial loss: 0.511520\n",
      "epoch 7; iter: 200; batch classifier loss: 2.095588; batch adversarial loss: 0.419011\n",
      "epoch 8; iter: 0; batch classifier loss: 1.018569; batch adversarial loss: 0.439099\n",
      "epoch 8; iter: 200; batch classifier loss: 0.730368; batch adversarial loss: 0.362958\n",
      "epoch 9; iter: 0; batch classifier loss: 0.831686; batch adversarial loss: 0.389585\n",
      "epoch 9; iter: 200; batch classifier loss: 0.536225; batch adversarial loss: 0.343536\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470480; batch adversarial loss: 0.383451\n",
      "epoch 10; iter: 200; batch classifier loss: 0.656995; batch adversarial loss: 0.423189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.497763; batch adversarial loss: 0.405764\n",
      "epoch 11; iter: 200; batch classifier loss: 0.495345; batch adversarial loss: 0.392497\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506976; batch adversarial loss: 0.374508\n",
      "epoch 12; iter: 200; batch classifier loss: 0.352688; batch adversarial loss: 0.384149\n",
      "epoch 13; iter: 0; batch classifier loss: 0.623124; batch adversarial loss: 0.416421\n",
      "epoch 13; iter: 200; batch classifier loss: 0.337506; batch adversarial loss: 0.424240\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331523; batch adversarial loss: 0.463094\n",
      "epoch 14; iter: 200; batch classifier loss: 0.526670; batch adversarial loss: 0.389619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.392235; batch adversarial loss: 0.457552\n",
      "epoch 15; iter: 200; batch classifier loss: 0.409473; batch adversarial loss: 0.364965\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387231; batch adversarial loss: 0.463616\n",
      "epoch 16; iter: 200; batch classifier loss: 0.375462; batch adversarial loss: 0.421859\n",
      "epoch 17; iter: 0; batch classifier loss: 0.386063; batch adversarial loss: 0.342412\n",
      "epoch 17; iter: 200; batch classifier loss: 0.288358; batch adversarial loss: 0.528599\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348247; batch adversarial loss: 0.464153\n",
      "epoch 18; iter: 200; batch classifier loss: 0.347097; batch adversarial loss: 0.318441\n",
      "epoch 19; iter: 0; batch classifier loss: 0.353029; batch adversarial loss: 0.401655\n",
      "epoch 19; iter: 200; batch classifier loss: 0.390924; batch adversarial loss: 0.410634\n",
      "epoch 0; iter: 0; batch classifier loss: 12.272047; batch adversarial loss: 0.621858\n",
      "epoch 0; iter: 200; batch classifier loss: 5.912625; batch adversarial loss: 0.575112\n",
      "epoch 1; iter: 0; batch classifier loss: 5.157489; batch adversarial loss: 0.563386\n",
      "epoch 1; iter: 200; batch classifier loss: 10.228030; batch adversarial loss: 0.547046\n",
      "epoch 2; iter: 0; batch classifier loss: 3.714600; batch adversarial loss: 0.487334\n",
      "epoch 2; iter: 200; batch classifier loss: 1.708866; batch adversarial loss: 0.483136\n",
      "epoch 3; iter: 0; batch classifier loss: 3.233626; batch adversarial loss: 0.480764\n",
      "epoch 3; iter: 200; batch classifier loss: 1.444839; batch adversarial loss: 0.442184\n",
      "epoch 4; iter: 0; batch classifier loss: 2.143404; batch adversarial loss: 0.512829\n",
      "epoch 4; iter: 200; batch classifier loss: 2.068774; batch adversarial loss: 0.415982\n",
      "epoch 5; iter: 0; batch classifier loss: 1.113786; batch adversarial loss: 0.463521\n",
      "epoch 5; iter: 200; batch classifier loss: 1.805353; batch adversarial loss: 0.401102\n",
      "epoch 6; iter: 0; batch classifier loss: 0.805057; batch adversarial loss: 0.542869\n",
      "epoch 6; iter: 200; batch classifier loss: 0.646264; batch adversarial loss: 0.363192\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462895; batch adversarial loss: 0.483121\n",
      "epoch 7; iter: 200; batch classifier loss: 0.389309; batch adversarial loss: 0.329968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.480731; batch adversarial loss: 0.362977\n",
      "epoch 8; iter: 200; batch classifier loss: 0.678024; batch adversarial loss: 0.406590\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420674; batch adversarial loss: 0.433037\n",
      "epoch 9; iter: 200; batch classifier loss: 0.315941; batch adversarial loss: 0.456308\n",
      "epoch 10; iter: 0; batch classifier loss: 0.355703; batch adversarial loss: 0.357397\n",
      "epoch 10; iter: 200; batch classifier loss: 0.413236; batch adversarial loss: 0.328470\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313471; batch adversarial loss: 0.357211\n",
      "epoch 11; iter: 200; batch classifier loss: 0.307389; batch adversarial loss: 0.453003\n",
      "epoch 12; iter: 0; batch classifier loss: 0.359310; batch adversarial loss: 0.362276\n",
      "epoch 12; iter: 200; batch classifier loss: 0.306852; batch adversarial loss: 0.441674\n",
      "epoch 13; iter: 0; batch classifier loss: 0.422663; batch adversarial loss: 0.379089\n",
      "epoch 13; iter: 200; batch classifier loss: 0.560515; batch adversarial loss: 0.456291\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412652; batch adversarial loss: 0.415743\n",
      "epoch 14; iter: 200; batch classifier loss: 0.346753; batch adversarial loss: 0.300585\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433794; batch adversarial loss: 0.428936\n",
      "epoch 15; iter: 200; batch classifier loss: 0.282945; batch adversarial loss: 0.370488\n",
      "epoch 16; iter: 0; batch classifier loss: 0.347083; batch adversarial loss: 0.383005\n",
      "epoch 16; iter: 200; batch classifier loss: 0.359173; batch adversarial loss: 0.506692\n",
      "epoch 17; iter: 0; batch classifier loss: 0.304366; batch adversarial loss: 0.362466\n",
      "epoch 17; iter: 200; batch classifier loss: 0.295883; batch adversarial loss: 0.431630\n",
      "epoch 18; iter: 0; batch classifier loss: 0.413518; batch adversarial loss: 0.429042\n",
      "epoch 18; iter: 200; batch classifier loss: 0.317211; batch adversarial loss: 0.403487\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385446; batch adversarial loss: 0.502379\n",
      "epoch 19; iter: 200; batch classifier loss: 0.321463; batch adversarial loss: 0.332834\n",
      "epoch 0; iter: 0; batch classifier loss: 24.469757; batch adversarial loss: 0.684483\n",
      "epoch 0; iter: 200; batch classifier loss: 28.049721; batch adversarial loss: 0.571047\n",
      "epoch 1; iter: 0; batch classifier loss: 4.065064; batch adversarial loss: 0.567399\n",
      "epoch 1; iter: 200; batch classifier loss: 14.438881; batch adversarial loss: 0.509192\n",
      "epoch 2; iter: 0; batch classifier loss: 2.643074; batch adversarial loss: 0.477611\n",
      "epoch 2; iter: 200; batch classifier loss: 2.664454; batch adversarial loss: 0.478564\n",
      "epoch 3; iter: 0; batch classifier loss: 1.809160; batch adversarial loss: 0.474240\n",
      "epoch 3; iter: 200; batch classifier loss: 1.229700; batch adversarial loss: 0.475233\n",
      "epoch 4; iter: 0; batch classifier loss: 3.168144; batch adversarial loss: 0.364513\n",
      "epoch 4; iter: 200; batch classifier loss: 1.490637; batch adversarial loss: 0.446598\n",
      "epoch 5; iter: 0; batch classifier loss: 1.660854; batch adversarial loss: 0.370753\n",
      "epoch 5; iter: 200; batch classifier loss: 1.014927; batch adversarial loss: 0.443189\n",
      "epoch 6; iter: 0; batch classifier loss: 0.665264; batch adversarial loss: 0.395750\n",
      "epoch 6; iter: 200; batch classifier loss: 0.761077; batch adversarial loss: 0.443780\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586566; batch adversarial loss: 0.440837\n",
      "epoch 7; iter: 200; batch classifier loss: 0.426621; batch adversarial loss: 0.316715\n",
      "epoch 8; iter: 0; batch classifier loss: 0.412400; batch adversarial loss: 0.330812\n",
      "epoch 8; iter: 200; batch classifier loss: 0.558547; batch adversarial loss: 0.373483\n",
      "epoch 9; iter: 0; batch classifier loss: 0.694031; batch adversarial loss: 0.504426\n",
      "epoch 9; iter: 200; batch classifier loss: 0.371036; batch adversarial loss: 0.418441\n",
      "epoch 10; iter: 0; batch classifier loss: 0.448764; batch adversarial loss: 0.380726\n",
      "epoch 10; iter: 200; batch classifier loss: 0.347817; batch adversarial loss: 0.405984\n",
      "epoch 11; iter: 0; batch classifier loss: 0.422653; batch adversarial loss: 0.277074\n",
      "epoch 11; iter: 200; batch classifier loss: 0.445204; batch adversarial loss: 0.469914\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522132; batch adversarial loss: 0.393990\n",
      "epoch 12; iter: 200; batch classifier loss: 0.325329; batch adversarial loss: 0.344583\n",
      "epoch 13; iter: 0; batch classifier loss: 0.378967; batch adversarial loss: 0.380486\n",
      "epoch 13; iter: 200; batch classifier loss: 0.368115; batch adversarial loss: 0.385793\n",
      "epoch 14; iter: 0; batch classifier loss: 0.305344; batch adversarial loss: 0.406037\n",
      "epoch 14; iter: 200; batch classifier loss: 0.437497; batch adversarial loss: 0.379162\n",
      "epoch 15; iter: 0; batch classifier loss: 0.411713; batch adversarial loss: 0.414097\n",
      "epoch 15; iter: 200; batch classifier loss: 0.388189; batch adversarial loss: 0.422691\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352861; batch adversarial loss: 0.408015\n",
      "epoch 16; iter: 200; batch classifier loss: 0.327706; batch adversarial loss: 0.491997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.536496; batch adversarial loss: 0.465599\n",
      "epoch 17; iter: 200; batch classifier loss: 0.560637; batch adversarial loss: 0.503636\n",
      "epoch 18; iter: 0; batch classifier loss: 0.373794; batch adversarial loss: 0.407748\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326988; batch adversarial loss: 0.318421\n",
      "epoch 19; iter: 0; batch classifier loss: 0.389303; batch adversarial loss: 0.425248\n",
      "epoch 19; iter: 200; batch classifier loss: 0.298581; batch adversarial loss: 0.424189\n",
      "epoch 0; iter: 0; batch classifier loss: 21.859604; batch adversarial loss: 0.628947\n",
      "epoch 0; iter: 200; batch classifier loss: 3.700894; batch adversarial loss: 0.609702\n",
      "epoch 1; iter: 0; batch classifier loss: 9.239059; batch adversarial loss: 0.598238\n",
      "epoch 1; iter: 200; batch classifier loss: 7.810561; batch adversarial loss: 0.569741\n",
      "epoch 2; iter: 0; batch classifier loss: 5.770837; batch adversarial loss: 0.524595\n",
      "epoch 2; iter: 200; batch classifier loss: 5.980756; batch adversarial loss: 0.509212\n",
      "epoch 3; iter: 0; batch classifier loss: 3.104462; batch adversarial loss: 0.435600\n",
      "epoch 3; iter: 200; batch classifier loss: 1.033391; batch adversarial loss: 0.461216\n",
      "epoch 4; iter: 0; batch classifier loss: 1.792930; batch adversarial loss: 0.481480\n",
      "epoch 4; iter: 200; batch classifier loss: 2.098420; batch adversarial loss: 0.434649\n",
      "epoch 5; iter: 0; batch classifier loss: 1.611316; batch adversarial loss: 0.417505\n",
      "epoch 5; iter: 200; batch classifier loss: 0.903289; batch adversarial loss: 0.456387\n",
      "epoch 6; iter: 0; batch classifier loss: 1.418012; batch adversarial loss: 0.439788\n",
      "epoch 6; iter: 200; batch classifier loss: 0.806982; batch adversarial loss: 0.343681\n",
      "epoch 7; iter: 0; batch classifier loss: 0.673205; batch adversarial loss: 0.392875\n",
      "epoch 7; iter: 200; batch classifier loss: 0.673410; batch adversarial loss: 0.446831\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539806; batch adversarial loss: 0.466781\n",
      "epoch 8; iter: 200; batch classifier loss: 1.002449; batch adversarial loss: 0.408847\n",
      "epoch 9; iter: 0; batch classifier loss: 0.481645; batch adversarial loss: 0.450936\n",
      "epoch 9; iter: 200; batch classifier loss: 0.348858; batch adversarial loss: 0.385773\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419940; batch adversarial loss: 0.352537\n",
      "epoch 10; iter: 200; batch classifier loss: 0.320150; batch adversarial loss: 0.404875\n",
      "epoch 11; iter: 0; batch classifier loss: 0.707101; batch adversarial loss: 0.402861\n",
      "epoch 11; iter: 200; batch classifier loss: 0.336520; batch adversarial loss: 0.354274\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345113; batch adversarial loss: 0.426912\n",
      "epoch 12; iter: 200; batch classifier loss: 0.457316; batch adversarial loss: 0.435185\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346188; batch adversarial loss: 0.353488\n",
      "epoch 13; iter: 200; batch classifier loss: 0.452640; batch adversarial loss: 0.408041\n",
      "epoch 14; iter: 0; batch classifier loss: 0.358761; batch adversarial loss: 0.349117\n",
      "epoch 14; iter: 200; batch classifier loss: 0.299583; batch adversarial loss: 0.391619\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370181; batch adversarial loss: 0.397765\n",
      "epoch 15; iter: 200; batch classifier loss: 0.403418; batch adversarial loss: 0.274221\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419430; batch adversarial loss: 0.446423\n",
      "epoch 16; iter: 200; batch classifier loss: 0.343179; batch adversarial loss: 0.406671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.389864; batch adversarial loss: 0.344052\n",
      "epoch 17; iter: 200; batch classifier loss: 0.363405; batch adversarial loss: 0.439088\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329286; batch adversarial loss: 0.349942\n",
      "epoch 18; iter: 200; batch classifier loss: 0.303635; batch adversarial loss: 0.585826\n",
      "epoch 19; iter: 0; batch classifier loss: 0.370854; batch adversarial loss: 0.445627\n",
      "epoch 19; iter: 200; batch classifier loss: 0.322564; batch adversarial loss: 0.506413\n",
      "epoch 0; iter: 0; batch classifier loss: 354.666290; batch adversarial loss: 0.884522\n",
      "epoch 0; iter: 200; batch classifier loss: 7.124145; batch adversarial loss: 0.822369\n",
      "epoch 1; iter: 0; batch classifier loss: 9.168115; batch adversarial loss: 0.723887\n",
      "epoch 1; iter: 200; batch classifier loss: 4.131069; batch adversarial loss: 0.604205\n",
      "epoch 2; iter: 0; batch classifier loss: 3.736175; batch adversarial loss: 0.603725\n",
      "epoch 2; iter: 200; batch classifier loss: 5.946767; batch adversarial loss: 0.545597\n",
      "epoch 3; iter: 0; batch classifier loss: 6.784012; batch adversarial loss: 0.535283\n",
      "epoch 3; iter: 200; batch classifier loss: 0.832967; batch adversarial loss: 0.540826\n",
      "epoch 4; iter: 0; batch classifier loss: 7.459194; batch adversarial loss: 0.491384\n",
      "epoch 4; iter: 200; batch classifier loss: 8.725362; batch adversarial loss: 0.414177\n",
      "epoch 5; iter: 0; batch classifier loss: 3.015122; batch adversarial loss: 0.468808\n",
      "epoch 5; iter: 200; batch classifier loss: 0.820055; batch adversarial loss: 0.421052\n",
      "epoch 6; iter: 0; batch classifier loss: 1.130013; batch adversarial loss: 0.406376\n",
      "epoch 6; iter: 200; batch classifier loss: 0.688970; batch adversarial loss: 0.405460\n",
      "epoch 7; iter: 0; batch classifier loss: 1.640925; batch adversarial loss: 0.450052\n",
      "epoch 7; iter: 200; batch classifier loss: 0.985316; batch adversarial loss: 0.399834\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568179; batch adversarial loss: 0.422996\n",
      "epoch 8; iter: 200; batch classifier loss: 1.122121; batch adversarial loss: 0.431647\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381957; batch adversarial loss: 0.416738\n",
      "epoch 9; iter: 200; batch classifier loss: 0.861938; batch adversarial loss: 0.492733\n",
      "epoch 10; iter: 0; batch classifier loss: 0.609126; batch adversarial loss: 0.385365\n",
      "epoch 10; iter: 200; batch classifier loss: 0.550345; batch adversarial loss: 0.435625\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562337; batch adversarial loss: 0.415026\n",
      "epoch 11; iter: 200; batch classifier loss: 0.421979; batch adversarial loss: 0.392675\n",
      "epoch 12; iter: 0; batch classifier loss: 0.725119; batch adversarial loss: 0.361568\n",
      "epoch 12; iter: 200; batch classifier loss: 0.514296; batch adversarial loss: 0.425045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.362146; batch adversarial loss: 0.430473\n",
      "epoch 13; iter: 200; batch classifier loss: 0.417233; batch adversarial loss: 0.342674\n",
      "epoch 14; iter: 0; batch classifier loss: 0.366611; batch adversarial loss: 0.410185\n",
      "epoch 14; iter: 200; batch classifier loss: 0.361912; batch adversarial loss: 0.318982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.397709; batch adversarial loss: 0.448861\n",
      "epoch 15; iter: 200; batch classifier loss: 0.408953; batch adversarial loss: 0.412171\n",
      "epoch 16; iter: 0; batch classifier loss: 0.439415; batch adversarial loss: 0.377328\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342825; batch adversarial loss: 0.543369\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363612; batch adversarial loss: 0.350482\n",
      "epoch 17; iter: 200; batch classifier loss: 0.407370; batch adversarial loss: 0.491388\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337443; batch adversarial loss: 0.454477\n",
      "epoch 18; iter: 200; batch classifier loss: 0.389911; batch adversarial loss: 0.432119\n",
      "epoch 19; iter: 0; batch classifier loss: 0.366946; batch adversarial loss: 0.364405\n",
      "epoch 19; iter: 200; batch classifier loss: 0.403762; batch adversarial loss: 0.481739\n",
      "epoch 0; iter: 0; batch classifier loss: 12.564054; batch adversarial loss: 0.544923\n",
      "epoch 0; iter: 200; batch classifier loss: 9.451612; batch adversarial loss: 0.567471\n",
      "epoch 1; iter: 0; batch classifier loss: 3.746640; batch adversarial loss: 0.585627\n",
      "epoch 1; iter: 200; batch classifier loss: 3.986084; batch adversarial loss: 0.524948\n",
      "epoch 2; iter: 0; batch classifier loss: 2.741966; batch adversarial loss: 0.510220\n",
      "epoch 2; iter: 200; batch classifier loss: 3.229586; batch adversarial loss: 0.444614\n",
      "epoch 3; iter: 0; batch classifier loss: 2.053031; batch adversarial loss: 0.486518\n",
      "epoch 3; iter: 200; batch classifier loss: 1.803350; batch adversarial loss: 0.437931\n",
      "epoch 4; iter: 0; batch classifier loss: 2.780139; batch adversarial loss: 0.475222\n",
      "epoch 4; iter: 200; batch classifier loss: 2.564040; batch adversarial loss: 0.431085\n",
      "epoch 5; iter: 0; batch classifier loss: 0.665263; batch adversarial loss: 0.460353\n",
      "epoch 5; iter: 200; batch classifier loss: 0.728263; batch adversarial loss: 0.367800\n",
      "epoch 6; iter: 0; batch classifier loss: 0.711363; batch adversarial loss: 0.491103\n",
      "epoch 6; iter: 200; batch classifier loss: 0.818578; batch adversarial loss: 0.352311\n",
      "epoch 7; iter: 0; batch classifier loss: 0.351219; batch adversarial loss: 0.420081\n",
      "epoch 7; iter: 200; batch classifier loss: 0.546880; batch adversarial loss: 0.461737\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549013; batch adversarial loss: 0.526844\n",
      "epoch 8; iter: 200; batch classifier loss: 0.476486; batch adversarial loss: 0.404262\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421285; batch adversarial loss: 0.397486\n",
      "epoch 9; iter: 200; batch classifier loss: 0.420246; batch adversarial loss: 0.509661\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469493; batch adversarial loss: 0.402617\n",
      "epoch 10; iter: 200; batch classifier loss: 0.498891; batch adversarial loss: 0.447602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362405; batch adversarial loss: 0.534195\n",
      "epoch 11; iter: 200; batch classifier loss: 0.417993; batch adversarial loss: 0.483526\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349845; batch adversarial loss: 0.362290\n",
      "epoch 12; iter: 200; batch classifier loss: 0.368299; batch adversarial loss: 0.462470\n",
      "epoch 13; iter: 0; batch classifier loss: 0.401965; batch adversarial loss: 0.399416\n",
      "epoch 13; iter: 200; batch classifier loss: 0.415338; batch adversarial loss: 0.440075\n",
      "epoch 14; iter: 0; batch classifier loss: 0.420786; batch adversarial loss: 0.454765\n",
      "epoch 14; iter: 200; batch classifier loss: 0.438420; batch adversarial loss: 0.402110\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309732; batch adversarial loss: 0.389541\n",
      "epoch 15; iter: 200; batch classifier loss: 0.399829; batch adversarial loss: 0.547067\n",
      "epoch 16; iter: 0; batch classifier loss: 0.361735; batch adversarial loss: 0.493029\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383641; batch adversarial loss: 0.327857\n",
      "epoch 17; iter: 0; batch classifier loss: 0.380438; batch adversarial loss: 0.514457\n",
      "epoch 17; iter: 200; batch classifier loss: 0.391889; batch adversarial loss: 0.398866\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414942; batch adversarial loss: 0.327705\n",
      "epoch 18; iter: 200; batch classifier loss: 0.314723; batch adversarial loss: 0.320204\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375336; batch adversarial loss: 0.401938\n",
      "epoch 19; iter: 200; batch classifier loss: 0.293433; batch adversarial loss: 0.424881\n",
      "epoch 0; iter: 0; batch classifier loss: 50.618168; batch adversarial loss: 0.598698\n",
      "epoch 0; iter: 200; batch classifier loss: 10.947978; batch adversarial loss: 0.577246\n",
      "epoch 1; iter: 0; batch classifier loss: 29.222708; batch adversarial loss: 0.534672\n",
      "epoch 1; iter: 200; batch classifier loss: 7.982309; batch adversarial loss: 0.517515\n",
      "epoch 2; iter: 0; batch classifier loss: 1.659534; batch adversarial loss: 0.519047\n",
      "epoch 2; iter: 200; batch classifier loss: 8.696209; batch adversarial loss: 0.476233\n",
      "epoch 3; iter: 0; batch classifier loss: 5.118567; batch adversarial loss: 0.397308\n",
      "epoch 3; iter: 200; batch classifier loss: 5.562238; batch adversarial loss: 0.385920\n",
      "epoch 4; iter: 0; batch classifier loss: 4.254386; batch adversarial loss: 0.495608\n",
      "epoch 4; iter: 200; batch classifier loss: 1.055949; batch adversarial loss: 0.403832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.801447; batch adversarial loss: 0.449301\n",
      "epoch 5; iter: 200; batch classifier loss: 1.760245; batch adversarial loss: 0.537917\n",
      "epoch 6; iter: 0; batch classifier loss: 1.475026; batch adversarial loss: 0.383301\n",
      "epoch 6; iter: 200; batch classifier loss: 0.973921; batch adversarial loss: 0.347688\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632807; batch adversarial loss: 0.409058\n",
      "epoch 7; iter: 200; batch classifier loss: 0.588186; batch adversarial loss: 0.346279\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466129; batch adversarial loss: 0.510960\n",
      "epoch 8; iter: 200; batch classifier loss: 1.140253; batch adversarial loss: 0.310255\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486920; batch adversarial loss: 0.469021\n",
      "epoch 9; iter: 200; batch classifier loss: 0.402471; batch adversarial loss: 0.467860\n",
      "epoch 10; iter: 0; batch classifier loss: 0.438550; batch adversarial loss: 0.429371\n",
      "epoch 10; iter: 200; batch classifier loss: 0.534561; batch adversarial loss: 0.353081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441745; batch adversarial loss: 0.428716\n",
      "epoch 11; iter: 200; batch classifier loss: 0.498856; batch adversarial loss: 0.404549\n",
      "epoch 12; iter: 0; batch classifier loss: 0.443088; batch adversarial loss: 0.488295\n",
      "epoch 12; iter: 200; batch classifier loss: 0.474520; batch adversarial loss: 0.459507\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394652; batch adversarial loss: 0.421014\n",
      "epoch 13; iter: 200; batch classifier loss: 0.380366; batch adversarial loss: 0.336635\n",
      "epoch 14; iter: 0; batch classifier loss: 0.398828; batch adversarial loss: 0.379244\n",
      "epoch 14; iter: 200; batch classifier loss: 0.301759; batch adversarial loss: 0.429427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.410715; batch adversarial loss: 0.356612\n",
      "epoch 15; iter: 200; batch classifier loss: 0.406654; batch adversarial loss: 0.385831\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289511; batch adversarial loss: 0.502924\n",
      "epoch 16; iter: 200; batch classifier loss: 0.343417; batch adversarial loss: 0.384250\n",
      "epoch 17; iter: 0; batch classifier loss: 0.273075; batch adversarial loss: 0.382737\n",
      "epoch 17; iter: 200; batch classifier loss: 0.472919; batch adversarial loss: 0.356709\n",
      "epoch 18; iter: 0; batch classifier loss: 0.377459; batch adversarial loss: 0.520771\n",
      "epoch 18; iter: 200; batch classifier loss: 0.313083; batch adversarial loss: 0.376737\n",
      "epoch 19; iter: 0; batch classifier loss: 0.348813; batch adversarial loss: 0.358163\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429988; batch adversarial loss: 0.302746\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 55.320618; batch adversarial loss: 0.697971\n",
      "epoch 0; iter: 200; batch classifier loss: 5.842278; batch adversarial loss: 0.595619\n",
      "epoch 1; iter: 0; batch classifier loss: 5.134553; batch adversarial loss: 0.561916\n",
      "epoch 1; iter: 200; batch classifier loss: 5.438994; batch adversarial loss: 0.512899\n",
      "epoch 2; iter: 0; batch classifier loss: 3.649149; batch adversarial loss: 0.456856\n",
      "epoch 2; iter: 200; batch classifier loss: 8.894793; batch adversarial loss: 0.456294\n",
      "epoch 3; iter: 0; batch classifier loss: 4.052201; batch adversarial loss: 0.475005\n",
      "epoch 3; iter: 200; batch classifier loss: 3.222743; batch adversarial loss: 0.458513\n",
      "epoch 4; iter: 0; batch classifier loss: 0.940389; batch adversarial loss: 0.402325\n",
      "epoch 4; iter: 200; batch classifier loss: 2.169640; batch adversarial loss: 0.490532\n",
      "epoch 5; iter: 0; batch classifier loss: 1.912506; batch adversarial loss: 0.410921\n",
      "epoch 5; iter: 200; batch classifier loss: 1.022658; batch adversarial loss: 0.451121\n",
      "epoch 6; iter: 0; batch classifier loss: 1.019938; batch adversarial loss: 0.436883\n",
      "epoch 6; iter: 200; batch classifier loss: 1.088840; batch adversarial loss: 0.386593\n",
      "epoch 7; iter: 0; batch classifier loss: 0.382748; batch adversarial loss: 0.412260\n",
      "epoch 7; iter: 200; batch classifier loss: 0.606459; batch adversarial loss: 0.398742\n",
      "epoch 8; iter: 0; batch classifier loss: 0.638108; batch adversarial loss: 0.391215\n",
      "epoch 8; iter: 200; batch classifier loss: 0.514562; batch adversarial loss: 0.446220\n",
      "epoch 9; iter: 0; batch classifier loss: 0.963089; batch adversarial loss: 0.444036\n",
      "epoch 9; iter: 200; batch classifier loss: 0.565481; batch adversarial loss: 0.439023\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541366; batch adversarial loss: 0.392797\n",
      "epoch 10; iter: 200; batch classifier loss: 0.441445; batch adversarial loss: 0.391169\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398673; batch adversarial loss: 0.407977\n",
      "epoch 11; iter: 200; batch classifier loss: 0.677782; batch adversarial loss: 0.299547\n",
      "epoch 12; iter: 0; batch classifier loss: 0.640923; batch adversarial loss: 0.336100\n",
      "epoch 12; iter: 200; batch classifier loss: 0.381323; batch adversarial loss: 0.386810\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348526; batch adversarial loss: 0.323351\n",
      "epoch 13; iter: 200; batch classifier loss: 0.324901; batch adversarial loss: 0.503875\n",
      "epoch 14; iter: 0; batch classifier loss: 0.416936; batch adversarial loss: 0.439689\n",
      "epoch 14; iter: 200; batch classifier loss: 0.353438; batch adversarial loss: 0.400125\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382796; batch adversarial loss: 0.383145\n",
      "epoch 15; iter: 200; batch classifier loss: 0.336152; batch adversarial loss: 0.380770\n",
      "epoch 16; iter: 0; batch classifier loss: 0.290052; batch adversarial loss: 0.402757\n",
      "epoch 16; iter: 200; batch classifier loss: 0.300328; batch adversarial loss: 0.515943\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338234; batch adversarial loss: 0.329499\n",
      "epoch 17; iter: 200; batch classifier loss: 0.323318; batch adversarial loss: 0.414455\n",
      "epoch 18; iter: 0; batch classifier loss: 0.372406; batch adversarial loss: 0.385042\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321421; batch adversarial loss: 0.391677\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331068; batch adversarial loss: 0.529822\n",
      "epoch 19; iter: 200; batch classifier loss: 0.319957; batch adversarial loss: 0.434881\n",
      "epoch 20; iter: 0; batch classifier loss: 0.285737; batch adversarial loss: 0.385731\n",
      "epoch 20; iter: 200; batch classifier loss: 0.311642; batch adversarial loss: 0.428289\n",
      "epoch 21; iter: 0; batch classifier loss: 0.326646; batch adversarial loss: 0.492345\n",
      "epoch 21; iter: 200; batch classifier loss: 0.313752; batch adversarial loss: 0.456355\n",
      "epoch 22; iter: 0; batch classifier loss: 0.367670; batch adversarial loss: 0.419139\n",
      "epoch 22; iter: 200; batch classifier loss: 0.324628; batch adversarial loss: 0.438901\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288082; batch adversarial loss: 0.439161\n",
      "epoch 23; iter: 200; batch classifier loss: 0.402239; batch adversarial loss: 0.375224\n",
      "epoch 24; iter: 0; batch classifier loss: 0.306341; batch adversarial loss: 0.426886\n",
      "epoch 24; iter: 200; batch classifier loss: 0.338113; batch adversarial loss: 0.365954\n",
      "epoch 25; iter: 0; batch classifier loss: 0.361881; batch adversarial loss: 0.345431\n",
      "epoch 25; iter: 200; batch classifier loss: 0.255281; batch adversarial loss: 0.377273\n",
      "epoch 26; iter: 0; batch classifier loss: 0.304310; batch adversarial loss: 0.484335\n",
      "epoch 26; iter: 200; batch classifier loss: 0.382735; batch adversarial loss: 0.360556\n",
      "epoch 27; iter: 0; batch classifier loss: 0.291628; batch adversarial loss: 0.374710\n",
      "epoch 27; iter: 200; batch classifier loss: 0.381687; batch adversarial loss: 0.381215\n",
      "epoch 28; iter: 0; batch classifier loss: 0.300088; batch adversarial loss: 0.427188\n",
      "epoch 28; iter: 200; batch classifier loss: 0.379538; batch adversarial loss: 0.361129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323211; batch adversarial loss: 0.308463\n",
      "epoch 29; iter: 200; batch classifier loss: 0.348343; batch adversarial loss: 0.453154\n",
      "epoch 30; iter: 0; batch classifier loss: 0.369652; batch adversarial loss: 0.429981\n",
      "epoch 30; iter: 200; batch classifier loss: 0.323619; batch adversarial loss: 0.332078\n",
      "epoch 31; iter: 0; batch classifier loss: 0.303515; batch adversarial loss: 0.353774\n",
      "epoch 31; iter: 200; batch classifier loss: 0.264875; batch adversarial loss: 0.442665\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348414; batch adversarial loss: 0.248640\n",
      "epoch 32; iter: 200; batch classifier loss: 0.327837; batch adversarial loss: 0.485668\n",
      "epoch 33; iter: 0; batch classifier loss: 0.369527; batch adversarial loss: 0.397703\n",
      "epoch 33; iter: 200; batch classifier loss: 0.314993; batch adversarial loss: 0.400129\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331674; batch adversarial loss: 0.454143\n",
      "epoch 34; iter: 200; batch classifier loss: 0.313134; batch adversarial loss: 0.388926\n",
      "epoch 35; iter: 0; batch classifier loss: 0.271716; batch adversarial loss: 0.451726\n",
      "epoch 35; iter: 200; batch classifier loss: 0.418594; batch adversarial loss: 0.393821\n",
      "epoch 36; iter: 0; batch classifier loss: 0.362445; batch adversarial loss: 0.326912\n",
      "epoch 36; iter: 200; batch classifier loss: 0.277216; batch adversarial loss: 0.421401\n",
      "epoch 37; iter: 0; batch classifier loss: 0.327525; batch adversarial loss: 0.394449\n",
      "epoch 37; iter: 200; batch classifier loss: 0.351099; batch adversarial loss: 0.477799\n",
      "epoch 38; iter: 0; batch classifier loss: 0.215108; batch adversarial loss: 0.409991\n",
      "epoch 38; iter: 200; batch classifier loss: 0.339547; batch adversarial loss: 0.356246\n",
      "epoch 39; iter: 0; batch classifier loss: 0.340313; batch adversarial loss: 0.350281\n",
      "epoch 39; iter: 200; batch classifier loss: 0.360501; batch adversarial loss: 0.475714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367922; batch adversarial loss: 0.399847\n",
      "epoch 40; iter: 200; batch classifier loss: 0.407805; batch adversarial loss: 0.488891\n",
      "epoch 41; iter: 0; batch classifier loss: 0.321978; batch adversarial loss: 0.348406\n",
      "epoch 41; iter: 200; batch classifier loss: 0.252375; batch adversarial loss: 0.504975\n",
      "epoch 42; iter: 0; batch classifier loss: 0.371944; batch adversarial loss: 0.357983\n",
      "epoch 42; iter: 200; batch classifier loss: 0.467466; batch adversarial loss: 0.432563\n",
      "epoch 43; iter: 0; batch classifier loss: 0.301618; batch adversarial loss: 0.432682\n",
      "epoch 43; iter: 200; batch classifier loss: 0.333064; batch adversarial loss: 0.385765\n",
      "epoch 44; iter: 0; batch classifier loss: 0.280777; batch adversarial loss: 0.426361\n",
      "epoch 44; iter: 200; batch classifier loss: 0.320976; batch adversarial loss: 0.467297\n",
      "epoch 45; iter: 0; batch classifier loss: 0.349707; batch adversarial loss: 0.406013\n",
      "epoch 45; iter: 200; batch classifier loss: 0.353049; batch adversarial loss: 0.419407\n",
      "epoch 46; iter: 0; batch classifier loss: 0.258030; batch adversarial loss: 0.370299\n",
      "epoch 46; iter: 200; batch classifier loss: 0.391881; batch adversarial loss: 0.546822\n",
      "epoch 47; iter: 0; batch classifier loss: 0.318396; batch adversarial loss: 0.317261\n",
      "epoch 47; iter: 200; batch classifier loss: 0.385789; batch adversarial loss: 0.416378\n",
      "epoch 48; iter: 0; batch classifier loss: 0.276051; batch adversarial loss: 0.428104\n",
      "epoch 48; iter: 200; batch classifier loss: 0.309672; batch adversarial loss: 0.386188\n",
      "epoch 49; iter: 0; batch classifier loss: 0.348627; batch adversarial loss: 0.423315\n",
      "epoch 49; iter: 200; batch classifier loss: 0.307322; batch adversarial loss: 0.376616\n",
      "epoch 0; iter: 0; batch classifier loss: 19.294565; batch adversarial loss: 0.815904\n",
      "epoch 0; iter: 200; batch classifier loss: 5.694916; batch adversarial loss: 0.665615\n",
      "epoch 1; iter: 0; batch classifier loss: 7.081156; batch adversarial loss: 0.620888\n",
      "epoch 1; iter: 200; batch classifier loss: 6.079931; batch adversarial loss: 0.560859\n",
      "epoch 2; iter: 0; batch classifier loss: 2.895304; batch adversarial loss: 0.555993\n",
      "epoch 2; iter: 200; batch classifier loss: 2.387754; batch adversarial loss: 0.528757\n",
      "epoch 3; iter: 0; batch classifier loss: 1.943780; batch adversarial loss: 0.469444\n",
      "epoch 3; iter: 200; batch classifier loss: 0.450352; batch adversarial loss: 0.474008\n",
      "epoch 4; iter: 0; batch classifier loss: 1.529368; batch adversarial loss: 0.444651\n",
      "epoch 4; iter: 200; batch classifier loss: 3.985050; batch adversarial loss: 0.439164\n",
      "epoch 5; iter: 0; batch classifier loss: 3.470367; batch adversarial loss: 0.445709\n",
      "epoch 5; iter: 200; batch classifier loss: 1.974251; batch adversarial loss: 0.406797\n",
      "epoch 6; iter: 0; batch classifier loss: 1.760319; batch adversarial loss: 0.403391\n",
      "epoch 6; iter: 200; batch classifier loss: 1.314559; batch adversarial loss: 0.386517\n",
      "epoch 7; iter: 0; batch classifier loss: 0.571660; batch adversarial loss: 0.397650\n",
      "epoch 7; iter: 200; batch classifier loss: 0.880274; batch adversarial loss: 0.435978\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577675; batch adversarial loss: 0.357128\n",
      "epoch 8; iter: 200; batch classifier loss: 0.428019; batch adversarial loss: 0.474269\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458039; batch adversarial loss: 0.414756\n",
      "epoch 9; iter: 200; batch classifier loss: 0.324543; batch adversarial loss: 0.412682\n",
      "epoch 10; iter: 0; batch classifier loss: 0.423325; batch adversarial loss: 0.483394\n",
      "epoch 10; iter: 200; batch classifier loss: 0.354234; batch adversarial loss: 0.428118\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424782; batch adversarial loss: 0.460297\n",
      "epoch 11; iter: 200; batch classifier loss: 0.468233; batch adversarial loss: 0.436614\n",
      "epoch 12; iter: 0; batch classifier loss: 0.426610; batch adversarial loss: 0.407484\n",
      "epoch 12; iter: 200; batch classifier loss: 0.382530; batch adversarial loss: 0.406545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412133; batch adversarial loss: 0.534925\n",
      "epoch 13; iter: 200; batch classifier loss: 0.385415; batch adversarial loss: 0.398141\n",
      "epoch 14; iter: 0; batch classifier loss: 0.378018; batch adversarial loss: 0.438198\n",
      "epoch 14; iter: 200; batch classifier loss: 0.411739; batch adversarial loss: 0.400055\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375443; batch adversarial loss: 0.393245\n",
      "epoch 15; iter: 200; batch classifier loss: 0.308131; batch adversarial loss: 0.451967\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346706; batch adversarial loss: 0.395913\n",
      "epoch 16; iter: 200; batch classifier loss: 0.423725; batch adversarial loss: 0.487717\n",
      "epoch 17; iter: 0; batch classifier loss: 0.325076; batch adversarial loss: 0.465359\n",
      "epoch 17; iter: 200; batch classifier loss: 0.359843; batch adversarial loss: 0.347779\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295609; batch adversarial loss: 0.355776\n",
      "epoch 18; iter: 200; batch classifier loss: 0.335704; batch adversarial loss: 0.421558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340498; batch adversarial loss: 0.386234\n",
      "epoch 19; iter: 200; batch classifier loss: 0.443137; batch adversarial loss: 0.381928\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432570; batch adversarial loss: 0.385496\n",
      "epoch 20; iter: 200; batch classifier loss: 0.328942; batch adversarial loss: 0.298686\n",
      "epoch 21; iter: 0; batch classifier loss: 0.322238; batch adversarial loss: 0.389769\n",
      "epoch 21; iter: 200; batch classifier loss: 0.276693; batch adversarial loss: 0.451448\n",
      "epoch 22; iter: 0; batch classifier loss: 0.366875; batch adversarial loss: 0.390759\n",
      "epoch 22; iter: 200; batch classifier loss: 0.419148; batch adversarial loss: 0.440696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378891; batch adversarial loss: 0.422802\n",
      "epoch 23; iter: 200; batch classifier loss: 0.280085; batch adversarial loss: 0.414684\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405327; batch adversarial loss: 0.432897\n",
      "epoch 24; iter: 200; batch classifier loss: 0.293506; batch adversarial loss: 0.459775\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321676; batch adversarial loss: 0.440718\n",
      "epoch 25; iter: 200; batch classifier loss: 0.313847; batch adversarial loss: 0.360011\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363571; batch adversarial loss: 0.310039\n",
      "epoch 26; iter: 200; batch classifier loss: 0.311425; batch adversarial loss: 0.365992\n",
      "epoch 27; iter: 0; batch classifier loss: 0.281987; batch adversarial loss: 0.529938\n",
      "epoch 27; iter: 200; batch classifier loss: 0.338285; batch adversarial loss: 0.479099\n",
      "epoch 28; iter: 0; batch classifier loss: 0.327960; batch adversarial loss: 0.324449\n",
      "epoch 28; iter: 200; batch classifier loss: 0.377972; batch adversarial loss: 0.376760\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451205; batch adversarial loss: 0.421514\n",
      "epoch 29; iter: 200; batch classifier loss: 0.317199; batch adversarial loss: 0.388141\n",
      "epoch 30; iter: 0; batch classifier loss: 0.294139; batch adversarial loss: 0.335548\n",
      "epoch 30; iter: 200; batch classifier loss: 0.280783; batch adversarial loss: 0.408611\n",
      "epoch 31; iter: 0; batch classifier loss: 0.279043; batch adversarial loss: 0.523850\n",
      "epoch 31; iter: 200; batch classifier loss: 0.288716; batch adversarial loss: 0.360831\n",
      "epoch 32; iter: 0; batch classifier loss: 0.262560; batch adversarial loss: 0.416091\n",
      "epoch 32; iter: 200; batch classifier loss: 0.392977; batch adversarial loss: 0.349568\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272871; batch adversarial loss: 0.409531\n",
      "epoch 33; iter: 200; batch classifier loss: 0.318976; batch adversarial loss: 0.427356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.269890; batch adversarial loss: 0.365485\n",
      "epoch 34; iter: 200; batch classifier loss: 0.418262; batch adversarial loss: 0.338766\n",
      "epoch 35; iter: 0; batch classifier loss: 0.277986; batch adversarial loss: 0.441200\n",
      "epoch 35; iter: 200; batch classifier loss: 0.337570; batch adversarial loss: 0.351618\n",
      "epoch 36; iter: 0; batch classifier loss: 0.399509; batch adversarial loss: 0.411613\n",
      "epoch 36; iter: 200; batch classifier loss: 0.383872; batch adversarial loss: 0.383028\n",
      "epoch 37; iter: 0; batch classifier loss: 0.307868; batch adversarial loss: 0.428563\n",
      "epoch 37; iter: 200; batch classifier loss: 0.357558; batch adversarial loss: 0.397646\n",
      "epoch 38; iter: 0; batch classifier loss: 0.275158; batch adversarial loss: 0.394207\n",
      "epoch 38; iter: 200; batch classifier loss: 0.365624; batch adversarial loss: 0.350112\n",
      "epoch 39; iter: 0; batch classifier loss: 0.310843; batch adversarial loss: 0.293647\n",
      "epoch 39; iter: 200; batch classifier loss: 0.321938; batch adversarial loss: 0.471993\n",
      "epoch 40; iter: 0; batch classifier loss: 0.333546; batch adversarial loss: 0.451093\n",
      "epoch 40; iter: 200; batch classifier loss: 0.288396; batch adversarial loss: 0.337530\n",
      "epoch 41; iter: 0; batch classifier loss: 0.267568; batch adversarial loss: 0.403285\n",
      "epoch 41; iter: 200; batch classifier loss: 0.309318; batch adversarial loss: 0.331182\n",
      "epoch 42; iter: 0; batch classifier loss: 0.349166; batch adversarial loss: 0.433351\n",
      "epoch 42; iter: 200; batch classifier loss: 0.287978; batch adversarial loss: 0.389828\n",
      "epoch 43; iter: 0; batch classifier loss: 0.229760; batch adversarial loss: 0.434847\n",
      "epoch 43; iter: 200; batch classifier loss: 0.362334; batch adversarial loss: 0.522369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.279039; batch adversarial loss: 0.478397\n",
      "epoch 44; iter: 200; batch classifier loss: 0.296036; batch adversarial loss: 0.543603\n",
      "epoch 45; iter: 0; batch classifier loss: 0.340537; batch adversarial loss: 0.390713\n",
      "epoch 45; iter: 200; batch classifier loss: 0.428830; batch adversarial loss: 0.525104\n",
      "epoch 46; iter: 0; batch classifier loss: 0.337778; batch adversarial loss: 0.403955\n",
      "epoch 46; iter: 200; batch classifier loss: 0.343210; batch adversarial loss: 0.349247\n",
      "epoch 47; iter: 0; batch classifier loss: 0.280081; batch adversarial loss: 0.308307\n",
      "epoch 47; iter: 200; batch classifier loss: 0.378534; batch adversarial loss: 0.420628\n",
      "epoch 48; iter: 0; batch classifier loss: 0.299009; batch adversarial loss: 0.393045\n",
      "epoch 48; iter: 200; batch classifier loss: 0.398532; batch adversarial loss: 0.335956\n",
      "epoch 49; iter: 0; batch classifier loss: 0.323134; batch adversarial loss: 0.406265\n",
      "epoch 49; iter: 200; batch classifier loss: 0.364698; batch adversarial loss: 0.329588\n",
      "epoch 0; iter: 0; batch classifier loss: 16.681665; batch adversarial loss: 0.564819\n",
      "epoch 0; iter: 200; batch classifier loss: 4.523745; batch adversarial loss: 0.562693\n",
      "epoch 1; iter: 0; batch classifier loss: 1.946280; batch adversarial loss: 0.543787\n",
      "epoch 1; iter: 200; batch classifier loss: 2.509612; batch adversarial loss: 0.540856\n",
      "epoch 2; iter: 0; batch classifier loss: 6.268049; batch adversarial loss: 0.522902\n",
      "epoch 2; iter: 200; batch classifier loss: 3.755998; batch adversarial loss: 0.460353\n",
      "epoch 3; iter: 0; batch classifier loss: 4.314814; batch adversarial loss: 0.452793\n",
      "epoch 3; iter: 200; batch classifier loss: 3.186535; batch adversarial loss: 0.454128\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521030; batch adversarial loss: 0.437869\n",
      "epoch 4; iter: 200; batch classifier loss: 3.075431; batch adversarial loss: 0.410838\n",
      "epoch 5; iter: 0; batch classifier loss: 1.628390; batch adversarial loss: 0.413431\n",
      "epoch 5; iter: 200; batch classifier loss: 0.452382; batch adversarial loss: 0.428332\n",
      "epoch 6; iter: 0; batch classifier loss: 0.616493; batch adversarial loss: 0.428896\n",
      "epoch 6; iter: 200; batch classifier loss: 0.569368; batch adversarial loss: 0.445711\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603854; batch adversarial loss: 0.490760\n",
      "epoch 7; iter: 200; batch classifier loss: 0.446288; batch adversarial loss: 0.527163\n",
      "epoch 8; iter: 0; batch classifier loss: 0.374722; batch adversarial loss: 0.390562\n",
      "epoch 8; iter: 200; batch classifier loss: 0.492765; batch adversarial loss: 0.428825\n",
      "epoch 9; iter: 0; batch classifier loss: 0.477153; batch adversarial loss: 0.364767\n",
      "epoch 9; iter: 200; batch classifier loss: 0.334404; batch adversarial loss: 0.400872\n",
      "epoch 10; iter: 0; batch classifier loss: 0.315172; batch adversarial loss: 0.413575\n",
      "epoch 10; iter: 200; batch classifier loss: 0.382872; batch adversarial loss: 0.429285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.677834; batch adversarial loss: 0.450392\n",
      "epoch 11; iter: 200; batch classifier loss: 0.300071; batch adversarial loss: 0.488536\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347460; batch adversarial loss: 0.438234\n",
      "epoch 12; iter: 200; batch classifier loss: 0.435452; batch adversarial loss: 0.416821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.559135; batch adversarial loss: 0.433731\n",
      "epoch 13; iter: 200; batch classifier loss: 0.472047; batch adversarial loss: 0.394216\n",
      "epoch 14; iter: 0; batch classifier loss: 0.284284; batch adversarial loss: 0.364710\n",
      "epoch 14; iter: 200; batch classifier loss: 0.399732; batch adversarial loss: 0.377605\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462654; batch adversarial loss: 0.409634\n",
      "epoch 15; iter: 200; batch classifier loss: 0.394161; batch adversarial loss: 0.490775\n",
      "epoch 16; iter: 0; batch classifier loss: 0.305927; batch adversarial loss: 0.398086\n",
      "epoch 16; iter: 200; batch classifier loss: 0.343946; batch adversarial loss: 0.462278\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382340; batch adversarial loss: 0.381334\n",
      "epoch 17; iter: 200; batch classifier loss: 0.334370; batch adversarial loss: 0.394028\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338443; batch adversarial loss: 0.360999\n",
      "epoch 18; iter: 200; batch classifier loss: 0.344582; batch adversarial loss: 0.354966\n",
      "epoch 19; iter: 0; batch classifier loss: 0.389723; batch adversarial loss: 0.468603\n",
      "epoch 19; iter: 200; batch classifier loss: 0.276751; batch adversarial loss: 0.434783\n",
      "epoch 20; iter: 0; batch classifier loss: 0.367527; batch adversarial loss: 0.349634\n",
      "epoch 20; iter: 200; batch classifier loss: 0.419021; batch adversarial loss: 0.346305\n",
      "epoch 21; iter: 0; batch classifier loss: 0.364764; batch adversarial loss: 0.277805\n",
      "epoch 21; iter: 200; batch classifier loss: 0.417725; batch adversarial loss: 0.498111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.313654; batch adversarial loss: 0.543107\n",
      "epoch 22; iter: 200; batch classifier loss: 0.282965; batch adversarial loss: 0.399895\n",
      "epoch 23; iter: 0; batch classifier loss: 0.322998; batch adversarial loss: 0.366034\n",
      "epoch 23; iter: 200; batch classifier loss: 0.378328; batch adversarial loss: 0.404975\n",
      "epoch 24; iter: 0; batch classifier loss: 0.358005; batch adversarial loss: 0.368152\n",
      "epoch 24; iter: 200; batch classifier loss: 0.324617; batch adversarial loss: 0.463978\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326882; batch adversarial loss: 0.335170\n",
      "epoch 25; iter: 200; batch classifier loss: 0.390601; batch adversarial loss: 0.400051\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340852; batch adversarial loss: 0.446103\n",
      "epoch 26; iter: 200; batch classifier loss: 0.303285; batch adversarial loss: 0.398660\n",
      "epoch 27; iter: 0; batch classifier loss: 0.345141; batch adversarial loss: 0.464047\n",
      "epoch 27; iter: 200; batch classifier loss: 0.307432; batch adversarial loss: 0.430135\n",
      "epoch 28; iter: 0; batch classifier loss: 0.333020; batch adversarial loss: 0.504593\n",
      "epoch 28; iter: 200; batch classifier loss: 0.352143; batch adversarial loss: 0.417689\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323076; batch adversarial loss: 0.368852\n",
      "epoch 29; iter: 200; batch classifier loss: 0.300564; batch adversarial loss: 0.418181\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342827; batch adversarial loss: 0.494729\n",
      "epoch 30; iter: 200; batch classifier loss: 0.371717; batch adversarial loss: 0.469980\n",
      "epoch 31; iter: 0; batch classifier loss: 0.252962; batch adversarial loss: 0.403613\n",
      "epoch 31; iter: 200; batch classifier loss: 0.281602; batch adversarial loss: 0.441141\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309867; batch adversarial loss: 0.273080\n",
      "epoch 32; iter: 200; batch classifier loss: 0.233274; batch adversarial loss: 0.417729\n",
      "epoch 33; iter: 0; batch classifier loss: 0.352191; batch adversarial loss: 0.465993\n",
      "epoch 33; iter: 200; batch classifier loss: 0.282303; batch adversarial loss: 0.361863\n",
      "epoch 34; iter: 0; batch classifier loss: 0.372884; batch adversarial loss: 0.347207\n",
      "epoch 34; iter: 200; batch classifier loss: 0.382723; batch adversarial loss: 0.471855\n",
      "epoch 35; iter: 0; batch classifier loss: 0.367944; batch adversarial loss: 0.273494\n",
      "epoch 35; iter: 200; batch classifier loss: 0.247148; batch adversarial loss: 0.350855\n",
      "epoch 36; iter: 0; batch classifier loss: 0.288378; batch adversarial loss: 0.408882\n",
      "epoch 36; iter: 200; batch classifier loss: 0.318797; batch adversarial loss: 0.425703\n",
      "epoch 37; iter: 0; batch classifier loss: 0.341987; batch adversarial loss: 0.475830\n",
      "epoch 37; iter: 200; batch classifier loss: 0.381245; batch adversarial loss: 0.370193\n",
      "epoch 38; iter: 0; batch classifier loss: 0.342639; batch adversarial loss: 0.417386\n",
      "epoch 38; iter: 200; batch classifier loss: 0.381052; batch adversarial loss: 0.417247\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322817; batch adversarial loss: 0.418792\n",
      "epoch 39; iter: 200; batch classifier loss: 0.285702; batch adversarial loss: 0.420899\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409054; batch adversarial loss: 0.373958\n",
      "epoch 40; iter: 200; batch classifier loss: 0.252234; batch adversarial loss: 0.445584\n",
      "epoch 41; iter: 0; batch classifier loss: 0.300207; batch adversarial loss: 0.427293\n",
      "epoch 41; iter: 200; batch classifier loss: 0.342983; batch adversarial loss: 0.332396\n",
      "epoch 42; iter: 0; batch classifier loss: 0.370155; batch adversarial loss: 0.367418\n",
      "epoch 42; iter: 200; batch classifier loss: 0.348003; batch adversarial loss: 0.449039\n",
      "epoch 43; iter: 0; batch classifier loss: 0.451269; batch adversarial loss: 0.500585\n",
      "epoch 43; iter: 200; batch classifier loss: 0.323967; batch adversarial loss: 0.423763\n",
      "epoch 44; iter: 0; batch classifier loss: 0.226563; batch adversarial loss: 0.412784\n",
      "epoch 44; iter: 200; batch classifier loss: 0.316982; batch adversarial loss: 0.495901\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364246; batch adversarial loss: 0.444064\n",
      "epoch 45; iter: 200; batch classifier loss: 0.461358; batch adversarial loss: 0.445028\n",
      "epoch 46; iter: 0; batch classifier loss: 0.432311; batch adversarial loss: 0.429146\n",
      "epoch 46; iter: 200; batch classifier loss: 0.470904; batch adversarial loss: 0.470849\n",
      "epoch 47; iter: 0; batch classifier loss: 0.352513; batch adversarial loss: 0.396457\n",
      "epoch 47; iter: 200; batch classifier loss: 0.412430; batch adversarial loss: 0.479094\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460003; batch adversarial loss: 0.385857\n",
      "epoch 48; iter: 200; batch classifier loss: 0.455169; batch adversarial loss: 0.455048\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448179; batch adversarial loss: 0.307568\n",
      "epoch 49; iter: 200; batch classifier loss: 0.553724; batch adversarial loss: 0.428541\n",
      "epoch 0; iter: 0; batch classifier loss: 18.145308; batch adversarial loss: 0.532116\n",
      "epoch 0; iter: 200; batch classifier loss: 13.453585; batch adversarial loss: 0.564039\n",
      "epoch 1; iter: 0; batch classifier loss: 4.314494; batch adversarial loss: 0.498640\n",
      "epoch 1; iter: 200; batch classifier loss: 2.812922; batch adversarial loss: 0.486893\n",
      "epoch 2; iter: 0; batch classifier loss: 4.858788; batch adversarial loss: 0.495963\n",
      "epoch 2; iter: 200; batch classifier loss: 0.457051; batch adversarial loss: 0.474702\n",
      "epoch 3; iter: 0; batch classifier loss: 1.831919; batch adversarial loss: 0.478550\n",
      "epoch 3; iter: 200; batch classifier loss: 4.088108; batch adversarial loss: 0.428184\n",
      "epoch 4; iter: 0; batch classifier loss: 5.142939; batch adversarial loss: 0.409876\n",
      "epoch 4; iter: 200; batch classifier loss: 0.619732; batch adversarial loss: 0.452075\n",
      "epoch 5; iter: 0; batch classifier loss: 1.488478; batch adversarial loss: 0.428310\n",
      "epoch 5; iter: 200; batch classifier loss: 0.765924; batch adversarial loss: 0.401328\n",
      "epoch 6; iter: 0; batch classifier loss: 2.034904; batch adversarial loss: 0.466371\n",
      "epoch 6; iter: 200; batch classifier loss: 1.247495; batch adversarial loss: 0.439628\n",
      "epoch 7; iter: 0; batch classifier loss: 0.717948; batch adversarial loss: 0.505549\n",
      "epoch 7; iter: 200; batch classifier loss: 1.016316; batch adversarial loss: 0.409583\n",
      "epoch 8; iter: 0; batch classifier loss: 0.740000; batch adversarial loss: 0.465003\n",
      "epoch 8; iter: 200; batch classifier loss: 0.539859; batch adversarial loss: 0.374531\n",
      "epoch 9; iter: 0; batch classifier loss: 0.583780; batch adversarial loss: 0.424487\n",
      "epoch 9; iter: 200; batch classifier loss: 0.695232; batch adversarial loss: 0.392162\n",
      "epoch 10; iter: 0; batch classifier loss: 0.502202; batch adversarial loss: 0.455628\n",
      "epoch 10; iter: 200; batch classifier loss: 0.486384; batch adversarial loss: 0.550420\n",
      "epoch 11; iter: 0; batch classifier loss: 0.432830; batch adversarial loss: 0.432389\n",
      "epoch 11; iter: 200; batch classifier loss: 0.403995; batch adversarial loss: 0.493642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350239; batch adversarial loss: 0.435093\n",
      "epoch 12; iter: 200; batch classifier loss: 0.356719; batch adversarial loss: 0.407543\n",
      "epoch 13; iter: 0; batch classifier loss: 0.360925; batch adversarial loss: 0.327688\n",
      "epoch 13; iter: 200; batch classifier loss: 0.385610; batch adversarial loss: 0.407037\n",
      "epoch 14; iter: 0; batch classifier loss: 0.416323; batch adversarial loss: 0.403685\n",
      "epoch 14; iter: 200; batch classifier loss: 0.408425; batch adversarial loss: 0.398728\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475346; batch adversarial loss: 0.288003\n",
      "epoch 15; iter: 200; batch classifier loss: 0.318081; batch adversarial loss: 0.482282\n",
      "epoch 16; iter: 0; batch classifier loss: 0.428116; batch adversarial loss: 0.406459\n",
      "epoch 16; iter: 200; batch classifier loss: 0.329278; batch adversarial loss: 0.481529\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426639; batch adversarial loss: 0.397205\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341232; batch adversarial loss: 0.330875\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322300; batch adversarial loss: 0.472029\n",
      "epoch 18; iter: 200; batch classifier loss: 0.314461; batch adversarial loss: 0.386186\n",
      "epoch 19; iter: 0; batch classifier loss: 0.363231; batch adversarial loss: 0.421584\n",
      "epoch 19; iter: 200; batch classifier loss: 0.291216; batch adversarial loss: 0.391097\n",
      "epoch 20; iter: 0; batch classifier loss: 0.461118; batch adversarial loss: 0.368787\n",
      "epoch 20; iter: 200; batch classifier loss: 0.358865; batch adversarial loss: 0.352579\n",
      "epoch 21; iter: 0; batch classifier loss: 0.380006; batch adversarial loss: 0.439167\n",
      "epoch 21; iter: 200; batch classifier loss: 0.387729; batch adversarial loss: 0.435167\n",
      "epoch 22; iter: 0; batch classifier loss: 0.276028; batch adversarial loss: 0.403845\n",
      "epoch 22; iter: 200; batch classifier loss: 0.398900; batch adversarial loss: 0.371053\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422899; batch adversarial loss: 0.434586\n",
      "epoch 23; iter: 200; batch classifier loss: 0.328026; batch adversarial loss: 0.411525\n",
      "epoch 24; iter: 0; batch classifier loss: 0.441236; batch adversarial loss: 0.371253\n",
      "epoch 24; iter: 200; batch classifier loss: 0.433074; batch adversarial loss: 0.497800\n",
      "epoch 25; iter: 0; batch classifier loss: 0.392947; batch adversarial loss: 0.375766\n",
      "epoch 25; iter: 200; batch classifier loss: 0.369755; batch adversarial loss: 0.368121\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393158; batch adversarial loss: 0.432004\n",
      "epoch 26; iter: 200; batch classifier loss: 0.358745; batch adversarial loss: 0.454133\n",
      "epoch 27; iter: 0; batch classifier loss: 0.357020; batch adversarial loss: 0.397222\n",
      "epoch 27; iter: 200; batch classifier loss: 0.340320; batch adversarial loss: 0.441795\n",
      "epoch 28; iter: 0; batch classifier loss: 0.371041; batch adversarial loss: 0.367729\n",
      "epoch 28; iter: 200; batch classifier loss: 0.307471; batch adversarial loss: 0.489097\n",
      "epoch 29; iter: 0; batch classifier loss: 0.267327; batch adversarial loss: 0.401278\n",
      "epoch 29; iter: 200; batch classifier loss: 0.331800; batch adversarial loss: 0.370136\n",
      "epoch 30; iter: 0; batch classifier loss: 0.350327; batch adversarial loss: 0.485536\n",
      "epoch 30; iter: 200; batch classifier loss: 0.378162; batch adversarial loss: 0.399179\n",
      "epoch 31; iter: 0; batch classifier loss: 0.313421; batch adversarial loss: 0.411470\n",
      "epoch 31; iter: 200; batch classifier loss: 0.312789; batch adversarial loss: 0.460029\n",
      "epoch 32; iter: 0; batch classifier loss: 0.337389; batch adversarial loss: 0.476979\n",
      "epoch 32; iter: 200; batch classifier loss: 0.388346; batch adversarial loss: 0.396943\n",
      "epoch 33; iter: 0; batch classifier loss: 0.369576; batch adversarial loss: 0.312501\n",
      "epoch 33; iter: 200; batch classifier loss: 0.296286; batch adversarial loss: 0.374541\n",
      "epoch 34; iter: 0; batch classifier loss: 0.355112; batch adversarial loss: 0.467474\n",
      "epoch 34; iter: 200; batch classifier loss: 0.337402; batch adversarial loss: 0.472797\n",
      "epoch 35; iter: 0; batch classifier loss: 0.356145; batch adversarial loss: 0.378706\n",
      "epoch 35; iter: 200; batch classifier loss: 0.295773; batch adversarial loss: 0.370544\n",
      "epoch 36; iter: 0; batch classifier loss: 0.253785; batch adversarial loss: 0.376161\n",
      "epoch 36; iter: 200; batch classifier loss: 0.280945; batch adversarial loss: 0.350854\n",
      "epoch 37; iter: 0; batch classifier loss: 0.364416; batch adversarial loss: 0.350070\n",
      "epoch 37; iter: 200; batch classifier loss: 0.302608; batch adversarial loss: 0.424328\n",
      "epoch 38; iter: 0; batch classifier loss: 0.393740; batch adversarial loss: 0.361395\n",
      "epoch 38; iter: 200; batch classifier loss: 0.312574; batch adversarial loss: 0.361470\n",
      "epoch 39; iter: 0; batch classifier loss: 0.305763; batch adversarial loss: 0.336129\n",
      "epoch 39; iter: 200; batch classifier loss: 0.359364; batch adversarial loss: 0.412259\n",
      "epoch 40; iter: 0; batch classifier loss: 0.350206; batch adversarial loss: 0.465171\n",
      "epoch 40; iter: 200; batch classifier loss: 0.312776; batch adversarial loss: 0.467239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.394150; batch adversarial loss: 0.445440\n",
      "epoch 41; iter: 200; batch classifier loss: 0.371925; batch adversarial loss: 0.433804\n",
      "epoch 42; iter: 0; batch classifier loss: 0.258157; batch adversarial loss: 0.387265\n",
      "epoch 42; iter: 200; batch classifier loss: 0.329155; batch adversarial loss: 0.375471\n",
      "epoch 43; iter: 0; batch classifier loss: 0.319944; batch adversarial loss: 0.363163\n",
      "epoch 43; iter: 200; batch classifier loss: 0.524583; batch adversarial loss: 0.386245\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390862; batch adversarial loss: 0.365127\n",
      "epoch 44; iter: 200; batch classifier loss: 0.336955; batch adversarial loss: 0.349249\n",
      "epoch 45; iter: 0; batch classifier loss: 0.315870; batch adversarial loss: 0.385382\n",
      "epoch 45; iter: 200; batch classifier loss: 0.408382; batch adversarial loss: 0.334686\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377339; batch adversarial loss: 0.484600\n",
      "epoch 46; iter: 200; batch classifier loss: 0.418389; batch adversarial loss: 0.367307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.299732; batch adversarial loss: 0.417870\n",
      "epoch 47; iter: 200; batch classifier loss: 0.339427; batch adversarial loss: 0.426895\n",
      "epoch 48; iter: 0; batch classifier loss: 0.378861; batch adversarial loss: 0.347926\n",
      "epoch 48; iter: 200; batch classifier loss: 0.371027; batch adversarial loss: 0.452897\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384530; batch adversarial loss: 0.446362\n",
      "epoch 49; iter: 200; batch classifier loss: 0.265526; batch adversarial loss: 0.383925\n",
      "epoch 0; iter: 0; batch classifier loss: 23.632118; batch adversarial loss: 0.763276\n",
      "epoch 0; iter: 200; batch classifier loss: 2.314035; batch adversarial loss: 0.645415\n",
      "epoch 1; iter: 0; batch classifier loss: 10.942791; batch adversarial loss: 0.599199\n",
      "epoch 1; iter: 200; batch classifier loss: 8.853747; batch adversarial loss: 0.532650\n",
      "epoch 2; iter: 0; batch classifier loss: 5.274113; batch adversarial loss: 0.498985\n",
      "epoch 2; iter: 200; batch classifier loss: 5.520225; batch adversarial loss: 0.482859\n",
      "epoch 3; iter: 0; batch classifier loss: 4.375640; batch adversarial loss: 0.441101\n",
      "epoch 3; iter: 200; batch classifier loss: 2.667228; batch adversarial loss: 0.463448\n",
      "epoch 4; iter: 0; batch classifier loss: 2.555748; batch adversarial loss: 0.418481\n",
      "epoch 4; iter: 200; batch classifier loss: 0.703574; batch adversarial loss: 0.511921\n",
      "epoch 5; iter: 0; batch classifier loss: 0.827621; batch adversarial loss: 0.413107\n",
      "epoch 5; iter: 200; batch classifier loss: 0.659836; batch adversarial loss: 0.444084\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577952; batch adversarial loss: 0.445590\n",
      "epoch 6; iter: 200; batch classifier loss: 0.586545; batch adversarial loss: 0.370476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517572; batch adversarial loss: 0.473510\n",
      "epoch 7; iter: 200; batch classifier loss: 0.624158; batch adversarial loss: 0.381572\n",
      "epoch 8; iter: 0; batch classifier loss: 0.471744; batch adversarial loss: 0.403343\n",
      "epoch 8; iter: 200; batch classifier loss: 0.500135; batch adversarial loss: 0.356679\n",
      "epoch 9; iter: 0; batch classifier loss: 1.194960; batch adversarial loss: 0.358576\n",
      "epoch 9; iter: 200; batch classifier loss: 0.372061; batch adversarial loss: 0.405197\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388839; batch adversarial loss: 0.401584\n",
      "epoch 10; iter: 200; batch classifier loss: 0.513184; batch adversarial loss: 0.404541\n",
      "epoch 11; iter: 0; batch classifier loss: 0.431499; batch adversarial loss: 0.457662\n",
      "epoch 11; iter: 200; batch classifier loss: 0.436129; batch adversarial loss: 0.424695\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502742; batch adversarial loss: 0.384863\n",
      "epoch 12; iter: 200; batch classifier loss: 0.379511; batch adversarial loss: 0.351789\n",
      "epoch 13; iter: 0; batch classifier loss: 0.444611; batch adversarial loss: 0.386543\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396437; batch adversarial loss: 0.455418\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369700; batch adversarial loss: 0.441032\n",
      "epoch 14; iter: 200; batch classifier loss: 0.374107; batch adversarial loss: 0.373463\n",
      "epoch 15; iter: 0; batch classifier loss: 0.305054; batch adversarial loss: 0.467247\n",
      "epoch 15; iter: 200; batch classifier loss: 0.368204; batch adversarial loss: 0.405796\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324049; batch adversarial loss: 0.358849\n",
      "epoch 16; iter: 200; batch classifier loss: 0.407850; batch adversarial loss: 0.397092\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319357; batch adversarial loss: 0.432365\n",
      "epoch 17; iter: 200; batch classifier loss: 0.405648; batch adversarial loss: 0.316664\n",
      "epoch 18; iter: 0; batch classifier loss: 0.327554; batch adversarial loss: 0.416949\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382415; batch adversarial loss: 0.494986\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343291; batch adversarial loss: 0.426385\n",
      "epoch 19; iter: 200; batch classifier loss: 0.256294; batch adversarial loss: 0.449761\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342283; batch adversarial loss: 0.349989\n",
      "epoch 20; iter: 200; batch classifier loss: 0.375611; batch adversarial loss: 0.428846\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308694; batch adversarial loss: 0.435515\n",
      "epoch 21; iter: 200; batch classifier loss: 0.310317; batch adversarial loss: 0.453767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361167; batch adversarial loss: 0.447926\n",
      "epoch 22; iter: 200; batch classifier loss: 0.352148; batch adversarial loss: 0.379613\n",
      "epoch 23; iter: 0; batch classifier loss: 0.293067; batch adversarial loss: 0.332101\n",
      "epoch 23; iter: 200; batch classifier loss: 0.325099; batch adversarial loss: 0.445859\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343180; batch adversarial loss: 0.413652\n",
      "epoch 24; iter: 200; batch classifier loss: 0.425787; batch adversarial loss: 0.387864\n",
      "epoch 25; iter: 0; batch classifier loss: 0.286828; batch adversarial loss: 0.412826\n",
      "epoch 25; iter: 200; batch classifier loss: 0.268074; batch adversarial loss: 0.508164\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387152; batch adversarial loss: 0.429849\n",
      "epoch 26; iter: 200; batch classifier loss: 0.313303; batch adversarial loss: 0.429698\n",
      "epoch 27; iter: 0; batch classifier loss: 0.305411; batch adversarial loss: 0.359740\n",
      "epoch 27; iter: 200; batch classifier loss: 0.260655; batch adversarial loss: 0.346461\n",
      "epoch 28; iter: 0; batch classifier loss: 0.310318; batch adversarial loss: 0.441374\n",
      "epoch 28; iter: 200; batch classifier loss: 0.298598; batch adversarial loss: 0.350546\n",
      "epoch 29; iter: 0; batch classifier loss: 0.362279; batch adversarial loss: 0.442999\n",
      "epoch 29; iter: 200; batch classifier loss: 0.301367; batch adversarial loss: 0.491448\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283115; batch adversarial loss: 0.433086\n",
      "epoch 30; iter: 200; batch classifier loss: 0.372993; batch adversarial loss: 0.448820\n",
      "epoch 31; iter: 0; batch classifier loss: 0.255997; batch adversarial loss: 0.412330\n",
      "epoch 31; iter: 200; batch classifier loss: 0.282783; batch adversarial loss: 0.407913\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329482; batch adversarial loss: 0.381308\n",
      "epoch 32; iter: 200; batch classifier loss: 0.360192; batch adversarial loss: 0.419778\n",
      "epoch 33; iter: 0; batch classifier loss: 0.280036; batch adversarial loss: 0.365566\n",
      "epoch 33; iter: 200; batch classifier loss: 0.337851; batch adversarial loss: 0.327965\n",
      "epoch 34; iter: 0; batch classifier loss: 0.403278; batch adversarial loss: 0.407012\n",
      "epoch 34; iter: 200; batch classifier loss: 0.272741; batch adversarial loss: 0.381778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.312579; batch adversarial loss: 0.424947\n",
      "epoch 35; iter: 200; batch classifier loss: 0.314731; batch adversarial loss: 0.408462\n",
      "epoch 36; iter: 0; batch classifier loss: 0.321034; batch adversarial loss: 0.421817\n",
      "epoch 36; iter: 200; batch classifier loss: 0.319380; batch adversarial loss: 0.432175\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415825; batch adversarial loss: 0.451235\n",
      "epoch 37; iter: 200; batch classifier loss: 0.387197; batch adversarial loss: 0.467115\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461653; batch adversarial loss: 0.348357\n",
      "epoch 38; iter: 200; batch classifier loss: 0.333395; batch adversarial loss: 0.366057\n",
      "epoch 39; iter: 0; batch classifier loss: 0.321028; batch adversarial loss: 0.422943\n",
      "epoch 39; iter: 200; batch classifier loss: 0.429412; batch adversarial loss: 0.388179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.350503; batch adversarial loss: 0.319995\n",
      "epoch 40; iter: 200; batch classifier loss: 0.360966; batch adversarial loss: 0.381710\n",
      "epoch 41; iter: 0; batch classifier loss: 0.336599; batch adversarial loss: 0.462836\n",
      "epoch 41; iter: 200; batch classifier loss: 0.341917; batch adversarial loss: 0.401466\n",
      "epoch 42; iter: 0; batch classifier loss: 0.259631; batch adversarial loss: 0.428198\n",
      "epoch 42; iter: 200; batch classifier loss: 0.435289; batch adversarial loss: 0.378844\n",
      "epoch 43; iter: 0; batch classifier loss: 0.356838; batch adversarial loss: 0.447102\n",
      "epoch 43; iter: 200; batch classifier loss: 0.288119; batch adversarial loss: 0.324766\n",
      "epoch 44; iter: 0; batch classifier loss: 0.280321; batch adversarial loss: 0.354539\n",
      "epoch 44; iter: 200; batch classifier loss: 0.353282; batch adversarial loss: 0.401087\n",
      "epoch 45; iter: 0; batch classifier loss: 0.327793; batch adversarial loss: 0.392683\n",
      "epoch 45; iter: 200; batch classifier loss: 0.380545; batch adversarial loss: 0.454944\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466189; batch adversarial loss: 0.462338\n",
      "epoch 46; iter: 200; batch classifier loss: 0.393292; batch adversarial loss: 0.460751\n",
      "epoch 47; iter: 0; batch classifier loss: 0.445099; batch adversarial loss: 0.399943\n",
      "epoch 47; iter: 200; batch classifier loss: 0.342987; batch adversarial loss: 0.376487\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399512; batch adversarial loss: 0.417136\n",
      "epoch 48; iter: 200; batch classifier loss: 0.321597; batch adversarial loss: 0.434669\n",
      "epoch 49; iter: 0; batch classifier loss: 0.331014; batch adversarial loss: 0.321092\n",
      "epoch 49; iter: 200; batch classifier loss: 0.332785; batch adversarial loss: 0.316653\n",
      "epoch 0; iter: 0; batch classifier loss: 52.912117; batch adversarial loss: 0.804803\n",
      "epoch 0; iter: 200; batch classifier loss: 7.253207; batch adversarial loss: 0.682209\n",
      "epoch 1; iter: 0; batch classifier loss: 6.149341; batch adversarial loss: 0.622625\n",
      "epoch 1; iter: 200; batch classifier loss: 4.996918; batch adversarial loss: 0.565787\n",
      "epoch 2; iter: 0; batch classifier loss: 2.017207; batch adversarial loss: 0.527820\n",
      "epoch 2; iter: 200; batch classifier loss: 17.267174; batch adversarial loss: 0.521976\n",
      "epoch 3; iter: 0; batch classifier loss: 3.909686; batch adversarial loss: 0.437183\n",
      "epoch 3; iter: 200; batch classifier loss: 3.626819; batch adversarial loss: 0.447168\n",
      "epoch 4; iter: 0; batch classifier loss: 2.374627; batch adversarial loss: 0.462314\n",
      "epoch 4; iter: 200; batch classifier loss: 5.053009; batch adversarial loss: 0.427875\n",
      "epoch 5; iter: 0; batch classifier loss: 0.395705; batch adversarial loss: 0.485355\n",
      "epoch 5; iter: 200; batch classifier loss: 0.736037; batch adversarial loss: 0.427551\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639232; batch adversarial loss: 0.447565\n",
      "epoch 6; iter: 200; batch classifier loss: 0.569120; batch adversarial loss: 0.454028\n",
      "epoch 7; iter: 0; batch classifier loss: 0.877948; batch adversarial loss: 0.362331\n",
      "epoch 7; iter: 200; batch classifier loss: 0.542866; batch adversarial loss: 0.385526\n",
      "epoch 8; iter: 0; batch classifier loss: 0.673819; batch adversarial loss: 0.416111\n",
      "epoch 8; iter: 200; batch classifier loss: 0.641094; batch adversarial loss: 0.510706\n",
      "epoch 9; iter: 0; batch classifier loss: 0.962253; batch adversarial loss: 0.451388\n",
      "epoch 9; iter: 200; batch classifier loss: 0.488239; batch adversarial loss: 0.393771\n",
      "epoch 10; iter: 0; batch classifier loss: 0.433406; batch adversarial loss: 0.412593\n",
      "epoch 10; iter: 200; batch classifier loss: 0.426645; batch adversarial loss: 0.423828\n",
      "epoch 11; iter: 0; batch classifier loss: 0.686503; batch adversarial loss: 0.335591\n",
      "epoch 11; iter: 200; batch classifier loss: 0.491649; batch adversarial loss: 0.366746\n",
      "epoch 12; iter: 0; batch classifier loss: 0.617435; batch adversarial loss: 0.408667\n",
      "epoch 12; iter: 200; batch classifier loss: 0.573554; batch adversarial loss: 0.498379\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488494; batch adversarial loss: 0.347154\n",
      "epoch 13; iter: 200; batch classifier loss: 0.468121; batch adversarial loss: 0.381830\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456763; batch adversarial loss: 0.425019\n",
      "epoch 14; iter: 200; batch classifier loss: 0.316332; batch adversarial loss: 0.348419\n",
      "epoch 15; iter: 0; batch classifier loss: 0.356735; batch adversarial loss: 0.563918\n",
      "epoch 15; iter: 200; batch classifier loss: 0.557242; batch adversarial loss: 0.438897\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330861; batch adversarial loss: 0.396465\n",
      "epoch 16; iter: 200; batch classifier loss: 0.464332; batch adversarial loss: 0.435133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.359726; batch adversarial loss: 0.428831\n",
      "epoch 17; iter: 200; batch classifier loss: 0.338481; batch adversarial loss: 0.273731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.448022; batch adversarial loss: 0.373567\n",
      "epoch 18; iter: 200; batch classifier loss: 0.363533; batch adversarial loss: 0.347098\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338508; batch adversarial loss: 0.472313\n",
      "epoch 19; iter: 200; batch classifier loss: 0.601604; batch adversarial loss: 0.382886\n",
      "epoch 20; iter: 0; batch classifier loss: 0.321968; batch adversarial loss: 0.452926\n",
      "epoch 20; iter: 200; batch classifier loss: 0.317620; batch adversarial loss: 0.453899\n",
      "epoch 21; iter: 0; batch classifier loss: 0.394036; batch adversarial loss: 0.378480\n",
      "epoch 21; iter: 200; batch classifier loss: 0.330406; batch adversarial loss: 0.453730\n",
      "epoch 22; iter: 0; batch classifier loss: 0.396628; batch adversarial loss: 0.393484\n",
      "epoch 22; iter: 200; batch classifier loss: 0.335805; batch adversarial loss: 0.373545\n",
      "epoch 23; iter: 0; batch classifier loss: 0.355650; batch adversarial loss: 0.430199\n",
      "epoch 23; iter: 200; batch classifier loss: 0.337200; batch adversarial loss: 0.308450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.337019; batch adversarial loss: 0.454763\n",
      "epoch 24; iter: 200; batch classifier loss: 0.316387; batch adversarial loss: 0.379760\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321151; batch adversarial loss: 0.335828\n",
      "epoch 25; iter: 200; batch classifier loss: 0.383243; batch adversarial loss: 0.340078\n",
      "epoch 26; iter: 0; batch classifier loss: 0.381256; batch adversarial loss: 0.383471\n",
      "epoch 26; iter: 200; batch classifier loss: 0.299560; batch adversarial loss: 0.434519\n",
      "epoch 27; iter: 0; batch classifier loss: 0.371393; batch adversarial loss: 0.383974\n",
      "epoch 27; iter: 200; batch classifier loss: 0.345849; batch adversarial loss: 0.485697\n",
      "epoch 28; iter: 0; batch classifier loss: 0.294195; batch adversarial loss: 0.344546\n",
      "epoch 28; iter: 200; batch classifier loss: 0.295087; batch adversarial loss: 0.388395\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323996; batch adversarial loss: 0.389768\n",
      "epoch 29; iter: 200; batch classifier loss: 0.305247; batch adversarial loss: 0.365067\n",
      "epoch 30; iter: 0; batch classifier loss: 0.328890; batch adversarial loss: 0.441411\n",
      "epoch 30; iter: 200; batch classifier loss: 0.381692; batch adversarial loss: 0.456134\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269510; batch adversarial loss: 0.296281\n",
      "epoch 31; iter: 200; batch classifier loss: 0.395381; batch adversarial loss: 0.408875\n",
      "epoch 32; iter: 0; batch classifier loss: 0.500045; batch adversarial loss: 0.365932\n",
      "epoch 32; iter: 200; batch classifier loss: 0.413479; batch adversarial loss: 0.420313\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446173; batch adversarial loss: 0.410553\n",
      "epoch 33; iter: 200; batch classifier loss: 0.467185; batch adversarial loss: 0.365718\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415433; batch adversarial loss: 0.456613\n",
      "epoch 34; iter: 200; batch classifier loss: 0.338860; batch adversarial loss: 0.365087\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474069; batch adversarial loss: 0.369465\n",
      "epoch 35; iter: 200; batch classifier loss: 0.471928; batch adversarial loss: 0.476316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390310; batch adversarial loss: 0.350569\n",
      "epoch 36; iter: 200; batch classifier loss: 0.493773; batch adversarial loss: 0.353781\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445949; batch adversarial loss: 0.436522\n",
      "epoch 37; iter: 200; batch classifier loss: 0.484751; batch adversarial loss: 0.432705\n",
      "epoch 38; iter: 0; batch classifier loss: 0.389447; batch adversarial loss: 0.448236\n",
      "epoch 38; iter: 200; batch classifier loss: 0.471551; batch adversarial loss: 0.295431\n",
      "epoch 39; iter: 0; batch classifier loss: 0.474162; batch adversarial loss: 0.317610\n",
      "epoch 39; iter: 200; batch classifier loss: 0.382299; batch adversarial loss: 0.461151\n",
      "epoch 40; iter: 0; batch classifier loss: 0.486833; batch adversarial loss: 0.416784\n",
      "epoch 40; iter: 200; batch classifier loss: 0.430118; batch adversarial loss: 0.458904\n",
      "epoch 41; iter: 0; batch classifier loss: 0.322749; batch adversarial loss: 0.375047\n",
      "epoch 41; iter: 200; batch classifier loss: 0.413941; batch adversarial loss: 0.392768\n",
      "epoch 42; iter: 0; batch classifier loss: 0.437495; batch adversarial loss: 0.336653\n",
      "epoch 42; iter: 200; batch classifier loss: 0.430794; batch adversarial loss: 0.430099\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408591; batch adversarial loss: 0.370990\n",
      "epoch 43; iter: 200; batch classifier loss: 0.518306; batch adversarial loss: 0.277232\n",
      "epoch 44; iter: 0; batch classifier loss: 0.534652; batch adversarial loss: 0.375132\n",
      "epoch 44; iter: 200; batch classifier loss: 0.357061; batch adversarial loss: 0.418805\n",
      "epoch 45; iter: 0; batch classifier loss: 0.500032; batch adversarial loss: 0.351663\n",
      "epoch 45; iter: 200; batch classifier loss: 0.391800; batch adversarial loss: 0.467604\n",
      "epoch 46; iter: 0; batch classifier loss: 0.533259; batch adversarial loss: 0.393253\n",
      "epoch 46; iter: 200; batch classifier loss: 0.457777; batch adversarial loss: 0.348733\n",
      "epoch 47; iter: 0; batch classifier loss: 0.321973; batch adversarial loss: 0.422371\n",
      "epoch 47; iter: 200; batch classifier loss: 0.467381; batch adversarial loss: 0.333068\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382706; batch adversarial loss: 0.364318\n",
      "epoch 48; iter: 200; batch classifier loss: 0.559909; batch adversarial loss: 0.429089\n",
      "epoch 49; iter: 0; batch classifier loss: 0.523130; batch adversarial loss: 0.426246\n",
      "epoch 49; iter: 200; batch classifier loss: 0.400449; batch adversarial loss: 0.334648\n",
      "epoch 0; iter: 0; batch classifier loss: 13.002668; batch adversarial loss: 0.630500\n",
      "epoch 0; iter: 200; batch classifier loss: 5.204208; batch adversarial loss: 0.552843\n",
      "epoch 1; iter: 0; batch classifier loss: 8.154302; batch adversarial loss: 0.542724\n",
      "epoch 1; iter: 200; batch classifier loss: 2.679361; batch adversarial loss: 0.493807\n",
      "epoch 2; iter: 0; batch classifier loss: 7.001931; batch adversarial loss: 0.477520\n",
      "epoch 2; iter: 200; batch classifier loss: 2.036721; batch adversarial loss: 0.529871\n",
      "epoch 3; iter: 0; batch classifier loss: 1.968936; batch adversarial loss: 0.465848\n",
      "epoch 3; iter: 200; batch classifier loss: 2.425384; batch adversarial loss: 0.414868\n",
      "epoch 4; iter: 0; batch classifier loss: 1.120909; batch adversarial loss: 0.427931\n",
      "epoch 4; iter: 200; batch classifier loss: 2.376441; batch adversarial loss: 0.470510\n",
      "epoch 5; iter: 0; batch classifier loss: 1.870082; batch adversarial loss: 0.493157\n",
      "epoch 5; iter: 200; batch classifier loss: 0.449846; batch adversarial loss: 0.442794\n",
      "epoch 6; iter: 0; batch classifier loss: 1.005411; batch adversarial loss: 0.336737\n",
      "epoch 6; iter: 200; batch classifier loss: 0.589152; batch adversarial loss: 0.507800\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497658; batch adversarial loss: 0.330347\n",
      "epoch 7; iter: 200; batch classifier loss: 0.880421; batch adversarial loss: 0.462149\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530057; batch adversarial loss: 0.500051\n",
      "epoch 8; iter: 200; batch classifier loss: 0.576897; batch adversarial loss: 0.419188\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371682; batch adversarial loss: 0.394928\n",
      "epoch 9; iter: 200; batch classifier loss: 0.449488; batch adversarial loss: 0.436835\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522177; batch adversarial loss: 0.456771\n",
      "epoch 10; iter: 200; batch classifier loss: 0.339676; batch adversarial loss: 0.402954\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499522; batch adversarial loss: 0.405824\n",
      "epoch 11; iter: 200; batch classifier loss: 0.426376; batch adversarial loss: 0.436311\n",
      "epoch 12; iter: 0; batch classifier loss: 0.324671; batch adversarial loss: 0.460351\n",
      "epoch 12; iter: 200; batch classifier loss: 0.321989; batch adversarial loss: 0.430131\n",
      "epoch 13; iter: 0; batch classifier loss: 0.326224; batch adversarial loss: 0.412688\n",
      "epoch 13; iter: 200; batch classifier loss: 0.447799; batch adversarial loss: 0.408170\n",
      "epoch 14; iter: 0; batch classifier loss: 0.349478; batch adversarial loss: 0.447885\n",
      "epoch 14; iter: 200; batch classifier loss: 0.521694; batch adversarial loss: 0.388925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.397096; batch adversarial loss: 0.417212\n",
      "epoch 15; iter: 200; batch classifier loss: 0.312408; batch adversarial loss: 0.428067\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495658; batch adversarial loss: 0.391716\n",
      "epoch 16; iter: 200; batch classifier loss: 0.396815; batch adversarial loss: 0.369943\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330746; batch adversarial loss: 0.434215\n",
      "epoch 17; iter: 200; batch classifier loss: 0.413821; batch adversarial loss: 0.384005\n",
      "epoch 18; iter: 0; batch classifier loss: 0.324649; batch adversarial loss: 0.433150\n",
      "epoch 18; iter: 200; batch classifier loss: 0.318286; batch adversarial loss: 0.286568\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430470; batch adversarial loss: 0.319380\n",
      "epoch 19; iter: 200; batch classifier loss: 0.439467; batch adversarial loss: 0.392267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.390759; batch adversarial loss: 0.401070\n",
      "epoch 20; iter: 200; batch classifier loss: 0.317604; batch adversarial loss: 0.477656\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336956; batch adversarial loss: 0.539273\n",
      "epoch 21; iter: 200; batch classifier loss: 0.305880; batch adversarial loss: 0.291916\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372520; batch adversarial loss: 0.445495\n",
      "epoch 22; iter: 200; batch classifier loss: 0.330302; batch adversarial loss: 0.411610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.294589; batch adversarial loss: 0.515635\n",
      "epoch 23; iter: 200; batch classifier loss: 0.375163; batch adversarial loss: 0.426421\n",
      "epoch 24; iter: 0; batch classifier loss: 0.350000; batch adversarial loss: 0.407045\n",
      "epoch 24; iter: 200; batch classifier loss: 0.309119; batch adversarial loss: 0.420801\n",
      "epoch 25; iter: 0; batch classifier loss: 0.370141; batch adversarial loss: 0.417148\n",
      "epoch 25; iter: 200; batch classifier loss: 0.287554; batch adversarial loss: 0.431260\n",
      "epoch 26; iter: 0; batch classifier loss: 0.331522; batch adversarial loss: 0.410466\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343978; batch adversarial loss: 0.387419\n",
      "epoch 27; iter: 0; batch classifier loss: 0.323901; batch adversarial loss: 0.413298\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328816; batch adversarial loss: 0.288923\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368929; batch adversarial loss: 0.404527\n",
      "epoch 28; iter: 200; batch classifier loss: 0.334717; batch adversarial loss: 0.326934\n",
      "epoch 29; iter: 0; batch classifier loss: 0.363408; batch adversarial loss: 0.376098\n",
      "epoch 29; iter: 200; batch classifier loss: 0.367076; batch adversarial loss: 0.478056\n",
      "epoch 30; iter: 0; batch classifier loss: 0.386346; batch adversarial loss: 0.501960\n",
      "epoch 30; iter: 200; batch classifier loss: 0.284902; batch adversarial loss: 0.366053\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366614; batch adversarial loss: 0.453242\n",
      "epoch 31; iter: 200; batch classifier loss: 0.301056; batch adversarial loss: 0.484630\n",
      "epoch 32; iter: 0; batch classifier loss: 0.551787; batch adversarial loss: 0.403500\n",
      "epoch 32; iter: 200; batch classifier loss: 0.264636; batch adversarial loss: 0.412939\n",
      "epoch 33; iter: 0; batch classifier loss: 0.352050; batch adversarial loss: 0.406076\n",
      "epoch 33; iter: 200; batch classifier loss: 0.258757; batch adversarial loss: 0.405742\n",
      "epoch 34; iter: 0; batch classifier loss: 0.296044; batch adversarial loss: 0.314839\n",
      "epoch 34; iter: 200; batch classifier loss: 0.336203; batch adversarial loss: 0.414057\n",
      "epoch 35; iter: 0; batch classifier loss: 0.287099; batch adversarial loss: 0.483353\n",
      "epoch 35; iter: 200; batch classifier loss: 0.360255; batch adversarial loss: 0.379001\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366414; batch adversarial loss: 0.389193\n",
      "epoch 36; iter: 200; batch classifier loss: 0.407663; batch adversarial loss: 0.437065\n",
      "epoch 37; iter: 0; batch classifier loss: 0.380539; batch adversarial loss: 0.401739\n",
      "epoch 37; iter: 200; batch classifier loss: 0.310334; batch adversarial loss: 0.441695\n",
      "epoch 38; iter: 0; batch classifier loss: 0.295364; batch adversarial loss: 0.402406\n",
      "epoch 38; iter: 200; batch classifier loss: 0.628815; batch adversarial loss: 0.461667\n",
      "epoch 39; iter: 0; batch classifier loss: 0.507261; batch adversarial loss: 0.412646\n",
      "epoch 39; iter: 200; batch classifier loss: 0.409033; batch adversarial loss: 0.422834\n",
      "epoch 40; iter: 0; batch classifier loss: 0.568849; batch adversarial loss: 0.504155\n",
      "epoch 40; iter: 200; batch classifier loss: 0.427356; batch adversarial loss: 0.436642\n",
      "epoch 41; iter: 0; batch classifier loss: 0.590739; batch adversarial loss: 0.417875\n",
      "epoch 41; iter: 200; batch classifier loss: 0.516528; batch adversarial loss: 0.365933\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405087; batch adversarial loss: 0.419269\n",
      "epoch 42; iter: 200; batch classifier loss: 0.448711; batch adversarial loss: 0.388370\n",
      "epoch 43; iter: 0; batch classifier loss: 0.442089; batch adversarial loss: 0.337145\n",
      "epoch 43; iter: 200; batch classifier loss: 0.471687; batch adversarial loss: 0.444691\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516540; batch adversarial loss: 0.388233\n",
      "epoch 44; iter: 200; batch classifier loss: 0.435731; batch adversarial loss: 0.432955\n",
      "epoch 45; iter: 0; batch classifier loss: 0.311077; batch adversarial loss: 0.425940\n",
      "epoch 45; iter: 200; batch classifier loss: 0.373289; batch adversarial loss: 0.408137\n",
      "epoch 46; iter: 0; batch classifier loss: 0.483755; batch adversarial loss: 0.394523\n",
      "epoch 46; iter: 200; batch classifier loss: 0.528478; batch adversarial loss: 0.392078\n",
      "epoch 47; iter: 0; batch classifier loss: 0.424699; batch adversarial loss: 0.370157\n",
      "epoch 47; iter: 200; batch classifier loss: 0.623941; batch adversarial loss: 0.427860\n",
      "epoch 48; iter: 0; batch classifier loss: 0.515416; batch adversarial loss: 0.438336\n",
      "epoch 48; iter: 200; batch classifier loss: 0.539019; batch adversarial loss: 0.402649\n",
      "epoch 49; iter: 0; batch classifier loss: 0.516729; batch adversarial loss: 0.384070\n",
      "epoch 49; iter: 200; batch classifier loss: 0.564958; batch adversarial loss: 0.333570\n",
      "epoch 0; iter: 0; batch classifier loss: 177.924561; batch adversarial loss: 1.283531\n",
      "epoch 0; iter: 200; batch classifier loss: 13.432287; batch adversarial loss: 1.385324\n",
      "epoch 1; iter: 0; batch classifier loss: 41.496971; batch adversarial loss: 1.108266\n",
      "epoch 1; iter: 200; batch classifier loss: 8.745348; batch adversarial loss: 0.896573\n",
      "epoch 2; iter: 0; batch classifier loss: 4.371096; batch adversarial loss: 0.785572\n",
      "epoch 2; iter: 200; batch classifier loss: 7.284662; batch adversarial loss: 0.696371\n",
      "epoch 3; iter: 0; batch classifier loss: 8.935910; batch adversarial loss: 0.604094\n",
      "epoch 3; iter: 200; batch classifier loss: 3.463892; batch adversarial loss: 0.498795\n",
      "epoch 4; iter: 0; batch classifier loss: 2.551784; batch adversarial loss: 0.461209\n",
      "epoch 4; iter: 200; batch classifier loss: 1.012690; batch adversarial loss: 0.466867\n",
      "epoch 5; iter: 0; batch classifier loss: 3.536125; batch adversarial loss: 0.447055\n",
      "epoch 5; iter: 200; batch classifier loss: 0.876933; batch adversarial loss: 0.426838\n",
      "epoch 6; iter: 0; batch classifier loss: 1.521405; batch adversarial loss: 0.442595\n",
      "epoch 6; iter: 200; batch classifier loss: 0.765022; batch adversarial loss: 0.468436\n",
      "epoch 7; iter: 0; batch classifier loss: 0.827363; batch adversarial loss: 0.409640\n",
      "epoch 7; iter: 200; batch classifier loss: 3.738050; batch adversarial loss: 0.399515\n",
      "epoch 8; iter: 0; batch classifier loss: 0.452144; batch adversarial loss: 0.478004\n",
      "epoch 8; iter: 200; batch classifier loss: 0.687347; batch adversarial loss: 0.419351\n",
      "epoch 9; iter: 0; batch classifier loss: 0.473163; batch adversarial loss: 0.447562\n",
      "epoch 9; iter: 200; batch classifier loss: 0.716200; batch adversarial loss: 0.371135\n",
      "epoch 10; iter: 0; batch classifier loss: 0.778709; batch adversarial loss: 0.391781\n",
      "epoch 10; iter: 200; batch classifier loss: 0.343721; batch adversarial loss: 0.438147\n",
      "epoch 11; iter: 0; batch classifier loss: 0.748742; batch adversarial loss: 0.406143\n",
      "epoch 11; iter: 200; batch classifier loss: 0.464879; batch adversarial loss: 0.436117\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560025; batch adversarial loss: 0.514692\n",
      "epoch 12; iter: 200; batch classifier loss: 0.454467; batch adversarial loss: 0.396979\n",
      "epoch 13; iter: 0; batch classifier loss: 0.393255; batch adversarial loss: 0.438649\n",
      "epoch 13; iter: 200; batch classifier loss: 0.529428; batch adversarial loss: 0.406091\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470018; batch adversarial loss: 0.449172\n",
      "epoch 14; iter: 200; batch classifier loss: 0.393704; batch adversarial loss: 0.374855\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458069; batch adversarial loss: 0.376663\n",
      "epoch 15; iter: 200; batch classifier loss: 0.486117; batch adversarial loss: 0.460369\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378630; batch adversarial loss: 0.435883\n",
      "epoch 16; iter: 200; batch classifier loss: 0.439690; batch adversarial loss: 0.350424\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404299; batch adversarial loss: 0.448361\n",
      "epoch 17; iter: 200; batch classifier loss: 0.396052; batch adversarial loss: 0.377692\n",
      "epoch 18; iter: 0; batch classifier loss: 0.344655; batch adversarial loss: 0.352292\n",
      "epoch 18; iter: 200; batch classifier loss: 0.458843; batch adversarial loss: 0.321913\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396192; batch adversarial loss: 0.372784\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316221; batch adversarial loss: 0.459085\n",
      "epoch 20; iter: 0; batch classifier loss: 0.312334; batch adversarial loss: 0.362963\n",
      "epoch 20; iter: 200; batch classifier loss: 0.414645; batch adversarial loss: 0.437224\n",
      "epoch 21; iter: 0; batch classifier loss: 0.363246; batch adversarial loss: 0.427672\n",
      "epoch 21; iter: 200; batch classifier loss: 0.419393; batch adversarial loss: 0.404808\n",
      "epoch 22; iter: 0; batch classifier loss: 0.310703; batch adversarial loss: 0.371649\n",
      "epoch 22; iter: 200; batch classifier loss: 0.364736; batch adversarial loss: 0.444923\n",
      "epoch 23; iter: 0; batch classifier loss: 0.403284; batch adversarial loss: 0.363332\n",
      "epoch 23; iter: 200; batch classifier loss: 0.285133; batch adversarial loss: 0.384425\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468759; batch adversarial loss: 0.384507\n",
      "epoch 24; iter: 200; batch classifier loss: 0.363677; batch adversarial loss: 0.320625\n",
      "epoch 25; iter: 0; batch classifier loss: 0.345486; batch adversarial loss: 0.565804\n",
      "epoch 25; iter: 200; batch classifier loss: 0.397039; batch adversarial loss: 0.332237\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352317; batch adversarial loss: 0.429935\n",
      "epoch 26; iter: 200; batch classifier loss: 0.349082; batch adversarial loss: 0.381367\n",
      "epoch 27; iter: 0; batch classifier loss: 0.349534; batch adversarial loss: 0.446255\n",
      "epoch 27; iter: 200; batch classifier loss: 0.331145; batch adversarial loss: 0.487279\n",
      "epoch 28; iter: 0; batch classifier loss: 0.377020; batch adversarial loss: 0.411366\n",
      "epoch 28; iter: 200; batch classifier loss: 0.322999; batch adversarial loss: 0.394479\n",
      "epoch 29; iter: 0; batch classifier loss: 0.282806; batch adversarial loss: 0.444061\n",
      "epoch 29; iter: 200; batch classifier loss: 0.321226; batch adversarial loss: 0.378731\n",
      "epoch 30; iter: 0; batch classifier loss: 0.314402; batch adversarial loss: 0.374650\n",
      "epoch 30; iter: 200; batch classifier loss: 0.369846; batch adversarial loss: 0.452063\n",
      "epoch 31; iter: 0; batch classifier loss: 0.323141; batch adversarial loss: 0.355521\n",
      "epoch 31; iter: 200; batch classifier loss: 0.358443; batch adversarial loss: 0.461956\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348115; batch adversarial loss: 0.467308\n",
      "epoch 32; iter: 200; batch classifier loss: 0.287364; batch adversarial loss: 0.380063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.395910; batch adversarial loss: 0.364338\n",
      "epoch 33; iter: 200; batch classifier loss: 0.359253; batch adversarial loss: 0.434257\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474745; batch adversarial loss: 0.398062\n",
      "epoch 34; iter: 200; batch classifier loss: 0.334647; batch adversarial loss: 0.369770\n",
      "epoch 35; iter: 0; batch classifier loss: 0.378013; batch adversarial loss: 0.341806\n",
      "epoch 35; iter: 200; batch classifier loss: 0.326522; batch adversarial loss: 0.399106\n",
      "epoch 36; iter: 0; batch classifier loss: 0.337037; batch adversarial loss: 0.406269\n",
      "epoch 36; iter: 200; batch classifier loss: 0.395145; batch adversarial loss: 0.399806\n",
      "epoch 37; iter: 0; batch classifier loss: 0.297667; batch adversarial loss: 0.354714\n",
      "epoch 37; iter: 200; batch classifier loss: 0.453634; batch adversarial loss: 0.380065\n",
      "epoch 38; iter: 0; batch classifier loss: 0.326614; batch adversarial loss: 0.391653\n",
      "epoch 38; iter: 200; batch classifier loss: 0.329356; batch adversarial loss: 0.411704\n",
      "epoch 39; iter: 0; batch classifier loss: 0.355798; batch adversarial loss: 0.362121\n",
      "epoch 39; iter: 200; batch classifier loss: 0.323312; batch adversarial loss: 0.384585\n",
      "epoch 40; iter: 0; batch classifier loss: 0.319181; batch adversarial loss: 0.454173\n",
      "epoch 40; iter: 200; batch classifier loss: 0.349570; batch adversarial loss: 0.430559\n",
      "epoch 41; iter: 0; batch classifier loss: 0.367716; batch adversarial loss: 0.433674\n",
      "epoch 41; iter: 200; batch classifier loss: 0.411186; batch adversarial loss: 0.409967\n",
      "epoch 42; iter: 0; batch classifier loss: 0.346553; batch adversarial loss: 0.382928\n",
      "epoch 42; iter: 200; batch classifier loss: 0.334578; batch adversarial loss: 0.446617\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401298; batch adversarial loss: 0.466948\n",
      "epoch 43; iter: 200; batch classifier loss: 0.407908; batch adversarial loss: 0.389038\n",
      "epoch 44; iter: 0; batch classifier loss: 0.449272; batch adversarial loss: 0.398376\n",
      "epoch 44; iter: 200; batch classifier loss: 0.331402; batch adversarial loss: 0.447120\n",
      "epoch 45; iter: 0; batch classifier loss: 0.359773; batch adversarial loss: 0.400725\n",
      "epoch 45; iter: 200; batch classifier loss: 0.453872; batch adversarial loss: 0.430372\n",
      "epoch 46; iter: 0; batch classifier loss: 0.441979; batch adversarial loss: 0.369067\n",
      "epoch 46; iter: 200; batch classifier loss: 0.437319; batch adversarial loss: 0.431496\n",
      "epoch 47; iter: 0; batch classifier loss: 0.320385; batch adversarial loss: 0.445332\n",
      "epoch 47; iter: 200; batch classifier loss: 0.320757; batch adversarial loss: 0.433397\n",
      "epoch 48; iter: 0; batch classifier loss: 0.296238; batch adversarial loss: 0.401615\n",
      "epoch 48; iter: 200; batch classifier loss: 0.402752; batch adversarial loss: 0.330143\n",
      "epoch 49; iter: 0; batch classifier loss: 0.308738; batch adversarial loss: 0.507000\n",
      "epoch 49; iter: 200; batch classifier loss: 0.425707; batch adversarial loss: 0.407915\n",
      "epoch 0; iter: 0; batch classifier loss: 12.861217; batch adversarial loss: 0.721509\n",
      "epoch 0; iter: 200; batch classifier loss: 6.955744; batch adversarial loss: 0.610401\n",
      "epoch 1; iter: 0; batch classifier loss: 5.963518; batch adversarial loss: 0.579677\n",
      "epoch 1; iter: 200; batch classifier loss: 3.978288; batch adversarial loss: 0.515398\n",
      "epoch 2; iter: 0; batch classifier loss: 5.209831; batch adversarial loss: 0.515108\n",
      "epoch 2; iter: 200; batch classifier loss: 23.099072; batch adversarial loss: 0.449661\n",
      "epoch 3; iter: 0; batch classifier loss: 2.796283; batch adversarial loss: 0.433389\n",
      "epoch 3; iter: 200; batch classifier loss: 2.089875; batch adversarial loss: 0.437365\n",
      "epoch 4; iter: 0; batch classifier loss: 13.325955; batch adversarial loss: 0.463382\n",
      "epoch 4; iter: 200; batch classifier loss: 2.894966; batch adversarial loss: 0.444881\n",
      "epoch 5; iter: 0; batch classifier loss: 0.830814; batch adversarial loss: 0.405314\n",
      "epoch 5; iter: 200; batch classifier loss: 1.318541; batch adversarial loss: 0.529170\n",
      "epoch 6; iter: 0; batch classifier loss: 1.177724; batch adversarial loss: 0.465158\n",
      "epoch 6; iter: 200; batch classifier loss: 1.341659; batch adversarial loss: 0.409132\n",
      "epoch 7; iter: 0; batch classifier loss: 0.543416; batch adversarial loss: 0.420093\n",
      "epoch 7; iter: 200; batch classifier loss: 0.531727; batch adversarial loss: 0.439308\n",
      "epoch 8; iter: 0; batch classifier loss: 0.431164; batch adversarial loss: 0.373573\n",
      "epoch 8; iter: 200; batch classifier loss: 0.398292; batch adversarial loss: 0.340678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450443; batch adversarial loss: 0.369608\n",
      "epoch 9; iter: 200; batch classifier loss: 0.520088; batch adversarial loss: 0.476574\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445353; batch adversarial loss: 0.337692\n",
      "epoch 10; iter: 200; batch classifier loss: 0.435098; batch adversarial loss: 0.364040\n",
      "epoch 11; iter: 0; batch classifier loss: 0.395602; batch adversarial loss: 0.438314\n",
      "epoch 11; iter: 200; batch classifier loss: 0.398814; batch adversarial loss: 0.326188\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357805; batch adversarial loss: 0.533003\n",
      "epoch 12; iter: 200; batch classifier loss: 0.349784; batch adversarial loss: 0.468855\n",
      "epoch 13; iter: 0; batch classifier loss: 0.359780; batch adversarial loss: 0.339276\n",
      "epoch 13; iter: 200; batch classifier loss: 0.372032; batch adversarial loss: 0.326378\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352511; batch adversarial loss: 0.466476\n",
      "epoch 14; iter: 200; batch classifier loss: 0.425903; batch adversarial loss: 0.444693\n",
      "epoch 15; iter: 0; batch classifier loss: 0.434679; batch adversarial loss: 0.459205\n",
      "epoch 15; iter: 200; batch classifier loss: 0.411030; batch adversarial loss: 0.361850\n",
      "epoch 16; iter: 0; batch classifier loss: 0.635504; batch adversarial loss: 0.499032\n",
      "epoch 16; iter: 200; batch classifier loss: 0.355016; batch adversarial loss: 0.407488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336309; batch adversarial loss: 0.397506\n",
      "epoch 17; iter: 200; batch classifier loss: 0.390497; batch adversarial loss: 0.379471\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329542; batch adversarial loss: 0.441685\n",
      "epoch 18; iter: 200; batch classifier loss: 0.361475; batch adversarial loss: 0.367821\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356203; batch adversarial loss: 0.426923\n",
      "epoch 19; iter: 200; batch classifier loss: 0.339856; batch adversarial loss: 0.376184\n",
      "epoch 20; iter: 0; batch classifier loss: 0.299683; batch adversarial loss: 0.451314\n",
      "epoch 20; iter: 200; batch classifier loss: 0.316915; batch adversarial loss: 0.425515\n",
      "epoch 21; iter: 0; batch classifier loss: 0.325020; batch adversarial loss: 0.486559\n",
      "epoch 21; iter: 200; batch classifier loss: 0.395138; batch adversarial loss: 0.341693\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459448; batch adversarial loss: 0.357977\n",
      "epoch 22; iter: 200; batch classifier loss: 0.334572; batch adversarial loss: 0.432053\n",
      "epoch 23; iter: 0; batch classifier loss: 0.359299; batch adversarial loss: 0.455714\n",
      "epoch 23; iter: 200; batch classifier loss: 0.350962; batch adversarial loss: 0.407226\n",
      "epoch 24; iter: 0; batch classifier loss: 0.371619; batch adversarial loss: 0.438768\n",
      "epoch 24; iter: 200; batch classifier loss: 0.333879; batch adversarial loss: 0.364058\n",
      "epoch 25; iter: 0; batch classifier loss: 0.433766; batch adversarial loss: 0.401907\n",
      "epoch 25; iter: 200; batch classifier loss: 0.295220; batch adversarial loss: 0.415689\n",
      "epoch 26; iter: 0; batch classifier loss: 0.278498; batch adversarial loss: 0.437611\n",
      "epoch 26; iter: 200; batch classifier loss: 0.394751; batch adversarial loss: 0.399399\n",
      "epoch 27; iter: 0; batch classifier loss: 0.294084; batch adversarial loss: 0.396380\n",
      "epoch 27; iter: 200; batch classifier loss: 0.381630; batch adversarial loss: 0.379380\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328940; batch adversarial loss: 0.354199\n",
      "epoch 28; iter: 200; batch classifier loss: 0.281884; batch adversarial loss: 0.406812\n",
      "epoch 29; iter: 0; batch classifier loss: 0.331269; batch adversarial loss: 0.395679\n",
      "epoch 29; iter: 200; batch classifier loss: 0.263923; batch adversarial loss: 0.408867\n",
      "epoch 30; iter: 0; batch classifier loss: 0.357466; batch adversarial loss: 0.358130\n",
      "epoch 30; iter: 200; batch classifier loss: 0.294033; batch adversarial loss: 0.393201\n",
      "epoch 31; iter: 0; batch classifier loss: 0.397761; batch adversarial loss: 0.509314\n",
      "epoch 31; iter: 200; batch classifier loss: 0.344334; batch adversarial loss: 0.455715\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329192; batch adversarial loss: 0.451768\n",
      "epoch 32; iter: 200; batch classifier loss: 0.324604; batch adversarial loss: 0.339739\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318476; batch adversarial loss: 0.422390\n",
      "epoch 33; iter: 200; batch classifier loss: 0.391055; batch adversarial loss: 0.358904\n",
      "epoch 34; iter: 0; batch classifier loss: 0.358283; batch adversarial loss: 0.373841\n",
      "epoch 34; iter: 200; batch classifier loss: 0.323309; batch adversarial loss: 0.480029\n",
      "epoch 35; iter: 0; batch classifier loss: 0.401829; batch adversarial loss: 0.386222\n",
      "epoch 35; iter: 200; batch classifier loss: 0.338665; batch adversarial loss: 0.402898\n",
      "epoch 36; iter: 0; batch classifier loss: 0.309546; batch adversarial loss: 0.445387\n",
      "epoch 36; iter: 200; batch classifier loss: 0.426195; batch adversarial loss: 0.389458\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395754; batch adversarial loss: 0.333134\n",
      "epoch 37; iter: 200; batch classifier loss: 0.366122; batch adversarial loss: 0.416785\n",
      "epoch 38; iter: 0; batch classifier loss: 0.295752; batch adversarial loss: 0.487379\n",
      "epoch 38; iter: 200; batch classifier loss: 0.347536; batch adversarial loss: 0.362348\n",
      "epoch 39; iter: 0; batch classifier loss: 0.284752; batch adversarial loss: 0.379264\n",
      "epoch 39; iter: 200; batch classifier loss: 0.395086; batch adversarial loss: 0.474658\n",
      "epoch 40; iter: 0; batch classifier loss: 0.334338; batch adversarial loss: 0.366680\n",
      "epoch 40; iter: 200; batch classifier loss: 0.349279; batch adversarial loss: 0.447874\n",
      "epoch 41; iter: 0; batch classifier loss: 0.381019; batch adversarial loss: 0.422583\n",
      "epoch 41; iter: 200; batch classifier loss: 0.417943; batch adversarial loss: 0.365886\n",
      "epoch 42; iter: 0; batch classifier loss: 0.370083; batch adversarial loss: 0.456122\n",
      "epoch 42; iter: 200; batch classifier loss: 0.344384; batch adversarial loss: 0.449080\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415088; batch adversarial loss: 0.405668\n",
      "epoch 43; iter: 200; batch classifier loss: 0.425112; batch adversarial loss: 0.424579\n",
      "epoch 44; iter: 0; batch classifier loss: 0.330383; batch adversarial loss: 0.511574\n",
      "epoch 44; iter: 200; batch classifier loss: 0.362093; batch adversarial loss: 0.313008\n",
      "epoch 45; iter: 0; batch classifier loss: 0.425798; batch adversarial loss: 0.372211\n",
      "epoch 45; iter: 200; batch classifier loss: 0.301955; batch adversarial loss: 0.430484\n",
      "epoch 46; iter: 0; batch classifier loss: 0.489222; batch adversarial loss: 0.488880\n",
      "epoch 46; iter: 200; batch classifier loss: 0.356759; batch adversarial loss: 0.377869\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491899; batch adversarial loss: 0.441057\n",
      "epoch 47; iter: 200; batch classifier loss: 0.330207; batch adversarial loss: 0.418943\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435857; batch adversarial loss: 0.427792\n",
      "epoch 48; iter: 200; batch classifier loss: 0.358145; batch adversarial loss: 0.374898\n",
      "epoch 49; iter: 0; batch classifier loss: 0.430619; batch adversarial loss: 0.330438\n",
      "epoch 49; iter: 200; batch classifier loss: 0.444507; batch adversarial loss: 0.336653\n",
      "epoch 0; iter: 0; batch classifier loss: 18.607327; batch adversarial loss: 0.542582\n",
      "epoch 0; iter: 200; batch classifier loss: 10.310440; batch adversarial loss: 0.579509\n",
      "epoch 1; iter: 0; batch classifier loss: 6.146061; batch adversarial loss: 0.537262\n",
      "epoch 1; iter: 200; batch classifier loss: 8.414272; batch adversarial loss: 0.562481\n",
      "epoch 2; iter: 0; batch classifier loss: 5.518112; batch adversarial loss: 0.535499\n",
      "epoch 2; iter: 200; batch classifier loss: 2.108421; batch adversarial loss: 0.531500\n",
      "epoch 3; iter: 0; batch classifier loss: 4.980348; batch adversarial loss: 0.571167\n",
      "epoch 3; iter: 200; batch classifier loss: 4.109739; batch adversarial loss: 0.419091\n",
      "epoch 4; iter: 0; batch classifier loss: 2.054121; batch adversarial loss: 0.468763\n",
      "epoch 4; iter: 200; batch classifier loss: 1.630607; batch adversarial loss: 0.498292\n",
      "epoch 5; iter: 0; batch classifier loss: 0.744824; batch adversarial loss: 0.416132\n",
      "epoch 5; iter: 200; batch classifier loss: 0.758741; batch adversarial loss: 0.490853\n",
      "epoch 6; iter: 0; batch classifier loss: 0.845574; batch adversarial loss: 0.427348\n",
      "epoch 6; iter: 200; batch classifier loss: 0.738559; batch adversarial loss: 0.396974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.924439; batch adversarial loss: 0.473252\n",
      "epoch 7; iter: 200; batch classifier loss: 0.651770; batch adversarial loss: 0.416050\n",
      "epoch 8; iter: 0; batch classifier loss: 1.096992; batch adversarial loss: 0.413896\n",
      "epoch 8; iter: 200; batch classifier loss: 0.480975; batch adversarial loss: 0.396976\n",
      "epoch 9; iter: 0; batch classifier loss: 0.788439; batch adversarial loss: 0.307828\n",
      "epoch 9; iter: 200; batch classifier loss: 0.428571; batch adversarial loss: 0.440145\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484662; batch adversarial loss: 0.363636\n",
      "epoch 10; iter: 200; batch classifier loss: 0.460896; batch adversarial loss: 0.424803\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500583; batch adversarial loss: 0.372026\n",
      "epoch 11; iter: 200; batch classifier loss: 0.322829; batch adversarial loss: 0.419916\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404059; batch adversarial loss: 0.460964\n",
      "epoch 12; iter: 200; batch classifier loss: 0.260608; batch adversarial loss: 0.340232\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327229; batch adversarial loss: 0.359788\n",
      "epoch 13; iter: 200; batch classifier loss: 0.419101; batch adversarial loss: 0.400854\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343573; batch adversarial loss: 0.414783\n",
      "epoch 14; iter: 200; batch classifier loss: 0.404289; batch adversarial loss: 0.426057\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499779; batch adversarial loss: 0.398859\n",
      "epoch 15; iter: 200; batch classifier loss: 0.312268; batch adversarial loss: 0.484184\n",
      "epoch 16; iter: 0; batch classifier loss: 0.516113; batch adversarial loss: 0.483686\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388900; batch adversarial loss: 0.437107\n",
      "epoch 17; iter: 0; batch classifier loss: 0.324843; batch adversarial loss: 0.432740\n",
      "epoch 17; iter: 200; batch classifier loss: 0.344682; batch adversarial loss: 0.461300\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334204; batch adversarial loss: 0.467546\n",
      "epoch 18; iter: 200; batch classifier loss: 0.331300; batch adversarial loss: 0.354210\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365895; batch adversarial loss: 0.382162\n",
      "epoch 19; iter: 200; batch classifier loss: 0.403008; batch adversarial loss: 0.409500\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281664; batch adversarial loss: 0.382856\n",
      "epoch 20; iter: 200; batch classifier loss: 0.305033; batch adversarial loss: 0.427466\n",
      "epoch 21; iter: 0; batch classifier loss: 0.342376; batch adversarial loss: 0.389855\n",
      "epoch 21; iter: 200; batch classifier loss: 0.358776; batch adversarial loss: 0.388618\n",
      "epoch 22; iter: 0; batch classifier loss: 0.379614; batch adversarial loss: 0.365365\n",
      "epoch 22; iter: 200; batch classifier loss: 0.383279; batch adversarial loss: 0.447070\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378745; batch adversarial loss: 0.447087\n",
      "epoch 23; iter: 200; batch classifier loss: 0.419918; batch adversarial loss: 0.368903\n",
      "epoch 24; iter: 0; batch classifier loss: 0.333918; batch adversarial loss: 0.330887\n",
      "epoch 24; iter: 200; batch classifier loss: 0.347216; batch adversarial loss: 0.402478\n",
      "epoch 25; iter: 0; batch classifier loss: 0.284827; batch adversarial loss: 0.525517\n",
      "epoch 25; iter: 200; batch classifier loss: 0.336878; batch adversarial loss: 0.470493\n",
      "epoch 26; iter: 0; batch classifier loss: 0.458039; batch adversarial loss: 0.395724\n",
      "epoch 26; iter: 200; batch classifier loss: 0.415401; batch adversarial loss: 0.359087\n",
      "epoch 27; iter: 0; batch classifier loss: 0.377741; batch adversarial loss: 0.404564\n",
      "epoch 27; iter: 200; batch classifier loss: 0.329475; batch adversarial loss: 0.410456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.288456; batch adversarial loss: 0.446583\n",
      "epoch 28; iter: 200; batch classifier loss: 0.382555; batch adversarial loss: 0.456560\n",
      "epoch 29; iter: 0; batch classifier loss: 0.299920; batch adversarial loss: 0.376300\n",
      "epoch 29; iter: 200; batch classifier loss: 0.527319; batch adversarial loss: 0.406108\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415136; batch adversarial loss: 0.346978\n",
      "epoch 30; iter: 200; batch classifier loss: 0.589234; batch adversarial loss: 0.496062\n",
      "epoch 31; iter: 0; batch classifier loss: 0.412936; batch adversarial loss: 0.377120\n",
      "epoch 31; iter: 200; batch classifier loss: 0.536054; batch adversarial loss: 0.458321\n",
      "epoch 32; iter: 0; batch classifier loss: 0.413381; batch adversarial loss: 0.415931\n",
      "epoch 32; iter: 200; batch classifier loss: 0.280368; batch adversarial loss: 0.421914\n",
      "epoch 33; iter: 0; batch classifier loss: 0.383043; batch adversarial loss: 0.510951\n",
      "epoch 33; iter: 200; batch classifier loss: 0.333752; batch adversarial loss: 0.348486\n",
      "epoch 34; iter: 0; batch classifier loss: 0.346533; batch adversarial loss: 0.430050\n",
      "epoch 34; iter: 200; batch classifier loss: 0.502380; batch adversarial loss: 0.379802\n",
      "epoch 35; iter: 0; batch classifier loss: 0.388161; batch adversarial loss: 0.482934\n",
      "epoch 35; iter: 200; batch classifier loss: 0.551997; batch adversarial loss: 0.423812\n",
      "epoch 36; iter: 0; batch classifier loss: 0.580200; batch adversarial loss: 0.506417\n",
      "epoch 36; iter: 200; batch classifier loss: 0.465279; batch adversarial loss: 0.541556\n",
      "epoch 37; iter: 0; batch classifier loss: 0.447921; batch adversarial loss: 0.375977\n",
      "epoch 37; iter: 200; batch classifier loss: 0.500592; batch adversarial loss: 0.462789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492749; batch adversarial loss: 0.357824\n",
      "epoch 38; iter: 200; batch classifier loss: 0.403931; batch adversarial loss: 0.471773\n",
      "epoch 39; iter: 0; batch classifier loss: 0.413188; batch adversarial loss: 0.373619\n",
      "epoch 39; iter: 200; batch classifier loss: 0.419569; batch adversarial loss: 0.377133\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500120; batch adversarial loss: 0.419705\n",
      "epoch 40; iter: 200; batch classifier loss: 0.581528; batch adversarial loss: 0.436002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.445005; batch adversarial loss: 0.391933\n",
      "epoch 41; iter: 200; batch classifier loss: 0.370649; batch adversarial loss: 0.361907\n",
      "epoch 42; iter: 0; batch classifier loss: 0.426713; batch adversarial loss: 0.373789\n",
      "epoch 42; iter: 200; batch classifier loss: 0.444213; batch adversarial loss: 0.516934\n",
      "epoch 43; iter: 0; batch classifier loss: 0.484580; batch adversarial loss: 0.462609\n",
      "epoch 43; iter: 200; batch classifier loss: 0.721917; batch adversarial loss: 0.439638\n",
      "epoch 44; iter: 0; batch classifier loss: 0.513893; batch adversarial loss: 0.380311\n",
      "epoch 44; iter: 200; batch classifier loss: 0.356639; batch adversarial loss: 0.395220\n",
      "epoch 45; iter: 0; batch classifier loss: 0.470030; batch adversarial loss: 0.401743\n",
      "epoch 45; iter: 200; batch classifier loss: 0.419496; batch adversarial loss: 0.335753\n",
      "epoch 46; iter: 0; batch classifier loss: 0.463421; batch adversarial loss: 0.429787\n",
      "epoch 46; iter: 200; batch classifier loss: 0.552540; batch adversarial loss: 0.393012\n",
      "epoch 47; iter: 0; batch classifier loss: 0.482924; batch adversarial loss: 0.445596\n",
      "epoch 47; iter: 200; batch classifier loss: 0.383334; batch adversarial loss: 0.403051\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366982; batch adversarial loss: 0.489447\n",
      "epoch 48; iter: 200; batch classifier loss: 0.316613; batch adversarial loss: 0.474256\n",
      "epoch 49; iter: 0; batch classifier loss: 0.499219; batch adversarial loss: 0.487308\n",
      "epoch 49; iter: 200; batch classifier loss: 0.448163; batch adversarial loss: 0.433666\n",
      "epoch 0; iter: 0; batch classifier loss: 20.846394; batch adversarial loss: 0.466835\n",
      "epoch 0; iter: 200; batch classifier loss: 15.479921; batch adversarial loss: 0.586271\n",
      "epoch 1; iter: 0; batch classifier loss: 2.059664; batch adversarial loss: 0.540196\n",
      "epoch 1; iter: 200; batch classifier loss: 8.691298; batch adversarial loss: 0.499994\n",
      "epoch 2; iter: 0; batch classifier loss: 4.184085; batch adversarial loss: 0.514928\n",
      "epoch 2; iter: 200; batch classifier loss: 2.408193; batch adversarial loss: 0.486845\n",
      "epoch 3; iter: 0; batch classifier loss: 4.756236; batch adversarial loss: 0.354750\n",
      "epoch 3; iter: 200; batch classifier loss: 4.866006; batch adversarial loss: 0.493304\n",
      "epoch 4; iter: 0; batch classifier loss: 1.191212; batch adversarial loss: 0.474330\n",
      "epoch 4; iter: 200; batch classifier loss: 1.446281; batch adversarial loss: 0.427050\n",
      "epoch 5; iter: 0; batch classifier loss: 1.341314; batch adversarial loss: 0.390340\n",
      "epoch 5; iter: 200; batch classifier loss: 0.734783; batch adversarial loss: 0.444573\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568177; batch adversarial loss: 0.392522\n",
      "epoch 6; iter: 200; batch classifier loss: 0.408180; batch adversarial loss: 0.465696\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549952; batch adversarial loss: 0.502279\n",
      "epoch 7; iter: 200; batch classifier loss: 0.418904; batch adversarial loss: 0.436082\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485846; batch adversarial loss: 0.424091\n",
      "epoch 8; iter: 200; batch classifier loss: 0.488925; batch adversarial loss: 0.417989\n",
      "epoch 9; iter: 0; batch classifier loss: 0.454536; batch adversarial loss: 0.485763\n",
      "epoch 9; iter: 200; batch classifier loss: 0.490496; batch adversarial loss: 0.364762\n",
      "epoch 10; iter: 0; batch classifier loss: 0.404566; batch adversarial loss: 0.447645\n",
      "epoch 10; iter: 200; batch classifier loss: 0.369204; batch adversarial loss: 0.460160\n",
      "epoch 11; iter: 0; batch classifier loss: 0.439825; batch adversarial loss: 0.462516\n",
      "epoch 11; iter: 200; batch classifier loss: 0.424830; batch adversarial loss: 0.415362\n",
      "epoch 12; iter: 0; batch classifier loss: 0.375500; batch adversarial loss: 0.411702\n",
      "epoch 12; iter: 200; batch classifier loss: 0.268998; batch adversarial loss: 0.336117\n",
      "epoch 13; iter: 0; batch classifier loss: 0.281902; batch adversarial loss: 0.440872\n",
      "epoch 13; iter: 200; batch classifier loss: 0.374953; batch adversarial loss: 0.442771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.421509; batch adversarial loss: 0.372614\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378377; batch adversarial loss: 0.373831\n",
      "epoch 15; iter: 0; batch classifier loss: 0.454373; batch adversarial loss: 0.519607\n",
      "epoch 15; iter: 200; batch classifier loss: 0.374720; batch adversarial loss: 0.410606\n",
      "epoch 16; iter: 0; batch classifier loss: 0.294740; batch adversarial loss: 0.304946\n",
      "epoch 16; iter: 200; batch classifier loss: 0.409573; batch adversarial loss: 0.390031\n",
      "epoch 17; iter: 0; batch classifier loss: 0.318182; batch adversarial loss: 0.434963\n",
      "epoch 17; iter: 200; batch classifier loss: 0.385121; batch adversarial loss: 0.431434\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358195; batch adversarial loss: 0.416663\n",
      "epoch 18; iter: 200; batch classifier loss: 0.400818; batch adversarial loss: 0.334771\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321602; batch adversarial loss: 0.396699\n",
      "epoch 19; iter: 200; batch classifier loss: 0.326103; batch adversarial loss: 0.529461\n",
      "epoch 20; iter: 0; batch classifier loss: 0.360491; batch adversarial loss: 0.436146\n",
      "epoch 20; iter: 200; batch classifier loss: 0.283318; batch adversarial loss: 0.346630\n",
      "epoch 21; iter: 0; batch classifier loss: 0.303523; batch adversarial loss: 0.411486\n",
      "epoch 21; iter: 200; batch classifier loss: 0.377960; batch adversarial loss: 0.381372\n",
      "epoch 22; iter: 0; batch classifier loss: 0.359173; batch adversarial loss: 0.372252\n",
      "epoch 22; iter: 200; batch classifier loss: 0.366966; batch adversarial loss: 0.492175\n",
      "epoch 23; iter: 0; batch classifier loss: 0.412655; batch adversarial loss: 0.299467\n",
      "epoch 23; iter: 200; batch classifier loss: 0.377607; batch adversarial loss: 0.326256\n",
      "epoch 24; iter: 0; batch classifier loss: 0.349682; batch adversarial loss: 0.358458\n",
      "epoch 24; iter: 200; batch classifier loss: 0.481982; batch adversarial loss: 0.453956\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360515; batch adversarial loss: 0.367650\n",
      "epoch 25; iter: 200; batch classifier loss: 0.333143; batch adversarial loss: 0.355363\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271349; batch adversarial loss: 0.530263\n",
      "epoch 26; iter: 200; batch classifier loss: 0.385853; batch adversarial loss: 0.415528\n",
      "epoch 27; iter: 0; batch classifier loss: 0.367565; batch adversarial loss: 0.332633\n",
      "epoch 27; iter: 200; batch classifier loss: 0.321160; batch adversarial loss: 0.422016\n",
      "epoch 28; iter: 0; batch classifier loss: 0.374424; batch adversarial loss: 0.335853\n",
      "epoch 28; iter: 200; batch classifier loss: 0.351825; batch adversarial loss: 0.320643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.349704; batch adversarial loss: 0.419435\n",
      "epoch 29; iter: 200; batch classifier loss: 0.440033; batch adversarial loss: 0.495328\n",
      "epoch 30; iter: 0; batch classifier loss: 0.322096; batch adversarial loss: 0.372870\n",
      "epoch 30; iter: 200; batch classifier loss: 0.393614; batch adversarial loss: 0.334342\n",
      "epoch 31; iter: 0; batch classifier loss: 0.264794; batch adversarial loss: 0.508194\n",
      "epoch 31; iter: 200; batch classifier loss: 0.363213; batch adversarial loss: 0.417472\n",
      "epoch 32; iter: 0; batch classifier loss: 0.316689; batch adversarial loss: 0.497683\n",
      "epoch 32; iter: 200; batch classifier loss: 0.292538; batch adversarial loss: 0.376387\n",
      "epoch 33; iter: 0; batch classifier loss: 0.319952; batch adversarial loss: 0.460595\n",
      "epoch 33; iter: 200; batch classifier loss: 0.325878; batch adversarial loss: 0.337264\n",
      "epoch 34; iter: 0; batch classifier loss: 0.382861; batch adversarial loss: 0.367855\n",
      "epoch 34; iter: 200; batch classifier loss: 0.282977; batch adversarial loss: 0.393514\n",
      "epoch 35; iter: 0; batch classifier loss: 0.323813; batch adversarial loss: 0.368905\n",
      "epoch 35; iter: 200; batch classifier loss: 0.513231; batch adversarial loss: 0.448601\n",
      "epoch 36; iter: 0; batch classifier loss: 0.364092; batch adversarial loss: 0.430484\n",
      "epoch 36; iter: 200; batch classifier loss: 0.347315; batch adversarial loss: 0.502060\n",
      "epoch 37; iter: 0; batch classifier loss: 0.365003; batch adversarial loss: 0.321746\n",
      "epoch 37; iter: 200; batch classifier loss: 0.342905; batch adversarial loss: 0.384242\n",
      "epoch 38; iter: 0; batch classifier loss: 0.311613; batch adversarial loss: 0.440993\n",
      "epoch 38; iter: 200; batch classifier loss: 0.343109; batch adversarial loss: 0.400443\n",
      "epoch 39; iter: 0; batch classifier loss: 0.314861; batch adversarial loss: 0.456955\n",
      "epoch 39; iter: 200; batch classifier loss: 0.322191; batch adversarial loss: 0.386411\n",
      "epoch 40; iter: 0; batch classifier loss: 0.377408; batch adversarial loss: 0.373489\n",
      "epoch 40; iter: 200; batch classifier loss: 0.429259; batch adversarial loss: 0.348989\n",
      "epoch 41; iter: 0; batch classifier loss: 0.329077; batch adversarial loss: 0.455255\n",
      "epoch 41; iter: 200; batch classifier loss: 0.391251; batch adversarial loss: 0.381728\n",
      "epoch 42; iter: 0; batch classifier loss: 0.392122; batch adversarial loss: 0.498046\n",
      "epoch 42; iter: 200; batch classifier loss: 0.411923; batch adversarial loss: 0.391320\n",
      "epoch 43; iter: 0; batch classifier loss: 0.403774; batch adversarial loss: 0.344795\n",
      "epoch 43; iter: 200; batch classifier loss: 0.376956; batch adversarial loss: 0.430776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.350819; batch adversarial loss: 0.490637\n",
      "epoch 44; iter: 200; batch classifier loss: 0.363976; batch adversarial loss: 0.474309\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377901; batch adversarial loss: 0.446571\n",
      "epoch 45; iter: 200; batch classifier loss: 0.483607; batch adversarial loss: 0.417718\n",
      "epoch 46; iter: 0; batch classifier loss: 0.317793; batch adversarial loss: 0.374424\n",
      "epoch 46; iter: 200; batch classifier loss: 0.289505; batch adversarial loss: 0.334455\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437262; batch adversarial loss: 0.393277\n",
      "epoch 47; iter: 200; batch classifier loss: 0.473291; batch adversarial loss: 0.507379\n",
      "epoch 48; iter: 0; batch classifier loss: 0.355420; batch adversarial loss: 0.465224\n",
      "epoch 48; iter: 200; batch classifier loss: 0.490770; batch adversarial loss: 0.462731\n",
      "epoch 49; iter: 0; batch classifier loss: 0.488427; batch adversarial loss: 0.458611\n",
      "epoch 49; iter: 200; batch classifier loss: 0.459905; batch adversarial loss: 0.408594\n",
      "epoch 0; iter: 0; batch classifier loss: 4.020616; batch adversarial loss: 0.786302\n",
      "epoch 0; iter: 200; batch classifier loss: 5.144797; batch adversarial loss: 0.661726\n",
      "epoch 1; iter: 0; batch classifier loss: 10.985677; batch adversarial loss: 0.585697\n",
      "epoch 1; iter: 200; batch classifier loss: 8.911130; batch adversarial loss: 0.537147\n",
      "epoch 2; iter: 0; batch classifier loss: 3.109296; batch adversarial loss: 0.537649\n",
      "epoch 2; iter: 200; batch classifier loss: 2.103731; batch adversarial loss: 0.513802\n",
      "epoch 3; iter: 0; batch classifier loss: 2.965659; batch adversarial loss: 0.472168\n",
      "epoch 3; iter: 200; batch classifier loss: 13.454009; batch adversarial loss: 0.484815\n",
      "epoch 4; iter: 0; batch classifier loss: 2.581613; batch adversarial loss: 0.432285\n",
      "epoch 4; iter: 200; batch classifier loss: 1.527348; batch adversarial loss: 0.465061\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588009; batch adversarial loss: 0.418311\n",
      "epoch 5; iter: 200; batch classifier loss: 0.780482; batch adversarial loss: 0.365750\n",
      "epoch 6; iter: 0; batch classifier loss: 1.076406; batch adversarial loss: 0.404604\n",
      "epoch 6; iter: 200; batch classifier loss: 0.651421; batch adversarial loss: 0.327462\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495880; batch adversarial loss: 0.399041\n",
      "epoch 7; iter: 200; batch classifier loss: 0.659914; batch adversarial loss: 0.396281\n",
      "epoch 8; iter: 0; batch classifier loss: 0.792184; batch adversarial loss: 0.381811\n",
      "epoch 8; iter: 200; batch classifier loss: 0.436527; batch adversarial loss: 0.504543\n",
      "epoch 9; iter: 0; batch classifier loss: 0.483804; batch adversarial loss: 0.359703\n",
      "epoch 9; iter: 200; batch classifier loss: 0.458965; batch adversarial loss: 0.427733\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582338; batch adversarial loss: 0.420159\n",
      "epoch 10; iter: 200; batch classifier loss: 0.421901; batch adversarial loss: 0.356227\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370893; batch adversarial loss: 0.435147\n",
      "epoch 11; iter: 200; batch classifier loss: 0.653869; batch adversarial loss: 0.408801\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347165; batch adversarial loss: 0.440871\n",
      "epoch 12; iter: 200; batch classifier loss: 0.423513; batch adversarial loss: 0.365529\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417787; batch adversarial loss: 0.439138\n",
      "epoch 13; iter: 200; batch classifier loss: 0.437078; batch adversarial loss: 0.412738\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412181; batch adversarial loss: 0.425950\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388403; batch adversarial loss: 0.410934\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361154; batch adversarial loss: 0.429351\n",
      "epoch 15; iter: 200; batch classifier loss: 0.388138; batch adversarial loss: 0.422401\n",
      "epoch 16; iter: 0; batch classifier loss: 0.488158; batch adversarial loss: 0.383793\n",
      "epoch 16; iter: 200; batch classifier loss: 0.475662; batch adversarial loss: 0.384510\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377490; batch adversarial loss: 0.392674\n",
      "epoch 17; iter: 200; batch classifier loss: 0.455731; batch adversarial loss: 0.457810\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449143; batch adversarial loss: 0.380425\n",
      "epoch 18; iter: 200; batch classifier loss: 0.342832; batch adversarial loss: 0.363266\n",
      "epoch 19; iter: 0; batch classifier loss: 0.392096; batch adversarial loss: 0.506729\n",
      "epoch 19; iter: 200; batch classifier loss: 0.281681; batch adversarial loss: 0.411889\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338590; batch adversarial loss: 0.402703\n",
      "epoch 20; iter: 200; batch classifier loss: 0.245147; batch adversarial loss: 0.436326\n",
      "epoch 21; iter: 0; batch classifier loss: 0.341409; batch adversarial loss: 0.413335\n",
      "epoch 21; iter: 200; batch classifier loss: 0.281874; batch adversarial loss: 0.404765\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437896; batch adversarial loss: 0.336588\n",
      "epoch 22; iter: 200; batch classifier loss: 0.335274; batch adversarial loss: 0.474403\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333982; batch adversarial loss: 0.419873\n",
      "epoch 23; iter: 200; batch classifier loss: 0.401414; batch adversarial loss: 0.305416\n",
      "epoch 24; iter: 0; batch classifier loss: 0.376958; batch adversarial loss: 0.307795\n",
      "epoch 24; iter: 200; batch classifier loss: 0.344513; batch adversarial loss: 0.421380\n",
      "epoch 25; iter: 0; batch classifier loss: 0.279416; batch adversarial loss: 0.424795\n",
      "epoch 25; iter: 200; batch classifier loss: 0.377737; batch adversarial loss: 0.439558\n",
      "epoch 26; iter: 0; batch classifier loss: 0.308163; batch adversarial loss: 0.420476\n",
      "epoch 26; iter: 200; batch classifier loss: 0.299967; batch adversarial loss: 0.514749\n",
      "epoch 27; iter: 0; batch classifier loss: 0.289681; batch adversarial loss: 0.344977\n",
      "epoch 27; iter: 200; batch classifier loss: 0.398495; batch adversarial loss: 0.441445\n",
      "epoch 28; iter: 0; batch classifier loss: 0.349690; batch adversarial loss: 0.430955\n",
      "epoch 28; iter: 200; batch classifier loss: 0.307279; batch adversarial loss: 0.437643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.290366; batch adversarial loss: 0.495608\n",
      "epoch 29; iter: 200; batch classifier loss: 0.410117; batch adversarial loss: 0.364941\n",
      "epoch 30; iter: 0; batch classifier loss: 0.373311; batch adversarial loss: 0.479149\n",
      "epoch 30; iter: 200; batch classifier loss: 0.333646; batch adversarial loss: 0.371762\n",
      "epoch 31; iter: 0; batch classifier loss: 0.335621; batch adversarial loss: 0.415925\n",
      "epoch 31; iter: 200; batch classifier loss: 0.289420; batch adversarial loss: 0.459535\n",
      "epoch 32; iter: 0; batch classifier loss: 0.363794; batch adversarial loss: 0.278816\n",
      "epoch 32; iter: 200; batch classifier loss: 0.325365; batch adversarial loss: 0.411229\n",
      "epoch 33; iter: 0; batch classifier loss: 0.260980; batch adversarial loss: 0.431874\n",
      "epoch 33; iter: 200; batch classifier loss: 0.364919; batch adversarial loss: 0.423933\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363697; batch adversarial loss: 0.290453\n",
      "epoch 34; iter: 200; batch classifier loss: 0.353689; batch adversarial loss: 0.519448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.439364; batch adversarial loss: 0.467992\n",
      "epoch 35; iter: 200; batch classifier loss: 0.292097; batch adversarial loss: 0.420853\n",
      "epoch 36; iter: 0; batch classifier loss: 0.274666; batch adversarial loss: 0.456255\n",
      "epoch 36; iter: 200; batch classifier loss: 0.445076; batch adversarial loss: 0.460667\n",
      "epoch 37; iter: 0; batch classifier loss: 0.287484; batch adversarial loss: 0.415103\n",
      "epoch 37; iter: 200; batch classifier loss: 0.295847; batch adversarial loss: 0.414162\n",
      "epoch 38; iter: 0; batch classifier loss: 0.311973; batch adversarial loss: 0.378095\n",
      "epoch 38; iter: 200; batch classifier loss: 0.286356; batch adversarial loss: 0.492480\n",
      "epoch 39; iter: 0; batch classifier loss: 0.303624; batch adversarial loss: 0.462068\n",
      "epoch 39; iter: 200; batch classifier loss: 0.346332; batch adversarial loss: 0.406900\n",
      "epoch 40; iter: 0; batch classifier loss: 0.335151; batch adversarial loss: 0.301163\n",
      "epoch 40; iter: 200; batch classifier loss: 0.304269; batch adversarial loss: 0.296838\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401871; batch adversarial loss: 0.449349\n",
      "epoch 41; iter: 200; batch classifier loss: 0.254046; batch adversarial loss: 0.473321\n",
      "epoch 42; iter: 0; batch classifier loss: 0.343123; batch adversarial loss: 0.365283\n",
      "epoch 42; iter: 200; batch classifier loss: 0.226544; batch adversarial loss: 0.402491\n",
      "epoch 43; iter: 0; batch classifier loss: 0.337784; batch adversarial loss: 0.402883\n",
      "epoch 43; iter: 200; batch classifier loss: 0.353644; batch adversarial loss: 0.349399\n",
      "epoch 44; iter: 0; batch classifier loss: 0.348557; batch adversarial loss: 0.456977\n",
      "epoch 44; iter: 200; batch classifier loss: 0.387127; batch adversarial loss: 0.409684\n",
      "epoch 45; iter: 0; batch classifier loss: 0.270597; batch adversarial loss: 0.406126\n",
      "epoch 45; iter: 200; batch classifier loss: 0.389887; batch adversarial loss: 0.474087\n",
      "epoch 46; iter: 0; batch classifier loss: 0.386511; batch adversarial loss: 0.413492\n",
      "epoch 46; iter: 200; batch classifier loss: 0.479739; batch adversarial loss: 0.441217\n",
      "epoch 47; iter: 0; batch classifier loss: 0.351323; batch adversarial loss: 0.442526\n",
      "epoch 47; iter: 200; batch classifier loss: 0.324905; batch adversarial loss: 0.326194\n",
      "epoch 48; iter: 0; batch classifier loss: 0.307870; batch adversarial loss: 0.530601\n",
      "epoch 48; iter: 200; batch classifier loss: 0.273291; batch adversarial loss: 0.430006\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400430; batch adversarial loss: 0.359237\n",
      "epoch 49; iter: 200; batch classifier loss: 0.342885; batch adversarial loss: 0.487937\n",
      "epoch 0; iter: 0; batch classifier loss: 3.535267; batch adversarial loss: 0.785699\n",
      "epoch 0; iter: 200; batch classifier loss: 17.993805; batch adversarial loss: 0.656767\n",
      "epoch 1; iter: 0; batch classifier loss: 12.590494; batch adversarial loss: 0.613338\n",
      "epoch 1; iter: 200; batch classifier loss: 38.339073; batch adversarial loss: 0.534274\n",
      "epoch 2; iter: 0; batch classifier loss: 5.469084; batch adversarial loss: 0.529189\n",
      "epoch 2; iter: 200; batch classifier loss: 6.582831; batch adversarial loss: 0.451619\n",
      "epoch 3; iter: 0; batch classifier loss: 2.855921; batch adversarial loss: 0.422530\n",
      "epoch 3; iter: 200; batch classifier loss: 0.458486; batch adversarial loss: 0.383386\n",
      "epoch 4; iter: 0; batch classifier loss: 2.764077; batch adversarial loss: 0.431197\n",
      "epoch 4; iter: 200; batch classifier loss: 1.065733; batch adversarial loss: 0.442643\n",
      "epoch 5; iter: 0; batch classifier loss: 1.118797; batch adversarial loss: 0.417244\n",
      "epoch 5; iter: 200; batch classifier loss: 0.789408; batch adversarial loss: 0.435233\n",
      "epoch 6; iter: 0; batch classifier loss: 1.070864; batch adversarial loss: 0.440572\n",
      "epoch 6; iter: 200; batch classifier loss: 0.939564; batch adversarial loss: 0.409378\n",
      "epoch 7; iter: 0; batch classifier loss: 2.034567; batch adversarial loss: 0.465267\n",
      "epoch 7; iter: 200; batch classifier loss: 0.878178; batch adversarial loss: 0.535062\n",
      "epoch 8; iter: 0; batch classifier loss: 0.900926; batch adversarial loss: 0.330971\n",
      "epoch 8; iter: 200; batch classifier loss: 0.454863; batch adversarial loss: 0.313243\n",
      "epoch 9; iter: 0; batch classifier loss: 0.448780; batch adversarial loss: 0.419912\n",
      "epoch 9; iter: 200; batch classifier loss: 0.345633; batch adversarial loss: 0.358250\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464420; batch adversarial loss: 0.507622\n",
      "epoch 10; iter: 200; batch classifier loss: 0.336431; batch adversarial loss: 0.416692\n",
      "epoch 11; iter: 0; batch classifier loss: 0.734523; batch adversarial loss: 0.436138\n",
      "epoch 11; iter: 200; batch classifier loss: 0.454412; batch adversarial loss: 0.474296\n",
      "epoch 12; iter: 0; batch classifier loss: 0.371604; batch adversarial loss: 0.427492\n",
      "epoch 12; iter: 200; batch classifier loss: 0.349503; batch adversarial loss: 0.439668\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338653; batch adversarial loss: 0.428499\n",
      "epoch 13; iter: 200; batch classifier loss: 0.358548; batch adversarial loss: 0.432426\n",
      "epoch 14; iter: 0; batch classifier loss: 0.398537; batch adversarial loss: 0.368681\n",
      "epoch 14; iter: 200; batch classifier loss: 0.310074; batch adversarial loss: 0.547766\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302723; batch adversarial loss: 0.431173\n",
      "epoch 15; iter: 200; batch classifier loss: 0.327514; batch adversarial loss: 0.428187\n",
      "epoch 16; iter: 0; batch classifier loss: 0.373232; batch adversarial loss: 0.385309\n",
      "epoch 16; iter: 200; batch classifier loss: 0.361963; batch adversarial loss: 0.457736\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390958; batch adversarial loss: 0.442249\n",
      "epoch 17; iter: 200; batch classifier loss: 0.343034; batch adversarial loss: 0.451590\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317770; batch adversarial loss: 0.402363\n",
      "epoch 18; iter: 200; batch classifier loss: 0.387655; batch adversarial loss: 0.372924\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297067; batch adversarial loss: 0.468893\n",
      "epoch 19; iter: 200; batch classifier loss: 0.421553; batch adversarial loss: 0.440433\n",
      "epoch 20; iter: 0; batch classifier loss: 0.357097; batch adversarial loss: 0.310092\n",
      "epoch 20; iter: 200; batch classifier loss: 0.398371; batch adversarial loss: 0.343740\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338750; batch adversarial loss: 0.482148\n",
      "epoch 21; iter: 200; batch classifier loss: 0.343820; batch adversarial loss: 0.433068\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471631; batch adversarial loss: 0.378288\n",
      "epoch 22; iter: 200; batch classifier loss: 0.423082; batch adversarial loss: 0.345385\n",
      "epoch 23; iter: 0; batch classifier loss: 0.308330; batch adversarial loss: 0.290892\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374754; batch adversarial loss: 0.345619\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361797; batch adversarial loss: 0.295343\n",
      "epoch 24; iter: 200; batch classifier loss: 0.287835; batch adversarial loss: 0.537808\n",
      "epoch 25; iter: 0; batch classifier loss: 0.307241; batch adversarial loss: 0.411916\n",
      "epoch 25; iter: 200; batch classifier loss: 0.325457; batch adversarial loss: 0.470076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378208; batch adversarial loss: 0.610815\n",
      "epoch 26; iter: 200; batch classifier loss: 0.246213; batch adversarial loss: 0.445947\n",
      "epoch 27; iter: 0; batch classifier loss: 0.316747; batch adversarial loss: 0.375165\n",
      "epoch 27; iter: 200; batch classifier loss: 0.383167; batch adversarial loss: 0.403236\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352503; batch adversarial loss: 0.464301\n",
      "epoch 28; iter: 200; batch classifier loss: 0.355057; batch adversarial loss: 0.468355\n",
      "epoch 29; iter: 0; batch classifier loss: 0.391624; batch adversarial loss: 0.422594\n",
      "epoch 29; iter: 200; batch classifier loss: 0.406048; batch adversarial loss: 0.365821\n",
      "epoch 30; iter: 0; batch classifier loss: 0.291680; batch adversarial loss: 0.411732\n",
      "epoch 30; iter: 200; batch classifier loss: 0.379618; batch adversarial loss: 0.364134\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315512; batch adversarial loss: 0.380683\n",
      "epoch 31; iter: 200; batch classifier loss: 0.326300; batch adversarial loss: 0.438576\n",
      "epoch 32; iter: 0; batch classifier loss: 0.333339; batch adversarial loss: 0.529077\n",
      "epoch 32; iter: 200; batch classifier loss: 0.359670; batch adversarial loss: 0.370988\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235064; batch adversarial loss: 0.465280\n",
      "epoch 33; iter: 200; batch classifier loss: 0.330462; batch adversarial loss: 0.377330\n",
      "epoch 34; iter: 0; batch classifier loss: 0.343353; batch adversarial loss: 0.469197\n",
      "epoch 34; iter: 200; batch classifier loss: 0.328284; batch adversarial loss: 0.356212\n",
      "epoch 35; iter: 0; batch classifier loss: 0.380688; batch adversarial loss: 0.407941\n",
      "epoch 35; iter: 200; batch classifier loss: 0.346688; batch adversarial loss: 0.436990\n",
      "epoch 36; iter: 0; batch classifier loss: 0.278499; batch adversarial loss: 0.382092\n",
      "epoch 36; iter: 200; batch classifier loss: 0.293568; batch adversarial loss: 0.388139\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343412; batch adversarial loss: 0.372160\n",
      "epoch 37; iter: 200; batch classifier loss: 0.351568; batch adversarial loss: 0.389489\n",
      "epoch 38; iter: 0; batch classifier loss: 0.344158; batch adversarial loss: 0.374222\n",
      "epoch 38; iter: 200; batch classifier loss: 0.354230; batch adversarial loss: 0.427234\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460097; batch adversarial loss: 0.376347\n",
      "epoch 39; iter: 200; batch classifier loss: 0.329870; batch adversarial loss: 0.393179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398862; batch adversarial loss: 0.411224\n",
      "epoch 40; iter: 200; batch classifier loss: 0.326881; batch adversarial loss: 0.459298\n",
      "epoch 41; iter: 0; batch classifier loss: 0.365281; batch adversarial loss: 0.406478\n",
      "epoch 41; iter: 200; batch classifier loss: 0.355412; batch adversarial loss: 0.389375\n",
      "epoch 42; iter: 0; batch classifier loss: 0.352557; batch adversarial loss: 0.538790\n",
      "epoch 42; iter: 200; batch classifier loss: 0.392059; batch adversarial loss: 0.389622\n",
      "epoch 43; iter: 0; batch classifier loss: 0.370520; batch adversarial loss: 0.503659\n",
      "epoch 43; iter: 200; batch classifier loss: 0.423642; batch adversarial loss: 0.518577\n",
      "epoch 44; iter: 0; batch classifier loss: 0.342880; batch adversarial loss: 0.355128\n",
      "epoch 44; iter: 200; batch classifier loss: 0.423289; batch adversarial loss: 0.368493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.272646; batch adversarial loss: 0.451575\n",
      "epoch 45; iter: 200; batch classifier loss: 0.370451; batch adversarial loss: 0.400494\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367728; batch adversarial loss: 0.349593\n",
      "epoch 46; iter: 200; batch classifier loss: 0.309875; batch adversarial loss: 0.406612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.464429; batch adversarial loss: 0.365967\n",
      "epoch 47; iter: 200; batch classifier loss: 0.339742; batch adversarial loss: 0.350549\n",
      "epoch 48; iter: 0; batch classifier loss: 0.419434; batch adversarial loss: 0.392598\n",
      "epoch 48; iter: 200; batch classifier loss: 0.306039; batch adversarial loss: 0.443122\n",
      "epoch 49; iter: 0; batch classifier loss: 0.325986; batch adversarial loss: 0.544768\n",
      "epoch 49; iter: 200; batch classifier loss: 0.412669; batch adversarial loss: 0.320500\n",
      "epoch 0; iter: 0; batch classifier loss: 16.589291; batch adversarial loss: 0.779104\n",
      "epoch 0; iter: 200; batch classifier loss: 13.435668; batch adversarial loss: 0.613715\n",
      "epoch 1; iter: 0; batch classifier loss: 13.955338; batch adversarial loss: 0.584341\n",
      "epoch 1; iter: 200; batch classifier loss: 1.557487; batch adversarial loss: 0.587026\n",
      "epoch 2; iter: 0; batch classifier loss: 6.498270; batch adversarial loss: 0.489682\n",
      "epoch 2; iter: 200; batch classifier loss: 1.813851; batch adversarial loss: 0.524875\n",
      "epoch 3; iter: 0; batch classifier loss: 2.699323; batch adversarial loss: 0.480120\n",
      "epoch 3; iter: 200; batch classifier loss: 2.976153; batch adversarial loss: 0.449222\n",
      "epoch 4; iter: 0; batch classifier loss: 1.883528; batch adversarial loss: 0.435593\n",
      "epoch 4; iter: 200; batch classifier loss: 1.076231; batch adversarial loss: 0.440741\n",
      "epoch 5; iter: 0; batch classifier loss: 2.579029; batch adversarial loss: 0.415738\n",
      "epoch 5; iter: 200; batch classifier loss: 1.748674; batch adversarial loss: 0.441131\n",
      "epoch 6; iter: 0; batch classifier loss: 1.191435; batch adversarial loss: 0.418202\n",
      "epoch 6; iter: 200; batch classifier loss: 0.676419; batch adversarial loss: 0.413907\n",
      "epoch 7; iter: 0; batch classifier loss: 0.846187; batch adversarial loss: 0.496043\n",
      "epoch 7; iter: 200; batch classifier loss: 0.492763; batch adversarial loss: 0.419667\n",
      "epoch 8; iter: 0; batch classifier loss: 1.222102; batch adversarial loss: 0.411836\n",
      "epoch 8; iter: 200; batch classifier loss: 0.515354; batch adversarial loss: 0.398907\n",
      "epoch 9; iter: 0; batch classifier loss: 0.403522; batch adversarial loss: 0.437699\n",
      "epoch 9; iter: 200; batch classifier loss: 0.345710; batch adversarial loss: 0.412255\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414469; batch adversarial loss: 0.360825\n",
      "epoch 10; iter: 200; batch classifier loss: 0.562960; batch adversarial loss: 0.463783\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406683; batch adversarial loss: 0.368067\n",
      "epoch 11; iter: 200; batch classifier loss: 0.413506; batch adversarial loss: 0.434290\n",
      "epoch 12; iter: 0; batch classifier loss: 0.339556; batch adversarial loss: 0.332822\n",
      "epoch 12; iter: 200; batch classifier loss: 0.372131; batch adversarial loss: 0.409241\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412135; batch adversarial loss: 0.344281\n",
      "epoch 13; iter: 200; batch classifier loss: 0.332670; batch adversarial loss: 0.381801\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318935; batch adversarial loss: 0.461102\n",
      "epoch 14; iter: 200; batch classifier loss: 0.391858; batch adversarial loss: 0.487513\n",
      "epoch 15; iter: 0; batch classifier loss: 0.365288; batch adversarial loss: 0.369314\n",
      "epoch 15; iter: 200; batch classifier loss: 0.354626; batch adversarial loss: 0.401530\n",
      "epoch 16; iter: 0; batch classifier loss: 0.326496; batch adversarial loss: 0.386300\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342983; batch adversarial loss: 0.367743\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313290; batch adversarial loss: 0.481593\n",
      "epoch 17; iter: 200; batch classifier loss: 0.369150; batch adversarial loss: 0.473200\n",
      "epoch 18; iter: 0; batch classifier loss: 0.324711; batch adversarial loss: 0.491536\n",
      "epoch 18; iter: 200; batch classifier loss: 0.379373; batch adversarial loss: 0.414817\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337046; batch adversarial loss: 0.392259\n",
      "epoch 19; iter: 200; batch classifier loss: 0.355500; batch adversarial loss: 0.383536\n",
      "epoch 20; iter: 0; batch classifier loss: 0.303277; batch adversarial loss: 0.447135\n",
      "epoch 20; iter: 200; batch classifier loss: 0.307521; batch adversarial loss: 0.456893\n",
      "epoch 21; iter: 0; batch classifier loss: 0.285860; batch adversarial loss: 0.262355\n",
      "epoch 21; iter: 200; batch classifier loss: 0.316478; batch adversarial loss: 0.349478\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350193; batch adversarial loss: 0.435298\n",
      "epoch 22; iter: 200; batch classifier loss: 0.309632; batch adversarial loss: 0.367921\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381574; batch adversarial loss: 0.470625\n",
      "epoch 23; iter: 200; batch classifier loss: 0.402098; batch adversarial loss: 0.395895\n",
      "epoch 24; iter: 0; batch classifier loss: 0.356574; batch adversarial loss: 0.449123\n",
      "epoch 24; iter: 200; batch classifier loss: 0.321376; batch adversarial loss: 0.321543\n",
      "epoch 25; iter: 0; batch classifier loss: 0.343360; batch adversarial loss: 0.430292\n",
      "epoch 25; iter: 200; batch classifier loss: 0.388061; batch adversarial loss: 0.345666\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352468; batch adversarial loss: 0.523525\n",
      "epoch 26; iter: 200; batch classifier loss: 0.308706; batch adversarial loss: 0.421235\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277665; batch adversarial loss: 0.475852\n",
      "epoch 27; iter: 200; batch classifier loss: 0.307232; batch adversarial loss: 0.353106\n",
      "epoch 28; iter: 0; batch classifier loss: 0.332246; batch adversarial loss: 0.324276\n",
      "epoch 28; iter: 200; batch classifier loss: 0.387681; batch adversarial loss: 0.356481\n",
      "epoch 29; iter: 0; batch classifier loss: 0.312886; batch adversarial loss: 0.395037\n",
      "epoch 29; iter: 200; batch classifier loss: 0.364675; batch adversarial loss: 0.465988\n",
      "epoch 30; iter: 0; batch classifier loss: 0.308196; batch adversarial loss: 0.434876\n",
      "epoch 30; iter: 200; batch classifier loss: 0.276037; batch adversarial loss: 0.404730\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387439; batch adversarial loss: 0.346497\n",
      "epoch 31; iter: 200; batch classifier loss: 0.357410; batch adversarial loss: 0.439138\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400981; batch adversarial loss: 0.408052\n",
      "epoch 32; iter: 200; batch classifier loss: 0.369907; batch adversarial loss: 0.413472\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358191; batch adversarial loss: 0.476475\n",
      "epoch 33; iter: 200; batch classifier loss: 0.388984; batch adversarial loss: 0.429578\n",
      "epoch 34; iter: 0; batch classifier loss: 0.292836; batch adversarial loss: 0.383593\n",
      "epoch 34; iter: 200; batch classifier loss: 0.283682; batch adversarial loss: 0.417433\n",
      "epoch 35; iter: 0; batch classifier loss: 0.301056; batch adversarial loss: 0.498776\n",
      "epoch 35; iter: 200; batch classifier loss: 0.371596; batch adversarial loss: 0.451215\n",
      "epoch 36; iter: 0; batch classifier loss: 0.380838; batch adversarial loss: 0.401911\n",
      "epoch 36; iter: 200; batch classifier loss: 0.317128; batch adversarial loss: 0.457707\n",
      "epoch 37; iter: 0; batch classifier loss: 0.302428; batch adversarial loss: 0.444961\n",
      "epoch 37; iter: 200; batch classifier loss: 0.367449; batch adversarial loss: 0.359914\n",
      "epoch 38; iter: 0; batch classifier loss: 0.365901; batch adversarial loss: 0.455590\n",
      "epoch 38; iter: 200; batch classifier loss: 0.357229; batch adversarial loss: 0.407548\n",
      "epoch 39; iter: 0; batch classifier loss: 0.283426; batch adversarial loss: 0.335769\n",
      "epoch 39; iter: 200; batch classifier loss: 0.263317; batch adversarial loss: 0.380008\n",
      "epoch 40; iter: 0; batch classifier loss: 0.276643; batch adversarial loss: 0.290026\n",
      "epoch 40; iter: 200; batch classifier loss: 0.380149; batch adversarial loss: 0.448803\n",
      "epoch 41; iter: 0; batch classifier loss: 0.344801; batch adversarial loss: 0.331529\n",
      "epoch 41; iter: 200; batch classifier loss: 0.326458; batch adversarial loss: 0.431766\n",
      "epoch 42; iter: 0; batch classifier loss: 0.304535; batch adversarial loss: 0.412759\n",
      "epoch 42; iter: 200; batch classifier loss: 0.318050; batch adversarial loss: 0.383847\n",
      "epoch 43; iter: 0; batch classifier loss: 0.308896; batch adversarial loss: 0.422407\n",
      "epoch 43; iter: 200; batch classifier loss: 0.315393; batch adversarial loss: 0.443303\n",
      "epoch 44; iter: 0; batch classifier loss: 0.324156; batch adversarial loss: 0.386855\n",
      "epoch 44; iter: 200; batch classifier loss: 0.401210; batch adversarial loss: 0.407739\n",
      "epoch 45; iter: 0; batch classifier loss: 0.445910; batch adversarial loss: 0.408098\n",
      "epoch 45; iter: 200; batch classifier loss: 0.307275; batch adversarial loss: 0.472334\n",
      "epoch 46; iter: 0; batch classifier loss: 0.405389; batch adversarial loss: 0.452254\n",
      "epoch 46; iter: 200; batch classifier loss: 0.358178; batch adversarial loss: 0.392177\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480911; batch adversarial loss: 0.321625\n",
      "epoch 47; iter: 200; batch classifier loss: 0.368998; batch adversarial loss: 0.331910\n",
      "epoch 48; iter: 0; batch classifier loss: 0.332070; batch adversarial loss: 0.361893\n",
      "epoch 48; iter: 200; batch classifier loss: 0.291437; batch adversarial loss: 0.457080\n",
      "epoch 49; iter: 0; batch classifier loss: 0.283018; batch adversarial loss: 0.535412\n",
      "epoch 49; iter: 200; batch classifier loss: 0.355471; batch adversarial loss: 0.390990\n",
      "epoch 0; iter: 0; batch classifier loss: 115.610123; batch adversarial loss: 0.654962\n",
      "epoch 0; iter: 200; batch classifier loss: 6.156636; batch adversarial loss: 0.579717\n",
      "epoch 1; iter: 0; batch classifier loss: 3.335133; batch adversarial loss: 0.539910\n",
      "epoch 1; iter: 200; batch classifier loss: 4.889103; batch adversarial loss: 0.489157\n",
      "epoch 2; iter: 0; batch classifier loss: 2.123465; batch adversarial loss: 0.509241\n",
      "epoch 2; iter: 200; batch classifier loss: 2.640697; batch adversarial loss: 0.517992\n",
      "epoch 3; iter: 0; batch classifier loss: 2.264096; batch adversarial loss: 0.439297\n",
      "epoch 3; iter: 200; batch classifier loss: 6.486716; batch adversarial loss: 0.477256\n",
      "epoch 4; iter: 0; batch classifier loss: 2.006927; batch adversarial loss: 0.419953\n",
      "epoch 4; iter: 200; batch classifier loss: 1.093859; batch adversarial loss: 0.456320\n",
      "epoch 5; iter: 0; batch classifier loss: 2.600744; batch adversarial loss: 0.428286\n",
      "epoch 5; iter: 200; batch classifier loss: 0.489451; batch adversarial loss: 0.520144\n",
      "epoch 6; iter: 0; batch classifier loss: 0.601519; batch adversarial loss: 0.454608\n",
      "epoch 6; iter: 200; batch classifier loss: 0.988224; batch adversarial loss: 0.396125\n",
      "epoch 7; iter: 0; batch classifier loss: 0.857972; batch adversarial loss: 0.413190\n",
      "epoch 7; iter: 200; batch classifier loss: 0.601160; batch adversarial loss: 0.361687\n",
      "epoch 8; iter: 0; batch classifier loss: 0.433188; batch adversarial loss: 0.379088\n",
      "epoch 8; iter: 200; batch classifier loss: 0.518026; batch adversarial loss: 0.450098\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604229; batch adversarial loss: 0.354725\n",
      "epoch 9; iter: 200; batch classifier loss: 0.381271; batch adversarial loss: 0.464042\n",
      "epoch 10; iter: 0; batch classifier loss: 0.377575; batch adversarial loss: 0.382235\n",
      "epoch 10; iter: 200; batch classifier loss: 0.518656; batch adversarial loss: 0.397528\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501096; batch adversarial loss: 0.341586\n",
      "epoch 11; iter: 200; batch classifier loss: 0.526927; batch adversarial loss: 0.353873\n",
      "epoch 12; iter: 0; batch classifier loss: 0.419998; batch adversarial loss: 0.450545\n",
      "epoch 12; iter: 200; batch classifier loss: 0.398382; batch adversarial loss: 0.517889\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380938; batch adversarial loss: 0.379313\n",
      "epoch 13; iter: 200; batch classifier loss: 0.345429; batch adversarial loss: 0.473287\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310773; batch adversarial loss: 0.489931\n",
      "epoch 14; iter: 200; batch classifier loss: 0.532464; batch adversarial loss: 0.483574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432033; batch adversarial loss: 0.460751\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353230; batch adversarial loss: 0.409059\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518534; batch adversarial loss: 0.401347\n",
      "epoch 16; iter: 200; batch classifier loss: 0.354386; batch adversarial loss: 0.423407\n",
      "epoch 17; iter: 0; batch classifier loss: 0.431832; batch adversarial loss: 0.474921\n",
      "epoch 17; iter: 200; batch classifier loss: 0.398467; batch adversarial loss: 0.318096\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361862; batch adversarial loss: 0.537177\n",
      "epoch 18; iter: 200; batch classifier loss: 0.376456; batch adversarial loss: 0.402192\n",
      "epoch 19; iter: 0; batch classifier loss: 0.397660; batch adversarial loss: 0.460346\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347885; batch adversarial loss: 0.438334\n",
      "epoch 20; iter: 0; batch classifier loss: 0.327435; batch adversarial loss: 0.320548\n",
      "epoch 20; iter: 200; batch classifier loss: 0.330430; batch adversarial loss: 0.414365\n",
      "epoch 21; iter: 0; batch classifier loss: 0.404247; batch adversarial loss: 0.516750\n",
      "epoch 21; iter: 200; batch classifier loss: 0.340990; batch adversarial loss: 0.390719\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331785; batch adversarial loss: 0.471271\n",
      "epoch 22; iter: 200; batch classifier loss: 0.339365; batch adversarial loss: 0.441441\n",
      "epoch 23; iter: 0; batch classifier loss: 0.372111; batch adversarial loss: 0.599495\n",
      "epoch 23; iter: 200; batch classifier loss: 0.357099; batch adversarial loss: 0.469343\n",
      "epoch 24; iter: 0; batch classifier loss: 0.339838; batch adversarial loss: 0.423835\n",
      "epoch 24; iter: 200; batch classifier loss: 0.392207; batch adversarial loss: 0.393138\n",
      "epoch 25; iter: 0; batch classifier loss: 0.282441; batch adversarial loss: 0.308861\n",
      "epoch 25; iter: 200; batch classifier loss: 0.345438; batch adversarial loss: 0.421787\n",
      "epoch 26; iter: 0; batch classifier loss: 0.398854; batch adversarial loss: 0.352869\n",
      "epoch 26; iter: 200; batch classifier loss: 0.297477; batch adversarial loss: 0.365239\n",
      "epoch 27; iter: 0; batch classifier loss: 0.344050; batch adversarial loss: 0.403300\n",
      "epoch 27; iter: 200; batch classifier loss: 0.286273; batch adversarial loss: 0.375750\n",
      "epoch 28; iter: 0; batch classifier loss: 0.363604; batch adversarial loss: 0.500252\n",
      "epoch 28; iter: 200; batch classifier loss: 0.394800; batch adversarial loss: 0.424257\n",
      "epoch 29; iter: 0; batch classifier loss: 0.337131; batch adversarial loss: 0.524044\n",
      "epoch 29; iter: 200; batch classifier loss: 0.345462; batch adversarial loss: 0.488532\n",
      "epoch 30; iter: 0; batch classifier loss: 0.314454; batch adversarial loss: 0.380924\n",
      "epoch 30; iter: 200; batch classifier loss: 0.294232; batch adversarial loss: 0.532858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.353602; batch adversarial loss: 0.435372\n",
      "epoch 31; iter: 200; batch classifier loss: 0.295792; batch adversarial loss: 0.405918\n",
      "epoch 32; iter: 0; batch classifier loss: 0.337430; batch adversarial loss: 0.371027\n",
      "epoch 32; iter: 200; batch classifier loss: 0.391667; batch adversarial loss: 0.368416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.275449; batch adversarial loss: 0.348788\n",
      "epoch 33; iter: 200; batch classifier loss: 0.330479; batch adversarial loss: 0.484137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.358929; batch adversarial loss: 0.410756\n",
      "epoch 34; iter: 200; batch classifier loss: 0.401431; batch adversarial loss: 0.484419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.321461; batch adversarial loss: 0.378510\n",
      "epoch 35; iter: 200; batch classifier loss: 0.421960; batch adversarial loss: 0.273039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.328665; batch adversarial loss: 0.429594\n",
      "epoch 36; iter: 200; batch classifier loss: 0.338016; batch adversarial loss: 0.395571\n",
      "epoch 37; iter: 0; batch classifier loss: 0.367772; batch adversarial loss: 0.392454\n",
      "epoch 37; iter: 200; batch classifier loss: 0.387499; batch adversarial loss: 0.364325\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390628; batch adversarial loss: 0.435888\n",
      "epoch 38; iter: 200; batch classifier loss: 0.343798; batch adversarial loss: 0.367018\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315292; batch adversarial loss: 0.362401\n",
      "epoch 39; iter: 200; batch classifier loss: 0.309381; batch adversarial loss: 0.360986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.263576; batch adversarial loss: 0.400466\n",
      "epoch 40; iter: 200; batch classifier loss: 0.246473; batch adversarial loss: 0.427667\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325950; batch adversarial loss: 0.267297\n",
      "epoch 41; iter: 200; batch classifier loss: 0.391397; batch adversarial loss: 0.382889\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415702; batch adversarial loss: 0.529393\n",
      "epoch 42; iter: 200; batch classifier loss: 0.383781; batch adversarial loss: 0.384546\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378948; batch adversarial loss: 0.466961\n",
      "epoch 43; iter: 200; batch classifier loss: 0.322475; batch adversarial loss: 0.475530\n",
      "epoch 44; iter: 0; batch classifier loss: 0.277662; batch adversarial loss: 0.427652\n",
      "epoch 44; iter: 200; batch classifier loss: 0.302194; batch adversarial loss: 0.456298\n",
      "epoch 45; iter: 0; batch classifier loss: 0.412227; batch adversarial loss: 0.337511\n",
      "epoch 45; iter: 200; batch classifier loss: 0.413604; batch adversarial loss: 0.409019\n",
      "epoch 46; iter: 0; batch classifier loss: 0.391659; batch adversarial loss: 0.371384\n",
      "epoch 46; iter: 200; batch classifier loss: 0.334878; batch adversarial loss: 0.385786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.331807; batch adversarial loss: 0.382928\n",
      "epoch 47; iter: 200; batch classifier loss: 0.390153; batch adversarial loss: 0.378669\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411553; batch adversarial loss: 0.363863\n",
      "epoch 48; iter: 200; batch classifier loss: 0.331781; batch adversarial loss: 0.471634\n",
      "epoch 49; iter: 0; batch classifier loss: 0.368281; batch adversarial loss: 0.432197\n",
      "epoch 49; iter: 200; batch classifier loss: 0.396298; batch adversarial loss: 0.354868\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 32.530190; batch adversarial loss: 0.729498\n",
      "epoch 0; iter: 200; batch classifier loss: 14.280523; batch adversarial loss: 0.618095\n",
      "epoch 0; iter: 400; batch classifier loss: 0.806295; batch adversarial loss: 0.530300\n",
      "epoch 0; iter: 600; batch classifier loss: 26.062122; batch adversarial loss: 0.494246\n",
      "epoch 1; iter: 0; batch classifier loss: 12.518818; batch adversarial loss: 0.504582\n",
      "epoch 1; iter: 200; batch classifier loss: 3.470586; batch adversarial loss: 0.478177\n",
      "epoch 1; iter: 400; batch classifier loss: 5.475103; batch adversarial loss: 0.533649\n",
      "epoch 1; iter: 600; batch classifier loss: 10.163322; batch adversarial loss: 0.418254\n",
      "epoch 2; iter: 0; batch classifier loss: 5.098125; batch adversarial loss: 0.480937\n",
      "epoch 2; iter: 200; batch classifier loss: 7.005876; batch adversarial loss: 0.596070\n",
      "epoch 2; iter: 400; batch classifier loss: 0.755661; batch adversarial loss: 0.380234\n",
      "epoch 2; iter: 600; batch classifier loss: 1.345989; batch adversarial loss: 0.437586\n",
      "epoch 3; iter: 0; batch classifier loss: 2.702678; batch adversarial loss: 0.483628\n",
      "epoch 3; iter: 200; batch classifier loss: 4.399693; batch adversarial loss: 0.384393\n",
      "epoch 3; iter: 400; batch classifier loss: 1.578511; batch adversarial loss: 0.354394\n",
      "epoch 3; iter: 600; batch classifier loss: 1.878025; batch adversarial loss: 0.392549\n",
      "epoch 4; iter: 0; batch classifier loss: 2.873801; batch adversarial loss: 0.435123\n",
      "epoch 4; iter: 200; batch classifier loss: 1.384893; batch adversarial loss: 0.434778\n",
      "epoch 4; iter: 400; batch classifier loss: 2.116521; batch adversarial loss: 0.408397\n",
      "epoch 4; iter: 600; batch classifier loss: 0.853102; batch adversarial loss: 0.435629\n",
      "epoch 5; iter: 0; batch classifier loss: 3.629296; batch adversarial loss: 0.483265\n",
      "epoch 5; iter: 200; batch classifier loss: 1.058124; batch adversarial loss: 0.519992\n",
      "epoch 5; iter: 400; batch classifier loss: 0.698256; batch adversarial loss: 0.425887\n",
      "epoch 5; iter: 600; batch classifier loss: 2.035796; batch adversarial loss: 0.402772\n",
      "epoch 6; iter: 0; batch classifier loss: 1.580482; batch adversarial loss: 0.404981\n",
      "epoch 6; iter: 200; batch classifier loss: 0.459941; batch adversarial loss: 0.421932\n",
      "epoch 6; iter: 400; batch classifier loss: 0.434800; batch adversarial loss: 0.354958\n",
      "epoch 6; iter: 600; batch classifier loss: 0.353952; batch adversarial loss: 0.410238\n",
      "epoch 7; iter: 0; batch classifier loss: 0.480736; batch adversarial loss: 0.488309\n",
      "epoch 7; iter: 200; batch classifier loss: 0.386897; batch adversarial loss: 0.408015\n",
      "epoch 7; iter: 400; batch classifier loss: 0.392533; batch adversarial loss: 0.428447\n",
      "epoch 7; iter: 600; batch classifier loss: 0.389420; batch adversarial loss: 0.446484\n",
      "epoch 8; iter: 0; batch classifier loss: 0.457614; batch adversarial loss: 0.438613\n",
      "epoch 8; iter: 200; batch classifier loss: 0.431144; batch adversarial loss: 0.410369\n",
      "epoch 8; iter: 400; batch classifier loss: 0.700588; batch adversarial loss: 0.548126\n",
      "epoch 8; iter: 600; batch classifier loss: 0.403616; batch adversarial loss: 0.396474\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401968; batch adversarial loss: 0.400404\n",
      "epoch 9; iter: 200; batch classifier loss: 0.424910; batch adversarial loss: 0.395563\n",
      "epoch 9; iter: 400; batch classifier loss: 0.430171; batch adversarial loss: 0.552317\n",
      "epoch 9; iter: 600; batch classifier loss: 0.362746; batch adversarial loss: 0.448658\n",
      "epoch 0; iter: 0; batch classifier loss: 5.373936; batch adversarial loss: 0.568404\n",
      "epoch 0; iter: 200; batch classifier loss: 6.370202; batch adversarial loss: 0.611082\n",
      "epoch 0; iter: 400; batch classifier loss: 1.098902; batch adversarial loss: 0.542895\n",
      "epoch 0; iter: 600; batch classifier loss: 7.094116; batch adversarial loss: 0.506351\n",
      "epoch 1; iter: 0; batch classifier loss: 8.396570; batch adversarial loss: 0.512850\n",
      "epoch 1; iter: 200; batch classifier loss: 5.777734; batch adversarial loss: 0.506847\n",
      "epoch 1; iter: 400; batch classifier loss: 0.246849; batch adversarial loss: 0.540746\n",
      "epoch 1; iter: 600; batch classifier loss: 4.009556; batch adversarial loss: 0.437619\n",
      "epoch 2; iter: 0; batch classifier loss: 4.923165; batch adversarial loss: 0.393218\n",
      "epoch 2; iter: 200; batch classifier loss: 3.102386; batch adversarial loss: 0.405564\n",
      "epoch 2; iter: 400; batch classifier loss: 2.018421; batch adversarial loss: 0.420127\n",
      "epoch 2; iter: 600; batch classifier loss: 4.694742; batch adversarial loss: 0.347861\n",
      "epoch 3; iter: 0; batch classifier loss: 7.600070; batch adversarial loss: 0.338804\n",
      "epoch 3; iter: 200; batch classifier loss: 3.075480; batch adversarial loss: 0.432349\n",
      "epoch 3; iter: 400; batch classifier loss: 1.691734; batch adversarial loss: 0.649503\n",
      "epoch 3; iter: 600; batch classifier loss: 2.410397; batch adversarial loss: 0.413368\n",
      "epoch 4; iter: 0; batch classifier loss: 0.402803; batch adversarial loss: 0.380396\n",
      "epoch 4; iter: 200; batch classifier loss: 0.359789; batch adversarial loss: 0.385452\n",
      "epoch 4; iter: 400; batch classifier loss: 2.128044; batch adversarial loss: 0.432755\n",
      "epoch 4; iter: 600; batch classifier loss: 1.259515; batch adversarial loss: 0.427407\n",
      "epoch 5; iter: 0; batch classifier loss: 0.733609; batch adversarial loss: 0.319796\n",
      "epoch 5; iter: 200; batch classifier loss: 1.624121; batch adversarial loss: 0.543195\n",
      "epoch 5; iter: 400; batch classifier loss: 2.022125; batch adversarial loss: 0.376320\n",
      "epoch 5; iter: 600; batch classifier loss: 0.534566; batch adversarial loss: 0.420949\n",
      "epoch 6; iter: 0; batch classifier loss: 0.339548; batch adversarial loss: 0.296022\n",
      "epoch 6; iter: 200; batch classifier loss: 0.645236; batch adversarial loss: 0.369311\n",
      "epoch 6; iter: 400; batch classifier loss: 0.411832; batch adversarial loss: 0.533664\n",
      "epoch 6; iter: 600; batch classifier loss: 0.365636; batch adversarial loss: 0.245126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.377649; batch adversarial loss: 0.411749\n",
      "epoch 7; iter: 200; batch classifier loss: 0.295466; batch adversarial loss: 0.366384\n",
      "epoch 7; iter: 400; batch classifier loss: 0.430524; batch adversarial loss: 0.441146\n",
      "epoch 7; iter: 600; batch classifier loss: 0.373704; batch adversarial loss: 0.417230\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449710; batch adversarial loss: 0.356641\n",
      "epoch 8; iter: 200; batch classifier loss: 0.371634; batch adversarial loss: 0.420127\n",
      "epoch 8; iter: 400; batch classifier loss: 0.362670; batch adversarial loss: 0.394076\n",
      "epoch 8; iter: 600; batch classifier loss: 0.452587; batch adversarial loss: 0.321915\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361240; batch adversarial loss: 0.451057\n",
      "epoch 9; iter: 200; batch classifier loss: 0.297984; batch adversarial loss: 0.476604\n",
      "epoch 9; iter: 400; batch classifier loss: 0.469789; batch adversarial loss: 0.371402\n",
      "epoch 9; iter: 600; batch classifier loss: 0.354671; batch adversarial loss: 0.407941\n",
      "epoch 0; iter: 0; batch classifier loss: 118.007721; batch adversarial loss: 0.821186\n",
      "epoch 0; iter: 200; batch classifier loss: 7.222117; batch adversarial loss: 0.724522\n",
      "epoch 0; iter: 400; batch classifier loss: 2.011583; batch adversarial loss: 0.568054\n",
      "epoch 0; iter: 600; batch classifier loss: 6.919602; batch adversarial loss: 0.543907\n",
      "epoch 1; iter: 0; batch classifier loss: 9.169034; batch adversarial loss: 0.567725\n",
      "epoch 1; iter: 200; batch classifier loss: 2.725427; batch adversarial loss: 0.508428\n",
      "epoch 1; iter: 400; batch classifier loss: 5.963517; batch adversarial loss: 0.433352\n",
      "epoch 1; iter: 600; batch classifier loss: 4.769876; batch adversarial loss: 0.486797\n",
      "epoch 2; iter: 0; batch classifier loss: 8.326262; batch adversarial loss: 0.532148\n",
      "epoch 2; iter: 200; batch classifier loss: 1.669870; batch adversarial loss: 0.426711\n",
      "epoch 2; iter: 400; batch classifier loss: 7.326284; batch adversarial loss: 0.451434\n",
      "epoch 2; iter: 600; batch classifier loss: 2.712188; batch adversarial loss: 0.466983\n",
      "epoch 3; iter: 0; batch classifier loss: 4.243387; batch adversarial loss: 0.430355\n",
      "epoch 3; iter: 200; batch classifier loss: 2.329034; batch adversarial loss: 0.431228\n",
      "epoch 3; iter: 400; batch classifier loss: 3.233985; batch adversarial loss: 0.410622\n",
      "epoch 3; iter: 600; batch classifier loss: 5.669277; batch adversarial loss: 0.453909\n",
      "epoch 4; iter: 0; batch classifier loss: 2.218513; batch adversarial loss: 0.498774\n",
      "epoch 4; iter: 200; batch classifier loss: 0.488716; batch adversarial loss: 0.526105\n",
      "epoch 4; iter: 400; batch classifier loss: 0.602613; batch adversarial loss: 0.401757\n",
      "epoch 4; iter: 600; batch classifier loss: 1.582616; batch adversarial loss: 0.395820\n",
      "epoch 5; iter: 0; batch classifier loss: 1.370500; batch adversarial loss: 0.294845\n",
      "epoch 5; iter: 200; batch classifier loss: 0.655073; batch adversarial loss: 0.422666\n",
      "epoch 5; iter: 400; batch classifier loss: 0.390072; batch adversarial loss: 0.277423\n",
      "epoch 5; iter: 600; batch classifier loss: 0.389146; batch adversarial loss: 0.404960\n",
      "epoch 6; iter: 0; batch classifier loss: 0.435854; batch adversarial loss: 0.350874\n",
      "epoch 6; iter: 200; batch classifier loss: 0.405414; batch adversarial loss: 0.527467\n",
      "epoch 6; iter: 400; batch classifier loss: 1.040718; batch adversarial loss: 0.326024\n",
      "epoch 6; iter: 600; batch classifier loss: 0.422632; batch adversarial loss: 0.379908\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557321; batch adversarial loss: 0.323048\n",
      "epoch 7; iter: 200; batch classifier loss: 0.510995; batch adversarial loss: 0.345112\n",
      "epoch 7; iter: 400; batch classifier loss: 0.436192; batch adversarial loss: 0.467459\n",
      "epoch 7; iter: 600; batch classifier loss: 0.645293; batch adversarial loss: 0.490962\n",
      "epoch 8; iter: 0; batch classifier loss: 1.412727; batch adversarial loss: 0.321388\n",
      "epoch 8; iter: 200; batch classifier loss: 0.499601; batch adversarial loss: 0.480035\n",
      "epoch 8; iter: 400; batch classifier loss: 0.364422; batch adversarial loss: 0.543815\n",
      "epoch 8; iter: 600; batch classifier loss: 0.289688; batch adversarial loss: 0.307487\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407009; batch adversarial loss: 0.419834\n",
      "epoch 9; iter: 200; batch classifier loss: 0.292248; batch adversarial loss: 0.436140\n",
      "epoch 9; iter: 400; batch classifier loss: 0.440065; batch adversarial loss: 0.370853\n",
      "epoch 9; iter: 600; batch classifier loss: 0.361159; batch adversarial loss: 0.451456\n",
      "epoch 0; iter: 0; batch classifier loss: 64.792885; batch adversarial loss: 0.651132\n",
      "epoch 0; iter: 200; batch classifier loss: 13.462187; batch adversarial loss: 0.589017\n",
      "epoch 0; iter: 400; batch classifier loss: 6.415782; batch adversarial loss: 0.583999\n",
      "epoch 0; iter: 600; batch classifier loss: 2.959597; batch adversarial loss: 0.523452\n",
      "epoch 1; iter: 0; batch classifier loss: 2.964548; batch adversarial loss: 0.492267\n",
      "epoch 1; iter: 200; batch classifier loss: 1.558909; batch adversarial loss: 0.510757\n",
      "epoch 1; iter: 400; batch classifier loss: 0.524707; batch adversarial loss: 0.533456\n",
      "epoch 1; iter: 600; batch classifier loss: 10.769905; batch adversarial loss: 0.455503\n",
      "epoch 2; iter: 0; batch classifier loss: 1.205684; batch adversarial loss: 0.518937\n",
      "epoch 2; iter: 200; batch classifier loss: 6.435436; batch adversarial loss: 0.349713\n",
      "epoch 2; iter: 400; batch classifier loss: 1.249659; batch adversarial loss: 0.430248\n",
      "epoch 2; iter: 600; batch classifier loss: 0.518082; batch adversarial loss: 0.477581\n",
      "epoch 3; iter: 0; batch classifier loss: 2.433312; batch adversarial loss: 0.365016\n",
      "epoch 3; iter: 200; batch classifier loss: 0.904041; batch adversarial loss: 0.332730\n",
      "epoch 3; iter: 400; batch classifier loss: 5.606491; batch adversarial loss: 0.414933\n",
      "epoch 3; iter: 600; batch classifier loss: 0.999208; batch adversarial loss: 0.466866\n",
      "epoch 4; iter: 0; batch classifier loss: 1.218607; batch adversarial loss: 0.309533\n",
      "epoch 4; iter: 200; batch classifier loss: 1.165556; batch adversarial loss: 0.440506\n",
      "epoch 4; iter: 400; batch classifier loss: 0.561948; batch adversarial loss: 0.375240\n",
      "epoch 4; iter: 600; batch classifier loss: 1.214404; batch adversarial loss: 0.521593\n",
      "epoch 5; iter: 0; batch classifier loss: 0.709648; batch adversarial loss: 0.497158\n",
      "epoch 5; iter: 200; batch classifier loss: 0.866687; batch adversarial loss: 0.374643\n",
      "epoch 5; iter: 400; batch classifier loss: 0.720940; batch adversarial loss: 0.431099\n",
      "epoch 5; iter: 600; batch classifier loss: 0.335961; batch adversarial loss: 0.324881\n",
      "epoch 6; iter: 0; batch classifier loss: 1.749080; batch adversarial loss: 0.396015\n",
      "epoch 6; iter: 200; batch classifier loss: 0.556267; batch adversarial loss: 0.398361\n",
      "epoch 6; iter: 400; batch classifier loss: 0.402528; batch adversarial loss: 0.469895\n",
      "epoch 6; iter: 600; batch classifier loss: 0.643494; batch adversarial loss: 0.421119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418999; batch adversarial loss: 0.318626\n",
      "epoch 7; iter: 200; batch classifier loss: 0.297322; batch adversarial loss: 0.342989\n",
      "epoch 7; iter: 400; batch classifier loss: 0.598967; batch adversarial loss: 0.398927\n",
      "epoch 7; iter: 600; batch classifier loss: 0.567709; batch adversarial loss: 0.355580\n",
      "epoch 8; iter: 0; batch classifier loss: 0.599292; batch adversarial loss: 0.314270\n",
      "epoch 8; iter: 200; batch classifier loss: 0.586030; batch adversarial loss: 0.356356\n",
      "epoch 8; iter: 400; batch classifier loss: 0.393377; batch adversarial loss: 0.495021\n",
      "epoch 8; iter: 600; batch classifier loss: 0.325877; batch adversarial loss: 0.307912\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407036; batch adversarial loss: 0.452701\n",
      "epoch 9; iter: 200; batch classifier loss: 0.434401; batch adversarial loss: 0.524287\n",
      "epoch 9; iter: 400; batch classifier loss: 0.331800; batch adversarial loss: 0.351798\n",
      "epoch 9; iter: 600; batch classifier loss: 0.357879; batch adversarial loss: 0.400453\n",
      "epoch 0; iter: 0; batch classifier loss: 78.451775; batch adversarial loss: 0.818579\n",
      "epoch 0; iter: 200; batch classifier loss: 19.493992; batch adversarial loss: 0.706480\n",
      "epoch 0; iter: 400; batch classifier loss: 17.449215; batch adversarial loss: 0.556465\n",
      "epoch 0; iter: 600; batch classifier loss: 3.283929; batch adversarial loss: 0.493413\n",
      "epoch 1; iter: 0; batch classifier loss: 1.963150; batch adversarial loss: 0.516349\n",
      "epoch 1; iter: 200; batch classifier loss: 2.609959; batch adversarial loss: 0.538808\n",
      "epoch 1; iter: 400; batch classifier loss: 11.111049; batch adversarial loss: 0.534831\n",
      "epoch 1; iter: 600; batch classifier loss: 8.696911; batch adversarial loss: 0.482784\n",
      "epoch 2; iter: 0; batch classifier loss: 2.576352; batch adversarial loss: 0.502476\n",
      "epoch 2; iter: 200; batch classifier loss: 7.670174; batch adversarial loss: 0.458015\n",
      "epoch 2; iter: 400; batch classifier loss: 3.879359; batch adversarial loss: 0.363662\n",
      "epoch 2; iter: 600; batch classifier loss: 1.491337; batch adversarial loss: 0.429729\n",
      "epoch 3; iter: 0; batch classifier loss: 1.805694; batch adversarial loss: 0.421005\n",
      "epoch 3; iter: 200; batch classifier loss: 1.680955; batch adversarial loss: 0.463960\n",
      "epoch 3; iter: 400; batch classifier loss: 1.017298; batch adversarial loss: 0.538730\n",
      "epoch 3; iter: 600; batch classifier loss: 0.697903; batch adversarial loss: 0.384844\n",
      "epoch 4; iter: 0; batch classifier loss: 1.669707; batch adversarial loss: 0.391274\n",
      "epoch 4; iter: 200; batch classifier loss: 0.359143; batch adversarial loss: 0.312756\n",
      "epoch 4; iter: 400; batch classifier loss: 2.691812; batch adversarial loss: 0.315902\n",
      "epoch 4; iter: 600; batch classifier loss: 0.478867; batch adversarial loss: 0.342810\n",
      "epoch 5; iter: 0; batch classifier loss: 0.435319; batch adversarial loss: 0.534080\n",
      "epoch 5; iter: 200; batch classifier loss: 1.250752; batch adversarial loss: 0.357667\n",
      "epoch 5; iter: 400; batch classifier loss: 0.843959; batch adversarial loss: 0.396512\n",
      "epoch 5; iter: 600; batch classifier loss: 0.667423; batch adversarial loss: 0.412344\n",
      "epoch 6; iter: 0; batch classifier loss: 0.611824; batch adversarial loss: 0.400705\n",
      "epoch 6; iter: 200; batch classifier loss: 0.503414; batch adversarial loss: 0.398562\n",
      "epoch 6; iter: 400; batch classifier loss: 0.656161; batch adversarial loss: 0.440545\n",
      "epoch 6; iter: 600; batch classifier loss: 0.594721; batch adversarial loss: 0.325599\n",
      "epoch 7; iter: 0; batch classifier loss: 0.515985; batch adversarial loss: 0.370157\n",
      "epoch 7; iter: 200; batch classifier loss: 0.341504; batch adversarial loss: 0.448906\n",
      "epoch 7; iter: 400; batch classifier loss: 0.322665; batch adversarial loss: 0.382625\n",
      "epoch 7; iter: 600; batch classifier loss: 0.343049; batch adversarial loss: 0.489619\n",
      "epoch 8; iter: 0; batch classifier loss: 0.328082; batch adversarial loss: 0.401397\n",
      "epoch 8; iter: 200; batch classifier loss: 0.495609; batch adversarial loss: 0.347441\n",
      "epoch 8; iter: 400; batch classifier loss: 0.354314; batch adversarial loss: 0.354774\n",
      "epoch 8; iter: 600; batch classifier loss: 0.299743; batch adversarial loss: 0.449538\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500795; batch adversarial loss: 0.466054\n",
      "epoch 9; iter: 200; batch classifier loss: 0.387918; batch adversarial loss: 0.482585\n",
      "epoch 9; iter: 400; batch classifier loss: 0.474737; batch adversarial loss: 0.365802\n",
      "epoch 9; iter: 600; batch classifier loss: 0.388295; batch adversarial loss: 0.592797\n",
      "epoch 0; iter: 0; batch classifier loss: 310.308228; batch adversarial loss: 0.589238\n",
      "epoch 0; iter: 200; batch classifier loss: 5.063223; batch adversarial loss: 0.570009\n",
      "epoch 0; iter: 400; batch classifier loss: 12.635126; batch adversarial loss: 0.539817\n",
      "epoch 0; iter: 600; batch classifier loss: 12.152126; batch adversarial loss: 0.526987\n",
      "epoch 1; iter: 0; batch classifier loss: 17.444645; batch adversarial loss: 0.527393\n",
      "epoch 1; iter: 200; batch classifier loss: 1.794921; batch adversarial loss: 0.441720\n",
      "epoch 1; iter: 400; batch classifier loss: 11.921360; batch adversarial loss: 0.469615\n",
      "epoch 1; iter: 600; batch classifier loss: 8.121155; batch adversarial loss: 0.486804\n",
      "epoch 2; iter: 0; batch classifier loss: 4.018399; batch adversarial loss: 0.440482\n",
      "epoch 2; iter: 200; batch classifier loss: 3.856457; batch adversarial loss: 0.513542\n",
      "epoch 2; iter: 400; batch classifier loss: 3.012792; batch adversarial loss: 0.525012\n",
      "epoch 2; iter: 600; batch classifier loss: 0.672902; batch adversarial loss: 0.513311\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637381; batch adversarial loss: 0.518606\n",
      "epoch 3; iter: 200; batch classifier loss: 1.823641; batch adversarial loss: 0.341406\n",
      "epoch 3; iter: 400; batch classifier loss: 2.477809; batch adversarial loss: 0.521617\n",
      "epoch 3; iter: 600; batch classifier loss: 0.959243; batch adversarial loss: 0.395729\n",
      "epoch 4; iter: 0; batch classifier loss: 1.418832; batch adversarial loss: 0.408232\n",
      "epoch 4; iter: 200; batch classifier loss: 1.218578; batch adversarial loss: 0.382292\n",
      "epoch 4; iter: 400; batch classifier loss: 1.978731; batch adversarial loss: 0.332450\n",
      "epoch 4; iter: 600; batch classifier loss: 0.857683; batch adversarial loss: 0.472110\n",
      "epoch 5; iter: 0; batch classifier loss: 0.775910; batch adversarial loss: 0.478216\n",
      "epoch 5; iter: 200; batch classifier loss: 0.314812; batch adversarial loss: 0.413269\n",
      "epoch 5; iter: 400; batch classifier loss: 0.867310; batch adversarial loss: 0.282816\n",
      "epoch 5; iter: 600; batch classifier loss: 0.604497; batch adversarial loss: 0.412189\n",
      "epoch 6; iter: 0; batch classifier loss: 0.579133; batch adversarial loss: 0.382327\n",
      "epoch 6; iter: 200; batch classifier loss: 1.463776; batch adversarial loss: 0.326825\n",
      "epoch 6; iter: 400; batch classifier loss: 0.703058; batch adversarial loss: 0.347492\n",
      "epoch 6; iter: 600; batch classifier loss: 0.464990; batch adversarial loss: 0.320980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512521; batch adversarial loss: 0.427989\n",
      "epoch 7; iter: 200; batch classifier loss: 0.370275; batch adversarial loss: 0.403566\n",
      "epoch 7; iter: 400; batch classifier loss: 0.625032; batch adversarial loss: 0.292326\n",
      "epoch 7; iter: 600; batch classifier loss: 0.242259; batch adversarial loss: 0.368468\n",
      "epoch 8; iter: 0; batch classifier loss: 0.472207; batch adversarial loss: 0.353696\n",
      "epoch 8; iter: 200; batch classifier loss: 0.380258; batch adversarial loss: 0.313626\n",
      "epoch 8; iter: 400; batch classifier loss: 0.405804; batch adversarial loss: 0.415078\n",
      "epoch 8; iter: 600; batch classifier loss: 0.348768; batch adversarial loss: 0.402506\n",
      "epoch 9; iter: 0; batch classifier loss: 0.376375; batch adversarial loss: 0.363563\n",
      "epoch 9; iter: 200; batch classifier loss: 0.226191; batch adversarial loss: 0.356759\n",
      "epoch 9; iter: 400; batch classifier loss: 0.726865; batch adversarial loss: 0.455604\n",
      "epoch 9; iter: 600; batch classifier loss: 0.359694; batch adversarial loss: 0.506762\n",
      "epoch 0; iter: 0; batch classifier loss: 16.049368; batch adversarial loss: 1.061858\n",
      "epoch 0; iter: 200; batch classifier loss: 10.696583; batch adversarial loss: 0.934598\n",
      "epoch 0; iter: 400; batch classifier loss: 11.478767; batch adversarial loss: 0.710530\n",
      "epoch 0; iter: 600; batch classifier loss: 4.860261; batch adversarial loss: 0.563547\n",
      "epoch 1; iter: 0; batch classifier loss: 1.264786; batch adversarial loss: 0.601850\n",
      "epoch 1; iter: 200; batch classifier loss: 7.073197; batch adversarial loss: 0.533005\n",
      "epoch 1; iter: 400; batch classifier loss: 6.760998; batch adversarial loss: 0.487715\n",
      "epoch 1; iter: 600; batch classifier loss: 2.051225; batch adversarial loss: 0.399701\n",
      "epoch 2; iter: 0; batch classifier loss: 1.004561; batch adversarial loss: 0.468509\n",
      "epoch 2; iter: 200; batch classifier loss: 5.426666; batch adversarial loss: 0.451920\n",
      "epoch 2; iter: 400; batch classifier loss: 2.645635; batch adversarial loss: 0.402432\n",
      "epoch 2; iter: 600; batch classifier loss: 1.583226; batch adversarial loss: 0.492354\n",
      "epoch 3; iter: 0; batch classifier loss: 3.180890; batch adversarial loss: 0.416618\n",
      "epoch 3; iter: 200; batch classifier loss: 1.290313; batch adversarial loss: 0.422305\n",
      "epoch 3; iter: 400; batch classifier loss: 0.643421; batch adversarial loss: 0.423584\n",
      "epoch 3; iter: 600; batch classifier loss: 0.414481; batch adversarial loss: 0.363548\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443200; batch adversarial loss: 0.348584\n",
      "epoch 4; iter: 200; batch classifier loss: 0.754990; batch adversarial loss: 0.505830\n",
      "epoch 4; iter: 400; batch classifier loss: 0.727464; batch adversarial loss: 0.389678\n",
      "epoch 4; iter: 600; batch classifier loss: 0.505038; batch adversarial loss: 0.430625\n",
      "epoch 5; iter: 0; batch classifier loss: 0.526482; batch adversarial loss: 0.337992\n",
      "epoch 5; iter: 200; batch classifier loss: 0.529500; batch adversarial loss: 0.405005\n",
      "epoch 5; iter: 400; batch classifier loss: 0.601801; batch adversarial loss: 0.419797\n",
      "epoch 5; iter: 600; batch classifier loss: 0.456067; batch adversarial loss: 0.461442\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556580; batch adversarial loss: 0.240979\n",
      "epoch 6; iter: 200; batch classifier loss: 0.394700; batch adversarial loss: 0.356416\n",
      "epoch 6; iter: 400; batch classifier loss: 0.559176; batch adversarial loss: 0.507361\n",
      "epoch 6; iter: 600; batch classifier loss: 0.508800; batch adversarial loss: 0.406000\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570839; batch adversarial loss: 0.467384\n",
      "epoch 7; iter: 200; batch classifier loss: 0.389645; batch adversarial loss: 0.379565\n",
      "epoch 7; iter: 400; batch classifier loss: 0.303129; batch adversarial loss: 0.381180\n",
      "epoch 7; iter: 600; batch classifier loss: 0.413695; batch adversarial loss: 0.380526\n",
      "epoch 8; iter: 0; batch classifier loss: 0.418396; batch adversarial loss: 0.449171\n",
      "epoch 8; iter: 200; batch classifier loss: 0.380555; batch adversarial loss: 0.461455\n",
      "epoch 8; iter: 400; batch classifier loss: 0.323129; batch adversarial loss: 0.449051\n",
      "epoch 8; iter: 600; batch classifier loss: 0.303830; batch adversarial loss: 0.320907\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442561; batch adversarial loss: 0.367150\n",
      "epoch 9; iter: 200; batch classifier loss: 0.329823; batch adversarial loss: 0.432602\n",
      "epoch 9; iter: 400; batch classifier loss: 0.312311; batch adversarial loss: 0.588006\n",
      "epoch 9; iter: 600; batch classifier loss: 0.480294; batch adversarial loss: 0.466093\n",
      "epoch 0; iter: 0; batch classifier loss: 68.316963; batch adversarial loss: 0.554524\n",
      "epoch 0; iter: 200; batch classifier loss: 43.770378; batch adversarial loss: 0.574050\n",
      "epoch 0; iter: 400; batch classifier loss: 4.337873; batch adversarial loss: 0.524446\n",
      "epoch 0; iter: 600; batch classifier loss: 7.518602; batch adversarial loss: 0.470460\n",
      "epoch 1; iter: 0; batch classifier loss: 3.734210; batch adversarial loss: 0.463411\n",
      "epoch 1; iter: 200; batch classifier loss: 7.870399; batch adversarial loss: 0.487104\n",
      "epoch 1; iter: 400; batch classifier loss: 23.070667; batch adversarial loss: 0.501574\n",
      "epoch 1; iter: 600; batch classifier loss: 2.825072; batch adversarial loss: 0.451980\n",
      "epoch 2; iter: 0; batch classifier loss: 1.083264; batch adversarial loss: 0.470860\n",
      "epoch 2; iter: 200; batch classifier loss: 5.299323; batch adversarial loss: 0.360335\n",
      "epoch 2; iter: 400; batch classifier loss: 2.141464; batch adversarial loss: 0.466344\n",
      "epoch 2; iter: 600; batch classifier loss: 2.704862; batch adversarial loss: 0.399267\n",
      "epoch 3; iter: 0; batch classifier loss: 3.458365; batch adversarial loss: 0.440643\n",
      "epoch 3; iter: 200; batch classifier loss: 0.659545; batch adversarial loss: 0.450168\n",
      "epoch 3; iter: 400; batch classifier loss: 1.663646; batch adversarial loss: 0.557548\n",
      "epoch 3; iter: 600; batch classifier loss: 1.746583; batch adversarial loss: 0.402981\n",
      "epoch 4; iter: 0; batch classifier loss: 2.143227; batch adversarial loss: 0.468667\n",
      "epoch 4; iter: 200; batch classifier loss: 0.703038; batch adversarial loss: 0.469510\n",
      "epoch 4; iter: 400; batch classifier loss: 0.754287; batch adversarial loss: 0.615276\n",
      "epoch 4; iter: 600; batch classifier loss: 0.702500; batch adversarial loss: 0.434043\n",
      "epoch 5; iter: 0; batch classifier loss: 0.923360; batch adversarial loss: 0.639762\n",
      "epoch 5; iter: 200; batch classifier loss: 0.446369; batch adversarial loss: 0.325423\n",
      "epoch 5; iter: 400; batch classifier loss: 0.643202; batch adversarial loss: 0.392201\n",
      "epoch 5; iter: 600; batch classifier loss: 0.458397; batch adversarial loss: 0.249828\n",
      "epoch 6; iter: 0; batch classifier loss: 0.733682; batch adversarial loss: 0.533602\n",
      "epoch 6; iter: 200; batch classifier loss: 0.402155; batch adversarial loss: 0.565492\n",
      "epoch 6; iter: 400; batch classifier loss: 0.406339; batch adversarial loss: 0.426288\n",
      "epoch 6; iter: 600; batch classifier loss: 0.383723; batch adversarial loss: 0.466612\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527782; batch adversarial loss: 0.407880\n",
      "epoch 7; iter: 200; batch classifier loss: 0.355222; batch adversarial loss: 0.478091\n",
      "epoch 7; iter: 400; batch classifier loss: 0.796225; batch adversarial loss: 0.482456\n",
      "epoch 7; iter: 600; batch classifier loss: 0.340142; batch adversarial loss: 0.505907\n",
      "epoch 8; iter: 0; batch classifier loss: 0.372276; batch adversarial loss: 0.346280\n",
      "epoch 8; iter: 200; batch classifier loss: 0.371984; batch adversarial loss: 0.280101\n",
      "epoch 8; iter: 400; batch classifier loss: 0.413608; batch adversarial loss: 0.570750\n",
      "epoch 8; iter: 600; batch classifier loss: 0.323212; batch adversarial loss: 0.380425\n",
      "epoch 9; iter: 0; batch classifier loss: 0.350404; batch adversarial loss: 0.455410\n",
      "epoch 9; iter: 200; batch classifier loss: 0.347843; batch adversarial loss: 0.350881\n",
      "epoch 9; iter: 400; batch classifier loss: 0.398523; batch adversarial loss: 0.471812\n",
      "epoch 9; iter: 600; batch classifier loss: 0.293380; batch adversarial loss: 0.298811\n",
      "epoch 0; iter: 0; batch classifier loss: 14.864321; batch adversarial loss: 0.554374\n",
      "epoch 0; iter: 200; batch classifier loss: 11.729034; batch adversarial loss: 0.599137\n",
      "epoch 0; iter: 400; batch classifier loss: 6.741435; batch adversarial loss: 0.533092\n",
      "epoch 0; iter: 600; batch classifier loss: 4.911114; batch adversarial loss: 0.472717\n",
      "epoch 1; iter: 0; batch classifier loss: 11.174075; batch adversarial loss: 0.494266\n",
      "epoch 1; iter: 200; batch classifier loss: 9.525036; batch adversarial loss: 0.482089\n",
      "epoch 1; iter: 400; batch classifier loss: 6.607728; batch adversarial loss: 0.481622\n",
      "epoch 1; iter: 600; batch classifier loss: 3.444442; batch adversarial loss: 0.462985\n",
      "epoch 2; iter: 0; batch classifier loss: 2.567972; batch adversarial loss: 0.453007\n",
      "epoch 2; iter: 200; batch classifier loss: 3.080894; batch adversarial loss: 0.341826\n",
      "epoch 2; iter: 400; batch classifier loss: 1.686254; batch adversarial loss: 0.455695\n",
      "epoch 2; iter: 600; batch classifier loss: 0.648355; batch adversarial loss: 0.451233\n",
      "epoch 3; iter: 0; batch classifier loss: 1.150638; batch adversarial loss: 0.402476\n",
      "epoch 3; iter: 200; batch classifier loss: 0.612905; batch adversarial loss: 0.421001\n",
      "epoch 3; iter: 400; batch classifier loss: 0.888351; batch adversarial loss: 0.584961\n",
      "epoch 3; iter: 600; batch classifier loss: 1.762880; batch adversarial loss: 0.445160\n",
      "epoch 4; iter: 0; batch classifier loss: 0.631296; batch adversarial loss: 0.588585\n",
      "epoch 4; iter: 200; batch classifier loss: 0.684450; batch adversarial loss: 0.420722\n",
      "epoch 4; iter: 400; batch classifier loss: 0.566298; batch adversarial loss: 0.324643\n",
      "epoch 4; iter: 600; batch classifier loss: 0.884387; batch adversarial loss: 0.407780\n",
      "epoch 5; iter: 0; batch classifier loss: 0.323613; batch adversarial loss: 0.489501\n",
      "epoch 5; iter: 200; batch classifier loss: 0.458995; batch adversarial loss: 0.443368\n",
      "epoch 5; iter: 400; batch classifier loss: 0.449413; batch adversarial loss: 0.385405\n",
      "epoch 5; iter: 600; batch classifier loss: 0.513071; batch adversarial loss: 0.343305\n",
      "epoch 6; iter: 0; batch classifier loss: 0.413266; batch adversarial loss: 0.447968\n",
      "epoch 6; iter: 200; batch classifier loss: 0.458031; batch adversarial loss: 0.464054\n",
      "epoch 6; iter: 400; batch classifier loss: 0.413627; batch adversarial loss: 0.406487\n",
      "epoch 6; iter: 600; batch classifier loss: 0.418789; batch adversarial loss: 0.428983\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288809; batch adversarial loss: 0.351724\n",
      "epoch 7; iter: 200; batch classifier loss: 0.370683; batch adversarial loss: 0.542397\n",
      "epoch 7; iter: 400; batch classifier loss: 0.339456; batch adversarial loss: 0.374405\n",
      "epoch 7; iter: 600; batch classifier loss: 0.443521; batch adversarial loss: 0.355392\n",
      "epoch 8; iter: 0; batch classifier loss: 1.194146; batch adversarial loss: 0.463592\n",
      "epoch 8; iter: 200; batch classifier loss: 0.407701; batch adversarial loss: 0.321061\n",
      "epoch 8; iter: 400; batch classifier loss: 0.426617; batch adversarial loss: 0.420106\n",
      "epoch 8; iter: 600; batch classifier loss: 0.428586; batch adversarial loss: 0.407033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.396680; batch adversarial loss: 0.298459\n",
      "epoch 9; iter: 200; batch classifier loss: 0.355517; batch adversarial loss: 0.358280\n",
      "epoch 9; iter: 400; batch classifier loss: 0.295314; batch adversarial loss: 0.390664\n",
      "epoch 9; iter: 600; batch classifier loss: 0.405973; batch adversarial loss: 0.403779\n",
      "epoch 0; iter: 0; batch classifier loss: 402.386597; batch adversarial loss: 0.700455\n",
      "epoch 0; iter: 200; batch classifier loss: 5.103944; batch adversarial loss: 0.617614\n",
      "epoch 0; iter: 400; batch classifier loss: 5.225636; batch adversarial loss: 0.616810\n",
      "epoch 0; iter: 600; batch classifier loss: 11.547146; batch adversarial loss: 0.531788\n",
      "epoch 1; iter: 0; batch classifier loss: 4.514854; batch adversarial loss: 0.559933\n",
      "epoch 1; iter: 200; batch classifier loss: 2.234736; batch adversarial loss: 0.476721\n",
      "epoch 1; iter: 400; batch classifier loss: 9.246552; batch adversarial loss: 0.467898\n",
      "epoch 1; iter: 600; batch classifier loss: 2.909537; batch adversarial loss: 0.403106\n",
      "epoch 2; iter: 0; batch classifier loss: 3.683852; batch adversarial loss: 0.463973\n",
      "epoch 2; iter: 200; batch classifier loss: 4.354731; batch adversarial loss: 0.432550\n",
      "epoch 2; iter: 400; batch classifier loss: 6.065367; batch adversarial loss: 0.455452\n",
      "epoch 2; iter: 600; batch classifier loss: 0.539053; batch adversarial loss: 0.409083\n",
      "epoch 3; iter: 0; batch classifier loss: 12.843949; batch adversarial loss: 0.396708\n",
      "epoch 3; iter: 200; batch classifier loss: 3.866314; batch adversarial loss: 0.452351\n",
      "epoch 3; iter: 400; batch classifier loss: 3.184225; batch adversarial loss: 0.436050\n",
      "epoch 3; iter: 600; batch classifier loss: 1.873128; batch adversarial loss: 0.399362\n",
      "epoch 4; iter: 0; batch classifier loss: 1.922738; batch adversarial loss: 0.410054\n",
      "epoch 4; iter: 200; batch classifier loss: 0.342131; batch adversarial loss: 0.342034\n",
      "epoch 4; iter: 400; batch classifier loss: 0.481910; batch adversarial loss: 0.337791\n",
      "epoch 4; iter: 600; batch classifier loss: 0.469570; batch adversarial loss: 0.504985\n",
      "epoch 5; iter: 0; batch classifier loss: 2.526875; batch adversarial loss: 0.365745\n",
      "epoch 5; iter: 200; batch classifier loss: 1.202508; batch adversarial loss: 0.426796\n",
      "epoch 5; iter: 400; batch classifier loss: 1.223131; batch adversarial loss: 0.456021\n",
      "epoch 5; iter: 600; batch classifier loss: 2.023086; batch adversarial loss: 0.463456\n",
      "epoch 6; iter: 0; batch classifier loss: 0.767813; batch adversarial loss: 0.379035\n",
      "epoch 6; iter: 200; batch classifier loss: 1.443880; batch adversarial loss: 0.399743\n",
      "epoch 6; iter: 400; batch classifier loss: 0.316767; batch adversarial loss: 0.359531\n",
      "epoch 6; iter: 600; batch classifier loss: 0.701231; batch adversarial loss: 0.485594\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393891; batch adversarial loss: 0.477339\n",
      "epoch 7; iter: 200; batch classifier loss: 0.917203; batch adversarial loss: 0.394051\n",
      "epoch 7; iter: 400; batch classifier loss: 1.204849; batch adversarial loss: 0.408923\n",
      "epoch 7; iter: 600; batch classifier loss: 0.406304; batch adversarial loss: 0.397351\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360077; batch adversarial loss: 0.313488\n",
      "epoch 8; iter: 200; batch classifier loss: 0.446392; batch adversarial loss: 0.397417\n",
      "epoch 8; iter: 400; batch classifier loss: 0.644287; batch adversarial loss: 0.406092\n",
      "epoch 8; iter: 600; batch classifier loss: 0.258194; batch adversarial loss: 0.349291\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371289; batch adversarial loss: 0.381385\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426339; batch adversarial loss: 0.354913\n",
      "epoch 9; iter: 400; batch classifier loss: 0.443449; batch adversarial loss: 0.240170\n",
      "epoch 9; iter: 600; batch classifier loss: 0.338145; batch adversarial loss: 0.292586\n",
      "epoch 0; iter: 0; batch classifier loss: 8.052277; batch adversarial loss: 0.641288\n",
      "epoch 0; iter: 200; batch classifier loss: 9.443747; batch adversarial loss: 0.593026\n",
      "epoch 0; iter: 400; batch classifier loss: 10.722857; batch adversarial loss: 0.561145\n",
      "epoch 0; iter: 600; batch classifier loss: 6.748376; batch adversarial loss: 0.457695\n",
      "epoch 1; iter: 0; batch classifier loss: 7.510750; batch adversarial loss: 0.473807\n",
      "epoch 1; iter: 200; batch classifier loss: 4.153214; batch adversarial loss: 0.509620\n",
      "epoch 1; iter: 400; batch classifier loss: 4.008046; batch adversarial loss: 0.502679\n",
      "epoch 1; iter: 600; batch classifier loss: 1.418002; batch adversarial loss: 0.416265\n",
      "epoch 2; iter: 0; batch classifier loss: 2.096893; batch adversarial loss: 0.409852\n",
      "epoch 2; iter: 200; batch classifier loss: 1.809599; batch adversarial loss: 0.395476\n",
      "epoch 2; iter: 400; batch classifier loss: 1.675376; batch adversarial loss: 0.322893\n",
      "epoch 2; iter: 600; batch classifier loss: 2.594627; batch adversarial loss: 0.401058\n",
      "epoch 3; iter: 0; batch classifier loss: 0.528954; batch adversarial loss: 0.522322\n",
      "epoch 3; iter: 200; batch classifier loss: 0.494771; batch adversarial loss: 0.395617\n",
      "epoch 3; iter: 400; batch classifier loss: 1.091353; batch adversarial loss: 0.404097\n",
      "epoch 3; iter: 600; batch classifier loss: 0.429932; batch adversarial loss: 0.597192\n",
      "epoch 4; iter: 0; batch classifier loss: 14.688804; batch adversarial loss: 0.370119\n",
      "epoch 4; iter: 200; batch classifier loss: 2.846850; batch adversarial loss: 0.469392\n",
      "epoch 4; iter: 400; batch classifier loss: 0.634690; batch adversarial loss: 0.446543\n",
      "epoch 4; iter: 600; batch classifier loss: 0.746093; batch adversarial loss: 0.274482\n",
      "epoch 5; iter: 0; batch classifier loss: 0.441817; batch adversarial loss: 0.571032\n",
      "epoch 5; iter: 200; batch classifier loss: 0.288713; batch adversarial loss: 0.253556\n",
      "epoch 5; iter: 400; batch classifier loss: 1.086490; batch adversarial loss: 0.296477\n",
      "epoch 5; iter: 600; batch classifier loss: 0.446101; batch adversarial loss: 0.427402\n",
      "epoch 6; iter: 0; batch classifier loss: 0.282248; batch adversarial loss: 0.464960\n",
      "epoch 6; iter: 200; batch classifier loss: 0.472432; batch adversarial loss: 0.343606\n",
      "epoch 6; iter: 400; batch classifier loss: 0.317894; batch adversarial loss: 0.317397\n",
      "epoch 6; iter: 600; batch classifier loss: 0.279636; batch adversarial loss: 0.349441\n",
      "epoch 7; iter: 0; batch classifier loss: 0.767457; batch adversarial loss: 0.512391\n",
      "epoch 7; iter: 200; batch classifier loss: 0.449294; batch adversarial loss: 0.460847\n",
      "epoch 7; iter: 400; batch classifier loss: 0.452432; batch adversarial loss: 0.375663\n",
      "epoch 7; iter: 600; batch classifier loss: 0.519497; batch adversarial loss: 0.319568\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421135; batch adversarial loss: 0.270257\n",
      "epoch 8; iter: 200; batch classifier loss: 0.462801; batch adversarial loss: 0.448061\n",
      "epoch 8; iter: 400; batch classifier loss: 0.339986; batch adversarial loss: 0.455326\n",
      "epoch 8; iter: 600; batch classifier loss: 0.430152; batch adversarial loss: 0.300289\n",
      "epoch 9; iter: 0; batch classifier loss: 0.415551; batch adversarial loss: 0.433283\n",
      "epoch 9; iter: 200; batch classifier loss: 0.323624; batch adversarial loss: 0.316150\n",
      "epoch 9; iter: 400; batch classifier loss: 0.395524; batch adversarial loss: 0.398271\n",
      "epoch 9; iter: 600; batch classifier loss: 0.441580; batch adversarial loss: 0.409229\n",
      "epoch 0; iter: 0; batch classifier loss: 10.654274; batch adversarial loss: 0.692563\n",
      "epoch 0; iter: 200; batch classifier loss: 9.882707; batch adversarial loss: 0.606725\n",
      "epoch 0; iter: 400; batch classifier loss: 7.512351; batch adversarial loss: 0.528532\n",
      "epoch 0; iter: 600; batch classifier loss: 3.864355; batch adversarial loss: 0.502283\n",
      "epoch 1; iter: 0; batch classifier loss: 4.444586; batch adversarial loss: 0.516144\n",
      "epoch 1; iter: 200; batch classifier loss: 10.633583; batch adversarial loss: 0.528745\n",
      "epoch 1; iter: 400; batch classifier loss: 3.081384; batch adversarial loss: 0.423087\n",
      "epoch 1; iter: 600; batch classifier loss: 3.999424; batch adversarial loss: 0.391074\n",
      "epoch 2; iter: 0; batch classifier loss: 1.736286; batch adversarial loss: 0.499906\n",
      "epoch 2; iter: 200; batch classifier loss: 8.712153; batch adversarial loss: 0.410897\n",
      "epoch 2; iter: 400; batch classifier loss: 4.799392; batch adversarial loss: 0.491296\n",
      "epoch 2; iter: 600; batch classifier loss: 2.924285; batch adversarial loss: 0.465284\n",
      "epoch 3; iter: 0; batch classifier loss: 3.548047; batch adversarial loss: 0.476524\n",
      "epoch 3; iter: 200; batch classifier loss: 0.687190; batch adversarial loss: 0.328177\n",
      "epoch 3; iter: 400; batch classifier loss: 0.464446; batch adversarial loss: 0.528081\n",
      "epoch 3; iter: 600; batch classifier loss: 1.254770; batch adversarial loss: 0.576472\n",
      "epoch 4; iter: 0; batch classifier loss: 1.532623; batch adversarial loss: 0.408495\n",
      "epoch 4; iter: 200; batch classifier loss: 0.814997; batch adversarial loss: 0.393269\n",
      "epoch 4; iter: 400; batch classifier loss: 0.910538; batch adversarial loss: 0.380708\n",
      "epoch 4; iter: 600; batch classifier loss: 0.549071; batch adversarial loss: 0.376046\n",
      "epoch 5; iter: 0; batch classifier loss: 0.831154; batch adversarial loss: 0.377945\n",
      "epoch 5; iter: 200; batch classifier loss: 0.568909; batch adversarial loss: 0.508491\n",
      "epoch 5; iter: 400; batch classifier loss: 0.494608; batch adversarial loss: 0.404450\n",
      "epoch 5; iter: 600; batch classifier loss: 0.547305; batch adversarial loss: 0.417644\n",
      "epoch 6; iter: 0; batch classifier loss: 0.362656; batch adversarial loss: 0.418090\n",
      "epoch 6; iter: 200; batch classifier loss: 0.472375; batch adversarial loss: 0.268068\n",
      "epoch 6; iter: 400; batch classifier loss: 0.512353; batch adversarial loss: 0.395680\n",
      "epoch 6; iter: 600; batch classifier loss: 0.327211; batch adversarial loss: 0.493234\n",
      "epoch 7; iter: 0; batch classifier loss: 0.499471; batch adversarial loss: 0.358405\n",
      "epoch 7; iter: 200; batch classifier loss: 0.438069; batch adversarial loss: 0.348344\n",
      "epoch 7; iter: 400; batch classifier loss: 0.417057; batch adversarial loss: 0.492091\n",
      "epoch 7; iter: 600; batch classifier loss: 0.357325; batch adversarial loss: 0.363106\n",
      "epoch 8; iter: 0; batch classifier loss: 0.471439; batch adversarial loss: 0.301071\n",
      "epoch 8; iter: 200; batch classifier loss: 0.350345; batch adversarial loss: 0.439169\n",
      "epoch 8; iter: 400; batch classifier loss: 0.443730; batch adversarial loss: 0.380702\n",
      "epoch 8; iter: 600; batch classifier loss: 0.322816; batch adversarial loss: 0.458184\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486521; batch adversarial loss: 0.334473\n",
      "epoch 9; iter: 200; batch classifier loss: 0.365898; batch adversarial loss: 0.573066\n",
      "epoch 9; iter: 400; batch classifier loss: 0.404950; batch adversarial loss: 0.327794\n",
      "epoch 9; iter: 600; batch classifier loss: 0.370730; batch adversarial loss: 0.382785\n",
      "epoch 0; iter: 0; batch classifier loss: 81.764145; batch adversarial loss: 0.921912\n",
      "epoch 0; iter: 200; batch classifier loss: 13.426464; batch adversarial loss: 0.759671\n",
      "epoch 0; iter: 400; batch classifier loss: 6.415115; batch adversarial loss: 0.630519\n",
      "epoch 0; iter: 600; batch classifier loss: 1.897612; batch adversarial loss: 0.494288\n",
      "epoch 1; iter: 0; batch classifier loss: 7.365592; batch adversarial loss: 0.541915\n",
      "epoch 1; iter: 200; batch classifier loss: 1.818587; batch adversarial loss: 0.524593\n",
      "epoch 1; iter: 400; batch classifier loss: 0.654062; batch adversarial loss: 0.487533\n",
      "epoch 1; iter: 600; batch classifier loss: 1.590260; batch adversarial loss: 0.459081\n",
      "epoch 2; iter: 0; batch classifier loss: 1.228037; batch adversarial loss: 0.435283\n",
      "epoch 2; iter: 200; batch classifier loss: 2.908373; batch adversarial loss: 0.463306\n",
      "epoch 2; iter: 400; batch classifier loss: 5.102793; batch adversarial loss: 0.518563\n",
      "epoch 2; iter: 600; batch classifier loss: 1.110798; batch adversarial loss: 0.412102\n",
      "epoch 3; iter: 0; batch classifier loss: 2.309524; batch adversarial loss: 0.389637\n",
      "epoch 3; iter: 200; batch classifier loss: 0.848520; batch adversarial loss: 0.378554\n",
      "epoch 3; iter: 400; batch classifier loss: 0.970762; batch adversarial loss: 0.352089\n",
      "epoch 3; iter: 600; batch classifier loss: 1.476165; batch adversarial loss: 0.386924\n",
      "epoch 4; iter: 0; batch classifier loss: 1.110558; batch adversarial loss: 0.374316\n",
      "epoch 4; iter: 200; batch classifier loss: 0.977573; batch adversarial loss: 0.440621\n",
      "epoch 4; iter: 400; batch classifier loss: 0.476335; batch adversarial loss: 0.443222\n",
      "epoch 4; iter: 600; batch classifier loss: 0.363043; batch adversarial loss: 0.441778\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581576; batch adversarial loss: 0.376289\n",
      "epoch 5; iter: 200; batch classifier loss: 0.470992; batch adversarial loss: 0.354116\n",
      "epoch 5; iter: 400; batch classifier loss: 0.643531; batch adversarial loss: 0.301369\n",
      "epoch 5; iter: 600; batch classifier loss: 0.493431; batch adversarial loss: 0.517610\n",
      "epoch 6; iter: 0; batch classifier loss: 1.620511; batch adversarial loss: 0.450323\n",
      "epoch 6; iter: 200; batch classifier loss: 0.378905; batch adversarial loss: 0.410787\n",
      "epoch 6; iter: 400; batch classifier loss: 0.529813; batch adversarial loss: 0.348577\n",
      "epoch 6; iter: 600; batch classifier loss: 0.324720; batch adversarial loss: 0.490079\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498034; batch adversarial loss: 0.514936\n",
      "epoch 7; iter: 200; batch classifier loss: 0.497579; batch adversarial loss: 0.410003\n",
      "epoch 7; iter: 400; batch classifier loss: 0.701738; batch adversarial loss: 0.440682\n",
      "epoch 7; iter: 600; batch classifier loss: 0.361636; batch adversarial loss: 0.447303\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381535; batch adversarial loss: 0.355292\n",
      "epoch 8; iter: 200; batch classifier loss: 0.362539; batch adversarial loss: 0.422756\n",
      "epoch 8; iter: 400; batch classifier loss: 0.346358; batch adversarial loss: 0.436429\n",
      "epoch 8; iter: 600; batch classifier loss: 0.464213; batch adversarial loss: 0.347849\n",
      "epoch 9; iter: 0; batch classifier loss: 0.348168; batch adversarial loss: 0.394438\n",
      "epoch 9; iter: 200; batch classifier loss: 0.415394; batch adversarial loss: 0.505334\n",
      "epoch 9; iter: 400; batch classifier loss: 0.372715; batch adversarial loss: 0.324855\n",
      "epoch 9; iter: 600; batch classifier loss: 0.417782; batch adversarial loss: 0.375452\n",
      "epoch 0; iter: 0; batch classifier loss: 5.287005; batch adversarial loss: 0.465253\n",
      "epoch 0; iter: 200; batch classifier loss: 7.528845; batch adversarial loss: 0.607614\n",
      "epoch 0; iter: 400; batch classifier loss: 5.410135; batch adversarial loss: 0.567786\n",
      "epoch 0; iter: 600; batch classifier loss: 6.273761; batch adversarial loss: 0.483655\n",
      "epoch 1; iter: 0; batch classifier loss: 8.061403; batch adversarial loss: 0.529227\n",
      "epoch 1; iter: 200; batch classifier loss: 3.137838; batch adversarial loss: 0.530370\n",
      "epoch 1; iter: 400; batch classifier loss: 15.583488; batch adversarial loss: 0.527971\n",
      "epoch 1; iter: 600; batch classifier loss: 1.490721; batch adversarial loss: 0.393020\n",
      "epoch 2; iter: 0; batch classifier loss: 2.231882; batch adversarial loss: 0.391543\n",
      "epoch 2; iter: 200; batch classifier loss: 1.535258; batch adversarial loss: 0.482516\n",
      "epoch 2; iter: 400; batch classifier loss: 5.424981; batch adversarial loss: 0.308258\n",
      "epoch 2; iter: 600; batch classifier loss: 0.441560; batch adversarial loss: 0.473127\n",
      "epoch 3; iter: 0; batch classifier loss: 4.649397; batch adversarial loss: 0.421292\n",
      "epoch 3; iter: 200; batch classifier loss: 1.485529; batch adversarial loss: 0.566310\n",
      "epoch 3; iter: 400; batch classifier loss: 0.907191; batch adversarial loss: 0.367675\n",
      "epoch 3; iter: 600; batch classifier loss: 0.431364; batch adversarial loss: 0.417415\n",
      "epoch 4; iter: 0; batch classifier loss: 0.402178; batch adversarial loss: 0.449154\n",
      "epoch 4; iter: 200; batch classifier loss: 0.489397; batch adversarial loss: 0.393466\n",
      "epoch 4; iter: 400; batch classifier loss: 1.222674; batch adversarial loss: 0.371711\n",
      "epoch 4; iter: 600; batch classifier loss: 0.520051; batch adversarial loss: 0.535832\n",
      "epoch 5; iter: 0; batch classifier loss: 0.801849; batch adversarial loss: 0.552561\n",
      "epoch 5; iter: 200; batch classifier loss: 0.634546; batch adversarial loss: 0.384483\n",
      "epoch 5; iter: 400; batch classifier loss: 0.514962; batch adversarial loss: 0.412351\n",
      "epoch 5; iter: 600; batch classifier loss: 0.622363; batch adversarial loss: 0.384527\n",
      "epoch 6; iter: 0; batch classifier loss: 0.386204; batch adversarial loss: 0.468092\n",
      "epoch 6; iter: 200; batch classifier loss: 0.735242; batch adversarial loss: 0.476793\n",
      "epoch 6; iter: 400; batch classifier loss: 0.528947; batch adversarial loss: 0.502697\n",
      "epoch 6; iter: 600; batch classifier loss: 0.315395; batch adversarial loss: 0.383735\n",
      "epoch 7; iter: 0; batch classifier loss: 0.484291; batch adversarial loss: 0.484409\n",
      "epoch 7; iter: 200; batch classifier loss: 0.616729; batch adversarial loss: 0.347402\n",
      "epoch 7; iter: 400; batch classifier loss: 0.331897; batch adversarial loss: 0.432456\n",
      "epoch 7; iter: 600; batch classifier loss: 0.427157; batch adversarial loss: 0.367207\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404007; batch adversarial loss: 0.540898\n",
      "epoch 8; iter: 200; batch classifier loss: 0.383158; batch adversarial loss: 0.522693\n",
      "epoch 8; iter: 400; batch classifier loss: 0.485839; batch adversarial loss: 0.425650\n",
      "epoch 8; iter: 600; batch classifier loss: 0.245342; batch adversarial loss: 0.384183\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367628; batch adversarial loss: 0.373477\n",
      "epoch 9; iter: 200; batch classifier loss: 0.363766; batch adversarial loss: 0.409340\n",
      "epoch 9; iter: 400; batch classifier loss: 0.284812; batch adversarial loss: 0.397273\n",
      "epoch 9; iter: 600; batch classifier loss: 0.376059; batch adversarial loss: 0.377941\n",
      "epoch 0; iter: 0; batch classifier loss: 9.183434; batch adversarial loss: 0.621893\n",
      "epoch 0; iter: 200; batch classifier loss: 3.840377; batch adversarial loss: 0.600029\n",
      "epoch 0; iter: 400; batch classifier loss: 9.125859; batch adversarial loss: 0.589546\n",
      "epoch 0; iter: 600; batch classifier loss: 5.825769; batch adversarial loss: 0.466236\n",
      "epoch 1; iter: 0; batch classifier loss: 0.456871; batch adversarial loss: 0.525627\n",
      "epoch 1; iter: 200; batch classifier loss: 8.537902; batch adversarial loss: 0.508641\n",
      "epoch 1; iter: 400; batch classifier loss: 2.845609; batch adversarial loss: 0.446538\n",
      "epoch 1; iter: 600; batch classifier loss: 1.647863; batch adversarial loss: 0.586795\n",
      "epoch 2; iter: 0; batch classifier loss: 1.848995; batch adversarial loss: 0.474211\n",
      "epoch 2; iter: 200; batch classifier loss: 4.861698; batch adversarial loss: 0.477791\n",
      "epoch 2; iter: 400; batch classifier loss: 1.042715; batch adversarial loss: 0.576230\n",
      "epoch 2; iter: 600; batch classifier loss: 2.131529; batch adversarial loss: 0.399410\n",
      "epoch 3; iter: 0; batch classifier loss: 3.604382; batch adversarial loss: 0.575786\n",
      "epoch 3; iter: 200; batch classifier loss: 1.040454; batch adversarial loss: 0.480916\n",
      "epoch 3; iter: 400; batch classifier loss: 1.093814; batch adversarial loss: 0.321900\n",
      "epoch 3; iter: 600; batch classifier loss: 1.799139; batch adversarial loss: 0.448067\n",
      "epoch 4; iter: 0; batch classifier loss: 6.901123; batch adversarial loss: 0.497314\n",
      "epoch 4; iter: 200; batch classifier loss: 0.530134; batch adversarial loss: 0.440010\n",
      "epoch 4; iter: 400; batch classifier loss: 1.363550; batch adversarial loss: 0.305334\n",
      "epoch 4; iter: 600; batch classifier loss: 0.448351; batch adversarial loss: 0.565955\n",
      "epoch 5; iter: 0; batch classifier loss: 1.531531; batch adversarial loss: 0.515339\n",
      "epoch 5; iter: 200; batch classifier loss: 0.447704; batch adversarial loss: 0.388176\n",
      "epoch 5; iter: 400; batch classifier loss: 0.658901; batch adversarial loss: 0.285667\n",
      "epoch 5; iter: 600; batch classifier loss: 0.834499; batch adversarial loss: 0.364369\n",
      "epoch 6; iter: 0; batch classifier loss: 0.978323; batch adversarial loss: 0.441496\n",
      "epoch 6; iter: 200; batch classifier loss: 0.613046; batch adversarial loss: 0.474470\n",
      "epoch 6; iter: 400; batch classifier loss: 0.364236; batch adversarial loss: 0.619596\n",
      "epoch 6; iter: 600; batch classifier loss: 0.524940; batch adversarial loss: 0.557939\n",
      "epoch 7; iter: 0; batch classifier loss: 0.331570; batch adversarial loss: 0.367487\n",
      "epoch 7; iter: 200; batch classifier loss: 0.435267; batch adversarial loss: 0.393239\n",
      "epoch 7; iter: 400; batch classifier loss: 0.427920; batch adversarial loss: 0.423502\n",
      "epoch 7; iter: 600; batch classifier loss: 0.574844; batch adversarial loss: 0.421558\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404069; batch adversarial loss: 0.307516\n",
      "epoch 8; iter: 200; batch classifier loss: 0.327745; batch adversarial loss: 0.375029\n",
      "epoch 8; iter: 400; batch classifier loss: 0.328227; batch adversarial loss: 0.345214\n",
      "epoch 8; iter: 600; batch classifier loss: 0.361860; batch adversarial loss: 0.478382\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547762; batch adversarial loss: 0.421228\n",
      "epoch 9; iter: 200; batch classifier loss: 0.360472; batch adversarial loss: 0.316331\n",
      "epoch 9; iter: 400; batch classifier loss: 0.358321; batch adversarial loss: 0.422338\n",
      "epoch 9; iter: 600; batch classifier loss: 0.450919; batch adversarial loss: 0.351434\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 5.770973; batch adversarial loss: 0.593760\n",
      "epoch 0; iter: 200; batch classifier loss: 17.351801; batch adversarial loss: 0.544738\n",
      "epoch 0; iter: 400; batch classifier loss: 9.767196; batch adversarial loss: 0.471831\n",
      "epoch 0; iter: 600; batch classifier loss: 7.072000; batch adversarial loss: 0.496074\n",
      "epoch 1; iter: 0; batch classifier loss: 1.418724; batch adversarial loss: 0.496821\n",
      "epoch 1; iter: 200; batch classifier loss: 10.220446; batch adversarial loss: 0.471724\n",
      "epoch 1; iter: 400; batch classifier loss: 34.004051; batch adversarial loss: 0.454654\n",
      "epoch 1; iter: 600; batch classifier loss: 13.935113; batch adversarial loss: 0.466467\n",
      "epoch 2; iter: 0; batch classifier loss: 1.762301; batch adversarial loss: 0.410230\n",
      "epoch 2; iter: 200; batch classifier loss: 8.306655; batch adversarial loss: 0.397542\n",
      "epoch 2; iter: 400; batch classifier loss: 0.344285; batch adversarial loss: 0.342582\n",
      "epoch 2; iter: 600; batch classifier loss: 2.573242; batch adversarial loss: 0.452493\n",
      "epoch 3; iter: 0; batch classifier loss: 2.376165; batch adversarial loss: 0.300044\n",
      "epoch 3; iter: 200; batch classifier loss: 1.723953; batch adversarial loss: 0.403596\n",
      "epoch 3; iter: 400; batch classifier loss: 1.818514; batch adversarial loss: 0.373913\n",
      "epoch 3; iter: 600; batch classifier loss: 0.927252; batch adversarial loss: 0.401293\n",
      "epoch 4; iter: 0; batch classifier loss: 1.705169; batch adversarial loss: 0.481013\n",
      "epoch 4; iter: 200; batch classifier loss: 0.668631; batch adversarial loss: 0.460700\n",
      "epoch 4; iter: 400; batch classifier loss: 0.915888; batch adversarial loss: 0.404902\n",
      "epoch 4; iter: 600; batch classifier loss: 0.615465; batch adversarial loss: 0.418725\n",
      "epoch 5; iter: 0; batch classifier loss: 1.954620; batch adversarial loss: 0.467027\n",
      "epoch 5; iter: 200; batch classifier loss: 0.593428; batch adversarial loss: 0.371612\n",
      "epoch 5; iter: 400; batch classifier loss: 0.420841; batch adversarial loss: 0.328044\n",
      "epoch 5; iter: 600; batch classifier loss: 0.518919; batch adversarial loss: 0.478878\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485020; batch adversarial loss: 0.458327\n",
      "epoch 6; iter: 200; batch classifier loss: 0.434204; batch adversarial loss: 0.470999\n",
      "epoch 6; iter: 400; batch classifier loss: 0.374533; batch adversarial loss: 0.396170\n",
      "epoch 6; iter: 600; batch classifier loss: 0.528822; batch adversarial loss: 0.431237\n",
      "epoch 7; iter: 0; batch classifier loss: 0.865166; batch adversarial loss: 0.303329\n",
      "epoch 7; iter: 200; batch classifier loss: 0.892879; batch adversarial loss: 0.382603\n",
      "epoch 7; iter: 400; batch classifier loss: 0.864937; batch adversarial loss: 0.465509\n",
      "epoch 7; iter: 600; batch classifier loss: 0.505852; batch adversarial loss: 0.417774\n",
      "epoch 8; iter: 0; batch classifier loss: 0.457819; batch adversarial loss: 0.324798\n",
      "epoch 8; iter: 200; batch classifier loss: 1.333598; batch adversarial loss: 0.429562\n",
      "epoch 8; iter: 400; batch classifier loss: 0.383843; batch adversarial loss: 0.473859\n",
      "epoch 8; iter: 600; batch classifier loss: 0.396217; batch adversarial loss: 0.349345\n",
      "epoch 9; iter: 0; batch classifier loss: 0.331439; batch adversarial loss: 0.489594\n",
      "epoch 9; iter: 200; batch classifier loss: 0.422179; batch adversarial loss: 0.398686\n",
      "epoch 9; iter: 400; batch classifier loss: 0.380159; batch adversarial loss: 0.458271\n",
      "epoch 9; iter: 600; batch classifier loss: 0.383263; batch adversarial loss: 0.515530\n",
      "epoch 10; iter: 0; batch classifier loss: 0.424705; batch adversarial loss: 0.377694\n",
      "epoch 10; iter: 200; batch classifier loss: 0.332166; batch adversarial loss: 0.378258\n",
      "epoch 10; iter: 400; batch classifier loss: 0.404457; batch adversarial loss: 0.529741\n",
      "epoch 10; iter: 600; batch classifier loss: 0.359499; batch adversarial loss: 0.414881\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459807; batch adversarial loss: 0.581681\n",
      "epoch 11; iter: 200; batch classifier loss: 0.369012; batch adversarial loss: 0.464691\n",
      "epoch 11; iter: 400; batch classifier loss: 0.396637; batch adversarial loss: 0.451704\n",
      "epoch 11; iter: 600; batch classifier loss: 0.475085; batch adversarial loss: 0.319270\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361938; batch adversarial loss: 0.462695\n",
      "epoch 12; iter: 200; batch classifier loss: 0.488524; batch adversarial loss: 0.487230\n",
      "epoch 12; iter: 400; batch classifier loss: 0.293756; batch adversarial loss: 0.369683\n",
      "epoch 12; iter: 600; batch classifier loss: 0.285690; batch adversarial loss: 0.346799\n",
      "epoch 13; iter: 0; batch classifier loss: 0.294275; batch adversarial loss: 0.461870\n",
      "epoch 13; iter: 200; batch classifier loss: 0.289546; batch adversarial loss: 0.435574\n",
      "epoch 13; iter: 400; batch classifier loss: 0.334061; batch adversarial loss: 0.448517\n",
      "epoch 13; iter: 600; batch classifier loss: 0.455553; batch adversarial loss: 0.490715\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389991; batch adversarial loss: 0.489348\n",
      "epoch 14; iter: 200; batch classifier loss: 0.485527; batch adversarial loss: 0.393936\n",
      "epoch 14; iter: 400; batch classifier loss: 0.319093; batch adversarial loss: 0.462890\n",
      "epoch 14; iter: 600; batch classifier loss: 0.455919; batch adversarial loss: 0.407304\n",
      "epoch 15; iter: 0; batch classifier loss: 0.447984; batch adversarial loss: 0.341233\n",
      "epoch 15; iter: 200; batch classifier loss: 0.260717; batch adversarial loss: 0.433833\n",
      "epoch 15; iter: 400; batch classifier loss: 0.384097; batch adversarial loss: 0.400745\n",
      "epoch 15; iter: 600; batch classifier loss: 0.295625; batch adversarial loss: 0.463176\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378401; batch adversarial loss: 0.452422\n",
      "epoch 16; iter: 200; batch classifier loss: 0.416543; batch adversarial loss: 0.319242\n",
      "epoch 16; iter: 400; batch classifier loss: 0.308817; batch adversarial loss: 0.457848\n",
      "epoch 16; iter: 600; batch classifier loss: 0.598587; batch adversarial loss: 0.429776\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524702; batch adversarial loss: 0.536733\n",
      "epoch 17; iter: 200; batch classifier loss: 0.418691; batch adversarial loss: 0.426568\n",
      "epoch 17; iter: 400; batch classifier loss: 0.418046; batch adversarial loss: 0.292603\n",
      "epoch 17; iter: 600; batch classifier loss: 0.395500; batch adversarial loss: 0.317209\n",
      "epoch 18; iter: 0; batch classifier loss: 0.387296; batch adversarial loss: 0.371979\n",
      "epoch 18; iter: 200; batch classifier loss: 0.398352; batch adversarial loss: 0.368490\n",
      "epoch 18; iter: 400; batch classifier loss: 0.460445; batch adversarial loss: 0.345421\n",
      "epoch 18; iter: 600; batch classifier loss: 0.362406; batch adversarial loss: 0.461331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.515027; batch adversarial loss: 0.347372\n",
      "epoch 19; iter: 200; batch classifier loss: 0.322342; batch adversarial loss: 0.475782\n",
      "epoch 19; iter: 400; batch classifier loss: 0.275298; batch adversarial loss: 0.270179\n",
      "epoch 19; iter: 600; batch classifier loss: 0.591435; batch adversarial loss: 0.508278\n",
      "epoch 0; iter: 0; batch classifier loss: 5.666380; batch adversarial loss: 0.683852\n",
      "epoch 0; iter: 200; batch classifier loss: 5.285603; batch adversarial loss: 0.625324\n",
      "epoch 0; iter: 400; batch classifier loss: 25.818871; batch adversarial loss: 0.536176\n",
      "epoch 0; iter: 600; batch classifier loss: 4.479221; batch adversarial loss: 0.436800\n",
      "epoch 1; iter: 0; batch classifier loss: 21.507597; batch adversarial loss: 0.464687\n",
      "epoch 1; iter: 200; batch classifier loss: 8.005114; batch adversarial loss: 0.408511\n",
      "epoch 1; iter: 400; batch classifier loss: 3.152092; batch adversarial loss: 0.403164\n",
      "epoch 1; iter: 600; batch classifier loss: 1.583807; batch adversarial loss: 0.380786\n",
      "epoch 2; iter: 0; batch classifier loss: 1.755580; batch adversarial loss: 0.511890\n",
      "epoch 2; iter: 200; batch classifier loss: 15.389478; batch adversarial loss: 0.488650\n",
      "epoch 2; iter: 400; batch classifier loss: 2.620504; batch adversarial loss: 0.334615\n",
      "epoch 2; iter: 600; batch classifier loss: 35.084061; batch adversarial loss: 0.436180\n",
      "epoch 3; iter: 0; batch classifier loss: 1.331748; batch adversarial loss: 0.341540\n",
      "epoch 3; iter: 200; batch classifier loss: 3.198872; batch adversarial loss: 0.347980\n",
      "epoch 3; iter: 400; batch classifier loss: 1.805905; batch adversarial loss: 0.495692\n",
      "epoch 3; iter: 600; batch classifier loss: 1.240261; batch adversarial loss: 0.342726\n",
      "epoch 4; iter: 0; batch classifier loss: 2.379746; batch adversarial loss: 0.498446\n",
      "epoch 4; iter: 200; batch classifier loss: 1.698738; batch adversarial loss: 0.262992\n",
      "epoch 4; iter: 400; batch classifier loss: 0.809588; batch adversarial loss: 0.454345\n",
      "epoch 4; iter: 600; batch classifier loss: 0.528995; batch adversarial loss: 0.557271\n",
      "epoch 5; iter: 0; batch classifier loss: 1.005394; batch adversarial loss: 0.238417\n",
      "epoch 5; iter: 200; batch classifier loss: 0.324606; batch adversarial loss: 0.358366\n",
      "epoch 5; iter: 400; batch classifier loss: 1.177751; batch adversarial loss: 0.537030\n",
      "epoch 5; iter: 600; batch classifier loss: 0.287334; batch adversarial loss: 0.433786\n",
      "epoch 6; iter: 0; batch classifier loss: 0.463360; batch adversarial loss: 0.471173\n",
      "epoch 6; iter: 200; batch classifier loss: 0.513184; batch adversarial loss: 0.501638\n",
      "epoch 6; iter: 400; batch classifier loss: 0.446750; batch adversarial loss: 0.433691\n",
      "epoch 6; iter: 600; batch classifier loss: 0.454436; batch adversarial loss: 0.334969\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491983; batch adversarial loss: 0.475954\n",
      "epoch 7; iter: 200; batch classifier loss: 0.425824; batch adversarial loss: 0.429098\n",
      "epoch 7; iter: 400; batch classifier loss: 0.467561; batch adversarial loss: 0.502193\n",
      "epoch 7; iter: 600; batch classifier loss: 0.444604; batch adversarial loss: 0.521758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.396929; batch adversarial loss: 0.445548\n",
      "epoch 8; iter: 200; batch classifier loss: 0.423806; batch adversarial loss: 0.511677\n",
      "epoch 8; iter: 400; batch classifier loss: 0.407381; batch adversarial loss: 0.398243\n",
      "epoch 8; iter: 600; batch classifier loss: 0.391595; batch adversarial loss: 0.457827\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361351; batch adversarial loss: 0.393864\n",
      "epoch 9; iter: 200; batch classifier loss: 0.289749; batch adversarial loss: 0.595931\n",
      "epoch 9; iter: 400; batch classifier loss: 0.270110; batch adversarial loss: 0.378124\n",
      "epoch 9; iter: 600; batch classifier loss: 0.438826; batch adversarial loss: 0.449815\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414717; batch adversarial loss: 0.331629\n",
      "epoch 10; iter: 200; batch classifier loss: 0.406258; batch adversarial loss: 0.409109\n",
      "epoch 10; iter: 400; batch classifier loss: 0.362594; batch adversarial loss: 0.498679\n",
      "epoch 10; iter: 600; batch classifier loss: 0.343664; batch adversarial loss: 0.402633\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368276; batch adversarial loss: 0.276942\n",
      "epoch 11; iter: 200; batch classifier loss: 0.375182; batch adversarial loss: 0.540000\n",
      "epoch 11; iter: 400; batch classifier loss: 0.352321; batch adversarial loss: 0.426607\n",
      "epoch 11; iter: 600; batch classifier loss: 0.286971; batch adversarial loss: 0.297369\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397999; batch adversarial loss: 0.317805\n",
      "epoch 12; iter: 200; batch classifier loss: 0.242928; batch adversarial loss: 0.437757\n",
      "epoch 12; iter: 400; batch classifier loss: 0.366011; batch adversarial loss: 0.422959\n",
      "epoch 12; iter: 600; batch classifier loss: 0.421014; batch adversarial loss: 0.268438\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329813; batch adversarial loss: 0.339321\n",
      "epoch 13; iter: 200; batch classifier loss: 0.289389; batch adversarial loss: 0.416781\n",
      "epoch 13; iter: 400; batch classifier loss: 0.297658; batch adversarial loss: 0.569921\n",
      "epoch 13; iter: 600; batch classifier loss: 0.320099; batch adversarial loss: 0.447762\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350394; batch adversarial loss: 0.385064\n",
      "epoch 14; iter: 200; batch classifier loss: 0.437023; batch adversarial loss: 0.359592\n",
      "epoch 14; iter: 400; batch classifier loss: 0.272654; batch adversarial loss: 0.557643\n",
      "epoch 14; iter: 600; batch classifier loss: 0.379163; batch adversarial loss: 0.508648\n",
      "epoch 15; iter: 0; batch classifier loss: 0.313660; batch adversarial loss: 0.488427\n",
      "epoch 15; iter: 200; batch classifier loss: 0.610496; batch adversarial loss: 0.504520\n",
      "epoch 15; iter: 400; batch classifier loss: 0.445598; batch adversarial loss: 0.400291\n",
      "epoch 15; iter: 600; batch classifier loss: 0.314777; batch adversarial loss: 0.398804\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378680; batch adversarial loss: 0.457764\n",
      "epoch 16; iter: 200; batch classifier loss: 0.314766; batch adversarial loss: 0.358492\n",
      "epoch 16; iter: 400; batch classifier loss: 0.482923; batch adversarial loss: 0.476464\n",
      "epoch 16; iter: 600; batch classifier loss: 0.367783; batch adversarial loss: 0.378731\n",
      "epoch 17; iter: 0; batch classifier loss: 0.298278; batch adversarial loss: 0.391130\n",
      "epoch 17; iter: 200; batch classifier loss: 0.391530; batch adversarial loss: 0.322711\n",
      "epoch 17; iter: 400; batch classifier loss: 0.456922; batch adversarial loss: 0.469444\n",
      "epoch 17; iter: 600; batch classifier loss: 0.347255; batch adversarial loss: 0.385447\n",
      "epoch 18; iter: 0; batch classifier loss: 0.594590; batch adversarial loss: 0.371896\n",
      "epoch 18; iter: 200; batch classifier loss: 0.401365; batch adversarial loss: 0.269641\n",
      "epoch 18; iter: 400; batch classifier loss: 0.428900; batch adversarial loss: 0.378438\n",
      "epoch 18; iter: 600; batch classifier loss: 0.416489; batch adversarial loss: 0.455644\n",
      "epoch 19; iter: 0; batch classifier loss: 0.542513; batch adversarial loss: 0.375028\n",
      "epoch 19; iter: 200; batch classifier loss: 0.523077; batch adversarial loss: 0.430168\n",
      "epoch 19; iter: 400; batch classifier loss: 0.464392; batch adversarial loss: 0.545284\n",
      "epoch 19; iter: 600; batch classifier loss: 0.422847; batch adversarial loss: 0.378912\n",
      "epoch 0; iter: 0; batch classifier loss: 8.674612; batch adversarial loss: 0.746905\n",
      "epoch 0; iter: 200; batch classifier loss: 0.900362; batch adversarial loss: 0.629364\n",
      "epoch 0; iter: 400; batch classifier loss: 8.854441; batch adversarial loss: 0.536350\n",
      "epoch 0; iter: 600; batch classifier loss: 2.148884; batch adversarial loss: 0.546816\n",
      "epoch 1; iter: 0; batch classifier loss: 8.236089; batch adversarial loss: 0.494346\n",
      "epoch 1; iter: 200; batch classifier loss: 0.809226; batch adversarial loss: 0.510446\n",
      "epoch 1; iter: 400; batch classifier loss: 3.332522; batch adversarial loss: 0.479370\n",
      "epoch 1; iter: 600; batch classifier loss: 1.918954; batch adversarial loss: 0.424407\n",
      "epoch 2; iter: 0; batch classifier loss: 16.594130; batch adversarial loss: 0.456912\n",
      "epoch 2; iter: 200; batch classifier loss: 2.909585; batch adversarial loss: 0.468974\n",
      "epoch 2; iter: 400; batch classifier loss: 6.536139; batch adversarial loss: 0.375810\n",
      "epoch 2; iter: 600; batch classifier loss: 1.438104; batch adversarial loss: 0.365511\n",
      "epoch 3; iter: 0; batch classifier loss: 2.121942; batch adversarial loss: 0.396449\n",
      "epoch 3; iter: 200; batch classifier loss: 1.030119; batch adversarial loss: 0.391263\n",
      "epoch 3; iter: 400; batch classifier loss: 1.750503; batch adversarial loss: 0.486111\n",
      "epoch 3; iter: 600; batch classifier loss: 0.697246; batch adversarial loss: 0.427884\n",
      "epoch 4; iter: 0; batch classifier loss: 1.628099; batch adversarial loss: 0.583475\n",
      "epoch 4; iter: 200; batch classifier loss: 1.721612; batch adversarial loss: 0.427281\n",
      "epoch 4; iter: 400; batch classifier loss: 0.718235; batch adversarial loss: 0.381403\n",
      "epoch 4; iter: 600; batch classifier loss: 0.476871; batch adversarial loss: 0.274002\n",
      "epoch 5; iter: 0; batch classifier loss: 0.401791; batch adversarial loss: 0.399989\n",
      "epoch 5; iter: 200; batch classifier loss: 0.670025; batch adversarial loss: 0.461569\n",
      "epoch 5; iter: 400; batch classifier loss: 0.496922; batch adversarial loss: 0.372707\n",
      "epoch 5; iter: 600; batch classifier loss: 0.501613; batch adversarial loss: 0.407551\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543058; batch adversarial loss: 0.503723\n",
      "epoch 6; iter: 200; batch classifier loss: 0.457605; batch adversarial loss: 0.407332\n",
      "epoch 6; iter: 400; batch classifier loss: 0.344145; batch adversarial loss: 0.481085\n",
      "epoch 6; iter: 600; batch classifier loss: 0.339995; batch adversarial loss: 0.530919\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360213; batch adversarial loss: 0.426845\n",
      "epoch 7; iter: 200; batch classifier loss: 0.320449; batch adversarial loss: 0.355589\n",
      "epoch 7; iter: 400; batch classifier loss: 0.648591; batch adversarial loss: 0.394975\n",
      "epoch 7; iter: 600; batch classifier loss: 0.459730; batch adversarial loss: 0.592613\n",
      "epoch 8; iter: 0; batch classifier loss: 0.374837; batch adversarial loss: 0.447879\n",
      "epoch 8; iter: 200; batch classifier loss: 0.422581; batch adversarial loss: 0.470412\n",
      "epoch 8; iter: 400; batch classifier loss: 0.301366; batch adversarial loss: 0.432073\n",
      "epoch 8; iter: 600; batch classifier loss: 0.438823; batch adversarial loss: 0.402466\n",
      "epoch 9; iter: 0; batch classifier loss: 0.353153; batch adversarial loss: 0.477965\n",
      "epoch 9; iter: 200; batch classifier loss: 0.320699; batch adversarial loss: 0.370346\n",
      "epoch 9; iter: 400; batch classifier loss: 0.367642; batch adversarial loss: 0.447779\n",
      "epoch 9; iter: 600; batch classifier loss: 0.253859; batch adversarial loss: 0.580611\n",
      "epoch 10; iter: 0; batch classifier loss: 0.417224; batch adversarial loss: 0.289018\n",
      "epoch 10; iter: 200; batch classifier loss: 0.320322; batch adversarial loss: 0.378185\n",
      "epoch 10; iter: 400; batch classifier loss: 0.305016; batch adversarial loss: 0.348747\n",
      "epoch 10; iter: 600; batch classifier loss: 0.360499; batch adversarial loss: 0.257890\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346213; batch adversarial loss: 0.467502\n",
      "epoch 11; iter: 200; batch classifier loss: 0.275707; batch adversarial loss: 0.316725\n",
      "epoch 11; iter: 400; batch classifier loss: 0.310049; batch adversarial loss: 0.322980\n",
      "epoch 11; iter: 600; batch classifier loss: 0.367046; batch adversarial loss: 0.431164\n",
      "epoch 12; iter: 0; batch classifier loss: 0.346002; batch adversarial loss: 0.622094\n",
      "epoch 12; iter: 200; batch classifier loss: 0.279029; batch adversarial loss: 0.447335\n",
      "epoch 12; iter: 400; batch classifier loss: 0.404787; batch adversarial loss: 0.396427\n",
      "epoch 12; iter: 600; batch classifier loss: 0.287028; batch adversarial loss: 0.341261\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342976; batch adversarial loss: 0.415953\n",
      "epoch 13; iter: 200; batch classifier loss: 0.347132; batch adversarial loss: 0.466122\n",
      "epoch 13; iter: 400; batch classifier loss: 0.269066; batch adversarial loss: 0.490846\n",
      "epoch 13; iter: 600; batch classifier loss: 0.333075; batch adversarial loss: 0.352912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.260290; batch adversarial loss: 0.467971\n",
      "epoch 14; iter: 200; batch classifier loss: 0.308319; batch adversarial loss: 0.452976\n",
      "epoch 14; iter: 400; batch classifier loss: 0.461959; batch adversarial loss: 0.444189\n",
      "epoch 14; iter: 600; batch classifier loss: 0.302448; batch adversarial loss: 0.525831\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350364; batch adversarial loss: 0.466261\n",
      "epoch 15; iter: 200; batch classifier loss: 0.435146; batch adversarial loss: 0.353630\n",
      "epoch 15; iter: 400; batch classifier loss: 0.420142; batch adversarial loss: 0.425329\n",
      "epoch 15; iter: 600; batch classifier loss: 0.300072; batch adversarial loss: 0.441720\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331641; batch adversarial loss: 0.365417\n",
      "epoch 16; iter: 200; batch classifier loss: 0.360727; batch adversarial loss: 0.302345\n",
      "epoch 16; iter: 400; batch classifier loss: 0.247972; batch adversarial loss: 0.424513\n",
      "epoch 16; iter: 600; batch classifier loss: 0.288275; batch adversarial loss: 0.513235\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287904; batch adversarial loss: 0.372286\n",
      "epoch 17; iter: 200; batch classifier loss: 0.285331; batch adversarial loss: 0.423499\n",
      "epoch 17; iter: 400; batch classifier loss: 0.356012; batch adversarial loss: 0.400894\n",
      "epoch 17; iter: 600; batch classifier loss: 0.426034; batch adversarial loss: 0.406318\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325164; batch adversarial loss: 0.453803\n",
      "epoch 18; iter: 200; batch classifier loss: 0.416746; batch adversarial loss: 0.298674\n",
      "epoch 18; iter: 400; batch classifier loss: 0.345860; batch adversarial loss: 0.583425\n",
      "epoch 18; iter: 600; batch classifier loss: 0.366481; batch adversarial loss: 0.442977\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520883; batch adversarial loss: 0.390069\n",
      "epoch 19; iter: 200; batch classifier loss: 0.330087; batch adversarial loss: 0.530282\n",
      "epoch 19; iter: 400; batch classifier loss: 0.441223; batch adversarial loss: 0.383079\n",
      "epoch 19; iter: 600; batch classifier loss: 0.511271; batch adversarial loss: 0.454256\n",
      "epoch 0; iter: 0; batch classifier loss: 93.732727; batch adversarial loss: 0.658479\n",
      "epoch 0; iter: 200; batch classifier loss: 3.063173; batch adversarial loss: 0.577654\n",
      "epoch 0; iter: 400; batch classifier loss: 14.715498; batch adversarial loss: 0.520732\n",
      "epoch 0; iter: 600; batch classifier loss: 4.446518; batch adversarial loss: 0.559478\n",
      "epoch 1; iter: 0; batch classifier loss: 7.961946; batch adversarial loss: 0.507964\n",
      "epoch 1; iter: 200; batch classifier loss: 4.754489; batch adversarial loss: 0.574412\n",
      "epoch 1; iter: 400; batch classifier loss: 2.006999; batch adversarial loss: 0.455387\n",
      "epoch 1; iter: 600; batch classifier loss: 11.282188; batch adversarial loss: 0.478704\n",
      "epoch 2; iter: 0; batch classifier loss: 1.916922; batch adversarial loss: 0.432957\n",
      "epoch 2; iter: 200; batch classifier loss: 6.388334; batch adversarial loss: 0.599420\n",
      "epoch 2; iter: 400; batch classifier loss: 0.784066; batch adversarial loss: 0.289824\n",
      "epoch 2; iter: 600; batch classifier loss: 2.218664; batch adversarial loss: 0.344825\n",
      "epoch 3; iter: 0; batch classifier loss: 0.936261; batch adversarial loss: 0.406749\n",
      "epoch 3; iter: 200; batch classifier loss: 1.964974; batch adversarial loss: 0.466224\n",
      "epoch 3; iter: 400; batch classifier loss: 0.908465; batch adversarial loss: 0.524634\n",
      "epoch 3; iter: 600; batch classifier loss: 1.797106; batch adversarial loss: 0.320137\n",
      "epoch 4; iter: 0; batch classifier loss: 0.894480; batch adversarial loss: 0.419095\n",
      "epoch 4; iter: 200; batch classifier loss: 0.708216; batch adversarial loss: 0.346623\n",
      "epoch 4; iter: 400; batch classifier loss: 2.680455; batch adversarial loss: 0.435158\n",
      "epoch 4; iter: 600; batch classifier loss: 1.057627; batch adversarial loss: 0.281296\n",
      "epoch 5; iter: 0; batch classifier loss: 0.408258; batch adversarial loss: 0.455623\n",
      "epoch 5; iter: 200; batch classifier loss: 1.350976; batch adversarial loss: 0.277941\n",
      "epoch 5; iter: 400; batch classifier loss: 0.703460; batch adversarial loss: 0.368398\n",
      "epoch 5; iter: 600; batch classifier loss: 0.441712; batch adversarial loss: 0.452316\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549814; batch adversarial loss: 0.463774\n",
      "epoch 6; iter: 200; batch classifier loss: 0.808284; batch adversarial loss: 0.387668\n",
      "epoch 6; iter: 400; batch classifier loss: 0.664642; batch adversarial loss: 0.433238\n",
      "epoch 6; iter: 600; batch classifier loss: 0.482911; batch adversarial loss: 0.297954\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514360; batch adversarial loss: 0.464451\n",
      "epoch 7; iter: 200; batch classifier loss: 0.538336; batch adversarial loss: 0.375159\n",
      "epoch 7; iter: 400; batch classifier loss: 0.489722; batch adversarial loss: 0.375034\n",
      "epoch 7; iter: 600; batch classifier loss: 0.370309; batch adversarial loss: 0.512677\n",
      "epoch 8; iter: 0; batch classifier loss: 0.410380; batch adversarial loss: 0.449728\n",
      "epoch 8; iter: 200; batch classifier loss: 0.379132; batch adversarial loss: 0.379375\n",
      "epoch 8; iter: 400; batch classifier loss: 0.386020; batch adversarial loss: 0.451789\n",
      "epoch 8; iter: 600; batch classifier loss: 0.345898; batch adversarial loss: 0.516154\n",
      "epoch 9; iter: 0; batch classifier loss: 0.400601; batch adversarial loss: 0.338994\n",
      "epoch 9; iter: 200; batch classifier loss: 0.448530; batch adversarial loss: 0.438664\n",
      "epoch 9; iter: 400; batch classifier loss: 0.371302; batch adversarial loss: 0.398163\n",
      "epoch 9; iter: 600; batch classifier loss: 0.314327; batch adversarial loss: 0.533126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.328797; batch adversarial loss: 0.555084\n",
      "epoch 10; iter: 200; batch classifier loss: 0.343790; batch adversarial loss: 0.412445\n",
      "epoch 10; iter: 400; batch classifier loss: 0.275262; batch adversarial loss: 0.427085\n",
      "epoch 10; iter: 600; batch classifier loss: 0.369551; batch adversarial loss: 0.446663\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364863; batch adversarial loss: 0.406194\n",
      "epoch 11; iter: 200; batch classifier loss: 0.381986; batch adversarial loss: 0.435620\n",
      "epoch 11; iter: 400; batch classifier loss: 0.455792; batch adversarial loss: 0.461056\n",
      "epoch 11; iter: 600; batch classifier loss: 0.321646; batch adversarial loss: 0.376744\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350611; batch adversarial loss: 0.377068\n",
      "epoch 12; iter: 200; batch classifier loss: 0.319361; batch adversarial loss: 0.423496\n",
      "epoch 12; iter: 400; batch classifier loss: 0.344792; batch adversarial loss: 0.399038\n",
      "epoch 12; iter: 600; batch classifier loss: 0.270198; batch adversarial loss: 0.347721\n",
      "epoch 13; iter: 0; batch classifier loss: 0.436393; batch adversarial loss: 0.453128\n",
      "epoch 13; iter: 200; batch classifier loss: 0.299916; batch adversarial loss: 0.352233\n",
      "epoch 13; iter: 400; batch classifier loss: 0.449626; batch adversarial loss: 0.486074\n",
      "epoch 13; iter: 600; batch classifier loss: 0.318817; batch adversarial loss: 0.414957\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350894; batch adversarial loss: 0.464391\n",
      "epoch 14; iter: 200; batch classifier loss: 0.326343; batch adversarial loss: 0.486694\n",
      "epoch 14; iter: 400; batch classifier loss: 0.292805; batch adversarial loss: 0.449753\n",
      "epoch 14; iter: 600; batch classifier loss: 0.312470; batch adversarial loss: 0.505382\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529409; batch adversarial loss: 0.354366\n",
      "epoch 15; iter: 200; batch classifier loss: 0.423086; batch adversarial loss: 0.295448\n",
      "epoch 15; iter: 400; batch classifier loss: 0.311345; batch adversarial loss: 0.405217\n",
      "epoch 15; iter: 600; batch classifier loss: 0.323877; batch adversarial loss: 0.353100\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265780; batch adversarial loss: 0.506233\n",
      "epoch 16; iter: 200; batch classifier loss: 0.235610; batch adversarial loss: 0.451061\n",
      "epoch 16; iter: 400; batch classifier loss: 0.372551; batch adversarial loss: 0.366093\n",
      "epoch 16; iter: 600; batch classifier loss: 0.390658; batch adversarial loss: 0.399524\n",
      "epoch 17; iter: 0; batch classifier loss: 0.513550; batch adversarial loss: 0.318056\n",
      "epoch 17; iter: 200; batch classifier loss: 0.430468; batch adversarial loss: 0.446115\n",
      "epoch 17; iter: 400; batch classifier loss: 0.405430; batch adversarial loss: 0.353397\n",
      "epoch 17; iter: 600; batch classifier loss: 0.362453; batch adversarial loss: 0.410305\n",
      "epoch 18; iter: 0; batch classifier loss: 0.297681; batch adversarial loss: 0.474356\n",
      "epoch 18; iter: 200; batch classifier loss: 0.204882; batch adversarial loss: 0.318142\n",
      "epoch 18; iter: 400; batch classifier loss: 0.284159; batch adversarial loss: 0.454088\n",
      "epoch 18; iter: 600; batch classifier loss: 0.417883; batch adversarial loss: 0.465800\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457437; batch adversarial loss: 0.458415\n",
      "epoch 19; iter: 200; batch classifier loss: 0.195169; batch adversarial loss: 0.454344\n",
      "epoch 19; iter: 400; batch classifier loss: 0.293651; batch adversarial loss: 0.349635\n",
      "epoch 19; iter: 600; batch classifier loss: 0.426802; batch adversarial loss: 0.402621\n",
      "epoch 0; iter: 0; batch classifier loss: 38.944946; batch adversarial loss: 0.737207\n",
      "epoch 0; iter: 200; batch classifier loss: 8.804304; batch adversarial loss: 0.642538\n",
      "epoch 0; iter: 400; batch classifier loss: 17.627548; batch adversarial loss: 0.575010\n",
      "epoch 0; iter: 600; batch classifier loss: 1.172989; batch adversarial loss: 0.590383\n",
      "epoch 1; iter: 0; batch classifier loss: 12.239427; batch adversarial loss: 0.540027\n",
      "epoch 1; iter: 200; batch classifier loss: 5.106028; batch adversarial loss: 0.469895\n",
      "epoch 1; iter: 400; batch classifier loss: 7.416731; batch adversarial loss: 0.537429\n",
      "epoch 1; iter: 600; batch classifier loss: 32.532833; batch adversarial loss: 0.383138\n",
      "epoch 2; iter: 0; batch classifier loss: 1.762830; batch adversarial loss: 0.422084\n",
      "epoch 2; iter: 200; batch classifier loss: 5.658360; batch adversarial loss: 0.454449\n",
      "epoch 2; iter: 400; batch classifier loss: 6.032522; batch adversarial loss: 0.425473\n",
      "epoch 2; iter: 600; batch classifier loss: 0.400359; batch adversarial loss: 0.399172\n",
      "epoch 3; iter: 0; batch classifier loss: 4.624856; batch adversarial loss: 0.443191\n",
      "epoch 3; iter: 200; batch classifier loss: 0.483854; batch adversarial loss: 0.420496\n",
      "epoch 3; iter: 400; batch classifier loss: 1.699194; batch adversarial loss: 0.529561\n",
      "epoch 3; iter: 600; batch classifier loss: 0.975656; batch adversarial loss: 0.503983\n",
      "epoch 4; iter: 0; batch classifier loss: 0.868944; batch adversarial loss: 0.526316\n",
      "epoch 4; iter: 200; batch classifier loss: 0.658664; batch adversarial loss: 0.518798\n",
      "epoch 4; iter: 400; batch classifier loss: 0.776555; batch adversarial loss: 0.516257\n",
      "epoch 4; iter: 600; batch classifier loss: 1.332514; batch adversarial loss: 0.364924\n",
      "epoch 5; iter: 0; batch classifier loss: 0.760086; batch adversarial loss: 0.486125\n",
      "epoch 5; iter: 200; batch classifier loss: 2.087105; batch adversarial loss: 0.332081\n",
      "epoch 5; iter: 400; batch classifier loss: 0.535703; batch adversarial loss: 0.373156\n",
      "epoch 5; iter: 600; batch classifier loss: 0.580958; batch adversarial loss: 0.551969\n",
      "epoch 6; iter: 0; batch classifier loss: 0.707549; batch adversarial loss: 0.492243\n",
      "epoch 6; iter: 200; batch classifier loss: 0.341958; batch adversarial loss: 0.352181\n",
      "epoch 6; iter: 400; batch classifier loss: 0.645289; batch adversarial loss: 0.247399\n",
      "epoch 6; iter: 600; batch classifier loss: 0.464665; batch adversarial loss: 0.398502\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517959; batch adversarial loss: 0.376601\n",
      "epoch 7; iter: 200; batch classifier loss: 0.402266; batch adversarial loss: 0.399268\n",
      "epoch 7; iter: 400; batch classifier loss: 0.465051; batch adversarial loss: 0.375742\n",
      "epoch 7; iter: 600; batch classifier loss: 0.597248; batch adversarial loss: 0.394558\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559151; batch adversarial loss: 0.241827\n",
      "epoch 8; iter: 200; batch classifier loss: 0.504239; batch adversarial loss: 0.349950\n",
      "epoch 8; iter: 400; batch classifier loss: 0.659384; batch adversarial loss: 0.259554\n",
      "epoch 8; iter: 600; batch classifier loss: 0.416679; batch adversarial loss: 0.535297\n",
      "epoch 9; iter: 0; batch classifier loss: 0.464787; batch adversarial loss: 0.479001\n",
      "epoch 9; iter: 200; batch classifier loss: 0.533710; batch adversarial loss: 0.563131\n",
      "epoch 9; iter: 400; batch classifier loss: 0.399241; batch adversarial loss: 0.431072\n",
      "epoch 9; iter: 600; batch classifier loss: 0.488873; batch adversarial loss: 0.341062\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572095; batch adversarial loss: 0.396726\n",
      "epoch 10; iter: 200; batch classifier loss: 0.377133; batch adversarial loss: 0.369983\n",
      "epoch 10; iter: 400; batch classifier loss: 0.414737; batch adversarial loss: 0.368726\n",
      "epoch 10; iter: 600; batch classifier loss: 0.376048; batch adversarial loss: 0.432424\n",
      "epoch 11; iter: 0; batch classifier loss: 0.279728; batch adversarial loss: 0.427032\n",
      "epoch 11; iter: 200; batch classifier loss: 0.334879; batch adversarial loss: 0.396672\n",
      "epoch 11; iter: 400; batch classifier loss: 0.387416; batch adversarial loss: 0.500647\n",
      "epoch 11; iter: 600; batch classifier loss: 0.419703; batch adversarial loss: 0.341535\n",
      "epoch 12; iter: 0; batch classifier loss: 0.342715; batch adversarial loss: 0.576014\n",
      "epoch 12; iter: 200; batch classifier loss: 0.374482; batch adversarial loss: 0.408927\n",
      "epoch 12; iter: 400; batch classifier loss: 0.385692; batch adversarial loss: 0.444193\n",
      "epoch 12; iter: 600; batch classifier loss: 0.370536; batch adversarial loss: 0.342978\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339736; batch adversarial loss: 0.314498\n",
      "epoch 13; iter: 200; batch classifier loss: 0.329332; batch adversarial loss: 0.476061\n",
      "epoch 13; iter: 400; batch classifier loss: 0.317159; batch adversarial loss: 0.434897\n",
      "epoch 13; iter: 600; batch classifier loss: 0.278033; batch adversarial loss: 0.318158\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336210; batch adversarial loss: 0.370757\n",
      "epoch 14; iter: 200; batch classifier loss: 0.370482; batch adversarial loss: 0.349531\n",
      "epoch 14; iter: 400; batch classifier loss: 0.285531; batch adversarial loss: 0.418515\n",
      "epoch 14; iter: 600; batch classifier loss: 0.238424; batch adversarial loss: 0.407492\n",
      "epoch 15; iter: 0; batch classifier loss: 0.249306; batch adversarial loss: 0.445687\n",
      "epoch 15; iter: 200; batch classifier loss: 0.418304; batch adversarial loss: 0.325102\n",
      "epoch 15; iter: 400; batch classifier loss: 0.384065; batch adversarial loss: 0.378909\n",
      "epoch 15; iter: 600; batch classifier loss: 0.397680; batch adversarial loss: 0.299054\n",
      "epoch 16; iter: 0; batch classifier loss: 0.286465; batch adversarial loss: 0.432038\n",
      "epoch 16; iter: 200; batch classifier loss: 0.508785; batch adversarial loss: 0.436581\n",
      "epoch 16; iter: 400; batch classifier loss: 0.393788; batch adversarial loss: 0.438551\n",
      "epoch 16; iter: 600; batch classifier loss: 0.342336; batch adversarial loss: 0.616438\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348556; batch adversarial loss: 0.336796\n",
      "epoch 17; iter: 200; batch classifier loss: 0.255096; batch adversarial loss: 0.353355\n",
      "epoch 17; iter: 400; batch classifier loss: 0.343834; batch adversarial loss: 0.436338\n",
      "epoch 17; iter: 600; batch classifier loss: 0.548450; batch adversarial loss: 0.474590\n",
      "epoch 18; iter: 0; batch classifier loss: 0.504504; batch adversarial loss: 0.483644\n",
      "epoch 18; iter: 200; batch classifier loss: 0.534416; batch adversarial loss: 0.485322\n",
      "epoch 18; iter: 400; batch classifier loss: 0.488706; batch adversarial loss: 0.430193\n",
      "epoch 18; iter: 600; batch classifier loss: 0.420128; batch adversarial loss: 0.551946\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430707; batch adversarial loss: 0.510609\n",
      "epoch 19; iter: 200; batch classifier loss: 0.591758; batch adversarial loss: 0.377211\n",
      "epoch 19; iter: 400; batch classifier loss: 0.490583; batch adversarial loss: 0.477963\n",
      "epoch 19; iter: 600; batch classifier loss: 0.373145; batch adversarial loss: 0.266103\n",
      "epoch 0; iter: 0; batch classifier loss: 8.302991; batch adversarial loss: 0.502988\n",
      "epoch 0; iter: 200; batch classifier loss: 3.609268; batch adversarial loss: 0.572770\n",
      "epoch 0; iter: 400; batch classifier loss: 6.538023; batch adversarial loss: 0.589873\n",
      "epoch 0; iter: 600; batch classifier loss: 5.707368; batch adversarial loss: 0.473766\n",
      "epoch 1; iter: 0; batch classifier loss: 7.121326; batch adversarial loss: 0.562544\n",
      "epoch 1; iter: 200; batch classifier loss: 6.084558; batch adversarial loss: 0.512645\n",
      "epoch 1; iter: 400; batch classifier loss: 7.120178; batch adversarial loss: 0.438754\n",
      "epoch 1; iter: 600; batch classifier loss: 4.860369; batch adversarial loss: 0.350199\n",
      "epoch 2; iter: 0; batch classifier loss: 0.468339; batch adversarial loss: 0.448677\n",
      "epoch 2; iter: 200; batch classifier loss: 4.789945; batch adversarial loss: 0.434637\n",
      "epoch 2; iter: 400; batch classifier loss: 2.706045; batch adversarial loss: 0.312746\n",
      "epoch 2; iter: 600; batch classifier loss: 1.882845; batch adversarial loss: 0.350610\n",
      "epoch 3; iter: 0; batch classifier loss: 1.644396; batch adversarial loss: 0.475579\n",
      "epoch 3; iter: 200; batch classifier loss: 0.904532; batch adversarial loss: 0.418150\n",
      "epoch 3; iter: 400; batch classifier loss: 1.116558; batch adversarial loss: 0.517498\n",
      "epoch 3; iter: 600; batch classifier loss: 1.966965; batch adversarial loss: 0.515909\n",
      "epoch 4; iter: 0; batch classifier loss: 1.150381; batch adversarial loss: 0.328326\n",
      "epoch 4; iter: 200; batch classifier loss: 0.569375; batch adversarial loss: 0.374429\n",
      "epoch 4; iter: 400; batch classifier loss: 1.505643; batch adversarial loss: 0.387698\n",
      "epoch 4; iter: 600; batch classifier loss: 0.914992; batch adversarial loss: 0.445837\n",
      "epoch 5; iter: 0; batch classifier loss: 0.946605; batch adversarial loss: 0.359296\n",
      "epoch 5; iter: 200; batch classifier loss: 0.826553; batch adversarial loss: 0.373714\n",
      "epoch 5; iter: 400; batch classifier loss: 0.350231; batch adversarial loss: 0.400727\n",
      "epoch 5; iter: 600; batch classifier loss: 0.499235; batch adversarial loss: 0.399498\n",
      "epoch 6; iter: 0; batch classifier loss: 0.417807; batch adversarial loss: 0.312206\n",
      "epoch 6; iter: 200; batch classifier loss: 0.571905; batch adversarial loss: 0.520615\n",
      "epoch 6; iter: 400; batch classifier loss: 0.347179; batch adversarial loss: 0.369046\n",
      "epoch 6; iter: 600; batch classifier loss: 0.412561; batch adversarial loss: 0.333499\n",
      "epoch 7; iter: 0; batch classifier loss: 0.313130; batch adversarial loss: 0.450685\n",
      "epoch 7; iter: 200; batch classifier loss: 0.359192; batch adversarial loss: 0.558700\n",
      "epoch 7; iter: 400; batch classifier loss: 0.394390; batch adversarial loss: 0.352914\n",
      "epoch 7; iter: 600; batch classifier loss: 0.434423; batch adversarial loss: 0.522516\n",
      "epoch 8; iter: 0; batch classifier loss: 0.312477; batch adversarial loss: 0.391388\n",
      "epoch 8; iter: 200; batch classifier loss: 0.494239; batch adversarial loss: 0.310341\n",
      "epoch 8; iter: 400; batch classifier loss: 0.458788; batch adversarial loss: 0.290556\n",
      "epoch 8; iter: 600; batch classifier loss: 0.448125; batch adversarial loss: 0.376954\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449885; batch adversarial loss: 0.470504\n",
      "epoch 9; iter: 200; batch classifier loss: 0.722771; batch adversarial loss: 0.385464\n",
      "epoch 9; iter: 400; batch classifier loss: 0.281771; batch adversarial loss: 0.571845\n",
      "epoch 9; iter: 600; batch classifier loss: 0.326328; batch adversarial loss: 0.389226\n",
      "epoch 10; iter: 0; batch classifier loss: 0.259679; batch adversarial loss: 0.379749\n",
      "epoch 10; iter: 200; batch classifier loss: 0.279360; batch adversarial loss: 0.439801\n",
      "epoch 10; iter: 400; batch classifier loss: 0.466090; batch adversarial loss: 0.518354\n",
      "epoch 10; iter: 600; batch classifier loss: 0.299289; batch adversarial loss: 0.439691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393121; batch adversarial loss: 0.373686\n",
      "epoch 11; iter: 200; batch classifier loss: 0.183417; batch adversarial loss: 0.515985\n",
      "epoch 11; iter: 400; batch classifier loss: 0.323892; batch adversarial loss: 0.462318\n",
      "epoch 11; iter: 600; batch classifier loss: 0.338188; batch adversarial loss: 0.319441\n",
      "epoch 12; iter: 0; batch classifier loss: 0.281128; batch adversarial loss: 0.363683\n",
      "epoch 12; iter: 200; batch classifier loss: 0.363105; batch adversarial loss: 0.499185\n",
      "epoch 12; iter: 400; batch classifier loss: 0.263465; batch adversarial loss: 0.319042\n",
      "epoch 12; iter: 600; batch classifier loss: 0.370391; batch adversarial loss: 0.430333\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342473; batch adversarial loss: 0.332863\n",
      "epoch 13; iter: 200; batch classifier loss: 0.378933; batch adversarial loss: 0.422336\n",
      "epoch 13; iter: 400; batch classifier loss: 0.303798; batch adversarial loss: 0.346863\n",
      "epoch 13; iter: 600; batch classifier loss: 0.604077; batch adversarial loss: 0.475396\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344369; batch adversarial loss: 0.477868\n",
      "epoch 14; iter: 200; batch classifier loss: 0.306087; batch adversarial loss: 0.434747\n",
      "epoch 14; iter: 400; batch classifier loss: 0.321134; batch adversarial loss: 0.422813\n",
      "epoch 14; iter: 600; batch classifier loss: 0.355961; batch adversarial loss: 0.295155\n",
      "epoch 15; iter: 0; batch classifier loss: 0.374860; batch adversarial loss: 0.371599\n",
      "epoch 15; iter: 200; batch classifier loss: 0.296006; batch adversarial loss: 0.443334\n",
      "epoch 15; iter: 400; batch classifier loss: 0.567631; batch adversarial loss: 0.375921\n",
      "epoch 15; iter: 600; batch classifier loss: 0.331980; batch adversarial loss: 0.327279\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442946; batch adversarial loss: 0.528432\n",
      "epoch 16; iter: 200; batch classifier loss: 0.462547; batch adversarial loss: 0.519261\n",
      "epoch 16; iter: 400; batch classifier loss: 0.298321; batch adversarial loss: 0.405015\n",
      "epoch 16; iter: 600; batch classifier loss: 0.517065; batch adversarial loss: 0.455770\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526744; batch adversarial loss: 0.537385\n",
      "epoch 17; iter: 200; batch classifier loss: 0.344069; batch adversarial loss: 0.602054\n",
      "epoch 17; iter: 400; batch classifier loss: 0.373471; batch adversarial loss: 0.380747\n",
      "epoch 17; iter: 600; batch classifier loss: 0.353789; batch adversarial loss: 0.460323\n",
      "epoch 18; iter: 0; batch classifier loss: 0.379193; batch adversarial loss: 0.354380\n",
      "epoch 18; iter: 200; batch classifier loss: 0.358744; batch adversarial loss: 0.439740\n",
      "epoch 18; iter: 400; batch classifier loss: 0.404705; batch adversarial loss: 0.368429\n",
      "epoch 18; iter: 600; batch classifier loss: 0.396743; batch adversarial loss: 0.347351\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356185; batch adversarial loss: 0.489949\n",
      "epoch 19; iter: 200; batch classifier loss: 0.535642; batch adversarial loss: 0.462082\n",
      "epoch 19; iter: 400; batch classifier loss: 0.457309; batch adversarial loss: 0.402115\n",
      "epoch 19; iter: 600; batch classifier loss: 0.471083; batch adversarial loss: 0.361987\n",
      "epoch 0; iter: 0; batch classifier loss: 62.218689; batch adversarial loss: 0.855646\n",
      "epoch 0; iter: 200; batch classifier loss: 11.867417; batch adversarial loss: 0.846970\n",
      "epoch 0; iter: 400; batch classifier loss: 6.621295; batch adversarial loss: 0.667811\n",
      "epoch 0; iter: 600; batch classifier loss: 5.457199; batch adversarial loss: 0.568925\n",
      "epoch 1; iter: 0; batch classifier loss: 5.830394; batch adversarial loss: 0.557259\n",
      "epoch 1; iter: 200; batch classifier loss: 2.608628; batch adversarial loss: 0.533705\n",
      "epoch 1; iter: 400; batch classifier loss: 0.185380; batch adversarial loss: 0.459434\n",
      "epoch 1; iter: 600; batch classifier loss: 3.627424; batch adversarial loss: 0.434700\n",
      "epoch 2; iter: 0; batch classifier loss: 1.464552; batch adversarial loss: 0.523932\n",
      "epoch 2; iter: 200; batch classifier loss: 9.494905; batch adversarial loss: 0.484575\n",
      "epoch 2; iter: 400; batch classifier loss: 3.141729; batch adversarial loss: 0.464823\n",
      "epoch 2; iter: 600; batch classifier loss: 4.461419; batch adversarial loss: 0.360635\n",
      "epoch 3; iter: 0; batch classifier loss: 0.665385; batch adversarial loss: 0.387904\n",
      "epoch 3; iter: 200; batch classifier loss: 1.029223; batch adversarial loss: 0.453436\n",
      "epoch 3; iter: 400; batch classifier loss: 2.466434; batch adversarial loss: 0.491405\n",
      "epoch 3; iter: 600; batch classifier loss: 1.299736; batch adversarial loss: 0.358001\n",
      "epoch 4; iter: 0; batch classifier loss: 1.638990; batch adversarial loss: 0.411625\n",
      "epoch 4; iter: 200; batch classifier loss: 0.784380; batch adversarial loss: 0.308242\n",
      "epoch 4; iter: 400; batch classifier loss: 0.981950; batch adversarial loss: 0.484476\n",
      "epoch 4; iter: 600; batch classifier loss: 0.369162; batch adversarial loss: 0.524743\n",
      "epoch 5; iter: 0; batch classifier loss: 0.638995; batch adversarial loss: 0.509552\n",
      "epoch 5; iter: 200; batch classifier loss: 4.492053; batch adversarial loss: 0.271618\n",
      "epoch 5; iter: 400; batch classifier loss: 1.020890; batch adversarial loss: 0.447190\n",
      "epoch 5; iter: 600; batch classifier loss: 0.592628; batch adversarial loss: 0.453305\n",
      "epoch 6; iter: 0; batch classifier loss: 0.654008; batch adversarial loss: 0.375377\n",
      "epoch 6; iter: 200; batch classifier loss: 0.357028; batch adversarial loss: 0.466996\n",
      "epoch 6; iter: 400; batch classifier loss: 0.600353; batch adversarial loss: 0.374462\n",
      "epoch 6; iter: 600; batch classifier loss: 0.614408; batch adversarial loss: 0.283126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498068; batch adversarial loss: 0.311703\n",
      "epoch 7; iter: 200; batch classifier loss: 0.379019; batch adversarial loss: 0.410713\n",
      "epoch 7; iter: 400; batch classifier loss: 0.399143; batch adversarial loss: 0.416617\n",
      "epoch 7; iter: 600; batch classifier loss: 0.332926; batch adversarial loss: 0.363723\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495498; batch adversarial loss: 0.511549\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387457; batch adversarial loss: 0.405898\n",
      "epoch 8; iter: 400; batch classifier loss: 0.414986; batch adversarial loss: 0.443053\n",
      "epoch 8; iter: 600; batch classifier loss: 0.320914; batch adversarial loss: 0.361529\n",
      "epoch 9; iter: 0; batch classifier loss: 0.307323; batch adversarial loss: 0.637804\n",
      "epoch 9; iter: 200; batch classifier loss: 0.391879; batch adversarial loss: 0.417782\n",
      "epoch 9; iter: 400; batch classifier loss: 0.324545; batch adversarial loss: 0.419087\n",
      "epoch 9; iter: 600; batch classifier loss: 0.271026; batch adversarial loss: 0.349868\n",
      "epoch 10; iter: 0; batch classifier loss: 0.399722; batch adversarial loss: 0.379528\n",
      "epoch 10; iter: 200; batch classifier loss: 0.490709; batch adversarial loss: 0.313592\n",
      "epoch 10; iter: 400; batch classifier loss: 0.314514; batch adversarial loss: 0.437764\n",
      "epoch 10; iter: 600; batch classifier loss: 0.386992; batch adversarial loss: 0.383274\n",
      "epoch 11; iter: 0; batch classifier loss: 0.293132; batch adversarial loss: 0.496042\n",
      "epoch 11; iter: 200; batch classifier loss: 0.333824; batch adversarial loss: 0.482727\n",
      "epoch 11; iter: 400; batch classifier loss: 0.326320; batch adversarial loss: 0.457940\n",
      "epoch 11; iter: 600; batch classifier loss: 0.400681; batch adversarial loss: 0.405758\n",
      "epoch 12; iter: 0; batch classifier loss: 0.355644; batch adversarial loss: 0.523405\n",
      "epoch 12; iter: 200; batch classifier loss: 0.274933; batch adversarial loss: 0.609766\n",
      "epoch 12; iter: 400; batch classifier loss: 0.436966; batch adversarial loss: 0.494637\n",
      "epoch 12; iter: 600; batch classifier loss: 0.201603; batch adversarial loss: 0.348472\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370566; batch adversarial loss: 0.385739\n",
      "epoch 13; iter: 200; batch classifier loss: 0.337611; batch adversarial loss: 0.486045\n",
      "epoch 13; iter: 400; batch classifier loss: 0.403424; batch adversarial loss: 0.403490\n",
      "epoch 13; iter: 600; batch classifier loss: 0.395225; batch adversarial loss: 0.476307\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430993; batch adversarial loss: 0.353882\n",
      "epoch 14; iter: 200; batch classifier loss: 0.403097; batch adversarial loss: 0.457145\n",
      "epoch 14; iter: 400; batch classifier loss: 0.270303; batch adversarial loss: 0.513193\n",
      "epoch 14; iter: 600; batch classifier loss: 0.512609; batch adversarial loss: 0.335524\n",
      "epoch 15; iter: 0; batch classifier loss: 0.335331; batch adversarial loss: 0.324270\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392272; batch adversarial loss: 0.507805\n",
      "epoch 15; iter: 400; batch classifier loss: 0.438139; batch adversarial loss: 0.295273\n",
      "epoch 15; iter: 600; batch classifier loss: 0.399678; batch adversarial loss: 0.415775\n",
      "epoch 16; iter: 0; batch classifier loss: 0.345327; batch adversarial loss: 0.262233\n",
      "epoch 16; iter: 200; batch classifier loss: 0.319595; batch adversarial loss: 0.384566\n",
      "epoch 16; iter: 400; batch classifier loss: 0.480647; batch adversarial loss: 0.262777\n",
      "epoch 16; iter: 600; batch classifier loss: 0.316405; batch adversarial loss: 0.404339\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322141; batch adversarial loss: 0.459453\n",
      "epoch 17; iter: 200; batch classifier loss: 0.304238; batch adversarial loss: 0.372020\n",
      "epoch 17; iter: 400; batch classifier loss: 0.269590; batch adversarial loss: 0.372017\n",
      "epoch 17; iter: 600; batch classifier loss: 0.363230; batch adversarial loss: 0.432658\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337579; batch adversarial loss: 0.479268\n",
      "epoch 18; iter: 200; batch classifier loss: 0.259356; batch adversarial loss: 0.372160\n",
      "epoch 18; iter: 400; batch classifier loss: 0.323155; batch adversarial loss: 0.353809\n",
      "epoch 18; iter: 600; batch classifier loss: 0.265137; batch adversarial loss: 0.421586\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325418; batch adversarial loss: 0.405535\n",
      "epoch 19; iter: 200; batch classifier loss: 0.382990; batch adversarial loss: 0.399999\n",
      "epoch 19; iter: 400; batch classifier loss: 0.323301; batch adversarial loss: 0.381531\n",
      "epoch 19; iter: 600; batch classifier loss: 0.347675; batch adversarial loss: 0.493201\n",
      "epoch 0; iter: 0; batch classifier loss: 40.708328; batch adversarial loss: 1.126770\n",
      "epoch 0; iter: 200; batch classifier loss: 5.466877; batch adversarial loss: 1.120812\n",
      "epoch 0; iter: 400; batch classifier loss: 9.439757; batch adversarial loss: 0.973743\n",
      "epoch 0; iter: 600; batch classifier loss: 22.943493; batch adversarial loss: 0.738502\n",
      "epoch 1; iter: 0; batch classifier loss: 10.346431; batch adversarial loss: 0.743532\n",
      "epoch 1; iter: 200; batch classifier loss: 3.640224; batch adversarial loss: 0.604860\n",
      "epoch 1; iter: 400; batch classifier loss: 2.664145; batch adversarial loss: 0.560171\n",
      "epoch 1; iter: 600; batch classifier loss: 7.771809; batch adversarial loss: 0.523630\n",
      "epoch 2; iter: 0; batch classifier loss: 2.944187; batch adversarial loss: 0.455878\n",
      "epoch 2; iter: 200; batch classifier loss: 2.847618; batch adversarial loss: 0.444828\n",
      "epoch 2; iter: 400; batch classifier loss: 0.774375; batch adversarial loss: 0.461536\n",
      "epoch 2; iter: 600; batch classifier loss: 1.212479; batch adversarial loss: 0.486051\n",
      "epoch 3; iter: 0; batch classifier loss: 2.223814; batch adversarial loss: 0.381426\n",
      "epoch 3; iter: 200; batch classifier loss: 2.722480; batch adversarial loss: 0.303425\n",
      "epoch 3; iter: 400; batch classifier loss: 1.575551; batch adversarial loss: 0.378694\n",
      "epoch 3; iter: 600; batch classifier loss: 2.006723; batch adversarial loss: 0.355536\n",
      "epoch 4; iter: 0; batch classifier loss: 0.951678; batch adversarial loss: 0.435027\n",
      "epoch 4; iter: 200; batch classifier loss: 0.848716; batch adversarial loss: 0.353420\n",
      "epoch 4; iter: 400; batch classifier loss: 0.621346; batch adversarial loss: 0.351407\n",
      "epoch 4; iter: 600; batch classifier loss: 1.094972; batch adversarial loss: 0.379361\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512256; batch adversarial loss: 0.351777\n",
      "epoch 5; iter: 200; batch classifier loss: 0.411548; batch adversarial loss: 0.427955\n",
      "epoch 5; iter: 400; batch classifier loss: 0.403220; batch adversarial loss: 0.452064\n",
      "epoch 5; iter: 600; batch classifier loss: 0.423898; batch adversarial loss: 0.497764\n",
      "epoch 6; iter: 0; batch classifier loss: 0.473083; batch adversarial loss: 0.423178\n",
      "epoch 6; iter: 200; batch classifier loss: 0.416403; batch adversarial loss: 0.538343\n",
      "epoch 6; iter: 400; batch classifier loss: 0.522797; batch adversarial loss: 0.406923\n",
      "epoch 6; iter: 600; batch classifier loss: 0.572924; batch adversarial loss: 0.363736\n",
      "epoch 7; iter: 0; batch classifier loss: 0.467842; batch adversarial loss: 0.393679\n",
      "epoch 7; iter: 200; batch classifier loss: 0.314896; batch adversarial loss: 0.416428\n",
      "epoch 7; iter: 400; batch classifier loss: 0.377367; batch adversarial loss: 0.415932\n",
      "epoch 7; iter: 600; batch classifier loss: 0.534116; batch adversarial loss: 0.351126\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417087; batch adversarial loss: 0.318385\n",
      "epoch 8; iter: 200; batch classifier loss: 0.394327; batch adversarial loss: 0.411780\n",
      "epoch 8; iter: 400; batch classifier loss: 0.423906; batch adversarial loss: 0.318975\n",
      "epoch 8; iter: 600; batch classifier loss: 0.330576; batch adversarial loss: 0.413884\n",
      "epoch 9; iter: 0; batch classifier loss: 0.403498; batch adversarial loss: 0.431345\n",
      "epoch 9; iter: 200; batch classifier loss: 0.524223; batch adversarial loss: 0.364236\n",
      "epoch 9; iter: 400; batch classifier loss: 0.325691; batch adversarial loss: 0.401396\n",
      "epoch 9; iter: 600; batch classifier loss: 0.382055; batch adversarial loss: 0.335081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280446; batch adversarial loss: 0.458764\n",
      "epoch 10; iter: 200; batch classifier loss: 0.487339; batch adversarial loss: 0.525179\n",
      "epoch 10; iter: 400; batch classifier loss: 0.366996; batch adversarial loss: 0.496216\n",
      "epoch 10; iter: 600; batch classifier loss: 0.307401; batch adversarial loss: 0.488233\n",
      "epoch 11; iter: 0; batch classifier loss: 0.379737; batch adversarial loss: 0.406135\n",
      "epoch 11; iter: 200; batch classifier loss: 0.438441; batch adversarial loss: 0.502132\n",
      "epoch 11; iter: 400; batch classifier loss: 0.401067; batch adversarial loss: 0.256890\n",
      "epoch 11; iter: 600; batch classifier loss: 0.428849; batch adversarial loss: 0.289016\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410986; batch adversarial loss: 0.338782\n",
      "epoch 12; iter: 200; batch classifier loss: 0.303220; batch adversarial loss: 0.378949\n",
      "epoch 12; iter: 400; batch classifier loss: 0.356364; batch adversarial loss: 0.379324\n",
      "epoch 12; iter: 600; batch classifier loss: 0.322344; batch adversarial loss: 0.613740\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292191; batch adversarial loss: 0.359537\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353102; batch adversarial loss: 0.464296\n",
      "epoch 13; iter: 400; batch classifier loss: 0.200209; batch adversarial loss: 0.472718\n",
      "epoch 13; iter: 600; batch classifier loss: 0.339750; batch adversarial loss: 0.372377\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265171; batch adversarial loss: 0.388188\n",
      "epoch 14; iter: 200; batch classifier loss: 0.287305; batch adversarial loss: 0.374817\n",
      "epoch 14; iter: 400; batch classifier loss: 0.339297; batch adversarial loss: 0.356518\n",
      "epoch 14; iter: 600; batch classifier loss: 0.287098; batch adversarial loss: 0.488077\n",
      "epoch 15; iter: 0; batch classifier loss: 0.274598; batch adversarial loss: 0.377783\n",
      "epoch 15; iter: 200; batch classifier loss: 0.391795; batch adversarial loss: 0.377216\n",
      "epoch 15; iter: 400; batch classifier loss: 0.278829; batch adversarial loss: 0.537678\n",
      "epoch 15; iter: 600; batch classifier loss: 0.368982; batch adversarial loss: 0.397184\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319455; batch adversarial loss: 0.449298\n",
      "epoch 16; iter: 200; batch classifier loss: 0.396303; batch adversarial loss: 0.500821\n",
      "epoch 16; iter: 400; batch classifier loss: 0.269586; batch adversarial loss: 0.418657\n",
      "epoch 16; iter: 600; batch classifier loss: 0.407277; batch adversarial loss: 0.380250\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500902; batch adversarial loss: 0.350441\n",
      "epoch 17; iter: 200; batch classifier loss: 0.305489; batch adversarial loss: 0.447025\n",
      "epoch 17; iter: 400; batch classifier loss: 0.512055; batch adversarial loss: 0.483136\n",
      "epoch 17; iter: 600; batch classifier loss: 0.393128; batch adversarial loss: 0.541926\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465936; batch adversarial loss: 0.426130\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371053; batch adversarial loss: 0.315521\n",
      "epoch 18; iter: 400; batch classifier loss: 0.467366; batch adversarial loss: 0.295050\n",
      "epoch 18; iter: 600; batch classifier loss: 0.319570; batch adversarial loss: 0.537656\n",
      "epoch 19; iter: 0; batch classifier loss: 0.339390; batch adversarial loss: 0.481562\n",
      "epoch 19; iter: 200; batch classifier loss: 0.323339; batch adversarial loss: 0.525824\n",
      "epoch 19; iter: 400; batch classifier loss: 0.361370; batch adversarial loss: 0.496228\n",
      "epoch 19; iter: 600; batch classifier loss: 0.529108; batch adversarial loss: 0.450694\n",
      "epoch 0; iter: 0; batch classifier loss: 14.420124; batch adversarial loss: 0.639289\n",
      "epoch 0; iter: 200; batch classifier loss: 1.352880; batch adversarial loss: 0.579660\n",
      "epoch 0; iter: 400; batch classifier loss: 6.339113; batch adversarial loss: 0.534756\n",
      "epoch 0; iter: 600; batch classifier loss: 0.724187; batch adversarial loss: 0.485334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.975619; batch adversarial loss: 0.583856\n",
      "epoch 1; iter: 200; batch classifier loss: 2.581378; batch adversarial loss: 0.461839\n",
      "epoch 1; iter: 400; batch classifier loss: 3.341189; batch adversarial loss: 0.488144\n",
      "epoch 1; iter: 600; batch classifier loss: 1.013447; batch adversarial loss: 0.481670\n",
      "epoch 2; iter: 0; batch classifier loss: 1.184639; batch adversarial loss: 0.484408\n",
      "epoch 2; iter: 200; batch classifier loss: 2.515276; batch adversarial loss: 0.541645\n",
      "epoch 2; iter: 400; batch classifier loss: 4.741869; batch adversarial loss: 0.412246\n",
      "epoch 2; iter: 600; batch classifier loss: 0.569322; batch adversarial loss: 0.399147\n",
      "epoch 3; iter: 0; batch classifier loss: 2.167451; batch adversarial loss: 0.503235\n",
      "epoch 3; iter: 200; batch classifier loss: 0.871033; batch adversarial loss: 0.441603\n",
      "epoch 3; iter: 400; batch classifier loss: 3.753064; batch adversarial loss: 0.433197\n",
      "epoch 3; iter: 600; batch classifier loss: 0.996390; batch adversarial loss: 0.403697\n",
      "epoch 4; iter: 0; batch classifier loss: 2.490302; batch adversarial loss: 0.470459\n",
      "epoch 4; iter: 200; batch classifier loss: 0.603807; batch adversarial loss: 0.404469\n",
      "epoch 4; iter: 400; batch classifier loss: 0.480349; batch adversarial loss: 0.492236\n",
      "epoch 4; iter: 600; batch classifier loss: 0.802217; batch adversarial loss: 0.470486\n",
      "epoch 5; iter: 0; batch classifier loss: 0.525204; batch adversarial loss: 0.403218\n",
      "epoch 5; iter: 200; batch classifier loss: 0.694799; batch adversarial loss: 0.301923\n",
      "epoch 5; iter: 400; batch classifier loss: 0.643903; batch adversarial loss: 0.382240\n",
      "epoch 5; iter: 600; batch classifier loss: 0.356344; batch adversarial loss: 0.293138\n",
      "epoch 6; iter: 0; batch classifier loss: 0.364946; batch adversarial loss: 0.581515\n",
      "epoch 6; iter: 200; batch classifier loss: 0.607366; batch adversarial loss: 0.402093\n",
      "epoch 6; iter: 400; batch classifier loss: 0.494942; batch adversarial loss: 0.550079\n",
      "epoch 6; iter: 600; batch classifier loss: 0.447211; batch adversarial loss: 0.406190\n",
      "epoch 7; iter: 0; batch classifier loss: 0.297310; batch adversarial loss: 0.364771\n",
      "epoch 7; iter: 200; batch classifier loss: 0.494451; batch adversarial loss: 0.441766\n",
      "epoch 7; iter: 400; batch classifier loss: 0.263185; batch adversarial loss: 0.397095\n",
      "epoch 7; iter: 600; batch classifier loss: 0.392326; batch adversarial loss: 0.419432\n",
      "epoch 8; iter: 0; batch classifier loss: 0.327411; batch adversarial loss: 0.429245\n",
      "epoch 8; iter: 200; batch classifier loss: 0.447980; batch adversarial loss: 0.520451\n",
      "epoch 8; iter: 400; batch classifier loss: 0.354421; batch adversarial loss: 0.237451\n",
      "epoch 8; iter: 600; batch classifier loss: 0.428248; batch adversarial loss: 0.308671\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367430; batch adversarial loss: 0.233714\n",
      "epoch 9; iter: 200; batch classifier loss: 0.408123; batch adversarial loss: 0.296839\n",
      "epoch 9; iter: 400; batch classifier loss: 0.336720; batch adversarial loss: 0.463524\n",
      "epoch 9; iter: 600; batch classifier loss: 0.450356; batch adversarial loss: 0.607715\n",
      "epoch 10; iter: 0; batch classifier loss: 0.389321; batch adversarial loss: 0.392337\n",
      "epoch 10; iter: 200; batch classifier loss: 0.339124; batch adversarial loss: 0.427201\n",
      "epoch 10; iter: 400; batch classifier loss: 0.321902; batch adversarial loss: 0.434878\n",
      "epoch 10; iter: 600; batch classifier loss: 0.311270; batch adversarial loss: 0.545076\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345425; batch adversarial loss: 0.339673\n",
      "epoch 11; iter: 200; batch classifier loss: 0.246326; batch adversarial loss: 0.497833\n",
      "epoch 11; iter: 400; batch classifier loss: 0.286517; batch adversarial loss: 0.374615\n",
      "epoch 11; iter: 600; batch classifier loss: 0.417420; batch adversarial loss: 0.468529\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327803; batch adversarial loss: 0.461712\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391175; batch adversarial loss: 0.530878\n",
      "epoch 12; iter: 400; batch classifier loss: 0.345626; batch adversarial loss: 0.446823\n",
      "epoch 12; iter: 600; batch classifier loss: 0.308516; batch adversarial loss: 0.399367\n",
      "epoch 13; iter: 0; batch classifier loss: 0.262401; batch adversarial loss: 0.528927\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352748; batch adversarial loss: 0.294829\n",
      "epoch 13; iter: 400; batch classifier loss: 0.324834; batch adversarial loss: 0.450257\n",
      "epoch 13; iter: 600; batch classifier loss: 0.244310; batch adversarial loss: 0.459181\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294987; batch adversarial loss: 0.259194\n",
      "epoch 14; iter: 200; batch classifier loss: 0.315314; batch adversarial loss: 0.403855\n",
      "epoch 14; iter: 400; batch classifier loss: 0.526345; batch adversarial loss: 0.344118\n",
      "epoch 14; iter: 600; batch classifier loss: 0.267856; batch adversarial loss: 0.379923\n",
      "epoch 15; iter: 0; batch classifier loss: 0.244098; batch adversarial loss: 0.315968\n",
      "epoch 15; iter: 200; batch classifier loss: 0.267758; batch adversarial loss: 0.316711\n",
      "epoch 15; iter: 400; batch classifier loss: 0.411571; batch adversarial loss: 0.398047\n",
      "epoch 15; iter: 600; batch classifier loss: 0.463757; batch adversarial loss: 0.344888\n",
      "epoch 16; iter: 0; batch classifier loss: 0.228525; batch adversarial loss: 0.504835\n",
      "epoch 16; iter: 200; batch classifier loss: 0.484520; batch adversarial loss: 0.383074\n",
      "epoch 16; iter: 400; batch classifier loss: 0.320033; batch adversarial loss: 0.376632\n",
      "epoch 16; iter: 600; batch classifier loss: 0.510062; batch adversarial loss: 0.366214\n",
      "epoch 17; iter: 0; batch classifier loss: 0.400782; batch adversarial loss: 0.383407\n",
      "epoch 17; iter: 200; batch classifier loss: 0.383744; batch adversarial loss: 0.491332\n",
      "epoch 17; iter: 400; batch classifier loss: 0.512598; batch adversarial loss: 0.293131\n",
      "epoch 17; iter: 600; batch classifier loss: 0.496260; batch adversarial loss: 0.322983\n",
      "epoch 18; iter: 0; batch classifier loss: 0.325093; batch adversarial loss: 0.426067\n",
      "epoch 18; iter: 200; batch classifier loss: 0.453706; batch adversarial loss: 0.322183\n",
      "epoch 18; iter: 400; batch classifier loss: 0.270988; batch adversarial loss: 0.371487\n",
      "epoch 18; iter: 600; batch classifier loss: 0.309722; batch adversarial loss: 0.355235\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385702; batch adversarial loss: 0.286006\n",
      "epoch 19; iter: 200; batch classifier loss: 0.232469; batch adversarial loss: 0.314903\n",
      "epoch 19; iter: 400; batch classifier loss: 0.359373; batch adversarial loss: 0.376351\n",
      "epoch 19; iter: 600; batch classifier loss: 0.453760; batch adversarial loss: 0.317467\n",
      "epoch 0; iter: 0; batch classifier loss: 17.092869; batch adversarial loss: 0.657960\n",
      "epoch 0; iter: 200; batch classifier loss: 32.721165; batch adversarial loss: 0.601030\n",
      "epoch 0; iter: 400; batch classifier loss: 4.066751; batch adversarial loss: 0.571321\n",
      "epoch 0; iter: 600; batch classifier loss: 2.610111; batch adversarial loss: 0.498405\n",
      "epoch 1; iter: 0; batch classifier loss: 30.301733; batch adversarial loss: 0.537359\n",
      "epoch 1; iter: 200; batch classifier loss: 5.748504; batch adversarial loss: 0.467648\n",
      "epoch 1; iter: 400; batch classifier loss: 12.262373; batch adversarial loss: 0.417575\n",
      "epoch 1; iter: 600; batch classifier loss: 1.932263; batch adversarial loss: 0.393643\n",
      "epoch 2; iter: 0; batch classifier loss: 0.711699; batch adversarial loss: 0.410451\n",
      "epoch 2; iter: 200; batch classifier loss: 0.556388; batch adversarial loss: 0.471484\n",
      "epoch 2; iter: 400; batch classifier loss: 0.992715; batch adversarial loss: 0.459398\n",
      "epoch 2; iter: 600; batch classifier loss: 1.713938; batch adversarial loss: 0.474472\n",
      "epoch 3; iter: 0; batch classifier loss: 1.063843; batch adversarial loss: 0.467961\n",
      "epoch 3; iter: 200; batch classifier loss: 1.158022; batch adversarial loss: 0.589277\n",
      "epoch 3; iter: 400; batch classifier loss: 0.547385; batch adversarial loss: 0.332870\n",
      "epoch 3; iter: 600; batch classifier loss: 0.502281; batch adversarial loss: 0.405155\n",
      "epoch 4; iter: 0; batch classifier loss: 0.900292; batch adversarial loss: 0.427639\n",
      "epoch 4; iter: 200; batch classifier loss: 0.758738; batch adversarial loss: 0.442982\n",
      "epoch 4; iter: 400; batch classifier loss: 0.528783; batch adversarial loss: 0.475939\n",
      "epoch 4; iter: 600; batch classifier loss: 0.667985; batch adversarial loss: 0.380329\n",
      "epoch 5; iter: 0; batch classifier loss: 0.856174; batch adversarial loss: 0.357524\n",
      "epoch 5; iter: 200; batch classifier loss: 0.497452; batch adversarial loss: 0.427681\n",
      "epoch 5; iter: 400; batch classifier loss: 0.512753; batch adversarial loss: 0.428332\n",
      "epoch 5; iter: 600; batch classifier loss: 0.419924; batch adversarial loss: 0.455921\n",
      "epoch 6; iter: 0; batch classifier loss: 0.434915; batch adversarial loss: 0.534668\n",
      "epoch 6; iter: 200; batch classifier loss: 0.900568; batch adversarial loss: 0.497792\n",
      "epoch 6; iter: 400; batch classifier loss: 0.537547; batch adversarial loss: 0.330704\n",
      "epoch 6; iter: 600; batch classifier loss: 0.395241; batch adversarial loss: 0.324954\n",
      "epoch 7; iter: 0; batch classifier loss: 0.387818; batch adversarial loss: 0.348503\n",
      "epoch 7; iter: 200; batch classifier loss: 0.614279; batch adversarial loss: 0.538939\n",
      "epoch 7; iter: 400; batch classifier loss: 0.432081; batch adversarial loss: 0.381100\n",
      "epoch 7; iter: 600; batch classifier loss: 0.481034; batch adversarial loss: 0.572913\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434265; batch adversarial loss: 0.398519\n",
      "epoch 8; iter: 200; batch classifier loss: 0.365586; batch adversarial loss: 0.566498\n",
      "epoch 8; iter: 400; batch classifier loss: 0.333229; batch adversarial loss: 0.466343\n",
      "epoch 8; iter: 600; batch classifier loss: 0.274777; batch adversarial loss: 0.466053\n",
      "epoch 9; iter: 0; batch classifier loss: 0.352040; batch adversarial loss: 0.457844\n",
      "epoch 9; iter: 200; batch classifier loss: 0.380322; batch adversarial loss: 0.397321\n",
      "epoch 9; iter: 400; batch classifier loss: 0.359085; batch adversarial loss: 0.342239\n",
      "epoch 9; iter: 600; batch classifier loss: 0.311819; batch adversarial loss: 0.549875\n",
      "epoch 10; iter: 0; batch classifier loss: 0.332119; batch adversarial loss: 0.408245\n",
      "epoch 10; iter: 200; batch classifier loss: 0.392419; batch adversarial loss: 0.368386\n",
      "epoch 10; iter: 400; batch classifier loss: 0.413821; batch adversarial loss: 0.401983\n",
      "epoch 10; iter: 600; batch classifier loss: 0.349047; batch adversarial loss: 0.445983\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447776; batch adversarial loss: 0.356554\n",
      "epoch 11; iter: 200; batch classifier loss: 0.350511; batch adversarial loss: 0.533379\n",
      "epoch 11; iter: 400; batch classifier loss: 0.368092; batch adversarial loss: 0.544566\n",
      "epoch 11; iter: 600; batch classifier loss: 0.263667; batch adversarial loss: 0.316293\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282185; batch adversarial loss: 0.296892\n",
      "epoch 12; iter: 200; batch classifier loss: 0.275673; batch adversarial loss: 0.401486\n",
      "epoch 12; iter: 400; batch classifier loss: 0.362737; batch adversarial loss: 0.447784\n",
      "epoch 12; iter: 600; batch classifier loss: 0.371766; batch adversarial loss: 0.482350\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421161; batch adversarial loss: 0.351671\n",
      "epoch 13; iter: 200; batch classifier loss: 0.346037; batch adversarial loss: 0.401002\n",
      "epoch 13; iter: 400; batch classifier loss: 0.333234; batch adversarial loss: 0.348803\n",
      "epoch 13; iter: 600; batch classifier loss: 0.437463; batch adversarial loss: 0.419619\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316717; batch adversarial loss: 0.483315\n",
      "epoch 14; iter: 200; batch classifier loss: 0.302053; batch adversarial loss: 0.501452\n",
      "epoch 14; iter: 400; batch classifier loss: 0.260529; batch adversarial loss: 0.428180\n",
      "epoch 14; iter: 600; batch classifier loss: 0.391255; batch adversarial loss: 0.377879\n",
      "epoch 15; iter: 0; batch classifier loss: 0.357130; batch adversarial loss: 0.295689\n",
      "epoch 15; iter: 200; batch classifier loss: 0.324905; batch adversarial loss: 0.439861\n",
      "epoch 15; iter: 400; batch classifier loss: 0.326912; batch adversarial loss: 0.341156\n",
      "epoch 15; iter: 600; batch classifier loss: 0.329170; batch adversarial loss: 0.319214\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273974; batch adversarial loss: 0.403713\n",
      "epoch 16; iter: 200; batch classifier loss: 0.384232; batch adversarial loss: 0.418891\n",
      "epoch 16; iter: 400; batch classifier loss: 0.319138; batch adversarial loss: 0.325589\n",
      "epoch 16; iter: 600; batch classifier loss: 0.418152; batch adversarial loss: 0.401922\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289428; batch adversarial loss: 0.368403\n",
      "epoch 17; iter: 200; batch classifier loss: 0.303428; batch adversarial loss: 0.427672\n",
      "epoch 17; iter: 400; batch classifier loss: 0.353616; batch adversarial loss: 0.367247\n",
      "epoch 17; iter: 600; batch classifier loss: 0.299471; batch adversarial loss: 0.477447\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323884; batch adversarial loss: 0.455535\n",
      "epoch 18; iter: 200; batch classifier loss: 0.368557; batch adversarial loss: 0.345430\n",
      "epoch 18; iter: 400; batch classifier loss: 0.484279; batch adversarial loss: 0.313636\n",
      "epoch 18; iter: 600; batch classifier loss: 0.404157; batch adversarial loss: 0.348469\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374179; batch adversarial loss: 0.475868\n",
      "epoch 19; iter: 200; batch classifier loss: 0.379854; batch adversarial loss: 0.387167\n",
      "epoch 19; iter: 400; batch classifier loss: 0.428568; batch adversarial loss: 0.479898\n",
      "epoch 19; iter: 600; batch classifier loss: 0.577691; batch adversarial loss: 0.326836\n",
      "epoch 0; iter: 0; batch classifier loss: 14.524069; batch adversarial loss: 0.731204\n",
      "epoch 0; iter: 200; batch classifier loss: 6.473243; batch adversarial loss: 0.613425\n",
      "epoch 0; iter: 400; batch classifier loss: 4.834088; batch adversarial loss: 0.564968\n",
      "epoch 0; iter: 600; batch classifier loss: 7.415388; batch adversarial loss: 0.503220\n",
      "epoch 1; iter: 0; batch classifier loss: 0.565299; batch adversarial loss: 0.556972\n",
      "epoch 1; iter: 200; batch classifier loss: 2.853871; batch adversarial loss: 0.455317\n",
      "epoch 1; iter: 400; batch classifier loss: 8.269873; batch adversarial loss: 0.440494\n",
      "epoch 1; iter: 600; batch classifier loss: 3.489609; batch adversarial loss: 0.467061\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553790; batch adversarial loss: 0.497133\n",
      "epoch 2; iter: 200; batch classifier loss: 1.072798; batch adversarial loss: 0.438369\n",
      "epoch 2; iter: 400; batch classifier loss: 4.606141; batch adversarial loss: 0.433244\n",
      "epoch 2; iter: 600; batch classifier loss: 1.212821; batch adversarial loss: 0.523425\n",
      "epoch 3; iter: 0; batch classifier loss: 2.572047; batch adversarial loss: 0.420877\n",
      "epoch 3; iter: 200; batch classifier loss: 1.618823; batch adversarial loss: 0.587365\n",
      "epoch 3; iter: 400; batch classifier loss: 3.127196; batch adversarial loss: 0.423559\n",
      "epoch 3; iter: 600; batch classifier loss: 0.500840; batch adversarial loss: 0.377989\n",
      "epoch 4; iter: 0; batch classifier loss: 1.421353; batch adversarial loss: 0.377754\n",
      "epoch 4; iter: 200; batch classifier loss: 0.411883; batch adversarial loss: 0.530433\n",
      "epoch 4; iter: 400; batch classifier loss: 0.787771; batch adversarial loss: 0.504815\n",
      "epoch 4; iter: 600; batch classifier loss: 0.646595; batch adversarial loss: 0.429267\n",
      "epoch 5; iter: 0; batch classifier loss: 0.993325; batch adversarial loss: 0.447320\n",
      "epoch 5; iter: 200; batch classifier loss: 5.133934; batch adversarial loss: 0.240683\n",
      "epoch 5; iter: 400; batch classifier loss: 0.540301; batch adversarial loss: 0.437685\n",
      "epoch 5; iter: 600; batch classifier loss: 1.259930; batch adversarial loss: 0.392239\n",
      "epoch 6; iter: 0; batch classifier loss: 0.761095; batch adversarial loss: 0.431292\n",
      "epoch 6; iter: 200; batch classifier loss: 0.422192; batch adversarial loss: 0.323139\n",
      "epoch 6; iter: 400; batch classifier loss: 0.496551; batch adversarial loss: 0.432562\n",
      "epoch 6; iter: 600; batch classifier loss: 0.457611; batch adversarial loss: 0.403229\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376072; batch adversarial loss: 0.390594\n",
      "epoch 7; iter: 200; batch classifier loss: 0.453700; batch adversarial loss: 0.508417\n",
      "epoch 7; iter: 400; batch classifier loss: 0.290200; batch adversarial loss: 0.440052\n",
      "epoch 7; iter: 600; batch classifier loss: 0.418431; batch adversarial loss: 0.391867\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402195; batch adversarial loss: 0.350426\n",
      "epoch 8; iter: 200; batch classifier loss: 0.354111; batch adversarial loss: 0.471776\n",
      "epoch 8; iter: 400; batch classifier loss: 0.371498; batch adversarial loss: 0.341602\n",
      "epoch 8; iter: 600; batch classifier loss: 0.331289; batch adversarial loss: 0.458609\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455458; batch adversarial loss: 0.482698\n",
      "epoch 9; iter: 200; batch classifier loss: 0.339537; batch adversarial loss: 0.376369\n",
      "epoch 9; iter: 400; batch classifier loss: 0.399901; batch adversarial loss: 0.370430\n",
      "epoch 9; iter: 600; batch classifier loss: 0.483196; batch adversarial loss: 0.459674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.388715; batch adversarial loss: 0.391749\n",
      "epoch 10; iter: 200; batch classifier loss: 0.278647; batch adversarial loss: 0.506892\n",
      "epoch 10; iter: 400; batch classifier loss: 0.320508; batch adversarial loss: 0.345338\n",
      "epoch 10; iter: 600; batch classifier loss: 0.323603; batch adversarial loss: 0.439917\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518004; batch adversarial loss: 0.407163\n",
      "epoch 11; iter: 200; batch classifier loss: 0.365185; batch adversarial loss: 0.349985\n",
      "epoch 11; iter: 400; batch classifier loss: 0.315643; batch adversarial loss: 0.399865\n",
      "epoch 11; iter: 600; batch classifier loss: 0.295146; batch adversarial loss: 0.371701\n",
      "epoch 12; iter: 0; batch classifier loss: 0.293216; batch adversarial loss: 0.517419\n",
      "epoch 12; iter: 200; batch classifier loss: 0.485663; batch adversarial loss: 0.433417\n",
      "epoch 12; iter: 400; batch classifier loss: 0.374623; batch adversarial loss: 0.398973\n",
      "epoch 12; iter: 600; batch classifier loss: 0.314363; batch adversarial loss: 0.404762\n",
      "epoch 13; iter: 0; batch classifier loss: 0.391284; batch adversarial loss: 0.559642\n",
      "epoch 13; iter: 200; batch classifier loss: 0.612524; batch adversarial loss: 0.440464\n",
      "epoch 13; iter: 400; batch classifier loss: 0.338934; batch adversarial loss: 0.377844\n",
      "epoch 13; iter: 600; batch classifier loss: 0.481767; batch adversarial loss: 0.451950\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296353; batch adversarial loss: 0.435034\n",
      "epoch 14; iter: 200; batch classifier loss: 0.323092; batch adversarial loss: 0.374836\n",
      "epoch 14; iter: 400; batch classifier loss: 0.498664; batch adversarial loss: 0.380485\n",
      "epoch 14; iter: 600; batch classifier loss: 0.413340; batch adversarial loss: 0.483712\n",
      "epoch 15; iter: 0; batch classifier loss: 0.402774; batch adversarial loss: 0.378623\n",
      "epoch 15; iter: 200; batch classifier loss: 0.303198; batch adversarial loss: 0.321045\n",
      "epoch 15; iter: 400; batch classifier loss: 0.314584; batch adversarial loss: 0.366307\n",
      "epoch 15; iter: 600; batch classifier loss: 0.281676; batch adversarial loss: 0.321710\n",
      "epoch 16; iter: 0; batch classifier loss: 0.262905; batch adversarial loss: 0.411393\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388057; batch adversarial loss: 0.502100\n",
      "epoch 16; iter: 400; batch classifier loss: 0.246784; batch adversarial loss: 0.398360\n",
      "epoch 16; iter: 600; batch classifier loss: 0.405770; batch adversarial loss: 0.342419\n",
      "epoch 17; iter: 0; batch classifier loss: 0.381900; batch adversarial loss: 0.269392\n",
      "epoch 17; iter: 200; batch classifier loss: 0.327651; batch adversarial loss: 0.497838\n",
      "epoch 17; iter: 400; batch classifier loss: 0.448054; batch adversarial loss: 0.398826\n",
      "epoch 17; iter: 600; batch classifier loss: 0.309170; batch adversarial loss: 0.409723\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523181; batch adversarial loss: 0.373999\n",
      "epoch 18; iter: 200; batch classifier loss: 0.363967; batch adversarial loss: 0.376626\n",
      "epoch 18; iter: 400; batch classifier loss: 0.554669; batch adversarial loss: 0.454619\n",
      "epoch 18; iter: 600; batch classifier loss: 0.550388; batch adversarial loss: 0.435294\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485361; batch adversarial loss: 0.571528\n",
      "epoch 19; iter: 200; batch classifier loss: 0.578257; batch adversarial loss: 0.406410\n",
      "epoch 19; iter: 400; batch classifier loss: 0.360179; batch adversarial loss: 0.428108\n",
      "epoch 19; iter: 600; batch classifier loss: 0.424137; batch adversarial loss: 0.380778\n",
      "epoch 0; iter: 0; batch classifier loss: 3.054894; batch adversarial loss: 0.661316\n",
      "epoch 0; iter: 200; batch classifier loss: 4.304774; batch adversarial loss: 0.589646\n",
      "epoch 0; iter: 400; batch classifier loss: 1.532307; batch adversarial loss: 0.571108\n",
      "epoch 0; iter: 600; batch classifier loss: 3.234973; batch adversarial loss: 0.455384\n",
      "epoch 1; iter: 0; batch classifier loss: 6.139417; batch adversarial loss: 0.527698\n",
      "epoch 1; iter: 200; batch classifier loss: 7.597877; batch adversarial loss: 0.493087\n",
      "epoch 1; iter: 400; batch classifier loss: 2.972427; batch adversarial loss: 0.459307\n",
      "epoch 1; iter: 600; batch classifier loss: 1.741802; batch adversarial loss: 0.468363\n",
      "epoch 2; iter: 0; batch classifier loss: 1.261407; batch adversarial loss: 0.428990\n",
      "epoch 2; iter: 200; batch classifier loss: 0.784127; batch adversarial loss: 0.449361\n",
      "epoch 2; iter: 400; batch classifier loss: 1.391492; batch adversarial loss: 0.356801\n",
      "epoch 2; iter: 600; batch classifier loss: 0.495774; batch adversarial loss: 0.488784\n",
      "epoch 3; iter: 0; batch classifier loss: 1.380089; batch adversarial loss: 0.411365\n",
      "epoch 3; iter: 200; batch classifier loss: 1.087509; batch adversarial loss: 0.357120\n",
      "epoch 3; iter: 400; batch classifier loss: 1.241498; batch adversarial loss: 0.465991\n",
      "epoch 3; iter: 600; batch classifier loss: 1.115039; batch adversarial loss: 0.395225\n",
      "epoch 4; iter: 0; batch classifier loss: 0.845283; batch adversarial loss: 0.500409\n",
      "epoch 4; iter: 200; batch classifier loss: 0.697257; batch adversarial loss: 0.381443\n",
      "epoch 4; iter: 400; batch classifier loss: 0.229320; batch adversarial loss: 0.630589\n",
      "epoch 4; iter: 600; batch classifier loss: 0.495914; batch adversarial loss: 0.374726\n",
      "epoch 5; iter: 0; batch classifier loss: 0.328601; batch adversarial loss: 0.528794\n",
      "epoch 5; iter: 200; batch classifier loss: 0.329096; batch adversarial loss: 0.396590\n",
      "epoch 5; iter: 400; batch classifier loss: 0.469237; batch adversarial loss: 0.302944\n",
      "epoch 5; iter: 600; batch classifier loss: 0.451433; batch adversarial loss: 0.463455\n",
      "epoch 6; iter: 0; batch classifier loss: 0.394984; batch adversarial loss: 0.352311\n",
      "epoch 6; iter: 200; batch classifier loss: 0.607488; batch adversarial loss: 0.424497\n",
      "epoch 6; iter: 400; batch classifier loss: 0.394667; batch adversarial loss: 0.331559\n",
      "epoch 6; iter: 600; batch classifier loss: 0.393187; batch adversarial loss: 0.400578\n",
      "epoch 7; iter: 0; batch classifier loss: 0.332612; batch adversarial loss: 0.405043\n",
      "epoch 7; iter: 200; batch classifier loss: 0.377562; batch adversarial loss: 0.530441\n",
      "epoch 7; iter: 400; batch classifier loss: 0.403191; batch adversarial loss: 0.532642\n",
      "epoch 7; iter: 600; batch classifier loss: 0.546980; batch adversarial loss: 0.368541\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466781; batch adversarial loss: 0.533722\n",
      "epoch 8; iter: 200; batch classifier loss: 0.295507; batch adversarial loss: 0.422398\n",
      "epoch 8; iter: 400; batch classifier loss: 0.419609; batch adversarial loss: 0.418908\n",
      "epoch 8; iter: 600; batch classifier loss: 0.368764; batch adversarial loss: 0.374664\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341839; batch adversarial loss: 0.365095\n",
      "epoch 9; iter: 200; batch classifier loss: 0.416432; batch adversarial loss: 0.486134\n",
      "epoch 9; iter: 400; batch classifier loss: 0.324315; batch adversarial loss: 0.371968\n",
      "epoch 9; iter: 600; batch classifier loss: 0.274165; batch adversarial loss: 0.316230\n",
      "epoch 10; iter: 0; batch classifier loss: 0.355333; batch adversarial loss: 0.383885\n",
      "epoch 10; iter: 200; batch classifier loss: 0.397031; batch adversarial loss: 0.291226\n",
      "epoch 10; iter: 400; batch classifier loss: 0.401690; batch adversarial loss: 0.408517\n",
      "epoch 10; iter: 600; batch classifier loss: 0.357385; batch adversarial loss: 0.343838\n",
      "epoch 11; iter: 0; batch classifier loss: 0.338131; batch adversarial loss: 0.352220\n",
      "epoch 11; iter: 200; batch classifier loss: 0.326036; batch adversarial loss: 0.379931\n",
      "epoch 11; iter: 400; batch classifier loss: 0.373106; batch adversarial loss: 0.395380\n",
      "epoch 11; iter: 600; batch classifier loss: 0.343085; batch adversarial loss: 0.423785\n",
      "epoch 12; iter: 0; batch classifier loss: 0.320542; batch adversarial loss: 0.488448\n",
      "epoch 12; iter: 200; batch classifier loss: 0.328144; batch adversarial loss: 0.487577\n",
      "epoch 12; iter: 400; batch classifier loss: 0.340593; batch adversarial loss: 0.431319\n",
      "epoch 12; iter: 600; batch classifier loss: 0.410330; batch adversarial loss: 0.423931\n",
      "epoch 13; iter: 0; batch classifier loss: 0.229865; batch adversarial loss: 0.493008\n",
      "epoch 13; iter: 200; batch classifier loss: 0.357524; batch adversarial loss: 0.456740\n",
      "epoch 13; iter: 400; batch classifier loss: 0.314119; batch adversarial loss: 0.368097\n",
      "epoch 13; iter: 600; batch classifier loss: 0.356071; batch adversarial loss: 0.274868\n",
      "epoch 14; iter: 0; batch classifier loss: 0.365063; batch adversarial loss: 0.523721\n",
      "epoch 14; iter: 200; batch classifier loss: 0.391510; batch adversarial loss: 0.382755\n",
      "epoch 14; iter: 400; batch classifier loss: 0.376526; batch adversarial loss: 0.481251\n",
      "epoch 14; iter: 600; batch classifier loss: 0.296931; batch adversarial loss: 0.480171\n",
      "epoch 15; iter: 0; batch classifier loss: 0.380331; batch adversarial loss: 0.383536\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387958; batch adversarial loss: 0.459982\n",
      "epoch 15; iter: 400; batch classifier loss: 0.291877; batch adversarial loss: 0.421580\n",
      "epoch 15; iter: 600; batch classifier loss: 0.375732; batch adversarial loss: 0.461039\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404729; batch adversarial loss: 0.456893\n",
      "epoch 16; iter: 200; batch classifier loss: 0.397261; batch adversarial loss: 0.405444\n",
      "epoch 16; iter: 400; batch classifier loss: 0.239565; batch adversarial loss: 0.464810\n",
      "epoch 16; iter: 600; batch classifier loss: 0.332180; batch adversarial loss: 0.547168\n",
      "epoch 17; iter: 0; batch classifier loss: 0.180711; batch adversarial loss: 0.604310\n",
      "epoch 17; iter: 200; batch classifier loss: 0.409539; batch adversarial loss: 0.234902\n",
      "epoch 17; iter: 400; batch classifier loss: 0.269375; batch adversarial loss: 0.434001\n",
      "epoch 17; iter: 600; batch classifier loss: 0.312880; batch adversarial loss: 0.351878\n",
      "epoch 18; iter: 0; batch classifier loss: 0.417567; batch adversarial loss: 0.369326\n",
      "epoch 18; iter: 200; batch classifier loss: 0.400826; batch adversarial loss: 0.460493\n",
      "epoch 18; iter: 400; batch classifier loss: 0.301437; batch adversarial loss: 0.409521\n",
      "epoch 18; iter: 600; batch classifier loss: 0.299933; batch adversarial loss: 0.516432\n",
      "epoch 19; iter: 0; batch classifier loss: 0.228199; batch adversarial loss: 0.324905\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429618; batch adversarial loss: 0.440066\n",
      "epoch 19; iter: 400; batch classifier loss: 0.369743; batch adversarial loss: 0.430668\n",
      "epoch 19; iter: 600; batch classifier loss: 0.314407; batch adversarial loss: 0.348494\n",
      "epoch 0; iter: 0; batch classifier loss: 119.813934; batch adversarial loss: 0.787040\n",
      "epoch 0; iter: 200; batch classifier loss: 21.055027; batch adversarial loss: 0.681036\n",
      "epoch 0; iter: 400; batch classifier loss: 6.930633; batch adversarial loss: 0.620396\n",
      "epoch 0; iter: 600; batch classifier loss: 1.633321; batch adversarial loss: 0.534719\n",
      "epoch 1; iter: 0; batch classifier loss: 6.302194; batch adversarial loss: 0.528991\n",
      "epoch 1; iter: 200; batch classifier loss: 0.884170; batch adversarial loss: 0.535384\n",
      "epoch 1; iter: 400; batch classifier loss: 2.221225; batch adversarial loss: 0.434888\n",
      "epoch 1; iter: 600; batch classifier loss: 12.958636; batch adversarial loss: 0.475032\n",
      "epoch 2; iter: 0; batch classifier loss: 5.509305; batch adversarial loss: 0.450632\n",
      "epoch 2; iter: 200; batch classifier loss: 0.594991; batch adversarial loss: 0.456365\n",
      "epoch 2; iter: 400; batch classifier loss: 2.544792; batch adversarial loss: 0.469388\n",
      "epoch 2; iter: 600; batch classifier loss: 2.600537; batch adversarial loss: 0.407804\n",
      "epoch 3; iter: 0; batch classifier loss: 34.168400; batch adversarial loss: 0.479219\n",
      "epoch 3; iter: 200; batch classifier loss: 2.761579; batch adversarial loss: 0.351443\n",
      "epoch 3; iter: 400; batch classifier loss: 1.116968; batch adversarial loss: 0.383546\n",
      "epoch 3; iter: 600; batch classifier loss: 1.250106; batch adversarial loss: 0.474409\n",
      "epoch 4; iter: 0; batch classifier loss: 0.690259; batch adversarial loss: 0.454248\n",
      "epoch 4; iter: 200; batch classifier loss: 0.752143; batch adversarial loss: 0.399874\n",
      "epoch 4; iter: 400; batch classifier loss: 0.829144; batch adversarial loss: 0.438704\n",
      "epoch 4; iter: 600; batch classifier loss: 0.712153; batch adversarial loss: 0.468208\n",
      "epoch 5; iter: 0; batch classifier loss: 4.362615; batch adversarial loss: 0.470812\n",
      "epoch 5; iter: 200; batch classifier loss: 0.944198; batch adversarial loss: 0.401454\n",
      "epoch 5; iter: 400; batch classifier loss: 0.671826; batch adversarial loss: 0.306349\n",
      "epoch 5; iter: 600; batch classifier loss: 0.421414; batch adversarial loss: 0.522716\n",
      "epoch 6; iter: 0; batch classifier loss: 0.387651; batch adversarial loss: 0.325511\n",
      "epoch 6; iter: 200; batch classifier loss: 0.544327; batch adversarial loss: 0.356126\n",
      "epoch 6; iter: 400; batch classifier loss: 0.426789; batch adversarial loss: 0.486943\n",
      "epoch 6; iter: 600; batch classifier loss: 0.421670; batch adversarial loss: 0.548749\n",
      "epoch 7; iter: 0; batch classifier loss: 0.391349; batch adversarial loss: 0.379782\n",
      "epoch 7; iter: 200; batch classifier loss: 0.727435; batch adversarial loss: 0.374851\n",
      "epoch 7; iter: 400; batch classifier loss: 0.427984; batch adversarial loss: 0.401686\n",
      "epoch 7; iter: 600; batch classifier loss: 0.411195; batch adversarial loss: 0.389313\n",
      "epoch 8; iter: 0; batch classifier loss: 0.494818; batch adversarial loss: 0.501349\n",
      "epoch 8; iter: 200; batch classifier loss: 0.463189; batch adversarial loss: 0.346613\n",
      "epoch 8; iter: 400; batch classifier loss: 0.493940; batch adversarial loss: 0.378825\n",
      "epoch 8; iter: 600; batch classifier loss: 0.357825; batch adversarial loss: 0.451201\n",
      "epoch 9; iter: 0; batch classifier loss: 0.399876; batch adversarial loss: 0.307876\n",
      "epoch 9; iter: 200; batch classifier loss: 0.363612; batch adversarial loss: 0.501520\n",
      "epoch 9; iter: 400; batch classifier loss: 0.332018; batch adversarial loss: 0.435979\n",
      "epoch 9; iter: 600; batch classifier loss: 0.319723; batch adversarial loss: 0.537940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368534; batch adversarial loss: 0.536322\n",
      "epoch 10; iter: 200; batch classifier loss: 0.334408; batch adversarial loss: 0.507256\n",
      "epoch 10; iter: 400; batch classifier loss: 0.373017; batch adversarial loss: 0.402776\n",
      "epoch 10; iter: 600; batch classifier loss: 0.309818; batch adversarial loss: 0.369547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.394136; batch adversarial loss: 0.352716\n",
      "epoch 11; iter: 200; batch classifier loss: 0.335313; batch adversarial loss: 0.454859\n",
      "epoch 11; iter: 400; batch classifier loss: 0.516634; batch adversarial loss: 0.479782\n",
      "epoch 11; iter: 600; batch classifier loss: 0.265320; batch adversarial loss: 0.308771\n",
      "epoch 12; iter: 0; batch classifier loss: 0.360484; batch adversarial loss: 0.401419\n",
      "epoch 12; iter: 200; batch classifier loss: 0.329722; batch adversarial loss: 0.428481\n",
      "epoch 12; iter: 400; batch classifier loss: 0.458515; batch adversarial loss: 0.531175\n",
      "epoch 12; iter: 600; batch classifier loss: 0.339041; batch adversarial loss: 0.407824\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347780; batch adversarial loss: 0.378465\n",
      "epoch 13; iter: 200; batch classifier loss: 0.442533; batch adversarial loss: 0.441420\n",
      "epoch 13; iter: 400; batch classifier loss: 0.299988; batch adversarial loss: 0.457982\n",
      "epoch 13; iter: 600; batch classifier loss: 0.186907; batch adversarial loss: 0.416340\n",
      "epoch 14; iter: 0; batch classifier loss: 0.491838; batch adversarial loss: 0.369737\n",
      "epoch 14; iter: 200; batch classifier loss: 0.374522; batch adversarial loss: 0.435932\n",
      "epoch 14; iter: 400; batch classifier loss: 0.313692; batch adversarial loss: 0.447470\n",
      "epoch 14; iter: 600; batch classifier loss: 0.356353; batch adversarial loss: 0.464435\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336785; batch adversarial loss: 0.480701\n",
      "epoch 15; iter: 200; batch classifier loss: 0.340918; batch adversarial loss: 0.339112\n",
      "epoch 15; iter: 400; batch classifier loss: 0.464873; batch adversarial loss: 0.341766\n",
      "epoch 15; iter: 600; batch classifier loss: 0.321703; batch adversarial loss: 0.423455\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350508; batch adversarial loss: 0.382072\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383617; batch adversarial loss: 0.337541\n",
      "epoch 16; iter: 400; batch classifier loss: 0.388776; batch adversarial loss: 0.435867\n",
      "epoch 16; iter: 600; batch classifier loss: 0.344614; batch adversarial loss: 0.376315\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317088; batch adversarial loss: 0.490027\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321842; batch adversarial loss: 0.429086\n",
      "epoch 17; iter: 400; batch classifier loss: 0.298925; batch adversarial loss: 0.324471\n",
      "epoch 17; iter: 600; batch classifier loss: 0.351572; batch adversarial loss: 0.314283\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370692; batch adversarial loss: 0.454941\n",
      "epoch 18; iter: 200; batch classifier loss: 0.319430; batch adversarial loss: 0.485234\n",
      "epoch 18; iter: 400; batch classifier loss: 0.302970; batch adversarial loss: 0.437538\n",
      "epoch 18; iter: 600; batch classifier loss: 0.522069; batch adversarial loss: 0.385176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325691; batch adversarial loss: 0.294822\n",
      "epoch 19; iter: 200; batch classifier loss: 0.313619; batch adversarial loss: 0.521131\n",
      "epoch 19; iter: 400; batch classifier loss: 0.462880; batch adversarial loss: 0.429574\n",
      "epoch 19; iter: 600; batch classifier loss: 0.319423; batch adversarial loss: 0.432351\n",
      "epoch 0; iter: 0; batch classifier loss: 13.240465; batch adversarial loss: 0.949174\n",
      "epoch 0; iter: 200; batch classifier loss: 15.048635; batch adversarial loss: 0.786870\n",
      "epoch 0; iter: 400; batch classifier loss: 4.821212; batch adversarial loss: 0.609535\n",
      "epoch 0; iter: 600; batch classifier loss: 0.592596; batch adversarial loss: 0.525864\n",
      "epoch 1; iter: 0; batch classifier loss: 25.331396; batch adversarial loss: 0.544379\n",
      "epoch 1; iter: 200; batch classifier loss: 5.751545; batch adversarial loss: 0.527618\n",
      "epoch 1; iter: 400; batch classifier loss: 14.968332; batch adversarial loss: 0.501264\n",
      "epoch 1; iter: 600; batch classifier loss: 1.407759; batch adversarial loss: 0.469020\n",
      "epoch 2; iter: 0; batch classifier loss: 0.644376; batch adversarial loss: 0.553224\n",
      "epoch 2; iter: 200; batch classifier loss: 1.225756; batch adversarial loss: 0.398212\n",
      "epoch 2; iter: 400; batch classifier loss: 2.329378; batch adversarial loss: 0.419074\n",
      "epoch 2; iter: 600; batch classifier loss: 1.878817; batch adversarial loss: 0.519918\n",
      "epoch 3; iter: 0; batch classifier loss: 3.260888; batch adversarial loss: 0.456615\n",
      "epoch 3; iter: 200; batch classifier loss: 4.962136; batch adversarial loss: 0.364738\n",
      "epoch 3; iter: 400; batch classifier loss: 5.873891; batch adversarial loss: 0.358664\n",
      "epoch 3; iter: 600; batch classifier loss: 0.575999; batch adversarial loss: 0.405680\n",
      "epoch 4; iter: 0; batch classifier loss: 2.263375; batch adversarial loss: 0.426084\n",
      "epoch 4; iter: 200; batch classifier loss: 1.897415; batch adversarial loss: 0.492197\n",
      "epoch 4; iter: 400; batch classifier loss: 1.658934; batch adversarial loss: 0.448038\n",
      "epoch 4; iter: 600; batch classifier loss: 0.986349; batch adversarial loss: 0.512542\n",
      "epoch 5; iter: 0; batch classifier loss: 0.669673; batch adversarial loss: 0.418819\n",
      "epoch 5; iter: 200; batch classifier loss: 0.512286; batch adversarial loss: 0.453612\n",
      "epoch 5; iter: 400; batch classifier loss: 0.615190; batch adversarial loss: 0.376717\n",
      "epoch 5; iter: 600; batch classifier loss: 0.478002; batch adversarial loss: 0.325609\n",
      "epoch 6; iter: 0; batch classifier loss: 1.612940; batch adversarial loss: 0.428279\n",
      "epoch 6; iter: 200; batch classifier loss: 0.471901; batch adversarial loss: 0.442236\n",
      "epoch 6; iter: 400; batch classifier loss: 0.489156; batch adversarial loss: 0.515784\n",
      "epoch 6; iter: 600; batch classifier loss: 0.496366; batch adversarial loss: 0.400208\n",
      "epoch 7; iter: 0; batch classifier loss: 0.422263; batch adversarial loss: 0.398069\n",
      "epoch 7; iter: 200; batch classifier loss: 0.435811; batch adversarial loss: 0.415451\n",
      "epoch 7; iter: 400; batch classifier loss: 0.382907; batch adversarial loss: 0.422361\n",
      "epoch 7; iter: 600; batch classifier loss: 0.398743; batch adversarial loss: 0.413773\n",
      "epoch 8; iter: 0; batch classifier loss: 0.379521; batch adversarial loss: 0.287744\n",
      "epoch 8; iter: 200; batch classifier loss: 0.470378; batch adversarial loss: 0.483055\n",
      "epoch 8; iter: 400; batch classifier loss: 0.384408; batch adversarial loss: 0.463393\n",
      "epoch 8; iter: 600; batch classifier loss: 0.328303; batch adversarial loss: 0.350511\n",
      "epoch 9; iter: 0; batch classifier loss: 0.335544; batch adversarial loss: 0.523533\n",
      "epoch 9; iter: 200; batch classifier loss: 0.377058; batch adversarial loss: 0.340215\n",
      "epoch 9; iter: 400; batch classifier loss: 0.299531; batch adversarial loss: 0.288544\n",
      "epoch 9; iter: 600; batch classifier loss: 0.390936; batch adversarial loss: 0.397740\n",
      "epoch 10; iter: 0; batch classifier loss: 0.302705; batch adversarial loss: 0.369951\n",
      "epoch 10; iter: 200; batch classifier loss: 0.277672; batch adversarial loss: 0.452555\n",
      "epoch 10; iter: 400; batch classifier loss: 0.351709; batch adversarial loss: 0.395871\n",
      "epoch 10; iter: 600; batch classifier loss: 0.283468; batch adversarial loss: 0.488159\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580472; batch adversarial loss: 0.317736\n",
      "epoch 11; iter: 200; batch classifier loss: 0.334506; batch adversarial loss: 0.345060\n",
      "epoch 11; iter: 400; batch classifier loss: 0.419598; batch adversarial loss: 0.315718\n",
      "epoch 11; iter: 600; batch classifier loss: 0.438183; batch adversarial loss: 0.425738\n",
      "epoch 12; iter: 0; batch classifier loss: 0.270566; batch adversarial loss: 0.449601\n",
      "epoch 12; iter: 200; batch classifier loss: 0.383601; batch adversarial loss: 0.479646\n",
      "epoch 12; iter: 400; batch classifier loss: 0.372745; batch adversarial loss: 0.351717\n",
      "epoch 12; iter: 600; batch classifier loss: 0.338302; batch adversarial loss: 0.459246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.301911; batch adversarial loss: 0.487043\n",
      "epoch 13; iter: 200; batch classifier loss: 0.341524; batch adversarial loss: 0.323943\n",
      "epoch 13; iter: 400; batch classifier loss: 0.299047; batch adversarial loss: 0.452172\n",
      "epoch 13; iter: 600; batch classifier loss: 0.408396; batch adversarial loss: 0.508817\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476920; batch adversarial loss: 0.417747\n",
      "epoch 14; iter: 200; batch classifier loss: 0.210154; batch adversarial loss: 0.371079\n",
      "epoch 14; iter: 400; batch classifier loss: 0.317469; batch adversarial loss: 0.428470\n",
      "epoch 14; iter: 600; batch classifier loss: 0.284944; batch adversarial loss: 0.375901\n",
      "epoch 15; iter: 0; batch classifier loss: 0.305458; batch adversarial loss: 0.322130\n",
      "epoch 15; iter: 200; batch classifier loss: 0.308214; batch adversarial loss: 0.538304\n",
      "epoch 15; iter: 400; batch classifier loss: 0.309974; batch adversarial loss: 0.385686\n",
      "epoch 15; iter: 600; batch classifier loss: 0.347072; batch adversarial loss: 0.329054\n",
      "epoch 16; iter: 0; batch classifier loss: 0.396452; batch adversarial loss: 0.470837\n",
      "epoch 16; iter: 200; batch classifier loss: 0.436106; batch adversarial loss: 0.321526\n",
      "epoch 16; iter: 400; batch classifier loss: 0.326753; batch adversarial loss: 0.496692\n",
      "epoch 16; iter: 600; batch classifier loss: 0.357622; batch adversarial loss: 0.531936\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340883; batch adversarial loss: 0.557976\n",
      "epoch 17; iter: 200; batch classifier loss: 0.393755; batch adversarial loss: 0.406378\n",
      "epoch 17; iter: 400; batch classifier loss: 0.585894; batch adversarial loss: 0.216327\n",
      "epoch 17; iter: 600; batch classifier loss: 0.348222; batch adversarial loss: 0.372781\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317975; batch adversarial loss: 0.424441\n",
      "epoch 18; iter: 200; batch classifier loss: 0.462093; batch adversarial loss: 0.380111\n",
      "epoch 18; iter: 400; batch classifier loss: 0.380654; batch adversarial loss: 0.544278\n",
      "epoch 18; iter: 600; batch classifier loss: 0.353880; batch adversarial loss: 0.375781\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459806; batch adversarial loss: 0.344744\n",
      "epoch 19; iter: 200; batch classifier loss: 0.539253; batch adversarial loss: 0.370896\n",
      "epoch 19; iter: 400; batch classifier loss: 0.452125; batch adversarial loss: 0.352044\n",
      "epoch 19; iter: 600; batch classifier loss: 0.409723; batch adversarial loss: 0.347365\n",
      "epoch 0; iter: 0; batch classifier loss: 16.590210; batch adversarial loss: 0.831586\n",
      "epoch 0; iter: 200; batch classifier loss: 13.009830; batch adversarial loss: 0.658793\n",
      "epoch 0; iter: 400; batch classifier loss: 6.998060; batch adversarial loss: 0.595594\n",
      "epoch 0; iter: 600; batch classifier loss: 1.668411; batch adversarial loss: 0.553085\n",
      "epoch 1; iter: 0; batch classifier loss: 9.750257; batch adversarial loss: 0.552496\n",
      "epoch 1; iter: 200; batch classifier loss: 18.698034; batch adversarial loss: 0.496475\n",
      "epoch 1; iter: 400; batch classifier loss: 3.692943; batch adversarial loss: 0.457245\n",
      "epoch 1; iter: 600; batch classifier loss: 4.204672; batch adversarial loss: 0.520076\n",
      "epoch 2; iter: 0; batch classifier loss: 13.096476; batch adversarial loss: 0.451685\n",
      "epoch 2; iter: 200; batch classifier loss: 2.763449; batch adversarial loss: 0.476533\n",
      "epoch 2; iter: 400; batch classifier loss: 2.499704; batch adversarial loss: 0.522976\n",
      "epoch 2; iter: 600; batch classifier loss: 0.592984; batch adversarial loss: 0.386512\n",
      "epoch 3; iter: 0; batch classifier loss: 1.202211; batch adversarial loss: 0.325926\n",
      "epoch 3; iter: 200; batch classifier loss: 1.689446; batch adversarial loss: 0.423538\n",
      "epoch 3; iter: 400; batch classifier loss: 1.317803; batch adversarial loss: 0.380119\n",
      "epoch 3; iter: 600; batch classifier loss: 0.691837; batch adversarial loss: 0.387055\n",
      "epoch 4; iter: 0; batch classifier loss: 1.053071; batch adversarial loss: 0.395348\n",
      "epoch 4; iter: 200; batch classifier loss: 0.748045; batch adversarial loss: 0.439605\n",
      "epoch 4; iter: 400; batch classifier loss: 0.949518; batch adversarial loss: 0.315863\n",
      "epoch 4; iter: 600; batch classifier loss: 0.391831; batch adversarial loss: 0.401418\n",
      "epoch 5; iter: 0; batch classifier loss: 0.984111; batch adversarial loss: 0.321752\n",
      "epoch 5; iter: 200; batch classifier loss: 0.448944; batch adversarial loss: 0.490983\n",
      "epoch 5; iter: 400; batch classifier loss: 0.832486; batch adversarial loss: 0.393918\n",
      "epoch 5; iter: 600; batch classifier loss: 0.692403; batch adversarial loss: 0.311469\n",
      "epoch 6; iter: 0; batch classifier loss: 0.307961; batch adversarial loss: 0.335639\n",
      "epoch 6; iter: 200; batch classifier loss: 0.447094; batch adversarial loss: 0.539526\n",
      "epoch 6; iter: 400; batch classifier loss: 0.732678; batch adversarial loss: 0.408410\n",
      "epoch 6; iter: 600; batch classifier loss: 0.413742; batch adversarial loss: 0.373873\n",
      "epoch 7; iter: 0; batch classifier loss: 0.335192; batch adversarial loss: 0.460680\n",
      "epoch 7; iter: 200; batch classifier loss: 0.291923; batch adversarial loss: 0.530173\n",
      "epoch 7; iter: 400; batch classifier loss: 0.417955; batch adversarial loss: 0.453257\n",
      "epoch 7; iter: 600; batch classifier loss: 0.524611; batch adversarial loss: 0.471248\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573757; batch adversarial loss: 0.377379\n",
      "epoch 8; iter: 200; batch classifier loss: 0.284561; batch adversarial loss: 0.370378\n",
      "epoch 8; iter: 400; batch classifier loss: 0.357686; batch adversarial loss: 0.300976\n",
      "epoch 8; iter: 600; batch classifier loss: 0.306181; batch adversarial loss: 0.399593\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465895; batch adversarial loss: 0.410242\n",
      "epoch 9; iter: 200; batch classifier loss: 0.365672; batch adversarial loss: 0.410586\n",
      "epoch 9; iter: 400; batch classifier loss: 0.455924; batch adversarial loss: 0.351655\n",
      "epoch 9; iter: 600; batch classifier loss: 0.240867; batch adversarial loss: 0.432943\n",
      "epoch 10; iter: 0; batch classifier loss: 0.263340; batch adversarial loss: 0.387544\n",
      "epoch 10; iter: 200; batch classifier loss: 0.275819; batch adversarial loss: 0.422001\n",
      "epoch 10; iter: 400; batch classifier loss: 0.301753; batch adversarial loss: 0.449996\n",
      "epoch 10; iter: 600; batch classifier loss: 0.364321; batch adversarial loss: 0.417869\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428081; batch adversarial loss: 0.512890\n",
      "epoch 11; iter: 200; batch classifier loss: 0.317713; batch adversarial loss: 0.461820\n",
      "epoch 11; iter: 400; batch classifier loss: 0.339001; batch adversarial loss: 0.412392\n",
      "epoch 11; iter: 600; batch classifier loss: 0.305661; batch adversarial loss: 0.494861\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312528; batch adversarial loss: 0.483314\n",
      "epoch 12; iter: 200; batch classifier loss: 0.444417; batch adversarial loss: 0.348795\n",
      "epoch 12; iter: 400; batch classifier loss: 0.302040; batch adversarial loss: 0.426118\n",
      "epoch 12; iter: 600; batch classifier loss: 0.493404; batch adversarial loss: 0.490130\n",
      "epoch 13; iter: 0; batch classifier loss: 0.247489; batch adversarial loss: 0.376196\n",
      "epoch 13; iter: 200; batch classifier loss: 0.367739; batch adversarial loss: 0.354142\n",
      "epoch 13; iter: 400; batch classifier loss: 0.310869; batch adversarial loss: 0.356126\n",
      "epoch 13; iter: 600; batch classifier loss: 0.482880; batch adversarial loss: 0.319588\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344699; batch adversarial loss: 0.515712\n",
      "epoch 14; iter: 200; batch classifier loss: 0.244609; batch adversarial loss: 0.475096\n",
      "epoch 14; iter: 400; batch classifier loss: 0.272036; batch adversarial loss: 0.526810\n",
      "epoch 14; iter: 600; batch classifier loss: 0.349301; batch adversarial loss: 0.430815\n",
      "epoch 15; iter: 0; batch classifier loss: 0.640417; batch adversarial loss: 0.376560\n",
      "epoch 15; iter: 200; batch classifier loss: 0.403943; batch adversarial loss: 0.488819\n",
      "epoch 15; iter: 400; batch classifier loss: 0.324865; batch adversarial loss: 0.619056\n",
      "epoch 15; iter: 600; batch classifier loss: 0.442709; batch adversarial loss: 0.526102\n",
      "epoch 16; iter: 0; batch classifier loss: 0.405095; batch adversarial loss: 0.474466\n",
      "epoch 16; iter: 200; batch classifier loss: 0.431182; batch adversarial loss: 0.571147\n",
      "epoch 16; iter: 400; batch classifier loss: 0.285825; batch adversarial loss: 0.481317\n",
      "epoch 16; iter: 600; batch classifier loss: 0.315206; batch adversarial loss: 0.260409\n",
      "epoch 17; iter: 0; batch classifier loss: 0.354298; batch adversarial loss: 0.400758\n",
      "epoch 17; iter: 200; batch classifier loss: 0.389462; batch adversarial loss: 0.433720\n",
      "epoch 17; iter: 400; batch classifier loss: 0.395169; batch adversarial loss: 0.343290\n",
      "epoch 17; iter: 600; batch classifier loss: 0.416852; batch adversarial loss: 0.456805\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476074; batch adversarial loss: 0.484664\n",
      "epoch 18; iter: 200; batch classifier loss: 0.346191; batch adversarial loss: 0.512587\n",
      "epoch 18; iter: 400; batch classifier loss: 0.379111; batch adversarial loss: 0.475297\n",
      "epoch 18; iter: 600; batch classifier loss: 0.347095; batch adversarial loss: 0.493544\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375856; batch adversarial loss: 0.381447\n",
      "epoch 19; iter: 200; batch classifier loss: 0.226767; batch adversarial loss: 0.290318\n",
      "epoch 19; iter: 400; batch classifier loss: 0.400328; batch adversarial loss: 0.429199\n",
      "epoch 19; iter: 600; batch classifier loss: 0.326051; batch adversarial loss: 0.295795\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 44.807255; batch adversarial loss: 0.556005\n",
      "epoch 0; iter: 200; batch classifier loss: 16.120157; batch adversarial loss: 0.597590\n",
      "epoch 0; iter: 400; batch classifier loss: 1.384639; batch adversarial loss: 0.545448\n",
      "epoch 0; iter: 600; batch classifier loss: 0.584279; batch adversarial loss: 0.518405\n",
      "epoch 1; iter: 0; batch classifier loss: 2.017109; batch adversarial loss: 0.540291\n",
      "epoch 1; iter: 200; batch classifier loss: 7.891961; batch adversarial loss: 0.450251\n",
      "epoch 1; iter: 400; batch classifier loss: 5.437518; batch adversarial loss: 0.380512\n",
      "epoch 1; iter: 600; batch classifier loss: 5.634694; batch adversarial loss: 0.456298\n",
      "epoch 2; iter: 0; batch classifier loss: 4.450827; batch adversarial loss: 0.397250\n",
      "epoch 2; iter: 200; batch classifier loss: 1.762211; batch adversarial loss: 0.502153\n",
      "epoch 2; iter: 400; batch classifier loss: 6.253793; batch adversarial loss: 0.358676\n",
      "epoch 2; iter: 600; batch classifier loss: 3.423510; batch adversarial loss: 0.524187\n",
      "epoch 3; iter: 0; batch classifier loss: 2.540093; batch adversarial loss: 0.449519\n",
      "epoch 3; iter: 200; batch classifier loss: 1.104397; batch adversarial loss: 0.298311\n",
      "epoch 3; iter: 400; batch classifier loss: 0.772620; batch adversarial loss: 0.331657\n",
      "epoch 3; iter: 600; batch classifier loss: 0.312408; batch adversarial loss: 0.452356\n",
      "epoch 4; iter: 0; batch classifier loss: 1.900607; batch adversarial loss: 0.350101\n",
      "epoch 4; iter: 200; batch classifier loss: 1.550443; batch adversarial loss: 0.269764\n",
      "epoch 4; iter: 400; batch classifier loss: 0.531654; batch adversarial loss: 0.511852\n",
      "epoch 4; iter: 600; batch classifier loss: 0.547592; batch adversarial loss: 0.417920\n",
      "epoch 5; iter: 0; batch classifier loss: 0.899395; batch adversarial loss: 0.456147\n",
      "epoch 5; iter: 200; batch classifier loss: 0.385338; batch adversarial loss: 0.426145\n",
      "epoch 5; iter: 400; batch classifier loss: 0.615472; batch adversarial loss: 0.423117\n",
      "epoch 5; iter: 600; batch classifier loss: 0.364189; batch adversarial loss: 0.389080\n",
      "epoch 6; iter: 0; batch classifier loss: 0.367814; batch adversarial loss: 0.305729\n",
      "epoch 6; iter: 200; batch classifier loss: 0.419239; batch adversarial loss: 0.525356\n",
      "epoch 6; iter: 400; batch classifier loss: 0.522055; batch adversarial loss: 0.316233\n",
      "epoch 6; iter: 600; batch classifier loss: 0.437446; batch adversarial loss: 0.428995\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495098; batch adversarial loss: 0.443321\n",
      "epoch 7; iter: 200; batch classifier loss: 0.471363; batch adversarial loss: 0.382480\n",
      "epoch 7; iter: 400; batch classifier loss: 0.830610; batch adversarial loss: 0.512705\n",
      "epoch 7; iter: 600; batch classifier loss: 0.447802; batch adversarial loss: 0.465190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421920; batch adversarial loss: 0.465912\n",
      "epoch 8; iter: 200; batch classifier loss: 0.335164; batch adversarial loss: 0.327364\n",
      "epoch 8; iter: 400; batch classifier loss: 0.900927; batch adversarial loss: 0.372786\n",
      "epoch 8; iter: 600; batch classifier loss: 0.459084; batch adversarial loss: 0.483841\n",
      "epoch 9; iter: 0; batch classifier loss: 0.244445; batch adversarial loss: 0.494566\n",
      "epoch 9; iter: 200; batch classifier loss: 0.372435; batch adversarial loss: 0.463381\n",
      "epoch 9; iter: 400; batch classifier loss: 0.470639; batch adversarial loss: 0.327640\n",
      "epoch 9; iter: 600; batch classifier loss: 0.334378; batch adversarial loss: 0.417998\n",
      "epoch 10; iter: 0; batch classifier loss: 0.358986; batch adversarial loss: 0.388283\n",
      "epoch 10; iter: 200; batch classifier loss: 0.610480; batch adversarial loss: 0.316734\n",
      "epoch 10; iter: 400; batch classifier loss: 0.399960; batch adversarial loss: 0.372862\n",
      "epoch 10; iter: 600; batch classifier loss: 0.293695; batch adversarial loss: 0.564822\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275312; batch adversarial loss: 0.347242\n",
      "epoch 11; iter: 200; batch classifier loss: 0.211778; batch adversarial loss: 0.396365\n",
      "epoch 11; iter: 400; batch classifier loss: 0.348474; batch adversarial loss: 0.369572\n",
      "epoch 11; iter: 600; batch classifier loss: 0.404727; batch adversarial loss: 0.209147\n",
      "epoch 12; iter: 0; batch classifier loss: 0.283674; batch adversarial loss: 0.447777\n",
      "epoch 12; iter: 200; batch classifier loss: 0.336046; batch adversarial loss: 0.462322\n",
      "epoch 12; iter: 400; batch classifier loss: 0.413446; batch adversarial loss: 0.403618\n",
      "epoch 12; iter: 600; batch classifier loss: 0.356259; batch adversarial loss: 0.369603\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396479; batch adversarial loss: 0.464609\n",
      "epoch 13; iter: 200; batch classifier loss: 0.329951; batch adversarial loss: 0.518157\n",
      "epoch 13; iter: 400; batch classifier loss: 0.305018; batch adversarial loss: 0.410972\n",
      "epoch 13; iter: 600; batch classifier loss: 0.252965; batch adversarial loss: 0.488665\n",
      "epoch 14; iter: 0; batch classifier loss: 0.422155; batch adversarial loss: 0.442838\n",
      "epoch 14; iter: 200; batch classifier loss: 0.368358; batch adversarial loss: 0.401540\n",
      "epoch 14; iter: 400; batch classifier loss: 0.411328; batch adversarial loss: 0.376093\n",
      "epoch 14; iter: 600; batch classifier loss: 0.295861; batch adversarial loss: 0.369144\n",
      "epoch 15; iter: 0; batch classifier loss: 0.188755; batch adversarial loss: 0.436750\n",
      "epoch 15; iter: 200; batch classifier loss: 0.301937; batch adversarial loss: 0.504351\n",
      "epoch 15; iter: 400; batch classifier loss: 0.344440; batch adversarial loss: 0.488058\n",
      "epoch 15; iter: 600; batch classifier loss: 0.313627; batch adversarial loss: 0.319975\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318594; batch adversarial loss: 0.375089\n",
      "epoch 16; iter: 200; batch classifier loss: 0.387470; batch adversarial loss: 0.365008\n",
      "epoch 16; iter: 400; batch classifier loss: 0.309426; batch adversarial loss: 0.446583\n",
      "epoch 16; iter: 600; batch classifier loss: 0.382033; batch adversarial loss: 0.426162\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522018; batch adversarial loss: 0.408275\n",
      "epoch 17; iter: 200; batch classifier loss: 0.445097; batch adversarial loss: 0.401240\n",
      "epoch 17; iter: 400; batch classifier loss: 0.477343; batch adversarial loss: 0.448071\n",
      "epoch 17; iter: 600; batch classifier loss: 0.436159; batch adversarial loss: 0.376053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476082; batch adversarial loss: 0.435611\n",
      "epoch 18; iter: 200; batch classifier loss: 0.303389; batch adversarial loss: 0.479669\n",
      "epoch 18; iter: 400; batch classifier loss: 0.566365; batch adversarial loss: 0.536611\n",
      "epoch 18; iter: 600; batch classifier loss: 0.447566; batch adversarial loss: 0.548720\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537681; batch adversarial loss: 0.473618\n",
      "epoch 19; iter: 200; batch classifier loss: 0.320970; batch adversarial loss: 0.354481\n",
      "epoch 19; iter: 400; batch classifier loss: 0.483756; batch adversarial loss: 0.346662\n",
      "epoch 19; iter: 600; batch classifier loss: 0.547603; batch adversarial loss: 0.295596\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440968; batch adversarial loss: 0.290195\n",
      "epoch 20; iter: 200; batch classifier loss: 0.341780; batch adversarial loss: 0.321276\n",
      "epoch 20; iter: 400; batch classifier loss: 0.530380; batch adversarial loss: 0.444154\n",
      "epoch 20; iter: 600; batch classifier loss: 0.690418; batch adversarial loss: 0.393523\n",
      "epoch 21; iter: 0; batch classifier loss: 0.382184; batch adversarial loss: 0.614368\n",
      "epoch 21; iter: 200; batch classifier loss: 0.369406; batch adversarial loss: 0.291259\n",
      "epoch 21; iter: 400; batch classifier loss: 0.381045; batch adversarial loss: 0.348621\n",
      "epoch 21; iter: 600; batch classifier loss: 0.486196; batch adversarial loss: 0.372449\n",
      "epoch 22; iter: 0; batch classifier loss: 0.569278; batch adversarial loss: 0.382012\n",
      "epoch 22; iter: 200; batch classifier loss: 0.491046; batch adversarial loss: 0.460497\n",
      "epoch 22; iter: 400; batch classifier loss: 0.544789; batch adversarial loss: 0.509568\n",
      "epoch 22; iter: 600; batch classifier loss: 0.277558; batch adversarial loss: 0.620438\n",
      "epoch 23; iter: 0; batch classifier loss: 0.346440; batch adversarial loss: 0.373079\n",
      "epoch 23; iter: 200; batch classifier loss: 0.379632; batch adversarial loss: 0.398547\n",
      "epoch 23; iter: 400; batch classifier loss: 0.451570; batch adversarial loss: 0.351457\n",
      "epoch 23; iter: 600; batch classifier loss: 0.458882; batch adversarial loss: 0.465035\n",
      "epoch 24; iter: 0; batch classifier loss: 0.478437; batch adversarial loss: 0.403647\n",
      "epoch 24; iter: 200; batch classifier loss: 0.403829; batch adversarial loss: 0.424796\n",
      "epoch 24; iter: 400; batch classifier loss: 0.555594; batch adversarial loss: 0.407192\n",
      "epoch 24; iter: 600; batch classifier loss: 0.398903; batch adversarial loss: 0.472104\n",
      "epoch 25; iter: 0; batch classifier loss: 0.595237; batch adversarial loss: 0.464923\n",
      "epoch 25; iter: 200; batch classifier loss: 0.622185; batch adversarial loss: 0.614770\n",
      "epoch 25; iter: 400; batch classifier loss: 0.425282; batch adversarial loss: 0.374948\n",
      "epoch 25; iter: 600; batch classifier loss: 0.323939; batch adversarial loss: 0.347352\n",
      "epoch 26; iter: 0; batch classifier loss: 0.418325; batch adversarial loss: 0.404922\n",
      "epoch 26; iter: 200; batch classifier loss: 0.591048; batch adversarial loss: 0.509557\n",
      "epoch 26; iter: 400; batch classifier loss: 0.416473; batch adversarial loss: 0.268280\n",
      "epoch 26; iter: 600; batch classifier loss: 0.381767; batch adversarial loss: 0.374807\n",
      "epoch 27; iter: 0; batch classifier loss: 0.639702; batch adversarial loss: 0.349252\n",
      "epoch 27; iter: 200; batch classifier loss: 0.573617; batch adversarial loss: 0.376134\n",
      "epoch 27; iter: 400; batch classifier loss: 0.675551; batch adversarial loss: 0.318009\n",
      "epoch 27; iter: 600; batch classifier loss: 0.550163; batch adversarial loss: 0.597848\n",
      "epoch 28; iter: 0; batch classifier loss: 0.611511; batch adversarial loss: 0.343094\n",
      "epoch 28; iter: 200; batch classifier loss: 0.386812; batch adversarial loss: 0.357985\n",
      "epoch 28; iter: 400; batch classifier loss: 0.292477; batch adversarial loss: 0.508151\n",
      "epoch 28; iter: 600; batch classifier loss: 0.605800; batch adversarial loss: 0.373398\n",
      "epoch 29; iter: 0; batch classifier loss: 0.791291; batch adversarial loss: 0.430490\n",
      "epoch 29; iter: 200; batch classifier loss: 0.457137; batch adversarial loss: 0.403757\n",
      "epoch 29; iter: 400; batch classifier loss: 0.558613; batch adversarial loss: 0.432925\n",
      "epoch 29; iter: 600; batch classifier loss: 0.415812; batch adversarial loss: 0.462689\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442529; batch adversarial loss: 0.320487\n",
      "epoch 30; iter: 200; batch classifier loss: 0.465299; batch adversarial loss: 0.358735\n",
      "epoch 30; iter: 400; batch classifier loss: 0.577164; batch adversarial loss: 0.381962\n",
      "epoch 30; iter: 600; batch classifier loss: 0.459972; batch adversarial loss: 0.463948\n",
      "epoch 31; iter: 0; batch classifier loss: 0.739842; batch adversarial loss: 0.492923\n",
      "epoch 31; iter: 200; batch classifier loss: 0.555979; batch adversarial loss: 0.381087\n",
      "epoch 31; iter: 400; batch classifier loss: 0.757313; batch adversarial loss: 0.347207\n",
      "epoch 31; iter: 600; batch classifier loss: 0.336793; batch adversarial loss: 0.321638\n",
      "epoch 32; iter: 0; batch classifier loss: 0.522662; batch adversarial loss: 0.499608\n",
      "epoch 32; iter: 200; batch classifier loss: 0.376089; batch adversarial loss: 0.462553\n",
      "epoch 32; iter: 400; batch classifier loss: 0.539399; batch adversarial loss: 0.541407\n",
      "epoch 32; iter: 600; batch classifier loss: 0.525758; batch adversarial loss: 0.404437\n",
      "epoch 33; iter: 0; batch classifier loss: 0.620799; batch adversarial loss: 0.436907\n",
      "epoch 33; iter: 200; batch classifier loss: 0.634801; batch adversarial loss: 0.371970\n",
      "epoch 33; iter: 400; batch classifier loss: 0.402339; batch adversarial loss: 0.573130\n",
      "epoch 33; iter: 600; batch classifier loss: 0.712030; batch adversarial loss: 0.409271\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427467; batch adversarial loss: 0.462322\n",
      "epoch 34; iter: 200; batch classifier loss: 0.328134; batch adversarial loss: 0.402345\n",
      "epoch 34; iter: 400; batch classifier loss: 0.537824; batch adversarial loss: 0.477655\n",
      "epoch 34; iter: 600; batch classifier loss: 0.740628; batch adversarial loss: 0.438362\n",
      "epoch 35; iter: 0; batch classifier loss: 0.734819; batch adversarial loss: 0.350941\n",
      "epoch 35; iter: 200; batch classifier loss: 0.617571; batch adversarial loss: 0.318316\n",
      "epoch 35; iter: 400; batch classifier loss: 0.554755; batch adversarial loss: 0.548195\n",
      "epoch 35; iter: 600; batch classifier loss: 0.782337; batch adversarial loss: 0.346704\n",
      "epoch 36; iter: 0; batch classifier loss: 0.519294; batch adversarial loss: 0.510529\n",
      "epoch 36; iter: 200; batch classifier loss: 0.504884; batch adversarial loss: 0.513172\n",
      "epoch 36; iter: 400; batch classifier loss: 0.550715; batch adversarial loss: 0.432738\n",
      "epoch 36; iter: 600; batch classifier loss: 0.566403; batch adversarial loss: 0.320869\n",
      "epoch 37; iter: 0; batch classifier loss: 0.744072; batch adversarial loss: 0.410636\n",
      "epoch 37; iter: 200; batch classifier loss: 0.679611; batch adversarial loss: 0.428888\n",
      "epoch 37; iter: 400; batch classifier loss: 0.823343; batch adversarial loss: 0.411225\n",
      "epoch 37; iter: 600; batch classifier loss: 0.589565; batch adversarial loss: 0.565865\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474941; batch adversarial loss: 0.376184\n",
      "epoch 38; iter: 200; batch classifier loss: 0.854381; batch adversarial loss: 0.357244\n",
      "epoch 38; iter: 400; batch classifier loss: 0.522616; batch adversarial loss: 0.432246\n",
      "epoch 38; iter: 600; batch classifier loss: 0.527603; batch adversarial loss: 0.269034\n",
      "epoch 39; iter: 0; batch classifier loss: 0.674692; batch adversarial loss: 0.375557\n",
      "epoch 39; iter: 200; batch classifier loss: 0.484061; batch adversarial loss: 0.321621\n",
      "epoch 39; iter: 400; batch classifier loss: 0.472081; batch adversarial loss: 0.347758\n",
      "epoch 39; iter: 600; batch classifier loss: 0.564661; batch adversarial loss: 0.563714\n",
      "epoch 40; iter: 0; batch classifier loss: 0.529013; batch adversarial loss: 0.464208\n",
      "epoch 40; iter: 200; batch classifier loss: 0.541569; batch adversarial loss: 0.290816\n",
      "epoch 40; iter: 400; batch classifier loss: 0.579126; batch adversarial loss: 0.520158\n",
      "epoch 40; iter: 600; batch classifier loss: 0.437905; batch adversarial loss: 0.292291\n",
      "epoch 41; iter: 0; batch classifier loss: 0.439485; batch adversarial loss: 0.292130\n",
      "epoch 41; iter: 200; batch classifier loss: 0.473933; batch adversarial loss: 0.428790\n",
      "epoch 41; iter: 400; batch classifier loss: 0.491523; batch adversarial loss: 0.347299\n",
      "epoch 41; iter: 600; batch classifier loss: 0.428603; batch adversarial loss: 0.376609\n",
      "epoch 42; iter: 0; batch classifier loss: 0.462260; batch adversarial loss: 0.374623\n",
      "epoch 42; iter: 200; batch classifier loss: 0.562226; batch adversarial loss: 0.295166\n",
      "epoch 42; iter: 400; batch classifier loss: 0.627083; batch adversarial loss: 0.321478\n",
      "epoch 42; iter: 600; batch classifier loss: 0.809682; batch adversarial loss: 0.406718\n",
      "epoch 43; iter: 0; batch classifier loss: 0.821037; batch adversarial loss: 0.374437\n",
      "epoch 43; iter: 200; batch classifier loss: 0.523127; batch adversarial loss: 0.380546\n",
      "epoch 43; iter: 400; batch classifier loss: 0.413477; batch adversarial loss: 0.402361\n",
      "epoch 43; iter: 600; batch classifier loss: 0.795721; batch adversarial loss: 0.483942\n",
      "epoch 44; iter: 0; batch classifier loss: 0.557455; batch adversarial loss: 0.332419\n",
      "epoch 44; iter: 200; batch classifier loss: 1.144380; batch adversarial loss: 0.375216\n",
      "epoch 44; iter: 400; batch classifier loss: 0.442673; batch adversarial loss: 0.459231\n",
      "epoch 44; iter: 600; batch classifier loss: 0.484400; batch adversarial loss: 0.401515\n",
      "epoch 45; iter: 0; batch classifier loss: 0.661839; batch adversarial loss: 0.420421\n",
      "epoch 45; iter: 200; batch classifier loss: 0.618146; batch adversarial loss: 0.400112\n",
      "epoch 45; iter: 400; batch classifier loss: 0.679254; batch adversarial loss: 0.291175\n",
      "epoch 45; iter: 600; batch classifier loss: 0.626860; batch adversarial loss: 0.460580\n",
      "epoch 46; iter: 0; batch classifier loss: 0.616393; batch adversarial loss: 0.522053\n",
      "epoch 46; iter: 200; batch classifier loss: 0.584629; batch adversarial loss: 0.427767\n",
      "epoch 46; iter: 400; batch classifier loss: 0.891650; batch adversarial loss: 0.402984\n",
      "epoch 46; iter: 600; batch classifier loss: 0.706812; batch adversarial loss: 0.274305\n",
      "epoch 47; iter: 0; batch classifier loss: 0.618249; batch adversarial loss: 0.457501\n",
      "epoch 47; iter: 200; batch classifier loss: 0.686727; batch adversarial loss: 0.429113\n",
      "epoch 47; iter: 400; batch classifier loss: 0.530808; batch adversarial loss: 0.263526\n",
      "epoch 47; iter: 600; batch classifier loss: 0.649244; batch adversarial loss: 0.345883\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452103; batch adversarial loss: 0.605236\n",
      "epoch 48; iter: 200; batch classifier loss: 1.031563; batch adversarial loss: 0.376403\n",
      "epoch 48; iter: 400; batch classifier loss: 0.581161; batch adversarial loss: 0.546213\n",
      "epoch 48; iter: 600; batch classifier loss: 0.414245; batch adversarial loss: 0.428493\n",
      "epoch 49; iter: 0; batch classifier loss: 0.728381; batch adversarial loss: 0.294195\n",
      "epoch 49; iter: 200; batch classifier loss: 0.524992; batch adversarial loss: 0.322363\n",
      "epoch 49; iter: 400; batch classifier loss: 0.688791; batch adversarial loss: 0.433496\n",
      "epoch 49; iter: 600; batch classifier loss: 0.539661; batch adversarial loss: 0.483277\n",
      "epoch 0; iter: 0; batch classifier loss: 30.873833; batch adversarial loss: 0.617530\n",
      "epoch 0; iter: 200; batch classifier loss: 6.713424; batch adversarial loss: 0.601461\n",
      "epoch 0; iter: 400; batch classifier loss: 5.869250; batch adversarial loss: 0.551295\n",
      "epoch 0; iter: 600; batch classifier loss: 12.721098; batch adversarial loss: 0.495160\n",
      "epoch 1; iter: 0; batch classifier loss: 8.962057; batch adversarial loss: 0.486256\n",
      "epoch 1; iter: 200; batch classifier loss: 9.437746; batch adversarial loss: 0.484690\n",
      "epoch 1; iter: 400; batch classifier loss: 3.733309; batch adversarial loss: 0.425734\n",
      "epoch 1; iter: 600; batch classifier loss: 0.840933; batch adversarial loss: 0.435392\n",
      "epoch 2; iter: 0; batch classifier loss: 7.649582; batch adversarial loss: 0.362904\n",
      "epoch 2; iter: 200; batch classifier loss: 2.242857; batch adversarial loss: 0.429592\n",
      "epoch 2; iter: 400; batch classifier loss: 0.852691; batch adversarial loss: 0.465774\n",
      "epoch 2; iter: 600; batch classifier loss: 6.780187; batch adversarial loss: 0.383512\n",
      "epoch 3; iter: 0; batch classifier loss: 1.766404; batch adversarial loss: 0.394026\n",
      "epoch 3; iter: 200; batch classifier loss: 0.447071; batch adversarial loss: 0.300683\n",
      "epoch 3; iter: 400; batch classifier loss: 0.673747; batch adversarial loss: 0.333947\n",
      "epoch 3; iter: 600; batch classifier loss: 0.815083; batch adversarial loss: 0.267694\n",
      "epoch 4; iter: 0; batch classifier loss: 1.146190; batch adversarial loss: 0.363847\n",
      "epoch 4; iter: 200; batch classifier loss: 0.980597; batch adversarial loss: 0.392939\n",
      "epoch 4; iter: 400; batch classifier loss: 0.777127; batch adversarial loss: 0.536322\n",
      "epoch 4; iter: 600; batch classifier loss: 0.482257; batch adversarial loss: 0.391907\n",
      "epoch 5; iter: 0; batch classifier loss: 0.896254; batch adversarial loss: 0.435861\n",
      "epoch 5; iter: 200; batch classifier loss: 0.335061; batch adversarial loss: 0.365099\n",
      "epoch 5; iter: 400; batch classifier loss: 0.918331; batch adversarial loss: 0.418578\n",
      "epoch 5; iter: 600; batch classifier loss: 0.710196; batch adversarial loss: 0.465259\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573253; batch adversarial loss: 0.385698\n",
      "epoch 6; iter: 200; batch classifier loss: 0.381158; batch adversarial loss: 0.291965\n",
      "epoch 6; iter: 400; batch classifier loss: 0.472523; batch adversarial loss: 0.425337\n",
      "epoch 6; iter: 600; batch classifier loss: 0.577061; batch adversarial loss: 0.399892\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410933; batch adversarial loss: 0.498269\n",
      "epoch 7; iter: 200; batch classifier loss: 0.489399; batch adversarial loss: 0.342688\n",
      "epoch 7; iter: 400; batch classifier loss: 0.791198; batch adversarial loss: 0.513791\n",
      "epoch 7; iter: 600; batch classifier loss: 0.326357; batch adversarial loss: 0.458278\n",
      "epoch 8; iter: 0; batch classifier loss: 0.373463; batch adversarial loss: 0.410328\n",
      "epoch 8; iter: 200; batch classifier loss: 0.583891; batch adversarial loss: 0.454928\n",
      "epoch 8; iter: 400; batch classifier loss: 0.366178; batch adversarial loss: 0.506383\n",
      "epoch 8; iter: 600; batch classifier loss: 0.382402; batch adversarial loss: 0.436987\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342580; batch adversarial loss: 0.368183\n",
      "epoch 9; iter: 200; batch classifier loss: 0.391073; batch adversarial loss: 0.516378\n",
      "epoch 9; iter: 400; batch classifier loss: 0.305413; batch adversarial loss: 0.411038\n",
      "epoch 9; iter: 600; batch classifier loss: 0.375093; batch adversarial loss: 0.360486\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549887; batch adversarial loss: 0.510703\n",
      "epoch 10; iter: 200; batch classifier loss: 0.361947; batch adversarial loss: 0.448672\n",
      "epoch 10; iter: 400; batch classifier loss: 0.355660; batch adversarial loss: 0.484399\n",
      "epoch 10; iter: 600; batch classifier loss: 0.272670; batch adversarial loss: 0.383409\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414879; batch adversarial loss: 0.397591\n",
      "epoch 11; iter: 200; batch classifier loss: 0.609781; batch adversarial loss: 0.466325\n",
      "epoch 11; iter: 400; batch classifier loss: 0.374834; batch adversarial loss: 0.543042\n",
      "epoch 11; iter: 600; batch classifier loss: 0.525415; batch adversarial loss: 0.453708\n",
      "epoch 12; iter: 0; batch classifier loss: 0.389530; batch adversarial loss: 0.369219\n",
      "epoch 12; iter: 200; batch classifier loss: 0.261932; batch adversarial loss: 0.536371\n",
      "epoch 12; iter: 400; batch classifier loss: 0.499224; batch adversarial loss: 0.419019\n",
      "epoch 12; iter: 600; batch classifier loss: 0.297653; batch adversarial loss: 0.302679\n",
      "epoch 13; iter: 0; batch classifier loss: 0.345313; batch adversarial loss: 0.337770\n",
      "epoch 13; iter: 200; batch classifier loss: 0.414194; batch adversarial loss: 0.338593\n",
      "epoch 13; iter: 400; batch classifier loss: 0.422450; batch adversarial loss: 0.374972\n",
      "epoch 13; iter: 600; batch classifier loss: 0.233080; batch adversarial loss: 0.429716\n",
      "epoch 14; iter: 0; batch classifier loss: 0.317380; batch adversarial loss: 0.312157\n",
      "epoch 14; iter: 200; batch classifier loss: 0.382081; batch adversarial loss: 0.396325\n",
      "epoch 14; iter: 400; batch classifier loss: 0.405182; batch adversarial loss: 0.495465\n",
      "epoch 14; iter: 600; batch classifier loss: 0.391998; batch adversarial loss: 0.398416\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348681; batch adversarial loss: 0.453031\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392383; batch adversarial loss: 0.397951\n",
      "epoch 15; iter: 400; batch classifier loss: 0.390757; batch adversarial loss: 0.352778\n",
      "epoch 15; iter: 600; batch classifier loss: 0.505800; batch adversarial loss: 0.455367\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332925; batch adversarial loss: 0.318802\n",
      "epoch 16; iter: 200; batch classifier loss: 0.312661; batch adversarial loss: 0.217270\n",
      "epoch 16; iter: 400; batch classifier loss: 0.390139; batch adversarial loss: 0.440969\n",
      "epoch 16; iter: 600; batch classifier loss: 0.390184; batch adversarial loss: 0.428784\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463714; batch adversarial loss: 0.543061\n",
      "epoch 17; iter: 200; batch classifier loss: 0.479677; batch adversarial loss: 0.289118\n",
      "epoch 17; iter: 400; batch classifier loss: 0.364798; batch adversarial loss: 0.238915\n",
      "epoch 17; iter: 600; batch classifier loss: 0.383544; batch adversarial loss: 0.517173\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279120; batch adversarial loss: 0.480163\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321050; batch adversarial loss: 0.345359\n",
      "epoch 18; iter: 400; batch classifier loss: 0.346662; batch adversarial loss: 0.296629\n",
      "epoch 18; iter: 600; batch classifier loss: 0.483775; batch adversarial loss: 0.320478\n",
      "epoch 19; iter: 0; batch classifier loss: 0.348545; batch adversarial loss: 0.345883\n",
      "epoch 19; iter: 200; batch classifier loss: 0.488667; batch adversarial loss: 0.570362\n",
      "epoch 19; iter: 400; batch classifier loss: 0.316691; batch adversarial loss: 0.434323\n",
      "epoch 19; iter: 600; batch classifier loss: 0.378895; batch adversarial loss: 0.322340\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457806; batch adversarial loss: 0.369691\n",
      "epoch 20; iter: 200; batch classifier loss: 0.384943; batch adversarial loss: 0.494779\n",
      "epoch 20; iter: 400; batch classifier loss: 0.547137; batch adversarial loss: 0.491834\n",
      "epoch 20; iter: 600; batch classifier loss: 0.373191; batch adversarial loss: 0.344195\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477510; batch adversarial loss: 0.370249\n",
      "epoch 21; iter: 200; batch classifier loss: 0.293040; batch adversarial loss: 0.400411\n",
      "epoch 21; iter: 400; batch classifier loss: 0.305873; batch adversarial loss: 0.421354\n",
      "epoch 21; iter: 600; batch classifier loss: 0.453467; batch adversarial loss: 0.545147\n",
      "epoch 22; iter: 0; batch classifier loss: 0.343814; batch adversarial loss: 0.353865\n",
      "epoch 22; iter: 200; batch classifier loss: 0.324486; batch adversarial loss: 0.424852\n",
      "epoch 22; iter: 400; batch classifier loss: 0.341254; batch adversarial loss: 0.520596\n",
      "epoch 22; iter: 600; batch classifier loss: 0.236275; batch adversarial loss: 0.458673\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380657; batch adversarial loss: 0.566945\n",
      "epoch 23; iter: 200; batch classifier loss: 0.303052; batch adversarial loss: 0.340125\n",
      "epoch 23; iter: 400; batch classifier loss: 0.307519; batch adversarial loss: 0.427408\n",
      "epoch 23; iter: 600; batch classifier loss: 0.522284; batch adversarial loss: 0.557053\n",
      "epoch 24; iter: 0; batch classifier loss: 0.509441; batch adversarial loss: 0.350396\n",
      "epoch 24; iter: 200; batch classifier loss: 0.398412; batch adversarial loss: 0.457532\n",
      "epoch 24; iter: 400; batch classifier loss: 0.349995; batch adversarial loss: 0.486249\n",
      "epoch 24; iter: 600; batch classifier loss: 0.408515; batch adversarial loss: 0.346703\n",
      "epoch 25; iter: 0; batch classifier loss: 0.400181; batch adversarial loss: 0.481722\n",
      "epoch 25; iter: 200; batch classifier loss: 0.461419; batch adversarial loss: 0.372682\n",
      "epoch 25; iter: 400; batch classifier loss: 0.398456; batch adversarial loss: 0.494402\n",
      "epoch 25; iter: 600; batch classifier loss: 0.392270; batch adversarial loss: 0.327342\n",
      "epoch 26; iter: 0; batch classifier loss: 0.408916; batch adversarial loss: 0.460963\n",
      "epoch 26; iter: 200; batch classifier loss: 0.431570; batch adversarial loss: 0.528571\n",
      "epoch 26; iter: 400; batch classifier loss: 0.522035; batch adversarial loss: 0.380743\n",
      "epoch 26; iter: 600; batch classifier loss: 0.402957; batch adversarial loss: 0.354228\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411903; batch adversarial loss: 0.316233\n",
      "epoch 27; iter: 200; batch classifier loss: 0.475839; batch adversarial loss: 0.405217\n",
      "epoch 27; iter: 400; batch classifier loss: 0.372145; batch adversarial loss: 0.351970\n",
      "epoch 27; iter: 600; batch classifier loss: 0.553490; batch adversarial loss: 0.492731\n",
      "epoch 28; iter: 0; batch classifier loss: 0.384946; batch adversarial loss: 0.471319\n",
      "epoch 28; iter: 200; batch classifier loss: 0.501928; batch adversarial loss: 0.463826\n",
      "epoch 28; iter: 400; batch classifier loss: 0.606000; batch adversarial loss: 0.437477\n",
      "epoch 28; iter: 600; batch classifier loss: 0.625955; batch adversarial loss: 0.708259\n",
      "epoch 29; iter: 0; batch classifier loss: 0.495377; batch adversarial loss: 0.488461\n",
      "epoch 29; iter: 200; batch classifier loss: 0.545750; batch adversarial loss: 0.322679\n",
      "epoch 29; iter: 400; batch classifier loss: 0.465990; batch adversarial loss: 0.458757\n",
      "epoch 29; iter: 600; batch classifier loss: 0.434667; batch adversarial loss: 0.377060\n",
      "epoch 30; iter: 0; batch classifier loss: 0.548114; batch adversarial loss: 0.317837\n",
      "epoch 30; iter: 200; batch classifier loss: 0.742930; batch adversarial loss: 0.417388\n",
      "epoch 30; iter: 400; batch classifier loss: 0.382236; batch adversarial loss: 0.547098\n",
      "epoch 30; iter: 600; batch classifier loss: 0.425336; batch adversarial loss: 0.482673\n",
      "epoch 31; iter: 0; batch classifier loss: 0.375105; batch adversarial loss: 0.427076\n",
      "epoch 31; iter: 200; batch classifier loss: 0.477471; batch adversarial loss: 0.512316\n",
      "epoch 31; iter: 400; batch classifier loss: 0.983796; batch adversarial loss: 0.407498\n",
      "epoch 31; iter: 600; batch classifier loss: 0.606919; batch adversarial loss: 0.292954\n",
      "epoch 32; iter: 0; batch classifier loss: 0.606286; batch adversarial loss: 0.325566\n",
      "epoch 32; iter: 200; batch classifier loss: 0.402949; batch adversarial loss: 0.409096\n",
      "epoch 32; iter: 400; batch classifier loss: 0.513709; batch adversarial loss: 0.376460\n",
      "epoch 32; iter: 600; batch classifier loss: 0.321130; batch adversarial loss: 0.347031\n",
      "epoch 33; iter: 0; batch classifier loss: 0.452014; batch adversarial loss: 0.290721\n",
      "epoch 33; iter: 200; batch classifier loss: 0.398614; batch adversarial loss: 0.461602\n",
      "epoch 33; iter: 400; batch classifier loss: 0.467984; batch adversarial loss: 0.442414\n",
      "epoch 33; iter: 600; batch classifier loss: 0.277544; batch adversarial loss: 0.430715\n",
      "epoch 34; iter: 0; batch classifier loss: 0.297456; batch adversarial loss: 0.298747\n",
      "epoch 34; iter: 200; batch classifier loss: 0.436208; batch adversarial loss: 0.401294\n",
      "epoch 34; iter: 400; batch classifier loss: 0.585245; batch adversarial loss: 0.469873\n",
      "epoch 34; iter: 600; batch classifier loss: 0.485366; batch adversarial loss: 0.398644\n",
      "epoch 35; iter: 0; batch classifier loss: 0.510550; batch adversarial loss: 0.410192\n",
      "epoch 35; iter: 200; batch classifier loss: 0.638084; batch adversarial loss: 0.376084\n",
      "epoch 35; iter: 400; batch classifier loss: 0.671369; batch adversarial loss: 0.378647\n",
      "epoch 35; iter: 600; batch classifier loss: 0.625130; batch adversarial loss: 0.322077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.588099; batch adversarial loss: 0.473157\n",
      "epoch 36; iter: 200; batch classifier loss: 0.524438; batch adversarial loss: 0.374445\n",
      "epoch 36; iter: 400; batch classifier loss: 0.568659; batch adversarial loss: 0.400547\n",
      "epoch 36; iter: 600; batch classifier loss: 0.257609; batch adversarial loss: 0.348434\n",
      "epoch 37; iter: 0; batch classifier loss: 0.494589; batch adversarial loss: 0.463369\n",
      "epoch 37; iter: 200; batch classifier loss: 0.663604; batch adversarial loss: 0.519374\n",
      "epoch 37; iter: 400; batch classifier loss: 0.537462; batch adversarial loss: 0.406435\n",
      "epoch 37; iter: 600; batch classifier loss: 0.424060; batch adversarial loss: 0.437555\n",
      "epoch 38; iter: 0; batch classifier loss: 0.383744; batch adversarial loss: 0.293800\n",
      "epoch 38; iter: 200; batch classifier loss: 0.523559; batch adversarial loss: 0.463702\n",
      "epoch 38; iter: 400; batch classifier loss: 0.461066; batch adversarial loss: 0.374176\n",
      "epoch 38; iter: 600; batch classifier loss: 0.610102; batch adversarial loss: 0.291458\n",
      "epoch 39; iter: 0; batch classifier loss: 0.546893; batch adversarial loss: 0.354503\n",
      "epoch 39; iter: 200; batch classifier loss: 0.445889; batch adversarial loss: 0.595315\n",
      "epoch 39; iter: 400; batch classifier loss: 0.626145; batch adversarial loss: 0.321672\n",
      "epoch 39; iter: 600; batch classifier loss: 0.492694; batch adversarial loss: 0.461994\n",
      "epoch 40; iter: 0; batch classifier loss: 0.650453; batch adversarial loss: 0.401009\n",
      "epoch 40; iter: 200; batch classifier loss: 0.596817; batch adversarial loss: 0.376046\n",
      "epoch 40; iter: 400; batch classifier loss: 0.670160; batch adversarial loss: 0.409613\n",
      "epoch 40; iter: 600; batch classifier loss: 0.651281; batch adversarial loss: 0.521223\n",
      "epoch 41; iter: 0; batch classifier loss: 0.639554; batch adversarial loss: 0.407863\n",
      "epoch 41; iter: 200; batch classifier loss: 0.596244; batch adversarial loss: 0.382578\n",
      "epoch 41; iter: 400; batch classifier loss: 0.472242; batch adversarial loss: 0.371614\n",
      "epoch 41; iter: 600; batch classifier loss: 0.348474; batch adversarial loss: 0.410582\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457748; batch adversarial loss: 0.515062\n",
      "epoch 42; iter: 200; batch classifier loss: 0.332991; batch adversarial loss: 0.402608\n",
      "epoch 42; iter: 400; batch classifier loss: 0.511792; batch adversarial loss: 0.275836\n",
      "epoch 42; iter: 600; batch classifier loss: 0.298455; batch adversarial loss: 0.414727\n",
      "epoch 43; iter: 0; batch classifier loss: 0.563883; batch adversarial loss: 0.245284\n",
      "epoch 43; iter: 200; batch classifier loss: 0.612766; batch adversarial loss: 0.601620\n",
      "epoch 43; iter: 400; batch classifier loss: 0.387529; batch adversarial loss: 0.346893\n",
      "epoch 43; iter: 600; batch classifier loss: 0.472220; batch adversarial loss: 0.511661\n",
      "epoch 44; iter: 0; batch classifier loss: 0.688114; batch adversarial loss: 0.465229\n",
      "epoch 44; iter: 200; batch classifier loss: 0.544478; batch adversarial loss: 0.327559\n",
      "epoch 44; iter: 400; batch classifier loss: 0.466096; batch adversarial loss: 0.401180\n",
      "epoch 44; iter: 600; batch classifier loss: 0.596052; batch adversarial loss: 0.380360\n",
      "epoch 45; iter: 0; batch classifier loss: 0.541514; batch adversarial loss: 0.489531\n",
      "epoch 45; iter: 200; batch classifier loss: 0.659195; batch adversarial loss: 0.265120\n",
      "epoch 45; iter: 400; batch classifier loss: 0.456733; batch adversarial loss: 0.350178\n",
      "epoch 45; iter: 600; batch classifier loss: 0.599954; batch adversarial loss: 0.408919\n",
      "epoch 46; iter: 0; batch classifier loss: 0.696907; batch adversarial loss: 0.347614\n",
      "epoch 46; iter: 200; batch classifier loss: 0.493010; batch adversarial loss: 0.479069\n",
      "epoch 46; iter: 400; batch classifier loss: 0.436670; batch adversarial loss: 0.455586\n",
      "epoch 46; iter: 600; batch classifier loss: 0.854549; batch adversarial loss: 0.437086\n",
      "epoch 47; iter: 0; batch classifier loss: 0.877380; batch adversarial loss: 0.458479\n",
      "epoch 47; iter: 200; batch classifier loss: 0.607396; batch adversarial loss: 0.598869\n",
      "epoch 47; iter: 400; batch classifier loss: 0.396770; batch adversarial loss: 0.487323\n",
      "epoch 47; iter: 600; batch classifier loss: 0.537296; batch adversarial loss: 0.429402\n",
      "epoch 48; iter: 0; batch classifier loss: 0.695010; batch adversarial loss: 0.293512\n",
      "epoch 48; iter: 200; batch classifier loss: 0.714246; batch adversarial loss: 0.429201\n",
      "epoch 48; iter: 400; batch classifier loss: 0.527060; batch adversarial loss: 0.484770\n",
      "epoch 48; iter: 600; batch classifier loss: 0.673067; batch adversarial loss: 0.404189\n",
      "epoch 49; iter: 0; batch classifier loss: 0.543903; batch adversarial loss: 0.404029\n",
      "epoch 49; iter: 200; batch classifier loss: 0.643813; batch adversarial loss: 0.354756\n",
      "epoch 49; iter: 400; batch classifier loss: 0.744556; batch adversarial loss: 0.485999\n",
      "epoch 49; iter: 600; batch classifier loss: 0.355134; batch adversarial loss: 0.438223\n",
      "epoch 0; iter: 0; batch classifier loss: 7.265358; batch adversarial loss: 0.480053\n",
      "epoch 0; iter: 200; batch classifier loss: 5.750246; batch adversarial loss: 0.582503\n",
      "epoch 0; iter: 400; batch classifier loss: 20.515911; batch adversarial loss: 0.573178\n",
      "epoch 0; iter: 600; batch classifier loss: 2.068043; batch adversarial loss: 0.507415\n",
      "epoch 1; iter: 0; batch classifier loss: 22.711712; batch adversarial loss: 0.489285\n",
      "epoch 1; iter: 200; batch classifier loss: 2.277308; batch adversarial loss: 0.510579\n",
      "epoch 1; iter: 400; batch classifier loss: 3.149401; batch adversarial loss: 0.469368\n",
      "epoch 1; iter: 600; batch classifier loss: 2.062426; batch adversarial loss: 0.514246\n",
      "epoch 2; iter: 0; batch classifier loss: 7.756651; batch adversarial loss: 0.410948\n",
      "epoch 2; iter: 200; batch classifier loss: 1.252536; batch adversarial loss: 0.411706\n",
      "epoch 2; iter: 400; batch classifier loss: 8.291809; batch adversarial loss: 0.515367\n",
      "epoch 2; iter: 600; batch classifier loss: 2.228619; batch adversarial loss: 0.415059\n",
      "epoch 3; iter: 0; batch classifier loss: 3.517684; batch adversarial loss: 0.485496\n",
      "epoch 3; iter: 200; batch classifier loss: 2.413392; batch adversarial loss: 0.540566\n",
      "epoch 3; iter: 400; batch classifier loss: 0.777591; batch adversarial loss: 0.474868\n",
      "epoch 3; iter: 600; batch classifier loss: 2.488901; batch adversarial loss: 0.485707\n",
      "epoch 4; iter: 0; batch classifier loss: 0.776877; batch adversarial loss: 0.510085\n",
      "epoch 4; iter: 200; batch classifier loss: 0.513977; batch adversarial loss: 0.462440\n",
      "epoch 4; iter: 400; batch classifier loss: 0.623955; batch adversarial loss: 0.439491\n",
      "epoch 4; iter: 600; batch classifier loss: 0.772952; batch adversarial loss: 0.411442\n",
      "epoch 5; iter: 0; batch classifier loss: 0.789782; batch adversarial loss: 0.366895\n",
      "epoch 5; iter: 200; batch classifier loss: 0.444672; batch adversarial loss: 0.418240\n",
      "epoch 5; iter: 400; batch classifier loss: 0.422555; batch adversarial loss: 0.322233\n",
      "epoch 5; iter: 600; batch classifier loss: 0.643907; batch adversarial loss: 0.407552\n",
      "epoch 6; iter: 0; batch classifier loss: 0.389890; batch adversarial loss: 0.511852\n",
      "epoch 6; iter: 200; batch classifier loss: 0.722284; batch adversarial loss: 0.486845\n",
      "epoch 6; iter: 400; batch classifier loss: 0.740655; batch adversarial loss: 0.376488\n",
      "epoch 6; iter: 600; batch classifier loss: 0.553976; batch adversarial loss: 0.455818\n",
      "epoch 7; iter: 0; batch classifier loss: 0.309285; batch adversarial loss: 0.433590\n",
      "epoch 7; iter: 200; batch classifier loss: 0.402000; batch adversarial loss: 0.316508\n",
      "epoch 7; iter: 400; batch classifier loss: 0.267907; batch adversarial loss: 0.523048\n",
      "epoch 7; iter: 600; batch classifier loss: 0.836432; batch adversarial loss: 0.440911\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438250; batch adversarial loss: 0.375792\n",
      "epoch 8; iter: 200; batch classifier loss: 0.567165; batch adversarial loss: 0.412177\n",
      "epoch 8; iter: 400; batch classifier loss: 0.548072; batch adversarial loss: 0.458611\n",
      "epoch 8; iter: 600; batch classifier loss: 0.395101; batch adversarial loss: 0.469719\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354888; batch adversarial loss: 0.458262\n",
      "epoch 9; iter: 200; batch classifier loss: 0.373480; batch adversarial loss: 0.471742\n",
      "epoch 9; iter: 400; batch classifier loss: 0.444672; batch adversarial loss: 0.346424\n",
      "epoch 9; iter: 600; batch classifier loss: 0.378150; batch adversarial loss: 0.336851\n",
      "epoch 10; iter: 0; batch classifier loss: 0.381727; batch adversarial loss: 0.562163\n",
      "epoch 10; iter: 200; batch classifier loss: 0.470986; batch adversarial loss: 0.344674\n",
      "epoch 10; iter: 400; batch classifier loss: 0.410931; batch adversarial loss: 0.411208\n",
      "epoch 10; iter: 600; batch classifier loss: 0.405400; batch adversarial loss: 0.543975\n",
      "epoch 11; iter: 0; batch classifier loss: 0.328582; batch adversarial loss: 0.545763\n",
      "epoch 11; iter: 200; batch classifier loss: 0.491701; batch adversarial loss: 0.453663\n",
      "epoch 11; iter: 400; batch classifier loss: 0.407963; batch adversarial loss: 0.502862\n",
      "epoch 11; iter: 600; batch classifier loss: 0.310152; batch adversarial loss: 0.576584\n",
      "epoch 12; iter: 0; batch classifier loss: 0.338413; batch adversarial loss: 0.551492\n",
      "epoch 12; iter: 200; batch classifier loss: 0.304156; batch adversarial loss: 0.400498\n",
      "epoch 12; iter: 400; batch classifier loss: 0.368468; batch adversarial loss: 0.458941\n",
      "epoch 12; iter: 600; batch classifier loss: 0.455485; batch adversarial loss: 0.289887\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356798; batch adversarial loss: 0.386950\n",
      "epoch 13; iter: 200; batch classifier loss: 0.330728; batch adversarial loss: 0.345712\n",
      "epoch 13; iter: 400; batch classifier loss: 0.396114; batch adversarial loss: 0.303995\n",
      "epoch 13; iter: 600; batch classifier loss: 0.348516; batch adversarial loss: 0.368815\n",
      "epoch 14; iter: 0; batch classifier loss: 0.272765; batch adversarial loss: 0.332292\n",
      "epoch 14; iter: 200; batch classifier loss: 0.463028; batch adversarial loss: 0.309812\n",
      "epoch 14; iter: 400; batch classifier loss: 0.403824; batch adversarial loss: 0.362951\n",
      "epoch 14; iter: 600; batch classifier loss: 0.422747; batch adversarial loss: 0.492532\n",
      "epoch 15; iter: 0; batch classifier loss: 0.315092; batch adversarial loss: 0.325181\n",
      "epoch 15; iter: 200; batch classifier loss: 0.347671; batch adversarial loss: 0.427166\n",
      "epoch 15; iter: 400; batch classifier loss: 0.388294; batch adversarial loss: 0.315942\n",
      "epoch 15; iter: 600; batch classifier loss: 0.450338; batch adversarial loss: 0.351239\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372534; batch adversarial loss: 0.447892\n",
      "epoch 16; iter: 200; batch classifier loss: 0.344589; batch adversarial loss: 0.342925\n",
      "epoch 16; iter: 400; batch classifier loss: 0.445502; batch adversarial loss: 0.321000\n",
      "epoch 16; iter: 600; batch classifier loss: 0.245741; batch adversarial loss: 0.343532\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463305; batch adversarial loss: 0.510683\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346297; batch adversarial loss: 0.442944\n",
      "epoch 17; iter: 400; batch classifier loss: 0.350138; batch adversarial loss: 0.371350\n",
      "epoch 17; iter: 600; batch classifier loss: 0.382530; batch adversarial loss: 0.500189\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476595; batch adversarial loss: 0.322042\n",
      "epoch 18; iter: 200; batch classifier loss: 0.510138; batch adversarial loss: 0.286524\n",
      "epoch 18; iter: 400; batch classifier loss: 0.452126; batch adversarial loss: 0.344908\n",
      "epoch 18; iter: 600; batch classifier loss: 0.358615; batch adversarial loss: 0.483943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302791; batch adversarial loss: 0.452164\n",
      "epoch 19; iter: 200; batch classifier loss: 0.518796; batch adversarial loss: 0.487366\n",
      "epoch 19; iter: 400; batch classifier loss: 0.290830; batch adversarial loss: 0.364825\n",
      "epoch 19; iter: 600; batch classifier loss: 0.337209; batch adversarial loss: 0.374786\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333328; batch adversarial loss: 0.402704\n",
      "epoch 20; iter: 200; batch classifier loss: 0.457250; batch adversarial loss: 0.413258\n",
      "epoch 20; iter: 400; batch classifier loss: 0.542349; batch adversarial loss: 0.466975\n",
      "epoch 20; iter: 600; batch classifier loss: 0.475142; batch adversarial loss: 0.297039\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477971; batch adversarial loss: 0.411562\n",
      "epoch 21; iter: 200; batch classifier loss: 0.418651; batch adversarial loss: 0.378360\n",
      "epoch 21; iter: 400; batch classifier loss: 0.475218; batch adversarial loss: 0.375800\n",
      "epoch 21; iter: 600; batch classifier loss: 0.413407; batch adversarial loss: 0.456994\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532731; batch adversarial loss: 0.345511\n",
      "epoch 22; iter: 200; batch classifier loss: 0.540246; batch adversarial loss: 0.339315\n",
      "epoch 22; iter: 400; batch classifier loss: 0.376786; batch adversarial loss: 0.546262\n",
      "epoch 22; iter: 600; batch classifier loss: 0.484249; batch adversarial loss: 0.441709\n",
      "epoch 23; iter: 0; batch classifier loss: 0.446189; batch adversarial loss: 0.406335\n",
      "epoch 23; iter: 200; batch classifier loss: 0.518639; batch adversarial loss: 0.371372\n",
      "epoch 23; iter: 400; batch classifier loss: 0.415411; batch adversarial loss: 0.319514\n",
      "epoch 23; iter: 600; batch classifier loss: 0.363420; batch adversarial loss: 0.431577\n",
      "epoch 24; iter: 0; batch classifier loss: 0.396117; batch adversarial loss: 0.573004\n",
      "epoch 24; iter: 200; batch classifier loss: 0.549723; batch adversarial loss: 0.373872\n",
      "epoch 24; iter: 400; batch classifier loss: 0.421395; batch adversarial loss: 0.315632\n",
      "epoch 24; iter: 600; batch classifier loss: 0.381924; batch adversarial loss: 0.413824\n",
      "epoch 25; iter: 0; batch classifier loss: 0.448737; batch adversarial loss: 0.484650\n",
      "epoch 25; iter: 200; batch classifier loss: 0.523639; batch adversarial loss: 0.485007\n",
      "epoch 25; iter: 400; batch classifier loss: 0.408320; batch adversarial loss: 0.370209\n",
      "epoch 25; iter: 600; batch classifier loss: 0.395256; batch adversarial loss: 0.410844\n",
      "epoch 26; iter: 0; batch classifier loss: 0.429774; batch adversarial loss: 0.437146\n",
      "epoch 26; iter: 200; batch classifier loss: 0.353093; batch adversarial loss: 0.364435\n",
      "epoch 26; iter: 400; batch classifier loss: 0.303610; batch adversarial loss: 0.385990\n",
      "epoch 26; iter: 600; batch classifier loss: 0.443464; batch adversarial loss: 0.434543\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413682; batch adversarial loss: 0.412589\n",
      "epoch 27; iter: 200; batch classifier loss: 0.620525; batch adversarial loss: 0.459146\n",
      "epoch 27; iter: 400; batch classifier loss: 0.345208; batch adversarial loss: 0.466237\n",
      "epoch 27; iter: 600; batch classifier loss: 0.443379; batch adversarial loss: 0.356624\n",
      "epoch 28; iter: 0; batch classifier loss: 0.438889; batch adversarial loss: 0.429053\n",
      "epoch 28; iter: 200; batch classifier loss: 0.615643; batch adversarial loss: 0.379419\n",
      "epoch 28; iter: 400; batch classifier loss: 0.601120; batch adversarial loss: 0.323162\n",
      "epoch 28; iter: 600; batch classifier loss: 0.568458; batch adversarial loss: 0.431626\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435368; batch adversarial loss: 0.615327\n",
      "epoch 29; iter: 200; batch classifier loss: 0.469599; batch adversarial loss: 0.460373\n",
      "epoch 29; iter: 400; batch classifier loss: 0.386081; batch adversarial loss: 0.537939\n",
      "epoch 29; iter: 600; batch classifier loss: 0.561515; batch adversarial loss: 0.266052\n",
      "epoch 30; iter: 0; batch classifier loss: 0.229122; batch adversarial loss: 0.324242\n",
      "epoch 30; iter: 200; batch classifier loss: 0.385948; batch adversarial loss: 0.264270\n",
      "epoch 30; iter: 400; batch classifier loss: 0.568067; batch adversarial loss: 0.291980\n",
      "epoch 30; iter: 600; batch classifier loss: 0.518936; batch adversarial loss: 0.504094\n",
      "epoch 31; iter: 0; batch classifier loss: 0.341450; batch adversarial loss: 0.431877\n",
      "epoch 31; iter: 200; batch classifier loss: 0.421327; batch adversarial loss: 0.571314\n",
      "epoch 31; iter: 400; batch classifier loss: 0.508486; batch adversarial loss: 0.349238\n",
      "epoch 31; iter: 600; batch classifier loss: 0.662366; batch adversarial loss: 0.411387\n",
      "epoch 32; iter: 0; batch classifier loss: 0.440977; batch adversarial loss: 0.249977\n",
      "epoch 32; iter: 200; batch classifier loss: 0.460286; batch adversarial loss: 0.507474\n",
      "epoch 32; iter: 400; batch classifier loss: 0.622481; batch adversarial loss: 0.548207\n",
      "epoch 32; iter: 600; batch classifier loss: 0.579169; batch adversarial loss: 0.268791\n",
      "epoch 33; iter: 0; batch classifier loss: 0.525316; batch adversarial loss: 0.409041\n",
      "epoch 33; iter: 200; batch classifier loss: 0.607399; batch adversarial loss: 0.382310\n",
      "epoch 33; iter: 400; batch classifier loss: 0.598929; batch adversarial loss: 0.296562\n",
      "epoch 33; iter: 600; batch classifier loss: 0.492049; batch adversarial loss: 0.356048\n",
      "epoch 34; iter: 0; batch classifier loss: 0.554254; batch adversarial loss: 0.323085\n",
      "epoch 34; iter: 200; batch classifier loss: 0.616511; batch adversarial loss: 0.345468\n",
      "epoch 34; iter: 400; batch classifier loss: 0.716786; batch adversarial loss: 0.466938\n",
      "epoch 34; iter: 600; batch classifier loss: 0.729551; batch adversarial loss: 0.267653\n",
      "epoch 35; iter: 0; batch classifier loss: 0.583582; batch adversarial loss: 0.383814\n",
      "epoch 35; iter: 200; batch classifier loss: 0.436500; batch adversarial loss: 0.376677\n",
      "epoch 35; iter: 400; batch classifier loss: 0.664041; batch adversarial loss: 0.412038\n",
      "epoch 35; iter: 600; batch classifier loss: 0.311473; batch adversarial loss: 0.411361\n",
      "epoch 36; iter: 0; batch classifier loss: 0.707966; batch adversarial loss: 0.406269\n",
      "epoch 36; iter: 200; batch classifier loss: 0.457455; batch adversarial loss: 0.401338\n",
      "epoch 36; iter: 400; batch classifier loss: 0.546818; batch adversarial loss: 0.405855\n",
      "epoch 36; iter: 600; batch classifier loss: 0.507979; batch adversarial loss: 0.294462\n",
      "epoch 37; iter: 0; batch classifier loss: 0.477095; batch adversarial loss: 0.412409\n",
      "epoch 37; iter: 200; batch classifier loss: 0.796183; batch adversarial loss: 0.468445\n",
      "epoch 37; iter: 400; batch classifier loss: 0.861441; batch adversarial loss: 0.346244\n",
      "epoch 37; iter: 600; batch classifier loss: 0.741059; batch adversarial loss: 0.461761\n",
      "epoch 38; iter: 0; batch classifier loss: 0.741644; batch adversarial loss: 0.436887\n",
      "epoch 38; iter: 200; batch classifier loss: 0.304605; batch adversarial loss: 0.403511\n",
      "epoch 38; iter: 400; batch classifier loss: 0.506961; batch adversarial loss: 0.485637\n",
      "epoch 38; iter: 600; batch classifier loss: 0.595760; batch adversarial loss: 0.486859\n",
      "epoch 39; iter: 0; batch classifier loss: 0.573623; batch adversarial loss: 0.482522\n",
      "epoch 39; iter: 200; batch classifier loss: 0.679896; batch adversarial loss: 0.348358\n",
      "epoch 39; iter: 400; batch classifier loss: 0.730869; batch adversarial loss: 0.407125\n",
      "epoch 39; iter: 600; batch classifier loss: 0.386761; batch adversarial loss: 0.426770\n",
      "epoch 40; iter: 0; batch classifier loss: 0.961302; batch adversarial loss: 0.437646\n",
      "epoch 40; iter: 200; batch classifier loss: 0.678919; batch adversarial loss: 0.404165\n",
      "epoch 40; iter: 400; batch classifier loss: 0.595147; batch adversarial loss: 0.624025\n",
      "epoch 40; iter: 600; batch classifier loss: 0.646013; batch adversarial loss: 0.294023\n",
      "epoch 41; iter: 0; batch classifier loss: 0.684189; batch adversarial loss: 0.375756\n",
      "epoch 41; iter: 200; batch classifier loss: 0.523353; batch adversarial loss: 0.542255\n",
      "epoch 41; iter: 400; batch classifier loss: 0.550319; batch adversarial loss: 0.434080\n",
      "epoch 41; iter: 600; batch classifier loss: 0.367147; batch adversarial loss: 0.268583\n",
      "epoch 42; iter: 0; batch classifier loss: 0.599129; batch adversarial loss: 0.322657\n",
      "epoch 42; iter: 200; batch classifier loss: 0.348903; batch adversarial loss: 0.376621\n",
      "epoch 42; iter: 400; batch classifier loss: 0.525032; batch adversarial loss: 0.320879\n",
      "epoch 42; iter: 600; batch classifier loss: 0.552306; batch adversarial loss: 0.458512\n",
      "epoch 43; iter: 0; batch classifier loss: 0.671632; batch adversarial loss: 0.348555\n",
      "epoch 43; iter: 200; batch classifier loss: 0.501312; batch adversarial loss: 0.343130\n",
      "epoch 43; iter: 400; batch classifier loss: 0.441676; batch adversarial loss: 0.347731\n",
      "epoch 43; iter: 600; batch classifier loss: 0.528578; batch adversarial loss: 0.294032\n",
      "epoch 44; iter: 0; batch classifier loss: 0.582231; batch adversarial loss: 0.317317\n",
      "epoch 44; iter: 200; batch classifier loss: 0.770679; batch adversarial loss: 0.347918\n",
      "epoch 44; iter: 400; batch classifier loss: 0.886627; batch adversarial loss: 0.431351\n",
      "epoch 44; iter: 600; batch classifier loss: 0.385043; batch adversarial loss: 0.358546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.656752; batch adversarial loss: 0.574805\n",
      "epoch 45; iter: 200; batch classifier loss: 0.410855; batch adversarial loss: 0.293040\n",
      "epoch 45; iter: 400; batch classifier loss: 0.507010; batch adversarial loss: 0.374672\n",
      "epoch 45; iter: 600; batch classifier loss: 0.755163; batch adversarial loss: 0.388656\n",
      "epoch 46; iter: 0; batch classifier loss: 0.710496; batch adversarial loss: 0.347291\n",
      "epoch 46; iter: 200; batch classifier loss: 0.275777; batch adversarial loss: 0.402666\n",
      "epoch 46; iter: 400; batch classifier loss: 0.572930; batch adversarial loss: 0.404785\n",
      "epoch 46; iter: 600; batch classifier loss: 0.456740; batch adversarial loss: 0.539805\n",
      "epoch 47; iter: 0; batch classifier loss: 0.497822; batch adversarial loss: 0.239178\n",
      "epoch 47; iter: 200; batch classifier loss: 0.564209; batch adversarial loss: 0.402298\n",
      "epoch 47; iter: 400; batch classifier loss: 0.888035; batch adversarial loss: 0.485809\n",
      "epoch 47; iter: 600; batch classifier loss: 0.452081; batch adversarial loss: 0.326323\n",
      "epoch 48; iter: 0; batch classifier loss: 0.470580; batch adversarial loss: 0.538826\n",
      "epoch 48; iter: 200; batch classifier loss: 0.528680; batch adversarial loss: 0.322524\n",
      "epoch 48; iter: 400; batch classifier loss: 0.617271; batch adversarial loss: 0.469693\n",
      "epoch 48; iter: 600; batch classifier loss: 0.632169; batch adversarial loss: 0.383106\n",
      "epoch 49; iter: 0; batch classifier loss: 0.987017; batch adversarial loss: 0.490902\n",
      "epoch 49; iter: 200; batch classifier loss: 0.409126; batch adversarial loss: 0.513080\n",
      "epoch 49; iter: 400; batch classifier loss: 0.562059; batch adversarial loss: 0.433818\n",
      "epoch 49; iter: 600; batch classifier loss: 0.505891; batch adversarial loss: 0.317015\n",
      "epoch 0; iter: 0; batch classifier loss: 49.680527; batch adversarial loss: 0.655198\n",
      "epoch 0; iter: 200; batch classifier loss: 0.360099; batch adversarial loss: 0.634573\n",
      "epoch 0; iter: 400; batch classifier loss: 9.966406; batch adversarial loss: 0.562287\n",
      "epoch 0; iter: 600; batch classifier loss: 4.229606; batch adversarial loss: 0.531434\n",
      "epoch 1; iter: 0; batch classifier loss: 0.908835; batch adversarial loss: 0.516697\n",
      "epoch 1; iter: 200; batch classifier loss: 12.521626; batch adversarial loss: 0.472475\n",
      "epoch 1; iter: 400; batch classifier loss: 2.187370; batch adversarial loss: 0.369180\n",
      "epoch 1; iter: 600; batch classifier loss: 3.550530; batch adversarial loss: 0.426466\n",
      "epoch 2; iter: 0; batch classifier loss: 2.265925; batch adversarial loss: 0.425281\n",
      "epoch 2; iter: 200; batch classifier loss: 0.799285; batch adversarial loss: 0.516835\n",
      "epoch 2; iter: 400; batch classifier loss: 1.786678; batch adversarial loss: 0.413007\n",
      "epoch 2; iter: 600; batch classifier loss: 3.026409; batch adversarial loss: 0.283205\n",
      "epoch 3; iter: 0; batch classifier loss: 1.525298; batch adversarial loss: 0.416919\n",
      "epoch 3; iter: 200; batch classifier loss: 0.896979; batch adversarial loss: 0.404040\n",
      "epoch 3; iter: 400; batch classifier loss: 3.310587; batch adversarial loss: 0.436479\n",
      "epoch 3; iter: 600; batch classifier loss: 0.786026; batch adversarial loss: 0.304643\n",
      "epoch 4; iter: 0; batch classifier loss: 1.446982; batch adversarial loss: 0.324094\n",
      "epoch 4; iter: 200; batch classifier loss: 0.565307; batch adversarial loss: 0.306273\n",
      "epoch 4; iter: 400; batch classifier loss: 0.467148; batch adversarial loss: 0.393116\n",
      "epoch 4; iter: 600; batch classifier loss: 0.737353; batch adversarial loss: 0.438230\n",
      "epoch 5; iter: 0; batch classifier loss: 0.292280; batch adversarial loss: 0.420498\n",
      "epoch 5; iter: 200; batch classifier loss: 0.483400; batch adversarial loss: 0.525153\n",
      "epoch 5; iter: 400; batch classifier loss: 0.441550; batch adversarial loss: 0.413665\n",
      "epoch 5; iter: 600; batch classifier loss: 0.434334; batch adversarial loss: 0.361829\n",
      "epoch 6; iter: 0; batch classifier loss: 0.785561; batch adversarial loss: 0.403952\n",
      "epoch 6; iter: 200; batch classifier loss: 0.469398; batch adversarial loss: 0.406223\n",
      "epoch 6; iter: 400; batch classifier loss: 0.288006; batch adversarial loss: 0.563002\n",
      "epoch 6; iter: 600; batch classifier loss: 0.371167; batch adversarial loss: 0.398969\n",
      "epoch 7; iter: 0; batch classifier loss: 0.472507; batch adversarial loss: 0.371065\n",
      "epoch 7; iter: 200; batch classifier loss: 0.430514; batch adversarial loss: 0.346206\n",
      "epoch 7; iter: 400; batch classifier loss: 0.397603; batch adversarial loss: 0.403811\n",
      "epoch 7; iter: 600; batch classifier loss: 0.455509; batch adversarial loss: 0.354370\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403224; batch adversarial loss: 0.395465\n",
      "epoch 8; iter: 200; batch classifier loss: 0.400033; batch adversarial loss: 0.379532\n",
      "epoch 8; iter: 400; batch classifier loss: 0.396145; batch adversarial loss: 0.578086\n",
      "epoch 8; iter: 600; batch classifier loss: 0.379255; batch adversarial loss: 0.318319\n",
      "epoch 9; iter: 0; batch classifier loss: 0.267389; batch adversarial loss: 0.461361\n",
      "epoch 9; iter: 200; batch classifier loss: 0.461817; batch adversarial loss: 0.296895\n",
      "epoch 9; iter: 400; batch classifier loss: 0.286093; batch adversarial loss: 0.343704\n",
      "epoch 9; iter: 600; batch classifier loss: 0.396937; batch adversarial loss: 0.261777\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333588; batch adversarial loss: 0.501770\n",
      "epoch 10; iter: 200; batch classifier loss: 0.310197; batch adversarial loss: 0.513381\n",
      "epoch 10; iter: 400; batch classifier loss: 0.319874; batch adversarial loss: 0.462718\n",
      "epoch 10; iter: 600; batch classifier loss: 0.321060; batch adversarial loss: 0.413736\n",
      "epoch 11; iter: 0; batch classifier loss: 0.425017; batch adversarial loss: 0.425086\n",
      "epoch 11; iter: 200; batch classifier loss: 0.335154; batch adversarial loss: 0.431270\n",
      "epoch 11; iter: 400; batch classifier loss: 0.370878; batch adversarial loss: 0.390943\n",
      "epoch 11; iter: 600; batch classifier loss: 0.403636; batch adversarial loss: 0.525449\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343818; batch adversarial loss: 0.350638\n",
      "epoch 12; iter: 200; batch classifier loss: 0.287982; batch adversarial loss: 0.432020\n",
      "epoch 12; iter: 400; batch classifier loss: 0.297635; batch adversarial loss: 0.326103\n",
      "epoch 12; iter: 600; batch classifier loss: 0.340193; batch adversarial loss: 0.376729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.288488; batch adversarial loss: 0.384922\n",
      "epoch 13; iter: 200; batch classifier loss: 0.399266; batch adversarial loss: 0.572763\n",
      "epoch 13; iter: 400; batch classifier loss: 0.389729; batch adversarial loss: 0.477960\n",
      "epoch 13; iter: 600; batch classifier loss: 0.569896; batch adversarial loss: 0.346238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413929; batch adversarial loss: 0.330123\n",
      "epoch 14; iter: 200; batch classifier loss: 0.362938; batch adversarial loss: 0.448549\n",
      "epoch 14; iter: 400; batch classifier loss: 0.320931; batch adversarial loss: 0.347448\n",
      "epoch 14; iter: 600; batch classifier loss: 0.407289; batch adversarial loss: 0.437980\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307949; batch adversarial loss: 0.365083\n",
      "epoch 15; iter: 200; batch classifier loss: 0.351055; batch adversarial loss: 0.592252\n",
      "epoch 15; iter: 400; batch classifier loss: 0.427433; batch adversarial loss: 0.507072\n",
      "epoch 15; iter: 600; batch classifier loss: 0.356610; batch adversarial loss: 0.608705\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296060; batch adversarial loss: 0.345216\n",
      "epoch 16; iter: 200; batch classifier loss: 0.460522; batch adversarial loss: 0.398305\n",
      "epoch 16; iter: 400; batch classifier loss: 0.368254; batch adversarial loss: 0.402121\n",
      "epoch 16; iter: 600; batch classifier loss: 0.430476; batch adversarial loss: 0.395782\n",
      "epoch 17; iter: 0; batch classifier loss: 0.306526; batch adversarial loss: 0.405337\n",
      "epoch 17; iter: 200; batch classifier loss: 0.461644; batch adversarial loss: 0.406259\n",
      "epoch 17; iter: 400; batch classifier loss: 0.370367; batch adversarial loss: 0.459320\n",
      "epoch 17; iter: 600; batch classifier loss: 0.365093; batch adversarial loss: 0.429335\n",
      "epoch 18; iter: 0; batch classifier loss: 0.237172; batch adversarial loss: 0.436478\n",
      "epoch 18; iter: 200; batch classifier loss: 0.403948; batch adversarial loss: 0.371438\n",
      "epoch 18; iter: 400; batch classifier loss: 0.375980; batch adversarial loss: 0.344554\n",
      "epoch 18; iter: 600; batch classifier loss: 0.380427; batch adversarial loss: 0.288178\n",
      "epoch 19; iter: 0; batch classifier loss: 0.372704; batch adversarial loss: 0.392555\n",
      "epoch 19; iter: 200; batch classifier loss: 0.390726; batch adversarial loss: 0.374360\n",
      "epoch 19; iter: 400; batch classifier loss: 0.498211; batch adversarial loss: 0.292262\n",
      "epoch 19; iter: 600; batch classifier loss: 0.361403; batch adversarial loss: 0.346789\n",
      "epoch 20; iter: 0; batch classifier loss: 0.413757; batch adversarial loss: 0.412373\n",
      "epoch 20; iter: 200; batch classifier loss: 0.396336; batch adversarial loss: 0.455300\n",
      "epoch 20; iter: 400; batch classifier loss: 0.567175; batch adversarial loss: 0.376926\n",
      "epoch 20; iter: 600; batch classifier loss: 0.406862; batch adversarial loss: 0.374736\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481707; batch adversarial loss: 0.461792\n",
      "epoch 21; iter: 200; batch classifier loss: 0.356266; batch adversarial loss: 0.492844\n",
      "epoch 21; iter: 400; batch classifier loss: 0.557170; batch adversarial loss: 0.408773\n",
      "epoch 21; iter: 600; batch classifier loss: 0.546194; batch adversarial loss: 0.548925\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361626; batch adversarial loss: 0.433600\n",
      "epoch 22; iter: 200; batch classifier loss: 0.447364; batch adversarial loss: 0.381832\n",
      "epoch 22; iter: 400; batch classifier loss: 0.506996; batch adversarial loss: 0.291627\n",
      "epoch 22; iter: 600; batch classifier loss: 0.357286; batch adversarial loss: 0.487518\n",
      "epoch 23; iter: 0; batch classifier loss: 0.471505; batch adversarial loss: 0.373062\n",
      "epoch 23; iter: 200; batch classifier loss: 0.611492; batch adversarial loss: 0.485601\n",
      "epoch 23; iter: 400; batch classifier loss: 0.473998; batch adversarial loss: 0.526230\n",
      "epoch 23; iter: 600; batch classifier loss: 0.276187; batch adversarial loss: 0.466018\n",
      "epoch 24; iter: 0; batch classifier loss: 0.514241; batch adversarial loss: 0.454290\n",
      "epoch 24; iter: 200; batch classifier loss: 0.441269; batch adversarial loss: 0.432386\n",
      "epoch 24; iter: 400; batch classifier loss: 0.500311; batch adversarial loss: 0.543994\n",
      "epoch 24; iter: 600; batch classifier loss: 0.455601; batch adversarial loss: 0.646110\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508871; batch adversarial loss: 0.443294\n",
      "epoch 25; iter: 200; batch classifier loss: 0.335322; batch adversarial loss: 0.599633\n",
      "epoch 25; iter: 400; batch classifier loss: 0.558416; batch adversarial loss: 0.489196\n",
      "epoch 25; iter: 600; batch classifier loss: 0.311971; batch adversarial loss: 0.378359\n",
      "epoch 26; iter: 0; batch classifier loss: 0.374120; batch adversarial loss: 0.481673\n",
      "epoch 26; iter: 200; batch classifier loss: 0.301606; batch adversarial loss: 0.350067\n",
      "epoch 26; iter: 400; batch classifier loss: 0.606294; batch adversarial loss: 0.426990\n",
      "epoch 26; iter: 600; batch classifier loss: 0.446333; batch adversarial loss: 0.491294\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521390; batch adversarial loss: 0.402961\n",
      "epoch 27; iter: 200; batch classifier loss: 0.425603; batch adversarial loss: 0.379881\n",
      "epoch 27; iter: 400; batch classifier loss: 0.402616; batch adversarial loss: 0.460023\n",
      "epoch 27; iter: 600; batch classifier loss: 0.230858; batch adversarial loss: 0.490367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328549; batch adversarial loss: 0.464707\n",
      "epoch 28; iter: 200; batch classifier loss: 0.295114; batch adversarial loss: 0.578381\n",
      "epoch 28; iter: 400; batch classifier loss: 0.436333; batch adversarial loss: 0.376775\n",
      "epoch 28; iter: 600; batch classifier loss: 0.416062; batch adversarial loss: 0.404087\n",
      "epoch 29; iter: 0; batch classifier loss: 0.576549; batch adversarial loss: 0.464733\n",
      "epoch 29; iter: 200; batch classifier loss: 0.412837; batch adversarial loss: 0.355836\n",
      "epoch 29; iter: 400; batch classifier loss: 0.658637; batch adversarial loss: 0.601141\n",
      "epoch 29; iter: 600; batch classifier loss: 0.647794; batch adversarial loss: 0.379110\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477999; batch adversarial loss: 0.347649\n",
      "epoch 30; iter: 200; batch classifier loss: 0.563063; batch adversarial loss: 0.411433\n",
      "epoch 30; iter: 400; batch classifier loss: 0.490263; batch adversarial loss: 0.515025\n",
      "epoch 30; iter: 600; batch classifier loss: 0.671681; batch adversarial loss: 0.430964\n",
      "epoch 31; iter: 0; batch classifier loss: 0.604784; batch adversarial loss: 0.545050\n",
      "epoch 31; iter: 200; batch classifier loss: 0.638405; batch adversarial loss: 0.462180\n",
      "epoch 31; iter: 400; batch classifier loss: 0.402679; batch adversarial loss: 0.460080\n",
      "epoch 31; iter: 600; batch classifier loss: 0.660132; batch adversarial loss: 0.431268\n",
      "epoch 32; iter: 0; batch classifier loss: 0.517181; batch adversarial loss: 0.437429\n",
      "epoch 32; iter: 200; batch classifier loss: 0.546864; batch adversarial loss: 0.322334\n",
      "epoch 32; iter: 400; batch classifier loss: 0.365179; batch adversarial loss: 0.407205\n",
      "epoch 32; iter: 600; batch classifier loss: 0.602791; batch adversarial loss: 0.433228\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346824; batch adversarial loss: 0.320746\n",
      "epoch 33; iter: 200; batch classifier loss: 0.685311; batch adversarial loss: 0.485723\n",
      "epoch 33; iter: 400; batch classifier loss: 0.371935; batch adversarial loss: 0.525421\n",
      "epoch 33; iter: 600; batch classifier loss: 0.439535; batch adversarial loss: 0.486692\n",
      "epoch 34; iter: 0; batch classifier loss: 0.537033; batch adversarial loss: 0.492967\n",
      "epoch 34; iter: 200; batch classifier loss: 0.427085; batch adversarial loss: 0.462812\n",
      "epoch 34; iter: 400; batch classifier loss: 0.559827; batch adversarial loss: 0.375549\n",
      "epoch 34; iter: 600; batch classifier loss: 0.822775; batch adversarial loss: 0.406545\n",
      "epoch 35; iter: 0; batch classifier loss: 0.691272; batch adversarial loss: 0.373846\n",
      "epoch 35; iter: 200; batch classifier loss: 0.498791; batch adversarial loss: 0.431818\n",
      "epoch 35; iter: 400; batch classifier loss: 0.611597; batch adversarial loss: 0.463951\n",
      "epoch 35; iter: 600; batch classifier loss: 0.497960; batch adversarial loss: 0.464995\n",
      "epoch 36; iter: 0; batch classifier loss: 0.344362; batch adversarial loss: 0.494282\n",
      "epoch 36; iter: 200; batch classifier loss: 0.794858; batch adversarial loss: 0.294729\n",
      "epoch 36; iter: 400; batch classifier loss: 0.606675; batch adversarial loss: 0.462961\n",
      "epoch 36; iter: 600; batch classifier loss: 0.513324; batch adversarial loss: 0.524402\n",
      "epoch 37; iter: 0; batch classifier loss: 0.530700; batch adversarial loss: 0.378875\n",
      "epoch 37; iter: 200; batch classifier loss: 0.605115; batch adversarial loss: 0.347187\n",
      "epoch 37; iter: 400; batch classifier loss: 0.563317; batch adversarial loss: 0.354078\n",
      "epoch 37; iter: 600; batch classifier loss: 0.907039; batch adversarial loss: 0.345983\n",
      "epoch 38; iter: 0; batch classifier loss: 0.320987; batch adversarial loss: 0.327470\n",
      "epoch 38; iter: 200; batch classifier loss: 0.457782; batch adversarial loss: 0.326320\n",
      "epoch 38; iter: 400; batch classifier loss: 0.729254; batch adversarial loss: 0.348440\n",
      "epoch 38; iter: 600; batch classifier loss: 0.745251; batch adversarial loss: 0.483940\n",
      "epoch 39; iter: 0; batch classifier loss: 0.344094; batch adversarial loss: 0.401443\n",
      "epoch 39; iter: 200; batch classifier loss: 0.655953; batch adversarial loss: 0.556824\n",
      "epoch 39; iter: 400; batch classifier loss: 0.528916; batch adversarial loss: 0.432555\n",
      "epoch 39; iter: 600; batch classifier loss: 0.429486; batch adversarial loss: 0.491386\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507487; batch adversarial loss: 0.403042\n",
      "epoch 40; iter: 200; batch classifier loss: 0.638526; batch adversarial loss: 0.515659\n",
      "epoch 40; iter: 400; batch classifier loss: 0.643261; batch adversarial loss: 0.408243\n",
      "epoch 40; iter: 600; batch classifier loss: 0.547792; batch adversarial loss: 0.347065\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487824; batch adversarial loss: 0.434453\n",
      "epoch 41; iter: 200; batch classifier loss: 0.569124; batch adversarial loss: 0.352893\n",
      "epoch 41; iter: 400; batch classifier loss: 0.680870; batch adversarial loss: 0.347890\n",
      "epoch 41; iter: 600; batch classifier loss: 0.647295; batch adversarial loss: 0.581467\n",
      "epoch 42; iter: 0; batch classifier loss: 0.559790; batch adversarial loss: 0.461861\n",
      "epoch 42; iter: 200; batch classifier loss: 0.475342; batch adversarial loss: 0.375779\n",
      "epoch 42; iter: 400; batch classifier loss: 0.632570; batch adversarial loss: 0.404686\n",
      "epoch 42; iter: 600; batch classifier loss: 0.508829; batch adversarial loss: 0.415774\n",
      "epoch 43; iter: 0; batch classifier loss: 0.606642; batch adversarial loss: 0.323706\n",
      "epoch 43; iter: 200; batch classifier loss: 0.513651; batch adversarial loss: 0.495936\n",
      "epoch 43; iter: 400; batch classifier loss: 0.866542; batch adversarial loss: 0.626033\n",
      "epoch 43; iter: 600; batch classifier loss: 0.583077; batch adversarial loss: 0.430837\n",
      "epoch 44; iter: 0; batch classifier loss: 0.839480; batch adversarial loss: 0.428698\n",
      "epoch 44; iter: 200; batch classifier loss: 0.303584; batch adversarial loss: 0.572266\n",
      "epoch 44; iter: 400; batch classifier loss: 0.468150; batch adversarial loss: 0.539567\n",
      "epoch 44; iter: 600; batch classifier loss: 0.621163; batch adversarial loss: 0.294847\n",
      "epoch 45; iter: 0; batch classifier loss: 0.672814; batch adversarial loss: 0.412832\n",
      "epoch 45; iter: 200; batch classifier loss: 0.623721; batch adversarial loss: 0.567583\n",
      "epoch 45; iter: 400; batch classifier loss: 0.678270; batch adversarial loss: 0.379757\n",
      "epoch 45; iter: 600; batch classifier loss: 0.616550; batch adversarial loss: 0.434448\n",
      "epoch 46; iter: 0; batch classifier loss: 0.568078; batch adversarial loss: 0.330242\n",
      "epoch 46; iter: 200; batch classifier loss: 0.446257; batch adversarial loss: 0.377572\n",
      "epoch 46; iter: 400; batch classifier loss: 0.598258; batch adversarial loss: 0.349871\n",
      "epoch 46; iter: 600; batch classifier loss: 0.513845; batch adversarial loss: 0.411503\n",
      "epoch 47; iter: 0; batch classifier loss: 0.632698; batch adversarial loss: 0.457256\n",
      "epoch 47; iter: 200; batch classifier loss: 0.629432; batch adversarial loss: 0.406874\n",
      "epoch 47; iter: 400; batch classifier loss: 0.551959; batch adversarial loss: 0.330248\n",
      "epoch 47; iter: 600; batch classifier loss: 0.554138; batch adversarial loss: 0.552455\n",
      "epoch 48; iter: 0; batch classifier loss: 0.522568; batch adversarial loss: 0.457890\n",
      "epoch 48; iter: 200; batch classifier loss: 0.668497; batch adversarial loss: 0.321755\n",
      "epoch 48; iter: 400; batch classifier loss: 0.514699; batch adversarial loss: 0.407537\n",
      "epoch 48; iter: 600; batch classifier loss: 0.756251; batch adversarial loss: 0.265796\n",
      "epoch 49; iter: 0; batch classifier loss: 0.785450; batch adversarial loss: 0.515420\n",
      "epoch 49; iter: 200; batch classifier loss: 0.671625; batch adversarial loss: 0.459716\n",
      "epoch 49; iter: 400; batch classifier loss: 0.502907; batch adversarial loss: 0.429585\n",
      "epoch 49; iter: 600; batch classifier loss: 0.666970; batch adversarial loss: 0.267129\n",
      "epoch 0; iter: 0; batch classifier loss: 4.714228; batch adversarial loss: 0.673173\n",
      "epoch 0; iter: 200; batch classifier loss: 4.940185; batch adversarial loss: 0.587164\n",
      "epoch 0; iter: 400; batch classifier loss: 0.444638; batch adversarial loss: 0.559928\n",
      "epoch 0; iter: 600; batch classifier loss: 33.709785; batch adversarial loss: 0.500775\n",
      "epoch 1; iter: 0; batch classifier loss: 12.672640; batch adversarial loss: 0.563037\n",
      "epoch 1; iter: 200; batch classifier loss: 2.850733; batch adversarial loss: 0.481734\n",
      "epoch 1; iter: 400; batch classifier loss: 10.927871; batch adversarial loss: 0.441046\n",
      "epoch 1; iter: 600; batch classifier loss: 5.331874; batch adversarial loss: 0.474658\n",
      "epoch 2; iter: 0; batch classifier loss: 0.743094; batch adversarial loss: 0.461617\n",
      "epoch 2; iter: 200; batch classifier loss: 3.981906; batch adversarial loss: 0.490927\n",
      "epoch 2; iter: 400; batch classifier loss: 5.613670; batch adversarial loss: 0.518572\n",
      "epoch 2; iter: 600; batch classifier loss: 0.553400; batch adversarial loss: 0.463882\n",
      "epoch 3; iter: 0; batch classifier loss: 5.893303; batch adversarial loss: 0.432758\n",
      "epoch 3; iter: 200; batch classifier loss: 2.133909; batch adversarial loss: 0.439587\n",
      "epoch 3; iter: 400; batch classifier loss: 1.123774; batch adversarial loss: 0.404380\n",
      "epoch 3; iter: 600; batch classifier loss: 1.628828; batch adversarial loss: 0.587072\n",
      "epoch 4; iter: 0; batch classifier loss: 1.826003; batch adversarial loss: 0.593753\n",
      "epoch 4; iter: 200; batch classifier loss: 3.680041; batch adversarial loss: 0.384550\n",
      "epoch 4; iter: 400; batch classifier loss: 1.674857; batch adversarial loss: 0.303967\n",
      "epoch 4; iter: 600; batch classifier loss: 0.850828; batch adversarial loss: 0.475968\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614021; batch adversarial loss: 0.454900\n",
      "epoch 5; iter: 200; batch classifier loss: 0.857223; batch adversarial loss: 0.481223\n",
      "epoch 5; iter: 400; batch classifier loss: 0.566140; batch adversarial loss: 0.419839\n",
      "epoch 5; iter: 600; batch classifier loss: 0.315908; batch adversarial loss: 0.314109\n",
      "epoch 6; iter: 0; batch classifier loss: 0.805206; batch adversarial loss: 0.401682\n",
      "epoch 6; iter: 200; batch classifier loss: 0.568523; batch adversarial loss: 0.402768\n",
      "epoch 6; iter: 400; batch classifier loss: 0.501906; batch adversarial loss: 0.296880\n",
      "epoch 6; iter: 600; batch classifier loss: 0.464899; batch adversarial loss: 0.374869\n",
      "epoch 7; iter: 0; batch classifier loss: 0.370232; batch adversarial loss: 0.478850\n",
      "epoch 7; iter: 200; batch classifier loss: 0.490843; batch adversarial loss: 0.393022\n",
      "epoch 7; iter: 400; batch classifier loss: 0.458514; batch adversarial loss: 0.351987\n",
      "epoch 7; iter: 600; batch classifier loss: 0.353223; batch adversarial loss: 0.449721\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356249; batch adversarial loss: 0.453922\n",
      "epoch 8; iter: 200; batch classifier loss: 0.370094; batch adversarial loss: 0.430523\n",
      "epoch 8; iter: 400; batch classifier loss: 0.289064; batch adversarial loss: 0.387887\n",
      "epoch 8; iter: 600; batch classifier loss: 0.519441; batch adversarial loss: 0.381247\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363545; batch adversarial loss: 0.433077\n",
      "epoch 9; iter: 200; batch classifier loss: 0.406542; batch adversarial loss: 0.422435\n",
      "epoch 9; iter: 400; batch classifier loss: 0.360615; batch adversarial loss: 0.288354\n",
      "epoch 9; iter: 600; batch classifier loss: 0.511089; batch adversarial loss: 0.426390\n",
      "epoch 10; iter: 0; batch classifier loss: 0.379734; batch adversarial loss: 0.408195\n",
      "epoch 10; iter: 200; batch classifier loss: 0.343284; batch adversarial loss: 0.373220\n",
      "epoch 10; iter: 400; batch classifier loss: 0.343816; batch adversarial loss: 0.481031\n",
      "epoch 10; iter: 600; batch classifier loss: 0.409647; batch adversarial loss: 0.370754\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520322; batch adversarial loss: 0.406315\n",
      "epoch 11; iter: 200; batch classifier loss: 0.358371; batch adversarial loss: 0.294869\n",
      "epoch 11; iter: 400; batch classifier loss: 0.348511; batch adversarial loss: 0.425070\n",
      "epoch 11; iter: 600; batch classifier loss: 0.299936; batch adversarial loss: 0.348188\n",
      "epoch 12; iter: 0; batch classifier loss: 0.233848; batch adversarial loss: 0.349119\n",
      "epoch 12; iter: 200; batch classifier loss: 0.358403; batch adversarial loss: 0.336188\n",
      "epoch 12; iter: 400; batch classifier loss: 0.268603; batch adversarial loss: 0.290149\n",
      "epoch 12; iter: 600; batch classifier loss: 0.425717; batch adversarial loss: 0.480690\n",
      "epoch 13; iter: 0; batch classifier loss: 0.235233; batch adversarial loss: 0.391953\n",
      "epoch 13; iter: 200; batch classifier loss: 0.378070; batch adversarial loss: 0.370589\n",
      "epoch 13; iter: 400; batch classifier loss: 0.313236; batch adversarial loss: 0.381653\n",
      "epoch 13; iter: 600; batch classifier loss: 0.381735; batch adversarial loss: 0.346057\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348438; batch adversarial loss: 0.496201\n",
      "epoch 14; iter: 200; batch classifier loss: 0.335759; batch adversarial loss: 0.426075\n",
      "epoch 14; iter: 400; batch classifier loss: 0.300731; batch adversarial loss: 0.408865\n",
      "epoch 14; iter: 600; batch classifier loss: 0.481541; batch adversarial loss: 0.374817\n",
      "epoch 15; iter: 0; batch classifier loss: 0.438375; batch adversarial loss: 0.471485\n",
      "epoch 15; iter: 200; batch classifier loss: 0.405297; batch adversarial loss: 0.366957\n",
      "epoch 15; iter: 400; batch classifier loss: 0.330011; batch adversarial loss: 0.385544\n",
      "epoch 15; iter: 600; batch classifier loss: 0.378964; batch adversarial loss: 0.477750\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307921; batch adversarial loss: 0.372714\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399611; batch adversarial loss: 0.516679\n",
      "epoch 16; iter: 400; batch classifier loss: 0.325951; batch adversarial loss: 0.510260\n",
      "epoch 16; iter: 600; batch classifier loss: 0.497586; batch adversarial loss: 0.520854\n",
      "epoch 17; iter: 0; batch classifier loss: 0.434824; batch adversarial loss: 0.533302\n",
      "epoch 17; iter: 200; batch classifier loss: 0.335653; batch adversarial loss: 0.314595\n",
      "epoch 17; iter: 400; batch classifier loss: 0.389089; batch adversarial loss: 0.510103\n",
      "epoch 17; iter: 600; batch classifier loss: 0.251317; batch adversarial loss: 0.458489\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454575; batch adversarial loss: 0.347556\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371959; batch adversarial loss: 0.511119\n",
      "epoch 18; iter: 400; batch classifier loss: 0.353123; batch adversarial loss: 0.341992\n",
      "epoch 18; iter: 600; batch classifier loss: 0.488705; batch adversarial loss: 0.299113\n",
      "epoch 19; iter: 0; batch classifier loss: 0.323363; batch adversarial loss: 0.401305\n",
      "epoch 19; iter: 200; batch classifier loss: 0.300721; batch adversarial loss: 0.563136\n",
      "epoch 19; iter: 400; batch classifier loss: 0.453897; batch adversarial loss: 0.463248\n",
      "epoch 19; iter: 600; batch classifier loss: 0.319573; batch adversarial loss: 0.464765\n",
      "epoch 20; iter: 0; batch classifier loss: 0.304544; batch adversarial loss: 0.504344\n",
      "epoch 20; iter: 200; batch classifier loss: 0.321739; batch adversarial loss: 0.457154\n",
      "epoch 20; iter: 400; batch classifier loss: 0.283095; batch adversarial loss: 0.533044\n",
      "epoch 20; iter: 600; batch classifier loss: 0.395077; batch adversarial loss: 0.346332\n",
      "epoch 21; iter: 0; batch classifier loss: 0.362110; batch adversarial loss: 0.380185\n",
      "epoch 21; iter: 200; batch classifier loss: 0.274429; batch adversarial loss: 0.294233\n",
      "epoch 21; iter: 400; batch classifier loss: 0.429630; batch adversarial loss: 0.401930\n",
      "epoch 21; iter: 600; batch classifier loss: 0.279288; batch adversarial loss: 0.427245\n",
      "epoch 22; iter: 0; batch classifier loss: 0.373648; batch adversarial loss: 0.437469\n",
      "epoch 22; iter: 200; batch classifier loss: 0.376813; batch adversarial loss: 0.429002\n",
      "epoch 22; iter: 400; batch classifier loss: 0.307650; batch adversarial loss: 0.532275\n",
      "epoch 22; iter: 600; batch classifier loss: 0.231156; batch adversarial loss: 0.408524\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339746; batch adversarial loss: 0.403084\n",
      "epoch 23; iter: 200; batch classifier loss: 0.300393; batch adversarial loss: 0.403428\n",
      "epoch 23; iter: 400; batch classifier loss: 0.330870; batch adversarial loss: 0.381943\n",
      "epoch 23; iter: 600; batch classifier loss: 0.437785; batch adversarial loss: 0.435729\n",
      "epoch 24; iter: 0; batch classifier loss: 0.334239; batch adversarial loss: 0.403271\n",
      "epoch 24; iter: 200; batch classifier loss: 0.426022; batch adversarial loss: 0.401770\n",
      "epoch 24; iter: 400; batch classifier loss: 0.277065; batch adversarial loss: 0.411973\n",
      "epoch 24; iter: 600; batch classifier loss: 0.363418; batch adversarial loss: 0.290606\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339680; batch adversarial loss: 0.353667\n",
      "epoch 25; iter: 200; batch classifier loss: 0.455055; batch adversarial loss: 0.618849\n",
      "epoch 25; iter: 400; batch classifier loss: 0.491763; batch adversarial loss: 0.382967\n",
      "epoch 25; iter: 600; batch classifier loss: 0.280584; batch adversarial loss: 0.523741\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484475; batch adversarial loss: 0.371697\n",
      "epoch 26; iter: 200; batch classifier loss: 0.360866; batch adversarial loss: 0.319667\n",
      "epoch 26; iter: 400; batch classifier loss: 0.485375; batch adversarial loss: 0.467858\n",
      "epoch 26; iter: 600; batch classifier loss: 0.290209; batch adversarial loss: 0.388700\n",
      "epoch 27; iter: 0; batch classifier loss: 0.371852; batch adversarial loss: 0.300477\n",
      "epoch 27; iter: 200; batch classifier loss: 0.276651; batch adversarial loss: 0.380665\n",
      "epoch 27; iter: 400; batch classifier loss: 0.300817; batch adversarial loss: 0.326872\n",
      "epoch 27; iter: 600; batch classifier loss: 0.434846; batch adversarial loss: 0.514297\n",
      "epoch 28; iter: 0; batch classifier loss: 0.391925; batch adversarial loss: 0.296320\n",
      "epoch 28; iter: 200; batch classifier loss: 0.232110; batch adversarial loss: 0.351949\n",
      "epoch 28; iter: 400; batch classifier loss: 0.371702; batch adversarial loss: 0.548409\n",
      "epoch 28; iter: 600; batch classifier loss: 0.325417; batch adversarial loss: 0.405758\n",
      "epoch 29; iter: 0; batch classifier loss: 0.342455; batch adversarial loss: 0.430147\n",
      "epoch 29; iter: 200; batch classifier loss: 0.286834; batch adversarial loss: 0.294817\n",
      "epoch 29; iter: 400; batch classifier loss: 0.387315; batch adversarial loss: 0.356321\n",
      "epoch 29; iter: 600; batch classifier loss: 0.391115; batch adversarial loss: 0.376534\n",
      "epoch 30; iter: 0; batch classifier loss: 0.496859; batch adversarial loss: 0.458578\n",
      "epoch 30; iter: 200; batch classifier loss: 0.344557; batch adversarial loss: 0.352513\n",
      "epoch 30; iter: 400; batch classifier loss: 0.439140; batch adversarial loss: 0.319141\n",
      "epoch 30; iter: 600; batch classifier loss: 0.325632; batch adversarial loss: 0.406640\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441643; batch adversarial loss: 0.510029\n",
      "epoch 31; iter: 200; batch classifier loss: 0.281688; batch adversarial loss: 0.382852\n",
      "epoch 31; iter: 400; batch classifier loss: 0.644877; batch adversarial loss: 0.321813\n",
      "epoch 31; iter: 600; batch classifier loss: 0.455525; batch adversarial loss: 0.432533\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318973; batch adversarial loss: 0.353649\n",
      "epoch 32; iter: 200; batch classifier loss: 0.361393; batch adversarial loss: 0.378597\n",
      "epoch 32; iter: 400; batch classifier loss: 0.403843; batch adversarial loss: 0.399938\n",
      "epoch 32; iter: 600; batch classifier loss: 0.523711; batch adversarial loss: 0.603378\n",
      "epoch 33; iter: 0; batch classifier loss: 0.380491; batch adversarial loss: 0.352654\n",
      "epoch 33; iter: 200; batch classifier loss: 0.390098; batch adversarial loss: 0.427949\n",
      "epoch 33; iter: 400; batch classifier loss: 0.255003; batch adversarial loss: 0.434414\n",
      "epoch 33; iter: 600; batch classifier loss: 0.401121; batch adversarial loss: 0.347407\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427365; batch adversarial loss: 0.488940\n",
      "epoch 34; iter: 200; batch classifier loss: 0.481274; batch adversarial loss: 0.489832\n",
      "epoch 34; iter: 400; batch classifier loss: 0.599370; batch adversarial loss: 0.346808\n",
      "epoch 34; iter: 600; batch classifier loss: 0.283203; batch adversarial loss: 0.406900\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490598; batch adversarial loss: 0.408089\n",
      "epoch 35; iter: 200; batch classifier loss: 0.343434; batch adversarial loss: 0.510690\n",
      "epoch 35; iter: 400; batch classifier loss: 0.618521; batch adversarial loss: 0.380292\n",
      "epoch 35; iter: 600; batch classifier loss: 0.341899; batch adversarial loss: 0.542094\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436313; batch adversarial loss: 0.409172\n",
      "epoch 36; iter: 200; batch classifier loss: 0.365870; batch adversarial loss: 0.432889\n",
      "epoch 36; iter: 400; batch classifier loss: 0.339363; batch adversarial loss: 0.405896\n",
      "epoch 36; iter: 600; batch classifier loss: 0.265541; batch adversarial loss: 0.460883\n",
      "epoch 37; iter: 0; batch classifier loss: 0.568512; batch adversarial loss: 0.374591\n",
      "epoch 37; iter: 200; batch classifier loss: 0.426035; batch adversarial loss: 0.382478\n",
      "epoch 37; iter: 400; batch classifier loss: 0.262071; batch adversarial loss: 0.461674\n",
      "epoch 37; iter: 600; batch classifier loss: 0.592233; batch adversarial loss: 0.459700\n",
      "epoch 38; iter: 0; batch classifier loss: 0.347505; batch adversarial loss: 0.353751\n",
      "epoch 38; iter: 200; batch classifier loss: 0.618240; batch adversarial loss: 0.374611\n",
      "epoch 38; iter: 400; batch classifier loss: 0.465868; batch adversarial loss: 0.407887\n",
      "epoch 38; iter: 600; batch classifier loss: 0.356217; batch adversarial loss: 0.401848\n",
      "epoch 39; iter: 0; batch classifier loss: 0.512921; batch adversarial loss: 0.460547\n",
      "epoch 39; iter: 200; batch classifier loss: 0.245564; batch adversarial loss: 0.380802\n",
      "epoch 39; iter: 400; batch classifier loss: 0.366749; batch adversarial loss: 0.349870\n",
      "epoch 39; iter: 600; batch classifier loss: 0.524884; batch adversarial loss: 0.490463\n",
      "epoch 40; iter: 0; batch classifier loss: 0.623402; batch adversarial loss: 0.215576\n",
      "epoch 40; iter: 200; batch classifier loss: 0.397820; batch adversarial loss: 0.293456\n",
      "epoch 40; iter: 400; batch classifier loss: 0.541753; batch adversarial loss: 0.348788\n",
      "epoch 40; iter: 600; batch classifier loss: 0.531152; batch adversarial loss: 0.462313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.587082; batch adversarial loss: 0.410988\n",
      "epoch 41; iter: 200; batch classifier loss: 0.431170; batch adversarial loss: 0.241395\n",
      "epoch 41; iter: 400; batch classifier loss: 0.348837; batch adversarial loss: 0.520102\n",
      "epoch 41; iter: 600; batch classifier loss: 0.525299; batch adversarial loss: 0.461338\n",
      "epoch 42; iter: 0; batch classifier loss: 0.430428; batch adversarial loss: 0.349285\n",
      "epoch 42; iter: 200; batch classifier loss: 0.438629; batch adversarial loss: 0.429541\n",
      "epoch 42; iter: 400; batch classifier loss: 0.209129; batch adversarial loss: 0.488403\n",
      "epoch 42; iter: 600; batch classifier loss: 0.464695; batch adversarial loss: 0.548136\n",
      "epoch 43; iter: 0; batch classifier loss: 0.439277; batch adversarial loss: 0.378094\n",
      "epoch 43; iter: 200; batch classifier loss: 0.758020; batch adversarial loss: 0.351646\n",
      "epoch 43; iter: 400; batch classifier loss: 0.418109; batch adversarial loss: 0.462634\n",
      "epoch 43; iter: 600; batch classifier loss: 0.389821; batch adversarial loss: 0.348604\n",
      "epoch 44; iter: 0; batch classifier loss: 0.473797; batch adversarial loss: 0.463054\n",
      "epoch 44; iter: 200; batch classifier loss: 0.781050; batch adversarial loss: 0.267180\n",
      "epoch 44; iter: 400; batch classifier loss: 0.425748; batch adversarial loss: 0.484668\n",
      "epoch 44; iter: 600; batch classifier loss: 0.337390; batch adversarial loss: 0.324338\n",
      "epoch 45; iter: 0; batch classifier loss: 0.225685; batch adversarial loss: 0.516767\n",
      "epoch 45; iter: 200; batch classifier loss: 0.321668; batch adversarial loss: 0.489028\n",
      "epoch 45; iter: 400; batch classifier loss: 0.446008; batch adversarial loss: 0.293542\n",
      "epoch 45; iter: 600; batch classifier loss: 0.343606; batch adversarial loss: 0.267809\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356270; batch adversarial loss: 0.295655\n",
      "epoch 46; iter: 200; batch classifier loss: 0.464345; batch adversarial loss: 0.458707\n",
      "epoch 46; iter: 400; batch classifier loss: 0.370304; batch adversarial loss: 0.463679\n",
      "epoch 46; iter: 600; batch classifier loss: 0.326550; batch adversarial loss: 0.377264\n",
      "epoch 47; iter: 0; batch classifier loss: 0.451079; batch adversarial loss: 0.460675\n",
      "epoch 47; iter: 200; batch classifier loss: 0.349541; batch adversarial loss: 0.298193\n",
      "epoch 47; iter: 400; batch classifier loss: 0.428755; batch adversarial loss: 0.294862\n",
      "epoch 47; iter: 600; batch classifier loss: 0.385766; batch adversarial loss: 0.242958\n",
      "epoch 48; iter: 0; batch classifier loss: 0.311647; batch adversarial loss: 0.409151\n",
      "epoch 48; iter: 200; batch classifier loss: 0.500095; batch adversarial loss: 0.464310\n",
      "epoch 48; iter: 400; batch classifier loss: 0.295030; batch adversarial loss: 0.348639\n",
      "epoch 48; iter: 600; batch classifier loss: 0.479547; batch adversarial loss: 0.463635\n",
      "epoch 49; iter: 0; batch classifier loss: 0.227670; batch adversarial loss: 0.435707\n",
      "epoch 49; iter: 200; batch classifier loss: 0.563631; batch adversarial loss: 0.380222\n",
      "epoch 49; iter: 400; batch classifier loss: 0.379972; batch adversarial loss: 0.264900\n",
      "epoch 49; iter: 600; batch classifier loss: 0.416930; batch adversarial loss: 0.351450\n",
      "epoch 0; iter: 0; batch classifier loss: 27.532412; batch adversarial loss: 0.591592\n",
      "epoch 0; iter: 200; batch classifier loss: 3.766616; batch adversarial loss: 0.519736\n",
      "epoch 0; iter: 400; batch classifier loss: 8.713184; batch adversarial loss: 0.474420\n",
      "epoch 0; iter: 600; batch classifier loss: 1.909211; batch adversarial loss: 0.373813\n",
      "epoch 1; iter: 0; batch classifier loss: 7.388367; batch adversarial loss: 0.505732\n",
      "epoch 1; iter: 200; batch classifier loss: 4.834967; batch adversarial loss: 0.468998\n",
      "epoch 1; iter: 400; batch classifier loss: 13.049728; batch adversarial loss: 0.435976\n",
      "epoch 1; iter: 600; batch classifier loss: 1.833237; batch adversarial loss: 0.407189\n",
      "epoch 2; iter: 0; batch classifier loss: 8.440422; batch adversarial loss: 0.487406\n",
      "epoch 2; iter: 200; batch classifier loss: 1.935442; batch adversarial loss: 0.439224\n",
      "epoch 2; iter: 400; batch classifier loss: 6.681022; batch adversarial loss: 0.591320\n",
      "epoch 2; iter: 600; batch classifier loss: 1.737299; batch adversarial loss: 0.528661\n",
      "epoch 3; iter: 0; batch classifier loss: 2.641614; batch adversarial loss: 0.364084\n",
      "epoch 3; iter: 200; batch classifier loss: 4.600861; batch adversarial loss: 0.482846\n",
      "epoch 3; iter: 400; batch classifier loss: 1.724249; batch adversarial loss: 0.391206\n",
      "epoch 3; iter: 600; batch classifier loss: 1.217346; batch adversarial loss: 0.477961\n",
      "epoch 4; iter: 0; batch classifier loss: 0.925504; batch adversarial loss: 0.496498\n",
      "epoch 4; iter: 200; batch classifier loss: 1.494493; batch adversarial loss: 0.451091\n",
      "epoch 4; iter: 400; batch classifier loss: 2.094378; batch adversarial loss: 0.510074\n",
      "epoch 4; iter: 600; batch classifier loss: 0.571676; batch adversarial loss: 0.338481\n",
      "epoch 5; iter: 0; batch classifier loss: 1.534990; batch adversarial loss: 0.341089\n",
      "epoch 5; iter: 200; batch classifier loss: 0.605126; batch adversarial loss: 0.491135\n",
      "epoch 5; iter: 400; batch classifier loss: 0.543950; batch adversarial loss: 0.388796\n",
      "epoch 5; iter: 600; batch classifier loss: 0.344688; batch adversarial loss: 0.556321\n",
      "epoch 6; iter: 0; batch classifier loss: 0.732234; batch adversarial loss: 0.455265\n",
      "epoch 6; iter: 200; batch classifier loss: 0.374852; batch adversarial loss: 0.403442\n",
      "epoch 6; iter: 400; batch classifier loss: 0.511406; batch adversarial loss: 0.294028\n",
      "epoch 6; iter: 600; batch classifier loss: 0.471429; batch adversarial loss: 0.443484\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553300; batch adversarial loss: 0.482455\n",
      "epoch 7; iter: 200; batch classifier loss: 0.378382; batch adversarial loss: 0.505505\n",
      "epoch 7; iter: 400; batch classifier loss: 0.448863; batch adversarial loss: 0.404300\n",
      "epoch 7; iter: 600; batch classifier loss: 0.476752; batch adversarial loss: 0.378825\n",
      "epoch 8; iter: 0; batch classifier loss: 0.480852; batch adversarial loss: 0.426408\n",
      "epoch 8; iter: 200; batch classifier loss: 0.352608; batch adversarial loss: 0.289740\n",
      "epoch 8; iter: 400; batch classifier loss: 0.366756; batch adversarial loss: 0.418033\n",
      "epoch 8; iter: 600; batch classifier loss: 0.266316; batch adversarial loss: 0.656526\n",
      "epoch 9; iter: 0; batch classifier loss: 0.418792; batch adversarial loss: 0.429996\n",
      "epoch 9; iter: 200; batch classifier loss: 0.270113; batch adversarial loss: 0.462326\n",
      "epoch 9; iter: 400; batch classifier loss: 0.383567; batch adversarial loss: 0.398857\n",
      "epoch 9; iter: 600; batch classifier loss: 0.302616; batch adversarial loss: 0.507231\n",
      "epoch 10; iter: 0; batch classifier loss: 0.326997; batch adversarial loss: 0.512225\n",
      "epoch 10; iter: 200; batch classifier loss: 0.426041; batch adversarial loss: 0.339104\n",
      "epoch 10; iter: 400; batch classifier loss: 0.326441; batch adversarial loss: 0.540820\n",
      "epoch 10; iter: 600; batch classifier loss: 0.454862; batch adversarial loss: 0.582093\n",
      "epoch 11; iter: 0; batch classifier loss: 0.278731; batch adversarial loss: 0.331672\n",
      "epoch 11; iter: 200; batch classifier loss: 0.271717; batch adversarial loss: 0.316122\n",
      "epoch 11; iter: 400; batch classifier loss: 0.405795; batch adversarial loss: 0.459880\n",
      "epoch 11; iter: 600; batch classifier loss: 0.398924; batch adversarial loss: 0.259393\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329773; batch adversarial loss: 0.430361\n",
      "epoch 12; iter: 200; batch classifier loss: 0.338229; batch adversarial loss: 0.412381\n",
      "epoch 12; iter: 400; batch classifier loss: 0.330307; batch adversarial loss: 0.384081\n",
      "epoch 12; iter: 600; batch classifier loss: 0.337045; batch adversarial loss: 0.319820\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489151; batch adversarial loss: 0.359391\n",
      "epoch 13; iter: 200; batch classifier loss: 0.383164; batch adversarial loss: 0.326203\n",
      "epoch 13; iter: 400; batch classifier loss: 0.402133; batch adversarial loss: 0.439112\n",
      "epoch 13; iter: 600; batch classifier loss: 0.372534; batch adversarial loss: 0.350773\n",
      "epoch 14; iter: 0; batch classifier loss: 0.232908; batch adversarial loss: 0.357931\n",
      "epoch 14; iter: 200; batch classifier loss: 0.358282; batch adversarial loss: 0.494650\n",
      "epoch 14; iter: 400; batch classifier loss: 0.490440; batch adversarial loss: 0.318305\n",
      "epoch 14; iter: 600; batch classifier loss: 0.326159; batch adversarial loss: 0.326994\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349196; batch adversarial loss: 0.370997\n",
      "epoch 15; iter: 200; batch classifier loss: 0.262693; batch adversarial loss: 0.458331\n",
      "epoch 15; iter: 400; batch classifier loss: 0.330401; batch adversarial loss: 0.424715\n",
      "epoch 15; iter: 600; batch classifier loss: 0.310434; batch adversarial loss: 0.549302\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430926; batch adversarial loss: 0.310222\n",
      "epoch 16; iter: 200; batch classifier loss: 0.355825; batch adversarial loss: 0.369705\n",
      "epoch 16; iter: 400; batch classifier loss: 0.272389; batch adversarial loss: 0.397638\n",
      "epoch 16; iter: 600; batch classifier loss: 0.320557; batch adversarial loss: 0.512791\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269038; batch adversarial loss: 0.440007\n",
      "epoch 17; iter: 200; batch classifier loss: 0.279122; batch adversarial loss: 0.372351\n",
      "epoch 17; iter: 400; batch classifier loss: 0.320820; batch adversarial loss: 0.264384\n",
      "epoch 17; iter: 600; batch classifier loss: 0.408838; batch adversarial loss: 0.444519\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323080; batch adversarial loss: 0.315727\n",
      "epoch 18; iter: 200; batch classifier loss: 0.285338; batch adversarial loss: 0.318089\n",
      "epoch 18; iter: 400; batch classifier loss: 0.514466; batch adversarial loss: 0.265147\n",
      "epoch 18; iter: 600; batch classifier loss: 0.312810; batch adversarial loss: 0.374775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406961; batch adversarial loss: 0.399733\n",
      "epoch 19; iter: 200; batch classifier loss: 0.456281; batch adversarial loss: 0.373103\n",
      "epoch 19; iter: 400; batch classifier loss: 0.349180; batch adversarial loss: 0.463103\n",
      "epoch 19; iter: 600; batch classifier loss: 0.395864; batch adversarial loss: 0.353650\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281478; batch adversarial loss: 0.326818\n",
      "epoch 20; iter: 200; batch classifier loss: 0.239517; batch adversarial loss: 0.425993\n",
      "epoch 20; iter: 400; batch classifier loss: 0.327697; batch adversarial loss: 0.382441\n",
      "epoch 20; iter: 600; batch classifier loss: 0.345149; batch adversarial loss: 0.354885\n",
      "epoch 21; iter: 0; batch classifier loss: 0.378430; batch adversarial loss: 0.264613\n",
      "epoch 21; iter: 200; batch classifier loss: 0.350657; batch adversarial loss: 0.462278\n",
      "epoch 21; iter: 400; batch classifier loss: 0.438001; batch adversarial loss: 0.444232\n",
      "epoch 21; iter: 600; batch classifier loss: 0.361250; batch adversarial loss: 0.375103\n",
      "epoch 22; iter: 0; batch classifier loss: 0.385361; batch adversarial loss: 0.411365\n",
      "epoch 22; iter: 200; batch classifier loss: 0.461565; batch adversarial loss: 0.458571\n",
      "epoch 22; iter: 400; batch classifier loss: 0.355355; batch adversarial loss: 0.536288\n",
      "epoch 22; iter: 600; batch classifier loss: 0.288892; batch adversarial loss: 0.373913\n",
      "epoch 23; iter: 0; batch classifier loss: 0.383805; batch adversarial loss: 0.421654\n",
      "epoch 23; iter: 200; batch classifier loss: 0.433149; batch adversarial loss: 0.460961\n",
      "epoch 23; iter: 400; batch classifier loss: 0.528596; batch adversarial loss: 0.385850\n",
      "epoch 23; iter: 600; batch classifier loss: 0.544123; batch adversarial loss: 0.341453\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435906; batch adversarial loss: 0.541727\n",
      "epoch 24; iter: 200; batch classifier loss: 0.452042; batch adversarial loss: 0.288786\n",
      "epoch 24; iter: 400; batch classifier loss: 0.324602; batch adversarial loss: 0.293473\n",
      "epoch 24; iter: 600; batch classifier loss: 0.390606; batch adversarial loss: 0.398140\n",
      "epoch 25; iter: 0; batch classifier loss: 0.278495; batch adversarial loss: 0.566371\n",
      "epoch 25; iter: 200; batch classifier loss: 0.400794; batch adversarial loss: 0.442179\n",
      "epoch 25; iter: 400; batch classifier loss: 0.452698; batch adversarial loss: 0.523301\n",
      "epoch 25; iter: 600; batch classifier loss: 0.385983; batch adversarial loss: 0.240169\n",
      "epoch 26; iter: 0; batch classifier loss: 0.500189; batch adversarial loss: 0.467415\n",
      "epoch 26; iter: 200; batch classifier loss: 0.565868; batch adversarial loss: 0.396992\n",
      "epoch 26; iter: 400; batch classifier loss: 0.399749; batch adversarial loss: 0.465641\n",
      "epoch 26; iter: 600; batch classifier loss: 0.343402; batch adversarial loss: 0.462581\n",
      "epoch 27; iter: 0; batch classifier loss: 0.302796; batch adversarial loss: 0.326311\n",
      "epoch 27; iter: 200; batch classifier loss: 0.540097; batch adversarial loss: 0.428525\n",
      "epoch 27; iter: 400; batch classifier loss: 0.385893; batch adversarial loss: 0.478629\n",
      "epoch 27; iter: 600; batch classifier loss: 0.414693; batch adversarial loss: 0.371587\n",
      "epoch 28; iter: 0; batch classifier loss: 0.460453; batch adversarial loss: 0.458634\n",
      "epoch 28; iter: 200; batch classifier loss: 0.399003; batch adversarial loss: 0.322981\n",
      "epoch 28; iter: 400; batch classifier loss: 0.710780; batch adversarial loss: 0.378865\n",
      "epoch 28; iter: 600; batch classifier loss: 0.321875; batch adversarial loss: 0.347852\n",
      "epoch 29; iter: 0; batch classifier loss: 0.371145; batch adversarial loss: 0.457554\n",
      "epoch 29; iter: 200; batch classifier loss: 0.405513; batch adversarial loss: 0.376075\n",
      "epoch 29; iter: 400; batch classifier loss: 0.486489; batch adversarial loss: 0.261414\n",
      "epoch 29; iter: 600; batch classifier loss: 0.612882; batch adversarial loss: 0.537240\n",
      "epoch 30; iter: 0; batch classifier loss: 0.659560; batch adversarial loss: 0.425341\n",
      "epoch 30; iter: 200; batch classifier loss: 0.603504; batch adversarial loss: 0.292976\n",
      "epoch 30; iter: 400; batch classifier loss: 0.472489; batch adversarial loss: 0.405474\n",
      "epoch 30; iter: 600; batch classifier loss: 0.370992; batch adversarial loss: 0.319406\n",
      "epoch 31; iter: 0; batch classifier loss: 0.577015; batch adversarial loss: 0.320897\n",
      "epoch 31; iter: 200; batch classifier loss: 0.379925; batch adversarial loss: 0.511085\n",
      "epoch 31; iter: 400; batch classifier loss: 0.414839; batch adversarial loss: 0.345480\n",
      "epoch 31; iter: 600; batch classifier loss: 0.411347; batch adversarial loss: 0.517344\n",
      "epoch 32; iter: 0; batch classifier loss: 0.392951; batch adversarial loss: 0.482842\n",
      "epoch 32; iter: 200; batch classifier loss: 0.470537; batch adversarial loss: 0.437621\n",
      "epoch 32; iter: 400; batch classifier loss: 0.600363; batch adversarial loss: 0.433264\n",
      "epoch 32; iter: 600; batch classifier loss: 0.470864; batch adversarial loss: 0.518790\n",
      "epoch 33; iter: 0; batch classifier loss: 0.552686; batch adversarial loss: 0.491036\n",
      "epoch 33; iter: 200; batch classifier loss: 0.515185; batch adversarial loss: 0.348456\n",
      "epoch 33; iter: 400; batch classifier loss: 0.427441; batch adversarial loss: 0.345245\n",
      "epoch 33; iter: 600; batch classifier loss: 0.537526; batch adversarial loss: 0.318147\n",
      "epoch 34; iter: 0; batch classifier loss: 0.461561; batch adversarial loss: 0.438152\n",
      "epoch 34; iter: 200; batch classifier loss: 0.382537; batch adversarial loss: 0.296634\n",
      "epoch 34; iter: 400; batch classifier loss: 0.601902; batch adversarial loss: 0.380303\n",
      "epoch 34; iter: 600; batch classifier loss: 0.476706; batch adversarial loss: 0.384953\n",
      "epoch 35; iter: 0; batch classifier loss: 0.524841; batch adversarial loss: 0.512678\n",
      "epoch 35; iter: 200; batch classifier loss: 0.436460; batch adversarial loss: 0.375342\n",
      "epoch 35; iter: 400; batch classifier loss: 0.337041; batch adversarial loss: 0.380938\n",
      "epoch 35; iter: 600; batch classifier loss: 0.703487; batch adversarial loss: 0.239318\n",
      "epoch 36; iter: 0; batch classifier loss: 0.394982; batch adversarial loss: 0.463343\n",
      "epoch 36; iter: 200; batch classifier loss: 0.620873; batch adversarial loss: 0.518209\n",
      "epoch 36; iter: 400; batch classifier loss: 0.468818; batch adversarial loss: 0.402832\n",
      "epoch 36; iter: 600; batch classifier loss: 0.635861; batch adversarial loss: 0.412582\n",
      "epoch 37; iter: 0; batch classifier loss: 0.567095; batch adversarial loss: 0.546308\n",
      "epoch 37; iter: 200; batch classifier loss: 0.547653; batch adversarial loss: 0.485074\n",
      "epoch 37; iter: 400; batch classifier loss: 0.389601; batch adversarial loss: 0.300121\n",
      "epoch 37; iter: 600; batch classifier loss: 0.503963; batch adversarial loss: 0.461957\n",
      "epoch 38; iter: 0; batch classifier loss: 0.494591; batch adversarial loss: 0.540819\n",
      "epoch 38; iter: 200; batch classifier loss: 0.660358; batch adversarial loss: 0.320507\n",
      "epoch 38; iter: 400; batch classifier loss: 0.479444; batch adversarial loss: 0.491192\n",
      "epoch 38; iter: 600; batch classifier loss: 0.405967; batch adversarial loss: 0.320188\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467191; batch adversarial loss: 0.467880\n",
      "epoch 39; iter: 200; batch classifier loss: 0.464317; batch adversarial loss: 0.349317\n",
      "epoch 39; iter: 400; batch classifier loss: 0.472758; batch adversarial loss: 0.406471\n",
      "epoch 39; iter: 600; batch classifier loss: 0.466185; batch adversarial loss: 0.403725\n",
      "epoch 40; iter: 0; batch classifier loss: 0.966583; batch adversarial loss: 0.353402\n",
      "epoch 40; iter: 200; batch classifier loss: 0.585808; batch adversarial loss: 0.545817\n",
      "epoch 40; iter: 400; batch classifier loss: 0.699314; batch adversarial loss: 0.410165\n",
      "epoch 40; iter: 600; batch classifier loss: 0.568951; batch adversarial loss: 0.466944\n",
      "epoch 41; iter: 0; batch classifier loss: 0.864289; batch adversarial loss: 0.431309\n",
      "epoch 41; iter: 200; batch classifier loss: 0.503454; batch adversarial loss: 0.404230\n",
      "epoch 41; iter: 400; batch classifier loss: 0.467850; batch adversarial loss: 0.577817\n",
      "epoch 41; iter: 600; batch classifier loss: 0.346917; batch adversarial loss: 0.379799\n",
      "epoch 42; iter: 0; batch classifier loss: 0.656787; batch adversarial loss: 0.461873\n",
      "epoch 42; iter: 200; batch classifier loss: 0.409267; batch adversarial loss: 0.427927\n",
      "epoch 42; iter: 400; batch classifier loss: 0.533748; batch adversarial loss: 0.430977\n",
      "epoch 42; iter: 600; batch classifier loss: 0.445069; batch adversarial loss: 0.516009\n",
      "epoch 43; iter: 0; batch classifier loss: 0.513974; batch adversarial loss: 0.350175\n",
      "epoch 43; iter: 200; batch classifier loss: 0.664336; batch adversarial loss: 0.376725\n",
      "epoch 43; iter: 400; batch classifier loss: 0.410446; batch adversarial loss: 0.569388\n",
      "epoch 43; iter: 600; batch classifier loss: 0.559433; batch adversarial loss: 0.321445\n",
      "epoch 44; iter: 0; batch classifier loss: 0.871676; batch adversarial loss: 0.374835\n",
      "epoch 44; iter: 200; batch classifier loss: 0.483441; batch adversarial loss: 0.404716\n",
      "epoch 44; iter: 400; batch classifier loss: 0.319127; batch adversarial loss: 0.430021\n",
      "epoch 44; iter: 600; batch classifier loss: 0.758602; batch adversarial loss: 0.319213\n",
      "epoch 45; iter: 0; batch classifier loss: 0.393823; batch adversarial loss: 0.408358\n",
      "epoch 45; iter: 200; batch classifier loss: 0.652334; batch adversarial loss: 0.431065\n",
      "epoch 45; iter: 400; batch classifier loss: 0.545838; batch adversarial loss: 0.325153\n",
      "epoch 45; iter: 600; batch classifier loss: 0.673350; batch adversarial loss: 0.348384\n",
      "epoch 46; iter: 0; batch classifier loss: 0.555763; batch adversarial loss: 0.319900\n",
      "epoch 46; iter: 200; batch classifier loss: 0.661365; batch adversarial loss: 0.406311\n",
      "epoch 46; iter: 400; batch classifier loss: 0.622922; batch adversarial loss: 0.403120\n",
      "epoch 46; iter: 600; batch classifier loss: 0.521091; batch adversarial loss: 0.460629\n",
      "epoch 47; iter: 0; batch classifier loss: 0.633576; batch adversarial loss: 0.380499\n",
      "epoch 47; iter: 200; batch classifier loss: 0.445676; batch adversarial loss: 0.406892\n",
      "epoch 47; iter: 400; batch classifier loss: 0.655808; batch adversarial loss: 0.349339\n",
      "epoch 47; iter: 600; batch classifier loss: 0.582815; batch adversarial loss: 0.485851\n",
      "epoch 48; iter: 0; batch classifier loss: 0.648228; batch adversarial loss: 0.489599\n",
      "epoch 48; iter: 200; batch classifier loss: 0.845943; batch adversarial loss: 0.381782\n",
      "epoch 48; iter: 400; batch classifier loss: 0.879415; batch adversarial loss: 0.377902\n",
      "epoch 48; iter: 600; batch classifier loss: 0.745017; batch adversarial loss: 0.516145\n",
      "epoch 49; iter: 0; batch classifier loss: 0.368772; batch adversarial loss: 0.601856\n",
      "epoch 49; iter: 200; batch classifier loss: 0.697102; batch adversarial loss: 0.321536\n",
      "epoch 49; iter: 400; batch classifier loss: 0.723329; batch adversarial loss: 0.465129\n",
      "epoch 49; iter: 600; batch classifier loss: 0.443212; batch adversarial loss: 0.402798\n",
      "epoch 0; iter: 0; batch classifier loss: 20.003475; batch adversarial loss: 0.592291\n",
      "epoch 0; iter: 200; batch classifier loss: 7.950895; batch adversarial loss: 0.573167\n",
      "epoch 0; iter: 400; batch classifier loss: 1.079432; batch adversarial loss: 0.559871\n",
      "epoch 0; iter: 600; batch classifier loss: 0.825538; batch adversarial loss: 0.575240\n",
      "epoch 1; iter: 0; batch classifier loss: 7.912668; batch adversarial loss: 0.510272\n",
      "epoch 1; iter: 200; batch classifier loss: 2.329217; batch adversarial loss: 0.503408\n",
      "epoch 1; iter: 400; batch classifier loss: 6.490566; batch adversarial loss: 0.381081\n",
      "epoch 1; iter: 600; batch classifier loss: 3.275592; batch adversarial loss: 0.422505\n",
      "epoch 2; iter: 0; batch classifier loss: 3.069025; batch adversarial loss: 0.446135\n",
      "epoch 2; iter: 200; batch classifier loss: 15.082709; batch adversarial loss: 0.433673\n",
      "epoch 2; iter: 400; batch classifier loss: 0.587197; batch adversarial loss: 0.375980\n",
      "epoch 2; iter: 600; batch classifier loss: 4.352037; batch adversarial loss: 0.392864\n",
      "epoch 3; iter: 0; batch classifier loss: 1.174633; batch adversarial loss: 0.472910\n",
      "epoch 3; iter: 200; batch classifier loss: 0.529545; batch adversarial loss: 0.376619\n",
      "epoch 3; iter: 400; batch classifier loss: 0.290467; batch adversarial loss: 0.456896\n",
      "epoch 3; iter: 600; batch classifier loss: 1.083628; batch adversarial loss: 0.495957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.919017; batch adversarial loss: 0.555418\n",
      "epoch 4; iter: 200; batch classifier loss: 1.445292; batch adversarial loss: 0.404664\n",
      "epoch 4; iter: 400; batch classifier loss: 0.506853; batch adversarial loss: 0.550783\n",
      "epoch 4; iter: 600; batch classifier loss: 1.149008; batch adversarial loss: 0.355689\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466950; batch adversarial loss: 0.332820\n",
      "epoch 5; iter: 200; batch classifier loss: 0.672012; batch adversarial loss: 0.303265\n",
      "epoch 5; iter: 400; batch classifier loss: 0.936107; batch adversarial loss: 0.400482\n",
      "epoch 5; iter: 600; batch classifier loss: 0.402543; batch adversarial loss: 0.494920\n",
      "epoch 6; iter: 0; batch classifier loss: 0.515200; batch adversarial loss: 0.319277\n",
      "epoch 6; iter: 200; batch classifier loss: 0.556015; batch adversarial loss: 0.554133\n",
      "epoch 6; iter: 400; batch classifier loss: 0.558748; batch adversarial loss: 0.502978\n",
      "epoch 6; iter: 600; batch classifier loss: 0.300719; batch adversarial loss: 0.392377\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342172; batch adversarial loss: 0.436281\n",
      "epoch 7; iter: 200; batch classifier loss: 0.359530; batch adversarial loss: 0.358222\n",
      "epoch 7; iter: 400; batch classifier loss: 0.565486; batch adversarial loss: 0.315594\n",
      "epoch 7; iter: 600; batch classifier loss: 0.236429; batch adversarial loss: 0.298677\n",
      "epoch 8; iter: 0; batch classifier loss: 0.317794; batch adversarial loss: 0.496613\n",
      "epoch 8; iter: 200; batch classifier loss: 0.311475; batch adversarial loss: 0.436843\n",
      "epoch 8; iter: 400; batch classifier loss: 0.429927; batch adversarial loss: 0.370718\n",
      "epoch 8; iter: 600; batch classifier loss: 0.233743; batch adversarial loss: 0.540199\n",
      "epoch 9; iter: 0; batch classifier loss: 0.451407; batch adversarial loss: 0.418103\n",
      "epoch 9; iter: 200; batch classifier loss: 0.318002; batch adversarial loss: 0.290708\n",
      "epoch 9; iter: 400; batch classifier loss: 0.463200; batch adversarial loss: 0.391534\n",
      "epoch 9; iter: 600; batch classifier loss: 0.363372; batch adversarial loss: 0.344754\n",
      "epoch 10; iter: 0; batch classifier loss: 0.381480; batch adversarial loss: 0.340857\n",
      "epoch 10; iter: 200; batch classifier loss: 0.421257; batch adversarial loss: 0.463505\n",
      "epoch 10; iter: 400; batch classifier loss: 0.364136; batch adversarial loss: 0.284096\n",
      "epoch 10; iter: 600; batch classifier loss: 0.407508; batch adversarial loss: 0.470504\n",
      "epoch 11; iter: 0; batch classifier loss: 0.361531; batch adversarial loss: 0.324511\n",
      "epoch 11; iter: 200; batch classifier loss: 0.329383; batch adversarial loss: 0.338251\n",
      "epoch 11; iter: 400; batch classifier loss: 0.257966; batch adversarial loss: 0.383749\n",
      "epoch 11; iter: 600; batch classifier loss: 0.327576; batch adversarial loss: 0.320556\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397356; batch adversarial loss: 0.454677\n",
      "epoch 12; iter: 200; batch classifier loss: 0.439603; batch adversarial loss: 0.367088\n",
      "epoch 12; iter: 400; batch classifier loss: 0.458885; batch adversarial loss: 0.433822\n",
      "epoch 12; iter: 600; batch classifier loss: 0.385807; batch adversarial loss: 0.253338\n",
      "epoch 13; iter: 0; batch classifier loss: 0.437938; batch adversarial loss: 0.264420\n",
      "epoch 13; iter: 200; batch classifier loss: 0.356376; batch adversarial loss: 0.488436\n",
      "epoch 13; iter: 400; batch classifier loss: 0.407593; batch adversarial loss: 0.295071\n",
      "epoch 13; iter: 600; batch classifier loss: 0.310761; batch adversarial loss: 0.452919\n",
      "epoch 14; iter: 0; batch classifier loss: 0.373645; batch adversarial loss: 0.488708\n",
      "epoch 14; iter: 200; batch classifier loss: 0.366054; batch adversarial loss: 0.602055\n",
      "epoch 14; iter: 400; batch classifier loss: 0.370959; batch adversarial loss: 0.347116\n",
      "epoch 14; iter: 600; batch classifier loss: 0.255291; batch adversarial loss: 0.393310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422289; batch adversarial loss: 0.338435\n",
      "epoch 15; iter: 200; batch classifier loss: 0.444813; batch adversarial loss: 0.380668\n",
      "epoch 15; iter: 400; batch classifier loss: 0.343124; batch adversarial loss: 0.352613\n",
      "epoch 15; iter: 600; batch classifier loss: 0.386581; batch adversarial loss: 0.299468\n",
      "epoch 16; iter: 0; batch classifier loss: 0.412841; batch adversarial loss: 0.376152\n",
      "epoch 16; iter: 200; batch classifier loss: 0.283322; batch adversarial loss: 0.487236\n",
      "epoch 16; iter: 400; batch classifier loss: 0.262467; batch adversarial loss: 0.454737\n",
      "epoch 16; iter: 600; batch classifier loss: 0.501854; batch adversarial loss: 0.378366\n",
      "epoch 17; iter: 0; batch classifier loss: 0.432285; batch adversarial loss: 0.376832\n",
      "epoch 17; iter: 200; batch classifier loss: 0.378033; batch adversarial loss: 0.330689\n",
      "epoch 17; iter: 400; batch classifier loss: 0.509073; batch adversarial loss: 0.405194\n",
      "epoch 17; iter: 600; batch classifier loss: 0.486992; batch adversarial loss: 0.357296\n",
      "epoch 18; iter: 0; batch classifier loss: 0.616914; batch adversarial loss: 0.411442\n",
      "epoch 18; iter: 200; batch classifier loss: 0.706066; batch adversarial loss: 0.351503\n",
      "epoch 18; iter: 400; batch classifier loss: 0.515131; batch adversarial loss: 0.357106\n",
      "epoch 18; iter: 600; batch classifier loss: 0.381464; batch adversarial loss: 0.436583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516559; batch adversarial loss: 0.625797\n",
      "epoch 19; iter: 200; batch classifier loss: 0.543968; batch adversarial loss: 0.516223\n",
      "epoch 19; iter: 400; batch classifier loss: 0.563437; batch adversarial loss: 0.440910\n",
      "epoch 19; iter: 600; batch classifier loss: 0.480620; batch adversarial loss: 0.380181\n",
      "epoch 20; iter: 0; batch classifier loss: 0.424257; batch adversarial loss: 0.380105\n",
      "epoch 20; iter: 200; batch classifier loss: 0.440178; batch adversarial loss: 0.492171\n",
      "epoch 20; iter: 400; batch classifier loss: 0.447811; batch adversarial loss: 0.514373\n",
      "epoch 20; iter: 600; batch classifier loss: 0.467608; batch adversarial loss: 0.349057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484204; batch adversarial loss: 0.542699\n",
      "epoch 21; iter: 200; batch classifier loss: 0.543367; batch adversarial loss: 0.452972\n",
      "epoch 21; iter: 400; batch classifier loss: 0.447072; batch adversarial loss: 0.377445\n",
      "epoch 21; iter: 600; batch classifier loss: 0.438994; batch adversarial loss: 0.375434\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438563; batch adversarial loss: 0.369241\n",
      "epoch 22; iter: 200; batch classifier loss: 0.630252; batch adversarial loss: 0.423793\n",
      "epoch 22; iter: 400; batch classifier loss: 0.476879; batch adversarial loss: 0.289726\n",
      "epoch 22; iter: 600; batch classifier loss: 0.552666; batch adversarial loss: 0.594123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505955; batch adversarial loss: 0.465194\n",
      "epoch 23; iter: 200; batch classifier loss: 0.561959; batch adversarial loss: 0.374571\n",
      "epoch 23; iter: 400; batch classifier loss: 0.494522; batch adversarial loss: 0.263707\n",
      "epoch 23; iter: 600; batch classifier loss: 0.496078; batch adversarial loss: 0.429348\n",
      "epoch 24; iter: 0; batch classifier loss: 0.538487; batch adversarial loss: 0.321757\n",
      "epoch 24; iter: 200; batch classifier loss: 0.355254; batch adversarial loss: 0.349153\n",
      "epoch 24; iter: 400; batch classifier loss: 0.608418; batch adversarial loss: 0.319027\n",
      "epoch 24; iter: 600; batch classifier loss: 0.577485; batch adversarial loss: 0.426169\n",
      "epoch 25; iter: 0; batch classifier loss: 0.560893; batch adversarial loss: 0.430520\n",
      "epoch 25; iter: 200; batch classifier loss: 0.448078; batch adversarial loss: 0.403189\n",
      "epoch 25; iter: 400; batch classifier loss: 0.680787; batch adversarial loss: 0.301431\n",
      "epoch 25; iter: 600; batch classifier loss: 0.484354; batch adversarial loss: 0.407074\n",
      "epoch 26; iter: 0; batch classifier loss: 0.524463; batch adversarial loss: 0.402600\n",
      "epoch 26; iter: 200; batch classifier loss: 0.433375; batch adversarial loss: 0.427555\n",
      "epoch 26; iter: 400; batch classifier loss: 0.737957; batch adversarial loss: 0.401772\n",
      "epoch 26; iter: 600; batch classifier loss: 0.364243; batch adversarial loss: 0.460367\n",
      "epoch 27; iter: 0; batch classifier loss: 0.614554; batch adversarial loss: 0.374507\n",
      "epoch 27; iter: 200; batch classifier loss: 0.364690; batch adversarial loss: 0.408573\n",
      "epoch 27; iter: 400; batch classifier loss: 0.590021; batch adversarial loss: 0.471322\n",
      "epoch 27; iter: 600; batch classifier loss: 0.679040; batch adversarial loss: 0.321138\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514484; batch adversarial loss: 0.295795\n",
      "epoch 28; iter: 200; batch classifier loss: 0.500233; batch adversarial loss: 0.411254\n",
      "epoch 28; iter: 400; batch classifier loss: 0.682681; batch adversarial loss: 0.430838\n",
      "epoch 28; iter: 600; batch classifier loss: 0.427584; batch adversarial loss: 0.487773\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534600; batch adversarial loss: 0.570618\n",
      "epoch 29; iter: 200; batch classifier loss: 0.593470; batch adversarial loss: 0.294120\n",
      "epoch 29; iter: 400; batch classifier loss: 0.597372; batch adversarial loss: 0.372407\n",
      "epoch 29; iter: 600; batch classifier loss: 0.616707; batch adversarial loss: 0.405352\n",
      "epoch 30; iter: 0; batch classifier loss: 0.726641; batch adversarial loss: 0.301618\n",
      "epoch 30; iter: 200; batch classifier loss: 0.540895; batch adversarial loss: 0.348115\n",
      "epoch 30; iter: 400; batch classifier loss: 0.565867; batch adversarial loss: 0.548539\n",
      "epoch 30; iter: 600; batch classifier loss: 0.577710; batch adversarial loss: 0.485608\n",
      "epoch 31; iter: 0; batch classifier loss: 0.415607; batch adversarial loss: 0.384706\n",
      "epoch 31; iter: 200; batch classifier loss: 0.602493; batch adversarial loss: 0.411934\n",
      "epoch 31; iter: 400; batch classifier loss: 0.565860; batch adversarial loss: 0.403101\n",
      "epoch 31; iter: 600; batch classifier loss: 0.576052; batch adversarial loss: 0.401033\n",
      "epoch 32; iter: 0; batch classifier loss: 0.417600; batch adversarial loss: 0.356287\n",
      "epoch 32; iter: 200; batch classifier loss: 0.480851; batch adversarial loss: 0.462090\n",
      "epoch 32; iter: 400; batch classifier loss: 0.537631; batch adversarial loss: 0.353849\n",
      "epoch 32; iter: 600; batch classifier loss: 0.364631; batch adversarial loss: 0.293892\n",
      "epoch 33; iter: 0; batch classifier loss: 0.739585; batch adversarial loss: 0.298471\n",
      "epoch 33; iter: 200; batch classifier loss: 0.508815; batch adversarial loss: 0.371755\n",
      "epoch 33; iter: 400; batch classifier loss: 0.626745; batch adversarial loss: 0.488307\n",
      "epoch 33; iter: 600; batch classifier loss: 0.401120; batch adversarial loss: 0.438839\n",
      "epoch 34; iter: 0; batch classifier loss: 0.621256; batch adversarial loss: 0.319304\n",
      "epoch 34; iter: 200; batch classifier loss: 0.514970; batch adversarial loss: 0.492294\n",
      "epoch 34; iter: 400; batch classifier loss: 0.456362; batch adversarial loss: 0.492628\n",
      "epoch 34; iter: 600; batch classifier loss: 0.545942; batch adversarial loss: 0.408630\n",
      "epoch 35; iter: 0; batch classifier loss: 0.389055; batch adversarial loss: 0.415911\n",
      "epoch 35; iter: 200; batch classifier loss: 0.585381; batch adversarial loss: 0.395605\n",
      "epoch 35; iter: 400; batch classifier loss: 0.592793; batch adversarial loss: 0.546144\n",
      "epoch 35; iter: 600; batch classifier loss: 0.467976; batch adversarial loss: 0.290542\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467846; batch adversarial loss: 0.374079\n",
      "epoch 36; iter: 200; batch classifier loss: 0.600252; batch adversarial loss: 0.293323\n",
      "epoch 36; iter: 400; batch classifier loss: 0.538341; batch adversarial loss: 0.319297\n",
      "epoch 36; iter: 600; batch classifier loss: 0.314868; batch adversarial loss: 0.273518\n",
      "epoch 37; iter: 0; batch classifier loss: 0.467552; batch adversarial loss: 0.371358\n",
      "epoch 37; iter: 200; batch classifier loss: 0.493790; batch adversarial loss: 0.294079\n",
      "epoch 37; iter: 400; batch classifier loss: 0.368706; batch adversarial loss: 0.431371\n",
      "epoch 37; iter: 600; batch classifier loss: 0.581168; batch adversarial loss: 0.349369\n",
      "epoch 38; iter: 0; batch classifier loss: 0.777859; batch adversarial loss: 0.528108\n",
      "epoch 38; iter: 200; batch classifier loss: 0.530118; batch adversarial loss: 0.489081\n",
      "epoch 38; iter: 400; batch classifier loss: 0.397785; batch adversarial loss: 0.458763\n",
      "epoch 38; iter: 600; batch classifier loss: 0.590189; batch adversarial loss: 0.403595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.629194; batch adversarial loss: 0.380421\n",
      "epoch 39; iter: 200; batch classifier loss: 0.660666; batch adversarial loss: 0.440037\n",
      "epoch 39; iter: 400; batch classifier loss: 0.438983; batch adversarial loss: 0.465282\n",
      "epoch 39; iter: 600; batch classifier loss: 0.459300; batch adversarial loss: 0.435077\n",
      "epoch 40; iter: 0; batch classifier loss: 0.572380; batch adversarial loss: 0.594474\n",
      "epoch 40; iter: 200; batch classifier loss: 0.554313; batch adversarial loss: 0.378007\n",
      "epoch 40; iter: 400; batch classifier loss: 0.563092; batch adversarial loss: 0.462710\n",
      "epoch 40; iter: 600; batch classifier loss: 0.783670; batch adversarial loss: 0.511770\n",
      "epoch 41; iter: 0; batch classifier loss: 0.604631; batch adversarial loss: 0.458718\n",
      "epoch 41; iter: 200; batch classifier loss: 0.525631; batch adversarial loss: 0.487871\n",
      "epoch 41; iter: 400; batch classifier loss: 0.721718; batch adversarial loss: 0.459044\n",
      "epoch 41; iter: 600; batch classifier loss: 0.638459; batch adversarial loss: 0.320959\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419185; batch adversarial loss: 0.383428\n",
      "epoch 42; iter: 200; batch classifier loss: 0.741076; batch adversarial loss: 0.591132\n",
      "epoch 42; iter: 400; batch classifier loss: 0.479039; batch adversarial loss: 0.457445\n",
      "epoch 42; iter: 600; batch classifier loss: 0.485803; batch adversarial loss: 0.352386\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482905; batch adversarial loss: 0.375821\n",
      "epoch 43; iter: 200; batch classifier loss: 0.320790; batch adversarial loss: 0.434008\n",
      "epoch 43; iter: 400; batch classifier loss: 0.652091; batch adversarial loss: 0.354531\n",
      "epoch 43; iter: 600; batch classifier loss: 0.960185; batch adversarial loss: 0.291452\n",
      "epoch 44; iter: 0; batch classifier loss: 0.627125; batch adversarial loss: 0.467718\n",
      "epoch 44; iter: 200; batch classifier loss: 0.633936; batch adversarial loss: 0.427743\n",
      "epoch 44; iter: 400; batch classifier loss: 0.679476; batch adversarial loss: 0.482638\n",
      "epoch 44; iter: 600; batch classifier loss: 0.466877; batch adversarial loss: 0.434576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.459329; batch adversarial loss: 0.374172\n",
      "epoch 45; iter: 200; batch classifier loss: 0.514093; batch adversarial loss: 0.360141\n",
      "epoch 45; iter: 400; batch classifier loss: 0.543092; batch adversarial loss: 0.436735\n",
      "epoch 45; iter: 600; batch classifier loss: 0.555666; batch adversarial loss: 0.428823\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511806; batch adversarial loss: 0.324018\n",
      "epoch 46; iter: 200; batch classifier loss: 0.531764; batch adversarial loss: 0.292022\n",
      "epoch 46; iter: 400; batch classifier loss: 0.710618; batch adversarial loss: 0.522392\n",
      "epoch 46; iter: 600; batch classifier loss: 0.602027; batch adversarial loss: 0.402652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.738584; batch adversarial loss: 0.526427\n",
      "epoch 47; iter: 200; batch classifier loss: 0.697507; batch adversarial loss: 0.429556\n",
      "epoch 47; iter: 400; batch classifier loss: 0.693119; batch adversarial loss: 0.294514\n",
      "epoch 47; iter: 600; batch classifier loss: 0.856440; batch adversarial loss: 0.405771\n",
      "epoch 48; iter: 0; batch classifier loss: 0.759851; batch adversarial loss: 0.538409\n",
      "epoch 48; iter: 200; batch classifier loss: 0.496581; batch adversarial loss: 0.349292\n",
      "epoch 48; iter: 400; batch classifier loss: 0.767646; batch adversarial loss: 0.404855\n",
      "epoch 48; iter: 600; batch classifier loss: 0.643593; batch adversarial loss: 0.518409\n",
      "epoch 49; iter: 0; batch classifier loss: 0.565801; batch adversarial loss: 0.519141\n",
      "epoch 49; iter: 200; batch classifier loss: 0.602997; batch adversarial loss: 0.550847\n",
      "epoch 49; iter: 400; batch classifier loss: 0.738816; batch adversarial loss: 0.376181\n",
      "epoch 49; iter: 600; batch classifier loss: 0.459437; batch adversarial loss: 0.212412\n",
      "epoch 0; iter: 0; batch classifier loss: 113.916183; batch adversarial loss: 0.629058\n",
      "epoch 0; iter: 200; batch classifier loss: 5.551833; batch adversarial loss: 0.594776\n",
      "epoch 0; iter: 400; batch classifier loss: 14.422359; batch adversarial loss: 0.534851\n",
      "epoch 0; iter: 600; batch classifier loss: 15.327576; batch adversarial loss: 0.493137\n",
      "epoch 1; iter: 0; batch classifier loss: 11.897651; batch adversarial loss: 0.538397\n",
      "epoch 1; iter: 200; batch classifier loss: 3.137378; batch adversarial loss: 0.568247\n",
      "epoch 1; iter: 400; batch classifier loss: 0.594469; batch adversarial loss: 0.551178\n",
      "epoch 1; iter: 600; batch classifier loss: 4.894507; batch adversarial loss: 0.455095\n",
      "epoch 2; iter: 0; batch classifier loss: 0.704317; batch adversarial loss: 0.378728\n",
      "epoch 2; iter: 200; batch classifier loss: 14.111650; batch adversarial loss: 0.464224\n",
      "epoch 2; iter: 400; batch classifier loss: 2.717905; batch adversarial loss: 0.502614\n",
      "epoch 2; iter: 600; batch classifier loss: 1.661526; batch adversarial loss: 0.570494\n",
      "epoch 3; iter: 0; batch classifier loss: 7.057599; batch adversarial loss: 0.560604\n",
      "epoch 3; iter: 200; batch classifier loss: 1.013633; batch adversarial loss: 0.349550\n",
      "epoch 3; iter: 400; batch classifier loss: 1.509063; batch adversarial loss: 0.296588\n",
      "epoch 3; iter: 600; batch classifier loss: 2.191669; batch adversarial loss: 0.424139\n",
      "epoch 4; iter: 0; batch classifier loss: 1.067920; batch adversarial loss: 0.533672\n",
      "epoch 4; iter: 200; batch classifier loss: 2.194174; batch adversarial loss: 0.358334\n",
      "epoch 4; iter: 400; batch classifier loss: 1.039554; batch adversarial loss: 0.455687\n",
      "epoch 4; iter: 600; batch classifier loss: 1.623888; batch adversarial loss: 0.565987\n",
      "epoch 5; iter: 0; batch classifier loss: 1.190558; batch adversarial loss: 0.384066\n",
      "epoch 5; iter: 200; batch classifier loss: 0.565744; batch adversarial loss: 0.466212\n",
      "epoch 5; iter: 400; batch classifier loss: 0.413387; batch adversarial loss: 0.426879\n",
      "epoch 5; iter: 600; batch classifier loss: 1.139075; batch adversarial loss: 0.369884\n",
      "epoch 6; iter: 0; batch classifier loss: 0.443223; batch adversarial loss: 0.465019\n",
      "epoch 6; iter: 200; batch classifier loss: 0.437813; batch adversarial loss: 0.517212\n",
      "epoch 6; iter: 400; batch classifier loss: 0.312181; batch adversarial loss: 0.503754\n",
      "epoch 6; iter: 600; batch classifier loss: 0.356856; batch adversarial loss: 0.372591\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336814; batch adversarial loss: 0.438129\n",
      "epoch 7; iter: 200; batch classifier loss: 1.093935; batch adversarial loss: 0.264354\n",
      "epoch 7; iter: 400; batch classifier loss: 0.652465; batch adversarial loss: 0.404893\n",
      "epoch 7; iter: 600; batch classifier loss: 0.373026; batch adversarial loss: 0.425256\n",
      "epoch 8; iter: 0; batch classifier loss: 0.367090; batch adversarial loss: 0.477959\n",
      "epoch 8; iter: 200; batch classifier loss: 0.481918; batch adversarial loss: 0.558594\n",
      "epoch 8; iter: 400; batch classifier loss: 0.424449; batch adversarial loss: 0.569173\n",
      "epoch 8; iter: 600; batch classifier loss: 0.345048; batch adversarial loss: 0.444171\n",
      "epoch 9; iter: 0; batch classifier loss: 0.464747; batch adversarial loss: 0.459015\n",
      "epoch 9; iter: 200; batch classifier loss: 0.298525; batch adversarial loss: 0.482061\n",
      "epoch 9; iter: 400; batch classifier loss: 0.340609; batch adversarial loss: 0.446659\n",
      "epoch 9; iter: 600; batch classifier loss: 0.412432; batch adversarial loss: 0.416729\n",
      "epoch 10; iter: 0; batch classifier loss: 0.354202; batch adversarial loss: 0.392437\n",
      "epoch 10; iter: 200; batch classifier loss: 0.423741; batch adversarial loss: 0.458421\n",
      "epoch 10; iter: 400; batch classifier loss: 0.351371; batch adversarial loss: 0.513419\n",
      "epoch 10; iter: 600; batch classifier loss: 0.379355; batch adversarial loss: 0.412112\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400578; batch adversarial loss: 0.425303\n",
      "epoch 11; iter: 200; batch classifier loss: 0.329568; batch adversarial loss: 0.332229\n",
      "epoch 11; iter: 400; batch classifier loss: 0.323561; batch adversarial loss: 0.504456\n",
      "epoch 11; iter: 600; batch classifier loss: 0.262770; batch adversarial loss: 0.540472\n",
      "epoch 12; iter: 0; batch classifier loss: 0.392575; batch adversarial loss: 0.317460\n",
      "epoch 12; iter: 200; batch classifier loss: 0.293195; batch adversarial loss: 0.343878\n",
      "epoch 12; iter: 400; batch classifier loss: 0.489235; batch adversarial loss: 0.474418\n",
      "epoch 12; iter: 600; batch classifier loss: 0.346821; batch adversarial loss: 0.366724\n",
      "epoch 13; iter: 0; batch classifier loss: 0.197567; batch adversarial loss: 0.428515\n",
      "epoch 13; iter: 200; batch classifier loss: 0.236449; batch adversarial loss: 0.487062\n",
      "epoch 13; iter: 400; batch classifier loss: 0.316994; batch adversarial loss: 0.481554\n",
      "epoch 13; iter: 600; batch classifier loss: 0.301687; batch adversarial loss: 0.482865\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367584; batch adversarial loss: 0.382430\n",
      "epoch 14; iter: 200; batch classifier loss: 0.345068; batch adversarial loss: 0.395279\n",
      "epoch 14; iter: 400; batch classifier loss: 0.294430; batch adversarial loss: 0.479183\n",
      "epoch 14; iter: 600; batch classifier loss: 0.375648; batch adversarial loss: 0.534569\n",
      "epoch 15; iter: 0; batch classifier loss: 0.271807; batch adversarial loss: 0.457613\n",
      "epoch 15; iter: 200; batch classifier loss: 0.369501; batch adversarial loss: 0.402297\n",
      "epoch 15; iter: 400; batch classifier loss: 0.319411; batch adversarial loss: 0.346318\n",
      "epoch 15; iter: 600; batch classifier loss: 0.462972; batch adversarial loss: 0.462574\n",
      "epoch 16; iter: 0; batch classifier loss: 0.309820; batch adversarial loss: 0.397925\n",
      "epoch 16; iter: 200; batch classifier loss: 0.303068; batch adversarial loss: 0.402887\n",
      "epoch 16; iter: 400; batch classifier loss: 0.330207; batch adversarial loss: 0.343398\n",
      "epoch 16; iter: 600; batch classifier loss: 0.342770; batch adversarial loss: 0.457488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.255008; batch adversarial loss: 0.478402\n",
      "epoch 17; iter: 200; batch classifier loss: 0.389214; batch adversarial loss: 0.529315\n",
      "epoch 17; iter: 400; batch classifier loss: 0.393079; batch adversarial loss: 0.275257\n",
      "epoch 17; iter: 600; batch classifier loss: 0.449674; batch adversarial loss: 0.266437\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391868; batch adversarial loss: 0.372442\n",
      "epoch 18; iter: 200; batch classifier loss: 0.250643; batch adversarial loss: 0.432699\n",
      "epoch 18; iter: 400; batch classifier loss: 0.551837; batch adversarial loss: 0.426904\n",
      "epoch 18; iter: 600; batch classifier loss: 0.455524; batch adversarial loss: 0.378917\n",
      "epoch 19; iter: 0; batch classifier loss: 0.420961; batch adversarial loss: 0.424128\n",
      "epoch 19; iter: 200; batch classifier loss: 0.269349; batch adversarial loss: 0.370684\n",
      "epoch 19; iter: 400; batch classifier loss: 0.311743; batch adversarial loss: 0.549531\n",
      "epoch 19; iter: 600; batch classifier loss: 0.362818; batch adversarial loss: 0.380517\n",
      "epoch 20; iter: 0; batch classifier loss: 0.347147; batch adversarial loss: 0.522386\n",
      "epoch 20; iter: 200; batch classifier loss: 0.304884; batch adversarial loss: 0.291528\n",
      "epoch 20; iter: 400; batch classifier loss: 0.398866; batch adversarial loss: 0.455667\n",
      "epoch 20; iter: 600; batch classifier loss: 0.397297; batch adversarial loss: 0.232455\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295170; batch adversarial loss: 0.426065\n",
      "epoch 21; iter: 200; batch classifier loss: 0.491875; batch adversarial loss: 0.287737\n",
      "epoch 21; iter: 400; batch classifier loss: 0.490100; batch adversarial loss: 0.399743\n",
      "epoch 21; iter: 600; batch classifier loss: 0.256571; batch adversarial loss: 0.382895\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437419; batch adversarial loss: 0.282669\n",
      "epoch 22; iter: 200; batch classifier loss: 0.377213; batch adversarial loss: 0.379425\n",
      "epoch 22; iter: 400; batch classifier loss: 0.402950; batch adversarial loss: 0.407824\n",
      "epoch 22; iter: 600; batch classifier loss: 0.619362; batch adversarial loss: 0.529399\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450536; batch adversarial loss: 0.429246\n",
      "epoch 23; iter: 200; batch classifier loss: 0.462109; batch adversarial loss: 0.427261\n",
      "epoch 23; iter: 400; batch classifier loss: 0.532434; batch adversarial loss: 0.324302\n",
      "epoch 23; iter: 600; batch classifier loss: 0.718333; batch adversarial loss: 0.355827\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361266; batch adversarial loss: 0.291662\n",
      "epoch 24; iter: 200; batch classifier loss: 0.642384; batch adversarial loss: 0.432102\n",
      "epoch 24; iter: 400; batch classifier loss: 0.497440; batch adversarial loss: 0.410700\n",
      "epoch 24; iter: 600; batch classifier loss: 0.393169; batch adversarial loss: 0.467419\n",
      "epoch 25; iter: 0; batch classifier loss: 0.284740; batch adversarial loss: 0.351299\n",
      "epoch 25; iter: 200; batch classifier loss: 0.363310; batch adversarial loss: 0.459656\n",
      "epoch 25; iter: 400; batch classifier loss: 0.745323; batch adversarial loss: 0.462499\n",
      "epoch 25; iter: 600; batch classifier loss: 0.443738; batch adversarial loss: 0.549767\n",
      "epoch 26; iter: 0; batch classifier loss: 0.373224; batch adversarial loss: 0.404745\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343535; batch adversarial loss: 0.489628\n",
      "epoch 26; iter: 400; batch classifier loss: 0.481919; batch adversarial loss: 0.431163\n",
      "epoch 26; iter: 600; batch classifier loss: 0.651555; batch adversarial loss: 0.483498\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480721; batch adversarial loss: 0.431025\n",
      "epoch 27; iter: 200; batch classifier loss: 0.594410; batch adversarial loss: 0.486231\n",
      "epoch 27; iter: 400; batch classifier loss: 0.350859; batch adversarial loss: 0.241001\n",
      "epoch 27; iter: 600; batch classifier loss: 0.626665; batch adversarial loss: 0.486198\n",
      "epoch 28; iter: 0; batch classifier loss: 0.617695; batch adversarial loss: 0.406883\n",
      "epoch 28; iter: 200; batch classifier loss: 0.694771; batch adversarial loss: 0.375304\n",
      "epoch 28; iter: 400; batch classifier loss: 0.658385; batch adversarial loss: 0.435668\n",
      "epoch 28; iter: 600; batch classifier loss: 0.416308; batch adversarial loss: 0.377562\n",
      "epoch 29; iter: 0; batch classifier loss: 0.556479; batch adversarial loss: 0.595560\n",
      "epoch 29; iter: 200; batch classifier loss: 0.589191; batch adversarial loss: 0.291549\n",
      "epoch 29; iter: 400; batch classifier loss: 0.578332; batch adversarial loss: 0.354630\n",
      "epoch 29; iter: 600; batch classifier loss: 0.421940; batch adversarial loss: 0.408322\n",
      "epoch 30; iter: 0; batch classifier loss: 0.471960; batch adversarial loss: 0.347962\n",
      "epoch 30; iter: 200; batch classifier loss: 0.299518; batch adversarial loss: 0.513837\n",
      "epoch 30; iter: 400; batch classifier loss: 0.557341; batch adversarial loss: 0.348141\n",
      "epoch 30; iter: 600; batch classifier loss: 0.631911; batch adversarial loss: 0.429382\n",
      "epoch 31; iter: 0; batch classifier loss: 0.336787; batch adversarial loss: 0.300197\n",
      "epoch 31; iter: 200; batch classifier loss: 0.444633; batch adversarial loss: 0.299631\n",
      "epoch 31; iter: 400; batch classifier loss: 0.312046; batch adversarial loss: 0.458234\n",
      "epoch 31; iter: 600; batch classifier loss: 0.528399; batch adversarial loss: 0.460665\n",
      "epoch 32; iter: 0; batch classifier loss: 0.538791; batch adversarial loss: 0.502310\n",
      "epoch 32; iter: 200; batch classifier loss: 0.425532; batch adversarial loss: 0.319595\n",
      "epoch 32; iter: 400; batch classifier loss: 0.561084; batch adversarial loss: 0.434941\n",
      "epoch 32; iter: 600; batch classifier loss: 0.814360; batch adversarial loss: 0.435194\n",
      "epoch 33; iter: 0; batch classifier loss: 0.679395; batch adversarial loss: 0.513776\n",
      "epoch 33; iter: 200; batch classifier loss: 0.692323; batch adversarial loss: 0.654082\n",
      "epoch 33; iter: 400; batch classifier loss: 0.481963; batch adversarial loss: 0.383079\n",
      "epoch 33; iter: 600; batch classifier loss: 0.336243; batch adversarial loss: 0.431557\n",
      "epoch 34; iter: 0; batch classifier loss: 0.790753; batch adversarial loss: 0.375386\n",
      "epoch 34; iter: 200; batch classifier loss: 0.521893; batch adversarial loss: 0.435309\n",
      "epoch 34; iter: 400; batch classifier loss: 0.551453; batch adversarial loss: 0.413197\n",
      "epoch 34; iter: 600; batch classifier loss: 0.737844; batch adversarial loss: 0.373878\n",
      "epoch 35; iter: 0; batch classifier loss: 0.677967; batch adversarial loss: 0.401666\n",
      "epoch 35; iter: 200; batch classifier loss: 0.458689; batch adversarial loss: 0.243949\n",
      "epoch 35; iter: 400; batch classifier loss: 0.744197; batch adversarial loss: 0.434489\n",
      "epoch 35; iter: 600; batch classifier loss: 0.536966; batch adversarial loss: 0.435205\n",
      "epoch 36; iter: 0; batch classifier loss: 0.542855; batch adversarial loss: 0.328441\n",
      "epoch 36; iter: 200; batch classifier loss: 0.552675; batch adversarial loss: 0.516022\n",
      "epoch 36; iter: 400; batch classifier loss: 0.666240; batch adversarial loss: 0.408934\n",
      "epoch 36; iter: 600; batch classifier loss: 0.754314; batch adversarial loss: 0.347804\n",
      "epoch 37; iter: 0; batch classifier loss: 0.671267; batch adversarial loss: 0.375963\n",
      "epoch 37; iter: 200; batch classifier loss: 0.540195; batch adversarial loss: 0.321567\n",
      "epoch 37; iter: 400; batch classifier loss: 0.633126; batch adversarial loss: 0.355223\n",
      "epoch 37; iter: 600; batch classifier loss: 0.896108; batch adversarial loss: 0.457647\n",
      "epoch 38; iter: 0; batch classifier loss: 0.698273; batch adversarial loss: 0.349887\n",
      "epoch 38; iter: 200; batch classifier loss: 0.597798; batch adversarial loss: 0.435743\n",
      "epoch 38; iter: 400; batch classifier loss: 0.527511; batch adversarial loss: 0.353307\n",
      "epoch 38; iter: 600; batch classifier loss: 0.481248; batch adversarial loss: 0.381265\n",
      "epoch 39; iter: 0; batch classifier loss: 0.812561; batch adversarial loss: 0.347129\n",
      "epoch 39; iter: 200; batch classifier loss: 0.751937; batch adversarial loss: 0.381207\n",
      "epoch 39; iter: 400; batch classifier loss: 0.570721; batch adversarial loss: 0.520033\n",
      "epoch 39; iter: 600; batch classifier loss: 0.472298; batch adversarial loss: 0.484290\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418322; batch adversarial loss: 0.324833\n",
      "epoch 40; iter: 200; batch classifier loss: 0.602440; batch adversarial loss: 0.403151\n",
      "epoch 40; iter: 400; batch classifier loss: 0.404967; batch adversarial loss: 0.407821\n",
      "epoch 40; iter: 600; batch classifier loss: 0.519648; batch adversarial loss: 0.430911\n",
      "epoch 41; iter: 0; batch classifier loss: 0.613631; batch adversarial loss: 0.435881\n",
      "epoch 41; iter: 200; batch classifier loss: 0.747303; batch adversarial loss: 0.416909\n",
      "epoch 41; iter: 400; batch classifier loss: 0.780516; batch adversarial loss: 0.316499\n",
      "epoch 41; iter: 600; batch classifier loss: 0.599338; batch adversarial loss: 0.577477\n",
      "epoch 42; iter: 0; batch classifier loss: 0.701274; batch adversarial loss: 0.484288\n",
      "epoch 42; iter: 200; batch classifier loss: 0.588701; batch adversarial loss: 0.485483\n",
      "epoch 42; iter: 400; batch classifier loss: 0.447633; batch adversarial loss: 0.485417\n",
      "epoch 42; iter: 600; batch classifier loss: 0.410881; batch adversarial loss: 0.487434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.525294; batch adversarial loss: 0.460753\n",
      "epoch 43; iter: 200; batch classifier loss: 0.888994; batch adversarial loss: 0.348714\n",
      "epoch 43; iter: 400; batch classifier loss: 0.944420; batch adversarial loss: 0.297783\n",
      "epoch 43; iter: 600; batch classifier loss: 0.493758; batch adversarial loss: 0.545810\n",
      "epoch 44; iter: 0; batch classifier loss: 0.715707; batch adversarial loss: 0.510737\n",
      "epoch 44; iter: 200; batch classifier loss: 0.699195; batch adversarial loss: 0.462811\n",
      "epoch 44; iter: 400; batch classifier loss: 0.763446; batch adversarial loss: 0.375216\n",
      "epoch 44; iter: 600; batch classifier loss: 0.309422; batch adversarial loss: 0.297685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.636282; batch adversarial loss: 0.470749\n",
      "epoch 45; iter: 200; batch classifier loss: 0.598028; batch adversarial loss: 0.516308\n",
      "epoch 45; iter: 400; batch classifier loss: 0.706921; batch adversarial loss: 0.472356\n",
      "epoch 45; iter: 600; batch classifier loss: 0.571724; batch adversarial loss: 0.346106\n",
      "epoch 46; iter: 0; batch classifier loss: 0.500469; batch adversarial loss: 0.608201\n",
      "epoch 46; iter: 200; batch classifier loss: 0.591025; batch adversarial loss: 0.345083\n",
      "epoch 46; iter: 400; batch classifier loss: 0.599303; batch adversarial loss: 0.542299\n",
      "epoch 46; iter: 600; batch classifier loss: 0.594639; batch adversarial loss: 0.539951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.527505; batch adversarial loss: 0.433815\n",
      "epoch 47; iter: 200; batch classifier loss: 0.906122; batch adversarial loss: 0.484605\n",
      "epoch 47; iter: 400; batch classifier loss: 0.504307; batch adversarial loss: 0.320819\n",
      "epoch 47; iter: 600; batch classifier loss: 0.557406; batch adversarial loss: 0.437886\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446793; batch adversarial loss: 0.320610\n",
      "epoch 48; iter: 200; batch classifier loss: 0.955300; batch adversarial loss: 0.411666\n",
      "epoch 48; iter: 400; batch classifier loss: 0.625569; batch adversarial loss: 0.414456\n",
      "epoch 48; iter: 600; batch classifier loss: 0.703870; batch adversarial loss: 0.492780\n",
      "epoch 49; iter: 0; batch classifier loss: 0.697585; batch adversarial loss: 0.551049\n",
      "epoch 49; iter: 200; batch classifier loss: 0.643378; batch adversarial loss: 0.297122\n",
      "epoch 49; iter: 400; batch classifier loss: 0.625261; batch adversarial loss: 0.430748\n",
      "epoch 49; iter: 600; batch classifier loss: 0.668524; batch adversarial loss: 0.352046\n",
      "epoch 0; iter: 0; batch classifier loss: 54.983227; batch adversarial loss: 0.594935\n",
      "epoch 0; iter: 200; batch classifier loss: 4.647027; batch adversarial loss: 0.575239\n",
      "epoch 0; iter: 400; batch classifier loss: 6.455164; batch adversarial loss: 0.558592\n",
      "epoch 0; iter: 600; batch classifier loss: 5.228271; batch adversarial loss: 0.467939\n",
      "epoch 1; iter: 0; batch classifier loss: 1.881522; batch adversarial loss: 0.511865\n",
      "epoch 1; iter: 200; batch classifier loss: 4.074097; batch adversarial loss: 0.503410\n",
      "epoch 1; iter: 400; batch classifier loss: 3.484449; batch adversarial loss: 0.426916\n",
      "epoch 1; iter: 600; batch classifier loss: 5.168926; batch adversarial loss: 0.394980\n",
      "epoch 2; iter: 0; batch classifier loss: 3.961164; batch adversarial loss: 0.361592\n",
      "epoch 2; iter: 200; batch classifier loss: 5.529610; batch adversarial loss: 0.432834\n",
      "epoch 2; iter: 400; batch classifier loss: 1.484994; batch adversarial loss: 0.428383\n",
      "epoch 2; iter: 600; batch classifier loss: 0.763212; batch adversarial loss: 0.528307\n",
      "epoch 3; iter: 0; batch classifier loss: 0.369499; batch adversarial loss: 0.399073\n",
      "epoch 3; iter: 200; batch classifier loss: 4.394135; batch adversarial loss: 0.397300\n",
      "epoch 3; iter: 400; batch classifier loss: 0.404020; batch adversarial loss: 0.399522\n",
      "epoch 3; iter: 600; batch classifier loss: 2.257831; batch adversarial loss: 0.456455\n",
      "epoch 4; iter: 0; batch classifier loss: 2.286408; batch adversarial loss: 0.553992\n",
      "epoch 4; iter: 200; batch classifier loss: 1.388644; batch adversarial loss: 0.464443\n",
      "epoch 4; iter: 400; batch classifier loss: 0.808001; batch adversarial loss: 0.459759\n",
      "epoch 4; iter: 600; batch classifier loss: 1.804459; batch adversarial loss: 0.352405\n",
      "epoch 5; iter: 0; batch classifier loss: 0.957134; batch adversarial loss: 0.409804\n",
      "epoch 5; iter: 200; batch classifier loss: 0.687009; batch adversarial loss: 0.401755\n",
      "epoch 5; iter: 400; batch classifier loss: 0.323448; batch adversarial loss: 0.349159\n",
      "epoch 5; iter: 600; batch classifier loss: 0.465886; batch adversarial loss: 0.293592\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451001; batch adversarial loss: 0.407175\n",
      "epoch 6; iter: 200; batch classifier loss: 0.841922; batch adversarial loss: 0.251618\n",
      "epoch 6; iter: 400; batch classifier loss: 0.430241; batch adversarial loss: 0.385056\n",
      "epoch 6; iter: 600; batch classifier loss: 0.329080; batch adversarial loss: 0.560767\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342827; batch adversarial loss: 0.344195\n",
      "epoch 7; iter: 200; batch classifier loss: 0.379167; batch adversarial loss: 0.342334\n",
      "epoch 7; iter: 400; batch classifier loss: 0.412450; batch adversarial loss: 0.326630\n",
      "epoch 7; iter: 600; batch classifier loss: 0.283292; batch adversarial loss: 0.326085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.447259; batch adversarial loss: 0.370654\n",
      "epoch 8; iter: 200; batch classifier loss: 0.441367; batch adversarial loss: 0.524712\n",
      "epoch 8; iter: 400; batch classifier loss: 0.337681; batch adversarial loss: 0.504836\n",
      "epoch 8; iter: 600; batch classifier loss: 0.428966; batch adversarial loss: 0.511432\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383965; batch adversarial loss: 0.369124\n",
      "epoch 9; iter: 200; batch classifier loss: 0.434040; batch adversarial loss: 0.344304\n",
      "epoch 9; iter: 400; batch classifier loss: 0.348620; batch adversarial loss: 0.432232\n",
      "epoch 9; iter: 600; batch classifier loss: 0.334633; batch adversarial loss: 0.468899\n",
      "epoch 10; iter: 0; batch classifier loss: 0.379323; batch adversarial loss: 0.482066\n",
      "epoch 10; iter: 200; batch classifier loss: 0.396333; batch adversarial loss: 0.517007\n",
      "epoch 10; iter: 400; batch classifier loss: 0.435878; batch adversarial loss: 0.515479\n",
      "epoch 10; iter: 600; batch classifier loss: 0.412231; batch adversarial loss: 0.450600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398539; batch adversarial loss: 0.350601\n",
      "epoch 11; iter: 200; batch classifier loss: 0.435212; batch adversarial loss: 0.263732\n",
      "epoch 11; iter: 400; batch classifier loss: 0.520338; batch adversarial loss: 0.439964\n",
      "epoch 11; iter: 600; batch classifier loss: 0.323283; batch adversarial loss: 0.450723\n",
      "epoch 12; iter: 0; batch classifier loss: 0.283315; batch adversarial loss: 0.418270\n",
      "epoch 12; iter: 200; batch classifier loss: 0.322659; batch adversarial loss: 0.523277\n",
      "epoch 12; iter: 400; batch classifier loss: 0.450940; batch adversarial loss: 0.341588\n",
      "epoch 12; iter: 600; batch classifier loss: 0.340565; batch adversarial loss: 0.426129\n",
      "epoch 13; iter: 0; batch classifier loss: 0.274069; batch adversarial loss: 0.373942\n",
      "epoch 13; iter: 200; batch classifier loss: 0.341292; batch adversarial loss: 0.372691\n",
      "epoch 13; iter: 400; batch classifier loss: 0.444421; batch adversarial loss: 0.431538\n",
      "epoch 13; iter: 600; batch classifier loss: 0.439056; batch adversarial loss: 0.384912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.365869; batch adversarial loss: 0.428186\n",
      "epoch 14; iter: 200; batch classifier loss: 0.289551; batch adversarial loss: 0.317508\n",
      "epoch 14; iter: 400; batch classifier loss: 0.439278; batch adversarial loss: 0.427847\n",
      "epoch 14; iter: 600; batch classifier loss: 0.470582; batch adversarial loss: 0.442724\n",
      "epoch 15; iter: 0; batch classifier loss: 0.345104; batch adversarial loss: 0.380143\n",
      "epoch 15; iter: 200; batch classifier loss: 0.426788; batch adversarial loss: 0.460406\n",
      "epoch 15; iter: 400; batch classifier loss: 0.585162; batch adversarial loss: 0.503237\n",
      "epoch 15; iter: 600; batch classifier loss: 0.336888; batch adversarial loss: 0.390506\n",
      "epoch 16; iter: 0; batch classifier loss: 0.313589; batch adversarial loss: 0.539417\n",
      "epoch 16; iter: 200; batch classifier loss: 0.345518; batch adversarial loss: 0.557485\n",
      "epoch 16; iter: 400; batch classifier loss: 0.434314; batch adversarial loss: 0.341114\n",
      "epoch 16; iter: 600; batch classifier loss: 0.337967; batch adversarial loss: 0.382904\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453447; batch adversarial loss: 0.455283\n",
      "epoch 17; iter: 200; batch classifier loss: 0.621209; batch adversarial loss: 0.438091\n",
      "epoch 17; iter: 400; batch classifier loss: 0.415920; batch adversarial loss: 0.319122\n",
      "epoch 17; iter: 600; batch classifier loss: 0.309852; batch adversarial loss: 0.369844\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396162; batch adversarial loss: 0.419096\n",
      "epoch 18; iter: 200; batch classifier loss: 0.240464; batch adversarial loss: 0.416636\n",
      "epoch 18; iter: 400; batch classifier loss: 0.278499; batch adversarial loss: 0.376311\n",
      "epoch 18; iter: 600; batch classifier loss: 0.532567; batch adversarial loss: 0.436124\n",
      "epoch 19; iter: 0; batch classifier loss: 0.452882; batch adversarial loss: 0.511008\n",
      "epoch 19; iter: 200; batch classifier loss: 0.423504; batch adversarial loss: 0.439232\n",
      "epoch 19; iter: 400; batch classifier loss: 0.499023; batch adversarial loss: 0.494025\n",
      "epoch 19; iter: 600; batch classifier loss: 0.369150; batch adversarial loss: 0.411435\n",
      "epoch 20; iter: 0; batch classifier loss: 0.500010; batch adversarial loss: 0.445337\n",
      "epoch 20; iter: 200; batch classifier loss: 0.352170; batch adversarial loss: 0.397512\n",
      "epoch 20; iter: 400; batch classifier loss: 0.520131; batch adversarial loss: 0.425395\n",
      "epoch 20; iter: 600; batch classifier loss: 0.273536; batch adversarial loss: 0.403790\n",
      "epoch 21; iter: 0; batch classifier loss: 0.399789; batch adversarial loss: 0.405811\n",
      "epoch 21; iter: 200; batch classifier loss: 0.373819; batch adversarial loss: 0.348238\n",
      "epoch 21; iter: 400; batch classifier loss: 0.584101; batch adversarial loss: 0.422700\n",
      "epoch 21; iter: 600; batch classifier loss: 0.434880; batch adversarial loss: 0.348596\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466334; batch adversarial loss: 0.454713\n",
      "epoch 22; iter: 200; batch classifier loss: 0.353206; batch adversarial loss: 0.430987\n",
      "epoch 22; iter: 400; batch classifier loss: 0.509912; batch adversarial loss: 0.484057\n",
      "epoch 22; iter: 600; batch classifier loss: 0.486821; batch adversarial loss: 0.349794\n",
      "epoch 23; iter: 0; batch classifier loss: 0.566506; batch adversarial loss: 0.464470\n",
      "epoch 23; iter: 200; batch classifier loss: 0.672037; batch adversarial loss: 0.322327\n",
      "epoch 23; iter: 400; batch classifier loss: 0.486323; batch adversarial loss: 0.374099\n",
      "epoch 23; iter: 600; batch classifier loss: 0.438682; batch adversarial loss: 0.266248\n",
      "epoch 24; iter: 0; batch classifier loss: 0.699250; batch adversarial loss: 0.568693\n",
      "epoch 24; iter: 200; batch classifier loss: 0.584162; batch adversarial loss: 0.345811\n",
      "epoch 24; iter: 400; batch classifier loss: 0.662439; batch adversarial loss: 0.517061\n",
      "epoch 24; iter: 600; batch classifier loss: 0.542374; batch adversarial loss: 0.427543\n",
      "epoch 25; iter: 0; batch classifier loss: 0.281780; batch adversarial loss: 0.506785\n",
      "epoch 25; iter: 200; batch classifier loss: 0.565979; batch adversarial loss: 0.491158\n",
      "epoch 25; iter: 400; batch classifier loss: 0.424237; batch adversarial loss: 0.400009\n",
      "epoch 25; iter: 600; batch classifier loss: 0.515765; batch adversarial loss: 0.356310\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444837; batch adversarial loss: 0.263346\n",
      "epoch 26; iter: 200; batch classifier loss: 0.499351; batch adversarial loss: 0.398610\n",
      "epoch 26; iter: 400; batch classifier loss: 0.392397; batch adversarial loss: 0.351770\n",
      "epoch 26; iter: 600; batch classifier loss: 0.423973; batch adversarial loss: 0.407714\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413573; batch adversarial loss: 0.430381\n",
      "epoch 27; iter: 200; batch classifier loss: 0.822949; batch adversarial loss: 0.431278\n",
      "epoch 27; iter: 400; batch classifier loss: 0.440404; batch adversarial loss: 0.427734\n",
      "epoch 27; iter: 600; batch classifier loss: 0.519137; batch adversarial loss: 0.373102\n",
      "epoch 28; iter: 0; batch classifier loss: 0.341401; batch adversarial loss: 0.407390\n",
      "epoch 28; iter: 200; batch classifier loss: 0.466304; batch adversarial loss: 0.380466\n",
      "epoch 28; iter: 400; batch classifier loss: 0.366118; batch adversarial loss: 0.318485\n",
      "epoch 28; iter: 600; batch classifier loss: 0.550856; batch adversarial loss: 0.573543\n",
      "epoch 29; iter: 0; batch classifier loss: 0.623929; batch adversarial loss: 0.454112\n",
      "epoch 29; iter: 200; batch classifier loss: 0.759843; batch adversarial loss: 0.409960\n",
      "epoch 29; iter: 400; batch classifier loss: 0.508212; batch adversarial loss: 0.541726\n",
      "epoch 29; iter: 600; batch classifier loss: 0.450999; batch adversarial loss: 0.377144\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524336; batch adversarial loss: 0.404090\n",
      "epoch 30; iter: 200; batch classifier loss: 0.526894; batch adversarial loss: 0.621627\n",
      "epoch 30; iter: 400; batch classifier loss: 0.598645; batch adversarial loss: 0.488189\n",
      "epoch 30; iter: 600; batch classifier loss: 0.489723; batch adversarial loss: 0.354187\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432704; batch adversarial loss: 0.429698\n",
      "epoch 31; iter: 200; batch classifier loss: 0.709854; batch adversarial loss: 0.265016\n",
      "epoch 31; iter: 400; batch classifier loss: 0.395433; batch adversarial loss: 0.296241\n",
      "epoch 31; iter: 600; batch classifier loss: 0.603361; batch adversarial loss: 0.316635\n",
      "epoch 32; iter: 0; batch classifier loss: 0.474683; batch adversarial loss: 0.408791\n",
      "epoch 32; iter: 200; batch classifier loss: 0.518028; batch adversarial loss: 0.320363\n",
      "epoch 32; iter: 400; batch classifier loss: 0.679703; batch adversarial loss: 0.437862\n",
      "epoch 32; iter: 600; batch classifier loss: 0.474148; batch adversarial loss: 0.485924\n",
      "epoch 33; iter: 0; batch classifier loss: 0.468044; batch adversarial loss: 0.436508\n",
      "epoch 33; iter: 200; batch classifier loss: 0.524804; batch adversarial loss: 0.266676\n",
      "epoch 33; iter: 400; batch classifier loss: 0.621175; batch adversarial loss: 0.402502\n",
      "epoch 33; iter: 600; batch classifier loss: 0.347203; batch adversarial loss: 0.348905\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533666; batch adversarial loss: 0.347262\n",
      "epoch 34; iter: 200; batch classifier loss: 0.401094; batch adversarial loss: 0.464477\n",
      "epoch 34; iter: 400; batch classifier loss: 0.570923; batch adversarial loss: 0.348526\n",
      "epoch 34; iter: 600; batch classifier loss: 0.428945; batch adversarial loss: 0.484855\n",
      "epoch 35; iter: 0; batch classifier loss: 0.267511; batch adversarial loss: 0.565351\n",
      "epoch 35; iter: 200; batch classifier loss: 0.893314; batch adversarial loss: 0.293418\n",
      "epoch 35; iter: 400; batch classifier loss: 0.582522; batch adversarial loss: 0.347302\n",
      "epoch 35; iter: 600; batch classifier loss: 0.621226; batch adversarial loss: 0.273535\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443340; batch adversarial loss: 0.379516\n",
      "epoch 36; iter: 200; batch classifier loss: 0.643237; batch adversarial loss: 0.375721\n",
      "epoch 36; iter: 400; batch classifier loss: 0.786517; batch adversarial loss: 0.438766\n",
      "epoch 36; iter: 600; batch classifier loss: 0.603215; batch adversarial loss: 0.426587\n",
      "epoch 37; iter: 0; batch classifier loss: 0.739730; batch adversarial loss: 0.403595\n",
      "epoch 37; iter: 200; batch classifier loss: 0.708400; batch adversarial loss: 0.408692\n",
      "epoch 37; iter: 400; batch classifier loss: 0.549770; batch adversarial loss: 0.433942\n",
      "epoch 37; iter: 600; batch classifier loss: 0.432941; batch adversarial loss: 0.406616\n",
      "epoch 38; iter: 0; batch classifier loss: 0.591821; batch adversarial loss: 0.636984\n",
      "epoch 38; iter: 200; batch classifier loss: 0.600730; batch adversarial loss: 0.375541\n",
      "epoch 38; iter: 400; batch classifier loss: 0.438435; batch adversarial loss: 0.403997\n",
      "epoch 38; iter: 600; batch classifier loss: 0.371246; batch adversarial loss: 0.353771\n",
      "epoch 39; iter: 0; batch classifier loss: 0.730345; batch adversarial loss: 0.241000\n",
      "epoch 39; iter: 200; batch classifier loss: 0.797595; batch adversarial loss: 0.352383\n",
      "epoch 39; iter: 400; batch classifier loss: 0.385372; batch adversarial loss: 0.431002\n",
      "epoch 39; iter: 600; batch classifier loss: 0.498511; batch adversarial loss: 0.384032\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477762; batch adversarial loss: 0.353193\n",
      "epoch 40; iter: 200; batch classifier loss: 0.626494; batch adversarial loss: 0.296694\n",
      "epoch 40; iter: 400; batch classifier loss: 0.632951; batch adversarial loss: 0.429314\n",
      "epoch 40; iter: 600; batch classifier loss: 0.425318; batch adversarial loss: 0.465172\n",
      "epoch 41; iter: 0; batch classifier loss: 0.565784; batch adversarial loss: 0.438072\n",
      "epoch 41; iter: 200; batch classifier loss: 0.898329; batch adversarial loss: 0.518245\n",
      "epoch 41; iter: 400; batch classifier loss: 0.526602; batch adversarial loss: 0.403066\n",
      "epoch 41; iter: 600; batch classifier loss: 0.952841; batch adversarial loss: 0.267868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.550640; batch adversarial loss: 0.319983\n",
      "epoch 42; iter: 200; batch classifier loss: 0.662864; batch adversarial loss: 0.290806\n",
      "epoch 42; iter: 400; batch classifier loss: 0.544086; batch adversarial loss: 0.348577\n",
      "epoch 42; iter: 600; batch classifier loss: 0.562019; batch adversarial loss: 0.471214\n",
      "epoch 43; iter: 0; batch classifier loss: 0.462979; batch adversarial loss: 0.462618\n",
      "epoch 43; iter: 200; batch classifier loss: 0.871380; batch adversarial loss: 0.457980\n",
      "epoch 43; iter: 400; batch classifier loss: 0.464703; batch adversarial loss: 0.376477\n",
      "epoch 43; iter: 600; batch classifier loss: 0.773029; batch adversarial loss: 0.514486\n",
      "epoch 44; iter: 0; batch classifier loss: 0.663440; batch adversarial loss: 0.446106\n",
      "epoch 44; iter: 200; batch classifier loss: 0.470731; batch adversarial loss: 0.431758\n",
      "epoch 44; iter: 400; batch classifier loss: 0.910655; batch adversarial loss: 0.321077\n",
      "epoch 44; iter: 600; batch classifier loss: 0.598462; batch adversarial loss: 0.521378\n",
      "epoch 45; iter: 0; batch classifier loss: 0.588415; batch adversarial loss: 0.372769\n",
      "epoch 45; iter: 200; batch classifier loss: 0.388873; batch adversarial loss: 0.347346\n",
      "epoch 45; iter: 400; batch classifier loss: 0.586476; batch adversarial loss: 0.354635\n",
      "epoch 45; iter: 600; batch classifier loss: 0.555999; batch adversarial loss: 0.327916\n",
      "epoch 46; iter: 0; batch classifier loss: 0.806238; batch adversarial loss: 0.346778\n",
      "epoch 46; iter: 200; batch classifier loss: 0.579963; batch adversarial loss: 0.413899\n",
      "epoch 46; iter: 400; batch classifier loss: 0.517017; batch adversarial loss: 0.289558\n",
      "epoch 46; iter: 600; batch classifier loss: 0.599980; batch adversarial loss: 0.404604\n",
      "epoch 47; iter: 0; batch classifier loss: 0.448027; batch adversarial loss: 0.381921\n",
      "epoch 47; iter: 200; batch classifier loss: 0.568256; batch adversarial loss: 0.373541\n",
      "epoch 47; iter: 400; batch classifier loss: 0.338179; batch adversarial loss: 0.513124\n",
      "epoch 47; iter: 600; batch classifier loss: 0.418099; batch adversarial loss: 0.295790\n",
      "epoch 48; iter: 0; batch classifier loss: 0.880588; batch adversarial loss: 0.325287\n",
      "epoch 48; iter: 200; batch classifier loss: 0.461966; batch adversarial loss: 0.428665\n",
      "epoch 48; iter: 400; batch classifier loss: 0.807308; batch adversarial loss: 0.375680\n",
      "epoch 48; iter: 600; batch classifier loss: 0.507536; batch adversarial loss: 0.466294\n",
      "epoch 49; iter: 0; batch classifier loss: 1.076049; batch adversarial loss: 0.345347\n",
      "epoch 49; iter: 200; batch classifier loss: 0.521510; batch adversarial loss: 0.515382\n",
      "epoch 49; iter: 400; batch classifier loss: 0.659861; batch adversarial loss: 0.599687\n",
      "epoch 49; iter: 600; batch classifier loss: 0.840661; batch adversarial loss: 0.461828\n",
      "epoch 0; iter: 0; batch classifier loss: 14.244443; batch adversarial loss: 0.618796\n",
      "epoch 0; iter: 200; batch classifier loss: 5.341588; batch adversarial loss: 0.579990\n",
      "epoch 0; iter: 400; batch classifier loss: 6.122806; batch adversarial loss: 0.599558\n",
      "epoch 0; iter: 600; batch classifier loss: 1.176532; batch adversarial loss: 0.502002\n",
      "epoch 1; iter: 0; batch classifier loss: 6.996413; batch adversarial loss: 0.599141\n",
      "epoch 1; iter: 200; batch classifier loss: 6.146925; batch adversarial loss: 0.440767\n",
      "epoch 1; iter: 400; batch classifier loss: 10.870019; batch adversarial loss: 0.435988\n",
      "epoch 1; iter: 600; batch classifier loss: 1.328514; batch adversarial loss: 0.495522\n",
      "epoch 2; iter: 0; batch classifier loss: 1.872629; batch adversarial loss: 0.433570\n",
      "epoch 2; iter: 200; batch classifier loss: 1.314424; batch adversarial loss: 0.433377\n",
      "epoch 2; iter: 400; batch classifier loss: 0.876608; batch adversarial loss: 0.455710\n",
      "epoch 2; iter: 600; batch classifier loss: 0.482596; batch adversarial loss: 0.412939\n",
      "epoch 3; iter: 0; batch classifier loss: 0.504678; batch adversarial loss: 0.447990\n",
      "epoch 3; iter: 200; batch classifier loss: 1.039229; batch adversarial loss: 0.561143\n",
      "epoch 3; iter: 400; batch classifier loss: 1.186292; batch adversarial loss: 0.368794\n",
      "epoch 3; iter: 600; batch classifier loss: 1.295796; batch adversarial loss: 0.417450\n",
      "epoch 4; iter: 0; batch classifier loss: 1.377935; batch adversarial loss: 0.376838\n",
      "epoch 4; iter: 200; batch classifier loss: 0.599531; batch adversarial loss: 0.367762\n",
      "epoch 4; iter: 400; batch classifier loss: 0.503524; batch adversarial loss: 0.369489\n",
      "epoch 4; iter: 600; batch classifier loss: 1.269880; batch adversarial loss: 0.513396\n",
      "epoch 5; iter: 0; batch classifier loss: 0.366617; batch adversarial loss: 0.541083\n",
      "epoch 5; iter: 200; batch classifier loss: 0.458971; batch adversarial loss: 0.389444\n",
      "epoch 5; iter: 400; batch classifier loss: 0.496016; batch adversarial loss: 0.402278\n",
      "epoch 5; iter: 600; batch classifier loss: 0.565984; batch adversarial loss: 0.490027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.542094; batch adversarial loss: 0.359010\n",
      "epoch 6; iter: 200; batch classifier loss: 0.309104; batch adversarial loss: 0.485344\n",
      "epoch 6; iter: 400; batch classifier loss: 0.458183; batch adversarial loss: 0.456213\n",
      "epoch 6; iter: 600; batch classifier loss: 0.402225; batch adversarial loss: 0.374908\n",
      "epoch 7; iter: 0; batch classifier loss: 0.360699; batch adversarial loss: 0.481225\n",
      "epoch 7; iter: 200; batch classifier loss: 0.518537; batch adversarial loss: 0.294244\n",
      "epoch 7; iter: 400; batch classifier loss: 0.320323; batch adversarial loss: 0.517880\n",
      "epoch 7; iter: 600; batch classifier loss: 0.330681; batch adversarial loss: 0.414618\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394970; batch adversarial loss: 0.413037\n",
      "epoch 8; iter: 200; batch classifier loss: 0.462920; batch adversarial loss: 0.374721\n",
      "epoch 8; iter: 400; batch classifier loss: 0.307044; batch adversarial loss: 0.301252\n",
      "epoch 8; iter: 600; batch classifier loss: 0.397497; batch adversarial loss: 0.311212\n",
      "epoch 9; iter: 0; batch classifier loss: 0.473781; batch adversarial loss: 0.347647\n",
      "epoch 9; iter: 200; batch classifier loss: 0.303460; batch adversarial loss: 0.439249\n",
      "epoch 9; iter: 400; batch classifier loss: 0.300399; batch adversarial loss: 0.428944\n",
      "epoch 9; iter: 600; batch classifier loss: 0.332479; batch adversarial loss: 0.484864\n",
      "epoch 10; iter: 0; batch classifier loss: 0.355509; batch adversarial loss: 0.401119\n",
      "epoch 10; iter: 200; batch classifier loss: 0.371431; batch adversarial loss: 0.318758\n",
      "epoch 10; iter: 400; batch classifier loss: 0.390599; batch adversarial loss: 0.458424\n",
      "epoch 10; iter: 600; batch classifier loss: 0.397023; batch adversarial loss: 0.546586\n",
      "epoch 11; iter: 0; batch classifier loss: 0.350457; batch adversarial loss: 0.512957\n",
      "epoch 11; iter: 200; batch classifier loss: 0.333656; batch adversarial loss: 0.445955\n",
      "epoch 11; iter: 400; batch classifier loss: 0.404481; batch adversarial loss: 0.413168\n",
      "epoch 11; iter: 600; batch classifier loss: 0.300182; batch adversarial loss: 0.483540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348867; batch adversarial loss: 0.407925\n",
      "epoch 12; iter: 200; batch classifier loss: 0.354903; batch adversarial loss: 0.324046\n",
      "epoch 12; iter: 400; batch classifier loss: 0.273428; batch adversarial loss: 0.475420\n",
      "epoch 12; iter: 600; batch classifier loss: 0.523966; batch adversarial loss: 0.400160\n",
      "epoch 13; iter: 0; batch classifier loss: 0.279919; batch adversarial loss: 0.312595\n",
      "epoch 13; iter: 200; batch classifier loss: 0.476759; batch adversarial loss: 0.571414\n",
      "epoch 13; iter: 400; batch classifier loss: 0.349974; batch adversarial loss: 0.374267\n",
      "epoch 13; iter: 600; batch classifier loss: 0.303100; batch adversarial loss: 0.448179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301776; batch adversarial loss: 0.401146\n",
      "epoch 14; iter: 200; batch classifier loss: 0.311552; batch adversarial loss: 0.434514\n",
      "epoch 14; iter: 400; batch classifier loss: 0.304320; batch adversarial loss: 0.599529\n",
      "epoch 14; iter: 600; batch classifier loss: 0.290467; batch adversarial loss: 0.326565\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361548; batch adversarial loss: 0.484860\n",
      "epoch 15; iter: 200; batch classifier loss: 0.373647; batch adversarial loss: 0.432181\n",
      "epoch 15; iter: 400; batch classifier loss: 0.448530; batch adversarial loss: 0.459466\n",
      "epoch 15; iter: 600; batch classifier loss: 0.344887; batch adversarial loss: 0.373233\n",
      "epoch 16; iter: 0; batch classifier loss: 0.321109; batch adversarial loss: 0.409003\n",
      "epoch 16; iter: 200; batch classifier loss: 0.404335; batch adversarial loss: 0.451441\n",
      "epoch 16; iter: 400; batch classifier loss: 0.334206; batch adversarial loss: 0.406780\n",
      "epoch 16; iter: 600; batch classifier loss: 0.344828; batch adversarial loss: 0.357085\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481350; batch adversarial loss: 0.323511\n",
      "epoch 17; iter: 200; batch classifier loss: 0.462530; batch adversarial loss: 0.324170\n",
      "epoch 17; iter: 400; batch classifier loss: 0.348295; batch adversarial loss: 0.350964\n",
      "epoch 17; iter: 600; batch classifier loss: 0.307909; batch adversarial loss: 0.436141\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366639; batch adversarial loss: 0.357548\n",
      "epoch 18; iter: 200; batch classifier loss: 0.440667; batch adversarial loss: 0.470851\n",
      "epoch 18; iter: 400; batch classifier loss: 0.285366; batch adversarial loss: 0.383764\n",
      "epoch 18; iter: 600; batch classifier loss: 0.559193; batch adversarial loss: 0.577617\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408334; batch adversarial loss: 0.401669\n",
      "epoch 19; iter: 200; batch classifier loss: 0.520185; batch adversarial loss: 0.403103\n",
      "epoch 19; iter: 400; batch classifier loss: 0.485826; batch adversarial loss: 0.385948\n",
      "epoch 19; iter: 600; batch classifier loss: 0.328836; batch adversarial loss: 0.373842\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432042; batch adversarial loss: 0.499388\n",
      "epoch 20; iter: 200; batch classifier loss: 0.620144; batch adversarial loss: 0.431681\n",
      "epoch 20; iter: 400; batch classifier loss: 0.450591; batch adversarial loss: 0.402068\n",
      "epoch 20; iter: 600; batch classifier loss: 0.449761; batch adversarial loss: 0.457498\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427074; batch adversarial loss: 0.355394\n",
      "epoch 21; iter: 200; batch classifier loss: 0.478964; batch adversarial loss: 0.424166\n",
      "epoch 21; iter: 400; batch classifier loss: 0.398422; batch adversarial loss: 0.433092\n",
      "epoch 21; iter: 600; batch classifier loss: 0.321341; batch adversarial loss: 0.294143\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483428; batch adversarial loss: 0.352270\n",
      "epoch 22; iter: 200; batch classifier loss: 0.557525; batch adversarial loss: 0.461618\n",
      "epoch 22; iter: 400; batch classifier loss: 0.403369; batch adversarial loss: 0.519858\n",
      "epoch 22; iter: 600; batch classifier loss: 0.444326; batch adversarial loss: 0.427647\n",
      "epoch 23; iter: 0; batch classifier loss: 0.323262; batch adversarial loss: 0.407359\n",
      "epoch 23; iter: 200; batch classifier loss: 0.378012; batch adversarial loss: 0.463543\n",
      "epoch 23; iter: 400; batch classifier loss: 0.555599; batch adversarial loss: 0.322983\n",
      "epoch 23; iter: 600; batch classifier loss: 0.707716; batch adversarial loss: 0.357948\n",
      "epoch 24; iter: 0; batch classifier loss: 0.554815; batch adversarial loss: 0.346140\n",
      "epoch 24; iter: 200; batch classifier loss: 0.327642; batch adversarial loss: 0.436829\n",
      "epoch 24; iter: 400; batch classifier loss: 0.375226; batch adversarial loss: 0.320839\n",
      "epoch 24; iter: 600; batch classifier loss: 0.606661; batch adversarial loss: 0.454999\n",
      "epoch 25; iter: 0; batch classifier loss: 0.423396; batch adversarial loss: 0.431517\n",
      "epoch 25; iter: 200; batch classifier loss: 0.480765; batch adversarial loss: 0.320460\n",
      "epoch 25; iter: 400; batch classifier loss: 0.338654; batch adversarial loss: 0.378718\n",
      "epoch 25; iter: 600; batch classifier loss: 0.523811; batch adversarial loss: 0.406319\n",
      "epoch 26; iter: 0; batch classifier loss: 0.357043; batch adversarial loss: 0.321174\n",
      "epoch 26; iter: 200; batch classifier loss: 0.567062; batch adversarial loss: 0.466275\n",
      "epoch 26; iter: 400; batch classifier loss: 0.636446; batch adversarial loss: 0.294632\n",
      "epoch 26; iter: 600; batch classifier loss: 0.533072; batch adversarial loss: 0.436024\n",
      "epoch 27; iter: 0; batch classifier loss: 0.626703; batch adversarial loss: 0.427966\n",
      "epoch 27; iter: 200; batch classifier loss: 0.436689; batch adversarial loss: 0.266169\n",
      "epoch 27; iter: 400; batch classifier loss: 0.332605; batch adversarial loss: 0.462930\n",
      "epoch 27; iter: 600; batch classifier loss: 0.641199; batch adversarial loss: 0.459924\n",
      "epoch 28; iter: 0; batch classifier loss: 0.548375; batch adversarial loss: 0.435817\n",
      "epoch 28; iter: 200; batch classifier loss: 0.630332; batch adversarial loss: 0.490056\n",
      "epoch 28; iter: 400; batch classifier loss: 0.665093; batch adversarial loss: 0.457290\n",
      "epoch 28; iter: 600; batch classifier loss: 0.577314; batch adversarial loss: 0.462906\n",
      "epoch 29; iter: 0; batch classifier loss: 0.587133; batch adversarial loss: 0.408361\n",
      "epoch 29; iter: 200; batch classifier loss: 0.517280; batch adversarial loss: 0.542076\n",
      "epoch 29; iter: 400; batch classifier loss: 0.607489; batch adversarial loss: 0.461135\n",
      "epoch 29; iter: 600; batch classifier loss: 0.745015; batch adversarial loss: 0.542324\n",
      "epoch 30; iter: 0; batch classifier loss: 0.347369; batch adversarial loss: 0.436480\n",
      "epoch 30; iter: 200; batch classifier loss: 0.538885; batch adversarial loss: 0.543775\n",
      "epoch 30; iter: 400; batch classifier loss: 0.431061; batch adversarial loss: 0.433767\n",
      "epoch 30; iter: 600; batch classifier loss: 0.331693; batch adversarial loss: 0.380391\n",
      "epoch 31; iter: 0; batch classifier loss: 0.407224; batch adversarial loss: 0.407173\n",
      "epoch 31; iter: 200; batch classifier loss: 0.740939; batch adversarial loss: 0.324622\n",
      "epoch 31; iter: 400; batch classifier loss: 0.434617; batch adversarial loss: 0.496176\n",
      "epoch 31; iter: 600; batch classifier loss: 0.733296; batch adversarial loss: 0.599144\n",
      "epoch 32; iter: 0; batch classifier loss: 0.534009; batch adversarial loss: 0.460685\n",
      "epoch 32; iter: 200; batch classifier loss: 0.385544; batch adversarial loss: 0.350293\n",
      "epoch 32; iter: 400; batch classifier loss: 0.596667; batch adversarial loss: 0.350348\n",
      "epoch 32; iter: 600; batch classifier loss: 0.470985; batch adversarial loss: 0.543333\n",
      "epoch 33; iter: 0; batch classifier loss: 0.475050; batch adversarial loss: 0.462395\n",
      "epoch 33; iter: 200; batch classifier loss: 0.451808; batch adversarial loss: 0.294972\n",
      "epoch 33; iter: 400; batch classifier loss: 0.666569; batch adversarial loss: 0.267665\n",
      "epoch 33; iter: 600; batch classifier loss: 0.524846; batch adversarial loss: 0.377078\n",
      "epoch 34; iter: 0; batch classifier loss: 0.568717; batch adversarial loss: 0.572151\n",
      "epoch 34; iter: 200; batch classifier loss: 0.435750; batch adversarial loss: 0.431868\n",
      "epoch 34; iter: 400; batch classifier loss: 0.413013; batch adversarial loss: 0.544462\n",
      "epoch 34; iter: 600; batch classifier loss: 0.710346; batch adversarial loss: 0.404988\n",
      "epoch 35; iter: 0; batch classifier loss: 0.719801; batch adversarial loss: 0.433067\n",
      "epoch 35; iter: 200; batch classifier loss: 0.480915; batch adversarial loss: 0.351341\n",
      "epoch 35; iter: 400; batch classifier loss: 0.410503; batch adversarial loss: 0.378278\n",
      "epoch 35; iter: 600; batch classifier loss: 0.387835; batch adversarial loss: 0.351804\n",
      "epoch 36; iter: 0; batch classifier loss: 0.536567; batch adversarial loss: 0.434498\n",
      "epoch 36; iter: 200; batch classifier loss: 0.563857; batch adversarial loss: 0.295085\n",
      "epoch 36; iter: 400; batch classifier loss: 0.535434; batch adversarial loss: 0.378228\n",
      "epoch 36; iter: 600; batch classifier loss: 0.416689; batch adversarial loss: 0.543500\n",
      "epoch 37; iter: 0; batch classifier loss: 0.551205; batch adversarial loss: 0.460473\n",
      "epoch 37; iter: 200; batch classifier loss: 0.599941; batch adversarial loss: 0.433262\n",
      "epoch 37; iter: 400; batch classifier loss: 0.667510; batch adversarial loss: 0.295790\n",
      "epoch 37; iter: 600; batch classifier loss: 0.634498; batch adversarial loss: 0.432906\n",
      "epoch 38; iter: 0; batch classifier loss: 0.596851; batch adversarial loss: 0.324014\n",
      "epoch 38; iter: 200; batch classifier loss: 0.689494; batch adversarial loss: 0.268175\n",
      "epoch 38; iter: 400; batch classifier loss: 0.489661; batch adversarial loss: 0.297284\n",
      "epoch 38; iter: 600; batch classifier loss: 0.340712; batch adversarial loss: 0.406083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.617556; batch adversarial loss: 0.463552\n",
      "epoch 39; iter: 200; batch classifier loss: 0.476145; batch adversarial loss: 0.295398\n",
      "epoch 39; iter: 400; batch classifier loss: 0.563450; batch adversarial loss: 0.378033\n",
      "epoch 39; iter: 600; batch classifier loss: 0.543534; batch adversarial loss: 0.406853\n",
      "epoch 40; iter: 0; batch classifier loss: 0.504824; batch adversarial loss: 0.461733\n",
      "epoch 40; iter: 200; batch classifier loss: 0.428966; batch adversarial loss: 0.433789\n",
      "epoch 40; iter: 400; batch classifier loss: 0.468580; batch adversarial loss: 0.268009\n",
      "epoch 40; iter: 600; batch classifier loss: 0.559625; batch adversarial loss: 0.350261\n",
      "epoch 41; iter: 0; batch classifier loss: 0.583889; batch adversarial loss: 0.323926\n",
      "epoch 41; iter: 200; batch classifier loss: 0.695973; batch adversarial loss: 0.434034\n",
      "epoch 41; iter: 400; batch classifier loss: 0.592310; batch adversarial loss: 0.350778\n",
      "epoch 41; iter: 600; batch classifier loss: 0.797072; batch adversarial loss: 0.460677\n",
      "epoch 42; iter: 0; batch classifier loss: 0.626934; batch adversarial loss: 0.460321\n",
      "epoch 42; iter: 200; batch classifier loss: 0.656826; batch adversarial loss: 0.350196\n",
      "epoch 42; iter: 400; batch classifier loss: 0.268265; batch adversarial loss: 0.350565\n",
      "epoch 42; iter: 600; batch classifier loss: 0.649420; batch adversarial loss: 0.461562\n",
      "epoch 43; iter: 0; batch classifier loss: 0.813318; batch adversarial loss: 0.350435\n",
      "epoch 43; iter: 200; batch classifier loss: 0.781859; batch adversarial loss: 0.323528\n",
      "epoch 43; iter: 400; batch classifier loss: 0.481151; batch adversarial loss: 0.434967\n",
      "epoch 43; iter: 600; batch classifier loss: 0.641846; batch adversarial loss: 0.269050\n",
      "epoch 44; iter: 0; batch classifier loss: 0.673624; batch adversarial loss: 0.515164\n",
      "epoch 44; iter: 200; batch classifier loss: 0.496884; batch adversarial loss: 0.407433\n",
      "epoch 44; iter: 400; batch classifier loss: 0.652013; batch adversarial loss: 0.377654\n",
      "epoch 44; iter: 600; batch classifier loss: 0.469601; batch adversarial loss: 0.681239\n",
      "epoch 45; iter: 0; batch classifier loss: 0.602691; batch adversarial loss: 0.433982\n",
      "epoch 45; iter: 200; batch classifier loss: 0.566940; batch adversarial loss: 0.352739\n",
      "epoch 45; iter: 400; batch classifier loss: 0.384515; batch adversarial loss: 0.378812\n",
      "epoch 45; iter: 600; batch classifier loss: 0.934183; batch adversarial loss: 0.460343\n",
      "epoch 46; iter: 0; batch classifier loss: 0.674144; batch adversarial loss: 0.377671\n",
      "epoch 46; iter: 200; batch classifier loss: 0.459373; batch adversarial loss: 0.516399\n",
      "epoch 46; iter: 400; batch classifier loss: 0.535774; batch adversarial loss: 0.296138\n",
      "epoch 46; iter: 600; batch classifier loss: 0.689619; batch adversarial loss: 0.405110\n",
      "epoch 47; iter: 0; batch classifier loss: 0.704591; batch adversarial loss: 0.349900\n",
      "epoch 47; iter: 200; batch classifier loss: 0.810948; batch adversarial loss: 0.377640\n",
      "epoch 47; iter: 400; batch classifier loss: 0.241927; batch adversarial loss: 0.515596\n",
      "epoch 47; iter: 600; batch classifier loss: 0.713619; batch adversarial loss: 0.295100\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442615; batch adversarial loss: 0.350350\n",
      "epoch 48; iter: 200; batch classifier loss: 0.566547; batch adversarial loss: 0.322142\n",
      "epoch 48; iter: 400; batch classifier loss: 0.962775; batch adversarial loss: 0.377814\n",
      "epoch 48; iter: 600; batch classifier loss: 0.726892; batch adversarial loss: 0.459926\n",
      "epoch 49; iter: 0; batch classifier loss: 0.614533; batch adversarial loss: 0.322884\n",
      "epoch 49; iter: 200; batch classifier loss: 0.681040; batch adversarial loss: 0.489326\n",
      "epoch 49; iter: 400; batch classifier loss: 0.653505; batch adversarial loss: 0.515083\n",
      "epoch 49; iter: 600; batch classifier loss: 0.660405; batch adversarial loss: 0.405301\n",
      "epoch 0; iter: 0; batch classifier loss: 2.328508; batch adversarial loss: 0.996373\n",
      "epoch 0; iter: 200; batch classifier loss: 3.619237; batch adversarial loss: 0.840292\n",
      "epoch 0; iter: 400; batch classifier loss: 19.925016; batch adversarial loss: 0.667451\n",
      "epoch 0; iter: 600; batch classifier loss: 9.336100; batch adversarial loss: 0.565484\n",
      "epoch 1; iter: 0; batch classifier loss: 2.735058; batch adversarial loss: 0.548918\n",
      "epoch 1; iter: 200; batch classifier loss: 5.073250; batch adversarial loss: 0.492264\n",
      "epoch 1; iter: 400; batch classifier loss: 7.877790; batch adversarial loss: 0.505327\n",
      "epoch 1; iter: 600; batch classifier loss: 1.871015; batch adversarial loss: 0.465649\n",
      "epoch 2; iter: 0; batch classifier loss: 3.516508; batch adversarial loss: 0.482487\n",
      "epoch 2; iter: 200; batch classifier loss: 3.891838; batch adversarial loss: 0.490628\n",
      "epoch 2; iter: 400; batch classifier loss: 3.728729; batch adversarial loss: 0.410780\n",
      "epoch 2; iter: 600; batch classifier loss: 1.711658; batch adversarial loss: 0.389830\n",
      "epoch 3; iter: 0; batch classifier loss: 0.293992; batch adversarial loss: 0.448675\n",
      "epoch 3; iter: 200; batch classifier loss: 2.050926; batch adversarial loss: 0.364156\n",
      "epoch 3; iter: 400; batch classifier loss: 0.891125; batch adversarial loss: 0.450562\n",
      "epoch 3; iter: 600; batch classifier loss: 0.997801; batch adversarial loss: 0.371499\n",
      "epoch 4; iter: 0; batch classifier loss: 1.194388; batch adversarial loss: 0.529774\n",
      "epoch 4; iter: 200; batch classifier loss: 1.442302; batch adversarial loss: 0.579351\n",
      "epoch 4; iter: 400; batch classifier loss: 0.630871; batch adversarial loss: 0.381915\n",
      "epoch 4; iter: 600; batch classifier loss: 1.064896; batch adversarial loss: 0.405632\n",
      "epoch 5; iter: 0; batch classifier loss: 0.941403; batch adversarial loss: 0.361454\n",
      "epoch 5; iter: 200; batch classifier loss: 1.071626; batch adversarial loss: 0.335134\n",
      "epoch 5; iter: 400; batch classifier loss: 0.749863; batch adversarial loss: 0.345990\n",
      "epoch 5; iter: 600; batch classifier loss: 0.552304; batch adversarial loss: 0.381829\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586110; batch adversarial loss: 0.300874\n",
      "epoch 6; iter: 200; batch classifier loss: 0.468456; batch adversarial loss: 0.399111\n",
      "epoch 6; iter: 400; batch classifier loss: 0.419885; batch adversarial loss: 0.588655\n",
      "epoch 6; iter: 600; batch classifier loss: 0.452175; batch adversarial loss: 0.406064\n",
      "epoch 7; iter: 0; batch classifier loss: 0.725618; batch adversarial loss: 0.280347\n",
      "epoch 7; iter: 200; batch classifier loss: 0.572480; batch adversarial loss: 0.370560\n",
      "epoch 7; iter: 400; batch classifier loss: 0.344538; batch adversarial loss: 0.372350\n",
      "epoch 7; iter: 600; batch classifier loss: 0.478880; batch adversarial loss: 0.486700\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566369; batch adversarial loss: 0.401508\n",
      "epoch 8; iter: 200; batch classifier loss: 0.508728; batch adversarial loss: 0.452273\n",
      "epoch 8; iter: 400; batch classifier loss: 0.507680; batch adversarial loss: 0.419996\n",
      "epoch 8; iter: 600; batch classifier loss: 0.333142; batch adversarial loss: 0.371730\n",
      "epoch 9; iter: 0; batch classifier loss: 0.367374; batch adversarial loss: 0.382976\n",
      "epoch 9; iter: 200; batch classifier loss: 0.418618; batch adversarial loss: 0.380917\n",
      "epoch 9; iter: 400; batch classifier loss: 0.402193; batch adversarial loss: 0.412341\n",
      "epoch 9; iter: 600; batch classifier loss: 0.368560; batch adversarial loss: 0.421818\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369029; batch adversarial loss: 0.490630\n",
      "epoch 10; iter: 200; batch classifier loss: 0.559378; batch adversarial loss: 0.517845\n",
      "epoch 10; iter: 400; batch classifier loss: 0.417370; batch adversarial loss: 0.584720\n",
      "epoch 10; iter: 600; batch classifier loss: 0.418758; batch adversarial loss: 0.428810\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447140; batch adversarial loss: 0.373827\n",
      "epoch 11; iter: 200; batch classifier loss: 0.448523; batch adversarial loss: 0.373735\n",
      "epoch 11; iter: 400; batch classifier loss: 0.354623; batch adversarial loss: 0.501039\n",
      "epoch 11; iter: 600; batch classifier loss: 0.448915; batch adversarial loss: 0.497660\n",
      "epoch 12; iter: 0; batch classifier loss: 0.382533; batch adversarial loss: 0.445067\n",
      "epoch 12; iter: 200; batch classifier loss: 0.359112; batch adversarial loss: 0.597434\n",
      "epoch 12; iter: 400; batch classifier loss: 0.420189; batch adversarial loss: 0.443503\n",
      "epoch 12; iter: 600; batch classifier loss: 0.260214; batch adversarial loss: 0.379919\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261947; batch adversarial loss: 0.514417\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396334; batch adversarial loss: 0.438425\n",
      "epoch 13; iter: 400; batch classifier loss: 0.388252; batch adversarial loss: 0.416862\n",
      "epoch 13; iter: 600; batch classifier loss: 0.330949; batch adversarial loss: 0.343805\n",
      "epoch 14; iter: 0; batch classifier loss: 0.315382; batch adversarial loss: 0.350957\n",
      "epoch 14; iter: 200; batch classifier loss: 0.373602; batch adversarial loss: 0.395629\n",
      "epoch 14; iter: 400; batch classifier loss: 0.506499; batch adversarial loss: 0.365505\n",
      "epoch 14; iter: 600; batch classifier loss: 0.371350; batch adversarial loss: 0.492956\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338010; batch adversarial loss: 0.338540\n",
      "epoch 15; iter: 200; batch classifier loss: 0.285666; batch adversarial loss: 0.357510\n",
      "epoch 15; iter: 400; batch classifier loss: 0.450120; batch adversarial loss: 0.346588\n",
      "epoch 15; iter: 600; batch classifier loss: 0.439263; batch adversarial loss: 0.423780\n",
      "epoch 16; iter: 0; batch classifier loss: 0.366060; batch adversarial loss: 0.320948\n",
      "epoch 16; iter: 200; batch classifier loss: 0.322652; batch adversarial loss: 0.402918\n",
      "epoch 16; iter: 400; batch classifier loss: 0.310027; batch adversarial loss: 0.490595\n",
      "epoch 16; iter: 600; batch classifier loss: 0.453326; batch adversarial loss: 0.268890\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328050; batch adversarial loss: 0.353896\n",
      "epoch 17; iter: 200; batch classifier loss: 0.324219; batch adversarial loss: 0.496073\n",
      "epoch 17; iter: 400; batch classifier loss: 0.464643; batch adversarial loss: 0.461792\n",
      "epoch 17; iter: 600; batch classifier loss: 0.379120; batch adversarial loss: 0.539479\n",
      "epoch 18; iter: 0; batch classifier loss: 0.427687; batch adversarial loss: 0.398323\n",
      "epoch 18; iter: 200; batch classifier loss: 0.396215; batch adversarial loss: 0.340439\n",
      "epoch 18; iter: 400; batch classifier loss: 0.387656; batch adversarial loss: 0.368545\n",
      "epoch 18; iter: 600; batch classifier loss: 0.303883; batch adversarial loss: 0.399779\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262324; batch adversarial loss: 0.263193\n",
      "epoch 19; iter: 200; batch classifier loss: 0.536926; batch adversarial loss: 0.397694\n",
      "epoch 19; iter: 400; batch classifier loss: 0.341474; batch adversarial loss: 0.451067\n",
      "epoch 19; iter: 600; batch classifier loss: 0.349543; batch adversarial loss: 0.429655\n",
      "epoch 20; iter: 0; batch classifier loss: 0.281591; batch adversarial loss: 0.378036\n",
      "epoch 20; iter: 200; batch classifier loss: 0.281077; batch adversarial loss: 0.400474\n",
      "epoch 20; iter: 400; batch classifier loss: 0.407574; batch adversarial loss: 0.423453\n",
      "epoch 20; iter: 600; batch classifier loss: 0.317304; batch adversarial loss: 0.558427\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478979; batch adversarial loss: 0.560582\n",
      "epoch 21; iter: 200; batch classifier loss: 0.386360; batch adversarial loss: 0.379053\n",
      "epoch 21; iter: 400; batch classifier loss: 0.434526; batch adversarial loss: 0.454929\n",
      "epoch 21; iter: 600; batch classifier loss: 0.335548; batch adversarial loss: 0.353892\n",
      "epoch 22; iter: 0; batch classifier loss: 0.623461; batch adversarial loss: 0.346876\n",
      "epoch 22; iter: 200; batch classifier loss: 0.399371; batch adversarial loss: 0.412185\n",
      "epoch 22; iter: 400; batch classifier loss: 0.450074; batch adversarial loss: 0.484627\n",
      "epoch 22; iter: 600; batch classifier loss: 0.377274; batch adversarial loss: 0.408666\n",
      "epoch 23; iter: 0; batch classifier loss: 0.415712; batch adversarial loss: 0.546300\n",
      "epoch 23; iter: 200; batch classifier loss: 0.370398; batch adversarial loss: 0.440607\n",
      "epoch 23; iter: 400; batch classifier loss: 0.294248; batch adversarial loss: 0.495190\n",
      "epoch 23; iter: 600; batch classifier loss: 0.463772; batch adversarial loss: 0.321592\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435940; batch adversarial loss: 0.417122\n",
      "epoch 24; iter: 200; batch classifier loss: 0.479984; batch adversarial loss: 0.535465\n",
      "epoch 24; iter: 400; batch classifier loss: 0.442498; batch adversarial loss: 0.399841\n",
      "epoch 24; iter: 600; batch classifier loss: 0.346562; batch adversarial loss: 0.294736\n",
      "epoch 25; iter: 0; batch classifier loss: 0.508283; batch adversarial loss: 0.327171\n",
      "epoch 25; iter: 200; batch classifier loss: 0.408247; batch adversarial loss: 0.454602\n",
      "epoch 25; iter: 400; batch classifier loss: 0.351109; batch adversarial loss: 0.577439\n",
      "epoch 25; iter: 600; batch classifier loss: 0.425130; batch adversarial loss: 0.489002\n",
      "epoch 26; iter: 0; batch classifier loss: 0.358019; batch adversarial loss: 0.491226\n",
      "epoch 26; iter: 200; batch classifier loss: 0.364470; batch adversarial loss: 0.540135\n",
      "epoch 26; iter: 400; batch classifier loss: 0.391159; batch adversarial loss: 0.433380\n",
      "epoch 26; iter: 600; batch classifier loss: 0.457535; batch adversarial loss: 0.276920\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284274; batch adversarial loss: 0.413439\n",
      "epoch 27; iter: 200; batch classifier loss: 0.414051; batch adversarial loss: 0.264520\n",
      "epoch 27; iter: 400; batch classifier loss: 0.346517; batch adversarial loss: 0.294060\n",
      "epoch 27; iter: 600; batch classifier loss: 0.399754; batch adversarial loss: 0.382968\n",
      "epoch 28; iter: 0; batch classifier loss: 0.444580; batch adversarial loss: 0.324187\n",
      "epoch 28; iter: 200; batch classifier loss: 0.379595; batch adversarial loss: 0.601438\n",
      "epoch 28; iter: 400; batch classifier loss: 0.498369; batch adversarial loss: 0.398997\n",
      "epoch 28; iter: 600; batch classifier loss: 0.380659; batch adversarial loss: 0.298240\n",
      "epoch 29; iter: 0; batch classifier loss: 0.341283; batch adversarial loss: 0.374144\n",
      "epoch 29; iter: 200; batch classifier loss: 0.360120; batch adversarial loss: 0.463312\n",
      "epoch 29; iter: 400; batch classifier loss: 0.366259; batch adversarial loss: 0.464013\n",
      "epoch 29; iter: 600; batch classifier loss: 0.374834; batch adversarial loss: 0.536722\n",
      "epoch 30; iter: 0; batch classifier loss: 0.381114; batch adversarial loss: 0.466188\n",
      "epoch 30; iter: 200; batch classifier loss: 0.429349; batch adversarial loss: 0.407658\n",
      "epoch 30; iter: 400; batch classifier loss: 0.589175; batch adversarial loss: 0.347651\n",
      "epoch 30; iter: 600; batch classifier loss: 0.357666; batch adversarial loss: 0.482937\n",
      "epoch 31; iter: 0; batch classifier loss: 0.511977; batch adversarial loss: 0.459879\n",
      "epoch 31; iter: 200; batch classifier loss: 0.462574; batch adversarial loss: 0.378461\n",
      "epoch 31; iter: 400; batch classifier loss: 0.390800; batch adversarial loss: 0.429230\n",
      "epoch 31; iter: 600; batch classifier loss: 0.510787; batch adversarial loss: 0.372299\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473198; batch adversarial loss: 0.347662\n",
      "epoch 32; iter: 200; batch classifier loss: 0.415863; batch adversarial loss: 0.327079\n",
      "epoch 32; iter: 400; batch classifier loss: 0.408929; batch adversarial loss: 0.485776\n",
      "epoch 32; iter: 600; batch classifier loss: 0.324533; batch adversarial loss: 0.327732\n",
      "epoch 33; iter: 0; batch classifier loss: 0.538812; batch adversarial loss: 0.436382\n",
      "epoch 33; iter: 200; batch classifier loss: 0.541971; batch adversarial loss: 0.379678\n",
      "epoch 33; iter: 400; batch classifier loss: 0.698151; batch adversarial loss: 0.316134\n",
      "epoch 33; iter: 600; batch classifier loss: 0.599602; batch adversarial loss: 0.404018\n",
      "epoch 34; iter: 0; batch classifier loss: 0.552510; batch adversarial loss: 0.463944\n",
      "epoch 34; iter: 200; batch classifier loss: 0.497370; batch adversarial loss: 0.521558\n",
      "epoch 34; iter: 400; batch classifier loss: 0.395546; batch adversarial loss: 0.325154\n",
      "epoch 34; iter: 600; batch classifier loss: 0.675117; batch adversarial loss: 0.431882\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507680; batch adversarial loss: 0.542291\n",
      "epoch 35; iter: 200; batch classifier loss: 0.648402; batch adversarial loss: 0.438275\n",
      "epoch 35; iter: 400; batch classifier loss: 0.245789; batch adversarial loss: 0.595139\n",
      "epoch 35; iter: 600; batch classifier loss: 0.569341; batch adversarial loss: 0.658291\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418089; batch adversarial loss: 0.484341\n",
      "epoch 36; iter: 200; batch classifier loss: 0.374518; batch adversarial loss: 0.408382\n",
      "epoch 36; iter: 400; batch classifier loss: 0.429952; batch adversarial loss: 0.524239\n",
      "epoch 36; iter: 600; batch classifier loss: 0.738208; batch adversarial loss: 0.323262\n",
      "epoch 37; iter: 0; batch classifier loss: 0.572376; batch adversarial loss: 0.323854\n",
      "epoch 37; iter: 200; batch classifier loss: 0.503577; batch adversarial loss: 0.483839\n",
      "epoch 37; iter: 400; batch classifier loss: 0.549397; batch adversarial loss: 0.432464\n",
      "epoch 37; iter: 600; batch classifier loss: 0.428416; batch adversarial loss: 0.494762\n",
      "epoch 38; iter: 0; batch classifier loss: 0.582794; batch adversarial loss: 0.405170\n",
      "epoch 38; iter: 200; batch classifier loss: 0.453563; batch adversarial loss: 0.404575\n",
      "epoch 38; iter: 400; batch classifier loss: 0.534721; batch adversarial loss: 0.538334\n",
      "epoch 38; iter: 600; batch classifier loss: 0.378559; batch adversarial loss: 0.457375\n",
      "epoch 39; iter: 0; batch classifier loss: 0.492803; batch adversarial loss: 0.405880\n",
      "epoch 39; iter: 200; batch classifier loss: 0.357810; batch adversarial loss: 0.290474\n",
      "epoch 39; iter: 400; batch classifier loss: 0.550540; batch adversarial loss: 0.483120\n",
      "epoch 39; iter: 600; batch classifier loss: 0.452648; batch adversarial loss: 0.406627\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477666; batch adversarial loss: 0.402451\n",
      "epoch 40; iter: 200; batch classifier loss: 0.493443; batch adversarial loss: 0.431417\n",
      "epoch 40; iter: 400; batch classifier loss: 0.401464; batch adversarial loss: 0.438434\n",
      "epoch 40; iter: 600; batch classifier loss: 0.567449; batch adversarial loss: 0.377216\n",
      "epoch 41; iter: 0; batch classifier loss: 0.756348; batch adversarial loss: 0.483754\n",
      "epoch 41; iter: 200; batch classifier loss: 0.380465; batch adversarial loss: 0.412459\n",
      "epoch 41; iter: 400; batch classifier loss: 0.483127; batch adversarial loss: 0.429333\n",
      "epoch 41; iter: 600; batch classifier loss: 0.576212; batch adversarial loss: 0.483245\n",
      "epoch 42; iter: 0; batch classifier loss: 0.564864; batch adversarial loss: 0.353966\n",
      "epoch 42; iter: 200; batch classifier loss: 0.390629; batch adversarial loss: 0.399435\n",
      "epoch 42; iter: 400; batch classifier loss: 0.421791; batch adversarial loss: 0.462724\n",
      "epoch 42; iter: 600; batch classifier loss: 0.440309; batch adversarial loss: 0.434522\n",
      "epoch 43; iter: 0; batch classifier loss: 0.471030; batch adversarial loss: 0.644531\n",
      "epoch 43; iter: 200; batch classifier loss: 0.676584; batch adversarial loss: 0.349112\n",
      "epoch 43; iter: 400; batch classifier loss: 0.332770; batch adversarial loss: 0.401847\n",
      "epoch 43; iter: 600; batch classifier loss: 0.491728; batch adversarial loss: 0.512511\n",
      "epoch 44; iter: 0; batch classifier loss: 0.434209; batch adversarial loss: 0.402380\n",
      "epoch 44; iter: 200; batch classifier loss: 0.302339; batch adversarial loss: 0.464070\n",
      "epoch 44; iter: 400; batch classifier loss: 0.620226; batch adversarial loss: 0.351575\n",
      "epoch 44; iter: 600; batch classifier loss: 0.893048; batch adversarial loss: 0.492392\n",
      "epoch 45; iter: 0; batch classifier loss: 0.440532; batch adversarial loss: 0.406988\n",
      "epoch 45; iter: 200; batch classifier loss: 0.559174; batch adversarial loss: 0.407494\n",
      "epoch 45; iter: 400; batch classifier loss: 0.473574; batch adversarial loss: 0.348142\n",
      "epoch 45; iter: 600; batch classifier loss: 0.569003; batch adversarial loss: 0.428948\n",
      "epoch 46; iter: 0; batch classifier loss: 0.772771; batch adversarial loss: 0.413414\n",
      "epoch 46; iter: 200; batch classifier loss: 0.546161; batch adversarial loss: 0.516598\n",
      "epoch 46; iter: 400; batch classifier loss: 0.677373; batch adversarial loss: 0.376987\n",
      "epoch 46; iter: 600; batch classifier loss: 0.602010; batch adversarial loss: 0.488181\n",
      "epoch 47; iter: 0; batch classifier loss: 0.408372; batch adversarial loss: 0.458121\n",
      "epoch 47; iter: 200; batch classifier loss: 0.611200; batch adversarial loss: 0.410719\n",
      "epoch 47; iter: 400; batch classifier loss: 0.441366; batch adversarial loss: 0.520565\n",
      "epoch 47; iter: 600; batch classifier loss: 0.803067; batch adversarial loss: 0.291673\n",
      "epoch 48; iter: 0; batch classifier loss: 0.751593; batch adversarial loss: 0.403511\n",
      "epoch 48; iter: 200; batch classifier loss: 0.757716; batch adversarial loss: 0.400550\n",
      "epoch 48; iter: 400; batch classifier loss: 0.606023; batch adversarial loss: 0.350530\n",
      "epoch 48; iter: 600; batch classifier loss: 0.796798; batch adversarial loss: 0.325038\n",
      "epoch 49; iter: 0; batch classifier loss: 0.589221; batch adversarial loss: 0.293339\n",
      "epoch 49; iter: 200; batch classifier loss: 0.725028; batch adversarial loss: 0.509501\n",
      "epoch 49; iter: 400; batch classifier loss: 0.906930; batch adversarial loss: 0.483905\n",
      "epoch 49; iter: 600; batch classifier loss: 0.435233; batch adversarial loss: 0.484378\n",
      "epoch 0; iter: 0; batch classifier loss: 5.510714; batch adversarial loss: 0.739900\n",
      "epoch 0; iter: 200; batch classifier loss: 4.419799; batch adversarial loss: 0.755083\n",
      "epoch 0; iter: 400; batch classifier loss: 9.162465; batch adversarial loss: 0.645467\n",
      "epoch 0; iter: 600; batch classifier loss: 3.281739; batch adversarial loss: 0.572963\n",
      "epoch 1; iter: 0; batch classifier loss: 5.889622; batch adversarial loss: 0.636601\n",
      "epoch 1; iter: 200; batch classifier loss: 10.358020; batch adversarial loss: 0.526486\n",
      "epoch 1; iter: 400; batch classifier loss: 4.925677; batch adversarial loss: 0.508524\n",
      "epoch 1; iter: 600; batch classifier loss: 0.493508; batch adversarial loss: 0.448896\n",
      "epoch 2; iter: 0; batch classifier loss: 5.077965; batch adversarial loss: 0.498089\n",
      "epoch 2; iter: 200; batch classifier loss: 4.301767; batch adversarial loss: 0.402134\n",
      "epoch 2; iter: 400; batch classifier loss: 1.409425; batch adversarial loss: 0.473908\n",
      "epoch 2; iter: 600; batch classifier loss: 2.371542; batch adversarial loss: 0.363364\n",
      "epoch 3; iter: 0; batch classifier loss: 11.327248; batch adversarial loss: 0.582169\n",
      "epoch 3; iter: 200; batch classifier loss: 0.330650; batch adversarial loss: 0.411653\n",
      "epoch 3; iter: 400; batch classifier loss: 2.010568; batch adversarial loss: 0.505599\n",
      "epoch 3; iter: 600; batch classifier loss: 1.067614; batch adversarial loss: 0.366247\n",
      "epoch 4; iter: 0; batch classifier loss: 1.086650; batch adversarial loss: 0.380863\n",
      "epoch 4; iter: 200; batch classifier loss: 0.861633; batch adversarial loss: 0.466889\n",
      "epoch 4; iter: 400; batch classifier loss: 1.721214; batch adversarial loss: 0.395212\n",
      "epoch 4; iter: 600; batch classifier loss: 0.721342; batch adversarial loss: 0.452144\n",
      "epoch 5; iter: 0; batch classifier loss: 1.002080; batch adversarial loss: 0.425378\n",
      "epoch 5; iter: 200; batch classifier loss: 0.418538; batch adversarial loss: 0.413588\n",
      "epoch 5; iter: 400; batch classifier loss: 0.351083; batch adversarial loss: 0.285927\n",
      "epoch 5; iter: 600; batch classifier loss: 0.509372; batch adversarial loss: 0.414694\n",
      "epoch 6; iter: 0; batch classifier loss: 0.489945; batch adversarial loss: 0.468657\n",
      "epoch 6; iter: 200; batch classifier loss: 0.427357; batch adversarial loss: 0.454708\n",
      "epoch 6; iter: 400; batch classifier loss: 0.613861; batch adversarial loss: 0.249710\n",
      "epoch 6; iter: 600; batch classifier loss: 0.525123; batch adversarial loss: 0.439773\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420752; batch adversarial loss: 0.348435\n",
      "epoch 7; iter: 200; batch classifier loss: 0.448908; batch adversarial loss: 0.382389\n",
      "epoch 7; iter: 400; batch classifier loss: 0.455062; batch adversarial loss: 0.484627\n",
      "epoch 7; iter: 600; batch classifier loss: 0.321727; batch adversarial loss: 0.364328\n",
      "epoch 8; iter: 0; batch classifier loss: 0.444756; batch adversarial loss: 0.506422\n",
      "epoch 8; iter: 200; batch classifier loss: 0.328249; batch adversarial loss: 0.348509\n",
      "epoch 8; iter: 400; batch classifier loss: 0.311908; batch adversarial loss: 0.483120\n",
      "epoch 8; iter: 600; batch classifier loss: 0.358378; batch adversarial loss: 0.454806\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455121; batch adversarial loss: 0.472608\n",
      "epoch 9; iter: 200; batch classifier loss: 0.487875; batch adversarial loss: 0.486762\n",
      "epoch 9; iter: 400; batch classifier loss: 0.327494; batch adversarial loss: 0.420070\n",
      "epoch 9; iter: 600; batch classifier loss: 0.413924; batch adversarial loss: 0.393510\n",
      "epoch 10; iter: 0; batch classifier loss: 0.270906; batch adversarial loss: 0.371742\n",
      "epoch 10; iter: 200; batch classifier loss: 0.339222; batch adversarial loss: 0.351735\n",
      "epoch 10; iter: 400; batch classifier loss: 0.430327; batch adversarial loss: 0.286504\n",
      "epoch 10; iter: 600; batch classifier loss: 0.483981; batch adversarial loss: 0.422538\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406812; batch adversarial loss: 0.279652\n",
      "epoch 11; iter: 200; batch classifier loss: 0.409919; batch adversarial loss: 0.365287\n",
      "epoch 11; iter: 400; batch classifier loss: 0.291398; batch adversarial loss: 0.545913\n",
      "epoch 11; iter: 600; batch classifier loss: 0.415243; batch adversarial loss: 0.364149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.473689; batch adversarial loss: 0.352973\n",
      "epoch 12; iter: 200; batch classifier loss: 0.343659; batch adversarial loss: 0.371678\n",
      "epoch 12; iter: 400; batch classifier loss: 0.219919; batch adversarial loss: 0.381922\n",
      "epoch 12; iter: 600; batch classifier loss: 0.477890; batch adversarial loss: 0.340394\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347540; batch adversarial loss: 0.355683\n",
      "epoch 13; iter: 200; batch classifier loss: 0.335655; batch adversarial loss: 0.433472\n",
      "epoch 13; iter: 400; batch classifier loss: 0.536682; batch adversarial loss: 0.373683\n",
      "epoch 13; iter: 600; batch classifier loss: 0.388701; batch adversarial loss: 0.273744\n",
      "epoch 14; iter: 0; batch classifier loss: 0.363235; batch adversarial loss: 0.482342\n",
      "epoch 14; iter: 200; batch classifier loss: 0.285356; batch adversarial loss: 0.339154\n",
      "epoch 14; iter: 400; batch classifier loss: 0.283617; batch adversarial loss: 0.279605\n",
      "epoch 14; iter: 600; batch classifier loss: 0.431771; batch adversarial loss: 0.429412\n",
      "epoch 15; iter: 0; batch classifier loss: 0.283607; batch adversarial loss: 0.398766\n",
      "epoch 15; iter: 200; batch classifier loss: 0.326692; batch adversarial loss: 0.408600\n",
      "epoch 15; iter: 400; batch classifier loss: 0.340653; batch adversarial loss: 0.477039\n",
      "epoch 15; iter: 600; batch classifier loss: 0.468238; batch adversarial loss: 0.442626\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306117; batch adversarial loss: 0.524359\n",
      "epoch 16; iter: 200; batch classifier loss: 0.368969; batch adversarial loss: 0.260758\n",
      "epoch 16; iter: 400; batch classifier loss: 0.295360; batch adversarial loss: 0.364153\n",
      "epoch 16; iter: 600; batch classifier loss: 0.390128; batch adversarial loss: 0.479736\n",
      "epoch 17; iter: 0; batch classifier loss: 0.260767; batch adversarial loss: 0.296603\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349677; batch adversarial loss: 0.241483\n",
      "epoch 17; iter: 400; batch classifier loss: 0.384056; batch adversarial loss: 0.399325\n",
      "epoch 17; iter: 600; batch classifier loss: 0.306101; batch adversarial loss: 0.408023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.463610; batch adversarial loss: 0.431952\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341133; batch adversarial loss: 0.417557\n",
      "epoch 18; iter: 400; batch classifier loss: 0.381246; batch adversarial loss: 0.483058\n",
      "epoch 18; iter: 600; batch classifier loss: 0.448793; batch adversarial loss: 0.406660\n",
      "epoch 19; iter: 0; batch classifier loss: 0.326820; batch adversarial loss: 0.402724\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346680; batch adversarial loss: 0.410534\n",
      "epoch 19; iter: 400; batch classifier loss: 0.334786; batch adversarial loss: 0.287643\n",
      "epoch 19; iter: 600; batch classifier loss: 0.353588; batch adversarial loss: 0.465966\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337513; batch adversarial loss: 0.353837\n",
      "epoch 20; iter: 200; batch classifier loss: 0.244605; batch adversarial loss: 0.481565\n",
      "epoch 20; iter: 400; batch classifier loss: 0.397207; batch adversarial loss: 0.325893\n",
      "epoch 20; iter: 600; batch classifier loss: 0.443187; batch adversarial loss: 0.465380\n",
      "epoch 21; iter: 0; batch classifier loss: 0.344564; batch adversarial loss: 0.461507\n",
      "epoch 21; iter: 200; batch classifier loss: 0.353437; batch adversarial loss: 0.330858\n",
      "epoch 21; iter: 400; batch classifier loss: 0.373215; batch adversarial loss: 0.430133\n",
      "epoch 21; iter: 600; batch classifier loss: 0.410840; batch adversarial loss: 0.486725\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582967; batch adversarial loss: 0.354869\n",
      "epoch 22; iter: 200; batch classifier loss: 0.408404; batch adversarial loss: 0.403601\n",
      "epoch 22; iter: 400; batch classifier loss: 0.448234; batch adversarial loss: 0.404192\n",
      "epoch 22; iter: 600; batch classifier loss: 0.349004; batch adversarial loss: 0.292326\n",
      "epoch 23; iter: 0; batch classifier loss: 0.328174; batch adversarial loss: 0.373362\n",
      "epoch 23; iter: 200; batch classifier loss: 0.393634; batch adversarial loss: 0.438501\n",
      "epoch 23; iter: 400; batch classifier loss: 0.492291; batch adversarial loss: 0.465660\n",
      "epoch 23; iter: 600; batch classifier loss: 0.281350; batch adversarial loss: 0.404005\n",
      "epoch 24; iter: 0; batch classifier loss: 0.298611; batch adversarial loss: 0.374808\n",
      "epoch 24; iter: 200; batch classifier loss: 0.301530; batch adversarial loss: 0.393665\n",
      "epoch 24; iter: 400; batch classifier loss: 0.283537; batch adversarial loss: 0.371639\n",
      "epoch 24; iter: 600; batch classifier loss: 0.309493; batch adversarial loss: 0.455819\n",
      "epoch 25; iter: 0; batch classifier loss: 0.237985; batch adversarial loss: 0.462185\n",
      "epoch 25; iter: 200; batch classifier loss: 0.452915; batch adversarial loss: 0.295949\n",
      "epoch 25; iter: 400; batch classifier loss: 0.298721; batch adversarial loss: 0.330638\n",
      "epoch 25; iter: 600; batch classifier loss: 0.266867; batch adversarial loss: 0.410195\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346119; batch adversarial loss: 0.459469\n",
      "epoch 26; iter: 200; batch classifier loss: 0.289719; batch adversarial loss: 0.319376\n",
      "epoch 26; iter: 400; batch classifier loss: 0.265579; batch adversarial loss: 0.294320\n",
      "epoch 26; iter: 600; batch classifier loss: 0.481406; batch adversarial loss: 0.477899\n",
      "epoch 27; iter: 0; batch classifier loss: 0.398133; batch adversarial loss: 0.516880\n",
      "epoch 27; iter: 200; batch classifier loss: 0.336572; batch adversarial loss: 0.376208\n",
      "epoch 27; iter: 400; batch classifier loss: 0.548068; batch adversarial loss: 0.368459\n",
      "epoch 27; iter: 600; batch classifier loss: 0.355031; batch adversarial loss: 0.462162\n",
      "epoch 28; iter: 0; batch classifier loss: 0.340115; batch adversarial loss: 0.430432\n",
      "epoch 28; iter: 200; batch classifier loss: 0.520875; batch adversarial loss: 0.379141\n",
      "epoch 28; iter: 400; batch classifier loss: 0.317145; batch adversarial loss: 0.467833\n",
      "epoch 28; iter: 600; batch classifier loss: 0.251434; batch adversarial loss: 0.412052\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235867; batch adversarial loss: 0.437032\n",
      "epoch 29; iter: 200; batch classifier loss: 0.443668; batch adversarial loss: 0.502169\n",
      "epoch 29; iter: 400; batch classifier loss: 0.384362; batch adversarial loss: 0.385261\n",
      "epoch 29; iter: 600; batch classifier loss: 0.295658; batch adversarial loss: 0.306489\n",
      "epoch 30; iter: 0; batch classifier loss: 0.307649; batch adversarial loss: 0.499408\n",
      "epoch 30; iter: 200; batch classifier loss: 0.332228; batch adversarial loss: 0.329814\n",
      "epoch 30; iter: 400; batch classifier loss: 0.293037; batch adversarial loss: 0.567814\n",
      "epoch 30; iter: 600; batch classifier loss: 0.332413; batch adversarial loss: 0.454139\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430458; batch adversarial loss: 0.481155\n",
      "epoch 31; iter: 200; batch classifier loss: 0.499991; batch adversarial loss: 0.347422\n",
      "epoch 31; iter: 400; batch classifier loss: 0.262765; batch adversarial loss: 0.386448\n",
      "epoch 31; iter: 600; batch classifier loss: 0.253810; batch adversarial loss: 0.461581\n",
      "epoch 32; iter: 0; batch classifier loss: 0.357054; batch adversarial loss: 0.606827\n",
      "epoch 32; iter: 200; batch classifier loss: 0.436729; batch adversarial loss: 0.508225\n",
      "epoch 32; iter: 400; batch classifier loss: 0.360698; batch adversarial loss: 0.401190\n",
      "epoch 32; iter: 600; batch classifier loss: 0.374517; batch adversarial loss: 0.481178\n",
      "epoch 33; iter: 0; batch classifier loss: 0.378217; batch adversarial loss: 0.374952\n",
      "epoch 33; iter: 200; batch classifier loss: 0.374001; batch adversarial loss: 0.273007\n",
      "epoch 33; iter: 400; batch classifier loss: 0.368818; batch adversarial loss: 0.493939\n",
      "epoch 33; iter: 600; batch classifier loss: 0.389926; batch adversarial loss: 0.419953\n",
      "epoch 34; iter: 0; batch classifier loss: 0.397391; batch adversarial loss: 0.408141\n",
      "epoch 34; iter: 200; batch classifier loss: 0.270570; batch adversarial loss: 0.403064\n",
      "epoch 34; iter: 400; batch classifier loss: 0.378298; batch adversarial loss: 0.407207\n",
      "epoch 34; iter: 600; batch classifier loss: 0.372406; batch adversarial loss: 0.435919\n",
      "epoch 35; iter: 0; batch classifier loss: 0.262226; batch adversarial loss: 0.436130\n",
      "epoch 35; iter: 200; batch classifier loss: 0.390671; batch adversarial loss: 0.465283\n",
      "epoch 35; iter: 400; batch classifier loss: 0.401086; batch adversarial loss: 0.547170\n",
      "epoch 35; iter: 600; batch classifier loss: 0.275763; batch adversarial loss: 0.299056\n",
      "epoch 36; iter: 0; batch classifier loss: 0.471440; batch adversarial loss: 0.566113\n",
      "epoch 36; iter: 200; batch classifier loss: 0.269392; batch adversarial loss: 0.523272\n",
      "epoch 36; iter: 400; batch classifier loss: 0.358936; batch adversarial loss: 0.455886\n",
      "epoch 36; iter: 600; batch classifier loss: 0.440676; batch adversarial loss: 0.294217\n",
      "epoch 37; iter: 0; batch classifier loss: 0.293929; batch adversarial loss: 0.411423\n",
      "epoch 37; iter: 200; batch classifier loss: 0.332262; batch adversarial loss: 0.349962\n",
      "epoch 37; iter: 400; batch classifier loss: 0.298627; batch adversarial loss: 0.295208\n",
      "epoch 37; iter: 600; batch classifier loss: 0.334419; batch adversarial loss: 0.349122\n",
      "epoch 38; iter: 0; batch classifier loss: 0.352067; batch adversarial loss: 0.493015\n",
      "epoch 38; iter: 200; batch classifier loss: 0.382404; batch adversarial loss: 0.461135\n",
      "epoch 38; iter: 400; batch classifier loss: 0.361728; batch adversarial loss: 0.379504\n",
      "epoch 38; iter: 600; batch classifier loss: 0.392489; batch adversarial loss: 0.519509\n",
      "epoch 39; iter: 0; batch classifier loss: 0.270163; batch adversarial loss: 0.515100\n",
      "epoch 39; iter: 200; batch classifier loss: 0.355033; batch adversarial loss: 0.487738\n",
      "epoch 39; iter: 400; batch classifier loss: 0.448692; batch adversarial loss: 0.378106\n",
      "epoch 39; iter: 600; batch classifier loss: 0.407145; batch adversarial loss: 0.486077\n",
      "epoch 40; iter: 0; batch classifier loss: 0.588256; batch adversarial loss: 0.458591\n",
      "epoch 40; iter: 200; batch classifier loss: 0.306028; batch adversarial loss: 0.488979\n",
      "epoch 40; iter: 400; batch classifier loss: 0.379193; batch adversarial loss: 0.484027\n",
      "epoch 40; iter: 600; batch classifier loss: 0.362875; batch adversarial loss: 0.267420\n",
      "epoch 41; iter: 0; batch classifier loss: 0.316281; batch adversarial loss: 0.303390\n",
      "epoch 41; iter: 200; batch classifier loss: 0.208340; batch adversarial loss: 0.410007\n",
      "epoch 41; iter: 400; batch classifier loss: 0.517372; batch adversarial loss: 0.462481\n",
      "epoch 41; iter: 600; batch classifier loss: 0.378724; batch adversarial loss: 0.435089\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427873; batch adversarial loss: 0.463270\n",
      "epoch 42; iter: 200; batch classifier loss: 0.433654; batch adversarial loss: 0.574157\n",
      "epoch 42; iter: 400; batch classifier loss: 0.291892; batch adversarial loss: 0.554691\n",
      "epoch 42; iter: 600; batch classifier loss: 0.562207; batch adversarial loss: 0.293343\n",
      "epoch 43; iter: 0; batch classifier loss: 0.418372; batch adversarial loss: 0.376116\n",
      "epoch 43; iter: 200; batch classifier loss: 0.388728; batch adversarial loss: 0.295227\n",
      "epoch 43; iter: 400; batch classifier loss: 0.331554; batch adversarial loss: 0.321248\n",
      "epoch 43; iter: 600; batch classifier loss: 0.304033; batch adversarial loss: 0.376286\n",
      "epoch 44; iter: 0; batch classifier loss: 0.516825; batch adversarial loss: 0.601068\n",
      "epoch 44; iter: 200; batch classifier loss: 0.412954; batch adversarial loss: 0.401989\n",
      "epoch 44; iter: 400; batch classifier loss: 0.378981; batch adversarial loss: 0.377311\n",
      "epoch 44; iter: 600; batch classifier loss: 0.281962; batch adversarial loss: 0.483600\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413050; batch adversarial loss: 0.376800\n",
      "epoch 45; iter: 200; batch classifier loss: 0.279839; batch adversarial loss: 0.404752\n",
      "epoch 45; iter: 400; batch classifier loss: 0.336068; batch adversarial loss: 0.407800\n",
      "epoch 45; iter: 600; batch classifier loss: 0.364721; batch adversarial loss: 0.542334\n",
      "epoch 46; iter: 0; batch classifier loss: 0.796486; batch adversarial loss: 0.543882\n",
      "epoch 46; iter: 200; batch classifier loss: 0.349700; batch adversarial loss: 0.516638\n",
      "epoch 46; iter: 400; batch classifier loss: 0.551611; batch adversarial loss: 0.401607\n",
      "epoch 46; iter: 600; batch classifier loss: 0.284782; batch adversarial loss: 0.435013\n",
      "epoch 47; iter: 0; batch classifier loss: 0.316443; batch adversarial loss: 0.406872\n",
      "epoch 47; iter: 200; batch classifier loss: 0.489417; batch adversarial loss: 0.489563\n",
      "epoch 47; iter: 400; batch classifier loss: 0.405907; batch adversarial loss: 0.567239\n",
      "epoch 47; iter: 600; batch classifier loss: 0.374531; batch adversarial loss: 0.379456\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432920; batch adversarial loss: 0.323175\n",
      "epoch 48; iter: 200; batch classifier loss: 0.357862; batch adversarial loss: 0.488345\n",
      "epoch 48; iter: 400; batch classifier loss: 0.448439; batch adversarial loss: 0.269201\n",
      "epoch 48; iter: 600; batch classifier loss: 0.393538; batch adversarial loss: 0.240215\n",
      "epoch 49; iter: 0; batch classifier loss: 0.379566; batch adversarial loss: 0.572012\n",
      "epoch 49; iter: 200; batch classifier loss: 0.341697; batch adversarial loss: 0.488222\n",
      "epoch 49; iter: 400; batch classifier loss: 0.319266; batch adversarial loss: 0.380794\n",
      "epoch 49; iter: 600; batch classifier loss: 0.552471; batch adversarial loss: 0.434570\n",
      "epoch 0; iter: 0; batch classifier loss: 79.366325; batch adversarial loss: 0.837764\n",
      "epoch 0; iter: 200; batch classifier loss: 3.715497; batch adversarial loss: 0.749304\n",
      "epoch 0; iter: 400; batch classifier loss: 7.070476; batch adversarial loss: 0.575894\n",
      "epoch 0; iter: 600; batch classifier loss: 13.284292; batch adversarial loss: 0.498357\n",
      "epoch 1; iter: 0; batch classifier loss: 9.474832; batch adversarial loss: 0.551953\n",
      "epoch 1; iter: 200; batch classifier loss: 4.216313; batch adversarial loss: 0.475038\n",
      "epoch 1; iter: 400; batch classifier loss: 16.201910; batch adversarial loss: 0.463994\n",
      "epoch 1; iter: 600; batch classifier loss: 4.209968; batch adversarial loss: 0.475537\n",
      "epoch 2; iter: 0; batch classifier loss: 2.023147; batch adversarial loss: 0.510512\n",
      "epoch 2; iter: 200; batch classifier loss: 7.502030; batch adversarial loss: 0.476199\n",
      "epoch 2; iter: 400; batch classifier loss: 2.190166; batch adversarial loss: 0.450764\n",
      "epoch 2; iter: 600; batch classifier loss: 1.405187; batch adversarial loss: 0.416312\n",
      "epoch 3; iter: 0; batch classifier loss: 3.455668; batch adversarial loss: 0.482638\n",
      "epoch 3; iter: 200; batch classifier loss: 6.012902; batch adversarial loss: 0.429194\n",
      "epoch 3; iter: 400; batch classifier loss: 1.267826; batch adversarial loss: 0.329410\n",
      "epoch 3; iter: 600; batch classifier loss: 1.167059; batch adversarial loss: 0.465848\n",
      "epoch 4; iter: 0; batch classifier loss: 2.701312; batch adversarial loss: 0.407716\n",
      "epoch 4; iter: 200; batch classifier loss: 3.450231; batch adversarial loss: 0.406692\n",
      "epoch 4; iter: 400; batch classifier loss: 1.593188; batch adversarial loss: 0.284483\n",
      "epoch 4; iter: 600; batch classifier loss: 2.208849; batch adversarial loss: 0.410797\n",
      "epoch 5; iter: 0; batch classifier loss: 0.992198; batch adversarial loss: 0.384384\n",
      "epoch 5; iter: 200; batch classifier loss: 0.468477; batch adversarial loss: 0.369267\n",
      "epoch 5; iter: 400; batch classifier loss: 0.665434; batch adversarial loss: 0.400938\n",
      "epoch 5; iter: 600; batch classifier loss: 0.477620; batch adversarial loss: 0.403005\n",
      "epoch 6; iter: 0; batch classifier loss: 1.349682; batch adversarial loss: 0.517278\n",
      "epoch 6; iter: 200; batch classifier loss: 0.480410; batch adversarial loss: 0.344054\n",
      "epoch 6; iter: 400; batch classifier loss: 0.380005; batch adversarial loss: 0.404447\n",
      "epoch 6; iter: 600; batch classifier loss: 0.556790; batch adversarial loss: 0.428816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405127; batch adversarial loss: 0.429923\n",
      "epoch 7; iter: 200; batch classifier loss: 0.517398; batch adversarial loss: 0.371233\n",
      "epoch 7; iter: 400; batch classifier loss: 0.572724; batch adversarial loss: 0.432783\n",
      "epoch 7; iter: 600; batch classifier loss: 0.484480; batch adversarial loss: 0.483378\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520597; batch adversarial loss: 0.348485\n",
      "epoch 8; iter: 200; batch classifier loss: 0.498167; batch adversarial loss: 0.359872\n",
      "epoch 8; iter: 400; batch classifier loss: 0.519659; batch adversarial loss: 0.427159\n",
      "epoch 8; iter: 600; batch classifier loss: 0.339353; batch adversarial loss: 0.547278\n",
      "epoch 9; iter: 0; batch classifier loss: 0.352849; batch adversarial loss: 0.430628\n",
      "epoch 9; iter: 200; batch classifier loss: 0.335031; batch adversarial loss: 0.378858\n",
      "epoch 9; iter: 400; batch classifier loss: 0.393813; batch adversarial loss: 0.468023\n",
      "epoch 9; iter: 600; batch classifier loss: 0.357240; batch adversarial loss: 0.558724\n",
      "epoch 10; iter: 0; batch classifier loss: 0.359717; batch adversarial loss: 0.503598\n",
      "epoch 10; iter: 200; batch classifier loss: 0.326589; batch adversarial loss: 0.372965\n",
      "epoch 10; iter: 400; batch classifier loss: 0.519210; batch adversarial loss: 0.437054\n",
      "epoch 10; iter: 600; batch classifier loss: 0.496685; batch adversarial loss: 0.565559\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362959; batch adversarial loss: 0.414073\n",
      "epoch 11; iter: 200; batch classifier loss: 0.333744; batch adversarial loss: 0.318639\n",
      "epoch 11; iter: 400; batch classifier loss: 0.402545; batch adversarial loss: 0.406267\n",
      "epoch 11; iter: 600; batch classifier loss: 0.437993; batch adversarial loss: 0.426783\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337164; batch adversarial loss: 0.519430\n",
      "epoch 12; iter: 200; batch classifier loss: 0.285498; batch adversarial loss: 0.579222\n",
      "epoch 12; iter: 400; batch classifier loss: 0.349487; batch adversarial loss: 0.407884\n",
      "epoch 12; iter: 600; batch classifier loss: 0.428986; batch adversarial loss: 0.270003\n",
      "epoch 13; iter: 0; batch classifier loss: 0.267020; batch adversarial loss: 0.514564\n",
      "epoch 13; iter: 200; batch classifier loss: 0.372450; batch adversarial loss: 0.377439\n",
      "epoch 13; iter: 400; batch classifier loss: 0.381572; batch adversarial loss: 0.240280\n",
      "epoch 13; iter: 600; batch classifier loss: 0.386942; batch adversarial loss: 0.330845\n",
      "epoch 14; iter: 0; batch classifier loss: 0.287079; batch adversarial loss: 0.365937\n",
      "epoch 14; iter: 200; batch classifier loss: 0.376492; batch adversarial loss: 0.261541\n",
      "epoch 14; iter: 400; batch classifier loss: 0.363001; batch adversarial loss: 0.450748\n",
      "epoch 14; iter: 600; batch classifier loss: 0.474885; batch adversarial loss: 0.407432\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442446; batch adversarial loss: 0.390086\n",
      "epoch 15; iter: 200; batch classifier loss: 0.414465; batch adversarial loss: 0.464178\n",
      "epoch 15; iter: 400; batch classifier loss: 0.474841; batch adversarial loss: 0.324595\n",
      "epoch 15; iter: 600; batch classifier loss: 0.387578; batch adversarial loss: 0.350466\n",
      "epoch 16; iter: 0; batch classifier loss: 0.431874; batch adversarial loss: 0.397343\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388967; batch adversarial loss: 0.299470\n",
      "epoch 16; iter: 400; batch classifier loss: 0.402053; batch adversarial loss: 0.379029\n",
      "epoch 16; iter: 600; batch classifier loss: 0.456629; batch adversarial loss: 0.466904\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316080; batch adversarial loss: 0.361426\n",
      "epoch 17; iter: 200; batch classifier loss: 0.450675; batch adversarial loss: 0.451525\n",
      "epoch 17; iter: 400; batch classifier loss: 0.362357; batch adversarial loss: 0.427699\n",
      "epoch 17; iter: 600; batch classifier loss: 0.271119; batch adversarial loss: 0.348185\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384447; batch adversarial loss: 0.269357\n",
      "epoch 18; iter: 200; batch classifier loss: 0.302566; batch adversarial loss: 0.466929\n",
      "epoch 18; iter: 400; batch classifier loss: 0.191097; batch adversarial loss: 0.239085\n",
      "epoch 18; iter: 600; batch classifier loss: 0.431788; batch adversarial loss: 0.476272\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396929; batch adversarial loss: 0.489771\n",
      "epoch 19; iter: 200; batch classifier loss: 0.483072; batch adversarial loss: 0.418189\n",
      "epoch 19; iter: 400; batch classifier loss: 0.386050; batch adversarial loss: 0.459495\n",
      "epoch 19; iter: 600; batch classifier loss: 0.439673; batch adversarial loss: 0.318562\n",
      "epoch 20; iter: 0; batch classifier loss: 0.523597; batch adversarial loss: 0.438834\n",
      "epoch 20; iter: 200; batch classifier loss: 0.515876; batch adversarial loss: 0.508879\n",
      "epoch 20; iter: 400; batch classifier loss: 0.366840; batch adversarial loss: 0.412997\n",
      "epoch 20; iter: 600; batch classifier loss: 0.527204; batch adversarial loss: 0.477500\n",
      "epoch 21; iter: 0; batch classifier loss: 0.356248; batch adversarial loss: 0.294610\n",
      "epoch 21; iter: 200; batch classifier loss: 0.407115; batch adversarial loss: 0.347020\n",
      "epoch 21; iter: 400; batch classifier loss: 0.439520; batch adversarial loss: 0.442056\n",
      "epoch 21; iter: 600; batch classifier loss: 0.528136; batch adversarial loss: 0.403746\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450600; batch adversarial loss: 0.543863\n",
      "epoch 22; iter: 200; batch classifier loss: 0.408505; batch adversarial loss: 0.373265\n",
      "epoch 22; iter: 400; batch classifier loss: 0.482078; batch adversarial loss: 0.400408\n",
      "epoch 22; iter: 600; batch classifier loss: 0.523094; batch adversarial loss: 0.537933\n",
      "epoch 23; iter: 0; batch classifier loss: 0.431982; batch adversarial loss: 0.528444\n",
      "epoch 23; iter: 200; batch classifier loss: 0.541274; batch adversarial loss: 0.374793\n",
      "epoch 23; iter: 400; batch classifier loss: 0.420727; batch adversarial loss: 0.353995\n",
      "epoch 23; iter: 600; batch classifier loss: 0.625896; batch adversarial loss: 0.297658\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455809; batch adversarial loss: 0.426946\n",
      "epoch 24; iter: 200; batch classifier loss: 0.475416; batch adversarial loss: 0.474500\n",
      "epoch 24; iter: 400; batch classifier loss: 0.435261; batch adversarial loss: 0.371385\n",
      "epoch 24; iter: 600; batch classifier loss: 0.443080; batch adversarial loss: 0.592316\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254122; batch adversarial loss: 0.435187\n",
      "epoch 25; iter: 200; batch classifier loss: 0.731363; batch adversarial loss: 0.322561\n",
      "epoch 25; iter: 400; batch classifier loss: 0.459209; batch adversarial loss: 0.507930\n",
      "epoch 25; iter: 600; batch classifier loss: 0.436176; batch adversarial loss: 0.535049\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483382; batch adversarial loss: 0.374174\n",
      "epoch 26; iter: 200; batch classifier loss: 0.637807; batch adversarial loss: 0.320393\n",
      "epoch 26; iter: 400; batch classifier loss: 0.607898; batch adversarial loss: 0.380281\n",
      "epoch 26; iter: 600; batch classifier loss: 0.500604; batch adversarial loss: 0.348510\n",
      "epoch 27; iter: 0; batch classifier loss: 0.548031; batch adversarial loss: 0.478044\n",
      "epoch 27; iter: 200; batch classifier loss: 0.437754; batch adversarial loss: 0.606380\n",
      "epoch 27; iter: 400; batch classifier loss: 0.433275; batch adversarial loss: 0.382713\n",
      "epoch 27; iter: 600; batch classifier loss: 0.704015; batch adversarial loss: 0.371974\n",
      "epoch 28; iter: 0; batch classifier loss: 0.387100; batch adversarial loss: 0.465797\n",
      "epoch 28; iter: 200; batch classifier loss: 0.522309; batch adversarial loss: 0.624677\n",
      "epoch 28; iter: 400; batch classifier loss: 0.327879; batch adversarial loss: 0.322493\n",
      "epoch 28; iter: 600; batch classifier loss: 0.526175; batch adversarial loss: 0.294013\n",
      "epoch 29; iter: 0; batch classifier loss: 0.474922; batch adversarial loss: 0.408231\n",
      "epoch 29; iter: 200; batch classifier loss: 0.470132; batch adversarial loss: 0.440680\n",
      "epoch 29; iter: 400; batch classifier loss: 0.405118; batch adversarial loss: 0.506452\n",
      "epoch 29; iter: 600; batch classifier loss: 0.420784; batch adversarial loss: 0.403353\n",
      "epoch 30; iter: 0; batch classifier loss: 0.592041; batch adversarial loss: 0.380452\n",
      "epoch 30; iter: 200; batch classifier loss: 0.465117; batch adversarial loss: 0.373697\n",
      "epoch 30; iter: 400; batch classifier loss: 0.704698; batch adversarial loss: 0.484846\n",
      "epoch 30; iter: 600; batch classifier loss: 0.430179; batch adversarial loss: 0.347084\n",
      "epoch 31; iter: 0; batch classifier loss: 0.530865; batch adversarial loss: 0.460680\n",
      "epoch 31; iter: 200; batch classifier loss: 0.473180; batch adversarial loss: 0.385543\n",
      "epoch 31; iter: 400; batch classifier loss: 0.470852; batch adversarial loss: 0.373155\n",
      "epoch 31; iter: 600; batch classifier loss: 0.537795; batch adversarial loss: 0.538336\n",
      "epoch 32; iter: 0; batch classifier loss: 0.650531; batch adversarial loss: 0.461299\n",
      "epoch 32; iter: 200; batch classifier loss: 0.583188; batch adversarial loss: 0.430187\n",
      "epoch 32; iter: 400; batch classifier loss: 0.546934; batch adversarial loss: 0.329263\n",
      "epoch 32; iter: 600; batch classifier loss: 0.579609; batch adversarial loss: 0.345775\n",
      "epoch 33; iter: 0; batch classifier loss: 0.304794; batch adversarial loss: 0.414932\n",
      "epoch 33; iter: 200; batch classifier loss: 0.505399; batch adversarial loss: 0.411435\n",
      "epoch 33; iter: 400; batch classifier loss: 0.415433; batch adversarial loss: 0.319030\n",
      "epoch 33; iter: 600; batch classifier loss: 0.418476; batch adversarial loss: 0.441943\n",
      "epoch 34; iter: 0; batch classifier loss: 0.548984; batch adversarial loss: 0.401147\n",
      "epoch 34; iter: 200; batch classifier loss: 0.485665; batch adversarial loss: 0.511412\n",
      "epoch 34; iter: 400; batch classifier loss: 0.510494; batch adversarial loss: 0.267555\n",
      "epoch 34; iter: 600; batch classifier loss: 0.677159; batch adversarial loss: 0.407877\n",
      "epoch 35; iter: 0; batch classifier loss: 0.781974; batch adversarial loss: 0.375157\n",
      "epoch 35; iter: 200; batch classifier loss: 0.636922; batch adversarial loss: 0.211275\n",
      "epoch 35; iter: 400; batch classifier loss: 0.543465; batch adversarial loss: 0.316207\n",
      "epoch 35; iter: 600; batch classifier loss: 0.587523; batch adversarial loss: 0.537129\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468905; batch adversarial loss: 0.320624\n",
      "epoch 36; iter: 200; batch classifier loss: 0.533647; batch adversarial loss: 0.538377\n",
      "epoch 36; iter: 400; batch classifier loss: 0.452082; batch adversarial loss: 0.377887\n",
      "epoch 36; iter: 600; batch classifier loss: 0.722005; batch adversarial loss: 0.494313\n",
      "epoch 37; iter: 0; batch classifier loss: 0.644310; batch adversarial loss: 0.456947\n",
      "epoch 37; iter: 200; batch classifier loss: 0.619967; batch adversarial loss: 0.427473\n",
      "epoch 37; iter: 400; batch classifier loss: 0.642525; batch adversarial loss: 0.442290\n",
      "epoch 37; iter: 600; batch classifier loss: 0.485378; batch adversarial loss: 0.381658\n",
      "epoch 38; iter: 0; batch classifier loss: 0.578516; batch adversarial loss: 0.293074\n",
      "epoch 38; iter: 200; batch classifier loss: 0.689443; batch adversarial loss: 0.454898\n",
      "epoch 38; iter: 400; batch classifier loss: 0.443128; batch adversarial loss: 0.457896\n",
      "epoch 38; iter: 600; batch classifier loss: 0.479152; batch adversarial loss: 0.567580\n",
      "epoch 39; iter: 0; batch classifier loss: 0.722005; batch adversarial loss: 0.402860\n",
      "epoch 39; iter: 200; batch classifier loss: 0.581548; batch adversarial loss: 0.561827\n",
      "epoch 39; iter: 400; batch classifier loss: 0.599018; batch adversarial loss: 0.432337\n",
      "epoch 39; iter: 600; batch classifier loss: 0.439856; batch adversarial loss: 0.428598\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240254; batch adversarial loss: 0.403506\n",
      "epoch 40; iter: 200; batch classifier loss: 0.642363; batch adversarial loss: 0.432549\n",
      "epoch 40; iter: 400; batch classifier loss: 0.446214; batch adversarial loss: 0.294803\n",
      "epoch 40; iter: 600; batch classifier loss: 0.568265; batch adversarial loss: 0.452628\n",
      "epoch 41; iter: 0; batch classifier loss: 0.533422; batch adversarial loss: 0.428746\n",
      "epoch 41; iter: 200; batch classifier loss: 0.613997; batch adversarial loss: 0.461071\n",
      "epoch 41; iter: 400; batch classifier loss: 0.698907; batch adversarial loss: 0.428643\n",
      "epoch 41; iter: 600; batch classifier loss: 0.590064; batch adversarial loss: 0.401731\n",
      "epoch 42; iter: 0; batch classifier loss: 0.334501; batch adversarial loss: 0.453508\n",
      "epoch 42; iter: 200; batch classifier loss: 0.533060; batch adversarial loss: 0.346681\n",
      "epoch 42; iter: 400; batch classifier loss: 0.486154; batch adversarial loss: 0.482855\n",
      "epoch 42; iter: 600; batch classifier loss: 0.837336; batch adversarial loss: 0.320378\n",
      "epoch 43; iter: 0; batch classifier loss: 0.543223; batch adversarial loss: 0.483760\n",
      "epoch 43; iter: 200; batch classifier loss: 0.469701; batch adversarial loss: 0.547655\n",
      "epoch 43; iter: 400; batch classifier loss: 0.616226; batch adversarial loss: 0.440990\n",
      "epoch 43; iter: 600; batch classifier loss: 0.634644; batch adversarial loss: 0.329482\n",
      "epoch 44; iter: 0; batch classifier loss: 0.690517; batch adversarial loss: 0.456314\n",
      "epoch 44; iter: 200; batch classifier loss: 0.837857; batch adversarial loss: 0.429220\n",
      "epoch 44; iter: 400; batch classifier loss: 0.564652; batch adversarial loss: 0.406837\n",
      "epoch 44; iter: 600; batch classifier loss: 0.510102; batch adversarial loss: 0.409010\n",
      "epoch 45; iter: 0; batch classifier loss: 0.479995; batch adversarial loss: 0.428306\n",
      "epoch 45; iter: 200; batch classifier loss: 0.741529; batch adversarial loss: 0.381866\n",
      "epoch 45; iter: 400; batch classifier loss: 0.799813; batch adversarial loss: 0.440264\n",
      "epoch 45; iter: 600; batch classifier loss: 0.459899; batch adversarial loss: 0.350349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.677013; batch adversarial loss: 0.345865\n",
      "epoch 46; iter: 200; batch classifier loss: 0.618001; batch adversarial loss: 0.653256\n",
      "epoch 46; iter: 400; batch classifier loss: 0.502023; batch adversarial loss: 0.432439\n",
      "epoch 46; iter: 600; batch classifier loss: 0.571906; batch adversarial loss: 0.487951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.665818; batch adversarial loss: 0.540309\n",
      "epoch 47; iter: 200; batch classifier loss: 0.535811; batch adversarial loss: 0.479329\n",
      "epoch 47; iter: 400; batch classifier loss: 0.491017; batch adversarial loss: 0.381910\n",
      "epoch 47; iter: 600; batch classifier loss: 0.615655; batch adversarial loss: 0.431073\n",
      "epoch 48; iter: 0; batch classifier loss: 0.432492; batch adversarial loss: 0.372857\n",
      "epoch 48; iter: 200; batch classifier loss: 0.552973; batch adversarial loss: 0.301013\n",
      "epoch 48; iter: 400; batch classifier loss: 0.591867; batch adversarial loss: 0.405249\n",
      "epoch 48; iter: 600; batch classifier loss: 0.617991; batch adversarial loss: 0.211917\n",
      "epoch 49; iter: 0; batch classifier loss: 0.609324; batch adversarial loss: 0.374119\n",
      "epoch 49; iter: 200; batch classifier loss: 0.847166; batch adversarial loss: 0.290051\n",
      "epoch 49; iter: 400; batch classifier loss: 0.617298; batch adversarial loss: 0.439648\n",
      "epoch 49; iter: 600; batch classifier loss: 0.675339; batch adversarial loss: 0.463356\n",
      "epoch 0; iter: 0; batch classifier loss: 8.655828; batch adversarial loss: 1.042616\n",
      "epoch 0; iter: 200; batch classifier loss: 13.266706; batch adversarial loss: 0.956948\n",
      "epoch 0; iter: 400; batch classifier loss: 7.000111; batch adversarial loss: 0.765931\n",
      "epoch 0; iter: 600; batch classifier loss: 5.329363; batch adversarial loss: 0.633823\n",
      "epoch 1; iter: 0; batch classifier loss: 13.599985; batch adversarial loss: 0.613069\n",
      "epoch 1; iter: 200; batch classifier loss: 4.625263; batch adversarial loss: 0.504233\n",
      "epoch 1; iter: 400; batch classifier loss: 3.296753; batch adversarial loss: 0.511583\n",
      "epoch 1; iter: 600; batch classifier loss: 4.991088; batch adversarial loss: 0.530134\n",
      "epoch 2; iter: 0; batch classifier loss: 1.205859; batch adversarial loss: 0.442283\n",
      "epoch 2; iter: 200; batch classifier loss: 6.781358; batch adversarial loss: 0.417754\n",
      "epoch 2; iter: 400; batch classifier loss: 1.253708; batch adversarial loss: 0.461594\n",
      "epoch 2; iter: 600; batch classifier loss: 2.742423; batch adversarial loss: 0.397176\n",
      "epoch 3; iter: 0; batch classifier loss: 2.361775; batch adversarial loss: 0.439279\n",
      "epoch 3; iter: 200; batch classifier loss: 1.067180; batch adversarial loss: 0.468304\n",
      "epoch 3; iter: 400; batch classifier loss: 1.543727; batch adversarial loss: 0.464489\n",
      "epoch 3; iter: 600; batch classifier loss: 1.250397; batch adversarial loss: 0.482474\n",
      "epoch 4; iter: 0; batch classifier loss: 1.936974; batch adversarial loss: 0.553447\n",
      "epoch 4; iter: 200; batch classifier loss: 0.393157; batch adversarial loss: 0.525420\n",
      "epoch 4; iter: 400; batch classifier loss: 0.744472; batch adversarial loss: 0.393931\n",
      "epoch 4; iter: 600; batch classifier loss: 0.606385; batch adversarial loss: 0.390637\n",
      "epoch 5; iter: 0; batch classifier loss: 0.742192; batch adversarial loss: 0.303304\n",
      "epoch 5; iter: 200; batch classifier loss: 0.693582; batch adversarial loss: 0.474186\n",
      "epoch 5; iter: 400; batch classifier loss: 0.451527; batch adversarial loss: 0.455074\n",
      "epoch 5; iter: 600; batch classifier loss: 0.557261; batch adversarial loss: 0.303512\n",
      "epoch 6; iter: 0; batch classifier loss: 0.436635; batch adversarial loss: 0.297494\n",
      "epoch 6; iter: 200; batch classifier loss: 0.530199; batch adversarial loss: 0.474199\n",
      "epoch 6; iter: 400; batch classifier loss: 0.349201; batch adversarial loss: 0.403400\n",
      "epoch 6; iter: 600; batch classifier loss: 0.555958; batch adversarial loss: 0.318518\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352375; batch adversarial loss: 0.422335\n",
      "epoch 7; iter: 200; batch classifier loss: 0.306343; batch adversarial loss: 0.582248\n",
      "epoch 7; iter: 400; batch classifier loss: 0.807920; batch adversarial loss: 0.335775\n",
      "epoch 7; iter: 600; batch classifier loss: 0.417062; batch adversarial loss: 0.418324\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400545; batch adversarial loss: 0.383685\n",
      "epoch 8; iter: 200; batch classifier loss: 0.380731; batch adversarial loss: 0.342773\n",
      "epoch 8; iter: 400; batch classifier loss: 0.342315; batch adversarial loss: 0.456067\n",
      "epoch 8; iter: 600; batch classifier loss: 0.417929; batch adversarial loss: 0.373890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.408899; batch adversarial loss: 0.408299\n",
      "epoch 9; iter: 200; batch classifier loss: 0.381848; batch adversarial loss: 0.574047\n",
      "epoch 9; iter: 400; batch classifier loss: 0.433159; batch adversarial loss: 0.464458\n",
      "epoch 9; iter: 600; batch classifier loss: 0.301692; batch adversarial loss: 0.508070\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363652; batch adversarial loss: 0.367094\n",
      "epoch 10; iter: 200; batch classifier loss: 0.289393; batch adversarial loss: 0.272337\n",
      "epoch 10; iter: 400; batch classifier loss: 0.378777; batch adversarial loss: 0.351137\n",
      "epoch 10; iter: 600; batch classifier loss: 0.384954; batch adversarial loss: 0.424506\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329281; batch adversarial loss: 0.398840\n",
      "epoch 11; iter: 200; batch classifier loss: 0.325396; batch adversarial loss: 0.429674\n",
      "epoch 11; iter: 400; batch classifier loss: 0.300470; batch adversarial loss: 0.429652\n",
      "epoch 11; iter: 600; batch classifier loss: 0.382599; batch adversarial loss: 0.328858\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300516; batch adversarial loss: 0.372255\n",
      "epoch 12; iter: 200; batch classifier loss: 0.345462; batch adversarial loss: 0.419180\n",
      "epoch 12; iter: 400; batch classifier loss: 0.541310; batch adversarial loss: 0.478338\n",
      "epoch 12; iter: 600; batch classifier loss: 0.288145; batch adversarial loss: 0.335642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.388853; batch adversarial loss: 0.495559\n",
      "epoch 13; iter: 200; batch classifier loss: 0.304584; batch adversarial loss: 0.395518\n",
      "epoch 13; iter: 400; batch classifier loss: 0.354187; batch adversarial loss: 0.395243\n",
      "epoch 13; iter: 600; batch classifier loss: 0.323164; batch adversarial loss: 0.415636\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318069; batch adversarial loss: 0.474248\n",
      "epoch 14; iter: 200; batch classifier loss: 0.258807; batch adversarial loss: 0.443417\n",
      "epoch 14; iter: 400; batch classifier loss: 0.327704; batch adversarial loss: 0.497394\n",
      "epoch 14; iter: 600; batch classifier loss: 0.372993; batch adversarial loss: 0.470448\n",
      "epoch 15; iter: 0; batch classifier loss: 0.333064; batch adversarial loss: 0.349558\n",
      "epoch 15; iter: 200; batch classifier loss: 0.257501; batch adversarial loss: 0.426672\n",
      "epoch 15; iter: 400; batch classifier loss: 0.408164; batch adversarial loss: 0.399901\n",
      "epoch 15; iter: 600; batch classifier loss: 0.271744; batch adversarial loss: 0.408145\n",
      "epoch 16; iter: 0; batch classifier loss: 0.289315; batch adversarial loss: 0.421761\n",
      "epoch 16; iter: 200; batch classifier loss: 0.365307; batch adversarial loss: 0.479951\n",
      "epoch 16; iter: 400; batch classifier loss: 0.272200; batch adversarial loss: 0.315033\n",
      "epoch 16; iter: 600; batch classifier loss: 0.213723; batch adversarial loss: 0.457108\n",
      "epoch 17; iter: 0; batch classifier loss: 0.524507; batch adversarial loss: 0.393681\n",
      "epoch 17; iter: 200; batch classifier loss: 0.428580; batch adversarial loss: 0.548945\n",
      "epoch 17; iter: 400; batch classifier loss: 0.510123; batch adversarial loss: 0.620290\n",
      "epoch 17; iter: 600; batch classifier loss: 0.327385; batch adversarial loss: 0.439738\n",
      "epoch 18; iter: 0; batch classifier loss: 0.550721; batch adversarial loss: 0.397095\n",
      "epoch 18; iter: 200; batch classifier loss: 0.275321; batch adversarial loss: 0.488926\n",
      "epoch 18; iter: 400; batch classifier loss: 0.379674; batch adversarial loss: 0.427920\n",
      "epoch 18; iter: 600; batch classifier loss: 0.430190; batch adversarial loss: 0.385279\n",
      "epoch 19; iter: 0; batch classifier loss: 0.433974; batch adversarial loss: 0.454916\n",
      "epoch 19; iter: 200; batch classifier loss: 0.313794; batch adversarial loss: 0.485776\n",
      "epoch 19; iter: 400; batch classifier loss: 0.423120; batch adversarial loss: 0.430055\n",
      "epoch 19; iter: 600; batch classifier loss: 0.393104; batch adversarial loss: 0.463009\n",
      "epoch 20; iter: 0; batch classifier loss: 0.416936; batch adversarial loss: 0.454613\n",
      "epoch 20; iter: 200; batch classifier loss: 0.303697; batch adversarial loss: 0.402002\n",
      "epoch 20; iter: 400; batch classifier loss: 0.378094; batch adversarial loss: 0.450866\n",
      "epoch 20; iter: 600; batch classifier loss: 0.432334; batch adversarial loss: 0.441786\n",
      "epoch 21; iter: 0; batch classifier loss: 0.483027; batch adversarial loss: 0.505250\n",
      "epoch 21; iter: 200; batch classifier loss: 0.355114; batch adversarial loss: 0.358209\n",
      "epoch 21; iter: 400; batch classifier loss: 0.368880; batch adversarial loss: 0.293541\n",
      "epoch 21; iter: 600; batch classifier loss: 0.419749; batch adversarial loss: 0.411193\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415181; batch adversarial loss: 0.377995\n",
      "epoch 22; iter: 200; batch classifier loss: 0.336158; batch adversarial loss: 0.433714\n",
      "epoch 22; iter: 400; batch classifier loss: 0.357615; batch adversarial loss: 0.321589\n",
      "epoch 22; iter: 600; batch classifier loss: 0.441146; batch adversarial loss: 0.371223\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351214; batch adversarial loss: 0.374929\n",
      "epoch 23; iter: 200; batch classifier loss: 0.382892; batch adversarial loss: 0.429954\n",
      "epoch 23; iter: 400; batch classifier loss: 0.513158; batch adversarial loss: 0.347926\n",
      "epoch 23; iter: 600; batch classifier loss: 0.466997; batch adversarial loss: 0.316547\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435308; batch adversarial loss: 0.353317\n",
      "epoch 24; iter: 200; batch classifier loss: 0.321172; batch adversarial loss: 0.492593\n",
      "epoch 24; iter: 400; batch classifier loss: 0.403082; batch adversarial loss: 0.436296\n",
      "epoch 24; iter: 600; batch classifier loss: 0.333174; batch adversarial loss: 0.368770\n",
      "epoch 25; iter: 0; batch classifier loss: 0.506867; batch adversarial loss: 0.454092\n",
      "epoch 25; iter: 200; batch classifier loss: 0.232881; batch adversarial loss: 0.562903\n",
      "epoch 25; iter: 400; batch classifier loss: 0.644596; batch adversarial loss: 0.322009\n",
      "epoch 25; iter: 600; batch classifier loss: 0.470381; batch adversarial loss: 0.408017\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446503; batch adversarial loss: 0.436407\n",
      "epoch 26; iter: 200; batch classifier loss: 0.277984; batch adversarial loss: 0.319543\n",
      "epoch 26; iter: 400; batch classifier loss: 0.440527; batch adversarial loss: 0.551611\n",
      "epoch 26; iter: 600; batch classifier loss: 0.431997; batch adversarial loss: 0.383132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.349205\n",
      "epoch 27; iter: 200; batch classifier loss: 0.375291; batch adversarial loss: 0.575473\n",
      "epoch 27; iter: 400; batch classifier loss: 0.337558; batch adversarial loss: 0.455057\n",
      "epoch 27; iter: 600; batch classifier loss: 0.434956; batch adversarial loss: 0.348758\n",
      "epoch 28; iter: 0; batch classifier loss: 0.502319; batch adversarial loss: 0.407127\n",
      "epoch 28; iter: 200; batch classifier loss: 0.454605; batch adversarial loss: 0.380387\n",
      "epoch 28; iter: 400; batch classifier loss: 0.384651; batch adversarial loss: 0.430991\n",
      "epoch 28; iter: 600; batch classifier loss: 0.542834; batch adversarial loss: 0.497539\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452609; batch adversarial loss: 0.322394\n",
      "epoch 29; iter: 200; batch classifier loss: 0.275656; batch adversarial loss: 0.371908\n",
      "epoch 29; iter: 400; batch classifier loss: 0.347110; batch adversarial loss: 0.438654\n",
      "epoch 29; iter: 600; batch classifier loss: 0.293829; batch adversarial loss: 0.241842\n",
      "epoch 30; iter: 0; batch classifier loss: 0.615818; batch adversarial loss: 0.318968\n",
      "epoch 30; iter: 200; batch classifier loss: 0.325763; batch adversarial loss: 0.523314\n",
      "epoch 30; iter: 400; batch classifier loss: 0.523368; batch adversarial loss: 0.397555\n",
      "epoch 30; iter: 600; batch classifier loss: 0.475840; batch adversarial loss: 0.323439\n",
      "epoch 31; iter: 0; batch classifier loss: 0.509551; batch adversarial loss: 0.466981\n",
      "epoch 31; iter: 200; batch classifier loss: 0.499697; batch adversarial loss: 0.489101\n",
      "epoch 31; iter: 400; batch classifier loss: 0.487463; batch adversarial loss: 0.486901\n",
      "epoch 31; iter: 600; batch classifier loss: 0.431405; batch adversarial loss: 0.431942\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410048; batch adversarial loss: 0.436449\n",
      "epoch 32; iter: 200; batch classifier loss: 0.249946; batch adversarial loss: 0.527527\n",
      "epoch 32; iter: 400; batch classifier loss: 0.350055; batch adversarial loss: 0.383005\n",
      "epoch 32; iter: 600; batch classifier loss: 0.569725; batch adversarial loss: 0.346513\n",
      "epoch 33; iter: 0; batch classifier loss: 0.331736; batch adversarial loss: 0.544804\n",
      "epoch 33; iter: 200; batch classifier loss: 0.464036; batch adversarial loss: 0.455033\n",
      "epoch 33; iter: 400; batch classifier loss: 0.495773; batch adversarial loss: 0.539448\n",
      "epoch 33; iter: 600; batch classifier loss: 0.359687; batch adversarial loss: 0.318856\n",
      "epoch 34; iter: 0; batch classifier loss: 0.456247; batch adversarial loss: 0.481370\n",
      "epoch 34; iter: 200; batch classifier loss: 0.303360; batch adversarial loss: 0.379611\n",
      "epoch 34; iter: 400; batch classifier loss: 0.382165; batch adversarial loss: 0.269107\n",
      "epoch 34; iter: 600; batch classifier loss: 0.613273; batch adversarial loss: 0.464083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.526624; batch adversarial loss: 0.586830\n",
      "epoch 35; iter: 200; batch classifier loss: 0.476579; batch adversarial loss: 0.372178\n",
      "epoch 35; iter: 400; batch classifier loss: 0.410192; batch adversarial loss: 0.293169\n",
      "epoch 35; iter: 600; batch classifier loss: 0.498011; batch adversarial loss: 0.380293\n",
      "epoch 36; iter: 0; batch classifier loss: 0.634904; batch adversarial loss: 0.430323\n",
      "epoch 36; iter: 200; batch classifier loss: 0.342403; batch adversarial loss: 0.384776\n",
      "epoch 36; iter: 400; batch classifier loss: 0.415135; batch adversarial loss: 0.354108\n",
      "epoch 36; iter: 600; batch classifier loss: 0.585415; batch adversarial loss: 0.373222\n",
      "epoch 37; iter: 0; batch classifier loss: 0.545179; batch adversarial loss: 0.484531\n",
      "epoch 37; iter: 200; batch classifier loss: 0.410029; batch adversarial loss: 0.182623\n",
      "epoch 37; iter: 400; batch classifier loss: 0.349129; batch adversarial loss: 0.494542\n",
      "epoch 37; iter: 600; batch classifier loss: 0.437724; batch adversarial loss: 0.401015\n",
      "epoch 38; iter: 0; batch classifier loss: 0.618630; batch adversarial loss: 0.495828\n",
      "epoch 38; iter: 200; batch classifier loss: 0.374614; batch adversarial loss: 0.373608\n",
      "epoch 38; iter: 400; batch classifier loss: 0.442077; batch adversarial loss: 0.429227\n",
      "epoch 38; iter: 600; batch classifier loss: 0.654599; batch adversarial loss: 0.432338\n",
      "epoch 39; iter: 0; batch classifier loss: 0.803701; batch adversarial loss: 0.372415\n",
      "epoch 39; iter: 200; batch classifier loss: 0.444364; batch adversarial loss: 0.457418\n",
      "epoch 39; iter: 400; batch classifier loss: 0.621661; batch adversarial loss: 0.460171\n",
      "epoch 39; iter: 600; batch classifier loss: 0.681026; batch adversarial loss: 0.329357\n",
      "epoch 40; iter: 0; batch classifier loss: 0.693829; batch adversarial loss: 0.317192\n",
      "epoch 40; iter: 200; batch classifier loss: 0.605983; batch adversarial loss: 0.454097\n",
      "epoch 40; iter: 400; batch classifier loss: 0.482137; batch adversarial loss: 0.400439\n",
      "epoch 40; iter: 600; batch classifier loss: 0.581042; batch adversarial loss: 0.294113\n",
      "epoch 41; iter: 0; batch classifier loss: 0.426862; batch adversarial loss: 0.485087\n",
      "epoch 41; iter: 200; batch classifier loss: 0.735381; batch adversarial loss: 0.346098\n",
      "epoch 41; iter: 400; batch classifier loss: 0.533911; batch adversarial loss: 0.430203\n",
      "epoch 41; iter: 600; batch classifier loss: 0.454175; batch adversarial loss: 0.349151\n",
      "epoch 42; iter: 0; batch classifier loss: 0.457855; batch adversarial loss: 0.482879\n",
      "epoch 42; iter: 200; batch classifier loss: 0.491053; batch adversarial loss: 0.486240\n",
      "epoch 42; iter: 400; batch classifier loss: 0.321336; batch adversarial loss: 0.548233\n",
      "epoch 42; iter: 600; batch classifier loss: 0.616730; batch adversarial loss: 0.429450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.609209; batch adversarial loss: 0.434444\n",
      "epoch 43; iter: 200; batch classifier loss: 0.491214; batch adversarial loss: 0.353250\n",
      "epoch 43; iter: 400; batch classifier loss: 0.454011; batch adversarial loss: 0.348136\n",
      "epoch 43; iter: 600; batch classifier loss: 0.439135; batch adversarial loss: 0.324102\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455114; batch adversarial loss: 0.317433\n",
      "epoch 44; iter: 200; batch classifier loss: 0.637726; batch adversarial loss: 0.408593\n",
      "epoch 44; iter: 400; batch classifier loss: 0.409134; batch adversarial loss: 0.436720\n",
      "epoch 44; iter: 600; batch classifier loss: 0.372521; batch adversarial loss: 0.571433\n",
      "epoch 45; iter: 0; batch classifier loss: 0.629334; batch adversarial loss: 0.457543\n",
      "epoch 45; iter: 200; batch classifier loss: 0.575763; batch adversarial loss: 0.359899\n",
      "epoch 45; iter: 400; batch classifier loss: 0.501501; batch adversarial loss: 0.428385\n",
      "epoch 45; iter: 600; batch classifier loss: 0.573092; batch adversarial loss: 0.324340\n",
      "epoch 46; iter: 0; batch classifier loss: 0.575036; batch adversarial loss: 0.322514\n",
      "epoch 46; iter: 200; batch classifier loss: 0.508171; batch adversarial loss: 0.437276\n",
      "epoch 46; iter: 400; batch classifier loss: 0.490068; batch adversarial loss: 0.350011\n",
      "epoch 46; iter: 600; batch classifier loss: 0.584726; batch adversarial loss: 0.543619\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414132; batch adversarial loss: 0.348433\n",
      "epoch 47; iter: 200; batch classifier loss: 0.527691; batch adversarial loss: 0.416610\n",
      "epoch 47; iter: 400; batch classifier loss: 0.434878; batch adversarial loss: 0.453405\n",
      "epoch 47; iter: 600; batch classifier loss: 0.426816; batch adversarial loss: 0.380071\n",
      "epoch 48; iter: 0; batch classifier loss: 0.579644; batch adversarial loss: 0.429749\n",
      "epoch 48; iter: 200; batch classifier loss: 0.594158; batch adversarial loss: 0.401547\n",
      "epoch 48; iter: 400; batch classifier loss: 0.480831; batch adversarial loss: 0.318951\n",
      "epoch 48; iter: 600; batch classifier loss: 0.687755; batch adversarial loss: 0.518268\n",
      "epoch 49; iter: 0; batch classifier loss: 0.644654; batch adversarial loss: 0.403135\n",
      "epoch 49; iter: 200; batch classifier loss: 0.660530; batch adversarial loss: 0.384036\n",
      "epoch 49; iter: 400; batch classifier loss: 0.510764; batch adversarial loss: 0.513719\n",
      "epoch 49; iter: 600; batch classifier loss: 0.622109; batch adversarial loss: 0.349755\n",
      "epoch 0; iter: 0; batch classifier loss: 157.360931; batch adversarial loss: 1.175623\n",
      "epoch 0; iter: 200; batch classifier loss: 17.051458; batch adversarial loss: 1.240758\n",
      "epoch 0; iter: 400; batch classifier loss: 25.066143; batch adversarial loss: 0.971365\n",
      "epoch 0; iter: 600; batch classifier loss: 17.795195; batch adversarial loss: 0.767460\n",
      "epoch 1; iter: 0; batch classifier loss: 4.930162; batch adversarial loss: 0.762123\n",
      "epoch 1; iter: 200; batch classifier loss: 10.876262; batch adversarial loss: 0.608849\n",
      "epoch 1; iter: 400; batch classifier loss: 6.233297; batch adversarial loss: 0.546830\n",
      "epoch 1; iter: 600; batch classifier loss: 1.093702; batch adversarial loss: 0.480737\n",
      "epoch 2; iter: 0; batch classifier loss: 4.241130; batch adversarial loss: 0.468952\n",
      "epoch 2; iter: 200; batch classifier loss: 6.375460; batch adversarial loss: 0.522243\n",
      "epoch 2; iter: 400; batch classifier loss: 3.020868; batch adversarial loss: 0.486602\n",
      "epoch 2; iter: 600; batch classifier loss: 1.504262; batch adversarial loss: 0.419092\n",
      "epoch 3; iter: 0; batch classifier loss: 0.839978; batch adversarial loss: 0.454730\n",
      "epoch 3; iter: 200; batch classifier loss: 1.470393; batch adversarial loss: 0.514422\n",
      "epoch 3; iter: 400; batch classifier loss: 2.430659; batch adversarial loss: 0.504491\n",
      "epoch 3; iter: 600; batch classifier loss: 1.530371; batch adversarial loss: 0.462434\n",
      "epoch 4; iter: 0; batch classifier loss: 0.509505; batch adversarial loss: 0.459991\n",
      "epoch 4; iter: 200; batch classifier loss: 0.931763; batch adversarial loss: 0.395879\n",
      "epoch 4; iter: 400; batch classifier loss: 0.477058; batch adversarial loss: 0.320509\n",
      "epoch 4; iter: 600; batch classifier loss: 0.637378; batch adversarial loss: 0.479607\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512022; batch adversarial loss: 0.411947\n",
      "epoch 5; iter: 200; batch classifier loss: 0.820675; batch adversarial loss: 0.387503\n",
      "epoch 5; iter: 400; batch classifier loss: 0.367602; batch adversarial loss: 0.260569\n",
      "epoch 5; iter: 600; batch classifier loss: 0.453616; batch adversarial loss: 0.559001\n",
      "epoch 6; iter: 0; batch classifier loss: 0.467156; batch adversarial loss: 0.346422\n",
      "epoch 6; iter: 200; batch classifier loss: 0.501089; batch adversarial loss: 0.580833\n",
      "epoch 6; iter: 400; batch classifier loss: 0.454431; batch adversarial loss: 0.424279\n",
      "epoch 6; iter: 600; batch classifier loss: 0.998660; batch adversarial loss: 0.405170\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632009; batch adversarial loss: 0.373622\n",
      "epoch 7; iter: 200; batch classifier loss: 0.442859; batch adversarial loss: 0.328814\n",
      "epoch 7; iter: 400; batch classifier loss: 0.588312; batch adversarial loss: 0.482859\n",
      "epoch 7; iter: 600; batch classifier loss: 0.277734; batch adversarial loss: 0.524750\n",
      "epoch 8; iter: 0; batch classifier loss: 0.792406; batch adversarial loss: 0.292908\n",
      "epoch 8; iter: 200; batch classifier loss: 0.568637; batch adversarial loss: 0.352173\n",
      "epoch 8; iter: 400; batch classifier loss: 0.346058; batch adversarial loss: 0.455995\n",
      "epoch 8; iter: 600; batch classifier loss: 0.411746; batch adversarial loss: 0.426062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474047; batch adversarial loss: 0.423748\n",
      "epoch 9; iter: 200; batch classifier loss: 0.324580; batch adversarial loss: 0.423804\n",
      "epoch 9; iter: 400; batch classifier loss: 0.307535; batch adversarial loss: 0.407170\n",
      "epoch 9; iter: 600; batch classifier loss: 0.413792; batch adversarial loss: 0.378933\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314994; batch adversarial loss: 0.324850\n",
      "epoch 10; iter: 200; batch classifier loss: 0.307958; batch adversarial loss: 0.485647\n",
      "epoch 10; iter: 400; batch classifier loss: 0.417115; batch adversarial loss: 0.368823\n",
      "epoch 10; iter: 600; batch classifier loss: 0.363034; batch adversarial loss: 0.536583\n",
      "epoch 11; iter: 0; batch classifier loss: 0.363943; batch adversarial loss: 0.585772\n",
      "epoch 11; iter: 200; batch classifier loss: 0.275237; batch adversarial loss: 0.561648\n",
      "epoch 11; iter: 400; batch classifier loss: 0.396908; batch adversarial loss: 0.429962\n",
      "epoch 11; iter: 600; batch classifier loss: 0.324391; batch adversarial loss: 0.440859\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312096; batch adversarial loss: 0.446885\n",
      "epoch 12; iter: 200; batch classifier loss: 0.370970; batch adversarial loss: 0.426663\n",
      "epoch 12; iter: 400; batch classifier loss: 0.403113; batch adversarial loss: 0.372388\n",
      "epoch 12; iter: 600; batch classifier loss: 0.302758; batch adversarial loss: 0.438658\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356481; batch adversarial loss: 0.375674\n",
      "epoch 13; iter: 200; batch classifier loss: 0.380413; batch adversarial loss: 0.379950\n",
      "epoch 13; iter: 400; batch classifier loss: 0.391632; batch adversarial loss: 0.240891\n",
      "epoch 13; iter: 600; batch classifier loss: 0.294878; batch adversarial loss: 0.415238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.299497; batch adversarial loss: 0.353637\n",
      "epoch 14; iter: 200; batch classifier loss: 0.368557; batch adversarial loss: 0.461367\n",
      "epoch 14; iter: 400; batch classifier loss: 0.328579; batch adversarial loss: 0.405508\n",
      "epoch 14; iter: 600; batch classifier loss: 0.327510; batch adversarial loss: 0.436037\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405720; batch adversarial loss: 0.421554\n",
      "epoch 15; iter: 200; batch classifier loss: 0.337544; batch adversarial loss: 0.463923\n",
      "epoch 15; iter: 400; batch classifier loss: 0.408200; batch adversarial loss: 0.481060\n",
      "epoch 15; iter: 600; batch classifier loss: 0.289306; batch adversarial loss: 0.552797\n",
      "epoch 16; iter: 0; batch classifier loss: 0.431545; batch adversarial loss: 0.296799\n",
      "epoch 16; iter: 200; batch classifier loss: 0.347601; batch adversarial loss: 0.389559\n",
      "epoch 16; iter: 400; batch classifier loss: 0.398725; batch adversarial loss: 0.392530\n",
      "epoch 16; iter: 600; batch classifier loss: 0.276722; batch adversarial loss: 0.352126\n",
      "epoch 17; iter: 0; batch classifier loss: 0.396649; batch adversarial loss: 0.423330\n",
      "epoch 17; iter: 200; batch classifier loss: 0.335699; batch adversarial loss: 0.510315\n",
      "epoch 17; iter: 400; batch classifier loss: 0.439210; batch adversarial loss: 0.376873\n",
      "epoch 17; iter: 600; batch classifier loss: 0.505044; batch adversarial loss: 0.439579\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328818; batch adversarial loss: 0.524680\n",
      "epoch 18; iter: 200; batch classifier loss: 0.458834; batch adversarial loss: 0.319096\n",
      "epoch 18; iter: 400; batch classifier loss: 0.326711; batch adversarial loss: 0.371937\n",
      "epoch 18; iter: 600; batch classifier loss: 0.330770; batch adversarial loss: 0.327518\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425024; batch adversarial loss: 0.395777\n",
      "epoch 19; iter: 200; batch classifier loss: 0.414889; batch adversarial loss: 0.426307\n",
      "epoch 19; iter: 400; batch classifier loss: 0.311657; batch adversarial loss: 0.296636\n",
      "epoch 19; iter: 600; batch classifier loss: 0.347435; batch adversarial loss: 0.398763\n",
      "epoch 20; iter: 0; batch classifier loss: 0.404353; batch adversarial loss: 0.345484\n",
      "epoch 20; iter: 200; batch classifier loss: 0.308829; batch adversarial loss: 0.436901\n",
      "epoch 20; iter: 400; batch classifier loss: 0.392669; batch adversarial loss: 0.207819\n",
      "epoch 20; iter: 600; batch classifier loss: 0.370805; batch adversarial loss: 0.560515\n",
      "epoch 21; iter: 0; batch classifier loss: 0.497982; batch adversarial loss: 0.327799\n",
      "epoch 21; iter: 200; batch classifier loss: 0.349836; batch adversarial loss: 0.406984\n",
      "epoch 21; iter: 400; batch classifier loss: 0.454601; batch adversarial loss: 0.436101\n",
      "epoch 21; iter: 600; batch classifier loss: 0.351905; batch adversarial loss: 0.321177\n",
      "epoch 22; iter: 0; batch classifier loss: 0.335758; batch adversarial loss: 0.512674\n",
      "epoch 22; iter: 200; batch classifier loss: 0.318738; batch adversarial loss: 0.451657\n",
      "epoch 22; iter: 400; batch classifier loss: 0.492335; batch adversarial loss: 0.409874\n",
      "epoch 22; iter: 600; batch classifier loss: 0.345746; batch adversarial loss: 0.406324\n",
      "epoch 23; iter: 0; batch classifier loss: 0.358662; batch adversarial loss: 0.370671\n",
      "epoch 23; iter: 200; batch classifier loss: 0.346621; batch adversarial loss: 0.348645\n",
      "epoch 23; iter: 400; batch classifier loss: 0.385850; batch adversarial loss: 0.428057\n",
      "epoch 23; iter: 600; batch classifier loss: 0.466263; batch adversarial loss: 0.357726\n",
      "epoch 24; iter: 0; batch classifier loss: 0.356330; batch adversarial loss: 0.433345\n",
      "epoch 24; iter: 200; batch classifier loss: 0.353252; batch adversarial loss: 0.468030\n",
      "epoch 24; iter: 400; batch classifier loss: 0.554867; batch adversarial loss: 0.426292\n",
      "epoch 24; iter: 600; batch classifier loss: 0.591269; batch adversarial loss: 0.425841\n",
      "epoch 25; iter: 0; batch classifier loss: 0.445143; batch adversarial loss: 0.429190\n",
      "epoch 25; iter: 200; batch classifier loss: 0.416521; batch adversarial loss: 0.509809\n",
      "epoch 25; iter: 400; batch classifier loss: 0.357504; batch adversarial loss: 0.403452\n",
      "epoch 25; iter: 600; batch classifier loss: 0.406506; batch adversarial loss: 0.478187\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453556; batch adversarial loss: 0.292436\n",
      "epoch 26; iter: 200; batch classifier loss: 0.606022; batch adversarial loss: 0.399433\n",
      "epoch 26; iter: 400; batch classifier loss: 0.296123; batch adversarial loss: 0.382421\n",
      "epoch 26; iter: 600; batch classifier loss: 0.531155; batch adversarial loss: 0.422428\n",
      "epoch 27; iter: 0; batch classifier loss: 0.356404; batch adversarial loss: 0.431886\n",
      "epoch 27; iter: 200; batch classifier loss: 0.551635; batch adversarial loss: 0.381163\n",
      "epoch 27; iter: 400; batch classifier loss: 0.412503; batch adversarial loss: 0.431146\n",
      "epoch 27; iter: 600; batch classifier loss: 0.454542; batch adversarial loss: 0.378793\n",
      "epoch 28; iter: 0; batch classifier loss: 0.551723; batch adversarial loss: 0.399980\n",
      "epoch 28; iter: 200; batch classifier loss: 0.293351; batch adversarial loss: 0.522912\n",
      "epoch 28; iter: 400; batch classifier loss: 0.447912; batch adversarial loss: 0.463905\n",
      "epoch 28; iter: 600; batch classifier loss: 0.470176; batch adversarial loss: 0.431188\n",
      "epoch 29; iter: 0; batch classifier loss: 0.514652; batch adversarial loss: 0.355895\n",
      "epoch 29; iter: 200; batch classifier loss: 0.477942; batch adversarial loss: 0.372510\n",
      "epoch 29; iter: 400; batch classifier loss: 0.493620; batch adversarial loss: 0.455869\n",
      "epoch 29; iter: 600; batch classifier loss: 0.392606; batch adversarial loss: 0.564127\n",
      "epoch 30; iter: 0; batch classifier loss: 0.330661; batch adversarial loss: 0.405665\n",
      "epoch 30; iter: 200; batch classifier loss: 0.564959; batch adversarial loss: 0.346188\n",
      "epoch 30; iter: 400; batch classifier loss: 0.567044; batch adversarial loss: 0.380932\n",
      "epoch 30; iter: 600; batch classifier loss: 0.447194; batch adversarial loss: 0.265830\n",
      "epoch 31; iter: 0; batch classifier loss: 0.534020; batch adversarial loss: 0.541720\n",
      "epoch 31; iter: 200; batch classifier loss: 0.450984; batch adversarial loss: 0.404960\n",
      "epoch 31; iter: 400; batch classifier loss: 0.419692; batch adversarial loss: 0.401015\n",
      "epoch 31; iter: 600; batch classifier loss: 0.438898; batch adversarial loss: 0.483422\n",
      "epoch 32; iter: 0; batch classifier loss: 0.692196; batch adversarial loss: 0.435757\n",
      "epoch 32; iter: 200; batch classifier loss: 0.504118; batch adversarial loss: 0.432728\n",
      "epoch 32; iter: 400; batch classifier loss: 0.354124; batch adversarial loss: 0.348318\n",
      "epoch 32; iter: 600; batch classifier loss: 0.440928; batch adversarial loss: 0.380028\n",
      "epoch 33; iter: 0; batch classifier loss: 0.553835; batch adversarial loss: 0.408177\n",
      "epoch 33; iter: 200; batch classifier loss: 0.474910; batch adversarial loss: 0.487708\n",
      "epoch 33; iter: 400; batch classifier loss: 0.413934; batch adversarial loss: 0.455557\n",
      "epoch 33; iter: 600; batch classifier loss: 0.409031; batch adversarial loss: 0.464827\n",
      "epoch 34; iter: 0; batch classifier loss: 0.351929; batch adversarial loss: 0.484522\n",
      "epoch 34; iter: 200; batch classifier loss: 0.506449; batch adversarial loss: 0.462333\n",
      "epoch 34; iter: 400; batch classifier loss: 0.336906; batch adversarial loss: 0.430181\n",
      "epoch 34; iter: 600; batch classifier loss: 0.443535; batch adversarial loss: 0.469417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435883; batch adversarial loss: 0.347343\n",
      "epoch 35; iter: 200; batch classifier loss: 0.571057; batch adversarial loss: 0.301925\n",
      "epoch 35; iter: 400; batch classifier loss: 0.327078; batch adversarial loss: 0.274100\n",
      "epoch 35; iter: 600; batch classifier loss: 0.528006; batch adversarial loss: 0.429163\n",
      "epoch 36; iter: 0; batch classifier loss: 0.538647; batch adversarial loss: 0.385205\n",
      "epoch 36; iter: 200; batch classifier loss: 0.563526; batch adversarial loss: 0.355524\n",
      "epoch 36; iter: 400; batch classifier loss: 0.516973; batch adversarial loss: 0.456577\n",
      "epoch 36; iter: 600; batch classifier loss: 0.437776; batch adversarial loss: 0.516243\n",
      "epoch 37; iter: 0; batch classifier loss: 0.594964; batch adversarial loss: 0.404103\n",
      "epoch 37; iter: 200; batch classifier loss: 0.677502; batch adversarial loss: 0.376642\n",
      "epoch 37; iter: 400; batch classifier loss: 0.602409; batch adversarial loss: 0.507608\n",
      "epoch 37; iter: 600; batch classifier loss: 0.403797; batch adversarial loss: 0.345047\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475187; batch adversarial loss: 0.237218\n",
      "epoch 38; iter: 200; batch classifier loss: 0.499193; batch adversarial loss: 0.371538\n",
      "epoch 38; iter: 400; batch classifier loss: 0.401218; batch adversarial loss: 0.373847\n",
      "epoch 38; iter: 600; batch classifier loss: 0.318669; batch adversarial loss: 0.349546\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404411; batch adversarial loss: 0.317341\n",
      "epoch 39; iter: 200; batch classifier loss: 0.420386; batch adversarial loss: 0.403134\n",
      "epoch 39; iter: 400; batch classifier loss: 0.413398; batch adversarial loss: 0.518576\n",
      "epoch 39; iter: 600; batch classifier loss: 0.546848; batch adversarial loss: 0.319313\n",
      "epoch 40; iter: 0; batch classifier loss: 0.414999; batch adversarial loss: 0.436892\n",
      "epoch 40; iter: 200; batch classifier loss: 0.396026; batch adversarial loss: 0.501687\n",
      "epoch 40; iter: 400; batch classifier loss: 0.411244; batch adversarial loss: 0.456442\n",
      "epoch 40; iter: 600; batch classifier loss: 0.437547; batch adversarial loss: 0.512884\n",
      "epoch 41; iter: 0; batch classifier loss: 0.725394; batch adversarial loss: 0.543890\n",
      "epoch 41; iter: 200; batch classifier loss: 0.586937; batch adversarial loss: 0.382326\n",
      "epoch 41; iter: 400; batch classifier loss: 0.714870; batch adversarial loss: 0.404969\n",
      "epoch 41; iter: 600; batch classifier loss: 0.409550; batch adversarial loss: 0.436146\n",
      "epoch 42; iter: 0; batch classifier loss: 0.381863; batch adversarial loss: 0.403840\n",
      "epoch 42; iter: 200; batch classifier loss: 0.422857; batch adversarial loss: 0.306118\n",
      "epoch 42; iter: 400; batch classifier loss: 0.546860; batch adversarial loss: 0.516688\n",
      "epoch 42; iter: 600; batch classifier loss: 0.606551; batch adversarial loss: 0.547031\n",
      "epoch 43; iter: 0; batch classifier loss: 0.658469; batch adversarial loss: 0.320670\n",
      "epoch 43; iter: 200; batch classifier loss: 0.691025; batch adversarial loss: 0.434949\n",
      "epoch 43; iter: 400; batch classifier loss: 0.555910; batch adversarial loss: 0.375952\n",
      "epoch 43; iter: 600; batch classifier loss: 0.416721; batch adversarial loss: 0.347591\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396784; batch adversarial loss: 0.403811\n",
      "epoch 44; iter: 200; batch classifier loss: 0.410474; batch adversarial loss: 0.487874\n",
      "epoch 44; iter: 400; batch classifier loss: 0.464727; batch adversarial loss: 0.403454\n",
      "epoch 44; iter: 600; batch classifier loss: 0.765667; batch adversarial loss: 0.633095\n",
      "epoch 45; iter: 0; batch classifier loss: 0.622286; batch adversarial loss: 0.464692\n",
      "epoch 45; iter: 200; batch classifier loss: 0.578526; batch adversarial loss: 0.325131\n",
      "epoch 45; iter: 400; batch classifier loss: 0.707749; batch adversarial loss: 0.566342\n",
      "epoch 45; iter: 600; batch classifier loss: 0.535645; batch adversarial loss: 0.350473\n",
      "epoch 46; iter: 0; batch classifier loss: 0.641429; batch adversarial loss: 0.327493\n",
      "epoch 46; iter: 200; batch classifier loss: 0.852154; batch adversarial loss: 0.400761\n",
      "epoch 46; iter: 400; batch classifier loss: 0.467763; batch adversarial loss: 0.516107\n",
      "epoch 46; iter: 600; batch classifier loss: 0.733547; batch adversarial loss: 0.512849\n",
      "epoch 47; iter: 0; batch classifier loss: 0.573611; batch adversarial loss: 0.484550\n",
      "epoch 47; iter: 200; batch classifier loss: 0.691476; batch adversarial loss: 0.436888\n",
      "epoch 47; iter: 400; batch classifier loss: 0.574455; batch adversarial loss: 0.429365\n",
      "epoch 47; iter: 600; batch classifier loss: 0.636933; batch adversarial loss: 0.349756\n",
      "epoch 48; iter: 0; batch classifier loss: 0.639388; batch adversarial loss: 0.354908\n",
      "epoch 48; iter: 200; batch classifier loss: 0.620976; batch adversarial loss: 0.387320\n",
      "epoch 48; iter: 400; batch classifier loss: 0.612121; batch adversarial loss: 0.491053\n",
      "epoch 48; iter: 600; batch classifier loss: 0.715966; batch adversarial loss: 0.514576\n",
      "epoch 49; iter: 0; batch classifier loss: 0.606389; batch adversarial loss: 0.429884\n",
      "epoch 49; iter: 200; batch classifier loss: 0.815253; batch adversarial loss: 0.317755\n",
      "epoch 49; iter: 400; batch classifier loss: 0.438062; batch adversarial loss: 0.242994\n",
      "epoch 49; iter: 600; batch classifier loss: 0.702567; batch adversarial loss: 0.512166\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 4.481777; batch adversarial loss: 0.752590\n",
      "epoch 0; iter: 200; batch classifier loss: 4.965721; batch adversarial loss: 0.613505\n",
      "epoch 1; iter: 0; batch classifier loss: 7.335955; batch adversarial loss: 0.570875\n",
      "epoch 1; iter: 200; batch classifier loss: 7.739335; batch adversarial loss: 0.540307\n",
      "epoch 2; iter: 0; batch classifier loss: 9.709236; batch adversarial loss: 0.514956\n",
      "epoch 2; iter: 200; batch classifier loss: 3.953637; batch adversarial loss: 0.465783\n",
      "epoch 3; iter: 0; batch classifier loss: 6.036959; batch adversarial loss: 0.506676\n",
      "epoch 3; iter: 200; batch classifier loss: 1.085886; batch adversarial loss: 0.497006\n",
      "epoch 4; iter: 0; batch classifier loss: 3.219435; batch adversarial loss: 0.470658\n",
      "epoch 4; iter: 200; batch classifier loss: 0.715262; batch adversarial loss: 0.420873\n",
      "epoch 5; iter: 0; batch classifier loss: 0.931911; batch adversarial loss: 0.438472\n",
      "epoch 5; iter: 200; batch classifier loss: 1.017306; batch adversarial loss: 0.359470\n",
      "epoch 6; iter: 0; batch classifier loss: 0.494867; batch adversarial loss: 0.476096\n",
      "epoch 6; iter: 200; batch classifier loss: 0.533113; batch adversarial loss: 0.409354\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493307; batch adversarial loss: 0.371783\n",
      "epoch 7; iter: 200; batch classifier loss: 0.458670; batch adversarial loss: 0.505768\n",
      "epoch 8; iter: 0; batch classifier loss: 0.461023; batch adversarial loss: 0.347083\n",
      "epoch 8; iter: 200; batch classifier loss: 0.494424; batch adversarial loss: 0.435009\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547508; batch adversarial loss: 0.431305\n",
      "epoch 9; iter: 200; batch classifier loss: 0.335196; batch adversarial loss: 0.483074\n",
      "epoch 0; iter: 0; batch classifier loss: 7.798787; batch adversarial loss: 0.749561\n",
      "epoch 0; iter: 200; batch classifier loss: 8.976786; batch adversarial loss: 0.645830\n",
      "epoch 1; iter: 0; batch classifier loss: 3.770881; batch adversarial loss: 0.583751\n",
      "epoch 1; iter: 200; batch classifier loss: 5.167640; batch adversarial loss: 0.517694\n",
      "epoch 2; iter: 0; batch classifier loss: 3.136401; batch adversarial loss: 0.516575\n",
      "epoch 2; iter: 200; batch classifier loss: 4.529406; batch adversarial loss: 0.463145\n",
      "epoch 3; iter: 0; batch classifier loss: 2.240280; batch adversarial loss: 0.497133\n",
      "epoch 3; iter: 200; batch classifier loss: 2.762594; batch adversarial loss: 0.429002\n",
      "epoch 4; iter: 0; batch classifier loss: 2.685216; batch adversarial loss: 0.473782\n",
      "epoch 4; iter: 200; batch classifier loss: 3.110476; batch adversarial loss: 0.453945\n",
      "epoch 5; iter: 0; batch classifier loss: 1.638402; batch adversarial loss: 0.449081\n",
      "epoch 5; iter: 200; batch classifier loss: 1.241445; batch adversarial loss: 0.410746\n",
      "epoch 6; iter: 0; batch classifier loss: 0.852503; batch adversarial loss: 0.415162\n",
      "epoch 6; iter: 200; batch classifier loss: 0.657045; batch adversarial loss: 0.411132\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471842; batch adversarial loss: 0.349464\n",
      "epoch 7; iter: 200; batch classifier loss: 0.904672; batch adversarial loss: 0.482239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.441190; batch adversarial loss: 0.405759\n",
      "epoch 8; iter: 200; batch classifier loss: 0.441793; batch adversarial loss: 0.388927\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488233; batch adversarial loss: 0.446734\n",
      "epoch 9; iter: 200; batch classifier loss: 0.450714; batch adversarial loss: 0.435096\n",
      "epoch 0; iter: 0; batch classifier loss: 27.623661; batch adversarial loss: 0.491359\n",
      "epoch 0; iter: 200; batch classifier loss: 2.693244; batch adversarial loss: 0.635748\n",
      "epoch 1; iter: 0; batch classifier loss: 11.095982; batch adversarial loss: 0.587419\n",
      "epoch 1; iter: 200; batch classifier loss: 20.470781; batch adversarial loss: 0.533829\n",
      "epoch 2; iter: 0; batch classifier loss: 5.342461; batch adversarial loss: 0.517499\n",
      "epoch 2; iter: 200; batch classifier loss: 7.822940; batch adversarial loss: 0.498972\n",
      "epoch 3; iter: 0; batch classifier loss: 2.152393; batch adversarial loss: 0.484858\n",
      "epoch 3; iter: 200; batch classifier loss: 5.793696; batch adversarial loss: 0.432386\n",
      "epoch 4; iter: 0; batch classifier loss: 2.801865; batch adversarial loss: 0.413211\n",
      "epoch 4; iter: 200; batch classifier loss: 1.336787; batch adversarial loss: 0.442799\n",
      "epoch 5; iter: 0; batch classifier loss: 1.497928; batch adversarial loss: 0.491940\n",
      "epoch 5; iter: 200; batch classifier loss: 3.196092; batch adversarial loss: 0.394587\n",
      "epoch 6; iter: 0; batch classifier loss: 2.874436; batch adversarial loss: 0.400001\n",
      "epoch 6; iter: 200; batch classifier loss: 0.700691; batch adversarial loss: 0.391612\n",
      "epoch 7; iter: 0; batch classifier loss: 1.034006; batch adversarial loss: 0.436371\n",
      "epoch 7; iter: 200; batch classifier loss: 0.636896; batch adversarial loss: 0.434227\n",
      "epoch 8; iter: 0; batch classifier loss: 1.760114; batch adversarial loss: 0.506149\n",
      "epoch 8; iter: 200; batch classifier loss: 0.698379; batch adversarial loss: 0.469890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.398596; batch adversarial loss: 0.400558\n",
      "epoch 9; iter: 200; batch classifier loss: 0.349000; batch adversarial loss: 0.475015\n",
      "epoch 0; iter: 0; batch classifier loss: 11.025534; batch adversarial loss: 1.013592\n",
      "epoch 0; iter: 200; batch classifier loss: 7.160786; batch adversarial loss: 1.011159\n",
      "epoch 1; iter: 0; batch classifier loss: 19.496603; batch adversarial loss: 1.013443\n",
      "epoch 1; iter: 200; batch classifier loss: 9.156647; batch adversarial loss: 0.749383\n",
      "epoch 2; iter: 0; batch classifier loss: 9.265905; batch adversarial loss: 0.693374\n",
      "epoch 2; iter: 200; batch classifier loss: 7.520774; batch adversarial loss: 0.563304\n",
      "epoch 3; iter: 0; batch classifier loss: 4.764356; batch adversarial loss: 0.550818\n",
      "epoch 3; iter: 200; batch classifier loss: 3.383677; batch adversarial loss: 0.492003\n",
      "epoch 4; iter: 0; batch classifier loss: 4.451346; batch adversarial loss: 0.450723\n",
      "epoch 4; iter: 200; batch classifier loss: 2.591944; batch adversarial loss: 0.461388\n",
      "epoch 5; iter: 0; batch classifier loss: 1.203769; batch adversarial loss: 0.390753\n",
      "epoch 5; iter: 200; batch classifier loss: 1.240902; batch adversarial loss: 0.419386\n",
      "epoch 6; iter: 0; batch classifier loss: 1.100441; batch adversarial loss: 0.426431\n",
      "epoch 6; iter: 200; batch classifier loss: 1.313027; batch adversarial loss: 0.392705\n",
      "epoch 7; iter: 0; batch classifier loss: 2.172113; batch adversarial loss: 0.436974\n",
      "epoch 7; iter: 200; batch classifier loss: 0.558057; batch adversarial loss: 0.410476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.875162; batch adversarial loss: 0.461945\n",
      "epoch 8; iter: 200; batch classifier loss: 0.688464; batch adversarial loss: 0.388398\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580283; batch adversarial loss: 0.406102\n",
      "epoch 9; iter: 200; batch classifier loss: 0.500599; batch adversarial loss: 0.436050\n",
      "epoch 0; iter: 0; batch classifier loss: 22.744076; batch adversarial loss: 0.590842\n",
      "epoch 0; iter: 200; batch classifier loss: 18.089634; batch adversarial loss: 0.610427\n",
      "epoch 1; iter: 0; batch classifier loss: 1.361914; batch adversarial loss: 0.577237\n",
      "epoch 1; iter: 200; batch classifier loss: 7.858909; batch adversarial loss: 0.536733\n",
      "epoch 2; iter: 0; batch classifier loss: 3.477993; batch adversarial loss: 0.521609\n",
      "epoch 2; iter: 200; batch classifier loss: 2.956560; batch adversarial loss: 0.473014\n",
      "epoch 3; iter: 0; batch classifier loss: 0.951205; batch adversarial loss: 0.506393\n",
      "epoch 3; iter: 200; batch classifier loss: 2.674694; batch adversarial loss: 0.461543\n",
      "epoch 4; iter: 0; batch classifier loss: 2.198030; batch adversarial loss: 0.416044\n",
      "epoch 4; iter: 200; batch classifier loss: 1.474106; batch adversarial loss: 0.432764\n",
      "epoch 5; iter: 0; batch classifier loss: 1.144311; batch adversarial loss: 0.453606\n",
      "epoch 5; iter: 200; batch classifier loss: 1.035482; batch adversarial loss: 0.436072\n",
      "epoch 6; iter: 0; batch classifier loss: 0.479884; batch adversarial loss: 0.383668\n",
      "epoch 6; iter: 200; batch classifier loss: 0.503410; batch adversarial loss: 0.468991\n",
      "epoch 7; iter: 0; batch classifier loss: 0.450786; batch adversarial loss: 0.358567\n",
      "epoch 7; iter: 200; batch classifier loss: 0.468091; batch adversarial loss: 0.406462\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537036; batch adversarial loss: 0.404962\n",
      "epoch 8; iter: 200; batch classifier loss: 0.361913; batch adversarial loss: 0.456739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500077; batch adversarial loss: 0.465133\n",
      "epoch 9; iter: 200; batch classifier loss: 0.323266; batch adversarial loss: 0.435390\n",
      "epoch 0; iter: 0; batch classifier loss: 25.999340; batch adversarial loss: 0.794305\n",
      "epoch 0; iter: 200; batch classifier loss: 10.490491; batch adversarial loss: 0.642852\n",
      "epoch 1; iter: 0; batch classifier loss: 26.754074; batch adversarial loss: 0.584509\n",
      "epoch 1; iter: 200; batch classifier loss: 5.298502; batch adversarial loss: 0.553555\n",
      "epoch 2; iter: 0; batch classifier loss: 5.232579; batch adversarial loss: 0.507809\n",
      "epoch 2; iter: 200; batch classifier loss: 1.994609; batch adversarial loss: 0.483335\n",
      "epoch 3; iter: 0; batch classifier loss: 5.243625; batch adversarial loss: 0.556671\n",
      "epoch 3; iter: 200; batch classifier loss: 2.807461; batch adversarial loss: 0.471715\n",
      "epoch 4; iter: 0; batch classifier loss: 2.572744; batch adversarial loss: 0.451969\n",
      "epoch 4; iter: 200; batch classifier loss: 1.789833; batch adversarial loss: 0.401365\n",
      "epoch 5; iter: 0; batch classifier loss: 1.952411; batch adversarial loss: 0.413100\n",
      "epoch 5; iter: 200; batch classifier loss: 1.934789; batch adversarial loss: 0.435409\n",
      "epoch 6; iter: 0; batch classifier loss: 0.884685; batch adversarial loss: 0.405823\n",
      "epoch 6; iter: 200; batch classifier loss: 0.480156; batch adversarial loss: 0.380358\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549174; batch adversarial loss: 0.413877\n",
      "epoch 7; iter: 200; batch classifier loss: 1.822725; batch adversarial loss: 0.435043\n",
      "epoch 8; iter: 0; batch classifier loss: 0.646717; batch adversarial loss: 0.456796\n",
      "epoch 8; iter: 200; batch classifier loss: 0.456017; batch adversarial loss: 0.363260\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504614; batch adversarial loss: 0.453286\n",
      "epoch 9; iter: 200; batch classifier loss: 0.428178; batch adversarial loss: 0.394690\n",
      "epoch 0; iter: 0; batch classifier loss: 16.413128; batch adversarial loss: 0.555226\n",
      "epoch 0; iter: 200; batch classifier loss: 7.691806; batch adversarial loss: 0.565572\n",
      "epoch 1; iter: 0; batch classifier loss: 19.133383; batch adversarial loss: 0.595870\n",
      "epoch 1; iter: 200; batch classifier loss: 10.427874; batch adversarial loss: 0.547541\n",
      "epoch 2; iter: 0; batch classifier loss: 5.340559; batch adversarial loss: 0.507531\n",
      "epoch 2; iter: 200; batch classifier loss: 3.708422; batch adversarial loss: 0.504771\n",
      "epoch 3; iter: 0; batch classifier loss: 3.124765; batch adversarial loss: 0.495828\n",
      "epoch 3; iter: 200; batch classifier loss: 0.561414; batch adversarial loss: 0.483062\n",
      "epoch 4; iter: 0; batch classifier loss: 3.213064; batch adversarial loss: 0.503433\n",
      "epoch 4; iter: 200; batch classifier loss: 1.948043; batch adversarial loss: 0.491465\n",
      "epoch 5; iter: 0; batch classifier loss: 5.090451; batch adversarial loss: 0.481472\n",
      "epoch 5; iter: 200; batch classifier loss: 1.557987; batch adversarial loss: 0.429156\n",
      "epoch 6; iter: 0; batch classifier loss: 1.496516; batch adversarial loss: 0.477230\n",
      "epoch 6; iter: 200; batch classifier loss: 1.093868; batch adversarial loss: 0.400270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.855827; batch adversarial loss: 0.442151\n",
      "epoch 7; iter: 200; batch classifier loss: 0.509671; batch adversarial loss: 0.511439\n",
      "epoch 8; iter: 0; batch classifier loss: 0.727068; batch adversarial loss: 0.313040\n",
      "epoch 8; iter: 200; batch classifier loss: 0.361076; batch adversarial loss: 0.365538\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501216; batch adversarial loss: 0.437552\n",
      "epoch 9; iter: 200; batch classifier loss: 0.509394; batch adversarial loss: 0.412943\n",
      "epoch 0; iter: 0; batch classifier loss: 4.305942; batch adversarial loss: 1.074634\n",
      "epoch 0; iter: 200; batch classifier loss: 11.903051; batch adversarial loss: 1.247604\n",
      "epoch 1; iter: 0; batch classifier loss: 8.743652; batch adversarial loss: 1.007027\n",
      "epoch 1; iter: 200; batch classifier loss: 5.838104; batch adversarial loss: 0.711145\n",
      "epoch 2; iter: 0; batch classifier loss: 3.289152; batch adversarial loss: 0.702164\n",
      "epoch 2; iter: 200; batch classifier loss: 7.978785; batch adversarial loss: 0.580693\n",
      "epoch 3; iter: 0; batch classifier loss: 4.509540; batch adversarial loss: 0.556325\n",
      "epoch 3; iter: 200; batch classifier loss: 3.394334; batch adversarial loss: 0.494682\n",
      "epoch 4; iter: 0; batch classifier loss: 2.920199; batch adversarial loss: 0.436610\n",
      "epoch 4; iter: 200; batch classifier loss: 2.019956; batch adversarial loss: 0.425218\n",
      "epoch 5; iter: 0; batch classifier loss: 1.989586; batch adversarial loss: 0.394472\n",
      "epoch 5; iter: 200; batch classifier loss: 1.197365; batch adversarial loss: 0.453701\n",
      "epoch 6; iter: 0; batch classifier loss: 0.990290; batch adversarial loss: 0.459025\n",
      "epoch 6; iter: 200; batch classifier loss: 0.736811; batch adversarial loss: 0.396969\n",
      "epoch 7; iter: 0; batch classifier loss: 0.576827; batch adversarial loss: 0.402804\n",
      "epoch 7; iter: 200; batch classifier loss: 0.909876; batch adversarial loss: 0.384330\n",
      "epoch 8; iter: 0; batch classifier loss: 0.809351; batch adversarial loss: 0.381323\n",
      "epoch 8; iter: 200; batch classifier loss: 0.574095; batch adversarial loss: 0.349633\n",
      "epoch 9; iter: 0; batch classifier loss: 0.536483; batch adversarial loss: 0.408301\n",
      "epoch 9; iter: 200; batch classifier loss: 0.622567; batch adversarial loss: 0.378757\n",
      "epoch 0; iter: 0; batch classifier loss: 36.413628; batch adversarial loss: 0.663651\n",
      "epoch 0; iter: 200; batch classifier loss: 15.866806; batch adversarial loss: 0.608779\n",
      "epoch 1; iter: 0; batch classifier loss: 8.607531; batch adversarial loss: 0.607962\n",
      "epoch 1; iter: 200; batch classifier loss: 7.549512; batch adversarial loss: 0.528906\n",
      "epoch 2; iter: 0; batch classifier loss: 5.935848; batch adversarial loss: 0.529161\n",
      "epoch 2; iter: 200; batch classifier loss: 6.007418; batch adversarial loss: 0.510251\n",
      "epoch 3; iter: 0; batch classifier loss: 9.815782; batch adversarial loss: 0.474532\n",
      "epoch 3; iter: 200; batch classifier loss: 8.258655; batch adversarial loss: 0.440582\n",
      "epoch 4; iter: 0; batch classifier loss: 1.220715; batch adversarial loss: 0.440525\n",
      "epoch 4; iter: 200; batch classifier loss: 0.836165; batch adversarial loss: 0.398300\n",
      "epoch 5; iter: 0; batch classifier loss: 1.781029; batch adversarial loss: 0.482537\n",
      "epoch 5; iter: 200; batch classifier loss: 0.519049; batch adversarial loss: 0.481302\n",
      "epoch 6; iter: 0; batch classifier loss: 0.688620; batch adversarial loss: 0.451915\n",
      "epoch 6; iter: 200; batch classifier loss: 0.798546; batch adversarial loss: 0.420980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462821; batch adversarial loss: 0.442635\n",
      "epoch 7; iter: 200; batch classifier loss: 0.498247; batch adversarial loss: 0.456791\n",
      "epoch 8; iter: 0; batch classifier loss: 0.792899; batch adversarial loss: 0.385457\n",
      "epoch 8; iter: 200; batch classifier loss: 0.613099; batch adversarial loss: 0.411114\n",
      "epoch 9; iter: 0; batch classifier loss: 0.799961; batch adversarial loss: 0.469502\n",
      "epoch 9; iter: 200; batch classifier loss: 0.517991; batch adversarial loss: 0.401328\n",
      "epoch 0; iter: 0; batch classifier loss: 12.649872; batch adversarial loss: 0.798537\n",
      "epoch 0; iter: 200; batch classifier loss: 9.622070; batch adversarial loss: 0.693848\n",
      "epoch 1; iter: 0; batch classifier loss: 8.340399; batch adversarial loss: 0.566752\n",
      "epoch 1; iter: 200; batch classifier loss: 1.016775; batch adversarial loss: 0.555928\n",
      "epoch 2; iter: 0; batch classifier loss: 2.409438; batch adversarial loss: 0.534375\n",
      "epoch 2; iter: 200; batch classifier loss: 4.271680; batch adversarial loss: 0.552361\n",
      "epoch 3; iter: 0; batch classifier loss: 1.206763; batch adversarial loss: 0.474318\n",
      "epoch 3; iter: 200; batch classifier loss: 1.039579; batch adversarial loss: 0.455465\n",
      "epoch 4; iter: 0; batch classifier loss: 5.419581; batch adversarial loss: 0.487123\n",
      "epoch 4; iter: 200; batch classifier loss: 0.918962; batch adversarial loss: 0.466948\n",
      "epoch 5; iter: 0; batch classifier loss: 1.627694; batch adversarial loss: 0.441821\n",
      "epoch 5; iter: 200; batch classifier loss: 0.736315; batch adversarial loss: 0.487702\n",
      "epoch 6; iter: 0; batch classifier loss: 1.591554; batch adversarial loss: 0.376792\n",
      "epoch 6; iter: 200; batch classifier loss: 0.811239; batch adversarial loss: 0.432890\n",
      "epoch 7; iter: 0; batch classifier loss: 2.479297; batch adversarial loss: 0.436112\n",
      "epoch 7; iter: 200; batch classifier loss: 0.856454; batch adversarial loss: 0.429060\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579673; batch adversarial loss: 0.374162\n",
      "epoch 8; iter: 200; batch classifier loss: 0.563787; batch adversarial loss: 0.325631\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598725; batch adversarial loss: 0.450792\n",
      "epoch 9; iter: 200; batch classifier loss: 0.456134; batch adversarial loss: 0.413876\n",
      "epoch 0; iter: 0; batch classifier loss: 128.844681; batch adversarial loss: 0.565955\n",
      "epoch 0; iter: 200; batch classifier loss: 12.603095; batch adversarial loss: 0.546411\n",
      "epoch 1; iter: 0; batch classifier loss: 5.111963; batch adversarial loss: 0.556027\n",
      "epoch 1; iter: 200; batch classifier loss: 32.990528; batch adversarial loss: 0.460715\n",
      "epoch 2; iter: 0; batch classifier loss: 1.386889; batch adversarial loss: 0.531858\n",
      "epoch 2; iter: 200; batch classifier loss: 4.602036; batch adversarial loss: 0.446856\n",
      "epoch 3; iter: 0; batch classifier loss: 1.958941; batch adversarial loss: 0.449934\n",
      "epoch 3; iter: 200; batch classifier loss: 2.825862; batch adversarial loss: 0.395059\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625310; batch adversarial loss: 0.434834\n",
      "epoch 4; iter: 200; batch classifier loss: 1.874720; batch adversarial loss: 0.428706\n",
      "epoch 5; iter: 0; batch classifier loss: 1.069178; batch adversarial loss: 0.537578\n",
      "epoch 5; iter: 200; batch classifier loss: 2.293326; batch adversarial loss: 0.447433\n",
      "epoch 6; iter: 0; batch classifier loss: 1.748799; batch adversarial loss: 0.421718\n",
      "epoch 6; iter: 200; batch classifier loss: 0.774185; batch adversarial loss: 0.450692\n",
      "epoch 7; iter: 0; batch classifier loss: 0.833927; batch adversarial loss: 0.440828\n",
      "epoch 7; iter: 200; batch classifier loss: 0.398680; batch adversarial loss: 0.479603\n",
      "epoch 8; iter: 0; batch classifier loss: 1.030889; batch adversarial loss: 0.368339\n",
      "epoch 8; iter: 200; batch classifier loss: 0.546778; batch adversarial loss: 0.388461\n",
      "epoch 9; iter: 0; batch classifier loss: 0.818225; batch adversarial loss: 0.424124\n",
      "epoch 9; iter: 200; batch classifier loss: 0.355676; batch adversarial loss: 0.362960\n",
      "epoch 0; iter: 0; batch classifier loss: 9.185947; batch adversarial loss: 0.461940\n",
      "epoch 0; iter: 200; batch classifier loss: 3.807488; batch adversarial loss: 0.577104\n",
      "epoch 1; iter: 0; batch classifier loss: 6.635012; batch adversarial loss: 0.556078\n",
      "epoch 1; iter: 200; batch classifier loss: 5.797502; batch adversarial loss: 0.549282\n",
      "epoch 2; iter: 0; batch classifier loss: 4.511491; batch adversarial loss: 0.494249\n",
      "epoch 2; iter: 200; batch classifier loss: 5.586365; batch adversarial loss: 0.442308\n",
      "epoch 3; iter: 0; batch classifier loss: 5.690483; batch adversarial loss: 0.494968\n",
      "epoch 3; iter: 200; batch classifier loss: 5.211705; batch adversarial loss: 0.469051\n",
      "epoch 4; iter: 0; batch classifier loss: 2.857873; batch adversarial loss: 0.492809\n",
      "epoch 4; iter: 200; batch classifier loss: 7.821882; batch adversarial loss: 0.440544\n",
      "epoch 5; iter: 0; batch classifier loss: 1.686856; batch adversarial loss: 0.390015\n",
      "epoch 5; iter: 200; batch classifier loss: 1.933507; batch adversarial loss: 0.493762\n",
      "epoch 6; iter: 0; batch classifier loss: 0.920029; batch adversarial loss: 0.358208\n",
      "epoch 6; iter: 200; batch classifier loss: 0.617863; batch adversarial loss: 0.421010\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562280; batch adversarial loss: 0.453272\n",
      "epoch 7; iter: 200; batch classifier loss: 0.823502; batch adversarial loss: 0.426057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428215; batch adversarial loss: 0.436184\n",
      "epoch 8; iter: 200; batch classifier loss: 0.509514; batch adversarial loss: 0.364438\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460330; batch adversarial loss: 0.500989\n",
      "epoch 9; iter: 200; batch classifier loss: 0.648665; batch adversarial loss: 0.349724\n",
      "epoch 0; iter: 0; batch classifier loss: 44.786053; batch adversarial loss: 0.558618\n",
      "epoch 0; iter: 200; batch classifier loss: 15.933087; batch adversarial loss: 0.606811\n",
      "epoch 1; iter: 0; batch classifier loss: 16.910629; batch adversarial loss: 0.538137\n",
      "epoch 1; iter: 200; batch classifier loss: 7.394357; batch adversarial loss: 0.521330\n",
      "epoch 2; iter: 0; batch classifier loss: 8.899325; batch adversarial loss: 0.479890\n",
      "epoch 2; iter: 200; batch classifier loss: 2.108668; batch adversarial loss: 0.510119\n",
      "epoch 3; iter: 0; batch classifier loss: 1.854116; batch adversarial loss: 0.476451\n",
      "epoch 3; iter: 200; batch classifier loss: 7.894740; batch adversarial loss: 0.477563\n",
      "epoch 4; iter: 0; batch classifier loss: 2.473825; batch adversarial loss: 0.391388\n",
      "epoch 4; iter: 200; batch classifier loss: 1.495089; batch adversarial loss: 0.448857\n",
      "epoch 5; iter: 0; batch classifier loss: 0.492454; batch adversarial loss: 0.497986\n",
      "epoch 5; iter: 200; batch classifier loss: 1.866166; batch adversarial loss: 0.467374\n",
      "epoch 6; iter: 0; batch classifier loss: 1.220214; batch adversarial loss: 0.372454\n",
      "epoch 6; iter: 200; batch classifier loss: 0.505659; batch adversarial loss: 0.349469\n",
      "epoch 7; iter: 0; batch classifier loss: 0.954461; batch adversarial loss: 0.488187\n",
      "epoch 7; iter: 200; batch classifier loss: 0.709593; batch adversarial loss: 0.512475\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526598; batch adversarial loss: 0.433323\n",
      "epoch 8; iter: 200; batch classifier loss: 0.390285; batch adversarial loss: 0.444767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.370527; batch adversarial loss: 0.388235\n",
      "epoch 9; iter: 200; batch classifier loss: 0.585272; batch adversarial loss: 0.444494\n",
      "epoch 0; iter: 0; batch classifier loss: 138.908035; batch adversarial loss: 0.685541\n",
      "epoch 0; iter: 200; batch classifier loss: 4.257605; batch adversarial loss: 0.603254\n",
      "epoch 1; iter: 0; batch classifier loss: 3.915595; batch adversarial loss: 0.570292\n",
      "epoch 1; iter: 200; batch classifier loss: 6.593053; batch adversarial loss: 0.514247\n",
      "epoch 2; iter: 0; batch classifier loss: 3.884553; batch adversarial loss: 0.499918\n",
      "epoch 2; iter: 200; batch classifier loss: 2.311475; batch adversarial loss: 0.528376\n",
      "epoch 3; iter: 0; batch classifier loss: 2.141591; batch adversarial loss: 0.443763\n",
      "epoch 3; iter: 200; batch classifier loss: 3.568725; batch adversarial loss: 0.475628\n",
      "epoch 4; iter: 0; batch classifier loss: 2.578398; batch adversarial loss: 0.462777\n",
      "epoch 4; iter: 200; batch classifier loss: 1.462914; batch adversarial loss: 0.411821\n",
      "epoch 5; iter: 0; batch classifier loss: 0.675084; batch adversarial loss: 0.458446\n",
      "epoch 5; iter: 200; batch classifier loss: 1.488801; batch adversarial loss: 0.454628\n",
      "epoch 6; iter: 0; batch classifier loss: 1.269371; batch adversarial loss: 0.347264\n",
      "epoch 6; iter: 200; batch classifier loss: 0.692746; batch adversarial loss: 0.377150\n",
      "epoch 7; iter: 0; batch classifier loss: 0.884948; batch adversarial loss: 0.420863\n",
      "epoch 7; iter: 200; batch classifier loss: 1.063154; batch adversarial loss: 0.384826\n",
      "epoch 8; iter: 0; batch classifier loss: 0.406664; batch adversarial loss: 0.469661\n",
      "epoch 8; iter: 200; batch classifier loss: 0.493849; batch adversarial loss: 0.439467\n",
      "epoch 9; iter: 0; batch classifier loss: 0.330770; batch adversarial loss: 0.450579\n",
      "epoch 9; iter: 200; batch classifier loss: 0.506859; batch adversarial loss: 0.444373\n",
      "epoch 0; iter: 0; batch classifier loss: 59.826767; batch adversarial loss: 0.729534\n",
      "epoch 0; iter: 200; batch classifier loss: 23.135960; batch adversarial loss: 0.621267\n",
      "epoch 1; iter: 0; batch classifier loss: 3.128624; batch adversarial loss: 0.580521\n",
      "epoch 1; iter: 200; batch classifier loss: 9.528207; batch adversarial loss: 0.545598\n",
      "epoch 2; iter: 0; batch classifier loss: 5.639311; batch adversarial loss: 0.503395\n",
      "epoch 2; iter: 200; batch classifier loss: 2.512404; batch adversarial loss: 0.485907\n",
      "epoch 3; iter: 0; batch classifier loss: 7.204268; batch adversarial loss: 0.465837\n",
      "epoch 3; iter: 200; batch classifier loss: 5.442628; batch adversarial loss: 0.435411\n",
      "epoch 4; iter: 0; batch classifier loss: 6.598032; batch adversarial loss: 0.462904\n",
      "epoch 4; iter: 200; batch classifier loss: 4.489045; batch adversarial loss: 0.451211\n",
      "epoch 5; iter: 0; batch classifier loss: 2.465470; batch adversarial loss: 0.407284\n",
      "epoch 5; iter: 200; batch classifier loss: 3.054383; batch adversarial loss: 0.413067\n",
      "epoch 6; iter: 0; batch classifier loss: 2.946901; batch adversarial loss: 0.410524\n",
      "epoch 6; iter: 200; batch classifier loss: 1.356849; batch adversarial loss: 0.380635\n",
      "epoch 7; iter: 0; batch classifier loss: 0.892833; batch adversarial loss: 0.331853\n",
      "epoch 7; iter: 200; batch classifier loss: 0.655846; batch adversarial loss: 0.520216\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618333; batch adversarial loss: 0.348063\n",
      "epoch 8; iter: 200; batch classifier loss: 0.680738; batch adversarial loss: 0.337522\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545671; batch adversarial loss: 0.275742\n",
      "epoch 9; iter: 200; batch classifier loss: 0.460371; batch adversarial loss: 0.421058\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 45.300182; batch adversarial loss: 0.866608\n",
      "epoch 0; iter: 200; batch classifier loss: 8.064039; batch adversarial loss: 0.776100\n",
      "epoch 1; iter: 0; batch classifier loss: 16.162336; batch adversarial loss: 0.690143\n",
      "epoch 1; iter: 200; batch classifier loss: 41.795006; batch adversarial loss: 0.580175\n",
      "epoch 2; iter: 0; batch classifier loss: 2.711399; batch adversarial loss: 0.520455\n",
      "epoch 2; iter: 200; batch classifier loss: 2.027040; batch adversarial loss: 0.481771\n",
      "epoch 3; iter: 0; batch classifier loss: 2.548412; batch adversarial loss: 0.519801\n",
      "epoch 3; iter: 200; batch classifier loss: 14.807291; batch adversarial loss: 0.428108\n",
      "epoch 4; iter: 0; batch classifier loss: 1.988494; batch adversarial loss: 0.421233\n",
      "epoch 4; iter: 200; batch classifier loss: 1.201817; batch adversarial loss: 0.477258\n",
      "epoch 5; iter: 0; batch classifier loss: 1.606681; batch adversarial loss: 0.444895\n",
      "epoch 5; iter: 200; batch classifier loss: 0.932690; batch adversarial loss: 0.485973\n",
      "epoch 6; iter: 0; batch classifier loss: 1.092419; batch adversarial loss: 0.467517\n",
      "epoch 6; iter: 200; batch classifier loss: 0.583279; batch adversarial loss: 0.412637\n",
      "epoch 7; iter: 0; batch classifier loss: 0.428194; batch adversarial loss: 0.418172\n",
      "epoch 7; iter: 200; batch classifier loss: 0.508902; batch adversarial loss: 0.428536\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464642; batch adversarial loss: 0.383835\n",
      "epoch 8; iter: 200; batch classifier loss: 0.516773; batch adversarial loss: 0.421632\n",
      "epoch 9; iter: 0; batch classifier loss: 0.433633; batch adversarial loss: 0.388078\n",
      "epoch 9; iter: 200; batch classifier loss: 0.467772; batch adversarial loss: 0.423369\n",
      "epoch 10; iter: 0; batch classifier loss: 0.446175; batch adversarial loss: 0.467335\n",
      "epoch 10; iter: 200; batch classifier loss: 0.387933; batch adversarial loss: 0.411092\n",
      "epoch 11; iter: 0; batch classifier loss: 0.710079; batch adversarial loss: 0.504668\n",
      "epoch 11; iter: 200; batch classifier loss: 0.413990; batch adversarial loss: 0.401029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430634; batch adversarial loss: 0.352461\n",
      "epoch 12; iter: 200; batch classifier loss: 0.600354; batch adversarial loss: 0.349172\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448493; batch adversarial loss: 0.424428\n",
      "epoch 13; iter: 200; batch classifier loss: 0.412619; batch adversarial loss: 0.411002\n",
      "epoch 14; iter: 0; batch classifier loss: 0.336422; batch adversarial loss: 0.330681\n",
      "epoch 14; iter: 200; batch classifier loss: 0.385527; batch adversarial loss: 0.492241\n",
      "epoch 15; iter: 0; batch classifier loss: 0.283361; batch adversarial loss: 0.378702\n",
      "epoch 15; iter: 200; batch classifier loss: 0.399265; batch adversarial loss: 0.373515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387194; batch adversarial loss: 0.458097\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388816; batch adversarial loss: 0.436027\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333013; batch adversarial loss: 0.421693\n",
      "epoch 17; iter: 200; batch classifier loss: 0.436516; batch adversarial loss: 0.416461\n",
      "epoch 18; iter: 0; batch classifier loss: 0.355753; batch adversarial loss: 0.422393\n",
      "epoch 18; iter: 200; batch classifier loss: 0.302636; batch adversarial loss: 0.377973\n",
      "epoch 19; iter: 0; batch classifier loss: 0.310288; batch adversarial loss: 0.410639\n",
      "epoch 19; iter: 200; batch classifier loss: 0.343776; batch adversarial loss: 0.347232\n",
      "epoch 0; iter: 0; batch classifier loss: 3.758220; batch adversarial loss: 0.641686\n",
      "epoch 0; iter: 200; batch classifier loss: 10.089824; batch adversarial loss: 0.631857\n",
      "epoch 1; iter: 0; batch classifier loss: 7.704450; batch adversarial loss: 0.588936\n",
      "epoch 1; iter: 200; batch classifier loss: 2.586359; batch adversarial loss: 0.573057\n",
      "epoch 2; iter: 0; batch classifier loss: 2.744210; batch adversarial loss: 0.570528\n",
      "epoch 2; iter: 200; batch classifier loss: 4.333770; batch adversarial loss: 0.521711\n",
      "epoch 3; iter: 0; batch classifier loss: 3.258611; batch adversarial loss: 0.460285\n",
      "epoch 3; iter: 200; batch classifier loss: 4.415334; batch adversarial loss: 0.461399\n",
      "epoch 4; iter: 0; batch classifier loss: 3.346973; batch adversarial loss: 0.512850\n",
      "epoch 4; iter: 200; batch classifier loss: 1.458921; batch adversarial loss: 0.381031\n",
      "epoch 5; iter: 0; batch classifier loss: 1.582866; batch adversarial loss: 0.492834\n",
      "epoch 5; iter: 200; batch classifier loss: 0.565922; batch adversarial loss: 0.414038\n",
      "epoch 6; iter: 0; batch classifier loss: 1.748542; batch adversarial loss: 0.478070\n",
      "epoch 6; iter: 200; batch classifier loss: 1.495928; batch adversarial loss: 0.529922\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611377; batch adversarial loss: 0.468015\n",
      "epoch 7; iter: 200; batch classifier loss: 0.650592; batch adversarial loss: 0.458910\n",
      "epoch 8; iter: 0; batch classifier loss: 0.494194; batch adversarial loss: 0.404962\n",
      "epoch 8; iter: 200; batch classifier loss: 0.536639; batch adversarial loss: 0.423697\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392599; batch adversarial loss: 0.393524\n",
      "epoch 9; iter: 200; batch classifier loss: 0.536435; batch adversarial loss: 0.448613\n",
      "epoch 10; iter: 0; batch classifier loss: 0.453910; batch adversarial loss: 0.372155\n",
      "epoch 10; iter: 200; batch classifier loss: 0.542024; batch adversarial loss: 0.430202\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428402; batch adversarial loss: 0.327735\n",
      "epoch 11; iter: 200; batch classifier loss: 0.415911; batch adversarial loss: 0.469734\n",
      "epoch 12; iter: 0; batch classifier loss: 0.421796; batch adversarial loss: 0.380706\n",
      "epoch 12; iter: 200; batch classifier loss: 0.429293; batch adversarial loss: 0.391184\n",
      "epoch 13; iter: 0; batch classifier loss: 0.322869; batch adversarial loss: 0.373258\n",
      "epoch 13; iter: 200; batch classifier loss: 0.454945; batch adversarial loss: 0.373581\n",
      "epoch 14; iter: 0; batch classifier loss: 0.581956; batch adversarial loss: 0.417412\n",
      "epoch 14; iter: 200; batch classifier loss: 0.391570; batch adversarial loss: 0.413211\n",
      "epoch 15; iter: 0; batch classifier loss: 0.405947; batch adversarial loss: 0.407226\n",
      "epoch 15; iter: 200; batch classifier loss: 0.356657; batch adversarial loss: 0.473346\n",
      "epoch 16; iter: 0; batch classifier loss: 0.397813; batch adversarial loss: 0.473539\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388139; batch adversarial loss: 0.419298\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330822; batch adversarial loss: 0.327690\n",
      "epoch 17; iter: 200; batch classifier loss: 0.434255; batch adversarial loss: 0.458535\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358678; batch adversarial loss: 0.448566\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371952; batch adversarial loss: 0.360829\n",
      "epoch 19; iter: 0; batch classifier loss: 0.320530; batch adversarial loss: 0.490959\n",
      "epoch 19; iter: 200; batch classifier loss: 0.353023; batch adversarial loss: 0.439428\n",
      "epoch 0; iter: 0; batch classifier loss: 24.880566; batch adversarial loss: 0.591077\n",
      "epoch 0; iter: 200; batch classifier loss: 5.893091; batch adversarial loss: 0.617999\n",
      "epoch 1; iter: 0; batch classifier loss: 3.918543; batch adversarial loss: 0.579856\n",
      "epoch 1; iter: 200; batch classifier loss: 9.635810; batch adversarial loss: 0.569273\n",
      "epoch 2; iter: 0; batch classifier loss: 4.754314; batch adversarial loss: 0.530205\n",
      "epoch 2; iter: 200; batch classifier loss: 3.889106; batch adversarial loss: 0.494765\n",
      "epoch 3; iter: 0; batch classifier loss: 4.565015; batch adversarial loss: 0.442434\n",
      "epoch 3; iter: 200; batch classifier loss: 1.911048; batch adversarial loss: 0.454493\n",
      "epoch 4; iter: 0; batch classifier loss: 3.452906; batch adversarial loss: 0.448468\n",
      "epoch 4; iter: 200; batch classifier loss: 1.495654; batch adversarial loss: 0.391228\n",
      "epoch 5; iter: 0; batch classifier loss: 3.358283; batch adversarial loss: 0.530625\n",
      "epoch 5; iter: 200; batch classifier loss: 1.975119; batch adversarial loss: 0.376515\n",
      "epoch 6; iter: 0; batch classifier loss: 0.679175; batch adversarial loss: 0.460066\n",
      "epoch 6; iter: 200; batch classifier loss: 1.165506; batch adversarial loss: 0.410464\n",
      "epoch 7; iter: 0; batch classifier loss: 0.478630; batch adversarial loss: 0.451171\n",
      "epoch 7; iter: 200; batch classifier loss: 0.845246; batch adversarial loss: 0.553589\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426879; batch adversarial loss: 0.381035\n",
      "epoch 8; iter: 200; batch classifier loss: 0.367620; batch adversarial loss: 0.460334\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500509; batch adversarial loss: 0.581170\n",
      "epoch 9; iter: 200; batch classifier loss: 0.429877; batch adversarial loss: 0.393309\n",
      "epoch 10; iter: 0; batch classifier loss: 0.475164; batch adversarial loss: 0.374576\n",
      "epoch 10; iter: 200; batch classifier loss: 0.427575; batch adversarial loss: 0.448924\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345364; batch adversarial loss: 0.492669\n",
      "epoch 11; iter: 200; batch classifier loss: 0.436118; batch adversarial loss: 0.412853\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553013; batch adversarial loss: 0.479079\n",
      "epoch 12; iter: 200; batch classifier loss: 0.499749; batch adversarial loss: 0.415033\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339563; batch adversarial loss: 0.441001\n",
      "epoch 13; iter: 200; batch classifier loss: 0.376817; batch adversarial loss: 0.389976\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360920; batch adversarial loss: 0.347728\n",
      "epoch 14; iter: 200; batch classifier loss: 0.391049; batch adversarial loss: 0.399698\n",
      "epoch 15; iter: 0; batch classifier loss: 0.417065; batch adversarial loss: 0.378667\n",
      "epoch 15; iter: 200; batch classifier loss: 0.281852; batch adversarial loss: 0.438862\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323871; batch adversarial loss: 0.370112\n",
      "epoch 16; iter: 200; batch classifier loss: 0.371642; batch adversarial loss: 0.372088\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420564; batch adversarial loss: 0.439245\n",
      "epoch 17; iter: 200; batch classifier loss: 0.332403; batch adversarial loss: 0.429139\n",
      "epoch 18; iter: 0; batch classifier loss: 0.344624; batch adversarial loss: 0.330745\n",
      "epoch 18; iter: 200; batch classifier loss: 0.273961; batch adversarial loss: 0.431324\n",
      "epoch 19; iter: 0; batch classifier loss: 0.318846; batch adversarial loss: 0.390970\n",
      "epoch 19; iter: 200; batch classifier loss: 0.420022; batch adversarial loss: 0.440684\n",
      "epoch 0; iter: 0; batch classifier loss: 37.834164; batch adversarial loss: 0.849565\n",
      "epoch 0; iter: 200; batch classifier loss: 11.121993; batch adversarial loss: 0.732355\n",
      "epoch 1; iter: 0; batch classifier loss: 6.454958; batch adversarial loss: 0.684737\n",
      "epoch 1; iter: 200; batch classifier loss: 6.085695; batch adversarial loss: 0.573324\n",
      "epoch 2; iter: 0; batch classifier loss: 2.879661; batch adversarial loss: 0.569730\n",
      "epoch 2; iter: 200; batch classifier loss: 6.038377; batch adversarial loss: 0.493133\n",
      "epoch 3; iter: 0; batch classifier loss: 2.345894; batch adversarial loss: 0.519133\n",
      "epoch 3; iter: 200; batch classifier loss: 1.281464; batch adversarial loss: 0.491726\n",
      "epoch 4; iter: 0; batch classifier loss: 1.295725; batch adversarial loss: 0.488057\n",
      "epoch 4; iter: 200; batch classifier loss: 0.841311; batch adversarial loss: 0.511013\n",
      "epoch 5; iter: 0; batch classifier loss: 1.632382; batch adversarial loss: 0.512737\n",
      "epoch 5; iter: 200; batch classifier loss: 0.725116; batch adversarial loss: 0.466954\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521846; batch adversarial loss: 0.455789\n",
      "epoch 6; iter: 200; batch classifier loss: 0.732378; batch adversarial loss: 0.430977\n",
      "epoch 7; iter: 0; batch classifier loss: 0.818492; batch adversarial loss: 0.402126\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416342; batch adversarial loss: 0.423055\n",
      "epoch 8; iter: 0; batch classifier loss: 0.353496; batch adversarial loss: 0.400608\n",
      "epoch 8; iter: 200; batch classifier loss: 0.355560; batch adversarial loss: 0.442844\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516271; batch adversarial loss: 0.449653\n",
      "epoch 9; iter: 200; batch classifier loss: 0.617768; batch adversarial loss: 0.344462\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472008; batch adversarial loss: 0.411467\n",
      "epoch 10; iter: 200; batch classifier loss: 0.468353; batch adversarial loss: 0.421205\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420486; batch adversarial loss: 0.484086\n",
      "epoch 11; iter: 200; batch classifier loss: 0.437092; batch adversarial loss: 0.450128\n",
      "epoch 12; iter: 0; batch classifier loss: 0.299327; batch adversarial loss: 0.407227\n",
      "epoch 12; iter: 200; batch classifier loss: 0.600720; batch adversarial loss: 0.419028\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361013; batch adversarial loss: 0.470297\n",
      "epoch 13; iter: 200; batch classifier loss: 0.366212; batch adversarial loss: 0.365223\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292807; batch adversarial loss: 0.320605\n",
      "epoch 14; iter: 200; batch classifier loss: 0.463830; batch adversarial loss: 0.401461\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386289; batch adversarial loss: 0.436008\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380411; batch adversarial loss: 0.468721\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370451; batch adversarial loss: 0.445904\n",
      "epoch 16; iter: 200; batch classifier loss: 0.369996; batch adversarial loss: 0.412299\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371917; batch adversarial loss: 0.385221\n",
      "epoch 17; iter: 200; batch classifier loss: 0.368322; batch adversarial loss: 0.450805\n",
      "epoch 18; iter: 0; batch classifier loss: 0.271072; batch adversarial loss: 0.345618\n",
      "epoch 18; iter: 200; batch classifier loss: 0.353230; batch adversarial loss: 0.356353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.285255; batch adversarial loss: 0.380526\n",
      "epoch 19; iter: 200; batch classifier loss: 0.395968; batch adversarial loss: 0.388072\n",
      "epoch 0; iter: 0; batch classifier loss: 41.981781; batch adversarial loss: 0.496404\n",
      "epoch 0; iter: 200; batch classifier loss: 5.919268; batch adversarial loss: 0.618691\n",
      "epoch 1; iter: 0; batch classifier loss: 9.750797; batch adversarial loss: 0.523274\n",
      "epoch 1; iter: 200; batch classifier loss: 3.433486; batch adversarial loss: 0.523917\n",
      "epoch 2; iter: 0; batch classifier loss: 2.738503; batch adversarial loss: 0.536462\n",
      "epoch 2; iter: 200; batch classifier loss: 4.546409; batch adversarial loss: 0.462708\n",
      "epoch 3; iter: 0; batch classifier loss: 4.336199; batch adversarial loss: 0.541337\n",
      "epoch 3; iter: 200; batch classifier loss: 1.916737; batch adversarial loss: 0.438243\n",
      "epoch 4; iter: 0; batch classifier loss: 1.304126; batch adversarial loss: 0.460569\n",
      "epoch 4; iter: 200; batch classifier loss: 1.382282; batch adversarial loss: 0.462123\n",
      "epoch 5; iter: 0; batch classifier loss: 1.493635; batch adversarial loss: 0.464636\n",
      "epoch 5; iter: 200; batch classifier loss: 1.436941; batch adversarial loss: 0.419799\n",
      "epoch 6; iter: 0; batch classifier loss: 1.191592; batch adversarial loss: 0.380591\n",
      "epoch 6; iter: 200; batch classifier loss: 1.210932; batch adversarial loss: 0.478455\n",
      "epoch 7; iter: 0; batch classifier loss: 1.041472; batch adversarial loss: 0.429960\n",
      "epoch 7; iter: 200; batch classifier loss: 0.465310; batch adversarial loss: 0.549308\n",
      "epoch 8; iter: 0; batch classifier loss: 1.549734; batch adversarial loss: 0.383765\n",
      "epoch 8; iter: 200; batch classifier loss: 0.385818; batch adversarial loss: 0.420895\n",
      "epoch 9; iter: 0; batch classifier loss: 0.708223; batch adversarial loss: 0.359849\n",
      "epoch 9; iter: 200; batch classifier loss: 0.448910; batch adversarial loss: 0.446120\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510785; batch adversarial loss: 0.336197\n",
      "epoch 10; iter: 200; batch classifier loss: 0.696319; batch adversarial loss: 0.378744\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496603; batch adversarial loss: 0.452856\n",
      "epoch 11; iter: 200; batch classifier loss: 0.327804; batch adversarial loss: 0.483748\n",
      "epoch 12; iter: 0; batch classifier loss: 0.403993; batch adversarial loss: 0.428827\n",
      "epoch 12; iter: 200; batch classifier loss: 0.515971; batch adversarial loss: 0.382951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374559; batch adversarial loss: 0.297786\n",
      "epoch 13; iter: 200; batch classifier loss: 0.347267; batch adversarial loss: 0.415810\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437992; batch adversarial loss: 0.359237\n",
      "epoch 14; iter: 200; batch classifier loss: 0.386489; batch adversarial loss: 0.522629\n",
      "epoch 15; iter: 0; batch classifier loss: 0.325780; batch adversarial loss: 0.429741\n",
      "epoch 15; iter: 200; batch classifier loss: 0.425379; batch adversarial loss: 0.463068\n",
      "epoch 16; iter: 0; batch classifier loss: 0.515008; batch adversarial loss: 0.318885\n",
      "epoch 16; iter: 200; batch classifier loss: 0.355136; batch adversarial loss: 0.443307\n",
      "epoch 17; iter: 0; batch classifier loss: 0.380800; batch adversarial loss: 0.323228\n",
      "epoch 17; iter: 200; batch classifier loss: 0.395109; batch adversarial loss: 0.430717\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317038; batch adversarial loss: 0.448506\n",
      "epoch 18; iter: 200; batch classifier loss: 0.371565; batch adversarial loss: 0.418934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.428564; batch adversarial loss: 0.414089\n",
      "epoch 19; iter: 200; batch classifier loss: 0.352511; batch adversarial loss: 0.332561\n",
      "epoch 0; iter: 0; batch classifier loss: 24.927980; batch adversarial loss: 1.187937\n",
      "epoch 0; iter: 200; batch classifier loss: 3.967824; batch adversarial loss: 1.306334\n",
      "epoch 1; iter: 0; batch classifier loss: 24.573889; batch adversarial loss: 1.180508\n",
      "epoch 1; iter: 200; batch classifier loss: 3.940194; batch adversarial loss: 0.933515\n",
      "epoch 2; iter: 0; batch classifier loss: 4.958938; batch adversarial loss: 0.755136\n",
      "epoch 2; iter: 200; batch classifier loss: 5.091221; batch adversarial loss: 0.641918\n",
      "epoch 3; iter: 0; batch classifier loss: 2.764046; batch adversarial loss: 0.602227\n",
      "epoch 3; iter: 200; batch classifier loss: 2.075303; batch adversarial loss: 0.551741\n",
      "epoch 4; iter: 0; batch classifier loss: 2.246018; batch adversarial loss: 0.482422\n",
      "epoch 4; iter: 200; batch classifier loss: 2.146584; batch adversarial loss: 0.475281\n",
      "epoch 5; iter: 0; batch classifier loss: 1.725515; batch adversarial loss: 0.446575\n",
      "epoch 5; iter: 200; batch classifier loss: 2.997354; batch adversarial loss: 0.515624\n",
      "epoch 6; iter: 0; batch classifier loss: 3.320178; batch adversarial loss: 0.416707\n",
      "epoch 6; iter: 200; batch classifier loss: 0.778152; batch adversarial loss: 0.442531\n",
      "epoch 7; iter: 0; batch classifier loss: 0.747256; batch adversarial loss: 0.471670\n",
      "epoch 7; iter: 200; batch classifier loss: 1.107090; batch adversarial loss: 0.415114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.733980; batch adversarial loss: 0.422822\n",
      "epoch 8; iter: 200; batch classifier loss: 0.691616; batch adversarial loss: 0.361930\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527429; batch adversarial loss: 0.484135\n",
      "epoch 9; iter: 200; batch classifier loss: 0.596495; batch adversarial loss: 0.367145\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528801; batch adversarial loss: 0.411170\n",
      "epoch 10; iter: 200; batch classifier loss: 0.882221; batch adversarial loss: 0.360368\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464588; batch adversarial loss: 0.530830\n",
      "epoch 11; iter: 200; batch classifier loss: 0.453723; batch adversarial loss: 0.354743\n",
      "epoch 12; iter: 0; batch classifier loss: 0.447345; batch adversarial loss: 0.380753\n",
      "epoch 12; iter: 200; batch classifier loss: 0.409548; batch adversarial loss: 0.509729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.303177; batch adversarial loss: 0.366453\n",
      "epoch 13; iter: 200; batch classifier loss: 0.467212; batch adversarial loss: 0.323282\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342309; batch adversarial loss: 0.325176\n",
      "epoch 14; iter: 200; batch classifier loss: 0.452915; batch adversarial loss: 0.343713\n",
      "epoch 15; iter: 0; batch classifier loss: 0.300323; batch adversarial loss: 0.386991\n",
      "epoch 15; iter: 200; batch classifier loss: 0.399969; batch adversarial loss: 0.541633\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324722; batch adversarial loss: 0.388695\n",
      "epoch 16; iter: 200; batch classifier loss: 0.424031; batch adversarial loss: 0.529569\n",
      "epoch 17; iter: 0; batch classifier loss: 0.358181; batch adversarial loss: 0.397071\n",
      "epoch 17; iter: 200; batch classifier loss: 0.324025; batch adversarial loss: 0.480748\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482129; batch adversarial loss: 0.401061\n",
      "epoch 18; iter: 200; batch classifier loss: 0.444927; batch adversarial loss: 0.335411\n",
      "epoch 19; iter: 0; batch classifier loss: 0.429069; batch adversarial loss: 0.436872\n",
      "epoch 19; iter: 200; batch classifier loss: 0.312070; batch adversarial loss: 0.403442\n",
      "epoch 0; iter: 0; batch classifier loss: 4.561550; batch adversarial loss: 0.938211\n",
      "epoch 0; iter: 200; batch classifier loss: 4.880687; batch adversarial loss: 0.766759\n",
      "epoch 1; iter: 0; batch classifier loss: 10.896848; batch adversarial loss: 0.703294\n",
      "epoch 1; iter: 200; batch classifier loss: 8.525326; batch adversarial loss: 0.589616\n",
      "epoch 2; iter: 0; batch classifier loss: 4.664865; batch adversarial loss: 0.533650\n",
      "epoch 2; iter: 200; batch classifier loss: 2.561548; batch adversarial loss: 0.550538\n",
      "epoch 3; iter: 0; batch classifier loss: 3.063468; batch adversarial loss: 0.464509\n",
      "epoch 3; iter: 200; batch classifier loss: 3.934878; batch adversarial loss: 0.491756\n",
      "epoch 4; iter: 0; batch classifier loss: 0.419432; batch adversarial loss: 0.485781\n",
      "epoch 4; iter: 200; batch classifier loss: 1.955718; batch adversarial loss: 0.431975\n",
      "epoch 5; iter: 0; batch classifier loss: 1.338231; batch adversarial loss: 0.471503\n",
      "epoch 5; iter: 200; batch classifier loss: 1.602842; batch adversarial loss: 0.456973\n",
      "epoch 6; iter: 0; batch classifier loss: 0.884288; batch adversarial loss: 0.383179\n",
      "epoch 6; iter: 200; batch classifier loss: 0.530305; batch adversarial loss: 0.402340\n",
      "epoch 7; iter: 0; batch classifier loss: 0.489327; batch adversarial loss: 0.443419\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416915; batch adversarial loss: 0.401795\n",
      "epoch 8; iter: 0; batch classifier loss: 0.459003; batch adversarial loss: 0.402872\n",
      "epoch 8; iter: 200; batch classifier loss: 0.372456; batch adversarial loss: 0.411734\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548110; batch adversarial loss: 0.363983\n",
      "epoch 9; iter: 200; batch classifier loss: 0.421693; batch adversarial loss: 0.495447\n",
      "epoch 10; iter: 0; batch classifier loss: 0.597252; batch adversarial loss: 0.382431\n",
      "epoch 10; iter: 200; batch classifier loss: 0.645465; batch adversarial loss: 0.359879\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465033; batch adversarial loss: 0.416391\n",
      "epoch 11; iter: 200; batch classifier loss: 0.539250; batch adversarial loss: 0.425496\n",
      "epoch 12; iter: 0; batch classifier loss: 0.406366; batch adversarial loss: 0.434900\n",
      "epoch 12; iter: 200; batch classifier loss: 0.440834; batch adversarial loss: 0.404351\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392296; batch adversarial loss: 0.382804\n",
      "epoch 13; iter: 200; batch classifier loss: 0.411559; batch adversarial loss: 0.375140\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351637; batch adversarial loss: 0.371287\n",
      "epoch 14; iter: 200; batch classifier loss: 0.371340; batch adversarial loss: 0.413190\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322119; batch adversarial loss: 0.439402\n",
      "epoch 15; iter: 200; batch classifier loss: 0.305259; batch adversarial loss: 0.505078\n",
      "epoch 16; iter: 0; batch classifier loss: 0.412419; batch adversarial loss: 0.447230\n",
      "epoch 16; iter: 200; batch classifier loss: 0.345259; batch adversarial loss: 0.529255\n",
      "epoch 17; iter: 0; batch classifier loss: 0.419881; batch adversarial loss: 0.393139\n",
      "epoch 17; iter: 200; batch classifier loss: 0.354477; batch adversarial loss: 0.287298\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391263; batch adversarial loss: 0.468814\n",
      "epoch 18; iter: 200; batch classifier loss: 0.349707; batch adversarial loss: 0.411853\n",
      "epoch 19; iter: 0; batch classifier loss: 0.367123; batch adversarial loss: 0.426712\n",
      "epoch 19; iter: 200; batch classifier loss: 0.302080; batch adversarial loss: 0.436505\n",
      "epoch 0; iter: 0; batch classifier loss: 16.426973; batch adversarial loss: 0.565497\n",
      "epoch 0; iter: 200; batch classifier loss: 4.469554; batch adversarial loss: 0.609474\n",
      "epoch 1; iter: 0; batch classifier loss: 4.273008; batch adversarial loss: 0.558437\n",
      "epoch 1; iter: 200; batch classifier loss: 4.271564; batch adversarial loss: 0.541535\n",
      "epoch 2; iter: 0; batch classifier loss: 3.182996; batch adversarial loss: 0.508208\n",
      "epoch 2; iter: 200; batch classifier loss: 1.321865; batch adversarial loss: 0.481855\n",
      "epoch 3; iter: 0; batch classifier loss: 1.603333; batch adversarial loss: 0.475525\n",
      "epoch 3; iter: 200; batch classifier loss: 5.729897; batch adversarial loss: 0.472825\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562203; batch adversarial loss: 0.481481\n",
      "epoch 4; iter: 200; batch classifier loss: 1.365012; batch adversarial loss: 0.476460\n",
      "epoch 5; iter: 0; batch classifier loss: 2.151204; batch adversarial loss: 0.398878\n",
      "epoch 5; iter: 200; batch classifier loss: 1.520591; batch adversarial loss: 0.335135\n",
      "epoch 6; iter: 0; batch classifier loss: 1.995858; batch adversarial loss: 0.477902\n",
      "epoch 6; iter: 200; batch classifier loss: 0.656504; batch adversarial loss: 0.469333\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578145; batch adversarial loss: 0.460355\n",
      "epoch 7; iter: 200; batch classifier loss: 0.661449; batch adversarial loss: 0.359241\n",
      "epoch 8; iter: 0; batch classifier loss: 0.735279; batch adversarial loss: 0.441245\n",
      "epoch 8; iter: 200; batch classifier loss: 0.473210; batch adversarial loss: 0.395985\n",
      "epoch 9; iter: 0; batch classifier loss: 0.391179; batch adversarial loss: 0.616569\n",
      "epoch 9; iter: 200; batch classifier loss: 0.543455; batch adversarial loss: 0.395482\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414032; batch adversarial loss: 0.377941\n",
      "epoch 10; iter: 200; batch classifier loss: 0.403449; batch adversarial loss: 0.409321\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538532; batch adversarial loss: 0.455343\n",
      "epoch 11; iter: 200; batch classifier loss: 0.346660; batch adversarial loss: 0.384249\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428074; batch adversarial loss: 0.298715\n",
      "epoch 12; iter: 200; batch classifier loss: 0.284147; batch adversarial loss: 0.413453\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429519; batch adversarial loss: 0.441140\n",
      "epoch 13; iter: 200; batch classifier loss: 0.370875; batch adversarial loss: 0.361320\n",
      "epoch 14; iter: 0; batch classifier loss: 0.385620; batch adversarial loss: 0.372327\n",
      "epoch 14; iter: 200; batch classifier loss: 0.695719; batch adversarial loss: 0.409512\n",
      "epoch 15; iter: 0; batch classifier loss: 0.465886; batch adversarial loss: 0.381417\n",
      "epoch 15; iter: 200; batch classifier loss: 0.412017; batch adversarial loss: 0.402731\n",
      "epoch 16; iter: 0; batch classifier loss: 0.406549; batch adversarial loss: 0.454423\n",
      "epoch 16; iter: 200; batch classifier loss: 0.355578; batch adversarial loss: 0.386295\n",
      "epoch 17; iter: 0; batch classifier loss: 0.333445; batch adversarial loss: 0.403897\n",
      "epoch 17; iter: 200; batch classifier loss: 0.313115; batch adversarial loss: 0.511297\n",
      "epoch 18; iter: 0; batch classifier loss: 0.357513; batch adversarial loss: 0.343558\n",
      "epoch 18; iter: 200; batch classifier loss: 0.269434; batch adversarial loss: 0.414498\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301480; batch adversarial loss: 0.496092\n",
      "epoch 19; iter: 200; batch classifier loss: 0.295624; batch adversarial loss: 0.361820\n",
      "epoch 0; iter: 0; batch classifier loss: 21.176939; batch adversarial loss: 0.888093\n",
      "epoch 0; iter: 200; batch classifier loss: 5.016347; batch adversarial loss: 0.690773\n",
      "epoch 1; iter: 0; batch classifier loss: 14.707233; batch adversarial loss: 0.638422\n",
      "epoch 1; iter: 200; batch classifier loss: 3.017513; batch adversarial loss: 0.561951\n",
      "epoch 2; iter: 0; batch classifier loss: 6.793592; batch adversarial loss: 0.504812\n",
      "epoch 2; iter: 200; batch classifier loss: 3.308348; batch adversarial loss: 0.535420\n",
      "epoch 3; iter: 0; batch classifier loss: 5.813737; batch adversarial loss: 0.515080\n",
      "epoch 3; iter: 200; batch classifier loss: 3.512388; batch adversarial loss: 0.457594\n",
      "epoch 4; iter: 0; batch classifier loss: 2.598517; batch adversarial loss: 0.507539\n",
      "epoch 4; iter: 200; batch classifier loss: 3.092088; batch adversarial loss: 0.426744\n",
      "epoch 5; iter: 0; batch classifier loss: 2.729181; batch adversarial loss: 0.474226\n",
      "epoch 5; iter: 200; batch classifier loss: 2.866834; batch adversarial loss: 0.367560\n",
      "epoch 6; iter: 0; batch classifier loss: 1.040755; batch adversarial loss: 0.518746\n",
      "epoch 6; iter: 200; batch classifier loss: 0.527391; batch adversarial loss: 0.398335\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640824; batch adversarial loss: 0.403179\n",
      "epoch 7; iter: 200; batch classifier loss: 0.760228; batch adversarial loss: 0.449774\n",
      "epoch 8; iter: 0; batch classifier loss: 1.091681; batch adversarial loss: 0.402741\n",
      "epoch 8; iter: 200; batch classifier loss: 1.809251; batch adversarial loss: 0.454633\n",
      "epoch 9; iter: 0; batch classifier loss: 0.660802; batch adversarial loss: 0.304462\n",
      "epoch 9; iter: 200; batch classifier loss: 0.619636; batch adversarial loss: 0.411253\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339072; batch adversarial loss: 0.364838\n",
      "epoch 10; iter: 200; batch classifier loss: 0.507242; batch adversarial loss: 0.351691\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429163; batch adversarial loss: 0.353158\n",
      "epoch 11; iter: 200; batch classifier loss: 0.389290; batch adversarial loss: 0.415365\n",
      "epoch 12; iter: 0; batch classifier loss: 0.485710; batch adversarial loss: 0.358201\n",
      "epoch 12; iter: 200; batch classifier loss: 0.482938; batch adversarial loss: 0.318868\n",
      "epoch 13; iter: 0; batch classifier loss: 0.365168; batch adversarial loss: 0.432075\n",
      "epoch 13; iter: 200; batch classifier loss: 0.428200; batch adversarial loss: 0.328402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448947; batch adversarial loss: 0.470452\n",
      "epoch 14; iter: 200; batch classifier loss: 0.396421; batch adversarial loss: 0.371305\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390191; batch adversarial loss: 0.449935\n",
      "epoch 15; iter: 200; batch classifier loss: 0.413013; batch adversarial loss: 0.494626\n",
      "epoch 16; iter: 0; batch classifier loss: 0.431821; batch adversarial loss: 0.457426\n",
      "epoch 16; iter: 200; batch classifier loss: 0.337653; batch adversarial loss: 0.421309\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357851; batch adversarial loss: 0.316471\n",
      "epoch 17; iter: 200; batch classifier loss: 0.322593; batch adversarial loss: 0.451348\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442601; batch adversarial loss: 0.369762\n",
      "epoch 18; iter: 200; batch classifier loss: 0.361924; batch adversarial loss: 0.403857\n",
      "epoch 19; iter: 0; batch classifier loss: 0.460498; batch adversarial loss: 0.346851\n",
      "epoch 19; iter: 200; batch classifier loss: 0.330377; batch adversarial loss: 0.376231\n",
      "epoch 0; iter: 0; batch classifier loss: 3.781137; batch adversarial loss: 0.568746\n",
      "epoch 0; iter: 200; batch classifier loss: 15.785362; batch adversarial loss: 0.591060\n",
      "epoch 1; iter: 0; batch classifier loss: 4.346637; batch adversarial loss: 0.590515\n",
      "epoch 1; iter: 200; batch classifier loss: 4.638001; batch adversarial loss: 0.540218\n",
      "epoch 2; iter: 0; batch classifier loss: 5.387337; batch adversarial loss: 0.485299\n",
      "epoch 2; iter: 200; batch classifier loss: 3.484387; batch adversarial loss: 0.423888\n",
      "epoch 3; iter: 0; batch classifier loss: 5.931968; batch adversarial loss: 0.472156\n",
      "epoch 3; iter: 200; batch classifier loss: 2.595126; batch adversarial loss: 0.413681\n",
      "epoch 4; iter: 0; batch classifier loss: 3.925674; batch adversarial loss: 0.390110\n",
      "epoch 4; iter: 200; batch classifier loss: 1.233623; batch adversarial loss: 0.531197\n",
      "epoch 5; iter: 0; batch classifier loss: 1.945665; batch adversarial loss: 0.497794\n",
      "epoch 5; iter: 200; batch classifier loss: 0.733006; batch adversarial loss: 0.418235\n",
      "epoch 6; iter: 0; batch classifier loss: 0.720672; batch adversarial loss: 0.349676\n",
      "epoch 6; iter: 200; batch classifier loss: 1.340457; batch adversarial loss: 0.397682\n",
      "epoch 7; iter: 0; batch classifier loss: 0.703606; batch adversarial loss: 0.423866\n",
      "epoch 7; iter: 200; batch classifier loss: 0.960956; batch adversarial loss: 0.381151\n",
      "epoch 8; iter: 0; batch classifier loss: 0.623089; batch adversarial loss: 0.417011\n",
      "epoch 8; iter: 200; batch classifier loss: 0.747838; batch adversarial loss: 0.314457\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503099; batch adversarial loss: 0.420653\n",
      "epoch 9; iter: 200; batch classifier loss: 0.613630; batch adversarial loss: 0.314501\n",
      "epoch 10; iter: 0; batch classifier loss: 0.396387; batch adversarial loss: 0.356260\n",
      "epoch 10; iter: 200; batch classifier loss: 0.416469; batch adversarial loss: 0.491837\n",
      "epoch 11; iter: 0; batch classifier loss: 0.628778; batch adversarial loss: 0.385840\n",
      "epoch 11; iter: 200; batch classifier loss: 0.345761; batch adversarial loss: 0.473003\n",
      "epoch 12; iter: 0; batch classifier loss: 0.395118; batch adversarial loss: 0.386487\n",
      "epoch 12; iter: 200; batch classifier loss: 0.480771; batch adversarial loss: 0.389807\n",
      "epoch 13; iter: 0; batch classifier loss: 0.446816; batch adversarial loss: 0.387485\n",
      "epoch 13; iter: 200; batch classifier loss: 0.377882; batch adversarial loss: 0.454526\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318376; batch adversarial loss: 0.463149\n",
      "epoch 14; iter: 200; batch classifier loss: 0.392751; batch adversarial loss: 0.437837\n",
      "epoch 15; iter: 0; batch classifier loss: 0.455464; batch adversarial loss: 0.455466\n",
      "epoch 15; iter: 200; batch classifier loss: 0.406883; batch adversarial loss: 0.445211\n",
      "epoch 16; iter: 0; batch classifier loss: 0.304666; batch adversarial loss: 0.448026\n",
      "epoch 16; iter: 200; batch classifier loss: 0.504476; batch adversarial loss: 0.516254\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365795; batch adversarial loss: 0.478772\n",
      "epoch 17; iter: 200; batch classifier loss: 0.359474; batch adversarial loss: 0.371722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.441322; batch adversarial loss: 0.570896\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326868; batch adversarial loss: 0.390350\n",
      "epoch 19; iter: 0; batch classifier loss: 0.370999; batch adversarial loss: 0.422404\n",
      "epoch 19; iter: 200; batch classifier loss: 0.285430; batch adversarial loss: 0.347344\n",
      "epoch 0; iter: 0; batch classifier loss: 81.275566; batch adversarial loss: 0.654333\n",
      "epoch 0; iter: 200; batch classifier loss: 4.642365; batch adversarial loss: 0.623874\n",
      "epoch 1; iter: 0; batch classifier loss: 9.415332; batch adversarial loss: 0.593403\n",
      "epoch 1; iter: 200; batch classifier loss: 0.878909; batch adversarial loss: 0.498819\n",
      "epoch 2; iter: 0; batch classifier loss: 9.449709; batch adversarial loss: 0.469435\n",
      "epoch 2; iter: 200; batch classifier loss: 9.413034; batch adversarial loss: 0.511929\n",
      "epoch 3; iter: 0; batch classifier loss: 3.357963; batch adversarial loss: 0.502074\n",
      "epoch 3; iter: 200; batch classifier loss: 4.299221; batch adversarial loss: 0.439652\n",
      "epoch 4; iter: 0; batch classifier loss: 4.629823; batch adversarial loss: 0.470136\n",
      "epoch 4; iter: 200; batch classifier loss: 0.905838; batch adversarial loss: 0.475336\n",
      "epoch 5; iter: 0; batch classifier loss: 2.757060; batch adversarial loss: 0.382460\n",
      "epoch 5; iter: 200; batch classifier loss: 0.772685; batch adversarial loss: 0.394847\n",
      "epoch 6; iter: 0; batch classifier loss: 1.330819; batch adversarial loss: 0.518401\n",
      "epoch 6; iter: 200; batch classifier loss: 0.691416; batch adversarial loss: 0.351677\n",
      "epoch 7; iter: 0; batch classifier loss: 0.779110; batch adversarial loss: 0.490242\n",
      "epoch 7; iter: 200; batch classifier loss: 1.798573; batch adversarial loss: 0.507649\n",
      "epoch 8; iter: 0; batch classifier loss: 0.905435; batch adversarial loss: 0.427724\n",
      "epoch 8; iter: 200; batch classifier loss: 0.389953; batch adversarial loss: 0.440925\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571599; batch adversarial loss: 0.344865\n",
      "epoch 9; iter: 200; batch classifier loss: 0.482839; batch adversarial loss: 0.287113\n",
      "epoch 10; iter: 0; batch classifier loss: 0.591061; batch adversarial loss: 0.357134\n",
      "epoch 10; iter: 200; batch classifier loss: 0.323120; batch adversarial loss: 0.406788\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578535; batch adversarial loss: 0.443644\n",
      "epoch 11; iter: 200; batch classifier loss: 0.564221; batch adversarial loss: 0.355913\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.343513\n",
      "epoch 12; iter: 200; batch classifier loss: 0.660756; batch adversarial loss: 0.375763\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431654; batch adversarial loss: 0.266292\n",
      "epoch 13; iter: 200; batch classifier loss: 0.417077; batch adversarial loss: 0.370341\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412446; batch adversarial loss: 0.417333\n",
      "epoch 14; iter: 200; batch classifier loss: 0.347643; batch adversarial loss: 0.460054\n",
      "epoch 15; iter: 0; batch classifier loss: 0.392239; batch adversarial loss: 0.435960\n",
      "epoch 15; iter: 200; batch classifier loss: 0.324825; batch adversarial loss: 0.402375\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358798; batch adversarial loss: 0.376689\n",
      "epoch 16; iter: 200; batch classifier loss: 0.319579; batch adversarial loss: 0.460427\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328898; batch adversarial loss: 0.430993\n",
      "epoch 17; iter: 200; batch classifier loss: 0.405245; batch adversarial loss: 0.402373\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370702; batch adversarial loss: 0.417535\n",
      "epoch 18; iter: 200; batch classifier loss: 0.314210; batch adversarial loss: 0.316997\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355941; batch adversarial loss: 0.458422\n",
      "epoch 19; iter: 200; batch classifier loss: 0.294351; batch adversarial loss: 0.364713\n",
      "epoch 0; iter: 0; batch classifier loss: 24.256943; batch adversarial loss: 0.659004\n",
      "epoch 0; iter: 200; batch classifier loss: 7.918498; batch adversarial loss: 0.627020\n",
      "epoch 1; iter: 0; batch classifier loss: 11.545220; batch adversarial loss: 0.591060\n",
      "epoch 1; iter: 200; batch classifier loss: 3.187757; batch adversarial loss: 0.551819\n",
      "epoch 2; iter: 0; batch classifier loss: 6.663342; batch adversarial loss: 0.531977\n",
      "epoch 2; iter: 200; batch classifier loss: 1.838106; batch adversarial loss: 0.519257\n",
      "epoch 3; iter: 0; batch classifier loss: 3.636373; batch adversarial loss: 0.497345\n",
      "epoch 3; iter: 200; batch classifier loss: 2.793071; batch adversarial loss: 0.420703\n",
      "epoch 4; iter: 0; batch classifier loss: 2.736752; batch adversarial loss: 0.477869\n",
      "epoch 4; iter: 200; batch classifier loss: 1.176345; batch adversarial loss: 0.444863\n",
      "epoch 5; iter: 0; batch classifier loss: 4.935412; batch adversarial loss: 0.451860\n",
      "epoch 5; iter: 200; batch classifier loss: 1.314869; batch adversarial loss: 0.386161\n",
      "epoch 6; iter: 0; batch classifier loss: 0.642768; batch adversarial loss: 0.489160\n",
      "epoch 6; iter: 200; batch classifier loss: 0.591437; batch adversarial loss: 0.397205\n",
      "epoch 7; iter: 0; batch classifier loss: 0.779325; batch adversarial loss: 0.442023\n",
      "epoch 7; iter: 200; batch classifier loss: 0.492192; batch adversarial loss: 0.409239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.498216; batch adversarial loss: 0.327915\n",
      "epoch 8; iter: 200; batch classifier loss: 0.439789; batch adversarial loss: 0.385737\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527892; batch adversarial loss: 0.416460\n",
      "epoch 9; iter: 200; batch classifier loss: 0.409836; batch adversarial loss: 0.564706\n",
      "epoch 10; iter: 0; batch classifier loss: 0.447152; batch adversarial loss: 0.326721\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420109; batch adversarial loss: 0.425965\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514110; batch adversarial loss: 0.345836\n",
      "epoch 11; iter: 200; batch classifier loss: 0.396951; batch adversarial loss: 0.423851\n",
      "epoch 12; iter: 0; batch classifier loss: 0.451446; batch adversarial loss: 0.427720\n",
      "epoch 12; iter: 200; batch classifier loss: 0.576643; batch adversarial loss: 0.310856\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407603; batch adversarial loss: 0.398359\n",
      "epoch 13; iter: 200; batch classifier loss: 0.397093; batch adversarial loss: 0.388284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396514; batch adversarial loss: 0.391049\n",
      "epoch 14; iter: 200; batch classifier loss: 0.355794; batch adversarial loss: 0.418366\n",
      "epoch 15; iter: 0; batch classifier loss: 0.316431; batch adversarial loss: 0.428523\n",
      "epoch 15; iter: 200; batch classifier loss: 0.440117; batch adversarial loss: 0.388257\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281039; batch adversarial loss: 0.480590\n",
      "epoch 16; iter: 200; batch classifier loss: 0.341314; batch adversarial loss: 0.415105\n",
      "epoch 17; iter: 0; batch classifier loss: 0.381718; batch adversarial loss: 0.439983\n",
      "epoch 17; iter: 200; batch classifier loss: 0.418023; batch adversarial loss: 0.426758\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317118; batch adversarial loss: 0.444206\n",
      "epoch 18; iter: 200; batch classifier loss: 0.277278; batch adversarial loss: 0.433968\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338633; batch adversarial loss: 0.390261\n",
      "epoch 19; iter: 200; batch classifier loss: 0.304685; batch adversarial loss: 0.399035\n",
      "epoch 0; iter: 0; batch classifier loss: 80.236565; batch adversarial loss: 0.660881\n",
      "epoch 0; iter: 200; batch classifier loss: 12.802597; batch adversarial loss: 0.595399\n",
      "epoch 1; iter: 0; batch classifier loss: 8.602490; batch adversarial loss: 0.588427\n",
      "epoch 1; iter: 200; batch classifier loss: 14.580131; batch adversarial loss: 0.534393\n",
      "epoch 2; iter: 0; batch classifier loss: 11.688340; batch adversarial loss: 0.520354\n",
      "epoch 2; iter: 200; batch classifier loss: 1.526047; batch adversarial loss: 0.469464\n",
      "epoch 3; iter: 0; batch classifier loss: 3.336112; batch adversarial loss: 0.428033\n",
      "epoch 3; iter: 200; batch classifier loss: 2.692097; batch adversarial loss: 0.433559\n",
      "epoch 4; iter: 0; batch classifier loss: 1.588845; batch adversarial loss: 0.391765\n",
      "epoch 4; iter: 200; batch classifier loss: 2.968997; batch adversarial loss: 0.440080\n",
      "epoch 5; iter: 0; batch classifier loss: 1.823644; batch adversarial loss: 0.409688\n",
      "epoch 5; iter: 200; batch classifier loss: 1.671982; batch adversarial loss: 0.442040\n",
      "epoch 6; iter: 0; batch classifier loss: 0.999162; batch adversarial loss: 0.468316\n",
      "epoch 6; iter: 200; batch classifier loss: 0.901153; batch adversarial loss: 0.396720\n",
      "epoch 7; iter: 0; batch classifier loss: 0.943880; batch adversarial loss: 0.526875\n",
      "epoch 7; iter: 200; batch classifier loss: 0.923578; batch adversarial loss: 0.440120\n",
      "epoch 8; iter: 0; batch classifier loss: 1.159811; batch adversarial loss: 0.426206\n",
      "epoch 8; iter: 200; batch classifier loss: 0.564627; batch adversarial loss: 0.417103\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564991; batch adversarial loss: 0.442434\n",
      "epoch 9; iter: 200; batch classifier loss: 1.588272; batch adversarial loss: 0.514598\n",
      "epoch 10; iter: 0; batch classifier loss: 1.306728; batch adversarial loss: 0.429731\n",
      "epoch 10; iter: 200; batch classifier loss: 0.623476; batch adversarial loss: 0.433476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588529; batch adversarial loss: 0.484346\n",
      "epoch 11; iter: 200; batch classifier loss: 0.429223; batch adversarial loss: 0.399402\n",
      "epoch 12; iter: 0; batch classifier loss: 0.322126; batch adversarial loss: 0.440498\n",
      "epoch 12; iter: 200; batch classifier loss: 0.430385; batch adversarial loss: 0.415930\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349737; batch adversarial loss: 0.344384\n",
      "epoch 13; iter: 200; batch classifier loss: 0.323796; batch adversarial loss: 0.377210\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370544; batch adversarial loss: 0.483269\n",
      "epoch 14; iter: 200; batch classifier loss: 0.306654; batch adversarial loss: 0.392667\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385243; batch adversarial loss: 0.454972\n",
      "epoch 15; iter: 200; batch classifier loss: 0.332698; batch adversarial loss: 0.498142\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370030; batch adversarial loss: 0.416787\n",
      "epoch 16; iter: 200; batch classifier loss: 0.362039; batch adversarial loss: 0.427422\n",
      "epoch 17; iter: 0; batch classifier loss: 0.287232; batch adversarial loss: 0.382233\n",
      "epoch 17; iter: 200; batch classifier loss: 0.283828; batch adversarial loss: 0.465772\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378494; batch adversarial loss: 0.401934\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336173; batch adversarial loss: 0.540695\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337412; batch adversarial loss: 0.368407\n",
      "epoch 19; iter: 200; batch classifier loss: 0.546610; batch adversarial loss: 0.481847\n",
      "epoch 0; iter: 0; batch classifier loss: 2.287841; batch adversarial loss: 0.724890\n",
      "epoch 0; iter: 200; batch classifier loss: 6.232421; batch adversarial loss: 0.614261\n",
      "epoch 1; iter: 0; batch classifier loss: 5.989904; batch adversarial loss: 0.583759\n",
      "epoch 1; iter: 200; batch classifier loss: 4.327484; batch adversarial loss: 0.541035\n",
      "epoch 2; iter: 0; batch classifier loss: 5.515112; batch adversarial loss: 0.524856\n",
      "epoch 2; iter: 200; batch classifier loss: 4.355430; batch adversarial loss: 0.476254\n",
      "epoch 3; iter: 0; batch classifier loss: 3.405888; batch adversarial loss: 0.456193\n",
      "epoch 3; iter: 200; batch classifier loss: 2.435108; batch adversarial loss: 0.473270\n",
      "epoch 4; iter: 0; batch classifier loss: 1.534067; batch adversarial loss: 0.423582\n",
      "epoch 4; iter: 200; batch classifier loss: 0.880989; batch adversarial loss: 0.436721\n",
      "epoch 5; iter: 0; batch classifier loss: 1.070907; batch adversarial loss: 0.395646\n",
      "epoch 5; iter: 200; batch classifier loss: 0.845282; batch adversarial loss: 0.375811\n",
      "epoch 6; iter: 0; batch classifier loss: 1.671576; batch adversarial loss: 0.393788\n",
      "epoch 6; iter: 200; batch classifier loss: 1.109571; batch adversarial loss: 0.415972\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496387; batch adversarial loss: 0.409566\n",
      "epoch 7; iter: 200; batch classifier loss: 0.320336; batch adversarial loss: 0.427999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.639846; batch adversarial loss: 0.386457\n",
      "epoch 8; iter: 200; batch classifier loss: 0.425335; batch adversarial loss: 0.452842\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445624; batch adversarial loss: 0.419985\n",
      "epoch 9; iter: 200; batch classifier loss: 0.428808; batch adversarial loss: 0.467186\n",
      "epoch 10; iter: 0; batch classifier loss: 0.403623; batch adversarial loss: 0.400162\n",
      "epoch 10; iter: 200; batch classifier loss: 0.634629; batch adversarial loss: 0.445801\n",
      "epoch 11; iter: 0; batch classifier loss: 0.400051; batch adversarial loss: 0.397247\n",
      "epoch 11; iter: 200; batch classifier loss: 0.624716; batch adversarial loss: 0.417886\n",
      "epoch 12; iter: 0; batch classifier loss: 0.451383; batch adversarial loss: 0.423753\n",
      "epoch 12; iter: 200; batch classifier loss: 0.505167; batch adversarial loss: 0.349756\n",
      "epoch 13; iter: 0; batch classifier loss: 0.609802; batch adversarial loss: 0.404961\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352946; batch adversarial loss: 0.489642\n",
      "epoch 14; iter: 0; batch classifier loss: 0.347983; batch adversarial loss: 0.407641\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379835; batch adversarial loss: 0.376535\n",
      "epoch 15; iter: 0; batch classifier loss: 0.339482; batch adversarial loss: 0.408317\n",
      "epoch 15; iter: 200; batch classifier loss: 0.317600; batch adversarial loss: 0.399710\n",
      "epoch 16; iter: 0; batch classifier loss: 0.348294; batch adversarial loss: 0.418308\n",
      "epoch 16; iter: 200; batch classifier loss: 0.420251; batch adversarial loss: 0.414666\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392060; batch adversarial loss: 0.491412\n",
      "epoch 17; iter: 200; batch classifier loss: 0.472000; batch adversarial loss: 0.459327\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345932; batch adversarial loss: 0.333022\n",
      "epoch 18; iter: 200; batch classifier loss: 0.355964; batch adversarial loss: 0.404399\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338472; batch adversarial loss: 0.412559\n",
      "epoch 19; iter: 200; batch classifier loss: 0.351072; batch adversarial loss: 0.358018\n",
      "epoch 0; iter: 0; batch classifier loss: 4.599341; batch adversarial loss: 1.084522\n",
      "epoch 0; iter: 200; batch classifier loss: 7.340222; batch adversarial loss: 0.941110\n",
      "epoch 1; iter: 0; batch classifier loss: 7.808175; batch adversarial loss: 0.795916\n",
      "epoch 1; iter: 200; batch classifier loss: 8.354877; batch adversarial loss: 0.650994\n",
      "epoch 2; iter: 0; batch classifier loss: 6.125315; batch adversarial loss: 0.600450\n",
      "epoch 2; iter: 200; batch classifier loss: 9.425259; batch adversarial loss: 0.548112\n",
      "epoch 3; iter: 0; batch classifier loss: 33.625866; batch adversarial loss: 0.520993\n",
      "epoch 3; iter: 200; batch classifier loss: 4.972510; batch adversarial loss: 0.480344\n",
      "epoch 4; iter: 0; batch classifier loss: 3.751677; batch adversarial loss: 0.459440\n",
      "epoch 4; iter: 200; batch classifier loss: 1.559775; batch adversarial loss: 0.487995\n",
      "epoch 5; iter: 0; batch classifier loss: 1.816753; batch adversarial loss: 0.433056\n",
      "epoch 5; iter: 200; batch classifier loss: 1.462137; batch adversarial loss: 0.452931\n",
      "epoch 6; iter: 0; batch classifier loss: 0.817821; batch adversarial loss: 0.415083\n",
      "epoch 6; iter: 200; batch classifier loss: 0.730961; batch adversarial loss: 0.379099\n",
      "epoch 7; iter: 0; batch classifier loss: 0.914761; batch adversarial loss: 0.432425\n",
      "epoch 7; iter: 200; batch classifier loss: 0.762808; batch adversarial loss: 0.419827\n",
      "epoch 8; iter: 0; batch classifier loss: 0.650721; batch adversarial loss: 0.416256\n",
      "epoch 8; iter: 200; batch classifier loss: 0.603430; batch adversarial loss: 0.382701\n",
      "epoch 9; iter: 0; batch classifier loss: 0.424459; batch adversarial loss: 0.416051\n",
      "epoch 9; iter: 200; batch classifier loss: 1.393663; batch adversarial loss: 0.503793\n",
      "epoch 10; iter: 0; batch classifier loss: 0.621215; batch adversarial loss: 0.360564\n",
      "epoch 10; iter: 200; batch classifier loss: 0.589943; batch adversarial loss: 0.386458\n",
      "epoch 11; iter: 0; batch classifier loss: 0.840706; batch adversarial loss: 0.322105\n",
      "epoch 11; iter: 200; batch classifier loss: 0.609480; batch adversarial loss: 0.366924\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349176; batch adversarial loss: 0.366243\n",
      "epoch 12; iter: 200; batch classifier loss: 0.435778; batch adversarial loss: 0.403451\n",
      "epoch 13; iter: 0; batch classifier loss: 0.427968; batch adversarial loss: 0.427482\n",
      "epoch 13; iter: 200; batch classifier loss: 0.494079; batch adversarial loss: 0.402889\n",
      "epoch 14; iter: 0; batch classifier loss: 0.398740; batch adversarial loss: 0.457578\n",
      "epoch 14; iter: 200; batch classifier loss: 0.377434; batch adversarial loss: 0.472605\n",
      "epoch 15; iter: 0; batch classifier loss: 0.493503; batch adversarial loss: 0.386468\n",
      "epoch 15; iter: 200; batch classifier loss: 0.330474; batch adversarial loss: 0.425728\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331530; batch adversarial loss: 0.351410\n",
      "epoch 16; iter: 200; batch classifier loss: 0.338578; batch adversarial loss: 0.433295\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377727; batch adversarial loss: 0.376538\n",
      "epoch 17; iter: 200; batch classifier loss: 0.256175; batch adversarial loss: 0.360609\n",
      "epoch 18; iter: 0; batch classifier loss: 0.303625; batch adversarial loss: 0.422642\n",
      "epoch 18; iter: 200; batch classifier loss: 0.396638; batch adversarial loss: 0.361041\n",
      "epoch 19; iter: 0; batch classifier loss: 0.399928; batch adversarial loss: 0.446596\n",
      "epoch 19; iter: 200; batch classifier loss: 0.370190; batch adversarial loss: 0.368795\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 11.656866; batch adversarial loss: 0.670557\n",
      "epoch 0; iter: 200; batch classifier loss: 11.797144; batch adversarial loss: 0.594959\n",
      "epoch 1; iter: 0; batch classifier loss: 2.481339; batch adversarial loss: 0.567931\n",
      "epoch 1; iter: 200; batch classifier loss: 3.217100; batch adversarial loss: 0.556279\n",
      "epoch 2; iter: 0; batch classifier loss: 4.202458; batch adversarial loss: 0.501077\n",
      "epoch 2; iter: 200; batch classifier loss: 1.555064; batch adversarial loss: 0.469643\n",
      "epoch 3; iter: 0; batch classifier loss: 3.240787; batch adversarial loss: 0.514747\n",
      "epoch 3; iter: 200; batch classifier loss: 1.139859; batch adversarial loss: 0.483672\n",
      "epoch 4; iter: 0; batch classifier loss: 2.011009; batch adversarial loss: 0.477877\n",
      "epoch 4; iter: 200; batch classifier loss: 1.112181; batch adversarial loss: 0.414798\n",
      "epoch 5; iter: 0; batch classifier loss: 1.743641; batch adversarial loss: 0.451795\n",
      "epoch 5; iter: 200; batch classifier loss: 0.774658; batch adversarial loss: 0.436462\n",
      "epoch 6; iter: 0; batch classifier loss: 0.668234; batch adversarial loss: 0.463373\n",
      "epoch 6; iter: 200; batch classifier loss: 0.988563; batch adversarial loss: 0.405838\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565016; batch adversarial loss: 0.483442\n",
      "epoch 7; iter: 200; batch classifier loss: 0.520911; batch adversarial loss: 0.433986\n",
      "epoch 8; iter: 0; batch classifier loss: 0.479181; batch adversarial loss: 0.513584\n",
      "epoch 8; iter: 200; batch classifier loss: 0.873900; batch adversarial loss: 0.500169\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455238; batch adversarial loss: 0.401992\n",
      "epoch 9; iter: 200; batch classifier loss: 0.414188; batch adversarial loss: 0.487169\n",
      "epoch 10; iter: 0; batch classifier loss: 0.504405; batch adversarial loss: 0.484023\n",
      "epoch 10; iter: 200; batch classifier loss: 0.356190; batch adversarial loss: 0.503427\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368528; batch adversarial loss: 0.402940\n",
      "epoch 11; iter: 200; batch classifier loss: 0.453897; batch adversarial loss: 0.398839\n",
      "epoch 12; iter: 0; batch classifier loss: 0.305724; batch adversarial loss: 0.433616\n",
      "epoch 12; iter: 200; batch classifier loss: 0.504147; batch adversarial loss: 0.516715\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479653; batch adversarial loss: 0.456888\n",
      "epoch 13; iter: 200; batch classifier loss: 0.538939; batch adversarial loss: 0.415528\n",
      "epoch 14; iter: 0; batch classifier loss: 0.292765; batch adversarial loss: 0.468060\n",
      "epoch 14; iter: 200; batch classifier loss: 0.387119; batch adversarial loss: 0.451512\n",
      "epoch 15; iter: 0; batch classifier loss: 0.522803; batch adversarial loss: 0.444426\n",
      "epoch 15; iter: 200; batch classifier loss: 0.382167; batch adversarial loss: 0.419103\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453557; batch adversarial loss: 0.352518\n",
      "epoch 16; iter: 200; batch classifier loss: 0.377794; batch adversarial loss: 0.385465\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382811; batch adversarial loss: 0.390857\n",
      "epoch 17; iter: 200; batch classifier loss: 0.333976; batch adversarial loss: 0.358018\n",
      "epoch 18; iter: 0; batch classifier loss: 0.425442; batch adversarial loss: 0.408358\n",
      "epoch 18; iter: 200; batch classifier loss: 0.334150; batch adversarial loss: 0.406751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375909; batch adversarial loss: 0.414659\n",
      "epoch 19; iter: 200; batch classifier loss: 0.424459; batch adversarial loss: 0.481190\n",
      "epoch 20; iter: 0; batch classifier loss: 0.315704; batch adversarial loss: 0.383138\n",
      "epoch 20; iter: 200; batch classifier loss: 0.316923; batch adversarial loss: 0.402241\n",
      "epoch 21; iter: 0; batch classifier loss: 0.309694; batch adversarial loss: 0.463222\n",
      "epoch 21; iter: 200; batch classifier loss: 0.338743; batch adversarial loss: 0.428142\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433867; batch adversarial loss: 0.301090\n",
      "epoch 22; iter: 200; batch classifier loss: 0.406011; batch adversarial loss: 0.413060\n",
      "epoch 23; iter: 0; batch classifier loss: 0.358770; batch adversarial loss: 0.421512\n",
      "epoch 23; iter: 200; batch classifier loss: 0.233017; batch adversarial loss: 0.430204\n",
      "epoch 24; iter: 0; batch classifier loss: 0.335934; batch adversarial loss: 0.371230\n",
      "epoch 24; iter: 200; batch classifier loss: 0.286711; batch adversarial loss: 0.443417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.366269; batch adversarial loss: 0.441730\n",
      "epoch 25; iter: 200; batch classifier loss: 0.338198; batch adversarial loss: 0.388104\n",
      "epoch 26; iter: 0; batch classifier loss: 0.331907; batch adversarial loss: 0.448031\n",
      "epoch 26; iter: 200; batch classifier loss: 0.322529; batch adversarial loss: 0.390468\n",
      "epoch 27; iter: 0; batch classifier loss: 0.358865; batch adversarial loss: 0.376017\n",
      "epoch 27; iter: 200; batch classifier loss: 0.355027; batch adversarial loss: 0.429609\n",
      "epoch 28; iter: 0; batch classifier loss: 0.264882; batch adversarial loss: 0.446539\n",
      "epoch 28; iter: 200; batch classifier loss: 0.377216; batch adversarial loss: 0.460154\n",
      "epoch 29; iter: 0; batch classifier loss: 0.369095; batch adversarial loss: 0.434221\n",
      "epoch 29; iter: 200; batch classifier loss: 0.438878; batch adversarial loss: 0.481827\n",
      "epoch 30; iter: 0; batch classifier loss: 0.371123; batch adversarial loss: 0.399340\n",
      "epoch 30; iter: 200; batch classifier loss: 0.416304; batch adversarial loss: 0.340904\n",
      "epoch 31; iter: 0; batch classifier loss: 0.432548; batch adversarial loss: 0.446530\n",
      "epoch 31; iter: 200; batch classifier loss: 0.343611; batch adversarial loss: 0.301632\n",
      "epoch 32; iter: 0; batch classifier loss: 0.266918; batch adversarial loss: 0.404340\n",
      "epoch 32; iter: 200; batch classifier loss: 0.380322; batch adversarial loss: 0.425502\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347046; batch adversarial loss: 0.329115\n",
      "epoch 33; iter: 200; batch classifier loss: 0.389558; batch adversarial loss: 0.366888\n",
      "epoch 34; iter: 0; batch classifier loss: 0.395544; batch adversarial loss: 0.444383\n",
      "epoch 34; iter: 200; batch classifier loss: 0.443010; batch adversarial loss: 0.431751\n",
      "epoch 35; iter: 0; batch classifier loss: 0.311222; batch adversarial loss: 0.443130\n",
      "epoch 35; iter: 200; batch classifier loss: 0.307411; batch adversarial loss: 0.390377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.363925; batch adversarial loss: 0.418189\n",
      "epoch 36; iter: 200; batch classifier loss: 0.248049; batch adversarial loss: 0.536297\n",
      "epoch 37; iter: 0; batch classifier loss: 0.349303; batch adversarial loss: 0.389631\n",
      "epoch 37; iter: 200; batch classifier loss: 0.343848; batch adversarial loss: 0.359994\n",
      "epoch 38; iter: 0; batch classifier loss: 0.309460; batch adversarial loss: 0.457817\n",
      "epoch 38; iter: 200; batch classifier loss: 0.563536; batch adversarial loss: 0.482031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.391133; batch adversarial loss: 0.383488\n",
      "epoch 39; iter: 200; batch classifier loss: 0.335027; batch adversarial loss: 0.352285\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446391; batch adversarial loss: 0.366732\n",
      "epoch 40; iter: 200; batch classifier loss: 0.395962; batch adversarial loss: 0.463070\n",
      "epoch 41; iter: 0; batch classifier loss: 0.304719; batch adversarial loss: 0.397736\n",
      "epoch 41; iter: 200; batch classifier loss: 0.347525; batch adversarial loss: 0.404663\n",
      "epoch 42; iter: 0; batch classifier loss: 0.312425; batch adversarial loss: 0.347052\n",
      "epoch 42; iter: 200; batch classifier loss: 0.350197; batch adversarial loss: 0.349748\n",
      "epoch 43; iter: 0; batch classifier loss: 0.371496; batch adversarial loss: 0.443142\n",
      "epoch 43; iter: 200; batch classifier loss: 0.428727; batch adversarial loss: 0.396581\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493308; batch adversarial loss: 0.519302\n",
      "epoch 44; iter: 200; batch classifier loss: 0.412688; batch adversarial loss: 0.288883\n",
      "epoch 45; iter: 0; batch classifier loss: 0.321675; batch adversarial loss: 0.436595\n",
      "epoch 45; iter: 200; batch classifier loss: 0.428189; batch adversarial loss: 0.370212\n",
      "epoch 46; iter: 0; batch classifier loss: 0.346444; batch adversarial loss: 0.406658\n",
      "epoch 46; iter: 200; batch classifier loss: 0.401448; batch adversarial loss: 0.427931\n",
      "epoch 47; iter: 0; batch classifier loss: 0.308156; batch adversarial loss: 0.374169\n",
      "epoch 47; iter: 200; batch classifier loss: 0.299553; batch adversarial loss: 0.279952\n",
      "epoch 48; iter: 0; batch classifier loss: 0.387356; batch adversarial loss: 0.418606\n",
      "epoch 48; iter: 200; batch classifier loss: 0.265414; batch adversarial loss: 0.431692\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371471; batch adversarial loss: 0.383848\n",
      "epoch 49; iter: 200; batch classifier loss: 0.345756; batch adversarial loss: 0.340680\n",
      "epoch 0; iter: 0; batch classifier loss: 9.166893; batch adversarial loss: 0.952911\n",
      "epoch 0; iter: 200; batch classifier loss: 7.823250; batch adversarial loss: 0.887062\n",
      "epoch 1; iter: 0; batch classifier loss: 2.552911; batch adversarial loss: 0.838323\n",
      "epoch 1; iter: 200; batch classifier loss: 7.886946; batch adversarial loss: 0.646977\n",
      "epoch 2; iter: 0; batch classifier loss: 0.986479; batch adversarial loss: 0.552923\n",
      "epoch 2; iter: 200; batch classifier loss: 2.788466; batch adversarial loss: 0.502252\n",
      "epoch 3; iter: 0; batch classifier loss: 4.491896; batch adversarial loss: 0.477859\n",
      "epoch 3; iter: 200; batch classifier loss: 2.073481; batch adversarial loss: 0.471311\n",
      "epoch 4; iter: 0; batch classifier loss: 1.542341; batch adversarial loss: 0.469750\n",
      "epoch 4; iter: 200; batch classifier loss: 1.080234; batch adversarial loss: 0.447546\n",
      "epoch 5; iter: 0; batch classifier loss: 1.245410; batch adversarial loss: 0.448987\n",
      "epoch 5; iter: 200; batch classifier loss: 1.202049; batch adversarial loss: 0.429488\n",
      "epoch 6; iter: 0; batch classifier loss: 0.636015; batch adversarial loss: 0.392075\n",
      "epoch 6; iter: 200; batch classifier loss: 0.803348; batch adversarial loss: 0.438792\n",
      "epoch 7; iter: 0; batch classifier loss: 0.748975; batch adversarial loss: 0.456551\n",
      "epoch 7; iter: 200; batch classifier loss: 0.410259; batch adversarial loss: 0.375729\n",
      "epoch 8; iter: 0; batch classifier loss: 0.638759; batch adversarial loss: 0.413527\n",
      "epoch 8; iter: 200; batch classifier loss: 0.348668; batch adversarial loss: 0.514167\n",
      "epoch 9; iter: 0; batch classifier loss: 0.867620; batch adversarial loss: 0.366857\n",
      "epoch 9; iter: 200; batch classifier loss: 0.631611; batch adversarial loss: 0.422926\n",
      "epoch 10; iter: 0; batch classifier loss: 0.474898; batch adversarial loss: 0.414289\n",
      "epoch 10; iter: 200; batch classifier loss: 0.405448; batch adversarial loss: 0.414850\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454300; batch adversarial loss: 0.472652\n",
      "epoch 11; iter: 200; batch classifier loss: 0.534345; batch adversarial loss: 0.461183\n",
      "epoch 12; iter: 0; batch classifier loss: 0.426527; batch adversarial loss: 0.285070\n",
      "epoch 12; iter: 200; batch classifier loss: 0.396107; batch adversarial loss: 0.314948\n",
      "epoch 13; iter: 0; batch classifier loss: 0.404954; batch adversarial loss: 0.463312\n",
      "epoch 13; iter: 200; batch classifier loss: 0.443899; batch adversarial loss: 0.387369\n",
      "epoch 14; iter: 0; batch classifier loss: 0.415445; batch adversarial loss: 0.495687\n",
      "epoch 14; iter: 200; batch classifier loss: 0.370683; batch adversarial loss: 0.384769\n",
      "epoch 15; iter: 0; batch classifier loss: 0.384283; batch adversarial loss: 0.427738\n",
      "epoch 15; iter: 200; batch classifier loss: 0.527404; batch adversarial loss: 0.374688\n",
      "epoch 16; iter: 0; batch classifier loss: 0.360249; batch adversarial loss: 0.436944\n",
      "epoch 16; iter: 200; batch classifier loss: 0.340046; batch adversarial loss: 0.457699\n",
      "epoch 17; iter: 0; batch classifier loss: 0.454873; batch adversarial loss: 0.439914\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321459; batch adversarial loss: 0.438062\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343209; batch adversarial loss: 0.393670\n",
      "epoch 18; iter: 200; batch classifier loss: 0.327838; batch adversarial loss: 0.355012\n",
      "epoch 19; iter: 0; batch classifier loss: 0.367777; batch adversarial loss: 0.399016\n",
      "epoch 19; iter: 200; batch classifier loss: 0.354740; batch adversarial loss: 0.439866\n",
      "epoch 20; iter: 0; batch classifier loss: 0.274552; batch adversarial loss: 0.413150\n",
      "epoch 20; iter: 200; batch classifier loss: 0.339122; batch adversarial loss: 0.427103\n",
      "epoch 21; iter: 0; batch classifier loss: 0.304999; batch adversarial loss: 0.383187\n",
      "epoch 21; iter: 200; batch classifier loss: 0.372971; batch adversarial loss: 0.296411\n",
      "epoch 22; iter: 0; batch classifier loss: 0.295035; batch adversarial loss: 0.382797\n",
      "epoch 22; iter: 200; batch classifier loss: 0.343781; batch adversarial loss: 0.523430\n",
      "epoch 23; iter: 0; batch classifier loss: 0.348393; batch adversarial loss: 0.431970\n",
      "epoch 23; iter: 200; batch classifier loss: 0.340743; batch adversarial loss: 0.434084\n",
      "epoch 24; iter: 0; batch classifier loss: 0.291201; batch adversarial loss: 0.353070\n",
      "epoch 24; iter: 200; batch classifier loss: 0.280066; batch adversarial loss: 0.464802\n",
      "epoch 25; iter: 0; batch classifier loss: 0.357622; batch adversarial loss: 0.363914\n",
      "epoch 25; iter: 200; batch classifier loss: 0.331575; batch adversarial loss: 0.388571\n",
      "epoch 26; iter: 0; batch classifier loss: 0.353072; batch adversarial loss: 0.374945\n",
      "epoch 26; iter: 200; batch classifier loss: 0.300166; batch adversarial loss: 0.543073\n",
      "epoch 27; iter: 0; batch classifier loss: 0.425600; batch adversarial loss: 0.369746\n",
      "epoch 27; iter: 200; batch classifier loss: 0.290622; batch adversarial loss: 0.442184\n",
      "epoch 28; iter: 0; batch classifier loss: 0.338949; batch adversarial loss: 0.471315\n",
      "epoch 28; iter: 200; batch classifier loss: 0.396579; batch adversarial loss: 0.414321\n",
      "epoch 29; iter: 0; batch classifier loss: 0.374892; batch adversarial loss: 0.359308\n",
      "epoch 29; iter: 200; batch classifier loss: 0.296861; batch adversarial loss: 0.553652\n",
      "epoch 30; iter: 0; batch classifier loss: 0.304115; batch adversarial loss: 0.403325\n",
      "epoch 30; iter: 200; batch classifier loss: 0.365047; batch adversarial loss: 0.407749\n",
      "epoch 31; iter: 0; batch classifier loss: 0.288081; batch adversarial loss: 0.424137\n",
      "epoch 31; iter: 200; batch classifier loss: 0.384873; batch adversarial loss: 0.375999\n",
      "epoch 32; iter: 0; batch classifier loss: 0.341942; batch adversarial loss: 0.414086\n",
      "epoch 32; iter: 200; batch classifier loss: 0.358732; batch adversarial loss: 0.327106\n",
      "epoch 33; iter: 0; batch classifier loss: 0.449192; batch adversarial loss: 0.445272\n",
      "epoch 33; iter: 200; batch classifier loss: 0.392582; batch adversarial loss: 0.385347\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478534; batch adversarial loss: 0.376492\n",
      "epoch 34; iter: 200; batch classifier loss: 0.365203; batch adversarial loss: 0.320599\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398246; batch adversarial loss: 0.438373\n",
      "epoch 35; iter: 200; batch classifier loss: 0.440101; batch adversarial loss: 0.428399\n",
      "epoch 36; iter: 0; batch classifier loss: 0.454047; batch adversarial loss: 0.456722\n",
      "epoch 36; iter: 200; batch classifier loss: 0.419286; batch adversarial loss: 0.434266\n",
      "epoch 37; iter: 0; batch classifier loss: 0.476904; batch adversarial loss: 0.405417\n",
      "epoch 37; iter: 200; batch classifier loss: 0.425739; batch adversarial loss: 0.432761\n",
      "epoch 38; iter: 0; batch classifier loss: 0.351913; batch adversarial loss: 0.444143\n",
      "epoch 38; iter: 200; batch classifier loss: 0.397278; batch adversarial loss: 0.352769\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386597; batch adversarial loss: 0.442546\n",
      "epoch 39; iter: 200; batch classifier loss: 0.436213; batch adversarial loss: 0.283439\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428665; batch adversarial loss: 0.403550\n",
      "epoch 40; iter: 200; batch classifier loss: 0.413706; batch adversarial loss: 0.408672\n",
      "epoch 41; iter: 0; batch classifier loss: 0.376631; batch adversarial loss: 0.502862\n",
      "epoch 41; iter: 200; batch classifier loss: 0.369323; batch adversarial loss: 0.420019\n",
      "epoch 42; iter: 0; batch classifier loss: 0.430575; batch adversarial loss: 0.357646\n",
      "epoch 42; iter: 200; batch classifier loss: 0.383225; batch adversarial loss: 0.432680\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537882; batch adversarial loss: 0.426389\n",
      "epoch 43; iter: 200; batch classifier loss: 0.421178; batch adversarial loss: 0.347234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.474790; batch adversarial loss: 0.368956\n",
      "epoch 44; iter: 200; batch classifier loss: 0.384457; batch adversarial loss: 0.328439\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392301; batch adversarial loss: 0.389726\n",
      "epoch 45; iter: 200; batch classifier loss: 0.540894; batch adversarial loss: 0.382686\n",
      "epoch 46; iter: 0; batch classifier loss: 0.463593; batch adversarial loss: 0.430662\n",
      "epoch 46; iter: 200; batch classifier loss: 0.525509; batch adversarial loss: 0.511409\n",
      "epoch 47; iter: 0; batch classifier loss: 0.522120; batch adversarial loss: 0.461335\n",
      "epoch 47; iter: 200; batch classifier loss: 0.470515; batch adversarial loss: 0.345078\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489829; batch adversarial loss: 0.367783\n",
      "epoch 48; iter: 200; batch classifier loss: 0.312719; batch adversarial loss: 0.376091\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461024; batch adversarial loss: 0.442143\n",
      "epoch 49; iter: 200; batch classifier loss: 0.404158; batch adversarial loss: 0.468851\n",
      "epoch 0; iter: 0; batch classifier loss: 13.702071; batch adversarial loss: 0.948122\n",
      "epoch 0; iter: 200; batch classifier loss: 5.279490; batch adversarial loss: 0.801849\n",
      "epoch 1; iter: 0; batch classifier loss: 19.790146; batch adversarial loss: 0.704007\n",
      "epoch 1; iter: 200; batch classifier loss: 2.628639; batch adversarial loss: 0.589166\n",
      "epoch 2; iter: 0; batch classifier loss: 3.242505; batch adversarial loss: 0.543349\n",
      "epoch 2; iter: 200; batch classifier loss: 11.418656; batch adversarial loss: 0.485023\n",
      "epoch 3; iter: 0; batch classifier loss: 3.866161; batch adversarial loss: 0.518430\n",
      "epoch 3; iter: 200; batch classifier loss: 1.918139; batch adversarial loss: 0.497928\n",
      "epoch 4; iter: 0; batch classifier loss: 5.224739; batch adversarial loss: 0.494907\n",
      "epoch 4; iter: 200; batch classifier loss: 2.510680; batch adversarial loss: 0.462142\n",
      "epoch 5; iter: 0; batch classifier loss: 2.393588; batch adversarial loss: 0.413006\n",
      "epoch 5; iter: 200; batch classifier loss: 0.715014; batch adversarial loss: 0.397034\n",
      "epoch 6; iter: 0; batch classifier loss: 2.303281; batch adversarial loss: 0.435276\n",
      "epoch 6; iter: 200; batch classifier loss: 0.773357; batch adversarial loss: 0.418215\n",
      "epoch 7; iter: 0; batch classifier loss: 1.358299; batch adversarial loss: 0.415621\n",
      "epoch 7; iter: 200; batch classifier loss: 0.714668; batch adversarial loss: 0.366463\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518333; batch adversarial loss: 0.449343\n",
      "epoch 8; iter: 200; batch classifier loss: 0.493229; batch adversarial loss: 0.452713\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496733; batch adversarial loss: 0.360167\n",
      "epoch 9; iter: 200; batch classifier loss: 0.445880; batch adversarial loss: 0.397525\n",
      "epoch 10; iter: 0; batch classifier loss: 0.432711; batch adversarial loss: 0.426810\n",
      "epoch 10; iter: 200; batch classifier loss: 0.540707; batch adversarial loss: 0.413609\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522940; batch adversarial loss: 0.402457\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449827; batch adversarial loss: 0.428595\n",
      "epoch 12; iter: 0; batch classifier loss: 0.409853; batch adversarial loss: 0.433149\n",
      "epoch 12; iter: 200; batch classifier loss: 0.504252; batch adversarial loss: 0.500633\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550725; batch adversarial loss: 0.491848\n",
      "epoch 13; iter: 200; batch classifier loss: 0.343469; batch adversarial loss: 0.435539\n",
      "epoch 14; iter: 0; batch classifier loss: 0.443780; batch adversarial loss: 0.420495\n",
      "epoch 14; iter: 200; batch classifier loss: 0.431023; batch adversarial loss: 0.331510\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428634; batch adversarial loss: 0.369560\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380337; batch adversarial loss: 0.487149\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380313; batch adversarial loss: 0.450513\n",
      "epoch 16; iter: 200; batch classifier loss: 0.415054; batch adversarial loss: 0.367832\n",
      "epoch 17; iter: 0; batch classifier loss: 0.338589; batch adversarial loss: 0.404968\n",
      "epoch 17; iter: 200; batch classifier loss: 0.302586; batch adversarial loss: 0.490058\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438300; batch adversarial loss: 0.401246\n",
      "epoch 18; iter: 200; batch classifier loss: 0.363278; batch adversarial loss: 0.409151\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376970; batch adversarial loss: 0.425822\n",
      "epoch 19; iter: 200; batch classifier loss: 0.345571; batch adversarial loss: 0.416041\n",
      "epoch 20; iter: 0; batch classifier loss: 0.369364; batch adversarial loss: 0.457007\n",
      "epoch 20; iter: 200; batch classifier loss: 0.348609; batch adversarial loss: 0.378481\n",
      "epoch 21; iter: 0; batch classifier loss: 0.419299; batch adversarial loss: 0.449637\n",
      "epoch 21; iter: 200; batch classifier loss: 0.358607; batch adversarial loss: 0.420880\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431382; batch adversarial loss: 0.447075\n",
      "epoch 22; iter: 200; batch classifier loss: 0.363351; batch adversarial loss: 0.388648\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380467; batch adversarial loss: 0.459639\n",
      "epoch 23; iter: 200; batch classifier loss: 0.377009; batch adversarial loss: 0.413585\n",
      "epoch 24; iter: 0; batch classifier loss: 0.379164; batch adversarial loss: 0.429713\n",
      "epoch 24; iter: 200; batch classifier loss: 0.351154; batch adversarial loss: 0.356260\n",
      "epoch 25; iter: 0; batch classifier loss: 0.412726; batch adversarial loss: 0.362225\n",
      "epoch 25; iter: 200; batch classifier loss: 0.267499; batch adversarial loss: 0.347919\n",
      "epoch 26; iter: 0; batch classifier loss: 0.333100; batch adversarial loss: 0.448426\n",
      "epoch 26; iter: 200; batch classifier loss: 0.301465; batch adversarial loss: 0.423993\n",
      "epoch 27; iter: 0; batch classifier loss: 0.303865; batch adversarial loss: 0.357620\n",
      "epoch 27; iter: 200; batch classifier loss: 0.352011; batch adversarial loss: 0.372594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.307606; batch adversarial loss: 0.378731\n",
      "epoch 28; iter: 200; batch classifier loss: 0.282332; batch adversarial loss: 0.472834\n",
      "epoch 29; iter: 0; batch classifier loss: 0.302408; batch adversarial loss: 0.468922\n",
      "epoch 29; iter: 200; batch classifier loss: 0.339438; batch adversarial loss: 0.487297\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424819; batch adversarial loss: 0.321433\n",
      "epoch 30; iter: 200; batch classifier loss: 0.303973; batch adversarial loss: 0.426926\n",
      "epoch 31; iter: 0; batch classifier loss: 0.302337; batch adversarial loss: 0.489378\n",
      "epoch 31; iter: 200; batch classifier loss: 0.327197; batch adversarial loss: 0.633818\n",
      "epoch 32; iter: 0; batch classifier loss: 0.327572; batch adversarial loss: 0.348242\n",
      "epoch 32; iter: 200; batch classifier loss: 0.327555; batch adversarial loss: 0.459092\n",
      "epoch 33; iter: 0; batch classifier loss: 0.384038; batch adversarial loss: 0.408118\n",
      "epoch 33; iter: 200; batch classifier loss: 0.408006; batch adversarial loss: 0.423096\n",
      "epoch 34; iter: 0; batch classifier loss: 0.391008; batch adversarial loss: 0.398865\n",
      "epoch 34; iter: 200; batch classifier loss: 0.383441; batch adversarial loss: 0.443172\n",
      "epoch 35; iter: 0; batch classifier loss: 0.378848; batch adversarial loss: 0.535596\n",
      "epoch 35; iter: 200; batch classifier loss: 0.370659; batch adversarial loss: 0.404505\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448306; batch adversarial loss: 0.460429\n",
      "epoch 36; iter: 200; batch classifier loss: 0.392413; batch adversarial loss: 0.415150\n",
      "epoch 37; iter: 0; batch classifier loss: 0.365897; batch adversarial loss: 0.521678\n",
      "epoch 37; iter: 200; batch classifier loss: 0.337249; batch adversarial loss: 0.391600\n",
      "epoch 38; iter: 0; batch classifier loss: 0.496265; batch adversarial loss: 0.434934\n",
      "epoch 38; iter: 200; batch classifier loss: 0.421344; batch adversarial loss: 0.464308\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443785; batch adversarial loss: 0.418396\n",
      "epoch 39; iter: 200; batch classifier loss: 0.401012; batch adversarial loss: 0.403202\n",
      "epoch 40; iter: 0; batch classifier loss: 0.397432; batch adversarial loss: 0.421430\n",
      "epoch 40; iter: 200; batch classifier loss: 0.451312; batch adversarial loss: 0.483816\n",
      "epoch 41; iter: 0; batch classifier loss: 0.400111; batch adversarial loss: 0.407972\n",
      "epoch 41; iter: 200; batch classifier loss: 0.444765; batch adversarial loss: 0.426039\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510841; batch adversarial loss: 0.305225\n",
      "epoch 42; iter: 200; batch classifier loss: 0.366157; batch adversarial loss: 0.459830\n",
      "epoch 43; iter: 0; batch classifier loss: 0.469745; batch adversarial loss: 0.415152\n",
      "epoch 43; iter: 200; batch classifier loss: 0.359770; batch adversarial loss: 0.485418\n",
      "epoch 44; iter: 0; batch classifier loss: 0.356543; batch adversarial loss: 0.484223\n",
      "epoch 44; iter: 200; batch classifier loss: 0.531664; batch adversarial loss: 0.417138\n",
      "epoch 45; iter: 0; batch classifier loss: 0.357637; batch adversarial loss: 0.443342\n",
      "epoch 45; iter: 200; batch classifier loss: 0.407610; batch adversarial loss: 0.360328\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324644; batch adversarial loss: 0.426403\n",
      "epoch 46; iter: 200; batch classifier loss: 0.344252; batch adversarial loss: 0.435790\n",
      "epoch 47; iter: 0; batch classifier loss: 0.370705; batch adversarial loss: 0.454751\n",
      "epoch 47; iter: 200; batch classifier loss: 0.356457; batch adversarial loss: 0.452190\n",
      "epoch 48; iter: 0; batch classifier loss: 0.346836; batch adversarial loss: 0.406389\n",
      "epoch 48; iter: 200; batch classifier loss: 0.420502; batch adversarial loss: 0.481449\n",
      "epoch 49; iter: 0; batch classifier loss: 0.451025; batch adversarial loss: 0.418250\n",
      "epoch 49; iter: 200; batch classifier loss: 0.317749; batch adversarial loss: 0.445083\n",
      "epoch 0; iter: 0; batch classifier loss: 113.667801; batch adversarial loss: 0.551972\n",
      "epoch 0; iter: 200; batch classifier loss: 9.605185; batch adversarial loss: 0.600439\n",
      "epoch 1; iter: 0; batch classifier loss: 4.078748; batch adversarial loss: 0.585518\n",
      "epoch 1; iter: 200; batch classifier loss: 8.217659; batch adversarial loss: 0.531070\n",
      "epoch 2; iter: 0; batch classifier loss: 4.100695; batch adversarial loss: 0.537574\n",
      "epoch 2; iter: 200; batch classifier loss: 2.170642; batch adversarial loss: 0.491959\n",
      "epoch 3; iter: 0; batch classifier loss: 4.071534; batch adversarial loss: 0.478930\n",
      "epoch 3; iter: 200; batch classifier loss: 2.199456; batch adversarial loss: 0.463808\n",
      "epoch 4; iter: 0; batch classifier loss: 2.465286; batch adversarial loss: 0.435979\n",
      "epoch 4; iter: 200; batch classifier loss: 2.517905; batch adversarial loss: 0.467558\n",
      "epoch 5; iter: 0; batch classifier loss: 2.478748; batch adversarial loss: 0.567453\n",
      "epoch 5; iter: 200; batch classifier loss: 2.262349; batch adversarial loss: 0.479272\n",
      "epoch 6; iter: 0; batch classifier loss: 2.050800; batch adversarial loss: 0.466541\n",
      "epoch 6; iter: 200; batch classifier loss: 0.509070; batch adversarial loss: 0.432260\n",
      "epoch 7; iter: 0; batch classifier loss: 0.702753; batch adversarial loss: 0.333290\n",
      "epoch 7; iter: 200; batch classifier loss: 0.509206; batch adversarial loss: 0.383515\n",
      "epoch 8; iter: 0; batch classifier loss: 0.685839; batch adversarial loss: 0.346161\n",
      "epoch 8; iter: 200; batch classifier loss: 0.684645; batch adversarial loss: 0.358801\n",
      "epoch 9; iter: 0; batch classifier loss: 0.533618; batch adversarial loss: 0.435455\n",
      "epoch 9; iter: 200; batch classifier loss: 0.940231; batch adversarial loss: 0.316616\n",
      "epoch 10; iter: 0; batch classifier loss: 0.527330; batch adversarial loss: 0.386067\n",
      "epoch 10; iter: 200; batch classifier loss: 0.487571; batch adversarial loss: 0.396442\n",
      "epoch 11; iter: 0; batch classifier loss: 0.329718; batch adversarial loss: 0.402081\n",
      "epoch 11; iter: 200; batch classifier loss: 0.408602; batch adversarial loss: 0.365587\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379062; batch adversarial loss: 0.410570\n",
      "epoch 12; iter: 200; batch classifier loss: 0.485910; batch adversarial loss: 0.406197\n",
      "epoch 13; iter: 0; batch classifier loss: 0.404914; batch adversarial loss: 0.355861\n",
      "epoch 13; iter: 200; batch classifier loss: 0.407013; batch adversarial loss: 0.466611\n",
      "epoch 14; iter: 0; batch classifier loss: 0.303188; batch adversarial loss: 0.406623\n",
      "epoch 14; iter: 200; batch classifier loss: 0.408856; batch adversarial loss: 0.487991\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329683; batch adversarial loss: 0.359675\n",
      "epoch 15; iter: 200; batch classifier loss: 0.345851; batch adversarial loss: 0.426443\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336111; batch adversarial loss: 0.347895\n",
      "epoch 16; iter: 200; batch classifier loss: 0.478989; batch adversarial loss: 0.337723\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339922; batch adversarial loss: 0.449984\n",
      "epoch 17; iter: 200; batch classifier loss: 0.354692; batch adversarial loss: 0.334433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.352611; batch adversarial loss: 0.419019\n",
      "epoch 18; iter: 200; batch classifier loss: 0.444453; batch adversarial loss: 0.337407\n",
      "epoch 19; iter: 0; batch classifier loss: 0.264797; batch adversarial loss: 0.421534\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385443; batch adversarial loss: 0.405357\n",
      "epoch 20; iter: 0; batch classifier loss: 0.321950; batch adversarial loss: 0.452410\n",
      "epoch 20; iter: 200; batch classifier loss: 0.333882; batch adversarial loss: 0.385015\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256081; batch adversarial loss: 0.465945\n",
      "epoch 21; iter: 200; batch classifier loss: 0.322666; batch adversarial loss: 0.478923\n",
      "epoch 22; iter: 0; batch classifier loss: 0.286862; batch adversarial loss: 0.414728\n",
      "epoch 22; iter: 200; batch classifier loss: 0.346079; batch adversarial loss: 0.314668\n",
      "epoch 23; iter: 0; batch classifier loss: 0.367676; batch adversarial loss: 0.364406\n",
      "epoch 23; iter: 200; batch classifier loss: 0.384817; batch adversarial loss: 0.519408\n",
      "epoch 24; iter: 0; batch classifier loss: 0.294108; batch adversarial loss: 0.376271\n",
      "epoch 24; iter: 200; batch classifier loss: 0.316944; batch adversarial loss: 0.430451\n",
      "epoch 25; iter: 0; batch classifier loss: 0.369441; batch adversarial loss: 0.382468\n",
      "epoch 25; iter: 200; batch classifier loss: 0.324211; batch adversarial loss: 0.383192\n",
      "epoch 26; iter: 0; batch classifier loss: 0.312091; batch adversarial loss: 0.348838\n",
      "epoch 26; iter: 200; batch classifier loss: 0.246268; batch adversarial loss: 0.410985\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.316797\n",
      "epoch 27; iter: 200; batch classifier loss: 0.313549; batch adversarial loss: 0.418573\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416835; batch adversarial loss: 0.418779\n",
      "epoch 28; iter: 200; batch classifier loss: 0.377698; batch adversarial loss: 0.522422\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323624; batch adversarial loss: 0.462769\n",
      "epoch 29; iter: 200; batch classifier loss: 0.330658; batch adversarial loss: 0.354382\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394703; batch adversarial loss: 0.429694\n",
      "epoch 30; iter: 200; batch classifier loss: 0.298317; batch adversarial loss: 0.414835\n",
      "epoch 31; iter: 0; batch classifier loss: 0.312418; batch adversarial loss: 0.382211\n",
      "epoch 31; iter: 200; batch classifier loss: 0.426058; batch adversarial loss: 0.328556\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299423; batch adversarial loss: 0.389308\n",
      "epoch 32; iter: 200; batch classifier loss: 0.361142; batch adversarial loss: 0.360774\n",
      "epoch 33; iter: 0; batch classifier loss: 0.301798; batch adversarial loss: 0.423402\n",
      "epoch 33; iter: 200; batch classifier loss: 0.335750; batch adversarial loss: 0.423226\n",
      "epoch 34; iter: 0; batch classifier loss: 0.384738; batch adversarial loss: 0.451502\n",
      "epoch 34; iter: 200; batch classifier loss: 0.356458; batch adversarial loss: 0.333119\n",
      "epoch 35; iter: 0; batch classifier loss: 0.305399; batch adversarial loss: 0.435849\n",
      "epoch 35; iter: 200; batch classifier loss: 0.402240; batch adversarial loss: 0.425268\n",
      "epoch 36; iter: 0; batch classifier loss: 0.437675; batch adversarial loss: 0.512745\n",
      "epoch 36; iter: 200; batch classifier loss: 0.334157; batch adversarial loss: 0.379521\n",
      "epoch 37; iter: 0; batch classifier loss: 0.322594; batch adversarial loss: 0.335829\n",
      "epoch 37; iter: 200; batch classifier loss: 0.318465; batch adversarial loss: 0.441689\n",
      "epoch 38; iter: 0; batch classifier loss: 0.287292; batch adversarial loss: 0.493920\n",
      "epoch 38; iter: 200; batch classifier loss: 0.334427; batch adversarial loss: 0.375745\n",
      "epoch 39; iter: 0; batch classifier loss: 0.498552; batch adversarial loss: 0.313598\n",
      "epoch 39; iter: 200; batch classifier loss: 0.451517; batch adversarial loss: 0.459683\n",
      "epoch 40; iter: 0; batch classifier loss: 0.499728; batch adversarial loss: 0.515244\n",
      "epoch 40; iter: 200; batch classifier loss: 0.493190; batch adversarial loss: 0.492189\n",
      "epoch 41; iter: 0; batch classifier loss: 0.358322; batch adversarial loss: 0.389958\n",
      "epoch 41; iter: 200; batch classifier loss: 0.430547; batch adversarial loss: 0.429848\n",
      "epoch 42; iter: 0; batch classifier loss: 0.485052; batch adversarial loss: 0.419647\n",
      "epoch 42; iter: 200; batch classifier loss: 0.389467; batch adversarial loss: 0.525755\n",
      "epoch 43; iter: 0; batch classifier loss: 0.533480; batch adversarial loss: 0.371235\n",
      "epoch 43; iter: 200; batch classifier loss: 0.475707; batch adversarial loss: 0.428351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.454899; batch adversarial loss: 0.421039\n",
      "epoch 44; iter: 200; batch classifier loss: 0.487576; batch adversarial loss: 0.397495\n",
      "epoch 45; iter: 0; batch classifier loss: 0.443062; batch adversarial loss: 0.416313\n",
      "epoch 45; iter: 200; batch classifier loss: 0.421536; batch adversarial loss: 0.388371\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356663; batch adversarial loss: 0.321382\n",
      "epoch 46; iter: 200; batch classifier loss: 0.463397; batch adversarial loss: 0.488438\n",
      "epoch 47; iter: 0; batch classifier loss: 0.460165; batch adversarial loss: 0.419995\n",
      "epoch 47; iter: 200; batch classifier loss: 0.448001; batch adversarial loss: 0.369255\n",
      "epoch 48; iter: 0; batch classifier loss: 0.481046; batch adversarial loss: 0.511047\n",
      "epoch 48; iter: 200; batch classifier loss: 0.358142; batch adversarial loss: 0.405537\n",
      "epoch 49; iter: 0; batch classifier loss: 0.615284; batch adversarial loss: 0.464529\n",
      "epoch 49; iter: 200; batch classifier loss: 0.496634; batch adversarial loss: 0.306526\n",
      "epoch 0; iter: 0; batch classifier loss: 54.226170; batch adversarial loss: 0.609717\n",
      "epoch 0; iter: 200; batch classifier loss: 5.735748; batch adversarial loss: 0.620903\n",
      "epoch 1; iter: 0; batch classifier loss: 2.956019; batch adversarial loss: 0.576651\n",
      "epoch 1; iter: 200; batch classifier loss: 3.983221; batch adversarial loss: 0.529264\n",
      "epoch 2; iter: 0; batch classifier loss: 2.888753; batch adversarial loss: 0.492502\n",
      "epoch 2; iter: 200; batch classifier loss: 7.266262; batch adversarial loss: 0.474712\n",
      "epoch 3; iter: 0; batch classifier loss: 2.443110; batch adversarial loss: 0.506449\n",
      "epoch 3; iter: 200; batch classifier loss: 0.478146; batch adversarial loss: 0.398337\n",
      "epoch 4; iter: 0; batch classifier loss: 2.094361; batch adversarial loss: 0.478022\n",
      "epoch 4; iter: 200; batch classifier loss: 1.954573; batch adversarial loss: 0.397144\n",
      "epoch 5; iter: 0; batch classifier loss: 1.835371; batch adversarial loss: 0.511755\n",
      "epoch 5; iter: 200; batch classifier loss: 2.014555; batch adversarial loss: 0.376847\n",
      "epoch 6; iter: 0; batch classifier loss: 1.605716; batch adversarial loss: 0.415526\n",
      "epoch 6; iter: 200; batch classifier loss: 0.723595; batch adversarial loss: 0.407408\n",
      "epoch 7; iter: 0; batch classifier loss: 0.973617; batch adversarial loss: 0.377306\n",
      "epoch 7; iter: 200; batch classifier loss: 0.492148; batch adversarial loss: 0.450758\n",
      "epoch 8; iter: 0; batch classifier loss: 0.669163; batch adversarial loss: 0.384319\n",
      "epoch 8; iter: 200; batch classifier loss: 0.510860; batch adversarial loss: 0.410745\n",
      "epoch 9; iter: 0; batch classifier loss: 0.636925; batch adversarial loss: 0.438846\n",
      "epoch 9; iter: 200; batch classifier loss: 0.442768; batch adversarial loss: 0.461061\n",
      "epoch 10; iter: 0; batch classifier loss: 0.595244; batch adversarial loss: 0.388381\n",
      "epoch 10; iter: 200; batch classifier loss: 0.595813; batch adversarial loss: 0.340236\n",
      "epoch 11; iter: 0; batch classifier loss: 0.468378; batch adversarial loss: 0.450698\n",
      "epoch 11; iter: 200; batch classifier loss: 0.427224; batch adversarial loss: 0.515116\n",
      "epoch 12; iter: 0; batch classifier loss: 0.387099; batch adversarial loss: 0.376527\n",
      "epoch 12; iter: 200; batch classifier loss: 0.486930; batch adversarial loss: 0.384434\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479230; batch adversarial loss: 0.479959\n",
      "epoch 13; iter: 200; batch classifier loss: 0.379912; batch adversarial loss: 0.396370\n",
      "epoch 14; iter: 0; batch classifier loss: 0.338744; batch adversarial loss: 0.461421\n",
      "epoch 14; iter: 200; batch classifier loss: 0.443237; batch adversarial loss: 0.424372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298172; batch adversarial loss: 0.272600\n",
      "epoch 15; iter: 200; batch classifier loss: 0.433261; batch adversarial loss: 0.500587\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311319; batch adversarial loss: 0.440566\n",
      "epoch 16; iter: 200; batch classifier loss: 0.398947; batch adversarial loss: 0.468815\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424462; batch adversarial loss: 0.439498\n",
      "epoch 17; iter: 200; batch classifier loss: 0.411894; batch adversarial loss: 0.388896\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335796; batch adversarial loss: 0.413610\n",
      "epoch 18; iter: 200; batch classifier loss: 0.356758; batch adversarial loss: 0.398726\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280986; batch adversarial loss: 0.425629\n",
      "epoch 19; iter: 200; batch classifier loss: 0.399142; batch adversarial loss: 0.476191\n",
      "epoch 20; iter: 0; batch classifier loss: 0.341901; batch adversarial loss: 0.415908\n",
      "epoch 20; iter: 200; batch classifier loss: 0.336222; batch adversarial loss: 0.348421\n",
      "epoch 21; iter: 0; batch classifier loss: 0.316715; batch adversarial loss: 0.528335\n",
      "epoch 21; iter: 200; batch classifier loss: 0.391749; batch adversarial loss: 0.394670\n",
      "epoch 22; iter: 0; batch classifier loss: 0.239573; batch adversarial loss: 0.474294\n",
      "epoch 22; iter: 200; batch classifier loss: 0.346381; batch adversarial loss: 0.405266\n",
      "epoch 23; iter: 0; batch classifier loss: 0.311737; batch adversarial loss: 0.353485\n",
      "epoch 23; iter: 200; batch classifier loss: 0.360929; batch adversarial loss: 0.434478\n",
      "epoch 24; iter: 0; batch classifier loss: 0.371688; batch adversarial loss: 0.421325\n",
      "epoch 24; iter: 200; batch classifier loss: 0.349817; batch adversarial loss: 0.404518\n",
      "epoch 25; iter: 0; batch classifier loss: 0.316199; batch adversarial loss: 0.424830\n",
      "epoch 25; iter: 200; batch classifier loss: 0.325573; batch adversarial loss: 0.388627\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329473; batch adversarial loss: 0.431296\n",
      "epoch 26; iter: 200; batch classifier loss: 0.392171; batch adversarial loss: 0.373424\n",
      "epoch 27; iter: 0; batch classifier loss: 0.375741; batch adversarial loss: 0.375684\n",
      "epoch 27; iter: 200; batch classifier loss: 0.309009; batch adversarial loss: 0.465158\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286591; batch adversarial loss: 0.504457\n",
      "epoch 28; iter: 200; batch classifier loss: 0.336904; batch adversarial loss: 0.450097\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320071; batch adversarial loss: 0.354110\n",
      "epoch 29; iter: 200; batch classifier loss: 0.432654; batch adversarial loss: 0.435365\n",
      "epoch 30; iter: 0; batch classifier loss: 0.392396; batch adversarial loss: 0.410369\n",
      "epoch 30; iter: 200; batch classifier loss: 0.338596; batch adversarial loss: 0.413515\n",
      "epoch 31; iter: 0; batch classifier loss: 0.311169; batch adversarial loss: 0.424824\n",
      "epoch 31; iter: 200; batch classifier loss: 0.328770; batch adversarial loss: 0.344525\n",
      "epoch 32; iter: 0; batch classifier loss: 0.364539; batch adversarial loss: 0.436789\n",
      "epoch 32; iter: 200; batch classifier loss: 0.329778; batch adversarial loss: 0.468522\n",
      "epoch 33; iter: 0; batch classifier loss: 0.360768; batch adversarial loss: 0.472508\n",
      "epoch 33; iter: 200; batch classifier loss: 0.328415; batch adversarial loss: 0.379781\n",
      "epoch 34; iter: 0; batch classifier loss: 0.349749; batch adversarial loss: 0.460721\n",
      "epoch 34; iter: 200; batch classifier loss: 0.285840; batch adversarial loss: 0.479862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444521; batch adversarial loss: 0.402538\n",
      "epoch 35; iter: 200; batch classifier loss: 0.404618; batch adversarial loss: 0.376902\n",
      "epoch 36; iter: 0; batch classifier loss: 0.299566; batch adversarial loss: 0.406668\n",
      "epoch 36; iter: 200; batch classifier loss: 0.418220; batch adversarial loss: 0.428387\n",
      "epoch 37; iter: 0; batch classifier loss: 0.420025; batch adversarial loss: 0.389670\n",
      "epoch 37; iter: 200; batch classifier loss: 0.440485; batch adversarial loss: 0.463707\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400907; batch adversarial loss: 0.348139\n",
      "epoch 38; iter: 200; batch classifier loss: 0.276769; batch adversarial loss: 0.442720\n",
      "epoch 39; iter: 0; batch classifier loss: 0.280744; batch adversarial loss: 0.388062\n",
      "epoch 39; iter: 200; batch classifier loss: 0.366941; batch adversarial loss: 0.407667\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391273; batch adversarial loss: 0.360759\n",
      "epoch 40; iter: 200; batch classifier loss: 0.391358; batch adversarial loss: 0.328898\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408085; batch adversarial loss: 0.327155\n",
      "epoch 41; iter: 200; batch classifier loss: 0.427594; batch adversarial loss: 0.416445\n",
      "epoch 42; iter: 0; batch classifier loss: 0.511615; batch adversarial loss: 0.536776\n",
      "epoch 42; iter: 200; batch classifier loss: 0.382259; batch adversarial loss: 0.478025\n",
      "epoch 43; iter: 0; batch classifier loss: 0.353314; batch adversarial loss: 0.327974\n",
      "epoch 43; iter: 200; batch classifier loss: 0.609964; batch adversarial loss: 0.441855\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323062; batch adversarial loss: 0.419610\n",
      "epoch 44; iter: 200; batch classifier loss: 0.495981; batch adversarial loss: 0.487602\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404901; batch adversarial loss: 0.445587\n",
      "epoch 45; iter: 200; batch classifier loss: 0.479602; batch adversarial loss: 0.380314\n",
      "epoch 46; iter: 0; batch classifier loss: 0.649453; batch adversarial loss: 0.464717\n",
      "epoch 46; iter: 200; batch classifier loss: 0.366509; batch adversarial loss: 0.419337\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373832; batch adversarial loss: 0.424741\n",
      "epoch 47; iter: 200; batch classifier loss: 0.455501; batch adversarial loss: 0.304214\n",
      "epoch 48; iter: 0; batch classifier loss: 0.357224; batch adversarial loss: 0.479550\n",
      "epoch 48; iter: 200; batch classifier loss: 0.419245; batch adversarial loss: 0.434395\n",
      "epoch 49; iter: 0; batch classifier loss: 0.389634; batch adversarial loss: 0.365106\n",
      "epoch 49; iter: 200; batch classifier loss: 0.434106; batch adversarial loss: 0.446178\n",
      "epoch 0; iter: 0; batch classifier loss: 28.915186; batch adversarial loss: 1.026059\n",
      "epoch 0; iter: 200; batch classifier loss: 16.474146; batch adversarial loss: 1.155539\n",
      "epoch 1; iter: 0; batch classifier loss: 6.223948; batch adversarial loss: 0.985973\n",
      "epoch 1; iter: 200; batch classifier loss: 3.340470; batch adversarial loss: 0.772282\n",
      "epoch 2; iter: 0; batch classifier loss: 7.437258; batch adversarial loss: 0.669671\n",
      "epoch 2; iter: 200; batch classifier loss: 3.229492; batch adversarial loss: 0.568169\n",
      "epoch 3; iter: 0; batch classifier loss: 3.188514; batch adversarial loss: 0.532687\n",
      "epoch 3; iter: 200; batch classifier loss: 0.646641; batch adversarial loss: 0.532699\n",
      "epoch 4; iter: 0; batch classifier loss: 3.264181; batch adversarial loss: 0.502834\n",
      "epoch 4; iter: 200; batch classifier loss: 5.673540; batch adversarial loss: 0.478844\n",
      "epoch 5; iter: 0; batch classifier loss: 1.407534; batch adversarial loss: 0.512371\n",
      "epoch 5; iter: 200; batch classifier loss: 1.967446; batch adversarial loss: 0.432579\n",
      "epoch 6; iter: 0; batch classifier loss: 1.463426; batch adversarial loss: 0.436481\n",
      "epoch 6; iter: 200; batch classifier loss: 1.461862; batch adversarial loss: 0.424973\n",
      "epoch 7; iter: 0; batch classifier loss: 1.517472; batch adversarial loss: 0.486239\n",
      "epoch 7; iter: 200; batch classifier loss: 0.741577; batch adversarial loss: 0.523283\n",
      "epoch 8; iter: 0; batch classifier loss: 2.648932; batch adversarial loss: 0.461885\n",
      "epoch 8; iter: 200; batch classifier loss: 0.621055; batch adversarial loss: 0.397538\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558147; batch adversarial loss: 0.425793\n",
      "epoch 9; iter: 200; batch classifier loss: 0.528345; batch adversarial loss: 0.443144\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581351; batch adversarial loss: 0.410804\n",
      "epoch 10; iter: 200; batch classifier loss: 0.680184; batch adversarial loss: 0.415805\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392817; batch adversarial loss: 0.467742\n",
      "epoch 11; iter: 200; batch classifier loss: 0.442058; batch adversarial loss: 0.419809\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598657; batch adversarial loss: 0.412641\n",
      "epoch 12; iter: 200; batch classifier loss: 0.456498; batch adversarial loss: 0.553237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520194; batch adversarial loss: 0.382897\n",
      "epoch 13; iter: 200; batch classifier loss: 0.633842; batch adversarial loss: 0.363893\n",
      "epoch 14; iter: 0; batch classifier loss: 0.423657; batch adversarial loss: 0.396627\n",
      "epoch 14; iter: 200; batch classifier loss: 0.403768; batch adversarial loss: 0.394333\n",
      "epoch 15; iter: 0; batch classifier loss: 1.907007; batch adversarial loss: 0.390290\n",
      "epoch 15; iter: 200; batch classifier loss: 0.377210; batch adversarial loss: 0.515546\n",
      "epoch 16; iter: 0; batch classifier loss: 0.405047; batch adversarial loss: 0.486823\n",
      "epoch 16; iter: 200; batch classifier loss: 0.377474; batch adversarial loss: 0.389052\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375009; batch adversarial loss: 0.460166\n",
      "epoch 17; iter: 200; batch classifier loss: 0.378271; batch adversarial loss: 0.460974\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348782; batch adversarial loss: 0.366600\n",
      "epoch 18; iter: 200; batch classifier loss: 0.491138; batch adversarial loss: 0.363318\n",
      "epoch 19; iter: 0; batch classifier loss: 0.476787; batch adversarial loss: 0.389308\n",
      "epoch 19; iter: 200; batch classifier loss: 0.351482; batch adversarial loss: 0.352063\n",
      "epoch 20; iter: 0; batch classifier loss: 0.399200; batch adversarial loss: 0.365026\n",
      "epoch 20; iter: 200; batch classifier loss: 0.289284; batch adversarial loss: 0.433393\n",
      "epoch 21; iter: 0; batch classifier loss: 0.520467; batch adversarial loss: 0.438765\n",
      "epoch 21; iter: 200; batch classifier loss: 0.327125; batch adversarial loss: 0.567892\n",
      "epoch 22; iter: 0; batch classifier loss: 0.426376; batch adversarial loss: 0.431852\n",
      "epoch 22; iter: 200; batch classifier loss: 0.359144; batch adversarial loss: 0.468979\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418512; batch adversarial loss: 0.390053\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371302; batch adversarial loss: 0.364501\n",
      "epoch 24; iter: 0; batch classifier loss: 0.424068; batch adversarial loss: 0.445958\n",
      "epoch 24; iter: 200; batch classifier loss: 0.400095; batch adversarial loss: 0.535933\n",
      "epoch 25; iter: 0; batch classifier loss: 0.383505; batch adversarial loss: 0.380844\n",
      "epoch 25; iter: 200; batch classifier loss: 0.385831; batch adversarial loss: 0.479763\n",
      "epoch 26; iter: 0; batch classifier loss: 0.281495; batch adversarial loss: 0.388103\n",
      "epoch 26; iter: 200; batch classifier loss: 0.501929; batch adversarial loss: 0.427623\n",
      "epoch 27; iter: 0; batch classifier loss: 0.378230; batch adversarial loss: 0.342011\n",
      "epoch 27; iter: 200; batch classifier loss: 0.276108; batch adversarial loss: 0.346251\n",
      "epoch 28; iter: 0; batch classifier loss: 0.300012; batch adversarial loss: 0.399765\n",
      "epoch 28; iter: 200; batch classifier loss: 0.382953; batch adversarial loss: 0.443154\n",
      "epoch 29; iter: 0; batch classifier loss: 0.351165; batch adversarial loss: 0.345132\n",
      "epoch 29; iter: 200; batch classifier loss: 0.238781; batch adversarial loss: 0.391962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.417112; batch adversarial loss: 0.520971\n",
      "epoch 30; iter: 200; batch classifier loss: 0.386835; batch adversarial loss: 0.321413\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334367; batch adversarial loss: 0.408170\n",
      "epoch 31; iter: 200; batch classifier loss: 0.406423; batch adversarial loss: 0.332510\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348854; batch adversarial loss: 0.423391\n",
      "epoch 32; iter: 200; batch classifier loss: 0.381943; batch adversarial loss: 0.449647\n",
      "epoch 33; iter: 0; batch classifier loss: 0.290508; batch adversarial loss: 0.463308\n",
      "epoch 33; iter: 200; batch classifier loss: 0.487470; batch adversarial loss: 0.347707\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408255; batch adversarial loss: 0.380512\n",
      "epoch 34; iter: 200; batch classifier loss: 0.319663; batch adversarial loss: 0.399522\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434314; batch adversarial loss: 0.396075\n",
      "epoch 35; iter: 200; batch classifier loss: 0.379060; batch adversarial loss: 0.430644\n",
      "epoch 36; iter: 0; batch classifier loss: 0.387844; batch adversarial loss: 0.420769\n",
      "epoch 36; iter: 200; batch classifier loss: 0.433037; batch adversarial loss: 0.388457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399459; batch adversarial loss: 0.380898\n",
      "epoch 37; iter: 200; batch classifier loss: 0.474051; batch adversarial loss: 0.435515\n",
      "epoch 38; iter: 0; batch classifier loss: 0.342620; batch adversarial loss: 0.371806\n",
      "epoch 38; iter: 200; batch classifier loss: 0.417131; batch adversarial loss: 0.448233\n",
      "epoch 39; iter: 0; batch classifier loss: 0.349816; batch adversarial loss: 0.455248\n",
      "epoch 39; iter: 200; batch classifier loss: 0.447904; batch adversarial loss: 0.385408\n",
      "epoch 40; iter: 0; batch classifier loss: 0.362042; batch adversarial loss: 0.427534\n",
      "epoch 40; iter: 200; batch classifier loss: 0.470962; batch adversarial loss: 0.416189\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385997; batch adversarial loss: 0.342614\n",
      "epoch 41; iter: 200; batch classifier loss: 0.328550; batch adversarial loss: 0.450467\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415375; batch adversarial loss: 0.451176\n",
      "epoch 42; iter: 200; batch classifier loss: 0.368950; batch adversarial loss: 0.442209\n",
      "epoch 43; iter: 0; batch classifier loss: 0.372823; batch adversarial loss: 0.490623\n",
      "epoch 43; iter: 200; batch classifier loss: 0.419661; batch adversarial loss: 0.344404\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430005; batch adversarial loss: 0.376309\n",
      "epoch 44; iter: 200; batch classifier loss: 0.328630; batch adversarial loss: 0.441731\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371340; batch adversarial loss: 0.433033\n",
      "epoch 45; iter: 200; batch classifier loss: 0.352770; batch adversarial loss: 0.349686\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381979; batch adversarial loss: 0.424234\n",
      "epoch 46; iter: 200; batch classifier loss: 0.434563; batch adversarial loss: 0.400902\n",
      "epoch 47; iter: 0; batch classifier loss: 0.328903; batch adversarial loss: 0.442865\n",
      "epoch 47; iter: 200; batch classifier loss: 0.422291; batch adversarial loss: 0.426949\n",
      "epoch 48; iter: 0; batch classifier loss: 0.587686; batch adversarial loss: 0.427833\n",
      "epoch 48; iter: 200; batch classifier loss: 0.364597; batch adversarial loss: 0.491191\n",
      "epoch 49; iter: 0; batch classifier loss: 0.504503; batch adversarial loss: 0.400603\n",
      "epoch 49; iter: 200; batch classifier loss: 0.337656; batch adversarial loss: 0.372010\n",
      "epoch 0; iter: 0; batch classifier loss: 14.841000; batch adversarial loss: 0.810194\n",
      "epoch 0; iter: 200; batch classifier loss: 3.370831; batch adversarial loss: 0.663621\n",
      "epoch 1; iter: 0; batch classifier loss: 2.989476; batch adversarial loss: 0.573532\n",
      "epoch 1; iter: 200; batch classifier loss: 5.954346; batch adversarial loss: 0.533704\n",
      "epoch 2; iter: 0; batch classifier loss: 3.865140; batch adversarial loss: 0.525033\n",
      "epoch 2; iter: 200; batch classifier loss: 3.290200; batch adversarial loss: 0.531608\n",
      "epoch 3; iter: 0; batch classifier loss: 2.432329; batch adversarial loss: 0.460336\n",
      "epoch 3; iter: 200; batch classifier loss: 1.781390; batch adversarial loss: 0.443570\n",
      "epoch 4; iter: 0; batch classifier loss: 1.694709; batch adversarial loss: 0.493983\n",
      "epoch 4; iter: 200; batch classifier loss: 2.989731; batch adversarial loss: 0.423935\n",
      "epoch 5; iter: 0; batch classifier loss: 0.869916; batch adversarial loss: 0.426746\n",
      "epoch 5; iter: 200; batch classifier loss: 0.762360; batch adversarial loss: 0.451624\n",
      "epoch 6; iter: 0; batch classifier loss: 0.936544; batch adversarial loss: 0.371637\n",
      "epoch 6; iter: 200; batch classifier loss: 0.728602; batch adversarial loss: 0.444907\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584407; batch adversarial loss: 0.433076\n",
      "epoch 7; iter: 200; batch classifier loss: 0.501063; batch adversarial loss: 0.425592\n",
      "epoch 8; iter: 0; batch classifier loss: 0.842855; batch adversarial loss: 0.494963\n",
      "epoch 8; iter: 200; batch classifier loss: 0.347358; batch adversarial loss: 0.392566\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517009; batch adversarial loss: 0.392863\n",
      "epoch 9; iter: 200; batch classifier loss: 0.455465; batch adversarial loss: 0.473059\n",
      "epoch 10; iter: 0; batch classifier loss: 0.607357; batch adversarial loss: 0.362237\n",
      "epoch 10; iter: 200; batch classifier loss: 0.643167; batch adversarial loss: 0.327388\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553258; batch adversarial loss: 0.408856\n",
      "epoch 11; iter: 200; batch classifier loss: 0.387720; batch adversarial loss: 0.336930\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475258; batch adversarial loss: 0.397746\n",
      "epoch 12; iter: 200; batch classifier loss: 0.399272; batch adversarial loss: 0.403566\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389219; batch adversarial loss: 0.393626\n",
      "epoch 13; iter: 200; batch classifier loss: 0.329123; batch adversarial loss: 0.539986\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330212; batch adversarial loss: 0.440332\n",
      "epoch 14; iter: 200; batch classifier loss: 0.773991; batch adversarial loss: 0.334186\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343018; batch adversarial loss: 0.418174\n",
      "epoch 15; iter: 200; batch classifier loss: 0.477614; batch adversarial loss: 0.361414\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391862; batch adversarial loss: 0.385403\n",
      "epoch 16; iter: 200; batch classifier loss: 0.375086; batch adversarial loss: 0.380040\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372261; batch adversarial loss: 0.422543\n",
      "epoch 17; iter: 200; batch classifier loss: 0.410661; batch adversarial loss: 0.383249\n",
      "epoch 18; iter: 0; batch classifier loss: 0.377864; batch adversarial loss: 0.425482\n",
      "epoch 18; iter: 200; batch classifier loss: 0.375077; batch adversarial loss: 0.336983\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378282; batch adversarial loss: 0.480494\n",
      "epoch 19; iter: 200; batch classifier loss: 0.392544; batch adversarial loss: 0.302501\n",
      "epoch 20; iter: 0; batch classifier loss: 0.339189; batch adversarial loss: 0.390794\n",
      "epoch 20; iter: 200; batch classifier loss: 0.444905; batch adversarial loss: 0.386334\n",
      "epoch 21; iter: 0; batch classifier loss: 0.383036; batch adversarial loss: 0.315006\n",
      "epoch 21; iter: 200; batch classifier loss: 0.374716; batch adversarial loss: 0.364937\n",
      "epoch 22; iter: 0; batch classifier loss: 0.260176; batch adversarial loss: 0.439485\n",
      "epoch 22; iter: 200; batch classifier loss: 0.259777; batch adversarial loss: 0.419493\n",
      "epoch 23; iter: 0; batch classifier loss: 0.371585; batch adversarial loss: 0.374649\n",
      "epoch 23; iter: 200; batch classifier loss: 0.460755; batch adversarial loss: 0.463494\n",
      "epoch 24; iter: 0; batch classifier loss: 0.352262; batch adversarial loss: 0.354200\n",
      "epoch 24; iter: 200; batch classifier loss: 0.393129; batch adversarial loss: 0.406834\n",
      "epoch 25; iter: 0; batch classifier loss: 0.310126; batch adversarial loss: 0.371878\n",
      "epoch 25; iter: 200; batch classifier loss: 0.303913; batch adversarial loss: 0.412572\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296641; batch adversarial loss: 0.350859\n",
      "epoch 26; iter: 200; batch classifier loss: 0.352186; batch adversarial loss: 0.320654\n",
      "epoch 27; iter: 0; batch classifier loss: 0.330617; batch adversarial loss: 0.469093\n",
      "epoch 27; iter: 200; batch classifier loss: 0.316902; batch adversarial loss: 0.255950\n",
      "epoch 28; iter: 0; batch classifier loss: 0.299188; batch adversarial loss: 0.480216\n",
      "epoch 28; iter: 200; batch classifier loss: 0.414965; batch adversarial loss: 0.438245\n",
      "epoch 29; iter: 0; batch classifier loss: 0.306058; batch adversarial loss: 0.359115\n",
      "epoch 29; iter: 200; batch classifier loss: 0.347737; batch adversarial loss: 0.434945\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444311; batch adversarial loss: 0.481950\n",
      "epoch 30; iter: 200; batch classifier loss: 0.365605; batch adversarial loss: 0.389390\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366893; batch adversarial loss: 0.401443\n",
      "epoch 31; iter: 200; batch classifier loss: 0.348739; batch adversarial loss: 0.398448\n",
      "epoch 32; iter: 0; batch classifier loss: 0.334466; batch adversarial loss: 0.395244\n",
      "epoch 32; iter: 200; batch classifier loss: 0.395475; batch adversarial loss: 0.492987\n",
      "epoch 33; iter: 0; batch classifier loss: 0.331425; batch adversarial loss: 0.393430\n",
      "epoch 33; iter: 200; batch classifier loss: 0.318031; batch adversarial loss: 0.444411\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310605; batch adversarial loss: 0.405543\n",
      "epoch 34; iter: 200; batch classifier loss: 0.349513; batch adversarial loss: 0.484062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.334139; batch adversarial loss: 0.378893\n",
      "epoch 35; iter: 200; batch classifier loss: 0.271941; batch adversarial loss: 0.454356\n",
      "epoch 36; iter: 0; batch classifier loss: 0.323247; batch adversarial loss: 0.333045\n",
      "epoch 36; iter: 200; batch classifier loss: 0.397040; batch adversarial loss: 0.411132\n",
      "epoch 37; iter: 0; batch classifier loss: 0.340710; batch adversarial loss: 0.499316\n",
      "epoch 37; iter: 200; batch classifier loss: 0.437450; batch adversarial loss: 0.326658\n",
      "epoch 38; iter: 0; batch classifier loss: 0.327863; batch adversarial loss: 0.552938\n",
      "epoch 38; iter: 200; batch classifier loss: 0.358968; batch adversarial loss: 0.467942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.345798; batch adversarial loss: 0.422853\n",
      "epoch 39; iter: 200; batch classifier loss: 0.349705; batch adversarial loss: 0.482613\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367790; batch adversarial loss: 0.355016\n",
      "epoch 40; iter: 200; batch classifier loss: 0.448779; batch adversarial loss: 0.330723\n",
      "epoch 41; iter: 0; batch classifier loss: 0.341643; batch adversarial loss: 0.402356\n",
      "epoch 41; iter: 200; batch classifier loss: 0.473100; batch adversarial loss: 0.396086\n",
      "epoch 42; iter: 0; batch classifier loss: 0.322284; batch adversarial loss: 0.448770\n",
      "epoch 42; iter: 200; batch classifier loss: 0.360831; batch adversarial loss: 0.371865\n",
      "epoch 43; iter: 0; batch classifier loss: 0.307205; batch adversarial loss: 0.383002\n",
      "epoch 43; iter: 200; batch classifier loss: 0.373677; batch adversarial loss: 0.500183\n",
      "epoch 44; iter: 0; batch classifier loss: 0.329581; batch adversarial loss: 0.406635\n",
      "epoch 44; iter: 200; batch classifier loss: 0.317918; batch adversarial loss: 0.483557\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403514; batch adversarial loss: 0.467900\n",
      "epoch 45; iter: 200; batch classifier loss: 0.356371; batch adversarial loss: 0.315025\n",
      "epoch 46; iter: 0; batch classifier loss: 0.526006; batch adversarial loss: 0.395784\n",
      "epoch 46; iter: 200; batch classifier loss: 0.351619; batch adversarial loss: 0.427931\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433973; batch adversarial loss: 0.426078\n",
      "epoch 47; iter: 200; batch classifier loss: 0.254461; batch adversarial loss: 0.527914\n",
      "epoch 48; iter: 0; batch classifier loss: 0.232509; batch adversarial loss: 0.349231\n",
      "epoch 48; iter: 200; batch classifier loss: 0.459466; batch adversarial loss: 0.445907\n",
      "epoch 49; iter: 0; batch classifier loss: 0.426517; batch adversarial loss: 0.381958\n",
      "epoch 49; iter: 200; batch classifier loss: 0.442661; batch adversarial loss: 0.388947\n",
      "epoch 0; iter: 0; batch classifier loss: 106.479561; batch adversarial loss: 0.797526\n",
      "epoch 0; iter: 200; batch classifier loss: 9.775826; batch adversarial loss: 0.734374\n",
      "epoch 1; iter: 0; batch classifier loss: 6.627483; batch adversarial loss: 0.636414\n",
      "epoch 1; iter: 200; batch classifier loss: 8.313911; batch adversarial loss: 0.546143\n",
      "epoch 2; iter: 0; batch classifier loss: 3.840646; batch adversarial loss: 0.507422\n",
      "epoch 2; iter: 200; batch classifier loss: 3.423306; batch adversarial loss: 0.537509\n",
      "epoch 3; iter: 0; batch classifier loss: 3.490082; batch adversarial loss: 0.475321\n",
      "epoch 3; iter: 200; batch classifier loss: 3.639997; batch adversarial loss: 0.478454\n",
      "epoch 4; iter: 0; batch classifier loss: 3.045899; batch adversarial loss: 0.462765\n",
      "epoch 4; iter: 200; batch classifier loss: 0.612037; batch adversarial loss: 0.533354\n",
      "epoch 5; iter: 0; batch classifier loss: 1.425201; batch adversarial loss: 0.539308\n",
      "epoch 5; iter: 200; batch classifier loss: 1.468001; batch adversarial loss: 0.399618\n",
      "epoch 6; iter: 0; batch classifier loss: 1.398137; batch adversarial loss: 0.479715\n",
      "epoch 6; iter: 200; batch classifier loss: 0.716361; batch adversarial loss: 0.423316\n",
      "epoch 7; iter: 0; batch classifier loss: 0.646764; batch adversarial loss: 0.373385\n",
      "epoch 7; iter: 200; batch classifier loss: 0.511694; batch adversarial loss: 0.372055\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533204; batch adversarial loss: 0.477483\n",
      "epoch 8; iter: 200; batch classifier loss: 0.518680; batch adversarial loss: 0.409592\n",
      "epoch 9; iter: 0; batch classifier loss: 0.419401; batch adversarial loss: 0.387147\n",
      "epoch 9; iter: 200; batch classifier loss: 0.544385; batch adversarial loss: 0.396079\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496458; batch adversarial loss: 0.429680\n",
      "epoch 10; iter: 200; batch classifier loss: 0.577072; batch adversarial loss: 0.374449\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344841; batch adversarial loss: 0.312793\n",
      "epoch 11; iter: 200; batch classifier loss: 0.354746; batch adversarial loss: 0.369388\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361345; batch adversarial loss: 0.352052\n",
      "epoch 12; iter: 200; batch classifier loss: 0.587843; batch adversarial loss: 0.389154\n",
      "epoch 13; iter: 0; batch classifier loss: 1.071572; batch adversarial loss: 0.530008\n",
      "epoch 13; iter: 200; batch classifier loss: 0.711788; batch adversarial loss: 0.406203\n",
      "epoch 14; iter: 0; batch classifier loss: 0.332916; batch adversarial loss: 0.424985\n",
      "epoch 14; iter: 200; batch classifier loss: 0.381337; batch adversarial loss: 0.355062\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350624; batch adversarial loss: 0.387365\n",
      "epoch 15; iter: 200; batch classifier loss: 0.371419; batch adversarial loss: 0.413768\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387916; batch adversarial loss: 0.428756\n",
      "epoch 16; iter: 200; batch classifier loss: 0.374744; batch adversarial loss: 0.401520\n",
      "epoch 17; iter: 0; batch classifier loss: 0.441657; batch adversarial loss: 0.442064\n",
      "epoch 17; iter: 200; batch classifier loss: 0.385447; batch adversarial loss: 0.478935\n",
      "epoch 18; iter: 0; batch classifier loss: 0.421145; batch adversarial loss: 0.415384\n",
      "epoch 18; iter: 200; batch classifier loss: 0.876852; batch adversarial loss: 0.440085\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294652; batch adversarial loss: 0.481343\n",
      "epoch 19; iter: 200; batch classifier loss: 0.376537; batch adversarial loss: 0.390779\n",
      "epoch 20; iter: 0; batch classifier loss: 0.329534; batch adversarial loss: 0.378473\n",
      "epoch 20; iter: 200; batch classifier loss: 0.345448; batch adversarial loss: 0.424144\n",
      "epoch 21; iter: 0; batch classifier loss: 0.316139; batch adversarial loss: 0.412024\n",
      "epoch 21; iter: 200; batch classifier loss: 0.303890; batch adversarial loss: 0.514995\n",
      "epoch 22; iter: 0; batch classifier loss: 0.337741; batch adversarial loss: 0.447239\n",
      "epoch 22; iter: 200; batch classifier loss: 0.411841; batch adversarial loss: 0.391375\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285857; batch adversarial loss: 0.457851\n",
      "epoch 23; iter: 200; batch classifier loss: 0.349031; batch adversarial loss: 0.425612\n",
      "epoch 24; iter: 0; batch classifier loss: 0.368866; batch adversarial loss: 0.429349\n",
      "epoch 24; iter: 200; batch classifier loss: 0.387967; batch adversarial loss: 0.538712\n",
      "epoch 25; iter: 0; batch classifier loss: 0.365236; batch adversarial loss: 0.358649\n",
      "epoch 25; iter: 200; batch classifier loss: 0.382360; batch adversarial loss: 0.362792\n",
      "epoch 26; iter: 0; batch classifier loss: 0.285310; batch adversarial loss: 0.344857\n",
      "epoch 26; iter: 200; batch classifier loss: 0.448933; batch adversarial loss: 0.335559\n",
      "epoch 27; iter: 0; batch classifier loss: 0.294405; batch adversarial loss: 0.492409\n",
      "epoch 27; iter: 200; batch classifier loss: 0.342001; batch adversarial loss: 0.337093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352556; batch adversarial loss: 0.421268\n",
      "epoch 28; iter: 200; batch classifier loss: 0.369695; batch adversarial loss: 0.275309\n",
      "epoch 29; iter: 0; batch classifier loss: 0.325745; batch adversarial loss: 0.443690\n",
      "epoch 29; iter: 200; batch classifier loss: 0.346550; batch adversarial loss: 0.441216\n",
      "epoch 30; iter: 0; batch classifier loss: 0.366229; batch adversarial loss: 0.409817\n",
      "epoch 30; iter: 200; batch classifier loss: 0.409139; batch adversarial loss: 0.467017\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390892; batch adversarial loss: 0.371548\n",
      "epoch 31; iter: 200; batch classifier loss: 0.319111; batch adversarial loss: 0.316488\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320331; batch adversarial loss: 0.401182\n",
      "epoch 32; iter: 200; batch classifier loss: 0.381093; batch adversarial loss: 0.469056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.378990; batch adversarial loss: 0.351108\n",
      "epoch 33; iter: 200; batch classifier loss: 0.399350; batch adversarial loss: 0.508060\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350814; batch adversarial loss: 0.506253\n",
      "epoch 34; iter: 200; batch classifier loss: 0.342429; batch adversarial loss: 0.335525\n",
      "epoch 35; iter: 0; batch classifier loss: 0.362958; batch adversarial loss: 0.410124\n",
      "epoch 35; iter: 200; batch classifier loss: 0.325935; batch adversarial loss: 0.378424\n",
      "epoch 36; iter: 0; batch classifier loss: 0.277171; batch adversarial loss: 0.433773\n",
      "epoch 36; iter: 200; batch classifier loss: 0.287551; batch adversarial loss: 0.361018\n",
      "epoch 37; iter: 0; batch classifier loss: 0.326582; batch adversarial loss: 0.302384\n",
      "epoch 37; iter: 200; batch classifier loss: 0.377911; batch adversarial loss: 0.405320\n",
      "epoch 38; iter: 0; batch classifier loss: 0.322338; batch adversarial loss: 0.536867\n",
      "epoch 38; iter: 200; batch classifier loss: 0.349951; batch adversarial loss: 0.343892\n",
      "epoch 39; iter: 0; batch classifier loss: 0.319792; batch adversarial loss: 0.420538\n",
      "epoch 39; iter: 200; batch classifier loss: 0.325967; batch adversarial loss: 0.347002\n",
      "epoch 40; iter: 0; batch classifier loss: 0.352456; batch adversarial loss: 0.400423\n",
      "epoch 40; iter: 200; batch classifier loss: 0.293526; batch adversarial loss: 0.386914\n",
      "epoch 41; iter: 0; batch classifier loss: 0.321509; batch adversarial loss: 0.462172\n",
      "epoch 41; iter: 200; batch classifier loss: 0.487466; batch adversarial loss: 0.433819\n",
      "epoch 42; iter: 0; batch classifier loss: 0.245958; batch adversarial loss: 0.472069\n",
      "epoch 42; iter: 200; batch classifier loss: 0.434134; batch adversarial loss: 0.425671\n",
      "epoch 43; iter: 0; batch classifier loss: 0.387263; batch adversarial loss: 0.354703\n",
      "epoch 43; iter: 200; batch classifier loss: 0.280836; batch adversarial loss: 0.457543\n",
      "epoch 44; iter: 0; batch classifier loss: 0.313689; batch adversarial loss: 0.355042\n",
      "epoch 44; iter: 200; batch classifier loss: 0.308925; batch adversarial loss: 0.432627\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442237; batch adversarial loss: 0.292785\n",
      "epoch 45; iter: 200; batch classifier loss: 0.295761; batch adversarial loss: 0.397309\n",
      "epoch 46; iter: 0; batch classifier loss: 0.301349; batch adversarial loss: 0.374835\n",
      "epoch 46; iter: 200; batch classifier loss: 0.314819; batch adversarial loss: 0.483532\n",
      "epoch 47; iter: 0; batch classifier loss: 0.352240; batch adversarial loss: 0.385946\n",
      "epoch 47; iter: 200; batch classifier loss: 0.400748; batch adversarial loss: 0.338212\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382063; batch adversarial loss: 0.391521\n",
      "epoch 48; iter: 200; batch classifier loss: 0.269965; batch adversarial loss: 0.354196\n",
      "epoch 49; iter: 0; batch classifier loss: 0.305564; batch adversarial loss: 0.471375\n",
      "epoch 49; iter: 200; batch classifier loss: 0.351027; batch adversarial loss: 0.397333\n",
      "epoch 0; iter: 0; batch classifier loss: 20.658209; batch adversarial loss: 1.053020\n",
      "epoch 0; iter: 200; batch classifier loss: 10.034805; batch adversarial loss: 0.923383\n",
      "epoch 1; iter: 0; batch classifier loss: 11.140269; batch adversarial loss: 0.812430\n",
      "epoch 1; iter: 200; batch classifier loss: 7.877841; batch adversarial loss: 0.637364\n",
      "epoch 2; iter: 0; batch classifier loss: 2.046397; batch adversarial loss: 0.582274\n",
      "epoch 2; iter: 200; batch classifier loss: 4.355681; batch adversarial loss: 0.479569\n",
      "epoch 3; iter: 0; batch classifier loss: 7.571899; batch adversarial loss: 0.440449\n",
      "epoch 3; iter: 200; batch classifier loss: 0.845929; batch adversarial loss: 0.464390\n",
      "epoch 4; iter: 0; batch classifier loss: 1.544060; batch adversarial loss: 0.478447\n",
      "epoch 4; iter: 200; batch classifier loss: 0.969004; batch adversarial loss: 0.464586\n",
      "epoch 5; iter: 0; batch classifier loss: 3.513046; batch adversarial loss: 0.478770\n",
      "epoch 5; iter: 200; batch classifier loss: 1.589543; batch adversarial loss: 0.511024\n",
      "epoch 6; iter: 0; batch classifier loss: 0.640404; batch adversarial loss: 0.349934\n",
      "epoch 6; iter: 200; batch classifier loss: 0.660651; batch adversarial loss: 0.464553\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485970; batch adversarial loss: 0.476542\n",
      "epoch 7; iter: 200; batch classifier loss: 0.619265; batch adversarial loss: 0.422576\n",
      "epoch 8; iter: 0; batch classifier loss: 0.527593; batch adversarial loss: 0.376723\n",
      "epoch 8; iter: 200; batch classifier loss: 0.359951; batch adversarial loss: 0.482537\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519867; batch adversarial loss: 0.441566\n",
      "epoch 9; iter: 200; batch classifier loss: 0.521566; batch adversarial loss: 0.372228\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486562; batch adversarial loss: 0.480284\n",
      "epoch 10; iter: 200; batch classifier loss: 0.510470; batch adversarial loss: 0.425475\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392810; batch adversarial loss: 0.473517\n",
      "epoch 11; iter: 200; batch classifier loss: 0.520316; batch adversarial loss: 0.469056\n",
      "epoch 12; iter: 0; batch classifier loss: 0.332434; batch adversarial loss: 0.324566\n",
      "epoch 12; iter: 200; batch classifier loss: 0.372666; batch adversarial loss: 0.527793\n",
      "epoch 13; iter: 0; batch classifier loss: 0.385425; batch adversarial loss: 0.279929\n",
      "epoch 13; iter: 200; batch classifier loss: 0.543752; batch adversarial loss: 0.423682\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548067; batch adversarial loss: 0.478437\n",
      "epoch 14; iter: 200; batch classifier loss: 0.609219; batch adversarial loss: 0.357933\n",
      "epoch 15; iter: 0; batch classifier loss: 0.388901; batch adversarial loss: 0.462142\n",
      "epoch 15; iter: 200; batch classifier loss: 0.446464; batch adversarial loss: 0.408504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.333208; batch adversarial loss: 0.489249\n",
      "epoch 16; iter: 200; batch classifier loss: 0.259662; batch adversarial loss: 0.403666\n",
      "epoch 17; iter: 0; batch classifier loss: 0.276402; batch adversarial loss: 0.349264\n",
      "epoch 17; iter: 200; batch classifier loss: 0.300692; batch adversarial loss: 0.402471\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482064; batch adversarial loss: 0.359170\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341166; batch adversarial loss: 0.480880\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311718; batch adversarial loss: 0.479738\n",
      "epoch 19; iter: 200; batch classifier loss: 0.399450; batch adversarial loss: 0.355515\n",
      "epoch 20; iter: 0; batch classifier loss: 0.393006; batch adversarial loss: 0.364412\n",
      "epoch 20; iter: 200; batch classifier loss: 0.340555; batch adversarial loss: 0.496509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.335160; batch adversarial loss: 0.412224\n",
      "epoch 21; iter: 200; batch classifier loss: 0.326736; batch adversarial loss: 0.312827\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462558; batch adversarial loss: 0.450390\n",
      "epoch 22; iter: 200; batch classifier loss: 0.410767; batch adversarial loss: 0.441533\n",
      "epoch 23; iter: 0; batch classifier loss: 0.374252; batch adversarial loss: 0.387103\n",
      "epoch 23; iter: 200; batch classifier loss: 0.332737; batch adversarial loss: 0.453214\n",
      "epoch 24; iter: 0; batch classifier loss: 0.366921; batch adversarial loss: 0.348289\n",
      "epoch 24; iter: 200; batch classifier loss: 0.422373; batch adversarial loss: 0.290884\n",
      "epoch 25; iter: 0; batch classifier loss: 0.319644; batch adversarial loss: 0.420528\n",
      "epoch 25; iter: 200; batch classifier loss: 0.341005; batch adversarial loss: 0.377475\n",
      "epoch 26; iter: 0; batch classifier loss: 0.240656; batch adversarial loss: 0.454567\n",
      "epoch 26; iter: 200; batch classifier loss: 0.344088; batch adversarial loss: 0.402196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.284051; batch adversarial loss: 0.379843\n",
      "epoch 27; iter: 200; batch classifier loss: 0.272458; batch adversarial loss: 0.412869\n",
      "epoch 28; iter: 0; batch classifier loss: 0.379941; batch adversarial loss: 0.351610\n",
      "epoch 28; iter: 200; batch classifier loss: 0.361634; batch adversarial loss: 0.318598\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303943; batch adversarial loss: 0.378841\n",
      "epoch 29; iter: 200; batch classifier loss: 0.406463; batch adversarial loss: 0.392043\n",
      "epoch 30; iter: 0; batch classifier loss: 0.361000; batch adversarial loss: 0.385441\n",
      "epoch 30; iter: 200; batch classifier loss: 0.267160; batch adversarial loss: 0.445235\n",
      "epoch 31; iter: 0; batch classifier loss: 0.326181; batch adversarial loss: 0.344458\n",
      "epoch 31; iter: 200; batch classifier loss: 0.318789; batch adversarial loss: 0.399230\n",
      "epoch 32; iter: 0; batch classifier loss: 0.332242; batch adversarial loss: 0.392307\n",
      "epoch 32; iter: 200; batch classifier loss: 0.352881; batch adversarial loss: 0.426954\n",
      "epoch 33; iter: 0; batch classifier loss: 0.375535; batch adversarial loss: 0.395461\n",
      "epoch 33; iter: 200; batch classifier loss: 0.292374; batch adversarial loss: 0.527112\n",
      "epoch 34; iter: 0; batch classifier loss: 0.337391; batch adversarial loss: 0.428435\n",
      "epoch 34; iter: 200; batch classifier loss: 0.269406; batch adversarial loss: 0.338862\n",
      "epoch 35; iter: 0; batch classifier loss: 0.274959; batch adversarial loss: 0.395360\n",
      "epoch 35; iter: 200; batch classifier loss: 0.407539; batch adversarial loss: 0.514035\n",
      "epoch 36; iter: 0; batch classifier loss: 0.385735; batch adversarial loss: 0.487459\n",
      "epoch 36; iter: 200; batch classifier loss: 0.373111; batch adversarial loss: 0.349064\n",
      "epoch 37; iter: 0; batch classifier loss: 0.393981; batch adversarial loss: 0.330029\n",
      "epoch 37; iter: 200; batch classifier loss: 0.426029; batch adversarial loss: 0.393341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.349713; batch adversarial loss: 0.378694\n",
      "epoch 38; iter: 200; batch classifier loss: 0.421841; batch adversarial loss: 0.484594\n",
      "epoch 39; iter: 0; batch classifier loss: 0.349695; batch adversarial loss: 0.472553\n",
      "epoch 39; iter: 200; batch classifier loss: 0.356609; batch adversarial loss: 0.375114\n",
      "epoch 40; iter: 0; batch classifier loss: 0.340165; batch adversarial loss: 0.487299\n",
      "epoch 40; iter: 200; batch classifier loss: 0.476853; batch adversarial loss: 0.420610\n",
      "epoch 41; iter: 0; batch classifier loss: 0.276568; batch adversarial loss: 0.459268\n",
      "epoch 41; iter: 200; batch classifier loss: 0.362446; batch adversarial loss: 0.466237\n",
      "epoch 42; iter: 0; batch classifier loss: 0.380538; batch adversarial loss: 0.363068\n",
      "epoch 42; iter: 200; batch classifier loss: 0.373124; batch adversarial loss: 0.446442\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435406; batch adversarial loss: 0.440697\n",
      "epoch 43; iter: 200; batch classifier loss: 0.504500; batch adversarial loss: 0.317904\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415502; batch adversarial loss: 0.462337\n",
      "epoch 44; iter: 200; batch classifier loss: 0.457017; batch adversarial loss: 0.419229\n",
      "epoch 45; iter: 0; batch classifier loss: 0.427318; batch adversarial loss: 0.473780\n",
      "epoch 45; iter: 200; batch classifier loss: 0.536567; batch adversarial loss: 0.449911\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382096; batch adversarial loss: 0.410027\n",
      "epoch 46; iter: 200; batch classifier loss: 0.455312; batch adversarial loss: 0.294893\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417268; batch adversarial loss: 0.363155\n",
      "epoch 47; iter: 200; batch classifier loss: 0.441864; batch adversarial loss: 0.399942\n",
      "epoch 48; iter: 0; batch classifier loss: 0.331846; batch adversarial loss: 0.391872\n",
      "epoch 48; iter: 200; batch classifier loss: 0.390748; batch adversarial loss: 0.319149\n",
      "epoch 49; iter: 0; batch classifier loss: 0.663521; batch adversarial loss: 0.307137\n",
      "epoch 49; iter: 200; batch classifier loss: 0.391200; batch adversarial loss: 0.420161\n",
      "epoch 0; iter: 0; batch classifier loss: 100.685890; batch adversarial loss: 0.624991\n",
      "epoch 0; iter: 200; batch classifier loss: 15.000206; batch adversarial loss: 0.635963\n",
      "epoch 1; iter: 0; batch classifier loss: 7.784863; batch adversarial loss: 0.572753\n",
      "epoch 1; iter: 200; batch classifier loss: 7.958184; batch adversarial loss: 0.541818\n",
      "epoch 2; iter: 0; batch classifier loss: 4.784418; batch adversarial loss: 0.514969\n",
      "epoch 2; iter: 200; batch classifier loss: 10.927023; batch adversarial loss: 0.506517\n",
      "epoch 3; iter: 0; batch classifier loss: 6.133774; batch adversarial loss: 0.483673\n",
      "epoch 3; iter: 200; batch classifier loss: 1.987205; batch adversarial loss: 0.453455\n",
      "epoch 4; iter: 0; batch classifier loss: 1.467609; batch adversarial loss: 0.503283\n",
      "epoch 4; iter: 200; batch classifier loss: 2.977804; batch adversarial loss: 0.477851\n",
      "epoch 5; iter: 0; batch classifier loss: 2.653465; batch adversarial loss: 0.520457\n",
      "epoch 5; iter: 200; batch classifier loss: 2.631165; batch adversarial loss: 0.438054\n",
      "epoch 6; iter: 0; batch classifier loss: 2.581419; batch adversarial loss: 0.447304\n",
      "epoch 6; iter: 200; batch classifier loss: 1.480721; batch adversarial loss: 0.406446\n",
      "epoch 7; iter: 0; batch classifier loss: 1.423421; batch adversarial loss: 0.499911\n",
      "epoch 7; iter: 200; batch classifier loss: 0.721655; batch adversarial loss: 0.420414\n",
      "epoch 8; iter: 0; batch classifier loss: 0.429885; batch adversarial loss: 0.383463\n",
      "epoch 8; iter: 200; batch classifier loss: 0.677755; batch adversarial loss: 0.362365\n",
      "epoch 9; iter: 0; batch classifier loss: 0.933414; batch adversarial loss: 0.546848\n",
      "epoch 9; iter: 200; batch classifier loss: 0.418790; batch adversarial loss: 0.444856\n",
      "epoch 10; iter: 0; batch classifier loss: 0.591833; batch adversarial loss: 0.375242\n",
      "epoch 10; iter: 200; batch classifier loss: 0.405927; batch adversarial loss: 0.410996\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500641; batch adversarial loss: 0.363859\n",
      "epoch 11; iter: 200; batch classifier loss: 0.447809; batch adversarial loss: 0.344076\n",
      "epoch 12; iter: 0; batch classifier loss: 0.604544; batch adversarial loss: 0.454098\n",
      "epoch 12; iter: 200; batch classifier loss: 0.451174; batch adversarial loss: 0.499243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488850; batch adversarial loss: 0.421893\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353643; batch adversarial loss: 0.303987\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396719; batch adversarial loss: 0.418720\n",
      "epoch 14; iter: 200; batch classifier loss: 0.401319; batch adversarial loss: 0.433710\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364373; batch adversarial loss: 0.498951\n",
      "epoch 15; iter: 200; batch classifier loss: 0.382297; batch adversarial loss: 0.472621\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391801; batch adversarial loss: 0.380566\n",
      "epoch 16; iter: 200; batch classifier loss: 0.417133; batch adversarial loss: 0.370917\n",
      "epoch 17; iter: 0; batch classifier loss: 0.387852; batch adversarial loss: 0.344424\n",
      "epoch 17; iter: 200; batch classifier loss: 0.383076; batch adversarial loss: 0.516256\n",
      "epoch 18; iter: 0; batch classifier loss: 0.311755; batch adversarial loss: 0.428522\n",
      "epoch 18; iter: 200; batch classifier loss: 0.357786; batch adversarial loss: 0.424805\n",
      "epoch 19; iter: 0; batch classifier loss: 0.287949; batch adversarial loss: 0.434112\n",
      "epoch 19; iter: 200; batch classifier loss: 0.405721; batch adversarial loss: 0.430710\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449597; batch adversarial loss: 0.368803\n",
      "epoch 20; iter: 200; batch classifier loss: 0.386508; batch adversarial loss: 0.436905\n",
      "epoch 21; iter: 0; batch classifier loss: 0.361200; batch adversarial loss: 0.460072\n",
      "epoch 21; iter: 200; batch classifier loss: 0.318261; batch adversarial loss: 0.461444\n",
      "epoch 22; iter: 0; batch classifier loss: 0.319051; batch adversarial loss: 0.478469\n",
      "epoch 22; iter: 200; batch classifier loss: 0.338088; batch adversarial loss: 0.410955\n",
      "epoch 23; iter: 0; batch classifier loss: 0.341948; batch adversarial loss: 0.294868\n",
      "epoch 23; iter: 200; batch classifier loss: 0.397527; batch adversarial loss: 0.298389\n",
      "epoch 24; iter: 0; batch classifier loss: 0.300490; batch adversarial loss: 0.463604\n",
      "epoch 24; iter: 200; batch classifier loss: 0.304563; batch adversarial loss: 0.355124\n",
      "epoch 25; iter: 0; batch classifier loss: 0.367696; batch adversarial loss: 0.495567\n",
      "epoch 25; iter: 200; batch classifier loss: 0.341570; batch adversarial loss: 0.412716\n",
      "epoch 26; iter: 0; batch classifier loss: 0.305946; batch adversarial loss: 0.459950\n",
      "epoch 26; iter: 200; batch classifier loss: 0.361126; batch adversarial loss: 0.446656\n",
      "epoch 27; iter: 0; batch classifier loss: 0.293723; batch adversarial loss: 0.441079\n",
      "epoch 27; iter: 200; batch classifier loss: 0.317493; batch adversarial loss: 0.415578\n",
      "epoch 28; iter: 0; batch classifier loss: 0.383950; batch adversarial loss: 0.414243\n",
      "epoch 28; iter: 200; batch classifier loss: 0.290069; batch adversarial loss: 0.454416\n",
      "epoch 29; iter: 0; batch classifier loss: 0.365892; batch adversarial loss: 0.351510\n",
      "epoch 29; iter: 200; batch classifier loss: 0.313116; batch adversarial loss: 0.441866\n",
      "epoch 30; iter: 0; batch classifier loss: 0.349017; batch adversarial loss: 0.396214\n",
      "epoch 30; iter: 200; batch classifier loss: 0.356528; batch adversarial loss: 0.412482\n",
      "epoch 31; iter: 0; batch classifier loss: 0.275541; batch adversarial loss: 0.459879\n",
      "epoch 31; iter: 200; batch classifier loss: 0.457560; batch adversarial loss: 0.390998\n",
      "epoch 32; iter: 0; batch classifier loss: 0.277885; batch adversarial loss: 0.368691\n",
      "epoch 32; iter: 200; batch classifier loss: 0.361742; batch adversarial loss: 0.424806\n",
      "epoch 33; iter: 0; batch classifier loss: 0.413700; batch adversarial loss: 0.434616\n",
      "epoch 33; iter: 200; batch classifier loss: 0.288456; batch adversarial loss: 0.479067\n",
      "epoch 34; iter: 0; batch classifier loss: 0.377945; batch adversarial loss: 0.461931\n",
      "epoch 34; iter: 200; batch classifier loss: 0.321776; batch adversarial loss: 0.494593\n",
      "epoch 35; iter: 0; batch classifier loss: 0.334001; batch adversarial loss: 0.432102\n",
      "epoch 35; iter: 200; batch classifier loss: 0.335518; batch adversarial loss: 0.426787\n",
      "epoch 36; iter: 0; batch classifier loss: 0.327247; batch adversarial loss: 0.432147\n",
      "epoch 36; iter: 200; batch classifier loss: 0.301438; batch adversarial loss: 0.417596\n",
      "epoch 37; iter: 0; batch classifier loss: 0.347671; batch adversarial loss: 0.441869\n",
      "epoch 37; iter: 200; batch classifier loss: 0.707471; batch adversarial loss: 0.513202\n",
      "epoch 38; iter: 0; batch classifier loss: 0.346496; batch adversarial loss: 0.472558\n",
      "epoch 38; iter: 200; batch classifier loss: 0.322386; batch adversarial loss: 0.493536\n",
      "epoch 39; iter: 0; batch classifier loss: 0.339643; batch adversarial loss: 0.498992\n",
      "epoch 39; iter: 200; batch classifier loss: 0.305264; batch adversarial loss: 0.443093\n",
      "epoch 40; iter: 0; batch classifier loss: 0.466157; batch adversarial loss: 0.423425\n",
      "epoch 40; iter: 200; batch classifier loss: 0.323990; batch adversarial loss: 0.331198\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410853; batch adversarial loss: 0.407781\n",
      "epoch 41; iter: 200; batch classifier loss: 0.377997; batch adversarial loss: 0.343614\n",
      "epoch 42; iter: 0; batch classifier loss: 0.278103; batch adversarial loss: 0.420393\n",
      "epoch 42; iter: 200; batch classifier loss: 0.341028; batch adversarial loss: 0.435510\n",
      "epoch 43; iter: 0; batch classifier loss: 0.388072; batch adversarial loss: 0.509004\n",
      "epoch 43; iter: 200; batch classifier loss: 0.381229; batch adversarial loss: 0.449882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.489924; batch adversarial loss: 0.453997\n",
      "epoch 44; iter: 200; batch classifier loss: 0.270665; batch adversarial loss: 0.346700\n",
      "epoch 45; iter: 0; batch classifier loss: 0.344286; batch adversarial loss: 0.585320\n",
      "epoch 45; iter: 200; batch classifier loss: 0.360212; batch adversarial loss: 0.442061\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411982; batch adversarial loss: 0.373496\n",
      "epoch 46; iter: 200; batch classifier loss: 0.472654; batch adversarial loss: 0.527165\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443533; batch adversarial loss: 0.523952\n",
      "epoch 47; iter: 200; batch classifier loss: 0.624302; batch adversarial loss: 0.526006\n",
      "epoch 48; iter: 0; batch classifier loss: 0.445749; batch adversarial loss: 0.426811\n",
      "epoch 48; iter: 200; batch classifier loss: 0.594669; batch adversarial loss: 0.525238\n",
      "epoch 49; iter: 0; batch classifier loss: 0.465120; batch adversarial loss: 0.449512\n",
      "epoch 49; iter: 200; batch classifier loss: 0.337355; batch adversarial loss: 0.480753\n",
      "epoch 0; iter: 0; batch classifier loss: 3.288010; batch adversarial loss: 0.591761\n",
      "epoch 0; iter: 200; batch classifier loss: 22.736286; batch adversarial loss: 0.599167\n",
      "epoch 1; iter: 0; batch classifier loss: 8.135470; batch adversarial loss: 0.563131\n",
      "epoch 1; iter: 200; batch classifier loss: 3.619190; batch adversarial loss: 0.515885\n",
      "epoch 2; iter: 0; batch classifier loss: 7.983100; batch adversarial loss: 0.516125\n",
      "epoch 2; iter: 200; batch classifier loss: 2.058783; batch adversarial loss: 0.482672\n",
      "epoch 3; iter: 0; batch classifier loss: 6.044279; batch adversarial loss: 0.475296\n",
      "epoch 3; iter: 200; batch classifier loss: 3.588884; batch adversarial loss: 0.442956\n",
      "epoch 4; iter: 0; batch classifier loss: 1.779267; batch adversarial loss: 0.436306\n",
      "epoch 4; iter: 200; batch classifier loss: 1.942580; batch adversarial loss: 0.512563\n",
      "epoch 5; iter: 0; batch classifier loss: 1.272289; batch adversarial loss: 0.416947\n",
      "epoch 5; iter: 200; batch classifier loss: 1.157192; batch adversarial loss: 0.487950\n",
      "epoch 6; iter: 0; batch classifier loss: 0.807327; batch adversarial loss: 0.393950\n",
      "epoch 6; iter: 200; batch classifier loss: 0.508141; batch adversarial loss: 0.487202\n",
      "epoch 7; iter: 0; batch classifier loss: 0.672584; batch adversarial loss: 0.462976\n",
      "epoch 7; iter: 200; batch classifier loss: 0.551566; batch adversarial loss: 0.405382\n",
      "epoch 8; iter: 0; batch classifier loss: 0.568954; batch adversarial loss: 0.469944\n",
      "epoch 8; iter: 200; batch classifier loss: 0.369397; batch adversarial loss: 0.351536\n",
      "epoch 9; iter: 0; batch classifier loss: 0.703344; batch adversarial loss: 0.336507\n",
      "epoch 9; iter: 200; batch classifier loss: 0.371541; batch adversarial loss: 0.363432\n",
      "epoch 10; iter: 0; batch classifier loss: 0.416607; batch adversarial loss: 0.474628\n",
      "epoch 10; iter: 200; batch classifier loss: 0.328965; batch adversarial loss: 0.375332\n",
      "epoch 11; iter: 0; batch classifier loss: 0.346745; batch adversarial loss: 0.402505\n",
      "epoch 11; iter: 200; batch classifier loss: 0.348321; batch adversarial loss: 0.363578\n",
      "epoch 12; iter: 0; batch classifier loss: 0.401449; batch adversarial loss: 0.403527\n",
      "epoch 12; iter: 200; batch classifier loss: 0.287595; batch adversarial loss: 0.288774\n",
      "epoch 13; iter: 0; batch classifier loss: 0.321321; batch adversarial loss: 0.437624\n",
      "epoch 13; iter: 200; batch classifier loss: 0.386537; batch adversarial loss: 0.432075\n",
      "epoch 14; iter: 0; batch classifier loss: 0.428588; batch adversarial loss: 0.524864\n",
      "epoch 14; iter: 200; batch classifier loss: 0.371505; batch adversarial loss: 0.409833\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499649; batch adversarial loss: 0.411602\n",
      "epoch 15; iter: 200; batch classifier loss: 0.312530; batch adversarial loss: 0.374545\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364268; batch adversarial loss: 0.379746\n",
      "epoch 16; iter: 200; batch classifier loss: 0.407359; batch adversarial loss: 0.331859\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409182; batch adversarial loss: 0.404651\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364675; batch adversarial loss: 0.468899\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378069; batch adversarial loss: 0.476095\n",
      "epoch 18; iter: 200; batch classifier loss: 0.370723; batch adversarial loss: 0.529350\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275469; batch adversarial loss: 0.422326\n",
      "epoch 19; iter: 200; batch classifier loss: 0.342715; batch adversarial loss: 0.370505\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256929; batch adversarial loss: 0.446797\n",
      "epoch 20; iter: 200; batch classifier loss: 0.328803; batch adversarial loss: 0.447981\n",
      "epoch 21; iter: 0; batch classifier loss: 0.395875; batch adversarial loss: 0.378699\n",
      "epoch 21; iter: 200; batch classifier loss: 0.355769; batch adversarial loss: 0.382297\n",
      "epoch 22; iter: 0; batch classifier loss: 0.349254; batch adversarial loss: 0.416242\n",
      "epoch 22; iter: 200; batch classifier loss: 0.343634; batch adversarial loss: 0.302170\n",
      "epoch 23; iter: 0; batch classifier loss: 0.282423; batch adversarial loss: 0.483145\n",
      "epoch 23; iter: 200; batch classifier loss: 0.376440; batch adversarial loss: 0.352861\n",
      "epoch 24; iter: 0; batch classifier loss: 0.351383; batch adversarial loss: 0.479660\n",
      "epoch 24; iter: 200; batch classifier loss: 0.294541; batch adversarial loss: 0.381013\n",
      "epoch 25; iter: 0; batch classifier loss: 0.342136; batch adversarial loss: 0.453858\n",
      "epoch 25; iter: 200; batch classifier loss: 0.394319; batch adversarial loss: 0.375899\n",
      "epoch 26; iter: 0; batch classifier loss: 0.351153; batch adversarial loss: 0.353579\n",
      "epoch 26; iter: 200; batch classifier loss: 0.310536; batch adversarial loss: 0.438110\n",
      "epoch 27; iter: 0; batch classifier loss: 0.400430; batch adversarial loss: 0.423771\n",
      "epoch 27; iter: 200; batch classifier loss: 0.339237; batch adversarial loss: 0.353646\n",
      "epoch 28; iter: 0; batch classifier loss: 0.338739; batch adversarial loss: 0.489483\n",
      "epoch 28; iter: 200; batch classifier loss: 0.391138; batch adversarial loss: 0.436164\n",
      "epoch 29; iter: 0; batch classifier loss: 0.263236; batch adversarial loss: 0.391458\n",
      "epoch 29; iter: 200; batch classifier loss: 0.354084; batch adversarial loss: 0.380204\n",
      "epoch 30; iter: 0; batch classifier loss: 0.296420; batch adversarial loss: 0.389858\n",
      "epoch 30; iter: 200; batch classifier loss: 0.392047; batch adversarial loss: 0.394319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.370532; batch adversarial loss: 0.399904\n",
      "epoch 31; iter: 200; batch classifier loss: 0.313807; batch adversarial loss: 0.495257\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409445; batch adversarial loss: 0.370085\n",
      "epoch 32; iter: 200; batch classifier loss: 0.437060; batch adversarial loss: 0.523955\n",
      "epoch 33; iter: 0; batch classifier loss: 0.311345; batch adversarial loss: 0.504180\n",
      "epoch 33; iter: 200; batch classifier loss: 0.287341; batch adversarial loss: 0.385500\n",
      "epoch 34; iter: 0; batch classifier loss: 0.296676; batch adversarial loss: 0.430951\n",
      "epoch 34; iter: 200; batch classifier loss: 0.360406; batch adversarial loss: 0.466980\n",
      "epoch 35; iter: 0; batch classifier loss: 0.346137; batch adversarial loss: 0.393179\n",
      "epoch 35; iter: 200; batch classifier loss: 0.443909; batch adversarial loss: 0.506994\n",
      "epoch 36; iter: 0; batch classifier loss: 0.301104; batch adversarial loss: 0.342100\n",
      "epoch 36; iter: 200; batch classifier loss: 0.359169; batch adversarial loss: 0.444916\n",
      "epoch 37; iter: 0; batch classifier loss: 0.304562; batch adversarial loss: 0.399412\n",
      "epoch 37; iter: 200; batch classifier loss: 0.375365; batch adversarial loss: 0.435989\n",
      "epoch 38; iter: 0; batch classifier loss: 0.605762; batch adversarial loss: 0.349862\n",
      "epoch 38; iter: 200; batch classifier loss: 0.473526; batch adversarial loss: 0.500932\n",
      "epoch 39; iter: 0; batch classifier loss: 0.391795; batch adversarial loss: 0.475595\n",
      "epoch 39; iter: 200; batch classifier loss: 0.455773; batch adversarial loss: 0.432468\n",
      "epoch 40; iter: 0; batch classifier loss: 0.504250; batch adversarial loss: 0.373824\n",
      "epoch 40; iter: 200; batch classifier loss: 0.572502; batch adversarial loss: 0.405796\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467244; batch adversarial loss: 0.406073\n",
      "epoch 41; iter: 200; batch classifier loss: 0.483995; batch adversarial loss: 0.393448\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495365; batch adversarial loss: 0.419765\n",
      "epoch 42; iter: 200; batch classifier loss: 0.434956; batch adversarial loss: 0.408257\n",
      "epoch 43; iter: 0; batch classifier loss: 0.398656; batch adversarial loss: 0.437226\n",
      "epoch 43; iter: 200; batch classifier loss: 0.592930; batch adversarial loss: 0.366084\n",
      "epoch 44; iter: 0; batch classifier loss: 0.544374; batch adversarial loss: 0.390950\n",
      "epoch 44; iter: 200; batch classifier loss: 0.607476; batch adversarial loss: 0.414363\n",
      "epoch 45; iter: 0; batch classifier loss: 0.595875; batch adversarial loss: 0.334519\n",
      "epoch 45; iter: 200; batch classifier loss: 0.542592; batch adversarial loss: 0.361185\n",
      "epoch 46; iter: 0; batch classifier loss: 0.334785; batch adversarial loss: 0.372987\n",
      "epoch 46; iter: 200; batch classifier loss: 0.665601; batch adversarial loss: 0.381378\n",
      "epoch 47; iter: 0; batch classifier loss: 0.463818; batch adversarial loss: 0.305857\n",
      "epoch 47; iter: 200; batch classifier loss: 0.389078; batch adversarial loss: 0.387988\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430222; batch adversarial loss: 0.310112\n",
      "epoch 48; iter: 200; batch classifier loss: 0.512626; batch adversarial loss: 0.444224\n",
      "epoch 49; iter: 0; batch classifier loss: 0.741735; batch adversarial loss: 0.357627\n",
      "epoch 49; iter: 200; batch classifier loss: 0.562481; batch adversarial loss: 0.423212\n",
      "epoch 0; iter: 0; batch classifier loss: 34.326721; batch adversarial loss: 1.017234\n",
      "epoch 0; iter: 200; batch classifier loss: 11.800943; batch adversarial loss: 1.038644\n",
      "epoch 1; iter: 0; batch classifier loss: 4.465388; batch adversarial loss: 0.902737\n",
      "epoch 1; iter: 200; batch classifier loss: 2.640121; batch adversarial loss: 0.711497\n",
      "epoch 2; iter: 0; batch classifier loss: 4.290284; batch adversarial loss: 0.636467\n",
      "epoch 2; iter: 200; batch classifier loss: 3.214112; batch adversarial loss: 0.549416\n",
      "epoch 3; iter: 0; batch classifier loss: 4.414658; batch adversarial loss: 0.532259\n",
      "epoch 3; iter: 200; batch classifier loss: 1.798743; batch adversarial loss: 0.437049\n",
      "epoch 4; iter: 0; batch classifier loss: 1.389686; batch adversarial loss: 0.496583\n",
      "epoch 4; iter: 200; batch classifier loss: 1.903101; batch adversarial loss: 0.423021\n",
      "epoch 5; iter: 0; batch classifier loss: 1.787434; batch adversarial loss: 0.438753\n",
      "epoch 5; iter: 200; batch classifier loss: 0.993345; batch adversarial loss: 0.448999\n",
      "epoch 6; iter: 0; batch classifier loss: 1.222535; batch adversarial loss: 0.422334\n",
      "epoch 6; iter: 200; batch classifier loss: 0.957260; batch adversarial loss: 0.358020\n",
      "epoch 7; iter: 0; batch classifier loss: 1.101002; batch adversarial loss: 0.504288\n",
      "epoch 7; iter: 200; batch classifier loss: 0.899136; batch adversarial loss: 0.413660\n",
      "epoch 8; iter: 0; batch classifier loss: 1.420194; batch adversarial loss: 0.449876\n",
      "epoch 8; iter: 200; batch classifier loss: 0.700871; batch adversarial loss: 0.379089\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531914; batch adversarial loss: 0.374211\n",
      "epoch 9; iter: 200; batch classifier loss: 0.919575; batch adversarial loss: 0.508927\n",
      "epoch 10; iter: 0; batch classifier loss: 0.344364; batch adversarial loss: 0.425329\n",
      "epoch 10; iter: 200; batch classifier loss: 0.438817; batch adversarial loss: 0.413267\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494954; batch adversarial loss: 0.406635\n",
      "epoch 11; iter: 200; batch classifier loss: 0.465862; batch adversarial loss: 0.377412\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427215; batch adversarial loss: 0.393366\n",
      "epoch 12; iter: 200; batch classifier loss: 0.368243; batch adversarial loss: 0.401983\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492616; batch adversarial loss: 0.421181\n",
      "epoch 13; iter: 200; batch classifier loss: 0.427783; batch adversarial loss: 0.397136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.353161; batch adversarial loss: 0.410986\n",
      "epoch 14; iter: 200; batch classifier loss: 0.367678; batch adversarial loss: 0.405077\n",
      "epoch 15; iter: 0; batch classifier loss: 0.362644; batch adversarial loss: 0.443368\n",
      "epoch 15; iter: 200; batch classifier loss: 0.412431; batch adversarial loss: 0.322865\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296128; batch adversarial loss: 0.416535\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380733; batch adversarial loss: 0.391072\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349459; batch adversarial loss: 0.396535\n",
      "epoch 17; iter: 200; batch classifier loss: 0.407253; batch adversarial loss: 0.337954\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359909; batch adversarial loss: 0.405158\n",
      "epoch 18; iter: 200; batch classifier loss: 0.372011; batch adversarial loss: 0.331070\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334374; batch adversarial loss: 0.413977\n",
      "epoch 19; iter: 200; batch classifier loss: 0.378231; batch adversarial loss: 0.443604\n",
      "epoch 20; iter: 0; batch classifier loss: 0.344037; batch adversarial loss: 0.336076\n",
      "epoch 20; iter: 200; batch classifier loss: 0.333724; batch adversarial loss: 0.394344\n",
      "epoch 21; iter: 0; batch classifier loss: 0.386653; batch adversarial loss: 0.391124\n",
      "epoch 21; iter: 200; batch classifier loss: 0.365145; batch adversarial loss: 0.332724\n",
      "epoch 22; iter: 0; batch classifier loss: 0.334091; batch adversarial loss: 0.393908\n",
      "epoch 22; iter: 200; batch classifier loss: 0.385219; batch adversarial loss: 0.371148\n",
      "epoch 23; iter: 0; batch classifier loss: 0.368513; batch adversarial loss: 0.398968\n",
      "epoch 23; iter: 200; batch classifier loss: 0.346348; batch adversarial loss: 0.356569\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364117; batch adversarial loss: 0.422216\n",
      "epoch 24; iter: 200; batch classifier loss: 0.403198; batch adversarial loss: 0.414893\n",
      "epoch 25; iter: 0; batch classifier loss: 0.341558; batch adversarial loss: 0.516276\n",
      "epoch 25; iter: 200; batch classifier loss: 0.309668; batch adversarial loss: 0.322289\n",
      "epoch 26; iter: 0; batch classifier loss: 0.322015; batch adversarial loss: 0.377602\n",
      "epoch 26; iter: 200; batch classifier loss: 0.361030; batch adversarial loss: 0.366178\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391713; batch adversarial loss: 0.343427\n",
      "epoch 27; iter: 200; batch classifier loss: 0.357879; batch adversarial loss: 0.403334\n",
      "epoch 28; iter: 0; batch classifier loss: 0.388703; batch adversarial loss: 0.485823\n",
      "epoch 28; iter: 200; batch classifier loss: 0.324063; batch adversarial loss: 0.408574\n",
      "epoch 29; iter: 0; batch classifier loss: 0.352536; batch adversarial loss: 0.419238\n",
      "epoch 29; iter: 200; batch classifier loss: 0.428468; batch adversarial loss: 0.402362\n",
      "epoch 30; iter: 0; batch classifier loss: 0.312401; batch adversarial loss: 0.336246\n",
      "epoch 30; iter: 200; batch classifier loss: 0.481983; batch adversarial loss: 0.488230\n",
      "epoch 31; iter: 0; batch classifier loss: 0.316279; batch adversarial loss: 0.447705\n",
      "epoch 31; iter: 200; batch classifier loss: 0.366049; batch adversarial loss: 0.468896\n",
      "epoch 32; iter: 0; batch classifier loss: 0.362276; batch adversarial loss: 0.401815\n",
      "epoch 32; iter: 200; batch classifier loss: 0.373778; batch adversarial loss: 0.401734\n",
      "epoch 33; iter: 0; batch classifier loss: 0.340123; batch adversarial loss: 0.441407\n",
      "epoch 33; iter: 200; batch classifier loss: 0.384956; batch adversarial loss: 0.430744\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380002; batch adversarial loss: 0.378040\n",
      "epoch 34; iter: 200; batch classifier loss: 0.392323; batch adversarial loss: 0.410479\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400742; batch adversarial loss: 0.481806\n",
      "epoch 35; iter: 200; batch classifier loss: 0.448562; batch adversarial loss: 0.427611\n",
      "epoch 36; iter: 0; batch classifier loss: 0.299661; batch adversarial loss: 0.345388\n",
      "epoch 36; iter: 200; batch classifier loss: 0.346966; batch adversarial loss: 0.536587\n",
      "epoch 37; iter: 0; batch classifier loss: 0.425892; batch adversarial loss: 0.377474\n",
      "epoch 37; iter: 200; batch classifier loss: 0.334205; batch adversarial loss: 0.349931\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386208; batch adversarial loss: 0.520255\n",
      "epoch 38; iter: 200; batch classifier loss: 0.328969; batch adversarial loss: 0.398929\n",
      "epoch 39; iter: 0; batch classifier loss: 0.304578; batch adversarial loss: 0.357423\n",
      "epoch 39; iter: 200; batch classifier loss: 0.346188; batch adversarial loss: 0.410012\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394368; batch adversarial loss: 0.453910\n",
      "epoch 40; iter: 200; batch classifier loss: 0.312827; batch adversarial loss: 0.456747\n",
      "epoch 41; iter: 0; batch classifier loss: 0.330005; batch adversarial loss: 0.373147\n",
      "epoch 41; iter: 200; batch classifier loss: 0.324088; batch adversarial loss: 0.354512\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383495; batch adversarial loss: 0.411656\n",
      "epoch 42; iter: 200; batch classifier loss: 0.403571; batch adversarial loss: 0.354225\n",
      "epoch 43; iter: 0; batch classifier loss: 0.433182; batch adversarial loss: 0.523206\n",
      "epoch 43; iter: 200; batch classifier loss: 0.366455; batch adversarial loss: 0.372333\n",
      "epoch 44; iter: 0; batch classifier loss: 0.522581; batch adversarial loss: 0.431066\n",
      "epoch 44; iter: 200; batch classifier loss: 0.323027; batch adversarial loss: 0.369816\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408395; batch adversarial loss: 0.514872\n",
      "epoch 45; iter: 200; batch classifier loss: 0.450022; batch adversarial loss: 0.371754\n",
      "epoch 46; iter: 0; batch classifier loss: 0.364201; batch adversarial loss: 0.349801\n",
      "epoch 46; iter: 200; batch classifier loss: 0.568510; batch adversarial loss: 0.424158\n",
      "epoch 47; iter: 0; batch classifier loss: 0.387995; batch adversarial loss: 0.419584\n",
      "epoch 47; iter: 200; batch classifier loss: 0.366822; batch adversarial loss: 0.374527\n",
      "epoch 48; iter: 0; batch classifier loss: 0.508410; batch adversarial loss: 0.546606\n",
      "epoch 48; iter: 200; batch classifier loss: 0.500254; batch adversarial loss: 0.498531\n",
      "epoch 49; iter: 0; batch classifier loss: 0.519674; batch adversarial loss: 0.334676\n",
      "epoch 49; iter: 200; batch classifier loss: 0.409058; batch adversarial loss: 0.486662\n",
      "epoch 0; iter: 0; batch classifier loss: 156.436462; batch adversarial loss: 0.594045\n",
      "epoch 0; iter: 200; batch classifier loss: 20.258993; batch adversarial loss: 0.580556\n",
      "epoch 1; iter: 0; batch classifier loss: 5.326799; batch adversarial loss: 0.555911\n",
      "epoch 1; iter: 200; batch classifier loss: 8.096744; batch adversarial loss: 0.526944\n",
      "epoch 2; iter: 0; batch classifier loss: 4.060385; batch adversarial loss: 0.495178\n",
      "epoch 2; iter: 200; batch classifier loss: 2.464878; batch adversarial loss: 0.483139\n",
      "epoch 3; iter: 0; batch classifier loss: 2.894328; batch adversarial loss: 0.450051\n",
      "epoch 3; iter: 200; batch classifier loss: 2.217283; batch adversarial loss: 0.427234\n",
      "epoch 4; iter: 0; batch classifier loss: 1.800145; batch adversarial loss: 0.584003\n",
      "epoch 4; iter: 200; batch classifier loss: 2.649164; batch adversarial loss: 0.473404\n",
      "epoch 5; iter: 0; batch classifier loss: 0.963070; batch adversarial loss: 0.412983\n",
      "epoch 5; iter: 200; batch classifier loss: 5.153295; batch adversarial loss: 0.493853\n",
      "epoch 6; iter: 0; batch classifier loss: 0.754281; batch adversarial loss: 0.425457\n",
      "epoch 6; iter: 200; batch classifier loss: 0.457646; batch adversarial loss: 0.398993\n",
      "epoch 7; iter: 0; batch classifier loss: 0.514997; batch adversarial loss: 0.440125\n",
      "epoch 7; iter: 200; batch classifier loss: 0.476483; batch adversarial loss: 0.463211\n",
      "epoch 8; iter: 0; batch classifier loss: 0.415654; batch adversarial loss: 0.429013\n",
      "epoch 8; iter: 200; batch classifier loss: 0.508018; batch adversarial loss: 0.440005\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461996; batch adversarial loss: 0.335269\n",
      "epoch 9; iter: 200; batch classifier loss: 0.449425; batch adversarial loss: 0.338866\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559449; batch adversarial loss: 0.431700\n",
      "epoch 10; iter: 200; batch classifier loss: 0.435292; batch adversarial loss: 0.414673\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370842; batch adversarial loss: 0.340776\n",
      "epoch 11; iter: 200; batch classifier loss: 0.460379; batch adversarial loss: 0.473784\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452728; batch adversarial loss: 0.370706\n",
      "epoch 12; iter: 200; batch classifier loss: 0.394222; batch adversarial loss: 0.468949\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396876; batch adversarial loss: 0.418050\n",
      "epoch 13; iter: 200; batch classifier loss: 0.397730; batch adversarial loss: 0.441891\n",
      "epoch 14; iter: 0; batch classifier loss: 0.332074; batch adversarial loss: 0.478243\n",
      "epoch 14; iter: 200; batch classifier loss: 0.317824; batch adversarial loss: 0.309751\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338744; batch adversarial loss: 0.330518\n",
      "epoch 15; iter: 200; batch classifier loss: 0.359743; batch adversarial loss: 0.390175\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357879; batch adversarial loss: 0.346757\n",
      "epoch 16; iter: 200; batch classifier loss: 0.368365; batch adversarial loss: 0.385478\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363946; batch adversarial loss: 0.400373\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364028; batch adversarial loss: 0.427533\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354841; batch adversarial loss: 0.400580\n",
      "epoch 18; iter: 200; batch classifier loss: 0.264478; batch adversarial loss: 0.480353\n",
      "epoch 19; iter: 0; batch classifier loss: 0.304198; batch adversarial loss: 0.449896\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385899; batch adversarial loss: 0.461875\n",
      "epoch 20; iter: 0; batch classifier loss: 0.327091; batch adversarial loss: 0.417794\n",
      "epoch 20; iter: 200; batch classifier loss: 0.358327; batch adversarial loss: 0.477399\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392445; batch adversarial loss: 0.399365\n",
      "epoch 21; iter: 200; batch classifier loss: 0.314458; batch adversarial loss: 0.405753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.341715; batch adversarial loss: 0.369251\n",
      "epoch 22; iter: 200; batch classifier loss: 0.332444; batch adversarial loss: 0.375602\n",
      "epoch 23; iter: 0; batch classifier loss: 0.301414; batch adversarial loss: 0.470226\n",
      "epoch 23; iter: 200; batch classifier loss: 0.458023; batch adversarial loss: 0.384011\n",
      "epoch 24; iter: 0; batch classifier loss: 0.326804; batch adversarial loss: 0.483710\n",
      "epoch 24; iter: 200; batch classifier loss: 0.313806; batch adversarial loss: 0.317689\n",
      "epoch 25; iter: 0; batch classifier loss: 0.294671; batch adversarial loss: 0.474031\n",
      "epoch 25; iter: 200; batch classifier loss: 0.326536; batch adversarial loss: 0.424149\n",
      "epoch 26; iter: 0; batch classifier loss: 0.307203; batch adversarial loss: 0.344189\n",
      "epoch 26; iter: 200; batch classifier loss: 0.378244; batch adversarial loss: 0.376565\n",
      "epoch 27; iter: 0; batch classifier loss: 0.370100; batch adversarial loss: 0.433530\n",
      "epoch 27; iter: 200; batch classifier loss: 0.367638; batch adversarial loss: 0.386366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.356035; batch adversarial loss: 0.334488\n",
      "epoch 28; iter: 200; batch classifier loss: 0.317265; batch adversarial loss: 0.463989\n",
      "epoch 29; iter: 0; batch classifier loss: 0.314649; batch adversarial loss: 0.382968\n",
      "epoch 29; iter: 200; batch classifier loss: 0.291055; batch adversarial loss: 0.313591\n",
      "epoch 30; iter: 0; batch classifier loss: 0.328429; batch adversarial loss: 0.431607\n",
      "epoch 30; iter: 200; batch classifier loss: 0.313962; batch adversarial loss: 0.380000\n",
      "epoch 31; iter: 0; batch classifier loss: 0.279710; batch adversarial loss: 0.374136\n",
      "epoch 31; iter: 200; batch classifier loss: 0.362403; batch adversarial loss: 0.516872\n",
      "epoch 32; iter: 0; batch classifier loss: 0.382959; batch adversarial loss: 0.379495\n",
      "epoch 32; iter: 200; batch classifier loss: 0.304501; batch adversarial loss: 0.388388\n",
      "epoch 33; iter: 0; batch classifier loss: 0.332725; batch adversarial loss: 0.347485\n",
      "epoch 33; iter: 200; batch classifier loss: 0.263562; batch adversarial loss: 0.522663\n",
      "epoch 34; iter: 0; batch classifier loss: 0.364012; batch adversarial loss: 0.394090\n",
      "epoch 34; iter: 200; batch classifier loss: 0.362818; batch adversarial loss: 0.388822\n",
      "epoch 35; iter: 0; batch classifier loss: 0.388452; batch adversarial loss: 0.464037\n",
      "epoch 35; iter: 200; batch classifier loss: 0.392831; batch adversarial loss: 0.435399\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403854; batch adversarial loss: 0.418190\n",
      "epoch 36; iter: 200; batch classifier loss: 0.408419; batch adversarial loss: 0.396090\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400985; batch adversarial loss: 0.389415\n",
      "epoch 37; iter: 200; batch classifier loss: 0.339476; batch adversarial loss: 0.518070\n",
      "epoch 38; iter: 0; batch classifier loss: 0.289576; batch adversarial loss: 0.430078\n",
      "epoch 38; iter: 200; batch classifier loss: 0.260734; batch adversarial loss: 0.379010\n",
      "epoch 39; iter: 0; batch classifier loss: 0.273451; batch adversarial loss: 0.433472\n",
      "epoch 39; iter: 200; batch classifier loss: 0.411279; batch adversarial loss: 0.459672\n",
      "epoch 40; iter: 0; batch classifier loss: 0.396609; batch adversarial loss: 0.498534\n",
      "epoch 40; iter: 200; batch classifier loss: 0.290714; batch adversarial loss: 0.428365\n",
      "epoch 41; iter: 0; batch classifier loss: 0.472125; batch adversarial loss: 0.356628\n",
      "epoch 41; iter: 200; batch classifier loss: 0.318405; batch adversarial loss: 0.435291\n",
      "epoch 42; iter: 0; batch classifier loss: 0.361471; batch adversarial loss: 0.536963\n",
      "epoch 42; iter: 200; batch classifier loss: 0.352724; batch adversarial loss: 0.353691\n",
      "epoch 43; iter: 0; batch classifier loss: 0.361690; batch adversarial loss: 0.438188\n",
      "epoch 43; iter: 200; batch classifier loss: 0.397654; batch adversarial loss: 0.445782\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386074; batch adversarial loss: 0.407252\n",
      "epoch 44; iter: 200; batch classifier loss: 0.339808; batch adversarial loss: 0.371917\n",
      "epoch 45; iter: 0; batch classifier loss: 0.246682; batch adversarial loss: 0.426982\n",
      "epoch 45; iter: 200; batch classifier loss: 0.537716; batch adversarial loss: 0.486804\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406913; batch adversarial loss: 0.348460\n",
      "epoch 46; iter: 200; batch classifier loss: 0.372808; batch adversarial loss: 0.407198\n",
      "epoch 47; iter: 0; batch classifier loss: 0.448771; batch adversarial loss: 0.399320\n",
      "epoch 47; iter: 200; batch classifier loss: 0.424271; batch adversarial loss: 0.408504\n",
      "epoch 48; iter: 0; batch classifier loss: 0.482745; batch adversarial loss: 0.326333\n",
      "epoch 48; iter: 200; batch classifier loss: 0.565586; batch adversarial loss: 0.322876\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393440; batch adversarial loss: 0.421223\n",
      "epoch 49; iter: 200; batch classifier loss: 0.559329; batch adversarial loss: 0.379548\n",
      "epoch 0; iter: 0; batch classifier loss: 44.744827; batch adversarial loss: 0.757076\n",
      "epoch 0; iter: 200; batch classifier loss: 2.112493; batch adversarial loss: 0.605768\n",
      "epoch 1; iter: 0; batch classifier loss: 4.676584; batch adversarial loss: 0.549709\n",
      "epoch 1; iter: 200; batch classifier loss: 3.829934; batch adversarial loss: 0.516048\n",
      "epoch 2; iter: 0; batch classifier loss: 5.869153; batch adversarial loss: 0.541329\n",
      "epoch 2; iter: 200; batch classifier loss: 2.078115; batch adversarial loss: 0.487784\n",
      "epoch 3; iter: 0; batch classifier loss: 4.571528; batch adversarial loss: 0.503582\n",
      "epoch 3; iter: 200; batch classifier loss: 3.757379; batch adversarial loss: 0.482345\n",
      "epoch 4; iter: 0; batch classifier loss: 16.747080; batch adversarial loss: 0.492688\n",
      "epoch 4; iter: 200; batch classifier loss: 1.315316; batch adversarial loss: 0.457839\n",
      "epoch 5; iter: 0; batch classifier loss: 4.656662; batch adversarial loss: 0.415913\n",
      "epoch 5; iter: 200; batch classifier loss: 2.289268; batch adversarial loss: 0.388087\n",
      "epoch 6; iter: 0; batch classifier loss: 1.281104; batch adversarial loss: 0.487059\n",
      "epoch 6; iter: 200; batch classifier loss: 1.126131; batch adversarial loss: 0.417038\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490490; batch adversarial loss: 0.442157\n",
      "epoch 7; iter: 200; batch classifier loss: 0.843251; batch adversarial loss: 0.438101\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588848; batch adversarial loss: 0.397746\n",
      "epoch 8; iter: 200; batch classifier loss: 0.478681; batch adversarial loss: 0.358827\n",
      "epoch 9; iter: 0; batch classifier loss: 0.658184; batch adversarial loss: 0.390840\n",
      "epoch 9; iter: 200; batch classifier loss: 0.508147; batch adversarial loss: 0.355822\n",
      "epoch 10; iter: 0; batch classifier loss: 0.491723; batch adversarial loss: 0.402852\n",
      "epoch 10; iter: 200; batch classifier loss: 0.809472; batch adversarial loss: 0.394268\n",
      "epoch 11; iter: 0; batch classifier loss: 0.469499; batch adversarial loss: 0.470012\n",
      "epoch 11; iter: 200; batch classifier loss: 0.522129; batch adversarial loss: 0.441217\n",
      "epoch 12; iter: 0; batch classifier loss: 0.556300; batch adversarial loss: 0.394559\n",
      "epoch 12; iter: 200; batch classifier loss: 0.494624; batch adversarial loss: 0.384880\n",
      "epoch 13; iter: 0; batch classifier loss: 0.387339; batch adversarial loss: 0.471460\n",
      "epoch 13; iter: 200; batch classifier loss: 0.516504; batch adversarial loss: 0.352078\n",
      "epoch 14; iter: 0; batch classifier loss: 0.424732; batch adversarial loss: 0.348430\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352144; batch adversarial loss: 0.439393\n",
      "epoch 15; iter: 0; batch classifier loss: 0.467652; batch adversarial loss: 0.442904\n",
      "epoch 15; iter: 200; batch classifier loss: 0.419442; batch adversarial loss: 0.357333\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465011; batch adversarial loss: 0.386207\n",
      "epoch 16; iter: 200; batch classifier loss: 0.549276; batch adversarial loss: 0.432586\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330111; batch adversarial loss: 0.445280\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341777; batch adversarial loss: 0.443575\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308404; batch adversarial loss: 0.392859\n",
      "epoch 18; iter: 200; batch classifier loss: 0.384693; batch adversarial loss: 0.343381\n",
      "epoch 19; iter: 0; batch classifier loss: 0.360707; batch adversarial loss: 0.512122\n",
      "epoch 19; iter: 200; batch classifier loss: 0.368977; batch adversarial loss: 0.377195\n",
      "epoch 20; iter: 0; batch classifier loss: 0.319482; batch adversarial loss: 0.441660\n",
      "epoch 20; iter: 200; batch classifier loss: 0.362889; batch adversarial loss: 0.411166\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415482; batch adversarial loss: 0.459389\n",
      "epoch 21; iter: 200; batch classifier loss: 0.414408; batch adversarial loss: 0.481292\n",
      "epoch 22; iter: 0; batch classifier loss: 0.261228; batch adversarial loss: 0.461323\n",
      "epoch 22; iter: 200; batch classifier loss: 0.332472; batch adversarial loss: 0.389943\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339797; batch adversarial loss: 0.470569\n",
      "epoch 23; iter: 200; batch classifier loss: 0.330099; batch adversarial loss: 0.357849\n",
      "epoch 24; iter: 0; batch classifier loss: 0.326340; batch adversarial loss: 0.400195\n",
      "epoch 24; iter: 200; batch classifier loss: 0.369740; batch adversarial loss: 0.312689\n",
      "epoch 25; iter: 0; batch classifier loss: 0.259483; batch adversarial loss: 0.418041\n",
      "epoch 25; iter: 200; batch classifier loss: 0.464088; batch adversarial loss: 0.347027\n",
      "epoch 26; iter: 0; batch classifier loss: 0.349442; batch adversarial loss: 0.490410\n",
      "epoch 26; iter: 200; batch classifier loss: 0.292202; batch adversarial loss: 0.374441\n",
      "epoch 27; iter: 0; batch classifier loss: 0.360856; batch adversarial loss: 0.383753\n",
      "epoch 27; iter: 200; batch classifier loss: 0.391345; batch adversarial loss: 0.338463\n",
      "epoch 28; iter: 0; batch classifier loss: 0.381028; batch adversarial loss: 0.333897\n",
      "epoch 28; iter: 200; batch classifier loss: 0.418029; batch adversarial loss: 0.360954\n",
      "epoch 29; iter: 0; batch classifier loss: 0.300310; batch adversarial loss: 0.385494\n",
      "epoch 29; iter: 200; batch classifier loss: 0.318884; batch adversarial loss: 0.386721\n",
      "epoch 30; iter: 0; batch classifier loss: 0.370125; batch adversarial loss: 0.322313\n",
      "epoch 30; iter: 200; batch classifier loss: 0.349256; batch adversarial loss: 0.314691\n",
      "epoch 31; iter: 0; batch classifier loss: 0.352682; batch adversarial loss: 0.328363\n",
      "epoch 31; iter: 200; batch classifier loss: 0.433986; batch adversarial loss: 0.388357\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430332; batch adversarial loss: 0.438974\n",
      "epoch 32; iter: 200; batch classifier loss: 0.275088; batch adversarial loss: 0.414391\n",
      "epoch 33; iter: 0; batch classifier loss: 0.334789; batch adversarial loss: 0.394080\n",
      "epoch 33; iter: 200; batch classifier loss: 0.377752; batch adversarial loss: 0.404774\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266981; batch adversarial loss: 0.332575\n",
      "epoch 34; iter: 200; batch classifier loss: 0.387391; batch adversarial loss: 0.488587\n",
      "epoch 35; iter: 0; batch classifier loss: 0.289291; batch adversarial loss: 0.427021\n",
      "epoch 35; iter: 200; batch classifier loss: 0.402040; batch adversarial loss: 0.322762\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360197; batch adversarial loss: 0.402269\n",
      "epoch 36; iter: 200; batch classifier loss: 0.327315; batch adversarial loss: 0.375654\n",
      "epoch 37; iter: 0; batch classifier loss: 0.338688; batch adversarial loss: 0.301515\n",
      "epoch 37; iter: 200; batch classifier loss: 0.364490; batch adversarial loss: 0.389517\n",
      "epoch 38; iter: 0; batch classifier loss: 0.268988; batch adversarial loss: 0.407244\n",
      "epoch 38; iter: 200; batch classifier loss: 0.270346; batch adversarial loss: 0.450747\n",
      "epoch 39; iter: 0; batch classifier loss: 0.373331; batch adversarial loss: 0.428643\n",
      "epoch 39; iter: 200; batch classifier loss: 0.554586; batch adversarial loss: 0.403678\n",
      "epoch 40; iter: 0; batch classifier loss: 0.360511; batch adversarial loss: 0.353992\n",
      "epoch 40; iter: 200; batch classifier loss: 0.274994; batch adversarial loss: 0.458844\n",
      "epoch 41; iter: 0; batch classifier loss: 0.293968; batch adversarial loss: 0.325728\n",
      "epoch 41; iter: 200; batch classifier loss: 0.373145; batch adversarial loss: 0.348515\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394543; batch adversarial loss: 0.355523\n",
      "epoch 42; iter: 200; batch classifier loss: 0.380049; batch adversarial loss: 0.353908\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328380; batch adversarial loss: 0.418926\n",
      "epoch 43; iter: 200; batch classifier loss: 0.327384; batch adversarial loss: 0.515031\n",
      "epoch 44; iter: 0; batch classifier loss: 0.352085; batch adversarial loss: 0.460032\n",
      "epoch 44; iter: 200; batch classifier loss: 0.339615; batch adversarial loss: 0.379646\n",
      "epoch 45; iter: 0; batch classifier loss: 0.328668; batch adversarial loss: 0.365403\n",
      "epoch 45; iter: 200; batch classifier loss: 0.360255; batch adversarial loss: 0.329245\n",
      "epoch 46; iter: 0; batch classifier loss: 0.542169; batch adversarial loss: 0.320313\n",
      "epoch 46; iter: 200; batch classifier loss: 0.377797; batch adversarial loss: 0.395940\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434790; batch adversarial loss: 0.399857\n",
      "epoch 47; iter: 200; batch classifier loss: 0.234071; batch adversarial loss: 0.359896\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372346; batch adversarial loss: 0.499114\n",
      "epoch 48; iter: 200; batch classifier loss: 0.383233; batch adversarial loss: 0.464261\n",
      "epoch 49; iter: 0; batch classifier loss: 0.329308; batch adversarial loss: 0.425099\n",
      "epoch 49; iter: 200; batch classifier loss: 0.333217; batch adversarial loss: 0.399886\n",
      "epoch 0; iter: 0; batch classifier loss: 16.439198; batch adversarial loss: 1.078880\n",
      "epoch 0; iter: 200; batch classifier loss: 8.043377; batch adversarial loss: 1.016654\n",
      "epoch 1; iter: 0; batch classifier loss: 8.106277; batch adversarial loss: 0.902168\n",
      "epoch 1; iter: 200; batch classifier loss: 8.716662; batch adversarial loss: 0.673058\n",
      "epoch 2; iter: 0; batch classifier loss: 1.755145; batch adversarial loss: 0.609032\n",
      "epoch 2; iter: 200; batch classifier loss: 3.570744; batch adversarial loss: 0.543159\n",
      "epoch 3; iter: 0; batch classifier loss: 3.419249; batch adversarial loss: 0.514003\n",
      "epoch 3; iter: 200; batch classifier loss: 3.637754; batch adversarial loss: 0.504589\n",
      "epoch 4; iter: 0; batch classifier loss: 1.218466; batch adversarial loss: 0.487214\n",
      "epoch 4; iter: 200; batch classifier loss: 1.838990; batch adversarial loss: 0.417179\n",
      "epoch 5; iter: 0; batch classifier loss: 1.470948; batch adversarial loss: 0.484371\n",
      "epoch 5; iter: 200; batch classifier loss: 3.699259; batch adversarial loss: 0.508978\n",
      "epoch 6; iter: 0; batch classifier loss: 1.710597; batch adversarial loss: 0.488704\n",
      "epoch 6; iter: 200; batch classifier loss: 1.153573; batch adversarial loss: 0.465280\n",
      "epoch 7; iter: 0; batch classifier loss: 0.768917; batch adversarial loss: 0.416180\n",
      "epoch 7; iter: 200; batch classifier loss: 0.959194; batch adversarial loss: 0.488738\n",
      "epoch 8; iter: 0; batch classifier loss: 1.237824; batch adversarial loss: 0.486237\n",
      "epoch 8; iter: 200; batch classifier loss: 0.979946; batch adversarial loss: 0.401563\n",
      "epoch 9; iter: 0; batch classifier loss: 0.733987; batch adversarial loss: 0.449411\n",
      "epoch 9; iter: 200; batch classifier loss: 0.508939; batch adversarial loss: 0.480319\n",
      "epoch 10; iter: 0; batch classifier loss: 0.560904; batch adversarial loss: 0.469990\n",
      "epoch 10; iter: 200; batch classifier loss: 0.553691; batch adversarial loss: 0.322728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.449228; batch adversarial loss: 0.440136\n",
      "epoch 11; iter: 200; batch classifier loss: 0.708678; batch adversarial loss: 0.375947\n",
      "epoch 12; iter: 0; batch classifier loss: 0.351437; batch adversarial loss: 0.459085\n",
      "epoch 12; iter: 200; batch classifier loss: 0.498848; batch adversarial loss: 0.389393\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421604; batch adversarial loss: 0.350234\n",
      "epoch 13; iter: 200; batch classifier loss: 0.406071; batch adversarial loss: 0.330309\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402119; batch adversarial loss: 0.387169\n",
      "epoch 14; iter: 200; batch classifier loss: 0.528847; batch adversarial loss: 0.403215\n",
      "epoch 15; iter: 0; batch classifier loss: 0.369378; batch adversarial loss: 0.491972\n",
      "epoch 15; iter: 200; batch classifier loss: 0.389087; batch adversarial loss: 0.339942\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419055; batch adversarial loss: 0.458877\n",
      "epoch 16; iter: 200; batch classifier loss: 0.323946; batch adversarial loss: 0.344364\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349278; batch adversarial loss: 0.488346\n",
      "epoch 17; iter: 200; batch classifier loss: 0.404837; batch adversarial loss: 0.372624\n",
      "epoch 18; iter: 0; batch classifier loss: 0.264485; batch adversarial loss: 0.416293\n",
      "epoch 18; iter: 200; batch classifier loss: 0.259672; batch adversarial loss: 0.363193\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354546; batch adversarial loss: 0.357188\n",
      "epoch 19; iter: 200; batch classifier loss: 0.415397; batch adversarial loss: 0.441095\n",
      "epoch 20; iter: 0; batch classifier loss: 0.355872; batch adversarial loss: 0.415638\n",
      "epoch 20; iter: 200; batch classifier loss: 0.423191; batch adversarial loss: 0.420457\n",
      "epoch 21; iter: 0; batch classifier loss: 0.416898; batch adversarial loss: 0.405837\n",
      "epoch 21; iter: 200; batch classifier loss: 0.316408; batch adversarial loss: 0.345780\n",
      "epoch 22; iter: 0; batch classifier loss: 0.351772; batch adversarial loss: 0.403810\n",
      "epoch 22; iter: 200; batch classifier loss: 0.356442; batch adversarial loss: 0.477789\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396139; batch adversarial loss: 0.458729\n",
      "epoch 23; iter: 200; batch classifier loss: 0.252364; batch adversarial loss: 0.401002\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338490; batch adversarial loss: 0.542633\n",
      "epoch 24; iter: 200; batch classifier loss: 0.370844; batch adversarial loss: 0.415267\n",
      "epoch 25; iter: 0; batch classifier loss: 0.299951; batch adversarial loss: 0.383131\n",
      "epoch 25; iter: 200; batch classifier loss: 0.285351; batch adversarial loss: 0.437959\n",
      "epoch 26; iter: 0; batch classifier loss: 0.355027; batch adversarial loss: 0.428604\n",
      "epoch 26; iter: 200; batch classifier loss: 0.365825; batch adversarial loss: 0.399490\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321730; batch adversarial loss: 0.381033\n",
      "epoch 27; iter: 200; batch classifier loss: 0.242872; batch adversarial loss: 0.365702\n",
      "epoch 28; iter: 0; batch classifier loss: 0.358687; batch adversarial loss: 0.387373\n",
      "epoch 28; iter: 200; batch classifier loss: 0.382555; batch adversarial loss: 0.456931\n",
      "epoch 29; iter: 0; batch classifier loss: 0.257450; batch adversarial loss: 0.408766\n",
      "epoch 29; iter: 200; batch classifier loss: 0.347391; batch adversarial loss: 0.353708\n",
      "epoch 30; iter: 0; batch classifier loss: 0.334235; batch adversarial loss: 0.435818\n",
      "epoch 30; iter: 200; batch classifier loss: 0.340593; batch adversarial loss: 0.448110\n",
      "epoch 31; iter: 0; batch classifier loss: 0.286918; batch adversarial loss: 0.384228\n",
      "epoch 31; iter: 200; batch classifier loss: 0.369539; batch adversarial loss: 0.463489\n",
      "epoch 32; iter: 0; batch classifier loss: 0.230803; batch adversarial loss: 0.437445\n",
      "epoch 32; iter: 200; batch classifier loss: 0.310510; batch adversarial loss: 0.334806\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323121; batch adversarial loss: 0.395634\n",
      "epoch 33; iter: 200; batch classifier loss: 0.336231; batch adversarial loss: 0.582933\n",
      "epoch 34; iter: 0; batch classifier loss: 0.246136; batch adversarial loss: 0.360983\n",
      "epoch 34; iter: 200; batch classifier loss: 0.398448; batch adversarial loss: 0.358680\n",
      "epoch 35; iter: 0; batch classifier loss: 0.329663; batch adversarial loss: 0.445954\n",
      "epoch 35; iter: 200; batch classifier loss: 0.336054; batch adversarial loss: 0.499039\n",
      "epoch 36; iter: 0; batch classifier loss: 0.329583; batch adversarial loss: 0.489766\n",
      "epoch 36; iter: 200; batch classifier loss: 0.396630; batch adversarial loss: 0.394654\n",
      "epoch 37; iter: 0; batch classifier loss: 0.296245; batch adversarial loss: 0.405271\n",
      "epoch 37; iter: 200; batch classifier loss: 0.366248; batch adversarial loss: 0.426464\n",
      "epoch 38; iter: 0; batch classifier loss: 0.338099; batch adversarial loss: 0.398074\n",
      "epoch 38; iter: 200; batch classifier loss: 0.386536; batch adversarial loss: 0.420538\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386697; batch adversarial loss: 0.435161\n",
      "epoch 39; iter: 200; batch classifier loss: 0.374485; batch adversarial loss: 0.470395\n",
      "epoch 40; iter: 0; batch classifier loss: 0.361960; batch adversarial loss: 0.485999\n",
      "epoch 40; iter: 200; batch classifier loss: 0.389706; batch adversarial loss: 0.447313\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398540; batch adversarial loss: 0.340874\n",
      "epoch 41; iter: 200; batch classifier loss: 0.356328; batch adversarial loss: 0.436195\n",
      "epoch 42; iter: 0; batch classifier loss: 0.409759; batch adversarial loss: 0.354756\n",
      "epoch 42; iter: 200; batch classifier loss: 0.483422; batch adversarial loss: 0.454871\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421820; batch adversarial loss: 0.384858\n",
      "epoch 43; iter: 200; batch classifier loss: 0.463830; batch adversarial loss: 0.377391\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406939; batch adversarial loss: 0.413802\n",
      "epoch 44; iter: 200; batch classifier loss: 0.338632; batch adversarial loss: 0.415759\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421808; batch adversarial loss: 0.426631\n",
      "epoch 45; iter: 200; batch classifier loss: 0.494795; batch adversarial loss: 0.401584\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406838; batch adversarial loss: 0.392875\n",
      "epoch 46; iter: 200; batch classifier loss: 0.462509; batch adversarial loss: 0.400828\n",
      "epoch 47; iter: 0; batch classifier loss: 0.422675; batch adversarial loss: 0.390920\n",
      "epoch 47; iter: 200; batch classifier loss: 0.347481; batch adversarial loss: 0.421099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.366498; batch adversarial loss: 0.413506\n",
      "epoch 48; iter: 200; batch classifier loss: 0.451214; batch adversarial loss: 0.398076\n",
      "epoch 49; iter: 0; batch classifier loss: 0.472778; batch adversarial loss: 0.429729\n",
      "epoch 49; iter: 200; batch classifier loss: 0.447223; batch adversarial loss: 0.405794\n",
      "Best parameters: adversary_loss_weight      0.500000\n",
      "batch_size               128.000000\n",
      "num_epochs                50.000000\n",
      "acc_mean                   0.823230\n",
      "acc_std                    0.020463\n",
      "f1_mean                    0.526108\n",
      "f1_std                     0.083688\n",
      "SPD_mean                   0.004823\n",
      "SPD_std                    0.015178\n",
      "DI_mean                    1.045982\n",
      "DI_std                     0.117935\n",
      "EOD_mean                   0.124004\n",
      "EOD_std                    0.042145\n",
      "AOD_mean                   0.075303\n",
      "AOD_std                    0.023496\n",
      "fairness_score             0.050806\n",
      "Name: 5, dtype: float64\n",
      "epoch 0; iter: 0; batch classifier loss: 138.343506; batch adversarial loss: 0.740680\n",
      "epoch 0; iter: 200; batch classifier loss: 5.860970; batch adversarial loss: 0.652335\n",
      "epoch 1; iter: 0; batch classifier loss: 5.344526; batch adversarial loss: 0.589153\n",
      "epoch 1; iter: 200; batch classifier loss: 7.891682; batch adversarial loss: 0.548553\n",
      "epoch 2; iter: 0; batch classifier loss: 30.822945; batch adversarial loss: 0.516605\n",
      "epoch 2; iter: 200; batch classifier loss: 3.929190; batch adversarial loss: 0.475426\n",
      "epoch 3; iter: 0; batch classifier loss: 7.111454; batch adversarial loss: 0.447287\n",
      "epoch 3; iter: 200; batch classifier loss: 1.911630; batch adversarial loss: 0.509269\n",
      "epoch 4; iter: 0; batch classifier loss: 2.398500; batch adversarial loss: 0.364887\n",
      "epoch 4; iter: 200; batch classifier loss: 2.792722; batch adversarial loss: 0.416207\n",
      "epoch 5; iter: 0; batch classifier loss: 1.367570; batch adversarial loss: 0.382391\n",
      "epoch 5; iter: 200; batch classifier loss: 0.714504; batch adversarial loss: 0.461668\n",
      "epoch 6; iter: 0; batch classifier loss: 1.367544; batch adversarial loss: 0.449496\n",
      "epoch 6; iter: 200; batch classifier loss: 0.486782; batch adversarial loss: 0.358201\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561104; batch adversarial loss: 0.424910\n",
      "epoch 7; iter: 200; batch classifier loss: 0.443797; batch adversarial loss: 0.427717\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486564; batch adversarial loss: 0.369682\n",
      "epoch 8; iter: 200; batch classifier loss: 0.423267; batch adversarial loss: 0.381626\n",
      "epoch 9; iter: 0; batch classifier loss: 0.339635; batch adversarial loss: 0.383173\n",
      "epoch 9; iter: 200; batch classifier loss: 0.438321; batch adversarial loss: 0.345121\n",
      "epoch 10; iter: 0; batch classifier loss: 0.350791; batch adversarial loss: 0.396469\n",
      "epoch 10; iter: 200; batch classifier loss: 0.353569; batch adversarial loss: 0.464975\n",
      "epoch 11; iter: 0; batch classifier loss: 0.342421; batch adversarial loss: 0.432012\n",
      "epoch 11; iter: 200; batch classifier loss: 0.378482; batch adversarial loss: 0.441062\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390749; batch adversarial loss: 0.403490\n",
      "epoch 12; iter: 200; batch classifier loss: 0.382975; batch adversarial loss: 0.496938\n",
      "epoch 13; iter: 0; batch classifier loss: 0.385915; batch adversarial loss: 0.441115\n",
      "epoch 13; iter: 200; batch classifier loss: 0.505759; batch adversarial loss: 0.440882\n",
      "epoch 14; iter: 0; batch classifier loss: 0.320646; batch adversarial loss: 0.540137\n",
      "epoch 14; iter: 200; batch classifier loss: 0.327167; batch adversarial loss: 0.385955\n",
      "epoch 15; iter: 0; batch classifier loss: 0.338206; batch adversarial loss: 0.420749\n",
      "epoch 15; iter: 200; batch classifier loss: 0.320523; batch adversarial loss: 0.436922\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430189; batch adversarial loss: 0.394367\n",
      "epoch 16; iter: 200; batch classifier loss: 0.329272; batch adversarial loss: 0.421128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375574; batch adversarial loss: 0.324054\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345255; batch adversarial loss: 0.407886\n",
      "epoch 18; iter: 0; batch classifier loss: 0.292377; batch adversarial loss: 0.368539\n",
      "epoch 18; iter: 200; batch classifier loss: 0.307626; batch adversarial loss: 0.374189\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278878; batch adversarial loss: 0.416396\n",
      "epoch 19; iter: 200; batch classifier loss: 0.293187; batch adversarial loss: 0.369358\n",
      "epoch 20; iter: 0; batch classifier loss: 0.303275; batch adversarial loss: 0.426631\n",
      "epoch 20; iter: 200; batch classifier loss: 0.378102; batch adversarial loss: 0.357652\n",
      "epoch 21; iter: 0; batch classifier loss: 0.337025; batch adversarial loss: 0.431352\n",
      "epoch 21; iter: 200; batch classifier loss: 0.392697; batch adversarial loss: 0.386079\n",
      "epoch 22; iter: 0; batch classifier loss: 0.313860; batch adversarial loss: 0.384621\n",
      "epoch 22; iter: 200; batch classifier loss: 0.285790; batch adversarial loss: 0.497192\n",
      "epoch 23; iter: 0; batch classifier loss: 0.354469; batch adversarial loss: 0.454849\n",
      "epoch 23; iter: 200; batch classifier loss: 0.375717; batch adversarial loss: 0.415787\n",
      "epoch 24; iter: 0; batch classifier loss: 0.356502; batch adversarial loss: 0.425929\n",
      "epoch 24; iter: 200; batch classifier loss: 0.381167; batch adversarial loss: 0.421495\n",
      "epoch 25; iter: 0; batch classifier loss: 0.229327; batch adversarial loss: 0.407174\n",
      "epoch 25; iter: 200; batch classifier loss: 0.387099; batch adversarial loss: 0.427824\n",
      "epoch 26; iter: 0; batch classifier loss: 0.354051; batch adversarial loss: 0.356224\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336004; batch adversarial loss: 0.389442\n",
      "epoch 27; iter: 0; batch classifier loss: 0.418996; batch adversarial loss: 0.332734\n",
      "epoch 27; iter: 200; batch classifier loss: 0.405484; batch adversarial loss: 0.492594\n",
      "epoch 28; iter: 0; batch classifier loss: 0.259216; batch adversarial loss: 0.370144\n",
      "epoch 28; iter: 200; batch classifier loss: 0.334974; batch adversarial loss: 0.304459\n",
      "epoch 29; iter: 0; batch classifier loss: 0.299280; batch adversarial loss: 0.359114\n",
      "epoch 29; iter: 200; batch classifier loss: 0.322100; batch adversarial loss: 0.445155\n",
      "epoch 30; iter: 0; batch classifier loss: 0.261344; batch adversarial loss: 0.360330\n",
      "epoch 30; iter: 200; batch classifier loss: 0.303514; batch adversarial loss: 0.456833\n",
      "epoch 31; iter: 0; batch classifier loss: 0.343396; batch adversarial loss: 0.437842\n",
      "epoch 31; iter: 200; batch classifier loss: 0.314709; batch adversarial loss: 0.458798\n",
      "epoch 32; iter: 0; batch classifier loss: 0.322578; batch adversarial loss: 0.464179\n",
      "epoch 32; iter: 200; batch classifier loss: 0.316856; batch adversarial loss: 0.375574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.334554; batch adversarial loss: 0.370710\n",
      "epoch 33; iter: 200; batch classifier loss: 0.326183; batch adversarial loss: 0.478224\n",
      "epoch 34; iter: 0; batch classifier loss: 0.349717; batch adversarial loss: 0.421302\n",
      "epoch 34; iter: 200; batch classifier loss: 0.236391; batch adversarial loss: 0.446424\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392280; batch adversarial loss: 0.401009\n",
      "epoch 35; iter: 200; batch classifier loss: 0.323013; batch adversarial loss: 0.353255\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357481; batch adversarial loss: 0.359571\n",
      "epoch 36; iter: 200; batch classifier loss: 0.315062; batch adversarial loss: 0.401420\n",
      "epoch 37; iter: 0; batch classifier loss: 0.373554; batch adversarial loss: 0.403529\n",
      "epoch 37; iter: 200; batch classifier loss: 0.353390; batch adversarial loss: 0.379742\n",
      "epoch 38; iter: 0; batch classifier loss: 0.317715; batch adversarial loss: 0.489146\n",
      "epoch 38; iter: 200; batch classifier loss: 0.287262; batch adversarial loss: 0.467743\n",
      "epoch 39; iter: 0; batch classifier loss: 0.384277; batch adversarial loss: 0.379040\n",
      "epoch 39; iter: 200; batch classifier loss: 0.409956; batch adversarial loss: 0.435116\n",
      "epoch 40; iter: 0; batch classifier loss: 0.368339; batch adversarial loss: 0.473968\n",
      "epoch 40; iter: 200; batch classifier loss: 0.438120; batch adversarial loss: 0.418053\n",
      "epoch 41; iter: 0; batch classifier loss: 0.355104; batch adversarial loss: 0.404551\n",
      "epoch 41; iter: 200; batch classifier loss: 0.328213; batch adversarial loss: 0.453838\n",
      "epoch 42; iter: 0; batch classifier loss: 0.306144; batch adversarial loss: 0.346575\n",
      "epoch 42; iter: 200; batch classifier loss: 0.428123; batch adversarial loss: 0.416384\n",
      "epoch 43; iter: 0; batch classifier loss: 0.351257; batch adversarial loss: 0.364558\n",
      "epoch 43; iter: 200; batch classifier loss: 0.273344; batch adversarial loss: 0.365692\n",
      "epoch 44; iter: 0; batch classifier loss: 0.245638; batch adversarial loss: 0.415434\n",
      "epoch 44; iter: 200; batch classifier loss: 0.299948; batch adversarial loss: 0.421286\n",
      "epoch 45; iter: 0; batch classifier loss: 0.355282; batch adversarial loss: 0.574590\n",
      "epoch 45; iter: 200; batch classifier loss: 0.481179; batch adversarial loss: 0.393054\n",
      "epoch 46; iter: 0; batch classifier loss: 0.423248; batch adversarial loss: 0.419414\n",
      "epoch 46; iter: 200; batch classifier loss: 0.371337; batch adversarial loss: 0.416562\n",
      "epoch 47; iter: 0; batch classifier loss: 0.461399; batch adversarial loss: 0.331761\n",
      "epoch 47; iter: 200; batch classifier loss: 0.367983; batch adversarial loss: 0.390874\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347214; batch adversarial loss: 0.354016\n",
      "epoch 48; iter: 200; batch classifier loss: 0.362696; batch adversarial loss: 0.609508\n",
      "epoch 49; iter: 0; batch classifier loss: 0.466542; batch adversarial loss: 0.477008\n",
      "epoch 49; iter: 200; batch classifier loss: 0.333605; batch adversarial loss: 0.469243\n",
      "epoch 0; iter: 0; batch classifier loss: 148.652695; batch adversarial loss: 0.783478\n",
      "epoch 0; iter: 200; batch classifier loss: 6.958099; batch adversarial loss: 0.687078\n",
      "epoch 1; iter: 0; batch classifier loss: 9.813816; batch adversarial loss: 0.590791\n",
      "epoch 1; iter: 200; batch classifier loss: 15.347698; batch adversarial loss: 0.527186\n",
      "epoch 2; iter: 0; batch classifier loss: 11.242826; batch adversarial loss: 0.480385\n",
      "epoch 2; iter: 200; batch classifier loss: 4.141749; batch adversarial loss: 0.478804\n",
      "epoch 3; iter: 0; batch classifier loss: 2.462243; batch adversarial loss: 0.437671\n",
      "epoch 3; iter: 200; batch classifier loss: 7.962622; batch adversarial loss: 0.439279\n",
      "epoch 4; iter: 0; batch classifier loss: 3.958175; batch adversarial loss: 0.497317\n",
      "epoch 4; iter: 200; batch classifier loss: 9.305100; batch adversarial loss: 0.481958\n",
      "epoch 5; iter: 0; batch classifier loss: 0.584476; batch adversarial loss: 0.449047\n",
      "epoch 5; iter: 200; batch classifier loss: 1.331034; batch adversarial loss: 0.442970\n",
      "epoch 6; iter: 0; batch classifier loss: 1.404612; batch adversarial loss: 0.416174\n",
      "epoch 6; iter: 200; batch classifier loss: 1.401779; batch adversarial loss: 0.389002\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504574; batch adversarial loss: 0.330499\n",
      "epoch 7; iter: 200; batch classifier loss: 0.641007; batch adversarial loss: 0.411890\n",
      "epoch 8; iter: 0; batch classifier loss: 0.806407; batch adversarial loss: 0.450517\n",
      "epoch 8; iter: 200; batch classifier loss: 0.668438; batch adversarial loss: 0.450743\n",
      "epoch 9; iter: 0; batch classifier loss: 0.521191; batch adversarial loss: 0.382410\n",
      "epoch 9; iter: 200; batch classifier loss: 0.502958; batch adversarial loss: 0.399362\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343448; batch adversarial loss: 0.355732\n",
      "epoch 10; iter: 200; batch classifier loss: 0.420036; batch adversarial loss: 0.345764\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566151; batch adversarial loss: 0.385818\n",
      "epoch 11; iter: 200; batch classifier loss: 0.514104; batch adversarial loss: 0.385743\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396856; batch adversarial loss: 0.535703\n",
      "epoch 12; iter: 200; batch classifier loss: 0.676460; batch adversarial loss: 0.349564\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476424; batch adversarial loss: 0.514436\n",
      "epoch 13; iter: 200; batch classifier loss: 0.380811; batch adversarial loss: 0.388445\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395916; batch adversarial loss: 0.438466\n",
      "epoch 14; iter: 200; batch classifier loss: 0.516227; batch adversarial loss: 0.458262\n",
      "epoch 15; iter: 0; batch classifier loss: 0.453696; batch adversarial loss: 0.329775\n",
      "epoch 15; iter: 200; batch classifier loss: 0.388483; batch adversarial loss: 0.381925\n",
      "epoch 16; iter: 0; batch classifier loss: 0.406003; batch adversarial loss: 0.392632\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304143; batch adversarial loss: 0.465610\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537100; batch adversarial loss: 0.425241\n",
      "epoch 17; iter: 200; batch classifier loss: 0.312343; batch adversarial loss: 0.453876\n",
      "epoch 18; iter: 0; batch classifier loss: 0.434438; batch adversarial loss: 0.477480\n",
      "epoch 18; iter: 200; batch classifier loss: 0.313832; batch adversarial loss: 0.487558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.394270; batch adversarial loss: 0.435724\n",
      "epoch 19; iter: 200; batch classifier loss: 0.340142; batch adversarial loss: 0.460183\n",
      "epoch 20; iter: 0; batch classifier loss: 0.248157; batch adversarial loss: 0.426690\n",
      "epoch 20; iter: 200; batch classifier loss: 0.383413; batch adversarial loss: 0.491725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.330244; batch adversarial loss: 0.412838\n",
      "epoch 21; iter: 200; batch classifier loss: 0.281709; batch adversarial loss: 0.436302\n",
      "epoch 22; iter: 0; batch classifier loss: 0.304344; batch adversarial loss: 0.482324\n",
      "epoch 22; iter: 200; batch classifier loss: 0.332895; batch adversarial loss: 0.443621\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351657; batch adversarial loss: 0.291465\n",
      "epoch 23; iter: 200; batch classifier loss: 0.322733; batch adversarial loss: 0.409060\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440202; batch adversarial loss: 0.456764\n",
      "epoch 24; iter: 200; batch classifier loss: 0.371904; batch adversarial loss: 0.401336\n",
      "epoch 25; iter: 0; batch classifier loss: 0.335587; batch adversarial loss: 0.389519\n",
      "epoch 25; iter: 200; batch classifier loss: 0.306344; batch adversarial loss: 0.359121\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378977; batch adversarial loss: 0.420888\n",
      "epoch 26; iter: 200; batch classifier loss: 0.413676; batch adversarial loss: 0.409106\n",
      "epoch 27; iter: 0; batch classifier loss: 0.276453; batch adversarial loss: 0.462546\n",
      "epoch 27; iter: 200; batch classifier loss: 0.375280; batch adversarial loss: 0.383837\n",
      "epoch 28; iter: 0; batch classifier loss: 0.341801; batch adversarial loss: 0.507358\n",
      "epoch 28; iter: 200; batch classifier loss: 0.477395; batch adversarial loss: 0.393865\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322520; batch adversarial loss: 0.406041\n",
      "epoch 29; iter: 200; batch classifier loss: 0.371125; batch adversarial loss: 0.511248\n",
      "epoch 30; iter: 0; batch classifier loss: 0.325331; batch adversarial loss: 0.376735\n",
      "epoch 30; iter: 200; batch classifier loss: 0.364411; batch adversarial loss: 0.361815\n",
      "epoch 31; iter: 0; batch classifier loss: 0.381186; batch adversarial loss: 0.379669\n",
      "epoch 31; iter: 200; batch classifier loss: 0.309748; batch adversarial loss: 0.359476\n",
      "epoch 32; iter: 0; batch classifier loss: 0.323600; batch adversarial loss: 0.415169\n",
      "epoch 32; iter: 200; batch classifier loss: 0.323582; batch adversarial loss: 0.378463\n",
      "epoch 33; iter: 0; batch classifier loss: 0.319958; batch adversarial loss: 0.410448\n",
      "epoch 33; iter: 200; batch classifier loss: 0.364806; batch adversarial loss: 0.459645\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276904; batch adversarial loss: 0.387805\n",
      "epoch 34; iter: 200; batch classifier loss: 0.321272; batch adversarial loss: 0.403012\n",
      "epoch 35; iter: 0; batch classifier loss: 0.369464; batch adversarial loss: 0.472376\n",
      "epoch 35; iter: 200; batch classifier loss: 0.279503; batch adversarial loss: 0.405306\n",
      "epoch 36; iter: 0; batch classifier loss: 0.302094; batch adversarial loss: 0.347300\n",
      "epoch 36; iter: 200; batch classifier loss: 0.395585; batch adversarial loss: 0.413229\n",
      "epoch 37; iter: 0; batch classifier loss: 0.287663; batch adversarial loss: 0.431635\n",
      "epoch 37; iter: 200; batch classifier loss: 0.289180; batch adversarial loss: 0.446257\n",
      "epoch 38; iter: 0; batch classifier loss: 0.330519; batch adversarial loss: 0.388897\n",
      "epoch 38; iter: 200; batch classifier loss: 0.313941; batch adversarial loss: 0.442445\n",
      "epoch 39; iter: 0; batch classifier loss: 0.317987; batch adversarial loss: 0.431922\n",
      "epoch 39; iter: 200; batch classifier loss: 0.351809; batch adversarial loss: 0.381744\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351201; batch adversarial loss: 0.502074\n",
      "epoch 40; iter: 200; batch classifier loss: 0.318279; batch adversarial loss: 0.481894\n",
      "epoch 41; iter: 0; batch classifier loss: 0.331577; batch adversarial loss: 0.354367\n",
      "epoch 41; iter: 200; batch classifier loss: 0.347978; batch adversarial loss: 0.380896\n",
      "epoch 42; iter: 0; batch classifier loss: 0.360880; batch adversarial loss: 0.440784\n",
      "epoch 42; iter: 200; batch classifier loss: 0.449176; batch adversarial loss: 0.442480\n",
      "epoch 43; iter: 0; batch classifier loss: 0.356721; batch adversarial loss: 0.373423\n",
      "epoch 43; iter: 200; batch classifier loss: 0.358635; batch adversarial loss: 0.403277\n",
      "epoch 44; iter: 0; batch classifier loss: 0.415688; batch adversarial loss: 0.373529\n",
      "epoch 44; iter: 200; batch classifier loss: 0.413189; batch adversarial loss: 0.424991\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374485; batch adversarial loss: 0.359612\n",
      "epoch 45; iter: 200; batch classifier loss: 0.372522; batch adversarial loss: 0.372746\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396907; batch adversarial loss: 0.530813\n",
      "epoch 46; iter: 200; batch classifier loss: 0.459707; batch adversarial loss: 0.404363\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366586; batch adversarial loss: 0.309230\n",
      "epoch 47; iter: 200; batch classifier loss: 0.401826; batch adversarial loss: 0.343061\n",
      "epoch 48; iter: 0; batch classifier loss: 0.310531; batch adversarial loss: 0.385721\n",
      "epoch 48; iter: 200; batch classifier loss: 0.391060; batch adversarial loss: 0.383286\n",
      "epoch 49; iter: 0; batch classifier loss: 0.382567; batch adversarial loss: 0.353806\n",
      "epoch 49; iter: 200; batch classifier loss: 0.600771; batch adversarial loss: 0.509196\n",
      "epoch 0; iter: 0; batch classifier loss: 8.971134; batch adversarial loss: 0.583341\n",
      "epoch 0; iter: 200; batch classifier loss: 5.209236; batch adversarial loss: 0.530944\n",
      "epoch 1; iter: 0; batch classifier loss: 5.884396; batch adversarial loss: 0.565097\n",
      "epoch 1; iter: 200; batch classifier loss: 3.270955; batch adversarial loss: 0.520853\n",
      "epoch 2; iter: 0; batch classifier loss: 6.719643; batch adversarial loss: 0.439531\n",
      "epoch 2; iter: 200; batch classifier loss: 4.651103; batch adversarial loss: 0.423829\n",
      "epoch 3; iter: 0; batch classifier loss: 3.763370; batch adversarial loss: 0.463260\n",
      "epoch 3; iter: 200; batch classifier loss: 1.238829; batch adversarial loss: 0.398460\n",
      "epoch 4; iter: 0; batch classifier loss: 1.484529; batch adversarial loss: 0.485001\n",
      "epoch 4; iter: 200; batch classifier loss: 2.147645; batch adversarial loss: 0.491949\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599661; batch adversarial loss: 0.454731\n",
      "epoch 5; iter: 200; batch classifier loss: 0.496283; batch adversarial loss: 0.447351\n",
      "epoch 6; iter: 0; batch classifier loss: 0.483441; batch adversarial loss: 0.416161\n",
      "epoch 6; iter: 200; batch classifier loss: 0.451136; batch adversarial loss: 0.383274\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416489; batch adversarial loss: 0.419367\n",
      "epoch 7; iter: 200; batch classifier loss: 0.469235; batch adversarial loss: 0.468228\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434866; batch adversarial loss: 0.424031\n",
      "epoch 8; iter: 200; batch classifier loss: 0.581101; batch adversarial loss: 0.354814\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634889; batch adversarial loss: 0.431619\n",
      "epoch 9; iter: 200; batch classifier loss: 0.439457; batch adversarial loss: 0.449178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.694866; batch adversarial loss: 0.495701\n",
      "epoch 10; iter: 200; batch classifier loss: 0.332077; batch adversarial loss: 0.372761\n",
      "epoch 11; iter: 0; batch classifier loss: 0.462609; batch adversarial loss: 0.376226\n",
      "epoch 11; iter: 200; batch classifier loss: 0.303071; batch adversarial loss: 0.360540\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345786; batch adversarial loss: 0.429987\n",
      "epoch 12; iter: 200; batch classifier loss: 0.415222; batch adversarial loss: 0.312019\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579674; batch adversarial loss: 0.439471\n",
      "epoch 13; iter: 200; batch classifier loss: 0.326485; batch adversarial loss: 0.486982\n",
      "epoch 14; iter: 0; batch classifier loss: 0.361998; batch adversarial loss: 0.339081\n",
      "epoch 14; iter: 200; batch classifier loss: 0.253565; batch adversarial loss: 0.430793\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358162; batch adversarial loss: 0.405788\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380970; batch adversarial loss: 0.490058\n",
      "epoch 16; iter: 0; batch classifier loss: 0.359941; batch adversarial loss: 0.449963\n",
      "epoch 16; iter: 200; batch classifier loss: 0.378885; batch adversarial loss: 0.315809\n",
      "epoch 17; iter: 0; batch classifier loss: 0.293972; batch adversarial loss: 0.442166\n",
      "epoch 17; iter: 200; batch classifier loss: 0.385297; batch adversarial loss: 0.384499\n",
      "epoch 18; iter: 0; batch classifier loss: 0.351736; batch adversarial loss: 0.414883\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341214; batch adversarial loss: 0.354961\n",
      "epoch 19; iter: 0; batch classifier loss: 0.386711; batch adversarial loss: 0.337175\n",
      "epoch 19; iter: 200; batch classifier loss: 0.307160; batch adversarial loss: 0.493540\n",
      "epoch 20; iter: 0; batch classifier loss: 0.343100; batch adversarial loss: 0.362655\n",
      "epoch 20; iter: 200; batch classifier loss: 0.264137; batch adversarial loss: 0.369624\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311660; batch adversarial loss: 0.436824\n",
      "epoch 21; iter: 200; batch classifier loss: 0.320614; batch adversarial loss: 0.396121\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348386; batch adversarial loss: 0.409688\n",
      "epoch 22; iter: 200; batch classifier loss: 0.266482; batch adversarial loss: 0.320210\n",
      "epoch 23; iter: 0; batch classifier loss: 0.317645; batch adversarial loss: 0.360752\n",
      "epoch 23; iter: 200; batch classifier loss: 0.355431; batch adversarial loss: 0.444823\n",
      "epoch 24; iter: 0; batch classifier loss: 0.342227; batch adversarial loss: 0.354052\n",
      "epoch 24; iter: 200; batch classifier loss: 0.355529; batch adversarial loss: 0.379374\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442323; batch adversarial loss: 0.385752\n",
      "epoch 25; iter: 200; batch classifier loss: 0.308375; batch adversarial loss: 0.487286\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366225; batch adversarial loss: 0.338267\n",
      "epoch 26; iter: 200; batch classifier loss: 0.355008; batch adversarial loss: 0.374897\n",
      "epoch 27; iter: 0; batch classifier loss: 0.370886; batch adversarial loss: 0.389190\n",
      "epoch 27; iter: 200; batch classifier loss: 0.199936; batch adversarial loss: 0.312368\n",
      "epoch 28; iter: 0; batch classifier loss: 0.320909; batch adversarial loss: 0.327227\n",
      "epoch 28; iter: 200; batch classifier loss: 0.279309; batch adversarial loss: 0.443305\n",
      "epoch 29; iter: 0; batch classifier loss: 0.343990; batch adversarial loss: 0.413058\n",
      "epoch 29; iter: 200; batch classifier loss: 0.331159; batch adversarial loss: 0.415638\n",
      "epoch 30; iter: 0; batch classifier loss: 0.344122; batch adversarial loss: 0.363001\n",
      "epoch 30; iter: 200; batch classifier loss: 0.279801; batch adversarial loss: 0.337025\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387376; batch adversarial loss: 0.430783\n",
      "epoch 31; iter: 200; batch classifier loss: 0.333411; batch adversarial loss: 0.464863\n",
      "epoch 32; iter: 0; batch classifier loss: 0.402286; batch adversarial loss: 0.433046\n",
      "epoch 32; iter: 200; batch classifier loss: 0.340097; batch adversarial loss: 0.409971\n",
      "epoch 33; iter: 0; batch classifier loss: 0.436694; batch adversarial loss: 0.360251\n",
      "epoch 33; iter: 200; batch classifier loss: 0.427880; batch adversarial loss: 0.432096\n",
      "epoch 34; iter: 0; batch classifier loss: 0.342022; batch adversarial loss: 0.604882\n",
      "epoch 34; iter: 200; batch classifier loss: 0.323693; batch adversarial loss: 0.413954\n",
      "epoch 35; iter: 0; batch classifier loss: 0.331077; batch adversarial loss: 0.506413\n",
      "epoch 35; iter: 200; batch classifier loss: 0.351386; batch adversarial loss: 0.364360\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 0.420953\n",
      "epoch 36; iter: 200; batch classifier loss: 0.406850; batch adversarial loss: 0.377468\n",
      "epoch 37; iter: 0; batch classifier loss: 0.299169; batch adversarial loss: 0.449217\n",
      "epoch 37; iter: 200; batch classifier loss: 0.405820; batch adversarial loss: 0.421617\n",
      "epoch 38; iter: 0; batch classifier loss: 0.410836; batch adversarial loss: 0.510902\n",
      "epoch 38; iter: 200; batch classifier loss: 0.440764; batch adversarial loss: 0.477952\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255841; batch adversarial loss: 0.415379\n",
      "epoch 39; iter: 200; batch classifier loss: 0.325802; batch adversarial loss: 0.497087\n",
      "epoch 40; iter: 0; batch classifier loss: 0.350230; batch adversarial loss: 0.425077\n",
      "epoch 40; iter: 200; batch classifier loss: 0.304890; batch adversarial loss: 0.488044\n",
      "epoch 41; iter: 0; batch classifier loss: 0.280498; batch adversarial loss: 0.449862\n",
      "epoch 41; iter: 200; batch classifier loss: 0.331793; batch adversarial loss: 0.264378\n",
      "epoch 42; iter: 0; batch classifier loss: 0.348697; batch adversarial loss: 0.411982\n",
      "epoch 42; iter: 200; batch classifier loss: 0.502207; batch adversarial loss: 0.447854\n",
      "epoch 43; iter: 0; batch classifier loss: 0.269465; batch adversarial loss: 0.454289\n",
      "epoch 43; iter: 200; batch classifier loss: 0.420476; batch adversarial loss: 0.297639\n",
      "epoch 44; iter: 0; batch classifier loss: 0.380594; batch adversarial loss: 0.401489\n",
      "epoch 44; iter: 200; batch classifier loss: 0.395618; batch adversarial loss: 0.374718\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411386; batch adversarial loss: 0.322057\n",
      "epoch 45; iter: 200; batch classifier loss: 0.281219; batch adversarial loss: 0.422200\n",
      "epoch 46; iter: 0; batch classifier loss: 0.252880; batch adversarial loss: 0.479845\n",
      "epoch 46; iter: 200; batch classifier loss: 0.350773; batch adversarial loss: 0.512187\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416528; batch adversarial loss: 0.417236\n",
      "epoch 47; iter: 200; batch classifier loss: 0.377937; batch adversarial loss: 0.350261\n",
      "epoch 48; iter: 0; batch classifier loss: 0.465666; batch adversarial loss: 0.399232\n",
      "epoch 48; iter: 200; batch classifier loss: 0.449211; batch adversarial loss: 0.395853\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371884; batch adversarial loss: 0.565080\n",
      "epoch 49; iter: 200; batch classifier loss: 0.388377; batch adversarial loss: 0.486839\n",
      "epoch 0; iter: 0; batch classifier loss: 105.459541; batch adversarial loss: 0.781023\n",
      "epoch 0; iter: 200; batch classifier loss: 12.600159; batch adversarial loss: 0.646085\n",
      "epoch 1; iter: 0; batch classifier loss: 3.620937; batch adversarial loss: 0.588251\n",
      "epoch 1; iter: 200; batch classifier loss: 3.252802; batch adversarial loss: 0.544445\n",
      "epoch 2; iter: 0; batch classifier loss: 1.980085; batch adversarial loss: 0.501956\n",
      "epoch 2; iter: 200; batch classifier loss: 2.068016; batch adversarial loss: 0.495677\n",
      "epoch 3; iter: 0; batch classifier loss: 5.054071; batch adversarial loss: 0.483640\n",
      "epoch 3; iter: 200; batch classifier loss: 1.616079; batch adversarial loss: 0.461384\n",
      "epoch 4; iter: 0; batch classifier loss: 0.724544; batch adversarial loss: 0.471609\n",
      "epoch 4; iter: 200; batch classifier loss: 0.800820; batch adversarial loss: 0.400512\n",
      "epoch 5; iter: 0; batch classifier loss: 1.032893; batch adversarial loss: 0.525341\n",
      "epoch 5; iter: 200; batch classifier loss: 0.486456; batch adversarial loss: 0.531357\n",
      "epoch 6; iter: 0; batch classifier loss: 0.461852; batch adversarial loss: 0.376537\n",
      "epoch 6; iter: 200; batch classifier loss: 0.510080; batch adversarial loss: 0.476918\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486618; batch adversarial loss: 0.375199\n",
      "epoch 7; iter: 200; batch classifier loss: 0.408663; batch adversarial loss: 0.426651\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468684; batch adversarial loss: 0.524941\n",
      "epoch 8; iter: 200; batch classifier loss: 0.889246; batch adversarial loss: 0.458172\n",
      "epoch 9; iter: 0; batch classifier loss: 0.805121; batch adversarial loss: 0.494110\n",
      "epoch 9; iter: 200; batch classifier loss: 0.378753; batch adversarial loss: 0.452363\n",
      "epoch 10; iter: 0; batch classifier loss: 0.414292; batch adversarial loss: 0.345128\n",
      "epoch 10; iter: 200; batch classifier loss: 0.671895; batch adversarial loss: 0.491404\n",
      "epoch 11; iter: 0; batch classifier loss: 0.311744; batch adversarial loss: 0.468821\n",
      "epoch 11; iter: 200; batch classifier loss: 0.363743; batch adversarial loss: 0.517029\n",
      "epoch 12; iter: 0; batch classifier loss: 0.447425; batch adversarial loss: 0.356533\n",
      "epoch 12; iter: 200; batch classifier loss: 0.363101; batch adversarial loss: 0.436740\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510162; batch adversarial loss: 0.464391\n",
      "epoch 13; iter: 200; batch classifier loss: 0.394215; batch adversarial loss: 0.410671\n",
      "epoch 14; iter: 0; batch classifier loss: 0.340856; batch adversarial loss: 0.326844\n",
      "epoch 14; iter: 200; batch classifier loss: 0.325055; batch adversarial loss: 0.397711\n",
      "epoch 15; iter: 0; batch classifier loss: 0.320716; batch adversarial loss: 0.506435\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341749; batch adversarial loss: 0.427988\n",
      "epoch 16; iter: 0; batch classifier loss: 0.425905; batch adversarial loss: 0.414612\n",
      "epoch 16; iter: 200; batch classifier loss: 0.366712; batch adversarial loss: 0.428366\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332292; batch adversarial loss: 0.380966\n",
      "epoch 17; iter: 200; batch classifier loss: 0.289942; batch adversarial loss: 0.427867\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371493; batch adversarial loss: 0.485350\n",
      "epoch 18; iter: 200; batch classifier loss: 0.350643; batch adversarial loss: 0.371129\n",
      "epoch 19; iter: 0; batch classifier loss: 0.323563; batch adversarial loss: 0.495272\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350723; batch adversarial loss: 0.480304\n",
      "epoch 20; iter: 0; batch classifier loss: 0.391884; batch adversarial loss: 0.453386\n",
      "epoch 20; iter: 200; batch classifier loss: 0.363011; batch adversarial loss: 0.449381\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311299; batch adversarial loss: 0.413050\n",
      "epoch 21; iter: 200; batch classifier loss: 0.303067; batch adversarial loss: 0.458688\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294730; batch adversarial loss: 0.438152\n",
      "epoch 22; iter: 200; batch classifier loss: 0.341432; batch adversarial loss: 0.518385\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418254; batch adversarial loss: 0.364047\n",
      "epoch 23; iter: 200; batch classifier loss: 0.313271; batch adversarial loss: 0.378498\n",
      "epoch 24; iter: 0; batch classifier loss: 0.394623; batch adversarial loss: 0.437191\n",
      "epoch 24; iter: 200; batch classifier loss: 0.298463; batch adversarial loss: 0.388258\n",
      "epoch 25; iter: 0; batch classifier loss: 0.335107; batch adversarial loss: 0.392060\n",
      "epoch 25; iter: 200; batch classifier loss: 0.374681; batch adversarial loss: 0.457533\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329497; batch adversarial loss: 0.438685\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343013; batch adversarial loss: 0.384398\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383258; batch adversarial loss: 0.406899\n",
      "epoch 27; iter: 200; batch classifier loss: 0.378442; batch adversarial loss: 0.422636\n",
      "epoch 28; iter: 0; batch classifier loss: 0.353718; batch adversarial loss: 0.370332\n",
      "epoch 28; iter: 200; batch classifier loss: 0.269966; batch adversarial loss: 0.478487\n",
      "epoch 29; iter: 0; batch classifier loss: 0.329895; batch adversarial loss: 0.460554\n",
      "epoch 29; iter: 200; batch classifier loss: 0.276710; batch adversarial loss: 0.303565\n",
      "epoch 30; iter: 0; batch classifier loss: 0.340554; batch adversarial loss: 0.477017\n",
      "epoch 30; iter: 200; batch classifier loss: 0.341242; batch adversarial loss: 0.391909\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387961; batch adversarial loss: 0.389965\n",
      "epoch 31; iter: 200; batch classifier loss: 0.273289; batch adversarial loss: 0.413869\n",
      "epoch 32; iter: 0; batch classifier loss: 0.303400; batch adversarial loss: 0.387230\n",
      "epoch 32; iter: 200; batch classifier loss: 0.355901; batch adversarial loss: 0.444651\n",
      "epoch 33; iter: 0; batch classifier loss: 0.395662; batch adversarial loss: 0.377619\n",
      "epoch 33; iter: 200; batch classifier loss: 0.361817; batch adversarial loss: 0.417110\n",
      "epoch 34; iter: 0; batch classifier loss: 0.319667; batch adversarial loss: 0.424476\n",
      "epoch 34; iter: 200; batch classifier loss: 0.279854; batch adversarial loss: 0.393155\n",
      "epoch 35; iter: 0; batch classifier loss: 0.473313; batch adversarial loss: 0.332566\n",
      "epoch 35; iter: 200; batch classifier loss: 0.349261; batch adversarial loss: 0.365066\n",
      "epoch 36; iter: 0; batch classifier loss: 0.318490; batch adversarial loss: 0.400936\n",
      "epoch 36; iter: 200; batch classifier loss: 0.332870; batch adversarial loss: 0.516555\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343925; batch adversarial loss: 0.406405\n",
      "epoch 37; iter: 200; batch classifier loss: 0.332992; batch adversarial loss: 0.363665\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381424; batch adversarial loss: 0.343049\n",
      "epoch 38; iter: 200; batch classifier loss: 0.335315; batch adversarial loss: 0.486548\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241016; batch adversarial loss: 0.434767\n",
      "epoch 39; iter: 200; batch classifier loss: 0.259949; batch adversarial loss: 0.441604\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389518; batch adversarial loss: 0.375997\n",
      "epoch 40; iter: 200; batch classifier loss: 0.329381; batch adversarial loss: 0.304552\n",
      "epoch 41; iter: 0; batch classifier loss: 0.242518; batch adversarial loss: 0.422341\n",
      "epoch 41; iter: 200; batch classifier loss: 0.393308; batch adversarial loss: 0.393464\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283157; batch adversarial loss: 0.433612\n",
      "epoch 42; iter: 200; batch classifier loss: 0.371663; batch adversarial loss: 0.412143\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362890; batch adversarial loss: 0.439699\n",
      "epoch 43; iter: 200; batch classifier loss: 0.292995; batch adversarial loss: 0.428953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.292433; batch adversarial loss: 0.367566\n",
      "epoch 44; iter: 200; batch classifier loss: 0.459952; batch adversarial loss: 0.320437\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371123; batch adversarial loss: 0.464731\n",
      "epoch 45; iter: 200; batch classifier loss: 0.319173; batch adversarial loss: 0.356466\n",
      "epoch 46; iter: 0; batch classifier loss: 0.340684; batch adversarial loss: 0.341036\n",
      "epoch 46; iter: 200; batch classifier loss: 0.407542; batch adversarial loss: 0.359273\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435675; batch adversarial loss: 0.529332\n",
      "epoch 47; iter: 200; batch classifier loss: 0.329297; batch adversarial loss: 0.429675\n",
      "epoch 48; iter: 0; batch classifier loss: 0.490115; batch adversarial loss: 0.379681\n",
      "epoch 48; iter: 200; batch classifier loss: 0.304555; batch adversarial loss: 0.450028\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433702; batch adversarial loss: 0.459256\n",
      "epoch 49; iter: 200; batch classifier loss: 0.375725; batch adversarial loss: 0.373319\n",
      "epoch 0; iter: 0; batch classifier loss: 7.807097; batch adversarial loss: 0.928606\n",
      "epoch 0; iter: 200; batch classifier loss: 10.680721; batch adversarial loss: 0.763047\n",
      "epoch 1; iter: 0; batch classifier loss: 11.654291; batch adversarial loss: 0.655594\n",
      "epoch 1; iter: 200; batch classifier loss: 4.149653; batch adversarial loss: 0.550318\n",
      "epoch 2; iter: 0; batch classifier loss: 8.257978; batch adversarial loss: 0.516554\n",
      "epoch 2; iter: 200; batch classifier loss: 1.249543; batch adversarial loss: 0.491556\n",
      "epoch 3; iter: 0; batch classifier loss: 1.865010; batch adversarial loss: 0.403622\n",
      "epoch 3; iter: 200; batch classifier loss: 8.113022; batch adversarial loss: 0.464670\n",
      "epoch 4; iter: 0; batch classifier loss: 1.384707; batch adversarial loss: 0.499318\n",
      "epoch 4; iter: 200; batch classifier loss: 1.377570; batch adversarial loss: 0.411410\n",
      "epoch 5; iter: 0; batch classifier loss: 0.659215; batch adversarial loss: 0.428457\n",
      "epoch 5; iter: 200; batch classifier loss: 0.879470; batch adversarial loss: 0.398542\n",
      "epoch 6; iter: 0; batch classifier loss: 1.051826; batch adversarial loss: 0.374419\n",
      "epoch 6; iter: 200; batch classifier loss: 0.760200; batch adversarial loss: 0.490201\n",
      "epoch 7; iter: 0; batch classifier loss: 0.904250; batch adversarial loss: 0.375713\n",
      "epoch 7; iter: 200; batch classifier loss: 0.496272; batch adversarial loss: 0.418524\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438374; batch adversarial loss: 0.411564\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387854; batch adversarial loss: 0.401950\n",
      "epoch 9; iter: 0; batch classifier loss: 0.441342; batch adversarial loss: 0.411747\n",
      "epoch 9; iter: 200; batch classifier loss: 0.375608; batch adversarial loss: 0.337362\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405918; batch adversarial loss: 0.324738\n",
      "epoch 10; iter: 200; batch classifier loss: 0.611843; batch adversarial loss: 0.508760\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392356; batch adversarial loss: 0.386073\n",
      "epoch 11; iter: 200; batch classifier loss: 0.494031; batch adversarial loss: 0.445162\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452504; batch adversarial loss: 0.405727\n",
      "epoch 12; iter: 200; batch classifier loss: 0.376721; batch adversarial loss: 0.402976\n",
      "epoch 13; iter: 0; batch classifier loss: 0.308932; batch adversarial loss: 0.330722\n",
      "epoch 13; iter: 200; batch classifier loss: 0.363367; batch adversarial loss: 0.273293\n",
      "epoch 14; iter: 0; batch classifier loss: 0.356566; batch adversarial loss: 0.384953\n",
      "epoch 14; iter: 200; batch classifier loss: 0.462516; batch adversarial loss: 0.383541\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343192; batch adversarial loss: 0.385925\n",
      "epoch 15; iter: 200; batch classifier loss: 0.275968; batch adversarial loss: 0.389316\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324411; batch adversarial loss: 0.373600\n",
      "epoch 16; iter: 200; batch classifier loss: 0.395740; batch adversarial loss: 0.380617\n",
      "epoch 17; iter: 0; batch classifier loss: 0.445901; batch adversarial loss: 0.289860\n",
      "epoch 17; iter: 200; batch classifier loss: 0.312580; batch adversarial loss: 0.365754\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396588; batch adversarial loss: 0.434722\n",
      "epoch 18; iter: 200; batch classifier loss: 0.266963; batch adversarial loss: 0.539015\n",
      "epoch 19; iter: 0; batch classifier loss: 0.280164; batch adversarial loss: 0.431716\n",
      "epoch 19; iter: 200; batch classifier loss: 0.310069; batch adversarial loss: 0.507366\n",
      "epoch 20; iter: 0; batch classifier loss: 0.319026; batch adversarial loss: 0.357361\n",
      "epoch 20; iter: 200; batch classifier loss: 0.358510; batch adversarial loss: 0.570371\n",
      "epoch 21; iter: 0; batch classifier loss: 0.320466; batch adversarial loss: 0.390678\n",
      "epoch 21; iter: 200; batch classifier loss: 0.249401; batch adversarial loss: 0.454231\n",
      "epoch 22; iter: 0; batch classifier loss: 0.356650; batch adversarial loss: 0.388682\n",
      "epoch 22; iter: 200; batch classifier loss: 0.363874; batch adversarial loss: 0.411006\n",
      "epoch 23; iter: 0; batch classifier loss: 0.384226; batch adversarial loss: 0.475071\n",
      "epoch 23; iter: 200; batch classifier loss: 0.317649; batch adversarial loss: 0.499283\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364110; batch adversarial loss: 0.408837\n",
      "epoch 24; iter: 200; batch classifier loss: 0.326168; batch adversarial loss: 0.427977\n",
      "epoch 25; iter: 0; batch classifier loss: 0.352222; batch adversarial loss: 0.419191\n",
      "epoch 25; iter: 200; batch classifier loss: 0.355119; batch adversarial loss: 0.342440\n",
      "epoch 26; iter: 0; batch classifier loss: 0.325818; batch adversarial loss: 0.468151\n",
      "epoch 26; iter: 200; batch classifier loss: 0.380632; batch adversarial loss: 0.464436\n",
      "epoch 27; iter: 0; batch classifier loss: 0.364147; batch adversarial loss: 0.513373\n",
      "epoch 27; iter: 200; batch classifier loss: 0.286429; batch adversarial loss: 0.530323\n",
      "epoch 28; iter: 0; batch classifier loss: 0.444084; batch adversarial loss: 0.396462\n",
      "epoch 28; iter: 200; batch classifier loss: 0.336008; batch adversarial loss: 0.419610\n",
      "epoch 29; iter: 0; batch classifier loss: 0.330578; batch adversarial loss: 0.428278\n",
      "epoch 29; iter: 200; batch classifier loss: 0.381151; batch adversarial loss: 0.407127\n",
      "epoch 30; iter: 0; batch classifier loss: 0.293930; batch adversarial loss: 0.470709\n",
      "epoch 30; iter: 200; batch classifier loss: 0.327193; batch adversarial loss: 0.329908\n",
      "epoch 31; iter: 0; batch classifier loss: 0.363892; batch adversarial loss: 0.447784\n",
      "epoch 31; iter: 200; batch classifier loss: 0.373647; batch adversarial loss: 0.451032\n",
      "epoch 32; iter: 0; batch classifier loss: 0.283794; batch adversarial loss: 0.504181\n",
      "epoch 32; iter: 200; batch classifier loss: 0.396501; batch adversarial loss: 0.415081\n",
      "epoch 33; iter: 0; batch classifier loss: 0.342723; batch adversarial loss: 0.405077\n",
      "epoch 33; iter: 200; batch classifier loss: 0.365966; batch adversarial loss: 0.342530\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419951; batch adversarial loss: 0.435569\n",
      "epoch 34; iter: 200; batch classifier loss: 0.429184; batch adversarial loss: 0.420641\n",
      "epoch 35; iter: 0; batch classifier loss: 0.342065; batch adversarial loss: 0.268447\n",
      "epoch 35; iter: 200; batch classifier loss: 0.341967; batch adversarial loss: 0.430655\n",
      "epoch 36; iter: 0; batch classifier loss: 0.358130; batch adversarial loss: 0.417788\n",
      "epoch 36; iter: 200; batch classifier loss: 0.379614; batch adversarial loss: 0.319902\n",
      "epoch 37; iter: 0; batch classifier loss: 0.414640; batch adversarial loss: 0.418042\n",
      "epoch 37; iter: 200; batch classifier loss: 0.516746; batch adversarial loss: 0.314395\n",
      "epoch 38; iter: 0; batch classifier loss: 0.259461; batch adversarial loss: 0.370352\n",
      "epoch 38; iter: 200; batch classifier loss: 0.435526; batch adversarial loss: 0.389705\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399516; batch adversarial loss: 0.404026\n",
      "epoch 39; iter: 200; batch classifier loss: 0.388503; batch adversarial loss: 0.355859\n",
      "epoch 40; iter: 0; batch classifier loss: 0.456751; batch adversarial loss: 0.368815\n",
      "epoch 40; iter: 200; batch classifier loss: 0.353733; batch adversarial loss: 0.404715\n",
      "epoch 41; iter: 0; batch classifier loss: 0.346111; batch adversarial loss: 0.339743\n",
      "epoch 41; iter: 200; batch classifier loss: 0.428724; batch adversarial loss: 0.411757\n",
      "epoch 42; iter: 0; batch classifier loss: 0.355051; batch adversarial loss: 0.391352\n",
      "epoch 42; iter: 200; batch classifier loss: 0.293011; batch adversarial loss: 0.368957\n",
      "epoch 43; iter: 0; batch classifier loss: 0.334668; batch adversarial loss: 0.423509\n",
      "epoch 43; iter: 200; batch classifier loss: 0.244681; batch adversarial loss: 0.432598\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401950; batch adversarial loss: 0.321730\n",
      "epoch 44; iter: 200; batch classifier loss: 0.259718; batch adversarial loss: 0.439799\n",
      "epoch 45; iter: 0; batch classifier loss: 0.386390; batch adversarial loss: 0.388220\n",
      "epoch 45; iter: 200; batch classifier loss: 0.420098; batch adversarial loss: 0.627110\n",
      "epoch 46; iter: 0; batch classifier loss: 0.509526; batch adversarial loss: 0.451450\n",
      "epoch 46; iter: 200; batch classifier loss: 0.338312; batch adversarial loss: 0.378588\n",
      "epoch 47; iter: 0; batch classifier loss: 0.314018; batch adversarial loss: 0.456761\n",
      "epoch 47; iter: 200; batch classifier loss: 0.376395; batch adversarial loss: 0.350926\n",
      "epoch 48; iter: 0; batch classifier loss: 0.273821; batch adversarial loss: 0.400582\n",
      "epoch 48; iter: 200; batch classifier loss: 0.288711; batch adversarial loss: 0.455754\n",
      "epoch 49; iter: 0; batch classifier loss: 0.331980; batch adversarial loss: 0.374562\n",
      "epoch 49; iter: 200; batch classifier loss: 0.276310; batch adversarial loss: 0.436293\n",
      "epoch 0; iter: 0; batch classifier loss: 393.420410; batch adversarial loss: 0.584136\n",
      "epoch 0; iter: 200; batch classifier loss: 7.312107; batch adversarial loss: 0.548084\n",
      "epoch 1; iter: 0; batch classifier loss: 16.876476; batch adversarial loss: 0.512501\n",
      "epoch 1; iter: 200; batch classifier loss: 9.467086; batch adversarial loss: 0.493343\n",
      "epoch 2; iter: 0; batch classifier loss: 5.362847; batch adversarial loss: 0.538444\n",
      "epoch 2; iter: 200; batch classifier loss: 1.978106; batch adversarial loss: 0.450317\n",
      "epoch 3; iter: 0; batch classifier loss: 12.448824; batch adversarial loss: 0.532900\n",
      "epoch 3; iter: 200; batch classifier loss: 6.576835; batch adversarial loss: 0.431905\n",
      "epoch 4; iter: 0; batch classifier loss: 1.779333; batch adversarial loss: 0.439236\n",
      "epoch 4; iter: 200; batch classifier loss: 1.259357; batch adversarial loss: 0.457898\n",
      "epoch 5; iter: 0; batch classifier loss: 1.942724; batch adversarial loss: 0.428179\n",
      "epoch 5; iter: 200; batch classifier loss: 1.863618; batch adversarial loss: 0.464500\n",
      "epoch 6; iter: 0; batch classifier loss: 0.778278; batch adversarial loss: 0.428525\n",
      "epoch 6; iter: 200; batch classifier loss: 0.989475; batch adversarial loss: 0.432604\n",
      "epoch 7; iter: 0; batch classifier loss: 0.719764; batch adversarial loss: 0.316161\n",
      "epoch 7; iter: 200; batch classifier loss: 0.508957; batch adversarial loss: 0.470415\n",
      "epoch 8; iter: 0; batch classifier loss: 0.515248; batch adversarial loss: 0.508452\n",
      "epoch 8; iter: 200; batch classifier loss: 0.494809; batch adversarial loss: 0.458576\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518479; batch adversarial loss: 0.370183\n",
      "epoch 9; iter: 200; batch classifier loss: 0.555793; batch adversarial loss: 0.417324\n",
      "epoch 10; iter: 0; batch classifier loss: 0.856700; batch adversarial loss: 0.433104\n",
      "epoch 10; iter: 200; batch classifier loss: 0.404984; batch adversarial loss: 0.474799\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578342; batch adversarial loss: 0.506912\n",
      "epoch 11; iter: 200; batch classifier loss: 0.581410; batch adversarial loss: 0.417738\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402694; batch adversarial loss: 0.313990\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420732; batch adversarial loss: 0.444865\n",
      "epoch 13; iter: 0; batch classifier loss: 0.431875; batch adversarial loss: 0.359030\n",
      "epoch 13; iter: 200; batch classifier loss: 0.484205; batch adversarial loss: 0.401028\n",
      "epoch 14; iter: 0; batch classifier loss: 0.344953; batch adversarial loss: 0.481089\n",
      "epoch 14; iter: 200; batch classifier loss: 0.315580; batch adversarial loss: 0.426401\n",
      "epoch 15; iter: 0; batch classifier loss: 0.420422; batch adversarial loss: 0.396617\n",
      "epoch 15; iter: 200; batch classifier loss: 0.397583; batch adversarial loss: 0.517182\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493931; batch adversarial loss: 0.331824\n",
      "epoch 16; iter: 200; batch classifier loss: 0.310845; batch adversarial loss: 0.394850\n",
      "epoch 17; iter: 0; batch classifier loss: 0.362116; batch adversarial loss: 0.416812\n",
      "epoch 17; iter: 200; batch classifier loss: 0.376563; batch adversarial loss: 0.466491\n",
      "epoch 18; iter: 0; batch classifier loss: 0.313752; batch adversarial loss: 0.557204\n",
      "epoch 18; iter: 200; batch classifier loss: 0.396264; batch adversarial loss: 0.352916\n",
      "epoch 19; iter: 0; batch classifier loss: 0.450977; batch adversarial loss: 0.384151\n",
      "epoch 19; iter: 200; batch classifier loss: 0.339270; batch adversarial loss: 0.355182\n",
      "epoch 20; iter: 0; batch classifier loss: 0.452436; batch adversarial loss: 0.380893\n",
      "epoch 20; iter: 200; batch classifier loss: 0.367161; batch adversarial loss: 0.483608\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319510; batch adversarial loss: 0.427500\n",
      "epoch 21; iter: 200; batch classifier loss: 0.377141; batch adversarial loss: 0.497753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.363566; batch adversarial loss: 0.358681\n",
      "epoch 22; iter: 200; batch classifier loss: 0.371211; batch adversarial loss: 0.416357\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378327; batch adversarial loss: 0.430816\n",
      "epoch 23; iter: 200; batch classifier loss: 0.226729; batch adversarial loss: 0.460538\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271588; batch adversarial loss: 0.358673\n",
      "epoch 24; iter: 200; batch classifier loss: 0.299185; batch adversarial loss: 0.447824\n",
      "epoch 25; iter: 0; batch classifier loss: 0.304337; batch adversarial loss: 0.428457\n",
      "epoch 25; iter: 200; batch classifier loss: 0.225848; batch adversarial loss: 0.471802\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440066; batch adversarial loss: 0.427196\n",
      "epoch 26; iter: 200; batch classifier loss: 0.338025; batch adversarial loss: 0.380318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321415; batch adversarial loss: 0.366005\n",
      "epoch 27; iter: 200; batch classifier loss: 0.336921; batch adversarial loss: 0.503127\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386823; batch adversarial loss: 0.491833\n",
      "epoch 28; iter: 200; batch classifier loss: 0.329117; batch adversarial loss: 0.354129\n",
      "epoch 29; iter: 0; batch classifier loss: 0.392345; batch adversarial loss: 0.388356\n",
      "epoch 29; iter: 200; batch classifier loss: 0.319877; batch adversarial loss: 0.320872\n",
      "epoch 30; iter: 0; batch classifier loss: 0.353930; batch adversarial loss: 0.423793\n",
      "epoch 30; iter: 200; batch classifier loss: 0.400156; batch adversarial loss: 0.471242\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268523; batch adversarial loss: 0.353520\n",
      "epoch 31; iter: 200; batch classifier loss: 0.508179; batch adversarial loss: 0.366226\n",
      "epoch 32; iter: 0; batch classifier loss: 0.367106; batch adversarial loss: 0.360795\n",
      "epoch 32; iter: 200; batch classifier loss: 0.490291; batch adversarial loss: 0.332390\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442834; batch adversarial loss: 0.361627\n",
      "epoch 33; iter: 200; batch classifier loss: 0.363958; batch adversarial loss: 0.411546\n",
      "epoch 34; iter: 0; batch classifier loss: 0.512905; batch adversarial loss: 0.414786\n",
      "epoch 34; iter: 200; batch classifier loss: 0.380937; batch adversarial loss: 0.401152\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458880; batch adversarial loss: 0.551242\n",
      "epoch 35; iter: 200; batch classifier loss: 0.473317; batch adversarial loss: 0.364345\n",
      "epoch 36; iter: 0; batch classifier loss: 0.438371; batch adversarial loss: 0.399531\n",
      "epoch 36; iter: 200; batch classifier loss: 0.425479; batch adversarial loss: 0.389194\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480040; batch adversarial loss: 0.395886\n",
      "epoch 37; iter: 200; batch classifier loss: 0.517315; batch adversarial loss: 0.404193\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404540; batch adversarial loss: 0.333028\n",
      "epoch 38; iter: 200; batch classifier loss: 0.476885; batch adversarial loss: 0.335225\n",
      "epoch 39; iter: 0; batch classifier loss: 0.320673; batch adversarial loss: 0.548133\n",
      "epoch 39; iter: 200; batch classifier loss: 0.456006; batch adversarial loss: 0.360121\n",
      "epoch 40; iter: 0; batch classifier loss: 0.389036; batch adversarial loss: 0.492413\n",
      "epoch 40; iter: 200; batch classifier loss: 0.427903; batch adversarial loss: 0.451754\n",
      "epoch 41; iter: 0; batch classifier loss: 0.457283; batch adversarial loss: 0.417565\n",
      "epoch 41; iter: 200; batch classifier loss: 0.452974; batch adversarial loss: 0.357034\n",
      "epoch 42; iter: 0; batch classifier loss: 0.414895; batch adversarial loss: 0.443429\n",
      "epoch 42; iter: 200; batch classifier loss: 0.463242; batch adversarial loss: 0.375859\n",
      "epoch 43; iter: 0; batch classifier loss: 0.531132; batch adversarial loss: 0.320639\n",
      "epoch 43; iter: 200; batch classifier loss: 0.525667; batch adversarial loss: 0.432003\n",
      "epoch 44; iter: 0; batch classifier loss: 0.575855; batch adversarial loss: 0.403961\n",
      "epoch 44; iter: 200; batch classifier loss: 0.427097; batch adversarial loss: 0.443614\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384359; batch adversarial loss: 0.381986\n",
      "epoch 45; iter: 200; batch classifier loss: 0.605317; batch adversarial loss: 0.446673\n",
      "epoch 46; iter: 0; batch classifier loss: 0.497985; batch adversarial loss: 0.467113\n",
      "epoch 46; iter: 200; batch classifier loss: 0.473087; batch adversarial loss: 0.426058\n",
      "epoch 47; iter: 0; batch classifier loss: 0.594644; batch adversarial loss: 0.321196\n",
      "epoch 47; iter: 200; batch classifier loss: 0.396975; batch adversarial loss: 0.398318\n",
      "epoch 48; iter: 0; batch classifier loss: 0.525008; batch adversarial loss: 0.418014\n",
      "epoch 48; iter: 200; batch classifier loss: 0.437633; batch adversarial loss: 0.378162\n",
      "epoch 49; iter: 0; batch classifier loss: 0.456383; batch adversarial loss: 0.347227\n",
      "epoch 49; iter: 200; batch classifier loss: 0.619515; batch adversarial loss: 0.424766\n",
      "epoch 0; iter: 0; batch classifier loss: 4.090528; batch adversarial loss: 0.618496\n",
      "epoch 0; iter: 200; batch classifier loss: 6.405572; batch adversarial loss: 0.597530\n",
      "epoch 1; iter: 0; batch classifier loss: 3.341415; batch adversarial loss: 0.556338\n",
      "epoch 1; iter: 200; batch classifier loss: 11.010900; batch adversarial loss: 0.528439\n",
      "epoch 2; iter: 0; batch classifier loss: 2.034476; batch adversarial loss: 0.519982\n",
      "epoch 2; iter: 200; batch classifier loss: 4.767939; batch adversarial loss: 0.494945\n",
      "epoch 3; iter: 0; batch classifier loss: 3.794074; batch adversarial loss: 0.437330\n",
      "epoch 3; iter: 200; batch classifier loss: 1.079442; batch adversarial loss: 0.447486\n",
      "epoch 4; iter: 0; batch classifier loss: 0.687884; batch adversarial loss: 0.377974\n",
      "epoch 4; iter: 200; batch classifier loss: 0.774294; batch adversarial loss: 0.457707\n",
      "epoch 5; iter: 0; batch classifier loss: 1.033396; batch adversarial loss: 0.387602\n",
      "epoch 5; iter: 200; batch classifier loss: 0.980705; batch adversarial loss: 0.447685\n",
      "epoch 6; iter: 0; batch classifier loss: 0.419538; batch adversarial loss: 0.484769\n",
      "epoch 6; iter: 200; batch classifier loss: 0.467331; batch adversarial loss: 0.394088\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493242; batch adversarial loss: 0.445311\n",
      "epoch 7; iter: 200; batch classifier loss: 0.361665; batch adversarial loss: 0.372813\n",
      "epoch 8; iter: 0; batch classifier loss: 0.354351; batch adversarial loss: 0.411412\n",
      "epoch 8; iter: 200; batch classifier loss: 0.385886; batch adversarial loss: 0.394971\n",
      "epoch 9; iter: 0; batch classifier loss: 0.382776; batch adversarial loss: 0.339795\n",
      "epoch 9; iter: 200; batch classifier loss: 0.360543; batch adversarial loss: 0.434442\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337976; batch adversarial loss: 0.431017\n",
      "epoch 10; iter: 200; batch classifier loss: 0.349273; batch adversarial loss: 0.476137\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372759; batch adversarial loss: 0.461021\n",
      "epoch 11; iter: 200; batch classifier loss: 0.311539; batch adversarial loss: 0.535257\n",
      "epoch 12; iter: 0; batch classifier loss: 0.335948; batch adversarial loss: 0.384174\n",
      "epoch 12; iter: 200; batch classifier loss: 0.333840; batch adversarial loss: 0.333513\n",
      "epoch 13; iter: 0; batch classifier loss: 0.260490; batch adversarial loss: 0.437770\n",
      "epoch 13; iter: 200; batch classifier loss: 0.408136; batch adversarial loss: 0.502412\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233768; batch adversarial loss: 0.528123\n",
      "epoch 14; iter: 200; batch classifier loss: 0.344854; batch adversarial loss: 0.397574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371335; batch adversarial loss: 0.457728\n",
      "epoch 15; iter: 200; batch classifier loss: 0.389890; batch adversarial loss: 0.361932\n",
      "epoch 16; iter: 0; batch classifier loss: 0.386266; batch adversarial loss: 0.389718\n",
      "epoch 16; iter: 200; batch classifier loss: 0.300928; batch adversarial loss: 0.460424\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383794; batch adversarial loss: 0.414820\n",
      "epoch 17; iter: 200; batch classifier loss: 0.286765; batch adversarial loss: 0.381748\n",
      "epoch 18; iter: 0; batch classifier loss: 0.335360; batch adversarial loss: 0.418640\n",
      "epoch 18; iter: 200; batch classifier loss: 0.342077; batch adversarial loss: 0.433798\n",
      "epoch 19; iter: 0; batch classifier loss: 0.330265; batch adversarial loss: 0.425447\n",
      "epoch 19; iter: 200; batch classifier loss: 0.345214; batch adversarial loss: 0.427422\n",
      "epoch 20; iter: 0; batch classifier loss: 0.296305; batch adversarial loss: 0.381677\n",
      "epoch 20; iter: 200; batch classifier loss: 0.410805; batch adversarial loss: 0.520715\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282052; batch adversarial loss: 0.433076\n",
      "epoch 21; iter: 200; batch classifier loss: 0.295879; batch adversarial loss: 0.373361\n",
      "epoch 22; iter: 0; batch classifier loss: 0.338818; batch adversarial loss: 0.499682\n",
      "epoch 22; iter: 200; batch classifier loss: 0.372401; batch adversarial loss: 0.427917\n",
      "epoch 23; iter: 0; batch classifier loss: 0.347548; batch adversarial loss: 0.452971\n",
      "epoch 23; iter: 200; batch classifier loss: 0.311707; batch adversarial loss: 0.383804\n",
      "epoch 24; iter: 0; batch classifier loss: 0.381384; batch adversarial loss: 0.468419\n",
      "epoch 24; iter: 200; batch classifier loss: 0.348812; batch adversarial loss: 0.501319\n",
      "epoch 25; iter: 0; batch classifier loss: 0.312884; batch adversarial loss: 0.456260\n",
      "epoch 25; iter: 200; batch classifier loss: 0.339635; batch adversarial loss: 0.378537\n",
      "epoch 26; iter: 0; batch classifier loss: 0.419675; batch adversarial loss: 0.412974\n",
      "epoch 26; iter: 200; batch classifier loss: 0.407659; batch adversarial loss: 0.462540\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391925; batch adversarial loss: 0.472551\n",
      "epoch 27; iter: 200; batch classifier loss: 0.321385; batch adversarial loss: 0.375849\n",
      "epoch 28; iter: 0; batch classifier loss: 0.331307; batch adversarial loss: 0.347851\n",
      "epoch 28; iter: 200; batch classifier loss: 0.240007; batch adversarial loss: 0.487258\n",
      "epoch 29; iter: 0; batch classifier loss: 0.446122; batch adversarial loss: 0.420693\n",
      "epoch 29; iter: 200; batch classifier loss: 0.384136; batch adversarial loss: 0.402036\n",
      "epoch 30; iter: 0; batch classifier loss: 0.503740; batch adversarial loss: 0.515934\n",
      "epoch 30; iter: 200; batch classifier loss: 0.445358; batch adversarial loss: 0.334113\n",
      "epoch 31; iter: 0; batch classifier loss: 0.290570; batch adversarial loss: 0.407345\n",
      "epoch 31; iter: 200; batch classifier loss: 0.307793; batch adversarial loss: 0.375527\n",
      "epoch 32; iter: 0; batch classifier loss: 0.332104; batch adversarial loss: 0.401431\n",
      "epoch 32; iter: 200; batch classifier loss: 0.379696; batch adversarial loss: 0.398393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.295341; batch adversarial loss: 0.372630\n",
      "epoch 33; iter: 200; batch classifier loss: 0.447141; batch adversarial loss: 0.305275\n",
      "epoch 34; iter: 0; batch classifier loss: 0.274629; batch adversarial loss: 0.399343\n",
      "epoch 34; iter: 200; batch classifier loss: 0.243395; batch adversarial loss: 0.429097\n",
      "epoch 35; iter: 0; batch classifier loss: 0.278152; batch adversarial loss: 0.566022\n",
      "epoch 35; iter: 200; batch classifier loss: 0.414911; batch adversarial loss: 0.422142\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379569; batch adversarial loss: 0.388316\n",
      "epoch 36; iter: 200; batch classifier loss: 0.538034; batch adversarial loss: 0.325796\n",
      "epoch 37; iter: 0; batch classifier loss: 0.334294; batch adversarial loss: 0.413403\n",
      "epoch 37; iter: 200; batch classifier loss: 0.204876; batch adversarial loss: 0.467205\n",
      "epoch 38; iter: 0; batch classifier loss: 0.399015; batch adversarial loss: 0.432141\n",
      "epoch 38; iter: 200; batch classifier loss: 0.362804; batch adversarial loss: 0.362802\n",
      "epoch 39; iter: 0; batch classifier loss: 0.471443; batch adversarial loss: 0.384302\n",
      "epoch 39; iter: 200; batch classifier loss: 0.406924; batch adversarial loss: 0.342220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484345; batch adversarial loss: 0.429948\n",
      "epoch 40; iter: 200; batch classifier loss: 0.358992; batch adversarial loss: 0.393260\n",
      "epoch 41; iter: 0; batch classifier loss: 0.219541; batch adversarial loss: 0.394283\n",
      "epoch 41; iter: 200; batch classifier loss: 0.403456; batch adversarial loss: 0.355070\n",
      "epoch 42; iter: 0; batch classifier loss: 0.382805; batch adversarial loss: 0.391926\n",
      "epoch 42; iter: 200; batch classifier loss: 0.357670; batch adversarial loss: 0.429434\n",
      "epoch 43; iter: 0; batch classifier loss: 0.263606; batch adversarial loss: 0.452047\n",
      "epoch 43; iter: 200; batch classifier loss: 0.387296; batch adversarial loss: 0.350284\n",
      "epoch 44; iter: 0; batch classifier loss: 0.731631; batch adversarial loss: 0.489345\n",
      "epoch 44; iter: 200; batch classifier loss: 0.306406; batch adversarial loss: 0.399401\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364369; batch adversarial loss: 0.390054\n",
      "epoch 45; iter: 200; batch classifier loss: 0.508336; batch adversarial loss: 0.294586\n",
      "epoch 46; iter: 0; batch classifier loss: 0.302127; batch adversarial loss: 0.340151\n",
      "epoch 46; iter: 200; batch classifier loss: 0.461690; batch adversarial loss: 0.388172\n",
      "epoch 47; iter: 0; batch classifier loss: 0.285132; batch adversarial loss: 0.458683\n",
      "epoch 47; iter: 200; batch classifier loss: 0.451557; batch adversarial loss: 0.349624\n",
      "epoch 48; iter: 0; batch classifier loss: 0.474810; batch adversarial loss: 0.533569\n",
      "epoch 48; iter: 200; batch classifier loss: 0.408665; batch adversarial loss: 0.418612\n",
      "epoch 49; iter: 0; batch classifier loss: 0.308830; batch adversarial loss: 0.435711\n",
      "epoch 49; iter: 200; batch classifier loss: 0.417286; batch adversarial loss: 0.418144\n",
      "epoch 0; iter: 0; batch classifier loss: 8.181394; batch adversarial loss: 0.730238\n",
      "epoch 0; iter: 200; batch classifier loss: 31.698639; batch adversarial loss: 0.639609\n",
      "epoch 1; iter: 0; batch classifier loss: 6.229455; batch adversarial loss: 0.605377\n",
      "epoch 1; iter: 200; batch classifier loss: 3.442910; batch adversarial loss: 0.557553\n",
      "epoch 2; iter: 0; batch classifier loss: 3.594591; batch adversarial loss: 0.522925\n",
      "epoch 2; iter: 200; batch classifier loss: 2.146076; batch adversarial loss: 0.499931\n",
      "epoch 3; iter: 0; batch classifier loss: 5.099024; batch adversarial loss: 0.450807\n",
      "epoch 3; iter: 200; batch classifier loss: 1.278850; batch adversarial loss: 0.437589\n",
      "epoch 4; iter: 0; batch classifier loss: 1.284353; batch adversarial loss: 0.431239\n",
      "epoch 4; iter: 200; batch classifier loss: 1.035185; batch adversarial loss: 0.500740\n",
      "epoch 5; iter: 0; batch classifier loss: 1.108267; batch adversarial loss: 0.438894\n",
      "epoch 5; iter: 200; batch classifier loss: 0.894268; batch adversarial loss: 0.402271\n",
      "epoch 6; iter: 0; batch classifier loss: 0.637297; batch adversarial loss: 0.473674\n",
      "epoch 6; iter: 200; batch classifier loss: 0.611366; batch adversarial loss: 0.438249\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563965; batch adversarial loss: 0.400244\n",
      "epoch 7; iter: 200; batch classifier loss: 0.684539; batch adversarial loss: 0.425857\n",
      "epoch 8; iter: 0; batch classifier loss: 0.716528; batch adversarial loss: 0.430281\n",
      "epoch 8; iter: 200; batch classifier loss: 0.483219; batch adversarial loss: 0.426434\n",
      "epoch 9; iter: 0; batch classifier loss: 0.374071; batch adversarial loss: 0.416989\n",
      "epoch 9; iter: 200; batch classifier loss: 0.316154; batch adversarial loss: 0.510937\n",
      "epoch 10; iter: 0; batch classifier loss: 0.328998; batch adversarial loss: 0.371178\n",
      "epoch 10; iter: 200; batch classifier loss: 0.424905; batch adversarial loss: 0.449639\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492381; batch adversarial loss: 0.428868\n",
      "epoch 11; iter: 200; batch classifier loss: 0.351454; batch adversarial loss: 0.424491\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367564; batch adversarial loss: 0.378889\n",
      "epoch 12; iter: 200; batch classifier loss: 0.407672; batch adversarial loss: 0.467545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372461; batch adversarial loss: 0.435295\n",
      "epoch 13; iter: 200; batch classifier loss: 0.308080; batch adversarial loss: 0.401267\n",
      "epoch 14; iter: 0; batch classifier loss: 0.439420; batch adversarial loss: 0.440588\n",
      "epoch 14; iter: 200; batch classifier loss: 0.328425; batch adversarial loss: 0.425328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377617; batch adversarial loss: 0.323129\n",
      "epoch 15; iter: 200; batch classifier loss: 0.281905; batch adversarial loss: 0.457812\n",
      "epoch 16; iter: 0; batch classifier loss: 0.260808; batch adversarial loss: 0.359560\n",
      "epoch 16; iter: 200; batch classifier loss: 0.405317; batch adversarial loss: 0.459429\n",
      "epoch 17; iter: 0; batch classifier loss: 0.299145; batch adversarial loss: 0.468238\n",
      "epoch 17; iter: 200; batch classifier loss: 0.357075; batch adversarial loss: 0.351595\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332256; batch adversarial loss: 0.457516\n",
      "epoch 18; iter: 200; batch classifier loss: 0.377850; batch adversarial loss: 0.473541\n",
      "epoch 19; iter: 0; batch classifier loss: 0.305512; batch adversarial loss: 0.381367\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385201; batch adversarial loss: 0.302457\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426295; batch adversarial loss: 0.575651\n",
      "epoch 20; iter: 200; batch classifier loss: 0.344736; batch adversarial loss: 0.385825\n",
      "epoch 21; iter: 0; batch classifier loss: 0.289063; batch adversarial loss: 0.454374\n",
      "epoch 21; iter: 200; batch classifier loss: 0.336750; batch adversarial loss: 0.450641\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378356; batch adversarial loss: 0.360683\n",
      "epoch 22; iter: 200; batch classifier loss: 0.317977; batch adversarial loss: 0.434483\n",
      "epoch 23; iter: 0; batch classifier loss: 0.303697; batch adversarial loss: 0.423660\n",
      "epoch 23; iter: 200; batch classifier loss: 0.284341; batch adversarial loss: 0.476062\n",
      "epoch 24; iter: 0; batch classifier loss: 0.385795; batch adversarial loss: 0.539860\n",
      "epoch 24; iter: 200; batch classifier loss: 0.287322; batch adversarial loss: 0.447937\n",
      "epoch 25; iter: 0; batch classifier loss: 0.340907; batch adversarial loss: 0.452547\n",
      "epoch 25; iter: 200; batch classifier loss: 0.383600; batch adversarial loss: 0.430292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329940; batch adversarial loss: 0.482161\n",
      "epoch 26; iter: 200; batch classifier loss: 0.354880; batch adversarial loss: 0.482670\n",
      "epoch 27; iter: 0; batch classifier loss: 0.335293; batch adversarial loss: 0.369814\n",
      "epoch 27; iter: 200; batch classifier loss: 0.260757; batch adversarial loss: 0.398695\n",
      "epoch 28; iter: 0; batch classifier loss: 0.344576; batch adversarial loss: 0.585384\n",
      "epoch 28; iter: 200; batch classifier loss: 0.302501; batch adversarial loss: 0.447131\n",
      "epoch 29; iter: 0; batch classifier loss: 0.356236; batch adversarial loss: 0.294746\n",
      "epoch 29; iter: 200; batch classifier loss: 0.337439; batch adversarial loss: 0.358517\n",
      "epoch 30; iter: 0; batch classifier loss: 0.289064; batch adversarial loss: 0.479398\n",
      "epoch 30; iter: 200; batch classifier loss: 0.425606; batch adversarial loss: 0.373109\n",
      "epoch 31; iter: 0; batch classifier loss: 0.311496; batch adversarial loss: 0.399428\n",
      "epoch 31; iter: 200; batch classifier loss: 0.309644; batch adversarial loss: 0.510953\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393958; batch adversarial loss: 0.437432\n",
      "epoch 32; iter: 200; batch classifier loss: 0.465116; batch adversarial loss: 0.374426\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401577; batch adversarial loss: 0.466368\n",
      "epoch 33; iter: 200; batch classifier loss: 0.426718; batch adversarial loss: 0.378214\n",
      "epoch 34; iter: 0; batch classifier loss: 0.555652; batch adversarial loss: 0.414605\n",
      "epoch 34; iter: 200; batch classifier loss: 0.404344; batch adversarial loss: 0.389627\n",
      "epoch 35; iter: 0; batch classifier loss: 0.462775; batch adversarial loss: 0.429308\n",
      "epoch 35; iter: 200; batch classifier loss: 0.542738; batch adversarial loss: 0.398956\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403134; batch adversarial loss: 0.449431\n",
      "epoch 36; iter: 200; batch classifier loss: 0.507294; batch adversarial loss: 0.424513\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475522; batch adversarial loss: 0.502174\n",
      "epoch 37; iter: 200; batch classifier loss: 0.439209; batch adversarial loss: 0.601648\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470850; batch adversarial loss: 0.367052\n",
      "epoch 38; iter: 200; batch classifier loss: 0.485358; batch adversarial loss: 0.292680\n",
      "epoch 39; iter: 0; batch classifier loss: 0.538208; batch adversarial loss: 0.339104\n",
      "epoch 39; iter: 200; batch classifier loss: 0.449343; batch adversarial loss: 0.431097\n",
      "epoch 40; iter: 0; batch classifier loss: 0.408779; batch adversarial loss: 0.430704\n",
      "epoch 40; iter: 200; batch classifier loss: 0.382804; batch adversarial loss: 0.422034\n",
      "epoch 41; iter: 0; batch classifier loss: 0.449596; batch adversarial loss: 0.505279\n",
      "epoch 41; iter: 200; batch classifier loss: 0.461752; batch adversarial loss: 0.348438\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417571; batch adversarial loss: 0.350113\n",
      "epoch 42; iter: 200; batch classifier loss: 0.554527; batch adversarial loss: 0.423489\n",
      "epoch 43; iter: 0; batch classifier loss: 0.434323; batch adversarial loss: 0.481576\n",
      "epoch 43; iter: 200; batch classifier loss: 0.416578; batch adversarial loss: 0.444651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.399038; batch adversarial loss: 0.551488\n",
      "epoch 44; iter: 200; batch classifier loss: 0.439323; batch adversarial loss: 0.447539\n",
      "epoch 45; iter: 0; batch classifier loss: 0.313239; batch adversarial loss: 0.440916\n",
      "epoch 45; iter: 200; batch classifier loss: 0.485153; batch adversarial loss: 0.468924\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396858; batch adversarial loss: 0.518733\n",
      "epoch 46; iter: 200; batch classifier loss: 0.384359; batch adversarial loss: 0.388497\n",
      "epoch 47; iter: 0; batch classifier loss: 0.426160; batch adversarial loss: 0.475758\n",
      "epoch 47; iter: 200; batch classifier loss: 0.664591; batch adversarial loss: 0.417004\n",
      "epoch 48; iter: 0; batch classifier loss: 0.423246; batch adversarial loss: 0.359294\n",
      "epoch 48; iter: 200; batch classifier loss: 0.510165; batch adversarial loss: 0.389956\n",
      "epoch 49; iter: 0; batch classifier loss: 0.501648; batch adversarial loss: 0.373916\n",
      "epoch 49; iter: 200; batch classifier loss: 0.470375; batch adversarial loss: 0.416274\n",
      "epoch 0; iter: 0; batch classifier loss: 309.552063; batch adversarial loss: 0.568598\n",
      "epoch 0; iter: 200; batch classifier loss: 2.155465; batch adversarial loss: 0.531535\n",
      "epoch 1; iter: 0; batch classifier loss: 11.865382; batch adversarial loss: 0.589259\n",
      "epoch 1; iter: 200; batch classifier loss: 6.229713; batch adversarial loss: 0.499013\n",
      "epoch 2; iter: 0; batch classifier loss: 2.083787; batch adversarial loss: 0.533753\n",
      "epoch 2; iter: 200; batch classifier loss: 3.237939; batch adversarial loss: 0.460885\n",
      "epoch 3; iter: 0; batch classifier loss: 2.843784; batch adversarial loss: 0.442711\n",
      "epoch 3; iter: 200; batch classifier loss: 3.998115; batch adversarial loss: 0.431666\n",
      "epoch 4; iter: 0; batch classifier loss: 2.936671; batch adversarial loss: 0.487123\n",
      "epoch 4; iter: 200; batch classifier loss: 2.165643; batch adversarial loss: 0.436049\n",
      "epoch 5; iter: 0; batch classifier loss: 1.704853; batch adversarial loss: 0.399819\n",
      "epoch 5; iter: 200; batch classifier loss: 2.172333; batch adversarial loss: 0.403252\n",
      "epoch 6; iter: 0; batch classifier loss: 0.774387; batch adversarial loss: 0.416389\n",
      "epoch 6; iter: 200; batch classifier loss: 1.285239; batch adversarial loss: 0.449986\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527327; batch adversarial loss: 0.472148\n",
      "epoch 7; iter: 200; batch classifier loss: 1.460355; batch adversarial loss: 0.433561\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426158; batch adversarial loss: 0.401090\n",
      "epoch 8; iter: 200; batch classifier loss: 0.461794; batch adversarial loss: 0.408756\n",
      "epoch 9; iter: 0; batch classifier loss: 1.024064; batch adversarial loss: 0.399891\n",
      "epoch 9; iter: 200; batch classifier loss: 0.334304; batch adversarial loss: 0.307728\n",
      "epoch 10; iter: 0; batch classifier loss: 0.359400; batch adversarial loss: 0.375867\n",
      "epoch 10; iter: 200; batch classifier loss: 0.447316; batch adversarial loss: 0.368133\n",
      "epoch 11; iter: 0; batch classifier loss: 0.411761; batch adversarial loss: 0.432507\n",
      "epoch 11; iter: 200; batch classifier loss: 0.436315; batch adversarial loss: 0.500527\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383497; batch adversarial loss: 0.430822\n",
      "epoch 12; iter: 200; batch classifier loss: 0.531830; batch adversarial loss: 0.384219\n",
      "epoch 13; iter: 0; batch classifier loss: 0.313927; batch adversarial loss: 0.424760\n",
      "epoch 13; iter: 200; batch classifier loss: 0.290290; batch adversarial loss: 0.434476\n",
      "epoch 14; iter: 0; batch classifier loss: 0.309578; batch adversarial loss: 0.442033\n",
      "epoch 14; iter: 200; batch classifier loss: 0.315595; batch adversarial loss: 0.402682\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422451; batch adversarial loss: 0.403716\n",
      "epoch 15; iter: 200; batch classifier loss: 0.372909; batch adversarial loss: 0.424568\n",
      "epoch 16; iter: 0; batch classifier loss: 0.302190; batch adversarial loss: 0.459382\n",
      "epoch 16; iter: 200; batch classifier loss: 0.373588; batch adversarial loss: 0.428433\n",
      "epoch 17; iter: 0; batch classifier loss: 0.364471; batch adversarial loss: 0.472657\n",
      "epoch 17; iter: 200; batch classifier loss: 0.331102; batch adversarial loss: 0.477502\n",
      "epoch 18; iter: 0; batch classifier loss: 0.354110; batch adversarial loss: 0.565807\n",
      "epoch 18; iter: 200; batch classifier loss: 0.325503; batch adversarial loss: 0.442479\n",
      "epoch 19; iter: 0; batch classifier loss: 0.323569; batch adversarial loss: 0.404935\n",
      "epoch 19; iter: 200; batch classifier loss: 0.305703; batch adversarial loss: 0.480006\n",
      "epoch 20; iter: 0; batch classifier loss: 0.296780; batch adversarial loss: 0.327448\n",
      "epoch 20; iter: 200; batch classifier loss: 0.333060; batch adversarial loss: 0.469943\n",
      "epoch 21; iter: 0; batch classifier loss: 0.342331; batch adversarial loss: 0.426807\n",
      "epoch 21; iter: 200; batch classifier loss: 0.340253; batch adversarial loss: 0.391488\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303084; batch adversarial loss: 0.290295\n",
      "epoch 22; iter: 200; batch classifier loss: 0.253561; batch adversarial loss: 0.377017\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457205; batch adversarial loss: 0.480981\n",
      "epoch 23; iter: 200; batch classifier loss: 0.306922; batch adversarial loss: 0.429444\n",
      "epoch 24; iter: 0; batch classifier loss: 0.395016; batch adversarial loss: 0.453323\n",
      "epoch 24; iter: 200; batch classifier loss: 0.335007; batch adversarial loss: 0.356797\n",
      "epoch 25; iter: 0; batch classifier loss: 0.325843; batch adversarial loss: 0.406654\n",
      "epoch 25; iter: 200; batch classifier loss: 0.294000; batch adversarial loss: 0.436590\n",
      "epoch 26; iter: 0; batch classifier loss: 0.306077; batch adversarial loss: 0.360152\n",
      "epoch 26; iter: 200; batch classifier loss: 0.367722; batch adversarial loss: 0.393416\n",
      "epoch 27; iter: 0; batch classifier loss: 0.272783; batch adversarial loss: 0.324684\n",
      "epoch 27; iter: 200; batch classifier loss: 0.361174; batch adversarial loss: 0.396690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.379395; batch adversarial loss: 0.333050\n",
      "epoch 28; iter: 200; batch classifier loss: 0.321861; batch adversarial loss: 0.476476\n",
      "epoch 29; iter: 0; batch classifier loss: 0.393247; batch adversarial loss: 0.483819\n",
      "epoch 29; iter: 200; batch classifier loss: 0.344645; batch adversarial loss: 0.370087\n",
      "epoch 30; iter: 0; batch classifier loss: 0.357965; batch adversarial loss: 0.398356\n",
      "epoch 30; iter: 200; batch classifier loss: 0.307901; batch adversarial loss: 0.473773\n",
      "epoch 31; iter: 0; batch classifier loss: 0.340017; batch adversarial loss: 0.440334\n",
      "epoch 31; iter: 200; batch classifier loss: 0.248891; batch adversarial loss: 0.376628\n",
      "epoch 32; iter: 0; batch classifier loss: 0.295160; batch adversarial loss: 0.472654\n",
      "epoch 32; iter: 200; batch classifier loss: 0.355751; batch adversarial loss: 0.401035\n",
      "epoch 33; iter: 0; batch classifier loss: 0.353255; batch adversarial loss: 0.321252\n",
      "epoch 33; iter: 200; batch classifier loss: 0.323296; batch adversarial loss: 0.442196\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310259; batch adversarial loss: 0.436508\n",
      "epoch 34; iter: 200; batch classifier loss: 0.272761; batch adversarial loss: 0.435689\n",
      "epoch 35; iter: 0; batch classifier loss: 0.303043; batch adversarial loss: 0.338613\n",
      "epoch 35; iter: 200; batch classifier loss: 0.304811; batch adversarial loss: 0.443977\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280189; batch adversarial loss: 0.449999\n",
      "epoch 36; iter: 200; batch classifier loss: 0.355767; batch adversarial loss: 0.427637\n",
      "epoch 37; iter: 0; batch classifier loss: 0.372042; batch adversarial loss: 0.440225\n",
      "epoch 37; iter: 200; batch classifier loss: 0.286370; batch adversarial loss: 0.441180\n",
      "epoch 38; iter: 0; batch classifier loss: 0.333562; batch adversarial loss: 0.435655\n",
      "epoch 38; iter: 200; batch classifier loss: 0.341746; batch adversarial loss: 0.369294\n",
      "epoch 39; iter: 0; batch classifier loss: 0.317157; batch adversarial loss: 0.420335\n",
      "epoch 39; iter: 200; batch classifier loss: 0.339572; batch adversarial loss: 0.455520\n",
      "epoch 40; iter: 0; batch classifier loss: 0.371291; batch adversarial loss: 0.401389\n",
      "epoch 40; iter: 200; batch classifier loss: 0.422645; batch adversarial loss: 0.435486\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415963; batch adversarial loss: 0.432134\n",
      "epoch 41; iter: 200; batch classifier loss: 0.339474; batch adversarial loss: 0.466522\n",
      "epoch 42; iter: 0; batch classifier loss: 0.344553; batch adversarial loss: 0.435993\n",
      "epoch 42; iter: 200; batch classifier loss: 0.446067; batch adversarial loss: 0.364156\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482616; batch adversarial loss: 0.408139\n",
      "epoch 43; iter: 200; batch classifier loss: 0.369894; batch adversarial loss: 0.398119\n",
      "epoch 44; iter: 0; batch classifier loss: 0.318479; batch adversarial loss: 0.370082\n",
      "epoch 44; iter: 200; batch classifier loss: 0.412729; batch adversarial loss: 0.454731\n",
      "epoch 45; iter: 0; batch classifier loss: 0.431732; batch adversarial loss: 0.539810\n",
      "epoch 45; iter: 200; batch classifier loss: 0.456413; batch adversarial loss: 0.452671\n",
      "epoch 46; iter: 0; batch classifier loss: 0.290886; batch adversarial loss: 0.390550\n",
      "epoch 46; iter: 200; batch classifier loss: 0.352354; batch adversarial loss: 0.401071\n",
      "epoch 47; iter: 0; batch classifier loss: 0.240950; batch adversarial loss: 0.486917\n",
      "epoch 47; iter: 200; batch classifier loss: 0.396501; batch adversarial loss: 0.472842\n",
      "epoch 48; iter: 0; batch classifier loss: 0.360877; batch adversarial loss: 0.570578\n",
      "epoch 48; iter: 200; batch classifier loss: 0.441870; batch adversarial loss: 0.366258\n",
      "epoch 49; iter: 0; batch classifier loss: 0.344452; batch adversarial loss: 0.432209\n",
      "epoch 49; iter: 200; batch classifier loss: 0.340423; batch adversarial loss: 0.363825\n",
      "epoch 0; iter: 0; batch classifier loss: 26.006535; batch adversarial loss: 0.509237\n",
      "epoch 0; iter: 200; batch classifier loss: 4.636810; batch adversarial loss: 0.563886\n",
      "epoch 1; iter: 0; batch classifier loss: 8.145577; batch adversarial loss: 0.567673\n",
      "epoch 1; iter: 200; batch classifier loss: 5.579607; batch adversarial loss: 0.498882\n",
      "epoch 2; iter: 0; batch classifier loss: 16.045345; batch adversarial loss: 0.521076\n",
      "epoch 2; iter: 200; batch classifier loss: 6.915069; batch adversarial loss: 0.482714\n",
      "epoch 3; iter: 0; batch classifier loss: 3.307113; batch adversarial loss: 0.385986\n",
      "epoch 3; iter: 200; batch classifier loss: 2.724154; batch adversarial loss: 0.476054\n",
      "epoch 4; iter: 0; batch classifier loss: 6.029401; batch adversarial loss: 0.514050\n",
      "epoch 4; iter: 200; batch classifier loss: 2.319892; batch adversarial loss: 0.397209\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466480; batch adversarial loss: 0.427634\n",
      "epoch 5; iter: 200; batch classifier loss: 0.683604; batch adversarial loss: 0.419415\n",
      "epoch 6; iter: 0; batch classifier loss: 1.008175; batch adversarial loss: 0.460560\n",
      "epoch 6; iter: 200; batch classifier loss: 0.408404; batch adversarial loss: 0.432757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532133; batch adversarial loss: 0.467896\n",
      "epoch 7; iter: 200; batch classifier loss: 0.413305; batch adversarial loss: 0.453739\n",
      "epoch 8; iter: 0; batch classifier loss: 0.864624; batch adversarial loss: 0.330749\n",
      "epoch 8; iter: 200; batch classifier loss: 0.648763; batch adversarial loss: 0.438095\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479098; batch adversarial loss: 0.451119\n",
      "epoch 9; iter: 200; batch classifier loss: 0.491378; batch adversarial loss: 0.472299\n",
      "epoch 10; iter: 0; batch classifier loss: 0.409092; batch adversarial loss: 0.475228\n",
      "epoch 10; iter: 200; batch classifier loss: 0.416686; batch adversarial loss: 0.435623\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454091; batch adversarial loss: 0.407658\n",
      "epoch 11; iter: 200; batch classifier loss: 0.317349; batch adversarial loss: 0.441762\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402282; batch adversarial loss: 0.446367\n",
      "epoch 12; iter: 200; batch classifier loss: 0.450977; batch adversarial loss: 0.448265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384493; batch adversarial loss: 0.443463\n",
      "epoch 13; iter: 200; batch classifier loss: 0.361818; batch adversarial loss: 0.436845\n",
      "epoch 14; iter: 0; batch classifier loss: 0.375232; batch adversarial loss: 0.348477\n",
      "epoch 14; iter: 200; batch classifier loss: 0.482796; batch adversarial loss: 0.418459\n",
      "epoch 15; iter: 0; batch classifier loss: 0.276573; batch adversarial loss: 0.306057\n",
      "epoch 15; iter: 200; batch classifier loss: 0.276243; batch adversarial loss: 0.642104\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358304; batch adversarial loss: 0.488348\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352580; batch adversarial loss: 0.400449\n",
      "epoch 17; iter: 0; batch classifier loss: 0.326070; batch adversarial loss: 0.416763\n",
      "epoch 17; iter: 200; batch classifier loss: 0.356734; batch adversarial loss: 0.439913\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331478; batch adversarial loss: 0.394576\n",
      "epoch 18; iter: 200; batch classifier loss: 0.327309; batch adversarial loss: 0.467128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.286329; batch adversarial loss: 0.446893\n",
      "epoch 19; iter: 200; batch classifier loss: 0.355636; batch adversarial loss: 0.458161\n",
      "epoch 20; iter: 0; batch classifier loss: 0.275222; batch adversarial loss: 0.376037\n",
      "epoch 20; iter: 200; batch classifier loss: 0.394402; batch adversarial loss: 0.341372\n",
      "epoch 21; iter: 0; batch classifier loss: 0.411317; batch adversarial loss: 0.404938\n",
      "epoch 21; iter: 200; batch classifier loss: 0.286628; batch adversarial loss: 0.326414\n",
      "epoch 22; iter: 0; batch classifier loss: 0.332620; batch adversarial loss: 0.415229\n",
      "epoch 22; iter: 200; batch classifier loss: 0.322502; batch adversarial loss: 0.371395\n",
      "epoch 23; iter: 0; batch classifier loss: 0.332872; batch adversarial loss: 0.460462\n",
      "epoch 23; iter: 200; batch classifier loss: 0.389017; batch adversarial loss: 0.353810\n",
      "epoch 24; iter: 0; batch classifier loss: 0.297062; batch adversarial loss: 0.441539\n",
      "epoch 24; iter: 200; batch classifier loss: 0.434833; batch adversarial loss: 0.465544\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306976; batch adversarial loss: 0.363385\n",
      "epoch 25; iter: 200; batch classifier loss: 0.323741; batch adversarial loss: 0.461737\n",
      "epoch 26; iter: 0; batch classifier loss: 0.308776; batch adversarial loss: 0.371219\n",
      "epoch 26; iter: 200; batch classifier loss: 0.401369; batch adversarial loss: 0.400784\n",
      "epoch 27; iter: 0; batch classifier loss: 0.338805; batch adversarial loss: 0.487300\n",
      "epoch 27; iter: 200; batch classifier loss: 0.343360; batch adversarial loss: 0.421917\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386028; batch adversarial loss: 0.365290\n",
      "epoch 28; iter: 200; batch classifier loss: 0.267445; batch adversarial loss: 0.530043\n",
      "epoch 29; iter: 0; batch classifier loss: 0.258178; batch adversarial loss: 0.489095\n",
      "epoch 29; iter: 200; batch classifier loss: 0.324113; batch adversarial loss: 0.441292\n",
      "epoch 30; iter: 0; batch classifier loss: 0.377253; batch adversarial loss: 0.434356\n",
      "epoch 30; iter: 200; batch classifier loss: 0.296377; batch adversarial loss: 0.401227\n",
      "epoch 31; iter: 0; batch classifier loss: 0.324171; batch adversarial loss: 0.423939\n",
      "epoch 31; iter: 200; batch classifier loss: 0.349273; batch adversarial loss: 0.339204\n",
      "epoch 32; iter: 0; batch classifier loss: 0.286990; batch adversarial loss: 0.395830\n",
      "epoch 32; iter: 200; batch classifier loss: 0.242786; batch adversarial loss: 0.535008\n",
      "epoch 33; iter: 0; batch classifier loss: 0.221082; batch adversarial loss: 0.471347\n",
      "epoch 33; iter: 200; batch classifier loss: 0.376220; batch adversarial loss: 0.444614\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262309; batch adversarial loss: 0.474427\n",
      "epoch 34; iter: 200; batch classifier loss: 0.370779; batch adversarial loss: 0.401050\n",
      "epoch 35; iter: 0; batch classifier loss: 0.302768; batch adversarial loss: 0.438184\n",
      "epoch 35; iter: 200; batch classifier loss: 0.410789; batch adversarial loss: 0.490807\n",
      "epoch 36; iter: 0; batch classifier loss: 0.273156; batch adversarial loss: 0.467902\n",
      "epoch 36; iter: 200; batch classifier loss: 0.325086; batch adversarial loss: 0.431877\n",
      "epoch 37; iter: 0; batch classifier loss: 0.347077; batch adversarial loss: 0.326397\n",
      "epoch 37; iter: 200; batch classifier loss: 0.385060; batch adversarial loss: 0.402348\n",
      "epoch 38; iter: 0; batch classifier loss: 0.469194; batch adversarial loss: 0.408551\n",
      "epoch 38; iter: 200; batch classifier loss: 0.329550; batch adversarial loss: 0.339393\n",
      "epoch 39; iter: 0; batch classifier loss: 0.272894; batch adversarial loss: 0.391747\n",
      "epoch 39; iter: 200; batch classifier loss: 0.338606; batch adversarial loss: 0.321133\n",
      "epoch 40; iter: 0; batch classifier loss: 0.343034; batch adversarial loss: 0.368801\n",
      "epoch 40; iter: 200; batch classifier loss: 0.448752; batch adversarial loss: 0.434675\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404371; batch adversarial loss: 0.396890\n",
      "epoch 41; iter: 200; batch classifier loss: 0.361938; batch adversarial loss: 0.382822\n",
      "epoch 42; iter: 0; batch classifier loss: 0.339565; batch adversarial loss: 0.345841\n",
      "epoch 42; iter: 200; batch classifier loss: 0.258417; batch adversarial loss: 0.440459\n",
      "epoch 43; iter: 0; batch classifier loss: 0.303580; batch adversarial loss: 0.427171\n",
      "epoch 43; iter: 200; batch classifier loss: 0.362083; batch adversarial loss: 0.502937\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365219; batch adversarial loss: 0.376085\n",
      "epoch 44; iter: 200; batch classifier loss: 0.354394; batch adversarial loss: 0.545690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.420064; batch adversarial loss: 0.412063\n",
      "epoch 45; iter: 200; batch classifier loss: 0.442819; batch adversarial loss: 0.443195\n",
      "epoch 46; iter: 0; batch classifier loss: 0.335208; batch adversarial loss: 0.477919\n",
      "epoch 46; iter: 200; batch classifier loss: 0.324774; batch adversarial loss: 0.388976\n",
      "epoch 47; iter: 0; batch classifier loss: 0.238549; batch adversarial loss: 0.326864\n",
      "epoch 47; iter: 200; batch classifier loss: 0.390795; batch adversarial loss: 0.427791\n",
      "epoch 48; iter: 0; batch classifier loss: 0.388041; batch adversarial loss: 0.318710\n",
      "epoch 48; iter: 200; batch classifier loss: 0.333289; batch adversarial loss: 0.436355\n",
      "epoch 49; iter: 0; batch classifier loss: 0.296498; batch adversarial loss: 0.423742\n",
      "epoch 49; iter: 200; batch classifier loss: 0.466382; batch adversarial loss: 0.385761\n",
      "epoch 0; iter: 0; batch classifier loss: 14.069233; batch adversarial loss: 0.712428\n",
      "epoch 0; iter: 200; batch classifier loss: 5.587595; batch adversarial loss: 0.626746\n",
      "epoch 1; iter: 0; batch classifier loss: 5.105485; batch adversarial loss: 0.585535\n",
      "epoch 1; iter: 200; batch classifier loss: 3.300331; batch adversarial loss: 0.523938\n",
      "epoch 2; iter: 0; batch classifier loss: 3.868632; batch adversarial loss: 0.482905\n",
      "epoch 2; iter: 200; batch classifier loss: 4.947277; batch adversarial loss: 0.464037\n",
      "epoch 3; iter: 0; batch classifier loss: 1.730731; batch adversarial loss: 0.454943\n",
      "epoch 3; iter: 200; batch classifier loss: 2.517313; batch adversarial loss: 0.511707\n",
      "epoch 4; iter: 0; batch classifier loss: 1.763344; batch adversarial loss: 0.362849\n",
      "epoch 4; iter: 200; batch classifier loss: 1.893170; batch adversarial loss: 0.450396\n",
      "epoch 5; iter: 0; batch classifier loss: 1.172326; batch adversarial loss: 0.446366\n",
      "epoch 5; iter: 200; batch classifier loss: 0.933972; batch adversarial loss: 0.382626\n",
      "epoch 6; iter: 0; batch classifier loss: 0.766045; batch adversarial loss: 0.396194\n",
      "epoch 6; iter: 200; batch classifier loss: 0.665400; batch adversarial loss: 0.480114\n",
      "epoch 7; iter: 0; batch classifier loss: 0.659349; batch adversarial loss: 0.455036\n",
      "epoch 7; iter: 200; batch classifier loss: 0.456270; batch adversarial loss: 0.487098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.714400; batch adversarial loss: 0.340467\n",
      "epoch 8; iter: 200; batch classifier loss: 0.433646; batch adversarial loss: 0.451180\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384336; batch adversarial loss: 0.430037\n",
      "epoch 9; iter: 200; batch classifier loss: 0.286305; batch adversarial loss: 0.423575\n",
      "epoch 10; iter: 0; batch classifier loss: 0.369975; batch adversarial loss: 0.364082\n",
      "epoch 10; iter: 200; batch classifier loss: 0.297910; batch adversarial loss: 0.444284\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362020; batch adversarial loss: 0.432588\n",
      "epoch 11; iter: 200; batch classifier loss: 0.413914; batch adversarial loss: 0.322449\n",
      "epoch 12; iter: 0; batch classifier loss: 0.351439; batch adversarial loss: 0.434894\n",
      "epoch 12; iter: 200; batch classifier loss: 0.273981; batch adversarial loss: 0.404764\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278867; batch adversarial loss: 0.468640\n",
      "epoch 13; iter: 200; batch classifier loss: 0.347132; batch adversarial loss: 0.360790\n",
      "epoch 14; iter: 0; batch classifier loss: 0.364599; batch adversarial loss: 0.415153\n",
      "epoch 14; iter: 200; batch classifier loss: 0.347501; batch adversarial loss: 0.458330\n",
      "epoch 15; iter: 0; batch classifier loss: 0.352703; batch adversarial loss: 0.421470\n",
      "epoch 15; iter: 200; batch classifier loss: 0.354196; batch adversarial loss: 0.407534\n",
      "epoch 16; iter: 0; batch classifier loss: 0.290237; batch adversarial loss: 0.503130\n",
      "epoch 16; iter: 200; batch classifier loss: 0.330662; batch adversarial loss: 0.442105\n",
      "epoch 17; iter: 0; batch classifier loss: 0.355073; batch adversarial loss: 0.366383\n",
      "epoch 17; iter: 200; batch classifier loss: 0.399726; batch adversarial loss: 0.461240\n",
      "epoch 18; iter: 0; batch classifier loss: 0.403997; batch adversarial loss: 0.405222\n",
      "epoch 18; iter: 200; batch classifier loss: 0.351781; batch adversarial loss: 0.449159\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382391; batch adversarial loss: 0.380985\n",
      "epoch 19; iter: 200; batch classifier loss: 0.383853; batch adversarial loss: 0.314587\n",
      "epoch 20; iter: 0; batch classifier loss: 0.329877; batch adversarial loss: 0.346772\n",
      "epoch 20; iter: 200; batch classifier loss: 0.300261; batch adversarial loss: 0.386580\n",
      "epoch 21; iter: 0; batch classifier loss: 0.356598; batch adversarial loss: 0.447876\n",
      "epoch 21; iter: 200; batch classifier loss: 0.260435; batch adversarial loss: 0.530743\n",
      "epoch 22; iter: 0; batch classifier loss: 0.345447; batch adversarial loss: 0.360524\n",
      "epoch 22; iter: 200; batch classifier loss: 0.355768; batch adversarial loss: 0.397449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.457903; batch adversarial loss: 0.345782\n",
      "epoch 23; iter: 200; batch classifier loss: 0.353700; batch adversarial loss: 0.389034\n",
      "epoch 24; iter: 0; batch classifier loss: 0.389919; batch adversarial loss: 0.416700\n",
      "epoch 24; iter: 200; batch classifier loss: 0.325008; batch adversarial loss: 0.489742\n",
      "epoch 25; iter: 0; batch classifier loss: 0.412706; batch adversarial loss: 0.409384\n",
      "epoch 25; iter: 200; batch classifier loss: 0.419466; batch adversarial loss: 0.393224\n",
      "epoch 26; iter: 0; batch classifier loss: 0.297580; batch adversarial loss: 0.398802\n",
      "epoch 26; iter: 200; batch classifier loss: 0.393307; batch adversarial loss: 0.345833\n",
      "epoch 27; iter: 0; batch classifier loss: 0.369413; batch adversarial loss: 0.437765\n",
      "epoch 27; iter: 200; batch classifier loss: 0.317510; batch adversarial loss: 0.507771\n",
      "epoch 28; iter: 0; batch classifier loss: 0.240180; batch adversarial loss: 0.447951\n",
      "epoch 28; iter: 200; batch classifier loss: 0.385202; batch adversarial loss: 0.342251\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439006; batch adversarial loss: 0.371422\n",
      "epoch 29; iter: 200; batch classifier loss: 0.310723; batch adversarial loss: 0.439524\n",
      "epoch 30; iter: 0; batch classifier loss: 0.338244; batch adversarial loss: 0.411586\n",
      "epoch 30; iter: 200; batch classifier loss: 0.391590; batch adversarial loss: 0.314313\n",
      "epoch 31; iter: 0; batch classifier loss: 0.352541; batch adversarial loss: 0.421285\n",
      "epoch 31; iter: 200; batch classifier loss: 0.408955; batch adversarial loss: 0.367251\n",
      "epoch 32; iter: 0; batch classifier loss: 0.324840; batch adversarial loss: 0.528382\n",
      "epoch 32; iter: 200; batch classifier loss: 0.355834; batch adversarial loss: 0.403555\n",
      "epoch 33; iter: 0; batch classifier loss: 0.293356; batch adversarial loss: 0.365880\n",
      "epoch 33; iter: 200; batch classifier loss: 0.492329; batch adversarial loss: 0.480497\n",
      "epoch 34; iter: 0; batch classifier loss: 0.271471; batch adversarial loss: 0.357894\n",
      "epoch 34; iter: 200; batch classifier loss: 0.303107; batch adversarial loss: 0.479909\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397946; batch adversarial loss: 0.337054\n",
      "epoch 35; iter: 200; batch classifier loss: 0.481125; batch adversarial loss: 0.354724\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389618; batch adversarial loss: 0.379759\n",
      "epoch 36; iter: 200; batch classifier loss: 0.311125; batch adversarial loss: 0.433300\n",
      "epoch 37; iter: 0; batch classifier loss: 0.293763; batch adversarial loss: 0.421397\n",
      "epoch 37; iter: 200; batch classifier loss: 0.335700; batch adversarial loss: 0.482482\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407405; batch adversarial loss: 0.374314\n",
      "epoch 38; iter: 200; batch classifier loss: 0.326212; batch adversarial loss: 0.385453\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417253; batch adversarial loss: 0.306896\n",
      "epoch 39; iter: 200; batch classifier loss: 0.312392; batch adversarial loss: 0.441253\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423927; batch adversarial loss: 0.375606\n",
      "epoch 40; iter: 200; batch classifier loss: 0.452145; batch adversarial loss: 0.426530\n",
      "epoch 41; iter: 0; batch classifier loss: 0.332716; batch adversarial loss: 0.332804\n",
      "epoch 41; iter: 200; batch classifier loss: 0.277578; batch adversarial loss: 0.487221\n",
      "epoch 42; iter: 0; batch classifier loss: 0.369819; batch adversarial loss: 0.528215\n",
      "epoch 42; iter: 200; batch classifier loss: 0.381681; batch adversarial loss: 0.469534\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391062; batch adversarial loss: 0.335920\n",
      "epoch 43; iter: 200; batch classifier loss: 0.325875; batch adversarial loss: 0.442961\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457234; batch adversarial loss: 0.470399\n",
      "epoch 44; iter: 200; batch classifier loss: 0.421294; batch adversarial loss: 0.490268\n",
      "epoch 45; iter: 0; batch classifier loss: 0.442206; batch adversarial loss: 0.497821\n",
      "epoch 45; iter: 200; batch classifier loss: 0.367265; batch adversarial loss: 0.425835\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356250; batch adversarial loss: 0.377096\n",
      "epoch 46; iter: 200; batch classifier loss: 0.420511; batch adversarial loss: 0.429661\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357306; batch adversarial loss: 0.371359\n",
      "epoch 47; iter: 200; batch classifier loss: 0.287081; batch adversarial loss: 0.449805\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421532; batch adversarial loss: 0.363474\n",
      "epoch 48; iter: 200; batch classifier loss: 0.311997; batch adversarial loss: 0.433434\n",
      "epoch 49; iter: 0; batch classifier loss: 0.516079; batch adversarial loss: 0.429135\n",
      "epoch 49; iter: 200; batch classifier loss: 0.477941; batch adversarial loss: 0.317951\n",
      "epoch 0; iter: 0; batch classifier loss: 6.622127; batch adversarial loss: 0.571289\n",
      "epoch 0; iter: 200; batch classifier loss: 6.274465; batch adversarial loss: 0.572931\n",
      "epoch 1; iter: 0; batch classifier loss: 7.962748; batch adversarial loss: 0.569355\n",
      "epoch 1; iter: 200; batch classifier loss: 4.476988; batch adversarial loss: 0.528943\n",
      "epoch 2; iter: 0; batch classifier loss: 8.262106; batch adversarial loss: 0.479171\n",
      "epoch 2; iter: 200; batch classifier loss: 0.946596; batch adversarial loss: 0.517346\n",
      "epoch 3; iter: 0; batch classifier loss: 3.414528; batch adversarial loss: 0.475830\n",
      "epoch 3; iter: 200; batch classifier loss: 9.863924; batch adversarial loss: 0.461580\n",
      "epoch 4; iter: 0; batch classifier loss: 1.870020; batch adversarial loss: 0.477304\n",
      "epoch 4; iter: 200; batch classifier loss: 2.062248; batch adversarial loss: 0.410214\n",
      "epoch 5; iter: 0; batch classifier loss: 2.256997; batch adversarial loss: 0.488893\n",
      "epoch 5; iter: 200; batch classifier loss: 0.651442; batch adversarial loss: 0.383445\n",
      "epoch 6; iter: 0; batch classifier loss: 0.632956; batch adversarial loss: 0.436686\n",
      "epoch 6; iter: 200; batch classifier loss: 0.650037; batch adversarial loss: 0.416178\n",
      "epoch 7; iter: 0; batch classifier loss: 0.396826; batch adversarial loss: 0.434307\n",
      "epoch 7; iter: 200; batch classifier loss: 0.609779; batch adversarial loss: 0.450227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.593314; batch adversarial loss: 0.466520\n",
      "epoch 8; iter: 200; batch classifier loss: 0.503829; batch adversarial loss: 0.517732\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421593; batch adversarial loss: 0.429461\n",
      "epoch 9; iter: 200; batch classifier loss: 0.388183; batch adversarial loss: 0.442385\n",
      "epoch 10; iter: 0; batch classifier loss: 0.510320; batch adversarial loss: 0.476354\n",
      "epoch 10; iter: 200; batch classifier loss: 0.532022; batch adversarial loss: 0.323732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362567; batch adversarial loss: 0.472654\n",
      "epoch 11; iter: 200; batch classifier loss: 0.421156; batch adversarial loss: 0.344596\n",
      "epoch 12; iter: 0; batch classifier loss: 0.398864; batch adversarial loss: 0.525436\n",
      "epoch 12; iter: 200; batch classifier loss: 0.461748; batch adversarial loss: 0.348826\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339001; batch adversarial loss: 0.406220\n",
      "epoch 13; iter: 200; batch classifier loss: 0.389105; batch adversarial loss: 0.413501\n",
      "epoch 14; iter: 0; batch classifier loss: 0.490203; batch adversarial loss: 0.391637\n",
      "epoch 14; iter: 200; batch classifier loss: 0.401542; batch adversarial loss: 0.386791\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322824; batch adversarial loss: 0.486755\n",
      "epoch 15; iter: 200; batch classifier loss: 0.358495; batch adversarial loss: 0.452783\n",
      "epoch 16; iter: 0; batch classifier loss: 0.301567; batch adversarial loss: 0.415607\n",
      "epoch 16; iter: 200; batch classifier loss: 0.336039; batch adversarial loss: 0.603394\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269757; batch adversarial loss: 0.380942\n",
      "epoch 17; iter: 200; batch classifier loss: 0.325127; batch adversarial loss: 0.414428\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338699; batch adversarial loss: 0.381646\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399067; batch adversarial loss: 0.464834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376043; batch adversarial loss: 0.415052\n",
      "epoch 19; iter: 200; batch classifier loss: 0.411310; batch adversarial loss: 0.362607\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440160; batch adversarial loss: 0.548048\n",
      "epoch 20; iter: 200; batch classifier loss: 0.338747; batch adversarial loss: 0.448000\n",
      "epoch 21; iter: 0; batch classifier loss: 0.385671; batch adversarial loss: 0.316280\n",
      "epoch 21; iter: 200; batch classifier loss: 0.330306; batch adversarial loss: 0.450021\n",
      "epoch 22; iter: 0; batch classifier loss: 0.276022; batch adversarial loss: 0.453780\n",
      "epoch 22; iter: 200; batch classifier loss: 0.370773; batch adversarial loss: 0.435696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.242228; batch adversarial loss: 0.425910\n",
      "epoch 23; iter: 200; batch classifier loss: 0.329561; batch adversarial loss: 0.332326\n",
      "epoch 24; iter: 0; batch classifier loss: 0.391475; batch adversarial loss: 0.372534\n",
      "epoch 24; iter: 200; batch classifier loss: 0.309913; batch adversarial loss: 0.470754\n",
      "epoch 25; iter: 0; batch classifier loss: 0.225683; batch adversarial loss: 0.345432\n",
      "epoch 25; iter: 200; batch classifier loss: 0.311475; batch adversarial loss: 0.385635\n",
      "epoch 26; iter: 0; batch classifier loss: 0.360720; batch adversarial loss: 0.354174\n",
      "epoch 26; iter: 200; batch classifier loss: 0.380588; batch adversarial loss: 0.489632\n",
      "epoch 27; iter: 0; batch classifier loss: 0.258060; batch adversarial loss: 0.540765\n",
      "epoch 27; iter: 200; batch classifier loss: 0.404387; batch adversarial loss: 0.325136\n",
      "epoch 28; iter: 0; batch classifier loss: 0.275081; batch adversarial loss: 0.458525\n",
      "epoch 28; iter: 200; batch classifier loss: 0.378908; batch adversarial loss: 0.356749\n",
      "epoch 29; iter: 0; batch classifier loss: 0.293640; batch adversarial loss: 0.294361\n",
      "epoch 29; iter: 200; batch classifier loss: 0.346785; batch adversarial loss: 0.498214\n",
      "epoch 30; iter: 0; batch classifier loss: 0.216417; batch adversarial loss: 0.281116\n",
      "epoch 30; iter: 200; batch classifier loss: 0.332204; batch adversarial loss: 0.386250\n",
      "epoch 31; iter: 0; batch classifier loss: 0.250945; batch adversarial loss: 0.388034\n",
      "epoch 31; iter: 200; batch classifier loss: 0.333880; batch adversarial loss: 0.389230\n",
      "epoch 32; iter: 0; batch classifier loss: 0.316970; batch adversarial loss: 0.440697\n",
      "epoch 32; iter: 200; batch classifier loss: 0.348937; batch adversarial loss: 0.447970\n",
      "epoch 33; iter: 0; batch classifier loss: 0.314360; batch adversarial loss: 0.413049\n",
      "epoch 33; iter: 200; batch classifier loss: 0.351753; batch adversarial loss: 0.425563\n",
      "epoch 34; iter: 0; batch classifier loss: 0.313901; batch adversarial loss: 0.409096\n",
      "epoch 34; iter: 200; batch classifier loss: 0.311894; batch adversarial loss: 0.450680\n",
      "epoch 35; iter: 0; batch classifier loss: 0.291393; batch adversarial loss: 0.400778\n",
      "epoch 35; iter: 200; batch classifier loss: 0.327409; batch adversarial loss: 0.511067\n",
      "epoch 36; iter: 0; batch classifier loss: 0.309326; batch adversarial loss: 0.391654\n",
      "epoch 36; iter: 200; batch classifier loss: 0.371575; batch adversarial loss: 0.492699\n",
      "epoch 37; iter: 0; batch classifier loss: 0.291892; batch adversarial loss: 0.343603\n",
      "epoch 37; iter: 200; batch classifier loss: 0.431243; batch adversarial loss: 0.403763\n",
      "epoch 38; iter: 0; batch classifier loss: 0.257825; batch adversarial loss: 0.437700\n",
      "epoch 38; iter: 200; batch classifier loss: 0.289409; batch adversarial loss: 0.333008\n",
      "epoch 39; iter: 0; batch classifier loss: 0.354623; batch adversarial loss: 0.407414\n",
      "epoch 39; iter: 200; batch classifier loss: 0.460291; batch adversarial loss: 0.343756\n",
      "epoch 40; iter: 0; batch classifier loss: 0.318528; batch adversarial loss: 0.400675\n",
      "epoch 40; iter: 200; batch classifier loss: 0.273251; batch adversarial loss: 0.427945\n",
      "epoch 41; iter: 0; batch classifier loss: 0.389062; batch adversarial loss: 0.469967\n",
      "epoch 41; iter: 200; batch classifier loss: 0.355002; batch adversarial loss: 0.421238\n",
      "epoch 42; iter: 0; batch classifier loss: 0.277709; batch adversarial loss: 0.529944\n",
      "epoch 42; iter: 200; batch classifier loss: 0.411276; batch adversarial loss: 0.396340\n",
      "epoch 43; iter: 0; batch classifier loss: 0.349410; batch adversarial loss: 0.421673\n",
      "epoch 43; iter: 200; batch classifier loss: 0.296829; batch adversarial loss: 0.461611\n",
      "epoch 44; iter: 0; batch classifier loss: 0.326324; batch adversarial loss: 0.320942\n",
      "epoch 44; iter: 200; batch classifier loss: 0.421849; batch adversarial loss: 0.364071\n",
      "epoch 45; iter: 0; batch classifier loss: 0.555439; batch adversarial loss: 0.412665\n",
      "epoch 45; iter: 200; batch classifier loss: 0.402340; batch adversarial loss: 0.424581\n",
      "epoch 46; iter: 0; batch classifier loss: 0.571852; batch adversarial loss: 0.469293\n",
      "epoch 46; iter: 200; batch classifier loss: 0.351493; batch adversarial loss: 0.451533\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511472; batch adversarial loss: 0.423515\n",
      "epoch 47; iter: 200; batch classifier loss: 0.309252; batch adversarial loss: 0.390105\n",
      "epoch 48; iter: 0; batch classifier loss: 0.517304; batch adversarial loss: 0.436351\n",
      "epoch 48; iter: 200; batch classifier loss: 0.446916; batch adversarial loss: 0.380317\n",
      "epoch 49; iter: 0; batch classifier loss: 0.390981; batch adversarial loss: 0.382125\n",
      "epoch 49; iter: 200; batch classifier loss: 0.659757; batch adversarial loss: 0.367643\n",
      "epoch 0; iter: 0; batch classifier loss: 10.940767; batch adversarial loss: 0.576074\n",
      "epoch 0; iter: 200; batch classifier loss: 5.928903; batch adversarial loss: 0.517715\n",
      "epoch 1; iter: 0; batch classifier loss: 3.759591; batch adversarial loss: 0.525012\n",
      "epoch 1; iter: 200; batch classifier loss: 4.700062; batch adversarial loss: 0.523091\n",
      "epoch 2; iter: 0; batch classifier loss: 3.164922; batch adversarial loss: 0.505188\n",
      "epoch 2; iter: 200; batch classifier loss: 2.571817; batch adversarial loss: 0.463672\n",
      "epoch 3; iter: 0; batch classifier loss: 3.817316; batch adversarial loss: 0.493371\n",
      "epoch 3; iter: 200; batch classifier loss: 0.884789; batch adversarial loss: 0.428017\n",
      "epoch 4; iter: 0; batch classifier loss: 1.134973; batch adversarial loss: 0.385005\n",
      "epoch 4; iter: 200; batch classifier loss: 0.746802; batch adversarial loss: 0.418155\n",
      "epoch 5; iter: 0; batch classifier loss: 0.639019; batch adversarial loss: 0.466937\n",
      "epoch 5; iter: 200; batch classifier loss: 0.796872; batch adversarial loss: 0.571778\n",
      "epoch 6; iter: 0; batch classifier loss: 0.651554; batch adversarial loss: 0.415538\n",
      "epoch 6; iter: 200; batch classifier loss: 0.644741; batch adversarial loss: 0.388322\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495960; batch adversarial loss: 0.338635\n",
      "epoch 7; iter: 200; batch classifier loss: 0.541110; batch adversarial loss: 0.372058\n",
      "epoch 8; iter: 0; batch classifier loss: 0.445078; batch adversarial loss: 0.471099\n",
      "epoch 8; iter: 200; batch classifier loss: 0.404471; batch adversarial loss: 0.420667\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614557; batch adversarial loss: 0.366200\n",
      "epoch 9; iter: 200; batch classifier loss: 0.439241; batch adversarial loss: 0.371402\n",
      "epoch 10; iter: 0; batch classifier loss: 0.318222; batch adversarial loss: 0.420782\n",
      "epoch 10; iter: 200; batch classifier loss: 0.345287; batch adversarial loss: 0.399163\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368390; batch adversarial loss: 0.411909\n",
      "epoch 11; iter: 200; batch classifier loss: 0.464038; batch adversarial loss: 0.397571\n",
      "epoch 12; iter: 0; batch classifier loss: 0.393077; batch adversarial loss: 0.362060\n",
      "epoch 12; iter: 200; batch classifier loss: 0.363849; batch adversarial loss: 0.293188\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372163; batch adversarial loss: 0.401169\n",
      "epoch 13; iter: 200; batch classifier loss: 0.370962; batch adversarial loss: 0.376234\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408048; batch adversarial loss: 0.457601\n",
      "epoch 14; iter: 200; batch classifier loss: 0.376009; batch adversarial loss: 0.432040\n",
      "epoch 15; iter: 0; batch classifier loss: 0.302607; batch adversarial loss: 0.444616\n",
      "epoch 15; iter: 200; batch classifier loss: 0.408898; batch adversarial loss: 0.348409\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354291; batch adversarial loss: 0.442788\n",
      "epoch 16; iter: 200; batch classifier loss: 0.293968; batch adversarial loss: 0.443261\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353444; batch adversarial loss: 0.401074\n",
      "epoch 17; iter: 200; batch classifier loss: 0.448613; batch adversarial loss: 0.389995\n",
      "epoch 18; iter: 0; batch classifier loss: 0.341417; batch adversarial loss: 0.403630\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336939; batch adversarial loss: 0.389291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.330122; batch adversarial loss: 0.414571\n",
      "epoch 19; iter: 200; batch classifier loss: 0.325648; batch adversarial loss: 0.477393\n",
      "epoch 20; iter: 0; batch classifier loss: 0.301543; batch adversarial loss: 0.370221\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379558; batch adversarial loss: 0.403028\n",
      "epoch 21; iter: 0; batch classifier loss: 0.343659; batch adversarial loss: 0.420524\n",
      "epoch 21; iter: 200; batch classifier loss: 0.252478; batch adversarial loss: 0.461067\n",
      "epoch 22; iter: 0; batch classifier loss: 0.384091; batch adversarial loss: 0.438806\n",
      "epoch 22; iter: 200; batch classifier loss: 0.327483; batch adversarial loss: 0.420140\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342759; batch adversarial loss: 0.410896\n",
      "epoch 23; iter: 200; batch classifier loss: 0.375514; batch adversarial loss: 0.518373\n",
      "epoch 24; iter: 0; batch classifier loss: 0.351599; batch adversarial loss: 0.379755\n",
      "epoch 24; iter: 200; batch classifier loss: 0.385297; batch adversarial loss: 0.428845\n",
      "epoch 25; iter: 0; batch classifier loss: 0.334078; batch adversarial loss: 0.489594\n",
      "epoch 25; iter: 200; batch classifier loss: 0.350011; batch adversarial loss: 0.613797\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356017; batch adversarial loss: 0.293515\n",
      "epoch 26; iter: 200; batch classifier loss: 0.395649; batch adversarial loss: 0.338152\n",
      "epoch 27; iter: 0; batch classifier loss: 0.343981; batch adversarial loss: 0.468195\n",
      "epoch 27; iter: 200; batch classifier loss: 0.317860; batch adversarial loss: 0.441472\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291903; batch adversarial loss: 0.386450\n",
      "epoch 28; iter: 200; batch classifier loss: 0.368953; batch adversarial loss: 0.479653\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398144; batch adversarial loss: 0.415824\n",
      "epoch 29; iter: 200; batch classifier loss: 0.409451; batch adversarial loss: 0.412393\n",
      "epoch 30; iter: 0; batch classifier loss: 0.301717; batch adversarial loss: 0.375576\n",
      "epoch 30; iter: 200; batch classifier loss: 0.298503; batch adversarial loss: 0.389633\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417599; batch adversarial loss: 0.416555\n",
      "epoch 31; iter: 200; batch classifier loss: 0.398169; batch adversarial loss: 0.304095\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436069; batch adversarial loss: 0.444975\n",
      "epoch 32; iter: 200; batch classifier loss: 0.385081; batch adversarial loss: 0.450208\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415062; batch adversarial loss: 0.626880\n",
      "epoch 33; iter: 200; batch classifier loss: 0.293382; batch adversarial loss: 0.499033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.386312; batch adversarial loss: 0.412998\n",
      "epoch 34; iter: 200; batch classifier loss: 0.299230; batch adversarial loss: 0.305070\n",
      "epoch 35; iter: 0; batch classifier loss: 0.366412; batch adversarial loss: 0.346431\n",
      "epoch 35; iter: 200; batch classifier loss: 0.393724; batch adversarial loss: 0.375579\n",
      "epoch 36; iter: 0; batch classifier loss: 0.355130; batch adversarial loss: 0.494643\n",
      "epoch 36; iter: 200; batch classifier loss: 0.391385; batch adversarial loss: 0.353393\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438273; batch adversarial loss: 0.445454\n",
      "epoch 37; iter: 200; batch classifier loss: 0.342104; batch adversarial loss: 0.401857\n",
      "epoch 38; iter: 0; batch classifier loss: 0.369778; batch adversarial loss: 0.491475\n",
      "epoch 38; iter: 200; batch classifier loss: 0.389471; batch adversarial loss: 0.395390\n",
      "epoch 39; iter: 0; batch classifier loss: 0.352479; batch adversarial loss: 0.459620\n",
      "epoch 39; iter: 200; batch classifier loss: 0.375665; batch adversarial loss: 0.386094\n",
      "epoch 40; iter: 0; batch classifier loss: 0.384450; batch adversarial loss: 0.350682\n",
      "epoch 40; iter: 200; batch classifier loss: 0.374202; batch adversarial loss: 0.446486\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385293; batch adversarial loss: 0.436381\n",
      "epoch 41; iter: 200; batch classifier loss: 0.340787; batch adversarial loss: 0.468398\n",
      "epoch 42; iter: 0; batch classifier loss: 0.254057; batch adversarial loss: 0.308483\n",
      "epoch 42; iter: 200; batch classifier loss: 0.367468; batch adversarial loss: 0.369393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384060; batch adversarial loss: 0.339156\n",
      "epoch 43; iter: 200; batch classifier loss: 0.304846; batch adversarial loss: 0.440535\n",
      "epoch 44; iter: 0; batch classifier loss: 0.363531; batch adversarial loss: 0.452695\n",
      "epoch 44; iter: 200; batch classifier loss: 0.286435; batch adversarial loss: 0.413908\n",
      "epoch 45; iter: 0; batch classifier loss: 0.323493; batch adversarial loss: 0.366018\n",
      "epoch 45; iter: 200; batch classifier loss: 0.359928; batch adversarial loss: 0.467817\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453511; batch adversarial loss: 0.476765\n",
      "epoch 46; iter: 200; batch classifier loss: 0.308322; batch adversarial loss: 0.379928\n",
      "epoch 47; iter: 0; batch classifier loss: 0.374495; batch adversarial loss: 0.352969\n",
      "epoch 47; iter: 200; batch classifier loss: 0.383264; batch adversarial loss: 0.514332\n",
      "epoch 48; iter: 0; batch classifier loss: 0.312525; batch adversarial loss: 0.372608\n",
      "epoch 48; iter: 200; batch classifier loss: 0.347850; batch adversarial loss: 0.393158\n",
      "epoch 49; iter: 0; batch classifier loss: 0.342513; batch adversarial loss: 0.305753\n",
      "epoch 49; iter: 200; batch classifier loss: 0.371276; batch adversarial loss: 0.486780\n",
      "epoch 0; iter: 0; batch classifier loss: 99.054504; batch adversarial loss: 0.717609\n",
      "epoch 0; iter: 200; batch classifier loss: 3.508544; batch adversarial loss: 0.602340\n",
      "epoch 1; iter: 0; batch classifier loss: 13.513180; batch adversarial loss: 0.579103\n",
      "epoch 1; iter: 200; batch classifier loss: 1.635864; batch adversarial loss: 0.539457\n",
      "epoch 2; iter: 0; batch classifier loss: 4.322515; batch adversarial loss: 0.493643\n",
      "epoch 2; iter: 200; batch classifier loss: 3.470605; batch adversarial loss: 0.499818\n",
      "epoch 3; iter: 0; batch classifier loss: 1.637367; batch adversarial loss: 0.525854\n",
      "epoch 3; iter: 200; batch classifier loss: 1.112670; batch adversarial loss: 0.541439\n",
      "epoch 4; iter: 0; batch classifier loss: 0.718602; batch adversarial loss: 0.413169\n",
      "epoch 4; iter: 200; batch classifier loss: 1.086701; batch adversarial loss: 0.456100\n",
      "epoch 5; iter: 0; batch classifier loss: 0.529883; batch adversarial loss: 0.456333\n",
      "epoch 5; iter: 200; batch classifier loss: 0.741707; batch adversarial loss: 0.432992\n",
      "epoch 6; iter: 0; batch classifier loss: 0.958628; batch adversarial loss: 0.353194\n",
      "epoch 6; iter: 200; batch classifier loss: 1.148478; batch adversarial loss: 0.499528\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469879; batch adversarial loss: 0.417335\n",
      "epoch 7; iter: 200; batch classifier loss: 0.478285; batch adversarial loss: 0.504236\n",
      "epoch 8; iter: 0; batch classifier loss: 0.537847; batch adversarial loss: 0.415838\n",
      "epoch 8; iter: 200; batch classifier loss: 0.465649; batch adversarial loss: 0.378875\n",
      "epoch 9; iter: 0; batch classifier loss: 0.396394; batch adversarial loss: 0.414216\n",
      "epoch 9; iter: 200; batch classifier loss: 0.398921; batch adversarial loss: 0.391965\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386522; batch adversarial loss: 0.433050\n",
      "epoch 10; iter: 200; batch classifier loss: 0.486552; batch adversarial loss: 0.397827\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488940; batch adversarial loss: 0.422238\n",
      "epoch 11; iter: 200; batch classifier loss: 0.447368; batch adversarial loss: 0.511820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.356442; batch adversarial loss: 0.310134\n",
      "epoch 12; iter: 200; batch classifier loss: 0.361400; batch adversarial loss: 0.461583\n",
      "epoch 13; iter: 0; batch classifier loss: 0.356377; batch adversarial loss: 0.391918\n",
      "epoch 13; iter: 200; batch classifier loss: 0.376358; batch adversarial loss: 0.337180\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367395; batch adversarial loss: 0.365040\n",
      "epoch 14; iter: 200; batch classifier loss: 0.277593; batch adversarial loss: 0.466882\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331106; batch adversarial loss: 0.411169\n",
      "epoch 15; iter: 200; batch classifier loss: 0.352916; batch adversarial loss: 0.331811\n",
      "epoch 16; iter: 0; batch classifier loss: 0.373291; batch adversarial loss: 0.376958\n",
      "epoch 16; iter: 200; batch classifier loss: 0.379315; batch adversarial loss: 0.474223\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459348; batch adversarial loss: 0.473106\n",
      "epoch 17; iter: 200; batch classifier loss: 0.370155; batch adversarial loss: 0.444535\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304762; batch adversarial loss: 0.474124\n",
      "epoch 18; iter: 200; batch classifier loss: 0.332422; batch adversarial loss: 0.504885\n",
      "epoch 19; iter: 0; batch classifier loss: 0.399371; batch adversarial loss: 0.460202\n",
      "epoch 19; iter: 200; batch classifier loss: 0.361234; batch adversarial loss: 0.335816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.346831; batch adversarial loss: 0.286575\n",
      "epoch 20; iter: 200; batch classifier loss: 0.319106; batch adversarial loss: 0.442156\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319626; batch adversarial loss: 0.447414\n",
      "epoch 21; iter: 200; batch classifier loss: 0.401313; batch adversarial loss: 0.334492\n",
      "epoch 22; iter: 0; batch classifier loss: 0.338404; batch adversarial loss: 0.453559\n",
      "epoch 22; iter: 200; batch classifier loss: 0.346601; batch adversarial loss: 0.310141\n",
      "epoch 23; iter: 0; batch classifier loss: 0.325039; batch adversarial loss: 0.308502\n",
      "epoch 23; iter: 200; batch classifier loss: 0.251167; batch adversarial loss: 0.429441\n",
      "epoch 24; iter: 0; batch classifier loss: 0.321604; batch adversarial loss: 0.372719\n",
      "epoch 24; iter: 200; batch classifier loss: 0.329532; batch adversarial loss: 0.372504\n",
      "epoch 25; iter: 0; batch classifier loss: 0.291696; batch adversarial loss: 0.367985\n",
      "epoch 25; iter: 200; batch classifier loss: 0.249818; batch adversarial loss: 0.503548\n",
      "epoch 26; iter: 0; batch classifier loss: 0.353435; batch adversarial loss: 0.435509\n",
      "epoch 26; iter: 200; batch classifier loss: 0.376777; batch adversarial loss: 0.389063\n",
      "epoch 27; iter: 0; batch classifier loss: 0.347110; batch adversarial loss: 0.443208\n",
      "epoch 27; iter: 200; batch classifier loss: 0.318302; batch adversarial loss: 0.417119\n",
      "epoch 28; iter: 0; batch classifier loss: 0.321831; batch adversarial loss: 0.411018\n",
      "epoch 28; iter: 200; batch classifier loss: 0.380145; batch adversarial loss: 0.448942\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322288; batch adversarial loss: 0.439344\n",
      "epoch 29; iter: 200; batch classifier loss: 0.297847; batch adversarial loss: 0.305675\n",
      "epoch 30; iter: 0; batch classifier loss: 0.283009; batch adversarial loss: 0.441250\n",
      "epoch 30; iter: 200; batch classifier loss: 0.378874; batch adversarial loss: 0.418548\n",
      "epoch 31; iter: 0; batch classifier loss: 0.308897; batch adversarial loss: 0.468823\n",
      "epoch 31; iter: 200; batch classifier loss: 0.265364; batch adversarial loss: 0.380520\n",
      "epoch 32; iter: 0; batch classifier loss: 0.324022; batch adversarial loss: 0.302281\n",
      "epoch 32; iter: 200; batch classifier loss: 0.297575; batch adversarial loss: 0.442540\n",
      "epoch 33; iter: 0; batch classifier loss: 0.316166; batch adversarial loss: 0.365780\n",
      "epoch 33; iter: 200; batch classifier loss: 0.374717; batch adversarial loss: 0.463700\n",
      "epoch 34; iter: 0; batch classifier loss: 0.304413; batch adversarial loss: 0.502223\n",
      "epoch 34; iter: 200; batch classifier loss: 0.376668; batch adversarial loss: 0.437043\n",
      "epoch 35; iter: 0; batch classifier loss: 0.316685; batch adversarial loss: 0.455493\n",
      "epoch 35; iter: 200; batch classifier loss: 0.284686; batch adversarial loss: 0.483401\n",
      "epoch 36; iter: 0; batch classifier loss: 0.354678; batch adversarial loss: 0.395053\n",
      "epoch 36; iter: 200; batch classifier loss: 0.308678; batch adversarial loss: 0.405048\n",
      "epoch 37; iter: 0; batch classifier loss: 0.294886; batch adversarial loss: 0.452845\n",
      "epoch 37; iter: 200; batch classifier loss: 0.390478; batch adversarial loss: 0.398133\n",
      "epoch 38; iter: 0; batch classifier loss: 0.314815; batch adversarial loss: 0.373246\n",
      "epoch 38; iter: 200; batch classifier loss: 0.337255; batch adversarial loss: 0.501820\n",
      "epoch 39; iter: 0; batch classifier loss: 0.326268; batch adversarial loss: 0.408069\n",
      "epoch 39; iter: 200; batch classifier loss: 0.419726; batch adversarial loss: 0.498709\n",
      "epoch 40; iter: 0; batch classifier loss: 0.266484; batch adversarial loss: 0.405187\n",
      "epoch 40; iter: 200; batch classifier loss: 0.324516; batch adversarial loss: 0.499219\n",
      "epoch 41; iter: 0; batch classifier loss: 0.332148; batch adversarial loss: 0.379523\n",
      "epoch 41; iter: 200; batch classifier loss: 0.436428; batch adversarial loss: 0.309320\n",
      "epoch 42; iter: 0; batch classifier loss: 0.327100; batch adversarial loss: 0.347469\n",
      "epoch 42; iter: 200; batch classifier loss: 0.376994; batch adversarial loss: 0.480862\n",
      "epoch 43; iter: 0; batch classifier loss: 0.346557; batch adversarial loss: 0.447640\n",
      "epoch 43; iter: 200; batch classifier loss: 0.409260; batch adversarial loss: 0.449679\n",
      "epoch 44; iter: 0; batch classifier loss: 0.301707; batch adversarial loss: 0.461461\n",
      "epoch 44; iter: 200; batch classifier loss: 0.331214; batch adversarial loss: 0.407493\n",
      "epoch 45; iter: 0; batch classifier loss: 0.295278; batch adversarial loss: 0.387421\n",
      "epoch 45; iter: 200; batch classifier loss: 0.366196; batch adversarial loss: 0.418118\n",
      "epoch 46; iter: 0; batch classifier loss: 0.336624; batch adversarial loss: 0.435766\n",
      "epoch 46; iter: 200; batch classifier loss: 0.246270; batch adversarial loss: 0.350967\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483681; batch adversarial loss: 0.419198\n",
      "epoch 47; iter: 200; batch classifier loss: 0.396016; batch adversarial loss: 0.431286\n",
      "epoch 48; iter: 0; batch classifier loss: 0.348249; batch adversarial loss: 0.377376\n",
      "epoch 48; iter: 200; batch classifier loss: 0.327635; batch adversarial loss: 0.420500\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384668; batch adversarial loss: 0.434110\n",
      "epoch 49; iter: 200; batch classifier loss: 0.365312; batch adversarial loss: 0.512772\n",
      "epoch 0; iter: 0; batch classifier loss: 40.021332; batch adversarial loss: 0.638101\n",
      "epoch 0; iter: 200; batch classifier loss: 11.002928; batch adversarial loss: 0.571932\n",
      "epoch 1; iter: 0; batch classifier loss: 7.359201; batch adversarial loss: 0.552837\n",
      "epoch 1; iter: 200; batch classifier loss: 9.322254; batch adversarial loss: 0.500753\n",
      "epoch 2; iter: 0; batch classifier loss: 13.648655; batch adversarial loss: 0.501200\n",
      "epoch 2; iter: 200; batch classifier loss: 2.065748; batch adversarial loss: 0.433317\n",
      "epoch 3; iter: 0; batch classifier loss: 2.584539; batch adversarial loss: 0.444172\n",
      "epoch 3; iter: 200; batch classifier loss: 1.121790; batch adversarial loss: 0.353711\n",
      "epoch 4; iter: 0; batch classifier loss: 2.834104; batch adversarial loss: 0.405588\n",
      "epoch 4; iter: 200; batch classifier loss: 1.503394; batch adversarial loss: 0.525721\n",
      "epoch 5; iter: 0; batch classifier loss: 1.119143; batch adversarial loss: 0.389237\n",
      "epoch 5; iter: 200; batch classifier loss: 1.164802; batch adversarial loss: 0.352383\n",
      "epoch 6; iter: 0; batch classifier loss: 0.727985; batch adversarial loss: 0.408935\n",
      "epoch 6; iter: 200; batch classifier loss: 0.688511; batch adversarial loss: 0.408058\n",
      "epoch 7; iter: 0; batch classifier loss: 0.603329; batch adversarial loss: 0.458466\n",
      "epoch 7; iter: 200; batch classifier loss: 0.512829; batch adversarial loss: 0.429487\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507608; batch adversarial loss: 0.467747\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401270; batch adversarial loss: 0.360385\n",
      "epoch 9; iter: 0; batch classifier loss: 0.397442; batch adversarial loss: 0.314507\n",
      "epoch 9; iter: 200; batch classifier loss: 0.411359; batch adversarial loss: 0.426912\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426883; batch adversarial loss: 0.385247\n",
      "epoch 10; iter: 200; batch classifier loss: 0.293306; batch adversarial loss: 0.475536\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429912; batch adversarial loss: 0.438162\n",
      "epoch 11; iter: 200; batch classifier loss: 0.367929; batch adversarial loss: 0.367677\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402258; batch adversarial loss: 0.511758\n",
      "epoch 12; iter: 200; batch classifier loss: 0.335317; batch adversarial loss: 0.335347\n",
      "epoch 13; iter: 0; batch classifier loss: 0.358690; batch adversarial loss: 0.433442\n",
      "epoch 13; iter: 200; batch classifier loss: 0.655250; batch adversarial loss: 0.414383\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518559; batch adversarial loss: 0.302808\n",
      "epoch 14; iter: 200; batch classifier loss: 0.421200; batch adversarial loss: 0.485905\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386318; batch adversarial loss: 0.403156\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333743; batch adversarial loss: 0.472367\n",
      "epoch 16; iter: 0; batch classifier loss: 0.278775; batch adversarial loss: 0.447591\n",
      "epoch 16; iter: 200; batch classifier loss: 0.366108; batch adversarial loss: 0.410510\n",
      "epoch 17; iter: 0; batch classifier loss: 0.281994; batch adversarial loss: 0.419673\n",
      "epoch 17; iter: 200; batch classifier loss: 0.371572; batch adversarial loss: 0.416661\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362835; batch adversarial loss: 0.423530\n",
      "epoch 18; iter: 200; batch classifier loss: 0.349706; batch adversarial loss: 0.346026\n",
      "epoch 19; iter: 0; batch classifier loss: 0.262355; batch adversarial loss: 0.407687\n",
      "epoch 19; iter: 200; batch classifier loss: 0.346200; batch adversarial loss: 0.468681\n",
      "epoch 20; iter: 0; batch classifier loss: 0.306862; batch adversarial loss: 0.433551\n",
      "epoch 20; iter: 200; batch classifier loss: 0.376066; batch adversarial loss: 0.406124\n",
      "epoch 21; iter: 0; batch classifier loss: 0.359247; batch adversarial loss: 0.542594\n",
      "epoch 21; iter: 200; batch classifier loss: 0.294841; batch adversarial loss: 0.448729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.314804; batch adversarial loss: 0.476673\n",
      "epoch 22; iter: 200; batch classifier loss: 0.323277; batch adversarial loss: 0.436005\n",
      "epoch 23; iter: 0; batch classifier loss: 0.296599; batch adversarial loss: 0.495214\n",
      "epoch 23; iter: 200; batch classifier loss: 0.381497; batch adversarial loss: 0.333930\n",
      "epoch 24; iter: 0; batch classifier loss: 0.342502; batch adversarial loss: 0.440660\n",
      "epoch 24; iter: 200; batch classifier loss: 0.239163; batch adversarial loss: 0.375720\n",
      "epoch 25; iter: 0; batch classifier loss: 0.415110; batch adversarial loss: 0.411038\n",
      "epoch 25; iter: 200; batch classifier loss: 0.299292; batch adversarial loss: 0.353466\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352732; batch adversarial loss: 0.349743\n",
      "epoch 26; iter: 200; batch classifier loss: 0.339186; batch adversarial loss: 0.386021\n",
      "epoch 27; iter: 0; batch classifier loss: 0.372391; batch adversarial loss: 0.405169\n",
      "epoch 27; iter: 200; batch classifier loss: 0.369340; batch adversarial loss: 0.510178\n",
      "epoch 28; iter: 0; batch classifier loss: 0.332185; batch adversarial loss: 0.397644\n",
      "epoch 28; iter: 200; batch classifier loss: 0.375045; batch adversarial loss: 0.359435\n",
      "epoch 29; iter: 0; batch classifier loss: 0.335352; batch adversarial loss: 0.301416\n",
      "epoch 29; iter: 200; batch classifier loss: 0.371359; batch adversarial loss: 0.350742\n",
      "epoch 30; iter: 0; batch classifier loss: 0.398391; batch adversarial loss: 0.377047\n",
      "epoch 30; iter: 200; batch classifier loss: 0.297477; batch adversarial loss: 0.523571\n",
      "epoch 31; iter: 0; batch classifier loss: 0.328066; batch adversarial loss: 0.426975\n",
      "epoch 31; iter: 200; batch classifier loss: 0.452756; batch adversarial loss: 0.490643\n",
      "epoch 32; iter: 0; batch classifier loss: 0.367788; batch adversarial loss: 0.519012\n",
      "epoch 32; iter: 200; batch classifier loss: 0.317131; batch adversarial loss: 0.396631\n",
      "epoch 33; iter: 0; batch classifier loss: 0.378764; batch adversarial loss: 0.506086\n",
      "epoch 33; iter: 200; batch classifier loss: 0.243412; batch adversarial loss: 0.573892\n",
      "epoch 34; iter: 0; batch classifier loss: 0.292153; batch adversarial loss: 0.415615\n",
      "epoch 34; iter: 200; batch classifier loss: 0.342070; batch adversarial loss: 0.427055\n",
      "epoch 35; iter: 0; batch classifier loss: 0.367270; batch adversarial loss: 0.349764\n",
      "epoch 35; iter: 200; batch classifier loss: 0.478377; batch adversarial loss: 0.421048\n",
      "epoch 36; iter: 0; batch classifier loss: 0.308515; batch adversarial loss: 0.343673\n",
      "epoch 36; iter: 200; batch classifier loss: 0.338330; batch adversarial loss: 0.426094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.287566; batch adversarial loss: 0.434894\n",
      "epoch 37; iter: 200; batch classifier loss: 0.558200; batch adversarial loss: 0.464830\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481936; batch adversarial loss: 0.392414\n",
      "epoch 38; iter: 200; batch classifier loss: 0.473578; batch adversarial loss: 0.389196\n",
      "epoch 39; iter: 0; batch classifier loss: 0.364981; batch adversarial loss: 0.368937\n",
      "epoch 39; iter: 200; batch classifier loss: 0.320606; batch adversarial loss: 0.494304\n",
      "epoch 40; iter: 0; batch classifier loss: 0.257170; batch adversarial loss: 0.352212\n",
      "epoch 40; iter: 200; batch classifier loss: 0.330286; batch adversarial loss: 0.407662\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450766; batch adversarial loss: 0.383764\n",
      "epoch 41; iter: 200; batch classifier loss: 0.334403; batch adversarial loss: 0.331786\n",
      "epoch 42; iter: 0; batch classifier loss: 0.408818; batch adversarial loss: 0.456093\n",
      "epoch 42; iter: 200; batch classifier loss: 0.327472; batch adversarial loss: 0.402482\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386872; batch adversarial loss: 0.387946\n",
      "epoch 43; iter: 200; batch classifier loss: 0.386835; batch adversarial loss: 0.453513\n",
      "epoch 44; iter: 0; batch classifier loss: 0.385236; batch adversarial loss: 0.381977\n",
      "epoch 44; iter: 200; batch classifier loss: 0.389666; batch adversarial loss: 0.450621\n",
      "epoch 45; iter: 0; batch classifier loss: 0.371603; batch adversarial loss: 0.496776\n",
      "epoch 45; iter: 200; batch classifier loss: 0.436237; batch adversarial loss: 0.456178\n",
      "epoch 46; iter: 0; batch classifier loss: 0.275923; batch adversarial loss: 0.376278\n",
      "epoch 46; iter: 200; batch classifier loss: 0.345716; batch adversarial loss: 0.496610\n",
      "epoch 47; iter: 0; batch classifier loss: 0.317295; batch adversarial loss: 0.490848\n",
      "epoch 47; iter: 200; batch classifier loss: 0.265861; batch adversarial loss: 0.404281\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404388; batch adversarial loss: 0.386810\n",
      "epoch 48; iter: 200; batch classifier loss: 0.320108; batch adversarial loss: 0.445545\n",
      "epoch 49; iter: 0; batch classifier loss: 0.271451; batch adversarial loss: 0.491632\n",
      "epoch 49; iter: 200; batch classifier loss: 0.481488; batch adversarial loss: 0.376618\n",
      "epoch 0; iter: 0; batch classifier loss: 37.786804; batch adversarial loss: 0.531614\n",
      "epoch 0; iter: 200; batch classifier loss: 5.788207; batch adversarial loss: 0.595079\n",
      "epoch 1; iter: 0; batch classifier loss: 7.386385; batch adversarial loss: 0.583551\n",
      "epoch 1; iter: 200; batch classifier loss: 2.274577; batch adversarial loss: 0.525105\n",
      "epoch 2; iter: 0; batch classifier loss: 1.299991; batch adversarial loss: 0.489937\n",
      "epoch 2; iter: 200; batch classifier loss: 2.556873; batch adversarial loss: 0.465629\n",
      "epoch 3; iter: 0; batch classifier loss: 2.653563; batch adversarial loss: 0.437658\n",
      "epoch 3; iter: 200; batch classifier loss: 0.972116; batch adversarial loss: 0.426655\n",
      "epoch 4; iter: 0; batch classifier loss: 0.804786; batch adversarial loss: 0.431530\n",
      "epoch 4; iter: 200; batch classifier loss: 1.367242; batch adversarial loss: 0.482636\n",
      "epoch 5; iter: 0; batch classifier loss: 0.521048; batch adversarial loss: 0.399176\n",
      "epoch 5; iter: 200; batch classifier loss: 0.767985; batch adversarial loss: 0.530041\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395417; batch adversarial loss: 0.451184\n",
      "epoch 6; iter: 200; batch classifier loss: 0.378090; batch adversarial loss: 0.383715\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454269; batch adversarial loss: 0.479946\n",
      "epoch 7; iter: 200; batch classifier loss: 0.476646; batch adversarial loss: 0.468331\n",
      "epoch 8; iter: 0; batch classifier loss: 1.710235; batch adversarial loss: 0.422946\n",
      "epoch 8; iter: 200; batch classifier loss: 0.443084; batch adversarial loss: 0.402890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435950; batch adversarial loss: 0.453240\n",
      "epoch 9; iter: 200; batch classifier loss: 0.346622; batch adversarial loss: 0.403488\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375561; batch adversarial loss: 0.487908\n",
      "epoch 10; iter: 200; batch classifier loss: 0.428546; batch adversarial loss: 0.368881\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403129; batch adversarial loss: 0.441187\n",
      "epoch 11; iter: 200; batch classifier loss: 0.382749; batch adversarial loss: 0.398720\n",
      "epoch 12; iter: 0; batch classifier loss: 0.397930; batch adversarial loss: 0.453843\n",
      "epoch 12; iter: 200; batch classifier loss: 0.314784; batch adversarial loss: 0.417614\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302509; batch adversarial loss: 0.386566\n",
      "epoch 13; iter: 200; batch classifier loss: 0.392081; batch adversarial loss: 0.395325\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394339; batch adversarial loss: 0.400506\n",
      "epoch 14; iter: 200; batch classifier loss: 0.309797; batch adversarial loss: 0.388194\n",
      "epoch 15; iter: 0; batch classifier loss: 0.321689; batch adversarial loss: 0.471439\n",
      "epoch 15; iter: 200; batch classifier loss: 0.319403; batch adversarial loss: 0.413702\n",
      "epoch 16; iter: 0; batch classifier loss: 0.395529; batch adversarial loss: 0.437849\n",
      "epoch 16; iter: 200; batch classifier loss: 0.322824; batch adversarial loss: 0.422813\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390657; batch adversarial loss: 0.494639\n",
      "epoch 17; iter: 200; batch classifier loss: 0.473574; batch adversarial loss: 0.344984\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332790; batch adversarial loss: 0.475873\n",
      "epoch 18; iter: 200; batch classifier loss: 0.367243; batch adversarial loss: 0.381094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.349092; batch adversarial loss: 0.283041\n",
      "epoch 19; iter: 200; batch classifier loss: 0.242058; batch adversarial loss: 0.390195\n",
      "epoch 20; iter: 0; batch classifier loss: 0.293756; batch adversarial loss: 0.488107\n",
      "epoch 20; iter: 200; batch classifier loss: 0.251755; batch adversarial loss: 0.445712\n",
      "epoch 21; iter: 0; batch classifier loss: 0.302397; batch adversarial loss: 0.500315\n",
      "epoch 21; iter: 200; batch classifier loss: 0.330664; batch adversarial loss: 0.517623\n",
      "epoch 22; iter: 0; batch classifier loss: 0.300254; batch adversarial loss: 0.368815\n",
      "epoch 22; iter: 200; batch classifier loss: 0.351220; batch adversarial loss: 0.413589\n",
      "epoch 23; iter: 0; batch classifier loss: 0.263289; batch adversarial loss: 0.405378\n",
      "epoch 23; iter: 200; batch classifier loss: 0.320864; batch adversarial loss: 0.435746\n",
      "epoch 24; iter: 0; batch classifier loss: 0.289246; batch adversarial loss: 0.509922\n",
      "epoch 24; iter: 200; batch classifier loss: 0.347057; batch adversarial loss: 0.541106\n",
      "epoch 25; iter: 0; batch classifier loss: 0.287210; batch adversarial loss: 0.376464\n",
      "epoch 25; iter: 200; batch classifier loss: 0.348955; batch adversarial loss: 0.372351\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346199; batch adversarial loss: 0.375020\n",
      "epoch 26; iter: 200; batch classifier loss: 0.357624; batch adversarial loss: 0.294993\n",
      "epoch 27; iter: 0; batch classifier loss: 0.254775; batch adversarial loss: 0.467800\n",
      "epoch 27; iter: 200; batch classifier loss: 0.362650; batch adversarial loss: 0.422264\n",
      "epoch 28; iter: 0; batch classifier loss: 0.324136; batch adversarial loss: 0.399870\n",
      "epoch 28; iter: 200; batch classifier loss: 0.316506; batch adversarial loss: 0.499211\n",
      "epoch 29; iter: 0; batch classifier loss: 0.372381; batch adversarial loss: 0.400711\n",
      "epoch 29; iter: 200; batch classifier loss: 0.331776; batch adversarial loss: 0.426900\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324720; batch adversarial loss: 0.381203\n",
      "epoch 30; iter: 200; batch classifier loss: 0.343416; batch adversarial loss: 0.424240\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320365; batch adversarial loss: 0.348087\n",
      "epoch 31; iter: 200; batch classifier loss: 0.415252; batch adversarial loss: 0.493173\n",
      "epoch 32; iter: 0; batch classifier loss: 0.341416; batch adversarial loss: 0.418200\n",
      "epoch 32; iter: 200; batch classifier loss: 0.370335; batch adversarial loss: 0.456544\n",
      "epoch 33; iter: 0; batch classifier loss: 0.461695; batch adversarial loss: 0.442237\n",
      "epoch 33; iter: 200; batch classifier loss: 0.409990; batch adversarial loss: 0.441152\n",
      "epoch 34; iter: 0; batch classifier loss: 0.356471; batch adversarial loss: 0.414281\n",
      "epoch 34; iter: 200; batch classifier loss: 0.324045; batch adversarial loss: 0.365256\n",
      "epoch 35; iter: 0; batch classifier loss: 0.344347; batch adversarial loss: 0.342967\n",
      "epoch 35; iter: 200; batch classifier loss: 0.409300; batch adversarial loss: 0.518242\n",
      "epoch 36; iter: 0; batch classifier loss: 0.500124; batch adversarial loss: 0.426836\n",
      "epoch 36; iter: 200; batch classifier loss: 0.308004; batch adversarial loss: 0.434497\n",
      "epoch 37; iter: 0; batch classifier loss: 0.317667; batch adversarial loss: 0.407467\n",
      "epoch 37; iter: 200; batch classifier loss: 0.292365; batch adversarial loss: 0.386174\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386005; batch adversarial loss: 0.356154\n",
      "epoch 38; iter: 200; batch classifier loss: 0.378837; batch adversarial loss: 0.387062\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421543; batch adversarial loss: 0.464620\n",
      "epoch 39; iter: 200; batch classifier loss: 0.346675; batch adversarial loss: 0.401353\n",
      "epoch 40; iter: 0; batch classifier loss: 0.310460; batch adversarial loss: 0.364349\n",
      "epoch 40; iter: 200; batch classifier loss: 0.326969; batch adversarial loss: 0.398802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.289056; batch adversarial loss: 0.377763\n",
      "epoch 41; iter: 200; batch classifier loss: 0.286906; batch adversarial loss: 0.457183\n",
      "epoch 42; iter: 0; batch classifier loss: 0.302778; batch adversarial loss: 0.395776\n",
      "epoch 42; iter: 200; batch classifier loss: 0.316616; batch adversarial loss: 0.399596\n",
      "epoch 43; iter: 0; batch classifier loss: 0.327496; batch adversarial loss: 0.389838\n",
      "epoch 43; iter: 200; batch classifier loss: 0.362349; batch adversarial loss: 0.462921\n",
      "epoch 44; iter: 0; batch classifier loss: 0.398130; batch adversarial loss: 0.438471\n",
      "epoch 44; iter: 200; batch classifier loss: 0.345179; batch adversarial loss: 0.403845\n",
      "epoch 45; iter: 0; batch classifier loss: 0.273702; batch adversarial loss: 0.470411\n",
      "epoch 45; iter: 200; batch classifier loss: 0.382674; batch adversarial loss: 0.493727\n",
      "epoch 46; iter: 0; batch classifier loss: 0.360935; batch adversarial loss: 0.369209\n",
      "epoch 46; iter: 200; batch classifier loss: 0.318354; batch adversarial loss: 0.447944\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418953; batch adversarial loss: 0.436450\n",
      "epoch 47; iter: 200; batch classifier loss: 0.345774; batch adversarial loss: 0.364510\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375739; batch adversarial loss: 0.413043\n",
      "epoch 48; iter: 200; batch classifier loss: 0.278385; batch adversarial loss: 0.401598\n",
      "epoch 49; iter: 0; batch classifier loss: 0.348863; batch adversarial loss: 0.573811\n",
      "epoch 49; iter: 200; batch classifier loss: 0.332855; batch adversarial loss: 0.447470\n",
      "epoch 0; iter: 0; batch classifier loss: 50.476849; batch adversarial loss: 0.930129\n",
      "epoch 0; iter: 200; batch classifier loss: 3.457010; batch adversarial loss: 0.880489\n",
      "epoch 1; iter: 0; batch classifier loss: 14.687272; batch adversarial loss: 0.750314\n",
      "epoch 1; iter: 200; batch classifier loss: 5.237064; batch adversarial loss: 0.588383\n",
      "epoch 2; iter: 0; batch classifier loss: 8.669924; batch adversarial loss: 0.505066\n",
      "epoch 2; iter: 200; batch classifier loss: 7.057701; batch adversarial loss: 0.476048\n",
      "epoch 3; iter: 0; batch classifier loss: 4.063536; batch adversarial loss: 0.450734\n",
      "epoch 3; iter: 200; batch classifier loss: 1.815563; batch adversarial loss: 0.438405\n",
      "epoch 4; iter: 0; batch classifier loss: 0.912748; batch adversarial loss: 0.428295\n",
      "epoch 4; iter: 200; batch classifier loss: 1.383429; batch adversarial loss: 0.444608\n",
      "epoch 5; iter: 0; batch classifier loss: 0.984169; batch adversarial loss: 0.331883\n",
      "epoch 5; iter: 200; batch classifier loss: 0.622866; batch adversarial loss: 0.433642\n",
      "epoch 6; iter: 0; batch classifier loss: 0.556251; batch adversarial loss: 0.365331\n",
      "epoch 6; iter: 200; batch classifier loss: 0.929765; batch adversarial loss: 0.395098\n",
      "epoch 7; iter: 0; batch classifier loss: 1.181131; batch adversarial loss: 0.369172\n",
      "epoch 7; iter: 200; batch classifier loss: 0.634755; batch adversarial loss: 0.354367\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598207; batch adversarial loss: 0.420278\n",
      "epoch 8; iter: 200; batch classifier loss: 0.447407; batch adversarial loss: 0.477798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.504294; batch adversarial loss: 0.391046\n",
      "epoch 9; iter: 200; batch classifier loss: 0.461283; batch adversarial loss: 0.344179\n",
      "epoch 10; iter: 0; batch classifier loss: 0.599831; batch adversarial loss: 0.408504\n",
      "epoch 10; iter: 200; batch classifier loss: 0.375054; batch adversarial loss: 0.452495\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499935; batch adversarial loss: 0.317075\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412943; batch adversarial loss: 0.477844\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461019; batch adversarial loss: 0.400430\n",
      "epoch 12; iter: 200; batch classifier loss: 0.341812; batch adversarial loss: 0.387357\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412553; batch adversarial loss: 0.352389\n",
      "epoch 13; iter: 200; batch classifier loss: 0.551320; batch adversarial loss: 0.370221\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352028; batch adversarial loss: 0.290871\n",
      "epoch 14; iter: 200; batch classifier loss: 0.490053; batch adversarial loss: 0.357113\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395676; batch adversarial loss: 0.380980\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380326; batch adversarial loss: 0.481568\n",
      "epoch 16; iter: 0; batch classifier loss: 0.307110; batch adversarial loss: 0.491339\n",
      "epoch 16; iter: 200; batch classifier loss: 0.410713; batch adversarial loss: 0.405834\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366192; batch adversarial loss: 0.443575\n",
      "epoch 17; iter: 200; batch classifier loss: 0.290629; batch adversarial loss: 0.399049\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350768; batch adversarial loss: 0.340828\n",
      "epoch 18; iter: 200; batch classifier loss: 0.376245; batch adversarial loss: 0.385379\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362368; batch adversarial loss: 0.472756\n",
      "epoch 19; iter: 200; batch classifier loss: 0.348732; batch adversarial loss: 0.442273\n",
      "epoch 20; iter: 0; batch classifier loss: 0.391096; batch adversarial loss: 0.470013\n",
      "epoch 20; iter: 200; batch classifier loss: 0.353644; batch adversarial loss: 0.400666\n",
      "epoch 21; iter: 0; batch classifier loss: 0.311894; batch adversarial loss: 0.529776\n",
      "epoch 21; iter: 200; batch classifier loss: 0.391338; batch adversarial loss: 0.367352\n",
      "epoch 22; iter: 0; batch classifier loss: 0.263999; batch adversarial loss: 0.323014\n",
      "epoch 22; iter: 200; batch classifier loss: 0.322131; batch adversarial loss: 0.372536\n",
      "epoch 23; iter: 0; batch classifier loss: 0.338740; batch adversarial loss: 0.352168\n",
      "epoch 23; iter: 200; batch classifier loss: 0.344244; batch adversarial loss: 0.469923\n",
      "epoch 24; iter: 0; batch classifier loss: 0.283948; batch adversarial loss: 0.360539\n",
      "epoch 24; iter: 200; batch classifier loss: 0.350811; batch adversarial loss: 0.428727\n",
      "epoch 25; iter: 0; batch classifier loss: 0.319365; batch adversarial loss: 0.565738\n",
      "epoch 25; iter: 200; batch classifier loss: 0.313461; batch adversarial loss: 0.420806\n",
      "epoch 26; iter: 0; batch classifier loss: 0.332624; batch adversarial loss: 0.419569\n",
      "epoch 26; iter: 200; batch classifier loss: 0.451422; batch adversarial loss: 0.331571\n",
      "epoch 27; iter: 0; batch classifier loss: 0.357141; batch adversarial loss: 0.373042\n",
      "epoch 27; iter: 200; batch classifier loss: 0.343796; batch adversarial loss: 0.381122\n",
      "epoch 28; iter: 0; batch classifier loss: 0.333268; batch adversarial loss: 0.415593\n",
      "epoch 28; iter: 200; batch classifier loss: 0.348586; batch adversarial loss: 0.340112\n",
      "epoch 29; iter: 0; batch classifier loss: 0.363802; batch adversarial loss: 0.375164\n",
      "epoch 29; iter: 200; batch classifier loss: 0.391056; batch adversarial loss: 0.386163\n",
      "epoch 30; iter: 0; batch classifier loss: 0.293480; batch adversarial loss: 0.409934\n",
      "epoch 30; iter: 200; batch classifier loss: 0.314358; batch adversarial loss: 0.341713\n",
      "epoch 31; iter: 0; batch classifier loss: 0.351046; batch adversarial loss: 0.380191\n",
      "epoch 31; iter: 200; batch classifier loss: 0.357793; batch adversarial loss: 0.438108\n",
      "epoch 32; iter: 0; batch classifier loss: 0.356138; batch adversarial loss: 0.344428\n",
      "epoch 32; iter: 200; batch classifier loss: 0.307510; batch adversarial loss: 0.474624\n",
      "epoch 33; iter: 0; batch classifier loss: 0.291796; batch adversarial loss: 0.468240\n",
      "epoch 33; iter: 200; batch classifier loss: 0.334956; batch adversarial loss: 0.529321\n",
      "epoch 34; iter: 0; batch classifier loss: 0.360769; batch adversarial loss: 0.425218\n",
      "epoch 34; iter: 200; batch classifier loss: 0.328629; batch adversarial loss: 0.396627\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400112; batch adversarial loss: 0.466665\n",
      "epoch 35; iter: 200; batch classifier loss: 0.324622; batch adversarial loss: 0.389807\n",
      "epoch 36; iter: 0; batch classifier loss: 0.341179; batch adversarial loss: 0.350050\n",
      "epoch 36; iter: 200; batch classifier loss: 0.333272; batch adversarial loss: 0.415100\n",
      "epoch 37; iter: 0; batch classifier loss: 0.335912; batch adversarial loss: 0.340858\n",
      "epoch 37; iter: 200; batch classifier loss: 0.464022; batch adversarial loss: 0.370976\n",
      "epoch 38; iter: 0; batch classifier loss: 0.333468; batch adversarial loss: 0.297646\n",
      "epoch 38; iter: 200; batch classifier loss: 0.381123; batch adversarial loss: 0.300123\n",
      "epoch 39; iter: 0; batch classifier loss: 0.414508; batch adversarial loss: 0.361456\n",
      "epoch 39; iter: 200; batch classifier loss: 0.396457; batch adversarial loss: 0.497759\n",
      "epoch 40; iter: 0; batch classifier loss: 0.461927; batch adversarial loss: 0.289905\n",
      "epoch 40; iter: 200; batch classifier loss: 0.475241; batch adversarial loss: 0.410540\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408556; batch adversarial loss: 0.386506\n",
      "epoch 41; iter: 200; batch classifier loss: 0.353212; batch adversarial loss: 0.432957\n",
      "epoch 42; iter: 0; batch classifier loss: 0.305612; batch adversarial loss: 0.359089\n",
      "epoch 42; iter: 200; batch classifier loss: 0.404023; batch adversarial loss: 0.418521\n",
      "epoch 43; iter: 0; batch classifier loss: 0.384190; batch adversarial loss: 0.427342\n",
      "epoch 43; iter: 200; batch classifier loss: 0.386437; batch adversarial loss: 0.390677\n",
      "epoch 44; iter: 0; batch classifier loss: 0.344224; batch adversarial loss: 0.416798\n",
      "epoch 44; iter: 200; batch classifier loss: 0.360284; batch adversarial loss: 0.508017\n",
      "epoch 45; iter: 0; batch classifier loss: 0.505235; batch adversarial loss: 0.420679\n",
      "epoch 45; iter: 200; batch classifier loss: 0.343462; batch adversarial loss: 0.445449\n",
      "epoch 46; iter: 0; batch classifier loss: 0.336594; batch adversarial loss: 0.347219\n",
      "epoch 46; iter: 200; batch classifier loss: 0.511827; batch adversarial loss: 0.384396\n",
      "epoch 47; iter: 0; batch classifier loss: 0.434799; batch adversarial loss: 0.375937\n",
      "epoch 47; iter: 200; batch classifier loss: 0.429917; batch adversarial loss: 0.418071\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418116; batch adversarial loss: 0.530398\n",
      "epoch 48; iter: 200; batch classifier loss: 0.416392; batch adversarial loss: 0.352475\n",
      "epoch 49; iter: 0; batch classifier loss: 0.407403; batch adversarial loss: 0.474399\n",
      "epoch 49; iter: 200; batch classifier loss: 0.451623; batch adversarial loss: 0.376364\n",
      "epoch 0; iter: 0; batch classifier loss: 108.779076; batch adversarial loss: 0.885340\n",
      "epoch 0; iter: 200; batch classifier loss: 9.131733; batch adversarial loss: 0.869359\n",
      "epoch 1; iter: 0; batch classifier loss: 5.523292; batch adversarial loss: 0.727001\n",
      "epoch 1; iter: 200; batch classifier loss: 6.000015; batch adversarial loss: 0.597537\n",
      "epoch 2; iter: 0; batch classifier loss: 5.329806; batch adversarial loss: 0.564369\n",
      "epoch 2; iter: 200; batch classifier loss: 2.392124; batch adversarial loss: 0.491414\n",
      "epoch 3; iter: 0; batch classifier loss: 1.812518; batch adversarial loss: 0.459047\n",
      "epoch 3; iter: 200; batch classifier loss: 1.700285; batch adversarial loss: 0.437904\n",
      "epoch 4; iter: 0; batch classifier loss: 3.162700; batch adversarial loss: 0.466182\n",
      "epoch 4; iter: 200; batch classifier loss: 1.876014; batch adversarial loss: 0.388756\n",
      "epoch 5; iter: 0; batch classifier loss: 1.074928; batch adversarial loss: 0.483448\n",
      "epoch 5; iter: 200; batch classifier loss: 1.107760; batch adversarial loss: 0.439823\n",
      "epoch 6; iter: 0; batch classifier loss: 0.721308; batch adversarial loss: 0.417901\n",
      "epoch 6; iter: 200; batch classifier loss: 1.075890; batch adversarial loss: 0.432487\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566255; batch adversarial loss: 0.429422\n",
      "epoch 7; iter: 200; batch classifier loss: 0.443375; batch adversarial loss: 0.409538\n",
      "epoch 8; iter: 0; batch classifier loss: 0.358189; batch adversarial loss: 0.388037\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387272; batch adversarial loss: 0.504792\n",
      "epoch 9; iter: 0; batch classifier loss: 0.414678; batch adversarial loss: 0.353531\n",
      "epoch 9; iter: 200; batch classifier loss: 0.456514; batch adversarial loss: 0.402362\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366005; batch adversarial loss: 0.473748\n",
      "epoch 10; iter: 200; batch classifier loss: 0.401503; batch adversarial loss: 0.453361\n",
      "epoch 11; iter: 0; batch classifier loss: 0.437233; batch adversarial loss: 0.363017\n",
      "epoch 11; iter: 200; batch classifier loss: 0.288812; batch adversarial loss: 0.350615\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477513; batch adversarial loss: 0.520931\n",
      "epoch 12; iter: 200; batch classifier loss: 0.377397; batch adversarial loss: 0.422265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.386961; batch adversarial loss: 0.345432\n",
      "epoch 13; iter: 200; batch classifier loss: 0.393952; batch adversarial loss: 0.310024\n",
      "epoch 14; iter: 0; batch classifier loss: 0.331451; batch adversarial loss: 0.471285\n",
      "epoch 14; iter: 200; batch classifier loss: 0.340833; batch adversarial loss: 0.352359\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324053; batch adversarial loss: 0.395040\n",
      "epoch 15; iter: 200; batch classifier loss: 0.331990; batch adversarial loss: 0.483304\n",
      "epoch 16; iter: 0; batch classifier loss: 0.438613; batch adversarial loss: 0.372326\n",
      "epoch 16; iter: 200; batch classifier loss: 0.325359; batch adversarial loss: 0.316300\n",
      "epoch 17; iter: 0; batch classifier loss: 0.306735; batch adversarial loss: 0.399592\n",
      "epoch 17; iter: 200; batch classifier loss: 0.378260; batch adversarial loss: 0.439437\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350569; batch adversarial loss: 0.337646\n",
      "epoch 18; iter: 200; batch classifier loss: 0.406208; batch adversarial loss: 0.439094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.271120; batch adversarial loss: 0.318899\n",
      "epoch 19; iter: 200; batch classifier loss: 0.405335; batch adversarial loss: 0.369979\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440981; batch adversarial loss: 0.357248\n",
      "epoch 20; iter: 200; batch classifier loss: 0.245912; batch adversarial loss: 0.379131\n",
      "epoch 21; iter: 0; batch classifier loss: 0.394794; batch adversarial loss: 0.439830\n",
      "epoch 21; iter: 200; batch classifier loss: 0.296010; batch adversarial loss: 0.430420\n",
      "epoch 22; iter: 0; batch classifier loss: 0.298107; batch adversarial loss: 0.444010\n",
      "epoch 22; iter: 200; batch classifier loss: 0.259359; batch adversarial loss: 0.430932\n",
      "epoch 23; iter: 0; batch classifier loss: 0.296355; batch adversarial loss: 0.332780\n",
      "epoch 23; iter: 200; batch classifier loss: 0.347834; batch adversarial loss: 0.544329\n",
      "epoch 24; iter: 0; batch classifier loss: 0.381254; batch adversarial loss: 0.434111\n",
      "epoch 24; iter: 200; batch classifier loss: 0.338978; batch adversarial loss: 0.404850\n",
      "epoch 25; iter: 0; batch classifier loss: 0.324436; batch adversarial loss: 0.452601\n",
      "epoch 25; iter: 200; batch classifier loss: 0.305170; batch adversarial loss: 0.435747\n",
      "epoch 26; iter: 0; batch classifier loss: 0.372911; batch adversarial loss: 0.430953\n",
      "epoch 26; iter: 200; batch classifier loss: 0.303701; batch adversarial loss: 0.398150\n",
      "epoch 27; iter: 0; batch classifier loss: 0.374254; batch adversarial loss: 0.402030\n",
      "epoch 27; iter: 200; batch classifier loss: 0.402690; batch adversarial loss: 0.404705\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404272; batch adversarial loss: 0.344982\n",
      "epoch 28; iter: 200; batch classifier loss: 0.451062; batch adversarial loss: 0.454547\n",
      "epoch 29; iter: 0; batch classifier loss: 0.316268; batch adversarial loss: 0.421498\n",
      "epoch 29; iter: 200; batch classifier loss: 0.423738; batch adversarial loss: 0.455104\n",
      "epoch 30; iter: 0; batch classifier loss: 0.295030; batch adversarial loss: 0.412890\n",
      "epoch 30; iter: 200; batch classifier loss: 0.354711; batch adversarial loss: 0.330476\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315487; batch adversarial loss: 0.460365\n",
      "epoch 31; iter: 200; batch classifier loss: 0.275995; batch adversarial loss: 0.472969\n",
      "epoch 32; iter: 0; batch classifier loss: 0.373727; batch adversarial loss: 0.459367\n",
      "epoch 32; iter: 200; batch classifier loss: 0.279327; batch adversarial loss: 0.430454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.328140; batch adversarial loss: 0.408044\n",
      "epoch 33; iter: 200; batch classifier loss: 0.280277; batch adversarial loss: 0.379037\n",
      "epoch 34; iter: 0; batch classifier loss: 0.342223; batch adversarial loss: 0.323884\n",
      "epoch 34; iter: 200; batch classifier loss: 0.348525; batch adversarial loss: 0.325124\n",
      "epoch 35; iter: 0; batch classifier loss: 0.386702; batch adversarial loss: 0.372308\n",
      "epoch 35; iter: 200; batch classifier loss: 0.278800; batch adversarial loss: 0.425883\n",
      "epoch 36; iter: 0; batch classifier loss: 0.325161; batch adversarial loss: 0.374508\n",
      "epoch 36; iter: 200; batch classifier loss: 0.365753; batch adversarial loss: 0.330880\n",
      "epoch 37; iter: 0; batch classifier loss: 0.548990; batch adversarial loss: 0.370401\n",
      "epoch 37; iter: 200; batch classifier loss: 0.343022; batch adversarial loss: 0.370268\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476827; batch adversarial loss: 0.351766\n",
      "epoch 38; iter: 200; batch classifier loss: 0.447570; batch adversarial loss: 0.332929\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459944; batch adversarial loss: 0.414345\n",
      "epoch 39; iter: 200; batch classifier loss: 0.375504; batch adversarial loss: 0.347095\n",
      "epoch 40; iter: 0; batch classifier loss: 0.535373; batch adversarial loss: 0.391564\n",
      "epoch 40; iter: 200; batch classifier loss: 0.465115; batch adversarial loss: 0.455074\n",
      "epoch 41; iter: 0; batch classifier loss: 0.422253; batch adversarial loss: 0.346965\n",
      "epoch 41; iter: 200; batch classifier loss: 0.468570; batch adversarial loss: 0.427224\n",
      "epoch 42; iter: 0; batch classifier loss: 0.421189; batch adversarial loss: 0.383035\n",
      "epoch 42; iter: 200; batch classifier loss: 0.402875; batch adversarial loss: 0.491102\n",
      "epoch 43; iter: 0; batch classifier loss: 0.364805; batch adversarial loss: 0.477175\n",
      "epoch 43; iter: 200; batch classifier loss: 0.330964; batch adversarial loss: 0.394115\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414572; batch adversarial loss: 0.450953\n",
      "epoch 44; iter: 200; batch classifier loss: 0.496344; batch adversarial loss: 0.525020\n",
      "epoch 45; iter: 0; batch classifier loss: 0.525863; batch adversarial loss: 0.365523\n",
      "epoch 45; iter: 200; batch classifier loss: 0.462138; batch adversarial loss: 0.390532\n",
      "epoch 46; iter: 0; batch classifier loss: 0.435894; batch adversarial loss: 0.416158\n",
      "epoch 46; iter: 200; batch classifier loss: 0.484518; batch adversarial loss: 0.464908\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415320; batch adversarial loss: 0.404947\n",
      "epoch 47; iter: 200; batch classifier loss: 0.453155; batch adversarial loss: 0.462726\n",
      "epoch 48; iter: 0; batch classifier loss: 0.548470; batch adversarial loss: 0.380062\n",
      "epoch 48; iter: 200; batch classifier loss: 0.514503; batch adversarial loss: 0.333855\n",
      "epoch 49; iter: 0; batch classifier loss: 0.271928; batch adversarial loss: 0.444485\n",
      "epoch 49; iter: 200; batch classifier loss: 0.511436; batch adversarial loss: 0.421300\n",
      "epoch 0; iter: 0; batch classifier loss: 43.307503; batch adversarial loss: 0.631421\n",
      "epoch 0; iter: 200; batch classifier loss: 10.267333; batch adversarial loss: 0.577213\n",
      "epoch 1; iter: 0; batch classifier loss: 5.878739; batch adversarial loss: 0.557420\n",
      "epoch 1; iter: 200; batch classifier loss: 7.953720; batch adversarial loss: 0.560686\n",
      "epoch 2; iter: 0; batch classifier loss: 11.519985; batch adversarial loss: 0.541969\n",
      "epoch 2; iter: 200; batch classifier loss: 5.180254; batch adversarial loss: 0.491637\n",
      "epoch 3; iter: 0; batch classifier loss: 2.705909; batch adversarial loss: 0.487209\n",
      "epoch 3; iter: 200; batch classifier loss: 5.151358; batch adversarial loss: 0.440536\n",
      "epoch 4; iter: 0; batch classifier loss: 1.504332; batch adversarial loss: 0.475887\n",
      "epoch 4; iter: 200; batch classifier loss: 0.585601; batch adversarial loss: 0.522901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.656959; batch adversarial loss: 0.429739\n",
      "epoch 5; iter: 200; batch classifier loss: 2.837472; batch adversarial loss: 0.517067\n",
      "epoch 6; iter: 0; batch classifier loss: 0.681810; batch adversarial loss: 0.378509\n",
      "epoch 6; iter: 200; batch classifier loss: 0.527959; batch adversarial loss: 0.376938\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537283; batch adversarial loss: 0.404486\n",
      "epoch 7; iter: 200; batch classifier loss: 0.517361; batch adversarial loss: 0.416261\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595453; batch adversarial loss: 0.454804\n",
      "epoch 8; iter: 200; batch classifier loss: 0.504760; batch adversarial loss: 0.417117\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523676; batch adversarial loss: 0.452275\n",
      "epoch 9; iter: 200; batch classifier loss: 0.496646; batch adversarial loss: 0.408976\n",
      "epoch 10; iter: 0; batch classifier loss: 0.571737; batch adversarial loss: 0.382176\n",
      "epoch 10; iter: 200; batch classifier loss: 0.491184; batch adversarial loss: 0.489752\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331047; batch adversarial loss: 0.411460\n",
      "epoch 11; iter: 200; batch classifier loss: 0.459777; batch adversarial loss: 0.345874\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348993; batch adversarial loss: 0.376345\n",
      "epoch 12; iter: 200; batch classifier loss: 0.684052; batch adversarial loss: 0.493992\n",
      "epoch 13; iter: 0; batch classifier loss: 0.455285; batch adversarial loss: 0.445915\n",
      "epoch 13; iter: 200; batch classifier loss: 0.377150; batch adversarial loss: 0.353289\n",
      "epoch 14; iter: 0; batch classifier loss: 0.306634; batch adversarial loss: 0.415418\n",
      "epoch 14; iter: 200; batch classifier loss: 0.320592; batch adversarial loss: 0.395378\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306544; batch adversarial loss: 0.366684\n",
      "epoch 15; iter: 200; batch classifier loss: 0.306447; batch adversarial loss: 0.421030\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403575; batch adversarial loss: 0.379207\n",
      "epoch 16; iter: 200; batch classifier loss: 0.319739; batch adversarial loss: 0.415897\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319873; batch adversarial loss: 0.393181\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364069; batch adversarial loss: 0.466095\n",
      "epoch 18; iter: 0; batch classifier loss: 0.353809; batch adversarial loss: 0.317708\n",
      "epoch 18; iter: 200; batch classifier loss: 0.323192; batch adversarial loss: 0.398925\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315906; batch adversarial loss: 0.368057\n",
      "epoch 19; iter: 200; batch classifier loss: 0.325736; batch adversarial loss: 0.448254\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385883; batch adversarial loss: 0.343020\n",
      "epoch 20; iter: 200; batch classifier loss: 0.325199; batch adversarial loss: 0.438591\n",
      "epoch 21; iter: 0; batch classifier loss: 0.365130; batch adversarial loss: 0.424568\n",
      "epoch 21; iter: 200; batch classifier loss: 0.346625; batch adversarial loss: 0.419217\n",
      "epoch 22; iter: 0; batch classifier loss: 0.333383; batch adversarial loss: 0.390748\n",
      "epoch 22; iter: 200; batch classifier loss: 0.392411; batch adversarial loss: 0.463202\n",
      "epoch 23; iter: 0; batch classifier loss: 0.271411; batch adversarial loss: 0.361319\n",
      "epoch 23; iter: 200; batch classifier loss: 0.306179; batch adversarial loss: 0.386280\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457296; batch adversarial loss: 0.415988\n",
      "epoch 24; iter: 200; batch classifier loss: 0.309830; batch adversarial loss: 0.321208\n",
      "epoch 25; iter: 0; batch classifier loss: 0.289122; batch adversarial loss: 0.526865\n",
      "epoch 25; iter: 200; batch classifier loss: 0.329049; batch adversarial loss: 0.409406\n",
      "epoch 26; iter: 0; batch classifier loss: 0.314199; batch adversarial loss: 0.372423\n",
      "epoch 26; iter: 200; batch classifier loss: 0.375251; batch adversarial loss: 0.412165\n",
      "epoch 27; iter: 0; batch classifier loss: 0.336871; batch adversarial loss: 0.366799\n",
      "epoch 27; iter: 200; batch classifier loss: 0.325607; batch adversarial loss: 0.422370\n",
      "epoch 28; iter: 0; batch classifier loss: 0.299962; batch adversarial loss: 0.532506\n",
      "epoch 28; iter: 200; batch classifier loss: 0.256131; batch adversarial loss: 0.468656\n",
      "epoch 29; iter: 0; batch classifier loss: 0.340488; batch adversarial loss: 0.367313\n",
      "epoch 29; iter: 200; batch classifier loss: 0.324729; batch adversarial loss: 0.479249\n",
      "epoch 30; iter: 0; batch classifier loss: 0.358759; batch adversarial loss: 0.389847\n",
      "epoch 30; iter: 200; batch classifier loss: 0.351301; batch adversarial loss: 0.325604\n",
      "epoch 31; iter: 0; batch classifier loss: 0.446169; batch adversarial loss: 0.380011\n",
      "epoch 31; iter: 200; batch classifier loss: 0.411621; batch adversarial loss: 0.401137\n",
      "epoch 32; iter: 0; batch classifier loss: 0.439218; batch adversarial loss: 0.481120\n",
      "epoch 32; iter: 200; batch classifier loss: 0.388588; batch adversarial loss: 0.362437\n",
      "epoch 33; iter: 0; batch classifier loss: 0.469675; batch adversarial loss: 0.372433\n",
      "epoch 33; iter: 200; batch classifier loss: 0.571302; batch adversarial loss: 0.440370\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363289; batch adversarial loss: 0.555205\n",
      "epoch 34; iter: 200; batch classifier loss: 0.525661; batch adversarial loss: 0.422383\n",
      "epoch 35; iter: 0; batch classifier loss: 0.466446; batch adversarial loss: 0.410649\n",
      "epoch 35; iter: 200; batch classifier loss: 0.317793; batch adversarial loss: 0.296091\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430761; batch adversarial loss: 0.433275\n",
      "epoch 36; iter: 200; batch classifier loss: 0.435755; batch adversarial loss: 0.415137\n",
      "epoch 37; iter: 0; batch classifier loss: 0.480256; batch adversarial loss: 0.319134\n",
      "epoch 37; iter: 200; batch classifier loss: 0.583514; batch adversarial loss: 0.489800\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408213; batch adversarial loss: 0.404175\n",
      "epoch 38; iter: 200; batch classifier loss: 0.397234; batch adversarial loss: 0.548640\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432183; batch adversarial loss: 0.390334\n",
      "epoch 39; iter: 200; batch classifier loss: 0.262249; batch adversarial loss: 0.443935\n",
      "epoch 40; iter: 0; batch classifier loss: 0.484546; batch adversarial loss: 0.321891\n",
      "epoch 40; iter: 200; batch classifier loss: 0.555441; batch adversarial loss: 0.344919\n",
      "epoch 41; iter: 0; batch classifier loss: 0.523095; batch adversarial loss: 0.445196\n",
      "epoch 41; iter: 200; batch classifier loss: 0.402565; batch adversarial loss: 0.363924\n",
      "epoch 42; iter: 0; batch classifier loss: 0.525643; batch adversarial loss: 0.424015\n",
      "epoch 42; iter: 200; batch classifier loss: 0.472115; batch adversarial loss: 0.363348\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449465; batch adversarial loss: 0.391234\n",
      "epoch 43; iter: 200; batch classifier loss: 0.521820; batch adversarial loss: 0.420014\n",
      "epoch 44; iter: 0; batch classifier loss: 0.518778; batch adversarial loss: 0.347320\n",
      "epoch 44; iter: 200; batch classifier loss: 0.449356; batch adversarial loss: 0.501742\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417626; batch adversarial loss: 0.423986\n",
      "epoch 45; iter: 200; batch classifier loss: 0.496438; batch adversarial loss: 0.368675\n",
      "epoch 46; iter: 0; batch classifier loss: 0.466364; batch adversarial loss: 0.482428\n",
      "epoch 46; iter: 200; batch classifier loss: 0.464970; batch adversarial loss: 0.378823\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520667; batch adversarial loss: 0.373438\n",
      "epoch 47; iter: 200; batch classifier loss: 0.575000; batch adversarial loss: 0.476269\n",
      "epoch 48; iter: 0; batch classifier loss: 0.489178; batch adversarial loss: 0.483751\n",
      "epoch 48; iter: 200; batch classifier loss: 0.494689; batch adversarial loss: 0.486508\n",
      "epoch 49; iter: 0; batch classifier loss: 0.541458; batch adversarial loss: 0.373436\n",
      "epoch 49; iter: 200; batch classifier loss: 0.510091; batch adversarial loss: 0.469283\n",
      "epoch 0; iter: 0; batch classifier loss: 14.890515; batch adversarial loss: 0.652045\n",
      "epoch 0; iter: 200; batch classifier loss: 7.467040; batch adversarial loss: 0.571604\n",
      "epoch 1; iter: 0; batch classifier loss: 8.924685; batch adversarial loss: 0.536899\n",
      "epoch 1; iter: 200; batch classifier loss: 8.685650; batch adversarial loss: 0.543974\n",
      "epoch 2; iter: 0; batch classifier loss: 4.754555; batch adversarial loss: 0.479429\n",
      "epoch 2; iter: 200; batch classifier loss: 2.952573; batch adversarial loss: 0.456685\n",
      "epoch 3; iter: 0; batch classifier loss: 2.013429; batch adversarial loss: 0.447815\n",
      "epoch 3; iter: 200; batch classifier loss: 4.742204; batch adversarial loss: 0.394857\n",
      "epoch 4; iter: 0; batch classifier loss: 2.781279; batch adversarial loss: 0.529779\n",
      "epoch 4; iter: 200; batch classifier loss: 0.388108; batch adversarial loss: 0.395934\n",
      "epoch 5; iter: 0; batch classifier loss: 1.351453; batch adversarial loss: 0.462378\n",
      "epoch 5; iter: 200; batch classifier loss: 0.928630; batch adversarial loss: 0.382292\n",
      "epoch 6; iter: 0; batch classifier loss: 0.686705; batch adversarial loss: 0.437980\n",
      "epoch 6; iter: 200; batch classifier loss: 1.050719; batch adversarial loss: 0.407109\n",
      "epoch 7; iter: 0; batch classifier loss: 0.820471; batch adversarial loss: 0.480418\n",
      "epoch 7; iter: 200; batch classifier loss: 0.584505; batch adversarial loss: 0.438846\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571232; batch adversarial loss: 0.378190\n",
      "epoch 8; iter: 200; batch classifier loss: 0.887619; batch adversarial loss: 0.482116\n",
      "epoch 9; iter: 0; batch classifier loss: 0.424212; batch adversarial loss: 0.348791\n",
      "epoch 9; iter: 200; batch classifier loss: 0.373589; batch adversarial loss: 0.292295\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370108; batch adversarial loss: 0.370761\n",
      "epoch 10; iter: 200; batch classifier loss: 0.447499; batch adversarial loss: 0.352006\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407144; batch adversarial loss: 0.349973\n",
      "epoch 11; iter: 200; batch classifier loss: 0.409821; batch adversarial loss: 0.451811\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413686; batch adversarial loss: 0.503699\n",
      "epoch 12; iter: 200; batch classifier loss: 0.324207; batch adversarial loss: 0.454608\n",
      "epoch 13; iter: 0; batch classifier loss: 0.343374; batch adversarial loss: 0.327492\n",
      "epoch 13; iter: 200; batch classifier loss: 0.413672; batch adversarial loss: 0.454917\n",
      "epoch 14; iter: 0; batch classifier loss: 0.427204; batch adversarial loss: 0.523128\n",
      "epoch 14; iter: 200; batch classifier loss: 0.349814; batch adversarial loss: 0.397074\n",
      "epoch 15; iter: 0; batch classifier loss: 0.360542; batch adversarial loss: 0.437820\n",
      "epoch 15; iter: 200; batch classifier loss: 0.287106; batch adversarial loss: 0.395665\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430344; batch adversarial loss: 0.354770\n",
      "epoch 16; iter: 200; batch classifier loss: 0.356864; batch adversarial loss: 0.385435\n",
      "epoch 17; iter: 0; batch classifier loss: 0.292106; batch adversarial loss: 0.387079\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321587; batch adversarial loss: 0.475528\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367025; batch adversarial loss: 0.391246\n",
      "epoch 18; iter: 200; batch classifier loss: 0.266421; batch adversarial loss: 0.337102\n",
      "epoch 19; iter: 0; batch classifier loss: 0.395168; batch adversarial loss: 0.444472\n",
      "epoch 19; iter: 200; batch classifier loss: 0.273613; batch adversarial loss: 0.341736\n",
      "epoch 20; iter: 0; batch classifier loss: 0.335825; batch adversarial loss: 0.487159\n",
      "epoch 20; iter: 200; batch classifier loss: 0.328121; batch adversarial loss: 0.403785\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387149; batch adversarial loss: 0.380623\n",
      "epoch 21; iter: 200; batch classifier loss: 0.297712; batch adversarial loss: 0.514581\n",
      "epoch 22; iter: 0; batch classifier loss: 0.346848; batch adversarial loss: 0.387097\n",
      "epoch 22; iter: 200; batch classifier loss: 0.357314; batch adversarial loss: 0.341497\n",
      "epoch 23; iter: 0; batch classifier loss: 0.411019; batch adversarial loss: 0.455744\n",
      "epoch 23; iter: 200; batch classifier loss: 0.328085; batch adversarial loss: 0.348806\n",
      "epoch 24; iter: 0; batch classifier loss: 0.307374; batch adversarial loss: 0.443095\n",
      "epoch 24; iter: 200; batch classifier loss: 0.342731; batch adversarial loss: 0.427937\n",
      "epoch 25; iter: 0; batch classifier loss: 0.384736; batch adversarial loss: 0.402059\n",
      "epoch 25; iter: 200; batch classifier loss: 0.404630; batch adversarial loss: 0.500943\n",
      "epoch 26; iter: 0; batch classifier loss: 0.341635; batch adversarial loss: 0.312422\n",
      "epoch 26; iter: 200; batch classifier loss: 0.428654; batch adversarial loss: 0.342537\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389566; batch adversarial loss: 0.386211\n",
      "epoch 27; iter: 200; batch classifier loss: 0.383523; batch adversarial loss: 0.448456\n",
      "epoch 28; iter: 0; batch classifier loss: 0.377142; batch adversarial loss: 0.412859\n",
      "epoch 28; iter: 200; batch classifier loss: 0.463213; batch adversarial loss: 0.348557\n",
      "epoch 29; iter: 0; batch classifier loss: 0.624522; batch adversarial loss: 0.448616\n",
      "epoch 29; iter: 200; batch classifier loss: 0.485178; batch adversarial loss: 0.401780\n",
      "epoch 30; iter: 0; batch classifier loss: 0.510525; batch adversarial loss: 0.382835\n",
      "epoch 30; iter: 200; batch classifier loss: 0.503931; batch adversarial loss: 0.398205\n",
      "epoch 31; iter: 0; batch classifier loss: 0.307663; batch adversarial loss: 0.433974\n",
      "epoch 31; iter: 200; batch classifier loss: 0.462151; batch adversarial loss: 0.412027\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487568; batch adversarial loss: 0.387396\n",
      "epoch 32; iter: 200; batch classifier loss: 0.393189; batch adversarial loss: 0.526364\n",
      "epoch 33; iter: 0; batch classifier loss: 0.504016; batch adversarial loss: 0.456249\n",
      "epoch 33; iter: 200; batch classifier loss: 0.502278; batch adversarial loss: 0.414638\n",
      "epoch 34; iter: 0; batch classifier loss: 0.474103; batch adversarial loss: 0.488252\n",
      "epoch 34; iter: 200; batch classifier loss: 0.653583; batch adversarial loss: 0.449563\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461067; batch adversarial loss: 0.501964\n",
      "epoch 35; iter: 200; batch classifier loss: 0.511334; batch adversarial loss: 0.385172\n",
      "epoch 36; iter: 0; batch classifier loss: 0.512978; batch adversarial loss: 0.406727\n",
      "epoch 36; iter: 200; batch classifier loss: 0.479397; batch adversarial loss: 0.393863\n",
      "epoch 37; iter: 0; batch classifier loss: 0.377712; batch adversarial loss: 0.446274\n",
      "epoch 37; iter: 200; batch classifier loss: 0.377465; batch adversarial loss: 0.406107\n",
      "epoch 38; iter: 0; batch classifier loss: 0.560795; batch adversarial loss: 0.439839\n",
      "epoch 38; iter: 200; batch classifier loss: 0.445837; batch adversarial loss: 0.517000\n",
      "epoch 39; iter: 0; batch classifier loss: 0.435822; batch adversarial loss: 0.444417\n",
      "epoch 39; iter: 200; batch classifier loss: 0.466391; batch adversarial loss: 0.394445\n",
      "epoch 40; iter: 0; batch classifier loss: 0.385050; batch adversarial loss: 0.391782\n",
      "epoch 40; iter: 200; batch classifier loss: 0.467083; batch adversarial loss: 0.417563\n",
      "epoch 41; iter: 0; batch classifier loss: 0.580883; batch adversarial loss: 0.348453\n",
      "epoch 41; iter: 200; batch classifier loss: 0.639686; batch adversarial loss: 0.482751\n",
      "epoch 42; iter: 0; batch classifier loss: 0.360474; batch adversarial loss: 0.541929\n",
      "epoch 42; iter: 200; batch classifier loss: 0.458399; batch adversarial loss: 0.479573\n",
      "epoch 43; iter: 0; batch classifier loss: 0.475956; batch adversarial loss: 0.421093\n",
      "epoch 43; iter: 200; batch classifier loss: 0.667069; batch adversarial loss: 0.363514\n",
      "epoch 44; iter: 0; batch classifier loss: 0.419345; batch adversarial loss: 0.427571\n",
      "epoch 44; iter: 200; batch classifier loss: 0.482408; batch adversarial loss: 0.417704\n",
      "epoch 45; iter: 0; batch classifier loss: 0.484711; batch adversarial loss: 0.461241\n",
      "epoch 45; iter: 200; batch classifier loss: 0.424183; batch adversarial loss: 0.403620\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479485; batch adversarial loss: 0.405514\n",
      "epoch 46; iter: 200; batch classifier loss: 0.505246; batch adversarial loss: 0.400855\n",
      "epoch 47; iter: 0; batch classifier loss: 0.537353; batch adversarial loss: 0.346022\n",
      "epoch 47; iter: 200; batch classifier loss: 0.567399; batch adversarial loss: 0.435707\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403499; batch adversarial loss: 0.513366\n",
      "epoch 48; iter: 200; batch classifier loss: 0.409316; batch adversarial loss: 0.496353\n",
      "epoch 49; iter: 0; batch classifier loss: 0.521079; batch adversarial loss: 0.304590\n",
      "epoch 49; iter: 200; batch classifier loss: 0.522232; batch adversarial loss: 0.335920\n",
      "epoch 0; iter: 0; batch classifier loss: 7.299717; batch adversarial loss: 0.534990\n",
      "epoch 0; iter: 200; batch classifier loss: 5.916246; batch adversarial loss: 0.580094\n",
      "epoch 1; iter: 0; batch classifier loss: 12.218523; batch adversarial loss: 0.546073\n",
      "epoch 1; iter: 200; batch classifier loss: 27.917118; batch adversarial loss: 0.516579\n",
      "epoch 2; iter: 0; batch classifier loss: 3.369341; batch adversarial loss: 0.482354\n",
      "epoch 2; iter: 200; batch classifier loss: 2.234130; batch adversarial loss: 0.466243\n",
      "epoch 3; iter: 0; batch classifier loss: 5.328225; batch adversarial loss: 0.453965\n",
      "epoch 3; iter: 200; batch classifier loss: 2.108734; batch adversarial loss: 0.425326\n",
      "epoch 4; iter: 0; batch classifier loss: 3.591290; batch adversarial loss: 0.533507\n",
      "epoch 4; iter: 200; batch classifier loss: 1.608553; batch adversarial loss: 0.378200\n",
      "epoch 5; iter: 0; batch classifier loss: 0.958246; batch adversarial loss: 0.393385\n",
      "epoch 5; iter: 200; batch classifier loss: 0.424517; batch adversarial loss: 0.402422\n",
      "epoch 6; iter: 0; batch classifier loss: 1.148916; batch adversarial loss: 0.399193\n",
      "epoch 6; iter: 200; batch classifier loss: 0.637103; batch adversarial loss: 0.371630\n",
      "epoch 7; iter: 0; batch classifier loss: 0.381327; batch adversarial loss: 0.413184\n",
      "epoch 7; iter: 200; batch classifier loss: 0.460926; batch adversarial loss: 0.369588\n",
      "epoch 8; iter: 0; batch classifier loss: 0.675046; batch adversarial loss: 0.429716\n",
      "epoch 8; iter: 200; batch classifier loss: 0.364560; batch adversarial loss: 0.451869\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404473; batch adversarial loss: 0.374359\n",
      "epoch 9; iter: 200; batch classifier loss: 0.406983; batch adversarial loss: 0.458458\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430664; batch adversarial loss: 0.436753\n",
      "epoch 10; iter: 200; batch classifier loss: 0.397730; batch adversarial loss: 0.423882\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406445; batch adversarial loss: 0.324868\n",
      "epoch 11; iter: 200; batch classifier loss: 0.354667; batch adversarial loss: 0.379295\n",
      "epoch 12; iter: 0; batch classifier loss: 0.524652; batch adversarial loss: 0.429013\n",
      "epoch 12; iter: 200; batch classifier loss: 0.365230; batch adversarial loss: 0.384973\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340017; batch adversarial loss: 0.372617\n",
      "epoch 13; iter: 200; batch classifier loss: 0.317953; batch adversarial loss: 0.403878\n",
      "epoch 14; iter: 0; batch classifier loss: 0.375556; batch adversarial loss: 0.447215\n",
      "epoch 14; iter: 200; batch classifier loss: 0.272067; batch adversarial loss: 0.429966\n",
      "epoch 15; iter: 0; batch classifier loss: 0.340902; batch adversarial loss: 0.447678\n",
      "epoch 15; iter: 200; batch classifier loss: 0.337560; batch adversarial loss: 0.413135\n",
      "epoch 16; iter: 0; batch classifier loss: 0.432676; batch adversarial loss: 0.514058\n",
      "epoch 16; iter: 200; batch classifier loss: 0.321213; batch adversarial loss: 0.425639\n",
      "epoch 17; iter: 0; batch classifier loss: 0.425330; batch adversarial loss: 0.416602\n",
      "epoch 17; iter: 200; batch classifier loss: 0.420825; batch adversarial loss: 0.316423\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350453; batch adversarial loss: 0.413125\n",
      "epoch 18; iter: 200; batch classifier loss: 0.376263; batch adversarial loss: 0.482266\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484166; batch adversarial loss: 0.374194\n",
      "epoch 19; iter: 200; batch classifier loss: 0.293157; batch adversarial loss: 0.409463\n",
      "epoch 20; iter: 0; batch classifier loss: 0.339141; batch adversarial loss: 0.388970\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368019; batch adversarial loss: 0.478938\n",
      "epoch 21; iter: 0; batch classifier loss: 0.365570; batch adversarial loss: 0.344173\n",
      "epoch 21; iter: 200; batch classifier loss: 0.298717; batch adversarial loss: 0.447799\n",
      "epoch 22; iter: 0; batch classifier loss: 0.294594; batch adversarial loss: 0.325251\n",
      "epoch 22; iter: 200; batch classifier loss: 0.367421; batch adversarial loss: 0.343065\n",
      "epoch 23; iter: 0; batch classifier loss: 0.347784; batch adversarial loss: 0.380762\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374890; batch adversarial loss: 0.400133\n",
      "epoch 24; iter: 0; batch classifier loss: 0.321739; batch adversarial loss: 0.366828\n",
      "epoch 24; iter: 200; batch classifier loss: 0.405419; batch adversarial loss: 0.429175\n",
      "epoch 25; iter: 0; batch classifier loss: 0.419775; batch adversarial loss: 0.371640\n",
      "epoch 25; iter: 200; batch classifier loss: 0.291859; batch adversarial loss: 0.418522\n",
      "epoch 26; iter: 0; batch classifier loss: 0.407238; batch adversarial loss: 0.401081\n",
      "epoch 26; iter: 200; batch classifier loss: 0.347364; batch adversarial loss: 0.404734\n",
      "epoch 27; iter: 0; batch classifier loss: 0.373646; batch adversarial loss: 0.384796\n",
      "epoch 27; iter: 200; batch classifier loss: 0.424186; batch adversarial loss: 0.449818\n",
      "epoch 28; iter: 0; batch classifier loss: 0.302381; batch adversarial loss: 0.454685\n",
      "epoch 28; iter: 200; batch classifier loss: 0.423109; batch adversarial loss: 0.336859\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358159; batch adversarial loss: 0.274966\n",
      "epoch 29; iter: 200; batch classifier loss: 0.299041; batch adversarial loss: 0.456681\n",
      "epoch 30; iter: 0; batch classifier loss: 0.327697; batch adversarial loss: 0.345242\n",
      "epoch 30; iter: 200; batch classifier loss: 0.257523; batch adversarial loss: 0.494820\n",
      "epoch 31; iter: 0; batch classifier loss: 0.265227; batch adversarial loss: 0.451912\n",
      "epoch 31; iter: 200; batch classifier loss: 0.362799; batch adversarial loss: 0.537278\n",
      "epoch 32; iter: 0; batch classifier loss: 0.299735; batch adversarial loss: 0.351199\n",
      "epoch 32; iter: 200; batch classifier loss: 0.313318; batch adversarial loss: 0.376030\n",
      "epoch 33; iter: 0; batch classifier loss: 0.384824; batch adversarial loss: 0.419254\n",
      "epoch 33; iter: 200; batch classifier loss: 0.301750; batch adversarial loss: 0.550436\n",
      "epoch 34; iter: 0; batch classifier loss: 0.355717; batch adversarial loss: 0.490393\n",
      "epoch 34; iter: 200; batch classifier loss: 0.415377; batch adversarial loss: 0.388630\n",
      "epoch 35; iter: 0; batch classifier loss: 0.287846; batch adversarial loss: 0.461858\n",
      "epoch 35; iter: 200; batch classifier loss: 0.319712; batch adversarial loss: 0.281545\n",
      "epoch 36; iter: 0; batch classifier loss: 0.321705; batch adversarial loss: 0.472847\n",
      "epoch 36; iter: 200; batch classifier loss: 0.318192; batch adversarial loss: 0.347119\n",
      "epoch 37; iter: 0; batch classifier loss: 0.302901; batch adversarial loss: 0.390777\n",
      "epoch 37; iter: 200; batch classifier loss: 0.402763; batch adversarial loss: 0.430711\n",
      "epoch 38; iter: 0; batch classifier loss: 0.353378; batch adversarial loss: 0.345218\n",
      "epoch 38; iter: 200; batch classifier loss: 0.311940; batch adversarial loss: 0.401577\n",
      "epoch 39; iter: 0; batch classifier loss: 0.386456; batch adversarial loss: 0.492660\n",
      "epoch 39; iter: 200; batch classifier loss: 0.313771; batch adversarial loss: 0.366436\n",
      "epoch 40; iter: 0; batch classifier loss: 0.359669; batch adversarial loss: 0.374263\n",
      "epoch 40; iter: 200; batch classifier loss: 0.294288; batch adversarial loss: 0.369938\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404174; batch adversarial loss: 0.339329\n",
      "epoch 41; iter: 200; batch classifier loss: 0.307471; batch adversarial loss: 0.418999\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429825; batch adversarial loss: 0.419015\n",
      "epoch 42; iter: 200; batch classifier loss: 0.198027; batch adversarial loss: 0.407046\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386663; batch adversarial loss: 0.466332\n",
      "epoch 43; iter: 200; batch classifier loss: 0.388594; batch adversarial loss: 0.442390\n",
      "epoch 44; iter: 0; batch classifier loss: 0.337166; batch adversarial loss: 0.299724\n",
      "epoch 44; iter: 200; batch classifier loss: 0.415001; batch adversarial loss: 0.379769\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414324; batch adversarial loss: 0.400139\n",
      "epoch 45; iter: 200; batch classifier loss: 0.224579; batch adversarial loss: 0.418613\n",
      "epoch 46; iter: 0; batch classifier loss: 0.355915; batch adversarial loss: 0.432666\n",
      "epoch 46; iter: 200; batch classifier loss: 0.388552; batch adversarial loss: 0.319386\n",
      "epoch 47; iter: 0; batch classifier loss: 0.269961; batch adversarial loss: 0.513696\n",
      "epoch 47; iter: 200; batch classifier loss: 0.425541; batch adversarial loss: 0.449349\n",
      "epoch 48; iter: 0; batch classifier loss: 0.337036; batch adversarial loss: 0.472933\n",
      "epoch 48; iter: 200; batch classifier loss: 0.467006; batch adversarial loss: 0.402104\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417263; batch adversarial loss: 0.321192\n",
      "epoch 49; iter: 200; batch classifier loss: 0.244406; batch adversarial loss: 0.538450\n",
      "epoch 0; iter: 0; batch classifier loss: 22.370943; batch adversarial loss: 0.785956\n",
      "epoch 0; iter: 200; batch classifier loss: 10.395334; batch adversarial loss: 0.674617\n",
      "epoch 1; iter: 0; batch classifier loss: 7.182924; batch adversarial loss: 0.591942\n",
      "epoch 1; iter: 200; batch classifier loss: 8.212234; batch adversarial loss: 0.555766\n",
      "epoch 2; iter: 0; batch classifier loss: 10.091991; batch adversarial loss: 0.467352\n",
      "epoch 2; iter: 200; batch classifier loss: 4.618795; batch adversarial loss: 0.521419\n",
      "epoch 3; iter: 0; batch classifier loss: 2.000100; batch adversarial loss: 0.496567\n",
      "epoch 3; iter: 200; batch classifier loss: 1.640553; batch adversarial loss: 0.431611\n",
      "epoch 4; iter: 0; batch classifier loss: 1.809509; batch adversarial loss: 0.447603\n",
      "epoch 4; iter: 200; batch classifier loss: 5.681544; batch adversarial loss: 0.481722\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579120; batch adversarial loss: 0.394054\n",
      "epoch 5; iter: 200; batch classifier loss: 0.457087; batch adversarial loss: 0.433258\n",
      "epoch 6; iter: 0; batch classifier loss: 0.397031; batch adversarial loss: 0.396796\n",
      "epoch 6; iter: 200; batch classifier loss: 0.481381; batch adversarial loss: 0.382574\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458231; batch adversarial loss: 0.348375\n",
      "epoch 7; iter: 200; batch classifier loss: 0.448272; batch adversarial loss: 0.446490\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475102; batch adversarial loss: 0.367767\n",
      "epoch 8; iter: 200; batch classifier loss: 0.340315; batch adversarial loss: 0.394223\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389880; batch adversarial loss: 0.411132\n",
      "epoch 9; iter: 200; batch classifier loss: 0.465025; batch adversarial loss: 0.412488\n",
      "epoch 10; iter: 0; batch classifier loss: 0.380233; batch adversarial loss: 0.403401\n",
      "epoch 10; iter: 200; batch classifier loss: 0.418012; batch adversarial loss: 0.417605\n",
      "epoch 11; iter: 0; batch classifier loss: 0.417054; batch adversarial loss: 0.422547\n",
      "epoch 11; iter: 200; batch classifier loss: 0.337123; batch adversarial loss: 0.439124\n",
      "epoch 12; iter: 0; batch classifier loss: 0.336454; batch adversarial loss: 0.411223\n",
      "epoch 12; iter: 200; batch classifier loss: 0.348964; batch adversarial loss: 0.405627\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340669; batch adversarial loss: 0.394968\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396641; batch adversarial loss: 0.387613\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351345; batch adversarial loss: 0.383708\n",
      "epoch 14; iter: 200; batch classifier loss: 0.381873; batch adversarial loss: 0.360779\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307687; batch adversarial loss: 0.371948\n",
      "epoch 15; iter: 200; batch classifier loss: 0.305932; batch adversarial loss: 0.346369\n",
      "epoch 16; iter: 0; batch classifier loss: 0.410679; batch adversarial loss: 0.519580\n",
      "epoch 16; iter: 200; batch classifier loss: 0.375350; batch adversarial loss: 0.431273\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375597; batch adversarial loss: 0.475464\n",
      "epoch 17; iter: 200; batch classifier loss: 0.351960; batch adversarial loss: 0.359684\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286641; batch adversarial loss: 0.507718\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321694; batch adversarial loss: 0.435542\n",
      "epoch 19; iter: 0; batch classifier loss: 0.301329; batch adversarial loss: 0.442466\n",
      "epoch 19; iter: 200; batch classifier loss: 0.304561; batch adversarial loss: 0.459110\n",
      "epoch 20; iter: 0; batch classifier loss: 0.307202; batch adversarial loss: 0.425006\n",
      "epoch 20; iter: 200; batch classifier loss: 0.380763; batch adversarial loss: 0.421298\n",
      "epoch 21; iter: 0; batch classifier loss: 0.364831; batch adversarial loss: 0.361703\n",
      "epoch 21; iter: 200; batch classifier loss: 0.400867; batch adversarial loss: 0.389288\n",
      "epoch 22; iter: 0; batch classifier loss: 0.389027; batch adversarial loss: 0.354744\n",
      "epoch 22; iter: 200; batch classifier loss: 0.384287; batch adversarial loss: 0.354449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380886; batch adversarial loss: 0.392222\n",
      "epoch 23; iter: 200; batch classifier loss: 0.314523; batch adversarial loss: 0.507095\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343723; batch adversarial loss: 0.347071\n",
      "epoch 24; iter: 200; batch classifier loss: 0.303582; batch adversarial loss: 0.449181\n",
      "epoch 25; iter: 0; batch classifier loss: 0.334483; batch adversarial loss: 0.318836\n",
      "epoch 25; iter: 200; batch classifier loss: 0.389379; batch adversarial loss: 0.384034\n",
      "epoch 26; iter: 0; batch classifier loss: 0.293364; batch adversarial loss: 0.454899\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336119; batch adversarial loss: 0.454536\n",
      "epoch 27; iter: 0; batch classifier loss: 0.363910; batch adversarial loss: 0.519315\n",
      "epoch 27; iter: 200; batch classifier loss: 0.317301; batch adversarial loss: 0.429839\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286668; batch adversarial loss: 0.446648\n",
      "epoch 28; iter: 200; batch classifier loss: 0.297507; batch adversarial loss: 0.489889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.271495; batch adversarial loss: 0.517055\n",
      "epoch 29; iter: 200; batch classifier loss: 0.362381; batch adversarial loss: 0.476375\n",
      "epoch 30; iter: 0; batch classifier loss: 0.308520; batch adversarial loss: 0.465554\n",
      "epoch 30; iter: 200; batch classifier loss: 0.369992; batch adversarial loss: 0.371992\n",
      "epoch 31; iter: 0; batch classifier loss: 0.363284; batch adversarial loss: 0.423768\n",
      "epoch 31; iter: 200; batch classifier loss: 0.444220; batch adversarial loss: 0.403676\n",
      "epoch 32; iter: 0; batch classifier loss: 0.405557; batch adversarial loss: 0.416671\n",
      "epoch 32; iter: 200; batch classifier loss: 0.411200; batch adversarial loss: 0.428349\n",
      "epoch 33; iter: 0; batch classifier loss: 0.383139; batch adversarial loss: 0.405846\n",
      "epoch 33; iter: 200; batch classifier loss: 0.414173; batch adversarial loss: 0.581850\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419101; batch adversarial loss: 0.538939\n",
      "epoch 34; iter: 200; batch classifier loss: 0.287523; batch adversarial loss: 0.464151\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432936; batch adversarial loss: 0.399375\n",
      "epoch 35; iter: 200; batch classifier loss: 0.454640; batch adversarial loss: 0.415856\n",
      "epoch 36; iter: 0; batch classifier loss: 0.341738; batch adversarial loss: 0.445622\n",
      "epoch 36; iter: 200; batch classifier loss: 0.546107; batch adversarial loss: 0.366195\n",
      "epoch 37; iter: 0; batch classifier loss: 0.487954; batch adversarial loss: 0.395201\n",
      "epoch 37; iter: 200; batch classifier loss: 0.667206; batch adversarial loss: 0.436626\n",
      "epoch 38; iter: 0; batch classifier loss: 0.365636; batch adversarial loss: 0.468974\n",
      "epoch 38; iter: 200; batch classifier loss: 0.347535; batch adversarial loss: 0.395774\n",
      "epoch 39; iter: 0; batch classifier loss: 0.378394; batch adversarial loss: 0.406653\n",
      "epoch 39; iter: 200; batch classifier loss: 0.492885; batch adversarial loss: 0.368545\n",
      "epoch 40; iter: 0; batch classifier loss: 0.503017; batch adversarial loss: 0.391978\n",
      "epoch 40; iter: 200; batch classifier loss: 0.408104; batch adversarial loss: 0.386346\n",
      "epoch 41; iter: 0; batch classifier loss: 0.482596; batch adversarial loss: 0.322099\n",
      "epoch 41; iter: 200; batch classifier loss: 0.308195; batch adversarial loss: 0.387662\n",
      "epoch 42; iter: 0; batch classifier loss: 0.510056; batch adversarial loss: 0.364865\n",
      "epoch 42; iter: 200; batch classifier loss: 0.525120; batch adversarial loss: 0.391010\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486329; batch adversarial loss: 0.450279\n",
      "epoch 43; iter: 200; batch classifier loss: 0.429774; batch adversarial loss: 0.359103\n",
      "epoch 44; iter: 0; batch classifier loss: 0.456988; batch adversarial loss: 0.358012\n",
      "epoch 44; iter: 200; batch classifier loss: 0.491255; batch adversarial loss: 0.405872\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481297; batch adversarial loss: 0.404959\n",
      "epoch 45; iter: 200; batch classifier loss: 0.488541; batch adversarial loss: 0.427350\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401707; batch adversarial loss: 0.362252\n",
      "epoch 46; iter: 200; batch classifier loss: 0.514821; batch adversarial loss: 0.412560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.433100; batch adversarial loss: 0.336826\n",
      "epoch 47; iter: 200; batch classifier loss: 0.445280; batch adversarial loss: 0.402481\n",
      "epoch 48; iter: 0; batch classifier loss: 0.498419; batch adversarial loss: 0.415325\n",
      "epoch 48; iter: 200; batch classifier loss: 0.416747; batch adversarial loss: 0.418184\n",
      "epoch 49; iter: 0; batch classifier loss: 0.601491; batch adversarial loss: 0.539518\n",
      "epoch 49; iter: 200; batch classifier loss: 0.561690; batch adversarial loss: 0.412037\n",
      "epoch 0; iter: 0; batch classifier loss: 136.401031; batch adversarial loss: 0.724584\n",
      "epoch 0; iter: 200; batch classifier loss: 5.956638; batch adversarial loss: 0.627147\n",
      "epoch 1; iter: 0; batch classifier loss: 3.866292; batch adversarial loss: 0.569800\n",
      "epoch 1; iter: 200; batch classifier loss: 6.698146; batch adversarial loss: 0.506939\n",
      "epoch 2; iter: 0; batch classifier loss: 3.160946; batch adversarial loss: 0.547440\n",
      "epoch 2; iter: 200; batch classifier loss: 3.710830; batch adversarial loss: 0.470581\n",
      "epoch 3; iter: 0; batch classifier loss: 6.460340; batch adversarial loss: 0.470090\n",
      "epoch 3; iter: 200; batch classifier loss: 7.840589; batch adversarial loss: 0.532905\n",
      "epoch 4; iter: 0; batch classifier loss: 0.880528; batch adversarial loss: 0.449560\n",
      "epoch 4; iter: 200; batch classifier loss: 2.027667; batch adversarial loss: 0.457687\n",
      "epoch 5; iter: 0; batch classifier loss: 1.668205; batch adversarial loss: 0.441386\n",
      "epoch 5; iter: 200; batch classifier loss: 0.553257; batch adversarial loss: 0.500506\n",
      "epoch 6; iter: 0; batch classifier loss: 0.993114; batch adversarial loss: 0.352902\n",
      "epoch 6; iter: 200; batch classifier loss: 0.588753; batch adversarial loss: 0.450834\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549183; batch adversarial loss: 0.399230\n",
      "epoch 7; iter: 200; batch classifier loss: 0.328192; batch adversarial loss: 0.372218\n",
      "epoch 8; iter: 0; batch classifier loss: 0.676306; batch adversarial loss: 0.445202\n",
      "epoch 8; iter: 200; batch classifier loss: 0.422149; batch adversarial loss: 0.431307\n",
      "epoch 9; iter: 0; batch classifier loss: 0.750147; batch adversarial loss: 0.434917\n",
      "epoch 9; iter: 200; batch classifier loss: 0.391514; batch adversarial loss: 0.409976\n",
      "epoch 10; iter: 0; batch classifier loss: 0.387680; batch adversarial loss: 0.449524\n",
      "epoch 10; iter: 200; batch classifier loss: 0.424752; batch adversarial loss: 0.423216\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409165; batch adversarial loss: 0.449882\n",
      "epoch 11; iter: 200; batch classifier loss: 0.433726; batch adversarial loss: 0.403132\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457862; batch adversarial loss: 0.250335\n",
      "epoch 12; iter: 200; batch classifier loss: 0.370526; batch adversarial loss: 0.320062\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291895; batch adversarial loss: 0.336235\n",
      "epoch 13; iter: 200; batch classifier loss: 0.377633; batch adversarial loss: 0.413142\n",
      "epoch 14; iter: 0; batch classifier loss: 0.341788; batch adversarial loss: 0.450030\n",
      "epoch 14; iter: 200; batch classifier loss: 0.307214; batch adversarial loss: 0.445312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318188; batch adversarial loss: 0.370986\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387783; batch adversarial loss: 0.443622\n",
      "epoch 16; iter: 0; batch classifier loss: 0.381360; batch adversarial loss: 0.408395\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383595; batch adversarial loss: 0.366207\n",
      "epoch 17; iter: 0; batch classifier loss: 0.289207; batch adversarial loss: 0.400007\n",
      "epoch 17; iter: 200; batch classifier loss: 0.489255; batch adversarial loss: 0.376084\n",
      "epoch 18; iter: 0; batch classifier loss: 0.386850; batch adversarial loss: 0.436030\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341510; batch adversarial loss: 0.405825\n",
      "epoch 19; iter: 0; batch classifier loss: 0.290228; batch adversarial loss: 0.368641\n",
      "epoch 19; iter: 200; batch classifier loss: 0.314487; batch adversarial loss: 0.402888\n",
      "epoch 20; iter: 0; batch classifier loss: 0.300586; batch adversarial loss: 0.367499\n",
      "epoch 20; iter: 200; batch classifier loss: 0.339917; batch adversarial loss: 0.338642\n",
      "epoch 21; iter: 0; batch classifier loss: 0.273090; batch adversarial loss: 0.396968\n",
      "epoch 21; iter: 200; batch classifier loss: 0.366739; batch adversarial loss: 0.420097\n",
      "epoch 22; iter: 0; batch classifier loss: 0.520856; batch adversarial loss: 0.330160\n",
      "epoch 22; iter: 200; batch classifier loss: 0.368237; batch adversarial loss: 0.361347\n",
      "epoch 23; iter: 0; batch classifier loss: 0.284265; batch adversarial loss: 0.393074\n",
      "epoch 23; iter: 200; batch classifier loss: 0.321078; batch adversarial loss: 0.307206\n",
      "epoch 24; iter: 0; batch classifier loss: 0.352636; batch adversarial loss: 0.372276\n",
      "epoch 24; iter: 200; batch classifier loss: 0.244134; batch adversarial loss: 0.483574\n",
      "epoch 25; iter: 0; batch classifier loss: 0.325268; batch adversarial loss: 0.434742\n",
      "epoch 25; iter: 200; batch classifier loss: 0.330224; batch adversarial loss: 0.424859\n",
      "epoch 26; iter: 0; batch classifier loss: 0.337689; batch adversarial loss: 0.441905\n",
      "epoch 26; iter: 200; batch classifier loss: 0.418534; batch adversarial loss: 0.389034\n",
      "epoch 27; iter: 0; batch classifier loss: 0.294534; batch adversarial loss: 0.439120\n",
      "epoch 27; iter: 200; batch classifier loss: 0.328734; batch adversarial loss: 0.336638\n",
      "epoch 28; iter: 0; batch classifier loss: 0.309443; batch adversarial loss: 0.407028\n",
      "epoch 28; iter: 200; batch classifier loss: 0.333369; batch adversarial loss: 0.362224\n",
      "epoch 29; iter: 0; batch classifier loss: 0.334909; batch adversarial loss: 0.430321\n",
      "epoch 29; iter: 200; batch classifier loss: 0.354359; batch adversarial loss: 0.434647\n",
      "epoch 30; iter: 0; batch classifier loss: 0.380847; batch adversarial loss: 0.461649\n",
      "epoch 30; iter: 200; batch classifier loss: 0.349620; batch adversarial loss: 0.388810\n",
      "epoch 31; iter: 0; batch classifier loss: 0.320237; batch adversarial loss: 0.333015\n",
      "epoch 31; iter: 200; batch classifier loss: 0.456486; batch adversarial loss: 0.403626\n",
      "epoch 32; iter: 0; batch classifier loss: 0.321230; batch adversarial loss: 0.360838\n",
      "epoch 32; iter: 200; batch classifier loss: 0.329559; batch adversarial loss: 0.378794\n",
      "epoch 33; iter: 0; batch classifier loss: 0.263501; batch adversarial loss: 0.338910\n",
      "epoch 33; iter: 200; batch classifier loss: 0.443163; batch adversarial loss: 0.433928\n",
      "epoch 34; iter: 0; batch classifier loss: 0.379801; batch adversarial loss: 0.384246\n",
      "epoch 34; iter: 200; batch classifier loss: 0.307927; batch adversarial loss: 0.397020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410669; batch adversarial loss: 0.380847\n",
      "epoch 35; iter: 200; batch classifier loss: 0.321340; batch adversarial loss: 0.431367\n",
      "epoch 36; iter: 0; batch classifier loss: 0.313712; batch adversarial loss: 0.372363\n",
      "epoch 36; iter: 200; batch classifier loss: 0.412623; batch adversarial loss: 0.332183\n",
      "epoch 37; iter: 0; batch classifier loss: 0.436884; batch adversarial loss: 0.362584\n",
      "epoch 37; iter: 200; batch classifier loss: 0.398531; batch adversarial loss: 0.499367\n",
      "epoch 38; iter: 0; batch classifier loss: 0.500394; batch adversarial loss: 0.317396\n",
      "epoch 38; iter: 200; batch classifier loss: 0.354420; batch adversarial loss: 0.432517\n",
      "epoch 39; iter: 0; batch classifier loss: 0.275964; batch adversarial loss: 0.455825\n",
      "epoch 39; iter: 200; batch classifier loss: 0.332022; batch adversarial loss: 0.466772\n",
      "epoch 40; iter: 0; batch classifier loss: 0.297174; batch adversarial loss: 0.525406\n",
      "epoch 40; iter: 200; batch classifier loss: 0.332807; batch adversarial loss: 0.362566\n",
      "epoch 41; iter: 0; batch classifier loss: 0.313649; batch adversarial loss: 0.429870\n",
      "epoch 41; iter: 200; batch classifier loss: 0.399507; batch adversarial loss: 0.357101\n",
      "epoch 42; iter: 0; batch classifier loss: 0.398524; batch adversarial loss: 0.462888\n",
      "epoch 42; iter: 200; batch classifier loss: 0.316765; batch adversarial loss: 0.396620\n",
      "epoch 43; iter: 0; batch classifier loss: 0.385761; batch adversarial loss: 0.448949\n",
      "epoch 43; iter: 200; batch classifier loss: 0.416894; batch adversarial loss: 0.504514\n",
      "epoch 44; iter: 0; batch classifier loss: 0.364829; batch adversarial loss: 0.447230\n",
      "epoch 44; iter: 200; batch classifier loss: 0.389920; batch adversarial loss: 0.350394\n",
      "epoch 45; iter: 0; batch classifier loss: 0.448429; batch adversarial loss: 0.400518\n",
      "epoch 45; iter: 200; batch classifier loss: 0.255370; batch adversarial loss: 0.485947\n",
      "epoch 46; iter: 0; batch classifier loss: 0.343070; batch adversarial loss: 0.398489\n",
      "epoch 46; iter: 200; batch classifier loss: 0.396499; batch adversarial loss: 0.447999\n",
      "epoch 47; iter: 0; batch classifier loss: 0.427677; batch adversarial loss: 0.432017\n",
      "epoch 47; iter: 200; batch classifier loss: 0.504051; batch adversarial loss: 0.419856\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400208; batch adversarial loss: 0.394185\n",
      "epoch 48; iter: 200; batch classifier loss: 0.302737; batch adversarial loss: 0.365099\n",
      "epoch 49; iter: 0; batch classifier loss: 0.444570; batch adversarial loss: 0.483403\n",
      "epoch 49; iter: 200; batch classifier loss: 0.487981; batch adversarial loss: 0.438124\n",
      "epoch 0; iter: 0; batch classifier loss: 28.978298; batch adversarial loss: 0.762061\n",
      "epoch 0; iter: 200; batch classifier loss: 11.481031; batch adversarial loss: 0.624127\n",
      "epoch 1; iter: 0; batch classifier loss: 6.834821; batch adversarial loss: 0.565502\n",
      "epoch 1; iter: 200; batch classifier loss: 23.405064; batch adversarial loss: 0.555268\n",
      "epoch 2; iter: 0; batch classifier loss: 4.028558; batch adversarial loss: 0.504206\n",
      "epoch 2; iter: 200; batch classifier loss: 1.438670; batch adversarial loss: 0.514223\n",
      "epoch 3; iter: 0; batch classifier loss: 1.394803; batch adversarial loss: 0.473639\n",
      "epoch 3; iter: 200; batch classifier loss: 4.234028; batch adversarial loss: 0.427439\n",
      "epoch 4; iter: 0; batch classifier loss: 1.450870; batch adversarial loss: 0.389989\n",
      "epoch 4; iter: 200; batch classifier loss: 2.178165; batch adversarial loss: 0.393638\n",
      "epoch 5; iter: 0; batch classifier loss: 2.118171; batch adversarial loss: 0.472561\n",
      "epoch 5; iter: 200; batch classifier loss: 3.161921; batch adversarial loss: 0.388706\n",
      "epoch 6; iter: 0; batch classifier loss: 0.653866; batch adversarial loss: 0.429290\n",
      "epoch 6; iter: 200; batch classifier loss: 2.526145; batch adversarial loss: 0.401413\n",
      "epoch 7; iter: 0; batch classifier loss: 1.098002; batch adversarial loss: 0.372372\n",
      "epoch 7; iter: 200; batch classifier loss: 0.526262; batch adversarial loss: 0.458942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.658356; batch adversarial loss: 0.445720\n",
      "epoch 8; iter: 200; batch classifier loss: 0.641241; batch adversarial loss: 0.434710\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601979; batch adversarial loss: 0.403876\n",
      "epoch 9; iter: 200; batch classifier loss: 0.666151; batch adversarial loss: 0.377209\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541947; batch adversarial loss: 0.506412\n",
      "epoch 10; iter: 200; batch classifier loss: 0.381818; batch adversarial loss: 0.425104\n",
      "epoch 11; iter: 0; batch classifier loss: 0.469892; batch adversarial loss: 0.452965\n",
      "epoch 11; iter: 200; batch classifier loss: 0.438370; batch adversarial loss: 0.395141\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448770; batch adversarial loss: 0.419804\n",
      "epoch 12; iter: 200; batch classifier loss: 0.401064; batch adversarial loss: 0.474589\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445622; batch adversarial loss: 0.415706\n",
      "epoch 13; iter: 200; batch classifier loss: 0.366133; batch adversarial loss: 0.363099\n",
      "epoch 14; iter: 0; batch classifier loss: 0.727540; batch adversarial loss: 0.418856\n",
      "epoch 14; iter: 200; batch classifier loss: 0.334811; batch adversarial loss: 0.357621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349763; batch adversarial loss: 0.350994\n",
      "epoch 15; iter: 200; batch classifier loss: 0.315642; batch adversarial loss: 0.502707\n",
      "epoch 16; iter: 0; batch classifier loss: 0.283478; batch adversarial loss: 0.403899\n",
      "epoch 16; iter: 200; batch classifier loss: 0.382268; batch adversarial loss: 0.368671\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347533; batch adversarial loss: 0.486097\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339086; batch adversarial loss: 0.359947\n",
      "epoch 18; iter: 0; batch classifier loss: 0.423321; batch adversarial loss: 0.467067\n",
      "epoch 18; iter: 200; batch classifier loss: 0.407310; batch adversarial loss: 0.394657\n",
      "epoch 19; iter: 0; batch classifier loss: 0.298177; batch adversarial loss: 0.428917\n",
      "epoch 19; iter: 200; batch classifier loss: 0.319475; batch adversarial loss: 0.442698\n",
      "epoch 20; iter: 0; batch classifier loss: 0.318045; batch adversarial loss: 0.400347\n",
      "epoch 20; iter: 200; batch classifier loss: 0.442220; batch adversarial loss: 0.339459\n",
      "epoch 21; iter: 0; batch classifier loss: 0.343733; batch adversarial loss: 0.444503\n",
      "epoch 21; iter: 200; batch classifier loss: 0.335835; batch adversarial loss: 0.403079\n",
      "epoch 22; iter: 0; batch classifier loss: 0.406915; batch adversarial loss: 0.431028\n",
      "epoch 22; iter: 200; batch classifier loss: 0.343262; batch adversarial loss: 0.470363\n",
      "epoch 23; iter: 0; batch classifier loss: 0.332290; batch adversarial loss: 0.324981\n",
      "epoch 23; iter: 200; batch classifier loss: 0.321742; batch adversarial loss: 0.428641\n",
      "epoch 24; iter: 0; batch classifier loss: 0.373447; batch adversarial loss: 0.382748\n",
      "epoch 24; iter: 200; batch classifier loss: 0.350643; batch adversarial loss: 0.379681\n",
      "epoch 25; iter: 0; batch classifier loss: 0.305017; batch adversarial loss: 0.474408\n",
      "epoch 25; iter: 200; batch classifier loss: 0.235002; batch adversarial loss: 0.428886\n",
      "epoch 26; iter: 0; batch classifier loss: 0.380287; batch adversarial loss: 0.377472\n",
      "epoch 26; iter: 200; batch classifier loss: 0.432729; batch adversarial loss: 0.429650\n",
      "epoch 27; iter: 0; batch classifier loss: 0.293004; batch adversarial loss: 0.447116\n",
      "epoch 27; iter: 200; batch classifier loss: 0.352863; batch adversarial loss: 0.378629\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352394; batch adversarial loss: 0.428635\n",
      "epoch 28; iter: 200; batch classifier loss: 0.297944; batch adversarial loss: 0.492321\n",
      "epoch 29; iter: 0; batch classifier loss: 0.314999; batch adversarial loss: 0.366355\n",
      "epoch 29; iter: 200; batch classifier loss: 0.445788; batch adversarial loss: 0.392104\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414145; batch adversarial loss: 0.381881\n",
      "epoch 30; iter: 200; batch classifier loss: 0.399149; batch adversarial loss: 0.496795\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315670; batch adversarial loss: 0.458384\n",
      "epoch 31; iter: 200; batch classifier loss: 0.450539; batch adversarial loss: 0.398026\n",
      "epoch 32; iter: 0; batch classifier loss: 0.232381; batch adversarial loss: 0.390163\n",
      "epoch 32; iter: 200; batch classifier loss: 0.393561; batch adversarial loss: 0.410537\n",
      "epoch 33; iter: 0; batch classifier loss: 0.284464; batch adversarial loss: 0.399214\n",
      "epoch 33; iter: 200; batch classifier loss: 0.339430; batch adversarial loss: 0.472954\n",
      "epoch 34; iter: 0; batch classifier loss: 0.336193; batch adversarial loss: 0.459782\n",
      "epoch 34; iter: 200; batch classifier loss: 0.369545; batch adversarial loss: 0.362556\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430948; batch adversarial loss: 0.445727\n",
      "epoch 35; iter: 200; batch classifier loss: 0.445380; batch adversarial loss: 0.413660\n",
      "epoch 36; iter: 0; batch classifier loss: 0.375866; batch adversarial loss: 0.388854\n",
      "epoch 36; iter: 200; batch classifier loss: 0.326509; batch adversarial loss: 0.402646\n",
      "epoch 37; iter: 0; batch classifier loss: 0.342941; batch adversarial loss: 0.368357\n",
      "epoch 37; iter: 200; batch classifier loss: 0.303410; batch adversarial loss: 0.469014\n",
      "epoch 38; iter: 0; batch classifier loss: 0.377013; batch adversarial loss: 0.534756\n",
      "epoch 38; iter: 200; batch classifier loss: 0.518080; batch adversarial loss: 0.405421\n",
      "epoch 39; iter: 0; batch classifier loss: 0.516042; batch adversarial loss: 0.510996\n",
      "epoch 39; iter: 200; batch classifier loss: 0.498680; batch adversarial loss: 0.410495\n",
      "epoch 40; iter: 0; batch classifier loss: 0.493896; batch adversarial loss: 0.474852\n",
      "epoch 40; iter: 200; batch classifier loss: 0.603491; batch adversarial loss: 0.411792\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388139; batch adversarial loss: 0.468745\n",
      "epoch 41; iter: 200; batch classifier loss: 0.528522; batch adversarial loss: 0.379869\n",
      "epoch 42; iter: 0; batch classifier loss: 0.504892; batch adversarial loss: 0.350916\n",
      "epoch 42; iter: 200; batch classifier loss: 0.659475; batch adversarial loss: 0.332877\n",
      "epoch 43; iter: 0; batch classifier loss: 0.637428; batch adversarial loss: 0.430378\n",
      "epoch 43; iter: 200; batch classifier loss: 0.396393; batch adversarial loss: 0.339793\n",
      "epoch 44; iter: 0; batch classifier loss: 0.361149; batch adversarial loss: 0.439516\n",
      "epoch 44; iter: 200; batch classifier loss: 0.472486; batch adversarial loss: 0.383185\n",
      "epoch 45; iter: 0; batch classifier loss: 0.379207; batch adversarial loss: 0.484931\n",
      "epoch 45; iter: 200; batch classifier loss: 0.483795; batch adversarial loss: 0.450425\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420711; batch adversarial loss: 0.372651\n",
      "epoch 46; iter: 200; batch classifier loss: 0.476976; batch adversarial loss: 0.342956\n",
      "epoch 47; iter: 0; batch classifier loss: 0.512300; batch adversarial loss: 0.494982\n",
      "epoch 47; iter: 200; batch classifier loss: 0.511859; batch adversarial loss: 0.434892\n",
      "epoch 48; iter: 0; batch classifier loss: 0.495984; batch adversarial loss: 0.521990\n",
      "epoch 48; iter: 200; batch classifier loss: 0.435078; batch adversarial loss: 0.308798\n",
      "epoch 49; iter: 0; batch classifier loss: 0.491203; batch adversarial loss: 0.407972\n",
      "epoch 49; iter: 200; batch classifier loss: 0.691884; batch adversarial loss: 0.390856\n",
      "epoch 0; iter: 0; batch classifier loss: 5.482606; batch adversarial loss: 0.560017\n",
      "epoch 0; iter: 200; batch classifier loss: 3.319817; batch adversarial loss: 0.578034\n",
      "epoch 1; iter: 0; batch classifier loss: 1.044440; batch adversarial loss: 0.546270\n",
      "epoch 1; iter: 200; batch classifier loss: 7.500479; batch adversarial loss: 0.489905\n",
      "epoch 2; iter: 0; batch classifier loss: 3.166385; batch adversarial loss: 0.508411\n",
      "epoch 2; iter: 200; batch classifier loss: 9.555504; batch adversarial loss: 0.456159\n",
      "epoch 3; iter: 0; batch classifier loss: 2.885408; batch adversarial loss: 0.445621\n",
      "epoch 3; iter: 200; batch classifier loss: 0.840303; batch adversarial loss: 0.433701\n",
      "epoch 4; iter: 0; batch classifier loss: 2.416007; batch adversarial loss: 0.435762\n",
      "epoch 4; iter: 200; batch classifier loss: 2.072885; batch adversarial loss: 0.431564\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597059; batch adversarial loss: 0.406381\n",
      "epoch 5; iter: 200; batch classifier loss: 0.807069; batch adversarial loss: 0.356856\n",
      "epoch 6; iter: 0; batch classifier loss: 0.890619; batch adversarial loss: 0.410495\n",
      "epoch 6; iter: 200; batch classifier loss: 0.507074; batch adversarial loss: 0.378075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.341565; batch adversarial loss: 0.421234\n",
      "epoch 7; iter: 200; batch classifier loss: 0.462319; batch adversarial loss: 0.376827\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633567; batch adversarial loss: 0.464042\n",
      "epoch 8; iter: 200; batch classifier loss: 0.426131; batch adversarial loss: 0.422838\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389657; batch adversarial loss: 0.427728\n",
      "epoch 9; iter: 200; batch classifier loss: 0.475244; batch adversarial loss: 0.437098\n",
      "epoch 10; iter: 0; batch classifier loss: 0.377647; batch adversarial loss: 0.448989\n",
      "epoch 10; iter: 200; batch classifier loss: 0.384624; batch adversarial loss: 0.381511\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448578; batch adversarial loss: 0.476872\n",
      "epoch 11; iter: 200; batch classifier loss: 0.432377; batch adversarial loss: 0.421803\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347292; batch adversarial loss: 0.364343\n",
      "epoch 12; iter: 200; batch classifier loss: 0.378065; batch adversarial loss: 0.410368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417434; batch adversarial loss: 0.416803\n",
      "epoch 13; iter: 200; batch classifier loss: 0.414354; batch adversarial loss: 0.431440\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437724; batch adversarial loss: 0.398424\n",
      "epoch 14; iter: 200; batch classifier loss: 0.367829; batch adversarial loss: 0.452301\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350546; batch adversarial loss: 0.254498\n",
      "epoch 15; iter: 200; batch classifier loss: 0.276381; batch adversarial loss: 0.436985\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306036; batch adversarial loss: 0.489248\n",
      "epoch 16; iter: 200; batch classifier loss: 0.433126; batch adversarial loss: 0.472850\n",
      "epoch 17; iter: 0; batch classifier loss: 0.431372; batch adversarial loss: 0.434971\n",
      "epoch 17; iter: 200; batch classifier loss: 0.297217; batch adversarial loss: 0.397668\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268082; batch adversarial loss: 0.403792\n",
      "epoch 18; iter: 200; batch classifier loss: 0.347641; batch adversarial loss: 0.461241\n",
      "epoch 19; iter: 0; batch classifier loss: 0.413978; batch adversarial loss: 0.442122\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350402; batch adversarial loss: 0.495732\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333481; batch adversarial loss: 0.420077\n",
      "epoch 20; iter: 200; batch classifier loss: 0.319374; batch adversarial loss: 0.347393\n",
      "epoch 21; iter: 0; batch classifier loss: 0.290002; batch adversarial loss: 0.566643\n",
      "epoch 21; iter: 200; batch classifier loss: 0.301117; batch adversarial loss: 0.365692\n",
      "epoch 22; iter: 0; batch classifier loss: 0.338272; batch adversarial loss: 0.290453\n",
      "epoch 22; iter: 200; batch classifier loss: 0.308724; batch adversarial loss: 0.424421\n",
      "epoch 23; iter: 0; batch classifier loss: 0.305000; batch adversarial loss: 0.370386\n",
      "epoch 23; iter: 200; batch classifier loss: 0.361228; batch adversarial loss: 0.426450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.409016; batch adversarial loss: 0.365750\n",
      "epoch 24; iter: 200; batch classifier loss: 0.346316; batch adversarial loss: 0.403188\n",
      "epoch 25; iter: 0; batch classifier loss: 0.338256; batch adversarial loss: 0.387982\n",
      "epoch 25; iter: 200; batch classifier loss: 0.305233; batch adversarial loss: 0.428198\n",
      "epoch 26; iter: 0; batch classifier loss: 0.338369; batch adversarial loss: 0.422399\n",
      "epoch 26; iter: 200; batch classifier loss: 0.379263; batch adversarial loss: 0.535354\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362776; batch adversarial loss: 0.310150\n",
      "epoch 27; iter: 200; batch classifier loss: 0.324027; batch adversarial loss: 0.507637\n",
      "epoch 28; iter: 0; batch classifier loss: 0.356116; batch adversarial loss: 0.382790\n",
      "epoch 28; iter: 200; batch classifier loss: 0.434478; batch adversarial loss: 0.327734\n",
      "epoch 29; iter: 0; batch classifier loss: 0.371264; batch adversarial loss: 0.346994\n",
      "epoch 29; iter: 200; batch classifier loss: 0.368848; batch adversarial loss: 0.448520\n",
      "epoch 30; iter: 0; batch classifier loss: 0.258753; batch adversarial loss: 0.433973\n",
      "epoch 30; iter: 200; batch classifier loss: 0.322746; batch adversarial loss: 0.429051\n",
      "epoch 31; iter: 0; batch classifier loss: 0.281736; batch adversarial loss: 0.385239\n",
      "epoch 31; iter: 200; batch classifier loss: 0.254427; batch adversarial loss: 0.392664\n",
      "epoch 32; iter: 0; batch classifier loss: 0.293989; batch adversarial loss: 0.468903\n",
      "epoch 32; iter: 200; batch classifier loss: 0.317839; batch adversarial loss: 0.411647\n",
      "epoch 33; iter: 0; batch classifier loss: 0.356090; batch adversarial loss: 0.338553\n",
      "epoch 33; iter: 200; batch classifier loss: 0.388696; batch adversarial loss: 0.416176\n",
      "epoch 34; iter: 0; batch classifier loss: 0.373410; batch adversarial loss: 0.449185\n",
      "epoch 34; iter: 200; batch classifier loss: 0.293858; batch adversarial loss: 0.378271\n",
      "epoch 35; iter: 0; batch classifier loss: 0.341062; batch adversarial loss: 0.419580\n",
      "epoch 35; iter: 200; batch classifier loss: 0.438980; batch adversarial loss: 0.393800\n",
      "epoch 36; iter: 0; batch classifier loss: 0.292871; batch adversarial loss: 0.462469\n",
      "epoch 36; iter: 200; batch classifier loss: 0.364761; batch adversarial loss: 0.489114\n",
      "epoch 37; iter: 0; batch classifier loss: 0.344711; batch adversarial loss: 0.421600\n",
      "epoch 37; iter: 200; batch classifier loss: 0.546668; batch adversarial loss: 0.383038\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400349; batch adversarial loss: 0.415360\n",
      "epoch 38; iter: 200; batch classifier loss: 0.403399; batch adversarial loss: 0.361776\n",
      "epoch 39; iter: 0; batch classifier loss: 0.291369; batch adversarial loss: 0.453676\n",
      "epoch 39; iter: 200; batch classifier loss: 0.343706; batch adversarial loss: 0.435811\n",
      "epoch 40; iter: 0; batch classifier loss: 0.307405; batch adversarial loss: 0.490316\n",
      "epoch 40; iter: 200; batch classifier loss: 0.375724; batch adversarial loss: 0.421334\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416713; batch adversarial loss: 0.479337\n",
      "epoch 41; iter: 200; batch classifier loss: 0.379614; batch adversarial loss: 0.441213\n",
      "epoch 42; iter: 0; batch classifier loss: 0.371481; batch adversarial loss: 0.463000\n",
      "epoch 42; iter: 200; batch classifier loss: 0.293240; batch adversarial loss: 0.268937\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421999; batch adversarial loss: 0.397830\n",
      "epoch 43; iter: 200; batch classifier loss: 0.418788; batch adversarial loss: 0.361758\n",
      "epoch 44; iter: 0; batch classifier loss: 0.508234; batch adversarial loss: 0.321236\n",
      "epoch 44; iter: 200; batch classifier loss: 0.309814; batch adversarial loss: 0.513012\n",
      "epoch 45; iter: 0; batch classifier loss: 0.309498; batch adversarial loss: 0.333001\n",
      "epoch 45; iter: 200; batch classifier loss: 0.315200; batch adversarial loss: 0.488484\n",
      "epoch 46; iter: 0; batch classifier loss: 0.398594; batch adversarial loss: 0.402451\n",
      "epoch 46; iter: 200; batch classifier loss: 0.308850; batch adversarial loss: 0.388438\n",
      "epoch 47; iter: 0; batch classifier loss: 0.549110; batch adversarial loss: 0.356027\n",
      "epoch 47; iter: 200; batch classifier loss: 0.383286; batch adversarial loss: 0.406944\n",
      "epoch 48; iter: 0; batch classifier loss: 0.356538; batch adversarial loss: 0.486232\n",
      "epoch 48; iter: 200; batch classifier loss: 0.355637; batch adversarial loss: 0.427451\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449640; batch adversarial loss: 0.380576\n",
      "epoch 49; iter: 200; batch classifier loss: 0.547746; batch adversarial loss: 0.467115\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.824350  0.521927  0.019024  1.188628  0.173825  0.103728\n",
      "std   0.018989  0.084946  0.026998  0.270351  0.078823  0.043187\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedShuffleSplit, StratifiedKFold\n",
    "from src.metrics import best_hyperparameter_advdeb\n",
    "\n",
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Hyperparameter Search\n",
    "param_grid = {\n",
    "    'adversary_loss_weight': [0.5, 1.0],\n",
    "    'num_epochs':            [10, 20, 50],\n",
    "    'batch_size':            [64, 128]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "grid_results = []\n",
    "# Perform hyperparameter search with 15 stratified shuffle splits\n",
    "for params in grid:\n",
    "    print(f\"Testing config: {params}\")\n",
    "    fold_metrics = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=15, test_size=0.2, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            privileged_groups, unprivileged_groups,\n",
    "            scope_name='adv',\n",
    "            num_epochs=params['num_epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            adversary_loss_weight=params['adversary_loss_weight']\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "    \n",
    "    df_fm = pd.DataFrame(fold_metrics)\n",
    "    agg = df_fm.agg(['mean', 'std'])\n",
    "    \n",
    "    grid_results.append({\n",
    "        **params,\n",
    "        'acc_mean':   agg.loc['mean', 'accuracy'],\n",
    "        'acc_std':    agg.loc['std',  'accuracy'],\n",
    "        'f1_mean':    agg.loc['mean', 'f1_score'],\n",
    "        'f1_std':     agg.loc['std',  'f1_score'],\n",
    "        'SPD_mean':   agg.loc['mean', 'SPD'],\n",
    "        'SPD_std':    agg.loc['std',  'SPD'],\n",
    "        'DI_mean':    agg.loc['mean', 'DI'],\n",
    "        'DI_std':     agg.loc['std',  'DI'],\n",
    "        'EOD_mean':   agg.loc['mean', 'EOD'],\n",
    "        'EOD_std':    agg.loc['std',  'EOD'],\n",
    "        'AOD_mean':   agg.loc['mean', 'AOD'],\n",
    "        'AOD_std':    agg.loc['std',  'AOD'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Hyperparameter Selection\n",
    "best_param = best_hyperparameter_advdeb(results_df)\n",
    "print(f\"Best parameters: {best_param}\")\n",
    "\n",
    "# Final evaluation with StratifiedKFold\n",
    "loss_weight = best_param['adversary_loss_weight']\n",
    "n_epochs    = int(best_param['num_epochs'])\n",
    "batch_sz    = int(best_param['batch_size'])\n",
    "\n",
    "# 4) Run experiment, Evaluate\n",
    "results = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        privileged_groups, unprivileged_groups,\n",
    "        scope_name='adv',\n",
    "        num_epochs=n_epochs,\n",
    "        batch_size=batch_sz,\n",
    "        adversary_loss_weight=loss_weight\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "    \n",
    "# 5) Aggregate results\n",
    "adult_race_metrics = pd.DataFrame(results)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6497f4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', 'Hyperparametertuned Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a3525",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c2fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 25.771790; batch adversarial loss: 0.833647\n",
      "epoch 0; iter: 200; batch classifier loss: 3.460274; batch adversarial loss: 0.837948\n",
      "epoch 0; iter: 400; batch classifier loss: 5.854748; batch adversarial loss: 0.687311\n",
      "epoch 1; iter: 0; batch classifier loss: 9.761111; batch adversarial loss: 0.616297\n",
      "epoch 1; iter: 200; batch classifier loss: 4.855860; batch adversarial loss: 0.653524\n",
      "epoch 1; iter: 400; batch classifier loss: 6.527667; batch adversarial loss: 0.602765\n",
      "epoch 2; iter: 0; batch classifier loss: 3.862137; batch adversarial loss: 0.699010\n",
      "epoch 2; iter: 200; batch classifier loss: 12.679238; batch adversarial loss: 0.591481\n",
      "epoch 2; iter: 400; batch classifier loss: 4.127738; batch adversarial loss: 0.605022\n",
      "epoch 3; iter: 0; batch classifier loss: 1.010226; batch adversarial loss: 0.724721\n",
      "epoch 3; iter: 200; batch classifier loss: 5.852661; batch adversarial loss: 0.629028\n",
      "epoch 3; iter: 400; batch classifier loss: 2.485197; batch adversarial loss: 0.648892\n",
      "epoch 4; iter: 0; batch classifier loss: 1.503626; batch adversarial loss: 0.619250\n",
      "epoch 4; iter: 200; batch classifier loss: 1.922454; batch adversarial loss: 0.593586\n",
      "epoch 4; iter: 400; batch classifier loss: 2.481415; batch adversarial loss: 0.686086\n",
      "epoch 5; iter: 0; batch classifier loss: 1.625989; batch adversarial loss: 0.595727\n",
      "epoch 5; iter: 200; batch classifier loss: 1.370272; batch adversarial loss: 0.648544\n",
      "epoch 5; iter: 400; batch classifier loss: 1.259546; batch adversarial loss: 0.626240\n",
      "epoch 6; iter: 0; batch classifier loss: 1.013876; batch adversarial loss: 0.598512\n",
      "epoch 6; iter: 200; batch classifier loss: 1.355655; batch adversarial loss: 0.696466\n",
      "epoch 6; iter: 400; batch classifier loss: 0.837688; batch adversarial loss: 0.590056\n",
      "epoch 7; iter: 0; batch classifier loss: 1.708735; batch adversarial loss: 0.611741\n",
      "epoch 7; iter: 200; batch classifier loss: 0.579610; batch adversarial loss: 0.586282\n",
      "epoch 7; iter: 400; batch classifier loss: 0.472124; batch adversarial loss: 0.537856\n",
      "epoch 8; iter: 0; batch classifier loss: 0.645451; batch adversarial loss: 0.601614\n",
      "epoch 8; iter: 200; batch classifier loss: 0.583539; batch adversarial loss: 0.604289\n",
      "epoch 8; iter: 400; batch classifier loss: 0.363722; batch adversarial loss: 0.654272\n",
      "epoch 9; iter: 0; batch classifier loss: 0.378230; batch adversarial loss: 0.598126\n",
      "epoch 9; iter: 200; batch classifier loss: 0.492690; batch adversarial loss: 0.576682\n",
      "epoch 9; iter: 400; batch classifier loss: 0.361144; batch adversarial loss: 0.684645\n",
      "epoch 0; iter: 0; batch classifier loss: 19.715633; batch adversarial loss: 0.706180\n",
      "epoch 0; iter: 200; batch classifier loss: 2.360439; batch adversarial loss: 0.628239\n",
      "epoch 0; iter: 400; batch classifier loss: 29.750219; batch adversarial loss: 0.620290\n",
      "epoch 1; iter: 0; batch classifier loss: 8.895914; batch adversarial loss: 0.636048\n",
      "epoch 1; iter: 200; batch classifier loss: 1.545693; batch adversarial loss: 0.581152\n",
      "epoch 1; iter: 400; batch classifier loss: 4.307802; batch adversarial loss: 0.613762\n",
      "epoch 2; iter: 0; batch classifier loss: 5.989153; batch adversarial loss: 0.633904\n",
      "epoch 2; iter: 200; batch classifier loss: 5.487988; batch adversarial loss: 0.627262\n",
      "epoch 2; iter: 400; batch classifier loss: 2.063115; batch adversarial loss: 0.622290\n",
      "epoch 3; iter: 0; batch classifier loss: 0.987097; batch adversarial loss: 0.634067\n",
      "epoch 3; iter: 200; batch classifier loss: 1.498271; batch adversarial loss: 0.695367\n",
      "epoch 3; iter: 400; batch classifier loss: 0.522768; batch adversarial loss: 0.595139\n",
      "epoch 4; iter: 0; batch classifier loss: 0.920993; batch adversarial loss: 0.633715\n",
      "epoch 4; iter: 200; batch classifier loss: 0.625814; batch adversarial loss: 0.582704\n",
      "epoch 4; iter: 400; batch classifier loss: 0.576534; batch adversarial loss: 0.601639\n",
      "epoch 5; iter: 0; batch classifier loss: 0.391424; batch adversarial loss: 0.648128\n",
      "epoch 5; iter: 200; batch classifier loss: 0.645386; batch adversarial loss: 0.641433\n",
      "epoch 5; iter: 400; batch classifier loss: 0.564702; batch adversarial loss: 0.641262\n",
      "epoch 6; iter: 0; batch classifier loss: 0.737087; batch adversarial loss: 0.646661\n",
      "epoch 6; iter: 200; batch classifier loss: 0.487658; batch adversarial loss: 0.544503\n",
      "epoch 6; iter: 400; batch classifier loss: 0.318882; batch adversarial loss: 0.616037\n",
      "epoch 7; iter: 0; batch classifier loss: 0.519342; batch adversarial loss: 0.658003\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416711; batch adversarial loss: 0.616093\n",
      "epoch 7; iter: 400; batch classifier loss: 0.242464; batch adversarial loss: 0.633508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.466871; batch adversarial loss: 0.685592\n",
      "epoch 8; iter: 200; batch classifier loss: 0.580280; batch adversarial loss: 0.631180\n",
      "epoch 8; iter: 400; batch classifier loss: 0.264694; batch adversarial loss: 0.607807\n",
      "epoch 9; iter: 0; batch classifier loss: 0.672518; batch adversarial loss: 0.657328\n",
      "epoch 9; iter: 200; batch classifier loss: 0.470686; batch adversarial loss: 0.653280\n",
      "epoch 9; iter: 400; batch classifier loss: 0.358423; batch adversarial loss: 0.633563\n",
      "epoch 0; iter: 0; batch classifier loss: 20.181463; batch adversarial loss: 0.679745\n",
      "epoch 0; iter: 200; batch classifier loss: 13.359194; batch adversarial loss: 0.602020\n",
      "epoch 0; iter: 400; batch classifier loss: 7.406876; batch adversarial loss: 0.659489\n",
      "epoch 1; iter: 0; batch classifier loss: 2.851528; batch adversarial loss: 0.606879\n",
      "epoch 1; iter: 200; batch classifier loss: 10.967255; batch adversarial loss: 0.550622\n",
      "epoch 1; iter: 400; batch classifier loss: 8.003029; batch adversarial loss: 0.632574\n",
      "epoch 2; iter: 0; batch classifier loss: 2.112222; batch adversarial loss: 0.651913\n",
      "epoch 2; iter: 200; batch classifier loss: 3.884469; batch adversarial loss: 0.637601\n",
      "epoch 2; iter: 400; batch classifier loss: 1.352267; batch adversarial loss: 0.614661\n",
      "epoch 3; iter: 0; batch classifier loss: 2.178936; batch adversarial loss: 0.629839\n",
      "epoch 3; iter: 200; batch classifier loss: 1.066302; batch adversarial loss: 0.597724\n",
      "epoch 3; iter: 400; batch classifier loss: 1.202955; batch adversarial loss: 0.632685\n",
      "epoch 4; iter: 0; batch classifier loss: 1.007691; batch adversarial loss: 0.590505\n",
      "epoch 4; iter: 200; batch classifier loss: 2.616129; batch adversarial loss: 0.645437\n",
      "epoch 4; iter: 400; batch classifier loss: 0.552093; batch adversarial loss: 0.637172\n",
      "epoch 5; iter: 0; batch classifier loss: 1.232975; batch adversarial loss: 0.638860\n",
      "epoch 5; iter: 200; batch classifier loss: 0.802916; batch adversarial loss: 0.639353\n",
      "epoch 5; iter: 400; batch classifier loss: 0.767902; batch adversarial loss: 0.602507\n",
      "epoch 6; iter: 0; batch classifier loss: 0.413621; batch adversarial loss: 0.595186\n",
      "epoch 6; iter: 200; batch classifier loss: 0.509111; batch adversarial loss: 0.472582\n",
      "epoch 6; iter: 400; batch classifier loss: 0.503329; batch adversarial loss: 0.615476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.439738; batch adversarial loss: 0.577953\n",
      "epoch 7; iter: 200; batch classifier loss: 0.424127; batch adversarial loss: 0.639267\n",
      "epoch 7; iter: 400; batch classifier loss: 0.537289; batch adversarial loss: 0.574991\n",
      "epoch 8; iter: 0; batch classifier loss: 0.388598; batch adversarial loss: 0.608660\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387533; batch adversarial loss: 0.637617\n",
      "epoch 8; iter: 400; batch classifier loss: 0.436482; batch adversarial loss: 0.647330\n",
      "epoch 9; iter: 0; batch classifier loss: 0.381145; batch adversarial loss: 0.593911\n",
      "epoch 9; iter: 200; batch classifier loss: 0.355631; batch adversarial loss: 0.535373\n",
      "epoch 9; iter: 400; batch classifier loss: 0.386674; batch adversarial loss: 0.587201\n",
      "epoch 0; iter: 0; batch classifier loss: 20.005737; batch adversarial loss: 0.591090\n",
      "epoch 0; iter: 200; batch classifier loss: 40.794617; batch adversarial loss: 0.714055\n",
      "epoch 0; iter: 400; batch classifier loss: 4.090986; batch adversarial loss: 0.672717\n",
      "epoch 1; iter: 0; batch classifier loss: 17.347488; batch adversarial loss: 0.664805\n",
      "epoch 1; iter: 200; batch classifier loss: 14.953726; batch adversarial loss: 0.716273\n",
      "epoch 1; iter: 400; batch classifier loss: 2.692203; batch adversarial loss: 0.590328\n",
      "epoch 2; iter: 0; batch classifier loss: 2.260182; batch adversarial loss: 0.684141\n",
      "epoch 2; iter: 200; batch classifier loss: 0.329404; batch adversarial loss: 0.629511\n",
      "epoch 2; iter: 400; batch classifier loss: 3.425925; batch adversarial loss: 0.548138\n",
      "epoch 3; iter: 0; batch classifier loss: 5.762330; batch adversarial loss: 0.611311\n",
      "epoch 3; iter: 200; batch classifier loss: 1.841594; batch adversarial loss: 0.609165\n",
      "epoch 3; iter: 400; batch classifier loss: 2.401172; batch adversarial loss: 0.663120\n",
      "epoch 4; iter: 0; batch classifier loss: 9.393579; batch adversarial loss: 0.607392\n",
      "epoch 4; iter: 200; batch classifier loss: 0.886197; batch adversarial loss: 0.666199\n",
      "epoch 4; iter: 400; batch classifier loss: 3.851737; batch adversarial loss: 0.607075\n",
      "epoch 5; iter: 0; batch classifier loss: 0.454240; batch adversarial loss: 0.708269\n",
      "epoch 5; iter: 200; batch classifier loss: 1.910722; batch adversarial loss: 0.681116\n",
      "epoch 5; iter: 400; batch classifier loss: 1.229434; batch adversarial loss: 0.608087\n",
      "epoch 6; iter: 0; batch classifier loss: 3.438385; batch adversarial loss: 0.685581\n",
      "epoch 6; iter: 200; batch classifier loss: 2.825699; batch adversarial loss: 0.557224\n",
      "epoch 6; iter: 400; batch classifier loss: 2.607625; batch adversarial loss: 0.577484\n",
      "epoch 7; iter: 0; batch classifier loss: 0.861157; batch adversarial loss: 0.597358\n",
      "epoch 7; iter: 200; batch classifier loss: 0.316961; batch adversarial loss: 0.667698\n",
      "epoch 7; iter: 400; batch classifier loss: 0.531067; batch adversarial loss: 0.519637\n",
      "epoch 8; iter: 0; batch classifier loss: 0.706991; batch adversarial loss: 0.635733\n",
      "epoch 8; iter: 200; batch classifier loss: 0.594350; batch adversarial loss: 0.550603\n",
      "epoch 8; iter: 400; batch classifier loss: 0.450296; batch adversarial loss: 0.642070\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531685; batch adversarial loss: 0.673736\n",
      "epoch 9; iter: 200; batch classifier loss: 0.278293; batch adversarial loss: 0.677467\n",
      "epoch 9; iter: 400; batch classifier loss: 0.337628; batch adversarial loss: 0.572425\n",
      "epoch 0; iter: 0; batch classifier loss: 10.134456; batch adversarial loss: 0.854685\n",
      "epoch 0; iter: 200; batch classifier loss: 9.189554; batch adversarial loss: 0.723359\n",
      "epoch 0; iter: 400; batch classifier loss: 2.494456; batch adversarial loss: 0.662940\n",
      "epoch 1; iter: 0; batch classifier loss: 2.240729; batch adversarial loss: 0.665343\n",
      "epoch 1; iter: 200; batch classifier loss: 0.404517; batch adversarial loss: 0.600196\n",
      "epoch 1; iter: 400; batch classifier loss: 1.993522; batch adversarial loss: 0.615808\n",
      "epoch 2; iter: 0; batch classifier loss: 1.435102; batch adversarial loss: 0.599473\n",
      "epoch 2; iter: 200; batch classifier loss: 2.311862; batch adversarial loss: 0.604668\n",
      "epoch 2; iter: 400; batch classifier loss: 3.080791; batch adversarial loss: 0.634339\n",
      "epoch 3; iter: 0; batch classifier loss: 4.255270; batch adversarial loss: 0.628931\n",
      "epoch 3; iter: 200; batch classifier loss: 3.244517; batch adversarial loss: 0.608646\n",
      "epoch 3; iter: 400; batch classifier loss: 0.503229; batch adversarial loss: 0.634433\n",
      "epoch 4; iter: 0; batch classifier loss: 2.064069; batch adversarial loss: 0.630632\n",
      "epoch 4; iter: 200; batch classifier loss: 3.721630; batch adversarial loss: 0.607162\n",
      "epoch 4; iter: 400; batch classifier loss: 0.665388; batch adversarial loss: 0.611695\n",
      "epoch 5; iter: 0; batch classifier loss: 0.723846; batch adversarial loss: 0.681761\n",
      "epoch 5; iter: 200; batch classifier loss: 0.815825; batch adversarial loss: 0.662168\n",
      "epoch 5; iter: 400; batch classifier loss: 1.257237; batch adversarial loss: 0.614482\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388820; batch adversarial loss: 0.671305\n",
      "epoch 6; iter: 200; batch classifier loss: 0.505206; batch adversarial loss: 0.647222\n",
      "epoch 6; iter: 400; batch classifier loss: 0.337583; batch adversarial loss: 0.643849\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615625; batch adversarial loss: 0.630623\n",
      "epoch 7; iter: 200; batch classifier loss: 0.480384; batch adversarial loss: 0.616311\n",
      "epoch 7; iter: 400; batch classifier loss: 0.376049; batch adversarial loss: 0.615735\n",
      "epoch 8; iter: 0; batch classifier loss: 0.473937; batch adversarial loss: 0.529579\n",
      "epoch 8; iter: 200; batch classifier loss: 0.213665; batch adversarial loss: 0.662120\n",
      "epoch 8; iter: 400; batch classifier loss: 0.258364; batch adversarial loss: 0.565037\n",
      "epoch 9; iter: 0; batch classifier loss: 0.383300; batch adversarial loss: 0.626274\n",
      "epoch 9; iter: 200; batch classifier loss: 0.221346; batch adversarial loss: 0.592392\n",
      "epoch 9; iter: 400; batch classifier loss: 0.421543; batch adversarial loss: 0.673958\n",
      "epoch 0; iter: 0; batch classifier loss: 24.384344; batch adversarial loss: 0.638331\n",
      "epoch 0; iter: 200; batch classifier loss: 7.911035; batch adversarial loss: 0.613040\n",
      "epoch 0; iter: 400; batch classifier loss: 45.246567; batch adversarial loss: 0.652629\n",
      "epoch 1; iter: 0; batch classifier loss: 4.885251; batch adversarial loss: 0.646637\n",
      "epoch 1; iter: 200; batch classifier loss: 1.360730; batch adversarial loss: 0.532894\n",
      "epoch 1; iter: 400; batch classifier loss: 2.594996; batch adversarial loss: 0.684757\n",
      "epoch 2; iter: 0; batch classifier loss: 16.712505; batch adversarial loss: 0.731761\n",
      "epoch 2; iter: 200; batch classifier loss: 5.481382; batch adversarial loss: 0.563219\n",
      "epoch 2; iter: 400; batch classifier loss: 2.975121; batch adversarial loss: 0.611324\n",
      "epoch 3; iter: 0; batch classifier loss: 3.855530; batch adversarial loss: 0.681016\n",
      "epoch 3; iter: 200; batch classifier loss: 0.851696; batch adversarial loss: 0.682464\n",
      "epoch 3; iter: 400; batch classifier loss: 1.306283; batch adversarial loss: 0.617604\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539450; batch adversarial loss: 0.589617\n",
      "epoch 4; iter: 200; batch classifier loss: 0.748031; batch adversarial loss: 0.587808\n",
      "epoch 4; iter: 400; batch classifier loss: 1.152580; batch adversarial loss: 0.594706\n",
      "epoch 5; iter: 0; batch classifier loss: 1.086723; batch adversarial loss: 0.585021\n",
      "epoch 5; iter: 200; batch classifier loss: 0.684266; batch adversarial loss: 0.612393\n",
      "epoch 5; iter: 400; batch classifier loss: 0.650615; batch adversarial loss: 0.593883\n",
      "epoch 6; iter: 0; batch classifier loss: 0.433535; batch adversarial loss: 0.631952\n",
      "epoch 6; iter: 200; batch classifier loss: 0.308468; batch adversarial loss: 0.647539\n",
      "epoch 6; iter: 400; batch classifier loss: 0.528116; batch adversarial loss: 0.626816\n",
      "epoch 7; iter: 0; batch classifier loss: 0.463929; batch adversarial loss: 0.633055\n",
      "epoch 7; iter: 200; batch classifier loss: 0.632719; batch adversarial loss: 0.620114\n",
      "epoch 7; iter: 400; batch classifier loss: 0.419799; batch adversarial loss: 0.690148\n",
      "epoch 8; iter: 0; batch classifier loss: 0.386327; batch adversarial loss: 0.627743\n",
      "epoch 8; iter: 200; batch classifier loss: 0.480975; batch adversarial loss: 0.693041\n",
      "epoch 8; iter: 400; batch classifier loss: 0.424475; batch adversarial loss: 0.665143\n",
      "epoch 9; iter: 0; batch classifier loss: 0.370890; batch adversarial loss: 0.616827\n",
      "epoch 9; iter: 200; batch classifier loss: 0.241315; batch adversarial loss: 0.657613\n",
      "epoch 9; iter: 400; batch classifier loss: 0.334776; batch adversarial loss: 0.632097\n",
      "epoch 0; iter: 0; batch classifier loss: 19.807407; batch adversarial loss: 0.646585\n",
      "epoch 0; iter: 200; batch classifier loss: 9.218254; batch adversarial loss: 0.628993\n",
      "epoch 0; iter: 400; batch classifier loss: 2.946995; batch adversarial loss: 0.569114\n",
      "epoch 1; iter: 0; batch classifier loss: 13.771723; batch adversarial loss: 0.635965\n",
      "epoch 1; iter: 200; batch classifier loss: 0.323250; batch adversarial loss: 0.627153\n",
      "epoch 1; iter: 400; batch classifier loss: 3.301211; batch adversarial loss: 0.565484\n",
      "epoch 2; iter: 0; batch classifier loss: 3.053127; batch adversarial loss: 0.601761\n",
      "epoch 2; iter: 200; batch classifier loss: 8.657500; batch adversarial loss: 0.614208\n",
      "epoch 2; iter: 400; batch classifier loss: 0.460555; batch adversarial loss: 0.651495\n",
      "epoch 3; iter: 0; batch classifier loss: 2.271775; batch adversarial loss: 0.652387\n",
      "epoch 3; iter: 200; batch classifier loss: 3.939985; batch adversarial loss: 0.653478\n",
      "epoch 3; iter: 400; batch classifier loss: 1.582732; batch adversarial loss: 0.623727\n",
      "epoch 4; iter: 0; batch classifier loss: 0.932773; batch adversarial loss: 0.700599\n",
      "epoch 4; iter: 200; batch classifier loss: 0.773277; batch adversarial loss: 0.568888\n",
      "epoch 4; iter: 400; batch classifier loss: 0.630379; batch adversarial loss: 0.585412\n",
      "epoch 5; iter: 0; batch classifier loss: 0.685795; batch adversarial loss: 0.585195\n",
      "epoch 5; iter: 200; batch classifier loss: 0.524338; batch adversarial loss: 0.684493\n",
      "epoch 5; iter: 400; batch classifier loss: 0.405068; batch adversarial loss: 0.640117\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501197; batch adversarial loss: 0.643495\n",
      "epoch 6; iter: 200; batch classifier loss: 0.311697; batch adversarial loss: 0.689063\n",
      "epoch 6; iter: 400; batch classifier loss: 0.492237; batch adversarial loss: 0.596165\n",
      "epoch 7; iter: 0; batch classifier loss: 0.407200; batch adversarial loss: 0.612671\n",
      "epoch 7; iter: 200; batch classifier loss: 0.357056; batch adversarial loss: 0.607286\n",
      "epoch 7; iter: 400; batch classifier loss: 0.506282; batch adversarial loss: 0.567711\n",
      "epoch 8; iter: 0; batch classifier loss: 0.338093; batch adversarial loss: 0.545835\n",
      "epoch 8; iter: 200; batch classifier loss: 0.312862; batch adversarial loss: 0.658243\n",
      "epoch 8; iter: 400; batch classifier loss: 0.447160; batch adversarial loss: 0.603249\n",
      "epoch 9; iter: 0; batch classifier loss: 0.245665; batch adversarial loss: 0.703728\n",
      "epoch 9; iter: 200; batch classifier loss: 0.320653; batch adversarial loss: 0.615282\n",
      "epoch 9; iter: 400; batch classifier loss: 0.402668; batch adversarial loss: 0.632213\n",
      "epoch 0; iter: 0; batch classifier loss: 33.046780; batch adversarial loss: 0.649690\n",
      "epoch 0; iter: 200; batch classifier loss: 2.764007; batch adversarial loss: 0.808570\n",
      "epoch 0; iter: 400; batch classifier loss: 0.565178; batch adversarial loss: 0.720727\n",
      "epoch 1; iter: 0; batch classifier loss: 2.665142; batch adversarial loss: 0.667928\n",
      "epoch 1; iter: 200; batch classifier loss: 4.379919; batch adversarial loss: 0.695627\n",
      "epoch 1; iter: 400; batch classifier loss: 2.842757; batch adversarial loss: 0.640480\n",
      "epoch 2; iter: 0; batch classifier loss: 6.636330; batch adversarial loss: 0.641973\n",
      "epoch 2; iter: 200; batch classifier loss: 3.834131; batch adversarial loss: 0.637934\n",
      "epoch 2; iter: 400; batch classifier loss: 9.044106; batch adversarial loss: 0.585984\n",
      "epoch 3; iter: 0; batch classifier loss: 1.252597; batch adversarial loss: 0.595367\n",
      "epoch 3; iter: 200; batch classifier loss: 1.392583; batch adversarial loss: 0.636194\n",
      "epoch 3; iter: 400; batch classifier loss: 1.366899; batch adversarial loss: 0.640422\n",
      "epoch 4; iter: 0; batch classifier loss: 2.997460; batch adversarial loss: 0.558384\n",
      "epoch 4; iter: 200; batch classifier loss: 1.180320; batch adversarial loss: 0.597261\n",
      "epoch 4; iter: 400; batch classifier loss: 1.373131; batch adversarial loss: 0.640675\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651048; batch adversarial loss: 0.608389\n",
      "epoch 5; iter: 200; batch classifier loss: 1.499513; batch adversarial loss: 0.661843\n",
      "epoch 5; iter: 400; batch classifier loss: 0.474051; batch adversarial loss: 0.580007\n",
      "epoch 6; iter: 0; batch classifier loss: 0.357710; batch adversarial loss: 0.599797\n",
      "epoch 6; iter: 200; batch classifier loss: 0.570833; batch adversarial loss: 0.584935\n",
      "epoch 6; iter: 400; batch classifier loss: 0.627827; batch adversarial loss: 0.577528\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393661; batch adversarial loss: 0.592316\n",
      "epoch 7; iter: 200; batch classifier loss: 0.422720; batch adversarial loss: 0.617417\n",
      "epoch 7; iter: 400; batch classifier loss: 0.460169; batch adversarial loss: 0.615660\n",
      "epoch 8; iter: 0; batch classifier loss: 1.621220; batch adversarial loss: 0.634801\n",
      "epoch 8; iter: 200; batch classifier loss: 0.327793; batch adversarial loss: 0.623764\n",
      "epoch 8; iter: 400; batch classifier loss: 0.396651; batch adversarial loss: 0.614577\n",
      "epoch 9; iter: 0; batch classifier loss: 0.522538; batch adversarial loss: 0.648004\n",
      "epoch 9; iter: 200; batch classifier loss: 0.361889; batch adversarial loss: 0.661735\n",
      "epoch 9; iter: 400; batch classifier loss: 0.470033; batch adversarial loss: 0.663165\n",
      "epoch 0; iter: 0; batch classifier loss: 45.893116; batch adversarial loss: 0.661381\n",
      "epoch 0; iter: 200; batch classifier loss: 23.198154; batch adversarial loss: 0.712257\n",
      "epoch 0; iter: 400; batch classifier loss: 12.340130; batch adversarial loss: 0.577028\n",
      "epoch 1; iter: 0; batch classifier loss: 5.373460; batch adversarial loss: 0.618421\n",
      "epoch 1; iter: 200; batch classifier loss: 8.172218; batch adversarial loss: 0.602319\n",
      "epoch 1; iter: 400; batch classifier loss: 4.198499; batch adversarial loss: 0.556107\n",
      "epoch 2; iter: 0; batch classifier loss: 8.344858; batch adversarial loss: 0.611283\n",
      "epoch 2; iter: 200; batch classifier loss: 2.914113; batch adversarial loss: 0.643480\n",
      "epoch 2; iter: 400; batch classifier loss: 0.959724; batch adversarial loss: 0.585893\n",
      "epoch 3; iter: 0; batch classifier loss: 2.955118; batch adversarial loss: 0.611268\n",
      "epoch 3; iter: 200; batch classifier loss: 4.009783; batch adversarial loss: 0.580554\n",
      "epoch 3; iter: 400; batch classifier loss: 3.474448; batch adversarial loss: 0.694608\n",
      "epoch 4; iter: 0; batch classifier loss: 19.511555; batch adversarial loss: 0.687367\n",
      "epoch 4; iter: 200; batch classifier loss: 3.091261; batch adversarial loss: 0.618318\n",
      "epoch 4; iter: 400; batch classifier loss: 1.206588; batch adversarial loss: 0.568386\n",
      "epoch 5; iter: 0; batch classifier loss: 0.995293; batch adversarial loss: 0.643248\n",
      "epoch 5; iter: 200; batch classifier loss: 1.048735; batch adversarial loss: 0.655634\n",
      "epoch 5; iter: 400; batch classifier loss: 0.399351; batch adversarial loss: 0.599387\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561687; batch adversarial loss: 0.640219\n",
      "epoch 6; iter: 200; batch classifier loss: 0.570935; batch adversarial loss: 0.644151\n",
      "epoch 6; iter: 400; batch classifier loss: 0.405567; batch adversarial loss: 0.540883\n",
      "epoch 7; iter: 0; batch classifier loss: 0.336145; batch adversarial loss: 0.692375\n",
      "epoch 7; iter: 200; batch classifier loss: 0.664223; batch adversarial loss: 0.631906\n",
      "epoch 7; iter: 400; batch classifier loss: 0.496713; batch adversarial loss: 0.600864\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518840; batch adversarial loss: 0.660110\n",
      "epoch 8; iter: 200; batch classifier loss: 1.235649; batch adversarial loss: 0.633934\n",
      "epoch 8; iter: 400; batch classifier loss: 0.391604; batch adversarial loss: 0.645036\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450081; batch adversarial loss: 0.591068\n",
      "epoch 9; iter: 200; batch classifier loss: 0.392233; batch adversarial loss: 0.542459\n",
      "epoch 9; iter: 400; batch classifier loss: 0.281029; batch adversarial loss: 0.631875\n",
      "epoch 0; iter: 0; batch classifier loss: 21.352711; batch adversarial loss: 0.668368\n",
      "epoch 0; iter: 200; batch classifier loss: 21.957850; batch adversarial loss: 0.589489\n",
      "epoch 0; iter: 400; batch classifier loss: 10.069878; batch adversarial loss: 0.614996\n",
      "epoch 1; iter: 0; batch classifier loss: 2.373442; batch adversarial loss: 0.651318\n",
      "epoch 1; iter: 200; batch classifier loss: 4.937460; batch adversarial loss: 0.650227\n",
      "epoch 1; iter: 400; batch classifier loss: 0.850715; batch adversarial loss: 0.639306\n",
      "epoch 2; iter: 0; batch classifier loss: 8.687395; batch adversarial loss: 0.729614\n",
      "epoch 2; iter: 200; batch classifier loss: 4.632702; batch adversarial loss: 0.661561\n",
      "epoch 2; iter: 400; batch classifier loss: 8.773440; batch adversarial loss: 0.581916\n",
      "epoch 3; iter: 0; batch classifier loss: 2.455164; batch adversarial loss: 0.618696\n",
      "epoch 3; iter: 200; batch classifier loss: 1.668850; batch adversarial loss: 0.635191\n",
      "epoch 3; iter: 400; batch classifier loss: 6.508613; batch adversarial loss: 0.649948\n",
      "epoch 4; iter: 0; batch classifier loss: 6.203976; batch adversarial loss: 0.637736\n",
      "epoch 4; iter: 200; batch classifier loss: 0.881921; batch adversarial loss: 0.627669\n",
      "epoch 4; iter: 400; batch classifier loss: 1.533983; batch adversarial loss: 0.695103\n",
      "epoch 5; iter: 0; batch classifier loss: 1.434705; batch adversarial loss: 0.555792\n",
      "epoch 5; iter: 200; batch classifier loss: 1.920638; batch adversarial loss: 0.602198\n",
      "epoch 5; iter: 400; batch classifier loss: 1.607859; batch adversarial loss: 0.656968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.856803; batch adversarial loss: 0.556588\n",
      "epoch 6; iter: 200; batch classifier loss: 1.246487; batch adversarial loss: 0.655228\n",
      "epoch 6; iter: 400; batch classifier loss: 0.544257; batch adversarial loss: 0.684782\n",
      "epoch 7; iter: 0; batch classifier loss: 0.955238; batch adversarial loss: 0.616549\n",
      "epoch 7; iter: 200; batch classifier loss: 0.470629; batch adversarial loss: 0.607419\n",
      "epoch 7; iter: 400; batch classifier loss: 0.498737; batch adversarial loss: 0.539488\n",
      "epoch 8; iter: 0; batch classifier loss: 0.218560; batch adversarial loss: 0.703684\n",
      "epoch 8; iter: 200; batch classifier loss: 0.412153; batch adversarial loss: 0.689844\n",
      "epoch 8; iter: 400; batch classifier loss: 0.432704; batch adversarial loss: 0.606787\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465287; batch adversarial loss: 0.579052\n",
      "epoch 9; iter: 200; batch classifier loss: 0.548597; batch adversarial loss: 0.613914\n",
      "epoch 9; iter: 400; batch classifier loss: 0.338618; batch adversarial loss: 0.577188\n",
      "epoch 0; iter: 0; batch classifier loss: 14.382456; batch adversarial loss: 0.639528\n",
      "epoch 0; iter: 200; batch classifier loss: 1.503296; batch adversarial loss: 0.625897\n",
      "epoch 0; iter: 400; batch classifier loss: 10.068714; batch adversarial loss: 0.618654\n",
      "epoch 1; iter: 0; batch classifier loss: 2.052790; batch adversarial loss: 0.624772\n",
      "epoch 1; iter: 200; batch classifier loss: 12.571640; batch adversarial loss: 0.630864\n",
      "epoch 1; iter: 400; batch classifier loss: 2.494923; batch adversarial loss: 0.605910\n",
      "epoch 2; iter: 0; batch classifier loss: 3.782998; batch adversarial loss: 0.605027\n",
      "epoch 2; iter: 200; batch classifier loss: 1.797587; batch adversarial loss: 0.606733\n",
      "epoch 2; iter: 400; batch classifier loss: 5.229501; batch adversarial loss: 0.634417\n",
      "epoch 3; iter: 0; batch classifier loss: 4.611915; batch adversarial loss: 0.579337\n",
      "epoch 3; iter: 200; batch classifier loss: 1.754911; batch adversarial loss: 0.722498\n",
      "epoch 3; iter: 400; batch classifier loss: 2.401163; batch adversarial loss: 0.571113\n",
      "epoch 4; iter: 0; batch classifier loss: 2.929111; batch adversarial loss: 0.564779\n",
      "epoch 4; iter: 200; batch classifier loss: 0.598001; batch adversarial loss: 0.651160\n",
      "epoch 4; iter: 400; batch classifier loss: 1.581247; batch adversarial loss: 0.655683\n",
      "epoch 5; iter: 0; batch classifier loss: 1.500625; batch adversarial loss: 0.622581\n",
      "epoch 5; iter: 200; batch classifier loss: 1.619976; batch adversarial loss: 0.595252\n",
      "epoch 5; iter: 400; batch classifier loss: 0.337868; batch adversarial loss: 0.675769\n",
      "epoch 6; iter: 0; batch classifier loss: 0.493720; batch adversarial loss: 0.635019\n",
      "epoch 6; iter: 200; batch classifier loss: 0.610515; batch adversarial loss: 0.667308\n",
      "epoch 6; iter: 400; batch classifier loss: 0.552966; batch adversarial loss: 0.623546\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616976; batch adversarial loss: 0.607471\n",
      "epoch 7; iter: 200; batch classifier loss: 0.345650; batch adversarial loss: 0.619325\n",
      "epoch 7; iter: 400; batch classifier loss: 0.465431; batch adversarial loss: 0.588132\n",
      "epoch 8; iter: 0; batch classifier loss: 0.328809; batch adversarial loss: 0.618653\n",
      "epoch 8; iter: 200; batch classifier loss: 0.438968; batch adversarial loss: 0.625544\n",
      "epoch 8; iter: 400; batch classifier loss: 0.550514; batch adversarial loss: 0.596525\n",
      "epoch 9; iter: 0; batch classifier loss: 0.392443; batch adversarial loss: 0.651877\n",
      "epoch 9; iter: 200; batch classifier loss: 0.396627; batch adversarial loss: 0.543519\n",
      "epoch 9; iter: 400; batch classifier loss: 0.307491; batch adversarial loss: 0.693599\n",
      "epoch 0; iter: 0; batch classifier loss: 40.914459; batch adversarial loss: 0.693681\n",
      "epoch 0; iter: 200; batch classifier loss: 3.884324; batch adversarial loss: 0.654949\n",
      "epoch 0; iter: 400; batch classifier loss: 24.715969; batch adversarial loss: 0.626089\n",
      "epoch 1; iter: 0; batch classifier loss: 6.278267; batch adversarial loss: 0.597540\n",
      "epoch 1; iter: 200; batch classifier loss: 2.283858; batch adversarial loss: 0.675321\n",
      "epoch 1; iter: 400; batch classifier loss: 2.514026; batch adversarial loss: 0.630466\n",
      "epoch 2; iter: 0; batch classifier loss: 3.969919; batch adversarial loss: 0.600732\n",
      "epoch 2; iter: 200; batch classifier loss: 3.591371; batch adversarial loss: 0.585031\n",
      "epoch 2; iter: 400; batch classifier loss: 5.103820; batch adversarial loss: 0.611043\n",
      "epoch 3; iter: 0; batch classifier loss: 3.685691; batch adversarial loss: 0.628274\n",
      "epoch 3; iter: 200; batch classifier loss: 3.382234; batch adversarial loss: 0.651060\n",
      "epoch 3; iter: 400; batch classifier loss: 1.399563; batch adversarial loss: 0.596387\n",
      "epoch 4; iter: 0; batch classifier loss: 0.692338; batch adversarial loss: 0.642389\n",
      "epoch 4; iter: 200; batch classifier loss: 0.536333; batch adversarial loss: 0.659539\n",
      "epoch 4; iter: 400; batch classifier loss: 5.536834; batch adversarial loss: 0.625646\n",
      "epoch 5; iter: 0; batch classifier loss: 1.268007; batch adversarial loss: 0.617136\n",
      "epoch 5; iter: 200; batch classifier loss: 0.842923; batch adversarial loss: 0.647628\n",
      "epoch 5; iter: 400; batch classifier loss: 0.607174; batch adversarial loss: 0.617389\n",
      "epoch 6; iter: 0; batch classifier loss: 0.413587; batch adversarial loss: 0.642199\n",
      "epoch 6; iter: 200; batch classifier loss: 0.939250; batch adversarial loss: 0.712518\n",
      "epoch 6; iter: 400; batch classifier loss: 0.427762; batch adversarial loss: 0.657173\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435074; batch adversarial loss: 0.641020\n",
      "epoch 7; iter: 200; batch classifier loss: 0.563371; batch adversarial loss: 0.596380\n",
      "epoch 7; iter: 400; batch classifier loss: 0.730055; batch adversarial loss: 0.575031\n",
      "epoch 8; iter: 0; batch classifier loss: 0.413908; batch adversarial loss: 0.708518\n",
      "epoch 8; iter: 200; batch classifier loss: 0.407492; batch adversarial loss: 0.630094\n",
      "epoch 8; iter: 400; batch classifier loss: 0.259170; batch adversarial loss: 0.700575\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389267; batch adversarial loss: 0.553435\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383642; batch adversarial loss: 0.725483\n",
      "epoch 9; iter: 400; batch classifier loss: 0.347605; batch adversarial loss: 0.618290\n",
      "epoch 0; iter: 0; batch classifier loss: 18.900028; batch adversarial loss: 0.764246\n",
      "epoch 0; iter: 200; batch classifier loss: 5.616111; batch adversarial loss: 0.696776\n",
      "epoch 0; iter: 400; batch classifier loss: 0.592505; batch adversarial loss: 0.679155\n",
      "epoch 1; iter: 0; batch classifier loss: 6.362003; batch adversarial loss: 0.671188\n",
      "epoch 1; iter: 200; batch classifier loss: 0.248262; batch adversarial loss: 0.629070\n",
      "epoch 1; iter: 400; batch classifier loss: 8.070743; batch adversarial loss: 0.612569\n",
      "epoch 2; iter: 0; batch classifier loss: 2.225268; batch adversarial loss: 0.611523\n",
      "epoch 2; iter: 200; batch classifier loss: 0.791523; batch adversarial loss: 0.636027\n",
      "epoch 2; iter: 400; batch classifier loss: 2.709527; batch adversarial loss: 0.584657\n",
      "epoch 3; iter: 0; batch classifier loss: 7.306532; batch adversarial loss: 0.526092\n",
      "epoch 3; iter: 200; batch classifier loss: 1.264129; batch adversarial loss: 0.609350\n",
      "epoch 3; iter: 400; batch classifier loss: 1.252835; batch adversarial loss: 0.701014\n",
      "epoch 4; iter: 0; batch classifier loss: 1.749458; batch adversarial loss: 0.608581\n",
      "epoch 4; iter: 200; batch classifier loss: 0.433478; batch adversarial loss: 0.670767\n",
      "epoch 4; iter: 400; batch classifier loss: 1.228697; batch adversarial loss: 0.594605\n",
      "epoch 5; iter: 0; batch classifier loss: 1.513760; batch adversarial loss: 0.559383\n",
      "epoch 5; iter: 200; batch classifier loss: 2.276759; batch adversarial loss: 0.618562\n",
      "epoch 5; iter: 400; batch classifier loss: 0.365212; batch adversarial loss: 0.705782\n",
      "epoch 6; iter: 0; batch classifier loss: 0.408694; batch adversarial loss: 0.645968\n",
      "epoch 6; iter: 200; batch classifier loss: 1.050874; batch adversarial loss: 0.639703\n",
      "epoch 6; iter: 400; batch classifier loss: 0.769804; batch adversarial loss: 0.586425\n",
      "epoch 7; iter: 0; batch classifier loss: 0.464839; batch adversarial loss: 0.614481\n",
      "epoch 7; iter: 200; batch classifier loss: 0.504803; batch adversarial loss: 0.684115\n",
      "epoch 7; iter: 400; batch classifier loss: 0.422397; batch adversarial loss: 0.705341\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528609; batch adversarial loss: 0.611598\n",
      "epoch 8; iter: 200; batch classifier loss: 0.391575; batch adversarial loss: 0.568934\n",
      "epoch 8; iter: 400; batch classifier loss: 0.367713; batch adversarial loss: 0.637064\n",
      "epoch 9; iter: 0; batch classifier loss: 0.288914; batch adversarial loss: 0.570566\n",
      "epoch 9; iter: 200; batch classifier loss: 0.507216; batch adversarial loss: 0.647849\n",
      "epoch 9; iter: 400; batch classifier loss: 0.427444; batch adversarial loss: 0.500005\n",
      "epoch 0; iter: 0; batch classifier loss: 11.389313; batch adversarial loss: 0.762250\n",
      "epoch 0; iter: 200; batch classifier loss: 10.138347; batch adversarial loss: 0.770955\n",
      "epoch 0; iter: 400; batch classifier loss: 1.583497; batch adversarial loss: 0.705003\n",
      "epoch 1; iter: 0; batch classifier loss: 5.878757; batch adversarial loss: 0.780070\n",
      "epoch 1; iter: 200; batch classifier loss: 1.193175; batch adversarial loss: 0.600435\n",
      "epoch 1; iter: 400; batch classifier loss: 14.358727; batch adversarial loss: 0.646931\n",
      "epoch 2; iter: 0; batch classifier loss: 4.365319; batch adversarial loss: 0.634813\n",
      "epoch 2; iter: 200; batch classifier loss: 12.661624; batch adversarial loss: 0.624598\n",
      "epoch 2; iter: 400; batch classifier loss: 2.703727; batch adversarial loss: 0.617481\n",
      "epoch 3; iter: 0; batch classifier loss: 5.615445; batch adversarial loss: 0.651791\n",
      "epoch 3; iter: 200; batch classifier loss: 2.023262; batch adversarial loss: 0.622620\n",
      "epoch 3; iter: 400; batch classifier loss: 1.214914; batch adversarial loss: 0.589695\n",
      "epoch 4; iter: 0; batch classifier loss: 1.050451; batch adversarial loss: 0.708562\n",
      "epoch 4; iter: 200; batch classifier loss: 0.489445; batch adversarial loss: 0.623930\n",
      "epoch 4; iter: 400; batch classifier loss: 0.561407; batch adversarial loss: 0.662163\n",
      "epoch 5; iter: 0; batch classifier loss: 0.866308; batch adversarial loss: 0.604825\n",
      "epoch 5; iter: 200; batch classifier loss: 0.783858; batch adversarial loss: 0.612447\n",
      "epoch 5; iter: 400; batch classifier loss: 0.482987; batch adversarial loss: 0.650272\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482902; batch adversarial loss: 0.632211\n",
      "epoch 6; iter: 200; batch classifier loss: 0.396358; batch adversarial loss: 0.521576\n",
      "epoch 6; iter: 400; batch classifier loss: 0.656249; batch adversarial loss: 0.617367\n",
      "epoch 7; iter: 0; batch classifier loss: 0.341623; batch adversarial loss: 0.579954\n",
      "epoch 7; iter: 200; batch classifier loss: 0.497681; batch adversarial loss: 0.597094\n",
      "epoch 7; iter: 400; batch classifier loss: 0.635531; batch adversarial loss: 0.657109\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615388; batch adversarial loss: 0.513809\n",
      "epoch 8; iter: 200; batch classifier loss: 0.407329; batch adversarial loss: 0.610670\n",
      "epoch 8; iter: 400; batch classifier loss: 0.366482; batch adversarial loss: 0.506548\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492048; batch adversarial loss: 0.632188\n",
      "epoch 9; iter: 200; batch classifier loss: 0.598814; batch adversarial loss: 0.586562\n",
      "epoch 9; iter: 400; batch classifier loss: 0.470047; batch adversarial loss: 0.647681\n",
      "epoch 0; iter: 0; batch classifier loss: 11.227172; batch adversarial loss: 0.643369\n",
      "epoch 0; iter: 200; batch classifier loss: 6.828166; batch adversarial loss: 0.591984\n",
      "epoch 0; iter: 400; batch classifier loss: 9.184767; batch adversarial loss: 0.643229\n",
      "epoch 1; iter: 0; batch classifier loss: 18.119884; batch adversarial loss: 0.641868\n",
      "epoch 1; iter: 200; batch classifier loss: 5.190569; batch adversarial loss: 0.596846\n",
      "epoch 1; iter: 400; batch classifier loss: 0.222507; batch adversarial loss: 0.675520\n",
      "epoch 2; iter: 0; batch classifier loss: 2.532633; batch adversarial loss: 0.669199\n",
      "epoch 2; iter: 200; batch classifier loss: 6.777362; batch adversarial loss: 0.691387\n",
      "epoch 2; iter: 400; batch classifier loss: 5.066954; batch adversarial loss: 0.605974\n",
      "epoch 3; iter: 0; batch classifier loss: 6.302839; batch adversarial loss: 0.604461\n",
      "epoch 3; iter: 200; batch classifier loss: 3.950394; batch adversarial loss: 0.564448\n",
      "epoch 3; iter: 400; batch classifier loss: 3.840703; batch adversarial loss: 0.618376\n",
      "epoch 4; iter: 0; batch classifier loss: 13.215672; batch adversarial loss: 0.565294\n",
      "epoch 4; iter: 200; batch classifier loss: 1.456993; batch adversarial loss: 0.639372\n",
      "epoch 4; iter: 400; batch classifier loss: 0.499133; batch adversarial loss: 0.678517\n",
      "epoch 5; iter: 0; batch classifier loss: 0.648983; batch adversarial loss: 0.532977\n",
      "epoch 5; iter: 200; batch classifier loss: 1.020005; batch adversarial loss: 0.547623\n",
      "epoch 5; iter: 400; batch classifier loss: 0.428455; batch adversarial loss: 0.604826\n",
      "epoch 6; iter: 0; batch classifier loss: 2.479789; batch adversarial loss: 0.613541\n",
      "epoch 6; iter: 200; batch classifier loss: 0.479054; batch adversarial loss: 0.684625\n",
      "epoch 6; iter: 400; batch classifier loss: 0.475058; batch adversarial loss: 0.660003\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607869; batch adversarial loss: 0.627494\n",
      "epoch 7; iter: 200; batch classifier loss: 0.306888; batch adversarial loss: 0.652505\n",
      "epoch 7; iter: 400; batch classifier loss: 0.500788; batch adversarial loss: 0.683834\n",
      "epoch 8; iter: 0; batch classifier loss: 0.645096; batch adversarial loss: 0.622482\n",
      "epoch 8; iter: 200; batch classifier loss: 0.500539; batch adversarial loss: 0.566050\n",
      "epoch 8; iter: 400; batch classifier loss: 0.418032; batch adversarial loss: 0.708467\n",
      "epoch 9; iter: 0; batch classifier loss: 0.458043; batch adversarial loss: 0.585031\n",
      "epoch 9; iter: 200; batch classifier loss: 0.248340; batch adversarial loss: 0.638661\n",
      "epoch 9; iter: 400; batch classifier loss: 0.491950; batch adversarial loss: 0.523503\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 13.326582; batch adversarial loss: 0.685387\n",
      "epoch 0; iter: 200; batch classifier loss: 15.696688; batch adversarial loss: 0.652813\n",
      "epoch 0; iter: 400; batch classifier loss: 10.613142; batch adversarial loss: 0.725068\n",
      "epoch 1; iter: 0; batch classifier loss: 9.930647; batch adversarial loss: 0.657525\n",
      "epoch 1; iter: 200; batch classifier loss: 9.046343; batch adversarial loss: 0.668105\n",
      "epoch 1; iter: 400; batch classifier loss: 5.805729; batch adversarial loss: 0.687501\n",
      "epoch 2; iter: 0; batch classifier loss: 16.992842; batch adversarial loss: 0.570282\n",
      "epoch 2; iter: 200; batch classifier loss: 2.629294; batch adversarial loss: 0.662861\n",
      "epoch 2; iter: 400; batch classifier loss: 1.323162; batch adversarial loss: 0.593853\n",
      "epoch 3; iter: 0; batch classifier loss: 6.941048; batch adversarial loss: 0.648624\n",
      "epoch 3; iter: 200; batch classifier loss: 1.180778; batch adversarial loss: 0.695617\n",
      "epoch 3; iter: 400; batch classifier loss: 10.744533; batch adversarial loss: 0.662157\n",
      "epoch 4; iter: 0; batch classifier loss: 0.884684; batch adversarial loss: 0.657779\n",
      "epoch 4; iter: 200; batch classifier loss: 1.724436; batch adversarial loss: 0.612336\n",
      "epoch 4; iter: 400; batch classifier loss: 2.382829; batch adversarial loss: 0.627616\n",
      "epoch 5; iter: 0; batch classifier loss: 0.427963; batch adversarial loss: 0.582173\n",
      "epoch 5; iter: 200; batch classifier loss: 0.648011; batch adversarial loss: 0.601246\n",
      "epoch 5; iter: 400; batch classifier loss: 0.991672; batch adversarial loss: 0.612923\n",
      "epoch 6; iter: 0; batch classifier loss: 1.657539; batch adversarial loss: 0.636581\n",
      "epoch 6; iter: 200; batch classifier loss: 0.603087; batch adversarial loss: 0.654391\n",
      "epoch 6; iter: 400; batch classifier loss: 0.593295; batch adversarial loss: 0.653612\n",
      "epoch 7; iter: 0; batch classifier loss: 0.534026; batch adversarial loss: 0.629916\n",
      "epoch 7; iter: 200; batch classifier loss: 0.510603; batch adversarial loss: 0.606983\n",
      "epoch 7; iter: 400; batch classifier loss: 0.562473; batch adversarial loss: 0.553104\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428132; batch adversarial loss: 0.643814\n",
      "epoch 8; iter: 200; batch classifier loss: 0.627420; batch adversarial loss: 0.539701\n",
      "epoch 8; iter: 400; batch classifier loss: 0.463837; batch adversarial loss: 0.675633\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508124; batch adversarial loss: 0.574553\n",
      "epoch 9; iter: 200; batch classifier loss: 0.408677; batch adversarial loss: 0.601243\n",
      "epoch 9; iter: 400; batch classifier loss: 0.291944; batch adversarial loss: 0.598853\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469163; batch adversarial loss: 0.658581\n",
      "epoch 10; iter: 200; batch classifier loss: 0.535125; batch adversarial loss: 0.562002\n",
      "epoch 10; iter: 400; batch classifier loss: 0.366593; batch adversarial loss: 0.659199\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406097; batch adversarial loss: 0.632287\n",
      "epoch 11; iter: 200; batch classifier loss: 0.446979; batch adversarial loss: 0.706852\n",
      "epoch 11; iter: 400; batch classifier loss: 0.505430; batch adversarial loss: 0.609043\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368935; batch adversarial loss: 0.624896\n",
      "epoch 12; iter: 200; batch classifier loss: 0.387568; batch adversarial loss: 0.599557\n",
      "epoch 12; iter: 400; batch classifier loss: 0.409961; batch adversarial loss: 0.585796\n",
      "epoch 13; iter: 0; batch classifier loss: 0.435625; batch adversarial loss: 0.654046\n",
      "epoch 13; iter: 200; batch classifier loss: 0.239746; batch adversarial loss: 0.648653\n",
      "epoch 13; iter: 400; batch classifier loss: 0.403519; batch adversarial loss: 0.552469\n",
      "epoch 14; iter: 0; batch classifier loss: 0.401761; batch adversarial loss: 0.674229\n",
      "epoch 14; iter: 200; batch classifier loss: 0.501355; batch adversarial loss: 0.617662\n",
      "epoch 14; iter: 400; batch classifier loss: 0.282599; batch adversarial loss: 0.631903\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422088; batch adversarial loss: 0.677340\n",
      "epoch 15; iter: 200; batch classifier loss: 0.376248; batch adversarial loss: 0.646474\n",
      "epoch 15; iter: 400; batch classifier loss: 0.264865; batch adversarial loss: 0.532914\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418372; batch adversarial loss: 0.598056\n",
      "epoch 16; iter: 200; batch classifier loss: 0.337629; batch adversarial loss: 0.636848\n",
      "epoch 16; iter: 400; batch classifier loss: 0.331151; batch adversarial loss: 0.616226\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489345; batch adversarial loss: 0.553268\n",
      "epoch 17; iter: 200; batch classifier loss: 0.337706; batch adversarial loss: 0.695946\n",
      "epoch 17; iter: 400; batch classifier loss: 0.386840; batch adversarial loss: 0.594979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317610; batch adversarial loss: 0.523273\n",
      "epoch 18; iter: 200; batch classifier loss: 0.357694; batch adversarial loss: 0.624462\n",
      "epoch 18; iter: 400; batch classifier loss: 0.296607; batch adversarial loss: 0.636040\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455908; batch adversarial loss: 0.650557\n",
      "epoch 19; iter: 200; batch classifier loss: 0.449384; batch adversarial loss: 0.514543\n",
      "epoch 19; iter: 400; batch classifier loss: 0.391332; batch adversarial loss: 0.654249\n",
      "epoch 0; iter: 0; batch classifier loss: 54.972904; batch adversarial loss: 0.719903\n",
      "epoch 0; iter: 200; batch classifier loss: 6.799365; batch adversarial loss: 0.664093\n",
      "epoch 0; iter: 400; batch classifier loss: 17.847710; batch adversarial loss: 0.643669\n",
      "epoch 1; iter: 0; batch classifier loss: 5.894057; batch adversarial loss: 0.640186\n",
      "epoch 1; iter: 200; batch classifier loss: 2.502016; batch adversarial loss: 0.685158\n",
      "epoch 1; iter: 400; batch classifier loss: 1.701508; batch adversarial loss: 0.683661\n",
      "epoch 2; iter: 0; batch classifier loss: 6.821798; batch adversarial loss: 0.655633\n",
      "epoch 2; iter: 200; batch classifier loss: 10.877112; batch adversarial loss: 0.646190\n",
      "epoch 2; iter: 400; batch classifier loss: 1.089940; batch adversarial loss: 0.598129\n",
      "epoch 3; iter: 0; batch classifier loss: 2.103543; batch adversarial loss: 0.640380\n",
      "epoch 3; iter: 200; batch classifier loss: 1.600776; batch adversarial loss: 0.619590\n",
      "epoch 3; iter: 400; batch classifier loss: 0.495588; batch adversarial loss: 0.699118\n",
      "epoch 4; iter: 0; batch classifier loss: 1.767044; batch adversarial loss: 0.584369\n",
      "epoch 4; iter: 200; batch classifier loss: 0.527658; batch adversarial loss: 0.689429\n",
      "epoch 4; iter: 400; batch classifier loss: 0.394705; batch adversarial loss: 0.605669\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466431; batch adversarial loss: 0.587506\n",
      "epoch 5; iter: 200; batch classifier loss: 0.546775; batch adversarial loss: 0.618999\n",
      "epoch 5; iter: 400; batch classifier loss: 0.560146; batch adversarial loss: 0.652256\n",
      "epoch 6; iter: 0; batch classifier loss: 0.877304; batch adversarial loss: 0.518305\n",
      "epoch 6; iter: 200; batch classifier loss: 0.641049; batch adversarial loss: 0.584607\n",
      "epoch 6; iter: 400; batch classifier loss: 0.376774; batch adversarial loss: 0.605397\n",
      "epoch 7; iter: 0; batch classifier loss: 0.758701; batch adversarial loss: 0.531078\n",
      "epoch 7; iter: 200; batch classifier loss: 0.530141; batch adversarial loss: 0.639126\n",
      "epoch 7; iter: 400; batch classifier loss: 0.475614; batch adversarial loss: 0.632952\n",
      "epoch 8; iter: 0; batch classifier loss: 0.743321; batch adversarial loss: 0.648132\n",
      "epoch 8; iter: 200; batch classifier loss: 0.301051; batch adversarial loss: 0.589482\n",
      "epoch 8; iter: 400; batch classifier loss: 0.421145; batch adversarial loss: 0.640494\n",
      "epoch 9; iter: 0; batch classifier loss: 0.408605; batch adversarial loss: 0.629396\n",
      "epoch 9; iter: 200; batch classifier loss: 0.366636; batch adversarial loss: 0.582424\n",
      "epoch 9; iter: 400; batch classifier loss: 0.575132; batch adversarial loss: 0.576348\n",
      "epoch 10; iter: 0; batch classifier loss: 0.332835; batch adversarial loss: 0.678406\n",
      "epoch 10; iter: 200; batch classifier loss: 0.501524; batch adversarial loss: 0.599819\n",
      "epoch 10; iter: 400; batch classifier loss: 0.408637; batch adversarial loss: 0.611669\n",
      "epoch 11; iter: 0; batch classifier loss: 0.432265; batch adversarial loss: 0.567890\n",
      "epoch 11; iter: 200; batch classifier loss: 0.228993; batch adversarial loss: 0.526598\n",
      "epoch 11; iter: 400; batch classifier loss: 0.286223; batch adversarial loss: 0.656801\n",
      "epoch 12; iter: 0; batch classifier loss: 0.328955; batch adversarial loss: 0.606462\n",
      "epoch 12; iter: 200; batch classifier loss: 0.393561; batch adversarial loss: 0.682947\n",
      "epoch 12; iter: 400; batch classifier loss: 0.313572; batch adversarial loss: 0.621805\n",
      "epoch 13; iter: 0; batch classifier loss: 0.271630; batch adversarial loss: 0.616404\n",
      "epoch 13; iter: 200; batch classifier loss: 0.336435; batch adversarial loss: 0.582177\n",
      "epoch 13; iter: 400; batch classifier loss: 0.434108; batch adversarial loss: 0.595724\n",
      "epoch 14; iter: 0; batch classifier loss: 0.244497; batch adversarial loss: 0.696560\n",
      "epoch 14; iter: 200; batch classifier loss: 0.447218; batch adversarial loss: 0.566565\n",
      "epoch 14; iter: 400; batch classifier loss: 0.376932; batch adversarial loss: 0.628011\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401768; batch adversarial loss: 0.647306\n",
      "epoch 15; iter: 200; batch classifier loss: 0.335024; batch adversarial loss: 0.673567\n",
      "epoch 15; iter: 400; batch classifier loss: 0.324354; batch adversarial loss: 0.683440\n",
      "epoch 16; iter: 0; batch classifier loss: 0.264394; batch adversarial loss: 0.671020\n",
      "epoch 16; iter: 200; batch classifier loss: 0.218145; batch adversarial loss: 0.630552\n",
      "epoch 16; iter: 400; batch classifier loss: 0.313375; batch adversarial loss: 0.597974\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294689; batch adversarial loss: 0.661289\n",
      "epoch 17; iter: 200; batch classifier loss: 0.310150; batch adversarial loss: 0.708945\n",
      "epoch 17; iter: 400; batch classifier loss: 0.419610; batch adversarial loss: 0.665742\n",
      "epoch 18; iter: 0; batch classifier loss: 0.259057; batch adversarial loss: 0.619948\n",
      "epoch 18; iter: 200; batch classifier loss: 0.427192; batch adversarial loss: 0.655055\n",
      "epoch 18; iter: 400; batch classifier loss: 0.326993; batch adversarial loss: 0.591242\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440689; batch adversarial loss: 0.602446\n",
      "epoch 19; iter: 200; batch classifier loss: 0.278407; batch adversarial loss: 0.685449\n",
      "epoch 19; iter: 400; batch classifier loss: 0.433659; batch adversarial loss: 0.592928\n",
      "epoch 0; iter: 0; batch classifier loss: 6.116145; batch adversarial loss: 0.719196\n",
      "epoch 0; iter: 200; batch classifier loss: 6.326377; batch adversarial loss: 0.796653\n",
      "epoch 0; iter: 400; batch classifier loss: 10.639853; batch adversarial loss: 0.730206\n",
      "epoch 1; iter: 0; batch classifier loss: 4.598488; batch adversarial loss: 0.728521\n",
      "epoch 1; iter: 200; batch classifier loss: 9.632874; batch adversarial loss: 0.698165\n",
      "epoch 1; iter: 400; batch classifier loss: 3.567329; batch adversarial loss: 0.670448\n",
      "epoch 2; iter: 0; batch classifier loss: 3.987040; batch adversarial loss: 0.636598\n",
      "epoch 2; iter: 200; batch classifier loss: 5.306124; batch adversarial loss: 0.615237\n",
      "epoch 2; iter: 400; batch classifier loss: 4.003521; batch adversarial loss: 0.642345\n",
      "epoch 3; iter: 0; batch classifier loss: 3.914279; batch adversarial loss: 0.563513\n",
      "epoch 3; iter: 200; batch classifier loss: 4.638308; batch adversarial loss: 0.699561\n",
      "epoch 3; iter: 400; batch classifier loss: 1.598625; batch adversarial loss: 0.675722\n",
      "epoch 4; iter: 0; batch classifier loss: 1.454702; batch adversarial loss: 0.601947\n",
      "epoch 4; iter: 200; batch classifier loss: 1.350408; batch adversarial loss: 0.677113\n",
      "epoch 4; iter: 400; batch classifier loss: 1.487406; batch adversarial loss: 0.578255\n",
      "epoch 5; iter: 0; batch classifier loss: 1.511605; batch adversarial loss: 0.582572\n",
      "epoch 5; iter: 200; batch classifier loss: 0.366676; batch adversarial loss: 0.569910\n",
      "epoch 5; iter: 400; batch classifier loss: 0.210253; batch adversarial loss: 0.645032\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553120; batch adversarial loss: 0.673400\n",
      "epoch 6; iter: 200; batch classifier loss: 0.620391; batch adversarial loss: 0.580692\n",
      "epoch 6; iter: 400; batch classifier loss: 0.604331; batch adversarial loss: 0.626864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.388230; batch adversarial loss: 0.621032\n",
      "epoch 7; iter: 200; batch classifier loss: 0.833069; batch adversarial loss: 0.570061\n",
      "epoch 7; iter: 400; batch classifier loss: 0.385288; batch adversarial loss: 0.642234\n",
      "epoch 8; iter: 0; batch classifier loss: 1.212977; batch adversarial loss: 0.669891\n",
      "epoch 8; iter: 200; batch classifier loss: 0.531772; batch adversarial loss: 0.603089\n",
      "epoch 8; iter: 400; batch classifier loss: 0.516240; batch adversarial loss: 0.659611\n",
      "epoch 9; iter: 0; batch classifier loss: 0.345092; batch adversarial loss: 0.635091\n",
      "epoch 9; iter: 200; batch classifier loss: 0.423210; batch adversarial loss: 0.677211\n",
      "epoch 9; iter: 400; batch classifier loss: 0.391388; batch adversarial loss: 0.622116\n",
      "epoch 10; iter: 0; batch classifier loss: 1.153983; batch adversarial loss: 0.686356\n",
      "epoch 10; iter: 200; batch classifier loss: 0.424564; batch adversarial loss: 0.537541\n",
      "epoch 10; iter: 400; batch classifier loss: 0.343354; batch adversarial loss: 0.634285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503964; batch adversarial loss: 0.621697\n",
      "epoch 11; iter: 200; batch classifier loss: 0.351049; batch adversarial loss: 0.623522\n",
      "epoch 11; iter: 400; batch classifier loss: 0.426514; batch adversarial loss: 0.619235\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325833; batch adversarial loss: 0.643411\n",
      "epoch 12; iter: 200; batch classifier loss: 0.357105; batch adversarial loss: 0.618305\n",
      "epoch 12; iter: 400; batch classifier loss: 0.417778; batch adversarial loss: 0.753737\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500657; batch adversarial loss: 0.624336\n",
      "epoch 13; iter: 200; batch classifier loss: 0.338497; batch adversarial loss: 0.662705\n",
      "epoch 13; iter: 400; batch classifier loss: 0.320191; batch adversarial loss: 0.691407\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556439; batch adversarial loss: 0.613979\n",
      "epoch 14; iter: 200; batch classifier loss: 0.365008; batch adversarial loss: 0.615578\n",
      "epoch 14; iter: 400; batch classifier loss: 0.281989; batch adversarial loss: 0.681182\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466751; batch adversarial loss: 0.578574\n",
      "epoch 15; iter: 200; batch classifier loss: 0.513899; batch adversarial loss: 0.553070\n",
      "epoch 15; iter: 400; batch classifier loss: 0.311839; batch adversarial loss: 0.612692\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311674; batch adversarial loss: 0.636285\n",
      "epoch 16; iter: 200; batch classifier loss: 0.327309; batch adversarial loss: 0.619456\n",
      "epoch 16; iter: 400; batch classifier loss: 0.426114; batch adversarial loss: 0.555052\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383966; batch adversarial loss: 0.561865\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341076; batch adversarial loss: 0.592450\n",
      "epoch 17; iter: 400; batch classifier loss: 0.301141; batch adversarial loss: 0.642764\n",
      "epoch 18; iter: 0; batch classifier loss: 0.305753; batch adversarial loss: 0.684402\n",
      "epoch 18; iter: 200; batch classifier loss: 0.262405; batch adversarial loss: 0.621478\n",
      "epoch 18; iter: 400; batch classifier loss: 0.462655; batch adversarial loss: 0.642954\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374949; batch adversarial loss: 0.539659\n",
      "epoch 19; iter: 200; batch classifier loss: 0.471419; batch adversarial loss: 0.638773\n",
      "epoch 19; iter: 400; batch classifier loss: 0.288906; batch adversarial loss: 0.658358\n",
      "epoch 0; iter: 0; batch classifier loss: 206.195709; batch adversarial loss: 0.627903\n",
      "epoch 0; iter: 200; batch classifier loss: 4.846788; batch adversarial loss: 0.710290\n",
      "epoch 0; iter: 400; batch classifier loss: 6.563960; batch adversarial loss: 0.713105\n",
      "epoch 1; iter: 0; batch classifier loss: 9.421507; batch adversarial loss: 0.614030\n",
      "epoch 1; iter: 200; batch classifier loss: 3.197788; batch adversarial loss: 0.628011\n",
      "epoch 1; iter: 400; batch classifier loss: 15.698588; batch adversarial loss: 0.718008\n",
      "epoch 2; iter: 0; batch classifier loss: 8.797425; batch adversarial loss: 0.666436\n",
      "epoch 2; iter: 200; batch classifier loss: 5.521684; batch adversarial loss: 0.702016\n",
      "epoch 2; iter: 400; batch classifier loss: 3.137100; batch adversarial loss: 0.667892\n",
      "epoch 3; iter: 0; batch classifier loss: 1.759679; batch adversarial loss: 0.668128\n",
      "epoch 3; iter: 200; batch classifier loss: 20.335491; batch adversarial loss: 0.533508\n",
      "epoch 3; iter: 400; batch classifier loss: 3.392804; batch adversarial loss: 0.631909\n",
      "epoch 4; iter: 0; batch classifier loss: 0.737883; batch adversarial loss: 0.705489\n",
      "epoch 4; iter: 200; batch classifier loss: 1.472519; batch adversarial loss: 0.690681\n",
      "epoch 4; iter: 400; batch classifier loss: 1.433908; batch adversarial loss: 0.653251\n",
      "epoch 5; iter: 0; batch classifier loss: 2.174895; batch adversarial loss: 0.597744\n",
      "epoch 5; iter: 200; batch classifier loss: 0.720196; batch adversarial loss: 0.550451\n",
      "epoch 5; iter: 400; batch classifier loss: 0.534806; batch adversarial loss: 0.585639\n",
      "epoch 6; iter: 0; batch classifier loss: 5.148831; batch adversarial loss: 0.621862\n",
      "epoch 6; iter: 200; batch classifier loss: 0.613841; batch adversarial loss: 0.588184\n",
      "epoch 6; iter: 400; batch classifier loss: 0.748554; batch adversarial loss: 0.610021\n",
      "epoch 7; iter: 0; batch classifier loss: 0.683765; batch adversarial loss: 0.545157\n",
      "epoch 7; iter: 200; batch classifier loss: 0.578042; batch adversarial loss: 0.651994\n",
      "epoch 7; iter: 400; batch classifier loss: 0.347887; batch adversarial loss: 0.586396\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553635; batch adversarial loss: 0.592878\n",
      "epoch 8; iter: 200; batch classifier loss: 0.528641; batch adversarial loss: 0.690074\n",
      "epoch 8; iter: 400; batch classifier loss: 0.403568; batch adversarial loss: 0.572231\n",
      "epoch 9; iter: 0; batch classifier loss: 0.343858; batch adversarial loss: 0.563074\n",
      "epoch 9; iter: 200; batch classifier loss: 0.447951; batch adversarial loss: 0.482100\n",
      "epoch 9; iter: 400; batch classifier loss: 0.335230; batch adversarial loss: 0.610384\n",
      "epoch 10; iter: 0; batch classifier loss: 0.420108; batch adversarial loss: 0.621561\n",
      "epoch 10; iter: 200; batch classifier loss: 0.431806; batch adversarial loss: 0.515274\n",
      "epoch 10; iter: 400; batch classifier loss: 0.425021; batch adversarial loss: 0.549044\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428769; batch adversarial loss: 0.586231\n",
      "epoch 11; iter: 200; batch classifier loss: 0.427159; batch adversarial loss: 0.483061\n",
      "epoch 11; iter: 400; batch classifier loss: 0.372855; batch adversarial loss: 0.594266\n",
      "epoch 12; iter: 0; batch classifier loss: 0.508118; batch adversarial loss: 0.570739\n",
      "epoch 12; iter: 200; batch classifier loss: 0.822008; batch adversarial loss: 0.730900\n",
      "epoch 12; iter: 400; batch classifier loss: 0.454474; batch adversarial loss: 0.606686\n",
      "epoch 13; iter: 0; batch classifier loss: 0.332235; batch adversarial loss: 0.598715\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353081; batch adversarial loss: 0.631345\n",
      "epoch 13; iter: 400; batch classifier loss: 0.310171; batch adversarial loss: 0.702442\n",
      "epoch 14; iter: 0; batch classifier loss: 0.360153; batch adversarial loss: 0.725617\n",
      "epoch 14; iter: 200; batch classifier loss: 0.356147; batch adversarial loss: 0.635612\n",
      "epoch 14; iter: 400; batch classifier loss: 0.355166; batch adversarial loss: 0.554032\n",
      "epoch 15; iter: 0; batch classifier loss: 0.331988; batch adversarial loss: 0.570657\n",
      "epoch 15; iter: 200; batch classifier loss: 0.346396; batch adversarial loss: 0.683920\n",
      "epoch 15; iter: 400; batch classifier loss: 0.297729; batch adversarial loss: 0.565187\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475965; batch adversarial loss: 0.629867\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304625; batch adversarial loss: 0.710903\n",
      "epoch 16; iter: 400; batch classifier loss: 0.382439; batch adversarial loss: 0.595354\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322218; batch adversarial loss: 0.687281\n",
      "epoch 17; iter: 200; batch classifier loss: 0.356737; batch adversarial loss: 0.604844\n",
      "epoch 17; iter: 400; batch classifier loss: 0.542883; batch adversarial loss: 0.560780\n",
      "epoch 18; iter: 0; batch classifier loss: 0.380211; batch adversarial loss: 0.601929\n",
      "epoch 18; iter: 200; batch classifier loss: 0.383673; batch adversarial loss: 0.654961\n",
      "epoch 18; iter: 400; batch classifier loss: 0.340710; batch adversarial loss: 0.621827\n",
      "epoch 19; iter: 0; batch classifier loss: 0.226321; batch adversarial loss: 0.627387\n",
      "epoch 19; iter: 200; batch classifier loss: 0.340091; batch adversarial loss: 0.628281\n",
      "epoch 19; iter: 400; batch classifier loss: 0.285322; batch adversarial loss: 0.582483\n",
      "epoch 0; iter: 0; batch classifier loss: 39.252998; batch adversarial loss: 0.763827\n",
      "epoch 0; iter: 200; batch classifier loss: 7.274978; batch adversarial loss: 0.711925\n",
      "epoch 0; iter: 400; batch classifier loss: 18.059425; batch adversarial loss: 0.675758\n",
      "epoch 1; iter: 0; batch classifier loss: 7.473203; batch adversarial loss: 0.687729\n",
      "epoch 1; iter: 200; batch classifier loss: 19.764357; batch adversarial loss: 0.671129\n",
      "epoch 1; iter: 400; batch classifier loss: 1.190017; batch adversarial loss: 0.706274\n",
      "epoch 2; iter: 0; batch classifier loss: 0.306635; batch adversarial loss: 0.613644\n",
      "epoch 2; iter: 200; batch classifier loss: 4.723474; batch adversarial loss: 0.594359\n",
      "epoch 2; iter: 400; batch classifier loss: 5.207895; batch adversarial loss: 0.692378\n",
      "epoch 3; iter: 0; batch classifier loss: 3.482411; batch adversarial loss: 0.600118\n",
      "epoch 3; iter: 200; batch classifier loss: 2.273925; batch adversarial loss: 0.659353\n",
      "epoch 3; iter: 400; batch classifier loss: 0.789354; batch adversarial loss: 0.749025\n",
      "epoch 4; iter: 0; batch classifier loss: 2.024604; batch adversarial loss: 0.674255\n",
      "epoch 4; iter: 200; batch classifier loss: 1.719009; batch adversarial loss: 0.624380\n",
      "epoch 4; iter: 400; batch classifier loss: 0.840515; batch adversarial loss: 0.574067\n",
      "epoch 5; iter: 0; batch classifier loss: 0.847231; batch adversarial loss: 0.603619\n",
      "epoch 5; iter: 200; batch classifier loss: 1.434731; batch adversarial loss: 0.666571\n",
      "epoch 5; iter: 400; batch classifier loss: 1.113105; batch adversarial loss: 0.641116\n",
      "epoch 6; iter: 0; batch classifier loss: 0.722492; batch adversarial loss: 0.627466\n",
      "epoch 6; iter: 200; batch classifier loss: 0.325095; batch adversarial loss: 0.664970\n",
      "epoch 6; iter: 400; batch classifier loss: 0.390523; batch adversarial loss: 0.631773\n",
      "epoch 7; iter: 0; batch classifier loss: 0.381498; batch adversarial loss: 0.602243\n",
      "epoch 7; iter: 200; batch classifier loss: 0.339080; batch adversarial loss: 0.656001\n",
      "epoch 7; iter: 400; batch classifier loss: 0.424321; batch adversarial loss: 0.664511\n",
      "epoch 8; iter: 0; batch classifier loss: 0.376714; batch adversarial loss: 0.575363\n",
      "epoch 8; iter: 200; batch classifier loss: 0.474167; batch adversarial loss: 0.617622\n",
      "epoch 8; iter: 400; batch classifier loss: 0.456089; batch adversarial loss: 0.707255\n",
      "epoch 9; iter: 0; batch classifier loss: 0.476434; batch adversarial loss: 0.599688\n",
      "epoch 9; iter: 200; batch classifier loss: 0.420411; batch adversarial loss: 0.670232\n",
      "epoch 9; iter: 400; batch classifier loss: 0.406689; batch adversarial loss: 0.596138\n",
      "epoch 10; iter: 0; batch classifier loss: 0.379320; batch adversarial loss: 0.609480\n",
      "epoch 10; iter: 200; batch classifier loss: 0.333512; batch adversarial loss: 0.609998\n",
      "epoch 10; iter: 400; batch classifier loss: 0.355799; batch adversarial loss: 0.714820\n",
      "epoch 11; iter: 0; batch classifier loss: 0.340879; batch adversarial loss: 0.614666\n",
      "epoch 11; iter: 200; batch classifier loss: 0.474810; batch adversarial loss: 0.635861\n",
      "epoch 11; iter: 400; batch classifier loss: 0.324116; batch adversarial loss: 0.667173\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407797; batch adversarial loss: 0.565349\n",
      "epoch 12; iter: 200; batch classifier loss: 0.317146; batch adversarial loss: 0.580460\n",
      "epoch 12; iter: 400; batch classifier loss: 0.374813; batch adversarial loss: 0.666581\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341581; batch adversarial loss: 0.667986\n",
      "epoch 13; iter: 200; batch classifier loss: 0.417188; batch adversarial loss: 0.604930\n",
      "epoch 13; iter: 400; batch classifier loss: 0.248326; batch adversarial loss: 0.614063\n",
      "epoch 14; iter: 0; batch classifier loss: 0.318698; batch adversarial loss: 0.631261\n",
      "epoch 14; iter: 200; batch classifier loss: 0.391865; batch adversarial loss: 0.620855\n",
      "epoch 14; iter: 400; batch classifier loss: 0.353719; batch adversarial loss: 0.680965\n",
      "epoch 15; iter: 0; batch classifier loss: 0.342452; batch adversarial loss: 0.646273\n",
      "epoch 15; iter: 200; batch classifier loss: 0.345246; batch adversarial loss: 0.662946\n",
      "epoch 15; iter: 400; batch classifier loss: 0.347945; batch adversarial loss: 0.605746\n",
      "epoch 16; iter: 0; batch classifier loss: 0.346356; batch adversarial loss: 0.604819\n",
      "epoch 16; iter: 200; batch classifier loss: 0.286670; batch adversarial loss: 0.679314\n",
      "epoch 16; iter: 400; batch classifier loss: 0.354663; batch adversarial loss: 0.629098\n",
      "epoch 17; iter: 0; batch classifier loss: 0.262477; batch adversarial loss: 0.594100\n",
      "epoch 17; iter: 200; batch classifier loss: 0.286175; batch adversarial loss: 0.660688\n",
      "epoch 17; iter: 400; batch classifier loss: 0.214377; batch adversarial loss: 0.589979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.318713; batch adversarial loss: 0.628025\n",
      "epoch 18; iter: 200; batch classifier loss: 0.350196; batch adversarial loss: 0.629753\n",
      "epoch 18; iter: 400; batch classifier loss: 0.425428; batch adversarial loss: 0.642003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325683; batch adversarial loss: 0.695850\n",
      "epoch 19; iter: 200; batch classifier loss: 0.366789; batch adversarial loss: 0.674427\n",
      "epoch 19; iter: 400; batch classifier loss: 0.506282; batch adversarial loss: 0.560387\n",
      "epoch 0; iter: 0; batch classifier loss: 6.077227; batch adversarial loss: 0.734380\n",
      "epoch 0; iter: 200; batch classifier loss: 6.004944; batch adversarial loss: 0.678341\n",
      "epoch 0; iter: 400; batch classifier loss: 14.678993; batch adversarial loss: 0.661566\n",
      "epoch 1; iter: 0; batch classifier loss: 18.873268; batch adversarial loss: 0.677145\n",
      "epoch 1; iter: 200; batch classifier loss: 3.057160; batch adversarial loss: 0.605017\n",
      "epoch 1; iter: 400; batch classifier loss: 1.348487; batch adversarial loss: 0.669101\n",
      "epoch 2; iter: 0; batch classifier loss: 5.990531; batch adversarial loss: 0.607072\n",
      "epoch 2; iter: 200; batch classifier loss: 1.230277; batch adversarial loss: 0.612470\n",
      "epoch 2; iter: 400; batch classifier loss: 3.889705; batch adversarial loss: 0.595778\n",
      "epoch 3; iter: 0; batch classifier loss: 6.100470; batch adversarial loss: 0.662547\n",
      "epoch 3; iter: 200; batch classifier loss: 1.367424; batch adversarial loss: 0.604748\n",
      "epoch 3; iter: 400; batch classifier loss: 1.825077; batch adversarial loss: 0.560920\n",
      "epoch 4; iter: 0; batch classifier loss: 1.004490; batch adversarial loss: 0.592637\n",
      "epoch 4; iter: 200; batch classifier loss: 0.979150; batch adversarial loss: 0.612547\n",
      "epoch 4; iter: 400; batch classifier loss: 0.256779; batch adversarial loss: 0.631497\n",
      "epoch 5; iter: 0; batch classifier loss: 0.642630; batch adversarial loss: 0.527601\n",
      "epoch 5; iter: 200; batch classifier loss: 0.624431; batch adversarial loss: 0.589100\n",
      "epoch 5; iter: 400; batch classifier loss: 0.334911; batch adversarial loss: 0.635602\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322815; batch adversarial loss: 0.624812\n",
      "epoch 6; iter: 200; batch classifier loss: 0.235961; batch adversarial loss: 0.597259\n",
      "epoch 6; iter: 400; batch classifier loss: 0.365260; batch adversarial loss: 0.682132\n",
      "epoch 7; iter: 0; batch classifier loss: 0.472607; batch adversarial loss: 0.661687\n",
      "epoch 7; iter: 200; batch classifier loss: 0.307119; batch adversarial loss: 0.578779\n",
      "epoch 7; iter: 400; batch classifier loss: 0.402072; batch adversarial loss: 0.530514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579188; batch adversarial loss: 0.698255\n",
      "epoch 8; iter: 200; batch classifier loss: 0.553615; batch adversarial loss: 0.621563\n",
      "epoch 8; iter: 400; batch classifier loss: 0.436028; batch adversarial loss: 0.523227\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349071; batch adversarial loss: 0.597713\n",
      "epoch 9; iter: 200; batch classifier loss: 0.340577; batch adversarial loss: 0.564266\n",
      "epoch 9; iter: 400; batch classifier loss: 0.293734; batch adversarial loss: 0.570071\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460124; batch adversarial loss: 0.741482\n",
      "epoch 10; iter: 200; batch classifier loss: 0.273476; batch adversarial loss: 0.579507\n",
      "epoch 10; iter: 400; batch classifier loss: 0.428778; batch adversarial loss: 0.616593\n",
      "epoch 11; iter: 0; batch classifier loss: 0.357989; batch adversarial loss: 0.678993\n",
      "epoch 11; iter: 200; batch classifier loss: 0.511086; batch adversarial loss: 0.621396\n",
      "epoch 11; iter: 400; batch classifier loss: 0.292387; batch adversarial loss: 0.700656\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430469; batch adversarial loss: 0.551605\n",
      "epoch 12; iter: 200; batch classifier loss: 0.243653; batch adversarial loss: 0.636146\n",
      "epoch 12; iter: 400; batch classifier loss: 0.481617; batch adversarial loss: 0.566020\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335270; batch adversarial loss: 0.576497\n",
      "epoch 13; iter: 200; batch classifier loss: 0.348430; batch adversarial loss: 0.613721\n",
      "epoch 13; iter: 400; batch classifier loss: 0.319307; batch adversarial loss: 0.692621\n",
      "epoch 14; iter: 0; batch classifier loss: 0.319823; batch adversarial loss: 0.563209\n",
      "epoch 14; iter: 200; batch classifier loss: 0.334091; batch adversarial loss: 0.687278\n",
      "epoch 14; iter: 400; batch classifier loss: 0.280722; batch adversarial loss: 0.599176\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457564; batch adversarial loss: 0.646183\n",
      "epoch 15; iter: 200; batch classifier loss: 0.364854; batch adversarial loss: 0.578405\n",
      "epoch 15; iter: 400; batch classifier loss: 0.278861; batch adversarial loss: 0.627357\n",
      "epoch 16; iter: 0; batch classifier loss: 0.357528; batch adversarial loss: 0.677447\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304054; batch adversarial loss: 0.608499\n",
      "epoch 16; iter: 400; batch classifier loss: 0.293961; batch adversarial loss: 0.641796\n",
      "epoch 17; iter: 0; batch classifier loss: 0.469123; batch adversarial loss: 0.630672\n",
      "epoch 17; iter: 200; batch classifier loss: 0.351043; batch adversarial loss: 0.633868\n",
      "epoch 17; iter: 400; batch classifier loss: 0.370286; batch adversarial loss: 0.618501\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398068; batch adversarial loss: 0.587151\n",
      "epoch 18; iter: 200; batch classifier loss: 0.409531; batch adversarial loss: 0.616690\n",
      "epoch 18; iter: 400; batch classifier loss: 0.294532; batch adversarial loss: 0.635396\n",
      "epoch 19; iter: 0; batch classifier loss: 0.316626; batch adversarial loss: 0.640077\n",
      "epoch 19; iter: 200; batch classifier loss: 0.491150; batch adversarial loss: 0.678997\n",
      "epoch 19; iter: 400; batch classifier loss: 0.346937; batch adversarial loss: 0.619610\n",
      "epoch 0; iter: 0; batch classifier loss: 77.554466; batch adversarial loss: 0.731076\n",
      "epoch 0; iter: 200; batch classifier loss: 21.224529; batch adversarial loss: 0.876992\n",
      "epoch 0; iter: 400; batch classifier loss: 13.715416; batch adversarial loss: 0.664720\n",
      "epoch 1; iter: 0; batch classifier loss: 1.975527; batch adversarial loss: 0.615987\n",
      "epoch 1; iter: 200; batch classifier loss: 12.850759; batch adversarial loss: 0.592165\n",
      "epoch 1; iter: 400; batch classifier loss: 4.505376; batch adversarial loss: 0.649117\n",
      "epoch 2; iter: 0; batch classifier loss: 4.195032; batch adversarial loss: 0.565287\n",
      "epoch 2; iter: 200; batch classifier loss: 4.484039; batch adversarial loss: 0.681905\n",
      "epoch 2; iter: 400; batch classifier loss: 2.756389; batch adversarial loss: 0.575406\n",
      "epoch 3; iter: 0; batch classifier loss: 1.723681; batch adversarial loss: 0.652877\n",
      "epoch 3; iter: 200; batch classifier loss: 0.474707; batch adversarial loss: 0.651810\n",
      "epoch 3; iter: 400; batch classifier loss: 0.706184; batch adversarial loss: 0.644895\n",
      "epoch 4; iter: 0; batch classifier loss: 0.881715; batch adversarial loss: 0.587932\n",
      "epoch 4; iter: 200; batch classifier loss: 2.674825; batch adversarial loss: 0.585129\n",
      "epoch 4; iter: 400; batch classifier loss: 0.617153; batch adversarial loss: 0.537831\n",
      "epoch 5; iter: 0; batch classifier loss: 1.155089; batch adversarial loss: 0.659979\n",
      "epoch 5; iter: 200; batch classifier loss: 1.075947; batch adversarial loss: 0.594351\n",
      "epoch 5; iter: 400; batch classifier loss: 0.985325; batch adversarial loss: 0.602251\n",
      "epoch 6; iter: 0; batch classifier loss: 0.637258; batch adversarial loss: 0.571016\n",
      "epoch 6; iter: 200; batch classifier loss: 0.810667; batch adversarial loss: 0.584551\n",
      "epoch 6; iter: 400; batch classifier loss: 0.521945; batch adversarial loss: 0.632208\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532170; batch adversarial loss: 0.580643\n",
      "epoch 7; iter: 200; batch classifier loss: 0.673157; batch adversarial loss: 0.606421\n",
      "epoch 7; iter: 400; batch classifier loss: 0.571254; batch adversarial loss: 0.607155\n",
      "epoch 8; iter: 0; batch classifier loss: 0.504926; batch adversarial loss: 0.602739\n",
      "epoch 8; iter: 200; batch classifier loss: 0.622960; batch adversarial loss: 0.566910\n",
      "epoch 8; iter: 400; batch classifier loss: 0.587739; batch adversarial loss: 0.672663\n",
      "epoch 9; iter: 0; batch classifier loss: 0.423169; batch adversarial loss: 0.657330\n",
      "epoch 9; iter: 200; batch classifier loss: 0.384572; batch adversarial loss: 0.657429\n",
      "epoch 9; iter: 400; batch classifier loss: 0.619350; batch adversarial loss: 0.638915\n",
      "epoch 10; iter: 0; batch classifier loss: 0.334278; batch adversarial loss: 0.603174\n",
      "epoch 10; iter: 200; batch classifier loss: 0.408118; batch adversarial loss: 0.627746\n",
      "epoch 10; iter: 400; batch classifier loss: 0.432054; batch adversarial loss: 0.549059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.421143; batch adversarial loss: 0.665093\n",
      "epoch 11; iter: 200; batch classifier loss: 0.393530; batch adversarial loss: 0.590259\n",
      "epoch 11; iter: 400; batch classifier loss: 0.358301; batch adversarial loss: 0.558352\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417483; batch adversarial loss: 0.566584\n",
      "epoch 12; iter: 200; batch classifier loss: 0.330638; batch adversarial loss: 0.629755\n",
      "epoch 12; iter: 400; batch classifier loss: 0.362653; batch adversarial loss: 0.499321\n",
      "epoch 13; iter: 0; batch classifier loss: 0.395001; batch adversarial loss: 0.638017\n",
      "epoch 13; iter: 200; batch classifier loss: 0.333434; batch adversarial loss: 0.608473\n",
      "epoch 13; iter: 400; batch classifier loss: 0.409956; batch adversarial loss: 0.631422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.437500; batch adversarial loss: 0.646990\n",
      "epoch 14; iter: 200; batch classifier loss: 0.308173; batch adversarial loss: 0.599685\n",
      "epoch 14; iter: 400; batch classifier loss: 0.335475; batch adversarial loss: 0.737197\n",
      "epoch 15; iter: 0; batch classifier loss: 0.346595; batch adversarial loss: 0.613232\n",
      "epoch 15; iter: 200; batch classifier loss: 0.365408; batch adversarial loss: 0.553843\n",
      "epoch 15; iter: 400; batch classifier loss: 0.398893; batch adversarial loss: 0.581619\n",
      "epoch 16; iter: 0; batch classifier loss: 0.275977; batch adversarial loss: 0.610650\n",
      "epoch 16; iter: 200; batch classifier loss: 0.269285; batch adversarial loss: 0.569777\n",
      "epoch 16; iter: 400; batch classifier loss: 0.810111; batch adversarial loss: 0.626888\n",
      "epoch 17; iter: 0; batch classifier loss: 0.210414; batch adversarial loss: 0.678645\n",
      "epoch 17; iter: 200; batch classifier loss: 0.318684; batch adversarial loss: 0.600032\n",
      "epoch 17; iter: 400; batch classifier loss: 0.270424; batch adversarial loss: 0.575711\n",
      "epoch 18; iter: 0; batch classifier loss: 0.400019; batch adversarial loss: 0.722497\n",
      "epoch 18; iter: 200; batch classifier loss: 0.282542; batch adversarial loss: 0.637205\n",
      "epoch 18; iter: 400; batch classifier loss: 0.272713; batch adversarial loss: 0.610215\n",
      "epoch 19; iter: 0; batch classifier loss: 0.383028; batch adversarial loss: 0.553021\n",
      "epoch 19; iter: 200; batch classifier loss: 0.410941; batch adversarial loss: 0.739392\n",
      "epoch 19; iter: 400; batch classifier loss: 0.313307; batch adversarial loss: 0.621840\n",
      "epoch 0; iter: 0; batch classifier loss: 31.191376; batch adversarial loss: 1.059000\n",
      "epoch 0; iter: 200; batch classifier loss: 8.545134; batch adversarial loss: 1.050647\n",
      "epoch 0; iter: 400; batch classifier loss: 3.231298; batch adversarial loss: 0.817804\n",
      "epoch 1; iter: 0; batch classifier loss: 6.257021; batch adversarial loss: 0.769096\n",
      "epoch 1; iter: 200; batch classifier loss: 5.528071; batch adversarial loss: 0.742343\n",
      "epoch 1; iter: 400; batch classifier loss: 5.016521; batch adversarial loss: 0.729647\n",
      "epoch 2; iter: 0; batch classifier loss: 1.140986; batch adversarial loss: 0.660234\n",
      "epoch 2; iter: 200; batch classifier loss: 4.055923; batch adversarial loss: 0.648694\n",
      "epoch 2; iter: 400; batch classifier loss: 3.824928; batch adversarial loss: 0.688244\n",
      "epoch 3; iter: 0; batch classifier loss: 5.228113; batch adversarial loss: 0.701523\n",
      "epoch 3; iter: 200; batch classifier loss: 3.893178; batch adversarial loss: 0.595750\n",
      "epoch 3; iter: 400; batch classifier loss: 2.562355; batch adversarial loss: 0.667421\n",
      "epoch 4; iter: 0; batch classifier loss: 5.663823; batch adversarial loss: 0.622050\n",
      "epoch 4; iter: 200; batch classifier loss: 3.681229; batch adversarial loss: 0.613020\n",
      "epoch 4; iter: 400; batch classifier loss: 3.635751; batch adversarial loss: 0.598883\n",
      "epoch 5; iter: 0; batch classifier loss: 0.427302; batch adversarial loss: 0.646269\n",
      "epoch 5; iter: 200; batch classifier loss: 0.439155; batch adversarial loss: 0.680275\n",
      "epoch 5; iter: 400; batch classifier loss: 0.422458; batch adversarial loss: 0.653637\n",
      "epoch 6; iter: 0; batch classifier loss: 0.441907; batch adversarial loss: 0.688643\n",
      "epoch 6; iter: 200; batch classifier loss: 0.949831; batch adversarial loss: 0.562689\n",
      "epoch 6; iter: 400; batch classifier loss: 0.610352; batch adversarial loss: 0.605146\n",
      "epoch 7; iter: 0; batch classifier loss: 0.668884; batch adversarial loss: 0.624321\n",
      "epoch 7; iter: 200; batch classifier loss: 0.444848; batch adversarial loss: 0.641820\n",
      "epoch 7; iter: 400; batch classifier loss: 0.707181; batch adversarial loss: 0.614140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495001; batch adversarial loss: 0.616240\n",
      "epoch 8; iter: 200; batch classifier loss: 0.448747; batch adversarial loss: 0.576137\n",
      "epoch 8; iter: 400; batch classifier loss: 0.403936; batch adversarial loss: 0.646395\n",
      "epoch 9; iter: 0; batch classifier loss: 0.737895; batch adversarial loss: 0.625539\n",
      "epoch 9; iter: 200; batch classifier loss: 1.140481; batch adversarial loss: 0.679090\n",
      "epoch 9; iter: 400; batch classifier loss: 0.411374; batch adversarial loss: 0.586831\n",
      "epoch 10; iter: 0; batch classifier loss: 0.756839; batch adversarial loss: 0.701593\n",
      "epoch 10; iter: 200; batch classifier loss: 0.255021; batch adversarial loss: 0.748156\n",
      "epoch 10; iter: 400; batch classifier loss: 0.364049; batch adversarial loss: 0.592919\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398278; batch adversarial loss: 0.657572\n",
      "epoch 11; iter: 200; batch classifier loss: 0.287799; batch adversarial loss: 0.619678\n",
      "epoch 11; iter: 400; batch classifier loss: 0.295142; batch adversarial loss: 0.658082\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377400; batch adversarial loss: 0.614028\n",
      "epoch 12; iter: 200; batch classifier loss: 0.510729; batch adversarial loss: 0.670596\n",
      "epoch 12; iter: 400; batch classifier loss: 0.349532; batch adversarial loss: 0.717180\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293630; batch adversarial loss: 0.615369\n",
      "epoch 13; iter: 200; batch classifier loss: 0.319653; batch adversarial loss: 0.582618\n",
      "epoch 13; iter: 400; batch classifier loss: 0.385166; batch adversarial loss: 0.584732\n",
      "epoch 14; iter: 0; batch classifier loss: 0.230749; batch adversarial loss: 0.613926\n",
      "epoch 14; iter: 200; batch classifier loss: 0.474652; batch adversarial loss: 0.543671\n",
      "epoch 14; iter: 400; batch classifier loss: 0.445373; batch adversarial loss: 0.584231\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436494; batch adversarial loss: 0.647262\n",
      "epoch 15; iter: 200; batch classifier loss: 0.314091; batch adversarial loss: 0.583464\n",
      "epoch 15; iter: 400; batch classifier loss: 0.395421; batch adversarial loss: 0.644262\n",
      "epoch 16; iter: 0; batch classifier loss: 0.397706; batch adversarial loss: 0.653554\n",
      "epoch 16; iter: 200; batch classifier loss: 0.324789; batch adversarial loss: 0.652596\n",
      "epoch 16; iter: 400; batch classifier loss: 0.296168; batch adversarial loss: 0.567263\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368953; batch adversarial loss: 0.613644\n",
      "epoch 17; iter: 200; batch classifier loss: 0.329932; batch adversarial loss: 0.707984\n",
      "epoch 17; iter: 400; batch classifier loss: 0.463806; batch adversarial loss: 0.618983\n",
      "epoch 18; iter: 0; batch classifier loss: 0.329630; batch adversarial loss: 0.686668\n",
      "epoch 18; iter: 200; batch classifier loss: 0.331581; batch adversarial loss: 0.617002\n",
      "epoch 18; iter: 400; batch classifier loss: 0.411180; batch adversarial loss: 0.671037\n",
      "epoch 19; iter: 0; batch classifier loss: 0.349136; batch adversarial loss: 0.662917\n",
      "epoch 19; iter: 200; batch classifier loss: 0.561667; batch adversarial loss: 0.619955\n",
      "epoch 19; iter: 400; batch classifier loss: 0.371763; batch adversarial loss: 0.638207\n",
      "epoch 0; iter: 0; batch classifier loss: 13.210180; batch adversarial loss: 0.803442\n",
      "epoch 0; iter: 200; batch classifier loss: 8.492714; batch adversarial loss: 0.792636\n",
      "epoch 0; iter: 400; batch classifier loss: 17.918791; batch adversarial loss: 0.744230\n",
      "epoch 1; iter: 0; batch classifier loss: 0.840100; batch adversarial loss: 0.652282\n",
      "epoch 1; iter: 200; batch classifier loss: 1.670890; batch adversarial loss: 0.636585\n",
      "epoch 1; iter: 400; batch classifier loss: 2.417840; batch adversarial loss: 0.546454\n",
      "epoch 2; iter: 0; batch classifier loss: 4.773932; batch adversarial loss: 0.644239\n",
      "epoch 2; iter: 200; batch classifier loss: 1.421138; batch adversarial loss: 0.611029\n",
      "epoch 2; iter: 400; batch classifier loss: 2.598908; batch adversarial loss: 0.664506\n",
      "epoch 3; iter: 0; batch classifier loss: 6.777494; batch adversarial loss: 0.569597\n",
      "epoch 3; iter: 200; batch classifier loss: 2.956747; batch adversarial loss: 0.672157\n",
      "epoch 3; iter: 400; batch classifier loss: 0.846998; batch adversarial loss: 0.678552\n",
      "epoch 4; iter: 0; batch classifier loss: 1.846920; batch adversarial loss: 0.643824\n",
      "epoch 4; iter: 200; batch classifier loss: 1.139965; batch adversarial loss: 0.617707\n",
      "epoch 4; iter: 400; batch classifier loss: 1.467700; batch adversarial loss: 0.657017\n",
      "epoch 5; iter: 0; batch classifier loss: 1.700588; batch adversarial loss: 0.681906\n",
      "epoch 5; iter: 200; batch classifier loss: 1.264310; batch adversarial loss: 0.620527\n",
      "epoch 5; iter: 400; batch classifier loss: 0.662391; batch adversarial loss: 0.521729\n",
      "epoch 6; iter: 0; batch classifier loss: 0.641084; batch adversarial loss: 0.669011\n",
      "epoch 6; iter: 200; batch classifier loss: 0.383316; batch adversarial loss: 0.572635\n",
      "epoch 6; iter: 400; batch classifier loss: 0.446384; batch adversarial loss: 0.598093\n",
      "epoch 7; iter: 0; batch classifier loss: 0.885870; batch adversarial loss: 0.566009\n",
      "epoch 7; iter: 200; batch classifier loss: 0.330732; batch adversarial loss: 0.733728\n",
      "epoch 7; iter: 400; batch classifier loss: 0.861566; batch adversarial loss: 0.660799\n",
      "epoch 8; iter: 0; batch classifier loss: 0.861328; batch adversarial loss: 0.649142\n",
      "epoch 8; iter: 200; batch classifier loss: 0.482432; batch adversarial loss: 0.629025\n",
      "epoch 8; iter: 400; batch classifier loss: 0.509783; batch adversarial loss: 0.582117\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409140; batch adversarial loss: 0.643612\n",
      "epoch 9; iter: 200; batch classifier loss: 0.379389; batch adversarial loss: 0.732837\n",
      "epoch 9; iter: 400; batch classifier loss: 0.634530; batch adversarial loss: 0.542682\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574837; batch adversarial loss: 0.573616\n",
      "epoch 10; iter: 200; batch classifier loss: 0.400500; batch adversarial loss: 0.770606\n",
      "epoch 10; iter: 400; batch classifier loss: 0.408966; batch adversarial loss: 0.551664\n",
      "epoch 11; iter: 0; batch classifier loss: 0.372870; batch adversarial loss: 0.590560\n",
      "epoch 11; iter: 200; batch classifier loss: 0.497092; batch adversarial loss: 0.564023\n",
      "epoch 11; iter: 400; batch classifier loss: 0.346175; batch adversarial loss: 0.577471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.273040; batch adversarial loss: 0.595245\n",
      "epoch 12; iter: 200; batch classifier loss: 0.293498; batch adversarial loss: 0.693592\n",
      "epoch 12; iter: 400; batch classifier loss: 0.338292; batch adversarial loss: 0.640482\n",
      "epoch 13; iter: 0; batch classifier loss: 0.291500; batch adversarial loss: 0.595629\n",
      "epoch 13; iter: 200; batch classifier loss: 0.427664; batch adversarial loss: 0.580795\n",
      "epoch 13; iter: 400; batch classifier loss: 0.287781; batch adversarial loss: 0.578238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.246182; batch adversarial loss: 0.623056\n",
      "epoch 14; iter: 200; batch classifier loss: 0.373992; batch adversarial loss: 0.662880\n",
      "epoch 14; iter: 400; batch classifier loss: 0.339241; batch adversarial loss: 0.546891\n",
      "epoch 15; iter: 0; batch classifier loss: 0.326365; batch adversarial loss: 0.584445\n",
      "epoch 15; iter: 200; batch classifier loss: 0.356012; batch adversarial loss: 0.597886\n",
      "epoch 15; iter: 400; batch classifier loss: 0.313230; batch adversarial loss: 0.561688\n",
      "epoch 16; iter: 0; batch classifier loss: 0.678210; batch adversarial loss: 0.588600\n",
      "epoch 16; iter: 200; batch classifier loss: 0.475359; batch adversarial loss: 0.508864\n",
      "epoch 16; iter: 400; batch classifier loss: 0.358238; batch adversarial loss: 0.667393\n",
      "epoch 17; iter: 0; batch classifier loss: 0.379793; batch adversarial loss: 0.624623\n",
      "epoch 17; iter: 200; batch classifier loss: 0.379513; batch adversarial loss: 0.609096\n",
      "epoch 17; iter: 400; batch classifier loss: 0.388579; batch adversarial loss: 0.591748\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286845; batch adversarial loss: 0.660303\n",
      "epoch 18; iter: 200; batch classifier loss: 0.442793; batch adversarial loss: 0.600711\n",
      "epoch 18; iter: 400; batch classifier loss: 0.304383; batch adversarial loss: 0.665151\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324915; batch adversarial loss: 0.545812\n",
      "epoch 19; iter: 200; batch classifier loss: 0.361525; batch adversarial loss: 0.642281\n",
      "epoch 19; iter: 400; batch classifier loss: 0.281299; batch adversarial loss: 0.645935\n",
      "epoch 0; iter: 0; batch classifier loss: 22.406652; batch adversarial loss: 0.752129\n",
      "epoch 0; iter: 200; batch classifier loss: 12.529924; batch adversarial loss: 0.654771\n",
      "epoch 0; iter: 400; batch classifier loss: 4.713797; batch adversarial loss: 0.631815\n",
      "epoch 1; iter: 0; batch classifier loss: 17.326191; batch adversarial loss: 0.584680\n",
      "epoch 1; iter: 200; batch classifier loss: 6.083240; batch adversarial loss: 0.566593\n",
      "epoch 1; iter: 400; batch classifier loss: 1.075753; batch adversarial loss: 0.672537\n",
      "epoch 2; iter: 0; batch classifier loss: 45.729828; batch adversarial loss: 0.613752\n",
      "epoch 2; iter: 200; batch classifier loss: 0.672167; batch adversarial loss: 0.553386\n",
      "epoch 2; iter: 400; batch classifier loss: 0.304720; batch adversarial loss: 0.626405\n",
      "epoch 3; iter: 0; batch classifier loss: 4.214785; batch adversarial loss: 0.656929\n",
      "epoch 3; iter: 200; batch classifier loss: 1.720217; batch adversarial loss: 0.607026\n",
      "epoch 3; iter: 400; batch classifier loss: 2.966659; batch adversarial loss: 0.656299\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517212; batch adversarial loss: 0.563129\n",
      "epoch 4; iter: 200; batch classifier loss: 1.709861; batch adversarial loss: 0.616280\n",
      "epoch 4; iter: 400; batch classifier loss: 0.774530; batch adversarial loss: 0.619201\n",
      "epoch 5; iter: 0; batch classifier loss: 0.722904; batch adversarial loss: 0.651676\n",
      "epoch 5; iter: 200; batch classifier loss: 0.635315; batch adversarial loss: 0.532705\n",
      "epoch 5; iter: 400; batch classifier loss: 0.625066; batch adversarial loss: 0.670709\n",
      "epoch 6; iter: 0; batch classifier loss: 1.412406; batch adversarial loss: 0.648739\n",
      "epoch 6; iter: 200; batch classifier loss: 1.120575; batch adversarial loss: 0.604691\n",
      "epoch 6; iter: 400; batch classifier loss: 0.827574; batch adversarial loss: 0.598121\n",
      "epoch 7; iter: 0; batch classifier loss: 0.696894; batch adversarial loss: 0.610805\n",
      "epoch 7; iter: 200; batch classifier loss: 0.424933; batch adversarial loss: 0.688858\n",
      "epoch 7; iter: 400; batch classifier loss: 0.686295; batch adversarial loss: 0.597517\n",
      "epoch 8; iter: 0; batch classifier loss: 0.416229; batch adversarial loss: 0.603718\n",
      "epoch 8; iter: 200; batch classifier loss: 0.392142; batch adversarial loss: 0.695594\n",
      "epoch 8; iter: 400; batch classifier loss: 0.612541; batch adversarial loss: 0.710645\n",
      "epoch 9; iter: 0; batch classifier loss: 0.419646; batch adversarial loss: 0.564871\n",
      "epoch 9; iter: 200; batch classifier loss: 0.469549; batch adversarial loss: 0.655301\n",
      "epoch 9; iter: 400; batch classifier loss: 0.467138; batch adversarial loss: 0.625278\n",
      "epoch 10; iter: 0; batch classifier loss: 0.332208; batch adversarial loss: 0.651031\n",
      "epoch 10; iter: 200; batch classifier loss: 0.397389; batch adversarial loss: 0.637598\n",
      "epoch 10; iter: 400; batch classifier loss: 0.326713; batch adversarial loss: 0.600308\n",
      "epoch 11; iter: 0; batch classifier loss: 0.259023; batch adversarial loss: 0.648280\n",
      "epoch 11; iter: 200; batch classifier loss: 0.379160; batch adversarial loss: 0.591345\n",
      "epoch 11; iter: 400; batch classifier loss: 0.335961; batch adversarial loss: 0.636619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312708; batch adversarial loss: 0.689223\n",
      "epoch 12; iter: 200; batch classifier loss: 0.239445; batch adversarial loss: 0.599890\n",
      "epoch 12; iter: 400; batch classifier loss: 0.448105; batch adversarial loss: 0.647415\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399707; batch adversarial loss: 0.501268\n",
      "epoch 13; iter: 200; batch classifier loss: 0.406547; batch adversarial loss: 0.601520\n",
      "epoch 13; iter: 400; batch classifier loss: 0.351135; batch adversarial loss: 0.588789\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487641; batch adversarial loss: 0.627473\n",
      "epoch 14; iter: 200; batch classifier loss: 0.262611; batch adversarial loss: 0.581507\n",
      "epoch 14; iter: 400; batch classifier loss: 0.257756; batch adversarial loss: 0.548213\n",
      "epoch 15; iter: 0; batch classifier loss: 0.296969; batch adversarial loss: 0.634533\n",
      "epoch 15; iter: 200; batch classifier loss: 0.303031; batch adversarial loss: 0.674687\n",
      "epoch 15; iter: 400; batch classifier loss: 0.391659; batch adversarial loss: 0.641753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.450370; batch adversarial loss: 0.675436\n",
      "epoch 16; iter: 200; batch classifier loss: 0.394294; batch adversarial loss: 0.565256\n",
      "epoch 16; iter: 400; batch classifier loss: 0.491509; batch adversarial loss: 0.600102\n",
      "epoch 17; iter: 0; batch classifier loss: 0.427868; batch adversarial loss: 0.660085\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341078; batch adversarial loss: 0.607228\n",
      "epoch 17; iter: 400; batch classifier loss: 0.520591; batch adversarial loss: 0.635836\n",
      "epoch 18; iter: 0; batch classifier loss: 0.306042; batch adversarial loss: 0.631105\n",
      "epoch 18; iter: 200; batch classifier loss: 0.426859; batch adversarial loss: 0.602703\n",
      "epoch 18; iter: 400; batch classifier loss: 0.190336; batch adversarial loss: 0.613744\n",
      "epoch 19; iter: 0; batch classifier loss: 0.329961; batch adversarial loss: 0.648082\n",
      "epoch 19; iter: 200; batch classifier loss: 0.328145; batch adversarial loss: 0.683886\n",
      "epoch 19; iter: 400; batch classifier loss: 0.289674; batch adversarial loss: 0.603028\n",
      "epoch 0; iter: 0; batch classifier loss: 18.693045; batch adversarial loss: 0.623935\n",
      "epoch 0; iter: 200; batch classifier loss: 0.423245; batch adversarial loss: 0.569755\n",
      "epoch 0; iter: 400; batch classifier loss: 18.540455; batch adversarial loss: 0.670541\n",
      "epoch 1; iter: 0; batch classifier loss: 7.291763; batch adversarial loss: 0.636458\n",
      "epoch 1; iter: 200; batch classifier loss: 1.045759; batch adversarial loss: 0.595564\n",
      "epoch 1; iter: 400; batch classifier loss: 1.122121; batch adversarial loss: 0.629250\n",
      "epoch 2; iter: 0; batch classifier loss: 3.600308; batch adversarial loss: 0.624237\n",
      "epoch 2; iter: 200; batch classifier loss: 1.820966; batch adversarial loss: 0.634445\n",
      "epoch 2; iter: 400; batch classifier loss: 0.529061; batch adversarial loss: 0.633931\n",
      "epoch 3; iter: 0; batch classifier loss: 5.289169; batch adversarial loss: 0.593214\n",
      "epoch 3; iter: 200; batch classifier loss: 3.727842; batch adversarial loss: 0.643274\n",
      "epoch 3; iter: 400; batch classifier loss: 5.954842; batch adversarial loss: 0.648247\n",
      "epoch 4; iter: 0; batch classifier loss: 2.274832; batch adversarial loss: 0.615929\n",
      "epoch 4; iter: 200; batch classifier loss: 5.920122; batch adversarial loss: 0.534364\n",
      "epoch 4; iter: 400; batch classifier loss: 2.405503; batch adversarial loss: 0.609762\n",
      "epoch 5; iter: 0; batch classifier loss: 1.643177; batch adversarial loss: 0.607147\n",
      "epoch 5; iter: 200; batch classifier loss: 0.466957; batch adversarial loss: 0.591669\n",
      "epoch 5; iter: 400; batch classifier loss: 0.715533; batch adversarial loss: 0.585862\n",
      "epoch 6; iter: 0; batch classifier loss: 0.951473; batch adversarial loss: 0.654482\n",
      "epoch 6; iter: 200; batch classifier loss: 0.805496; batch adversarial loss: 0.654334\n",
      "epoch 6; iter: 400; batch classifier loss: 0.414760; batch adversarial loss: 0.646664\n",
      "epoch 7; iter: 0; batch classifier loss: 0.643929; batch adversarial loss: 0.631958\n",
      "epoch 7; iter: 200; batch classifier loss: 0.325472; batch adversarial loss: 0.644216\n",
      "epoch 7; iter: 400; batch classifier loss: 0.680246; batch adversarial loss: 0.546678\n",
      "epoch 8; iter: 0; batch classifier loss: 0.364124; batch adversarial loss: 0.549709\n",
      "epoch 8; iter: 200; batch classifier loss: 0.559464; batch adversarial loss: 0.554250\n",
      "epoch 8; iter: 400; batch classifier loss: 0.457274; batch adversarial loss: 0.541549\n",
      "epoch 9; iter: 0; batch classifier loss: 0.312609; batch adversarial loss: 0.617661\n",
      "epoch 9; iter: 200; batch classifier loss: 0.314038; batch adversarial loss: 0.701314\n",
      "epoch 9; iter: 400; batch classifier loss: 0.485747; batch adversarial loss: 0.644335\n",
      "epoch 10; iter: 0; batch classifier loss: 0.399965; batch adversarial loss: 0.641778\n",
      "epoch 10; iter: 200; batch classifier loss: 0.352153; batch adversarial loss: 0.653765\n",
      "epoch 10; iter: 400; batch classifier loss: 0.241393; batch adversarial loss: 0.804931\n",
      "epoch 11; iter: 0; batch classifier loss: 0.392356; batch adversarial loss: 0.621225\n",
      "epoch 11; iter: 200; batch classifier loss: 0.342695; batch adversarial loss: 0.625291\n",
      "epoch 11; iter: 400; batch classifier loss: 0.475808; batch adversarial loss: 0.671100\n",
      "epoch 12; iter: 0; batch classifier loss: 0.480714; batch adversarial loss: 0.607019\n",
      "epoch 12; iter: 200; batch classifier loss: 0.258543; batch adversarial loss: 0.673406\n",
      "epoch 12; iter: 400; batch classifier loss: 0.381761; batch adversarial loss: 0.643971\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392657; batch adversarial loss: 0.704320\n",
      "epoch 13; iter: 200; batch classifier loss: 0.461322; batch adversarial loss: 0.633435\n",
      "epoch 13; iter: 400; batch classifier loss: 0.451382; batch adversarial loss: 0.553509\n",
      "epoch 14; iter: 0; batch classifier loss: 0.267357; batch adversarial loss: 0.676328\n",
      "epoch 14; iter: 200; batch classifier loss: 0.441537; batch adversarial loss: 0.679793\n",
      "epoch 14; iter: 400; batch classifier loss: 0.433391; batch adversarial loss: 0.626283\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432694; batch adversarial loss: 0.634609\n",
      "epoch 15; iter: 200; batch classifier loss: 0.339132; batch adversarial loss: 0.681076\n",
      "epoch 15; iter: 400; batch classifier loss: 0.389757; batch adversarial loss: 0.603924\n",
      "epoch 16; iter: 0; batch classifier loss: 0.355332; batch adversarial loss: 0.587125\n",
      "epoch 16; iter: 200; batch classifier loss: 0.393424; batch adversarial loss: 0.571437\n",
      "epoch 16; iter: 400; batch classifier loss: 0.331299; batch adversarial loss: 0.526857\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377156; batch adversarial loss: 0.761094\n",
      "epoch 17; iter: 200; batch classifier loss: 0.403891; batch adversarial loss: 0.608596\n",
      "epoch 17; iter: 400; batch classifier loss: 0.293187; batch adversarial loss: 0.590183\n",
      "epoch 18; iter: 0; batch classifier loss: 0.494870; batch adversarial loss: 0.664760\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321917; batch adversarial loss: 0.566614\n",
      "epoch 18; iter: 400; batch classifier loss: 0.319856; batch adversarial loss: 0.660835\n",
      "epoch 19; iter: 0; batch classifier loss: 0.335068; batch adversarial loss: 0.630478\n",
      "epoch 19; iter: 200; batch classifier loss: 0.336572; batch adversarial loss: 0.644732\n",
      "epoch 19; iter: 400; batch classifier loss: 0.343323; batch adversarial loss: 0.792186\n",
      "epoch 0; iter: 0; batch classifier loss: 65.388847; batch adversarial loss: 0.662331\n",
      "epoch 0; iter: 200; batch classifier loss: 5.988539; batch adversarial loss: 0.629537\n",
      "epoch 0; iter: 400; batch classifier loss: 18.914574; batch adversarial loss: 0.649090\n",
      "epoch 1; iter: 0; batch classifier loss: 9.346996; batch adversarial loss: 0.589149\n",
      "epoch 1; iter: 200; batch classifier loss: 8.692265; batch adversarial loss: 0.650310\n",
      "epoch 1; iter: 400; batch classifier loss: 1.771897; batch adversarial loss: 0.634463\n",
      "epoch 2; iter: 0; batch classifier loss: 1.094431; batch adversarial loss: 0.587195\n",
      "epoch 2; iter: 200; batch classifier loss: 5.782502; batch adversarial loss: 0.642949\n",
      "epoch 2; iter: 400; batch classifier loss: 9.950500; batch adversarial loss: 0.635641\n",
      "epoch 3; iter: 0; batch classifier loss: 5.795387; batch adversarial loss: 0.680536\n",
      "epoch 3; iter: 200; batch classifier loss: 1.519072; batch adversarial loss: 0.634724\n",
      "epoch 3; iter: 400; batch classifier loss: 1.275331; batch adversarial loss: 0.657771\n",
      "epoch 4; iter: 0; batch classifier loss: 2.620665; batch adversarial loss: 0.735769\n",
      "epoch 4; iter: 200; batch classifier loss: 0.558745; batch adversarial loss: 0.650789\n",
      "epoch 4; iter: 400; batch classifier loss: 1.147491; batch adversarial loss: 0.630586\n",
      "epoch 5; iter: 0; batch classifier loss: 0.449298; batch adversarial loss: 0.707060\n",
      "epoch 5; iter: 200; batch classifier loss: 1.158299; batch adversarial loss: 0.610276\n",
      "epoch 5; iter: 400; batch classifier loss: 0.609290; batch adversarial loss: 0.577372\n",
      "epoch 6; iter: 0; batch classifier loss: 0.489200; batch adversarial loss: 0.699908\n",
      "epoch 6; iter: 200; batch classifier loss: 0.473964; batch adversarial loss: 0.591115\n",
      "epoch 6; iter: 400; batch classifier loss: 0.493547; batch adversarial loss: 0.633857\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486890; batch adversarial loss: 0.678345\n",
      "epoch 7; iter: 200; batch classifier loss: 0.385253; batch adversarial loss: 0.631122\n",
      "epoch 7; iter: 400; batch classifier loss: 0.367513; batch adversarial loss: 0.627469\n",
      "epoch 8; iter: 0; batch classifier loss: 0.511103; batch adversarial loss: 0.626638\n",
      "epoch 8; iter: 200; batch classifier loss: 0.475299; batch adversarial loss: 0.564699\n",
      "epoch 8; iter: 400; batch classifier loss: 0.322760; batch adversarial loss: 0.616421\n",
      "epoch 9; iter: 0; batch classifier loss: 0.487123; batch adversarial loss: 0.570845\n",
      "epoch 9; iter: 200; batch classifier loss: 0.501099; batch adversarial loss: 0.677393\n",
      "epoch 9; iter: 400; batch classifier loss: 0.304978; batch adversarial loss: 0.661513\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321660; batch adversarial loss: 0.624733\n",
      "epoch 10; iter: 200; batch classifier loss: 0.491244; batch adversarial loss: 0.591958\n",
      "epoch 10; iter: 400; batch classifier loss: 0.412718; batch adversarial loss: 0.646490\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448156; batch adversarial loss: 0.673472\n",
      "epoch 11; iter: 200; batch classifier loss: 0.329430; batch adversarial loss: 0.587750\n",
      "epoch 11; iter: 400; batch classifier loss: 0.370240; batch adversarial loss: 0.654489\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326680; batch adversarial loss: 0.628993\n",
      "epoch 12; iter: 200; batch classifier loss: 0.331743; batch adversarial loss: 0.682784\n",
      "epoch 12; iter: 400; batch classifier loss: 0.398425; batch adversarial loss: 0.584989\n",
      "epoch 13; iter: 0; batch classifier loss: 0.406741; batch adversarial loss: 0.591914\n",
      "epoch 13; iter: 200; batch classifier loss: 0.415452; batch adversarial loss: 0.614508\n",
      "epoch 13; iter: 400; batch classifier loss: 0.316623; batch adversarial loss: 0.640811\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488110; batch adversarial loss: 0.649355\n",
      "epoch 14; iter: 200; batch classifier loss: 0.380287; batch adversarial loss: 0.598950\n",
      "epoch 14; iter: 400; batch classifier loss: 0.307455; batch adversarial loss: 0.640781\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334429; batch adversarial loss: 0.647111\n",
      "epoch 15; iter: 200; batch classifier loss: 0.221793; batch adversarial loss: 0.569508\n",
      "epoch 15; iter: 400; batch classifier loss: 0.349813; batch adversarial loss: 0.707066\n",
      "epoch 16; iter: 0; batch classifier loss: 0.383668; batch adversarial loss: 0.614001\n",
      "epoch 16; iter: 200; batch classifier loss: 0.255246; batch adversarial loss: 0.639171\n",
      "epoch 16; iter: 400; batch classifier loss: 0.257586; batch adversarial loss: 0.548997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.354690; batch adversarial loss: 0.645078\n",
      "epoch 17; iter: 200; batch classifier loss: 0.459012; batch adversarial loss: 0.638010\n",
      "epoch 17; iter: 400; batch classifier loss: 0.353689; batch adversarial loss: 0.679494\n",
      "epoch 18; iter: 0; batch classifier loss: 0.447599; batch adversarial loss: 0.574050\n",
      "epoch 18; iter: 200; batch classifier loss: 0.339429; batch adversarial loss: 0.636561\n",
      "epoch 18; iter: 400; batch classifier loss: 0.259933; batch adversarial loss: 0.701288\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436803; batch adversarial loss: 0.577610\n",
      "epoch 19; iter: 200; batch classifier loss: 0.417891; batch adversarial loss: 0.639010\n",
      "epoch 19; iter: 400; batch classifier loss: 0.491659; batch adversarial loss: 0.649084\n",
      "epoch 0; iter: 0; batch classifier loss: 24.831924; batch adversarial loss: 0.863703\n",
      "epoch 0; iter: 200; batch classifier loss: 14.210918; batch adversarial loss: 0.710519\n",
      "epoch 0; iter: 400; batch classifier loss: 2.647760; batch adversarial loss: 0.692956\n",
      "epoch 1; iter: 0; batch classifier loss: 2.745088; batch adversarial loss: 0.717973\n",
      "epoch 1; iter: 200; batch classifier loss: 3.747443; batch adversarial loss: 0.676703\n",
      "epoch 1; iter: 400; batch classifier loss: 5.583869; batch adversarial loss: 0.647203\n",
      "epoch 2; iter: 0; batch classifier loss: 3.110744; batch adversarial loss: 0.647096\n",
      "epoch 2; iter: 200; batch classifier loss: 2.228333; batch adversarial loss: 0.594130\n",
      "epoch 2; iter: 400; batch classifier loss: 3.805920; batch adversarial loss: 0.603646\n",
      "epoch 3; iter: 0; batch classifier loss: 1.439340; batch adversarial loss: 0.682317\n",
      "epoch 3; iter: 200; batch classifier loss: 1.859090; batch adversarial loss: 0.611900\n",
      "epoch 3; iter: 400; batch classifier loss: 0.882868; batch adversarial loss: 0.711727\n",
      "epoch 4; iter: 0; batch classifier loss: 0.968843; batch adversarial loss: 0.641853\n",
      "epoch 4; iter: 200; batch classifier loss: 1.185540; batch adversarial loss: 0.708362\n",
      "epoch 4; iter: 400; batch classifier loss: 1.827761; batch adversarial loss: 0.625861\n",
      "epoch 5; iter: 0; batch classifier loss: 1.592959; batch adversarial loss: 0.624281\n",
      "epoch 5; iter: 200; batch classifier loss: 0.811330; batch adversarial loss: 0.596717\n",
      "epoch 5; iter: 400; batch classifier loss: 0.744864; batch adversarial loss: 0.591318\n",
      "epoch 6; iter: 0; batch classifier loss: 3.370092; batch adversarial loss: 0.547358\n",
      "epoch 6; iter: 200; batch classifier loss: 0.584448; batch adversarial loss: 0.604352\n",
      "epoch 6; iter: 400; batch classifier loss: 0.412477; batch adversarial loss: 0.566125\n",
      "epoch 7; iter: 0; batch classifier loss: 0.366276; batch adversarial loss: 0.657593\n",
      "epoch 7; iter: 200; batch classifier loss: 0.688666; batch adversarial loss: 0.583941\n",
      "epoch 7; iter: 400; batch classifier loss: 1.794042; batch adversarial loss: 0.615594\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555665; batch adversarial loss: 0.608497\n",
      "epoch 8; iter: 200; batch classifier loss: 0.441312; batch adversarial loss: 0.659695\n",
      "epoch 8; iter: 400; batch classifier loss: 0.242647; batch adversarial loss: 0.663456\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357803; batch adversarial loss: 0.608471\n",
      "epoch 9; iter: 200; batch classifier loss: 0.343269; batch adversarial loss: 0.697469\n",
      "epoch 9; iter: 400; batch classifier loss: 0.416159; batch adversarial loss: 0.605337\n",
      "epoch 10; iter: 0; batch classifier loss: 0.394650; batch adversarial loss: 0.623039\n",
      "epoch 10; iter: 200; batch classifier loss: 0.305296; batch adversarial loss: 0.644325\n",
      "epoch 10; iter: 400; batch classifier loss: 0.371303; batch adversarial loss: 0.649108\n",
      "epoch 11; iter: 0; batch classifier loss: 0.458276; batch adversarial loss: 0.564808\n",
      "epoch 11; iter: 200; batch classifier loss: 0.463925; batch adversarial loss: 0.627755\n",
      "epoch 11; iter: 400; batch classifier loss: 0.436906; batch adversarial loss: 0.729654\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300820; batch adversarial loss: 0.661474\n",
      "epoch 12; iter: 200; batch classifier loss: 0.281854; batch adversarial loss: 0.690657\n",
      "epoch 12; iter: 400; batch classifier loss: 0.345738; batch adversarial loss: 0.565869\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483676; batch adversarial loss: 0.679634\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396294; batch adversarial loss: 0.569465\n",
      "epoch 13; iter: 400; batch classifier loss: 0.493639; batch adversarial loss: 0.620612\n",
      "epoch 14; iter: 0; batch classifier loss: 0.370952; batch adversarial loss: 0.623347\n",
      "epoch 14; iter: 200; batch classifier loss: 0.504605; batch adversarial loss: 0.499633\n",
      "epoch 14; iter: 400; batch classifier loss: 0.457059; batch adversarial loss: 0.585387\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494343; batch adversarial loss: 0.655077\n",
      "epoch 15; iter: 200; batch classifier loss: 0.289181; batch adversarial loss: 0.690687\n",
      "epoch 15; iter: 400; batch classifier loss: 0.361946; batch adversarial loss: 0.646673\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314278; batch adversarial loss: 0.632191\n",
      "epoch 16; iter: 200; batch classifier loss: 0.469248; batch adversarial loss: 0.559172\n",
      "epoch 16; iter: 400; batch classifier loss: 0.331457; batch adversarial loss: 0.621910\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443761; batch adversarial loss: 0.698565\n",
      "epoch 17; iter: 200; batch classifier loss: 0.410834; batch adversarial loss: 0.693621\n",
      "epoch 17; iter: 400; batch classifier loss: 0.320181; batch adversarial loss: 0.599098\n",
      "epoch 18; iter: 0; batch classifier loss: 0.391948; batch adversarial loss: 0.594958\n",
      "epoch 18; iter: 200; batch classifier loss: 0.438368; batch adversarial loss: 0.670680\n",
      "epoch 18; iter: 400; batch classifier loss: 0.207785; batch adversarial loss: 0.675217\n",
      "epoch 19; iter: 0; batch classifier loss: 0.360541; batch adversarial loss: 0.609446\n",
      "epoch 19; iter: 200; batch classifier loss: 0.406709; batch adversarial loss: 0.553838\n",
      "epoch 19; iter: 400; batch classifier loss: 0.631227; batch adversarial loss: 0.600622\n",
      "epoch 0; iter: 0; batch classifier loss: 12.565342; batch adversarial loss: 0.710753\n",
      "epoch 0; iter: 200; batch classifier loss: 4.658813; batch adversarial loss: 0.723623\n",
      "epoch 0; iter: 400; batch classifier loss: 5.038893; batch adversarial loss: 0.652773\n",
      "epoch 1; iter: 0; batch classifier loss: 10.611850; batch adversarial loss: 0.583369\n",
      "epoch 1; iter: 200; batch classifier loss: 0.205638; batch adversarial loss: 0.612062\n",
      "epoch 1; iter: 400; batch classifier loss: 5.223794; batch adversarial loss: 0.643191\n",
      "epoch 2; iter: 0; batch classifier loss: 8.268969; batch adversarial loss: 0.633181\n",
      "epoch 2; iter: 200; batch classifier loss: 1.371849; batch adversarial loss: 0.671673\n",
      "epoch 2; iter: 400; batch classifier loss: 6.064989; batch adversarial loss: 0.559830\n",
      "epoch 3; iter: 0; batch classifier loss: 0.608827; batch adversarial loss: 0.558111\n",
      "epoch 3; iter: 200; batch classifier loss: 1.097896; batch adversarial loss: 0.507675\n",
      "epoch 3; iter: 400; batch classifier loss: 2.335992; batch adversarial loss: 0.717392\n",
      "epoch 4; iter: 0; batch classifier loss: 1.398393; batch adversarial loss: 0.556285\n",
      "epoch 4; iter: 200; batch classifier loss: 0.623310; batch adversarial loss: 0.649129\n",
      "epoch 4; iter: 400; batch classifier loss: 0.808994; batch adversarial loss: 0.668426\n",
      "epoch 5; iter: 0; batch classifier loss: 0.517287; batch adversarial loss: 0.672234\n",
      "epoch 5; iter: 200; batch classifier loss: 1.050788; batch adversarial loss: 0.721561\n",
      "epoch 5; iter: 400; batch classifier loss: 0.621749; batch adversarial loss: 0.611226\n",
      "epoch 6; iter: 0; batch classifier loss: 0.956271; batch adversarial loss: 0.657303\n",
      "epoch 6; iter: 200; batch classifier loss: 0.835062; batch adversarial loss: 0.528593\n",
      "epoch 6; iter: 400; batch classifier loss: 0.435032; batch adversarial loss: 0.584627\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486070; batch adversarial loss: 0.576070\n",
      "epoch 7; iter: 200; batch classifier loss: 0.327769; batch adversarial loss: 0.554714\n",
      "epoch 7; iter: 400; batch classifier loss: 0.539465; batch adversarial loss: 0.591431\n",
      "epoch 8; iter: 0; batch classifier loss: 0.393401; batch adversarial loss: 0.646745\n",
      "epoch 8; iter: 200; batch classifier loss: 0.347955; batch adversarial loss: 0.656955\n",
      "epoch 8; iter: 400; batch classifier loss: 0.500176; batch adversarial loss: 0.631169\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576290; batch adversarial loss: 0.639447\n",
      "epoch 9; iter: 200; batch classifier loss: 0.303278; batch adversarial loss: 0.688735\n",
      "epoch 9; iter: 400; batch classifier loss: 0.349194; batch adversarial loss: 0.577904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.337645; batch adversarial loss: 0.573389\n",
      "epoch 10; iter: 200; batch classifier loss: 0.504259; batch adversarial loss: 0.548527\n",
      "epoch 10; iter: 400; batch classifier loss: 0.278739; batch adversarial loss: 0.607797\n",
      "epoch 11; iter: 0; batch classifier loss: 0.344893; batch adversarial loss: 0.602748\n",
      "epoch 11; iter: 200; batch classifier loss: 0.411435; batch adversarial loss: 0.609314\n",
      "epoch 11; iter: 400; batch classifier loss: 0.259135; batch adversarial loss: 0.622664\n",
      "epoch 12; iter: 0; batch classifier loss: 0.253877; batch adversarial loss: 0.597107\n",
      "epoch 12; iter: 200; batch classifier loss: 0.292547; batch adversarial loss: 0.701044\n",
      "epoch 12; iter: 400; batch classifier loss: 0.377404; batch adversarial loss: 0.629588\n",
      "epoch 13; iter: 0; batch classifier loss: 0.388218; batch adversarial loss: 0.668256\n",
      "epoch 13; iter: 200; batch classifier loss: 0.515695; batch adversarial loss: 0.620064\n",
      "epoch 13; iter: 400; batch classifier loss: 0.461321; batch adversarial loss: 0.563061\n",
      "epoch 14; iter: 0; batch classifier loss: 0.266490; batch adversarial loss: 0.652316\n",
      "epoch 14; iter: 200; batch classifier loss: 0.326152; batch adversarial loss: 0.625643\n",
      "epoch 14; iter: 400; batch classifier loss: 0.321994; batch adversarial loss: 0.640059\n",
      "epoch 15; iter: 0; batch classifier loss: 0.216722; batch adversarial loss: 0.662897\n",
      "epoch 15; iter: 200; batch classifier loss: 0.415482; batch adversarial loss: 0.665116\n",
      "epoch 15; iter: 400; batch classifier loss: 0.376845; batch adversarial loss: 0.640121\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418659; batch adversarial loss: 0.679013\n",
      "epoch 16; iter: 200; batch classifier loss: 0.317851; batch adversarial loss: 0.646280\n",
      "epoch 16; iter: 400; batch classifier loss: 0.358039; batch adversarial loss: 0.536596\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426746; batch adversarial loss: 0.595988\n",
      "epoch 17; iter: 200; batch classifier loss: 0.311208; batch adversarial loss: 0.537670\n",
      "epoch 17; iter: 400; batch classifier loss: 0.300920; batch adversarial loss: 0.631606\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517266; batch adversarial loss: 0.607714\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336240; batch adversarial loss: 0.677164\n",
      "epoch 18; iter: 400; batch classifier loss: 0.366829; batch adversarial loss: 0.623218\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400081; batch adversarial loss: 0.651289\n",
      "epoch 19; iter: 200; batch classifier loss: 0.472877; batch adversarial loss: 0.519504\n",
      "epoch 19; iter: 400; batch classifier loss: 0.317488; batch adversarial loss: 0.684730\n",
      "epoch 0; iter: 0; batch classifier loss: 32.066124; batch adversarial loss: 0.822635\n",
      "epoch 0; iter: 200; batch classifier loss: 20.494043; batch adversarial loss: 0.862124\n",
      "epoch 0; iter: 400; batch classifier loss: 0.331488; batch adversarial loss: 0.773743\n",
      "epoch 1; iter: 0; batch classifier loss: 11.726935; batch adversarial loss: 0.717444\n",
      "epoch 1; iter: 200; batch classifier loss: 0.469355; batch adversarial loss: 0.658573\n",
      "epoch 1; iter: 400; batch classifier loss: 12.206583; batch adversarial loss: 0.590566\n",
      "epoch 2; iter: 0; batch classifier loss: 3.060063; batch adversarial loss: 0.585475\n",
      "epoch 2; iter: 200; batch classifier loss: 2.394861; batch adversarial loss: 0.624508\n",
      "epoch 2; iter: 400; batch classifier loss: 4.184434; batch adversarial loss: 0.654347\n",
      "epoch 3; iter: 0; batch classifier loss: 2.103364; batch adversarial loss: 0.647310\n",
      "epoch 3; iter: 200; batch classifier loss: 2.177276; batch adversarial loss: 0.666849\n",
      "epoch 3; iter: 400; batch classifier loss: 1.319881; batch adversarial loss: 0.636571\n",
      "epoch 4; iter: 0; batch classifier loss: 1.075815; batch adversarial loss: 0.663586\n",
      "epoch 4; iter: 200; batch classifier loss: 2.341089; batch adversarial loss: 0.667540\n",
      "epoch 4; iter: 400; batch classifier loss: 0.957651; batch adversarial loss: 0.596474\n",
      "epoch 5; iter: 0; batch classifier loss: 2.039307; batch adversarial loss: 0.700371\n",
      "epoch 5; iter: 200; batch classifier loss: 1.268296; batch adversarial loss: 0.671884\n",
      "epoch 5; iter: 400; batch classifier loss: 0.735037; batch adversarial loss: 0.642280\n",
      "epoch 6; iter: 0; batch classifier loss: 0.916717; batch adversarial loss: 0.695610\n",
      "epoch 6; iter: 200; batch classifier loss: 0.715569; batch adversarial loss: 0.660517\n",
      "epoch 6; iter: 400; batch classifier loss: 1.252167; batch adversarial loss: 0.605838\n",
      "epoch 7; iter: 0; batch classifier loss: 0.447887; batch adversarial loss: 0.590865\n",
      "epoch 7; iter: 200; batch classifier loss: 0.554205; batch adversarial loss: 0.610395\n",
      "epoch 7; iter: 400; batch classifier loss: 0.518009; batch adversarial loss: 0.618290\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455540; batch adversarial loss: 0.637830\n",
      "epoch 8; iter: 200; batch classifier loss: 0.399325; batch adversarial loss: 0.577219\n",
      "epoch 8; iter: 400; batch classifier loss: 0.508106; batch adversarial loss: 0.552346\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514001; batch adversarial loss: 0.785110\n",
      "epoch 9; iter: 200; batch classifier loss: 0.475563; batch adversarial loss: 0.666040\n",
      "epoch 9; iter: 400; batch classifier loss: 0.329877; batch adversarial loss: 0.653305\n",
      "epoch 10; iter: 0; batch classifier loss: 0.417391; batch adversarial loss: 0.620507\n",
      "epoch 10; iter: 200; batch classifier loss: 0.315514; batch adversarial loss: 0.655594\n",
      "epoch 10; iter: 400; batch classifier loss: 0.354563; batch adversarial loss: 0.541857\n",
      "epoch 11; iter: 0; batch classifier loss: 0.332802; batch adversarial loss: 0.712680\n",
      "epoch 11; iter: 200; batch classifier loss: 0.312718; batch adversarial loss: 0.610583\n",
      "epoch 11; iter: 400; batch classifier loss: 0.328471; batch adversarial loss: 0.626737\n",
      "epoch 12; iter: 0; batch classifier loss: 0.284608; batch adversarial loss: 0.609432\n",
      "epoch 12; iter: 200; batch classifier loss: 0.414457; batch adversarial loss: 0.657091\n",
      "epoch 12; iter: 400; batch classifier loss: 0.431534; batch adversarial loss: 0.565246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.355372; batch adversarial loss: 0.648533\n",
      "epoch 13; iter: 200; batch classifier loss: 0.437122; batch adversarial loss: 0.644835\n",
      "epoch 13; iter: 400; batch classifier loss: 0.412909; batch adversarial loss: 0.588836\n",
      "epoch 14; iter: 0; batch classifier loss: 0.320633; batch adversarial loss: 0.568804\n",
      "epoch 14; iter: 200; batch classifier loss: 0.278587; batch adversarial loss: 0.607824\n",
      "epoch 14; iter: 400; batch classifier loss: 0.302647; batch adversarial loss: 0.611948\n",
      "epoch 15; iter: 0; batch classifier loss: 0.416326; batch adversarial loss: 0.587745\n",
      "epoch 15; iter: 200; batch classifier loss: 0.228647; batch adversarial loss: 0.618278\n",
      "epoch 15; iter: 400; batch classifier loss: 0.445298; batch adversarial loss: 0.529151\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344374; batch adversarial loss: 0.525032\n",
      "epoch 16; iter: 200; batch classifier loss: 0.350710; batch adversarial loss: 0.565772\n",
      "epoch 16; iter: 400; batch classifier loss: 0.348851; batch adversarial loss: 0.655879\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278089; batch adversarial loss: 0.685785\n",
      "epoch 17; iter: 200; batch classifier loss: 0.313864; batch adversarial loss: 0.642034\n",
      "epoch 17; iter: 400; batch classifier loss: 0.372699; batch adversarial loss: 0.646005\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304995; batch adversarial loss: 0.616858\n",
      "epoch 18; iter: 200; batch classifier loss: 0.346890; batch adversarial loss: 0.620860\n",
      "epoch 18; iter: 400; batch classifier loss: 0.325167; batch adversarial loss: 0.697709\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362494; batch adversarial loss: 0.564472\n",
      "epoch 19; iter: 200; batch classifier loss: 0.237614; batch adversarial loss: 0.618538\n",
      "epoch 19; iter: 400; batch classifier loss: 0.435563; batch adversarial loss: 0.641506\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 12.418823; batch adversarial loss: 0.653374\n",
      "epoch 0; iter: 200; batch classifier loss: 3.427803; batch adversarial loss: 0.657215\n",
      "epoch 0; iter: 400; batch classifier loss: 15.689410; batch adversarial loss: 0.630658\n",
      "epoch 1; iter: 0; batch classifier loss: 5.895973; batch adversarial loss: 0.662937\n",
      "epoch 1; iter: 200; batch classifier loss: 3.339487; batch adversarial loss: 0.668559\n",
      "epoch 1; iter: 400; batch classifier loss: 3.161618; batch adversarial loss: 0.643960\n",
      "epoch 2; iter: 0; batch classifier loss: 1.520242; batch adversarial loss: 0.629822\n",
      "epoch 2; iter: 200; batch classifier loss: 7.439881; batch adversarial loss: 0.693669\n",
      "epoch 2; iter: 400; batch classifier loss: 4.937590; batch adversarial loss: 0.654405\n",
      "epoch 3; iter: 0; batch classifier loss: 1.441191; batch adversarial loss: 0.648220\n",
      "epoch 3; iter: 200; batch classifier loss: 0.547225; batch adversarial loss: 0.664572\n",
      "epoch 3; iter: 400; batch classifier loss: 6.494984; batch adversarial loss: 0.602629\n",
      "epoch 4; iter: 0; batch classifier loss: 0.592076; batch adversarial loss: 0.650584\n",
      "epoch 4; iter: 200; batch classifier loss: 2.019918; batch adversarial loss: 0.665260\n",
      "epoch 4; iter: 400; batch classifier loss: 3.052308; batch adversarial loss: 0.616269\n",
      "epoch 5; iter: 0; batch classifier loss: 2.199440; batch adversarial loss: 0.633042\n",
      "epoch 5; iter: 200; batch classifier loss: 0.975022; batch adversarial loss: 0.691626\n",
      "epoch 5; iter: 400; batch classifier loss: 1.141060; batch adversarial loss: 0.625308\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592827; batch adversarial loss: 0.562424\n",
      "epoch 6; iter: 200; batch classifier loss: 0.457667; batch adversarial loss: 0.705322\n",
      "epoch 6; iter: 400; batch classifier loss: 1.429547; batch adversarial loss: 0.538403\n",
      "epoch 7; iter: 0; batch classifier loss: 0.709747; batch adversarial loss: 0.645513\n",
      "epoch 7; iter: 200; batch classifier loss: 0.663535; batch adversarial loss: 0.609518\n",
      "epoch 7; iter: 400; batch classifier loss: 0.974465; batch adversarial loss: 0.618540\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519340; batch adversarial loss: 0.532810\n",
      "epoch 8; iter: 200; batch classifier loss: 0.383828; batch adversarial loss: 0.642002\n",
      "epoch 8; iter: 400; batch classifier loss: 0.347250; batch adversarial loss: 0.525535\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528276; batch adversarial loss: 0.564298\n",
      "epoch 9; iter: 200; batch classifier loss: 0.405836; batch adversarial loss: 0.661741\n",
      "epoch 9; iter: 400; batch classifier loss: 0.533724; batch adversarial loss: 0.604235\n",
      "epoch 10; iter: 0; batch classifier loss: 0.292986; batch adversarial loss: 0.748226\n",
      "epoch 10; iter: 200; batch classifier loss: 0.378399; batch adversarial loss: 0.601142\n",
      "epoch 10; iter: 400; batch classifier loss: 0.317700; batch adversarial loss: 0.574713\n",
      "epoch 11; iter: 0; batch classifier loss: 0.319383; batch adversarial loss: 0.602672\n",
      "epoch 11; iter: 200; batch classifier loss: 0.473459; batch adversarial loss: 0.538176\n",
      "epoch 11; iter: 400; batch classifier loss: 0.412894; batch adversarial loss: 0.664534\n",
      "epoch 12; iter: 0; batch classifier loss: 0.332779; batch adversarial loss: 0.651206\n",
      "epoch 12; iter: 200; batch classifier loss: 0.362707; batch adversarial loss: 0.540093\n",
      "epoch 12; iter: 400; batch classifier loss: 0.433429; batch adversarial loss: 0.609584\n",
      "epoch 13; iter: 0; batch classifier loss: 0.304669; batch adversarial loss: 0.608000\n",
      "epoch 13; iter: 200; batch classifier loss: 0.320468; batch adversarial loss: 0.639771\n",
      "epoch 13; iter: 400; batch classifier loss: 0.346135; batch adversarial loss: 0.637473\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342092; batch adversarial loss: 0.595758\n",
      "epoch 14; iter: 200; batch classifier loss: 0.394340; batch adversarial loss: 0.559823\n",
      "epoch 14; iter: 400; batch classifier loss: 0.308913; batch adversarial loss: 0.636537\n",
      "epoch 15; iter: 0; batch classifier loss: 0.342734; batch adversarial loss: 0.613501\n",
      "epoch 15; iter: 200; batch classifier loss: 0.352196; batch adversarial loss: 0.595025\n",
      "epoch 15; iter: 400; batch classifier loss: 0.441711; batch adversarial loss: 0.558164\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370258; batch adversarial loss: 0.653950\n",
      "epoch 16; iter: 200; batch classifier loss: 0.297780; batch adversarial loss: 0.683286\n",
      "epoch 16; iter: 400; batch classifier loss: 0.226306; batch adversarial loss: 0.681786\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404878; batch adversarial loss: 0.643962\n",
      "epoch 17; iter: 200; batch classifier loss: 0.413744; batch adversarial loss: 0.679371\n",
      "epoch 17; iter: 400; batch classifier loss: 0.505739; batch adversarial loss: 0.681271\n",
      "epoch 18; iter: 0; batch classifier loss: 0.317342; batch adversarial loss: 0.581313\n",
      "epoch 18; iter: 200; batch classifier loss: 0.184018; batch adversarial loss: 0.628318\n",
      "epoch 18; iter: 400; batch classifier loss: 0.369959; batch adversarial loss: 0.657960\n",
      "epoch 19; iter: 0; batch classifier loss: 0.443321; batch adversarial loss: 0.669077\n",
      "epoch 19; iter: 200; batch classifier loss: 0.386746; batch adversarial loss: 0.557828\n",
      "epoch 19; iter: 400; batch classifier loss: 0.343791; batch adversarial loss: 0.559708\n",
      "epoch 20; iter: 0; batch classifier loss: 0.594841; batch adversarial loss: 0.598150\n",
      "epoch 20; iter: 200; batch classifier loss: 0.434957; batch adversarial loss: 0.544298\n",
      "epoch 20; iter: 400; batch classifier loss: 0.442560; batch adversarial loss: 0.701934\n",
      "epoch 21; iter: 0; batch classifier loss: 0.390595; batch adversarial loss: 0.649535\n",
      "epoch 21; iter: 200; batch classifier loss: 0.315984; batch adversarial loss: 0.593455\n",
      "epoch 21; iter: 400; batch classifier loss: 0.406123; batch adversarial loss: 0.681292\n",
      "epoch 22; iter: 0; batch classifier loss: 0.396759; batch adversarial loss: 0.611717\n",
      "epoch 22; iter: 200; batch classifier loss: 0.278722; batch adversarial loss: 0.630717\n",
      "epoch 22; iter: 400; batch classifier loss: 0.416653; batch adversarial loss: 0.633445\n",
      "epoch 23; iter: 0; batch classifier loss: 0.411875; batch adversarial loss: 0.602318\n",
      "epoch 23; iter: 200; batch classifier loss: 0.298289; batch adversarial loss: 0.641934\n",
      "epoch 23; iter: 400; batch classifier loss: 0.540876; batch adversarial loss: 0.586447\n",
      "epoch 24; iter: 0; batch classifier loss: 0.257501; batch adversarial loss: 0.707476\n",
      "epoch 24; iter: 200; batch classifier loss: 0.713927; batch adversarial loss: 0.602303\n",
      "epoch 24; iter: 400; batch classifier loss: 0.226428; batch adversarial loss: 0.640475\n",
      "epoch 25; iter: 0; batch classifier loss: 0.386124; batch adversarial loss: 0.592673\n",
      "epoch 25; iter: 200; batch classifier loss: 0.406300; batch adversarial loss: 0.648632\n",
      "epoch 25; iter: 400; batch classifier loss: 0.494837; batch adversarial loss: 0.739490\n",
      "epoch 26; iter: 0; batch classifier loss: 0.491721; batch adversarial loss: 0.639699\n",
      "epoch 26; iter: 200; batch classifier loss: 0.454267; batch adversarial loss: 0.577257\n",
      "epoch 26; iter: 400; batch classifier loss: 0.804358; batch adversarial loss: 0.665072\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278988; batch adversarial loss: 0.655121\n",
      "epoch 27; iter: 200; batch classifier loss: 0.521256; batch adversarial loss: 0.604363\n",
      "epoch 27; iter: 400; batch classifier loss: 0.275241; batch adversarial loss: 0.617803\n",
      "epoch 28; iter: 0; batch classifier loss: 0.566937; batch adversarial loss: 0.587119\n",
      "epoch 28; iter: 200; batch classifier loss: 0.650445; batch adversarial loss: 0.636359\n",
      "epoch 28; iter: 400; batch classifier loss: 0.520348; batch adversarial loss: 0.661365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.496586; batch adversarial loss: 0.609798\n",
      "epoch 29; iter: 200; batch classifier loss: 0.330266; batch adversarial loss: 0.660066\n",
      "epoch 29; iter: 400; batch classifier loss: 0.421915; batch adversarial loss: 0.655098\n",
      "epoch 30; iter: 0; batch classifier loss: 0.437567; batch adversarial loss: 0.644365\n",
      "epoch 30; iter: 200; batch classifier loss: 0.547844; batch adversarial loss: 0.637501\n",
      "epoch 30; iter: 400; batch classifier loss: 0.392520; batch adversarial loss: 0.598094\n",
      "epoch 31; iter: 0; batch classifier loss: 0.415526; batch adversarial loss: 0.598978\n",
      "epoch 31; iter: 200; batch classifier loss: 0.400298; batch adversarial loss: 0.580120\n",
      "epoch 31; iter: 400; batch classifier loss: 0.628981; batch adversarial loss: 0.618539\n",
      "epoch 32; iter: 0; batch classifier loss: 0.422463; batch adversarial loss: 0.713501\n",
      "epoch 32; iter: 200; batch classifier loss: 0.452626; batch adversarial loss: 0.645304\n",
      "epoch 32; iter: 400; batch classifier loss: 0.269482; batch adversarial loss: 0.655510\n",
      "epoch 33; iter: 0; batch classifier loss: 0.505096; batch adversarial loss: 0.723897\n",
      "epoch 33; iter: 200; batch classifier loss: 0.417998; batch adversarial loss: 0.628528\n",
      "epoch 33; iter: 400; batch classifier loss: 0.659924; batch adversarial loss: 0.668405\n",
      "epoch 34; iter: 0; batch classifier loss: 0.640159; batch adversarial loss: 0.618756\n",
      "epoch 34; iter: 200; batch classifier loss: 0.292264; batch adversarial loss: 0.667103\n",
      "epoch 34; iter: 400; batch classifier loss: 0.614270; batch adversarial loss: 0.631657\n",
      "epoch 35; iter: 0; batch classifier loss: 0.331372; batch adversarial loss: 0.562008\n",
      "epoch 35; iter: 200; batch classifier loss: 0.563093; batch adversarial loss: 0.652396\n",
      "epoch 35; iter: 400; batch classifier loss: 0.436032; batch adversarial loss: 0.634185\n",
      "epoch 36; iter: 0; batch classifier loss: 0.321738; batch adversarial loss: 0.624763\n",
      "epoch 36; iter: 200; batch classifier loss: 0.721144; batch adversarial loss: 0.595337\n",
      "epoch 36; iter: 400; batch classifier loss: 0.717175; batch adversarial loss: 0.662769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.672422; batch adversarial loss: 0.614185\n",
      "epoch 37; iter: 200; batch classifier loss: 0.576973; batch adversarial loss: 0.705736\n",
      "epoch 37; iter: 400; batch classifier loss: 0.456105; batch adversarial loss: 0.591071\n",
      "epoch 38; iter: 0; batch classifier loss: 0.464671; batch adversarial loss: 0.628972\n",
      "epoch 38; iter: 200; batch classifier loss: 0.448224; batch adversarial loss: 0.586249\n",
      "epoch 38; iter: 400; batch classifier loss: 0.451986; batch adversarial loss: 0.594923\n",
      "epoch 39; iter: 0; batch classifier loss: 0.575850; batch adversarial loss: 0.672328\n",
      "epoch 39; iter: 200; batch classifier loss: 0.497254; batch adversarial loss: 0.679125\n",
      "epoch 39; iter: 400; batch classifier loss: 0.494531; batch adversarial loss: 0.670897\n",
      "epoch 40; iter: 0; batch classifier loss: 0.386469; batch adversarial loss: 0.595862\n",
      "epoch 40; iter: 200; batch classifier loss: 0.348940; batch adversarial loss: 0.610479\n",
      "epoch 40; iter: 400; batch classifier loss: 0.583995; batch adversarial loss: 0.704239\n",
      "epoch 41; iter: 0; batch classifier loss: 0.369138; batch adversarial loss: 0.600952\n",
      "epoch 41; iter: 200; batch classifier loss: 0.383983; batch adversarial loss: 0.687907\n",
      "epoch 41; iter: 400; batch classifier loss: 0.547483; batch adversarial loss: 0.649410\n",
      "epoch 42; iter: 0; batch classifier loss: 0.386570; batch adversarial loss: 0.679650\n",
      "epoch 42; iter: 200; batch classifier loss: 0.478590; batch adversarial loss: 0.712869\n",
      "epoch 42; iter: 400; batch classifier loss: 0.488277; batch adversarial loss: 0.615343\n",
      "epoch 43; iter: 0; batch classifier loss: 0.294541; batch adversarial loss: 0.591554\n",
      "epoch 43; iter: 200; batch classifier loss: 0.531865; batch adversarial loss: 0.613253\n",
      "epoch 43; iter: 400; batch classifier loss: 0.650389; batch adversarial loss: 0.602579\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424162; batch adversarial loss: 0.678380\n",
      "epoch 44; iter: 200; batch classifier loss: 0.299284; batch adversarial loss: 0.600334\n",
      "epoch 44; iter: 400; batch classifier loss: 0.332724; batch adversarial loss: 0.661444\n",
      "epoch 45; iter: 0; batch classifier loss: 0.344428; batch adversarial loss: 0.644784\n",
      "epoch 45; iter: 200; batch classifier loss: 0.279494; batch adversarial loss: 0.626023\n",
      "epoch 45; iter: 400; batch classifier loss: 0.471487; batch adversarial loss: 0.592897\n",
      "epoch 46; iter: 0; batch classifier loss: 1.136334; batch adversarial loss: 0.627823\n",
      "epoch 46; iter: 200; batch classifier loss: 0.358603; batch adversarial loss: 0.650621\n",
      "epoch 46; iter: 400; batch classifier loss: 0.450845; batch adversarial loss: 0.568494\n",
      "epoch 47; iter: 0; batch classifier loss: 0.372525; batch adversarial loss: 0.721594\n",
      "epoch 47; iter: 200; batch classifier loss: 0.566915; batch adversarial loss: 0.604094\n",
      "epoch 47; iter: 400; batch classifier loss: 0.683253; batch adversarial loss: 0.706116\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414966; batch adversarial loss: 0.615993\n",
      "epoch 48; iter: 200; batch classifier loss: 0.382182; batch adversarial loss: 0.637200\n",
      "epoch 48; iter: 400; batch classifier loss: 0.291279; batch adversarial loss: 0.633279\n",
      "epoch 49; iter: 0; batch classifier loss: 0.601312; batch adversarial loss: 0.612464\n",
      "epoch 49; iter: 200; batch classifier loss: 0.453690; batch adversarial loss: 0.673306\n",
      "epoch 49; iter: 400; batch classifier loss: 0.428182; batch adversarial loss: 0.682559\n",
      "epoch 0; iter: 0; batch classifier loss: 6.045839; batch adversarial loss: 0.711227\n",
      "epoch 0; iter: 200; batch classifier loss: 6.429718; batch adversarial loss: 0.663877\n",
      "epoch 0; iter: 400; batch classifier loss: 7.056429; batch adversarial loss: 0.644771\n",
      "epoch 1; iter: 0; batch classifier loss: 8.765364; batch adversarial loss: 0.656098\n",
      "epoch 1; iter: 200; batch classifier loss: 6.856699; batch adversarial loss: 0.613958\n",
      "epoch 1; iter: 400; batch classifier loss: 7.589001; batch adversarial loss: 0.646592\n",
      "epoch 2; iter: 0; batch classifier loss: 1.601837; batch adversarial loss: 0.645813\n",
      "epoch 2; iter: 200; batch classifier loss: 1.388705; batch adversarial loss: 0.614536\n",
      "epoch 2; iter: 400; batch classifier loss: 1.009737; batch adversarial loss: 0.603897\n",
      "epoch 3; iter: 0; batch classifier loss: 4.046628; batch adversarial loss: 0.643399\n",
      "epoch 3; iter: 200; batch classifier loss: 1.629268; batch adversarial loss: 0.609365\n",
      "epoch 3; iter: 400; batch classifier loss: 0.824583; batch adversarial loss: 0.634465\n",
      "epoch 4; iter: 0; batch classifier loss: 2.975237; batch adversarial loss: 0.681405\n",
      "epoch 4; iter: 200; batch classifier loss: 1.004759; batch adversarial loss: 0.649389\n",
      "epoch 4; iter: 400; batch classifier loss: 2.090220; batch adversarial loss: 0.657113\n",
      "epoch 5; iter: 0; batch classifier loss: 0.364851; batch adversarial loss: 0.648942\n",
      "epoch 5; iter: 200; batch classifier loss: 0.773429; batch adversarial loss: 0.558522\n",
      "epoch 5; iter: 400; batch classifier loss: 1.145012; batch adversarial loss: 0.633704\n",
      "epoch 6; iter: 0; batch classifier loss: 0.807396; batch adversarial loss: 0.563295\n",
      "epoch 6; iter: 200; batch classifier loss: 0.603147; batch adversarial loss: 0.640674\n",
      "epoch 6; iter: 400; batch classifier loss: 0.323118; batch adversarial loss: 0.638632\n",
      "epoch 7; iter: 0; batch classifier loss: 0.467325; batch adversarial loss: 0.642190\n",
      "epoch 7; iter: 200; batch classifier loss: 0.515767; batch adversarial loss: 0.671203\n",
      "epoch 7; iter: 400; batch classifier loss: 0.494803; batch adversarial loss: 0.575815\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536998; batch adversarial loss: 0.555777\n",
      "epoch 8; iter: 200; batch classifier loss: 0.399957; batch adversarial loss: 0.669179\n",
      "epoch 8; iter: 400; batch classifier loss: 0.333632; batch adversarial loss: 0.630427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.290704; batch adversarial loss: 0.662441\n",
      "epoch 9; iter: 200; batch classifier loss: 0.342430; batch adversarial loss: 0.599639\n",
      "epoch 9; iter: 400; batch classifier loss: 0.402421; batch adversarial loss: 0.632953\n",
      "epoch 10; iter: 0; batch classifier loss: 0.269180; batch adversarial loss: 0.642465\n",
      "epoch 10; iter: 200; batch classifier loss: 0.452702; batch adversarial loss: 0.544772\n",
      "epoch 10; iter: 400; batch classifier loss: 0.373654; batch adversarial loss: 0.600662\n",
      "epoch 11; iter: 0; batch classifier loss: 0.313277; batch adversarial loss: 0.749039\n",
      "epoch 11; iter: 200; batch classifier loss: 0.434094; batch adversarial loss: 0.653415\n",
      "epoch 11; iter: 400; batch classifier loss: 0.445599; batch adversarial loss: 0.576470\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337299; batch adversarial loss: 0.611971\n",
      "epoch 12; iter: 200; batch classifier loss: 0.355632; batch adversarial loss: 0.666123\n",
      "epoch 12; iter: 400; batch classifier loss: 0.230964; batch adversarial loss: 0.771514\n",
      "epoch 13; iter: 0; batch classifier loss: 0.456413; batch adversarial loss: 0.582226\n",
      "epoch 13; iter: 200; batch classifier loss: 0.372873; batch adversarial loss: 0.613637\n",
      "epoch 13; iter: 400; batch classifier loss: 0.266171; batch adversarial loss: 0.631365\n",
      "epoch 14; iter: 0; batch classifier loss: 0.300024; batch adversarial loss: 0.604190\n",
      "epoch 14; iter: 200; batch classifier loss: 0.331157; batch adversarial loss: 0.546523\n",
      "epoch 14; iter: 400; batch classifier loss: 0.329096; batch adversarial loss: 0.532297\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323772; batch adversarial loss: 0.574582\n",
      "epoch 15; iter: 200; batch classifier loss: 0.339377; batch adversarial loss: 0.649675\n",
      "epoch 15; iter: 400; batch classifier loss: 0.260432; batch adversarial loss: 0.582232\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387741; batch adversarial loss: 0.617336\n",
      "epoch 16; iter: 200; batch classifier loss: 0.510773; batch adversarial loss: 0.634877\n",
      "epoch 16; iter: 400; batch classifier loss: 0.426650; batch adversarial loss: 0.606473\n",
      "epoch 17; iter: 0; batch classifier loss: 0.379717; batch adversarial loss: 0.568804\n",
      "epoch 17; iter: 200; batch classifier loss: 0.347990; batch adversarial loss: 0.578100\n",
      "epoch 17; iter: 400; batch classifier loss: 0.218114; batch adversarial loss: 0.678645\n",
      "epoch 18; iter: 0; batch classifier loss: 0.383086; batch adversarial loss: 0.601381\n",
      "epoch 18; iter: 200; batch classifier loss: 0.327226; batch adversarial loss: 0.588604\n",
      "epoch 18; iter: 400; batch classifier loss: 0.426277; batch adversarial loss: 0.608752\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331285; batch adversarial loss: 0.670025\n",
      "epoch 19; iter: 200; batch classifier loss: 0.281974; batch adversarial loss: 0.595901\n",
      "epoch 19; iter: 400; batch classifier loss: 0.506625; batch adversarial loss: 0.529605\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356012; batch adversarial loss: 0.538093\n",
      "epoch 20; iter: 200; batch classifier loss: 0.355958; batch adversarial loss: 0.656579\n",
      "epoch 20; iter: 400; batch classifier loss: 0.686107; batch adversarial loss: 0.672216\n",
      "epoch 21; iter: 0; batch classifier loss: 0.875171; batch adversarial loss: 0.645844\n",
      "epoch 21; iter: 200; batch classifier loss: 0.723743; batch adversarial loss: 0.603381\n",
      "epoch 21; iter: 400; batch classifier loss: 0.574411; batch adversarial loss: 0.675536\n",
      "epoch 22; iter: 0; batch classifier loss: 0.882552; batch adversarial loss: 0.683743\n",
      "epoch 22; iter: 200; batch classifier loss: 0.466588; batch adversarial loss: 0.620641\n",
      "epoch 22; iter: 400; batch classifier loss: 0.458853; batch adversarial loss: 0.648408\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480676; batch adversarial loss: 0.643348\n",
      "epoch 23; iter: 200; batch classifier loss: 0.511508; batch adversarial loss: 0.607629\n",
      "epoch 23; iter: 400; batch classifier loss: 0.588438; batch adversarial loss: 0.701181\n",
      "epoch 24; iter: 0; batch classifier loss: 0.521453; batch adversarial loss: 0.586471\n",
      "epoch 24; iter: 200; batch classifier loss: 0.572139; batch adversarial loss: 0.685157\n",
      "epoch 24; iter: 400; batch classifier loss: 0.385260; batch adversarial loss: 0.654560\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501008; batch adversarial loss: 0.608240\n",
      "epoch 25; iter: 200; batch classifier loss: 0.523569; batch adversarial loss: 0.650454\n",
      "epoch 25; iter: 400; batch classifier loss: 0.445604; batch adversarial loss: 0.691331\n",
      "epoch 26; iter: 0; batch classifier loss: 0.929451; batch adversarial loss: 0.664665\n",
      "epoch 26; iter: 200; batch classifier loss: 0.797913; batch adversarial loss: 0.589015\n",
      "epoch 26; iter: 400; batch classifier loss: 1.005383; batch adversarial loss: 0.619478\n",
      "epoch 27; iter: 0; batch classifier loss: 0.569603; batch adversarial loss: 0.682785\n",
      "epoch 27; iter: 200; batch classifier loss: 0.645284; batch adversarial loss: 0.629953\n",
      "epoch 27; iter: 400; batch classifier loss: 0.740243; batch adversarial loss: 0.723174\n",
      "epoch 28; iter: 0; batch classifier loss: 0.656196; batch adversarial loss: 0.657220\n",
      "epoch 28; iter: 200; batch classifier loss: 0.752940; batch adversarial loss: 0.614334\n",
      "epoch 28; iter: 400; batch classifier loss: 0.973522; batch adversarial loss: 0.644694\n",
      "epoch 29; iter: 0; batch classifier loss: 0.916827; batch adversarial loss: 0.606058\n",
      "epoch 29; iter: 200; batch classifier loss: 0.639203; batch adversarial loss: 0.593744\n",
      "epoch 29; iter: 400; batch classifier loss: 1.426645; batch adversarial loss: 0.653256\n",
      "epoch 30; iter: 0; batch classifier loss: 0.608983; batch adversarial loss: 0.687544\n",
      "epoch 30; iter: 200; batch classifier loss: 0.872818; batch adversarial loss: 0.615190\n",
      "epoch 30; iter: 400; batch classifier loss: 0.747854; batch adversarial loss: 0.597804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.783691; batch adversarial loss: 0.713851\n",
      "epoch 31; iter: 200; batch classifier loss: 0.685838; batch adversarial loss: 0.634369\n",
      "epoch 31; iter: 400; batch classifier loss: 0.485085; batch adversarial loss: 0.636990\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485437; batch adversarial loss: 0.651612\n",
      "epoch 32; iter: 200; batch classifier loss: 1.028400; batch adversarial loss: 0.634752\n",
      "epoch 32; iter: 400; batch classifier loss: 0.350367; batch adversarial loss: 0.650884\n",
      "epoch 33; iter: 0; batch classifier loss: 0.765809; batch adversarial loss: 0.644908\n",
      "epoch 33; iter: 200; batch classifier loss: 0.849705; batch adversarial loss: 0.669729\n",
      "epoch 33; iter: 400; batch classifier loss: 0.385939; batch adversarial loss: 0.617417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.683515; batch adversarial loss: 0.594021\n",
      "epoch 34; iter: 200; batch classifier loss: 1.367486; batch adversarial loss: 0.559665\n",
      "epoch 34; iter: 400; batch classifier loss: 0.628390; batch adversarial loss: 0.583645\n",
      "epoch 35; iter: 0; batch classifier loss: 0.520206; batch adversarial loss: 0.638020\n",
      "epoch 35; iter: 200; batch classifier loss: 0.605109; batch adversarial loss: 0.663851\n",
      "epoch 35; iter: 400; batch classifier loss: 0.753698; batch adversarial loss: 0.665533\n",
      "epoch 36; iter: 0; batch classifier loss: 0.434467; batch adversarial loss: 0.581745\n",
      "epoch 36; iter: 200; batch classifier loss: 0.946679; batch adversarial loss: 0.632520\n",
      "epoch 36; iter: 400; batch classifier loss: 0.734477; batch adversarial loss: 0.612703\n",
      "epoch 37; iter: 0; batch classifier loss: 0.715956; batch adversarial loss: 0.655160\n",
      "epoch 37; iter: 200; batch classifier loss: 1.154301; batch adversarial loss: 0.645066\n",
      "epoch 37; iter: 400; batch classifier loss: 1.102728; batch adversarial loss: 0.621389\n",
      "epoch 38; iter: 0; batch classifier loss: 0.729429; batch adversarial loss: 0.650679\n",
      "epoch 38; iter: 200; batch classifier loss: 0.941272; batch adversarial loss: 0.640854\n",
      "epoch 38; iter: 400; batch classifier loss: 0.464629; batch adversarial loss: 0.642721\n",
      "epoch 39; iter: 0; batch classifier loss: 1.288820; batch adversarial loss: 0.538312\n",
      "epoch 39; iter: 200; batch classifier loss: 0.576522; batch adversarial loss: 0.584857\n",
      "epoch 39; iter: 400; batch classifier loss: 0.791544; batch adversarial loss: 0.583096\n",
      "epoch 40; iter: 0; batch classifier loss: 1.028613; batch adversarial loss: 0.644666\n",
      "epoch 40; iter: 200; batch classifier loss: 0.857156; batch adversarial loss: 0.721986\n",
      "epoch 40; iter: 400; batch classifier loss: 0.874210; batch adversarial loss: 0.657203\n",
      "epoch 41; iter: 0; batch classifier loss: 1.527747; batch adversarial loss: 0.593204\n",
      "epoch 41; iter: 200; batch classifier loss: 0.912901; batch adversarial loss: 0.620321\n",
      "epoch 41; iter: 400; batch classifier loss: 0.554036; batch adversarial loss: 0.588816\n",
      "epoch 42; iter: 0; batch classifier loss: 0.605328; batch adversarial loss: 0.653574\n",
      "epoch 42; iter: 200; batch classifier loss: 0.892049; batch adversarial loss: 0.696292\n",
      "epoch 42; iter: 400; batch classifier loss: 1.277607; batch adversarial loss: 0.671195\n",
      "epoch 43; iter: 0; batch classifier loss: 0.441584; batch adversarial loss: 0.600800\n",
      "epoch 43; iter: 200; batch classifier loss: 0.582613; batch adversarial loss: 0.633985\n",
      "epoch 43; iter: 400; batch classifier loss: 0.958205; batch adversarial loss: 0.615412\n",
      "epoch 44; iter: 0; batch classifier loss: 0.746852; batch adversarial loss: 0.628620\n",
      "epoch 44; iter: 200; batch classifier loss: 1.385051; batch adversarial loss: 0.549298\n",
      "epoch 44; iter: 400; batch classifier loss: 0.939921; batch adversarial loss: 0.666324\n",
      "epoch 45; iter: 0; batch classifier loss: 0.726229; batch adversarial loss: 0.710702\n",
      "epoch 45; iter: 200; batch classifier loss: 0.275845; batch adversarial loss: 0.662932\n",
      "epoch 45; iter: 400; batch classifier loss: 1.003196; batch adversarial loss: 0.676286\n",
      "epoch 46; iter: 0; batch classifier loss: 0.727703; batch adversarial loss: 0.573319\n",
      "epoch 46; iter: 200; batch classifier loss: 1.017861; batch adversarial loss: 0.623579\n",
      "epoch 46; iter: 400; batch classifier loss: 1.204709; batch adversarial loss: 0.648818\n",
      "epoch 47; iter: 0; batch classifier loss: 1.252056; batch adversarial loss: 0.645784\n",
      "epoch 47; iter: 200; batch classifier loss: 1.108229; batch adversarial loss: 0.599042\n",
      "epoch 47; iter: 400; batch classifier loss: 0.688482; batch adversarial loss: 0.573095\n",
      "epoch 48; iter: 0; batch classifier loss: 1.032379; batch adversarial loss: 0.720249\n",
      "epoch 48; iter: 200; batch classifier loss: 1.259602; batch adversarial loss: 0.611841\n",
      "epoch 48; iter: 400; batch classifier loss: 0.950160; batch adversarial loss: 0.550968\n",
      "epoch 49; iter: 0; batch classifier loss: 0.654953; batch adversarial loss: 0.591901\n",
      "epoch 49; iter: 200; batch classifier loss: 1.351472; batch adversarial loss: 0.595802\n",
      "epoch 49; iter: 400; batch classifier loss: 1.287222; batch adversarial loss: 0.600933\n",
      "epoch 0; iter: 0; batch classifier loss: 41.613293; batch adversarial loss: 0.786645\n",
      "epoch 0; iter: 200; batch classifier loss: 9.094862; batch adversarial loss: 0.711742\n",
      "epoch 0; iter: 400; batch classifier loss: 4.212282; batch adversarial loss: 0.673457\n",
      "epoch 1; iter: 0; batch classifier loss: 2.162134; batch adversarial loss: 0.661728\n",
      "epoch 1; iter: 200; batch classifier loss: 6.001057; batch adversarial loss: 0.657140\n",
      "epoch 1; iter: 400; batch classifier loss: 2.281607; batch adversarial loss: 0.629696\n",
      "epoch 2; iter: 0; batch classifier loss: 6.600168; batch adversarial loss: 0.606521\n",
      "epoch 2; iter: 200; batch classifier loss: 7.438399; batch adversarial loss: 0.632205\n",
      "epoch 2; iter: 400; batch classifier loss: 1.391778; batch adversarial loss: 0.624052\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641220; batch adversarial loss: 0.680720\n",
      "epoch 3; iter: 200; batch classifier loss: 6.115347; batch adversarial loss: 0.619358\n",
      "epoch 3; iter: 400; batch classifier loss: 2.304436; batch adversarial loss: 0.588233\n",
      "epoch 4; iter: 0; batch classifier loss: 0.666095; batch adversarial loss: 0.521885\n",
      "epoch 4; iter: 200; batch classifier loss: 0.858715; batch adversarial loss: 0.686794\n",
      "epoch 4; iter: 400; batch classifier loss: 0.702787; batch adversarial loss: 0.647234\n",
      "epoch 5; iter: 0; batch classifier loss: 0.659822; batch adversarial loss: 0.595699\n",
      "epoch 5; iter: 200; batch classifier loss: 1.066166; batch adversarial loss: 0.644176\n",
      "epoch 5; iter: 400; batch classifier loss: 0.942830; batch adversarial loss: 0.657022\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552035; batch adversarial loss: 0.591510\n",
      "epoch 6; iter: 200; batch classifier loss: 0.435668; batch adversarial loss: 0.567269\n",
      "epoch 6; iter: 400; batch classifier loss: 0.641180; batch adversarial loss: 0.590013\n",
      "epoch 7; iter: 0; batch classifier loss: 0.643443; batch adversarial loss: 0.571616\n",
      "epoch 7; iter: 200; batch classifier loss: 0.450189; batch adversarial loss: 0.639099\n",
      "epoch 7; iter: 400; batch classifier loss: 0.954424; batch adversarial loss: 0.630401\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518806; batch adversarial loss: 0.622602\n",
      "epoch 8; iter: 200; batch classifier loss: 0.431962; batch adversarial loss: 0.648727\n",
      "epoch 8; iter: 400; batch classifier loss: 0.457421; batch adversarial loss: 0.643024\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434970; batch adversarial loss: 0.642061\n",
      "epoch 9; iter: 200; batch classifier loss: 0.391903; batch adversarial loss: 0.725099\n",
      "epoch 9; iter: 400; batch classifier loss: 0.378855; batch adversarial loss: 0.618267\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325830; batch adversarial loss: 0.607094\n",
      "epoch 10; iter: 200; batch classifier loss: 0.254955; batch adversarial loss: 0.593874\n",
      "epoch 10; iter: 400; batch classifier loss: 0.373326; batch adversarial loss: 0.616013\n",
      "epoch 11; iter: 0; batch classifier loss: 0.376513; batch adversarial loss: 0.628635\n",
      "epoch 11; iter: 200; batch classifier loss: 0.320077; batch adversarial loss: 0.642796\n",
      "epoch 11; iter: 400; batch classifier loss: 0.331556; batch adversarial loss: 0.618729\n",
      "epoch 12; iter: 0; batch classifier loss: 0.310925; batch adversarial loss: 0.683623\n",
      "epoch 12; iter: 200; batch classifier loss: 0.303467; batch adversarial loss: 0.646718\n",
      "epoch 12; iter: 400; batch classifier loss: 0.396425; batch adversarial loss: 0.594339\n",
      "epoch 13; iter: 0; batch classifier loss: 0.416437; batch adversarial loss: 0.579653\n",
      "epoch 13; iter: 200; batch classifier loss: 0.406033; batch adversarial loss: 0.555723\n",
      "epoch 13; iter: 400; batch classifier loss: 0.443761; batch adversarial loss: 0.636835\n",
      "epoch 14; iter: 0; batch classifier loss: 0.314158; batch adversarial loss: 0.687286\n",
      "epoch 14; iter: 200; batch classifier loss: 0.389516; batch adversarial loss: 0.577087\n",
      "epoch 14; iter: 400; batch classifier loss: 0.389162; batch adversarial loss: 0.516860\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310063; batch adversarial loss: 0.677273\n",
      "epoch 15; iter: 200; batch classifier loss: 0.367062; batch adversarial loss: 0.619525\n",
      "epoch 15; iter: 400; batch classifier loss: 0.348764; batch adversarial loss: 0.604981\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265119; batch adversarial loss: 0.633328\n",
      "epoch 16; iter: 200; batch classifier loss: 0.364540; batch adversarial loss: 0.635849\n",
      "epoch 16; iter: 400; batch classifier loss: 0.417755; batch adversarial loss: 0.553423\n",
      "epoch 17; iter: 0; batch classifier loss: 0.452915; batch adversarial loss: 0.589275\n",
      "epoch 17; iter: 200; batch classifier loss: 0.304190; batch adversarial loss: 0.678081\n",
      "epoch 17; iter: 400; batch classifier loss: 0.303816; batch adversarial loss: 0.668972\n",
      "epoch 18; iter: 0; batch classifier loss: 0.209054; batch adversarial loss: 0.609070\n",
      "epoch 18; iter: 200; batch classifier loss: 0.322453; batch adversarial loss: 0.599040\n",
      "epoch 18; iter: 400; batch classifier loss: 0.203208; batch adversarial loss: 0.659327\n",
      "epoch 19; iter: 0; batch classifier loss: 0.261660; batch adversarial loss: 0.587115\n",
      "epoch 19; iter: 200; batch classifier loss: 0.365102; batch adversarial loss: 0.578687\n",
      "epoch 19; iter: 400; batch classifier loss: 0.424626; batch adversarial loss: 0.657851\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434922; batch adversarial loss: 0.562687\n",
      "epoch 20; iter: 200; batch classifier loss: 0.384248; batch adversarial loss: 0.559445\n",
      "epoch 20; iter: 400; batch classifier loss: 0.390909; batch adversarial loss: 0.668186\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319501; batch adversarial loss: 0.644300\n",
      "epoch 21; iter: 200; batch classifier loss: 0.330902; batch adversarial loss: 0.693665\n",
      "epoch 21; iter: 400; batch classifier loss: 0.357152; batch adversarial loss: 0.600027\n",
      "epoch 22; iter: 0; batch classifier loss: 0.359159; batch adversarial loss: 0.627692\n",
      "epoch 22; iter: 200; batch classifier loss: 0.221537; batch adversarial loss: 0.613752\n",
      "epoch 22; iter: 400; batch classifier loss: 0.277467; batch adversarial loss: 0.683137\n",
      "epoch 23; iter: 0; batch classifier loss: 0.517688; batch adversarial loss: 0.513197\n",
      "epoch 23; iter: 200; batch classifier loss: 0.460180; batch adversarial loss: 0.542634\n",
      "epoch 23; iter: 400; batch classifier loss: 0.496900; batch adversarial loss: 0.621736\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533350; batch adversarial loss: 0.627568\n",
      "epoch 24; iter: 200; batch classifier loss: 0.288356; batch adversarial loss: 0.660961\n",
      "epoch 24; iter: 400; batch classifier loss: 0.269721; batch adversarial loss: 0.544970\n",
      "epoch 25; iter: 0; batch classifier loss: 0.410999; batch adversarial loss: 0.628190\n",
      "epoch 25; iter: 200; batch classifier loss: 0.447661; batch adversarial loss: 0.716417\n",
      "epoch 25; iter: 400; batch classifier loss: 0.305804; batch adversarial loss: 0.708710\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532055; batch adversarial loss: 0.607581\n",
      "epoch 26; iter: 200; batch classifier loss: 0.559829; batch adversarial loss: 0.639609\n",
      "epoch 26; iter: 400; batch classifier loss: 0.369850; batch adversarial loss: 0.683480\n",
      "epoch 27; iter: 0; batch classifier loss: 0.499894; batch adversarial loss: 0.707566\n",
      "epoch 27; iter: 200; batch classifier loss: 0.467839; batch adversarial loss: 0.673670\n",
      "epoch 27; iter: 400; batch classifier loss: 0.283935; batch adversarial loss: 0.678948\n",
      "epoch 28; iter: 0; batch classifier loss: 0.329720; batch adversarial loss: 0.585928\n",
      "epoch 28; iter: 200; batch classifier loss: 0.384285; batch adversarial loss: 0.652890\n",
      "epoch 28; iter: 400; batch classifier loss: 0.445946; batch adversarial loss: 0.648286\n",
      "epoch 29; iter: 0; batch classifier loss: 0.177364; batch adversarial loss: 0.613235\n",
      "epoch 29; iter: 200; batch classifier loss: 0.383948; batch adversarial loss: 0.600076\n",
      "epoch 29; iter: 400; batch classifier loss: 0.510331; batch adversarial loss: 0.672096\n",
      "epoch 30; iter: 0; batch classifier loss: 0.399960; batch adversarial loss: 0.704951\n",
      "epoch 30; iter: 200; batch classifier loss: 0.408525; batch adversarial loss: 0.727222\n",
      "epoch 30; iter: 400; batch classifier loss: 0.480866; batch adversarial loss: 0.630586\n",
      "epoch 31; iter: 0; batch classifier loss: 0.388673; batch adversarial loss: 0.659730\n",
      "epoch 31; iter: 200; batch classifier loss: 0.483453; batch adversarial loss: 0.606258\n",
      "epoch 31; iter: 400; batch classifier loss: 0.367294; batch adversarial loss: 0.643987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485986; batch adversarial loss: 0.653431\n",
      "epoch 32; iter: 200; batch classifier loss: 0.352357; batch adversarial loss: 0.650244\n",
      "epoch 32; iter: 400; batch classifier loss: 0.382268; batch adversarial loss: 0.646096\n",
      "epoch 33; iter: 0; batch classifier loss: 0.826249; batch adversarial loss: 0.650667\n",
      "epoch 33; iter: 200; batch classifier loss: 0.559239; batch adversarial loss: 0.681500\n",
      "epoch 33; iter: 400; batch classifier loss: 0.518203; batch adversarial loss: 0.606580\n",
      "epoch 34; iter: 0; batch classifier loss: 0.518962; batch adversarial loss: 0.586312\n",
      "epoch 34; iter: 200; batch classifier loss: 0.554428; batch adversarial loss: 0.677999\n",
      "epoch 34; iter: 400; batch classifier loss: 0.461407; batch adversarial loss: 0.612493\n",
      "epoch 35; iter: 0; batch classifier loss: 0.417338; batch adversarial loss: 0.687899\n",
      "epoch 35; iter: 200; batch classifier loss: 0.837735; batch adversarial loss: 0.608936\n",
      "epoch 35; iter: 400; batch classifier loss: 0.443232; batch adversarial loss: 0.729571\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389070; batch adversarial loss: 0.648391\n",
      "epoch 36; iter: 200; batch classifier loss: 0.553122; batch adversarial loss: 0.610384\n",
      "epoch 36; iter: 400; batch classifier loss: 0.434625; batch adversarial loss: 0.648656\n",
      "epoch 37; iter: 0; batch classifier loss: 0.473990; batch adversarial loss: 0.613561\n",
      "epoch 37; iter: 200; batch classifier loss: 0.441709; batch adversarial loss: 0.591490\n",
      "epoch 37; iter: 400; batch classifier loss: 0.354354; batch adversarial loss: 0.625537\n",
      "epoch 38; iter: 0; batch classifier loss: 0.741754; batch adversarial loss: 0.656349\n",
      "epoch 38; iter: 200; batch classifier loss: 0.321831; batch adversarial loss: 0.551242\n",
      "epoch 38; iter: 400; batch classifier loss: 0.406561; batch adversarial loss: 0.669676\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407895; batch adversarial loss: 0.630009\n",
      "epoch 39; iter: 200; batch classifier loss: 0.664714; batch adversarial loss: 0.640020\n",
      "epoch 39; iter: 400; batch classifier loss: 0.348559; batch adversarial loss: 0.665077\n",
      "epoch 40; iter: 0; batch classifier loss: 0.362647; batch adversarial loss: 0.616381\n",
      "epoch 40; iter: 200; batch classifier loss: 0.548272; batch adversarial loss: 0.564326\n",
      "epoch 40; iter: 400; batch classifier loss: 0.538105; batch adversarial loss: 0.666416\n",
      "epoch 41; iter: 0; batch classifier loss: 0.328031; batch adversarial loss: 0.723804\n",
      "epoch 41; iter: 200; batch classifier loss: 0.721478; batch adversarial loss: 0.592628\n",
      "epoch 41; iter: 400; batch classifier loss: 0.530869; batch adversarial loss: 0.628286\n",
      "epoch 42; iter: 0; batch classifier loss: 0.357551; batch adversarial loss: 0.596358\n",
      "epoch 42; iter: 200; batch classifier loss: 0.568066; batch adversarial loss: 0.546801\n",
      "epoch 42; iter: 400; batch classifier loss: 0.450918; batch adversarial loss: 0.655916\n",
      "epoch 43; iter: 0; batch classifier loss: 0.538736; batch adversarial loss: 0.627800\n",
      "epoch 43; iter: 200; batch classifier loss: 0.404237; batch adversarial loss: 0.653772\n",
      "epoch 43; iter: 400; batch classifier loss: 0.370392; batch adversarial loss: 0.618837\n",
      "epoch 44; iter: 0; batch classifier loss: 0.484592; batch adversarial loss: 0.628845\n",
      "epoch 44; iter: 200; batch classifier loss: 0.687029; batch adversarial loss: 0.692226\n",
      "epoch 44; iter: 400; batch classifier loss: 0.444997; batch adversarial loss: 0.658619\n",
      "epoch 45; iter: 0; batch classifier loss: 0.343966; batch adversarial loss: 0.620111\n",
      "epoch 45; iter: 200; batch classifier loss: 0.640242; batch adversarial loss: 0.605217\n",
      "epoch 45; iter: 400; batch classifier loss: 0.395346; batch adversarial loss: 0.651310\n",
      "epoch 46; iter: 0; batch classifier loss: 0.268116; batch adversarial loss: 0.610723\n",
      "epoch 46; iter: 200; batch classifier loss: 0.408048; batch adversarial loss: 0.653920\n",
      "epoch 46; iter: 400; batch classifier loss: 0.694344; batch adversarial loss: 0.602341\n",
      "epoch 47; iter: 0; batch classifier loss: 0.332716; batch adversarial loss: 0.640795\n",
      "epoch 47; iter: 200; batch classifier loss: 0.463500; batch adversarial loss: 0.598759\n",
      "epoch 47; iter: 400; batch classifier loss: 0.298008; batch adversarial loss: 0.668695\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375795; batch adversarial loss: 0.574586\n",
      "epoch 48; iter: 200; batch classifier loss: 0.389669; batch adversarial loss: 0.662678\n",
      "epoch 48; iter: 400; batch classifier loss: 0.450819; batch adversarial loss: 0.650156\n",
      "epoch 49; iter: 0; batch classifier loss: 0.273036; batch adversarial loss: 0.629491\n",
      "epoch 49; iter: 200; batch classifier loss: 0.489009; batch adversarial loss: 0.625990\n",
      "epoch 49; iter: 400; batch classifier loss: 0.351923; batch adversarial loss: 0.646124\n",
      "epoch 0; iter: 0; batch classifier loss: 47.093658; batch adversarial loss: 0.766694\n",
      "epoch 0; iter: 200; batch classifier loss: 46.410824; batch adversarial loss: 0.685286\n",
      "epoch 0; iter: 400; batch classifier loss: 3.956664; batch adversarial loss: 0.668855\n",
      "epoch 1; iter: 0; batch classifier loss: 11.170154; batch adversarial loss: 0.699186\n",
      "epoch 1; iter: 200; batch classifier loss: 3.331548; batch adversarial loss: 0.640120\n",
      "epoch 1; iter: 400; batch classifier loss: 0.372361; batch adversarial loss: 0.617016\n",
      "epoch 2; iter: 0; batch classifier loss: 5.840156; batch adversarial loss: 0.643400\n",
      "epoch 2; iter: 200; batch classifier loss: 6.947702; batch adversarial loss: 0.680382\n",
      "epoch 2; iter: 400; batch classifier loss: 4.363435; batch adversarial loss: 0.663960\n",
      "epoch 3; iter: 0; batch classifier loss: 1.459213; batch adversarial loss: 0.685176\n",
      "epoch 3; iter: 200; batch classifier loss: 2.034019; batch adversarial loss: 0.626640\n",
      "epoch 3; iter: 400; batch classifier loss: 0.819351; batch adversarial loss: 0.644446\n",
      "epoch 4; iter: 0; batch classifier loss: 2.004852; batch adversarial loss: 0.633459\n",
      "epoch 4; iter: 200; batch classifier loss: 1.412998; batch adversarial loss: 0.630134\n",
      "epoch 4; iter: 400; batch classifier loss: 1.531302; batch adversarial loss: 0.626171\n",
      "epoch 5; iter: 0; batch classifier loss: 0.463147; batch adversarial loss: 0.645592\n",
      "epoch 5; iter: 200; batch classifier loss: 1.127977; batch adversarial loss: 0.652078\n",
      "epoch 5; iter: 400; batch classifier loss: 0.590273; batch adversarial loss: 0.660238\n",
      "epoch 6; iter: 0; batch classifier loss: 2.204053; batch adversarial loss: 0.559399\n",
      "epoch 6; iter: 200; batch classifier loss: 0.477650; batch adversarial loss: 0.642474\n",
      "epoch 6; iter: 400; batch classifier loss: 0.336902; batch adversarial loss: 0.639780\n",
      "epoch 7; iter: 0; batch classifier loss: 0.458022; batch adversarial loss: 0.671953\n",
      "epoch 7; iter: 200; batch classifier loss: 0.497858; batch adversarial loss: 0.700026\n",
      "epoch 7; iter: 400; batch classifier loss: 0.480598; batch adversarial loss: 0.588298\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555698; batch adversarial loss: 0.611517\n",
      "epoch 8; iter: 200; batch classifier loss: 0.448749; batch adversarial loss: 0.788714\n",
      "epoch 8; iter: 400; batch classifier loss: 0.433143; batch adversarial loss: 0.666958\n",
      "epoch 9; iter: 0; batch classifier loss: 0.395320; batch adversarial loss: 0.659796\n",
      "epoch 9; iter: 200; batch classifier loss: 0.397588; batch adversarial loss: 0.652707\n",
      "epoch 9; iter: 400; batch classifier loss: 0.435440; batch adversarial loss: 0.607065\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407076; batch adversarial loss: 0.651949\n",
      "epoch 10; iter: 200; batch classifier loss: 0.347206; batch adversarial loss: 0.678158\n",
      "epoch 10; iter: 400; batch classifier loss: 0.255242; batch adversarial loss: 0.674327\n",
      "epoch 11; iter: 0; batch classifier loss: 0.267224; batch adversarial loss: 0.680647\n",
      "epoch 11; iter: 200; batch classifier loss: 0.276889; batch adversarial loss: 0.674640\n",
      "epoch 11; iter: 400; batch classifier loss: 0.262655; batch adversarial loss: 0.610284\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383464; batch adversarial loss: 0.637156\n",
      "epoch 12; iter: 200; batch classifier loss: 0.417463; batch adversarial loss: 0.558049\n",
      "epoch 12; iter: 400; batch classifier loss: 0.401550; batch adversarial loss: 0.619821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.464137; batch adversarial loss: 0.604209\n",
      "epoch 13; iter: 200; batch classifier loss: 0.224828; batch adversarial loss: 0.641123\n",
      "epoch 13; iter: 400; batch classifier loss: 0.489735; batch adversarial loss: 0.626912\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350951; batch adversarial loss: 0.564615\n",
      "epoch 14; iter: 200; batch classifier loss: 0.322435; batch adversarial loss: 0.585207\n",
      "epoch 14; iter: 400; batch classifier loss: 0.202807; batch adversarial loss: 0.616621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.407531; batch adversarial loss: 0.624328\n",
      "epoch 15; iter: 200; batch classifier loss: 0.417557; batch adversarial loss: 0.610335\n",
      "epoch 15; iter: 400; batch classifier loss: 0.249460; batch adversarial loss: 0.615884\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336718; batch adversarial loss: 0.566234\n",
      "epoch 16; iter: 200; batch classifier loss: 0.327422; batch adversarial loss: 0.567466\n",
      "epoch 16; iter: 400; batch classifier loss: 0.459950; batch adversarial loss: 0.658613\n",
      "epoch 17; iter: 0; batch classifier loss: 0.450017; batch adversarial loss: 0.571310\n",
      "epoch 17; iter: 200; batch classifier loss: 0.455164; batch adversarial loss: 0.632555\n",
      "epoch 17; iter: 400; batch classifier loss: 0.316370; batch adversarial loss: 0.623257\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349997; batch adversarial loss: 0.620269\n",
      "epoch 18; iter: 200; batch classifier loss: 0.657705; batch adversarial loss: 0.729787\n",
      "epoch 18; iter: 400; batch classifier loss: 0.305974; batch adversarial loss: 0.701448\n",
      "epoch 19; iter: 0; batch classifier loss: 0.543181; batch adversarial loss: 0.600642\n",
      "epoch 19; iter: 200; batch classifier loss: 0.318400; batch adversarial loss: 0.704896\n",
      "epoch 19; iter: 400; batch classifier loss: 0.430032; batch adversarial loss: 0.600994\n",
      "epoch 20; iter: 0; batch classifier loss: 0.487917; batch adversarial loss: 0.610051\n",
      "epoch 20; iter: 200; batch classifier loss: 0.510042; batch adversarial loss: 0.656699\n",
      "epoch 20; iter: 400; batch classifier loss: 0.403619; batch adversarial loss: 0.667993\n",
      "epoch 21; iter: 0; batch classifier loss: 0.445879; batch adversarial loss: 0.642349\n",
      "epoch 21; iter: 200; batch classifier loss: 0.411493; batch adversarial loss: 0.680892\n",
      "epoch 21; iter: 400; batch classifier loss: 0.351390; batch adversarial loss: 0.704753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372679; batch adversarial loss: 0.655630\n",
      "epoch 22; iter: 200; batch classifier loss: 0.433153; batch adversarial loss: 0.650684\n",
      "epoch 22; iter: 400; batch classifier loss: 0.286663; batch adversarial loss: 0.578853\n",
      "epoch 23; iter: 0; batch classifier loss: 0.261361; batch adversarial loss: 0.684480\n",
      "epoch 23; iter: 200; batch classifier loss: 0.370802; batch adversarial loss: 0.587785\n",
      "epoch 23; iter: 400; batch classifier loss: 0.460553; batch adversarial loss: 0.560686\n",
      "epoch 24; iter: 0; batch classifier loss: 0.501129; batch adversarial loss: 0.668907\n",
      "epoch 24; iter: 200; batch classifier loss: 0.403924; batch adversarial loss: 0.599759\n",
      "epoch 24; iter: 400; batch classifier loss: 0.442834; batch adversarial loss: 0.607823\n",
      "epoch 25; iter: 0; batch classifier loss: 0.338153; batch adversarial loss: 0.605899\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360521; batch adversarial loss: 0.703667\n",
      "epoch 25; iter: 400; batch classifier loss: 0.618387; batch adversarial loss: 0.631218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.337661; batch adversarial loss: 0.624270\n",
      "epoch 26; iter: 200; batch classifier loss: 0.507694; batch adversarial loss: 0.589332\n",
      "epoch 26; iter: 400; batch classifier loss: 0.521698; batch adversarial loss: 0.643449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.297425; batch adversarial loss: 0.587117\n",
      "epoch 27; iter: 200; batch classifier loss: 0.403334; batch adversarial loss: 0.569397\n",
      "epoch 27; iter: 400; batch classifier loss: 0.302623; batch adversarial loss: 0.616759\n",
      "epoch 28; iter: 0; batch classifier loss: 0.455035; batch adversarial loss: 0.652613\n",
      "epoch 28; iter: 200; batch classifier loss: 0.387791; batch adversarial loss: 0.618737\n",
      "epoch 28; iter: 400; batch classifier loss: 0.391070; batch adversarial loss: 0.685019\n",
      "epoch 29; iter: 0; batch classifier loss: 0.475933; batch adversarial loss: 0.640348\n",
      "epoch 29; iter: 200; batch classifier loss: 0.536904; batch adversarial loss: 0.650099\n",
      "epoch 29; iter: 400; batch classifier loss: 0.418153; batch adversarial loss: 0.655471\n",
      "epoch 30; iter: 0; batch classifier loss: 0.508305; batch adversarial loss: 0.582884\n",
      "epoch 30; iter: 200; batch classifier loss: 0.416721; batch adversarial loss: 0.602114\n",
      "epoch 30; iter: 400; batch classifier loss: 0.365821; batch adversarial loss: 0.665786\n",
      "epoch 31; iter: 0; batch classifier loss: 0.593619; batch adversarial loss: 0.585514\n",
      "epoch 31; iter: 200; batch classifier loss: 0.418045; batch adversarial loss: 0.627251\n",
      "epoch 31; iter: 400; batch classifier loss: 0.615734; batch adversarial loss: 0.590513\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441414; batch adversarial loss: 0.619515\n",
      "epoch 32; iter: 200; batch classifier loss: 0.358664; batch adversarial loss: 0.715459\n",
      "epoch 32; iter: 400; batch classifier loss: 0.305833; batch adversarial loss: 0.649031\n",
      "epoch 33; iter: 0; batch classifier loss: 0.354486; batch adversarial loss: 0.661513\n",
      "epoch 33; iter: 200; batch classifier loss: 0.441942; batch adversarial loss: 0.614635\n",
      "epoch 33; iter: 400; batch classifier loss: 0.571367; batch adversarial loss: 0.643685\n",
      "epoch 34; iter: 0; batch classifier loss: 0.290091; batch adversarial loss: 0.726431\n",
      "epoch 34; iter: 200; batch classifier loss: 0.490736; batch adversarial loss: 0.626805\n",
      "epoch 34; iter: 400; batch classifier loss: 0.419940; batch adversarial loss: 0.568004\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474379; batch adversarial loss: 0.631464\n",
      "epoch 35; iter: 200; batch classifier loss: 0.655558; batch adversarial loss: 0.589531\n",
      "epoch 35; iter: 400; batch classifier loss: 0.582949; batch adversarial loss: 0.602222\n",
      "epoch 36; iter: 0; batch classifier loss: 0.388359; batch adversarial loss: 0.635932\n",
      "epoch 36; iter: 200; batch classifier loss: 0.405439; batch adversarial loss: 0.604361\n",
      "epoch 36; iter: 400; batch classifier loss: 0.329095; batch adversarial loss: 0.693364\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404505; batch adversarial loss: 0.611820\n",
      "epoch 37; iter: 200; batch classifier loss: 0.402724; batch adversarial loss: 0.630655\n",
      "epoch 37; iter: 400; batch classifier loss: 0.629461; batch adversarial loss: 0.717561\n",
      "epoch 38; iter: 0; batch classifier loss: 0.351076; batch adversarial loss: 0.585751\n",
      "epoch 38; iter: 200; batch classifier loss: 0.380929; batch adversarial loss: 0.650014\n",
      "epoch 38; iter: 400; batch classifier loss: 0.473352; batch adversarial loss: 0.570988\n",
      "epoch 39; iter: 0; batch classifier loss: 0.541797; batch adversarial loss: 0.676408\n",
      "epoch 39; iter: 200; batch classifier loss: 0.392177; batch adversarial loss: 0.656311\n",
      "epoch 39; iter: 400; batch classifier loss: 0.449579; batch adversarial loss: 0.662762\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428410; batch adversarial loss: 0.586930\n",
      "epoch 40; iter: 200; batch classifier loss: 0.536487; batch adversarial loss: 0.659302\n",
      "epoch 40; iter: 400; batch classifier loss: 0.573586; batch adversarial loss: 0.636656\n",
      "epoch 41; iter: 0; batch classifier loss: 0.573917; batch adversarial loss: 0.710210\n",
      "epoch 41; iter: 200; batch classifier loss: 0.410131; batch adversarial loss: 0.627021\n",
      "epoch 41; iter: 400; batch classifier loss: 0.499320; batch adversarial loss: 0.626473\n",
      "epoch 42; iter: 0; batch classifier loss: 0.589581; batch adversarial loss: 0.603337\n",
      "epoch 42; iter: 200; batch classifier loss: 0.297649; batch adversarial loss: 0.670775\n",
      "epoch 42; iter: 400; batch classifier loss: 0.507144; batch adversarial loss: 0.591979\n",
      "epoch 43; iter: 0; batch classifier loss: 0.209677; batch adversarial loss: 0.586205\n",
      "epoch 43; iter: 200; batch classifier loss: 0.479808; batch adversarial loss: 0.585644\n",
      "epoch 43; iter: 400; batch classifier loss: 0.503618; batch adversarial loss: 0.586121\n",
      "epoch 44; iter: 0; batch classifier loss: 0.464208; batch adversarial loss: 0.547313\n",
      "epoch 44; iter: 200; batch classifier loss: 0.482816; batch adversarial loss: 0.641216\n",
      "epoch 44; iter: 400; batch classifier loss: 0.528041; batch adversarial loss: 0.663913\n",
      "epoch 45; iter: 0; batch classifier loss: 0.629473; batch adversarial loss: 0.602509\n",
      "epoch 45; iter: 200; batch classifier loss: 0.504040; batch adversarial loss: 0.609485\n",
      "epoch 45; iter: 400; batch classifier loss: 0.470809; batch adversarial loss: 0.563595\n",
      "epoch 46; iter: 0; batch classifier loss: 0.342260; batch adversarial loss: 0.574644\n",
      "epoch 46; iter: 200; batch classifier loss: 0.382892; batch adversarial loss: 0.658343\n",
      "epoch 46; iter: 400; batch classifier loss: 0.386540; batch adversarial loss: 0.682244\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371463; batch adversarial loss: 0.580807\n",
      "epoch 47; iter: 200; batch classifier loss: 0.395710; batch adversarial loss: 0.615771\n",
      "epoch 47; iter: 400; batch classifier loss: 0.514241; batch adversarial loss: 0.633638\n",
      "epoch 48; iter: 0; batch classifier loss: 0.510736; batch adversarial loss: 0.597618\n",
      "epoch 48; iter: 200; batch classifier loss: 0.432605; batch adversarial loss: 0.686569\n",
      "epoch 48; iter: 400; batch classifier loss: 0.391839; batch adversarial loss: 0.697061\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394381; batch adversarial loss: 0.571466\n",
      "epoch 49; iter: 200; batch classifier loss: 0.320841; batch adversarial loss: 0.561794\n",
      "epoch 49; iter: 400; batch classifier loss: 0.450914; batch adversarial loss: 0.625636\n",
      "epoch 0; iter: 0; batch classifier loss: 12.643188; batch adversarial loss: 0.657128\n",
      "epoch 0; iter: 200; batch classifier loss: 6.575269; batch adversarial loss: 0.665392\n",
      "epoch 0; iter: 400; batch classifier loss: 1.899889; batch adversarial loss: 0.621382\n",
      "epoch 1; iter: 0; batch classifier loss: 0.830951; batch adversarial loss: 0.652913\n",
      "epoch 1; iter: 200; batch classifier loss: 50.974377; batch adversarial loss: 0.646575\n",
      "epoch 1; iter: 400; batch classifier loss: 4.521036; batch adversarial loss: 0.663515\n",
      "epoch 2; iter: 0; batch classifier loss: 6.118955; batch adversarial loss: 0.605095\n",
      "epoch 2; iter: 200; batch classifier loss: 12.170759; batch adversarial loss: 0.664812\n",
      "epoch 2; iter: 400; batch classifier loss: 13.428967; batch adversarial loss: 0.660033\n",
      "epoch 3; iter: 0; batch classifier loss: 12.587662; batch adversarial loss: 0.628586\n",
      "epoch 3; iter: 200; batch classifier loss: 4.047945; batch adversarial loss: 0.555687\n",
      "epoch 3; iter: 400; batch classifier loss: 5.734866; batch adversarial loss: 0.647680\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605161; batch adversarial loss: 0.608484\n",
      "epoch 4; iter: 200; batch classifier loss: 1.790383; batch adversarial loss: 0.626259\n",
      "epoch 4; iter: 400; batch classifier loss: 2.848659; batch adversarial loss: 0.608476\n",
      "epoch 5; iter: 0; batch classifier loss: 0.946607; batch adversarial loss: 0.661978\n",
      "epoch 5; iter: 200; batch classifier loss: 1.203070; batch adversarial loss: 0.524688\n",
      "epoch 5; iter: 400; batch classifier loss: 1.403705; batch adversarial loss: 0.613443\n",
      "epoch 6; iter: 0; batch classifier loss: 0.702945; batch adversarial loss: 0.588755\n",
      "epoch 6; iter: 200; batch classifier loss: 1.165028; batch adversarial loss: 0.633352\n",
      "epoch 6; iter: 400; batch classifier loss: 0.767155; batch adversarial loss: 0.602899\n",
      "epoch 7; iter: 0; batch classifier loss: 0.831789; batch adversarial loss: 0.633725\n",
      "epoch 7; iter: 200; batch classifier loss: 0.369250; batch adversarial loss: 0.658065\n",
      "epoch 7; iter: 400; batch classifier loss: 0.585120; batch adversarial loss: 0.543015\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490436; batch adversarial loss: 0.559639\n",
      "epoch 8; iter: 200; batch classifier loss: 0.405730; batch adversarial loss: 0.621410\n",
      "epoch 8; iter: 400; batch classifier loss: 0.406069; batch adversarial loss: 0.646020\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545091; batch adversarial loss: 0.619914\n",
      "epoch 9; iter: 200; batch classifier loss: 0.308826; batch adversarial loss: 0.635002\n",
      "epoch 9; iter: 400; batch classifier loss: 0.347627; batch adversarial loss: 0.606688\n",
      "epoch 10; iter: 0; batch classifier loss: 0.467663; batch adversarial loss: 0.608248\n",
      "epoch 10; iter: 200; batch classifier loss: 0.504113; batch adversarial loss: 0.562747\n",
      "epoch 10; iter: 400; batch classifier loss: 0.266486; batch adversarial loss: 0.644797\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368916; batch adversarial loss: 0.689665\n",
      "epoch 11; iter: 200; batch classifier loss: 0.418228; batch adversarial loss: 0.622463\n",
      "epoch 11; iter: 400; batch classifier loss: 0.370447; batch adversarial loss: 0.591410\n",
      "epoch 12; iter: 0; batch classifier loss: 0.195349; batch adversarial loss: 0.665339\n",
      "epoch 12; iter: 200; batch classifier loss: 0.449896; batch adversarial loss: 0.620708\n",
      "epoch 12; iter: 400; batch classifier loss: 0.350301; batch adversarial loss: 0.672559\n",
      "epoch 13; iter: 0; batch classifier loss: 0.261910; batch adversarial loss: 0.654093\n",
      "epoch 13; iter: 200; batch classifier loss: 0.312618; batch adversarial loss: 0.661139\n",
      "epoch 13; iter: 400; batch classifier loss: 0.350231; batch adversarial loss: 0.686125\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504273; batch adversarial loss: 0.558262\n",
      "epoch 14; iter: 200; batch classifier loss: 0.369592; batch adversarial loss: 0.566911\n",
      "epoch 14; iter: 400; batch classifier loss: 0.281627; batch adversarial loss: 0.667278\n",
      "epoch 15; iter: 0; batch classifier loss: 0.367285; batch adversarial loss: 0.627281\n",
      "epoch 15; iter: 200; batch classifier loss: 0.269459; batch adversarial loss: 0.582887\n",
      "epoch 15; iter: 400; batch classifier loss: 0.458618; batch adversarial loss: 0.609896\n",
      "epoch 16; iter: 0; batch classifier loss: 0.416145; batch adversarial loss: 0.584566\n",
      "epoch 16; iter: 200; batch classifier loss: 0.346893; batch adversarial loss: 0.553450\n",
      "epoch 16; iter: 400; batch classifier loss: 0.258413; batch adversarial loss: 0.646158\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372599; batch adversarial loss: 0.597702\n",
      "epoch 17; iter: 200; batch classifier loss: 0.220622; batch adversarial loss: 0.567623\n",
      "epoch 17; iter: 400; batch classifier loss: 0.425286; batch adversarial loss: 0.614773\n",
      "epoch 18; iter: 0; batch classifier loss: 0.164276; batch adversarial loss: 0.681919\n",
      "epoch 18; iter: 200; batch classifier loss: 0.339954; batch adversarial loss: 0.657497\n",
      "epoch 18; iter: 400; batch classifier loss: 0.242504; batch adversarial loss: 0.698538\n",
      "epoch 19; iter: 0; batch classifier loss: 0.332650; batch adversarial loss: 0.658350\n",
      "epoch 19; iter: 200; batch classifier loss: 0.363835; batch adversarial loss: 0.675910\n",
      "epoch 19; iter: 400; batch classifier loss: 0.373891; batch adversarial loss: 0.635543\n",
      "epoch 20; iter: 0; batch classifier loss: 0.260051; batch adversarial loss: 0.676693\n",
      "epoch 20; iter: 200; batch classifier loss: 0.394739; batch adversarial loss: 0.692114\n",
      "epoch 20; iter: 400; batch classifier loss: 0.554054; batch adversarial loss: 0.643198\n",
      "epoch 21; iter: 0; batch classifier loss: 0.366043; batch adversarial loss: 0.602920\n",
      "epoch 21; iter: 200; batch classifier loss: 0.444728; batch adversarial loss: 0.623190\n",
      "epoch 21; iter: 400; batch classifier loss: 0.424510; batch adversarial loss: 0.584485\n",
      "epoch 22; iter: 0; batch classifier loss: 0.407933; batch adversarial loss: 0.655691\n",
      "epoch 22; iter: 200; batch classifier loss: 0.465460; batch adversarial loss: 0.601879\n",
      "epoch 22; iter: 400; batch classifier loss: 0.279898; batch adversarial loss: 0.714764\n",
      "epoch 23; iter: 0; batch classifier loss: 0.398686; batch adversarial loss: 0.623283\n",
      "epoch 23; iter: 200; batch classifier loss: 0.410163; batch adversarial loss: 0.557666\n",
      "epoch 23; iter: 400; batch classifier loss: 0.387189; batch adversarial loss: 0.664024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.261387; batch adversarial loss: 0.721566\n",
      "epoch 24; iter: 200; batch classifier loss: 0.429066; batch adversarial loss: 0.625190\n",
      "epoch 24; iter: 400; batch classifier loss: 0.390198; batch adversarial loss: 0.619322\n",
      "epoch 25; iter: 0; batch classifier loss: 0.356756; batch adversarial loss: 0.667928\n",
      "epoch 25; iter: 200; batch classifier loss: 0.350105; batch adversarial loss: 0.622343\n",
      "epoch 25; iter: 400; batch classifier loss: 0.286011; batch adversarial loss: 0.653278\n",
      "epoch 26; iter: 0; batch classifier loss: 0.521052; batch adversarial loss: 0.640710\n",
      "epoch 26; iter: 200; batch classifier loss: 0.451810; batch adversarial loss: 0.605719\n",
      "epoch 26; iter: 400; batch classifier loss: 0.326063; batch adversarial loss: 0.636216\n",
      "epoch 27; iter: 0; batch classifier loss: 0.222693; batch adversarial loss: 0.587860\n",
      "epoch 27; iter: 200; batch classifier loss: 0.391709; batch adversarial loss: 0.673674\n",
      "epoch 27; iter: 400; batch classifier loss: 0.311577; batch adversarial loss: 0.638139\n",
      "epoch 28; iter: 0; batch classifier loss: 0.393859; batch adversarial loss: 0.677366\n",
      "epoch 28; iter: 200; batch classifier loss: 0.341072; batch adversarial loss: 0.689474\n",
      "epoch 28; iter: 400; batch classifier loss: 0.359817; batch adversarial loss: 0.658498\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482910; batch adversarial loss: 0.609572\n",
      "epoch 29; iter: 200; batch classifier loss: 0.243982; batch adversarial loss: 0.672979\n",
      "epoch 29; iter: 400; batch classifier loss: 0.471014; batch adversarial loss: 0.638585\n",
      "epoch 30; iter: 0; batch classifier loss: 0.524740; batch adversarial loss: 0.616309\n",
      "epoch 30; iter: 200; batch classifier loss: 0.455114; batch adversarial loss: 0.642076\n",
      "epoch 30; iter: 400; batch classifier loss: 0.506892; batch adversarial loss: 0.632405\n",
      "epoch 31; iter: 0; batch classifier loss: 0.452016; batch adversarial loss: 0.608757\n",
      "epoch 31; iter: 200; batch classifier loss: 0.428051; batch adversarial loss: 0.562891\n",
      "epoch 31; iter: 400; batch classifier loss: 0.310317; batch adversarial loss: 0.677786\n",
      "epoch 32; iter: 0; batch classifier loss: 0.350560; batch adversarial loss: 0.640390\n",
      "epoch 32; iter: 200; batch classifier loss: 0.287839; batch adversarial loss: 0.691144\n",
      "epoch 32; iter: 400; batch classifier loss: 0.365494; batch adversarial loss: 0.566866\n",
      "epoch 33; iter: 0; batch classifier loss: 0.366001; batch adversarial loss: 0.626042\n",
      "epoch 33; iter: 200; batch classifier loss: 0.560272; batch adversarial loss: 0.662492\n",
      "epoch 33; iter: 400; batch classifier loss: 0.348519; batch adversarial loss: 0.676559\n",
      "epoch 34; iter: 0; batch classifier loss: 0.371629; batch adversarial loss: 0.635784\n",
      "epoch 34; iter: 200; batch classifier loss: 0.377347; batch adversarial loss: 0.589430\n",
      "epoch 34; iter: 400; batch classifier loss: 0.349225; batch adversarial loss: 0.682799\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429035; batch adversarial loss: 0.636571\n",
      "epoch 35; iter: 200; batch classifier loss: 0.414987; batch adversarial loss: 0.573105\n",
      "epoch 35; iter: 400; batch classifier loss: 0.531480; batch adversarial loss: 0.624368\n",
      "epoch 36; iter: 0; batch classifier loss: 0.294202; batch adversarial loss: 0.659507\n",
      "epoch 36; iter: 200; batch classifier loss: 0.385308; batch adversarial loss: 0.569865\n",
      "epoch 36; iter: 400; batch classifier loss: 0.415824; batch adversarial loss: 0.636516\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421481; batch adversarial loss: 0.675454\n",
      "epoch 37; iter: 200; batch classifier loss: 0.462034; batch adversarial loss: 0.686514\n",
      "epoch 37; iter: 400; batch classifier loss: 0.307003; batch adversarial loss: 0.671740\n",
      "epoch 38; iter: 0; batch classifier loss: 0.352502; batch adversarial loss: 0.629662\n",
      "epoch 38; iter: 200; batch classifier loss: 0.589443; batch adversarial loss: 0.674748\n",
      "epoch 38; iter: 400; batch classifier loss: 0.583993; batch adversarial loss: 0.658513\n",
      "epoch 39; iter: 0; batch classifier loss: 0.635706; batch adversarial loss: 0.655507\n",
      "epoch 39; iter: 200; batch classifier loss: 0.295640; batch adversarial loss: 0.560125\n",
      "epoch 39; iter: 400; batch classifier loss: 0.380678; batch adversarial loss: 0.574063\n",
      "epoch 40; iter: 0; batch classifier loss: 0.549551; batch adversarial loss: 0.570322\n",
      "epoch 40; iter: 200; batch classifier loss: 0.345151; batch adversarial loss: 0.647982\n",
      "epoch 40; iter: 400; batch classifier loss: 0.269565; batch adversarial loss: 0.649747\n",
      "epoch 41; iter: 0; batch classifier loss: 0.639816; batch adversarial loss: 0.628149\n",
      "epoch 41; iter: 200; batch classifier loss: 0.334965; batch adversarial loss: 0.617852\n",
      "epoch 41; iter: 400; batch classifier loss: 0.665526; batch adversarial loss: 0.583783\n",
      "epoch 42; iter: 0; batch classifier loss: 0.395670; batch adversarial loss: 0.612890\n",
      "epoch 42; iter: 200; batch classifier loss: 0.368409; batch adversarial loss: 0.632088\n",
      "epoch 42; iter: 400; batch classifier loss: 0.269811; batch adversarial loss: 0.609292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.355013; batch adversarial loss: 0.649203\n",
      "epoch 43; iter: 200; batch classifier loss: 0.402889; batch adversarial loss: 0.676734\n",
      "epoch 43; iter: 400; batch classifier loss: 0.337828; batch adversarial loss: 0.641493\n",
      "epoch 44; iter: 0; batch classifier loss: 0.437731; batch adversarial loss: 0.631438\n",
      "epoch 44; iter: 200; batch classifier loss: 0.487285; batch adversarial loss: 0.602013\n",
      "epoch 44; iter: 400; batch classifier loss: 0.647029; batch adversarial loss: 0.649165\n",
      "epoch 45; iter: 0; batch classifier loss: 0.599414; batch adversarial loss: 0.655262\n",
      "epoch 45; iter: 200; batch classifier loss: 0.382629; batch adversarial loss: 0.657394\n",
      "epoch 45; iter: 400; batch classifier loss: 0.336542; batch adversarial loss: 0.708508\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372259; batch adversarial loss: 0.659515\n",
      "epoch 46; iter: 200; batch classifier loss: 0.547798; batch adversarial loss: 0.622876\n",
      "epoch 46; iter: 400; batch classifier loss: 0.731762; batch adversarial loss: 0.629139\n",
      "epoch 47; iter: 0; batch classifier loss: 0.483607; batch adversarial loss: 0.588738\n",
      "epoch 47; iter: 200; batch classifier loss: 0.336381; batch adversarial loss: 0.614511\n",
      "epoch 47; iter: 400; batch classifier loss: 0.372785; batch adversarial loss: 0.580072\n",
      "epoch 48; iter: 0; batch classifier loss: 0.283796; batch adversarial loss: 0.690005\n",
      "epoch 48; iter: 200; batch classifier loss: 0.353354; batch adversarial loss: 0.684809\n",
      "epoch 48; iter: 400; batch classifier loss: 0.725609; batch adversarial loss: 0.600471\n",
      "epoch 49; iter: 0; batch classifier loss: 0.356234; batch adversarial loss: 0.633424\n",
      "epoch 49; iter: 200; batch classifier loss: 0.511573; batch adversarial loss: 0.648876\n",
      "epoch 49; iter: 400; batch classifier loss: 0.282533; batch adversarial loss: 0.603737\n",
      "epoch 0; iter: 0; batch classifier loss: 32.879734; batch adversarial loss: 0.696144\n",
      "epoch 0; iter: 200; batch classifier loss: 8.914762; batch adversarial loss: 0.641031\n",
      "epoch 0; iter: 400; batch classifier loss: 7.930123; batch adversarial loss: 0.627281\n",
      "epoch 1; iter: 0; batch classifier loss: 0.607623; batch adversarial loss: 0.633201\n",
      "epoch 1; iter: 200; batch classifier loss: 5.402209; batch adversarial loss: 0.672337\n",
      "epoch 1; iter: 400; batch classifier loss: 1.891382; batch adversarial loss: 0.531598\n",
      "epoch 2; iter: 0; batch classifier loss: 1.698262; batch adversarial loss: 0.641481\n",
      "epoch 2; iter: 200; batch classifier loss: 0.409855; batch adversarial loss: 0.629083\n",
      "epoch 2; iter: 400; batch classifier loss: 1.096765; batch adversarial loss: 0.634209\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677372; batch adversarial loss: 0.718999\n",
      "epoch 3; iter: 200; batch classifier loss: 4.419518; batch adversarial loss: 0.596148\n",
      "epoch 3; iter: 400; batch classifier loss: 2.704151; batch adversarial loss: 0.633704\n",
      "epoch 4; iter: 0; batch classifier loss: 3.709872; batch adversarial loss: 0.615788\n",
      "epoch 4; iter: 200; batch classifier loss: 2.272921; batch adversarial loss: 0.594836\n",
      "epoch 4; iter: 400; batch classifier loss: 1.515152; batch adversarial loss: 0.615234\n",
      "epoch 5; iter: 0; batch classifier loss: 0.365337; batch adversarial loss: 0.597515\n",
      "epoch 5; iter: 200; batch classifier loss: 0.853530; batch adversarial loss: 0.610719\n",
      "epoch 5; iter: 400; batch classifier loss: 1.040483; batch adversarial loss: 0.723875\n",
      "epoch 6; iter: 0; batch classifier loss: 0.926853; batch adversarial loss: 0.602413\n",
      "epoch 6; iter: 200; batch classifier loss: 0.867598; batch adversarial loss: 0.664545\n",
      "epoch 6; iter: 400; batch classifier loss: 1.151325; batch adversarial loss: 0.621119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.563950; batch adversarial loss: 0.567399\n",
      "epoch 7; iter: 200; batch classifier loss: 0.436380; batch adversarial loss: 0.669787\n",
      "epoch 7; iter: 400; batch classifier loss: 0.319862; batch adversarial loss: 0.550535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.316509; batch adversarial loss: 0.590682\n",
      "epoch 8; iter: 200; batch classifier loss: 0.876353; batch adversarial loss: 0.595813\n",
      "epoch 8; iter: 400; batch classifier loss: 0.356552; batch adversarial loss: 0.578439\n",
      "epoch 9; iter: 0; batch classifier loss: 0.341840; batch adversarial loss: 0.637911\n",
      "epoch 9; iter: 200; batch classifier loss: 0.308630; batch adversarial loss: 0.581111\n",
      "epoch 9; iter: 400; batch classifier loss: 0.379092; batch adversarial loss: 0.648000\n",
      "epoch 10; iter: 0; batch classifier loss: 0.380480; batch adversarial loss: 0.560634\n",
      "epoch 10; iter: 200; batch classifier loss: 0.499120; batch adversarial loss: 0.564268\n",
      "epoch 10; iter: 400; batch classifier loss: 0.294238; batch adversarial loss: 0.588285\n",
      "epoch 11; iter: 0; batch classifier loss: 0.323412; batch adversarial loss: 0.587044\n",
      "epoch 11; iter: 200; batch classifier loss: 0.388663; batch adversarial loss: 0.536557\n",
      "epoch 11; iter: 400; batch classifier loss: 0.207202; batch adversarial loss: 0.626272\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329915; batch adversarial loss: 0.600039\n",
      "epoch 12; iter: 200; batch classifier loss: 0.223357; batch adversarial loss: 0.714286\n",
      "epoch 12; iter: 400; batch classifier loss: 0.316396; batch adversarial loss: 0.680735\n",
      "epoch 13; iter: 0; batch classifier loss: 0.421219; batch adversarial loss: 0.607149\n",
      "epoch 13; iter: 200; batch classifier loss: 0.388442; batch adversarial loss: 0.621597\n",
      "epoch 13; iter: 400; batch classifier loss: 0.381757; batch adversarial loss: 0.602681\n",
      "epoch 14; iter: 0; batch classifier loss: 0.333069; batch adversarial loss: 0.622941\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416179; batch adversarial loss: 0.597855\n",
      "epoch 14; iter: 400; batch classifier loss: 0.239707; batch adversarial loss: 0.690181\n",
      "epoch 15; iter: 0; batch classifier loss: 0.285806; batch adversarial loss: 0.587994\n",
      "epoch 15; iter: 200; batch classifier loss: 0.232479; batch adversarial loss: 0.716827\n",
      "epoch 15; iter: 400; batch classifier loss: 0.314283; batch adversarial loss: 0.599287\n",
      "epoch 16; iter: 0; batch classifier loss: 0.269286; batch adversarial loss: 0.577387\n",
      "epoch 16; iter: 200; batch classifier loss: 0.340475; batch adversarial loss: 0.627506\n",
      "epoch 16; iter: 400; batch classifier loss: 0.332191; batch adversarial loss: 0.640059\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471208; batch adversarial loss: 0.565019\n",
      "epoch 17; iter: 200; batch classifier loss: 0.265527; batch adversarial loss: 0.573748\n",
      "epoch 17; iter: 400; batch classifier loss: 0.373730; batch adversarial loss: 0.632365\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350780; batch adversarial loss: 0.679580\n",
      "epoch 18; iter: 200; batch classifier loss: 0.396096; batch adversarial loss: 0.528804\n",
      "epoch 18; iter: 400; batch classifier loss: 0.568522; batch adversarial loss: 0.667643\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484583; batch adversarial loss: 0.665894\n",
      "epoch 19; iter: 200; batch classifier loss: 0.454352; batch adversarial loss: 0.666382\n",
      "epoch 19; iter: 400; batch classifier loss: 0.259084; batch adversarial loss: 0.628287\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446095; batch adversarial loss: 0.623035\n",
      "epoch 20; iter: 200; batch classifier loss: 0.280311; batch adversarial loss: 0.624717\n",
      "epoch 20; iter: 400; batch classifier loss: 0.390133; batch adversarial loss: 0.655339\n",
      "epoch 21; iter: 0; batch classifier loss: 0.326064; batch adversarial loss: 0.696615\n",
      "epoch 21; iter: 200; batch classifier loss: 0.274371; batch adversarial loss: 0.619157\n",
      "epoch 21; iter: 400; batch classifier loss: 0.379761; batch adversarial loss: 0.645988\n",
      "epoch 22; iter: 0; batch classifier loss: 0.406415; batch adversarial loss: 0.614155\n",
      "epoch 22; iter: 200; batch classifier loss: 0.371499; batch adversarial loss: 0.627198\n",
      "epoch 22; iter: 400; batch classifier loss: 0.371092; batch adversarial loss: 0.586130\n",
      "epoch 23; iter: 0; batch classifier loss: 0.395699; batch adversarial loss: 0.671744\n",
      "epoch 23; iter: 200; batch classifier loss: 0.385398; batch adversarial loss: 0.649921\n",
      "epoch 23; iter: 400; batch classifier loss: 0.407603; batch adversarial loss: 0.571268\n",
      "epoch 24; iter: 0; batch classifier loss: 0.572925; batch adversarial loss: 0.599821\n",
      "epoch 24; iter: 200; batch classifier loss: 0.364146; batch adversarial loss: 0.519284\n",
      "epoch 24; iter: 400; batch classifier loss: 0.356731; batch adversarial loss: 0.627262\n",
      "epoch 25; iter: 0; batch classifier loss: 0.248802; batch adversarial loss: 0.615021\n",
      "epoch 25; iter: 200; batch classifier loss: 0.377477; batch adversarial loss: 0.590512\n",
      "epoch 25; iter: 400; batch classifier loss: 0.429983; batch adversarial loss: 0.664898\n",
      "epoch 26; iter: 0; batch classifier loss: 0.347561; batch adversarial loss: 0.687901\n",
      "epoch 26; iter: 200; batch classifier loss: 0.424210; batch adversarial loss: 0.710345\n",
      "epoch 26; iter: 400; batch classifier loss: 0.473240; batch adversarial loss: 0.629417\n",
      "epoch 27; iter: 0; batch classifier loss: 0.382738; batch adversarial loss: 0.652111\n",
      "epoch 27; iter: 200; batch classifier loss: 0.253046; batch adversarial loss: 0.598982\n",
      "epoch 27; iter: 400; batch classifier loss: 0.347448; batch adversarial loss: 0.611563\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557698; batch adversarial loss: 0.608154\n",
      "epoch 28; iter: 200; batch classifier loss: 0.610071; batch adversarial loss: 0.637760\n",
      "epoch 28; iter: 400; batch classifier loss: 0.459979; batch adversarial loss: 0.674646\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397032; batch adversarial loss: 0.657702\n",
      "epoch 29; iter: 200; batch classifier loss: 0.338808; batch adversarial loss: 0.638955\n",
      "epoch 29; iter: 400; batch classifier loss: 0.561235; batch adversarial loss: 0.584141\n",
      "epoch 30; iter: 0; batch classifier loss: 0.472611; batch adversarial loss: 0.645327\n",
      "epoch 30; iter: 200; batch classifier loss: 0.351586; batch adversarial loss: 0.624866\n",
      "epoch 30; iter: 400; batch classifier loss: 0.328708; batch adversarial loss: 0.707266\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416636; batch adversarial loss: 0.666058\n",
      "epoch 31; iter: 200; batch classifier loss: 0.492303; batch adversarial loss: 0.566503\n",
      "epoch 31; iter: 400; batch classifier loss: 0.366871; batch adversarial loss: 0.681692\n",
      "epoch 32; iter: 0; batch classifier loss: 0.433686; batch adversarial loss: 0.622292\n",
      "epoch 32; iter: 200; batch classifier loss: 0.498229; batch adversarial loss: 0.637812\n",
      "epoch 32; iter: 400; batch classifier loss: 0.415131; batch adversarial loss: 0.630893\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405869; batch adversarial loss: 0.619145\n",
      "epoch 33; iter: 200; batch classifier loss: 0.345345; batch adversarial loss: 0.629439\n",
      "epoch 33; iter: 400; batch classifier loss: 0.557171; batch adversarial loss: 0.647262\n",
      "epoch 34; iter: 0; batch classifier loss: 0.590806; batch adversarial loss: 0.673755\n",
      "epoch 34; iter: 200; batch classifier loss: 0.305027; batch adversarial loss: 0.656131\n",
      "epoch 34; iter: 400; batch classifier loss: 0.707148; batch adversarial loss: 0.589620\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467626; batch adversarial loss: 0.633887\n",
      "epoch 35; iter: 200; batch classifier loss: 0.374869; batch adversarial loss: 0.629373\n",
      "epoch 35; iter: 400; batch classifier loss: 0.474574; batch adversarial loss: 0.596789\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427202; batch adversarial loss: 0.649286\n",
      "epoch 36; iter: 200; batch classifier loss: 0.640832; batch adversarial loss: 0.680346\n",
      "epoch 36; iter: 400; batch classifier loss: 0.579271; batch adversarial loss: 0.648100\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434307; batch adversarial loss: 0.589505\n",
      "epoch 37; iter: 200; batch classifier loss: 0.567947; batch adversarial loss: 0.591822\n",
      "epoch 37; iter: 400; batch classifier loss: 0.344768; batch adversarial loss: 0.649293\n",
      "epoch 38; iter: 0; batch classifier loss: 0.342266; batch adversarial loss: 0.722290\n",
      "epoch 38; iter: 200; batch classifier loss: 0.582067; batch adversarial loss: 0.641964\n",
      "epoch 38; iter: 400; batch classifier loss: 0.342053; batch adversarial loss: 0.553311\n",
      "epoch 39; iter: 0; batch classifier loss: 0.372166; batch adversarial loss: 0.681023\n",
      "epoch 39; iter: 200; batch classifier loss: 0.327913; batch adversarial loss: 0.610682\n",
      "epoch 39; iter: 400; batch classifier loss: 0.401190; batch adversarial loss: 0.641986\n",
      "epoch 40; iter: 0; batch classifier loss: 0.535913; batch adversarial loss: 0.701343\n",
      "epoch 40; iter: 200; batch classifier loss: 0.462717; batch adversarial loss: 0.579088\n",
      "epoch 40; iter: 400; batch classifier loss: 0.540265; batch adversarial loss: 0.621976\n",
      "epoch 41; iter: 0; batch classifier loss: 0.705346; batch adversarial loss: 0.655339\n",
      "epoch 41; iter: 200; batch classifier loss: 0.660052; batch adversarial loss: 0.707847\n",
      "epoch 41; iter: 400; batch classifier loss: 0.298180; batch adversarial loss: 0.614175\n",
      "epoch 42; iter: 0; batch classifier loss: 0.566656; batch adversarial loss: 0.596510\n",
      "epoch 42; iter: 200; batch classifier loss: 0.644117; batch adversarial loss: 0.669822\n",
      "epoch 42; iter: 400; batch classifier loss: 0.513065; batch adversarial loss: 0.585641\n",
      "epoch 43; iter: 0; batch classifier loss: 0.644283; batch adversarial loss: 0.576176\n",
      "epoch 43; iter: 200; batch classifier loss: 0.357559; batch adversarial loss: 0.680165\n",
      "epoch 43; iter: 400; batch classifier loss: 0.495207; batch adversarial loss: 0.532216\n",
      "epoch 44; iter: 0; batch classifier loss: 0.290729; batch adversarial loss: 0.584983\n",
      "epoch 44; iter: 200; batch classifier loss: 0.501333; batch adversarial loss: 0.596661\n",
      "epoch 44; iter: 400; batch classifier loss: 0.425533; batch adversarial loss: 0.690985\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422969; batch adversarial loss: 0.653997\n",
      "epoch 45; iter: 200; batch classifier loss: 0.424991; batch adversarial loss: 0.597965\n",
      "epoch 45; iter: 400; batch classifier loss: 0.271113; batch adversarial loss: 0.672805\n",
      "epoch 46; iter: 0; batch classifier loss: 0.406344; batch adversarial loss: 0.621182\n",
      "epoch 46; iter: 200; batch classifier loss: 0.560507; batch adversarial loss: 0.563423\n",
      "epoch 46; iter: 400; batch classifier loss: 0.465606; batch adversarial loss: 0.588319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371447; batch adversarial loss: 0.671799\n",
      "epoch 47; iter: 200; batch classifier loss: 0.451168; batch adversarial loss: 0.694825\n",
      "epoch 47; iter: 400; batch classifier loss: 0.827520; batch adversarial loss: 0.582425\n",
      "epoch 48; iter: 0; batch classifier loss: 0.545227; batch adversarial loss: 0.590024\n",
      "epoch 48; iter: 200; batch classifier loss: 0.586750; batch adversarial loss: 0.656717\n",
      "epoch 48; iter: 400; batch classifier loss: 0.403512; batch adversarial loss: 0.574197\n",
      "epoch 49; iter: 0; batch classifier loss: 0.359305; batch adversarial loss: 0.623539\n",
      "epoch 49; iter: 200; batch classifier loss: 0.224670; batch adversarial loss: 0.668594\n",
      "epoch 49; iter: 400; batch classifier loss: 0.533417; batch adversarial loss: 0.658457\n",
      "epoch 0; iter: 0; batch classifier loss: 22.472321; batch adversarial loss: 0.613897\n",
      "epoch 0; iter: 200; batch classifier loss: 17.488752; batch adversarial loss: 0.585364\n",
      "epoch 0; iter: 400; batch classifier loss: 13.531215; batch adversarial loss: 0.564817\n",
      "epoch 1; iter: 0; batch classifier loss: 6.442610; batch adversarial loss: 0.592306\n",
      "epoch 1; iter: 200; batch classifier loss: 5.101190; batch adversarial loss: 0.640365\n",
      "epoch 1; iter: 400; batch classifier loss: 3.945322; batch adversarial loss: 0.706443\n",
      "epoch 2; iter: 0; batch classifier loss: 4.955046; batch adversarial loss: 0.632550\n",
      "epoch 2; iter: 200; batch classifier loss: 0.531550; batch adversarial loss: 0.582398\n",
      "epoch 2; iter: 400; batch classifier loss: 1.572884; batch adversarial loss: 0.614665\n",
      "epoch 3; iter: 0; batch classifier loss: 5.846894; batch adversarial loss: 0.626513\n",
      "epoch 3; iter: 200; batch classifier loss: 1.103212; batch adversarial loss: 0.651275\n",
      "epoch 3; iter: 400; batch classifier loss: 3.287344; batch adversarial loss: 0.621621\n",
      "epoch 4; iter: 0; batch classifier loss: 2.687394; batch adversarial loss: 0.602953\n",
      "epoch 4; iter: 200; batch classifier loss: 11.347800; batch adversarial loss: 0.566350\n",
      "epoch 4; iter: 400; batch classifier loss: 2.819162; batch adversarial loss: 0.561300\n",
      "epoch 5; iter: 0; batch classifier loss: 0.750757; batch adversarial loss: 0.668022\n",
      "epoch 5; iter: 200; batch classifier loss: 2.104829; batch adversarial loss: 0.654320\n",
      "epoch 5; iter: 400; batch classifier loss: 0.455957; batch adversarial loss: 0.572109\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563364; batch adversarial loss: 0.590218\n",
      "epoch 6; iter: 200; batch classifier loss: 0.529780; batch adversarial loss: 0.566142\n",
      "epoch 6; iter: 400; batch classifier loss: 0.493222; batch adversarial loss: 0.628479\n",
      "epoch 7; iter: 0; batch classifier loss: 0.890983; batch adversarial loss: 0.713750\n",
      "epoch 7; iter: 200; batch classifier loss: 0.889368; batch adversarial loss: 0.596144\n",
      "epoch 7; iter: 400; batch classifier loss: 0.500288; batch adversarial loss: 0.601088\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526588; batch adversarial loss: 0.658701\n",
      "epoch 8; iter: 200; batch classifier loss: 0.498048; batch adversarial loss: 0.664120\n",
      "epoch 8; iter: 400; batch classifier loss: 0.448469; batch adversarial loss: 0.644003\n",
      "epoch 9; iter: 0; batch classifier loss: 0.452524; batch adversarial loss: 0.611948\n",
      "epoch 9; iter: 200; batch classifier loss: 0.390949; batch adversarial loss: 0.575932\n",
      "epoch 9; iter: 400; batch classifier loss: 0.296039; batch adversarial loss: 0.631252\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400018; batch adversarial loss: 0.534396\n",
      "epoch 10; iter: 200; batch classifier loss: 0.482368; batch adversarial loss: 0.700294\n",
      "epoch 10; iter: 400; batch classifier loss: 0.280017; batch adversarial loss: 0.613455\n",
      "epoch 11; iter: 0; batch classifier loss: 0.327449; batch adversarial loss: 0.658724\n",
      "epoch 11; iter: 200; batch classifier loss: 0.410187; batch adversarial loss: 0.707101\n",
      "epoch 11; iter: 400; batch classifier loss: 0.294932; batch adversarial loss: 0.622333\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472124; batch adversarial loss: 0.587200\n",
      "epoch 12; iter: 200; batch classifier loss: 0.429596; batch adversarial loss: 0.624673\n",
      "epoch 12; iter: 400; batch classifier loss: 0.296657; batch adversarial loss: 0.576841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342943; batch adversarial loss: 0.695311\n",
      "epoch 13; iter: 200; batch classifier loss: 0.249793; batch adversarial loss: 0.717748\n",
      "epoch 13; iter: 400; batch classifier loss: 0.312061; batch adversarial loss: 0.627597\n",
      "epoch 14; iter: 0; batch classifier loss: 0.279431; batch adversarial loss: 0.626309\n",
      "epoch 14; iter: 200; batch classifier loss: 0.290999; batch adversarial loss: 0.638538\n",
      "epoch 14; iter: 400; batch classifier loss: 0.400473; batch adversarial loss: 0.652861\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398901; batch adversarial loss: 0.595201\n",
      "epoch 15; iter: 200; batch classifier loss: 0.383334; batch adversarial loss: 0.559519\n",
      "epoch 15; iter: 400; batch classifier loss: 0.320556; batch adversarial loss: 0.669540\n",
      "epoch 16; iter: 0; batch classifier loss: 0.279446; batch adversarial loss: 0.658174\n",
      "epoch 16; iter: 200; batch classifier loss: 0.384024; batch adversarial loss: 0.625759\n",
      "epoch 16; iter: 400; batch classifier loss: 0.378125; batch adversarial loss: 0.619270\n",
      "epoch 17; iter: 0; batch classifier loss: 0.387354; batch adversarial loss: 0.673830\n",
      "epoch 17; iter: 200; batch classifier loss: 0.439140; batch adversarial loss: 0.573742\n",
      "epoch 17; iter: 400; batch classifier loss: 0.443922; batch adversarial loss: 0.622347\n",
      "epoch 18; iter: 0; batch classifier loss: 0.258582; batch adversarial loss: 0.663088\n",
      "epoch 18; iter: 200; batch classifier loss: 0.247479; batch adversarial loss: 0.683663\n",
      "epoch 18; iter: 400; batch classifier loss: 0.401228; batch adversarial loss: 0.596469\n",
      "epoch 19; iter: 0; batch classifier loss: 0.352498; batch adversarial loss: 0.715421\n",
      "epoch 19; iter: 200; batch classifier loss: 0.430533; batch adversarial loss: 0.618481\n",
      "epoch 19; iter: 400; batch classifier loss: 0.554953; batch adversarial loss: 0.611513\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368075; batch adversarial loss: 0.694150\n",
      "epoch 20; iter: 200; batch classifier loss: 0.432678; batch adversarial loss: 0.629088\n",
      "epoch 20; iter: 400; batch classifier loss: 0.388742; batch adversarial loss: 0.587531\n",
      "epoch 21; iter: 0; batch classifier loss: 0.313651; batch adversarial loss: 0.605954\n",
      "epoch 21; iter: 200; batch classifier loss: 0.483717; batch adversarial loss: 0.623451\n",
      "epoch 21; iter: 400; batch classifier loss: 0.446684; batch adversarial loss: 0.657219\n",
      "epoch 22; iter: 0; batch classifier loss: 0.471939; batch adversarial loss: 0.627125\n",
      "epoch 22; iter: 200; batch classifier loss: 0.371091; batch adversarial loss: 0.690850\n",
      "epoch 22; iter: 400; batch classifier loss: 0.269529; batch adversarial loss: 0.580950\n",
      "epoch 23; iter: 0; batch classifier loss: 0.505597; batch adversarial loss: 0.604392\n",
      "epoch 23; iter: 200; batch classifier loss: 0.334852; batch adversarial loss: 0.679011\n",
      "epoch 23; iter: 400; batch classifier loss: 0.356034; batch adversarial loss: 0.601670\n",
      "epoch 24; iter: 0; batch classifier loss: 0.320260; batch adversarial loss: 0.699022\n",
      "epoch 24; iter: 200; batch classifier loss: 0.394958; batch adversarial loss: 0.646155\n",
      "epoch 24; iter: 400; batch classifier loss: 0.429366; batch adversarial loss: 0.577782\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442590; batch adversarial loss: 0.620065\n",
      "epoch 25; iter: 200; batch classifier loss: 0.449966; batch adversarial loss: 0.556278\n",
      "epoch 25; iter: 400; batch classifier loss: 0.240361; batch adversarial loss: 0.646955\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508160; batch adversarial loss: 0.646571\n",
      "epoch 26; iter: 200; batch classifier loss: 0.464150; batch adversarial loss: 0.618247\n",
      "epoch 26; iter: 400; batch classifier loss: 0.325796; batch adversarial loss: 0.685407\n",
      "epoch 27; iter: 0; batch classifier loss: 0.305758; batch adversarial loss: 0.613012\n",
      "epoch 27; iter: 200; batch classifier loss: 0.298608; batch adversarial loss: 0.715834\n",
      "epoch 27; iter: 400; batch classifier loss: 0.287437; batch adversarial loss: 0.669822\n",
      "epoch 28; iter: 0; batch classifier loss: 0.441370; batch adversarial loss: 0.632013\n",
      "epoch 28; iter: 200; batch classifier loss: 0.282743; batch adversarial loss: 0.627764\n",
      "epoch 28; iter: 400; batch classifier loss: 0.406865; batch adversarial loss: 0.561973\n",
      "epoch 29; iter: 0; batch classifier loss: 0.558132; batch adversarial loss: 0.637160\n",
      "epoch 29; iter: 200; batch classifier loss: 0.315464; batch adversarial loss: 0.662341\n",
      "epoch 29; iter: 400; batch classifier loss: 0.440628; batch adversarial loss: 0.569742\n",
      "epoch 30; iter: 0; batch classifier loss: 0.377897; batch adversarial loss: 0.643245\n",
      "epoch 30; iter: 200; batch classifier loss: 0.423451; batch adversarial loss: 0.581956\n",
      "epoch 30; iter: 400; batch classifier loss: 0.444157; batch adversarial loss: 0.631413\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523804; batch adversarial loss: 0.617492\n",
      "epoch 31; iter: 200; batch classifier loss: 0.335454; batch adversarial loss: 0.637379\n",
      "epoch 31; iter: 400; batch classifier loss: 0.513453; batch adversarial loss: 0.647867\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361374; batch adversarial loss: 0.541500\n",
      "epoch 32; iter: 200; batch classifier loss: 0.262151; batch adversarial loss: 0.665220\n",
      "epoch 32; iter: 400; batch classifier loss: 0.594813; batch adversarial loss: 0.610776\n",
      "epoch 33; iter: 0; batch classifier loss: 0.324179; batch adversarial loss: 0.679007\n",
      "epoch 33; iter: 200; batch classifier loss: 0.397282; batch adversarial loss: 0.621278\n",
      "epoch 33; iter: 400; batch classifier loss: 0.363298; batch adversarial loss: 0.610035\n",
      "epoch 34; iter: 0; batch classifier loss: 0.473509; batch adversarial loss: 0.574216\n",
      "epoch 34; iter: 200; batch classifier loss: 0.462783; batch adversarial loss: 0.590939\n",
      "epoch 34; iter: 400; batch classifier loss: 0.428226; batch adversarial loss: 0.604115\n",
      "epoch 35; iter: 0; batch classifier loss: 0.198981; batch adversarial loss: 0.637169\n",
      "epoch 35; iter: 200; batch classifier loss: 0.372221; batch adversarial loss: 0.645580\n",
      "epoch 35; iter: 400; batch classifier loss: 0.333656; batch adversarial loss: 0.643154\n",
      "epoch 36; iter: 0; batch classifier loss: 0.249193; batch adversarial loss: 0.597946\n",
      "epoch 36; iter: 200; batch classifier loss: 0.315862; batch adversarial loss: 0.610771\n",
      "epoch 36; iter: 400; batch classifier loss: 0.551811; batch adversarial loss: 0.622673\n",
      "epoch 37; iter: 0; batch classifier loss: 0.660019; batch adversarial loss: 0.669627\n",
      "epoch 37; iter: 200; batch classifier loss: 0.304755; batch adversarial loss: 0.657385\n",
      "epoch 37; iter: 400; batch classifier loss: 0.359833; batch adversarial loss: 0.587878\n",
      "epoch 38; iter: 0; batch classifier loss: 0.366035; batch adversarial loss: 0.657847\n",
      "epoch 38; iter: 200; batch classifier loss: 0.489956; batch adversarial loss: 0.572606\n",
      "epoch 38; iter: 400; batch classifier loss: 0.501396; batch adversarial loss: 0.552135\n",
      "epoch 39; iter: 0; batch classifier loss: 0.279340; batch adversarial loss: 0.719357\n",
      "epoch 39; iter: 200; batch classifier loss: 0.440405; batch adversarial loss: 0.651168\n",
      "epoch 39; iter: 400; batch classifier loss: 0.565513; batch adversarial loss: 0.676138\n",
      "epoch 40; iter: 0; batch classifier loss: 0.381963; batch adversarial loss: 0.602002\n",
      "epoch 40; iter: 200; batch classifier loss: 0.378176; batch adversarial loss: 0.629867\n",
      "epoch 40; iter: 400; batch classifier loss: 0.607707; batch adversarial loss: 0.602078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.701855; batch adversarial loss: 0.580833\n",
      "epoch 41; iter: 200; batch classifier loss: 0.416345; batch adversarial loss: 0.640047\n",
      "epoch 41; iter: 400; batch classifier loss: 0.496787; batch adversarial loss: 0.612933\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502943; batch adversarial loss: 0.616677\n",
      "epoch 42; iter: 200; batch classifier loss: 0.474654; batch adversarial loss: 0.652200\n",
      "epoch 42; iter: 400; batch classifier loss: 0.548702; batch adversarial loss: 0.651820\n",
      "epoch 43; iter: 0; batch classifier loss: 0.331777; batch adversarial loss: 0.655919\n",
      "epoch 43; iter: 200; batch classifier loss: 0.324092; batch adversarial loss: 0.665102\n",
      "epoch 43; iter: 400; batch classifier loss: 0.506447; batch adversarial loss: 0.616248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.573652; batch adversarial loss: 0.678575\n",
      "epoch 44; iter: 200; batch classifier loss: 0.626222; batch adversarial loss: 0.667462\n",
      "epoch 44; iter: 400; batch classifier loss: 0.309981; batch adversarial loss: 0.568995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.545614; batch adversarial loss: 0.630044\n",
      "epoch 45; iter: 200; batch classifier loss: 0.427862; batch adversarial loss: 0.743918\n",
      "epoch 45; iter: 400; batch classifier loss: 0.362719; batch adversarial loss: 0.624860\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372816; batch adversarial loss: 0.631332\n",
      "epoch 46; iter: 200; batch classifier loss: 0.482341; batch adversarial loss: 0.634104\n",
      "epoch 46; iter: 400; batch classifier loss: 0.397569; batch adversarial loss: 0.602653\n",
      "epoch 47; iter: 0; batch classifier loss: 0.277776; batch adversarial loss: 0.676764\n",
      "epoch 47; iter: 200; batch classifier loss: 0.412093; batch adversarial loss: 0.584827\n",
      "epoch 47; iter: 400; batch classifier loss: 0.395692; batch adversarial loss: 0.674411\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412716; batch adversarial loss: 0.685809\n",
      "epoch 48; iter: 200; batch classifier loss: 0.501111; batch adversarial loss: 0.704986\n",
      "epoch 48; iter: 400; batch classifier loss: 0.374773; batch adversarial loss: 0.593298\n",
      "epoch 49; iter: 0; batch classifier loss: 0.334008; batch adversarial loss: 0.592241\n",
      "epoch 49; iter: 200; batch classifier loss: 0.838098; batch adversarial loss: 0.657900\n",
      "epoch 49; iter: 400; batch classifier loss: 0.456440; batch adversarial loss: 0.677404\n",
      "epoch 0; iter: 0; batch classifier loss: 8.076685; batch adversarial loss: 0.707135\n",
      "epoch 0; iter: 200; batch classifier loss: 8.702461; batch adversarial loss: 0.659402\n",
      "epoch 0; iter: 400; batch classifier loss: 1.700898; batch adversarial loss: 0.700317\n",
      "epoch 1; iter: 0; batch classifier loss: 1.849405; batch adversarial loss: 0.659843\n",
      "epoch 1; iter: 200; batch classifier loss: 5.928932; batch adversarial loss: 0.637041\n",
      "epoch 1; iter: 400; batch classifier loss: 8.429458; batch adversarial loss: 0.600964\n",
      "epoch 2; iter: 0; batch classifier loss: 6.936870; batch adversarial loss: 0.725306\n",
      "epoch 2; iter: 200; batch classifier loss: 3.221839; batch adversarial loss: 0.692849\n",
      "epoch 2; iter: 400; batch classifier loss: 3.048448; batch adversarial loss: 0.700418\n",
      "epoch 3; iter: 0; batch classifier loss: 1.899974; batch adversarial loss: 0.670656\n",
      "epoch 3; iter: 200; batch classifier loss: 1.945942; batch adversarial loss: 0.632105\n",
      "epoch 3; iter: 400; batch classifier loss: 0.646037; batch adversarial loss: 0.577088\n",
      "epoch 4; iter: 0; batch classifier loss: 0.611099; batch adversarial loss: 0.626631\n",
      "epoch 4; iter: 200; batch classifier loss: 3.881238; batch adversarial loss: 0.562354\n",
      "epoch 4; iter: 400; batch classifier loss: 0.603648; batch adversarial loss: 0.618448\n",
      "epoch 5; iter: 0; batch classifier loss: 0.498177; batch adversarial loss: 0.572078\n",
      "epoch 5; iter: 200; batch classifier loss: 0.765766; batch adversarial loss: 0.710415\n",
      "epoch 5; iter: 400; batch classifier loss: 0.868455; batch adversarial loss: 0.573300\n",
      "epoch 6; iter: 0; batch classifier loss: 0.310204; batch adversarial loss: 0.646413\n",
      "epoch 6; iter: 200; batch classifier loss: 0.804846; batch adversarial loss: 0.568592\n",
      "epoch 6; iter: 400; batch classifier loss: 0.414945; batch adversarial loss: 0.575014\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385359; batch adversarial loss: 0.600066\n",
      "epoch 7; iter: 200; batch classifier loss: 0.537952; batch adversarial loss: 0.564660\n",
      "epoch 7; iter: 400; batch classifier loss: 0.422353; batch adversarial loss: 0.535447\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453601; batch adversarial loss: 0.510395\n",
      "epoch 8; iter: 200; batch classifier loss: 0.286457; batch adversarial loss: 0.597917\n",
      "epoch 8; iter: 400; batch classifier loss: 0.317801; batch adversarial loss: 0.650528\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402817; batch adversarial loss: 0.586077\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383878; batch adversarial loss: 0.666404\n",
      "epoch 9; iter: 400; batch classifier loss: 0.319657; batch adversarial loss: 0.626642\n",
      "epoch 10; iter: 0; batch classifier loss: 0.348418; batch adversarial loss: 0.551405\n",
      "epoch 10; iter: 200; batch classifier loss: 0.401146; batch adversarial loss: 0.579242\n",
      "epoch 10; iter: 400; batch classifier loss: 0.362938; batch adversarial loss: 0.574675\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414415; batch adversarial loss: 0.617739\n",
      "epoch 11; iter: 200; batch classifier loss: 0.349637; batch adversarial loss: 0.669168\n",
      "epoch 11; iter: 400; batch classifier loss: 0.297203; batch adversarial loss: 0.632926\n",
      "epoch 12; iter: 0; batch classifier loss: 0.395878; batch adversarial loss: 0.642737\n",
      "epoch 12; iter: 200; batch classifier loss: 0.483726; batch adversarial loss: 0.636769\n",
      "epoch 12; iter: 400; batch classifier loss: 0.473384; batch adversarial loss: 0.558476\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504933; batch adversarial loss: 0.545821\n",
      "epoch 13; iter: 200; batch classifier loss: 0.419389; batch adversarial loss: 0.587417\n",
      "epoch 13; iter: 400; batch classifier loss: 0.338873; batch adversarial loss: 0.661257\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334675; batch adversarial loss: 0.705566\n",
      "epoch 14; iter: 200; batch classifier loss: 0.304212; batch adversarial loss: 0.613288\n",
      "epoch 14; iter: 400; batch classifier loss: 0.385377; batch adversarial loss: 0.581508\n",
      "epoch 15; iter: 0; batch classifier loss: 0.353930; batch adversarial loss: 0.612502\n",
      "epoch 15; iter: 200; batch classifier loss: 0.201670; batch adversarial loss: 0.627212\n",
      "epoch 15; iter: 400; batch classifier loss: 0.473514; batch adversarial loss: 0.607312\n",
      "epoch 16; iter: 0; batch classifier loss: 0.293010; batch adversarial loss: 0.705184\n",
      "epoch 16; iter: 200; batch classifier loss: 0.430791; batch adversarial loss: 0.562903\n",
      "epoch 16; iter: 400; batch classifier loss: 0.238571; batch adversarial loss: 0.505035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.506624; batch adversarial loss: 0.594177\n",
      "epoch 17; iter: 200; batch classifier loss: 0.326415; batch adversarial loss: 0.604924\n",
      "epoch 17; iter: 400; batch classifier loss: 0.378435; batch adversarial loss: 0.620222\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320804; batch adversarial loss: 0.588002\n",
      "epoch 18; iter: 200; batch classifier loss: 0.362956; batch adversarial loss: 0.664020\n",
      "epoch 18; iter: 400; batch classifier loss: 0.340604; batch adversarial loss: 0.676063\n",
      "epoch 19; iter: 0; batch classifier loss: 0.391111; batch adversarial loss: 0.672559\n",
      "epoch 19; iter: 200; batch classifier loss: 0.411460; batch adversarial loss: 0.650729\n",
      "epoch 19; iter: 400; batch classifier loss: 0.379637; batch adversarial loss: 0.628423\n",
      "epoch 20; iter: 0; batch classifier loss: 0.394653; batch adversarial loss: 0.652876\n",
      "epoch 20; iter: 200; batch classifier loss: 0.282569; batch adversarial loss: 0.630516\n",
      "epoch 20; iter: 400; batch classifier loss: 0.349396; batch adversarial loss: 0.627567\n",
      "epoch 21; iter: 0; batch classifier loss: 0.305783; batch adversarial loss: 0.576253\n",
      "epoch 21; iter: 200; batch classifier loss: 0.231442; batch adversarial loss: 0.762427\n",
      "epoch 21; iter: 400; batch classifier loss: 0.360073; batch adversarial loss: 0.574095\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477143; batch adversarial loss: 0.606555\n",
      "epoch 22; iter: 200; batch classifier loss: 0.481413; batch adversarial loss: 0.648665\n",
      "epoch 22; iter: 400; batch classifier loss: 0.620091; batch adversarial loss: 0.622540\n",
      "epoch 23; iter: 0; batch classifier loss: 0.304317; batch adversarial loss: 0.668567\n",
      "epoch 23; iter: 200; batch classifier loss: 0.519752; batch adversarial loss: 0.594262\n",
      "epoch 23; iter: 400; batch classifier loss: 0.337214; batch adversarial loss: 0.608948\n",
      "epoch 24; iter: 0; batch classifier loss: 0.492442; batch adversarial loss: 0.633149\n",
      "epoch 24; iter: 200; batch classifier loss: 0.362277; batch adversarial loss: 0.671843\n",
      "epoch 24; iter: 400; batch classifier loss: 0.302406; batch adversarial loss: 0.627481\n",
      "epoch 25; iter: 0; batch classifier loss: 0.607688; batch adversarial loss: 0.562107\n",
      "epoch 25; iter: 200; batch classifier loss: 0.949778; batch adversarial loss: 0.629944\n",
      "epoch 25; iter: 400; batch classifier loss: 0.770138; batch adversarial loss: 0.651765\n",
      "epoch 26; iter: 0; batch classifier loss: 0.884832; batch adversarial loss: 0.601891\n",
      "epoch 26; iter: 200; batch classifier loss: 0.721271; batch adversarial loss: 0.631109\n",
      "epoch 26; iter: 400; batch classifier loss: 0.783428; batch adversarial loss: 0.646490\n",
      "epoch 27; iter: 0; batch classifier loss: 0.693929; batch adversarial loss: 0.608528\n",
      "epoch 27; iter: 200; batch classifier loss: 0.652248; batch adversarial loss: 0.545715\n",
      "epoch 27; iter: 400; batch classifier loss: 0.957485; batch adversarial loss: 0.566582\n",
      "epoch 28; iter: 0; batch classifier loss: 0.646145; batch adversarial loss: 0.589932\n",
      "epoch 28; iter: 200; batch classifier loss: 0.591244; batch adversarial loss: 0.572208\n",
      "epoch 28; iter: 400; batch classifier loss: 0.877627; batch adversarial loss: 0.699854\n",
      "epoch 29; iter: 0; batch classifier loss: 0.819495; batch adversarial loss: 0.638139\n",
      "epoch 29; iter: 200; batch classifier loss: 0.738343; batch adversarial loss: 0.549252\n",
      "epoch 29; iter: 400; batch classifier loss: 0.862910; batch adversarial loss: 0.693680\n",
      "epoch 30; iter: 0; batch classifier loss: 0.841999; batch adversarial loss: 0.581158\n",
      "epoch 30; iter: 200; batch classifier loss: 1.059141; batch adversarial loss: 0.583318\n",
      "epoch 30; iter: 400; batch classifier loss: 0.747144; batch adversarial loss: 0.554266\n",
      "epoch 31; iter: 0; batch classifier loss: 0.358987; batch adversarial loss: 0.649700\n",
      "epoch 31; iter: 200; batch classifier loss: 0.667677; batch adversarial loss: 0.570885\n",
      "epoch 31; iter: 400; batch classifier loss: 0.911214; batch adversarial loss: 0.652721\n",
      "epoch 32; iter: 0; batch classifier loss: 0.926873; batch adversarial loss: 0.568758\n",
      "epoch 32; iter: 200; batch classifier loss: 0.888116; batch adversarial loss: 0.626324\n",
      "epoch 32; iter: 400; batch classifier loss: 0.742177; batch adversarial loss: 0.621207\n",
      "epoch 33; iter: 0; batch classifier loss: 1.286035; batch adversarial loss: 0.592140\n",
      "epoch 33; iter: 200; batch classifier loss: 0.678001; batch adversarial loss: 0.620054\n",
      "epoch 33; iter: 400; batch classifier loss: 0.290631; batch adversarial loss: 0.624630\n",
      "epoch 34; iter: 0; batch classifier loss: 0.666904; batch adversarial loss: 0.671300\n",
      "epoch 34; iter: 200; batch classifier loss: 0.547238; batch adversarial loss: 0.631970\n",
      "epoch 34; iter: 400; batch classifier loss: 1.090440; batch adversarial loss: 0.604835\n",
      "epoch 35; iter: 0; batch classifier loss: 0.800613; batch adversarial loss: 0.701285\n",
      "epoch 35; iter: 200; batch classifier loss: 1.023515; batch adversarial loss: 0.564026\n",
      "epoch 35; iter: 400; batch classifier loss: 0.981545; batch adversarial loss: 0.623558\n",
      "epoch 36; iter: 0; batch classifier loss: 0.853128; batch adversarial loss: 0.644666\n",
      "epoch 36; iter: 200; batch classifier loss: 0.966432; batch adversarial loss: 0.569385\n",
      "epoch 36; iter: 400; batch classifier loss: 0.528757; batch adversarial loss: 0.580124\n",
      "epoch 37; iter: 0; batch classifier loss: 0.708166; batch adversarial loss: 0.540987\n",
      "epoch 37; iter: 200; batch classifier loss: 0.494618; batch adversarial loss: 0.615702\n",
      "epoch 37; iter: 400; batch classifier loss: 0.916981; batch adversarial loss: 0.623086\n",
      "epoch 38; iter: 0; batch classifier loss: 0.379392; batch adversarial loss: 0.689912\n",
      "epoch 38; iter: 200; batch classifier loss: 0.762993; batch adversarial loss: 0.642503\n",
      "epoch 38; iter: 400; batch classifier loss: 0.834397; batch adversarial loss: 0.603349\n",
      "epoch 39; iter: 0; batch classifier loss: 0.722038; batch adversarial loss: 0.641910\n",
      "epoch 39; iter: 200; batch classifier loss: 1.035617; batch adversarial loss: 0.656820\n",
      "epoch 39; iter: 400; batch classifier loss: 1.138927; batch adversarial loss: 0.603356\n",
      "epoch 40; iter: 0; batch classifier loss: 0.685431; batch adversarial loss: 0.570138\n",
      "epoch 40; iter: 200; batch classifier loss: 0.613706; batch adversarial loss: 0.628713\n",
      "epoch 40; iter: 400; batch classifier loss: 1.189163; batch adversarial loss: 0.563820\n",
      "epoch 41; iter: 0; batch classifier loss: 0.810981; batch adversarial loss: 0.694188\n",
      "epoch 41; iter: 200; batch classifier loss: 0.383536; batch adversarial loss: 0.646169\n",
      "epoch 41; iter: 400; batch classifier loss: 1.239724; batch adversarial loss: 0.667361\n",
      "epoch 42; iter: 0; batch classifier loss: 1.031612; batch adversarial loss: 0.637081\n",
      "epoch 42; iter: 200; batch classifier loss: 1.179112; batch adversarial loss: 0.569805\n",
      "epoch 42; iter: 400; batch classifier loss: 1.324863; batch adversarial loss: 0.628004\n",
      "epoch 43; iter: 0; batch classifier loss: 0.876061; batch adversarial loss: 0.622947\n",
      "epoch 43; iter: 200; batch classifier loss: 0.938423; batch adversarial loss: 0.630623\n",
      "epoch 43; iter: 400; batch classifier loss: 0.432083; batch adversarial loss: 0.652067\n",
      "epoch 44; iter: 0; batch classifier loss: 0.574373; batch adversarial loss: 0.693920\n",
      "epoch 44; iter: 200; batch classifier loss: 1.092567; batch adversarial loss: 0.619314\n",
      "epoch 44; iter: 400; batch classifier loss: 0.668971; batch adversarial loss: 0.626260\n",
      "epoch 45; iter: 0; batch classifier loss: 0.944120; batch adversarial loss: 0.641098\n",
      "epoch 45; iter: 200; batch classifier loss: 0.744480; batch adversarial loss: 0.650219\n",
      "epoch 45; iter: 400; batch classifier loss: 0.645736; batch adversarial loss: 0.617965\n",
      "epoch 46; iter: 0; batch classifier loss: 0.982858; batch adversarial loss: 0.661308\n",
      "epoch 46; iter: 200; batch classifier loss: 0.995816; batch adversarial loss: 0.658063\n",
      "epoch 46; iter: 400; batch classifier loss: 0.519437; batch adversarial loss: 0.633134\n",
      "epoch 47; iter: 0; batch classifier loss: 1.018249; batch adversarial loss: 0.615280\n",
      "epoch 47; iter: 200; batch classifier loss: 1.099247; batch adversarial loss: 0.642137\n",
      "epoch 47; iter: 400; batch classifier loss: 0.676948; batch adversarial loss: 0.618136\n",
      "epoch 48; iter: 0; batch classifier loss: 0.591241; batch adversarial loss: 0.574518\n",
      "epoch 48; iter: 200; batch classifier loss: 1.077605; batch adversarial loss: 0.555939\n",
      "epoch 48; iter: 400; batch classifier loss: 0.662573; batch adversarial loss: 0.574808\n",
      "epoch 49; iter: 0; batch classifier loss: 1.240048; batch adversarial loss: 0.630143\n",
      "epoch 49; iter: 200; batch classifier loss: 0.475075; batch adversarial loss: 0.686455\n",
      "epoch 49; iter: 400; batch classifier loss: 1.449493; batch adversarial loss: 0.599622\n",
      "epoch 0; iter: 0; batch classifier loss: 7.618122; batch adversarial loss: 0.635138\n",
      "epoch 0; iter: 200; batch classifier loss: 0.362623; batch adversarial loss: 0.649668\n",
      "epoch 0; iter: 400; batch classifier loss: 4.783180; batch adversarial loss: 0.646617\n",
      "epoch 1; iter: 0; batch classifier loss: 19.762722; batch adversarial loss: 0.586086\n",
      "epoch 1; iter: 200; batch classifier loss: 6.776125; batch adversarial loss: 0.620829\n",
      "epoch 1; iter: 400; batch classifier loss: 3.348989; batch adversarial loss: 0.598718\n",
      "epoch 2; iter: 0; batch classifier loss: 8.523593; batch adversarial loss: 0.675965\n",
      "epoch 2; iter: 200; batch classifier loss: 5.515022; batch adversarial loss: 0.607110\n",
      "epoch 2; iter: 400; batch classifier loss: 0.788805; batch adversarial loss: 0.606010\n",
      "epoch 3; iter: 0; batch classifier loss: 3.187455; batch adversarial loss: 0.649579\n",
      "epoch 3; iter: 200; batch classifier loss: 1.914299; batch adversarial loss: 0.637824\n",
      "epoch 3; iter: 400; batch classifier loss: 1.364842; batch adversarial loss: 0.571368\n",
      "epoch 4; iter: 0; batch classifier loss: 0.585598; batch adversarial loss: 0.630618\n",
      "epoch 4; iter: 200; batch classifier loss: 1.006087; batch adversarial loss: 0.602120\n",
      "epoch 4; iter: 400; batch classifier loss: 2.871476; batch adversarial loss: 0.638663\n",
      "epoch 5; iter: 0; batch classifier loss: 1.334184; batch adversarial loss: 0.588488\n",
      "epoch 5; iter: 200; batch classifier loss: 0.806884; batch adversarial loss: 0.588607\n",
      "epoch 5; iter: 400; batch classifier loss: 1.210187; batch adversarial loss: 0.623125\n",
      "epoch 6; iter: 0; batch classifier loss: 0.791031; batch adversarial loss: 0.659174\n",
      "epoch 6; iter: 200; batch classifier loss: 0.857032; batch adversarial loss: 0.612778\n",
      "epoch 6; iter: 400; batch classifier loss: 0.371240; batch adversarial loss: 0.650558\n",
      "epoch 7; iter: 0; batch classifier loss: 0.718039; batch adversarial loss: 0.637028\n",
      "epoch 7; iter: 200; batch classifier loss: 0.527119; batch adversarial loss: 0.689643\n",
      "epoch 7; iter: 400; batch classifier loss: 0.441665; batch adversarial loss: 0.611863\n",
      "epoch 8; iter: 0; batch classifier loss: 0.631385; batch adversarial loss: 0.581538\n",
      "epoch 8; iter: 200; batch classifier loss: 0.607262; batch adversarial loss: 0.604761\n",
      "epoch 8; iter: 400; batch classifier loss: 0.338397; batch adversarial loss: 0.635391\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434115; batch adversarial loss: 0.633982\n",
      "epoch 9; iter: 200; batch classifier loss: 0.433577; batch adversarial loss: 0.656595\n",
      "epoch 9; iter: 400; batch classifier loss: 0.344991; batch adversarial loss: 0.665416\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372359; batch adversarial loss: 0.606750\n",
      "epoch 10; iter: 200; batch classifier loss: 0.338654; batch adversarial loss: 0.631457\n",
      "epoch 10; iter: 400; batch classifier loss: 0.503179; batch adversarial loss: 0.619355\n",
      "epoch 11; iter: 0; batch classifier loss: 0.345704; batch adversarial loss: 0.616336\n",
      "epoch 11; iter: 200; batch classifier loss: 0.336901; batch adversarial loss: 0.669788\n",
      "epoch 11; iter: 400; batch classifier loss: 0.520519; batch adversarial loss: 0.702902\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396960; batch adversarial loss: 0.640873\n",
      "epoch 12; iter: 200; batch classifier loss: 0.429513; batch adversarial loss: 0.554382\n",
      "epoch 12; iter: 400; batch classifier loss: 0.438853; batch adversarial loss: 0.748504\n",
      "epoch 13; iter: 0; batch classifier loss: 0.342561; batch adversarial loss: 0.603029\n",
      "epoch 13; iter: 200; batch classifier loss: 0.287763; batch adversarial loss: 0.664793\n",
      "epoch 13; iter: 400; batch classifier loss: 0.373735; batch adversarial loss: 0.565196\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396467; batch adversarial loss: 0.608670\n",
      "epoch 14; iter: 200; batch classifier loss: 0.293688; batch adversarial loss: 0.738944\n",
      "epoch 14; iter: 400; batch classifier loss: 0.309736; batch adversarial loss: 0.729404\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463794; batch adversarial loss: 0.603766\n",
      "epoch 15; iter: 200; batch classifier loss: 0.290217; batch adversarial loss: 0.548566\n",
      "epoch 15; iter: 400; batch classifier loss: 0.227370; batch adversarial loss: 0.604402\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354433; batch adversarial loss: 0.603426\n",
      "epoch 16; iter: 200; batch classifier loss: 0.515041; batch adversarial loss: 0.574898\n",
      "epoch 16; iter: 400; batch classifier loss: 0.367097; batch adversarial loss: 0.619678\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527168; batch adversarial loss: 0.655713\n",
      "epoch 17; iter: 200; batch classifier loss: 0.411904; batch adversarial loss: 0.593518\n",
      "epoch 17; iter: 400; batch classifier loss: 0.462266; batch adversarial loss: 0.565994\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414417; batch adversarial loss: 0.722537\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336764; batch adversarial loss: 0.600453\n",
      "epoch 18; iter: 400; batch classifier loss: 0.312671; batch adversarial loss: 0.621949\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331655; batch adversarial loss: 0.612876\n",
      "epoch 19; iter: 200; batch classifier loss: 0.453938; batch adversarial loss: 0.690375\n",
      "epoch 19; iter: 400; batch classifier loss: 0.348158; batch adversarial loss: 0.650136\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378269; batch adversarial loss: 0.585612\n",
      "epoch 20; iter: 200; batch classifier loss: 0.344987; batch adversarial loss: 0.691281\n",
      "epoch 20; iter: 400; batch classifier loss: 0.346921; batch adversarial loss: 0.608110\n",
      "epoch 21; iter: 0; batch classifier loss: 0.368863; batch adversarial loss: 0.560405\n",
      "epoch 21; iter: 200; batch classifier loss: 0.222499; batch adversarial loss: 0.750893\n",
      "epoch 21; iter: 400; batch classifier loss: 0.364760; batch adversarial loss: 0.603255\n",
      "epoch 22; iter: 0; batch classifier loss: 0.323221; batch adversarial loss: 0.553941\n",
      "epoch 22; iter: 200; batch classifier loss: 0.401907; batch adversarial loss: 0.587754\n",
      "epoch 22; iter: 400; batch classifier loss: 0.353189; batch adversarial loss: 0.658808\n",
      "epoch 23; iter: 0; batch classifier loss: 0.690922; batch adversarial loss: 0.554483\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371300; batch adversarial loss: 0.671957\n",
      "epoch 23; iter: 400; batch classifier loss: 0.320588; batch adversarial loss: 0.594371\n",
      "epoch 24; iter: 0; batch classifier loss: 0.228812; batch adversarial loss: 0.577262\n",
      "epoch 24; iter: 200; batch classifier loss: 0.267064; batch adversarial loss: 0.652438\n",
      "epoch 24; iter: 400; batch classifier loss: 0.325261; batch adversarial loss: 0.591881\n",
      "epoch 25; iter: 0; batch classifier loss: 0.397670; batch adversarial loss: 0.638517\n",
      "epoch 25; iter: 200; batch classifier loss: 0.368461; batch adversarial loss: 0.562397\n",
      "epoch 25; iter: 400; batch classifier loss: 0.359138; batch adversarial loss: 0.615449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.382705; batch adversarial loss: 0.593140\n",
      "epoch 26; iter: 200; batch classifier loss: 0.455678; batch adversarial loss: 0.645054\n",
      "epoch 26; iter: 400; batch classifier loss: 0.437064; batch adversarial loss: 0.618542\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451476; batch adversarial loss: 0.624366\n",
      "epoch 27; iter: 200; batch classifier loss: 0.525193; batch adversarial loss: 0.621353\n",
      "epoch 27; iter: 400; batch classifier loss: 0.430775; batch adversarial loss: 0.594830\n",
      "epoch 28; iter: 0; batch classifier loss: 1.252280; batch adversarial loss: 0.617378\n",
      "epoch 28; iter: 200; batch classifier loss: 0.324879; batch adversarial loss: 0.656540\n",
      "epoch 28; iter: 400; batch classifier loss: 0.293876; batch adversarial loss: 0.694742\n",
      "epoch 29; iter: 0; batch classifier loss: 0.440824; batch adversarial loss: 0.604998\n",
      "epoch 29; iter: 200; batch classifier loss: 0.754288; batch adversarial loss: 0.690777\n",
      "epoch 29; iter: 400; batch classifier loss: 0.820969; batch adversarial loss: 0.686518\n",
      "epoch 30; iter: 0; batch classifier loss: 0.588110; batch adversarial loss: 0.561743\n",
      "epoch 30; iter: 200; batch classifier loss: 0.320772; batch adversarial loss: 0.691841\n",
      "epoch 30; iter: 400; batch classifier loss: 0.549820; batch adversarial loss: 0.606085\n",
      "epoch 31; iter: 0; batch classifier loss: 0.571031; batch adversarial loss: 0.628747\n",
      "epoch 31; iter: 200; batch classifier loss: 0.218175; batch adversarial loss: 0.657959\n",
      "epoch 31; iter: 400; batch classifier loss: 0.436928; batch adversarial loss: 0.573716\n",
      "epoch 32; iter: 0; batch classifier loss: 0.319798; batch adversarial loss: 0.672980\n",
      "epoch 32; iter: 200; batch classifier loss: 0.356996; batch adversarial loss: 0.707704\n",
      "epoch 32; iter: 400; batch classifier loss: 0.272459; batch adversarial loss: 0.605657\n",
      "epoch 33; iter: 0; batch classifier loss: 0.441136; batch adversarial loss: 0.620857\n",
      "epoch 33; iter: 200; batch classifier loss: 0.523826; batch adversarial loss: 0.640363\n",
      "epoch 33; iter: 400; batch classifier loss: 0.275710; batch adversarial loss: 0.696652\n",
      "epoch 34; iter: 0; batch classifier loss: 0.403256; batch adversarial loss: 0.608198\n",
      "epoch 34; iter: 200; batch classifier loss: 0.542993; batch adversarial loss: 0.633262\n",
      "epoch 34; iter: 400; batch classifier loss: 0.419241; batch adversarial loss: 0.635800\n",
      "epoch 35; iter: 0; batch classifier loss: 0.651497; batch adversarial loss: 0.528683\n",
      "epoch 35; iter: 200; batch classifier loss: 0.472591; batch adversarial loss: 0.583446\n",
      "epoch 35; iter: 400; batch classifier loss: 0.660331; batch adversarial loss: 0.696424\n",
      "epoch 36; iter: 0; batch classifier loss: 0.289545; batch adversarial loss: 0.582548\n",
      "epoch 36; iter: 200; batch classifier loss: 0.352974; batch adversarial loss: 0.591412\n",
      "epoch 36; iter: 400; batch classifier loss: 0.400676; batch adversarial loss: 0.657570\n",
      "epoch 37; iter: 0; batch classifier loss: 0.521321; batch adversarial loss: 0.599229\n",
      "epoch 37; iter: 200; batch classifier loss: 0.662993; batch adversarial loss: 0.635978\n",
      "epoch 37; iter: 400; batch classifier loss: 0.335422; batch adversarial loss: 0.728581\n",
      "epoch 38; iter: 0; batch classifier loss: 0.476204; batch adversarial loss: 0.598106\n",
      "epoch 38; iter: 200; batch classifier loss: 0.536532; batch adversarial loss: 0.580997\n",
      "epoch 38; iter: 400; batch classifier loss: 0.283235; batch adversarial loss: 0.642244\n",
      "epoch 39; iter: 0; batch classifier loss: 0.365798; batch adversarial loss: 0.700315\n",
      "epoch 39; iter: 200; batch classifier loss: 0.463108; batch adversarial loss: 0.683076\n",
      "epoch 39; iter: 400; batch classifier loss: 0.450026; batch adversarial loss: 0.579398\n",
      "epoch 40; iter: 0; batch classifier loss: 0.506397; batch adversarial loss: 0.643383\n",
      "epoch 40; iter: 200; batch classifier loss: 0.258096; batch adversarial loss: 0.673390\n",
      "epoch 40; iter: 400; batch classifier loss: 0.347262; batch adversarial loss: 0.607057\n",
      "epoch 41; iter: 0; batch classifier loss: 0.530915; batch adversarial loss: 0.582041\n",
      "epoch 41; iter: 200; batch classifier loss: 0.673687; batch adversarial loss: 0.631638\n",
      "epoch 41; iter: 400; batch classifier loss: 0.589614; batch adversarial loss: 0.605078\n",
      "epoch 42; iter: 0; batch classifier loss: 0.420105; batch adversarial loss: 0.660036\n",
      "epoch 42; iter: 200; batch classifier loss: 0.549546; batch adversarial loss: 0.566436\n",
      "epoch 42; iter: 400; batch classifier loss: 0.206070; batch adversarial loss: 0.797365\n",
      "epoch 43; iter: 0; batch classifier loss: 0.531175; batch adversarial loss: 0.613184\n",
      "epoch 43; iter: 200; batch classifier loss: 0.434959; batch adversarial loss: 0.687555\n",
      "epoch 43; iter: 400; batch classifier loss: 0.550957; batch adversarial loss: 0.568822\n",
      "epoch 44; iter: 0; batch classifier loss: 0.362065; batch adversarial loss: 0.583365\n",
      "epoch 44; iter: 200; batch classifier loss: 0.445211; batch adversarial loss: 0.607622\n",
      "epoch 44; iter: 400; batch classifier loss: 0.312031; batch adversarial loss: 0.692506\n",
      "epoch 45; iter: 0; batch classifier loss: 0.343647; batch adversarial loss: 0.637656\n",
      "epoch 45; iter: 200; batch classifier loss: 0.485541; batch adversarial loss: 0.655396\n",
      "epoch 45; iter: 400; batch classifier loss: 0.315532; batch adversarial loss: 0.628744\n",
      "epoch 46; iter: 0; batch classifier loss: 0.251669; batch adversarial loss: 0.685170\n",
      "epoch 46; iter: 200; batch classifier loss: 0.529077; batch adversarial loss: 0.607699\n",
      "epoch 46; iter: 400; batch classifier loss: 0.516501; batch adversarial loss: 0.516279\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493310; batch adversarial loss: 0.574293\n",
      "epoch 47; iter: 200; batch classifier loss: 0.311699; batch adversarial loss: 0.624142\n",
      "epoch 47; iter: 400; batch classifier loss: 0.334456; batch adversarial loss: 0.655256\n",
      "epoch 48; iter: 0; batch classifier loss: 0.460118; batch adversarial loss: 0.623074\n",
      "epoch 48; iter: 200; batch classifier loss: 0.365274; batch adversarial loss: 0.661017\n",
      "epoch 48; iter: 400; batch classifier loss: 0.367430; batch adversarial loss: 0.679084\n",
      "epoch 49; iter: 0; batch classifier loss: 0.331590; batch adversarial loss: 0.582987\n",
      "epoch 49; iter: 200; batch classifier loss: 0.547166; batch adversarial loss: 0.579490\n",
      "epoch 49; iter: 400; batch classifier loss: 0.576440; batch adversarial loss: 0.584407\n",
      "epoch 0; iter: 0; batch classifier loss: 14.111210; batch adversarial loss: 0.840808\n",
      "epoch 0; iter: 200; batch classifier loss: 7.280877; batch adversarial loss: 0.811232\n",
      "epoch 0; iter: 400; batch classifier loss: 8.836715; batch adversarial loss: 0.646974\n",
      "epoch 1; iter: 0; batch classifier loss: 14.438129; batch adversarial loss: 0.676267\n",
      "epoch 1; iter: 200; batch classifier loss: 9.973208; batch adversarial loss: 0.615431\n",
      "epoch 1; iter: 400; batch classifier loss: 7.379997; batch adversarial loss: 0.706791\n",
      "epoch 2; iter: 0; batch classifier loss: 6.185345; batch adversarial loss: 0.657476\n",
      "epoch 2; iter: 200; batch classifier loss: 2.137061; batch adversarial loss: 0.532582\n",
      "epoch 2; iter: 400; batch classifier loss: 1.873440; batch adversarial loss: 0.536554\n",
      "epoch 3; iter: 0; batch classifier loss: 3.397901; batch adversarial loss: 0.669644\n",
      "epoch 3; iter: 200; batch classifier loss: 1.365025; batch adversarial loss: 0.660051\n",
      "epoch 3; iter: 400; batch classifier loss: 5.790030; batch adversarial loss: 0.626656\n",
      "epoch 4; iter: 0; batch classifier loss: 0.497403; batch adversarial loss: 0.692109\n",
      "epoch 4; iter: 200; batch classifier loss: 1.679147; batch adversarial loss: 0.631978\n",
      "epoch 4; iter: 400; batch classifier loss: 1.272205; batch adversarial loss: 0.631572\n",
      "epoch 5; iter: 0; batch classifier loss: 2.102453; batch adversarial loss: 0.652175\n",
      "epoch 5; iter: 200; batch classifier loss: 0.787912; batch adversarial loss: 0.571709\n",
      "epoch 5; iter: 400; batch classifier loss: 0.899232; batch adversarial loss: 0.706826\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508167; batch adversarial loss: 0.639565\n",
      "epoch 6; iter: 200; batch classifier loss: 0.484414; batch adversarial loss: 0.646196\n",
      "epoch 6; iter: 400; batch classifier loss: 0.428882; batch adversarial loss: 0.617567\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595494; batch adversarial loss: 0.623150\n",
      "epoch 7; iter: 200; batch classifier loss: 0.533108; batch adversarial loss: 0.564722\n",
      "epoch 7; iter: 400; batch classifier loss: 0.464942; batch adversarial loss: 0.627375\n",
      "epoch 8; iter: 0; batch classifier loss: 0.458912; batch adversarial loss: 0.603375\n",
      "epoch 8; iter: 200; batch classifier loss: 0.607310; batch adversarial loss: 0.536957\n",
      "epoch 8; iter: 400; batch classifier loss: 0.508544; batch adversarial loss: 0.643602\n",
      "epoch 9; iter: 0; batch classifier loss: 0.431468; batch adversarial loss: 0.539513\n",
      "epoch 9; iter: 200; batch classifier loss: 0.342151; batch adversarial loss: 0.647902\n",
      "epoch 9; iter: 400; batch classifier loss: 0.462042; batch adversarial loss: 0.586912\n",
      "epoch 10; iter: 0; batch classifier loss: 0.368515; batch adversarial loss: 0.673114\n",
      "epoch 10; iter: 200; batch classifier loss: 0.314899; batch adversarial loss: 0.666889\n",
      "epoch 10; iter: 400; batch classifier loss: 0.297341; batch adversarial loss: 0.622270\n",
      "epoch 11; iter: 0; batch classifier loss: 0.320110; batch adversarial loss: 0.642463\n",
      "epoch 11; iter: 200; batch classifier loss: 0.588885; batch adversarial loss: 0.655233\n",
      "epoch 11; iter: 400; batch classifier loss: 0.419851; batch adversarial loss: 0.553978\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391172; batch adversarial loss: 0.604357\n",
      "epoch 12; iter: 200; batch classifier loss: 0.570349; batch adversarial loss: 0.602926\n",
      "epoch 12; iter: 400; batch classifier loss: 0.564983; batch adversarial loss: 0.583146\n",
      "epoch 13; iter: 0; batch classifier loss: 0.799150; batch adversarial loss: 0.671558\n",
      "epoch 13; iter: 200; batch classifier loss: 0.251830; batch adversarial loss: 0.637495\n",
      "epoch 13; iter: 400; batch classifier loss: 0.400026; batch adversarial loss: 0.647730\n",
      "epoch 14; iter: 0; batch classifier loss: 0.239631; batch adversarial loss: 0.699435\n",
      "epoch 14; iter: 200; batch classifier loss: 0.356285; batch adversarial loss: 0.577688\n",
      "epoch 14; iter: 400; batch classifier loss: 0.400989; batch adversarial loss: 0.611489\n",
      "epoch 15; iter: 0; batch classifier loss: 0.288580; batch adversarial loss: 0.658074\n",
      "epoch 15; iter: 200; batch classifier loss: 0.374982; batch adversarial loss: 0.671523\n",
      "epoch 15; iter: 400; batch classifier loss: 0.336613; batch adversarial loss: 0.637563\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403548; batch adversarial loss: 0.589072\n",
      "epoch 16; iter: 200; batch classifier loss: 0.362267; batch adversarial loss: 0.611196\n",
      "epoch 16; iter: 400; batch classifier loss: 0.324284; batch adversarial loss: 0.637436\n",
      "epoch 17; iter: 0; batch classifier loss: 0.402523; batch adversarial loss: 0.736758\n",
      "epoch 17; iter: 200; batch classifier loss: 0.324938; batch adversarial loss: 0.615612\n",
      "epoch 17; iter: 400; batch classifier loss: 0.333360; batch adversarial loss: 0.663888\n",
      "epoch 18; iter: 0; batch classifier loss: 0.406479; batch adversarial loss: 0.538457\n",
      "epoch 18; iter: 200; batch classifier loss: 0.277965; batch adversarial loss: 0.621243\n",
      "epoch 18; iter: 400; batch classifier loss: 0.450398; batch adversarial loss: 0.605447\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444419; batch adversarial loss: 0.637338\n",
      "epoch 19; iter: 200; batch classifier loss: 0.438068; batch adversarial loss: 0.578990\n",
      "epoch 19; iter: 400; batch classifier loss: 0.388936; batch adversarial loss: 0.579138\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361358; batch adversarial loss: 0.583381\n",
      "epoch 20; iter: 200; batch classifier loss: 0.333652; batch adversarial loss: 0.565434\n",
      "epoch 20; iter: 400; batch classifier loss: 0.440834; batch adversarial loss: 0.666810\n",
      "epoch 21; iter: 0; batch classifier loss: 0.296590; batch adversarial loss: 0.701243\n",
      "epoch 21; iter: 200; batch classifier loss: 0.471666; batch adversarial loss: 0.642482\n",
      "epoch 21; iter: 400; batch classifier loss: 0.559447; batch adversarial loss: 0.573785\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441653; batch adversarial loss: 0.683341\n",
      "epoch 22; iter: 200; batch classifier loss: 0.511093; batch adversarial loss: 0.692394\n",
      "epoch 22; iter: 400; batch classifier loss: 0.291947; batch adversarial loss: 0.620407\n",
      "epoch 23; iter: 0; batch classifier loss: 0.359030; batch adversarial loss: 0.561925\n",
      "epoch 23; iter: 200; batch classifier loss: 0.433442; batch adversarial loss: 0.581581\n",
      "epoch 23; iter: 400; batch classifier loss: 0.225458; batch adversarial loss: 0.577982\n",
      "epoch 24; iter: 0; batch classifier loss: 0.211761; batch adversarial loss: 0.598946\n",
      "epoch 24; iter: 200; batch classifier loss: 0.269952; batch adversarial loss: 0.659248\n",
      "epoch 24; iter: 400; batch classifier loss: 0.478179; batch adversarial loss: 0.621527\n",
      "epoch 25; iter: 0; batch classifier loss: 0.373131; batch adversarial loss: 0.612366\n",
      "epoch 25; iter: 200; batch classifier loss: 0.668556; batch adversarial loss: 0.626708\n",
      "epoch 25; iter: 400; batch classifier loss: 0.356797; batch adversarial loss: 0.669206\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346371; batch adversarial loss: 0.634211\n",
      "epoch 26; iter: 200; batch classifier loss: 0.403226; batch adversarial loss: 0.609744\n",
      "epoch 26; iter: 400; batch classifier loss: 0.510824; batch adversarial loss: 0.619043\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362816; batch adversarial loss: 0.660972\n",
      "epoch 27; iter: 200; batch classifier loss: 0.383296; batch adversarial loss: 0.572527\n",
      "epoch 27; iter: 400; batch classifier loss: 0.373258; batch adversarial loss: 0.623381\n",
      "epoch 28; iter: 0; batch classifier loss: 0.319567; batch adversarial loss: 0.663677\n",
      "epoch 28; iter: 200; batch classifier loss: 0.432947; batch adversarial loss: 0.636400\n",
      "epoch 28; iter: 400; batch classifier loss: 0.440407; batch adversarial loss: 0.718531\n",
      "epoch 29; iter: 0; batch classifier loss: 0.222027; batch adversarial loss: 0.610860\n",
      "epoch 29; iter: 200; batch classifier loss: 0.214686; batch adversarial loss: 0.620664\n",
      "epoch 29; iter: 400; batch classifier loss: 0.517565; batch adversarial loss: 0.620155\n",
      "epoch 30; iter: 0; batch classifier loss: 0.374796; batch adversarial loss: 0.661314\n",
      "epoch 30; iter: 200; batch classifier loss: 0.381735; batch adversarial loss: 0.583779\n",
      "epoch 30; iter: 400; batch classifier loss: 0.414616; batch adversarial loss: 0.646639\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366622; batch adversarial loss: 0.554741\n",
      "epoch 31; iter: 200; batch classifier loss: 0.456533; batch adversarial loss: 0.567346\n",
      "epoch 31; iter: 400; batch classifier loss: 0.392566; batch adversarial loss: 0.630382\n",
      "epoch 32; iter: 0; batch classifier loss: 0.371097; batch adversarial loss: 0.604407\n",
      "epoch 32; iter: 200; batch classifier loss: 0.473985; batch adversarial loss: 0.631983\n",
      "epoch 32; iter: 400; batch classifier loss: 0.402284; batch adversarial loss: 0.661913\n",
      "epoch 33; iter: 0; batch classifier loss: 0.445659; batch adversarial loss: 0.520710\n",
      "epoch 33; iter: 200; batch classifier loss: 0.355668; batch adversarial loss: 0.559865\n",
      "epoch 33; iter: 400; batch classifier loss: 0.505985; batch adversarial loss: 0.558146\n",
      "epoch 34; iter: 0; batch classifier loss: 0.494154; batch adversarial loss: 0.644634\n",
      "epoch 34; iter: 200; batch classifier loss: 0.410890; batch adversarial loss: 0.720801\n",
      "epoch 34; iter: 400; batch classifier loss: 0.478880; batch adversarial loss: 0.618871\n",
      "epoch 35; iter: 0; batch classifier loss: 0.343551; batch adversarial loss: 0.575400\n",
      "epoch 35; iter: 200; batch classifier loss: 0.531929; batch adversarial loss: 0.631399\n",
      "epoch 35; iter: 400; batch classifier loss: 0.316251; batch adversarial loss: 0.641678\n",
      "epoch 36; iter: 0; batch classifier loss: 0.607428; batch adversarial loss: 0.696083\n",
      "epoch 36; iter: 200; batch classifier loss: 0.264048; batch adversarial loss: 0.655016\n",
      "epoch 36; iter: 400; batch classifier loss: 0.537209; batch adversarial loss: 0.572953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416372; batch adversarial loss: 0.702666\n",
      "epoch 37; iter: 200; batch classifier loss: 0.403669; batch adversarial loss: 0.636460\n",
      "epoch 37; iter: 400; batch classifier loss: 0.208156; batch adversarial loss: 0.631386\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381068; batch adversarial loss: 0.655070\n",
      "epoch 38; iter: 200; batch classifier loss: 0.335338; batch adversarial loss: 0.686792\n",
      "epoch 38; iter: 400; batch classifier loss: 0.697070; batch adversarial loss: 0.595089\n",
      "epoch 39; iter: 0; batch classifier loss: 0.350015; batch adversarial loss: 0.622780\n",
      "epoch 39; iter: 200; batch classifier loss: 0.337107; batch adversarial loss: 0.666950\n",
      "epoch 39; iter: 400; batch classifier loss: 0.425828; batch adversarial loss: 0.609893\n",
      "epoch 40; iter: 0; batch classifier loss: 0.322725; batch adversarial loss: 0.652307\n",
      "epoch 40; iter: 200; batch classifier loss: 0.492821; batch adversarial loss: 0.589096\n",
      "epoch 40; iter: 400; batch classifier loss: 0.344463; batch adversarial loss: 0.631797\n",
      "epoch 41; iter: 0; batch classifier loss: 0.379295; batch adversarial loss: 0.674021\n",
      "epoch 41; iter: 200; batch classifier loss: 0.346267; batch adversarial loss: 0.554389\n",
      "epoch 41; iter: 400; batch classifier loss: 0.297748; batch adversarial loss: 0.769223\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501354; batch adversarial loss: 0.552374\n",
      "epoch 42; iter: 200; batch classifier loss: 0.370345; batch adversarial loss: 0.631885\n",
      "epoch 42; iter: 400; batch classifier loss: 0.539688; batch adversarial loss: 0.676332\n",
      "epoch 43; iter: 0; batch classifier loss: 0.305654; batch adversarial loss: 0.642213\n",
      "epoch 43; iter: 200; batch classifier loss: 0.264914; batch adversarial loss: 0.606409\n",
      "epoch 43; iter: 400; batch classifier loss: 0.397098; batch adversarial loss: 0.636489\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365064; batch adversarial loss: 0.608357\n",
      "epoch 44; iter: 200; batch classifier loss: 0.548699; batch adversarial loss: 0.675261\n",
      "epoch 44; iter: 400; batch classifier loss: 0.409708; batch adversarial loss: 0.633264\n",
      "epoch 45; iter: 0; batch classifier loss: 0.434024; batch adversarial loss: 0.602606\n",
      "epoch 45; iter: 200; batch classifier loss: 0.643674; batch adversarial loss: 0.632469\n",
      "epoch 45; iter: 400; batch classifier loss: 0.310401; batch adversarial loss: 0.654753\n",
      "epoch 46; iter: 0; batch classifier loss: 0.242153; batch adversarial loss: 0.581510\n",
      "epoch 46; iter: 200; batch classifier loss: 0.406032; batch adversarial loss: 0.616065\n",
      "epoch 46; iter: 400; batch classifier loss: 0.468464; batch adversarial loss: 0.638608\n",
      "epoch 47; iter: 0; batch classifier loss: 0.456457; batch adversarial loss: 0.605089\n",
      "epoch 47; iter: 200; batch classifier loss: 0.354815; batch adversarial loss: 0.562234\n",
      "epoch 47; iter: 400; batch classifier loss: 0.411867; batch adversarial loss: 0.681678\n",
      "epoch 48; iter: 0; batch classifier loss: 0.814165; batch adversarial loss: 0.626561\n",
      "epoch 48; iter: 200; batch classifier loss: 0.332750; batch adversarial loss: 0.638807\n",
      "epoch 48; iter: 400; batch classifier loss: 0.490612; batch adversarial loss: 0.610476\n",
      "epoch 49; iter: 0; batch classifier loss: 0.737875; batch adversarial loss: 0.585286\n",
      "epoch 49; iter: 200; batch classifier loss: 0.359368; batch adversarial loss: 0.656210\n",
      "epoch 49; iter: 400; batch classifier loss: 0.269142; batch adversarial loss: 0.598041\n",
      "epoch 0; iter: 0; batch classifier loss: 139.382324; batch adversarial loss: 0.855331\n",
      "epoch 0; iter: 200; batch classifier loss: 10.506120; batch adversarial loss: 0.740510\n",
      "epoch 0; iter: 400; batch classifier loss: 0.578202; batch adversarial loss: 0.701262\n",
      "epoch 1; iter: 0; batch classifier loss: 8.114820; batch adversarial loss: 0.614948\n",
      "epoch 1; iter: 200; batch classifier loss: 4.740788; batch adversarial loss: 0.636735\n",
      "epoch 1; iter: 400; batch classifier loss: 0.665226; batch adversarial loss: 0.609951\n",
      "epoch 2; iter: 0; batch classifier loss: 0.419891; batch adversarial loss: 0.598041\n",
      "epoch 2; iter: 200; batch classifier loss: 0.398113; batch adversarial loss: 0.622845\n",
      "epoch 2; iter: 400; batch classifier loss: 1.926646; batch adversarial loss: 0.574178\n",
      "epoch 3; iter: 0; batch classifier loss: 1.126012; batch adversarial loss: 0.587534\n",
      "epoch 3; iter: 200; batch classifier loss: 1.234820; batch adversarial loss: 0.618650\n",
      "epoch 3; iter: 400; batch classifier loss: 3.857560; batch adversarial loss: 0.655102\n",
      "epoch 4; iter: 0; batch classifier loss: 2.250058; batch adversarial loss: 0.659210\n",
      "epoch 4; iter: 200; batch classifier loss: 2.813743; batch adversarial loss: 0.628268\n",
      "epoch 4; iter: 400; batch classifier loss: 1.939003; batch adversarial loss: 0.623894\n",
      "epoch 5; iter: 0; batch classifier loss: 0.624655; batch adversarial loss: 0.665750\n",
      "epoch 5; iter: 200; batch classifier loss: 0.504465; batch adversarial loss: 0.617363\n",
      "epoch 5; iter: 400; batch classifier loss: 0.517563; batch adversarial loss: 0.726288\n",
      "epoch 6; iter: 0; batch classifier loss: 0.649643; batch adversarial loss: 0.702817\n",
      "epoch 6; iter: 200; batch classifier loss: 0.822200; batch adversarial loss: 0.669135\n",
      "epoch 6; iter: 400; batch classifier loss: 0.501756; batch adversarial loss: 0.643958\n",
      "epoch 7; iter: 0; batch classifier loss: 0.530118; batch adversarial loss: 0.592183\n",
      "epoch 7; iter: 200; batch classifier loss: 0.425861; batch adversarial loss: 0.686026\n",
      "epoch 7; iter: 400; batch classifier loss: 0.410917; batch adversarial loss: 0.564153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435059; batch adversarial loss: 0.642643\n",
      "epoch 8; iter: 200; batch classifier loss: 0.488159; batch adversarial loss: 0.629129\n",
      "epoch 8; iter: 400; batch classifier loss: 0.321175; batch adversarial loss: 0.788860\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528446; batch adversarial loss: 0.618073\n",
      "epoch 9; iter: 200; batch classifier loss: 0.418016; batch adversarial loss: 0.629770\n",
      "epoch 9; iter: 400; batch classifier loss: 0.455952; batch adversarial loss: 0.569011\n",
      "epoch 10; iter: 0; batch classifier loss: 0.307732; batch adversarial loss: 0.640536\n",
      "epoch 10; iter: 200; batch classifier loss: 0.315875; batch adversarial loss: 0.664599\n",
      "epoch 10; iter: 400; batch classifier loss: 0.416342; batch adversarial loss: 0.596247\n",
      "epoch 11; iter: 0; batch classifier loss: 0.336101; batch adversarial loss: 0.727470\n",
      "epoch 11; iter: 200; batch classifier loss: 0.434229; batch adversarial loss: 0.666963\n",
      "epoch 11; iter: 400; batch classifier loss: 0.396080; batch adversarial loss: 0.590899\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343796; batch adversarial loss: 0.592489\n",
      "epoch 12; iter: 200; batch classifier loss: 0.229741; batch adversarial loss: 0.642283\n",
      "epoch 12; iter: 400; batch classifier loss: 0.366566; batch adversarial loss: 0.640148\n",
      "epoch 13; iter: 0; batch classifier loss: 0.428621; batch adversarial loss: 0.698773\n",
      "epoch 13; iter: 200; batch classifier loss: 0.250477; batch adversarial loss: 0.638237\n",
      "epoch 13; iter: 400; batch classifier loss: 0.310301; batch adversarial loss: 0.676272\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285724; batch adversarial loss: 0.683676\n",
      "epoch 14; iter: 200; batch classifier loss: 0.311692; batch adversarial loss: 0.520257\n",
      "epoch 14; iter: 400; batch classifier loss: 0.336548; batch adversarial loss: 0.670473\n",
      "epoch 15; iter: 0; batch classifier loss: 0.366402; batch adversarial loss: 0.547822\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366632; batch adversarial loss: 0.588756\n",
      "epoch 15; iter: 400; batch classifier loss: 0.306449; batch adversarial loss: 0.659844\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372264; batch adversarial loss: 0.630768\n",
      "epoch 16; iter: 200; batch classifier loss: 0.335205; batch adversarial loss: 0.647371\n",
      "epoch 16; iter: 400; batch classifier loss: 0.316162; batch adversarial loss: 0.563933\n",
      "epoch 17; iter: 0; batch classifier loss: 0.356620; batch adversarial loss: 0.625040\n",
      "epoch 17; iter: 200; batch classifier loss: 0.448329; batch adversarial loss: 0.540998\n",
      "epoch 17; iter: 400; batch classifier loss: 0.264286; batch adversarial loss: 0.595779\n",
      "epoch 18; iter: 0; batch classifier loss: 0.363217; batch adversarial loss: 0.704077\n",
      "epoch 18; iter: 200; batch classifier loss: 0.277792; batch adversarial loss: 0.607259\n",
      "epoch 18; iter: 400; batch classifier loss: 0.331239; batch adversarial loss: 0.653124\n",
      "epoch 19; iter: 0; batch classifier loss: 0.250174; batch adversarial loss: 0.696389\n",
      "epoch 19; iter: 200; batch classifier loss: 0.360404; batch adversarial loss: 0.572199\n",
      "epoch 19; iter: 400; batch classifier loss: 0.255515; batch adversarial loss: 0.631313\n",
      "epoch 20; iter: 0; batch classifier loss: 0.424496; batch adversarial loss: 0.631065\n",
      "epoch 20; iter: 200; batch classifier loss: 0.469684; batch adversarial loss: 0.644601\n",
      "epoch 20; iter: 400; batch classifier loss: 0.608248; batch adversarial loss: 0.560059\n",
      "epoch 21; iter: 0; batch classifier loss: 0.410283; batch adversarial loss: 0.754479\n",
      "epoch 21; iter: 200; batch classifier loss: 0.477593; batch adversarial loss: 0.552441\n",
      "epoch 21; iter: 400; batch classifier loss: 0.416566; batch adversarial loss: 0.650850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.554915; batch adversarial loss: 0.562534\n",
      "epoch 22; iter: 200; batch classifier loss: 0.508304; batch adversarial loss: 0.569491\n",
      "epoch 22; iter: 400; batch classifier loss: 0.501467; batch adversarial loss: 0.641706\n",
      "epoch 23; iter: 0; batch classifier loss: 0.226672; batch adversarial loss: 0.566838\n",
      "epoch 23; iter: 200; batch classifier loss: 0.432259; batch adversarial loss: 0.589939\n",
      "epoch 23; iter: 400; batch classifier loss: 0.481549; batch adversarial loss: 0.639199\n",
      "epoch 24; iter: 0; batch classifier loss: 0.310982; batch adversarial loss: 0.617589\n",
      "epoch 24; iter: 200; batch classifier loss: 0.455965; batch adversarial loss: 0.651168\n",
      "epoch 24; iter: 400; batch classifier loss: 0.296790; batch adversarial loss: 0.570737\n",
      "epoch 25; iter: 0; batch classifier loss: 0.624898; batch adversarial loss: 0.621617\n",
      "epoch 25; iter: 200; batch classifier loss: 0.634686; batch adversarial loss: 0.563691\n",
      "epoch 25; iter: 400; batch classifier loss: 0.371274; batch adversarial loss: 0.622442\n",
      "epoch 26; iter: 0; batch classifier loss: 0.516704; batch adversarial loss: 0.616624\n",
      "epoch 26; iter: 200; batch classifier loss: 0.307962; batch adversarial loss: 0.653727\n",
      "epoch 26; iter: 400; batch classifier loss: 0.373035; batch adversarial loss: 0.642339\n",
      "epoch 27; iter: 0; batch classifier loss: 0.358104; batch adversarial loss: 0.630261\n",
      "epoch 27; iter: 200; batch classifier loss: 0.505886; batch adversarial loss: 0.594194\n",
      "epoch 27; iter: 400; batch classifier loss: 0.453296; batch adversarial loss: 0.641380\n",
      "epoch 28; iter: 0; batch classifier loss: 0.420679; batch adversarial loss: 0.573520\n",
      "epoch 28; iter: 200; batch classifier loss: 0.509305; batch adversarial loss: 0.650634\n",
      "epoch 28; iter: 400; batch classifier loss: 0.274898; batch adversarial loss: 0.594462\n",
      "epoch 29; iter: 0; batch classifier loss: 0.367559; batch adversarial loss: 0.715481\n",
      "epoch 29; iter: 200; batch classifier loss: 0.412022; batch adversarial loss: 0.672648\n",
      "epoch 29; iter: 400; batch classifier loss: 0.289990; batch adversarial loss: 0.636941\n",
      "epoch 30; iter: 0; batch classifier loss: 0.481593; batch adversarial loss: 0.610302\n",
      "epoch 30; iter: 200; batch classifier loss: 0.528223; batch adversarial loss: 0.616668\n",
      "epoch 30; iter: 400; batch classifier loss: 0.332124; batch adversarial loss: 0.691117\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419466; batch adversarial loss: 0.599716\n",
      "epoch 31; iter: 200; batch classifier loss: 0.436629; batch adversarial loss: 0.586475\n",
      "epoch 31; iter: 400; batch classifier loss: 0.622854; batch adversarial loss: 0.700345\n",
      "epoch 32; iter: 0; batch classifier loss: 0.226736; batch adversarial loss: 0.600198\n",
      "epoch 32; iter: 200; batch classifier loss: 0.449604; batch adversarial loss: 0.600347\n",
      "epoch 32; iter: 400; batch classifier loss: 0.297240; batch adversarial loss: 0.662281\n",
      "epoch 33; iter: 0; batch classifier loss: 0.371818; batch adversarial loss: 0.677249\n",
      "epoch 33; iter: 200; batch classifier loss: 0.604850; batch adversarial loss: 0.700416\n",
      "epoch 33; iter: 400; batch classifier loss: 0.458392; batch adversarial loss: 0.704755\n",
      "epoch 34; iter: 0; batch classifier loss: 0.311808; batch adversarial loss: 0.563752\n",
      "epoch 34; iter: 200; batch classifier loss: 0.450936; batch adversarial loss: 0.631100\n",
      "epoch 34; iter: 400; batch classifier loss: 0.686112; batch adversarial loss: 0.712842\n",
      "epoch 35; iter: 0; batch classifier loss: 0.760169; batch adversarial loss: 0.632849\n",
      "epoch 35; iter: 200; batch classifier loss: 0.324384; batch adversarial loss: 0.661999\n",
      "epoch 35; iter: 400; batch classifier loss: 0.686543; batch adversarial loss: 0.548162\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459594; batch adversarial loss: 0.634088\n",
      "epoch 36; iter: 200; batch classifier loss: 0.752881; batch adversarial loss: 0.620207\n",
      "epoch 36; iter: 400; batch classifier loss: 0.452095; batch adversarial loss: 0.703108\n",
      "epoch 37; iter: 0; batch classifier loss: 0.541467; batch adversarial loss: 0.559751\n",
      "epoch 37; iter: 200; batch classifier loss: 0.352671; batch adversarial loss: 0.639569\n",
      "epoch 37; iter: 400; batch classifier loss: 0.431611; batch adversarial loss: 0.619060\n",
      "epoch 38; iter: 0; batch classifier loss: 0.491473; batch adversarial loss: 0.614552\n",
      "epoch 38; iter: 200; batch classifier loss: 0.469377; batch adversarial loss: 0.654030\n",
      "epoch 38; iter: 400; batch classifier loss: 0.494943; batch adversarial loss: 0.680646\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437505; batch adversarial loss: 0.606747\n",
      "epoch 39; iter: 200; batch classifier loss: 0.520455; batch adversarial loss: 0.567251\n",
      "epoch 39; iter: 400; batch classifier loss: 0.623120; batch adversarial loss: 0.647260\n",
      "epoch 40; iter: 0; batch classifier loss: 0.548013; batch adversarial loss: 0.618561\n",
      "epoch 40; iter: 200; batch classifier loss: 0.402242; batch adversarial loss: 0.665629\n",
      "epoch 40; iter: 400; batch classifier loss: 0.491091; batch adversarial loss: 0.533630\n",
      "epoch 41; iter: 0; batch classifier loss: 0.520878; batch adversarial loss: 0.643493\n",
      "epoch 41; iter: 200; batch classifier loss: 0.469077; batch adversarial loss: 0.705526\n",
      "epoch 41; iter: 400; batch classifier loss: 0.481158; batch adversarial loss: 0.602270\n",
      "epoch 42; iter: 0; batch classifier loss: 0.563993; batch adversarial loss: 0.596667\n",
      "epoch 42; iter: 200; batch classifier loss: 0.338073; batch adversarial loss: 0.649562\n",
      "epoch 42; iter: 400; batch classifier loss: 0.392133; batch adversarial loss: 0.655302\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239803; batch adversarial loss: 0.656804\n",
      "epoch 43; iter: 200; batch classifier loss: 0.479045; batch adversarial loss: 0.642739\n",
      "epoch 43; iter: 400; batch classifier loss: 0.359175; batch adversarial loss: 0.585001\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388042; batch adversarial loss: 0.614175\n",
      "epoch 44; iter: 200; batch classifier loss: 0.328958; batch adversarial loss: 0.582714\n",
      "epoch 44; iter: 400; batch classifier loss: 0.545162; batch adversarial loss: 0.656766\n",
      "epoch 45; iter: 0; batch classifier loss: 0.460472; batch adversarial loss: 0.697054\n",
      "epoch 45; iter: 200; batch classifier loss: 0.618976; batch adversarial loss: 0.634539\n",
      "epoch 45; iter: 400; batch classifier loss: 0.400472; batch adversarial loss: 0.683960\n",
      "epoch 46; iter: 0; batch classifier loss: 0.584863; batch adversarial loss: 0.571284\n",
      "epoch 46; iter: 200; batch classifier loss: 0.502545; batch adversarial loss: 0.604490\n",
      "epoch 46; iter: 400; batch classifier loss: 0.341107; batch adversarial loss: 0.694281\n",
      "epoch 47; iter: 0; batch classifier loss: 0.454662; batch adversarial loss: 0.581285\n",
      "epoch 47; iter: 200; batch classifier loss: 0.647042; batch adversarial loss: 0.614915\n",
      "epoch 47; iter: 400; batch classifier loss: 0.685038; batch adversarial loss: 0.668889\n",
      "epoch 48; iter: 0; batch classifier loss: 0.649991; batch adversarial loss: 0.608425\n",
      "epoch 48; iter: 200; batch classifier loss: 0.528199; batch adversarial loss: 0.652579\n",
      "epoch 48; iter: 400; batch classifier loss: 0.464396; batch adversarial loss: 0.624763\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388893; batch adversarial loss: 0.578960\n",
      "epoch 49; iter: 200; batch classifier loss: 0.651348; batch adversarial loss: 0.687463\n",
      "epoch 49; iter: 400; batch classifier loss: 0.624413; batch adversarial loss: 0.588184\n",
      "epoch 0; iter: 0; batch classifier loss: 23.751396; batch adversarial loss: 0.672686\n",
      "epoch 0; iter: 200; batch classifier loss: 10.551899; batch adversarial loss: 0.668738\n",
      "epoch 0; iter: 400; batch classifier loss: 6.179885; batch adversarial loss: 0.640522\n",
      "epoch 1; iter: 0; batch classifier loss: 20.167313; batch adversarial loss: 0.650669\n",
      "epoch 1; iter: 200; batch classifier loss: 3.043445; batch adversarial loss: 0.653953\n",
      "epoch 1; iter: 400; batch classifier loss: 1.714990; batch adversarial loss: 0.590892\n",
      "epoch 2; iter: 0; batch classifier loss: 5.994736; batch adversarial loss: 0.663921\n",
      "epoch 2; iter: 200; batch classifier loss: 8.750842; batch adversarial loss: 0.590842\n",
      "epoch 2; iter: 400; batch classifier loss: 3.237310; batch adversarial loss: 0.612753\n",
      "epoch 3; iter: 0; batch classifier loss: 1.603159; batch adversarial loss: 0.615756\n",
      "epoch 3; iter: 200; batch classifier loss: 1.907705; batch adversarial loss: 0.606781\n",
      "epoch 3; iter: 400; batch classifier loss: 2.529169; batch adversarial loss: 0.650372\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523305; batch adversarial loss: 0.597086\n",
      "epoch 4; iter: 200; batch classifier loss: 0.609646; batch adversarial loss: 0.614842\n",
      "epoch 4; iter: 400; batch classifier loss: 2.992271; batch adversarial loss: 0.596869\n",
      "epoch 5; iter: 0; batch classifier loss: 1.258052; batch adversarial loss: 0.587779\n",
      "epoch 5; iter: 200; batch classifier loss: 1.237984; batch adversarial loss: 0.653208\n",
      "epoch 5; iter: 400; batch classifier loss: 0.418000; batch adversarial loss: 0.626879\n",
      "epoch 6; iter: 0; batch classifier loss: 0.865448; batch adversarial loss: 0.572733\n",
      "epoch 6; iter: 200; batch classifier loss: 0.535608; batch adversarial loss: 0.666305\n",
      "epoch 6; iter: 400; batch classifier loss: 1.018796; batch adversarial loss: 0.561940\n",
      "epoch 7; iter: 0; batch classifier loss: 0.527281; batch adversarial loss: 0.643070\n",
      "epoch 7; iter: 200; batch classifier loss: 0.509804; batch adversarial loss: 0.634818\n",
      "epoch 7; iter: 400; batch classifier loss: 0.538239; batch adversarial loss: 0.594591\n",
      "epoch 8; iter: 0; batch classifier loss: 0.713041; batch adversarial loss: 0.662681\n",
      "epoch 8; iter: 200; batch classifier loss: 0.453616; batch adversarial loss: 0.572535\n",
      "epoch 8; iter: 400; batch classifier loss: 0.416191; batch adversarial loss: 0.664881\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347223; batch adversarial loss: 0.588220\n",
      "epoch 9; iter: 200; batch classifier loss: 0.471427; batch adversarial loss: 0.648151\n",
      "epoch 9; iter: 400; batch classifier loss: 0.316944; batch adversarial loss: 0.601901\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461905; batch adversarial loss: 0.560387\n",
      "epoch 10; iter: 200; batch classifier loss: 0.366041; batch adversarial loss: 0.637358\n",
      "epoch 10; iter: 400; batch classifier loss: 0.377465; batch adversarial loss: 0.628218\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570212; batch adversarial loss: 0.621239\n",
      "epoch 11; iter: 200; batch classifier loss: 0.343144; batch adversarial loss: 0.596881\n",
      "epoch 11; iter: 400; batch classifier loss: 0.283042; batch adversarial loss: 0.600713\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379116; batch adversarial loss: 0.579932\n",
      "epoch 12; iter: 200; batch classifier loss: 0.374417; batch adversarial loss: 0.557057\n",
      "epoch 12; iter: 400; batch classifier loss: 0.317111; batch adversarial loss: 0.604433\n",
      "epoch 13; iter: 0; batch classifier loss: 0.398365; batch adversarial loss: 0.651093\n",
      "epoch 13; iter: 200; batch classifier loss: 0.266894; batch adversarial loss: 0.672442\n",
      "epoch 13; iter: 400; batch classifier loss: 0.394009; batch adversarial loss: 0.598061\n",
      "epoch 14; iter: 0; batch classifier loss: 0.297107; batch adversarial loss: 0.706863\n",
      "epoch 14; iter: 200; batch classifier loss: 0.401804; batch adversarial loss: 0.604289\n",
      "epoch 14; iter: 400; batch classifier loss: 0.346415; batch adversarial loss: 0.582551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.309200; batch adversarial loss: 0.552082\n",
      "epoch 15; iter: 200; batch classifier loss: 0.348269; batch adversarial loss: 0.689729\n",
      "epoch 15; iter: 400; batch classifier loss: 0.368936; batch adversarial loss: 0.626564\n",
      "epoch 16; iter: 0; batch classifier loss: 0.306585; batch adversarial loss: 0.613666\n",
      "epoch 16; iter: 200; batch classifier loss: 0.304578; batch adversarial loss: 0.578369\n",
      "epoch 16; iter: 400; batch classifier loss: 0.365704; batch adversarial loss: 0.585221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.225746; batch adversarial loss: 0.636108\n",
      "epoch 17; iter: 200; batch classifier loss: 0.457293; batch adversarial loss: 0.554003\n",
      "epoch 17; iter: 400; batch classifier loss: 0.191432; batch adversarial loss: 0.719297\n",
      "epoch 18; iter: 0; batch classifier loss: 0.337821; batch adversarial loss: 0.658887\n",
      "epoch 18; iter: 200; batch classifier loss: 0.424278; batch adversarial loss: 0.623238\n",
      "epoch 18; iter: 400; batch classifier loss: 0.288931; batch adversarial loss: 0.667305\n",
      "epoch 19; iter: 0; batch classifier loss: 0.373901; batch adversarial loss: 0.591049\n",
      "epoch 19; iter: 200; batch classifier loss: 0.381560; batch adversarial loss: 0.526690\n",
      "epoch 19; iter: 400; batch classifier loss: 0.336477; batch adversarial loss: 0.575469\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294659; batch adversarial loss: 0.616491\n",
      "epoch 20; iter: 200; batch classifier loss: 0.226602; batch adversarial loss: 0.624090\n",
      "epoch 20; iter: 400; batch classifier loss: 0.256629; batch adversarial loss: 0.606143\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272198; batch adversarial loss: 0.594202\n",
      "epoch 21; iter: 200; batch classifier loss: 0.367240; batch adversarial loss: 0.681204\n",
      "epoch 21; iter: 400; batch classifier loss: 0.307505; batch adversarial loss: 0.575161\n",
      "epoch 22; iter: 0; batch classifier loss: 0.344757; batch adversarial loss: 0.667588\n",
      "epoch 22; iter: 200; batch classifier loss: 0.475986; batch adversarial loss: 0.629348\n",
      "epoch 22; iter: 400; batch classifier loss: 0.278620; batch adversarial loss: 0.651195\n",
      "epoch 23; iter: 0; batch classifier loss: 0.362384; batch adversarial loss: 0.553276\n",
      "epoch 23; iter: 200; batch classifier loss: 0.582694; batch adversarial loss: 0.635761\n",
      "epoch 23; iter: 400; batch classifier loss: 0.383396; batch adversarial loss: 0.702410\n",
      "epoch 24; iter: 0; batch classifier loss: 0.419195; batch adversarial loss: 0.565539\n",
      "epoch 24; iter: 200; batch classifier loss: 0.455349; batch adversarial loss: 0.584746\n",
      "epoch 24; iter: 400; batch classifier loss: 0.404214; batch adversarial loss: 0.608523\n",
      "epoch 25; iter: 0; batch classifier loss: 0.184020; batch adversarial loss: 0.650067\n",
      "epoch 25; iter: 200; batch classifier loss: 0.282433; batch adversarial loss: 0.666740\n",
      "epoch 25; iter: 400; batch classifier loss: 0.445171; batch adversarial loss: 0.654978\n",
      "epoch 26; iter: 0; batch classifier loss: 0.291781; batch adversarial loss: 0.569751\n",
      "epoch 26; iter: 200; batch classifier loss: 0.240656; batch adversarial loss: 0.593634\n",
      "epoch 26; iter: 400; batch classifier loss: 0.303226; batch adversarial loss: 0.602379\n",
      "epoch 27; iter: 0; batch classifier loss: 0.396666; batch adversarial loss: 0.621610\n",
      "epoch 27; iter: 200; batch classifier loss: 0.243611; batch adversarial loss: 0.685711\n",
      "epoch 27; iter: 400; batch classifier loss: 0.361481; batch adversarial loss: 0.671977\n",
      "epoch 28; iter: 0; batch classifier loss: 0.221397; batch adversarial loss: 0.676973\n",
      "epoch 28; iter: 200; batch classifier loss: 0.446356; batch adversarial loss: 0.638864\n",
      "epoch 28; iter: 400; batch classifier loss: 0.485568; batch adversarial loss: 0.599779\n",
      "epoch 29; iter: 0; batch classifier loss: 0.478439; batch adversarial loss: 0.505080\n",
      "epoch 29; iter: 200; batch classifier loss: 0.449187; batch adversarial loss: 0.636840\n",
      "epoch 29; iter: 400; batch classifier loss: 0.313925; batch adversarial loss: 0.610249\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342691; batch adversarial loss: 0.620420\n",
      "epoch 30; iter: 200; batch classifier loss: 0.543655; batch adversarial loss: 0.673358\n",
      "epoch 30; iter: 400; batch classifier loss: 0.509563; batch adversarial loss: 0.641766\n",
      "epoch 31; iter: 0; batch classifier loss: 0.350812; batch adversarial loss: 0.676899\n",
      "epoch 31; iter: 200; batch classifier loss: 0.471855; batch adversarial loss: 0.590482\n",
      "epoch 31; iter: 400; batch classifier loss: 0.270063; batch adversarial loss: 0.656963\n",
      "epoch 32; iter: 0; batch classifier loss: 0.532295; batch adversarial loss: 0.647005\n",
      "epoch 32; iter: 200; batch classifier loss: 0.489036; batch adversarial loss: 0.619313\n",
      "epoch 32; iter: 400; batch classifier loss: 0.506426; batch adversarial loss: 0.587013\n",
      "epoch 33; iter: 0; batch classifier loss: 0.484137; batch adversarial loss: 0.626989\n",
      "epoch 33; iter: 200; batch classifier loss: 0.589864; batch adversarial loss: 0.624773\n",
      "epoch 33; iter: 400; batch classifier loss: 1.028350; batch adversarial loss: 0.568094\n",
      "epoch 34; iter: 0; batch classifier loss: 0.480289; batch adversarial loss: 0.552985\n",
      "epoch 34; iter: 200; batch classifier loss: 0.492023; batch adversarial loss: 0.546338\n",
      "epoch 34; iter: 400; batch classifier loss: 0.480917; batch adversarial loss: 0.603821\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427230; batch adversarial loss: 0.703082\n",
      "epoch 35; iter: 200; batch classifier loss: 0.388758; batch adversarial loss: 0.624201\n",
      "epoch 35; iter: 400; batch classifier loss: 0.397676; batch adversarial loss: 0.620283\n",
      "epoch 36; iter: 0; batch classifier loss: 0.307375; batch adversarial loss: 0.657013\n",
      "epoch 36; iter: 200; batch classifier loss: 0.393911; batch adversarial loss: 0.626932\n",
      "epoch 36; iter: 400; batch classifier loss: 0.722318; batch adversarial loss: 0.666506\n",
      "epoch 37; iter: 0; batch classifier loss: 0.278479; batch adversarial loss: 0.651153\n",
      "epoch 37; iter: 200; batch classifier loss: 0.567037; batch adversarial loss: 0.711115\n",
      "epoch 37; iter: 400; batch classifier loss: 0.344288; batch adversarial loss: 0.636910\n",
      "epoch 38; iter: 0; batch classifier loss: 0.553682; batch adversarial loss: 0.634910\n",
      "epoch 38; iter: 200; batch classifier loss: 0.406151; batch adversarial loss: 0.662138\n",
      "epoch 38; iter: 400; batch classifier loss: 0.446742; batch adversarial loss: 0.698672\n",
      "epoch 39; iter: 0; batch classifier loss: 0.699956; batch adversarial loss: 0.706780\n",
      "epoch 39; iter: 200; batch classifier loss: 0.395584; batch adversarial loss: 0.574589\n",
      "epoch 39; iter: 400; batch classifier loss: 0.676702; batch adversarial loss: 0.631995\n",
      "epoch 40; iter: 0; batch classifier loss: 0.598990; batch adversarial loss: 0.604126\n",
      "epoch 40; iter: 200; batch classifier loss: 0.567869; batch adversarial loss: 0.582037\n",
      "epoch 40; iter: 400; batch classifier loss: 0.191896; batch adversarial loss: 0.693071\n",
      "epoch 41; iter: 0; batch classifier loss: 0.351176; batch adversarial loss: 0.613078\n",
      "epoch 41; iter: 200; batch classifier loss: 0.413364; batch adversarial loss: 0.577380\n",
      "epoch 41; iter: 400; batch classifier loss: 0.368159; batch adversarial loss: 0.588839\n",
      "epoch 42; iter: 0; batch classifier loss: 0.289865; batch adversarial loss: 0.623360\n",
      "epoch 42; iter: 200; batch classifier loss: 0.452056; batch adversarial loss: 0.611638\n",
      "epoch 42; iter: 400; batch classifier loss: 0.463862; batch adversarial loss: 0.654386\n",
      "epoch 43; iter: 0; batch classifier loss: 0.329739; batch adversarial loss: 0.697044\n",
      "epoch 43; iter: 200; batch classifier loss: 0.395780; batch adversarial loss: 0.567458\n",
      "epoch 43; iter: 400; batch classifier loss: 0.603651; batch adversarial loss: 0.650942\n",
      "epoch 44; iter: 0; batch classifier loss: 0.439254; batch adversarial loss: 0.657238\n",
      "epoch 44; iter: 200; batch classifier loss: 0.620721; batch adversarial loss: 0.703946\n",
      "epoch 44; iter: 400; batch classifier loss: 0.360316; batch adversarial loss: 0.637238\n",
      "epoch 45; iter: 0; batch classifier loss: 0.449470; batch adversarial loss: 0.631938\n",
      "epoch 45; iter: 200; batch classifier loss: 0.459060; batch adversarial loss: 0.665614\n",
      "epoch 45; iter: 400; batch classifier loss: 0.352483; batch adversarial loss: 0.626801\n",
      "epoch 46; iter: 0; batch classifier loss: 0.614545; batch adversarial loss: 0.659181\n",
      "epoch 46; iter: 200; batch classifier loss: 0.784474; batch adversarial loss: 0.618995\n",
      "epoch 46; iter: 400; batch classifier loss: 0.475568; batch adversarial loss: 0.576629\n",
      "epoch 47; iter: 0; batch classifier loss: 0.438928; batch adversarial loss: 0.664129\n",
      "epoch 47; iter: 200; batch classifier loss: 0.671392; batch adversarial loss: 0.671338\n",
      "epoch 47; iter: 400; batch classifier loss: 0.438453; batch adversarial loss: 0.558475\n",
      "epoch 48; iter: 0; batch classifier loss: 0.360256; batch adversarial loss: 0.674018\n",
      "epoch 48; iter: 200; batch classifier loss: 0.614904; batch adversarial loss: 0.612231\n",
      "epoch 48; iter: 400; batch classifier loss: 0.479105; batch adversarial loss: 0.624149\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369215; batch adversarial loss: 0.682775\n",
      "epoch 49; iter: 200; batch classifier loss: 0.557237; batch adversarial loss: 0.674363\n",
      "epoch 49; iter: 400; batch classifier loss: 3.042019; batch adversarial loss: 0.680622\n",
      "epoch 0; iter: 0; batch classifier loss: 11.778603; batch adversarial loss: 0.798858\n",
      "epoch 0; iter: 200; batch classifier loss: 34.551331; batch adversarial loss: 0.696933\n",
      "epoch 0; iter: 400; batch classifier loss: 12.313354; batch adversarial loss: 0.645196\n",
      "epoch 1; iter: 0; batch classifier loss: 1.386756; batch adversarial loss: 0.585349\n",
      "epoch 1; iter: 200; batch classifier loss: 7.069957; batch adversarial loss: 0.628365\n",
      "epoch 1; iter: 400; batch classifier loss: 11.115959; batch adversarial loss: 0.651741\n",
      "epoch 2; iter: 0; batch classifier loss: 3.893520; batch adversarial loss: 0.600054\n",
      "epoch 2; iter: 200; batch classifier loss: 1.292018; batch adversarial loss: 0.583489\n",
      "epoch 2; iter: 400; batch classifier loss: 3.015014; batch adversarial loss: 0.591062\n",
      "epoch 3; iter: 0; batch classifier loss: 0.344742; batch adversarial loss: 0.638385\n",
      "epoch 3; iter: 200; batch classifier loss: 4.715014; batch adversarial loss: 0.700732\n",
      "epoch 3; iter: 400; batch classifier loss: 4.307225; batch adversarial loss: 0.647536\n",
      "epoch 4; iter: 0; batch classifier loss: 0.819627; batch adversarial loss: 0.628690\n",
      "epoch 4; iter: 200; batch classifier loss: 2.290461; batch adversarial loss: 0.595153\n",
      "epoch 4; iter: 400; batch classifier loss: 2.862389; batch adversarial loss: 0.619196\n",
      "epoch 5; iter: 0; batch classifier loss: 0.462266; batch adversarial loss: 0.546243\n",
      "epoch 5; iter: 200; batch classifier loss: 1.922736; batch adversarial loss: 0.632434\n",
      "epoch 5; iter: 400; batch classifier loss: 1.304369; batch adversarial loss: 0.625471\n",
      "epoch 6; iter: 0; batch classifier loss: 0.429166; batch adversarial loss: 0.572373\n",
      "epoch 6; iter: 200; batch classifier loss: 0.843598; batch adversarial loss: 0.570580\n",
      "epoch 6; iter: 400; batch classifier loss: 0.390025; batch adversarial loss: 0.598865\n",
      "epoch 7; iter: 0; batch classifier loss: 0.479110; batch adversarial loss: 0.706423\n",
      "epoch 7; iter: 200; batch classifier loss: 0.618265; batch adversarial loss: 0.571180\n",
      "epoch 7; iter: 400; batch classifier loss: 0.551188; batch adversarial loss: 0.672834\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542957; batch adversarial loss: 0.663764\n",
      "epoch 8; iter: 200; batch classifier loss: 0.506684; batch adversarial loss: 0.626058\n",
      "epoch 8; iter: 400; batch classifier loss: 0.533754; batch adversarial loss: 0.683999\n",
      "epoch 9; iter: 0; batch classifier loss: 0.494586; batch adversarial loss: 0.648453\n",
      "epoch 9; iter: 200; batch classifier loss: 0.489995; batch adversarial loss: 0.605054\n",
      "epoch 9; iter: 400; batch classifier loss: 0.507836; batch adversarial loss: 0.630897\n",
      "epoch 10; iter: 0; batch classifier loss: 0.396072; batch adversarial loss: 0.631035\n",
      "epoch 10; iter: 200; batch classifier loss: 0.356902; batch adversarial loss: 0.628322\n",
      "epoch 10; iter: 400; batch classifier loss: 0.261772; batch adversarial loss: 0.635383\n",
      "epoch 11; iter: 0; batch classifier loss: 0.458213; batch adversarial loss: 0.562214\n",
      "epoch 11; iter: 200; batch classifier loss: 0.247685; batch adversarial loss: 0.585054\n",
      "epoch 11; iter: 400; batch classifier loss: 0.313320; batch adversarial loss: 0.691366\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410157; batch adversarial loss: 0.569218\n",
      "epoch 12; iter: 200; batch classifier loss: 0.335599; batch adversarial loss: 0.634874\n",
      "epoch 12; iter: 400; batch classifier loss: 0.327616; batch adversarial loss: 0.661380\n",
      "epoch 13; iter: 0; batch classifier loss: 0.331163; batch adversarial loss: 0.591135\n",
      "epoch 13; iter: 200; batch classifier loss: 0.565588; batch adversarial loss: 0.737262\n",
      "epoch 13; iter: 400; batch classifier loss: 0.336256; batch adversarial loss: 0.549045\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313763; batch adversarial loss: 0.551304\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388789; batch adversarial loss: 0.678721\n",
      "epoch 14; iter: 400; batch classifier loss: 0.353749; batch adversarial loss: 0.586463\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466389; batch adversarial loss: 0.528556\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341287; batch adversarial loss: 0.652790\n",
      "epoch 15; iter: 400; batch classifier loss: 0.291862; batch adversarial loss: 0.631732\n",
      "epoch 16; iter: 0; batch classifier loss: 0.239832; batch adversarial loss: 0.666830\n",
      "epoch 16; iter: 200; batch classifier loss: 0.899105; batch adversarial loss: 0.607128\n",
      "epoch 16; iter: 400; batch classifier loss: 0.364651; batch adversarial loss: 0.612471\n",
      "epoch 17; iter: 0; batch classifier loss: 0.330229; batch adversarial loss: 0.576399\n",
      "epoch 17; iter: 200; batch classifier loss: 0.327750; batch adversarial loss: 0.630159\n",
      "epoch 17; iter: 400; batch classifier loss: 0.363216; batch adversarial loss: 0.562948\n",
      "epoch 18; iter: 0; batch classifier loss: 0.451132; batch adversarial loss: 0.611604\n",
      "epoch 18; iter: 200; batch classifier loss: 0.326594; batch adversarial loss: 0.661663\n",
      "epoch 18; iter: 400; batch classifier loss: 0.251443; batch adversarial loss: 0.653212\n",
      "epoch 19; iter: 0; batch classifier loss: 0.269934; batch adversarial loss: 0.586571\n",
      "epoch 19; iter: 200; batch classifier loss: 0.398092; batch adversarial loss: 0.636643\n",
      "epoch 19; iter: 400; batch classifier loss: 0.313107; batch adversarial loss: 0.624859\n",
      "epoch 20; iter: 0; batch classifier loss: 0.537010; batch adversarial loss: 0.684336\n",
      "epoch 20; iter: 200; batch classifier loss: 0.283127; batch adversarial loss: 0.670350\n",
      "epoch 20; iter: 400; batch classifier loss: 0.349845; batch adversarial loss: 0.666586\n",
      "epoch 21; iter: 0; batch classifier loss: 0.313351; batch adversarial loss: 0.670117\n",
      "epoch 21; iter: 200; batch classifier loss: 0.316011; batch adversarial loss: 0.578312\n",
      "epoch 21; iter: 400; batch classifier loss: 0.490617; batch adversarial loss: 0.654845\n",
      "epoch 22; iter: 0; batch classifier loss: 0.246450; batch adversarial loss: 0.635678\n",
      "epoch 22; iter: 200; batch classifier loss: 0.350087; batch adversarial loss: 0.559570\n",
      "epoch 22; iter: 400; batch classifier loss: 0.369778; batch adversarial loss: 0.726286\n",
      "epoch 23; iter: 0; batch classifier loss: 0.317376; batch adversarial loss: 0.669037\n",
      "epoch 23; iter: 200; batch classifier loss: 0.246678; batch adversarial loss: 0.658552\n",
      "epoch 23; iter: 400; batch classifier loss: 0.527224; batch adversarial loss: 0.592403\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331068; batch adversarial loss: 0.629784\n",
      "epoch 24; iter: 200; batch classifier loss: 0.345181; batch adversarial loss: 0.618815\n",
      "epoch 24; iter: 400; batch classifier loss: 0.612026; batch adversarial loss: 0.638539\n",
      "epoch 25; iter: 0; batch classifier loss: 0.479786; batch adversarial loss: 0.659609\n",
      "epoch 25; iter: 200; batch classifier loss: 0.571204; batch adversarial loss: 0.610709\n",
      "epoch 25; iter: 400; batch classifier loss: 0.562507; batch adversarial loss: 0.530529\n",
      "epoch 26; iter: 0; batch classifier loss: 0.350863; batch adversarial loss: 0.579168\n",
      "epoch 26; iter: 200; batch classifier loss: 0.559732; batch adversarial loss: 0.651300\n",
      "epoch 26; iter: 400; batch classifier loss: 0.375521; batch adversarial loss: 0.609506\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321643; batch adversarial loss: 0.568307\n",
      "epoch 27; iter: 200; batch classifier loss: 0.515269; batch adversarial loss: 0.571665\n",
      "epoch 27; iter: 400; batch classifier loss: 0.353290; batch adversarial loss: 0.615446\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351117; batch adversarial loss: 0.690903\n",
      "epoch 28; iter: 200; batch classifier loss: 0.320381; batch adversarial loss: 0.620854\n",
      "epoch 28; iter: 400; batch classifier loss: 0.465985; batch adversarial loss: 0.599285\n",
      "epoch 29; iter: 0; batch classifier loss: 0.580656; batch adversarial loss: 0.606825\n",
      "epoch 29; iter: 200; batch classifier loss: 0.492801; batch adversarial loss: 0.610410\n",
      "epoch 29; iter: 400; batch classifier loss: 0.358533; batch adversarial loss: 0.615843\n",
      "epoch 30; iter: 0; batch classifier loss: 0.341325; batch adversarial loss: 0.710202\n",
      "epoch 30; iter: 200; batch classifier loss: 0.758563; batch adversarial loss: 0.629721\n",
      "epoch 30; iter: 400; batch classifier loss: 0.632856; batch adversarial loss: 0.614245\n",
      "epoch 31; iter: 0; batch classifier loss: 0.332408; batch adversarial loss: 0.743637\n",
      "epoch 31; iter: 200; batch classifier loss: 0.521936; batch adversarial loss: 0.569703\n",
      "epoch 31; iter: 400; batch classifier loss: 0.313578; batch adversarial loss: 0.653201\n",
      "epoch 32; iter: 0; batch classifier loss: 0.361532; batch adversarial loss: 0.665915\n",
      "epoch 32; iter: 200; batch classifier loss: 0.295405; batch adversarial loss: 0.671424\n",
      "epoch 32; iter: 400; batch classifier loss: 0.341984; batch adversarial loss: 0.634469\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415244; batch adversarial loss: 0.575998\n",
      "epoch 33; iter: 200; batch classifier loss: 0.366027; batch adversarial loss: 0.598964\n",
      "epoch 33; iter: 400; batch classifier loss: 0.548466; batch adversarial loss: 0.608887\n",
      "epoch 34; iter: 0; batch classifier loss: 0.402658; batch adversarial loss: 0.621359\n",
      "epoch 34; iter: 200; batch classifier loss: 0.325953; batch adversarial loss: 0.620167\n",
      "epoch 34; iter: 400; batch classifier loss: 0.440778; batch adversarial loss: 0.615027\n",
      "epoch 35; iter: 0; batch classifier loss: 0.367543; batch adversarial loss: 0.638996\n",
      "epoch 35; iter: 200; batch classifier loss: 0.266965; batch adversarial loss: 0.614759\n",
      "epoch 35; iter: 400; batch classifier loss: 0.681056; batch adversarial loss: 0.619006\n",
      "epoch 36; iter: 0; batch classifier loss: 0.267889; batch adversarial loss: 0.614095\n",
      "epoch 36; iter: 200; batch classifier loss: 0.345919; batch adversarial loss: 0.655947\n",
      "epoch 36; iter: 400; batch classifier loss: 0.434439; batch adversarial loss: 0.707258\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408228; batch adversarial loss: 0.618423\n",
      "epoch 37; iter: 200; batch classifier loss: 0.616732; batch adversarial loss: 0.564893\n",
      "epoch 37; iter: 400; batch classifier loss: 0.368225; batch adversarial loss: 0.652804\n",
      "epoch 38; iter: 0; batch classifier loss: 0.491308; batch adversarial loss: 0.547774\n",
      "epoch 38; iter: 200; batch classifier loss: 0.553257; batch adversarial loss: 0.640563\n",
      "epoch 38; iter: 400; batch classifier loss: 0.564638; batch adversarial loss: 0.590373\n",
      "epoch 39; iter: 0; batch classifier loss: 0.328580; batch adversarial loss: 0.640007\n",
      "epoch 39; iter: 200; batch classifier loss: 0.376145; batch adversarial loss: 0.645173\n",
      "epoch 39; iter: 400; batch classifier loss: 0.657142; batch adversarial loss: 0.635659\n",
      "epoch 40; iter: 0; batch classifier loss: 0.333461; batch adversarial loss: 0.588184\n",
      "epoch 40; iter: 200; batch classifier loss: 0.391755; batch adversarial loss: 0.618777\n",
      "epoch 40; iter: 400; batch classifier loss: 0.531890; batch adversarial loss: 0.544160\n",
      "epoch 41; iter: 0; batch classifier loss: 0.581668; batch adversarial loss: 0.579164\n",
      "epoch 41; iter: 200; batch classifier loss: 0.546616; batch adversarial loss: 0.625764\n",
      "epoch 41; iter: 400; batch classifier loss: 0.413737; batch adversarial loss: 0.615954\n",
      "epoch 42; iter: 0; batch classifier loss: 0.294837; batch adversarial loss: 0.682517\n",
      "epoch 42; iter: 200; batch classifier loss: 0.537980; batch adversarial loss: 0.659157\n",
      "epoch 42; iter: 400; batch classifier loss: 0.313258; batch adversarial loss: 0.627982\n",
      "epoch 43; iter: 0; batch classifier loss: 0.359346; batch adversarial loss: 0.614612\n",
      "epoch 43; iter: 200; batch classifier loss: 0.666998; batch adversarial loss: 0.627231\n",
      "epoch 43; iter: 400; batch classifier loss: 0.535546; batch adversarial loss: 0.574627\n",
      "epoch 44; iter: 0; batch classifier loss: 0.436981; batch adversarial loss: 0.680476\n",
      "epoch 44; iter: 200; batch classifier loss: 0.367473; batch adversarial loss: 0.640970\n",
      "epoch 44; iter: 400; batch classifier loss: 0.429930; batch adversarial loss: 0.642821\n",
      "epoch 45; iter: 0; batch classifier loss: 0.504873; batch adversarial loss: 0.596824\n",
      "epoch 45; iter: 200; batch classifier loss: 0.277833; batch adversarial loss: 0.664159\n",
      "epoch 45; iter: 400; batch classifier loss: 0.729326; batch adversarial loss: 0.589346\n",
      "epoch 46; iter: 0; batch classifier loss: 0.311321; batch adversarial loss: 0.643434\n",
      "epoch 46; iter: 200; batch classifier loss: 0.504423; batch adversarial loss: 0.648541\n",
      "epoch 46; iter: 400; batch classifier loss: 0.234870; batch adversarial loss: 0.654025\n",
      "epoch 47; iter: 0; batch classifier loss: 0.440631; batch adversarial loss: 0.611011\n",
      "epoch 47; iter: 200; batch classifier loss: 0.582281; batch adversarial loss: 0.644002\n",
      "epoch 47; iter: 400; batch classifier loss: 0.771928; batch adversarial loss: 0.671095\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468221; batch adversarial loss: 0.651457\n",
      "epoch 48; iter: 200; batch classifier loss: 0.487777; batch adversarial loss: 0.602031\n",
      "epoch 48; iter: 400; batch classifier loss: 0.580935; batch adversarial loss: 0.620509\n",
      "epoch 49; iter: 0; batch classifier loss: 0.538284; batch adversarial loss: 0.626245\n",
      "epoch 49; iter: 200; batch classifier loss: 0.470546; batch adversarial loss: 0.648107\n",
      "epoch 49; iter: 400; batch classifier loss: 0.457233; batch adversarial loss: 0.554413\n",
      "epoch 0; iter: 0; batch classifier loss: 11.756223; batch adversarial loss: 0.962870\n",
      "epoch 0; iter: 200; batch classifier loss: 16.991570; batch adversarial loss: 1.025873\n",
      "epoch 0; iter: 400; batch classifier loss: 7.990167; batch adversarial loss: 0.967190\n",
      "epoch 1; iter: 0; batch classifier loss: 2.234415; batch adversarial loss: 0.842922\n",
      "epoch 1; iter: 200; batch classifier loss: 3.045837; batch adversarial loss: 0.721486\n",
      "epoch 1; iter: 400; batch classifier loss: 2.647982; batch adversarial loss: 0.693632\n",
      "epoch 2; iter: 0; batch classifier loss: 3.994190; batch adversarial loss: 0.644236\n",
      "epoch 2; iter: 200; batch classifier loss: 2.133263; batch adversarial loss: 0.608207\n",
      "epoch 2; iter: 400; batch classifier loss: 0.709717; batch adversarial loss: 0.602948\n",
      "epoch 3; iter: 0; batch classifier loss: 4.809641; batch adversarial loss: 0.674915\n",
      "epoch 3; iter: 200; batch classifier loss: 7.168861; batch adversarial loss: 0.618449\n",
      "epoch 3; iter: 400; batch classifier loss: 1.005111; batch adversarial loss: 0.593906\n",
      "epoch 4; iter: 0; batch classifier loss: 1.223247; batch adversarial loss: 0.636373\n",
      "epoch 4; iter: 200; batch classifier loss: 2.546598; batch adversarial loss: 0.549391\n",
      "epoch 4; iter: 400; batch classifier loss: 0.956024; batch adversarial loss: 0.640929\n",
      "epoch 5; iter: 0; batch classifier loss: 0.928344; batch adversarial loss: 0.646208\n",
      "epoch 5; iter: 200; batch classifier loss: 0.832623; batch adversarial loss: 0.629242\n",
      "epoch 5; iter: 400; batch classifier loss: 0.822662; batch adversarial loss: 0.623472\n",
      "epoch 6; iter: 0; batch classifier loss: 0.444476; batch adversarial loss: 0.696218\n",
      "epoch 6; iter: 200; batch classifier loss: 0.517468; batch adversarial loss: 0.577843\n",
      "epoch 6; iter: 400; batch classifier loss: 0.616646; batch adversarial loss: 0.594539\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495275; batch adversarial loss: 0.624875\n",
      "epoch 7; iter: 200; batch classifier loss: 0.397383; batch adversarial loss: 0.585437\n",
      "epoch 7; iter: 400; batch classifier loss: 0.343480; batch adversarial loss: 0.624362\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518256; batch adversarial loss: 0.630032\n",
      "epoch 8; iter: 200; batch classifier loss: 0.426579; batch adversarial loss: 0.672348\n",
      "epoch 8; iter: 400; batch classifier loss: 0.325590; batch adversarial loss: 0.657879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421854; batch adversarial loss: 0.680399\n",
      "epoch 9; iter: 200; batch classifier loss: 0.443277; batch adversarial loss: 0.597545\n",
      "epoch 9; iter: 400; batch classifier loss: 0.519712; batch adversarial loss: 0.557717\n",
      "epoch 10; iter: 0; batch classifier loss: 0.317447; batch adversarial loss: 0.634164\n",
      "epoch 10; iter: 200; batch classifier loss: 0.495931; batch adversarial loss: 0.648386\n",
      "epoch 10; iter: 400; batch classifier loss: 0.380697; batch adversarial loss: 0.650589\n",
      "epoch 11; iter: 0; batch classifier loss: 0.330553; batch adversarial loss: 0.681942\n",
      "epoch 11; iter: 200; batch classifier loss: 0.261196; batch adversarial loss: 0.629503\n",
      "epoch 11; iter: 400; batch classifier loss: 0.479418; batch adversarial loss: 0.535575\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308895; batch adversarial loss: 0.624838\n",
      "epoch 12; iter: 200; batch classifier loss: 0.382323; batch adversarial loss: 0.622767\n",
      "epoch 12; iter: 400; batch classifier loss: 0.282942; batch adversarial loss: 0.654264\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429042; batch adversarial loss: 0.604578\n",
      "epoch 13; iter: 200; batch classifier loss: 0.432483; batch adversarial loss: 0.619727\n",
      "epoch 13; iter: 400; batch classifier loss: 0.399161; batch adversarial loss: 0.599656\n",
      "epoch 14; iter: 0; batch classifier loss: 0.387024; batch adversarial loss: 0.559243\n",
      "epoch 14; iter: 200; batch classifier loss: 0.314920; batch adversarial loss: 0.580272\n",
      "epoch 14; iter: 400; batch classifier loss: 0.333297; batch adversarial loss: 0.674219\n",
      "epoch 15; iter: 0; batch classifier loss: 0.292963; batch adversarial loss: 0.583121\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366145; batch adversarial loss: 0.570055\n",
      "epoch 15; iter: 400; batch classifier loss: 0.366275; batch adversarial loss: 0.642256\n",
      "epoch 16; iter: 0; batch classifier loss: 0.317945; batch adversarial loss: 0.662030\n",
      "epoch 16; iter: 200; batch classifier loss: 0.230144; batch adversarial loss: 0.568123\n",
      "epoch 16; iter: 400; batch classifier loss: 0.281595; batch adversarial loss: 0.712507\n",
      "epoch 17; iter: 0; batch classifier loss: 0.403206; batch adversarial loss: 0.641206\n",
      "epoch 17; iter: 200; batch classifier loss: 0.384850; batch adversarial loss: 0.603819\n",
      "epoch 17; iter: 400; batch classifier loss: 0.308900; batch adversarial loss: 0.601622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319452; batch adversarial loss: 0.668036\n",
      "epoch 18; iter: 200; batch classifier loss: 0.327728; batch adversarial loss: 0.677695\n",
      "epoch 18; iter: 400; batch classifier loss: 0.356726; batch adversarial loss: 0.599860\n",
      "epoch 19; iter: 0; batch classifier loss: 0.272165; batch adversarial loss: 0.648858\n",
      "epoch 19; iter: 200; batch classifier loss: 0.281254; batch adversarial loss: 0.564732\n",
      "epoch 19; iter: 400; batch classifier loss: 0.366972; batch adversarial loss: 0.635787\n",
      "epoch 20; iter: 0; batch classifier loss: 0.348250; batch adversarial loss: 0.697055\n",
      "epoch 20; iter: 200; batch classifier loss: 0.301987; batch adversarial loss: 0.610767\n",
      "epoch 20; iter: 400; batch classifier loss: 0.342268; batch adversarial loss: 0.622908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.331655; batch adversarial loss: 0.632613\n",
      "epoch 21; iter: 200; batch classifier loss: 0.313103; batch adversarial loss: 0.605999\n",
      "epoch 21; iter: 400; batch classifier loss: 0.334147; batch adversarial loss: 0.633363\n",
      "epoch 22; iter: 0; batch classifier loss: 0.403084; batch adversarial loss: 0.626543\n",
      "epoch 22; iter: 200; batch classifier loss: 0.327714; batch adversarial loss: 0.606241\n",
      "epoch 22; iter: 400; batch classifier loss: 0.511769; batch adversarial loss: 0.623021\n",
      "epoch 23; iter: 0; batch classifier loss: 0.361745; batch adversarial loss: 0.669442\n",
      "epoch 23; iter: 200; batch classifier loss: 0.367627; batch adversarial loss: 0.664752\n",
      "epoch 23; iter: 400; batch classifier loss: 0.363174; batch adversarial loss: 0.609458\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323018; batch adversarial loss: 0.565949\n",
      "epoch 24; iter: 200; batch classifier loss: 0.323529; batch adversarial loss: 0.630609\n",
      "epoch 24; iter: 400; batch classifier loss: 0.619562; batch adversarial loss: 0.521863\n",
      "epoch 25; iter: 0; batch classifier loss: 0.421002; batch adversarial loss: 0.615143\n",
      "epoch 25; iter: 200; batch classifier loss: 0.448493; batch adversarial loss: 0.600708\n",
      "epoch 25; iter: 400; batch classifier loss: 0.303113; batch adversarial loss: 0.627966\n",
      "epoch 26; iter: 0; batch classifier loss: 0.368050; batch adversarial loss: 0.617130\n",
      "epoch 26; iter: 200; batch classifier loss: 0.371662; batch adversarial loss: 0.573713\n",
      "epoch 26; iter: 400; batch classifier loss: 0.296011; batch adversarial loss: 0.579743\n",
      "epoch 27; iter: 0; batch classifier loss: 0.273690; batch adversarial loss: 0.706147\n",
      "epoch 27; iter: 200; batch classifier loss: 0.482144; batch adversarial loss: 0.590591\n",
      "epoch 27; iter: 400; batch classifier loss: 0.479440; batch adversarial loss: 0.663769\n",
      "epoch 28; iter: 0; batch classifier loss: 0.499429; batch adversarial loss: 0.605902\n",
      "epoch 28; iter: 200; batch classifier loss: 0.570671; batch adversarial loss: 0.630892\n",
      "epoch 28; iter: 400; batch classifier loss: 0.514133; batch adversarial loss: 0.685040\n",
      "epoch 29; iter: 0; batch classifier loss: 0.356469; batch adversarial loss: 0.645501\n",
      "epoch 29; iter: 200; batch classifier loss: 0.574630; batch adversarial loss: 0.712595\n",
      "epoch 29; iter: 400; batch classifier loss: 0.763595; batch adversarial loss: 0.673107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.723276; batch adversarial loss: 0.619181\n",
      "epoch 30; iter: 200; batch classifier loss: 0.393086; batch adversarial loss: 0.625176\n",
      "epoch 30; iter: 400; batch classifier loss: 0.431639; batch adversarial loss: 0.639403\n",
      "epoch 31; iter: 0; batch classifier loss: 0.620662; batch adversarial loss: 0.580163\n",
      "epoch 31; iter: 200; batch classifier loss: 0.793000; batch adversarial loss: 0.611482\n",
      "epoch 31; iter: 400; batch classifier loss: 0.598278; batch adversarial loss: 0.679107\n",
      "epoch 32; iter: 0; batch classifier loss: 0.837231; batch adversarial loss: 0.611513\n",
      "epoch 32; iter: 200; batch classifier loss: 0.523761; batch adversarial loss: 0.648434\n",
      "epoch 32; iter: 400; batch classifier loss: 0.648233; batch adversarial loss: 0.669744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.316677; batch adversarial loss: 0.676919\n",
      "epoch 33; iter: 200; batch classifier loss: 0.611546; batch adversarial loss: 0.591245\n",
      "epoch 33; iter: 400; batch classifier loss: 0.802342; batch adversarial loss: 0.639717\n",
      "epoch 34; iter: 0; batch classifier loss: 0.502225; batch adversarial loss: 0.674944\n",
      "epoch 34; iter: 200; batch classifier loss: 0.331378; batch adversarial loss: 0.664937\n",
      "epoch 34; iter: 400; batch classifier loss: 0.769888; batch adversarial loss: 0.579066\n",
      "epoch 35; iter: 0; batch classifier loss: 0.751844; batch adversarial loss: 0.600790\n",
      "epoch 35; iter: 200; batch classifier loss: 0.516703; batch adversarial loss: 0.600387\n",
      "epoch 35; iter: 400; batch classifier loss: 0.864073; batch adversarial loss: 0.609859\n",
      "epoch 36; iter: 0; batch classifier loss: 0.732445; batch adversarial loss: 0.622501\n",
      "epoch 36; iter: 200; batch classifier loss: 1.102788; batch adversarial loss: 0.614516\n",
      "epoch 36; iter: 400; batch classifier loss: 0.754710; batch adversarial loss: 0.585681\n",
      "epoch 37; iter: 0; batch classifier loss: 0.581522; batch adversarial loss: 0.699359\n",
      "epoch 37; iter: 200; batch classifier loss: 0.980238; batch adversarial loss: 0.662270\n",
      "epoch 37; iter: 400; batch classifier loss: 0.878134; batch adversarial loss: 0.650063\n",
      "epoch 38; iter: 0; batch classifier loss: 0.784671; batch adversarial loss: 0.599745\n",
      "epoch 38; iter: 200; batch classifier loss: 0.522155; batch adversarial loss: 0.677664\n",
      "epoch 38; iter: 400; batch classifier loss: 0.953117; batch adversarial loss: 0.678930\n",
      "epoch 39; iter: 0; batch classifier loss: 1.074471; batch adversarial loss: 0.570547\n",
      "epoch 39; iter: 200; batch classifier loss: 0.900814; batch adversarial loss: 0.666726\n",
      "epoch 39; iter: 400; batch classifier loss: 0.481417; batch adversarial loss: 0.606944\n",
      "epoch 40; iter: 0; batch classifier loss: 0.585941; batch adversarial loss: 0.679220\n",
      "epoch 40; iter: 200; batch classifier loss: 1.179605; batch adversarial loss: 0.588128\n",
      "epoch 40; iter: 400; batch classifier loss: 0.270327; batch adversarial loss: 0.693380\n",
      "epoch 41; iter: 0; batch classifier loss: 0.552632; batch adversarial loss: 0.686361\n",
      "epoch 41; iter: 200; batch classifier loss: 0.652868; batch adversarial loss: 0.705862\n",
      "epoch 41; iter: 400; batch classifier loss: 0.704687; batch adversarial loss: 0.567619\n",
      "epoch 42; iter: 0; batch classifier loss: 0.778709; batch adversarial loss: 0.617085\n",
      "epoch 42; iter: 200; batch classifier loss: 0.630584; batch adversarial loss: 0.544439\n",
      "epoch 42; iter: 400; batch classifier loss: 0.436775; batch adversarial loss: 0.680739\n",
      "epoch 43; iter: 0; batch classifier loss: 0.468941; batch adversarial loss: 0.615324\n",
      "epoch 43; iter: 200; batch classifier loss: 0.847002; batch adversarial loss: 0.628235\n",
      "epoch 43; iter: 400; batch classifier loss: 0.636250; batch adversarial loss: 0.659473\n",
      "epoch 44; iter: 0; batch classifier loss: 0.746359; batch adversarial loss: 0.630232\n",
      "epoch 44; iter: 200; batch classifier loss: 0.680133; batch adversarial loss: 0.572966\n",
      "epoch 44; iter: 400; batch classifier loss: 0.792916; batch adversarial loss: 0.669234\n",
      "epoch 45; iter: 0; batch classifier loss: 0.886700; batch adversarial loss: 0.603870\n",
      "epoch 45; iter: 200; batch classifier loss: 0.568881; batch adversarial loss: 0.663254\n",
      "epoch 45; iter: 400; batch classifier loss: 0.331280; batch adversarial loss: 0.718921\n",
      "epoch 46; iter: 0; batch classifier loss: 0.479674; batch adversarial loss: 0.651448\n",
      "epoch 46; iter: 200; batch classifier loss: 0.667404; batch adversarial loss: 0.706959\n",
      "epoch 46; iter: 400; batch classifier loss: 0.768953; batch adversarial loss: 0.587082\n",
      "epoch 47; iter: 0; batch classifier loss: 0.534598; batch adversarial loss: 0.668182\n",
      "epoch 47; iter: 200; batch classifier loss: 0.761620; batch adversarial loss: 0.664929\n",
      "epoch 47; iter: 400; batch classifier loss: 0.214821; batch adversarial loss: 0.647418\n",
      "epoch 48; iter: 0; batch classifier loss: 0.838151; batch adversarial loss: 0.649348\n",
      "epoch 48; iter: 200; batch classifier loss: 0.721810; batch adversarial loss: 0.624668\n",
      "epoch 48; iter: 400; batch classifier loss: 0.491279; batch adversarial loss: 0.678409\n",
      "epoch 49; iter: 0; batch classifier loss: 0.941089; batch adversarial loss: 0.640489\n",
      "epoch 49; iter: 200; batch classifier loss: 0.528595; batch adversarial loss: 0.682492\n",
      "epoch 49; iter: 400; batch classifier loss: 0.579991; batch adversarial loss: 0.673785\n",
      "epoch 0; iter: 0; batch classifier loss: 11.316553; batch adversarial loss: 0.853195\n",
      "epoch 0; iter: 200; batch classifier loss: 25.760969; batch adversarial loss: 0.786705\n",
      "epoch 0; iter: 400; batch classifier loss: 52.528698; batch adversarial loss: 0.740047\n",
      "epoch 1; iter: 0; batch classifier loss: 1.605421; batch adversarial loss: 0.644005\n",
      "epoch 1; iter: 200; batch classifier loss: 10.958020; batch adversarial loss: 0.623913\n",
      "epoch 1; iter: 400; batch classifier loss: 11.922120; batch adversarial loss: 0.634888\n",
      "epoch 2; iter: 0; batch classifier loss: 7.216957; batch adversarial loss: 0.630789\n",
      "epoch 2; iter: 200; batch classifier loss: 4.675719; batch adversarial loss: 0.611192\n",
      "epoch 2; iter: 400; batch classifier loss: 4.563174; batch adversarial loss: 0.663238\n",
      "epoch 3; iter: 0; batch classifier loss: 3.232650; batch adversarial loss: 0.700526\n",
      "epoch 3; iter: 200; batch classifier loss: 28.914661; batch adversarial loss: 0.657361\n",
      "epoch 3; iter: 400; batch classifier loss: 1.411277; batch adversarial loss: 0.629614\n",
      "epoch 4; iter: 0; batch classifier loss: 2.640298; batch adversarial loss: 0.541874\n",
      "epoch 4; iter: 200; batch classifier loss: 1.633119; batch adversarial loss: 0.680382\n",
      "epoch 4; iter: 400; batch classifier loss: 0.704958; batch adversarial loss: 0.666481\n",
      "epoch 5; iter: 0; batch classifier loss: 0.958625; batch adversarial loss: 0.639197\n",
      "epoch 5; iter: 200; batch classifier loss: 0.766735; batch adversarial loss: 0.662092\n",
      "epoch 5; iter: 400; batch classifier loss: 0.543435; batch adversarial loss: 0.725815\n",
      "epoch 6; iter: 0; batch classifier loss: 0.756744; batch adversarial loss: 0.642581\n",
      "epoch 6; iter: 200; batch classifier loss: 0.679417; batch adversarial loss: 0.656443\n",
      "epoch 6; iter: 400; batch classifier loss: 0.566948; batch adversarial loss: 0.615793\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557549; batch adversarial loss: 0.573878\n",
      "epoch 7; iter: 200; batch classifier loss: 0.522681; batch adversarial loss: 0.610474\n",
      "epoch 7; iter: 400; batch classifier loss: 0.555211; batch adversarial loss: 0.533090\n",
      "epoch 8; iter: 0; batch classifier loss: 0.349745; batch adversarial loss: 0.654697\n",
      "epoch 8; iter: 200; batch classifier loss: 0.522675; batch adversarial loss: 0.541610\n",
      "epoch 8; iter: 400; batch classifier loss: 0.481627; batch adversarial loss: 0.550396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434820; batch adversarial loss: 0.654817\n",
      "epoch 9; iter: 200; batch classifier loss: 0.451253; batch adversarial loss: 0.651245\n",
      "epoch 9; iter: 400; batch classifier loss: 0.425158; batch adversarial loss: 0.559894\n",
      "epoch 10; iter: 0; batch classifier loss: 0.296549; batch adversarial loss: 0.575256\n",
      "epoch 10; iter: 200; batch classifier loss: 0.308538; batch adversarial loss: 0.641480\n",
      "epoch 10; iter: 400; batch classifier loss: 0.351669; batch adversarial loss: 0.562416\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353954; batch adversarial loss: 0.628738\n",
      "epoch 11; iter: 200; batch classifier loss: 0.400295; batch adversarial loss: 0.654256\n",
      "epoch 11; iter: 400; batch classifier loss: 0.329745; batch adversarial loss: 0.691882\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313252; batch adversarial loss: 0.602546\n",
      "epoch 12; iter: 200; batch classifier loss: 0.324308; batch adversarial loss: 0.649656\n",
      "epoch 12; iter: 400; batch classifier loss: 0.395598; batch adversarial loss: 0.682215\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328772; batch adversarial loss: 0.639125\n",
      "epoch 13; iter: 200; batch classifier loss: 0.415340; batch adversarial loss: 0.574139\n",
      "epoch 13; iter: 400; batch classifier loss: 0.537820; batch adversarial loss: 0.557520\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408525; batch adversarial loss: 0.537593\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416622; batch adversarial loss: 0.654766\n",
      "epoch 14; iter: 400; batch classifier loss: 0.330976; batch adversarial loss: 0.583967\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310968; batch adversarial loss: 0.577533\n",
      "epoch 15; iter: 200; batch classifier loss: 0.385351; batch adversarial loss: 0.580546\n",
      "epoch 15; iter: 400; batch classifier loss: 0.327231; batch adversarial loss: 0.617754\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349201; batch adversarial loss: 0.656180\n",
      "epoch 16; iter: 200; batch classifier loss: 0.335042; batch adversarial loss: 0.686198\n",
      "epoch 16; iter: 400; batch classifier loss: 0.281027; batch adversarial loss: 0.659245\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349774; batch adversarial loss: 0.641461\n",
      "epoch 17; iter: 200; batch classifier loss: 0.300121; batch adversarial loss: 0.647238\n",
      "epoch 17; iter: 400; batch classifier loss: 0.423098; batch adversarial loss: 0.572574\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350329; batch adversarial loss: 0.544560\n",
      "epoch 18; iter: 200; batch classifier loss: 0.310271; batch adversarial loss: 0.627332\n",
      "epoch 18; iter: 400; batch classifier loss: 0.331275; batch adversarial loss: 0.598832\n",
      "epoch 19; iter: 0; batch classifier loss: 0.357595; batch adversarial loss: 0.672462\n",
      "epoch 19; iter: 200; batch classifier loss: 0.363592; batch adversarial loss: 0.563708\n",
      "epoch 19; iter: 400; batch classifier loss: 0.250329; batch adversarial loss: 0.579696\n",
      "epoch 20; iter: 0; batch classifier loss: 0.344730; batch adversarial loss: 0.697351\n",
      "epoch 20; iter: 200; batch classifier loss: 0.413147; batch adversarial loss: 0.592886\n",
      "epoch 20; iter: 400; batch classifier loss: 0.350815; batch adversarial loss: 0.572962\n",
      "epoch 21; iter: 0; batch classifier loss: 0.326964; batch adversarial loss: 0.643978\n",
      "epoch 21; iter: 200; batch classifier loss: 0.304772; batch adversarial loss: 0.624952\n",
      "epoch 21; iter: 400; batch classifier loss: 0.506646; batch adversarial loss: 0.508195\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438040; batch adversarial loss: 0.593803\n",
      "epoch 22; iter: 200; batch classifier loss: 0.633420; batch adversarial loss: 0.566434\n",
      "epoch 22; iter: 400; batch classifier loss: 0.363308; batch adversarial loss: 0.738838\n",
      "epoch 23; iter: 0; batch classifier loss: 0.361577; batch adversarial loss: 0.652328\n",
      "epoch 23; iter: 200; batch classifier loss: 0.357072; batch adversarial loss: 0.567962\n",
      "epoch 23; iter: 400; batch classifier loss: 0.525949; batch adversarial loss: 0.542130\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422346; batch adversarial loss: 0.601417\n",
      "epoch 24; iter: 200; batch classifier loss: 0.271729; batch adversarial loss: 0.726308\n",
      "epoch 24; iter: 400; batch classifier loss: 0.409543; batch adversarial loss: 0.589146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.209496; batch adversarial loss: 0.635225\n",
      "epoch 25; iter: 200; batch classifier loss: 0.460281; batch adversarial loss: 0.620564\n",
      "epoch 25; iter: 400; batch classifier loss: 0.338259; batch adversarial loss: 0.649282\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464240; batch adversarial loss: 0.586500\n",
      "epoch 26; iter: 200; batch classifier loss: 0.470713; batch adversarial loss: 0.577357\n",
      "epoch 26; iter: 400; batch classifier loss: 0.388496; batch adversarial loss: 0.641816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.537092; batch adversarial loss: 0.561782\n",
      "epoch 27; iter: 200; batch classifier loss: 0.451925; batch adversarial loss: 0.625399\n",
      "epoch 27; iter: 400; batch classifier loss: 0.237124; batch adversarial loss: 0.553863\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291733; batch adversarial loss: 0.555578\n",
      "epoch 28; iter: 200; batch classifier loss: 0.354417; batch adversarial loss: 0.631205\n",
      "epoch 28; iter: 400; batch classifier loss: 0.386272; batch adversarial loss: 0.579103\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453701; batch adversarial loss: 0.669713\n",
      "epoch 29; iter: 200; batch classifier loss: 0.327700; batch adversarial loss: 0.632190\n",
      "epoch 29; iter: 400; batch classifier loss: 0.299016; batch adversarial loss: 0.607675\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416189; batch adversarial loss: 0.654720\n",
      "epoch 30; iter: 200; batch classifier loss: 0.568856; batch adversarial loss: 0.590520\n",
      "epoch 30; iter: 400; batch classifier loss: 0.577489; batch adversarial loss: 0.529071\n",
      "epoch 31; iter: 0; batch classifier loss: 0.300850; batch adversarial loss: 0.582347\n",
      "epoch 31; iter: 200; batch classifier loss: 0.232349; batch adversarial loss: 0.680543\n",
      "epoch 31; iter: 400; batch classifier loss: 0.327930; batch adversarial loss: 0.654691\n",
      "epoch 32; iter: 0; batch classifier loss: 0.596938; batch adversarial loss: 0.656361\n",
      "epoch 32; iter: 200; batch classifier loss: 0.392663; batch adversarial loss: 0.709891\n",
      "epoch 32; iter: 400; batch classifier loss: 0.439512; batch adversarial loss: 0.682089\n",
      "epoch 33; iter: 0; batch classifier loss: 0.571585; batch adversarial loss: 0.619502\n",
      "epoch 33; iter: 200; batch classifier loss: 0.315559; batch adversarial loss: 0.545805\n",
      "epoch 33; iter: 400; batch classifier loss: 0.490931; batch adversarial loss: 0.586549\n",
      "epoch 34; iter: 0; batch classifier loss: 0.339227; batch adversarial loss: 0.560309\n",
      "epoch 34; iter: 200; batch classifier loss: 0.360961; batch adversarial loss: 0.622078\n",
      "epoch 34; iter: 400; batch classifier loss: 0.307813; batch adversarial loss: 0.580611\n",
      "epoch 35; iter: 0; batch classifier loss: 0.388993; batch adversarial loss: 0.639967\n",
      "epoch 35; iter: 200; batch classifier loss: 0.611259; batch adversarial loss: 0.686224\n",
      "epoch 35; iter: 400; batch classifier loss: 0.862690; batch adversarial loss: 0.653077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.675287; batch adversarial loss: 0.609255\n",
      "epoch 36; iter: 200; batch classifier loss: 0.727762; batch adversarial loss: 0.693816\n",
      "epoch 36; iter: 400; batch classifier loss: 0.363429; batch adversarial loss: 0.657910\n",
      "epoch 37; iter: 0; batch classifier loss: 0.232926; batch adversarial loss: 0.714036\n",
      "epoch 37; iter: 200; batch classifier loss: 0.707869; batch adversarial loss: 0.691379\n",
      "epoch 37; iter: 400; batch classifier loss: 0.304496; batch adversarial loss: 0.635643\n",
      "epoch 38; iter: 0; batch classifier loss: 0.636259; batch adversarial loss: 0.677910\n",
      "epoch 38; iter: 200; batch classifier loss: 0.510939; batch adversarial loss: 0.585833\n",
      "epoch 38; iter: 400; batch classifier loss: 0.328876; batch adversarial loss: 0.678932\n",
      "epoch 39; iter: 0; batch classifier loss: 0.552933; batch adversarial loss: 0.605922\n",
      "epoch 39; iter: 200; batch classifier loss: 0.263427; batch adversarial loss: 0.662628\n",
      "epoch 39; iter: 400; batch classifier loss: 0.378635; batch adversarial loss: 0.615554\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501890; batch adversarial loss: 0.592438\n",
      "epoch 40; iter: 200; batch classifier loss: 1.184073; batch adversarial loss: 0.640835\n",
      "epoch 40; iter: 400; batch classifier loss: 0.509812; batch adversarial loss: 0.610826\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461661; batch adversarial loss: 0.581670\n",
      "epoch 41; iter: 200; batch classifier loss: 0.295191; batch adversarial loss: 0.739157\n",
      "epoch 41; iter: 400; batch classifier loss: 0.378379; batch adversarial loss: 0.629575\n",
      "epoch 42; iter: 0; batch classifier loss: 0.637769; batch adversarial loss: 0.688646\n",
      "epoch 42; iter: 200; batch classifier loss: 0.462667; batch adversarial loss: 0.561597\n",
      "epoch 42; iter: 400; batch classifier loss: 0.355258; batch adversarial loss: 0.700993\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399171; batch adversarial loss: 0.530779\n",
      "epoch 43; iter: 200; batch classifier loss: 0.372226; batch adversarial loss: 0.657419\n",
      "epoch 43; iter: 400; batch classifier loss: 0.441443; batch adversarial loss: 0.664352\n",
      "epoch 44; iter: 0; batch classifier loss: 0.467219; batch adversarial loss: 0.598322\n",
      "epoch 44; iter: 200; batch classifier loss: 0.461485; batch adversarial loss: 0.569507\n",
      "epoch 44; iter: 400; batch classifier loss: 0.314715; batch adversarial loss: 0.719026\n",
      "epoch 45; iter: 0; batch classifier loss: 0.410446; batch adversarial loss: 0.625134\n",
      "epoch 45; iter: 200; batch classifier loss: 0.402483; batch adversarial loss: 0.543788\n",
      "epoch 45; iter: 400; batch classifier loss: 0.201175; batch adversarial loss: 0.725064\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443698; batch adversarial loss: 0.633816\n",
      "epoch 46; iter: 200; batch classifier loss: 0.751057; batch adversarial loss: 0.679389\n",
      "epoch 46; iter: 400; batch classifier loss: 1.452726; batch adversarial loss: 0.627678\n",
      "epoch 47; iter: 0; batch classifier loss: 0.410003; batch adversarial loss: 0.677789\n",
      "epoch 47; iter: 200; batch classifier loss: 0.366575; batch adversarial loss: 0.706367\n",
      "epoch 47; iter: 400; batch classifier loss: 0.458443; batch adversarial loss: 0.633795\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439070; batch adversarial loss: 0.618435\n",
      "epoch 48; iter: 200; batch classifier loss: 0.491956; batch adversarial loss: 0.636287\n",
      "epoch 48; iter: 400; batch classifier loss: 0.373154; batch adversarial loss: 0.662764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.576325; batch adversarial loss: 0.558610\n",
      "epoch 49; iter: 200; batch classifier loss: 0.282431; batch adversarial loss: 0.572030\n",
      "epoch 49; iter: 400; batch classifier loss: 0.438178; batch adversarial loss: 0.606879\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 173.130615; batch adversarial loss: 0.704809\n",
      "epoch 0; iter: 200; batch classifier loss: 13.573799; batch adversarial loss: 0.671245\n",
      "epoch 1; iter: 0; batch classifier loss: 10.255423; batch adversarial loss: 0.658674\n",
      "epoch 1; iter: 200; batch classifier loss: 7.737521; batch adversarial loss: 0.652298\n",
      "epoch 2; iter: 0; batch classifier loss: 5.674681; batch adversarial loss: 0.625645\n",
      "epoch 2; iter: 200; batch classifier loss: 6.427852; batch adversarial loss: 0.604561\n",
      "epoch 3; iter: 0; batch classifier loss: 4.750156; batch adversarial loss: 0.604768\n",
      "epoch 3; iter: 200; batch classifier loss: 1.345767; batch adversarial loss: 0.601184\n",
      "epoch 4; iter: 0; batch classifier loss: 1.288191; batch adversarial loss: 0.641032\n",
      "epoch 4; iter: 200; batch classifier loss: 1.003401; batch adversarial loss: 0.611107\n",
      "epoch 5; iter: 0; batch classifier loss: 1.485106; batch adversarial loss: 0.601467\n",
      "epoch 5; iter: 200; batch classifier loss: 1.578573; batch adversarial loss: 0.621596\n",
      "epoch 6; iter: 0; batch classifier loss: 4.099423; batch adversarial loss: 0.651882\n",
      "epoch 6; iter: 200; batch classifier loss: 0.971193; batch adversarial loss: 0.588521\n",
      "epoch 7; iter: 0; batch classifier loss: 1.723118; batch adversarial loss: 0.636510\n",
      "epoch 7; iter: 200; batch classifier loss: 1.208575; batch adversarial loss: 0.677024\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610039; batch adversarial loss: 0.623711\n",
      "epoch 8; iter: 200; batch classifier loss: 0.704262; batch adversarial loss: 0.633416\n",
      "epoch 9; iter: 0; batch classifier loss: 1.019115; batch adversarial loss: 0.616091\n",
      "epoch 9; iter: 200; batch classifier loss: 0.521996; batch adversarial loss: 0.636155\n",
      "epoch 0; iter: 0; batch classifier loss: 35.200184; batch adversarial loss: 0.669809\n",
      "epoch 0; iter: 200; batch classifier loss: 1.621916; batch adversarial loss: 0.643710\n",
      "epoch 1; iter: 0; batch classifier loss: 7.230179; batch adversarial loss: 0.649146\n",
      "epoch 1; iter: 200; batch classifier loss: 6.968352; batch adversarial loss: 0.630990\n",
      "epoch 2; iter: 0; batch classifier loss: 2.273775; batch adversarial loss: 0.589097\n",
      "epoch 2; iter: 200; batch classifier loss: 34.879284; batch adversarial loss: 0.567887\n",
      "epoch 3; iter: 0; batch classifier loss: 2.698537; batch adversarial loss: 0.634440\n",
      "epoch 3; iter: 200; batch classifier loss: 2.792525; batch adversarial loss: 0.629245\n",
      "epoch 4; iter: 0; batch classifier loss: 1.398287; batch adversarial loss: 0.682021\n",
      "epoch 4; iter: 200; batch classifier loss: 7.062145; batch adversarial loss: 0.642511\n",
      "epoch 5; iter: 0; batch classifier loss: 2.556090; batch adversarial loss: 0.670570\n",
      "epoch 5; iter: 200; batch classifier loss: 1.681192; batch adversarial loss: 0.627089\n",
      "epoch 6; iter: 0; batch classifier loss: 1.464942; batch adversarial loss: 0.592609\n",
      "epoch 6; iter: 200; batch classifier loss: 0.861720; batch adversarial loss: 0.618023\n",
      "epoch 7; iter: 0; batch classifier loss: 1.214100; batch adversarial loss: 0.638146\n",
      "epoch 7; iter: 200; batch classifier loss: 0.868343; batch adversarial loss: 0.610172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426129; batch adversarial loss: 0.603311\n",
      "epoch 8; iter: 200; batch classifier loss: 0.561599; batch adversarial loss: 0.620111\n",
      "epoch 9; iter: 0; batch classifier loss: 0.446185; batch adversarial loss: 0.587920\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426309; batch adversarial loss: 0.636728\n",
      "epoch 0; iter: 0; batch classifier loss: 66.603241; batch adversarial loss: 0.698398\n",
      "epoch 0; iter: 200; batch classifier loss: 17.573193; batch adversarial loss: 0.663727\n",
      "epoch 1; iter: 0; batch classifier loss: 44.132748; batch adversarial loss: 0.654552\n",
      "epoch 1; iter: 200; batch classifier loss: 9.512745; batch adversarial loss: 0.642497\n",
      "epoch 2; iter: 0; batch classifier loss: 5.017507; batch adversarial loss: 0.656479\n",
      "epoch 2; iter: 200; batch classifier loss: 4.357204; batch adversarial loss: 0.633788\n",
      "epoch 3; iter: 0; batch classifier loss: 7.310469; batch adversarial loss: 0.606056\n",
      "epoch 3; iter: 200; batch classifier loss: 6.051982; batch adversarial loss: 0.594439\n",
      "epoch 4; iter: 0; batch classifier loss: 1.651008; batch adversarial loss: 0.619085\n",
      "epoch 4; iter: 200; batch classifier loss: 1.893999; batch adversarial loss: 0.682572\n",
      "epoch 5; iter: 0; batch classifier loss: 3.010273; batch adversarial loss: 0.632293\n",
      "epoch 5; iter: 200; batch classifier loss: 0.852796; batch adversarial loss: 0.625891\n",
      "epoch 6; iter: 0; batch classifier loss: 1.095022; batch adversarial loss: 0.584422\n",
      "epoch 6; iter: 200; batch classifier loss: 0.724934; batch adversarial loss: 0.623282\n",
      "epoch 7; iter: 0; batch classifier loss: 1.474473; batch adversarial loss: 0.569876\n",
      "epoch 7; iter: 200; batch classifier loss: 0.856451; batch adversarial loss: 0.611200\n",
      "epoch 8; iter: 0; batch classifier loss: 0.604441; batch adversarial loss: 0.625485\n",
      "epoch 8; iter: 200; batch classifier loss: 0.381396; batch adversarial loss: 0.633866\n",
      "epoch 9; iter: 0; batch classifier loss: 0.666116; batch adversarial loss: 0.639415\n",
      "epoch 9; iter: 200; batch classifier loss: 0.533115; batch adversarial loss: 0.585205\n",
      "epoch 0; iter: 0; batch classifier loss: 22.456499; batch adversarial loss: 0.789888\n",
      "epoch 0; iter: 200; batch classifier loss: 10.540533; batch adversarial loss: 0.707359\n",
      "epoch 1; iter: 0; batch classifier loss: 6.251544; batch adversarial loss: 0.670487\n",
      "epoch 1; iter: 200; batch classifier loss: 2.212153; batch adversarial loss: 0.636565\n",
      "epoch 2; iter: 0; batch classifier loss: 7.129034; batch adversarial loss: 0.660180\n",
      "epoch 2; iter: 200; batch classifier loss: 3.386992; batch adversarial loss: 0.619030\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634009; batch adversarial loss: 0.628642\n",
      "epoch 3; iter: 200; batch classifier loss: 2.246649; batch adversarial loss: 0.616476\n",
      "epoch 4; iter: 0; batch classifier loss: 2.157299; batch adversarial loss: 0.642048\n",
      "epoch 4; iter: 200; batch classifier loss: 1.902277; batch adversarial loss: 0.674535\n",
      "epoch 5; iter: 0; batch classifier loss: 1.979112; batch adversarial loss: 0.625596\n",
      "epoch 5; iter: 200; batch classifier loss: 1.437043; batch adversarial loss: 0.676045\n",
      "epoch 6; iter: 0; batch classifier loss: 1.566824; batch adversarial loss: 0.599161\n",
      "epoch 6; iter: 200; batch classifier loss: 1.532990; batch adversarial loss: 0.657592\n",
      "epoch 7; iter: 0; batch classifier loss: 0.832208; batch adversarial loss: 0.683850\n",
      "epoch 7; iter: 200; batch classifier loss: 1.023229; batch adversarial loss: 0.685337\n",
      "epoch 8; iter: 0; batch classifier loss: 1.109576; batch adversarial loss: 0.596163\n",
      "epoch 8; iter: 200; batch classifier loss: 0.615469; batch adversarial loss: 0.611711\n",
      "epoch 9; iter: 0; batch classifier loss: 0.845123; batch adversarial loss: 0.649615\n",
      "epoch 9; iter: 200; batch classifier loss: 0.636490; batch adversarial loss: 0.586244\n",
      "epoch 0; iter: 0; batch classifier loss: 21.125074; batch adversarial loss: 0.721763\n",
      "epoch 0; iter: 200; batch classifier loss: 14.468558; batch adversarial loss: 0.669068\n",
      "epoch 1; iter: 0; batch classifier loss: 9.164467; batch adversarial loss: 0.671875\n",
      "epoch 1; iter: 200; batch classifier loss: 5.142420; batch adversarial loss: 0.658816\n",
      "epoch 2; iter: 0; batch classifier loss: 4.653071; batch adversarial loss: 0.622608\n",
      "epoch 2; iter: 200; batch classifier loss: 35.719929; batch adversarial loss: 0.615924\n",
      "epoch 3; iter: 0; batch classifier loss: 4.442129; batch adversarial loss: 0.637247\n",
      "epoch 3; iter: 200; batch classifier loss: 4.088552; batch adversarial loss: 0.607294\n",
      "epoch 4; iter: 0; batch classifier loss: 0.990115; batch adversarial loss: 0.608837\n",
      "epoch 4; iter: 200; batch classifier loss: 4.005424; batch adversarial loss: 0.591075\n",
      "epoch 5; iter: 0; batch classifier loss: 3.458449; batch adversarial loss: 0.675247\n",
      "epoch 5; iter: 200; batch classifier loss: 0.885171; batch adversarial loss: 0.647965\n",
      "epoch 6; iter: 0; batch classifier loss: 2.517990; batch adversarial loss: 0.597639\n",
      "epoch 6; iter: 200; batch classifier loss: 0.922077; batch adversarial loss: 0.571967\n",
      "epoch 7; iter: 0; batch classifier loss: 0.732123; batch adversarial loss: 0.658736\n",
      "epoch 7; iter: 200; batch classifier loss: 0.928561; batch adversarial loss: 0.642937\n",
      "epoch 8; iter: 0; batch classifier loss: 0.682777; batch adversarial loss: 0.677594\n",
      "epoch 8; iter: 200; batch classifier loss: 0.595927; batch adversarial loss: 0.589521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518165; batch adversarial loss: 0.603903\n",
      "epoch 9; iter: 200; batch classifier loss: 0.617996; batch adversarial loss: 0.593576\n",
      "epoch 0; iter: 0; batch classifier loss: 12.607822; batch adversarial loss: 0.924053\n",
      "epoch 0; iter: 200; batch classifier loss: 8.885013; batch adversarial loss: 0.870097\n",
      "epoch 1; iter: 0; batch classifier loss: 5.599353; batch adversarial loss: 0.823179\n",
      "epoch 1; iter: 200; batch classifier loss: 16.748045; batch adversarial loss: 0.692264\n",
      "epoch 2; iter: 0; batch classifier loss: 6.912169; batch adversarial loss: 0.666666\n",
      "epoch 2; iter: 200; batch classifier loss: 5.020361; batch adversarial loss: 0.684890\n",
      "epoch 3; iter: 0; batch classifier loss: 2.287116; batch adversarial loss: 0.660884\n",
      "epoch 3; iter: 200; batch classifier loss: 1.756966; batch adversarial loss: 0.654463\n",
      "epoch 4; iter: 0; batch classifier loss: 2.481234; batch adversarial loss: 0.640218\n",
      "epoch 4; iter: 200; batch classifier loss: 2.125094; batch adversarial loss: 0.626118\n",
      "epoch 5; iter: 0; batch classifier loss: 1.108329; batch adversarial loss: 0.638936\n",
      "epoch 5; iter: 200; batch classifier loss: 0.897825; batch adversarial loss: 0.674244\n",
      "epoch 6; iter: 0; batch classifier loss: 2.294340; batch adversarial loss: 0.642424\n",
      "epoch 6; iter: 200; batch classifier loss: 0.897673; batch adversarial loss: 0.586572\n",
      "epoch 7; iter: 0; batch classifier loss: 1.753921; batch adversarial loss: 0.645332\n",
      "epoch 7; iter: 200; batch classifier loss: 0.598472; batch adversarial loss: 0.632290\n",
      "epoch 8; iter: 0; batch classifier loss: 0.646020; batch adversarial loss: 0.631030\n",
      "epoch 8; iter: 200; batch classifier loss: 0.574830; batch adversarial loss: 0.655431\n",
      "epoch 9; iter: 0; batch classifier loss: 1.064504; batch adversarial loss: 0.667325\n",
      "epoch 9; iter: 200; batch classifier loss: 0.469466; batch adversarial loss: 0.609424\n",
      "epoch 0; iter: 0; batch classifier loss: 191.475693; batch adversarial loss: 0.680628\n",
      "epoch 0; iter: 200; batch classifier loss: 5.697587; batch adversarial loss: 0.641335\n",
      "epoch 1; iter: 0; batch classifier loss: 7.504451; batch adversarial loss: 0.651290\n",
      "epoch 1; iter: 200; batch classifier loss: 14.927734; batch adversarial loss: 0.648510\n",
      "epoch 2; iter: 0; batch classifier loss: 14.417809; batch adversarial loss: 0.671920\n",
      "epoch 2; iter: 200; batch classifier loss: 12.835045; batch adversarial loss: 0.600440\n",
      "epoch 3; iter: 0; batch classifier loss: 3.902508; batch adversarial loss: 0.679788\n",
      "epoch 3; iter: 200; batch classifier loss: 3.204111; batch adversarial loss: 0.645680\n",
      "epoch 4; iter: 0; batch classifier loss: 5.244833; batch adversarial loss: 0.611974\n",
      "epoch 4; iter: 200; batch classifier loss: 1.963289; batch adversarial loss: 0.608288\n",
      "epoch 5; iter: 0; batch classifier loss: 7.469474; batch adversarial loss: 0.618103\n",
      "epoch 5; iter: 200; batch classifier loss: 3.026038; batch adversarial loss: 0.601946\n",
      "epoch 6; iter: 0; batch classifier loss: 4.483281; batch adversarial loss: 0.589461\n",
      "epoch 6; iter: 200; batch classifier loss: 1.292726; batch adversarial loss: 0.598850\n",
      "epoch 7; iter: 0; batch classifier loss: 2.364568; batch adversarial loss: 0.659736\n",
      "epoch 7; iter: 200; batch classifier loss: 0.809127; batch adversarial loss: 0.652584\n",
      "epoch 8; iter: 0; batch classifier loss: 1.134455; batch adversarial loss: 0.618326\n",
      "epoch 8; iter: 200; batch classifier loss: 0.932797; batch adversarial loss: 0.603926\n",
      "epoch 9; iter: 0; batch classifier loss: 1.020677; batch adversarial loss: 0.616068\n",
      "epoch 9; iter: 200; batch classifier loss: 0.883228; batch adversarial loss: 0.654655\n",
      "epoch 0; iter: 0; batch classifier loss: 5.065640; batch adversarial loss: 0.659460\n",
      "epoch 0; iter: 200; batch classifier loss: 13.602435; batch adversarial loss: 0.662525\n",
      "epoch 1; iter: 0; batch classifier loss: 11.964553; batch adversarial loss: 0.675747\n",
      "epoch 1; iter: 200; batch classifier loss: 30.331476; batch adversarial loss: 0.685574\n",
      "epoch 2; iter: 0; batch classifier loss: 2.691593; batch adversarial loss: 0.608566\n",
      "epoch 2; iter: 200; batch classifier loss: 3.288224; batch adversarial loss: 0.612458\n",
      "epoch 3; iter: 0; batch classifier loss: 5.661373; batch adversarial loss: 0.650355\n",
      "epoch 3; iter: 200; batch classifier loss: 6.234728; batch adversarial loss: 0.645061\n",
      "epoch 4; iter: 0; batch classifier loss: 2.741035; batch adversarial loss: 0.661836\n",
      "epoch 4; iter: 200; batch classifier loss: 3.143452; batch adversarial loss: 0.642724\n",
      "epoch 5; iter: 0; batch classifier loss: 4.025564; batch adversarial loss: 0.596110\n",
      "epoch 5; iter: 200; batch classifier loss: 2.851095; batch adversarial loss: 0.615570\n",
      "epoch 6; iter: 0; batch classifier loss: 1.331641; batch adversarial loss: 0.621209\n",
      "epoch 6; iter: 200; batch classifier loss: 0.849441; batch adversarial loss: 0.608427\n",
      "epoch 7; iter: 0; batch classifier loss: 1.324557; batch adversarial loss: 0.642151\n",
      "epoch 7; iter: 200; batch classifier loss: 0.782296; batch adversarial loss: 0.638593\n",
      "epoch 8; iter: 0; batch classifier loss: 1.095073; batch adversarial loss: 0.595661\n",
      "epoch 8; iter: 200; batch classifier loss: 0.929695; batch adversarial loss: 0.675840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544093; batch adversarial loss: 0.609298\n",
      "epoch 9; iter: 200; batch classifier loss: 0.477214; batch adversarial loss: 0.592200\n",
      "epoch 0; iter: 0; batch classifier loss: 13.503028; batch adversarial loss: 0.658840\n",
      "epoch 0; iter: 200; batch classifier loss: 8.099588; batch adversarial loss: 0.670763\n",
      "epoch 1; iter: 0; batch classifier loss: 5.284024; batch adversarial loss: 0.666772\n",
      "epoch 1; iter: 200; batch classifier loss: 2.522726; batch adversarial loss: 0.635293\n",
      "epoch 2; iter: 0; batch classifier loss: 3.589069; batch adversarial loss: 0.635985\n",
      "epoch 2; iter: 200; batch classifier loss: 2.395122; batch adversarial loss: 0.631335\n",
      "epoch 3; iter: 0; batch classifier loss: 4.767693; batch adversarial loss: 0.606096\n",
      "epoch 3; iter: 200; batch classifier loss: 2.811377; batch adversarial loss: 0.608274\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568149; batch adversarial loss: 0.618744\n",
      "epoch 4; iter: 200; batch classifier loss: 0.706210; batch adversarial loss: 0.635502\n",
      "epoch 5; iter: 0; batch classifier loss: 1.838890; batch adversarial loss: 0.647387\n",
      "epoch 5; iter: 200; batch classifier loss: 2.284106; batch adversarial loss: 0.639231\n",
      "epoch 6; iter: 0; batch classifier loss: 1.272188; batch adversarial loss: 0.627989\n",
      "epoch 6; iter: 200; batch classifier loss: 0.748796; batch adversarial loss: 0.620010\n",
      "epoch 7; iter: 0; batch classifier loss: 0.903238; batch adversarial loss: 0.573245\n",
      "epoch 7; iter: 200; batch classifier loss: 0.654899; batch adversarial loss: 0.634449\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468234; batch adversarial loss: 0.587924\n",
      "epoch 8; iter: 200; batch classifier loss: 0.405736; batch adversarial loss: 0.627610\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357274; batch adversarial loss: 0.645696\n",
      "epoch 9; iter: 200; batch classifier loss: 0.522414; batch adversarial loss: 0.621218\n",
      "epoch 0; iter: 0; batch classifier loss: 12.194798; batch adversarial loss: 0.677892\n",
      "epoch 0; iter: 200; batch classifier loss: 12.984287; batch adversarial loss: 0.639318\n",
      "epoch 1; iter: 0; batch classifier loss: 5.116001; batch adversarial loss: 0.671704\n",
      "epoch 1; iter: 200; batch classifier loss: 6.155880; batch adversarial loss: 0.621831\n",
      "epoch 2; iter: 0; batch classifier loss: 16.385630; batch adversarial loss: 0.594712\n",
      "epoch 2; iter: 200; batch classifier loss: 6.028219; batch adversarial loss: 0.618217\n",
      "epoch 3; iter: 0; batch classifier loss: 2.805848; batch adversarial loss: 0.634151\n",
      "epoch 3; iter: 200; batch classifier loss: 1.787049; batch adversarial loss: 0.616623\n",
      "epoch 4; iter: 0; batch classifier loss: 1.043051; batch adversarial loss: 0.661508\n",
      "epoch 4; iter: 200; batch classifier loss: 1.023816; batch adversarial loss: 0.620833\n",
      "epoch 5; iter: 0; batch classifier loss: 1.394885; batch adversarial loss: 0.653594\n",
      "epoch 5; iter: 200; batch classifier loss: 1.925059; batch adversarial loss: 0.605602\n",
      "epoch 6; iter: 0; batch classifier loss: 1.676138; batch adversarial loss: 0.622299\n",
      "epoch 6; iter: 200; batch classifier loss: 0.932106; batch adversarial loss: 0.647270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435772; batch adversarial loss: 0.622781\n",
      "epoch 7; iter: 200; batch classifier loss: 0.844290; batch adversarial loss: 0.569624\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495419; batch adversarial loss: 0.636351\n",
      "epoch 8; iter: 200; batch classifier loss: 0.486971; batch adversarial loss: 0.627258\n",
      "epoch 9; iter: 0; batch classifier loss: 0.480123; batch adversarial loss: 0.611912\n",
      "epoch 9; iter: 200; batch classifier loss: 0.457475; batch adversarial loss: 0.584473\n",
      "epoch 0; iter: 0; batch classifier loss: 20.469288; batch adversarial loss: 0.652281\n",
      "epoch 0; iter: 200; batch classifier loss: 8.613348; batch adversarial loss: 0.662921\n",
      "epoch 1; iter: 0; batch classifier loss: 7.610860; batch adversarial loss: 0.687542\n",
      "epoch 1; iter: 200; batch classifier loss: 6.717001; batch adversarial loss: 0.637436\n",
      "epoch 2; iter: 0; batch classifier loss: 3.285130; batch adversarial loss: 0.623135\n",
      "epoch 2; iter: 200; batch classifier loss: 14.618961; batch adversarial loss: 0.642284\n",
      "epoch 3; iter: 0; batch classifier loss: 5.434478; batch adversarial loss: 0.626289\n",
      "epoch 3; iter: 200; batch classifier loss: 4.122770; batch adversarial loss: 0.622760\n",
      "epoch 4; iter: 0; batch classifier loss: 5.508850; batch adversarial loss: 0.625841\n",
      "epoch 4; iter: 200; batch classifier loss: 2.103347; batch adversarial loss: 0.623862\n",
      "epoch 5; iter: 0; batch classifier loss: 0.694529; batch adversarial loss: 0.638385\n",
      "epoch 5; iter: 200; batch classifier loss: 4.136733; batch adversarial loss: 0.686536\n",
      "epoch 6; iter: 0; batch classifier loss: 0.723871; batch adversarial loss: 0.638511\n",
      "epoch 6; iter: 200; batch classifier loss: 2.413047; batch adversarial loss: 0.581440\n",
      "epoch 7; iter: 0; batch classifier loss: 1.593374; batch adversarial loss: 0.601956\n",
      "epoch 7; iter: 200; batch classifier loss: 0.660378; batch adversarial loss: 0.677325\n",
      "epoch 8; iter: 0; batch classifier loss: 0.559568; batch adversarial loss: 0.616871\n",
      "epoch 8; iter: 200; batch classifier loss: 0.652293; batch adversarial loss: 0.620085\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478434; batch adversarial loss: 0.619174\n",
      "epoch 9; iter: 200; batch classifier loss: 0.498433; batch adversarial loss: 0.611249\n",
      "epoch 0; iter: 0; batch classifier loss: 37.151386; batch adversarial loss: 0.617091\n",
      "epoch 0; iter: 200; batch classifier loss: 13.760333; batch adversarial loss: 0.620328\n",
      "epoch 1; iter: 0; batch classifier loss: 9.560989; batch adversarial loss: 0.599694\n",
      "epoch 1; iter: 200; batch classifier loss: 6.162351; batch adversarial loss: 0.638868\n",
      "epoch 2; iter: 0; batch classifier loss: 2.494045; batch adversarial loss: 0.603089\n",
      "epoch 2; iter: 200; batch classifier loss: 3.268052; batch adversarial loss: 0.651695\n",
      "epoch 3; iter: 0; batch classifier loss: 0.573254; batch adversarial loss: 0.623897\n",
      "epoch 3; iter: 200; batch classifier loss: 3.496316; batch adversarial loss: 0.582302\n",
      "epoch 4; iter: 0; batch classifier loss: 4.120454; batch adversarial loss: 0.608772\n",
      "epoch 4; iter: 200; batch classifier loss: 1.519432; batch adversarial loss: 0.605207\n",
      "epoch 5; iter: 0; batch classifier loss: 2.623115; batch adversarial loss: 0.632472\n",
      "epoch 5; iter: 200; batch classifier loss: 1.209488; batch adversarial loss: 0.630853\n",
      "epoch 6; iter: 0; batch classifier loss: 1.658751; batch adversarial loss: 0.627989\n",
      "epoch 6; iter: 200; batch classifier loss: 0.616275; batch adversarial loss: 0.624531\n",
      "epoch 7; iter: 0; batch classifier loss: 1.030411; batch adversarial loss: 0.626908\n",
      "epoch 7; iter: 200; batch classifier loss: 0.547175; batch adversarial loss: 0.599240\n",
      "epoch 8; iter: 0; batch classifier loss: 0.721773; batch adversarial loss: 0.656419\n",
      "epoch 8; iter: 200; batch classifier loss: 0.485199; batch adversarial loss: 0.620521\n",
      "epoch 9; iter: 0; batch classifier loss: 0.357089; batch adversarial loss: 0.603939\n",
      "epoch 9; iter: 200; batch classifier loss: 0.550862; batch adversarial loss: 0.635741\n",
      "epoch 0; iter: 0; batch classifier loss: 19.209324; batch adversarial loss: 0.911938\n",
      "epoch 0; iter: 200; batch classifier loss: 12.733149; batch adversarial loss: 0.804991\n",
      "epoch 1; iter: 0; batch classifier loss: 11.128378; batch adversarial loss: 0.783279\n",
      "epoch 1; iter: 200; batch classifier loss: 2.862855; batch adversarial loss: 0.705995\n",
      "epoch 2; iter: 0; batch classifier loss: 7.363795; batch adversarial loss: 0.667405\n",
      "epoch 2; iter: 200; batch classifier loss: 4.744805; batch adversarial loss: 0.650790\n",
      "epoch 3; iter: 0; batch classifier loss: 3.244817; batch adversarial loss: 0.648020\n",
      "epoch 3; iter: 200; batch classifier loss: 2.771931; batch adversarial loss: 0.623965\n",
      "epoch 4; iter: 0; batch classifier loss: 2.691374; batch adversarial loss: 0.646795\n",
      "epoch 4; iter: 200; batch classifier loss: 0.725419; batch adversarial loss: 0.636145\n",
      "epoch 5; iter: 0; batch classifier loss: 1.658618; batch adversarial loss: 0.616433\n",
      "epoch 5; iter: 200; batch classifier loss: 0.581962; batch adversarial loss: 0.608950\n",
      "epoch 6; iter: 0; batch classifier loss: 0.956868; batch adversarial loss: 0.647069\n",
      "epoch 6; iter: 200; batch classifier loss: 3.100828; batch adversarial loss: 0.580942\n",
      "epoch 7; iter: 0; batch classifier loss: 0.459409; batch adversarial loss: 0.668809\n",
      "epoch 7; iter: 200; batch classifier loss: 0.438774; batch adversarial loss: 0.576401\n",
      "epoch 8; iter: 0; batch classifier loss: 0.605513; batch adversarial loss: 0.611197\n",
      "epoch 8; iter: 200; batch classifier loss: 0.474358; batch adversarial loss: 0.626858\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569145; batch adversarial loss: 0.619004\n",
      "epoch 9; iter: 200; batch classifier loss: 0.524263; batch adversarial loss: 0.651983\n",
      "epoch 0; iter: 0; batch classifier loss: 7.230802; batch adversarial loss: 0.880750\n",
      "epoch 0; iter: 200; batch classifier loss: 8.798454; batch adversarial loss: 0.819640\n",
      "epoch 1; iter: 0; batch classifier loss: 6.649078; batch adversarial loss: 0.764012\n",
      "epoch 1; iter: 200; batch classifier loss: 5.544549; batch adversarial loss: 0.665381\n",
      "epoch 2; iter: 0; batch classifier loss: 51.908924; batch adversarial loss: 0.674653\n",
      "epoch 2; iter: 200; batch classifier loss: 5.999915; batch adversarial loss: 0.654245\n",
      "epoch 3; iter: 0; batch classifier loss: 2.130721; batch adversarial loss: 0.618056\n",
      "epoch 3; iter: 200; batch classifier loss: 15.592794; batch adversarial loss: 0.591733\n",
      "epoch 4; iter: 0; batch classifier loss: 4.237856; batch adversarial loss: 0.658096\n",
      "epoch 4; iter: 200; batch classifier loss: 1.440383; batch adversarial loss: 0.611019\n",
      "epoch 5; iter: 0; batch classifier loss: 2.205891; batch adversarial loss: 0.591216\n",
      "epoch 5; iter: 200; batch classifier loss: 2.321277; batch adversarial loss: 0.572539\n",
      "epoch 6; iter: 0; batch classifier loss: 0.942000; batch adversarial loss: 0.640620\n",
      "epoch 6; iter: 200; batch classifier loss: 1.651116; batch adversarial loss: 0.602965\n",
      "epoch 7; iter: 0; batch classifier loss: 1.712826; batch adversarial loss: 0.607400\n",
      "epoch 7; iter: 200; batch classifier loss: 1.430926; batch adversarial loss: 0.626736\n",
      "epoch 8; iter: 0; batch classifier loss: 0.980863; batch adversarial loss: 0.612341\n",
      "epoch 8; iter: 200; batch classifier loss: 2.027002; batch adversarial loss: 0.619786\n",
      "epoch 9; iter: 0; batch classifier loss: 0.938205; batch adversarial loss: 0.602448\n",
      "epoch 9; iter: 200; batch classifier loss: 0.539189; batch adversarial loss: 0.637815\n",
      "epoch 0; iter: 0; batch classifier loss: 9.612138; batch adversarial loss: 0.660923\n",
      "epoch 0; iter: 200; batch classifier loss: 4.814962; batch adversarial loss: 0.668824\n",
      "epoch 1; iter: 0; batch classifier loss: 11.474325; batch adversarial loss: 0.659624\n",
      "epoch 1; iter: 200; batch classifier loss: 8.277998; batch adversarial loss: 0.630718\n",
      "epoch 2; iter: 0; batch classifier loss: 3.128111; batch adversarial loss: 0.648007\n",
      "epoch 2; iter: 200; batch classifier loss: 8.352554; batch adversarial loss: 0.631244\n",
      "epoch 3; iter: 0; batch classifier loss: 4.067366; batch adversarial loss: 0.634684\n",
      "epoch 3; iter: 200; batch classifier loss: 5.892870; batch adversarial loss: 0.598395\n",
      "epoch 4; iter: 0; batch classifier loss: 5.451888; batch adversarial loss: 0.616443\n",
      "epoch 4; iter: 200; batch classifier loss: 4.277681; batch adversarial loss: 0.667774\n",
      "epoch 5; iter: 0; batch classifier loss: 13.115627; batch adversarial loss: 0.564708\n",
      "epoch 5; iter: 200; batch classifier loss: 1.077597; batch adversarial loss: 0.572892\n",
      "epoch 6; iter: 0; batch classifier loss: 1.184963; batch adversarial loss: 0.626707\n",
      "epoch 6; iter: 200; batch classifier loss: 1.987718; batch adversarial loss: 0.565081\n",
      "epoch 7; iter: 0; batch classifier loss: 1.779040; batch adversarial loss: 0.622534\n",
      "epoch 7; iter: 200; batch classifier loss: 1.759626; batch adversarial loss: 0.634679\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602717; batch adversarial loss: 0.569915\n",
      "epoch 8; iter: 200; batch classifier loss: 0.473627; batch adversarial loss: 0.576071\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475605; batch adversarial loss: 0.643037\n",
      "epoch 9; iter: 200; batch classifier loss: 0.532383; batch adversarial loss: 0.629511\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 32.596184; batch adversarial loss: 0.777432\n",
      "epoch 0; iter: 200; batch classifier loss: 13.078285; batch adversarial loss: 0.786266\n",
      "epoch 1; iter: 0; batch classifier loss: 7.760291; batch adversarial loss: 0.795268\n",
      "epoch 1; iter: 200; batch classifier loss: 2.158380; batch adversarial loss: 0.683395\n",
      "epoch 2; iter: 0; batch classifier loss: 7.702293; batch adversarial loss: 0.663222\n",
      "epoch 2; iter: 200; batch classifier loss: 4.815497; batch adversarial loss: 0.658598\n",
      "epoch 3; iter: 0; batch classifier loss: 2.825143; batch adversarial loss: 0.651716\n",
      "epoch 3; iter: 200; batch classifier loss: 3.046675; batch adversarial loss: 0.666562\n",
      "epoch 4; iter: 0; batch classifier loss: 1.732414; batch adversarial loss: 0.651752\n",
      "epoch 4; iter: 200; batch classifier loss: 2.209304; batch adversarial loss: 0.644656\n",
      "epoch 5; iter: 0; batch classifier loss: 1.156597; batch adversarial loss: 0.650347\n",
      "epoch 5; iter: 200; batch classifier loss: 0.541359; batch adversarial loss: 0.604091\n",
      "epoch 6; iter: 0; batch classifier loss: 1.671047; batch adversarial loss: 0.545445\n",
      "epoch 6; iter: 200; batch classifier loss: 1.161504; batch adversarial loss: 0.583587\n",
      "epoch 7; iter: 0; batch classifier loss: 2.315922; batch adversarial loss: 0.580977\n",
      "epoch 7; iter: 200; batch classifier loss: 1.024581; batch adversarial loss: 0.591442\n",
      "epoch 8; iter: 0; batch classifier loss: 0.718919; batch adversarial loss: 0.590093\n",
      "epoch 8; iter: 200; batch classifier loss: 0.533445; batch adversarial loss: 0.603879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432791; batch adversarial loss: 0.599322\n",
      "epoch 9; iter: 200; batch classifier loss: 0.720967; batch adversarial loss: 0.621770\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370507; batch adversarial loss: 0.609280\n",
      "epoch 10; iter: 200; batch classifier loss: 0.432533; batch adversarial loss: 0.595504\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440398; batch adversarial loss: 0.616958\n",
      "epoch 11; iter: 200; batch classifier loss: 0.381830; batch adversarial loss: 0.651379\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476134; batch adversarial loss: 0.608964\n",
      "epoch 12; iter: 200; batch classifier loss: 0.410861; batch adversarial loss: 0.614068\n",
      "epoch 13; iter: 0; batch classifier loss: 0.459347; batch adversarial loss: 0.607499\n",
      "epoch 13; iter: 200; batch classifier loss: 0.503611; batch adversarial loss: 0.606495\n",
      "epoch 14; iter: 0; batch classifier loss: 0.877571; batch adversarial loss: 0.625524\n",
      "epoch 14; iter: 200; batch classifier loss: 0.636508; batch adversarial loss: 0.575793\n",
      "epoch 15; iter: 0; batch classifier loss: 0.577559; batch adversarial loss: 0.645415\n",
      "epoch 15; iter: 200; batch classifier loss: 0.402621; batch adversarial loss: 0.595580\n",
      "epoch 16; iter: 0; batch classifier loss: 0.345061; batch adversarial loss: 0.658331\n",
      "epoch 16; iter: 200; batch classifier loss: 0.355006; batch adversarial loss: 0.690687\n",
      "epoch 17; iter: 0; batch classifier loss: 0.411076; batch adversarial loss: 0.673399\n",
      "epoch 17; iter: 200; batch classifier loss: 0.399227; batch adversarial loss: 0.631840\n",
      "epoch 18; iter: 0; batch classifier loss: 0.279386; batch adversarial loss: 0.684711\n",
      "epoch 18; iter: 200; batch classifier loss: 0.315002; batch adversarial loss: 0.605647\n",
      "epoch 19; iter: 0; batch classifier loss: 0.417251; batch adversarial loss: 0.622756\n",
      "epoch 19; iter: 200; batch classifier loss: 0.312673; batch adversarial loss: 0.611984\n",
      "epoch 0; iter: 0; batch classifier loss: 76.006332; batch adversarial loss: 0.869221\n",
      "epoch 0; iter: 200; batch classifier loss: 7.871007; batch adversarial loss: 0.752776\n",
      "epoch 1; iter: 0; batch classifier loss: 9.164175; batch adversarial loss: 0.714736\n",
      "epoch 1; iter: 200; batch classifier loss: 3.096365; batch adversarial loss: 0.678124\n",
      "epoch 2; iter: 0; batch classifier loss: 1.282041; batch adversarial loss: 0.641969\n",
      "epoch 2; iter: 200; batch classifier loss: 1.540405; batch adversarial loss: 0.625222\n",
      "epoch 3; iter: 0; batch classifier loss: 2.424158; batch adversarial loss: 0.628570\n",
      "epoch 3; iter: 200; batch classifier loss: 1.712955; batch adversarial loss: 0.587910\n",
      "epoch 4; iter: 0; batch classifier loss: 2.265486; batch adversarial loss: 0.652998\n",
      "epoch 4; iter: 200; batch classifier loss: 0.744785; batch adversarial loss: 0.592257\n",
      "epoch 5; iter: 0; batch classifier loss: 2.589916; batch adversarial loss: 0.613110\n",
      "epoch 5; iter: 200; batch classifier loss: 1.071660; batch adversarial loss: 0.643601\n",
      "epoch 6; iter: 0; batch classifier loss: 0.968004; batch adversarial loss: 0.631154\n",
      "epoch 6; iter: 200; batch classifier loss: 2.234410; batch adversarial loss: 0.625423\n",
      "epoch 7; iter: 0; batch classifier loss: 0.938962; batch adversarial loss: 0.651634\n",
      "epoch 7; iter: 200; batch classifier loss: 0.749904; batch adversarial loss: 0.653116\n",
      "epoch 8; iter: 0; batch classifier loss: 0.469017; batch adversarial loss: 0.578579\n",
      "epoch 8; iter: 200; batch classifier loss: 0.843181; batch adversarial loss: 0.608034\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585774; batch adversarial loss: 0.618552\n",
      "epoch 9; iter: 200; batch classifier loss: 0.644686; batch adversarial loss: 0.594350\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471284; batch adversarial loss: 0.541218\n",
      "epoch 10; iter: 200; batch classifier loss: 0.492543; batch adversarial loss: 0.575495\n",
      "epoch 11; iter: 0; batch classifier loss: 0.867461; batch adversarial loss: 0.657421\n",
      "epoch 11; iter: 200; batch classifier loss: 0.408133; batch adversarial loss: 0.634788\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390397; batch adversarial loss: 0.589285\n",
      "epoch 12; iter: 200; batch classifier loss: 0.428089; batch adversarial loss: 0.600550\n",
      "epoch 13; iter: 0; batch classifier loss: 0.435163; batch adversarial loss: 0.570769\n",
      "epoch 13; iter: 200; batch classifier loss: 0.492789; batch adversarial loss: 0.583396\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343437; batch adversarial loss: 0.608186\n",
      "epoch 14; iter: 200; batch classifier loss: 0.412433; batch adversarial loss: 0.601444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440757; batch adversarial loss: 0.589180\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392772; batch adversarial loss: 0.633291\n",
      "epoch 16; iter: 0; batch classifier loss: 0.305620; batch adversarial loss: 0.698105\n",
      "epoch 16; iter: 200; batch classifier loss: 0.521970; batch adversarial loss: 0.637103\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353490; batch adversarial loss: 0.614882\n",
      "epoch 17; iter: 200; batch classifier loss: 0.468336; batch adversarial loss: 0.610235\n",
      "epoch 18; iter: 0; batch classifier loss: 0.401441; batch adversarial loss: 0.586833\n",
      "epoch 18; iter: 200; batch classifier loss: 0.294109; batch adversarial loss: 0.671938\n",
      "epoch 19; iter: 0; batch classifier loss: 0.356820; batch adversarial loss: 0.636206\n",
      "epoch 19; iter: 200; batch classifier loss: 0.391880; batch adversarial loss: 0.599242\n",
      "epoch 0; iter: 0; batch classifier loss: 18.640770; batch adversarial loss: 0.681331\n",
      "epoch 0; iter: 200; batch classifier loss: 8.318118; batch adversarial loss: 0.634663\n",
      "epoch 1; iter: 0; batch classifier loss: 15.463791; batch adversarial loss: 0.635314\n",
      "epoch 1; iter: 200; batch classifier loss: 3.149129; batch adversarial loss: 0.639517\n",
      "epoch 2; iter: 0; batch classifier loss: 11.959942; batch adversarial loss: 0.634997\n",
      "epoch 2; iter: 200; batch classifier loss: 24.305870; batch adversarial loss: 0.675032\n",
      "epoch 3; iter: 0; batch classifier loss: 2.382119; batch adversarial loss: 0.652221\n",
      "epoch 3; iter: 200; batch classifier loss: 3.650274; batch adversarial loss: 0.598827\n",
      "epoch 4; iter: 0; batch classifier loss: 3.633367; batch adversarial loss: 0.569028\n",
      "epoch 4; iter: 200; batch classifier loss: 0.937028; batch adversarial loss: 0.632257\n",
      "epoch 5; iter: 0; batch classifier loss: 1.323979; batch adversarial loss: 0.633124\n",
      "epoch 5; iter: 200; batch classifier loss: 1.679614; batch adversarial loss: 0.667329\n",
      "epoch 6; iter: 0; batch classifier loss: 8.114824; batch adversarial loss: 0.648728\n",
      "epoch 6; iter: 200; batch classifier loss: 3.467460; batch adversarial loss: 0.666657\n",
      "epoch 7; iter: 0; batch classifier loss: 0.766363; batch adversarial loss: 0.608009\n",
      "epoch 7; iter: 200; batch classifier loss: 0.596278; batch adversarial loss: 0.636850\n",
      "epoch 8; iter: 0; batch classifier loss: 2.142936; batch adversarial loss: 0.615332\n",
      "epoch 8; iter: 200; batch classifier loss: 0.661027; batch adversarial loss: 0.628573\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499935; batch adversarial loss: 0.640800\n",
      "epoch 9; iter: 200; batch classifier loss: 0.591694; batch adversarial loss: 0.581686\n",
      "epoch 10; iter: 0; batch classifier loss: 0.719849; batch adversarial loss: 0.619185\n",
      "epoch 10; iter: 200; batch classifier loss: 0.504013; batch adversarial loss: 0.615391\n",
      "epoch 11; iter: 0; batch classifier loss: 0.670271; batch adversarial loss: 0.598071\n",
      "epoch 11; iter: 200; batch classifier loss: 0.471744; batch adversarial loss: 0.627819\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452993; batch adversarial loss: 0.664100\n",
      "epoch 12; iter: 200; batch classifier loss: 0.445361; batch adversarial loss: 0.654804\n",
      "epoch 13; iter: 0; batch classifier loss: 1.061856; batch adversarial loss: 0.653521\n",
      "epoch 13; iter: 200; batch classifier loss: 0.429767; batch adversarial loss: 0.611105\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409517; batch adversarial loss: 0.565817\n",
      "epoch 14; iter: 200; batch classifier loss: 0.387020; batch adversarial loss: 0.584135\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330856; batch adversarial loss: 0.588926\n",
      "epoch 15; iter: 200; batch classifier loss: 0.367124; batch adversarial loss: 0.604906\n",
      "epoch 16; iter: 0; batch classifier loss: 0.362228; batch adversarial loss: 0.592378\n",
      "epoch 16; iter: 200; batch classifier loss: 0.424642; batch adversarial loss: 0.630584\n",
      "epoch 17; iter: 0; batch classifier loss: 0.385175; batch adversarial loss: 0.593842\n",
      "epoch 17; iter: 200; batch classifier loss: 0.287691; batch adversarial loss: 0.611938\n",
      "epoch 18; iter: 0; batch classifier loss: 0.390466; batch adversarial loss: 0.555353\n",
      "epoch 18; iter: 200; batch classifier loss: 0.328908; batch adversarial loss: 0.671305\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378792; batch adversarial loss: 0.583418\n",
      "epoch 19; iter: 200; batch classifier loss: 0.306701; batch adversarial loss: 0.640888\n",
      "epoch 0; iter: 0; batch classifier loss: 73.249802; batch adversarial loss: 0.713511\n",
      "epoch 0; iter: 200; batch classifier loss: 8.120715; batch adversarial loss: 0.662260\n",
      "epoch 1; iter: 0; batch classifier loss: 7.700413; batch adversarial loss: 0.657220\n",
      "epoch 1; iter: 200; batch classifier loss: 7.334313; batch adversarial loss: 0.644361\n",
      "epoch 2; iter: 0; batch classifier loss: 4.052439; batch adversarial loss: 0.604148\n",
      "epoch 2; iter: 200; batch classifier loss: 4.994670; batch adversarial loss: 0.575667\n",
      "epoch 3; iter: 0; batch classifier loss: 4.433160; batch adversarial loss: 0.595214\n",
      "epoch 3; iter: 200; batch classifier loss: 15.529448; batch adversarial loss: 0.617000\n",
      "epoch 4; iter: 0; batch classifier loss: 4.505205; batch adversarial loss: 0.634866\n",
      "epoch 4; iter: 200; batch classifier loss: 18.565992; batch adversarial loss: 0.654255\n",
      "epoch 5; iter: 0; batch classifier loss: 1.313940; batch adversarial loss: 0.627952\n",
      "epoch 5; iter: 200; batch classifier loss: 3.137558; batch adversarial loss: 0.578997\n",
      "epoch 6; iter: 0; batch classifier loss: 0.817148; batch adversarial loss: 0.661547\n",
      "epoch 6; iter: 200; batch classifier loss: 3.095831; batch adversarial loss: 0.673008\n",
      "epoch 7; iter: 0; batch classifier loss: 1.237709; batch adversarial loss: 0.637270\n",
      "epoch 7; iter: 200; batch classifier loss: 1.434539; batch adversarial loss: 0.574430\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615768; batch adversarial loss: 0.588445\n",
      "epoch 8; iter: 200; batch classifier loss: 0.697554; batch adversarial loss: 0.649945\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575800; batch adversarial loss: 0.674887\n",
      "epoch 9; iter: 200; batch classifier loss: 0.537697; batch adversarial loss: 0.611256\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468616; batch adversarial loss: 0.614219\n",
      "epoch 10; iter: 200; batch classifier loss: 0.401538; batch adversarial loss: 0.656423\n",
      "epoch 11; iter: 0; batch classifier loss: 0.442429; batch adversarial loss: 0.643318\n",
      "epoch 11; iter: 200; batch classifier loss: 0.454930; batch adversarial loss: 0.624886\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385405; batch adversarial loss: 0.621880\n",
      "epoch 12; iter: 200; batch classifier loss: 1.214781; batch adversarial loss: 0.581715\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567173; batch adversarial loss: 0.660368\n",
      "epoch 13; iter: 200; batch classifier loss: 0.386707; batch adversarial loss: 0.604771\n",
      "epoch 14; iter: 0; batch classifier loss: 0.383747; batch adversarial loss: 0.612565\n",
      "epoch 14; iter: 200; batch classifier loss: 0.274837; batch adversarial loss: 0.604230\n",
      "epoch 15; iter: 0; batch classifier loss: 0.325784; batch adversarial loss: 0.677310\n",
      "epoch 15; iter: 200; batch classifier loss: 0.435901; batch adversarial loss: 0.632449\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414706; batch adversarial loss: 0.552155\n",
      "epoch 16; iter: 200; batch classifier loss: 0.329994; batch adversarial loss: 0.603037\n",
      "epoch 17; iter: 0; batch classifier loss: 0.360809; batch adversarial loss: 0.615049\n",
      "epoch 17; iter: 200; batch classifier loss: 0.357576; batch adversarial loss: 0.624354\n",
      "epoch 18; iter: 0; batch classifier loss: 0.377918; batch adversarial loss: 0.638163\n",
      "epoch 18; iter: 200; batch classifier loss: 0.380313; batch adversarial loss: 0.557363\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451151; batch adversarial loss: 0.635182\n",
      "epoch 19; iter: 200; batch classifier loss: 0.352452; batch adversarial loss: 0.617954\n",
      "epoch 0; iter: 0; batch classifier loss: 30.698408; batch adversarial loss: 0.763771\n",
      "epoch 0; iter: 200; batch classifier loss: 8.030650; batch adversarial loss: 0.686680\n",
      "epoch 1; iter: 0; batch classifier loss: 16.462578; batch adversarial loss: 0.653893\n",
      "epoch 1; iter: 200; batch classifier loss: 10.837362; batch adversarial loss: 0.652981\n",
      "epoch 2; iter: 0; batch classifier loss: 6.101294; batch adversarial loss: 0.645681\n",
      "epoch 2; iter: 200; batch classifier loss: 2.233639; batch adversarial loss: 0.655459\n",
      "epoch 3; iter: 0; batch classifier loss: 3.127619; batch adversarial loss: 0.654091\n",
      "epoch 3; iter: 200; batch classifier loss: 5.818547; batch adversarial loss: 0.672086\n",
      "epoch 4; iter: 0; batch classifier loss: 12.821496; batch adversarial loss: 0.699977\n",
      "epoch 4; iter: 200; batch classifier loss: 1.274693; batch adversarial loss: 0.627286\n",
      "epoch 5; iter: 0; batch classifier loss: 1.994291; batch adversarial loss: 0.648981\n",
      "epoch 5; iter: 200; batch classifier loss: 1.427034; batch adversarial loss: 0.683833\n",
      "epoch 6; iter: 0; batch classifier loss: 0.648187; batch adversarial loss: 0.638233\n",
      "epoch 6; iter: 200; batch classifier loss: 1.452677; batch adversarial loss: 0.631312\n",
      "epoch 7; iter: 0; batch classifier loss: 0.901842; batch adversarial loss: 0.649522\n",
      "epoch 7; iter: 200; batch classifier loss: 0.711850; batch adversarial loss: 0.567532\n",
      "epoch 8; iter: 0; batch classifier loss: 0.605398; batch adversarial loss: 0.637184\n",
      "epoch 8; iter: 200; batch classifier loss: 0.833857; batch adversarial loss: 0.615725\n",
      "epoch 9; iter: 0; batch classifier loss: 0.489824; batch adversarial loss: 0.597317\n",
      "epoch 9; iter: 200; batch classifier loss: 0.597432; batch adversarial loss: 0.564968\n",
      "epoch 10; iter: 0; batch classifier loss: 0.717080; batch adversarial loss: 0.643317\n",
      "epoch 10; iter: 200; batch classifier loss: 0.527546; batch adversarial loss: 0.625205\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549285; batch adversarial loss: 0.638807\n",
      "epoch 11; iter: 200; batch classifier loss: 0.483038; batch adversarial loss: 0.638830\n",
      "epoch 12; iter: 0; batch classifier loss: 0.433459; batch adversarial loss: 0.622919\n",
      "epoch 12; iter: 200; batch classifier loss: 0.379241; batch adversarial loss: 0.658828\n",
      "epoch 13; iter: 0; batch classifier loss: 0.318082; batch adversarial loss: 0.633771\n",
      "epoch 13; iter: 200; batch classifier loss: 0.351148; batch adversarial loss: 0.578426\n",
      "epoch 14; iter: 0; batch classifier loss: 0.486206; batch adversarial loss: 0.567392\n",
      "epoch 14; iter: 200; batch classifier loss: 0.459891; batch adversarial loss: 0.552079\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398464; batch adversarial loss: 0.606902\n",
      "epoch 15; iter: 200; batch classifier loss: 0.379657; batch adversarial loss: 0.580749\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376502; batch adversarial loss: 0.655839\n",
      "epoch 16; iter: 200; batch classifier loss: 0.338214; batch adversarial loss: 0.599643\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340853; batch adversarial loss: 0.572229\n",
      "epoch 17; iter: 200; batch classifier loss: 0.311160; batch adversarial loss: 0.624850\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234531; batch adversarial loss: 0.604454\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382165; batch adversarial loss: 0.554380\n",
      "epoch 19; iter: 0; batch classifier loss: 0.361429; batch adversarial loss: 0.610103\n",
      "epoch 19; iter: 200; batch classifier loss: 0.332390; batch adversarial loss: 0.594269\n",
      "epoch 0; iter: 0; batch classifier loss: 81.177078; batch adversarial loss: 0.690181\n",
      "epoch 0; iter: 200; batch classifier loss: 5.300483; batch adversarial loss: 0.658141\n",
      "epoch 1; iter: 0; batch classifier loss: 4.954983; batch adversarial loss: 0.678555\n",
      "epoch 1; iter: 200; batch classifier loss: 2.452010; batch adversarial loss: 0.656863\n",
      "epoch 2; iter: 0; batch classifier loss: 7.590105; batch adversarial loss: 0.659156\n",
      "epoch 2; iter: 200; batch classifier loss: 2.575158; batch adversarial loss: 0.619491\n",
      "epoch 3; iter: 0; batch classifier loss: 6.730645; batch adversarial loss: 0.655157\n",
      "epoch 3; iter: 200; batch classifier loss: 2.191356; batch adversarial loss: 0.626178\n",
      "epoch 4; iter: 0; batch classifier loss: 2.080225; batch adversarial loss: 0.624873\n",
      "epoch 4; iter: 200; batch classifier loss: 2.432115; batch adversarial loss: 0.619153\n",
      "epoch 5; iter: 0; batch classifier loss: 1.609392; batch adversarial loss: 0.626390\n",
      "epoch 5; iter: 200; batch classifier loss: 1.267741; batch adversarial loss: 0.606743\n",
      "epoch 6; iter: 0; batch classifier loss: 0.852359; batch adversarial loss: 0.595133\n",
      "epoch 6; iter: 200; batch classifier loss: 1.851412; batch adversarial loss: 0.607748\n",
      "epoch 7; iter: 0; batch classifier loss: 1.408943; batch adversarial loss: 0.630043\n",
      "epoch 7; iter: 200; batch classifier loss: 0.571652; batch adversarial loss: 0.624041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578287; batch adversarial loss: 0.618294\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452444; batch adversarial loss: 0.651040\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499322; batch adversarial loss: 0.605957\n",
      "epoch 9; iter: 200; batch classifier loss: 0.368905; batch adversarial loss: 0.655561\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469687; batch adversarial loss: 0.695766\n",
      "epoch 10; iter: 200; batch classifier loss: 0.434266; batch adversarial loss: 0.651489\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514832; batch adversarial loss: 0.613676\n",
      "epoch 11; iter: 200; batch classifier loss: 0.488551; batch adversarial loss: 0.610270\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481965; batch adversarial loss: 0.598117\n",
      "epoch 12; iter: 200; batch classifier loss: 0.342084; batch adversarial loss: 0.657414\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392092; batch adversarial loss: 0.648105\n",
      "epoch 13; iter: 200; batch classifier loss: 0.493547; batch adversarial loss: 0.612238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.382845; batch adversarial loss: 0.600785\n",
      "epoch 14; iter: 200; batch classifier loss: 0.389301; batch adversarial loss: 0.614242\n",
      "epoch 15; iter: 0; batch classifier loss: 0.403776; batch adversarial loss: 0.595813\n",
      "epoch 15; iter: 200; batch classifier loss: 0.351678; batch adversarial loss: 0.579730\n",
      "epoch 16; iter: 0; batch classifier loss: 0.425126; batch adversarial loss: 0.640962\n",
      "epoch 16; iter: 200; batch classifier loss: 0.549792; batch adversarial loss: 0.552884\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532997; batch adversarial loss: 0.628572\n",
      "epoch 17; iter: 200; batch classifier loss: 0.260888; batch adversarial loss: 0.632143\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438706; batch adversarial loss: 0.539315\n",
      "epoch 18; iter: 200; batch classifier loss: 0.453965; batch adversarial loss: 0.537337\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365747; batch adversarial loss: 0.629252\n",
      "epoch 19; iter: 200; batch classifier loss: 0.300493; batch adversarial loss: 0.636407\n",
      "epoch 0; iter: 0; batch classifier loss: 27.483513; batch adversarial loss: 0.858227\n",
      "epoch 0; iter: 200; batch classifier loss: 23.901489; batch adversarial loss: 0.756196\n",
      "epoch 1; iter: 0; batch classifier loss: 4.407207; batch adversarial loss: 0.738623\n",
      "epoch 1; iter: 200; batch classifier loss: 7.284767; batch adversarial loss: 0.673300\n",
      "epoch 2; iter: 0; batch classifier loss: 5.157374; batch adversarial loss: 0.663098\n",
      "epoch 2; iter: 200; batch classifier loss: 5.452863; batch adversarial loss: 0.652480\n",
      "epoch 3; iter: 0; batch classifier loss: 1.471971; batch adversarial loss: 0.637140\n",
      "epoch 3; iter: 200; batch classifier loss: 2.697829; batch adversarial loss: 0.660036\n",
      "epoch 4; iter: 0; batch classifier loss: 1.475827; batch adversarial loss: 0.653102\n",
      "epoch 4; iter: 200; batch classifier loss: 3.374510; batch adversarial loss: 0.600783\n",
      "epoch 5; iter: 0; batch classifier loss: 1.875210; batch adversarial loss: 0.664672\n",
      "epoch 5; iter: 200; batch classifier loss: 3.292872; batch adversarial loss: 0.651537\n",
      "epoch 6; iter: 0; batch classifier loss: 1.675135; batch adversarial loss: 0.639341\n",
      "epoch 6; iter: 200; batch classifier loss: 0.823813; batch adversarial loss: 0.596193\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579429; batch adversarial loss: 0.643681\n",
      "epoch 7; iter: 200; batch classifier loss: 0.683918; batch adversarial loss: 0.653212\n",
      "epoch 8; iter: 0; batch classifier loss: 0.988420; batch adversarial loss: 0.641806\n",
      "epoch 8; iter: 200; batch classifier loss: 0.804679; batch adversarial loss: 0.580364\n",
      "epoch 9; iter: 0; batch classifier loss: 0.706238; batch adversarial loss: 0.657626\n",
      "epoch 9; iter: 200; batch classifier loss: 0.615549; batch adversarial loss: 0.609761\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454631; batch adversarial loss: 0.627127\n",
      "epoch 10; iter: 200; batch classifier loss: 0.784586; batch adversarial loss: 0.648982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.391671; batch adversarial loss: 0.586717\n",
      "epoch 11; iter: 200; batch classifier loss: 0.534134; batch adversarial loss: 0.583279\n",
      "epoch 12; iter: 0; batch classifier loss: 0.499720; batch adversarial loss: 0.621361\n",
      "epoch 12; iter: 200; batch classifier loss: 0.460236; batch adversarial loss: 0.623853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327162; batch adversarial loss: 0.606880\n",
      "epoch 13; iter: 200; batch classifier loss: 0.487623; batch adversarial loss: 0.603714\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389845; batch adversarial loss: 0.635095\n",
      "epoch 14; iter: 200; batch classifier loss: 0.509747; batch adversarial loss: 0.616971\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474150; batch adversarial loss: 0.607541\n",
      "epoch 15; iter: 200; batch classifier loss: 0.441278; batch adversarial loss: 0.635160\n",
      "epoch 16; iter: 0; batch classifier loss: 0.395711; batch adversarial loss: 0.612839\n",
      "epoch 16; iter: 200; batch classifier loss: 0.448510; batch adversarial loss: 0.544575\n",
      "epoch 17; iter: 0; batch classifier loss: 0.464563; batch adversarial loss: 0.569516\n",
      "epoch 17; iter: 200; batch classifier loss: 0.342624; batch adversarial loss: 0.603954\n",
      "epoch 18; iter: 0; batch classifier loss: 0.444356; batch adversarial loss: 0.608315\n",
      "epoch 18; iter: 200; batch classifier loss: 0.318357; batch adversarial loss: 0.609550\n",
      "epoch 19; iter: 0; batch classifier loss: 0.351425; batch adversarial loss: 0.593807\n",
      "epoch 19; iter: 200; batch classifier loss: 0.256215; batch adversarial loss: 0.678775\n",
      "epoch 0; iter: 0; batch classifier loss: 16.583120; batch adversarial loss: 0.699393\n",
      "epoch 0; iter: 200; batch classifier loss: 5.096600; batch adversarial loss: 0.671777\n",
      "epoch 1; iter: 0; batch classifier loss: 13.222823; batch adversarial loss: 0.661910\n",
      "epoch 1; iter: 200; batch classifier loss: 10.641797; batch adversarial loss: 0.690566\n",
      "epoch 2; iter: 0; batch classifier loss: 4.958591; batch adversarial loss: 0.634530\n",
      "epoch 2; iter: 200; batch classifier loss: 4.650263; batch adversarial loss: 0.619853\n",
      "epoch 3; iter: 0; batch classifier loss: 8.298830; batch adversarial loss: 0.628572\n",
      "epoch 3; iter: 200; batch classifier loss: 4.420733; batch adversarial loss: 0.649703\n",
      "epoch 4; iter: 0; batch classifier loss: 4.203154; batch adversarial loss: 0.650537\n",
      "epoch 4; iter: 200; batch classifier loss: 1.671419; batch adversarial loss: 0.607867\n",
      "epoch 5; iter: 0; batch classifier loss: 4.041750; batch adversarial loss: 0.655993\n",
      "epoch 5; iter: 200; batch classifier loss: 2.272974; batch adversarial loss: 0.635713\n",
      "epoch 6; iter: 0; batch classifier loss: 1.243237; batch adversarial loss: 0.643619\n",
      "epoch 6; iter: 200; batch classifier loss: 1.038402; batch adversarial loss: 0.607145\n",
      "epoch 7; iter: 0; batch classifier loss: 0.577674; batch adversarial loss: 0.593737\n",
      "epoch 7; iter: 200; batch classifier loss: 0.647373; batch adversarial loss: 0.655014\n",
      "epoch 8; iter: 0; batch classifier loss: 0.906648; batch adversarial loss: 0.597481\n",
      "epoch 8; iter: 200; batch classifier loss: 0.667178; batch adversarial loss: 0.638991\n",
      "epoch 9; iter: 0; batch classifier loss: 1.110888; batch adversarial loss: 0.652842\n",
      "epoch 9; iter: 200; batch classifier loss: 0.398082; batch adversarial loss: 0.613426\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553051; batch adversarial loss: 0.600985\n",
      "epoch 10; iter: 200; batch classifier loss: 0.374383; batch adversarial loss: 0.601292\n",
      "epoch 11; iter: 0; batch classifier loss: 0.676867; batch adversarial loss: 0.672924\n",
      "epoch 11; iter: 200; batch classifier loss: 0.493069; batch adversarial loss: 0.604533\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497475; batch adversarial loss: 0.620503\n",
      "epoch 12; iter: 200; batch classifier loss: 0.419926; batch adversarial loss: 0.620814\n",
      "epoch 13; iter: 0; batch classifier loss: 0.434738; batch adversarial loss: 0.674240\n",
      "epoch 13; iter: 200; batch classifier loss: 0.376171; batch adversarial loss: 0.592767\n",
      "epoch 14; iter: 0; batch classifier loss: 0.383528; batch adversarial loss: 0.626724\n",
      "epoch 14; iter: 200; batch classifier loss: 0.326258; batch adversarial loss: 0.693683\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396106; batch adversarial loss: 0.601519\n",
      "epoch 15; iter: 200; batch classifier loss: 0.390705; batch adversarial loss: 0.640154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.422061; batch adversarial loss: 0.638160\n",
      "epoch 16; iter: 200; batch classifier loss: 0.352563; batch adversarial loss: 0.608982\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365753; batch adversarial loss: 0.577829\n",
      "epoch 17; iter: 200; batch classifier loss: 0.354386; batch adversarial loss: 0.588952\n",
      "epoch 18; iter: 0; batch classifier loss: 0.417767; batch adversarial loss: 0.622475\n",
      "epoch 18; iter: 200; batch classifier loss: 0.334141; batch adversarial loss: 0.601868\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325849; batch adversarial loss: 0.649894\n",
      "epoch 19; iter: 200; batch classifier loss: 0.358438; batch adversarial loss: 0.634011\n",
      "epoch 0; iter: 0; batch classifier loss: 98.208115; batch adversarial loss: 0.656115\n",
      "epoch 0; iter: 200; batch classifier loss: 3.256194; batch adversarial loss: 0.622718\n",
      "epoch 1; iter: 0; batch classifier loss: 16.241079; batch adversarial loss: 0.664935\n",
      "epoch 1; iter: 200; batch classifier loss: 4.708293; batch adversarial loss: 0.625600\n",
      "epoch 2; iter: 0; batch classifier loss: 6.338634; batch adversarial loss: 0.634082\n",
      "epoch 2; iter: 200; batch classifier loss: 6.928144; batch adversarial loss: 0.634422\n",
      "epoch 3; iter: 0; batch classifier loss: 1.171530; batch adversarial loss: 0.591432\n",
      "epoch 3; iter: 200; batch classifier loss: 4.766449; batch adversarial loss: 0.609801\n",
      "epoch 4; iter: 0; batch classifier loss: 8.340963; batch adversarial loss: 0.623719\n",
      "epoch 4; iter: 200; batch classifier loss: 1.578853; batch adversarial loss: 0.588039\n",
      "epoch 5; iter: 0; batch classifier loss: 0.846385; batch adversarial loss: 0.636270\n",
      "epoch 5; iter: 200; batch classifier loss: 2.668432; batch adversarial loss: 0.620351\n",
      "epoch 6; iter: 0; batch classifier loss: 3.093947; batch adversarial loss: 0.594913\n",
      "epoch 6; iter: 200; batch classifier loss: 0.458374; batch adversarial loss: 0.621246\n",
      "epoch 7; iter: 0; batch classifier loss: 0.665786; batch adversarial loss: 0.684147\n",
      "epoch 7; iter: 200; batch classifier loss: 0.682969; batch adversarial loss: 0.552356\n",
      "epoch 8; iter: 0; batch classifier loss: 0.972186; batch adversarial loss: 0.587012\n",
      "epoch 8; iter: 200; batch classifier loss: 0.512053; batch adversarial loss: 0.620677\n",
      "epoch 9; iter: 0; batch classifier loss: 0.390582; batch adversarial loss: 0.599703\n",
      "epoch 9; iter: 200; batch classifier loss: 0.533735; batch adversarial loss: 0.634117\n",
      "epoch 10; iter: 0; batch classifier loss: 0.405100; batch adversarial loss: 0.651527\n",
      "epoch 10; iter: 200; batch classifier loss: 0.499137; batch adversarial loss: 0.636850\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540839; batch adversarial loss: 0.569661\n",
      "epoch 11; iter: 200; batch classifier loss: 0.569587; batch adversarial loss: 0.556542\n",
      "epoch 12; iter: 0; batch classifier loss: 0.388202; batch adversarial loss: 0.582573\n",
      "epoch 12; iter: 200; batch classifier loss: 0.430425; batch adversarial loss: 0.626961\n",
      "epoch 13; iter: 0; batch classifier loss: 0.456680; batch adversarial loss: 0.640616\n",
      "epoch 13; iter: 200; batch classifier loss: 0.337932; batch adversarial loss: 0.586827\n",
      "epoch 14; iter: 0; batch classifier loss: 0.324601; batch adversarial loss: 0.664680\n",
      "epoch 14; iter: 200; batch classifier loss: 0.412563; batch adversarial loss: 0.615581\n",
      "epoch 15; iter: 0; batch classifier loss: 0.443940; batch adversarial loss: 0.605689\n",
      "epoch 15; iter: 200; batch classifier loss: 0.477801; batch adversarial loss: 0.585235\n",
      "epoch 16; iter: 0; batch classifier loss: 0.592342; batch adversarial loss: 0.608069\n",
      "epoch 16; iter: 200; batch classifier loss: 0.300859; batch adversarial loss: 0.682347\n",
      "epoch 17; iter: 0; batch classifier loss: 0.590309; batch adversarial loss: 0.681838\n",
      "epoch 17; iter: 200; batch classifier loss: 0.361313; batch adversarial loss: 0.663732\n",
      "epoch 18; iter: 0; batch classifier loss: 0.352153; batch adversarial loss: 0.622402\n",
      "epoch 18; iter: 200; batch classifier loss: 0.540636; batch adversarial loss: 0.675586\n",
      "epoch 19; iter: 0; batch classifier loss: 0.329288; batch adversarial loss: 0.585019\n",
      "epoch 19; iter: 200; batch classifier loss: 0.435279; batch adversarial loss: 0.613020\n",
      "epoch 0; iter: 0; batch classifier loss: 34.271370; batch adversarial loss: 0.706476\n",
      "epoch 0; iter: 200; batch classifier loss: 28.576292; batch adversarial loss: 0.659893\n",
      "epoch 1; iter: 0; batch classifier loss: 12.062210; batch adversarial loss: 0.656342\n",
      "epoch 1; iter: 200; batch classifier loss: 29.016171; batch adversarial loss: 0.654192\n",
      "epoch 2; iter: 0; batch classifier loss: 25.046074; batch adversarial loss: 0.673332\n",
      "epoch 2; iter: 200; batch classifier loss: 5.015330; batch adversarial loss: 0.644431\n",
      "epoch 3; iter: 0; batch classifier loss: 2.575746; batch adversarial loss: 0.628614\n",
      "epoch 3; iter: 200; batch classifier loss: 4.034810; batch adversarial loss: 0.636479\n",
      "epoch 4; iter: 0; batch classifier loss: 7.382290; batch adversarial loss: 0.606768\n",
      "epoch 4; iter: 200; batch classifier loss: 2.597181; batch adversarial loss: 0.605693\n",
      "epoch 5; iter: 0; batch classifier loss: 8.220802; batch adversarial loss: 0.640127\n",
      "epoch 5; iter: 200; batch classifier loss: 3.057576; batch adversarial loss: 0.632815\n",
      "epoch 6; iter: 0; batch classifier loss: 1.390235; batch adversarial loss: 0.593412\n",
      "epoch 6; iter: 200; batch classifier loss: 0.727483; batch adversarial loss: 0.585254\n",
      "epoch 7; iter: 0; batch classifier loss: 3.532828; batch adversarial loss: 0.631438\n",
      "epoch 7; iter: 200; batch classifier loss: 1.294672; batch adversarial loss: 0.587612\n",
      "epoch 8; iter: 0; batch classifier loss: 0.621278; batch adversarial loss: 0.687613\n",
      "epoch 8; iter: 200; batch classifier loss: 1.188015; batch adversarial loss: 0.593626\n",
      "epoch 9; iter: 0; batch classifier loss: 0.796430; batch adversarial loss: 0.588607\n",
      "epoch 9; iter: 200; batch classifier loss: 0.651368; batch adversarial loss: 0.608988\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570982; batch adversarial loss: 0.681548\n",
      "epoch 10; iter: 200; batch classifier loss: 0.448290; batch adversarial loss: 0.614974\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403021; batch adversarial loss: 0.577373\n",
      "epoch 11; iter: 200; batch classifier loss: 0.466021; batch adversarial loss: 0.631915\n",
      "epoch 12; iter: 0; batch classifier loss: 0.458305; batch adversarial loss: 0.574739\n",
      "epoch 12; iter: 200; batch classifier loss: 0.421636; batch adversarial loss: 0.597045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.468554; batch adversarial loss: 0.594377\n",
      "epoch 13; iter: 200; batch classifier loss: 0.390034; batch adversarial loss: 0.666653\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301106; batch adversarial loss: 0.610163\n",
      "epoch 14; iter: 200; batch classifier loss: 0.375131; batch adversarial loss: 0.633381\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496204; batch adversarial loss: 0.735051\n",
      "epoch 15; iter: 200; batch classifier loss: 0.435593; batch adversarial loss: 0.567990\n",
      "epoch 16; iter: 0; batch classifier loss: 0.309153; batch adversarial loss: 0.636623\n",
      "epoch 16; iter: 200; batch classifier loss: 0.347108; batch adversarial loss: 0.558965\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327883; batch adversarial loss: 0.609645\n",
      "epoch 17; iter: 200; batch classifier loss: 0.397899; batch adversarial loss: 0.616640\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349797; batch adversarial loss: 0.623994\n",
      "epoch 18; iter: 200; batch classifier loss: 0.353651; batch adversarial loss: 0.645900\n",
      "epoch 19; iter: 0; batch classifier loss: 0.351185; batch adversarial loss: 0.572878\n",
      "epoch 19; iter: 200; batch classifier loss: 0.352092; batch adversarial loss: 0.589354\n",
      "epoch 0; iter: 0; batch classifier loss: 50.899536; batch adversarial loss: 0.656452\n",
      "epoch 0; iter: 200; batch classifier loss: 10.244067; batch adversarial loss: 0.624312\n",
      "epoch 1; iter: 0; batch classifier loss: 3.544789; batch adversarial loss: 0.629757\n",
      "epoch 1; iter: 200; batch classifier loss: 9.196810; batch adversarial loss: 0.639722\n",
      "epoch 2; iter: 0; batch classifier loss: 2.337172; batch adversarial loss: 0.608029\n",
      "epoch 2; iter: 200; batch classifier loss: 2.695221; batch adversarial loss: 0.689962\n",
      "epoch 3; iter: 0; batch classifier loss: 0.931159; batch adversarial loss: 0.614763\n",
      "epoch 3; iter: 200; batch classifier loss: 2.647563; batch adversarial loss: 0.669396\n",
      "epoch 4; iter: 0; batch classifier loss: 2.327713; batch adversarial loss: 0.616118\n",
      "epoch 4; iter: 200; batch classifier loss: 2.180533; batch adversarial loss: 0.605803\n",
      "epoch 5; iter: 0; batch classifier loss: 0.839125; batch adversarial loss: 0.632722\n",
      "epoch 5; iter: 200; batch classifier loss: 1.404952; batch adversarial loss: 0.619789\n",
      "epoch 6; iter: 0; batch classifier loss: 2.359578; batch adversarial loss: 0.648099\n",
      "epoch 6; iter: 200; batch classifier loss: 1.323564; batch adversarial loss: 0.597562\n",
      "epoch 7; iter: 0; batch classifier loss: 1.520685; batch adversarial loss: 0.647565\n",
      "epoch 7; iter: 200; batch classifier loss: 0.810330; batch adversarial loss: 0.628386\n",
      "epoch 8; iter: 0; batch classifier loss: 0.802825; batch adversarial loss: 0.638996\n",
      "epoch 8; iter: 200; batch classifier loss: 0.899571; batch adversarial loss: 0.597022\n",
      "epoch 9; iter: 0; batch classifier loss: 0.618899; batch adversarial loss: 0.623430\n",
      "epoch 9; iter: 200; batch classifier loss: 0.751248; batch adversarial loss: 0.632209\n",
      "epoch 10; iter: 0; batch classifier loss: 0.382377; batch adversarial loss: 0.560515\n",
      "epoch 10; iter: 200; batch classifier loss: 1.424029; batch adversarial loss: 0.613421\n",
      "epoch 11; iter: 0; batch classifier loss: 0.415960; batch adversarial loss: 0.637671\n",
      "epoch 11; iter: 200; batch classifier loss: 0.309013; batch adversarial loss: 0.619373\n",
      "epoch 12; iter: 0; batch classifier loss: 0.445999; batch adversarial loss: 0.586365\n",
      "epoch 12; iter: 200; batch classifier loss: 0.359112; batch adversarial loss: 0.551677\n",
      "epoch 13; iter: 0; batch classifier loss: 0.425600; batch adversarial loss: 0.655848\n",
      "epoch 13; iter: 200; batch classifier loss: 0.443114; batch adversarial loss: 0.625973\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519803; batch adversarial loss: 0.671261\n",
      "epoch 14; iter: 200; batch classifier loss: 0.588763; batch adversarial loss: 0.614326\n",
      "epoch 15; iter: 0; batch classifier loss: 0.477725; batch adversarial loss: 0.574494\n",
      "epoch 15; iter: 200; batch classifier loss: 0.454633; batch adversarial loss: 0.645105\n",
      "epoch 16; iter: 0; batch classifier loss: 0.466916; batch adversarial loss: 0.651613\n",
      "epoch 16; iter: 200; batch classifier loss: 0.464976; batch adversarial loss: 0.643695\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397875; batch adversarial loss: 0.575839\n",
      "epoch 17; iter: 200; batch classifier loss: 0.374296; batch adversarial loss: 0.592104\n",
      "epoch 18; iter: 0; batch classifier loss: 0.318775; batch adversarial loss: 0.599687\n",
      "epoch 18; iter: 200; batch classifier loss: 0.376303; batch adversarial loss: 0.576020\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374198; batch adversarial loss: 0.709321\n",
      "epoch 19; iter: 200; batch classifier loss: 0.270311; batch adversarial loss: 0.548024\n",
      "epoch 0; iter: 0; batch classifier loss: 21.905144; batch adversarial loss: 0.684895\n",
      "epoch 0; iter: 200; batch classifier loss: 28.300228; batch adversarial loss: 0.638158\n",
      "epoch 1; iter: 0; batch classifier loss: 15.842225; batch adversarial loss: 0.655489\n",
      "epoch 1; iter: 200; batch classifier loss: 4.435060; batch adversarial loss: 0.625070\n",
      "epoch 2; iter: 0; batch classifier loss: 12.337608; batch adversarial loss: 0.609041\n",
      "epoch 2; iter: 200; batch classifier loss: 4.520192; batch adversarial loss: 0.570367\n",
      "epoch 3; iter: 0; batch classifier loss: 2.847095; batch adversarial loss: 0.617814\n",
      "epoch 3; iter: 200; batch classifier loss: 12.749147; batch adversarial loss: 0.608788\n",
      "epoch 4; iter: 0; batch classifier loss: 5.274628; batch adversarial loss: 0.606538\n",
      "epoch 4; iter: 200; batch classifier loss: 3.466201; batch adversarial loss: 0.591884\n",
      "epoch 5; iter: 0; batch classifier loss: 3.985698; batch adversarial loss: 0.646479\n",
      "epoch 5; iter: 200; batch classifier loss: 2.112907; batch adversarial loss: 0.636327\n",
      "epoch 6; iter: 0; batch classifier loss: 1.925037; batch adversarial loss: 0.635390\n",
      "epoch 6; iter: 200; batch classifier loss: 2.340261; batch adversarial loss: 0.640219\n",
      "epoch 7; iter: 0; batch classifier loss: 0.824189; batch adversarial loss: 0.627124\n",
      "epoch 7; iter: 200; batch classifier loss: 1.220999; batch adversarial loss: 0.703671\n",
      "epoch 8; iter: 0; batch classifier loss: 0.791170; batch adversarial loss: 0.596046\n",
      "epoch 8; iter: 200; batch classifier loss: 0.688673; batch adversarial loss: 0.641441\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591476; batch adversarial loss: 0.606770\n",
      "epoch 9; iter: 200; batch classifier loss: 0.338364; batch adversarial loss: 0.604994\n",
      "epoch 10; iter: 0; batch classifier loss: 0.625708; batch adversarial loss: 0.646503\n",
      "epoch 10; iter: 200; batch classifier loss: 0.445369; batch adversarial loss: 0.647758\n",
      "epoch 11; iter: 0; batch classifier loss: 0.455230; batch adversarial loss: 0.607940\n",
      "epoch 11; iter: 200; batch classifier loss: 0.460762; batch adversarial loss: 0.561369\n",
      "epoch 12; iter: 0; batch classifier loss: 0.446088; batch adversarial loss: 0.627204\n",
      "epoch 12; iter: 200; batch classifier loss: 0.389890; batch adversarial loss: 0.648744\n",
      "epoch 13; iter: 0; batch classifier loss: 0.436395; batch adversarial loss: 0.607043\n",
      "epoch 13; iter: 200; batch classifier loss: 0.359205; batch adversarial loss: 0.575238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484117; batch adversarial loss: 0.653211\n",
      "epoch 14; iter: 200; batch classifier loss: 0.473901; batch adversarial loss: 0.600462\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372706; batch adversarial loss: 0.612138\n",
      "epoch 15; iter: 200; batch classifier loss: 0.341826; batch adversarial loss: 0.610265\n",
      "epoch 16; iter: 0; batch classifier loss: 0.383881; batch adversarial loss: 0.641976\n",
      "epoch 16; iter: 200; batch classifier loss: 0.349040; batch adversarial loss: 0.675142\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327923; batch adversarial loss: 0.596170\n",
      "epoch 17; iter: 200; batch classifier loss: 0.328114; batch adversarial loss: 0.617855\n",
      "epoch 18; iter: 0; batch classifier loss: 0.340430; batch adversarial loss: 0.641783\n",
      "epoch 18; iter: 200; batch classifier loss: 0.310010; batch adversarial loss: 0.625309\n",
      "epoch 19; iter: 0; batch classifier loss: 0.278451; batch adversarial loss: 0.596947\n",
      "epoch 19; iter: 200; batch classifier loss: 0.352473; batch adversarial loss: 0.612144\n",
      "epoch 0; iter: 0; batch classifier loss: 20.708984; batch adversarial loss: 0.652205\n",
      "epoch 0; iter: 200; batch classifier loss: 86.414543; batch adversarial loss: 0.719423\n",
      "epoch 1; iter: 0; batch classifier loss: 6.646191; batch adversarial loss: 0.661360\n",
      "epoch 1; iter: 200; batch classifier loss: 4.716245; batch adversarial loss: 0.687771\n",
      "epoch 2; iter: 0; batch classifier loss: 6.259249; batch adversarial loss: 0.726662\n",
      "epoch 2; iter: 200; batch classifier loss: 3.883411; batch adversarial loss: 0.710942\n",
      "epoch 3; iter: 0; batch classifier loss: 1.474797; batch adversarial loss: 0.716853\n",
      "epoch 3; iter: 200; batch classifier loss: 5.491617; batch adversarial loss: 0.673448\n",
      "epoch 4; iter: 0; batch classifier loss: 2.524527; batch adversarial loss: 0.640491\n",
      "epoch 4; iter: 200; batch classifier loss: 1.063695; batch adversarial loss: 0.661467\n",
      "epoch 5; iter: 0; batch classifier loss: 1.827877; batch adversarial loss: 0.647890\n",
      "epoch 5; iter: 200; batch classifier loss: 1.381766; batch adversarial loss: 0.588307\n",
      "epoch 6; iter: 0; batch classifier loss: 1.764358; batch adversarial loss: 0.595559\n",
      "epoch 6; iter: 200; batch classifier loss: 3.291475; batch adversarial loss: 0.596206\n",
      "epoch 7; iter: 0; batch classifier loss: 1.225857; batch adversarial loss: 0.591965\n",
      "epoch 7; iter: 200; batch classifier loss: 1.006436; batch adversarial loss: 0.595858\n",
      "epoch 8; iter: 0; batch classifier loss: 0.790192; batch adversarial loss: 0.591560\n",
      "epoch 8; iter: 200; batch classifier loss: 0.619102; batch adversarial loss: 0.618107\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589586; batch adversarial loss: 0.602481\n",
      "epoch 9; iter: 200; batch classifier loss: 0.551653; batch adversarial loss: 0.652602\n",
      "epoch 10; iter: 0; batch classifier loss: 0.448825; batch adversarial loss: 0.603715\n",
      "epoch 10; iter: 200; batch classifier loss: 0.417263; batch adversarial loss: 0.619129\n",
      "epoch 11; iter: 0; batch classifier loss: 0.435671; batch adversarial loss: 0.641826\n",
      "epoch 11; iter: 200; batch classifier loss: 0.516478; batch adversarial loss: 0.612189\n",
      "epoch 12; iter: 0; batch classifier loss: 0.389133; batch adversarial loss: 0.608128\n",
      "epoch 12; iter: 200; batch classifier loss: 0.404107; batch adversarial loss: 0.640175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.380073; batch adversarial loss: 0.581176\n",
      "epoch 13; iter: 200; batch classifier loss: 0.402155; batch adversarial loss: 0.590880\n",
      "epoch 14; iter: 0; batch classifier loss: 0.401259; batch adversarial loss: 0.665920\n",
      "epoch 14; iter: 200; batch classifier loss: 0.458518; batch adversarial loss: 0.645865\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382431; batch adversarial loss: 0.632042\n",
      "epoch 15; iter: 200; batch classifier loss: 0.363985; batch adversarial loss: 0.596035\n",
      "epoch 16; iter: 0; batch classifier loss: 0.334112; batch adversarial loss: 0.648593\n",
      "epoch 16; iter: 200; batch classifier loss: 0.400531; batch adversarial loss: 0.622434\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391051; batch adversarial loss: 0.574221\n",
      "epoch 17; iter: 200; batch classifier loss: 0.390712; batch adversarial loss: 0.618947\n",
      "epoch 18; iter: 0; batch classifier loss: 0.316384; batch adversarial loss: 0.603271\n",
      "epoch 18; iter: 200; batch classifier loss: 0.397787; batch adversarial loss: 0.579698\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426280; batch adversarial loss: 0.570727\n",
      "epoch 19; iter: 200; batch classifier loss: 0.358103; batch adversarial loss: 0.619465\n",
      "epoch 0; iter: 0; batch classifier loss: 146.987976; batch adversarial loss: 0.657775\n",
      "epoch 0; iter: 200; batch classifier loss: 14.666306; batch adversarial loss: 0.677493\n",
      "epoch 1; iter: 0; batch classifier loss: 9.212300; batch adversarial loss: 0.670637\n",
      "epoch 1; iter: 200; batch classifier loss: 6.165460; batch adversarial loss: 0.670259\n",
      "epoch 2; iter: 0; batch classifier loss: 3.129982; batch adversarial loss: 0.647167\n",
      "epoch 2; iter: 200; batch classifier loss: 3.882195; batch adversarial loss: 0.655647\n",
      "epoch 3; iter: 0; batch classifier loss: 6.159713; batch adversarial loss: 0.603672\n",
      "epoch 3; iter: 200; batch classifier loss: 4.190627; batch adversarial loss: 0.637202\n",
      "epoch 4; iter: 0; batch classifier loss: 3.710424; batch adversarial loss: 0.648276\n",
      "epoch 4; iter: 200; batch classifier loss: 2.863502; batch adversarial loss: 0.649210\n",
      "epoch 5; iter: 0; batch classifier loss: 1.896151; batch adversarial loss: 0.618866\n",
      "epoch 5; iter: 200; batch classifier loss: 3.145056; batch adversarial loss: 0.636274\n",
      "epoch 6; iter: 0; batch classifier loss: 2.527202; batch adversarial loss: 0.628386\n",
      "epoch 6; iter: 200; batch classifier loss: 1.926878; batch adversarial loss: 0.542233\n",
      "epoch 7; iter: 0; batch classifier loss: 1.919273; batch adversarial loss: 0.623196\n",
      "epoch 7; iter: 200; batch classifier loss: 0.838340; batch adversarial loss: 0.623566\n",
      "epoch 8; iter: 0; batch classifier loss: 1.300575; batch adversarial loss: 0.649381\n",
      "epoch 8; iter: 200; batch classifier loss: 0.653858; batch adversarial loss: 0.661835\n",
      "epoch 9; iter: 0; batch classifier loss: 0.934006; batch adversarial loss: 0.598234\n",
      "epoch 9; iter: 200; batch classifier loss: 0.467206; batch adversarial loss: 0.617451\n",
      "epoch 10; iter: 0; batch classifier loss: 0.270040; batch adversarial loss: 0.658242\n",
      "epoch 10; iter: 200; batch classifier loss: 0.345229; batch adversarial loss: 0.534300\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465814; batch adversarial loss: 0.599283\n",
      "epoch 11; iter: 200; batch classifier loss: 0.426017; batch adversarial loss: 0.675308\n",
      "epoch 12; iter: 0; batch classifier loss: 0.495612; batch adversarial loss: 0.581375\n",
      "epoch 12; iter: 200; batch classifier loss: 0.315055; batch adversarial loss: 0.620344\n",
      "epoch 13; iter: 0; batch classifier loss: 0.374218; batch adversarial loss: 0.609577\n",
      "epoch 13; iter: 200; batch classifier loss: 0.300574; batch adversarial loss: 0.644648\n",
      "epoch 14; iter: 0; batch classifier loss: 0.285812; batch adversarial loss: 0.559418\n",
      "epoch 14; iter: 200; batch classifier loss: 0.341604; batch adversarial loss: 0.680012\n",
      "epoch 15; iter: 0; batch classifier loss: 0.350771; batch adversarial loss: 0.648919\n",
      "epoch 15; iter: 200; batch classifier loss: 0.411149; batch adversarial loss: 0.584933\n",
      "epoch 16; iter: 0; batch classifier loss: 0.308107; batch adversarial loss: 0.626504\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357794; batch adversarial loss: 0.545280\n",
      "epoch 17; iter: 0; batch classifier loss: 0.372523; batch adversarial loss: 0.650642\n",
      "epoch 17; iter: 200; batch classifier loss: 0.378950; batch adversarial loss: 0.669011\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322171; batch adversarial loss: 0.633312\n",
      "epoch 18; iter: 200; batch classifier loss: 0.323600; batch adversarial loss: 0.637881\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327789; batch adversarial loss: 0.656098\n",
      "epoch 19; iter: 200; batch classifier loss: 0.386079; batch adversarial loss: 0.582272\n",
      "epoch 0; iter: 0; batch classifier loss: 29.994789; batch adversarial loss: 0.721085\n",
      "epoch 0; iter: 200; batch classifier loss: 5.102603; batch adversarial loss: 0.659815\n",
      "epoch 1; iter: 0; batch classifier loss: 9.808339; batch adversarial loss: 0.645945\n",
      "epoch 1; iter: 200; batch classifier loss: 7.163230; batch adversarial loss: 0.646167\n",
      "epoch 2; iter: 0; batch classifier loss: 11.062742; batch adversarial loss: 0.639578\n",
      "epoch 2; iter: 200; batch classifier loss: 5.947624; batch adversarial loss: 0.598263\n",
      "epoch 3; iter: 0; batch classifier loss: 4.455270; batch adversarial loss: 0.623837\n",
      "epoch 3; iter: 200; batch classifier loss: 1.985955; batch adversarial loss: 0.635612\n",
      "epoch 4; iter: 0; batch classifier loss: 4.345160; batch adversarial loss: 0.643839\n",
      "epoch 4; iter: 200; batch classifier loss: 1.754065; batch adversarial loss: 0.716720\n",
      "epoch 5; iter: 0; batch classifier loss: 0.948128; batch adversarial loss: 0.649610\n",
      "epoch 5; iter: 200; batch classifier loss: 1.296927; batch adversarial loss: 0.579861\n",
      "epoch 6; iter: 0; batch classifier loss: 1.043891; batch adversarial loss: 0.593415\n",
      "epoch 6; iter: 200; batch classifier loss: 1.049933; batch adversarial loss: 0.638531\n",
      "epoch 7; iter: 0; batch classifier loss: 0.568746; batch adversarial loss: 0.641736\n",
      "epoch 7; iter: 200; batch classifier loss: 0.734374; batch adversarial loss: 0.620090\n",
      "epoch 8; iter: 0; batch classifier loss: 0.719021; batch adversarial loss: 0.648119\n",
      "epoch 8; iter: 200; batch classifier loss: 0.510663; batch adversarial loss: 0.619131\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564291; batch adversarial loss: 0.662788\n",
      "epoch 9; iter: 200; batch classifier loss: 0.423695; batch adversarial loss: 0.628339\n",
      "epoch 10; iter: 0; batch classifier loss: 0.484181; batch adversarial loss: 0.615396\n",
      "epoch 10; iter: 200; batch classifier loss: 0.425280; batch adversarial loss: 0.643758\n",
      "epoch 11; iter: 0; batch classifier loss: 0.443962; batch adversarial loss: 0.618437\n",
      "epoch 11; iter: 200; batch classifier loss: 0.470216; batch adversarial loss: 0.633783\n",
      "epoch 12; iter: 0; batch classifier loss: 0.423144; batch adversarial loss: 0.650590\n",
      "epoch 12; iter: 200; batch classifier loss: 0.324268; batch adversarial loss: 0.653545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.551915; batch adversarial loss: 0.608881\n",
      "epoch 13; iter: 200; batch classifier loss: 0.447275; batch adversarial loss: 0.608855\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485720; batch adversarial loss: 0.636377\n",
      "epoch 14; iter: 200; batch classifier loss: 0.430261; batch adversarial loss: 0.550032\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347163; batch adversarial loss: 0.616434\n",
      "epoch 15; iter: 200; batch classifier loss: 0.347383; batch adversarial loss: 0.575055\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356876; batch adversarial loss: 0.611832\n",
      "epoch 16; iter: 200; batch classifier loss: 0.275527; batch adversarial loss: 0.622769\n",
      "epoch 17; iter: 0; batch classifier loss: 0.440980; batch adversarial loss: 0.630763\n",
      "epoch 17; iter: 200; batch classifier loss: 0.338339; batch adversarial loss: 0.646796\n",
      "epoch 18; iter: 0; batch classifier loss: 0.404145; batch adversarial loss: 0.656678\n",
      "epoch 18; iter: 200; batch classifier loss: 0.318492; batch adversarial loss: 0.634400\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338144; batch adversarial loss: 0.560146\n",
      "epoch 19; iter: 200; batch classifier loss: 0.409524; batch adversarial loss: 0.591361\n",
      "Testing config: {'adversary_loss_weight': 0.5, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 16.420403; batch adversarial loss: 0.787166\n",
      "epoch 0; iter: 200; batch classifier loss: 7.796494; batch adversarial loss: 0.675827\n",
      "epoch 1; iter: 0; batch classifier loss: 17.443636; batch adversarial loss: 0.679369\n",
      "epoch 1; iter: 200; batch classifier loss: 4.216164; batch adversarial loss: 0.643049\n",
      "epoch 2; iter: 0; batch classifier loss: 5.055449; batch adversarial loss: 0.645670\n",
      "epoch 2; iter: 200; batch classifier loss: 2.771514; batch adversarial loss: 0.621191\n",
      "epoch 3; iter: 0; batch classifier loss: 2.679122; batch adversarial loss: 0.615110\n",
      "epoch 3; iter: 200; batch classifier loss: 5.723858; batch adversarial loss: 0.581031\n",
      "epoch 4; iter: 0; batch classifier loss: 2.793751; batch adversarial loss: 0.591026\n",
      "epoch 4; iter: 200; batch classifier loss: 2.258089; batch adversarial loss: 0.591993\n",
      "epoch 5; iter: 0; batch classifier loss: 3.036992; batch adversarial loss: 0.611863\n",
      "epoch 5; iter: 200; batch classifier loss: 1.332762; batch adversarial loss: 0.579551\n",
      "epoch 6; iter: 0; batch classifier loss: 3.608231; batch adversarial loss: 0.561608\n",
      "epoch 6; iter: 200; batch classifier loss: 0.648191; batch adversarial loss: 0.663074\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538154; batch adversarial loss: 0.615288\n",
      "epoch 7; iter: 200; batch classifier loss: 1.250576; batch adversarial loss: 0.623823\n",
      "epoch 8; iter: 0; batch classifier loss: 0.598823; batch adversarial loss: 0.613395\n",
      "epoch 8; iter: 200; batch classifier loss: 0.844534; batch adversarial loss: 0.606531\n",
      "epoch 9; iter: 0; batch classifier loss: 0.451347; batch adversarial loss: 0.659450\n",
      "epoch 9; iter: 200; batch classifier loss: 0.383842; batch adversarial loss: 0.643134\n",
      "epoch 10; iter: 0; batch classifier loss: 0.627002; batch adversarial loss: 0.608638\n",
      "epoch 10; iter: 200; batch classifier loss: 0.503538; batch adversarial loss: 0.605186\n",
      "epoch 11; iter: 0; batch classifier loss: 0.456130; batch adversarial loss: 0.627786\n",
      "epoch 11; iter: 200; batch classifier loss: 0.451562; batch adversarial loss: 0.645344\n",
      "epoch 12; iter: 0; batch classifier loss: 0.493562; batch adversarial loss: 0.597073\n",
      "epoch 12; iter: 200; batch classifier loss: 0.494661; batch adversarial loss: 0.627325\n",
      "epoch 13; iter: 0; batch classifier loss: 0.414731; batch adversarial loss: 0.640293\n",
      "epoch 13; iter: 200; batch classifier loss: 0.354237; batch adversarial loss: 0.646392\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384039; batch adversarial loss: 0.649068\n",
      "epoch 14; iter: 200; batch classifier loss: 0.368668; batch adversarial loss: 0.603139\n",
      "epoch 15; iter: 0; batch classifier loss: 0.417520; batch adversarial loss: 0.636818\n",
      "epoch 15; iter: 200; batch classifier loss: 0.319733; batch adversarial loss: 0.642146\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419127; batch adversarial loss: 0.643335\n",
      "epoch 16; iter: 200; batch classifier loss: 0.432314; batch adversarial loss: 0.639567\n",
      "epoch 17; iter: 0; batch classifier loss: 0.382971; batch adversarial loss: 0.598825\n",
      "epoch 17; iter: 200; batch classifier loss: 0.331824; batch adversarial loss: 0.679320\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331781; batch adversarial loss: 0.623670\n",
      "epoch 18; iter: 200; batch classifier loss: 0.337832; batch adversarial loss: 0.631716\n",
      "epoch 19; iter: 0; batch classifier loss: 0.415858; batch adversarial loss: 0.590339\n",
      "epoch 19; iter: 200; batch classifier loss: 0.405158; batch adversarial loss: 0.619470\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333059; batch adversarial loss: 0.575529\n",
      "epoch 20; iter: 200; batch classifier loss: 0.466320; batch adversarial loss: 0.645116\n",
      "epoch 21; iter: 0; batch classifier loss: 0.315770; batch adversarial loss: 0.658560\n",
      "epoch 21; iter: 200; batch classifier loss: 0.344879; batch adversarial loss: 0.618454\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437851; batch adversarial loss: 0.573347\n",
      "epoch 22; iter: 200; batch classifier loss: 0.305408; batch adversarial loss: 0.656138\n",
      "epoch 23; iter: 0; batch classifier loss: 0.333291; batch adversarial loss: 0.625197\n",
      "epoch 23; iter: 200; batch classifier loss: 0.308620; batch adversarial loss: 0.661379\n",
      "epoch 24; iter: 0; batch classifier loss: 0.364107; batch adversarial loss: 0.621000\n",
      "epoch 24; iter: 200; batch classifier loss: 0.369353; batch adversarial loss: 0.647074\n",
      "epoch 25; iter: 0; batch classifier loss: 0.394103; batch adversarial loss: 0.570850\n",
      "epoch 25; iter: 200; batch classifier loss: 0.318926; batch adversarial loss: 0.624959\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453454; batch adversarial loss: 0.615412\n",
      "epoch 26; iter: 200; batch classifier loss: 0.299476; batch adversarial loss: 0.651132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.321648; batch adversarial loss: 0.648599\n",
      "epoch 27; iter: 200; batch classifier loss: 0.307150; batch adversarial loss: 0.595998\n",
      "epoch 28; iter: 0; batch classifier loss: 0.437012; batch adversarial loss: 0.593805\n",
      "epoch 28; iter: 200; batch classifier loss: 0.346401; batch adversarial loss: 0.634577\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388325; batch adversarial loss: 0.629607\n",
      "epoch 29; iter: 200; batch classifier loss: 0.379915; batch adversarial loss: 0.615533\n",
      "epoch 30; iter: 0; batch classifier loss: 0.333699; batch adversarial loss: 0.619883\n",
      "epoch 30; iter: 200; batch classifier loss: 0.429177; batch adversarial loss: 0.635459\n",
      "epoch 31; iter: 0; batch classifier loss: 0.407553; batch adversarial loss: 0.534875\n",
      "epoch 31; iter: 200; batch classifier loss: 0.315818; batch adversarial loss: 0.636930\n",
      "epoch 32; iter: 0; batch classifier loss: 0.370816; batch adversarial loss: 0.666101\n",
      "epoch 32; iter: 200; batch classifier loss: 0.275735; batch adversarial loss: 0.617626\n",
      "epoch 33; iter: 0; batch classifier loss: 0.391728; batch adversarial loss: 0.587027\n",
      "epoch 33; iter: 200; batch classifier loss: 0.436535; batch adversarial loss: 0.580850\n",
      "epoch 34; iter: 0; batch classifier loss: 0.333064; batch adversarial loss: 0.596157\n",
      "epoch 34; iter: 200; batch classifier loss: 0.376284; batch adversarial loss: 0.613005\n",
      "epoch 35; iter: 0; batch classifier loss: 0.310087; batch adversarial loss: 0.568683\n",
      "epoch 35; iter: 200; batch classifier loss: 0.351502; batch adversarial loss: 0.637253\n",
      "epoch 36; iter: 0; batch classifier loss: 0.314369; batch adversarial loss: 0.661146\n",
      "epoch 36; iter: 200; batch classifier loss: 0.339716; batch adversarial loss: 0.613215\n",
      "epoch 37; iter: 0; batch classifier loss: 0.340644; batch adversarial loss: 0.616192\n",
      "epoch 37; iter: 200; batch classifier loss: 0.404348; batch adversarial loss: 0.560982\n",
      "epoch 38; iter: 0; batch classifier loss: 0.322187; batch adversarial loss: 0.601560\n",
      "epoch 38; iter: 200; batch classifier loss: 0.338663; batch adversarial loss: 0.629894\n",
      "epoch 39; iter: 0; batch classifier loss: 0.304075; batch adversarial loss: 0.746766\n",
      "epoch 39; iter: 200; batch classifier loss: 0.273443; batch adversarial loss: 0.612175\n",
      "epoch 40; iter: 0; batch classifier loss: 0.409722; batch adversarial loss: 0.624012\n",
      "epoch 40; iter: 200; batch classifier loss: 0.369135; batch adversarial loss: 0.621130\n",
      "epoch 41; iter: 0; batch classifier loss: 0.416282; batch adversarial loss: 0.613847\n",
      "epoch 41; iter: 200; batch classifier loss: 0.368584; batch adversarial loss: 0.600067\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419238; batch adversarial loss: 0.602377\n",
      "epoch 42; iter: 200; batch classifier loss: 0.386947; batch adversarial loss: 0.587492\n",
      "epoch 43; iter: 0; batch classifier loss: 0.320756; batch adversarial loss: 0.617708\n",
      "epoch 43; iter: 200; batch classifier loss: 0.387299; batch adversarial loss: 0.593734\n",
      "epoch 44; iter: 0; batch classifier loss: 0.345884; batch adversarial loss: 0.628398\n",
      "epoch 44; iter: 200; batch classifier loss: 0.325347; batch adversarial loss: 0.586530\n",
      "epoch 45; iter: 0; batch classifier loss: 0.362027; batch adversarial loss: 0.663188\n",
      "epoch 45; iter: 200; batch classifier loss: 0.281187; batch adversarial loss: 0.615554\n",
      "epoch 46; iter: 0; batch classifier loss: 0.395091; batch adversarial loss: 0.621337\n",
      "epoch 46; iter: 200; batch classifier loss: 0.331620; batch adversarial loss: 0.665253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.261554; batch adversarial loss: 0.607056\n",
      "epoch 47; iter: 200; batch classifier loss: 0.341978; batch adversarial loss: 0.615548\n",
      "epoch 48; iter: 0; batch classifier loss: 0.386953; batch adversarial loss: 0.562063\n",
      "epoch 48; iter: 200; batch classifier loss: 0.342889; batch adversarial loss: 0.596620\n",
      "epoch 49; iter: 0; batch classifier loss: 0.474948; batch adversarial loss: 0.649849\n",
      "epoch 49; iter: 200; batch classifier loss: 0.335794; batch adversarial loss: 0.613003\n",
      "epoch 0; iter: 0; batch classifier loss: 48.927017; batch adversarial loss: 0.700643\n",
      "epoch 0; iter: 200; batch classifier loss: 11.324237; batch adversarial loss: 0.665725\n",
      "epoch 1; iter: 0; batch classifier loss: 16.317719; batch adversarial loss: 0.631302\n",
      "epoch 1; iter: 200; batch classifier loss: 4.293815; batch adversarial loss: 0.675114\n",
      "epoch 2; iter: 0; batch classifier loss: 4.921060; batch adversarial loss: 0.626008\n",
      "epoch 2; iter: 200; batch classifier loss: 4.739608; batch adversarial loss: 0.653449\n",
      "epoch 3; iter: 0; batch classifier loss: 3.535731; batch adversarial loss: 0.658980\n",
      "epoch 3; iter: 200; batch classifier loss: 2.550510; batch adversarial loss: 0.560397\n",
      "epoch 4; iter: 0; batch classifier loss: 1.792471; batch adversarial loss: 0.665087\n",
      "epoch 4; iter: 200; batch classifier loss: 3.854051; batch adversarial loss: 0.599812\n",
      "epoch 5; iter: 0; batch classifier loss: 2.773601; batch adversarial loss: 0.677283\n",
      "epoch 5; iter: 200; batch classifier loss: 1.209758; batch adversarial loss: 0.584179\n",
      "epoch 6; iter: 0; batch classifier loss: 2.295079; batch adversarial loss: 0.665701\n",
      "epoch 6; iter: 200; batch classifier loss: 0.756492; batch adversarial loss: 0.650670\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490711; batch adversarial loss: 0.634586\n",
      "epoch 7; iter: 200; batch classifier loss: 0.505182; batch adversarial loss: 0.658923\n",
      "epoch 8; iter: 0; batch classifier loss: 0.875441; batch adversarial loss: 0.596359\n",
      "epoch 8; iter: 200; batch classifier loss: 0.460388; batch adversarial loss: 0.585496\n",
      "epoch 9; iter: 0; batch classifier loss: 0.625876; batch adversarial loss: 0.630184\n",
      "epoch 9; iter: 200; batch classifier loss: 0.542789; batch adversarial loss: 0.609211\n",
      "epoch 10; iter: 0; batch classifier loss: 0.482539; batch adversarial loss: 0.616941\n",
      "epoch 10; iter: 200; batch classifier loss: 0.419833; batch adversarial loss: 0.662820\n",
      "epoch 11; iter: 0; batch classifier loss: 0.662514; batch adversarial loss: 0.620544\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383238; batch adversarial loss: 0.703583\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413217; batch adversarial loss: 0.632079\n",
      "epoch 12; iter: 200; batch classifier loss: 0.408186; batch adversarial loss: 0.611447\n",
      "epoch 13; iter: 0; batch classifier loss: 0.433417; batch adversarial loss: 0.593848\n",
      "epoch 13; iter: 200; batch classifier loss: 0.581347; batch adversarial loss: 0.534109\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394641; batch adversarial loss: 0.650170\n",
      "epoch 14; iter: 200; batch classifier loss: 0.371056; batch adversarial loss: 0.624465\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376926; batch adversarial loss: 0.593938\n",
      "epoch 15; iter: 200; batch classifier loss: 0.391003; batch adversarial loss: 0.609453\n",
      "epoch 16; iter: 0; batch classifier loss: 0.368113; batch adversarial loss: 0.608675\n",
      "epoch 16; iter: 200; batch classifier loss: 0.358018; batch adversarial loss: 0.619206\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339797; batch adversarial loss: 0.650903\n",
      "epoch 17; iter: 200; batch classifier loss: 0.297160; batch adversarial loss: 0.626758\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378829; batch adversarial loss: 0.655868\n",
      "epoch 18; iter: 200; batch classifier loss: 0.439590; batch adversarial loss: 0.597419\n",
      "epoch 19; iter: 0; batch classifier loss: 0.246619; batch adversarial loss: 0.616294\n",
      "epoch 19; iter: 200; batch classifier loss: 0.408259; batch adversarial loss: 0.593748\n",
      "epoch 20; iter: 0; batch classifier loss: 0.360562; batch adversarial loss: 0.613918\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379414; batch adversarial loss: 0.605245\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338633; batch adversarial loss: 0.548721\n",
      "epoch 21; iter: 200; batch classifier loss: 0.354672; batch adversarial loss: 0.656834\n",
      "epoch 22; iter: 0; batch classifier loss: 0.374495; batch adversarial loss: 0.630564\n",
      "epoch 22; iter: 200; batch classifier loss: 0.332379; batch adversarial loss: 0.634012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.394480; batch adversarial loss: 0.585070\n",
      "epoch 23; iter: 200; batch classifier loss: 0.359171; batch adversarial loss: 0.634773\n",
      "epoch 24; iter: 0; batch classifier loss: 0.326793; batch adversarial loss: 0.652024\n",
      "epoch 24; iter: 200; batch classifier loss: 0.468844; batch adversarial loss: 0.616888\n",
      "epoch 25; iter: 0; batch classifier loss: 0.361994; batch adversarial loss: 0.658340\n",
      "epoch 25; iter: 200; batch classifier loss: 0.415525; batch adversarial loss: 0.661089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.291504; batch adversarial loss: 0.619654\n",
      "epoch 26; iter: 200; batch classifier loss: 0.263351; batch adversarial loss: 0.619637\n",
      "epoch 27; iter: 0; batch classifier loss: 0.410039; batch adversarial loss: 0.595988\n",
      "epoch 27; iter: 200; batch classifier loss: 0.331506; batch adversarial loss: 0.593865\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532807; batch adversarial loss: 0.625106\n",
      "epoch 28; iter: 200; batch classifier loss: 0.304687; batch adversarial loss: 0.666860\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424644; batch adversarial loss: 0.645345\n",
      "epoch 29; iter: 200; batch classifier loss: 0.363778; batch adversarial loss: 0.623350\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421537; batch adversarial loss: 0.649098\n",
      "epoch 30; iter: 200; batch classifier loss: 0.402629; batch adversarial loss: 0.670797\n",
      "epoch 31; iter: 0; batch classifier loss: 0.323363; batch adversarial loss: 0.592088\n",
      "epoch 31; iter: 200; batch classifier loss: 0.386905; batch adversarial loss: 0.626646\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403823; batch adversarial loss: 0.617282\n",
      "epoch 32; iter: 200; batch classifier loss: 0.394396; batch adversarial loss: 0.600679\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355439; batch adversarial loss: 0.612898\n",
      "epoch 33; iter: 200; batch classifier loss: 0.303623; batch adversarial loss: 0.585719\n",
      "epoch 34; iter: 0; batch classifier loss: 0.431380; batch adversarial loss: 0.689735\n",
      "epoch 34; iter: 200; batch classifier loss: 0.459722; batch adversarial loss: 0.666623\n",
      "epoch 35; iter: 0; batch classifier loss: 0.333139; batch adversarial loss: 0.605501\n",
      "epoch 35; iter: 200; batch classifier loss: 0.317206; batch adversarial loss: 0.633641\n",
      "epoch 36; iter: 0; batch classifier loss: 0.361898; batch adversarial loss: 0.575101\n",
      "epoch 36; iter: 200; batch classifier loss: 0.303954; batch adversarial loss: 0.608698\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400963; batch adversarial loss: 0.657535\n",
      "epoch 37; iter: 200; batch classifier loss: 0.426440; batch adversarial loss: 0.575685\n",
      "epoch 38; iter: 0; batch classifier loss: 0.352972; batch adversarial loss: 0.675232\n",
      "epoch 38; iter: 200; batch classifier loss: 0.490933; batch adversarial loss: 0.575994\n",
      "epoch 39; iter: 0; batch classifier loss: 0.301182; batch adversarial loss: 0.606115\n",
      "epoch 39; iter: 200; batch classifier loss: 0.294056; batch adversarial loss: 0.599797\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405232; batch adversarial loss: 0.622572\n",
      "epoch 40; iter: 200; batch classifier loss: 0.383631; batch adversarial loss: 0.605802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256834; batch adversarial loss: 0.562999\n",
      "epoch 41; iter: 200; batch classifier loss: 0.474027; batch adversarial loss: 0.574948\n",
      "epoch 42; iter: 0; batch classifier loss: 0.264522; batch adversarial loss: 0.686364\n",
      "epoch 42; iter: 200; batch classifier loss: 0.382821; batch adversarial loss: 0.628840\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383938; batch adversarial loss: 0.597798\n",
      "epoch 43; iter: 200; batch classifier loss: 0.293549; batch adversarial loss: 0.617166\n",
      "epoch 44; iter: 0; batch classifier loss: 0.327959; batch adversarial loss: 0.555282\n",
      "epoch 44; iter: 200; batch classifier loss: 0.376416; batch adversarial loss: 0.613337\n",
      "epoch 45; iter: 0; batch classifier loss: 0.379679; batch adversarial loss: 0.634620\n",
      "epoch 45; iter: 200; batch classifier loss: 0.386120; batch adversarial loss: 0.678410\n",
      "epoch 46; iter: 0; batch classifier loss: 0.400636; batch adversarial loss: 0.607158\n",
      "epoch 46; iter: 200; batch classifier loss: 0.332154; batch adversarial loss: 0.580058\n",
      "epoch 47; iter: 0; batch classifier loss: 0.244488; batch adversarial loss: 0.594972\n",
      "epoch 47; iter: 200; batch classifier loss: 0.416645; batch adversarial loss: 0.657646\n",
      "epoch 48; iter: 0; batch classifier loss: 0.355268; batch adversarial loss: 0.586896\n",
      "epoch 48; iter: 200; batch classifier loss: 0.420977; batch adversarial loss: 0.629388\n",
      "epoch 49; iter: 0; batch classifier loss: 0.295351; batch adversarial loss: 0.557616\n",
      "epoch 49; iter: 200; batch classifier loss: 0.349693; batch adversarial loss: 0.611192\n",
      "epoch 0; iter: 0; batch classifier loss: 19.275188; batch adversarial loss: 0.669473\n",
      "epoch 0; iter: 200; batch classifier loss: 4.695323; batch adversarial loss: 0.665619\n",
      "epoch 1; iter: 0; batch classifier loss: 4.699365; batch adversarial loss: 0.660895\n",
      "epoch 1; iter: 200; batch classifier loss: 11.145451; batch adversarial loss: 0.612292\n",
      "epoch 2; iter: 0; batch classifier loss: 6.725661; batch adversarial loss: 0.587970\n",
      "epoch 2; iter: 200; batch classifier loss: 8.339340; batch adversarial loss: 0.652549\n",
      "epoch 3; iter: 0; batch classifier loss: 1.370928; batch adversarial loss: 0.594603\n",
      "epoch 3; iter: 200; batch classifier loss: 3.297702; batch adversarial loss: 0.635873\n",
      "epoch 4; iter: 0; batch classifier loss: 3.214112; batch adversarial loss: 0.642410\n",
      "epoch 4; iter: 200; batch classifier loss: 1.535796; batch adversarial loss: 0.660496\n",
      "epoch 5; iter: 0; batch classifier loss: 2.631608; batch adversarial loss: 0.602937\n",
      "epoch 5; iter: 200; batch classifier loss: 1.393402; batch adversarial loss: 0.589888\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605206; batch adversarial loss: 0.676760\n",
      "epoch 6; iter: 200; batch classifier loss: 1.212741; batch adversarial loss: 0.614133\n",
      "epoch 7; iter: 0; batch classifier loss: 1.272662; batch adversarial loss: 0.606381\n",
      "epoch 7; iter: 200; batch classifier loss: 1.311918; batch adversarial loss: 0.623187\n",
      "epoch 8; iter: 0; batch classifier loss: 1.059891; batch adversarial loss: 0.630784\n",
      "epoch 8; iter: 200; batch classifier loss: 0.529647; batch adversarial loss: 0.670207\n",
      "epoch 9; iter: 0; batch classifier loss: 0.716880; batch adversarial loss: 0.608025\n",
      "epoch 9; iter: 200; batch classifier loss: 0.656444; batch adversarial loss: 0.606860\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445252; batch adversarial loss: 0.588057\n",
      "epoch 10; iter: 200; batch classifier loss: 0.533150; batch adversarial loss: 0.579678\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521831; batch adversarial loss: 0.653316\n",
      "epoch 11; iter: 200; batch classifier loss: 0.357590; batch adversarial loss: 0.590660\n",
      "epoch 12; iter: 0; batch classifier loss: 0.302742; batch adversarial loss: 0.624436\n",
      "epoch 12; iter: 200; batch classifier loss: 0.404427; batch adversarial loss: 0.616005\n",
      "epoch 13; iter: 0; batch classifier loss: 0.413951; batch adversarial loss: 0.569172\n",
      "epoch 13; iter: 200; batch classifier loss: 0.442074; batch adversarial loss: 0.608101\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430384; batch adversarial loss: 0.680654\n",
      "epoch 14; iter: 200; batch classifier loss: 0.391593; batch adversarial loss: 0.589309\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361224; batch adversarial loss: 0.668969\n",
      "epoch 15; iter: 200; batch classifier loss: 0.407906; batch adversarial loss: 0.662611\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372389; batch adversarial loss: 0.607735\n",
      "epoch 16; iter: 200; batch classifier loss: 0.425258; batch adversarial loss: 0.608048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391386; batch adversarial loss: 0.597388\n",
      "epoch 17; iter: 200; batch classifier loss: 0.377808; batch adversarial loss: 0.610497\n",
      "epoch 18; iter: 0; batch classifier loss: 0.364710; batch adversarial loss: 0.576870\n",
      "epoch 18; iter: 200; batch classifier loss: 0.411336; batch adversarial loss: 0.630402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.297792; batch adversarial loss: 0.580824\n",
      "epoch 19; iter: 200; batch classifier loss: 0.383950; batch adversarial loss: 0.598434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342158; batch adversarial loss: 0.596250\n",
      "epoch 20; iter: 200; batch classifier loss: 0.367356; batch adversarial loss: 0.629041\n",
      "epoch 21; iter: 0; batch classifier loss: 0.320604; batch adversarial loss: 0.627649\n",
      "epoch 21; iter: 200; batch classifier loss: 0.333345; batch adversarial loss: 0.579738\n",
      "epoch 22; iter: 0; batch classifier loss: 0.433942; batch adversarial loss: 0.584159\n",
      "epoch 22; iter: 200; batch classifier loss: 0.413666; batch adversarial loss: 0.707039\n",
      "epoch 23; iter: 0; batch classifier loss: 0.323444; batch adversarial loss: 0.592909\n",
      "epoch 23; iter: 200; batch classifier loss: 0.335682; batch adversarial loss: 0.601565\n",
      "epoch 24; iter: 0; batch classifier loss: 0.322073; batch adversarial loss: 0.600350\n",
      "epoch 24; iter: 200; batch classifier loss: 0.370202; batch adversarial loss: 0.634864\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424864; batch adversarial loss: 0.630478\n",
      "epoch 25; iter: 200; batch classifier loss: 0.444165; batch adversarial loss: 0.622915\n",
      "epoch 26; iter: 0; batch classifier loss: 0.386967; batch adversarial loss: 0.615456\n",
      "epoch 26; iter: 200; batch classifier loss: 0.305383; batch adversarial loss: 0.689077\n",
      "epoch 27; iter: 0; batch classifier loss: 0.312423; batch adversarial loss: 0.646991\n",
      "epoch 27; iter: 200; batch classifier loss: 0.325127; batch adversarial loss: 0.626188\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345249; batch adversarial loss: 0.614935\n",
      "epoch 28; iter: 200; batch classifier loss: 0.329868; batch adversarial loss: 0.596959\n",
      "epoch 29; iter: 0; batch classifier loss: 0.406502; batch adversarial loss: 0.652092\n",
      "epoch 29; iter: 200; batch classifier loss: 0.409822; batch adversarial loss: 0.563813\n",
      "epoch 30; iter: 0; batch classifier loss: 0.343404; batch adversarial loss: 0.601922\n",
      "epoch 30; iter: 200; batch classifier loss: 0.341772; batch adversarial loss: 0.581956\n",
      "epoch 31; iter: 0; batch classifier loss: 0.396158; batch adversarial loss: 0.595569\n",
      "epoch 31; iter: 200; batch classifier loss: 0.425137; batch adversarial loss: 0.597230\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318144; batch adversarial loss: 0.673526\n",
      "epoch 32; iter: 200; batch classifier loss: 0.327148; batch adversarial loss: 0.603627\n",
      "epoch 33; iter: 0; batch classifier loss: 0.271254; batch adversarial loss: 0.636314\n",
      "epoch 33; iter: 200; batch classifier loss: 0.389027; batch adversarial loss: 0.622182\n",
      "epoch 34; iter: 0; batch classifier loss: 0.383530; batch adversarial loss: 0.553497\n",
      "epoch 34; iter: 200; batch classifier loss: 0.310177; batch adversarial loss: 0.591749\n",
      "epoch 35; iter: 0; batch classifier loss: 0.323755; batch adversarial loss: 0.642710\n",
      "epoch 35; iter: 200; batch classifier loss: 0.413161; batch adversarial loss: 0.613130\n",
      "epoch 36; iter: 0; batch classifier loss: 0.377299; batch adversarial loss: 0.669133\n",
      "epoch 36; iter: 200; batch classifier loss: 0.534650; batch adversarial loss: 0.616707\n",
      "epoch 37; iter: 0; batch classifier loss: 0.367129; batch adversarial loss: 0.607627\n",
      "epoch 37; iter: 200; batch classifier loss: 0.411150; batch adversarial loss: 0.609364\n",
      "epoch 38; iter: 0; batch classifier loss: 0.375784; batch adversarial loss: 0.610975\n",
      "epoch 38; iter: 200; batch classifier loss: 0.303029; batch adversarial loss: 0.628510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.358830; batch adversarial loss: 0.544311\n",
      "epoch 39; iter: 200; batch classifier loss: 0.350925; batch adversarial loss: 0.624119\n",
      "epoch 40; iter: 0; batch classifier loss: 0.313920; batch adversarial loss: 0.621386\n",
      "epoch 40; iter: 200; batch classifier loss: 0.359789; batch adversarial loss: 0.610464\n",
      "epoch 41; iter: 0; batch classifier loss: 0.282324; batch adversarial loss: 0.686822\n",
      "epoch 41; iter: 200; batch classifier loss: 0.367074; batch adversarial loss: 0.656886\n",
      "epoch 42; iter: 0; batch classifier loss: 0.352750; batch adversarial loss: 0.644536\n",
      "epoch 42; iter: 200; batch classifier loss: 0.355285; batch adversarial loss: 0.589568\n",
      "epoch 43; iter: 0; batch classifier loss: 0.371848; batch adversarial loss: 0.625879\n",
      "epoch 43; iter: 200; batch classifier loss: 0.364854; batch adversarial loss: 0.627293\n",
      "epoch 44; iter: 0; batch classifier loss: 0.422925; batch adversarial loss: 0.627907\n",
      "epoch 44; iter: 200; batch classifier loss: 0.401138; batch adversarial loss: 0.653216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374302; batch adversarial loss: 0.616108\n",
      "epoch 45; iter: 200; batch classifier loss: 0.349394; batch adversarial loss: 0.600459\n",
      "epoch 46; iter: 0; batch classifier loss: 0.255508; batch adversarial loss: 0.651406\n",
      "epoch 46; iter: 200; batch classifier loss: 0.456525; batch adversarial loss: 0.582667\n",
      "epoch 47; iter: 0; batch classifier loss: 0.308185; batch adversarial loss: 0.643939\n",
      "epoch 47; iter: 200; batch classifier loss: 0.323326; batch adversarial loss: 0.625888\n",
      "epoch 48; iter: 0; batch classifier loss: 0.313668; batch adversarial loss: 0.604897\n",
      "epoch 48; iter: 200; batch classifier loss: 0.432822; batch adversarial loss: 0.631849\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371386; batch adversarial loss: 0.621521\n",
      "epoch 49; iter: 200; batch classifier loss: 0.360775; batch adversarial loss: 0.627473\n",
      "epoch 0; iter: 0; batch classifier loss: 7.046251; batch adversarial loss: 0.711263\n",
      "epoch 0; iter: 200; batch classifier loss: 8.568531; batch adversarial loss: 0.679049\n",
      "epoch 1; iter: 0; batch classifier loss: 34.141582; batch adversarial loss: 0.674479\n",
      "epoch 1; iter: 200; batch classifier loss: 1.678461; batch adversarial loss: 0.638976\n",
      "epoch 2; iter: 0; batch classifier loss: 2.081983; batch adversarial loss: 0.655985\n",
      "epoch 2; iter: 200; batch classifier loss: 1.771204; batch adversarial loss: 0.612329\n",
      "epoch 3; iter: 0; batch classifier loss: 1.974032; batch adversarial loss: 0.594836\n",
      "epoch 3; iter: 200; batch classifier loss: 1.864896; batch adversarial loss: 0.641770\n",
      "epoch 4; iter: 0; batch classifier loss: 2.351606; batch adversarial loss: 0.668203\n",
      "epoch 4; iter: 200; batch classifier loss: 1.480198; batch adversarial loss: 0.629730\n",
      "epoch 5; iter: 0; batch classifier loss: 1.889441; batch adversarial loss: 0.685078\n",
      "epoch 5; iter: 200; batch classifier loss: 1.875583; batch adversarial loss: 0.652567\n",
      "epoch 6; iter: 0; batch classifier loss: 1.382918; batch adversarial loss: 0.654377\n",
      "epoch 6; iter: 200; batch classifier loss: 0.912758; batch adversarial loss: 0.622878\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526562; batch adversarial loss: 0.657133\n",
      "epoch 7; iter: 200; batch classifier loss: 1.347387; batch adversarial loss: 0.643727\n",
      "epoch 8; iter: 0; batch classifier loss: 0.768825; batch adversarial loss: 0.656538\n",
      "epoch 8; iter: 200; batch classifier loss: 0.545190; batch adversarial loss: 0.622890\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472753; batch adversarial loss: 0.618862\n",
      "epoch 9; iter: 200; batch classifier loss: 0.530534; batch adversarial loss: 0.665702\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505758; batch adversarial loss: 0.643462\n",
      "epoch 10; iter: 200; batch classifier loss: 0.441476; batch adversarial loss: 0.644575\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413055; batch adversarial loss: 0.636206\n",
      "epoch 11; iter: 200; batch classifier loss: 0.400613; batch adversarial loss: 0.594005\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535331; batch adversarial loss: 0.547260\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391961; batch adversarial loss: 0.683662\n",
      "epoch 13; iter: 0; batch classifier loss: 0.389117; batch adversarial loss: 0.597425\n",
      "epoch 13; iter: 200; batch classifier loss: 0.453610; batch adversarial loss: 0.634603\n",
      "epoch 14; iter: 0; batch classifier loss: 0.414862; batch adversarial loss: 0.623153\n",
      "epoch 14; iter: 200; batch classifier loss: 0.539835; batch adversarial loss: 0.658787\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519554; batch adversarial loss: 0.597378\n",
      "epoch 15; iter: 200; batch classifier loss: 0.372623; batch adversarial loss: 0.593067\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403828; batch adversarial loss: 0.671620\n",
      "epoch 16; iter: 200; batch classifier loss: 0.395859; batch adversarial loss: 0.640682\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373572; batch adversarial loss: 0.605276\n",
      "epoch 17; iter: 200; batch classifier loss: 0.337674; batch adversarial loss: 0.662552\n",
      "epoch 18; iter: 0; batch classifier loss: 0.375609; batch adversarial loss: 0.604006\n",
      "epoch 18; iter: 200; batch classifier loss: 0.448035; batch adversarial loss: 0.529247\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444084; batch adversarial loss: 0.623854\n",
      "epoch 19; iter: 200; batch classifier loss: 0.378145; batch adversarial loss: 0.572984\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361069; batch adversarial loss: 0.578595\n",
      "epoch 20; iter: 200; batch classifier loss: 0.273947; batch adversarial loss: 0.586065\n",
      "epoch 21; iter: 0; batch classifier loss: 0.389252; batch adversarial loss: 0.611837\n",
      "epoch 21; iter: 200; batch classifier loss: 0.294864; batch adversarial loss: 0.634773\n",
      "epoch 22; iter: 0; batch classifier loss: 0.333489; batch adversarial loss: 0.691070\n",
      "epoch 22; iter: 200; batch classifier loss: 0.291496; batch adversarial loss: 0.586393\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339488; batch adversarial loss: 0.637876\n",
      "epoch 23; iter: 200; batch classifier loss: 0.376548; batch adversarial loss: 0.636301\n",
      "epoch 24; iter: 0; batch classifier loss: 0.383636; batch adversarial loss: 0.659044\n",
      "epoch 24; iter: 200; batch classifier loss: 0.294668; batch adversarial loss: 0.616458\n",
      "epoch 25; iter: 0; batch classifier loss: 0.327759; batch adversarial loss: 0.644372\n",
      "epoch 25; iter: 200; batch classifier loss: 0.351394; batch adversarial loss: 0.575235\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363901; batch adversarial loss: 0.654527\n",
      "epoch 26; iter: 200; batch classifier loss: 0.319951; batch adversarial loss: 0.623999\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402477; batch adversarial loss: 0.620088\n",
      "epoch 27; iter: 200; batch classifier loss: 0.355112; batch adversarial loss: 0.642872\n",
      "epoch 28; iter: 0; batch classifier loss: 0.345108; batch adversarial loss: 0.624887\n",
      "epoch 28; iter: 200; batch classifier loss: 0.389030; batch adversarial loss: 0.657014\n",
      "epoch 29; iter: 0; batch classifier loss: 0.301955; batch adversarial loss: 0.653875\n",
      "epoch 29; iter: 200; batch classifier loss: 0.359275; batch adversarial loss: 0.588539\n",
      "epoch 30; iter: 0; batch classifier loss: 0.340423; batch adversarial loss: 0.611576\n",
      "epoch 30; iter: 200; batch classifier loss: 0.370048; batch adversarial loss: 0.596902\n",
      "epoch 31; iter: 0; batch classifier loss: 0.447486; batch adversarial loss: 0.576185\n",
      "epoch 31; iter: 200; batch classifier loss: 0.336913; batch adversarial loss: 0.560663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.330293; batch adversarial loss: 0.618118\n",
      "epoch 32; iter: 200; batch classifier loss: 0.306477; batch adversarial loss: 0.598436\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355822; batch adversarial loss: 0.643714\n",
      "epoch 33; iter: 200; batch classifier loss: 0.299830; batch adversarial loss: 0.681451\n",
      "epoch 34; iter: 0; batch classifier loss: 0.289464; batch adversarial loss: 0.616483\n",
      "epoch 34; iter: 200; batch classifier loss: 0.511882; batch adversarial loss: 0.658938\n",
      "epoch 35; iter: 0; batch classifier loss: 0.316459; batch adversarial loss: 0.603683\n",
      "epoch 35; iter: 200; batch classifier loss: 0.370850; batch adversarial loss: 0.607656\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368707; batch adversarial loss: 0.618148\n",
      "epoch 36; iter: 200; batch classifier loss: 0.270379; batch adversarial loss: 0.691628\n",
      "epoch 37; iter: 0; batch classifier loss: 0.282696; batch adversarial loss: 0.594775\n",
      "epoch 37; iter: 200; batch classifier loss: 0.286302; batch adversarial loss: 0.640299\n",
      "epoch 38; iter: 0; batch classifier loss: 0.367411; batch adversarial loss: 0.583959\n",
      "epoch 38; iter: 200; batch classifier loss: 0.357743; batch adversarial loss: 0.593036\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376457; batch adversarial loss: 0.626438\n",
      "epoch 39; iter: 200; batch classifier loss: 0.405971; batch adversarial loss: 0.649048\n",
      "epoch 40; iter: 0; batch classifier loss: 0.251609; batch adversarial loss: 0.603583\n",
      "epoch 40; iter: 200; batch classifier loss: 0.741976; batch adversarial loss: 0.604013\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396955; batch adversarial loss: 0.590391\n",
      "epoch 41; iter: 200; batch classifier loss: 0.377913; batch adversarial loss: 0.594880\n",
      "epoch 42; iter: 0; batch classifier loss: 0.399238; batch adversarial loss: 0.588521\n",
      "epoch 42; iter: 200; batch classifier loss: 0.314156; batch adversarial loss: 0.600665\n",
      "epoch 43; iter: 0; batch classifier loss: 0.330222; batch adversarial loss: 0.591079\n",
      "epoch 43; iter: 200; batch classifier loss: 0.426678; batch adversarial loss: 0.623301\n",
      "epoch 44; iter: 0; batch classifier loss: 0.337262; batch adversarial loss: 0.600931\n",
      "epoch 44; iter: 200; batch classifier loss: 0.360569; batch adversarial loss: 0.605053\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397904; batch adversarial loss: 0.627387\n",
      "epoch 45; iter: 200; batch classifier loss: 0.307342; batch adversarial loss: 0.632324\n",
      "epoch 46; iter: 0; batch classifier loss: 0.314464; batch adversarial loss: 0.667285\n",
      "epoch 46; iter: 200; batch classifier loss: 0.327958; batch adversarial loss: 0.621138\n",
      "epoch 47; iter: 0; batch classifier loss: 0.309670; batch adversarial loss: 0.623538\n",
      "epoch 47; iter: 200; batch classifier loss: 0.348666; batch adversarial loss: 0.563170\n",
      "epoch 48; iter: 0; batch classifier loss: 0.297981; batch adversarial loss: 0.646942\n",
      "epoch 48; iter: 200; batch classifier loss: 0.361346; batch adversarial loss: 0.645128\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371299; batch adversarial loss: 0.578034\n",
      "epoch 49; iter: 200; batch classifier loss: 0.294383; batch adversarial loss: 0.628972\n",
      "epoch 0; iter: 0; batch classifier loss: 84.838379; batch adversarial loss: 0.837773\n",
      "epoch 0; iter: 200; batch classifier loss: 7.868356; batch adversarial loss: 0.709567\n",
      "epoch 1; iter: 0; batch classifier loss: 10.453586; batch adversarial loss: 0.711794\n",
      "epoch 1; iter: 200; batch classifier loss: 70.217911; batch adversarial loss: 0.651692\n",
      "epoch 2; iter: 0; batch classifier loss: 2.859476; batch adversarial loss: 0.630133\n",
      "epoch 2; iter: 200; batch classifier loss: 2.752078; batch adversarial loss: 0.623654\n",
      "epoch 3; iter: 0; batch classifier loss: 1.020608; batch adversarial loss: 0.651019\n",
      "epoch 3; iter: 200; batch classifier loss: 2.194659; batch adversarial loss: 0.619159\n",
      "epoch 4; iter: 0; batch classifier loss: 4.833686; batch adversarial loss: 0.630162\n",
      "epoch 4; iter: 200; batch classifier loss: 2.102710; batch adversarial loss: 0.606948\n",
      "epoch 5; iter: 0; batch classifier loss: 2.110420; batch adversarial loss: 0.603296\n",
      "epoch 5; iter: 200; batch classifier loss: 7.471217; batch adversarial loss: 0.606859\n",
      "epoch 6; iter: 0; batch classifier loss: 2.274512; batch adversarial loss: 0.644108\n",
      "epoch 6; iter: 200; batch classifier loss: 2.311315; batch adversarial loss: 0.589687\n",
      "epoch 7; iter: 0; batch classifier loss: 3.470088; batch adversarial loss: 0.616050\n",
      "epoch 7; iter: 200; batch classifier loss: 1.018719; batch adversarial loss: 0.586646\n",
      "epoch 8; iter: 0; batch classifier loss: 0.942604; batch adversarial loss: 0.621362\n",
      "epoch 8; iter: 200; batch classifier loss: 1.462764; batch adversarial loss: 0.613101\n",
      "epoch 9; iter: 0; batch classifier loss: 0.938660; batch adversarial loss: 0.655284\n",
      "epoch 9; iter: 200; batch classifier loss: 0.417715; batch adversarial loss: 0.644307\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518455; batch adversarial loss: 0.587878\n",
      "epoch 10; iter: 200; batch classifier loss: 0.449780; batch adversarial loss: 0.611330\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459335; batch adversarial loss: 0.651189\n",
      "epoch 11; iter: 200; batch classifier loss: 0.770119; batch adversarial loss: 0.604955\n",
      "epoch 12; iter: 0; batch classifier loss: 0.559794; batch adversarial loss: 0.608649\n",
      "epoch 12; iter: 200; batch classifier loss: 0.383510; batch adversarial loss: 0.662388\n",
      "epoch 13; iter: 0; batch classifier loss: 0.433934; batch adversarial loss: 0.582923\n",
      "epoch 13; iter: 200; batch classifier loss: 0.443819; batch adversarial loss: 0.640309\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389018; batch adversarial loss: 0.620990\n",
      "epoch 14; iter: 200; batch classifier loss: 0.708922; batch adversarial loss: 0.621337\n",
      "epoch 15; iter: 0; batch classifier loss: 0.389984; batch adversarial loss: 0.632940\n",
      "epoch 15; iter: 200; batch classifier loss: 0.410584; batch adversarial loss: 0.566955\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394210; batch adversarial loss: 0.622532\n",
      "epoch 16; iter: 200; batch classifier loss: 0.329964; batch adversarial loss: 0.587668\n",
      "epoch 17; iter: 0; batch classifier loss: 0.346174; batch adversarial loss: 0.612413\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349144; batch adversarial loss: 0.616849\n",
      "epoch 18; iter: 0; batch classifier loss: 0.347074; batch adversarial loss: 0.617417\n",
      "epoch 18; iter: 200; batch classifier loss: 0.359092; batch adversarial loss: 0.633172\n",
      "epoch 19; iter: 0; batch classifier loss: 0.351981; batch adversarial loss: 0.670899\n",
      "epoch 19; iter: 200; batch classifier loss: 0.328401; batch adversarial loss: 0.613645\n",
      "epoch 20; iter: 0; batch classifier loss: 0.330451; batch adversarial loss: 0.661753\n",
      "epoch 20; iter: 200; batch classifier loss: 0.298638; batch adversarial loss: 0.639652\n",
      "epoch 21; iter: 0; batch classifier loss: 0.324229; batch adversarial loss: 0.677689\n",
      "epoch 21; iter: 200; batch classifier loss: 0.370361; batch adversarial loss: 0.600378\n",
      "epoch 22; iter: 0; batch classifier loss: 0.349633; batch adversarial loss: 0.563499\n",
      "epoch 22; iter: 200; batch classifier loss: 0.310191; batch adversarial loss: 0.605025\n",
      "epoch 23; iter: 0; batch classifier loss: 0.384308; batch adversarial loss: 0.588258\n",
      "epoch 23; iter: 200; batch classifier loss: 0.483565; batch adversarial loss: 0.585841\n",
      "epoch 24; iter: 0; batch classifier loss: 0.313709; batch adversarial loss: 0.611331\n",
      "epoch 24; iter: 200; batch classifier loss: 0.344034; batch adversarial loss: 0.605099\n",
      "epoch 25; iter: 0; batch classifier loss: 0.359222; batch adversarial loss: 0.587861\n",
      "epoch 25; iter: 200; batch classifier loss: 0.384507; batch adversarial loss: 0.607304\n",
      "epoch 26; iter: 0; batch classifier loss: 0.308820; batch adversarial loss: 0.635545\n",
      "epoch 26; iter: 200; batch classifier loss: 0.380290; batch adversarial loss: 0.578144\n",
      "epoch 27; iter: 0; batch classifier loss: 0.374521; batch adversarial loss: 0.660581\n",
      "epoch 27; iter: 200; batch classifier loss: 0.447268; batch adversarial loss: 0.580078\n",
      "epoch 28; iter: 0; batch classifier loss: 0.417435; batch adversarial loss: 0.548164\n",
      "epoch 28; iter: 200; batch classifier loss: 0.522433; batch adversarial loss: 0.654508\n",
      "epoch 29; iter: 0; batch classifier loss: 0.249524; batch adversarial loss: 0.673626\n",
      "epoch 29; iter: 200; batch classifier loss: 0.323580; batch adversarial loss: 0.604086\n",
      "epoch 30; iter: 0; batch classifier loss: 0.551051; batch adversarial loss: 0.615132\n",
      "epoch 30; iter: 200; batch classifier loss: 0.316159; batch adversarial loss: 0.628212\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366069; batch adversarial loss: 0.599719\n",
      "epoch 31; iter: 200; batch classifier loss: 0.388735; batch adversarial loss: 0.580463\n",
      "epoch 32; iter: 0; batch classifier loss: 0.390329; batch adversarial loss: 0.658735\n",
      "epoch 32; iter: 200; batch classifier loss: 0.331801; batch adversarial loss: 0.589833\n",
      "epoch 33; iter: 0; batch classifier loss: 0.244055; batch adversarial loss: 0.568554\n",
      "epoch 33; iter: 200; batch classifier loss: 0.276866; batch adversarial loss: 0.585865\n",
      "epoch 34; iter: 0; batch classifier loss: 0.484192; batch adversarial loss: 0.646424\n",
      "epoch 34; iter: 200; batch classifier loss: 0.399645; batch adversarial loss: 0.609694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.375269; batch adversarial loss: 0.616878\n",
      "epoch 35; iter: 200; batch classifier loss: 0.397903; batch adversarial loss: 0.711761\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390110; batch adversarial loss: 0.652552\n",
      "epoch 36; iter: 200; batch classifier loss: 0.360202; batch adversarial loss: 0.599752\n",
      "epoch 37; iter: 0; batch classifier loss: 0.403268; batch adversarial loss: 0.600007\n",
      "epoch 37; iter: 200; batch classifier loss: 0.401517; batch adversarial loss: 0.702584\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286444; batch adversarial loss: 0.640240\n",
      "epoch 38; iter: 200; batch classifier loss: 0.326644; batch adversarial loss: 0.652374\n",
      "epoch 39; iter: 0; batch classifier loss: 0.397952; batch adversarial loss: 0.628991\n",
      "epoch 39; iter: 200; batch classifier loss: 0.371846; batch adversarial loss: 0.658979\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441931; batch adversarial loss: 0.646444\n",
      "epoch 40; iter: 200; batch classifier loss: 0.497470; batch adversarial loss: 0.597345\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390682; batch adversarial loss: 0.631003\n",
      "epoch 41; iter: 200; batch classifier loss: 0.389985; batch adversarial loss: 0.628763\n",
      "epoch 42; iter: 0; batch classifier loss: 0.258005; batch adversarial loss: 0.619519\n",
      "epoch 42; iter: 200; batch classifier loss: 0.389570; batch adversarial loss: 0.625584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.293663; batch adversarial loss: 0.618244\n",
      "epoch 43; iter: 200; batch classifier loss: 0.258785; batch adversarial loss: 0.657812\n",
      "epoch 44; iter: 0; batch classifier loss: 0.346934; batch adversarial loss: 0.637456\n",
      "epoch 44; iter: 200; batch classifier loss: 0.382584; batch adversarial loss: 0.654451\n",
      "epoch 45; iter: 0; batch classifier loss: 0.349008; batch adversarial loss: 0.634254\n",
      "epoch 45; iter: 200; batch classifier loss: 0.282185; batch adversarial loss: 0.646265\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436349; batch adversarial loss: 0.634394\n",
      "epoch 46; iter: 200; batch classifier loss: 0.275861; batch adversarial loss: 0.622147\n",
      "epoch 47; iter: 0; batch classifier loss: 0.676357; batch adversarial loss: 0.630001\n",
      "epoch 47; iter: 200; batch classifier loss: 0.325596; batch adversarial loss: 0.623954\n",
      "epoch 48; iter: 0; batch classifier loss: 0.279051; batch adversarial loss: 0.586655\n",
      "epoch 48; iter: 200; batch classifier loss: 0.370085; batch adversarial loss: 0.600054\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403188; batch adversarial loss: 0.642781\n",
      "epoch 49; iter: 200; batch classifier loss: 0.390614; batch adversarial loss: 0.618351\n",
      "epoch 0; iter: 0; batch classifier loss: 47.535484; batch adversarial loss: 0.647431\n",
      "epoch 0; iter: 200; batch classifier loss: 3.727170; batch adversarial loss: 0.681730\n",
      "epoch 1; iter: 0; batch classifier loss: 10.787834; batch adversarial loss: 0.666595\n",
      "epoch 1; iter: 200; batch classifier loss: 3.420230; batch adversarial loss: 0.655252\n",
      "epoch 2; iter: 0; batch classifier loss: 5.176247; batch adversarial loss: 0.667997\n",
      "epoch 2; iter: 200; batch classifier loss: 2.279933; batch adversarial loss: 0.643200\n",
      "epoch 3; iter: 0; batch classifier loss: 2.303172; batch adversarial loss: 0.647053\n",
      "epoch 3; iter: 200; batch classifier loss: 1.295298; batch adversarial loss: 0.612878\n",
      "epoch 4; iter: 0; batch classifier loss: 4.153303; batch adversarial loss: 0.669647\n",
      "epoch 4; iter: 200; batch classifier loss: 6.472619; batch adversarial loss: 0.605002\n",
      "epoch 5; iter: 0; batch classifier loss: 2.897689; batch adversarial loss: 0.581685\n",
      "epoch 5; iter: 200; batch classifier loss: 1.415276; batch adversarial loss: 0.613233\n",
      "epoch 6; iter: 0; batch classifier loss: 1.324663; batch adversarial loss: 0.639697\n",
      "epoch 6; iter: 200; batch classifier loss: 1.008599; batch adversarial loss: 0.648080\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506358; batch adversarial loss: 0.581890\n",
      "epoch 7; iter: 200; batch classifier loss: 0.496352; batch adversarial loss: 0.590020\n",
      "epoch 8; iter: 0; batch classifier loss: 0.954951; batch adversarial loss: 0.598812\n",
      "epoch 8; iter: 200; batch classifier loss: 0.483247; batch adversarial loss: 0.644121\n",
      "epoch 9; iter: 0; batch classifier loss: 0.452319; batch adversarial loss: 0.593378\n",
      "epoch 9; iter: 200; batch classifier loss: 0.399973; batch adversarial loss: 0.616490\n",
      "epoch 10; iter: 0; batch classifier loss: 0.404632; batch adversarial loss: 0.639235\n",
      "epoch 10; iter: 200; batch classifier loss: 1.067293; batch adversarial loss: 0.628175\n",
      "epoch 11; iter: 0; batch classifier loss: 0.934453; batch adversarial loss: 0.616502\n",
      "epoch 11; iter: 200; batch classifier loss: 0.472136; batch adversarial loss: 0.621602\n",
      "epoch 12; iter: 0; batch classifier loss: 0.813674; batch adversarial loss: 0.633732\n",
      "epoch 12; iter: 200; batch classifier loss: 0.435419; batch adversarial loss: 0.661126\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336916; batch adversarial loss: 0.617225\n",
      "epoch 13; iter: 200; batch classifier loss: 0.409173; batch adversarial loss: 0.597489\n",
      "epoch 14; iter: 0; batch classifier loss: 0.450299; batch adversarial loss: 0.578011\n",
      "epoch 14; iter: 200; batch classifier loss: 0.241074; batch adversarial loss: 0.658273\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344477; batch adversarial loss: 0.643556\n",
      "epoch 15; iter: 200; batch classifier loss: 0.351230; batch adversarial loss: 0.617254\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332210; batch adversarial loss: 0.624000\n",
      "epoch 16; iter: 200; batch classifier loss: 0.404714; batch adversarial loss: 0.657863\n",
      "epoch 17; iter: 0; batch classifier loss: 0.358590; batch adversarial loss: 0.671421\n",
      "epoch 17; iter: 200; batch classifier loss: 0.350987; batch adversarial loss: 0.622223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.287686; batch adversarial loss: 0.644573\n",
      "epoch 18; iter: 200; batch classifier loss: 0.361544; batch adversarial loss: 0.574488\n",
      "epoch 19; iter: 0; batch classifier loss: 0.333652; batch adversarial loss: 0.609857\n",
      "epoch 19; iter: 200; batch classifier loss: 0.364547; batch adversarial loss: 0.621557\n",
      "epoch 20; iter: 0; batch classifier loss: 0.364949; batch adversarial loss: 0.600060\n",
      "epoch 20; iter: 200; batch classifier loss: 0.300392; batch adversarial loss: 0.630715\n",
      "epoch 21; iter: 0; batch classifier loss: 0.354041; batch adversarial loss: 0.580374\n",
      "epoch 21; iter: 200; batch classifier loss: 0.532508; batch adversarial loss: 0.590918\n",
      "epoch 22; iter: 0; batch classifier loss: 0.405877; batch adversarial loss: 0.687725\n",
      "epoch 22; iter: 200; batch classifier loss: 0.345247; batch adversarial loss: 0.603177\n",
      "epoch 23; iter: 0; batch classifier loss: 0.335661; batch adversarial loss: 0.621258\n",
      "epoch 23; iter: 200; batch classifier loss: 0.394415; batch adversarial loss: 0.597591\n",
      "epoch 24; iter: 0; batch classifier loss: 0.381080; batch adversarial loss: 0.565865\n",
      "epoch 24; iter: 200; batch classifier loss: 0.380474; batch adversarial loss: 0.735972\n",
      "epoch 25; iter: 0; batch classifier loss: 0.362515; batch adversarial loss: 0.615113\n",
      "epoch 25; iter: 200; batch classifier loss: 0.325730; batch adversarial loss: 0.575845\n",
      "epoch 26; iter: 0; batch classifier loss: 0.406654; batch adversarial loss: 0.610587\n",
      "epoch 26; iter: 200; batch classifier loss: 0.429878; batch adversarial loss: 0.648803\n",
      "epoch 27; iter: 0; batch classifier loss: 0.323415; batch adversarial loss: 0.623854\n",
      "epoch 27; iter: 200; batch classifier loss: 0.321452; batch adversarial loss: 0.658327\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418909; batch adversarial loss: 0.669308\n",
      "epoch 28; iter: 200; batch classifier loss: 0.321970; batch adversarial loss: 0.610795\n",
      "epoch 29; iter: 0; batch classifier loss: 0.321606; batch adversarial loss: 0.670513\n",
      "epoch 29; iter: 200; batch classifier loss: 0.279304; batch adversarial loss: 0.637800\n",
      "epoch 30; iter: 0; batch classifier loss: 0.556126; batch adversarial loss: 0.642672\n",
      "epoch 30; iter: 200; batch classifier loss: 0.373406; batch adversarial loss: 0.585839\n",
      "epoch 31; iter: 0; batch classifier loss: 0.357946; batch adversarial loss: 0.588256\n",
      "epoch 31; iter: 200; batch classifier loss: 0.399533; batch adversarial loss: 0.583586\n",
      "epoch 32; iter: 0; batch classifier loss: 0.334053; batch adversarial loss: 0.609042\n",
      "epoch 32; iter: 200; batch classifier loss: 0.340060; batch adversarial loss: 0.618652\n",
      "epoch 33; iter: 0; batch classifier loss: 0.359685; batch adversarial loss: 0.590641\n",
      "epoch 33; iter: 200; batch classifier loss: 0.364448; batch adversarial loss: 0.603150\n",
      "epoch 34; iter: 0; batch classifier loss: 0.338267; batch adversarial loss: 0.629464\n",
      "epoch 34; iter: 200; batch classifier loss: 0.333008; batch adversarial loss: 0.619127\n",
      "epoch 35; iter: 0; batch classifier loss: 0.458254; batch adversarial loss: 0.585764\n",
      "epoch 35; iter: 200; batch classifier loss: 0.305299; batch adversarial loss: 0.697908\n",
      "epoch 36; iter: 0; batch classifier loss: 0.418193; batch adversarial loss: 0.651059\n",
      "epoch 36; iter: 200; batch classifier loss: 0.401087; batch adversarial loss: 0.630012\n",
      "epoch 37; iter: 0; batch classifier loss: 0.306528; batch adversarial loss: 0.543662\n",
      "epoch 37; iter: 200; batch classifier loss: 0.303016; batch adversarial loss: 0.623749\n",
      "epoch 38; iter: 0; batch classifier loss: 0.321223; batch adversarial loss: 0.667874\n",
      "epoch 38; iter: 200; batch classifier loss: 0.410828; batch adversarial loss: 0.621975\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490043; batch adversarial loss: 0.586778\n",
      "epoch 39; iter: 200; batch classifier loss: 0.328367; batch adversarial loss: 0.679460\n",
      "epoch 40; iter: 0; batch classifier loss: 0.433207; batch adversarial loss: 0.593115\n",
      "epoch 40; iter: 200; batch classifier loss: 0.286373; batch adversarial loss: 0.630614\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377152; batch adversarial loss: 0.656649\n",
      "epoch 41; iter: 200; batch classifier loss: 0.406288; batch adversarial loss: 0.657916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.428494; batch adversarial loss: 0.612884\n",
      "epoch 42; iter: 200; batch classifier loss: 0.500318; batch adversarial loss: 0.555908\n",
      "epoch 43; iter: 0; batch classifier loss: 0.322581; batch adversarial loss: 0.633343\n",
      "epoch 43; iter: 200; batch classifier loss: 0.506478; batch adversarial loss: 0.553969\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383869; batch adversarial loss: 0.610118\n",
      "epoch 44; iter: 200; batch classifier loss: 0.358347; batch adversarial loss: 0.613713\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441225; batch adversarial loss: 0.636356\n",
      "epoch 45; iter: 200; batch classifier loss: 0.252030; batch adversarial loss: 0.612544\n",
      "epoch 46; iter: 0; batch classifier loss: 0.354566; batch adversarial loss: 0.577379\n",
      "epoch 46; iter: 200; batch classifier loss: 0.397927; batch adversarial loss: 0.654560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.554339; batch adversarial loss: 0.616802\n",
      "epoch 47; iter: 200; batch classifier loss: 0.387515; batch adversarial loss: 0.643141\n",
      "epoch 48; iter: 0; batch classifier loss: 0.322127; batch adversarial loss: 0.662343\n",
      "epoch 48; iter: 200; batch classifier loss: 0.388775; batch adversarial loss: 0.664781\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400556; batch adversarial loss: 0.614558\n",
      "epoch 49; iter: 200; batch classifier loss: 0.369823; batch adversarial loss: 0.613235\n",
      "epoch 0; iter: 0; batch classifier loss: 4.738235; batch adversarial loss: 0.841681\n",
      "epoch 0; iter: 200; batch classifier loss: 8.640079; batch adversarial loss: 0.754727\n",
      "epoch 1; iter: 0; batch classifier loss: 4.545905; batch adversarial loss: 0.706362\n",
      "epoch 1; iter: 200; batch classifier loss: 4.612766; batch adversarial loss: 0.695485\n",
      "epoch 2; iter: 0; batch classifier loss: 4.687475; batch adversarial loss: 0.663741\n",
      "epoch 2; iter: 200; batch classifier loss: 2.352471; batch adversarial loss: 0.631833\n",
      "epoch 3; iter: 0; batch classifier loss: 5.116171; batch adversarial loss: 0.661240\n",
      "epoch 3; iter: 200; batch classifier loss: 5.553498; batch adversarial loss: 0.622416\n",
      "epoch 4; iter: 0; batch classifier loss: 1.362591; batch adversarial loss: 0.633609\n",
      "epoch 4; iter: 200; batch classifier loss: 0.968560; batch adversarial loss: 0.623340\n",
      "epoch 5; iter: 0; batch classifier loss: 3.307369; batch adversarial loss: 0.609062\n",
      "epoch 5; iter: 200; batch classifier loss: 0.824740; batch adversarial loss: 0.626286\n",
      "epoch 6; iter: 0; batch classifier loss: 1.047301; batch adversarial loss: 0.636926\n",
      "epoch 6; iter: 200; batch classifier loss: 5.596247; batch adversarial loss: 0.582528\n",
      "epoch 7; iter: 0; batch classifier loss: 0.889078; batch adversarial loss: 0.680281\n",
      "epoch 7; iter: 200; batch classifier loss: 0.533916; batch adversarial loss: 0.694926\n",
      "epoch 8; iter: 0; batch classifier loss: 0.599118; batch adversarial loss: 0.641570\n",
      "epoch 8; iter: 200; batch classifier loss: 0.658115; batch adversarial loss: 0.660024\n",
      "epoch 9; iter: 0; batch classifier loss: 0.761504; batch adversarial loss: 0.555935\n",
      "epoch 9; iter: 200; batch classifier loss: 0.523017; batch adversarial loss: 0.612132\n",
      "epoch 10; iter: 0; batch classifier loss: 0.676666; batch adversarial loss: 0.581906\n",
      "epoch 10; iter: 200; batch classifier loss: 0.593818; batch adversarial loss: 0.645945\n",
      "epoch 11; iter: 0; batch classifier loss: 0.709339; batch adversarial loss: 0.588117\n",
      "epoch 11; iter: 200; batch classifier loss: 0.399850; batch adversarial loss: 0.566885\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441372; batch adversarial loss: 0.593667\n",
      "epoch 12; iter: 200; batch classifier loss: 0.406387; batch adversarial loss: 0.581878\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512747; batch adversarial loss: 0.665502\n",
      "epoch 13; iter: 200; batch classifier loss: 0.428545; batch adversarial loss: 0.605182\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402055; batch adversarial loss: 0.599064\n",
      "epoch 14; iter: 200; batch classifier loss: 0.326802; batch adversarial loss: 0.620938\n",
      "epoch 15; iter: 0; batch classifier loss: 0.388365; batch adversarial loss: 0.653214\n",
      "epoch 15; iter: 200; batch classifier loss: 0.391466; batch adversarial loss: 0.630539\n",
      "epoch 16; iter: 0; batch classifier loss: 0.391602; batch adversarial loss: 0.565400\n",
      "epoch 16; iter: 200; batch classifier loss: 0.323013; batch adversarial loss: 0.608638\n",
      "epoch 17; iter: 0; batch classifier loss: 0.332495; batch adversarial loss: 0.593987\n",
      "epoch 17; iter: 200; batch classifier loss: 0.299140; batch adversarial loss: 0.592387\n",
      "epoch 18; iter: 0; batch classifier loss: 0.376371; batch adversarial loss: 0.601398\n",
      "epoch 18; iter: 200; batch classifier loss: 0.345586; batch adversarial loss: 0.610359\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438444; batch adversarial loss: 0.615372\n",
      "epoch 19; iter: 200; batch classifier loss: 0.375483; batch adversarial loss: 0.592872\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361836; batch adversarial loss: 0.558343\n",
      "epoch 20; iter: 200; batch classifier loss: 0.372244; batch adversarial loss: 0.617392\n",
      "epoch 21; iter: 0; batch classifier loss: 0.343783; batch adversarial loss: 0.592759\n",
      "epoch 21; iter: 200; batch classifier loss: 0.370027; batch adversarial loss: 0.674568\n",
      "epoch 22; iter: 0; batch classifier loss: 0.397257; batch adversarial loss: 0.548611\n",
      "epoch 22; iter: 200; batch classifier loss: 0.297790; batch adversarial loss: 0.628168\n",
      "epoch 23; iter: 0; batch classifier loss: 0.313780; batch adversarial loss: 0.685519\n",
      "epoch 23; iter: 200; batch classifier loss: 0.359186; batch adversarial loss: 0.629728\n",
      "epoch 24; iter: 0; batch classifier loss: 0.407607; batch adversarial loss: 0.666856\n",
      "epoch 24; iter: 200; batch classifier loss: 0.286348; batch adversarial loss: 0.645661\n",
      "epoch 25; iter: 0; batch classifier loss: 0.344852; batch adversarial loss: 0.613832\n",
      "epoch 25; iter: 200; batch classifier loss: 0.361715; batch adversarial loss: 0.626740\n",
      "epoch 26; iter: 0; batch classifier loss: 0.317042; batch adversarial loss: 0.597116\n",
      "epoch 26; iter: 200; batch classifier loss: 0.364322; batch adversarial loss: 0.608290\n",
      "epoch 27; iter: 0; batch classifier loss: 0.346906; batch adversarial loss: 0.637023\n",
      "epoch 27; iter: 200; batch classifier loss: 0.394042; batch adversarial loss: 0.663983\n",
      "epoch 28; iter: 0; batch classifier loss: 0.322550; batch adversarial loss: 0.610620\n",
      "epoch 28; iter: 200; batch classifier loss: 0.369239; batch adversarial loss: 0.640421\n",
      "epoch 29; iter: 0; batch classifier loss: 0.347276; batch adversarial loss: 0.593151\n",
      "epoch 29; iter: 200; batch classifier loss: 0.410724; batch adversarial loss: 0.617738\n",
      "epoch 30; iter: 0; batch classifier loss: 0.326039; batch adversarial loss: 0.617077\n",
      "epoch 30; iter: 200; batch classifier loss: 0.443388; batch adversarial loss: 0.615883\n",
      "epoch 31; iter: 0; batch classifier loss: 0.393031; batch adversarial loss: 0.587674\n",
      "epoch 31; iter: 200; batch classifier loss: 0.484154; batch adversarial loss: 0.592895\n",
      "epoch 32; iter: 0; batch classifier loss: 0.309796; batch adversarial loss: 0.705632\n",
      "epoch 32; iter: 200; batch classifier loss: 0.345491; batch adversarial loss: 0.633416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.286911; batch adversarial loss: 0.640420\n",
      "epoch 33; iter: 200; batch classifier loss: 0.342276; batch adversarial loss: 0.695921\n",
      "epoch 34; iter: 0; batch classifier loss: 0.378305; batch adversarial loss: 0.630617\n",
      "epoch 34; iter: 200; batch classifier loss: 0.367022; batch adversarial loss: 0.604714\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402482; batch adversarial loss: 0.623181\n",
      "epoch 35; iter: 200; batch classifier loss: 0.308108; batch adversarial loss: 0.628788\n",
      "epoch 36; iter: 0; batch classifier loss: 0.346081; batch adversarial loss: 0.594719\n",
      "epoch 36; iter: 200; batch classifier loss: 0.347908; batch adversarial loss: 0.611068\n",
      "epoch 37; iter: 0; batch classifier loss: 0.490356; batch adversarial loss: 0.578714\n",
      "epoch 37; iter: 200; batch classifier loss: 0.396741; batch adversarial loss: 0.639182\n",
      "epoch 38; iter: 0; batch classifier loss: 0.328511; batch adversarial loss: 0.570742\n",
      "epoch 38; iter: 200; batch classifier loss: 0.395491; batch adversarial loss: 0.630153\n",
      "epoch 39; iter: 0; batch classifier loss: 0.433345; batch adversarial loss: 0.613711\n",
      "epoch 39; iter: 200; batch classifier loss: 0.333317; batch adversarial loss: 0.595680\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413158; batch adversarial loss: 0.578124\n",
      "epoch 40; iter: 200; batch classifier loss: 0.375297; batch adversarial loss: 0.651078\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411741; batch adversarial loss: 0.680939\n",
      "epoch 41; iter: 200; batch classifier loss: 0.392832; batch adversarial loss: 0.666040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.300136; batch adversarial loss: 0.618686\n",
      "epoch 42; iter: 200; batch classifier loss: 0.440165; batch adversarial loss: 0.654364\n",
      "epoch 43; iter: 0; batch classifier loss: 0.305041; batch adversarial loss: 0.637270\n",
      "epoch 43; iter: 200; batch classifier loss: 0.307582; batch adversarial loss: 0.662690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.252256; batch adversarial loss: 0.605604\n",
      "epoch 44; iter: 200; batch classifier loss: 0.389892; batch adversarial loss: 0.659730\n",
      "epoch 45; iter: 0; batch classifier loss: 0.381478; batch adversarial loss: 0.668243\n",
      "epoch 45; iter: 200; batch classifier loss: 0.296537; batch adversarial loss: 0.608106\n",
      "epoch 46; iter: 0; batch classifier loss: 0.445571; batch adversarial loss: 0.615116\n",
      "epoch 46; iter: 200; batch classifier loss: 0.315077; batch adversarial loss: 0.610971\n",
      "epoch 47; iter: 0; batch classifier loss: 0.257875; batch adversarial loss: 0.654354\n",
      "epoch 47; iter: 200; batch classifier loss: 0.330072; batch adversarial loss: 0.631227\n",
      "epoch 48; iter: 0; batch classifier loss: 0.361557; batch adversarial loss: 0.581978\n",
      "epoch 48; iter: 200; batch classifier loss: 0.388796; batch adversarial loss: 0.588803\n",
      "epoch 49; iter: 0; batch classifier loss: 0.286367; batch adversarial loss: 0.661106\n",
      "epoch 49; iter: 200; batch classifier loss: 0.348473; batch adversarial loss: 0.601142\n",
      "epoch 0; iter: 0; batch classifier loss: 22.726919; batch adversarial loss: 0.595394\n",
      "epoch 0; iter: 200; batch classifier loss: 23.839136; batch adversarial loss: 0.656187\n",
      "epoch 1; iter: 0; batch classifier loss: 11.024945; batch adversarial loss: 0.655295\n",
      "epoch 1; iter: 200; batch classifier loss: 15.811739; batch adversarial loss: 0.655997\n",
      "epoch 2; iter: 0; batch classifier loss: 3.474110; batch adversarial loss: 0.635483\n",
      "epoch 2; iter: 200; batch classifier loss: 1.470048; batch adversarial loss: 0.641318\n",
      "epoch 3; iter: 0; batch classifier loss: 2.167653; batch adversarial loss: 0.666915\n",
      "epoch 3; iter: 200; batch classifier loss: 3.486641; batch adversarial loss: 0.603821\n",
      "epoch 4; iter: 0; batch classifier loss: 8.478922; batch adversarial loss: 0.643887\n",
      "epoch 4; iter: 200; batch classifier loss: 3.023265; batch adversarial loss: 0.627108\n",
      "epoch 5; iter: 0; batch classifier loss: 1.568588; batch adversarial loss: 0.634462\n",
      "epoch 5; iter: 200; batch classifier loss: 4.468392; batch adversarial loss: 0.646750\n",
      "epoch 6; iter: 0; batch classifier loss: 1.397515; batch adversarial loss: 0.592035\n",
      "epoch 6; iter: 200; batch classifier loss: 2.796188; batch adversarial loss: 0.619492\n",
      "epoch 7; iter: 0; batch classifier loss: 2.250554; batch adversarial loss: 0.612877\n",
      "epoch 7; iter: 200; batch classifier loss: 0.754634; batch adversarial loss: 0.648168\n",
      "epoch 8; iter: 0; batch classifier loss: 0.763925; batch adversarial loss: 0.654077\n",
      "epoch 8; iter: 200; batch classifier loss: 0.561948; batch adversarial loss: 0.633214\n",
      "epoch 9; iter: 0; batch classifier loss: 0.624449; batch adversarial loss: 0.640218\n",
      "epoch 9; iter: 200; batch classifier loss: 0.568714; batch adversarial loss: 0.652938\n",
      "epoch 10; iter: 0; batch classifier loss: 1.324001; batch adversarial loss: 0.592846\n",
      "epoch 10; iter: 200; batch classifier loss: 0.591918; batch adversarial loss: 0.574233\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381267; batch adversarial loss: 0.680023\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412170; batch adversarial loss: 0.631349\n",
      "epoch 12; iter: 0; batch classifier loss: 0.278622; batch adversarial loss: 0.637945\n",
      "epoch 12; iter: 200; batch classifier loss: 0.458483; batch adversarial loss: 0.621327\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412482; batch adversarial loss: 0.622224\n",
      "epoch 13; iter: 200; batch classifier loss: 0.443791; batch adversarial loss: 0.577232\n",
      "epoch 14; iter: 0; batch classifier loss: 0.415898; batch adversarial loss: 0.574393\n",
      "epoch 14; iter: 200; batch classifier loss: 0.333584; batch adversarial loss: 0.592858\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371281; batch adversarial loss: 0.609607\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387203; batch adversarial loss: 0.620720\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379556; batch adversarial loss: 0.640904\n",
      "epoch 16; iter: 200; batch classifier loss: 0.360647; batch adversarial loss: 0.587069\n",
      "epoch 17; iter: 0; batch classifier loss: 0.302029; batch adversarial loss: 0.609341\n",
      "epoch 17; iter: 200; batch classifier loss: 0.372121; batch adversarial loss: 0.635637\n",
      "epoch 18; iter: 0; batch classifier loss: 0.388296; batch adversarial loss: 0.620813\n",
      "epoch 18; iter: 200; batch classifier loss: 0.405340; batch adversarial loss: 0.619923\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315383; batch adversarial loss: 0.640056\n",
      "epoch 19; iter: 200; batch classifier loss: 0.369419; batch adversarial loss: 0.581241\n",
      "epoch 20; iter: 0; batch classifier loss: 0.427342; batch adversarial loss: 0.610982\n",
      "epoch 20; iter: 200; batch classifier loss: 0.354440; batch adversarial loss: 0.619556\n",
      "epoch 21; iter: 0; batch classifier loss: 0.416736; batch adversarial loss: 0.606293\n",
      "epoch 21; iter: 200; batch classifier loss: 0.343183; batch adversarial loss: 0.570170\n",
      "epoch 22; iter: 0; batch classifier loss: 0.356222; batch adversarial loss: 0.576509\n",
      "epoch 22; iter: 200; batch classifier loss: 0.622357; batch adversarial loss: 0.606191\n",
      "epoch 23; iter: 0; batch classifier loss: 0.406084; batch adversarial loss: 0.598942\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371263; batch adversarial loss: 0.599157\n",
      "epoch 24; iter: 0; batch classifier loss: 0.341372; batch adversarial loss: 0.601660\n",
      "epoch 24; iter: 200; batch classifier loss: 0.377789; batch adversarial loss: 0.591417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.302854; batch adversarial loss: 0.686044\n",
      "epoch 25; iter: 200; batch classifier loss: 0.368970; batch adversarial loss: 0.609240\n",
      "epoch 26; iter: 0; batch classifier loss: 0.303076; batch adversarial loss: 0.617410\n",
      "epoch 26; iter: 200; batch classifier loss: 0.368213; batch adversarial loss: 0.629461\n",
      "epoch 27; iter: 0; batch classifier loss: 0.412276; batch adversarial loss: 0.607720\n",
      "epoch 27; iter: 200; batch classifier loss: 0.356677; batch adversarial loss: 0.639367\n",
      "epoch 28; iter: 0; batch classifier loss: 0.326295; batch adversarial loss: 0.652743\n",
      "epoch 28; iter: 200; batch classifier loss: 0.466768; batch adversarial loss: 0.633764\n",
      "epoch 29; iter: 0; batch classifier loss: 0.259906; batch adversarial loss: 0.612898\n",
      "epoch 29; iter: 200; batch classifier loss: 0.289614; batch adversarial loss: 0.604332\n",
      "epoch 30; iter: 0; batch classifier loss: 0.376647; batch adversarial loss: 0.653157\n",
      "epoch 30; iter: 200; batch classifier loss: 0.305565; batch adversarial loss: 0.627206\n",
      "epoch 31; iter: 0; batch classifier loss: 0.333876; batch adversarial loss: 0.636756\n",
      "epoch 31; iter: 200; batch classifier loss: 0.367867; batch adversarial loss: 0.642611\n",
      "epoch 32; iter: 0; batch classifier loss: 0.278867; batch adversarial loss: 0.627598\n",
      "epoch 32; iter: 200; batch classifier loss: 0.326994; batch adversarial loss: 0.588171\n",
      "epoch 33; iter: 0; batch classifier loss: 0.291167; batch adversarial loss: 0.629638\n",
      "epoch 33; iter: 200; batch classifier loss: 0.602373; batch adversarial loss: 0.634257\n",
      "epoch 34; iter: 0; batch classifier loss: 0.311320; batch adversarial loss: 0.715844\n",
      "epoch 34; iter: 200; batch classifier loss: 0.378547; batch adversarial loss: 0.619653\n",
      "epoch 35; iter: 0; batch classifier loss: 0.338690; batch adversarial loss: 0.592478\n",
      "epoch 35; iter: 200; batch classifier loss: 0.358014; batch adversarial loss: 0.594433\n",
      "epoch 36; iter: 0; batch classifier loss: 0.650396; batch adversarial loss: 0.590970\n",
      "epoch 36; iter: 200; batch classifier loss: 0.314195; batch adversarial loss: 0.583194\n",
      "epoch 37; iter: 0; batch classifier loss: 0.333963; batch adversarial loss: 0.662892\n",
      "epoch 37; iter: 200; batch classifier loss: 0.406123; batch adversarial loss: 0.605988\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478342; batch adversarial loss: 0.618578\n",
      "epoch 38; iter: 200; batch classifier loss: 0.335761; batch adversarial loss: 0.620782\n",
      "epoch 39; iter: 0; batch classifier loss: 0.332285; batch adversarial loss: 0.637527\n",
      "epoch 39; iter: 200; batch classifier loss: 0.352042; batch adversarial loss: 0.614073\n",
      "epoch 40; iter: 0; batch classifier loss: 0.328071; batch adversarial loss: 0.635967\n",
      "epoch 40; iter: 200; batch classifier loss: 0.354151; batch adversarial loss: 0.606936\n",
      "epoch 41; iter: 0; batch classifier loss: 0.341388; batch adversarial loss: 0.642063\n",
      "epoch 41; iter: 200; batch classifier loss: 0.365623; batch adversarial loss: 0.571187\n",
      "epoch 42; iter: 0; batch classifier loss: 0.326272; batch adversarial loss: 0.719901\n",
      "epoch 42; iter: 200; batch classifier loss: 0.454096; batch adversarial loss: 0.619378\n",
      "epoch 43; iter: 0; batch classifier loss: 0.365124; batch adversarial loss: 0.582690\n",
      "epoch 43; iter: 200; batch classifier loss: 0.286467; batch adversarial loss: 0.625863\n",
      "epoch 44; iter: 0; batch classifier loss: 0.301721; batch adversarial loss: 0.705499\n",
      "epoch 44; iter: 200; batch classifier loss: 0.325421; batch adversarial loss: 0.594793\n",
      "epoch 45; iter: 0; batch classifier loss: 0.438014; batch adversarial loss: 0.643503\n",
      "epoch 45; iter: 200; batch classifier loss: 0.397520; batch adversarial loss: 0.597975\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392101; batch adversarial loss: 0.654255\n",
      "epoch 46; iter: 200; batch classifier loss: 0.359027; batch adversarial loss: 0.635101\n",
      "epoch 47; iter: 0; batch classifier loss: 0.466126; batch adversarial loss: 0.639746\n",
      "epoch 47; iter: 200; batch classifier loss: 0.336947; batch adversarial loss: 0.650955\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380668; batch adversarial loss: 0.662659\n",
      "epoch 48; iter: 200; batch classifier loss: 0.767042; batch adversarial loss: 0.640405\n",
      "epoch 49; iter: 0; batch classifier loss: 0.417768; batch adversarial loss: 0.594764\n",
      "epoch 49; iter: 200; batch classifier loss: 0.410684; batch adversarial loss: 0.603897\n",
      "epoch 0; iter: 0; batch classifier loss: 187.741562; batch adversarial loss: 0.684075\n",
      "epoch 0; iter: 200; batch classifier loss: 8.194160; batch adversarial loss: 0.662785\n",
      "epoch 1; iter: 0; batch classifier loss: 9.712515; batch adversarial loss: 0.643570\n",
      "epoch 1; iter: 200; batch classifier loss: 8.079415; batch adversarial loss: 0.664509\n",
      "epoch 2; iter: 0; batch classifier loss: 16.594395; batch adversarial loss: 0.634831\n",
      "epoch 2; iter: 200; batch classifier loss: 4.476067; batch adversarial loss: 0.618018\n",
      "epoch 3; iter: 0; batch classifier loss: 5.207961; batch adversarial loss: 0.637768\n",
      "epoch 3; iter: 200; batch classifier loss: 13.772387; batch adversarial loss: 0.562774\n",
      "epoch 4; iter: 0; batch classifier loss: 0.924504; batch adversarial loss: 0.598862\n",
      "epoch 4; iter: 200; batch classifier loss: 3.042638; batch adversarial loss: 0.615954\n",
      "epoch 5; iter: 0; batch classifier loss: 2.152316; batch adversarial loss: 0.631820\n",
      "epoch 5; iter: 200; batch classifier loss: 3.201443; batch adversarial loss: 0.627230\n",
      "epoch 6; iter: 0; batch classifier loss: 1.954427; batch adversarial loss: 0.672826\n",
      "epoch 6; iter: 200; batch classifier loss: 2.423934; batch adversarial loss: 0.616043\n",
      "epoch 7; iter: 0; batch classifier loss: 4.597433; batch adversarial loss: 0.571871\n",
      "epoch 7; iter: 200; batch classifier loss: 1.007627; batch adversarial loss: 0.615868\n",
      "epoch 8; iter: 0; batch classifier loss: 1.934948; batch adversarial loss: 0.656369\n",
      "epoch 8; iter: 200; batch classifier loss: 1.581399; batch adversarial loss: 0.585202\n",
      "epoch 9; iter: 0; batch classifier loss: 1.369957; batch adversarial loss: 0.610555\n",
      "epoch 9; iter: 200; batch classifier loss: 0.946754; batch adversarial loss: 0.625757\n",
      "epoch 10; iter: 0; batch classifier loss: 0.357571; batch adversarial loss: 0.614908\n",
      "epoch 10; iter: 200; batch classifier loss: 0.445394; batch adversarial loss: 0.583087\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496333; batch adversarial loss: 0.612103\n",
      "epoch 11; iter: 200; batch classifier loss: 0.534112; batch adversarial loss: 0.633231\n",
      "epoch 12; iter: 0; batch classifier loss: 0.525397; batch adversarial loss: 0.650098\n",
      "epoch 12; iter: 200; batch classifier loss: 1.315207; batch adversarial loss: 0.588024\n",
      "epoch 13; iter: 0; batch classifier loss: 0.385453; batch adversarial loss: 0.633516\n",
      "epoch 13; iter: 200; batch classifier loss: 0.503700; batch adversarial loss: 0.625182\n",
      "epoch 14; iter: 0; batch classifier loss: 0.643886; batch adversarial loss: 0.634121\n",
      "epoch 14; iter: 200; batch classifier loss: 0.418614; batch adversarial loss: 0.623963\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287169; batch adversarial loss: 0.644175\n",
      "epoch 15; iter: 200; batch classifier loss: 0.339472; batch adversarial loss: 0.628744\n",
      "epoch 16; iter: 0; batch classifier loss: 0.421476; batch adversarial loss: 0.684281\n",
      "epoch 16; iter: 200; batch classifier loss: 0.369547; batch adversarial loss: 0.647550\n",
      "epoch 17; iter: 0; batch classifier loss: 0.475104; batch adversarial loss: 0.563230\n",
      "epoch 17; iter: 200; batch classifier loss: 0.381043; batch adversarial loss: 0.584863\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319187; batch adversarial loss: 0.620337\n",
      "epoch 18; iter: 200; batch classifier loss: 0.301700; batch adversarial loss: 0.634199\n",
      "epoch 19; iter: 0; batch classifier loss: 0.413954; batch adversarial loss: 0.630025\n",
      "epoch 19; iter: 200; batch classifier loss: 0.335933; batch adversarial loss: 0.528788\n",
      "epoch 20; iter: 0; batch classifier loss: 0.395833; batch adversarial loss: 0.625429\n",
      "epoch 20; iter: 200; batch classifier loss: 0.489826; batch adversarial loss: 0.595513\n",
      "epoch 21; iter: 0; batch classifier loss: 0.349696; batch adversarial loss: 0.615259\n",
      "epoch 21; iter: 200; batch classifier loss: 0.344191; batch adversarial loss: 0.712171\n",
      "epoch 22; iter: 0; batch classifier loss: 0.380078; batch adversarial loss: 0.622817\n",
      "epoch 22; iter: 200; batch classifier loss: 0.416583; batch adversarial loss: 0.618546\n",
      "epoch 23; iter: 0; batch classifier loss: 0.291001; batch adversarial loss: 0.677084\n",
      "epoch 23; iter: 200; batch classifier loss: 0.424907; batch adversarial loss: 0.601118\n",
      "epoch 24; iter: 0; batch classifier loss: 0.373129; batch adversarial loss: 0.618241\n",
      "epoch 24; iter: 200; batch classifier loss: 0.407403; batch adversarial loss: 0.597523\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442217; batch adversarial loss: 0.611858\n",
      "epoch 25; iter: 200; batch classifier loss: 0.308525; batch adversarial loss: 0.639849\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428826; batch adversarial loss: 0.587164\n",
      "epoch 26; iter: 200; batch classifier loss: 0.265117; batch adversarial loss: 0.619923\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362470; batch adversarial loss: 0.698341\n",
      "epoch 27; iter: 200; batch classifier loss: 0.355282; batch adversarial loss: 0.613281\n",
      "epoch 28; iter: 0; batch classifier loss: 0.336140; batch adversarial loss: 0.650143\n",
      "epoch 28; iter: 200; batch classifier loss: 0.335602; batch adversarial loss: 0.628829\n",
      "epoch 29; iter: 0; batch classifier loss: 0.366414; batch adversarial loss: 0.591003\n",
      "epoch 29; iter: 200; batch classifier loss: 0.411972; batch adversarial loss: 0.624952\n",
      "epoch 30; iter: 0; batch classifier loss: 0.328337; batch adversarial loss: 0.612617\n",
      "epoch 30; iter: 200; batch classifier loss: 0.306953; batch adversarial loss: 0.618989\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400397; batch adversarial loss: 0.644435\n",
      "epoch 31; iter: 200; batch classifier loss: 0.361483; batch adversarial loss: 0.599023\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415318; batch adversarial loss: 0.638665\n",
      "epoch 32; iter: 200; batch classifier loss: 0.298001; batch adversarial loss: 0.628181\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408960; batch adversarial loss: 0.597542\n",
      "epoch 33; iter: 200; batch classifier loss: 0.278132; batch adversarial loss: 0.562297\n",
      "epoch 34; iter: 0; batch classifier loss: 0.333386; batch adversarial loss: 0.642412\n",
      "epoch 34; iter: 200; batch classifier loss: 0.328511; batch adversarial loss: 0.656380\n",
      "epoch 35; iter: 0; batch classifier loss: 0.402339; batch adversarial loss: 0.634320\n",
      "epoch 35; iter: 200; batch classifier loss: 0.314799; batch adversarial loss: 0.629821\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432322; batch adversarial loss: 0.574955\n",
      "epoch 36; iter: 200; batch classifier loss: 0.376382; batch adversarial loss: 0.570186\n",
      "epoch 37; iter: 0; batch classifier loss: 0.380632; batch adversarial loss: 0.618366\n",
      "epoch 37; iter: 200; batch classifier loss: 0.308264; batch adversarial loss: 0.590486\n",
      "epoch 38; iter: 0; batch classifier loss: 0.516150; batch adversarial loss: 0.611238\n",
      "epoch 38; iter: 200; batch classifier loss: 0.334917; batch adversarial loss: 0.629198\n",
      "epoch 39; iter: 0; batch classifier loss: 0.368310; batch adversarial loss: 0.648686\n",
      "epoch 39; iter: 200; batch classifier loss: 0.282917; batch adversarial loss: 0.578357\n",
      "epoch 40; iter: 0; batch classifier loss: 0.302823; batch adversarial loss: 0.589738\n",
      "epoch 40; iter: 200; batch classifier loss: 0.493897; batch adversarial loss: 0.680228\n",
      "epoch 41; iter: 0; batch classifier loss: 0.379378; batch adversarial loss: 0.625324\n",
      "epoch 41; iter: 200; batch classifier loss: 0.291694; batch adversarial loss: 0.661536\n",
      "epoch 42; iter: 0; batch classifier loss: 0.323456; batch adversarial loss: 0.621292\n",
      "epoch 42; iter: 200; batch classifier loss: 0.344382; batch adversarial loss: 0.590092\n",
      "epoch 43; iter: 0; batch classifier loss: 0.305672; batch adversarial loss: 0.630443\n",
      "epoch 43; iter: 200; batch classifier loss: 0.400145; batch adversarial loss: 0.594234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.353977; batch adversarial loss: 0.625621\n",
      "epoch 44; iter: 200; batch classifier loss: 0.434237; batch adversarial loss: 0.647271\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414124; batch adversarial loss: 0.625717\n",
      "epoch 45; iter: 200; batch classifier loss: 0.401689; batch adversarial loss: 0.628956\n",
      "epoch 46; iter: 0; batch classifier loss: 0.489163; batch adversarial loss: 0.558058\n",
      "epoch 46; iter: 200; batch classifier loss: 0.357959; batch adversarial loss: 0.657884\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340388; batch adversarial loss: 0.640248\n",
      "epoch 47; iter: 200; batch classifier loss: 0.357172; batch adversarial loss: 0.641059\n",
      "epoch 48; iter: 0; batch classifier loss: 0.320098; batch adversarial loss: 0.565246\n",
      "epoch 48; iter: 200; batch classifier loss: 0.410809; batch adversarial loss: 0.699784\n",
      "epoch 49; iter: 0; batch classifier loss: 0.378135; batch adversarial loss: 0.568875\n",
      "epoch 49; iter: 200; batch classifier loss: 0.443617; batch adversarial loss: 0.597684\n",
      "epoch 0; iter: 0; batch classifier loss: 25.572392; batch adversarial loss: 0.586665\n",
      "epoch 0; iter: 200; batch classifier loss: 37.436245; batch adversarial loss: 0.676888\n",
      "epoch 1; iter: 0; batch classifier loss: 11.887604; batch adversarial loss: 0.640256\n",
      "epoch 1; iter: 200; batch classifier loss: 15.101028; batch adversarial loss: 0.641230\n",
      "epoch 2; iter: 0; batch classifier loss: 10.428936; batch adversarial loss: 0.622608\n",
      "epoch 2; iter: 200; batch classifier loss: 7.998019; batch adversarial loss: 0.633218\n",
      "epoch 3; iter: 0; batch classifier loss: 2.865853; batch adversarial loss: 0.607265\n",
      "epoch 3; iter: 200; batch classifier loss: 6.382005; batch adversarial loss: 0.641739\n",
      "epoch 4; iter: 0; batch classifier loss: 4.423823; batch adversarial loss: 0.597153\n",
      "epoch 4; iter: 200; batch classifier loss: 1.433118; batch adversarial loss: 0.588216\n",
      "epoch 5; iter: 0; batch classifier loss: 4.172137; batch adversarial loss: 0.649183\n",
      "epoch 5; iter: 200; batch classifier loss: 4.580850; batch adversarial loss: 0.679522\n",
      "epoch 6; iter: 0; batch classifier loss: 1.442595; batch adversarial loss: 0.631028\n",
      "epoch 6; iter: 200; batch classifier loss: 2.086101; batch adversarial loss: 0.590733\n",
      "epoch 7; iter: 0; batch classifier loss: 1.300407; batch adversarial loss: 0.623868\n",
      "epoch 7; iter: 200; batch classifier loss: 1.524661; batch adversarial loss: 0.656131\n",
      "epoch 8; iter: 0; batch classifier loss: 1.285101; batch adversarial loss: 0.611964\n",
      "epoch 8; iter: 200; batch classifier loss: 0.580580; batch adversarial loss: 0.631814\n",
      "epoch 9; iter: 0; batch classifier loss: 0.854724; batch adversarial loss: 0.624860\n",
      "epoch 9; iter: 200; batch classifier loss: 0.368959; batch adversarial loss: 0.661677\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576519; batch adversarial loss: 0.597930\n",
      "epoch 10; iter: 200; batch classifier loss: 0.454699; batch adversarial loss: 0.599276\n",
      "epoch 11; iter: 0; batch classifier loss: 1.169760; batch adversarial loss: 0.618165\n",
      "epoch 11; iter: 200; batch classifier loss: 0.644843; batch adversarial loss: 0.590431\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547360; batch adversarial loss: 0.607802\n",
      "epoch 12; iter: 200; batch classifier loss: 0.536887; batch adversarial loss: 0.636153\n",
      "epoch 13; iter: 0; batch classifier loss: 0.454830; batch adversarial loss: 0.589920\n",
      "epoch 13; iter: 200; batch classifier loss: 0.473092; batch adversarial loss: 0.592072\n",
      "epoch 14; iter: 0; batch classifier loss: 0.416948; batch adversarial loss: 0.622571\n",
      "epoch 14; iter: 200; batch classifier loss: 0.385484; batch adversarial loss: 0.587783\n",
      "epoch 15; iter: 0; batch classifier loss: 0.455817; batch adversarial loss: 0.593264\n",
      "epoch 15; iter: 200; batch classifier loss: 0.422938; batch adversarial loss: 0.636827\n",
      "epoch 16; iter: 0; batch classifier loss: 0.446181; batch adversarial loss: 0.642853\n",
      "epoch 16; iter: 200; batch classifier loss: 0.327706; batch adversarial loss: 0.647240\n",
      "epoch 17; iter: 0; batch classifier loss: 0.401958; batch adversarial loss: 0.622578\n",
      "epoch 17; iter: 200; batch classifier loss: 0.324000; batch adversarial loss: 0.662027\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349012; batch adversarial loss: 0.625718\n",
      "epoch 18; iter: 200; batch classifier loss: 0.384433; batch adversarial loss: 0.646510\n",
      "epoch 19; iter: 0; batch classifier loss: 0.312789; batch adversarial loss: 0.640121\n",
      "epoch 19; iter: 200; batch classifier loss: 0.306277; batch adversarial loss: 0.593780\n",
      "epoch 20; iter: 0; batch classifier loss: 0.316804; batch adversarial loss: 0.588548\n",
      "epoch 20; iter: 200; batch classifier loss: 0.373857; batch adversarial loss: 0.582062\n",
      "epoch 21; iter: 0; batch classifier loss: 0.349380; batch adversarial loss: 0.600034\n",
      "epoch 21; iter: 200; batch classifier loss: 0.365062; batch adversarial loss: 0.641161\n",
      "epoch 22; iter: 0; batch classifier loss: 0.345678; batch adversarial loss: 0.627459\n",
      "epoch 22; iter: 200; batch classifier loss: 0.400377; batch adversarial loss: 0.604948\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418754; batch adversarial loss: 0.596498\n",
      "epoch 23; iter: 200; batch classifier loss: 0.447608; batch adversarial loss: 0.557714\n",
      "epoch 24; iter: 0; batch classifier loss: 0.416205; batch adversarial loss: 0.618714\n",
      "epoch 24; iter: 200; batch classifier loss: 0.359095; batch adversarial loss: 0.609680\n",
      "epoch 25; iter: 0; batch classifier loss: 0.374316; batch adversarial loss: 0.621934\n",
      "epoch 25; iter: 200; batch classifier loss: 0.318996; batch adversarial loss: 0.622816\n",
      "epoch 26; iter: 0; batch classifier loss: 0.304407; batch adversarial loss: 0.603630\n",
      "epoch 26; iter: 200; batch classifier loss: 0.377097; batch adversarial loss: 0.663084\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433719; batch adversarial loss: 0.577838\n",
      "epoch 27; iter: 200; batch classifier loss: 0.239959; batch adversarial loss: 0.622381\n",
      "epoch 28; iter: 0; batch classifier loss: 0.359732; batch adversarial loss: 0.612710\n",
      "epoch 28; iter: 200; batch classifier loss: 0.373320; batch adversarial loss: 0.643235\n",
      "epoch 29; iter: 0; batch classifier loss: 0.365033; batch adversarial loss: 0.631220\n",
      "epoch 29; iter: 200; batch classifier loss: 0.419026; batch adversarial loss: 0.665946\n",
      "epoch 30; iter: 0; batch classifier loss: 0.398116; batch adversarial loss: 0.639169\n",
      "epoch 30; iter: 200; batch classifier loss: 0.389534; batch adversarial loss: 0.660358\n",
      "epoch 31; iter: 0; batch classifier loss: 0.274336; batch adversarial loss: 0.698831\n",
      "epoch 31; iter: 200; batch classifier loss: 0.358327; batch adversarial loss: 0.642309\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449710; batch adversarial loss: 0.609859\n",
      "epoch 32; iter: 200; batch classifier loss: 0.315169; batch adversarial loss: 0.600674\n",
      "epoch 33; iter: 0; batch classifier loss: 0.394956; batch adversarial loss: 0.633037\n",
      "epoch 33; iter: 200; batch classifier loss: 0.273165; batch adversarial loss: 0.576307\n",
      "epoch 34; iter: 0; batch classifier loss: 0.332808; batch adversarial loss: 0.655648\n",
      "epoch 34; iter: 200; batch classifier loss: 0.493002; batch adversarial loss: 0.595145\n",
      "epoch 35; iter: 0; batch classifier loss: 0.409943; batch adversarial loss: 0.625816\n",
      "epoch 35; iter: 200; batch classifier loss: 0.351232; batch adversarial loss: 0.588227\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261830; batch adversarial loss: 0.676634\n",
      "epoch 36; iter: 200; batch classifier loss: 0.318965; batch adversarial loss: 0.603137\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407474; batch adversarial loss: 0.620391\n",
      "epoch 37; iter: 200; batch classifier loss: 0.334906; batch adversarial loss: 0.609104\n",
      "epoch 38; iter: 0; batch classifier loss: 0.352559; batch adversarial loss: 0.607372\n",
      "epoch 38; iter: 200; batch classifier loss: 0.309206; batch adversarial loss: 0.627030\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396697; batch adversarial loss: 0.595051\n",
      "epoch 39; iter: 200; batch classifier loss: 0.305434; batch adversarial loss: 0.670717\n",
      "epoch 40; iter: 0; batch classifier loss: 0.310502; batch adversarial loss: 0.628019\n",
      "epoch 40; iter: 200; batch classifier loss: 0.399437; batch adversarial loss: 0.638865\n",
      "epoch 41; iter: 0; batch classifier loss: 0.284903; batch adversarial loss: 0.657565\n",
      "epoch 41; iter: 200; batch classifier loss: 0.319524; batch adversarial loss: 0.603131\n",
      "epoch 42; iter: 0; batch classifier loss: 0.306381; batch adversarial loss: 0.607027\n",
      "epoch 42; iter: 200; batch classifier loss: 0.311480; batch adversarial loss: 0.605879\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482062; batch adversarial loss: 0.627894\n",
      "epoch 43; iter: 200; batch classifier loss: 0.340254; batch adversarial loss: 0.635876\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375351; batch adversarial loss: 0.620680\n",
      "epoch 44; iter: 200; batch classifier loss: 0.309357; batch adversarial loss: 0.654986\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400392; batch adversarial loss: 0.591944\n",
      "epoch 45; iter: 200; batch classifier loss: 0.389687; batch adversarial loss: 0.617229\n",
      "epoch 46; iter: 0; batch classifier loss: 0.363249; batch adversarial loss: 0.585820\n",
      "epoch 46; iter: 200; batch classifier loss: 0.816843; batch adversarial loss: 0.601500\n",
      "epoch 47; iter: 0; batch classifier loss: 0.467879; batch adversarial loss: 0.606949\n",
      "epoch 47; iter: 200; batch classifier loss: 0.476105; batch adversarial loss: 0.581711\n",
      "epoch 48; iter: 0; batch classifier loss: 0.374967; batch adversarial loss: 0.600075\n",
      "epoch 48; iter: 200; batch classifier loss: 0.447088; batch adversarial loss: 0.616515\n",
      "epoch 49; iter: 0; batch classifier loss: 0.299217; batch adversarial loss: 0.642413\n",
      "epoch 49; iter: 200; batch classifier loss: 0.348941; batch adversarial loss: 0.604562\n",
      "epoch 0; iter: 0; batch classifier loss: 28.220942; batch adversarial loss: 0.696422\n",
      "epoch 0; iter: 200; batch classifier loss: 4.286734; batch adversarial loss: 0.658246\n",
      "epoch 1; iter: 0; batch classifier loss: 8.665717; batch adversarial loss: 0.660744\n",
      "epoch 1; iter: 200; batch classifier loss: 7.514450; batch adversarial loss: 0.648004\n",
      "epoch 2; iter: 0; batch classifier loss: 2.671035; batch adversarial loss: 0.636997\n",
      "epoch 2; iter: 200; batch classifier loss: 5.148074; batch adversarial loss: 0.612038\n",
      "epoch 3; iter: 0; batch classifier loss: 16.909752; batch adversarial loss: 0.663077\n",
      "epoch 3; iter: 200; batch classifier loss: 0.789247; batch adversarial loss: 0.631782\n",
      "epoch 4; iter: 0; batch classifier loss: 3.090453; batch adversarial loss: 0.624645\n",
      "epoch 4; iter: 200; batch classifier loss: 2.892868; batch adversarial loss: 0.644039\n",
      "epoch 5; iter: 0; batch classifier loss: 1.986806; batch adversarial loss: 0.665965\n",
      "epoch 5; iter: 200; batch classifier loss: 1.051959; batch adversarial loss: 0.615389\n",
      "epoch 6; iter: 0; batch classifier loss: 2.317868; batch adversarial loss: 0.597690\n",
      "epoch 6; iter: 200; batch classifier loss: 0.730675; batch adversarial loss: 0.644226\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553217; batch adversarial loss: 0.631607\n",
      "epoch 7; iter: 200; batch classifier loss: 0.565001; batch adversarial loss: 0.653443\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619159; batch adversarial loss: 0.587357\n",
      "epoch 8; iter: 200; batch classifier loss: 0.673165; batch adversarial loss: 0.602848\n",
      "epoch 9; iter: 0; batch classifier loss: 0.411017; batch adversarial loss: 0.643684\n",
      "epoch 9; iter: 200; batch classifier loss: 0.696324; batch adversarial loss: 0.685340\n",
      "epoch 10; iter: 0; batch classifier loss: 0.354427; batch adversarial loss: 0.695921\n",
      "epoch 10; iter: 200; batch classifier loss: 0.315741; batch adversarial loss: 0.612788\n",
      "epoch 11; iter: 0; batch classifier loss: 0.415339; batch adversarial loss: 0.617135\n",
      "epoch 11; iter: 200; batch classifier loss: 0.410954; batch adversarial loss: 0.618145\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452673; batch adversarial loss: 0.589884\n",
      "epoch 12; iter: 200; batch classifier loss: 0.520209; batch adversarial loss: 0.617356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448035; batch adversarial loss: 0.603363\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352455; batch adversarial loss: 0.622029\n",
      "epoch 14; iter: 0; batch classifier loss: 0.465757; batch adversarial loss: 0.577515\n",
      "epoch 14; iter: 200; batch classifier loss: 0.426592; batch adversarial loss: 0.628366\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463127; batch adversarial loss: 0.634791\n",
      "epoch 15; iter: 200; batch classifier loss: 0.323762; batch adversarial loss: 0.604647\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489169; batch adversarial loss: 0.571853\n",
      "epoch 16; iter: 200; batch classifier loss: 0.305644; batch adversarial loss: 0.627120\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397428; batch adversarial loss: 0.593437\n",
      "epoch 17; iter: 200; batch classifier loss: 0.282113; batch adversarial loss: 0.622590\n",
      "epoch 18; iter: 0; batch classifier loss: 0.404898; batch adversarial loss: 0.577729\n",
      "epoch 18; iter: 200; batch classifier loss: 0.346530; batch adversarial loss: 0.650547\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478875; batch adversarial loss: 0.597557\n",
      "epoch 19; iter: 200; batch classifier loss: 0.511125; batch adversarial loss: 0.592255\n",
      "epoch 20; iter: 0; batch classifier loss: 0.335639; batch adversarial loss: 0.652882\n",
      "epoch 20; iter: 200; batch classifier loss: 0.290227; batch adversarial loss: 0.647727\n",
      "epoch 21; iter: 0; batch classifier loss: 0.349303; batch adversarial loss: 0.621970\n",
      "epoch 21; iter: 200; batch classifier loss: 0.364447; batch adversarial loss: 0.600129\n",
      "epoch 22; iter: 0; batch classifier loss: 0.363951; batch adversarial loss: 0.633230\n",
      "epoch 22; iter: 200; batch classifier loss: 0.308282; batch adversarial loss: 0.651333\n",
      "epoch 23; iter: 0; batch classifier loss: 0.331148; batch adversarial loss: 0.616805\n",
      "epoch 23; iter: 200; batch classifier loss: 0.334513; batch adversarial loss: 0.573480\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338277; batch adversarial loss: 0.634769\n",
      "epoch 24; iter: 200; batch classifier loss: 0.345033; batch adversarial loss: 0.609533\n",
      "epoch 25; iter: 0; batch classifier loss: 0.310605; batch adversarial loss: 0.597578\n",
      "epoch 25; iter: 200; batch classifier loss: 0.325185; batch adversarial loss: 0.649636\n",
      "epoch 26; iter: 0; batch classifier loss: 0.305009; batch adversarial loss: 0.603704\n",
      "epoch 26; iter: 200; batch classifier loss: 0.388678; batch adversarial loss: 0.610943\n",
      "epoch 27; iter: 0; batch classifier loss: 0.382794; batch adversarial loss: 0.625447\n",
      "epoch 27; iter: 200; batch classifier loss: 0.327211; batch adversarial loss: 0.678698\n",
      "epoch 28; iter: 0; batch classifier loss: 0.361409; batch adversarial loss: 0.603302\n",
      "epoch 28; iter: 200; batch classifier loss: 0.238898; batch adversarial loss: 0.628573\n",
      "epoch 29; iter: 0; batch classifier loss: 0.385856; batch adversarial loss: 0.624310\n",
      "epoch 29; iter: 200; batch classifier loss: 0.344016; batch adversarial loss: 0.682203\n",
      "epoch 30; iter: 0; batch classifier loss: 0.316757; batch adversarial loss: 0.698321\n",
      "epoch 30; iter: 200; batch classifier loss: 0.239524; batch adversarial loss: 0.669315\n",
      "epoch 31; iter: 0; batch classifier loss: 0.271511; batch adversarial loss: 0.720753\n",
      "epoch 31; iter: 200; batch classifier loss: 0.321311; batch adversarial loss: 0.604910\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423259; batch adversarial loss: 0.588205\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397748; batch adversarial loss: 0.612256\n",
      "epoch 33; iter: 0; batch classifier loss: 0.415867; batch adversarial loss: 0.581498\n",
      "epoch 33; iter: 200; batch classifier loss: 0.388923; batch adversarial loss: 0.635750\n",
      "epoch 34; iter: 0; batch classifier loss: 0.388675; batch adversarial loss: 0.722503\n",
      "epoch 34; iter: 200; batch classifier loss: 0.320772; batch adversarial loss: 0.623012\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420478; batch adversarial loss: 0.650317\n",
      "epoch 35; iter: 200; batch classifier loss: 0.355499; batch adversarial loss: 0.604532\n",
      "epoch 36; iter: 0; batch classifier loss: 0.508465; batch adversarial loss: 0.607403\n",
      "epoch 36; iter: 200; batch classifier loss: 0.383318; batch adversarial loss: 0.609366\n",
      "epoch 37; iter: 0; batch classifier loss: 0.366913; batch adversarial loss: 0.642938\n",
      "epoch 37; iter: 200; batch classifier loss: 0.384530; batch adversarial loss: 0.684096\n",
      "epoch 38; iter: 0; batch classifier loss: 0.328769; batch adversarial loss: 0.656427\n",
      "epoch 38; iter: 200; batch classifier loss: 0.422842; batch adversarial loss: 0.655527\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422297; batch adversarial loss: 0.601948\n",
      "epoch 39; iter: 200; batch classifier loss: 0.305776; batch adversarial loss: 0.588223\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501793; batch adversarial loss: 0.556148\n",
      "epoch 40; iter: 200; batch classifier loss: 0.336206; batch adversarial loss: 0.646160\n",
      "epoch 41; iter: 0; batch classifier loss: 0.300801; batch adversarial loss: 0.644495\n",
      "epoch 41; iter: 200; batch classifier loss: 0.461830; batch adversarial loss: 0.629692\n",
      "epoch 42; iter: 0; batch classifier loss: 0.337381; batch adversarial loss: 0.674498\n",
      "epoch 42; iter: 200; batch classifier loss: 0.329225; batch adversarial loss: 0.608728\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470329; batch adversarial loss: 0.625162\n",
      "epoch 43; iter: 200; batch classifier loss: 0.845201; batch adversarial loss: 0.629903\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430477; batch adversarial loss: 0.594572\n",
      "epoch 44; iter: 200; batch classifier loss: 0.317452; batch adversarial loss: 0.629910\n",
      "epoch 45; iter: 0; batch classifier loss: 0.365287; batch adversarial loss: 0.643962\n",
      "epoch 45; iter: 200; batch classifier loss: 0.489928; batch adversarial loss: 0.632265\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459308; batch adversarial loss: 0.573704\n",
      "epoch 46; iter: 200; batch classifier loss: 0.379096; batch adversarial loss: 0.643907\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441890; batch adversarial loss: 0.602280\n",
      "epoch 47; iter: 200; batch classifier loss: 0.412313; batch adversarial loss: 0.590542\n",
      "epoch 48; iter: 0; batch classifier loss: 0.427833; batch adversarial loss: 0.636876\n",
      "epoch 48; iter: 200; batch classifier loss: 0.294504; batch adversarial loss: 0.606487\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400208; batch adversarial loss: 0.614049\n",
      "epoch 49; iter: 200; batch classifier loss: 0.416986; batch adversarial loss: 0.641009\n",
      "epoch 0; iter: 0; batch classifier loss: 32.088379; batch adversarial loss: 0.766726\n",
      "epoch 0; iter: 200; batch classifier loss: 5.943561; batch adversarial loss: 0.699003\n",
      "epoch 1; iter: 0; batch classifier loss: 6.078619; batch adversarial loss: 0.672125\n",
      "epoch 1; iter: 200; batch classifier loss: 5.256719; batch adversarial loss: 0.642179\n",
      "epoch 2; iter: 0; batch classifier loss: 9.616922; batch adversarial loss: 0.642725\n",
      "epoch 2; iter: 200; batch classifier loss: 1.223471; batch adversarial loss: 0.633255\n",
      "epoch 3; iter: 0; batch classifier loss: 1.499429; batch adversarial loss: 0.635036\n",
      "epoch 3; iter: 200; batch classifier loss: 1.510405; batch adversarial loss: 0.631043\n",
      "epoch 4; iter: 0; batch classifier loss: 1.056831; batch adversarial loss: 0.577255\n",
      "epoch 4; iter: 200; batch classifier loss: 3.325131; batch adversarial loss: 0.623810\n",
      "epoch 5; iter: 0; batch classifier loss: 3.003423; batch adversarial loss: 0.669267\n",
      "epoch 5; iter: 200; batch classifier loss: 3.359036; batch adversarial loss: 0.653929\n",
      "epoch 6; iter: 0; batch classifier loss: 0.655146; batch adversarial loss: 0.656387\n",
      "epoch 6; iter: 200; batch classifier loss: 0.751928; batch adversarial loss: 0.694962\n",
      "epoch 7; iter: 0; batch classifier loss: 1.368726; batch adversarial loss: 0.733012\n",
      "epoch 7; iter: 200; batch classifier loss: 1.042523; batch adversarial loss: 0.650366\n",
      "epoch 8; iter: 0; batch classifier loss: 0.670720; batch adversarial loss: 0.649503\n",
      "epoch 8; iter: 200; batch classifier loss: 0.645953; batch adversarial loss: 0.617791\n",
      "epoch 9; iter: 0; batch classifier loss: 0.701666; batch adversarial loss: 0.636227\n",
      "epoch 9; iter: 200; batch classifier loss: 0.486191; batch adversarial loss: 0.615463\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413988; batch adversarial loss: 0.599492\n",
      "epoch 10; iter: 200; batch classifier loss: 0.666604; batch adversarial loss: 0.654457\n",
      "epoch 11; iter: 0; batch classifier loss: 0.412843; batch adversarial loss: 0.612437\n",
      "epoch 11; iter: 200; batch classifier loss: 0.597499; batch adversarial loss: 0.590023\n",
      "epoch 12; iter: 0; batch classifier loss: 0.641765; batch adversarial loss: 0.645047\n",
      "epoch 12; iter: 200; batch classifier loss: 0.489451; batch adversarial loss: 0.643184\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473913; batch adversarial loss: 0.620638\n",
      "epoch 13; iter: 200; batch classifier loss: 0.456432; batch adversarial loss: 0.653921\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432426; batch adversarial loss: 0.603639\n",
      "epoch 14; iter: 200; batch classifier loss: 0.485865; batch adversarial loss: 0.605667\n",
      "epoch 15; iter: 0; batch classifier loss: 0.506612; batch adversarial loss: 0.579274\n",
      "epoch 15; iter: 200; batch classifier loss: 0.416822; batch adversarial loss: 0.652987\n",
      "epoch 16; iter: 0; batch classifier loss: 0.438451; batch adversarial loss: 0.593439\n",
      "epoch 16; iter: 200; batch classifier loss: 0.381965; batch adversarial loss: 0.558077\n",
      "epoch 17; iter: 0; batch classifier loss: 0.452734; batch adversarial loss: 0.623248\n",
      "epoch 17; iter: 200; batch classifier loss: 0.411255; batch adversarial loss: 0.592554\n",
      "epoch 18; iter: 0; batch classifier loss: 0.441299; batch adversarial loss: 0.603259\n",
      "epoch 18; iter: 200; batch classifier loss: 0.364305; batch adversarial loss: 0.598223\n",
      "epoch 19; iter: 0; batch classifier loss: 0.366524; batch adversarial loss: 0.626573\n",
      "epoch 19; iter: 200; batch classifier loss: 0.397935; batch adversarial loss: 0.645339\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324548; batch adversarial loss: 0.669741\n",
      "epoch 20; iter: 200; batch classifier loss: 0.368775; batch adversarial loss: 0.608160\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282526; batch adversarial loss: 0.675871\n",
      "epoch 21; iter: 200; batch classifier loss: 0.307963; batch adversarial loss: 0.622949\n",
      "epoch 22; iter: 0; batch classifier loss: 0.326088; batch adversarial loss: 0.609539\n",
      "epoch 22; iter: 200; batch classifier loss: 0.391430; batch adversarial loss: 0.589176\n",
      "epoch 23; iter: 0; batch classifier loss: 0.282150; batch adversarial loss: 0.612174\n",
      "epoch 23; iter: 200; batch classifier loss: 0.301652; batch adversarial loss: 0.669078\n",
      "epoch 24; iter: 0; batch classifier loss: 0.300178; batch adversarial loss: 0.608555\n",
      "epoch 24; iter: 200; batch classifier loss: 0.368841; batch adversarial loss: 0.589146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.366189; batch adversarial loss: 0.598657\n",
      "epoch 25; iter: 200; batch classifier loss: 0.291778; batch adversarial loss: 0.651117\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346691; batch adversarial loss: 0.603250\n",
      "epoch 26; iter: 200; batch classifier loss: 0.366644; batch adversarial loss: 0.564196\n",
      "epoch 27; iter: 0; batch classifier loss: 0.268293; batch adversarial loss: 0.623154\n",
      "epoch 27; iter: 200; batch classifier loss: 0.294438; batch adversarial loss: 0.597912\n",
      "epoch 28; iter: 0; batch classifier loss: 0.332089; batch adversarial loss: 0.627788\n",
      "epoch 28; iter: 200; batch classifier loss: 0.352845; batch adversarial loss: 0.669644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.363615; batch adversarial loss: 0.563130\n",
      "epoch 29; iter: 200; batch classifier loss: 0.396944; batch adversarial loss: 0.671924\n",
      "epoch 30; iter: 0; batch classifier loss: 0.361320; batch adversarial loss: 0.651405\n",
      "epoch 30; iter: 200; batch classifier loss: 0.376127; batch adversarial loss: 0.588966\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499071; batch adversarial loss: 0.727213\n",
      "epoch 31; iter: 200; batch classifier loss: 0.368576; batch adversarial loss: 0.647012\n",
      "epoch 32; iter: 0; batch classifier loss: 0.446095; batch adversarial loss: 0.585647\n",
      "epoch 32; iter: 200; batch classifier loss: 0.354894; batch adversarial loss: 0.661405\n",
      "epoch 33; iter: 0; batch classifier loss: 0.371902; batch adversarial loss: 0.671466\n",
      "epoch 33; iter: 200; batch classifier loss: 0.317893; batch adversarial loss: 0.643636\n",
      "epoch 34; iter: 0; batch classifier loss: 0.338502; batch adversarial loss: 0.631770\n",
      "epoch 34; iter: 200; batch classifier loss: 0.343215; batch adversarial loss: 0.628520\n",
      "epoch 35; iter: 0; batch classifier loss: 0.330176; batch adversarial loss: 0.561200\n",
      "epoch 35; iter: 200; batch classifier loss: 0.386397; batch adversarial loss: 0.610123\n",
      "epoch 36; iter: 0; batch classifier loss: 0.374842; batch adversarial loss: 0.612495\n",
      "epoch 36; iter: 200; batch classifier loss: 0.451135; batch adversarial loss: 0.581414\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434405; batch adversarial loss: 0.604956\n",
      "epoch 37; iter: 200; batch classifier loss: 0.363326; batch adversarial loss: 0.639184\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417575; batch adversarial loss: 0.560993\n",
      "epoch 38; iter: 200; batch classifier loss: 0.440208; batch adversarial loss: 0.589802\n",
      "epoch 39; iter: 0; batch classifier loss: 0.417416; batch adversarial loss: 0.578609\n",
      "epoch 39; iter: 200; batch classifier loss: 0.345231; batch adversarial loss: 0.646222\n",
      "epoch 40; iter: 0; batch classifier loss: 0.443155; batch adversarial loss: 0.645543\n",
      "epoch 40; iter: 200; batch classifier loss: 0.400103; batch adversarial loss: 0.613866\n",
      "epoch 41; iter: 0; batch classifier loss: 0.379588; batch adversarial loss: 0.578239\n",
      "epoch 41; iter: 200; batch classifier loss: 0.262400; batch adversarial loss: 0.658182\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378629; batch adversarial loss: 0.636544\n",
      "epoch 42; iter: 200; batch classifier loss: 0.381384; batch adversarial loss: 0.641152\n",
      "epoch 43; iter: 0; batch classifier loss: 0.281185; batch adversarial loss: 0.586934\n",
      "epoch 43; iter: 200; batch classifier loss: 0.311012; batch adversarial loss: 0.637638\n",
      "epoch 44; iter: 0; batch classifier loss: 0.300573; batch adversarial loss: 0.678992\n",
      "epoch 44; iter: 200; batch classifier loss: 0.382760; batch adversarial loss: 0.594740\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373065; batch adversarial loss: 0.620679\n",
      "epoch 45; iter: 200; batch classifier loss: 0.334874; batch adversarial loss: 0.583674\n",
      "epoch 46; iter: 0; batch classifier loss: 0.420672; batch adversarial loss: 0.667517\n",
      "epoch 46; iter: 200; batch classifier loss: 0.374870; batch adversarial loss: 0.658372\n",
      "epoch 47; iter: 0; batch classifier loss: 0.365192; batch adversarial loss: 0.629653\n",
      "epoch 47; iter: 200; batch classifier loss: 0.434359; batch adversarial loss: 0.622650\n",
      "epoch 48; iter: 0; batch classifier loss: 0.462568; batch adversarial loss: 0.599692\n",
      "epoch 48; iter: 200; batch classifier loss: 0.441763; batch adversarial loss: 0.642192\n",
      "epoch 49; iter: 0; batch classifier loss: 0.461323; batch adversarial loss: 0.601426\n",
      "epoch 49; iter: 200; batch classifier loss: 0.421978; batch adversarial loss: 0.617713\n",
      "epoch 0; iter: 0; batch classifier loss: 14.802799; batch adversarial loss: 0.691985\n",
      "epoch 0; iter: 200; batch classifier loss: 6.917868; batch adversarial loss: 0.652352\n",
      "epoch 1; iter: 0; batch classifier loss: 8.439362; batch adversarial loss: 0.639539\n",
      "epoch 1; iter: 200; batch classifier loss: 6.077726; batch adversarial loss: 0.632973\n",
      "epoch 2; iter: 0; batch classifier loss: 4.148623; batch adversarial loss: 0.633155\n",
      "epoch 2; iter: 200; batch classifier loss: 2.951231; batch adversarial loss: 0.624805\n",
      "epoch 3; iter: 0; batch classifier loss: 5.466924; batch adversarial loss: 0.595504\n",
      "epoch 3; iter: 200; batch classifier loss: 5.289745; batch adversarial loss: 0.668197\n",
      "epoch 4; iter: 0; batch classifier loss: 1.034552; batch adversarial loss: 0.658533\n",
      "epoch 4; iter: 200; batch classifier loss: 6.095087; batch adversarial loss: 0.631326\n",
      "epoch 5; iter: 0; batch classifier loss: 1.482764; batch adversarial loss: 0.612588\n",
      "epoch 5; iter: 200; batch classifier loss: 1.195027; batch adversarial loss: 0.577517\n",
      "epoch 6; iter: 0; batch classifier loss: 5.588703; batch adversarial loss: 0.622169\n",
      "epoch 6; iter: 200; batch classifier loss: 1.219558; batch adversarial loss: 0.648632\n",
      "epoch 7; iter: 0; batch classifier loss: 0.901357; batch adversarial loss: 0.594666\n",
      "epoch 7; iter: 200; batch classifier loss: 1.153363; batch adversarial loss: 0.676310\n",
      "epoch 8; iter: 0; batch classifier loss: 0.743785; batch adversarial loss: 0.657770\n",
      "epoch 8; iter: 200; batch classifier loss: 0.360746; batch adversarial loss: 0.657320\n",
      "epoch 9; iter: 0; batch classifier loss: 0.819063; batch adversarial loss: 0.530608\n",
      "epoch 9; iter: 200; batch classifier loss: 0.504288; batch adversarial loss: 0.627049\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398467; batch adversarial loss: 0.627737\n",
      "epoch 10; iter: 200; batch classifier loss: 0.378707; batch adversarial loss: 0.596265\n",
      "epoch 11; iter: 0; batch classifier loss: 0.453408; batch adversarial loss: 0.591005\n",
      "epoch 11; iter: 200; batch classifier loss: 0.499354; batch adversarial loss: 0.654999\n",
      "epoch 12; iter: 0; batch classifier loss: 0.454701; batch adversarial loss: 0.597840\n",
      "epoch 12; iter: 200; batch classifier loss: 0.526624; batch adversarial loss: 0.611963\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370781; batch adversarial loss: 0.651182\n",
      "epoch 13; iter: 200; batch classifier loss: 0.470292; batch adversarial loss: 0.596007\n",
      "epoch 14; iter: 0; batch classifier loss: 1.088091; batch adversarial loss: 0.623437\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416732; batch adversarial loss: 0.624836\n",
      "epoch 15; iter: 0; batch classifier loss: 0.348807; batch adversarial loss: 0.682598\n",
      "epoch 15; iter: 200; batch classifier loss: 0.369730; batch adversarial loss: 0.570170\n",
      "epoch 16; iter: 0; batch classifier loss: 0.328335; batch adversarial loss: 0.583856\n",
      "epoch 16; iter: 200; batch classifier loss: 0.370106; batch adversarial loss: 0.575050\n",
      "epoch 17; iter: 0; batch classifier loss: 0.428462; batch adversarial loss: 0.572070\n",
      "epoch 17; iter: 200; batch classifier loss: 0.374656; batch adversarial loss: 0.621735\n",
      "epoch 18; iter: 0; batch classifier loss: 0.395599; batch adversarial loss: 0.624019\n",
      "epoch 18; iter: 200; batch classifier loss: 0.345147; batch adversarial loss: 0.593523\n",
      "epoch 19; iter: 0; batch classifier loss: 0.384750; batch adversarial loss: 0.638804\n",
      "epoch 19; iter: 200; batch classifier loss: 0.344041; batch adversarial loss: 0.640494\n",
      "epoch 20; iter: 0; batch classifier loss: 0.310428; batch adversarial loss: 0.630202\n",
      "epoch 20; iter: 200; batch classifier loss: 0.356314; batch adversarial loss: 0.719818\n",
      "epoch 21; iter: 0; batch classifier loss: 0.252791; batch adversarial loss: 0.662504\n",
      "epoch 21; iter: 200; batch classifier loss: 0.307484; batch adversarial loss: 0.577139\n",
      "epoch 22; iter: 0; batch classifier loss: 0.334501; batch adversarial loss: 0.611664\n",
      "epoch 22; iter: 200; batch classifier loss: 0.596983; batch adversarial loss: 0.632985\n",
      "epoch 23; iter: 0; batch classifier loss: 0.406784; batch adversarial loss: 0.580578\n",
      "epoch 23; iter: 200; batch classifier loss: 0.394928; batch adversarial loss: 0.637690\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331705; batch adversarial loss: 0.598273\n",
      "epoch 24; iter: 200; batch classifier loss: 0.550703; batch adversarial loss: 0.584984\n",
      "epoch 25; iter: 0; batch classifier loss: 0.377256; batch adversarial loss: 0.642053\n",
      "epoch 25; iter: 200; batch classifier loss: 0.285649; batch adversarial loss: 0.613657\n",
      "epoch 26; iter: 0; batch classifier loss: 0.351317; batch adversarial loss: 0.698001\n",
      "epoch 26; iter: 200; batch classifier loss: 0.302085; batch adversarial loss: 0.636789\n",
      "epoch 27; iter: 0; batch classifier loss: 0.313230; batch adversarial loss: 0.606242\n",
      "epoch 27; iter: 200; batch classifier loss: 0.389509; batch adversarial loss: 0.583575\n",
      "epoch 28; iter: 0; batch classifier loss: 0.348450; batch adversarial loss: 0.571152\n",
      "epoch 28; iter: 200; batch classifier loss: 0.374704; batch adversarial loss: 0.571550\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358703; batch adversarial loss: 0.624093\n",
      "epoch 29; iter: 200; batch classifier loss: 0.413817; batch adversarial loss: 0.621145\n",
      "epoch 30; iter: 0; batch classifier loss: 0.347336; batch adversarial loss: 0.638184\n",
      "epoch 30; iter: 200; batch classifier loss: 0.390338; batch adversarial loss: 0.639743\n",
      "epoch 31; iter: 0; batch classifier loss: 0.304688; batch adversarial loss: 0.634356\n",
      "epoch 31; iter: 200; batch classifier loss: 0.343447; batch adversarial loss: 0.657347\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421409; batch adversarial loss: 0.589081\n",
      "epoch 32; iter: 200; batch classifier loss: 0.269771; batch adversarial loss: 0.625027\n",
      "epoch 33; iter: 0; batch classifier loss: 0.379656; batch adversarial loss: 0.619231\n",
      "epoch 33; iter: 200; batch classifier loss: 0.336138; batch adversarial loss: 0.613646\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306638; batch adversarial loss: 0.676567\n",
      "epoch 34; iter: 200; batch classifier loss: 0.333942; batch adversarial loss: 0.637211\n",
      "epoch 35; iter: 0; batch classifier loss: 0.321832; batch adversarial loss: 0.570898\n",
      "epoch 35; iter: 200; batch classifier loss: 0.464034; batch adversarial loss: 0.669011\n",
      "epoch 36; iter: 0; batch classifier loss: 0.400071; batch adversarial loss: 0.596283\n",
      "epoch 36; iter: 200; batch classifier loss: 0.420256; batch adversarial loss: 0.592154\n",
      "epoch 37; iter: 0; batch classifier loss: 0.617780; batch adversarial loss: 0.575103\n",
      "epoch 37; iter: 200; batch classifier loss: 0.416052; batch adversarial loss: 0.637625\n",
      "epoch 38; iter: 0; batch classifier loss: 0.393750; batch adversarial loss: 0.548447\n",
      "epoch 38; iter: 200; batch classifier loss: 0.285450; batch adversarial loss: 0.606596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.322803; batch adversarial loss: 0.643892\n",
      "epoch 39; iter: 200; batch classifier loss: 0.288730; batch adversarial loss: 0.647878\n",
      "epoch 40; iter: 0; batch classifier loss: 0.434179; batch adversarial loss: 0.601497\n",
      "epoch 40; iter: 200; batch classifier loss: 0.274688; batch adversarial loss: 0.656560\n",
      "epoch 41; iter: 0; batch classifier loss: 0.357053; batch adversarial loss: 0.640478\n",
      "epoch 41; iter: 200; batch classifier loss: 0.428758; batch adversarial loss: 0.626567\n",
      "epoch 42; iter: 0; batch classifier loss: 0.235581; batch adversarial loss: 0.683748\n",
      "epoch 42; iter: 200; batch classifier loss: 0.454564; batch adversarial loss: 0.657335\n",
      "epoch 43; iter: 0; batch classifier loss: 0.445054; batch adversarial loss: 0.637788\n",
      "epoch 43; iter: 200; batch classifier loss: 0.400447; batch adversarial loss: 0.614092\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382808; batch adversarial loss: 0.652395\n",
      "epoch 44; iter: 200; batch classifier loss: 0.449314; batch adversarial loss: 0.658211\n",
      "epoch 45; iter: 0; batch classifier loss: 0.465647; batch adversarial loss: 0.645855\n",
      "epoch 45; iter: 200; batch classifier loss: 0.353529; batch adversarial loss: 0.662956\n",
      "epoch 46; iter: 0; batch classifier loss: 0.287399; batch adversarial loss: 0.664681\n",
      "epoch 46; iter: 200; batch classifier loss: 0.434980; batch adversarial loss: 0.602644\n",
      "epoch 47; iter: 0; batch classifier loss: 0.355505; batch adversarial loss: 0.629404\n",
      "epoch 47; iter: 200; batch classifier loss: 0.294635; batch adversarial loss: 0.620655\n",
      "epoch 48; iter: 0; batch classifier loss: 0.376871; batch adversarial loss: 0.640364\n",
      "epoch 48; iter: 200; batch classifier loss: 0.392952; batch adversarial loss: 0.682288\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475669; batch adversarial loss: 0.656003\n",
      "epoch 49; iter: 200; batch classifier loss: 0.482850; batch adversarial loss: 0.565534\n",
      "epoch 0; iter: 0; batch classifier loss: 82.955040; batch adversarial loss: 0.756470\n",
      "epoch 0; iter: 200; batch classifier loss: 7.311009; batch adversarial loss: 0.713650\n",
      "epoch 1; iter: 0; batch classifier loss: 10.895792; batch adversarial loss: 0.688015\n",
      "epoch 1; iter: 200; batch classifier loss: 37.773174; batch adversarial loss: 0.644190\n",
      "epoch 2; iter: 0; batch classifier loss: 4.130274; batch adversarial loss: 0.644746\n",
      "epoch 2; iter: 200; batch classifier loss: 5.375505; batch adversarial loss: 0.634231\n",
      "epoch 3; iter: 0; batch classifier loss: 13.754940; batch adversarial loss: 0.607100\n",
      "epoch 3; iter: 200; batch classifier loss: 1.382871; batch adversarial loss: 0.611415\n",
      "epoch 4; iter: 0; batch classifier loss: 1.558696; batch adversarial loss: 0.671861\n",
      "epoch 4; iter: 200; batch classifier loss: 1.358012; batch adversarial loss: 0.617117\n",
      "epoch 5; iter: 0; batch classifier loss: 1.023500; batch adversarial loss: 0.634827\n",
      "epoch 5; iter: 200; batch classifier loss: 1.206270; batch adversarial loss: 0.584693\n",
      "epoch 6; iter: 0; batch classifier loss: 1.203428; batch adversarial loss: 0.558554\n",
      "epoch 6; iter: 200; batch classifier loss: 1.236804; batch adversarial loss: 0.636586\n",
      "epoch 7; iter: 0; batch classifier loss: 4.100633; batch adversarial loss: 0.563889\n",
      "epoch 7; iter: 200; batch classifier loss: 0.736034; batch adversarial loss: 0.602136\n",
      "epoch 8; iter: 0; batch classifier loss: 0.993265; batch adversarial loss: 0.684130\n",
      "epoch 8; iter: 200; batch classifier loss: 0.862327; batch adversarial loss: 0.625842\n",
      "epoch 9; iter: 0; batch classifier loss: 0.875948; batch adversarial loss: 0.604170\n",
      "epoch 9; iter: 200; batch classifier loss: 0.527403; batch adversarial loss: 0.598765\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426543; batch adversarial loss: 0.632805\n",
      "epoch 10; iter: 200; batch classifier loss: 0.675599; batch adversarial loss: 0.601547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429649; batch adversarial loss: 0.573332\n",
      "epoch 11; iter: 200; batch classifier loss: 0.496017; batch adversarial loss: 0.621956\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537677; batch adversarial loss: 0.536047\n",
      "epoch 12; iter: 200; batch classifier loss: 0.492028; batch adversarial loss: 0.597474\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396504; batch adversarial loss: 0.639075\n",
      "epoch 13; iter: 200; batch classifier loss: 0.388936; batch adversarial loss: 0.656008\n",
      "epoch 14; iter: 0; batch classifier loss: 0.379001; batch adversarial loss: 0.697543\n",
      "epoch 14; iter: 200; batch classifier loss: 0.460396; batch adversarial loss: 0.618441\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409905; batch adversarial loss: 0.552929\n",
      "epoch 15; iter: 200; batch classifier loss: 0.513326; batch adversarial loss: 0.561770\n",
      "epoch 16; iter: 0; batch classifier loss: 0.404125; batch adversarial loss: 0.650401\n",
      "epoch 16; iter: 200; batch classifier loss: 0.419346; batch adversarial loss: 0.625313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365973; batch adversarial loss: 0.547858\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346625; batch adversarial loss: 0.631463\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343432; batch adversarial loss: 0.598973\n",
      "epoch 18; iter: 200; batch classifier loss: 0.336683; batch adversarial loss: 0.575822\n",
      "epoch 19; iter: 0; batch classifier loss: 0.315101; batch adversarial loss: 0.645188\n",
      "epoch 19; iter: 200; batch classifier loss: 0.404812; batch adversarial loss: 0.636477\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325312; batch adversarial loss: 0.614800\n",
      "epoch 20; iter: 200; batch classifier loss: 0.376652; batch adversarial loss: 0.613696\n",
      "epoch 21; iter: 0; batch classifier loss: 0.368099; batch adversarial loss: 0.671737\n",
      "epoch 21; iter: 200; batch classifier loss: 0.354355; batch adversarial loss: 0.681157\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438997; batch adversarial loss: 0.560733\n",
      "epoch 22; iter: 200; batch classifier loss: 0.430467; batch adversarial loss: 0.605046\n",
      "epoch 23; iter: 0; batch classifier loss: 0.384366; batch adversarial loss: 0.630259\n",
      "epoch 23; iter: 200; batch classifier loss: 0.334240; batch adversarial loss: 0.663416\n",
      "epoch 24; iter: 0; batch classifier loss: 0.347929; batch adversarial loss: 0.564398\n",
      "epoch 24; iter: 200; batch classifier loss: 0.390277; batch adversarial loss: 0.659281\n",
      "epoch 25; iter: 0; batch classifier loss: 0.341831; batch adversarial loss: 0.622676\n",
      "epoch 25; iter: 200; batch classifier loss: 0.337829; batch adversarial loss: 0.619904\n",
      "epoch 26; iter: 0; batch classifier loss: 0.395523; batch adversarial loss: 0.605554\n",
      "epoch 26; iter: 200; batch classifier loss: 0.344728; batch adversarial loss: 0.598826\n",
      "epoch 27; iter: 0; batch classifier loss: 0.218980; batch adversarial loss: 0.673610\n",
      "epoch 27; iter: 200; batch classifier loss: 0.310933; batch adversarial loss: 0.663364\n",
      "epoch 28; iter: 0; batch classifier loss: 0.325462; batch adversarial loss: 0.573298\n",
      "epoch 28; iter: 200; batch classifier loss: 0.308168; batch adversarial loss: 0.636318\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398065; batch adversarial loss: 0.581518\n",
      "epoch 29; iter: 200; batch classifier loss: 0.353144; batch adversarial loss: 0.679058\n",
      "epoch 30; iter: 0; batch classifier loss: 0.360142; batch adversarial loss: 0.553018\n",
      "epoch 30; iter: 200; batch classifier loss: 0.249134; batch adversarial loss: 0.615738\n",
      "epoch 31; iter: 0; batch classifier loss: 0.392008; batch adversarial loss: 0.662386\n",
      "epoch 31; iter: 200; batch classifier loss: 0.307998; batch adversarial loss: 0.630948\n",
      "epoch 32; iter: 0; batch classifier loss: 0.460291; batch adversarial loss: 0.624868\n",
      "epoch 32; iter: 200; batch classifier loss: 0.312493; batch adversarial loss: 0.635760\n",
      "epoch 33; iter: 0; batch classifier loss: 0.280122; batch adversarial loss: 0.605676\n",
      "epoch 33; iter: 200; batch classifier loss: 0.397271; batch adversarial loss: 0.635107\n",
      "epoch 34; iter: 0; batch classifier loss: 0.334845; batch adversarial loss: 0.657068\n",
      "epoch 34; iter: 200; batch classifier loss: 0.319704; batch adversarial loss: 0.624944\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398357; batch adversarial loss: 0.640169\n",
      "epoch 35; iter: 200; batch classifier loss: 0.384131; batch adversarial loss: 0.589023\n",
      "epoch 36; iter: 0; batch classifier loss: 0.386327; batch adversarial loss: 0.653724\n",
      "epoch 36; iter: 200; batch classifier loss: 0.361365; batch adversarial loss: 0.569130\n",
      "epoch 37; iter: 0; batch classifier loss: 0.326948; batch adversarial loss: 0.582304\n",
      "epoch 37; iter: 200; batch classifier loss: 0.323021; batch adversarial loss: 0.648130\n",
      "epoch 38; iter: 0; batch classifier loss: 0.348020; batch adversarial loss: 0.666499\n",
      "epoch 38; iter: 200; batch classifier loss: 0.291867; batch adversarial loss: 0.601969\n",
      "epoch 39; iter: 0; batch classifier loss: 0.270304; batch adversarial loss: 0.626981\n",
      "epoch 39; iter: 200; batch classifier loss: 0.342541; batch adversarial loss: 0.614564\n",
      "epoch 40; iter: 0; batch classifier loss: 0.380139; batch adversarial loss: 0.599696\n",
      "epoch 40; iter: 200; batch classifier loss: 0.394613; batch adversarial loss: 0.593905\n",
      "epoch 41; iter: 0; batch classifier loss: 0.352117; batch adversarial loss: 0.561636\n",
      "epoch 41; iter: 200; batch classifier loss: 0.363593; batch adversarial loss: 0.594082\n",
      "epoch 42; iter: 0; batch classifier loss: 0.400596; batch adversarial loss: 0.630049\n",
      "epoch 42; iter: 200; batch classifier loss: 0.416594; batch adversarial loss: 0.666986\n",
      "epoch 43; iter: 0; batch classifier loss: 0.340182; batch adversarial loss: 0.597470\n",
      "epoch 43; iter: 200; batch classifier loss: 0.263685; batch adversarial loss: 0.629944\n",
      "epoch 44; iter: 0; batch classifier loss: 0.295904; batch adversarial loss: 0.594132\n",
      "epoch 44; iter: 200; batch classifier loss: 0.333817; batch adversarial loss: 0.597560\n",
      "epoch 45; iter: 0; batch classifier loss: 0.784529; batch adversarial loss: 0.625836\n",
      "epoch 45; iter: 200; batch classifier loss: 0.339171; batch adversarial loss: 0.620327\n",
      "epoch 46; iter: 0; batch classifier loss: 0.412868; batch adversarial loss: 0.549051\n",
      "epoch 46; iter: 200; batch classifier loss: 0.461439; batch adversarial loss: 0.597931\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383464; batch adversarial loss: 0.648006\n",
      "epoch 47; iter: 200; batch classifier loss: 0.309962; batch adversarial loss: 0.649179\n",
      "epoch 48; iter: 0; batch classifier loss: 0.413562; batch adversarial loss: 0.641773\n",
      "epoch 48; iter: 200; batch classifier loss: 0.395004; batch adversarial loss: 0.598551\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384061; batch adversarial loss: 0.580172\n",
      "epoch 49; iter: 200; batch classifier loss: 0.438072; batch adversarial loss: 0.593292\n",
      "epoch 0; iter: 0; batch classifier loss: 165.325958; batch adversarial loss: 0.642516\n",
      "epoch 0; iter: 200; batch classifier loss: 2.300281; batch adversarial loss: 0.633284\n",
      "epoch 1; iter: 0; batch classifier loss: 8.489521; batch adversarial loss: 0.637062\n",
      "epoch 1; iter: 200; batch classifier loss: 4.247258; batch adversarial loss: 0.639967\n",
      "epoch 2; iter: 0; batch classifier loss: 13.145939; batch adversarial loss: 0.606260\n",
      "epoch 2; iter: 200; batch classifier loss: 4.131235; batch adversarial loss: 0.610513\n",
      "epoch 3; iter: 0; batch classifier loss: 6.062890; batch adversarial loss: 0.623656\n",
      "epoch 3; iter: 200; batch classifier loss: 1.637727; batch adversarial loss: 0.633105\n",
      "epoch 4; iter: 0; batch classifier loss: 12.314713; batch adversarial loss: 0.646781\n",
      "epoch 4; iter: 200; batch classifier loss: 7.366261; batch adversarial loss: 0.647336\n",
      "epoch 5; iter: 0; batch classifier loss: 1.925230; batch adversarial loss: 0.653142\n",
      "epoch 5; iter: 200; batch classifier loss: 2.066112; batch adversarial loss: 0.630445\n",
      "epoch 6; iter: 0; batch classifier loss: 1.415878; batch adversarial loss: 0.690868\n",
      "epoch 6; iter: 200; batch classifier loss: 1.078702; batch adversarial loss: 0.610640\n",
      "epoch 7; iter: 0; batch classifier loss: 1.577814; batch adversarial loss: 0.551725\n",
      "epoch 7; iter: 200; batch classifier loss: 0.678250; batch adversarial loss: 0.634725\n",
      "epoch 8; iter: 0; batch classifier loss: 0.737555; batch adversarial loss: 0.635339\n",
      "epoch 8; iter: 200; batch classifier loss: 1.083495; batch adversarial loss: 0.558575\n",
      "epoch 9; iter: 0; batch classifier loss: 0.649052; batch adversarial loss: 0.598328\n",
      "epoch 9; iter: 200; batch classifier loss: 0.445956; batch adversarial loss: 0.596332\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584039; batch adversarial loss: 0.609597\n",
      "epoch 10; iter: 200; batch classifier loss: 0.546792; batch adversarial loss: 0.580453\n",
      "epoch 11; iter: 0; batch classifier loss: 0.542035; batch adversarial loss: 0.607009\n",
      "epoch 11; iter: 200; batch classifier loss: 0.403600; batch adversarial loss: 0.616497\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469352; batch adversarial loss: 0.651740\n",
      "epoch 12; iter: 200; batch classifier loss: 0.390423; batch adversarial loss: 0.564366\n",
      "epoch 13; iter: 0; batch classifier loss: 0.397032; batch adversarial loss: 0.610044\n",
      "epoch 13; iter: 200; batch classifier loss: 0.367611; batch adversarial loss: 0.603764\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474771; batch adversarial loss: 0.596991\n",
      "epoch 14; iter: 200; batch classifier loss: 0.437604; batch adversarial loss: 0.634222\n",
      "epoch 15; iter: 0; batch classifier loss: 0.425889; batch adversarial loss: 0.614850\n",
      "epoch 15; iter: 200; batch classifier loss: 0.383745; batch adversarial loss: 0.666148\n",
      "epoch 16; iter: 0; batch classifier loss: 0.399592; batch adversarial loss: 0.613710\n",
      "epoch 16; iter: 200; batch classifier loss: 0.359461; batch adversarial loss: 0.656321\n",
      "epoch 17; iter: 0; batch classifier loss: 0.423623; batch adversarial loss: 0.603008\n",
      "epoch 17; iter: 200; batch classifier loss: 0.338663; batch adversarial loss: 0.697092\n",
      "epoch 18; iter: 0; batch classifier loss: 0.510839; batch adversarial loss: 0.566592\n",
      "epoch 18; iter: 200; batch classifier loss: 0.404336; batch adversarial loss: 0.565324\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427636; batch adversarial loss: 0.598162\n",
      "epoch 19; iter: 200; batch classifier loss: 0.316259; batch adversarial loss: 0.618721\n",
      "epoch 20; iter: 0; batch classifier loss: 0.344605; batch adversarial loss: 0.604484\n",
      "epoch 20; iter: 200; batch classifier loss: 0.398928; batch adversarial loss: 0.590812\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403208; batch adversarial loss: 0.653024\n",
      "epoch 21; iter: 200; batch classifier loss: 0.287802; batch adversarial loss: 0.648767\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350452; batch adversarial loss: 0.623935\n",
      "epoch 22; iter: 200; batch classifier loss: 0.386366; batch adversarial loss: 0.627597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.321446; batch adversarial loss: 0.554890\n",
      "epoch 23; iter: 200; batch classifier loss: 0.389101; batch adversarial loss: 0.617664\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360997; batch adversarial loss: 0.631102\n",
      "epoch 24; iter: 200; batch classifier loss: 0.390579; batch adversarial loss: 0.585471\n",
      "epoch 25; iter: 0; batch classifier loss: 0.310828; batch adversarial loss: 0.615356\n",
      "epoch 25; iter: 200; batch classifier loss: 0.419378; batch adversarial loss: 0.590581\n",
      "epoch 26; iter: 0; batch classifier loss: 0.412744; batch adversarial loss: 0.625793\n",
      "epoch 26; iter: 200; batch classifier loss: 0.380963; batch adversarial loss: 0.629135\n",
      "epoch 27; iter: 0; batch classifier loss: 0.301933; batch adversarial loss: 0.650223\n",
      "epoch 27; iter: 200; batch classifier loss: 0.321160; batch adversarial loss: 0.647910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402893; batch adversarial loss: 0.573017\n",
      "epoch 28; iter: 200; batch classifier loss: 0.323612; batch adversarial loss: 0.615753\n",
      "epoch 29; iter: 0; batch classifier loss: 0.371812; batch adversarial loss: 0.617477\n",
      "epoch 29; iter: 200; batch classifier loss: 0.423544; batch adversarial loss: 0.603798\n",
      "epoch 30; iter: 0; batch classifier loss: 0.413118; batch adversarial loss: 0.686876\n",
      "epoch 30; iter: 200; batch classifier loss: 0.356977; batch adversarial loss: 0.670634\n",
      "epoch 31; iter: 0; batch classifier loss: 0.258190; batch adversarial loss: 0.648867\n",
      "epoch 31; iter: 200; batch classifier loss: 0.399842; batch adversarial loss: 0.616564\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407193; batch adversarial loss: 0.626237\n",
      "epoch 32; iter: 200; batch classifier loss: 0.369469; batch adversarial loss: 0.625032\n",
      "epoch 33; iter: 0; batch classifier loss: 0.380235; batch adversarial loss: 0.626306\n",
      "epoch 33; iter: 200; batch classifier loss: 0.413461; batch adversarial loss: 0.619622\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434350; batch adversarial loss: 0.656291\n",
      "epoch 34; iter: 200; batch classifier loss: 0.278487; batch adversarial loss: 0.608135\n",
      "epoch 35; iter: 0; batch classifier loss: 0.352518; batch adversarial loss: 0.651410\n",
      "epoch 35; iter: 200; batch classifier loss: 0.347379; batch adversarial loss: 0.642803\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389351; batch adversarial loss: 0.596355\n",
      "epoch 36; iter: 200; batch classifier loss: 0.345879; batch adversarial loss: 0.600877\n",
      "epoch 37; iter: 0; batch classifier loss: 0.334864; batch adversarial loss: 0.574812\n",
      "epoch 37; iter: 200; batch classifier loss: 0.287108; batch adversarial loss: 0.617453\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412673; batch adversarial loss: 0.613901\n",
      "epoch 38; iter: 200; batch classifier loss: 0.332826; batch adversarial loss: 0.601019\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430596; batch adversarial loss: 0.614697\n",
      "epoch 39; iter: 200; batch classifier loss: 0.351392; batch adversarial loss: 0.641636\n",
      "epoch 40; iter: 0; batch classifier loss: 0.300243; batch adversarial loss: 0.624965\n",
      "epoch 40; iter: 200; batch classifier loss: 0.368163; batch adversarial loss: 0.618993\n",
      "epoch 41; iter: 0; batch classifier loss: 0.348508; batch adversarial loss: 0.626414\n",
      "epoch 41; iter: 200; batch classifier loss: 0.400820; batch adversarial loss: 0.599682\n",
      "epoch 42; iter: 0; batch classifier loss: 0.382497; batch adversarial loss: 0.627864\n",
      "epoch 42; iter: 200; batch classifier loss: 0.322102; batch adversarial loss: 0.637517\n",
      "epoch 43; iter: 0; batch classifier loss: 0.316870; batch adversarial loss: 0.649696\n",
      "epoch 43; iter: 200; batch classifier loss: 0.272427; batch adversarial loss: 0.598033\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388108; batch adversarial loss: 0.625514\n",
      "epoch 44; iter: 200; batch classifier loss: 0.346585; batch adversarial loss: 0.633613\n",
      "epoch 45; iter: 0; batch classifier loss: 0.262345; batch adversarial loss: 0.658779\n",
      "epoch 45; iter: 200; batch classifier loss: 0.443728; batch adversarial loss: 0.546112\n",
      "epoch 46; iter: 0; batch classifier loss: 0.490909; batch adversarial loss: 0.582368\n",
      "epoch 46; iter: 200; batch classifier loss: 0.346769; batch adversarial loss: 0.588560\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435959; batch adversarial loss: 0.622502\n",
      "epoch 47; iter: 200; batch classifier loss: 0.329775; batch adversarial loss: 0.639606\n",
      "epoch 48; iter: 0; batch classifier loss: 0.616478; batch adversarial loss: 0.657036\n",
      "epoch 48; iter: 200; batch classifier loss: 0.370853; batch adversarial loss: 0.606775\n",
      "epoch 49; iter: 0; batch classifier loss: 0.482978; batch adversarial loss: 0.609829\n",
      "epoch 49; iter: 200; batch classifier loss: 0.391693; batch adversarial loss: 0.581640\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 6.361441; batch adversarial loss: 0.687065\n",
      "epoch 0; iter: 200; batch classifier loss: 34.646381; batch adversarial loss: 0.675487\n",
      "epoch 0; iter: 400; batch classifier loss: 1.270869; batch adversarial loss: 0.673581\n",
      "epoch 1; iter: 0; batch classifier loss: 7.466338; batch adversarial loss: 0.635863\n",
      "epoch 1; iter: 200; batch classifier loss: 5.736219; batch adversarial loss: 0.599434\n",
      "epoch 1; iter: 400; batch classifier loss: 1.442575; batch adversarial loss: 0.627579\n",
      "epoch 2; iter: 0; batch classifier loss: 2.827195; batch adversarial loss: 0.638949\n",
      "epoch 2; iter: 200; batch classifier loss: 1.019891; batch adversarial loss: 0.644740\n",
      "epoch 2; iter: 400; batch classifier loss: 2.377162; batch adversarial loss: 0.626088\n",
      "epoch 3; iter: 0; batch classifier loss: 2.075988; batch adversarial loss: 0.633061\n",
      "epoch 3; iter: 200; batch classifier loss: 1.942554; batch adversarial loss: 0.633911\n",
      "epoch 3; iter: 400; batch classifier loss: 2.774997; batch adversarial loss: 0.630696\n",
      "epoch 4; iter: 0; batch classifier loss: 3.478772; batch adversarial loss: 0.613283\n",
      "epoch 4; iter: 200; batch classifier loss: 0.290542; batch adversarial loss: 0.681296\n",
      "epoch 4; iter: 400; batch classifier loss: 1.766126; batch adversarial loss: 0.580308\n",
      "epoch 5; iter: 0; batch classifier loss: 0.892456; batch adversarial loss: 0.544529\n",
      "epoch 5; iter: 200; batch classifier loss: 0.460947; batch adversarial loss: 0.676646\n",
      "epoch 5; iter: 400; batch classifier loss: 0.891283; batch adversarial loss: 0.645287\n",
      "epoch 6; iter: 0; batch classifier loss: 0.656649; batch adversarial loss: 0.669106\n",
      "epoch 6; iter: 200; batch classifier loss: 0.867568; batch adversarial loss: 0.681217\n",
      "epoch 6; iter: 400; batch classifier loss: 0.428985; batch adversarial loss: 0.633064\n",
      "epoch 7; iter: 0; batch classifier loss: 0.411276; batch adversarial loss: 0.570295\n",
      "epoch 7; iter: 200; batch classifier loss: 0.335753; batch adversarial loss: 0.660488\n",
      "epoch 7; iter: 400; batch classifier loss: 0.515338; batch adversarial loss: 0.626218\n",
      "epoch 8; iter: 0; batch classifier loss: 1.315605; batch adversarial loss: 0.624052\n",
      "epoch 8; iter: 200; batch classifier loss: 0.496794; batch adversarial loss: 0.583274\n",
      "epoch 8; iter: 400; batch classifier loss: 0.387312; batch adversarial loss: 0.687918\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461031; batch adversarial loss: 0.637649\n",
      "epoch 9; iter: 200; batch classifier loss: 0.357567; batch adversarial loss: 0.721457\n",
      "epoch 9; iter: 400; batch classifier loss: 0.438449; batch adversarial loss: 0.596189\n",
      "epoch 0; iter: 0; batch classifier loss: 313.793091; batch adversarial loss: 0.713675\n",
      "epoch 0; iter: 200; batch classifier loss: 13.393673; batch adversarial loss: 0.679532\n",
      "epoch 0; iter: 400; batch classifier loss: 4.658694; batch adversarial loss: 0.625185\n",
      "epoch 1; iter: 0; batch classifier loss: 5.874671; batch adversarial loss: 0.649017\n",
      "epoch 1; iter: 200; batch classifier loss: 15.652687; batch adversarial loss: 0.628369\n",
      "epoch 1; iter: 400; batch classifier loss: 9.862425; batch adversarial loss: 0.679299\n",
      "epoch 2; iter: 0; batch classifier loss: 6.220477; batch adversarial loss: 0.724261\n",
      "epoch 2; iter: 200; batch classifier loss: 3.116448; batch adversarial loss: 0.639133\n",
      "epoch 2; iter: 400; batch classifier loss: 3.815611; batch adversarial loss: 0.720994\n",
      "epoch 3; iter: 0; batch classifier loss: 12.372450; batch adversarial loss: 0.708342\n",
      "epoch 3; iter: 200; batch classifier loss: 0.834026; batch adversarial loss: 0.667005\n",
      "epoch 3; iter: 400; batch classifier loss: 1.231972; batch adversarial loss: 0.694335\n",
      "epoch 4; iter: 0; batch classifier loss: 2.890306; batch adversarial loss: 0.593443\n",
      "epoch 4; iter: 200; batch classifier loss: 1.539775; batch adversarial loss: 0.662389\n",
      "epoch 4; iter: 400; batch classifier loss: 2.481256; batch adversarial loss: 0.623635\n",
      "epoch 5; iter: 0; batch classifier loss: 0.405063; batch adversarial loss: 0.604210\n",
      "epoch 5; iter: 200; batch classifier loss: 1.173504; batch adversarial loss: 0.694413\n",
      "epoch 5; iter: 400; batch classifier loss: 1.253404; batch adversarial loss: 0.559698\n",
      "epoch 6; iter: 0; batch classifier loss: 0.941771; batch adversarial loss: 0.652763\n",
      "epoch 6; iter: 200; batch classifier loss: 1.015538; batch adversarial loss: 0.662309\n",
      "epoch 6; iter: 400; batch classifier loss: 0.620638; batch adversarial loss: 0.669309\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461002; batch adversarial loss: 0.584523\n",
      "epoch 7; iter: 200; batch classifier loss: 0.379722; batch adversarial loss: 0.651542\n",
      "epoch 7; iter: 400; batch classifier loss: 0.608127; batch adversarial loss: 0.622441\n",
      "epoch 8; iter: 0; batch classifier loss: 0.356708; batch adversarial loss: 0.611458\n",
      "epoch 8; iter: 200; batch classifier loss: 0.518610; batch adversarial loss: 0.633108\n",
      "epoch 8; iter: 400; batch classifier loss: 0.481642; batch adversarial loss: 0.623148\n",
      "epoch 9; iter: 0; batch classifier loss: 0.591778; batch adversarial loss: 0.605430\n",
      "epoch 9; iter: 200; batch classifier loss: 0.564181; batch adversarial loss: 0.640713\n",
      "epoch 9; iter: 400; batch classifier loss: 0.488069; batch adversarial loss: 0.536190\n",
      "epoch 0; iter: 0; batch classifier loss: 2.330995; batch adversarial loss: 0.873310\n",
      "epoch 0; iter: 200; batch classifier loss: 2.608087; batch adversarial loss: 0.689733\n",
      "epoch 0; iter: 400; batch classifier loss: 2.001647; batch adversarial loss: 0.691370\n",
      "epoch 1; iter: 0; batch classifier loss: 1.795462; batch adversarial loss: 0.646202\n",
      "epoch 1; iter: 200; batch classifier loss: 2.672738; batch adversarial loss: 0.634382\n",
      "epoch 1; iter: 400; batch classifier loss: 4.103678; batch adversarial loss: 0.663915\n",
      "epoch 2; iter: 0; batch classifier loss: 1.202705; batch adversarial loss: 0.708963\n",
      "epoch 2; iter: 200; batch classifier loss: 2.493708; batch adversarial loss: 0.611163\n",
      "epoch 2; iter: 400; batch classifier loss: 1.166596; batch adversarial loss: 0.599679\n",
      "epoch 3; iter: 0; batch classifier loss: 3.870377; batch adversarial loss: 0.651155\n",
      "epoch 3; iter: 200; batch classifier loss: 6.386539; batch adversarial loss: 0.632457\n",
      "epoch 3; iter: 400; batch classifier loss: 1.762856; batch adversarial loss: 0.623993\n",
      "epoch 4; iter: 0; batch classifier loss: 2.590249; batch adversarial loss: 0.581352\n",
      "epoch 4; iter: 200; batch classifier loss: 0.625307; batch adversarial loss: 0.626160\n",
      "epoch 4; iter: 400; batch classifier loss: 0.785250; batch adversarial loss: 0.688189\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541155; batch adversarial loss: 0.662517\n",
      "epoch 5; iter: 200; batch classifier loss: 0.407522; batch adversarial loss: 0.644735\n",
      "epoch 5; iter: 400; batch classifier loss: 0.443234; batch adversarial loss: 0.689666\n",
      "epoch 6; iter: 0; batch classifier loss: 0.858480; batch adversarial loss: 0.672422\n",
      "epoch 6; iter: 200; batch classifier loss: 0.386882; batch adversarial loss: 0.614011\n",
      "epoch 6; iter: 400; batch classifier loss: 0.451558; batch adversarial loss: 0.624959\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454058; batch adversarial loss: 0.608324\n",
      "epoch 7; iter: 200; batch classifier loss: 0.507762; batch adversarial loss: 0.652613\n",
      "epoch 7; iter: 400; batch classifier loss: 0.459249; batch adversarial loss: 0.652599\n",
      "epoch 8; iter: 0; batch classifier loss: 0.514431; batch adversarial loss: 0.595274\n",
      "epoch 8; iter: 200; batch classifier loss: 0.428236; batch adversarial loss: 0.649764\n",
      "epoch 8; iter: 400; batch classifier loss: 0.352529; batch adversarial loss: 0.593919\n",
      "epoch 9; iter: 0; batch classifier loss: 0.311765; batch adversarial loss: 0.635929\n",
      "epoch 9; iter: 200; batch classifier loss: 0.489088; batch adversarial loss: 0.592122\n",
      "epoch 9; iter: 400; batch classifier loss: 0.370655; batch adversarial loss: 0.607624\n",
      "epoch 0; iter: 0; batch classifier loss: 16.975933; batch adversarial loss: 0.753930\n",
      "epoch 0; iter: 200; batch classifier loss: 10.059146; batch adversarial loss: 0.678794\n",
      "epoch 0; iter: 400; batch classifier loss: 4.022077; batch adversarial loss: 0.595397\n",
      "epoch 1; iter: 0; batch classifier loss: 9.398186; batch adversarial loss: 0.595149\n",
      "epoch 1; iter: 200; batch classifier loss: 2.141173; batch adversarial loss: 0.625708\n",
      "epoch 1; iter: 400; batch classifier loss: 4.741924; batch adversarial loss: 0.601519\n",
      "epoch 2; iter: 0; batch classifier loss: 5.894160; batch adversarial loss: 0.656096\n",
      "epoch 2; iter: 200; batch classifier loss: 5.675807; batch adversarial loss: 0.635398\n",
      "epoch 2; iter: 400; batch classifier loss: 1.842974; batch adversarial loss: 0.585349\n",
      "epoch 3; iter: 0; batch classifier loss: 2.212305; batch adversarial loss: 0.609410\n",
      "epoch 3; iter: 200; batch classifier loss: 2.896607; batch adversarial loss: 0.665322\n",
      "epoch 3; iter: 400; batch classifier loss: 0.915538; batch adversarial loss: 0.657882\n",
      "epoch 4; iter: 0; batch classifier loss: 0.457189; batch adversarial loss: 0.624902\n",
      "epoch 4; iter: 200; batch classifier loss: 0.733834; batch adversarial loss: 0.684917\n",
      "epoch 4; iter: 400; batch classifier loss: 1.208145; batch adversarial loss: 0.631965\n",
      "epoch 5; iter: 0; batch classifier loss: 1.559667; batch adversarial loss: 0.613412\n",
      "epoch 5; iter: 200; batch classifier loss: 2.232544; batch adversarial loss: 0.679629\n",
      "epoch 5; iter: 400; batch classifier loss: 0.746909; batch adversarial loss: 0.660011\n",
      "epoch 6; iter: 0; batch classifier loss: 0.877354; batch adversarial loss: 0.590562\n",
      "epoch 6; iter: 200; batch classifier loss: 0.804629; batch adversarial loss: 0.597218\n",
      "epoch 6; iter: 400; batch classifier loss: 0.362861; batch adversarial loss: 0.657512\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501098; batch adversarial loss: 0.616689\n",
      "epoch 7; iter: 200; batch classifier loss: 0.564331; batch adversarial loss: 0.626889\n",
      "epoch 7; iter: 400; batch classifier loss: 0.492826; batch adversarial loss: 0.576258\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486722; batch adversarial loss: 0.630785\n",
      "epoch 8; iter: 200; batch classifier loss: 0.392295; batch adversarial loss: 0.694755\n",
      "epoch 8; iter: 400; batch classifier loss: 0.392355; batch adversarial loss: 0.604064\n",
      "epoch 9; iter: 0; batch classifier loss: 0.379245; batch adversarial loss: 0.671998\n",
      "epoch 9; iter: 200; batch classifier loss: 0.464433; batch adversarial loss: 0.571299\n",
      "epoch 9; iter: 400; batch classifier loss: 1.820356; batch adversarial loss: 0.617426\n",
      "epoch 0; iter: 0; batch classifier loss: 415.022766; batch adversarial loss: 0.660263\n",
      "epoch 0; iter: 200; batch classifier loss: 13.241060; batch adversarial loss: 0.724897\n",
      "epoch 0; iter: 400; batch classifier loss: 14.077251; batch adversarial loss: 0.705111\n",
      "epoch 1; iter: 0; batch classifier loss: 25.662390; batch adversarial loss: 0.699442\n",
      "epoch 1; iter: 200; batch classifier loss: 5.439888; batch adversarial loss: 0.635752\n",
      "epoch 1; iter: 400; batch classifier loss: 1.709968; batch adversarial loss: 0.655048\n",
      "epoch 2; iter: 0; batch classifier loss: 18.724997; batch adversarial loss: 0.599341\n",
      "epoch 2; iter: 200; batch classifier loss: 9.008137; batch adversarial loss: 0.650888\n",
      "epoch 2; iter: 400; batch classifier loss: 2.976354; batch adversarial loss: 0.607815\n",
      "epoch 3; iter: 0; batch classifier loss: 0.706667; batch adversarial loss: 0.601220\n",
      "epoch 3; iter: 200; batch classifier loss: 1.504843; batch adversarial loss: 0.636338\n",
      "epoch 3; iter: 400; batch classifier loss: 3.312638; batch adversarial loss: 0.606181\n",
      "epoch 4; iter: 0; batch classifier loss: 2.497907; batch adversarial loss: 0.647582\n",
      "epoch 4; iter: 200; batch classifier loss: 2.377260; batch adversarial loss: 0.620879\n",
      "epoch 4; iter: 400; batch classifier loss: 6.994452; batch adversarial loss: 0.563456\n",
      "epoch 5; iter: 0; batch classifier loss: 0.485091; batch adversarial loss: 0.611184\n",
      "epoch 5; iter: 200; batch classifier loss: 4.020809; batch adversarial loss: 0.572964\n",
      "epoch 5; iter: 400; batch classifier loss: 1.610837; batch adversarial loss: 0.606092\n",
      "epoch 6; iter: 0; batch classifier loss: 2.936449; batch adversarial loss: 0.694087\n",
      "epoch 6; iter: 200; batch classifier loss: 0.591315; batch adversarial loss: 0.631239\n",
      "epoch 6; iter: 400; batch classifier loss: 0.513361; batch adversarial loss: 0.555838\n",
      "epoch 7; iter: 0; batch classifier loss: 0.383171; batch adversarial loss: 0.619461\n",
      "epoch 7; iter: 200; batch classifier loss: 0.826072; batch adversarial loss: 0.683881\n",
      "epoch 7; iter: 400; batch classifier loss: 1.006949; batch adversarial loss: 0.677572\n",
      "epoch 8; iter: 0; batch classifier loss: 0.447110; batch adversarial loss: 0.596800\n",
      "epoch 8; iter: 200; batch classifier loss: 0.504503; batch adversarial loss: 0.675793\n",
      "epoch 8; iter: 400; batch classifier loss: 0.428331; batch adversarial loss: 0.572259\n",
      "epoch 9; iter: 0; batch classifier loss: 0.369883; batch adversarial loss: 0.593244\n",
      "epoch 9; iter: 200; batch classifier loss: 0.369998; batch adversarial loss: 0.704521\n",
      "epoch 9; iter: 400; batch classifier loss: 0.401960; batch adversarial loss: 0.637476\n",
      "epoch 0; iter: 0; batch classifier loss: 21.708450; batch adversarial loss: 0.957589\n",
      "epoch 0; iter: 200; batch classifier loss: 8.145429; batch adversarial loss: 0.956878\n",
      "epoch 0; iter: 400; batch classifier loss: 3.547022; batch adversarial loss: 0.818696\n",
      "epoch 1; iter: 0; batch classifier loss: 5.585671; batch adversarial loss: 0.734409\n",
      "epoch 1; iter: 200; batch classifier loss: 9.612262; batch adversarial loss: 0.720606\n",
      "epoch 1; iter: 400; batch classifier loss: 1.753460; batch adversarial loss: 0.659931\n",
      "epoch 2; iter: 0; batch classifier loss: 1.007698; batch adversarial loss: 0.658117\n",
      "epoch 2; iter: 200; batch classifier loss: 2.179503; batch adversarial loss: 0.591012\n",
      "epoch 2; iter: 400; batch classifier loss: 1.922724; batch adversarial loss: 0.606231\n",
      "epoch 3; iter: 0; batch classifier loss: 2.187271; batch adversarial loss: 0.577677\n",
      "epoch 3; iter: 200; batch classifier loss: 2.271012; batch adversarial loss: 0.621276\n",
      "epoch 3; iter: 400; batch classifier loss: 0.765201; batch adversarial loss: 0.550212\n",
      "epoch 4; iter: 0; batch classifier loss: 1.258143; batch adversarial loss: 0.570893\n",
      "epoch 4; iter: 200; batch classifier loss: 0.826015; batch adversarial loss: 0.624299\n",
      "epoch 4; iter: 400; batch classifier loss: 0.971612; batch adversarial loss: 0.638718\n",
      "epoch 5; iter: 0; batch classifier loss: 1.346140; batch adversarial loss: 0.682246\n",
      "epoch 5; iter: 200; batch classifier loss: 1.812696; batch adversarial loss: 0.634425\n",
      "epoch 5; iter: 400; batch classifier loss: 0.748163; batch adversarial loss: 0.636263\n",
      "epoch 6; iter: 0; batch classifier loss: 0.431872; batch adversarial loss: 0.589068\n",
      "epoch 6; iter: 200; batch classifier loss: 0.389142; batch adversarial loss: 0.677429\n",
      "epoch 6; iter: 400; batch classifier loss: 0.328172; batch adversarial loss: 0.685919\n",
      "epoch 7; iter: 0; batch classifier loss: 0.797151; batch adversarial loss: 0.619772\n",
      "epoch 7; iter: 200; batch classifier loss: 0.515889; batch adversarial loss: 0.586671\n",
      "epoch 7; iter: 400; batch classifier loss: 0.963454; batch adversarial loss: 0.605422\n",
      "epoch 8; iter: 0; batch classifier loss: 0.431414; batch adversarial loss: 0.628175\n",
      "epoch 8; iter: 200; batch classifier loss: 0.417667; batch adversarial loss: 0.598956\n",
      "epoch 8; iter: 400; batch classifier loss: 0.512622; batch adversarial loss: 0.672229\n",
      "epoch 9; iter: 0; batch classifier loss: 0.407651; batch adversarial loss: 0.648497\n",
      "epoch 9; iter: 200; batch classifier loss: 0.304025; batch adversarial loss: 0.650178\n",
      "epoch 9; iter: 400; batch classifier loss: 0.421500; batch adversarial loss: 0.597076\n",
      "epoch 0; iter: 0; batch classifier loss: 3.841711; batch adversarial loss: 0.849906\n",
      "epoch 0; iter: 200; batch classifier loss: 3.596829; batch adversarial loss: 0.940679\n",
      "epoch 0; iter: 400; batch classifier loss: 10.738239; batch adversarial loss: 0.797443\n",
      "epoch 1; iter: 0; batch classifier loss: 3.974498; batch adversarial loss: 0.722184\n",
      "epoch 1; iter: 200; batch classifier loss: 7.414365; batch adversarial loss: 0.658551\n",
      "epoch 1; iter: 400; batch classifier loss: 5.175478; batch adversarial loss: 0.656489\n",
      "epoch 2; iter: 0; batch classifier loss: 5.348582; batch adversarial loss: 0.604110\n",
      "epoch 2; iter: 200; batch classifier loss: 7.680692; batch adversarial loss: 0.610774\n",
      "epoch 2; iter: 400; batch classifier loss: 3.919223; batch adversarial loss: 0.640621\n",
      "epoch 3; iter: 0; batch classifier loss: 0.640734; batch adversarial loss: 0.625613\n",
      "epoch 3; iter: 200; batch classifier loss: 1.790922; batch adversarial loss: 0.608062\n",
      "epoch 3; iter: 400; batch classifier loss: 1.191792; batch adversarial loss: 0.567970\n",
      "epoch 4; iter: 0; batch classifier loss: 1.606320; batch adversarial loss: 0.628653\n",
      "epoch 4; iter: 200; batch classifier loss: 0.425346; batch adversarial loss: 0.586363\n",
      "epoch 4; iter: 400; batch classifier loss: 1.024816; batch adversarial loss: 0.657654\n",
      "epoch 5; iter: 0; batch classifier loss: 1.333060; batch adversarial loss: 0.585141\n",
      "epoch 5; iter: 200; batch classifier loss: 0.534401; batch adversarial loss: 0.625584\n",
      "epoch 5; iter: 400; batch classifier loss: 0.579917; batch adversarial loss: 0.557207\n",
      "epoch 6; iter: 0; batch classifier loss: 0.932765; batch adversarial loss: 0.682270\n",
      "epoch 6; iter: 200; batch classifier loss: 0.612547; batch adversarial loss: 0.649380\n",
      "epoch 6; iter: 400; batch classifier loss: 0.647983; batch adversarial loss: 0.673552\n",
      "epoch 7; iter: 0; batch classifier loss: 0.409529; batch adversarial loss: 0.599672\n",
      "epoch 7; iter: 200; batch classifier loss: 0.743117; batch adversarial loss: 0.672388\n",
      "epoch 7; iter: 400; batch classifier loss: 0.525516; batch adversarial loss: 0.583346\n",
      "epoch 8; iter: 0; batch classifier loss: 0.437784; batch adversarial loss: 0.591295\n",
      "epoch 8; iter: 200; batch classifier loss: 0.396277; batch adversarial loss: 0.538934\n",
      "epoch 8; iter: 400; batch classifier loss: 0.491895; batch adversarial loss: 0.670207\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402266; batch adversarial loss: 0.582686\n",
      "epoch 9; iter: 200; batch classifier loss: 0.431153; batch adversarial loss: 0.548704\n",
      "epoch 9; iter: 400; batch classifier loss: 0.445076; batch adversarial loss: 0.543516\n",
      "epoch 0; iter: 0; batch classifier loss: 7.398306; batch adversarial loss: 0.636297\n",
      "epoch 0; iter: 200; batch classifier loss: 0.381298; batch adversarial loss: 0.643817\n",
      "epoch 0; iter: 400; batch classifier loss: 1.683929; batch adversarial loss: 0.625558\n",
      "epoch 1; iter: 0; batch classifier loss: 1.273239; batch adversarial loss: 0.659768\n",
      "epoch 1; iter: 200; batch classifier loss: 1.072514; batch adversarial loss: 0.635895\n",
      "epoch 1; iter: 400; batch classifier loss: 0.829630; batch adversarial loss: 0.613916\n",
      "epoch 2; iter: 0; batch classifier loss: 4.473314; batch adversarial loss: 0.635378\n",
      "epoch 2; iter: 200; batch classifier loss: 9.214739; batch adversarial loss: 0.667354\n",
      "epoch 2; iter: 400; batch classifier loss: 3.791775; batch adversarial loss: 0.621914\n",
      "epoch 3; iter: 0; batch classifier loss: 5.770760; batch adversarial loss: 0.572081\n",
      "epoch 3; iter: 200; batch classifier loss: 5.827968; batch adversarial loss: 0.619555\n",
      "epoch 3; iter: 400; batch classifier loss: 3.938849; batch adversarial loss: 0.716596\n",
      "epoch 4; iter: 0; batch classifier loss: 1.397204; batch adversarial loss: 0.614063\n",
      "epoch 4; iter: 200; batch classifier loss: 4.678552; batch adversarial loss: 0.644942\n",
      "epoch 4; iter: 400; batch classifier loss: 0.649694; batch adversarial loss: 0.644934\n",
      "epoch 5; iter: 0; batch classifier loss: 1.001572; batch adversarial loss: 0.573337\n",
      "epoch 5; iter: 200; batch classifier loss: 2.119107; batch adversarial loss: 0.679289\n",
      "epoch 5; iter: 400; batch classifier loss: 2.943009; batch adversarial loss: 0.619596\n",
      "epoch 6; iter: 0; batch classifier loss: 0.365766; batch adversarial loss: 0.561401\n",
      "epoch 6; iter: 200; batch classifier loss: 2.031682; batch adversarial loss: 0.575600\n",
      "epoch 6; iter: 400; batch classifier loss: 1.362709; batch adversarial loss: 0.643094\n",
      "epoch 7; iter: 0; batch classifier loss: 0.679539; batch adversarial loss: 0.631492\n",
      "epoch 7; iter: 200; batch classifier loss: 0.609409; batch adversarial loss: 0.541805\n",
      "epoch 7; iter: 400; batch classifier loss: 0.513282; batch adversarial loss: 0.681267\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588040; batch adversarial loss: 0.522629\n",
      "epoch 8; iter: 200; batch classifier loss: 0.483282; batch adversarial loss: 0.628582\n",
      "epoch 8; iter: 400; batch classifier loss: 0.490369; batch adversarial loss: 0.566219\n",
      "epoch 9; iter: 0; batch classifier loss: 0.489084; batch adversarial loss: 0.647518\n",
      "epoch 9; iter: 200; batch classifier loss: 0.505855; batch adversarial loss: 0.574680\n",
      "epoch 9; iter: 400; batch classifier loss: 0.372028; batch adversarial loss: 0.607318\n",
      "epoch 0; iter: 0; batch classifier loss: 6.087657; batch adversarial loss: 0.649588\n",
      "epoch 0; iter: 200; batch classifier loss: 2.354155; batch adversarial loss: 0.671734\n",
      "epoch 0; iter: 400; batch classifier loss: 0.676332; batch adversarial loss: 0.673541\n",
      "epoch 1; iter: 0; batch classifier loss: 1.012045; batch adversarial loss: 0.676091\n",
      "epoch 1; iter: 200; batch classifier loss: 7.081550; batch adversarial loss: 0.588140\n",
      "epoch 1; iter: 400; batch classifier loss: 2.347498; batch adversarial loss: 0.620897\n",
      "epoch 2; iter: 0; batch classifier loss: 3.880613; batch adversarial loss: 0.634967\n",
      "epoch 2; iter: 200; batch classifier loss: 1.292136; batch adversarial loss: 0.608511\n",
      "epoch 2; iter: 400; batch classifier loss: 2.974648; batch adversarial loss: 0.635118\n",
      "epoch 3; iter: 0; batch classifier loss: 4.587313; batch adversarial loss: 0.573911\n",
      "epoch 3; iter: 200; batch classifier loss: 1.802551; batch adversarial loss: 0.624023\n",
      "epoch 3; iter: 400; batch classifier loss: 2.951416; batch adversarial loss: 0.591688\n",
      "epoch 4; iter: 0; batch classifier loss: 0.975463; batch adversarial loss: 0.628435\n",
      "epoch 4; iter: 200; batch classifier loss: 1.616073; batch adversarial loss: 0.685821\n",
      "epoch 4; iter: 400; batch classifier loss: 2.812574; batch adversarial loss: 0.545638\n",
      "epoch 5; iter: 0; batch classifier loss: 1.843637; batch adversarial loss: 0.624439\n",
      "epoch 5; iter: 200; batch classifier loss: 2.011476; batch adversarial loss: 0.598203\n",
      "epoch 5; iter: 400; batch classifier loss: 0.288507; batch adversarial loss: 0.553489\n",
      "epoch 6; iter: 0; batch classifier loss: 1.049104; batch adversarial loss: 0.636549\n",
      "epoch 6; iter: 200; batch classifier loss: 0.647325; batch adversarial loss: 0.651090\n",
      "epoch 6; iter: 400; batch classifier loss: 0.521204; batch adversarial loss: 0.519764\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587616; batch adversarial loss: 0.610459\n",
      "epoch 7; iter: 200; batch classifier loss: 0.685720; batch adversarial loss: 0.624876\n",
      "epoch 7; iter: 400; batch classifier loss: 0.384348; batch adversarial loss: 0.597058\n",
      "epoch 8; iter: 0; batch classifier loss: 0.370836; batch adversarial loss: 0.645953\n",
      "epoch 8; iter: 200; batch classifier loss: 0.463113; batch adversarial loss: 0.604485\n",
      "epoch 8; iter: 400; batch classifier loss: 0.367217; batch adversarial loss: 0.691210\n",
      "epoch 9; iter: 0; batch classifier loss: 1.064615; batch adversarial loss: 0.602769\n",
      "epoch 9; iter: 200; batch classifier loss: 0.333097; batch adversarial loss: 0.656610\n",
      "epoch 9; iter: 400; batch classifier loss: 0.407186; batch adversarial loss: 0.601024\n",
      "epoch 0; iter: 0; batch classifier loss: 7.710535; batch adversarial loss: 0.704508\n",
      "epoch 0; iter: 200; batch classifier loss: 11.169877; batch adversarial loss: 0.650173\n",
      "epoch 0; iter: 400; batch classifier loss: 6.572710; batch adversarial loss: 0.658767\n",
      "epoch 1; iter: 0; batch classifier loss: 2.199014; batch adversarial loss: 0.651460\n",
      "epoch 1; iter: 200; batch classifier loss: 2.623299; batch adversarial loss: 0.659824\n",
      "epoch 1; iter: 400; batch classifier loss: 3.792649; batch adversarial loss: 0.578593\n",
      "epoch 2; iter: 0; batch classifier loss: 1.259664; batch adversarial loss: 0.647392\n",
      "epoch 2; iter: 200; batch classifier loss: 1.981780; batch adversarial loss: 0.671183\n",
      "epoch 2; iter: 400; batch classifier loss: 0.949276; batch adversarial loss: 0.672132\n",
      "epoch 3; iter: 0; batch classifier loss: 34.299976; batch adversarial loss: 0.609524\n",
      "epoch 3; iter: 200; batch classifier loss: 5.895062; batch adversarial loss: 0.681680\n",
      "epoch 3; iter: 400; batch classifier loss: 0.627836; batch adversarial loss: 0.646365\n",
      "epoch 4; iter: 0; batch classifier loss: 0.759891; batch adversarial loss: 0.693165\n",
      "epoch 4; iter: 200; batch classifier loss: 1.150994; batch adversarial loss: 0.602395\n",
      "epoch 4; iter: 400; batch classifier loss: 1.807337; batch adversarial loss: 0.648558\n",
      "epoch 5; iter: 0; batch classifier loss: 2.701091; batch adversarial loss: 0.696485\n",
      "epoch 5; iter: 200; batch classifier loss: 1.304575; batch adversarial loss: 0.567280\n",
      "epoch 5; iter: 400; batch classifier loss: 0.606985; batch adversarial loss: 0.607777\n",
      "epoch 6; iter: 0; batch classifier loss: 1.017768; batch adversarial loss: 0.561716\n",
      "epoch 6; iter: 200; batch classifier loss: 0.663759; batch adversarial loss: 0.620519\n",
      "epoch 6; iter: 400; batch classifier loss: 0.591858; batch adversarial loss: 0.617799\n",
      "epoch 7; iter: 0; batch classifier loss: 0.861554; batch adversarial loss: 0.560124\n",
      "epoch 7; iter: 200; batch classifier loss: 0.770741; batch adversarial loss: 0.617393\n",
      "epoch 7; iter: 400; batch classifier loss: 0.346814; batch adversarial loss: 0.592535\n",
      "epoch 8; iter: 0; batch classifier loss: 0.387906; batch adversarial loss: 0.575984\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401526; batch adversarial loss: 0.634791\n",
      "epoch 8; iter: 400; batch classifier loss: 0.392467; batch adversarial loss: 0.592358\n",
      "epoch 9; iter: 0; batch classifier loss: 0.444056; batch adversarial loss: 0.547704\n",
      "epoch 9; iter: 200; batch classifier loss: 0.312155; batch adversarial loss: 0.585089\n",
      "epoch 9; iter: 400; batch classifier loss: 0.348304; batch adversarial loss: 0.608746\n",
      "epoch 0; iter: 0; batch classifier loss: 55.093140; batch adversarial loss: 0.765184\n",
      "epoch 0; iter: 200; batch classifier loss: 9.212306; batch adversarial loss: 0.731247\n",
      "epoch 0; iter: 400; batch classifier loss: 12.716290; batch adversarial loss: 0.683300\n",
      "epoch 1; iter: 0; batch classifier loss: 4.705697; batch adversarial loss: 0.654956\n",
      "epoch 1; iter: 200; batch classifier loss: 4.258178; batch adversarial loss: 0.580089\n",
      "epoch 1; iter: 400; batch classifier loss: 2.630285; batch adversarial loss: 0.624784\n",
      "epoch 2; iter: 0; batch classifier loss: 3.988965; batch adversarial loss: 0.708652\n",
      "epoch 2; iter: 200; batch classifier loss: 2.451858; batch adversarial loss: 0.637155\n",
      "epoch 2; iter: 400; batch classifier loss: 5.466753; batch adversarial loss: 0.694178\n",
      "epoch 3; iter: 0; batch classifier loss: 4.185609; batch adversarial loss: 0.704184\n",
      "epoch 3; iter: 200; batch classifier loss: 2.545164; batch adversarial loss: 0.591458\n",
      "epoch 3; iter: 400; batch classifier loss: 1.403904; batch adversarial loss: 0.645768\n",
      "epoch 4; iter: 0; batch classifier loss: 1.106915; batch adversarial loss: 0.636383\n",
      "epoch 4; iter: 200; batch classifier loss: 0.703117; batch adversarial loss: 0.617030\n",
      "epoch 4; iter: 400; batch classifier loss: 0.944331; batch adversarial loss: 0.603146\n",
      "epoch 5; iter: 0; batch classifier loss: 1.322492; batch adversarial loss: 0.552390\n",
      "epoch 5; iter: 200; batch classifier loss: 0.838972; batch adversarial loss: 0.594773\n",
      "epoch 5; iter: 400; batch classifier loss: 0.356604; batch adversarial loss: 0.763571\n",
      "epoch 6; iter: 0; batch classifier loss: 0.763149; batch adversarial loss: 0.594476\n",
      "epoch 6; iter: 200; batch classifier loss: 0.459848; batch adversarial loss: 0.560382\n",
      "epoch 6; iter: 400; batch classifier loss: 0.581144; batch adversarial loss: 0.608484\n",
      "epoch 7; iter: 0; batch classifier loss: 0.405081; batch adversarial loss: 0.679077\n",
      "epoch 7; iter: 200; batch classifier loss: 0.411883; batch adversarial loss: 0.660316\n",
      "epoch 7; iter: 400; batch classifier loss: 0.368428; batch adversarial loss: 0.599807\n",
      "epoch 8; iter: 0; batch classifier loss: 0.386639; batch adversarial loss: 0.593212\n",
      "epoch 8; iter: 200; batch classifier loss: 0.525712; batch adversarial loss: 0.603977\n",
      "epoch 8; iter: 400; batch classifier loss: 0.504416; batch adversarial loss: 0.643239\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465656; batch adversarial loss: 0.643865\n",
      "epoch 9; iter: 200; batch classifier loss: 0.394735; batch adversarial loss: 0.605613\n",
      "epoch 9; iter: 400; batch classifier loss: 0.312153; batch adversarial loss: 0.620833\n",
      "epoch 0; iter: 0; batch classifier loss: 9.832180; batch adversarial loss: 0.736225\n",
      "epoch 0; iter: 200; batch classifier loss: 7.135122; batch adversarial loss: 0.717013\n",
      "epoch 0; iter: 400; batch classifier loss: 1.208933; batch adversarial loss: 0.723355\n",
      "epoch 1; iter: 0; batch classifier loss: 15.232513; batch adversarial loss: 0.662379\n",
      "epoch 1; iter: 200; batch classifier loss: 10.320553; batch adversarial loss: 0.651787\n",
      "epoch 1; iter: 400; batch classifier loss: 8.921900; batch adversarial loss: 0.687623\n",
      "epoch 2; iter: 0; batch classifier loss: 3.379646; batch adversarial loss: 0.677803\n",
      "epoch 2; iter: 200; batch classifier loss: 6.392346; batch adversarial loss: 0.650001\n",
      "epoch 2; iter: 400; batch classifier loss: 0.866444; batch adversarial loss: 0.686485\n",
      "epoch 3; iter: 0; batch classifier loss: 0.827688; batch adversarial loss: 0.578224\n",
      "epoch 3; iter: 200; batch classifier loss: 0.487557; batch adversarial loss: 0.540950\n",
      "epoch 3; iter: 400; batch classifier loss: 1.975282; batch adversarial loss: 0.605368\n",
      "epoch 4; iter: 0; batch classifier loss: 1.188790; batch adversarial loss: 0.615524\n",
      "epoch 4; iter: 200; batch classifier loss: 1.700326; batch adversarial loss: 0.619505\n",
      "epoch 4; iter: 400; batch classifier loss: 3.161350; batch adversarial loss: 0.652886\n",
      "epoch 5; iter: 0; batch classifier loss: 2.282772; batch adversarial loss: 0.639459\n",
      "epoch 5; iter: 200; batch classifier loss: 0.832836; batch adversarial loss: 0.643465\n",
      "epoch 5; iter: 400; batch classifier loss: 0.388686; batch adversarial loss: 0.671882\n",
      "epoch 6; iter: 0; batch classifier loss: 0.938021; batch adversarial loss: 0.544062\n",
      "epoch 6; iter: 200; batch classifier loss: 0.687338; batch adversarial loss: 0.616090\n",
      "epoch 6; iter: 400; batch classifier loss: 0.919965; batch adversarial loss: 0.700503\n",
      "epoch 7; iter: 0; batch classifier loss: 0.476698; batch adversarial loss: 0.583277\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416553; batch adversarial loss: 0.622728\n",
      "epoch 7; iter: 400; batch classifier loss: 0.795897; batch adversarial loss: 0.639454\n",
      "epoch 8; iter: 0; batch classifier loss: 0.427020; batch adversarial loss: 0.627281\n",
      "epoch 8; iter: 200; batch classifier loss: 0.399711; batch adversarial loss: 0.599864\n",
      "epoch 8; iter: 400; batch classifier loss: 0.437898; batch adversarial loss: 0.635774\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386418; batch adversarial loss: 0.650684\n",
      "epoch 9; iter: 200; batch classifier loss: 0.485349; batch adversarial loss: 0.647519\n",
      "epoch 9; iter: 400; batch classifier loss: 0.323696; batch adversarial loss: 0.651671\n",
      "epoch 0; iter: 0; batch classifier loss: 22.657612; batch adversarial loss: 0.679142\n",
      "epoch 0; iter: 200; batch classifier loss: 22.492607; batch adversarial loss: 0.632400\n",
      "epoch 0; iter: 400; batch classifier loss: 4.363399; batch adversarial loss: 0.656004\n",
      "epoch 1; iter: 0; batch classifier loss: 10.471473; batch adversarial loss: 0.655447\n",
      "epoch 1; iter: 200; batch classifier loss: 1.798340; batch adversarial loss: 0.606396\n",
      "epoch 1; iter: 400; batch classifier loss: 5.019074; batch adversarial loss: 0.667426\n",
      "epoch 2; iter: 0; batch classifier loss: 6.089846; batch adversarial loss: 0.697672\n",
      "epoch 2; iter: 200; batch classifier loss: 4.359646; batch adversarial loss: 0.539576\n",
      "epoch 2; iter: 400; batch classifier loss: 7.403669; batch adversarial loss: 0.654077\n",
      "epoch 3; iter: 0; batch classifier loss: 3.909874; batch adversarial loss: 0.617613\n",
      "epoch 3; iter: 200; batch classifier loss: 1.776978; batch adversarial loss: 0.588618\n",
      "epoch 3; iter: 400; batch classifier loss: 0.925139; batch adversarial loss: 0.618512\n",
      "epoch 4; iter: 0; batch classifier loss: 0.696127; batch adversarial loss: 0.611061\n",
      "epoch 4; iter: 200; batch classifier loss: 0.600323; batch adversarial loss: 0.666083\n",
      "epoch 4; iter: 400; batch classifier loss: 0.808038; batch adversarial loss: 0.636414\n",
      "epoch 5; iter: 0; batch classifier loss: 0.861124; batch adversarial loss: 0.634462\n",
      "epoch 5; iter: 200; batch classifier loss: 0.733362; batch adversarial loss: 0.551612\n",
      "epoch 5; iter: 400; batch classifier loss: 0.610200; batch adversarial loss: 0.587157\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508528; batch adversarial loss: 0.683782\n",
      "epoch 6; iter: 200; batch classifier loss: 0.476961; batch adversarial loss: 0.578171\n",
      "epoch 6; iter: 400; batch classifier loss: 0.478860; batch adversarial loss: 0.554199\n",
      "epoch 7; iter: 0; batch classifier loss: 0.338331; batch adversarial loss: 0.668101\n",
      "epoch 7; iter: 200; batch classifier loss: 0.553661; batch adversarial loss: 0.641949\n",
      "epoch 7; iter: 400; batch classifier loss: 0.346111; batch adversarial loss: 0.646649\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381937; batch adversarial loss: 0.567500\n",
      "epoch 8; iter: 200; batch classifier loss: 0.379990; batch adversarial loss: 0.588360\n",
      "epoch 8; iter: 400; batch classifier loss: 0.312525; batch adversarial loss: 0.595283\n",
      "epoch 9; iter: 0; batch classifier loss: 0.331947; batch adversarial loss: 0.703364\n",
      "epoch 9; iter: 200; batch classifier loss: 0.369514; batch adversarial loss: 0.657685\n",
      "epoch 9; iter: 400; batch classifier loss: 0.395498; batch adversarial loss: 0.589606\n",
      "epoch 0; iter: 0; batch classifier loss: 34.586243; batch adversarial loss: 0.900126\n",
      "epoch 0; iter: 200; batch classifier loss: 7.241532; batch adversarial loss: 0.744176\n",
      "epoch 0; iter: 400; batch classifier loss: 6.207710; batch adversarial loss: 0.663591\n",
      "epoch 1; iter: 0; batch classifier loss: 19.493124; batch adversarial loss: 0.682293\n",
      "epoch 1; iter: 200; batch classifier loss: 7.848586; batch adversarial loss: 0.642906\n",
      "epoch 1; iter: 400; batch classifier loss: 3.920871; batch adversarial loss: 0.633850\n",
      "epoch 2; iter: 0; batch classifier loss: 5.752179; batch adversarial loss: 0.600773\n",
      "epoch 2; iter: 200; batch classifier loss: 5.564097; batch adversarial loss: 0.632393\n",
      "epoch 2; iter: 400; batch classifier loss: 0.520722; batch adversarial loss: 0.579881\n",
      "epoch 3; iter: 0; batch classifier loss: 35.330547; batch adversarial loss: 0.673412\n",
      "epoch 3; iter: 200; batch classifier loss: 2.825147; batch adversarial loss: 0.648834\n",
      "epoch 3; iter: 400; batch classifier loss: 11.205506; batch adversarial loss: 0.637762\n",
      "epoch 4; iter: 0; batch classifier loss: 1.893660; batch adversarial loss: 0.660372\n",
      "epoch 4; iter: 200; batch classifier loss: 1.770835; batch adversarial loss: 0.675485\n",
      "epoch 4; iter: 400; batch classifier loss: 0.527987; batch adversarial loss: 0.555527\n",
      "epoch 5; iter: 0; batch classifier loss: 1.751000; batch adversarial loss: 0.642062\n",
      "epoch 5; iter: 200; batch classifier loss: 1.060052; batch adversarial loss: 0.620733\n",
      "epoch 5; iter: 400; batch classifier loss: 0.762683; batch adversarial loss: 0.666555\n",
      "epoch 6; iter: 0; batch classifier loss: 0.834946; batch adversarial loss: 0.664461\n",
      "epoch 6; iter: 200; batch classifier loss: 0.335081; batch adversarial loss: 0.693398\n",
      "epoch 6; iter: 400; batch classifier loss: 0.663263; batch adversarial loss: 0.590984\n",
      "epoch 7; iter: 0; batch classifier loss: 0.674427; batch adversarial loss: 0.595653\n",
      "epoch 7; iter: 200; batch classifier loss: 0.471194; batch adversarial loss: 0.669990\n",
      "epoch 7; iter: 400; batch classifier loss: 0.559038; batch adversarial loss: 0.611037\n",
      "epoch 8; iter: 0; batch classifier loss: 0.681122; batch adversarial loss: 0.600668\n",
      "epoch 8; iter: 200; batch classifier loss: 0.344916; batch adversarial loss: 0.632380\n",
      "epoch 8; iter: 400; batch classifier loss: 0.581445; batch adversarial loss: 0.674586\n",
      "epoch 9; iter: 0; batch classifier loss: 0.382508; batch adversarial loss: 0.734216\n",
      "epoch 9; iter: 200; batch classifier loss: 0.545278; batch adversarial loss: 0.507307\n",
      "epoch 9; iter: 400; batch classifier loss: 0.709427; batch adversarial loss: 0.654394\n",
      "epoch 0; iter: 0; batch classifier loss: 84.379028; batch adversarial loss: 0.729115\n",
      "epoch 0; iter: 200; batch classifier loss: 2.695966; batch adversarial loss: 0.702267\n",
      "epoch 0; iter: 400; batch classifier loss: 24.926947; batch adversarial loss: 0.652590\n",
      "epoch 1; iter: 0; batch classifier loss: 9.157822; batch adversarial loss: 0.658359\n",
      "epoch 1; iter: 200; batch classifier loss: 16.496510; batch adversarial loss: 0.673013\n",
      "epoch 1; iter: 400; batch classifier loss: 1.758557; batch adversarial loss: 0.614027\n",
      "epoch 2; iter: 0; batch classifier loss: 3.828067; batch adversarial loss: 0.608979\n",
      "epoch 2; iter: 200; batch classifier loss: 1.232517; batch adversarial loss: 0.608057\n",
      "epoch 2; iter: 400; batch classifier loss: 1.089289; batch adversarial loss: 0.640901\n",
      "epoch 3; iter: 0; batch classifier loss: 1.345227; batch adversarial loss: 0.661753\n",
      "epoch 3; iter: 200; batch classifier loss: 3.570611; batch adversarial loss: 0.613358\n",
      "epoch 3; iter: 400; batch classifier loss: 0.471023; batch adversarial loss: 0.665354\n",
      "epoch 4; iter: 0; batch classifier loss: 0.860798; batch adversarial loss: 0.676076\n",
      "epoch 4; iter: 200; batch classifier loss: 2.091432; batch adversarial loss: 0.719192\n",
      "epoch 4; iter: 400; batch classifier loss: 1.354031; batch adversarial loss: 0.667676\n",
      "epoch 5; iter: 0; batch classifier loss: 1.177564; batch adversarial loss: 0.685471\n",
      "epoch 5; iter: 200; batch classifier loss: 1.031589; batch adversarial loss: 0.675856\n",
      "epoch 5; iter: 400; batch classifier loss: 0.649952; batch adversarial loss: 0.568333\n",
      "epoch 6; iter: 0; batch classifier loss: 0.457160; batch adversarial loss: 0.607711\n",
      "epoch 6; iter: 200; batch classifier loss: 0.427076; batch adversarial loss: 0.551428\n",
      "epoch 6; iter: 400; batch classifier loss: 0.558358; batch adversarial loss: 0.638147\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352152; batch adversarial loss: 0.613871\n",
      "epoch 7; iter: 200; batch classifier loss: 0.276414; batch adversarial loss: 0.546835\n",
      "epoch 7; iter: 400; batch classifier loss: 0.472334; batch adversarial loss: 0.641762\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528072; batch adversarial loss: 0.632776\n",
      "epoch 8; iter: 200; batch classifier loss: 0.427495; batch adversarial loss: 0.523209\n",
      "epoch 8; iter: 400; batch classifier loss: 0.372803; batch adversarial loss: 0.629829\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470553; batch adversarial loss: 0.562773\n",
      "epoch 9; iter: 200; batch classifier loss: 0.459770; batch adversarial loss: 0.599619\n",
      "epoch 9; iter: 400; batch classifier loss: 0.259334; batch adversarial loss: 0.642779\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 5.303514; batch adversarial loss: 0.691978\n",
      "epoch 0; iter: 200; batch classifier loss: 6.836801; batch adversarial loss: 0.680024\n",
      "epoch 0; iter: 400; batch classifier loss: 5.069405; batch adversarial loss: 0.674692\n",
      "epoch 1; iter: 0; batch classifier loss: 8.401522; batch adversarial loss: 0.678642\n",
      "epoch 1; iter: 200; batch classifier loss: 1.817679; batch adversarial loss: 0.705270\n",
      "epoch 1; iter: 400; batch classifier loss: 5.022854; batch adversarial loss: 0.622596\n",
      "epoch 2; iter: 0; batch classifier loss: 2.140104; batch adversarial loss: 0.616099\n",
      "epoch 2; iter: 200; batch classifier loss: 2.035428; batch adversarial loss: 0.595581\n",
      "epoch 2; iter: 400; batch classifier loss: 0.666944; batch adversarial loss: 0.602273\n",
      "epoch 3; iter: 0; batch classifier loss: 1.792688; batch adversarial loss: 0.575595\n",
      "epoch 3; iter: 200; batch classifier loss: 0.400881; batch adversarial loss: 0.636084\n",
      "epoch 3; iter: 400; batch classifier loss: 2.103517; batch adversarial loss: 0.613004\n",
      "epoch 4; iter: 0; batch classifier loss: 1.072267; batch adversarial loss: 0.641716\n",
      "epoch 4; iter: 200; batch classifier loss: 1.065366; batch adversarial loss: 0.672659\n",
      "epoch 4; iter: 400; batch classifier loss: 1.565536; batch adversarial loss: 0.592625\n",
      "epoch 5; iter: 0; batch classifier loss: 0.798013; batch adversarial loss: 0.611705\n",
      "epoch 5; iter: 200; batch classifier loss: 0.716449; batch adversarial loss: 0.516497\n",
      "epoch 5; iter: 400; batch classifier loss: 0.888801; batch adversarial loss: 0.621693\n",
      "epoch 6; iter: 0; batch classifier loss: 0.620406; batch adversarial loss: 0.625725\n",
      "epoch 6; iter: 200; batch classifier loss: 0.446460; batch adversarial loss: 0.641870\n",
      "epoch 6; iter: 400; batch classifier loss: 0.483249; batch adversarial loss: 0.600170\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522116; batch adversarial loss: 0.609885\n",
      "epoch 7; iter: 200; batch classifier loss: 1.042217; batch adversarial loss: 0.584918\n",
      "epoch 7; iter: 400; batch classifier loss: 0.458201; batch adversarial loss: 0.658013\n",
      "epoch 8; iter: 0; batch classifier loss: 0.311963; batch adversarial loss: 0.604178\n",
      "epoch 8; iter: 200; batch classifier loss: 0.482967; batch adversarial loss: 0.639372\n",
      "epoch 8; iter: 400; batch classifier loss: 0.367021; batch adversarial loss: 0.600273\n",
      "epoch 9; iter: 0; batch classifier loss: 0.788354; batch adversarial loss: 0.585094\n",
      "epoch 9; iter: 200; batch classifier loss: 0.466590; batch adversarial loss: 0.536035\n",
      "epoch 9; iter: 400; batch classifier loss: 0.508132; batch adversarial loss: 0.580635\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462780; batch adversarial loss: 0.680686\n",
      "epoch 10; iter: 200; batch classifier loss: 0.487211; batch adversarial loss: 0.618340\n",
      "epoch 10; iter: 400; batch classifier loss: 0.541578; batch adversarial loss: 0.585821\n",
      "epoch 11; iter: 0; batch classifier loss: 0.349923; batch adversarial loss: 0.639663\n",
      "epoch 11; iter: 200; batch classifier loss: 0.240014; batch adversarial loss: 0.670175\n",
      "epoch 11; iter: 400; batch classifier loss: 0.292822; batch adversarial loss: 0.638135\n",
      "epoch 12; iter: 0; batch classifier loss: 0.390351; batch adversarial loss: 0.521196\n",
      "epoch 12; iter: 200; batch classifier loss: 0.385575; batch adversarial loss: 0.579742\n",
      "epoch 12; iter: 400; batch classifier loss: 0.367351; batch adversarial loss: 0.549755\n",
      "epoch 13; iter: 0; batch classifier loss: 0.450740; batch adversarial loss: 0.570479\n",
      "epoch 13; iter: 200; batch classifier loss: 0.260048; batch adversarial loss: 0.686115\n",
      "epoch 13; iter: 400; batch classifier loss: 0.406447; batch adversarial loss: 0.697539\n",
      "epoch 14; iter: 0; batch classifier loss: 0.291423; batch adversarial loss: 0.712193\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378051; batch adversarial loss: 0.656175\n",
      "epoch 14; iter: 400; batch classifier loss: 0.369782; batch adversarial loss: 0.625982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.291078; batch adversarial loss: 0.577467\n",
      "epoch 15; iter: 200; batch classifier loss: 0.367384; batch adversarial loss: 0.626943\n",
      "epoch 15; iter: 400; batch classifier loss: 0.372547; batch adversarial loss: 0.602699\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376133; batch adversarial loss: 0.615893\n",
      "epoch 16; iter: 200; batch classifier loss: 0.331419; batch adversarial loss: 0.611037\n",
      "epoch 16; iter: 400; batch classifier loss: 0.337772; batch adversarial loss: 0.595845\n",
      "epoch 17; iter: 0; batch classifier loss: 0.336164; batch adversarial loss: 0.627570\n",
      "epoch 17; iter: 200; batch classifier loss: 0.355656; batch adversarial loss: 0.639922\n",
      "epoch 17; iter: 400; batch classifier loss: 0.393134; batch adversarial loss: 0.602819\n",
      "epoch 18; iter: 0; batch classifier loss: 0.397631; batch adversarial loss: 0.691212\n",
      "epoch 18; iter: 200; batch classifier loss: 0.289593; batch adversarial loss: 0.678994\n",
      "epoch 18; iter: 400; batch classifier loss: 0.510791; batch adversarial loss: 0.635774\n",
      "epoch 19; iter: 0; batch classifier loss: 0.353127; batch adversarial loss: 0.642728\n",
      "epoch 19; iter: 200; batch classifier loss: 0.596689; batch adversarial loss: 0.550694\n",
      "epoch 19; iter: 400; batch classifier loss: 0.425326; batch adversarial loss: 0.597636\n",
      "epoch 0; iter: 0; batch classifier loss: 20.380816; batch adversarial loss: 0.762389\n",
      "epoch 0; iter: 200; batch classifier loss: 3.510128; batch adversarial loss: 0.798034\n",
      "epoch 0; iter: 400; batch classifier loss: 1.132681; batch adversarial loss: 0.707534\n",
      "epoch 1; iter: 0; batch classifier loss: 2.413111; batch adversarial loss: 0.636095\n",
      "epoch 1; iter: 200; batch classifier loss: 6.687959; batch adversarial loss: 0.600242\n",
      "epoch 1; iter: 400; batch classifier loss: 1.069508; batch adversarial loss: 0.625018\n",
      "epoch 2; iter: 0; batch classifier loss: 2.154988; batch adversarial loss: 0.627320\n",
      "epoch 2; iter: 200; batch classifier loss: 5.005873; batch adversarial loss: 0.662867\n",
      "epoch 2; iter: 400; batch classifier loss: 1.693914; batch adversarial loss: 0.606268\n",
      "epoch 3; iter: 0; batch classifier loss: 1.920182; batch adversarial loss: 0.621869\n",
      "epoch 3; iter: 200; batch classifier loss: 0.498044; batch adversarial loss: 0.657825\n",
      "epoch 3; iter: 400; batch classifier loss: 0.951749; batch adversarial loss: 0.661853\n",
      "epoch 4; iter: 0; batch classifier loss: 0.380321; batch adversarial loss: 0.668488\n",
      "epoch 4; iter: 200; batch classifier loss: 1.832461; batch adversarial loss: 0.617615\n",
      "epoch 4; iter: 400; batch classifier loss: 1.086846; batch adversarial loss: 0.570772\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447624; batch adversarial loss: 0.631185\n",
      "epoch 5; iter: 200; batch classifier loss: 0.504769; batch adversarial loss: 0.639478\n",
      "epoch 5; iter: 400; batch classifier loss: 0.628251; batch adversarial loss: 0.647306\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513855; batch adversarial loss: 0.596301\n",
      "epoch 6; iter: 200; batch classifier loss: 0.552405; batch adversarial loss: 0.583042\n",
      "epoch 6; iter: 400; batch classifier loss: 0.447930; batch adversarial loss: 0.533985\n",
      "epoch 7; iter: 0; batch classifier loss: 0.445061; batch adversarial loss: 0.612553\n",
      "epoch 7; iter: 200; batch classifier loss: 0.301954; batch adversarial loss: 0.619184\n",
      "epoch 7; iter: 400; batch classifier loss: 0.371810; batch adversarial loss: 0.681027\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438102; batch adversarial loss: 0.652522\n",
      "epoch 8; iter: 200; batch classifier loss: 0.417230; batch adversarial loss: 0.638885\n",
      "epoch 8; iter: 400; batch classifier loss: 0.322216; batch adversarial loss: 0.616067\n",
      "epoch 9; iter: 0; batch classifier loss: 0.267688; batch adversarial loss: 0.677552\n",
      "epoch 9; iter: 200; batch classifier loss: 0.406333; batch adversarial loss: 0.551654\n",
      "epoch 9; iter: 400; batch classifier loss: 0.396702; batch adversarial loss: 0.624262\n",
      "epoch 10; iter: 0; batch classifier loss: 0.373977; batch adversarial loss: 0.589411\n",
      "epoch 10; iter: 200; batch classifier loss: 0.303939; batch adversarial loss: 0.642426\n",
      "epoch 10; iter: 400; batch classifier loss: 0.402014; batch adversarial loss: 0.586093\n",
      "epoch 11; iter: 0; batch classifier loss: 0.291744; batch adversarial loss: 0.585439\n",
      "epoch 11; iter: 200; batch classifier loss: 0.421313; batch adversarial loss: 0.581241\n",
      "epoch 11; iter: 400; batch classifier loss: 0.407558; batch adversarial loss: 0.579294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347860; batch adversarial loss: 0.566691\n",
      "epoch 12; iter: 200; batch classifier loss: 0.357947; batch adversarial loss: 0.666869\n",
      "epoch 12; iter: 400; batch classifier loss: 0.262208; batch adversarial loss: 0.653155\n",
      "epoch 13; iter: 0; batch classifier loss: 0.252724; batch adversarial loss: 0.651629\n",
      "epoch 13; iter: 200; batch classifier loss: 0.356802; batch adversarial loss: 0.618967\n",
      "epoch 13; iter: 400; batch classifier loss: 0.342640; batch adversarial loss: 0.602872\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431719; batch adversarial loss: 0.697389\n",
      "epoch 14; iter: 200; batch classifier loss: 0.288035; batch adversarial loss: 0.594990\n",
      "epoch 14; iter: 400; batch classifier loss: 0.296220; batch adversarial loss: 0.572638\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486151; batch adversarial loss: 0.631150\n",
      "epoch 15; iter: 200; batch classifier loss: 0.384794; batch adversarial loss: 0.617185\n",
      "epoch 15; iter: 400; batch classifier loss: 0.272844; batch adversarial loss: 0.597725\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281926; batch adversarial loss: 0.639564\n",
      "epoch 16; iter: 200; batch classifier loss: 0.420046; batch adversarial loss: 0.660081\n",
      "epoch 16; iter: 400; batch classifier loss: 0.424744; batch adversarial loss: 0.555635\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521488; batch adversarial loss: 0.644735\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321580; batch adversarial loss: 0.640981\n",
      "epoch 17; iter: 400; batch classifier loss: 0.357991; batch adversarial loss: 0.656544\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449646; batch adversarial loss: 0.665111\n",
      "epoch 18; iter: 200; batch classifier loss: 0.355985; batch adversarial loss: 0.652182\n",
      "epoch 18; iter: 400; batch classifier loss: 0.305063; batch adversarial loss: 0.667801\n",
      "epoch 19; iter: 0; batch classifier loss: 0.232750; batch adversarial loss: 0.674033\n",
      "epoch 19; iter: 200; batch classifier loss: 0.349872; batch adversarial loss: 0.625288\n",
      "epoch 19; iter: 400; batch classifier loss: 0.299089; batch adversarial loss: 0.674286\n",
      "epoch 0; iter: 0; batch classifier loss: 13.447860; batch adversarial loss: 0.711489\n",
      "epoch 0; iter: 200; batch classifier loss: 3.844658; batch adversarial loss: 0.718665\n",
      "epoch 0; iter: 400; batch classifier loss: 7.799458; batch adversarial loss: 0.659131\n",
      "epoch 1; iter: 0; batch classifier loss: 7.694279; batch adversarial loss: 0.669892\n",
      "epoch 1; iter: 200; batch classifier loss: 8.989690; batch adversarial loss: 0.656358\n",
      "epoch 1; iter: 400; batch classifier loss: 1.586719; batch adversarial loss: 0.569998\n",
      "epoch 2; iter: 0; batch classifier loss: 1.297271; batch adversarial loss: 0.637529\n",
      "epoch 2; iter: 200; batch classifier loss: 4.325757; batch adversarial loss: 0.689420\n",
      "epoch 2; iter: 400; batch classifier loss: 1.708171; batch adversarial loss: 0.701163\n",
      "epoch 3; iter: 0; batch classifier loss: 6.045404; batch adversarial loss: 0.674525\n",
      "epoch 3; iter: 200; batch classifier loss: 2.487454; batch adversarial loss: 0.731092\n",
      "epoch 3; iter: 400; batch classifier loss: 2.548346; batch adversarial loss: 0.577211\n",
      "epoch 4; iter: 0; batch classifier loss: 1.464623; batch adversarial loss: 0.749048\n",
      "epoch 4; iter: 200; batch classifier loss: 3.040058; batch adversarial loss: 0.726406\n",
      "epoch 4; iter: 400; batch classifier loss: 0.740656; batch adversarial loss: 0.717919\n",
      "epoch 5; iter: 0; batch classifier loss: 0.826755; batch adversarial loss: 0.597314\n",
      "epoch 5; iter: 200; batch classifier loss: 1.049321; batch adversarial loss: 0.630531\n",
      "epoch 5; iter: 400; batch classifier loss: 0.500705; batch adversarial loss: 0.595856\n",
      "epoch 6; iter: 0; batch classifier loss: 1.449787; batch adversarial loss: 0.638260\n",
      "epoch 6; iter: 200; batch classifier loss: 0.597171; batch adversarial loss: 0.587936\n",
      "epoch 6; iter: 400; batch classifier loss: 0.317356; batch adversarial loss: 0.679564\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465577; batch adversarial loss: 0.684276\n",
      "epoch 7; iter: 200; batch classifier loss: 0.561377; batch adversarial loss: 0.593600\n",
      "epoch 7; iter: 400; batch classifier loss: 0.606008; batch adversarial loss: 0.645363\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518587; batch adversarial loss: 0.590779\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452598; batch adversarial loss: 0.636746\n",
      "epoch 8; iter: 400; batch classifier loss: 0.454284; batch adversarial loss: 0.545764\n",
      "epoch 9; iter: 0; batch classifier loss: 0.290041; batch adversarial loss: 0.672762\n",
      "epoch 9; iter: 200; batch classifier loss: 0.537916; batch adversarial loss: 0.593747\n",
      "epoch 9; iter: 400; batch classifier loss: 0.344700; batch adversarial loss: 0.582953\n",
      "epoch 10; iter: 0; batch classifier loss: 0.359428; batch adversarial loss: 0.648358\n",
      "epoch 10; iter: 200; batch classifier loss: 0.314427; batch adversarial loss: 0.660004\n",
      "epoch 10; iter: 400; batch classifier loss: 0.351619; batch adversarial loss: 0.684525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275585; batch adversarial loss: 0.609484\n",
      "epoch 11; iter: 200; batch classifier loss: 0.299900; batch adversarial loss: 0.696989\n",
      "epoch 11; iter: 400; batch classifier loss: 0.240730; batch adversarial loss: 0.727149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.403561; batch adversarial loss: 0.574016\n",
      "epoch 12; iter: 200; batch classifier loss: 0.242349; batch adversarial loss: 0.678328\n",
      "epoch 12; iter: 400; batch classifier loss: 0.415299; batch adversarial loss: 0.713262\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473407; batch adversarial loss: 0.581439\n",
      "epoch 13; iter: 200; batch classifier loss: 0.367869; batch adversarial loss: 0.641769\n",
      "epoch 13; iter: 400; batch classifier loss: 0.440437; batch adversarial loss: 0.670229\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432647; batch adversarial loss: 0.573338\n",
      "epoch 14; iter: 200; batch classifier loss: 0.267690; batch adversarial loss: 0.667462\n",
      "epoch 14; iter: 400; batch classifier loss: 0.250454; batch adversarial loss: 0.681455\n",
      "epoch 15; iter: 0; batch classifier loss: 0.273646; batch adversarial loss: 0.603690\n",
      "epoch 15; iter: 200; batch classifier loss: 0.308710; batch adversarial loss: 0.580155\n",
      "epoch 15; iter: 400; batch classifier loss: 0.301566; batch adversarial loss: 0.570115\n",
      "epoch 16; iter: 0; batch classifier loss: 0.314965; batch adversarial loss: 0.589772\n",
      "epoch 16; iter: 200; batch classifier loss: 0.388861; batch adversarial loss: 0.643880\n",
      "epoch 16; iter: 400; batch classifier loss: 0.455371; batch adversarial loss: 0.620147\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353120; batch adversarial loss: 0.587199\n",
      "epoch 17; iter: 200; batch classifier loss: 0.387338; batch adversarial loss: 0.579803\n",
      "epoch 17; iter: 400; batch classifier loss: 0.307235; batch adversarial loss: 0.601846\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334560; batch adversarial loss: 0.589963\n",
      "epoch 18; iter: 200; batch classifier loss: 0.286939; batch adversarial loss: 0.589903\n",
      "epoch 18; iter: 400; batch classifier loss: 0.428403; batch adversarial loss: 0.592627\n",
      "epoch 19; iter: 0; batch classifier loss: 0.212580; batch adversarial loss: 0.658959\n",
      "epoch 19; iter: 200; batch classifier loss: 0.419560; batch adversarial loss: 0.555465\n",
      "epoch 19; iter: 400; batch classifier loss: 0.315105; batch adversarial loss: 0.632573\n",
      "epoch 0; iter: 0; batch classifier loss: 68.573120; batch adversarial loss: 0.698063\n",
      "epoch 0; iter: 200; batch classifier loss: 9.358873; batch adversarial loss: 0.634789\n",
      "epoch 0; iter: 400; batch classifier loss: 13.940763; batch adversarial loss: 0.607292\n",
      "epoch 1; iter: 0; batch classifier loss: 5.834126; batch adversarial loss: 0.654089\n",
      "epoch 1; iter: 200; batch classifier loss: 4.548809; batch adversarial loss: 0.619707\n",
      "epoch 1; iter: 400; batch classifier loss: 8.517314; batch adversarial loss: 0.716647\n",
      "epoch 2; iter: 0; batch classifier loss: 3.454965; batch adversarial loss: 0.684012\n",
      "epoch 2; iter: 200; batch classifier loss: 14.663675; batch adversarial loss: 0.689552\n",
      "epoch 2; iter: 400; batch classifier loss: 0.872561; batch adversarial loss: 0.630037\n",
      "epoch 3; iter: 0; batch classifier loss: 16.518047; batch adversarial loss: 0.606855\n",
      "epoch 3; iter: 200; batch classifier loss: 1.603419; batch adversarial loss: 0.644346\n",
      "epoch 3; iter: 400; batch classifier loss: 3.076816; batch adversarial loss: 0.640404\n",
      "epoch 4; iter: 0; batch classifier loss: 5.427126; batch adversarial loss: 0.600553\n",
      "epoch 4; iter: 200; batch classifier loss: 2.202956; batch adversarial loss: 0.587015\n",
      "epoch 4; iter: 400; batch classifier loss: 0.518907; batch adversarial loss: 0.617249\n",
      "epoch 5; iter: 0; batch classifier loss: 1.994218; batch adversarial loss: 0.645282\n",
      "epoch 5; iter: 200; batch classifier loss: 1.685810; batch adversarial loss: 0.661944\n",
      "epoch 5; iter: 400; batch classifier loss: 0.977423; batch adversarial loss: 0.644978\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414659; batch adversarial loss: 0.655653\n",
      "epoch 6; iter: 200; batch classifier loss: 0.589893; batch adversarial loss: 0.619209\n",
      "epoch 6; iter: 400; batch classifier loss: 0.857670; batch adversarial loss: 0.577060\n",
      "epoch 7; iter: 0; batch classifier loss: 0.484250; batch adversarial loss: 0.744757\n",
      "epoch 7; iter: 200; batch classifier loss: 0.481545; batch adversarial loss: 0.596725\n",
      "epoch 7; iter: 400; batch classifier loss: 0.512945; batch adversarial loss: 0.570168\n",
      "epoch 8; iter: 0; batch classifier loss: 0.556536; batch adversarial loss: 0.608334\n",
      "epoch 8; iter: 200; batch classifier loss: 0.588730; batch adversarial loss: 0.604939\n",
      "epoch 8; iter: 400; batch classifier loss: 0.653516; batch adversarial loss: 0.671146\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389893; batch adversarial loss: 0.632482\n",
      "epoch 9; iter: 200; batch classifier loss: 0.324014; batch adversarial loss: 0.642427\n",
      "epoch 9; iter: 400; batch classifier loss: 0.335965; batch adversarial loss: 0.773321\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565931; batch adversarial loss: 0.581801\n",
      "epoch 10; iter: 200; batch classifier loss: 0.512944; batch adversarial loss: 0.700374\n",
      "epoch 10; iter: 400; batch classifier loss: 0.278306; batch adversarial loss: 0.615167\n",
      "epoch 11; iter: 0; batch classifier loss: 0.410280; batch adversarial loss: 0.722498\n",
      "epoch 11; iter: 200; batch classifier loss: 0.382016; batch adversarial loss: 0.654322\n",
      "epoch 11; iter: 400; batch classifier loss: 0.549626; batch adversarial loss: 0.596947\n",
      "epoch 12; iter: 0; batch classifier loss: 0.372116; batch adversarial loss: 0.656384\n",
      "epoch 12; iter: 200; batch classifier loss: 0.408889; batch adversarial loss: 0.589682\n",
      "epoch 12; iter: 400; batch classifier loss: 0.348095; batch adversarial loss: 0.608705\n",
      "epoch 13; iter: 0; batch classifier loss: 0.386824; batch adversarial loss: 0.557197\n",
      "epoch 13; iter: 200; batch classifier loss: 0.514263; batch adversarial loss: 0.660655\n",
      "epoch 13; iter: 400; batch classifier loss: 0.323708; batch adversarial loss: 0.626214\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351956; batch adversarial loss: 0.601122\n",
      "epoch 14; iter: 200; batch classifier loss: 0.366647; batch adversarial loss: 0.617902\n",
      "epoch 14; iter: 400; batch classifier loss: 0.388963; batch adversarial loss: 0.664661\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382021; batch adversarial loss: 0.617893\n",
      "epoch 15; iter: 200; batch classifier loss: 0.537667; batch adversarial loss: 0.631309\n",
      "epoch 15; iter: 400; batch classifier loss: 0.511249; batch adversarial loss: 0.647553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.409019; batch adversarial loss: 0.561205\n",
      "epoch 16; iter: 200; batch classifier loss: 0.486442; batch adversarial loss: 0.553168\n",
      "epoch 16; iter: 400; batch classifier loss: 0.256301; batch adversarial loss: 0.627048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.261530; batch adversarial loss: 0.656371\n",
      "epoch 17; iter: 200; batch classifier loss: 0.429434; batch adversarial loss: 0.686358\n",
      "epoch 17; iter: 400; batch classifier loss: 0.421801; batch adversarial loss: 0.633081\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350783; batch adversarial loss: 0.625054\n",
      "epoch 18; iter: 200; batch classifier loss: 0.288210; batch adversarial loss: 0.711972\n",
      "epoch 18; iter: 400; batch classifier loss: 0.428329; batch adversarial loss: 0.678751\n",
      "epoch 19; iter: 0; batch classifier loss: 0.237744; batch adversarial loss: 0.582502\n",
      "epoch 19; iter: 200; batch classifier loss: 0.304525; batch adversarial loss: 0.612200\n",
      "epoch 19; iter: 400; batch classifier loss: 0.501810; batch adversarial loss: 0.706738\n",
      "epoch 0; iter: 0; batch classifier loss: 45.540806; batch adversarial loss: 0.703098\n",
      "epoch 0; iter: 200; batch classifier loss: 18.700094; batch adversarial loss: 0.625547\n",
      "epoch 0; iter: 400; batch classifier loss: 7.877422; batch adversarial loss: 0.588755\n",
      "epoch 1; iter: 0; batch classifier loss: 7.184273; batch adversarial loss: 0.624115\n",
      "epoch 1; iter: 200; batch classifier loss: 2.587309; batch adversarial loss: 0.666766\n",
      "epoch 1; iter: 400; batch classifier loss: 0.428446; batch adversarial loss: 0.620674\n",
      "epoch 2; iter: 0; batch classifier loss: 2.185046; batch adversarial loss: 0.555427\n",
      "epoch 2; iter: 200; batch classifier loss: 1.060108; batch adversarial loss: 0.664935\n",
      "epoch 2; iter: 400; batch classifier loss: 2.119390; batch adversarial loss: 0.695405\n",
      "epoch 3; iter: 0; batch classifier loss: 2.492640; batch adversarial loss: 0.619365\n",
      "epoch 3; iter: 200; batch classifier loss: 5.593790; batch adversarial loss: 0.653640\n",
      "epoch 3; iter: 400; batch classifier loss: 1.588571; batch adversarial loss: 0.609167\n",
      "epoch 4; iter: 0; batch classifier loss: 1.845754; batch adversarial loss: 0.661888\n",
      "epoch 4; iter: 200; batch classifier loss: 1.865616; batch adversarial loss: 0.650043\n",
      "epoch 4; iter: 400; batch classifier loss: 0.609558; batch adversarial loss: 0.628592\n",
      "epoch 5; iter: 0; batch classifier loss: 3.264727; batch adversarial loss: 0.634687\n",
      "epoch 5; iter: 200; batch classifier loss: 0.446200; batch adversarial loss: 0.563521\n",
      "epoch 5; iter: 400; batch classifier loss: 0.478996; batch adversarial loss: 0.616121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.791103; batch adversarial loss: 0.645225\n",
      "epoch 6; iter: 200; batch classifier loss: 0.711535; batch adversarial loss: 0.605347\n",
      "epoch 6; iter: 400; batch classifier loss: 0.637402; batch adversarial loss: 0.639284\n",
      "epoch 7; iter: 0; batch classifier loss: 0.742953; batch adversarial loss: 0.603123\n",
      "epoch 7; iter: 200; batch classifier loss: 0.696085; batch adversarial loss: 0.604623\n",
      "epoch 7; iter: 400; batch classifier loss: 0.379516; batch adversarial loss: 0.635428\n",
      "epoch 8; iter: 0; batch classifier loss: 0.715720; batch adversarial loss: 0.623060\n",
      "epoch 8; iter: 200; batch classifier loss: 0.616970; batch adversarial loss: 0.503878\n",
      "epoch 8; iter: 400; batch classifier loss: 0.489246; batch adversarial loss: 0.645782\n",
      "epoch 9; iter: 0; batch classifier loss: 0.666711; batch adversarial loss: 0.631676\n",
      "epoch 9; iter: 200; batch classifier loss: 0.445906; batch adversarial loss: 0.709788\n",
      "epoch 9; iter: 400; batch classifier loss: 0.564311; batch adversarial loss: 0.617305\n",
      "epoch 10; iter: 0; batch classifier loss: 0.350054; batch adversarial loss: 0.639831\n",
      "epoch 10; iter: 200; batch classifier loss: 0.578773; batch adversarial loss: 0.586979\n",
      "epoch 10; iter: 400; batch classifier loss: 0.282685; batch adversarial loss: 0.688887\n",
      "epoch 11; iter: 0; batch classifier loss: 0.261459; batch adversarial loss: 0.751362\n",
      "epoch 11; iter: 200; batch classifier loss: 0.291209; batch adversarial loss: 0.596399\n",
      "epoch 11; iter: 400; batch classifier loss: 0.282897; batch adversarial loss: 0.692224\n",
      "epoch 12; iter: 0; batch classifier loss: 0.355838; batch adversarial loss: 0.642478\n",
      "epoch 12; iter: 200; batch classifier loss: 0.327427; batch adversarial loss: 0.608752\n",
      "epoch 12; iter: 400; batch classifier loss: 0.351013; batch adversarial loss: 0.655195\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327292; batch adversarial loss: 0.695158\n",
      "epoch 13; iter: 200; batch classifier loss: 0.345108; batch adversarial loss: 0.704936\n",
      "epoch 13; iter: 400; batch classifier loss: 0.318296; batch adversarial loss: 0.551260\n",
      "epoch 14; iter: 0; batch classifier loss: 0.439150; batch adversarial loss: 0.645294\n",
      "epoch 14; iter: 200; batch classifier loss: 0.345637; batch adversarial loss: 0.603935\n",
      "epoch 14; iter: 400; batch classifier loss: 0.296387; batch adversarial loss: 0.704617\n",
      "epoch 15; iter: 0; batch classifier loss: 0.591522; batch adversarial loss: 0.636309\n",
      "epoch 15; iter: 200; batch classifier loss: 0.411701; batch adversarial loss: 0.652257\n",
      "epoch 15; iter: 400; batch classifier loss: 0.352153; batch adversarial loss: 0.610700\n",
      "epoch 16; iter: 0; batch classifier loss: 0.484724; batch adversarial loss: 0.610722\n",
      "epoch 16; iter: 200; batch classifier loss: 0.309075; batch adversarial loss: 0.633697\n",
      "epoch 16; iter: 400; batch classifier loss: 0.420680; batch adversarial loss: 0.674255\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392850; batch adversarial loss: 0.625927\n",
      "epoch 17; iter: 200; batch classifier loss: 0.368081; batch adversarial loss: 0.643087\n",
      "epoch 17; iter: 400; batch classifier loss: 0.322534; batch adversarial loss: 0.618467\n",
      "epoch 18; iter: 0; batch classifier loss: 0.375729; batch adversarial loss: 0.619972\n",
      "epoch 18; iter: 200; batch classifier loss: 0.330334; batch adversarial loss: 0.580664\n",
      "epoch 18; iter: 400; batch classifier loss: 0.489004; batch adversarial loss: 0.721829\n",
      "epoch 19; iter: 0; batch classifier loss: 0.591056; batch adversarial loss: 0.653317\n",
      "epoch 19; iter: 200; batch classifier loss: 0.453583; batch adversarial loss: 0.672072\n",
      "epoch 19; iter: 400; batch classifier loss: 0.402187; batch adversarial loss: 0.584114\n",
      "epoch 0; iter: 0; batch classifier loss: 67.018852; batch adversarial loss: 0.851410\n",
      "epoch 0; iter: 200; batch classifier loss: 23.572155; batch adversarial loss: 0.810723\n",
      "epoch 0; iter: 400; batch classifier loss: 3.838989; batch adversarial loss: 0.739616\n",
      "epoch 1; iter: 0; batch classifier loss: 9.607071; batch adversarial loss: 0.736864\n",
      "epoch 1; iter: 200; batch classifier loss: 3.598777; batch adversarial loss: 0.726669\n",
      "epoch 1; iter: 400; batch classifier loss: 5.257584; batch adversarial loss: 0.619591\n",
      "epoch 2; iter: 0; batch classifier loss: 5.165105; batch adversarial loss: 0.641600\n",
      "epoch 2; iter: 200; batch classifier loss: 1.552275; batch adversarial loss: 0.608180\n",
      "epoch 2; iter: 400; batch classifier loss: 3.856101; batch adversarial loss: 0.630807\n",
      "epoch 3; iter: 0; batch classifier loss: 5.895384; batch adversarial loss: 0.526191\n",
      "epoch 3; iter: 200; batch classifier loss: 5.970253; batch adversarial loss: 0.586021\n",
      "epoch 3; iter: 400; batch classifier loss: 0.581194; batch adversarial loss: 0.576111\n",
      "epoch 4; iter: 0; batch classifier loss: 2.008266; batch adversarial loss: 0.712515\n",
      "epoch 4; iter: 200; batch classifier loss: 2.254360; batch adversarial loss: 0.685472\n",
      "epoch 4; iter: 400; batch classifier loss: 1.437916; batch adversarial loss: 0.698152\n",
      "epoch 5; iter: 0; batch classifier loss: 1.522527; batch adversarial loss: 0.641767\n",
      "epoch 5; iter: 200; batch classifier loss: 2.363567; batch adversarial loss: 0.622459\n",
      "epoch 5; iter: 400; batch classifier loss: 2.704487; batch adversarial loss: 0.599893\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574465; batch adversarial loss: 0.573397\n",
      "epoch 6; iter: 200; batch classifier loss: 0.692737; batch adversarial loss: 0.600806\n",
      "epoch 6; iter: 400; batch classifier loss: 0.570745; batch adversarial loss: 0.618759\n",
      "epoch 7; iter: 0; batch classifier loss: 0.485243; batch adversarial loss: 0.644277\n",
      "epoch 7; iter: 200; batch classifier loss: 0.559962; batch adversarial loss: 0.588874\n",
      "epoch 7; iter: 400; batch classifier loss: 0.559533; batch adversarial loss: 0.598827\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495540; batch adversarial loss: 0.603384\n",
      "epoch 8; iter: 200; batch classifier loss: 0.366298; batch adversarial loss: 0.668107\n",
      "epoch 8; iter: 400; batch classifier loss: 0.290727; batch adversarial loss: 0.632865\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523986; batch adversarial loss: 0.579901\n",
      "epoch 9; iter: 200; batch classifier loss: 0.419104; batch adversarial loss: 0.649613\n",
      "epoch 9; iter: 400; batch classifier loss: 0.393000; batch adversarial loss: 0.573212\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374166; batch adversarial loss: 0.668399\n",
      "epoch 10; iter: 200; batch classifier loss: 0.571511; batch adversarial loss: 0.606656\n",
      "epoch 10; iter: 400; batch classifier loss: 0.327421; batch adversarial loss: 0.603531\n",
      "epoch 11; iter: 0; batch classifier loss: 0.354432; batch adversarial loss: 0.631413\n",
      "epoch 11; iter: 200; batch classifier loss: 0.356087; batch adversarial loss: 0.681041\n",
      "epoch 11; iter: 400; batch classifier loss: 0.468102; batch adversarial loss: 0.582676\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341040; batch adversarial loss: 0.550765\n",
      "epoch 12; iter: 200; batch classifier loss: 0.363344; batch adversarial loss: 0.685232\n",
      "epoch 12; iter: 400; batch classifier loss: 0.277605; batch adversarial loss: 0.671246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.278999; batch adversarial loss: 0.663129\n",
      "epoch 13; iter: 200; batch classifier loss: 0.449317; batch adversarial loss: 0.553555\n",
      "epoch 13; iter: 400; batch classifier loss: 0.289339; batch adversarial loss: 0.671439\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409473; batch adversarial loss: 0.652051\n",
      "epoch 14; iter: 200; batch classifier loss: 0.410152; batch adversarial loss: 0.569058\n",
      "epoch 14; iter: 400; batch classifier loss: 0.429802; batch adversarial loss: 0.643611\n",
      "epoch 15; iter: 0; batch classifier loss: 0.319281; batch adversarial loss: 0.627199\n",
      "epoch 15; iter: 200; batch classifier loss: 0.281151; batch adversarial loss: 0.647084\n",
      "epoch 15; iter: 400; batch classifier loss: 0.255158; batch adversarial loss: 0.589099\n",
      "epoch 16; iter: 0; batch classifier loss: 0.265913; batch adversarial loss: 0.658721\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383223; batch adversarial loss: 0.688143\n",
      "epoch 16; iter: 400; batch classifier loss: 0.428445; batch adversarial loss: 0.623316\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285665; batch adversarial loss: 0.745922\n",
      "epoch 17; iter: 200; batch classifier loss: 0.429185; batch adversarial loss: 0.602509\n",
      "epoch 17; iter: 400; batch classifier loss: 0.465203; batch adversarial loss: 0.605525\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367696; batch adversarial loss: 0.584628\n",
      "epoch 18; iter: 200; batch classifier loss: 0.347716; batch adversarial loss: 0.579387\n",
      "epoch 18; iter: 400; batch classifier loss: 0.509075; batch adversarial loss: 0.651130\n",
      "epoch 19; iter: 0; batch classifier loss: 0.348790; batch adversarial loss: 0.646398\n",
      "epoch 19; iter: 200; batch classifier loss: 0.259878; batch adversarial loss: 0.641522\n",
      "epoch 19; iter: 400; batch classifier loss: 0.456688; batch adversarial loss: 0.596477\n",
      "epoch 0; iter: 0; batch classifier loss: 7.365741; batch adversarial loss: 0.811893\n",
      "epoch 0; iter: 200; batch classifier loss: 12.105489; batch adversarial loss: 0.713932\n",
      "epoch 0; iter: 400; batch classifier loss: 10.770296; batch adversarial loss: 0.701716\n",
      "epoch 1; iter: 0; batch classifier loss: 7.819378; batch adversarial loss: 0.685394\n",
      "epoch 1; iter: 200; batch classifier loss: 2.015948; batch adversarial loss: 0.613668\n",
      "epoch 1; iter: 400; batch classifier loss: 5.727292; batch adversarial loss: 0.601131\n",
      "epoch 2; iter: 0; batch classifier loss: 3.518727; batch adversarial loss: 0.581110\n",
      "epoch 2; iter: 200; batch classifier loss: 1.406977; batch adversarial loss: 0.667528\n",
      "epoch 2; iter: 400; batch classifier loss: 4.408206; batch adversarial loss: 0.573453\n",
      "epoch 3; iter: 0; batch classifier loss: 5.280977; batch adversarial loss: 0.643361\n",
      "epoch 3; iter: 200; batch classifier loss: 2.767509; batch adversarial loss: 0.626461\n",
      "epoch 3; iter: 400; batch classifier loss: 0.461117; batch adversarial loss: 0.620663\n",
      "epoch 4; iter: 0; batch classifier loss: 1.889993; batch adversarial loss: 0.664778\n",
      "epoch 4; iter: 200; batch classifier loss: 5.627641; batch adversarial loss: 0.664629\n",
      "epoch 4; iter: 400; batch classifier loss: 0.954491; batch adversarial loss: 0.674949\n",
      "epoch 5; iter: 0; batch classifier loss: 1.533422; batch adversarial loss: 0.652469\n",
      "epoch 5; iter: 200; batch classifier loss: 0.815508; batch adversarial loss: 0.595659\n",
      "epoch 5; iter: 400; batch classifier loss: 2.056267; batch adversarial loss: 0.634580\n",
      "epoch 6; iter: 0; batch classifier loss: 2.434733; batch adversarial loss: 0.612511\n",
      "epoch 6; iter: 200; batch classifier loss: 1.094557; batch adversarial loss: 0.597331\n",
      "epoch 6; iter: 400; batch classifier loss: 0.899121; batch adversarial loss: 0.563240\n",
      "epoch 7; iter: 0; batch classifier loss: 0.435058; batch adversarial loss: 0.637459\n",
      "epoch 7; iter: 200; batch classifier loss: 0.568676; batch adversarial loss: 0.601584\n",
      "epoch 7; iter: 400; batch classifier loss: 0.653481; batch adversarial loss: 0.544488\n",
      "epoch 8; iter: 0; batch classifier loss: 0.432309; batch adversarial loss: 0.588023\n",
      "epoch 8; iter: 200; batch classifier loss: 0.417948; batch adversarial loss: 0.577883\n",
      "epoch 8; iter: 400; batch classifier loss: 0.341002; batch adversarial loss: 0.616925\n",
      "epoch 9; iter: 0; batch classifier loss: 0.385245; batch adversarial loss: 0.557443\n",
      "epoch 9; iter: 200; batch classifier loss: 0.407417; batch adversarial loss: 0.653293\n",
      "epoch 9; iter: 400; batch classifier loss: 0.489242; batch adversarial loss: 0.582822\n",
      "epoch 10; iter: 0; batch classifier loss: 0.346669; batch adversarial loss: 0.548642\n",
      "epoch 10; iter: 200; batch classifier loss: 0.525731; batch adversarial loss: 0.552152\n",
      "epoch 10; iter: 400; batch classifier loss: 0.592292; batch adversarial loss: 0.569587\n",
      "epoch 11; iter: 0; batch classifier loss: 0.465005; batch adversarial loss: 0.572185\n",
      "epoch 11; iter: 200; batch classifier loss: 0.431650; batch adversarial loss: 0.593591\n",
      "epoch 11; iter: 400; batch classifier loss: 0.498506; batch adversarial loss: 0.617816\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582081; batch adversarial loss: 0.537674\n",
      "epoch 12; iter: 200; batch classifier loss: 0.290293; batch adversarial loss: 0.634953\n",
      "epoch 12; iter: 400; batch classifier loss: 0.314673; batch adversarial loss: 0.636740\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340957; batch adversarial loss: 0.685903\n",
      "epoch 13; iter: 200; batch classifier loss: 0.431283; batch adversarial loss: 0.608621\n",
      "epoch 13; iter: 400; batch classifier loss: 0.461710; batch adversarial loss: 0.633877\n",
      "epoch 14; iter: 0; batch classifier loss: 0.414857; batch adversarial loss: 0.629220\n",
      "epoch 14; iter: 200; batch classifier loss: 0.397774; batch adversarial loss: 0.533966\n",
      "epoch 14; iter: 400; batch classifier loss: 0.420163; batch adversarial loss: 0.637834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451938; batch adversarial loss: 0.672371\n",
      "epoch 15; iter: 200; batch classifier loss: 0.305866; batch adversarial loss: 0.582570\n",
      "epoch 15; iter: 400; batch classifier loss: 0.205015; batch adversarial loss: 0.646524\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350789; batch adversarial loss: 0.635213\n",
      "epoch 16; iter: 200; batch classifier loss: 0.270354; batch adversarial loss: 0.660776\n",
      "epoch 16; iter: 400; batch classifier loss: 0.357671; batch adversarial loss: 0.608832\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424796; batch adversarial loss: 0.684952\n",
      "epoch 17; iter: 200; batch classifier loss: 0.308864; batch adversarial loss: 0.629658\n",
      "epoch 17; iter: 400; batch classifier loss: 0.400189; batch adversarial loss: 0.654133\n",
      "epoch 18; iter: 0; batch classifier loss: 0.280773; batch adversarial loss: 0.603667\n",
      "epoch 18; iter: 200; batch classifier loss: 0.362406; batch adversarial loss: 0.678626\n",
      "epoch 18; iter: 400; batch classifier loss: 0.477653; batch adversarial loss: 0.738378\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334024; batch adversarial loss: 0.684329\n",
      "epoch 19; iter: 200; batch classifier loss: 0.358020; batch adversarial loss: 0.654163\n",
      "epoch 19; iter: 400; batch classifier loss: 0.357909; batch adversarial loss: 0.644590\n",
      "epoch 0; iter: 0; batch classifier loss: 5.946074; batch adversarial loss: 0.751906\n",
      "epoch 0; iter: 200; batch classifier loss: 2.054229; batch adversarial loss: 0.669609\n",
      "epoch 0; iter: 400; batch classifier loss: 4.952759; batch adversarial loss: 0.676433\n",
      "epoch 1; iter: 0; batch classifier loss: 2.556900; batch adversarial loss: 0.646135\n",
      "epoch 1; iter: 200; batch classifier loss: 2.124400; batch adversarial loss: 0.628807\n",
      "epoch 1; iter: 400; batch classifier loss: 8.491783; batch adversarial loss: 0.681259\n",
      "epoch 2; iter: 0; batch classifier loss: 8.708947; batch adversarial loss: 0.668422\n",
      "epoch 2; iter: 200; batch classifier loss: 7.385924; batch adversarial loss: 0.574342\n",
      "epoch 2; iter: 400; batch classifier loss: 2.613300; batch adversarial loss: 0.662591\n",
      "epoch 3; iter: 0; batch classifier loss: 2.524956; batch adversarial loss: 0.633455\n",
      "epoch 3; iter: 200; batch classifier loss: 2.589891; batch adversarial loss: 0.607042\n",
      "epoch 3; iter: 400; batch classifier loss: 0.411892; batch adversarial loss: 0.631496\n",
      "epoch 4; iter: 0; batch classifier loss: 0.658993; batch adversarial loss: 0.647218\n",
      "epoch 4; iter: 200; batch classifier loss: 4.959060; batch adversarial loss: 0.612771\n",
      "epoch 4; iter: 400; batch classifier loss: 0.857980; batch adversarial loss: 0.631411\n",
      "epoch 5; iter: 0; batch classifier loss: 1.919589; batch adversarial loss: 0.623758\n",
      "epoch 5; iter: 200; batch classifier loss: 2.602638; batch adversarial loss: 0.633451\n",
      "epoch 5; iter: 400; batch classifier loss: 2.331759; batch adversarial loss: 0.629326\n",
      "epoch 6; iter: 0; batch classifier loss: 1.274451; batch adversarial loss: 0.592571\n",
      "epoch 6; iter: 200; batch classifier loss: 0.348806; batch adversarial loss: 0.701252\n",
      "epoch 6; iter: 400; batch classifier loss: 0.460296; batch adversarial loss: 0.610890\n",
      "epoch 7; iter: 0; batch classifier loss: 0.500028; batch adversarial loss: 0.723483\n",
      "epoch 7; iter: 200; batch classifier loss: 0.406307; batch adversarial loss: 0.558068\n",
      "epoch 7; iter: 400; batch classifier loss: 0.600445; batch adversarial loss: 0.588217\n",
      "epoch 8; iter: 0; batch classifier loss: 0.329479; batch adversarial loss: 0.759921\n",
      "epoch 8; iter: 200; batch classifier loss: 0.634013; batch adversarial loss: 0.618936\n",
      "epoch 8; iter: 400; batch classifier loss: 0.486634; batch adversarial loss: 0.623879\n",
      "epoch 9; iter: 0; batch classifier loss: 0.787004; batch adversarial loss: 0.603776\n",
      "epoch 9; iter: 200; batch classifier loss: 0.349210; batch adversarial loss: 0.565965\n",
      "epoch 9; iter: 400; batch classifier loss: 0.498302; batch adversarial loss: 0.606156\n",
      "epoch 10; iter: 0; batch classifier loss: 0.453674; batch adversarial loss: 0.516643\n",
      "epoch 10; iter: 200; batch classifier loss: 0.376546; batch adversarial loss: 0.594121\n",
      "epoch 10; iter: 400; batch classifier loss: 0.288985; batch adversarial loss: 0.704263\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373550; batch adversarial loss: 0.662906\n",
      "epoch 11; iter: 200; batch classifier loss: 0.300806; batch adversarial loss: 0.629174\n",
      "epoch 11; iter: 400; batch classifier loss: 0.537261; batch adversarial loss: 0.628159\n",
      "epoch 12; iter: 0; batch classifier loss: 0.443928; batch adversarial loss: 0.612165\n",
      "epoch 12; iter: 200; batch classifier loss: 0.294498; batch adversarial loss: 0.625567\n",
      "epoch 12; iter: 400; batch classifier loss: 0.239112; batch adversarial loss: 0.604715\n",
      "epoch 13; iter: 0; batch classifier loss: 0.264001; batch adversarial loss: 0.714735\n",
      "epoch 13; iter: 200; batch classifier loss: 0.354447; batch adversarial loss: 0.581679\n",
      "epoch 13; iter: 400; batch classifier loss: 0.414083; batch adversarial loss: 0.578476\n",
      "epoch 14; iter: 0; batch classifier loss: 0.482437; batch adversarial loss: 0.643622\n",
      "epoch 14; iter: 200; batch classifier loss: 0.328301; batch adversarial loss: 0.527453\n",
      "epoch 14; iter: 400; batch classifier loss: 0.390076; batch adversarial loss: 0.608666\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427077; batch adversarial loss: 0.595967\n",
      "epoch 15; iter: 200; batch classifier loss: 0.276643; batch adversarial loss: 0.653455\n",
      "epoch 15; iter: 400; batch classifier loss: 0.389379; batch adversarial loss: 0.591973\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354636; batch adversarial loss: 0.681584\n",
      "epoch 16; iter: 200; batch classifier loss: 0.236991; batch adversarial loss: 0.619411\n",
      "epoch 16; iter: 400; batch classifier loss: 0.212020; batch adversarial loss: 0.627896\n",
      "epoch 17; iter: 0; batch classifier loss: 0.220641; batch adversarial loss: 0.619997\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321837; batch adversarial loss: 0.578877\n",
      "epoch 17; iter: 400; batch classifier loss: 0.354439; batch adversarial loss: 0.639771\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358237; batch adversarial loss: 0.623799\n",
      "epoch 18; iter: 200; batch classifier loss: 0.319176; batch adversarial loss: 0.588487\n",
      "epoch 18; iter: 400; batch classifier loss: 0.405853; batch adversarial loss: 0.610707\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247064; batch adversarial loss: 0.596212\n",
      "epoch 19; iter: 200; batch classifier loss: 0.308200; batch adversarial loss: 0.602426\n",
      "epoch 19; iter: 400; batch classifier loss: 0.477476; batch adversarial loss: 0.638362\n",
      "epoch 0; iter: 0; batch classifier loss: 14.716349; batch adversarial loss: 0.671111\n",
      "epoch 0; iter: 200; batch classifier loss: 7.419501; batch adversarial loss: 0.590734\n",
      "epoch 0; iter: 400; batch classifier loss: 5.827067; batch adversarial loss: 0.653691\n",
      "epoch 1; iter: 0; batch classifier loss: 5.876601; batch adversarial loss: 0.646569\n",
      "epoch 1; iter: 200; batch classifier loss: 2.693060; batch adversarial loss: 0.570780\n",
      "epoch 1; iter: 400; batch classifier loss: 2.799687; batch adversarial loss: 0.582644\n",
      "epoch 2; iter: 0; batch classifier loss: 0.969620; batch adversarial loss: 0.581934\n",
      "epoch 2; iter: 200; batch classifier loss: 1.294928; batch adversarial loss: 0.643301\n",
      "epoch 2; iter: 400; batch classifier loss: 2.943135; batch adversarial loss: 0.630836\n",
      "epoch 3; iter: 0; batch classifier loss: 2.689120; batch adversarial loss: 0.610063\n",
      "epoch 3; iter: 200; batch classifier loss: 1.856685; batch adversarial loss: 0.614792\n",
      "epoch 3; iter: 400; batch classifier loss: 1.364799; batch adversarial loss: 0.599530\n",
      "epoch 4; iter: 0; batch classifier loss: 0.720961; batch adversarial loss: 0.635393\n",
      "epoch 4; iter: 200; batch classifier loss: 2.583889; batch adversarial loss: 0.599660\n",
      "epoch 4; iter: 400; batch classifier loss: 1.003367; batch adversarial loss: 0.574731\n",
      "epoch 5; iter: 0; batch classifier loss: 0.938414; batch adversarial loss: 0.591517\n",
      "epoch 5; iter: 200; batch classifier loss: 0.960505; batch adversarial loss: 0.581397\n",
      "epoch 5; iter: 400; batch classifier loss: 0.987264; batch adversarial loss: 0.490570\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520583; batch adversarial loss: 0.588259\n",
      "epoch 6; iter: 200; batch classifier loss: 0.504687; batch adversarial loss: 0.570990\n",
      "epoch 6; iter: 400; batch classifier loss: 0.459756; batch adversarial loss: 0.667941\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545395; batch adversarial loss: 0.605999\n",
      "epoch 7; iter: 200; batch classifier loss: 0.317736; batch adversarial loss: 0.592540\n",
      "epoch 7; iter: 400; batch classifier loss: 0.407564; batch adversarial loss: 0.657965\n",
      "epoch 8; iter: 0; batch classifier loss: 0.494203; batch adversarial loss: 0.643438\n",
      "epoch 8; iter: 200; batch classifier loss: 0.961078; batch adversarial loss: 0.501562\n",
      "epoch 8; iter: 400; batch classifier loss: 0.341024; batch adversarial loss: 0.624200\n",
      "epoch 9; iter: 0; batch classifier loss: 0.378231; batch adversarial loss: 0.643689\n",
      "epoch 9; iter: 200; batch classifier loss: 0.370555; batch adversarial loss: 0.676153\n",
      "epoch 9; iter: 400; batch classifier loss: 0.445974; batch adversarial loss: 0.541808\n",
      "epoch 10; iter: 0; batch classifier loss: 0.324818; batch adversarial loss: 0.584671\n",
      "epoch 10; iter: 200; batch classifier loss: 0.394887; batch adversarial loss: 0.602895\n",
      "epoch 10; iter: 400; batch classifier loss: 0.292940; batch adversarial loss: 0.641220\n",
      "epoch 11; iter: 0; batch classifier loss: 0.375022; batch adversarial loss: 0.601513\n",
      "epoch 11; iter: 200; batch classifier loss: 0.232493; batch adversarial loss: 0.687602\n",
      "epoch 11; iter: 400; batch classifier loss: 0.276252; batch adversarial loss: 0.573669\n",
      "epoch 12; iter: 0; batch classifier loss: 0.271288; batch adversarial loss: 0.642631\n",
      "epoch 12; iter: 200; batch classifier loss: 0.311119; batch adversarial loss: 0.637763\n",
      "epoch 12; iter: 400; batch classifier loss: 0.444554; batch adversarial loss: 0.630970\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329805; batch adversarial loss: 0.622808\n",
      "epoch 13; iter: 200; batch classifier loss: 0.355329; batch adversarial loss: 0.625903\n",
      "epoch 13; iter: 400; batch classifier loss: 0.381182; batch adversarial loss: 0.617198\n",
      "epoch 14; iter: 0; batch classifier loss: 0.311425; batch adversarial loss: 0.601956\n",
      "epoch 14; iter: 200; batch classifier loss: 0.472315; batch adversarial loss: 0.628236\n",
      "epoch 14; iter: 400; batch classifier loss: 0.384696; batch adversarial loss: 0.648933\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466996; batch adversarial loss: 0.639163\n",
      "epoch 15; iter: 200; batch classifier loss: 0.357524; batch adversarial loss: 0.657318\n",
      "epoch 15; iter: 400; batch classifier loss: 0.827101; batch adversarial loss: 0.597675\n",
      "epoch 16; iter: 0; batch classifier loss: 0.340607; batch adversarial loss: 0.646869\n",
      "epoch 16; iter: 200; batch classifier loss: 0.354072; batch adversarial loss: 0.622773\n",
      "epoch 16; iter: 400; batch classifier loss: 0.392084; batch adversarial loss: 0.664663\n",
      "epoch 17; iter: 0; batch classifier loss: 0.316389; batch adversarial loss: 0.643694\n",
      "epoch 17; iter: 200; batch classifier loss: 0.298566; batch adversarial loss: 0.638194\n",
      "epoch 17; iter: 400; batch classifier loss: 0.357105; batch adversarial loss: 0.593779\n",
      "epoch 18; iter: 0; batch classifier loss: 0.341560; batch adversarial loss: 0.633643\n",
      "epoch 18; iter: 200; batch classifier loss: 0.362502; batch adversarial loss: 0.611844\n",
      "epoch 18; iter: 400; batch classifier loss: 0.333580; batch adversarial loss: 0.664433\n",
      "epoch 19; iter: 0; batch classifier loss: 0.337329; batch adversarial loss: 0.700941\n",
      "epoch 19; iter: 200; batch classifier loss: 0.265346; batch adversarial loss: 0.656273\n",
      "epoch 19; iter: 400; batch classifier loss: 0.244490; batch adversarial loss: 0.575805\n",
      "epoch 0; iter: 0; batch classifier loss: 13.721381; batch adversarial loss: 0.726508\n",
      "epoch 0; iter: 200; batch classifier loss: 1.972554; batch adversarial loss: 0.651634\n",
      "epoch 0; iter: 400; batch classifier loss: 1.290777; batch adversarial loss: 0.659578\n",
      "epoch 1; iter: 0; batch classifier loss: 12.940837; batch adversarial loss: 0.681890\n",
      "epoch 1; iter: 200; batch classifier loss: 1.622220; batch adversarial loss: 0.654455\n",
      "epoch 1; iter: 400; batch classifier loss: 0.960779; batch adversarial loss: 0.635112\n",
      "epoch 2; iter: 0; batch classifier loss: 1.483065; batch adversarial loss: 0.597961\n",
      "epoch 2; iter: 200; batch classifier loss: 1.742530; batch adversarial loss: 0.630640\n",
      "epoch 2; iter: 400; batch classifier loss: 3.520600; batch adversarial loss: 0.675720\n",
      "epoch 3; iter: 0; batch classifier loss: 2.654342; batch adversarial loss: 0.578300\n",
      "epoch 3; iter: 200; batch classifier loss: 1.347791; batch adversarial loss: 0.661276\n",
      "epoch 3; iter: 400; batch classifier loss: 4.388896; batch adversarial loss: 0.631895\n",
      "epoch 4; iter: 0; batch classifier loss: 1.419705; batch adversarial loss: 0.592220\n",
      "epoch 4; iter: 200; batch classifier loss: 0.874096; batch adversarial loss: 0.658874\n",
      "epoch 4; iter: 400; batch classifier loss: 1.907527; batch adversarial loss: 0.619303\n",
      "epoch 5; iter: 0; batch classifier loss: 1.387723; batch adversarial loss: 0.596267\n",
      "epoch 5; iter: 200; batch classifier loss: 0.585722; batch adversarial loss: 0.573926\n",
      "epoch 5; iter: 400; batch classifier loss: 1.927049; batch adversarial loss: 0.594945\n",
      "epoch 6; iter: 0; batch classifier loss: 0.680118; batch adversarial loss: 0.671531\n",
      "epoch 6; iter: 200; batch classifier loss: 0.873630; batch adversarial loss: 0.636138\n",
      "epoch 6; iter: 400; batch classifier loss: 0.465108; batch adversarial loss: 0.603730\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532359; batch adversarial loss: 0.694636\n",
      "epoch 7; iter: 200; batch classifier loss: 0.428336; batch adversarial loss: 0.630973\n",
      "epoch 7; iter: 400; batch classifier loss: 0.516136; batch adversarial loss: 0.589061\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566796; batch adversarial loss: 0.602879\n",
      "epoch 8; iter: 200; batch classifier loss: 1.173448; batch adversarial loss: 0.598750\n",
      "epoch 8; iter: 400; batch classifier loss: 0.401459; batch adversarial loss: 0.580361\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426708; batch adversarial loss: 0.660091\n",
      "epoch 9; iter: 200; batch classifier loss: 0.358179; batch adversarial loss: 0.623277\n",
      "epoch 9; iter: 400; batch classifier loss: 0.420545; batch adversarial loss: 0.651456\n",
      "epoch 10; iter: 0; batch classifier loss: 0.341065; batch adversarial loss: 0.644694\n",
      "epoch 10; iter: 200; batch classifier loss: 0.468958; batch adversarial loss: 0.660665\n",
      "epoch 10; iter: 400; batch classifier loss: 0.454021; batch adversarial loss: 0.573602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.383433; batch adversarial loss: 0.595767\n",
      "epoch 11; iter: 200; batch classifier loss: 0.499348; batch adversarial loss: 0.563496\n",
      "epoch 11; iter: 400; batch classifier loss: 0.342462; batch adversarial loss: 0.628367\n",
      "epoch 12; iter: 0; batch classifier loss: 0.312841; batch adversarial loss: 0.602385\n",
      "epoch 12; iter: 200; batch classifier loss: 0.513335; batch adversarial loss: 0.590494\n",
      "epoch 12; iter: 400; batch classifier loss: 0.300096; batch adversarial loss: 0.598895\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335365; batch adversarial loss: 0.750280\n",
      "epoch 13; iter: 200; batch classifier loss: 0.350501; batch adversarial loss: 0.628940\n",
      "epoch 13; iter: 400; batch classifier loss: 0.259183; batch adversarial loss: 0.662548\n",
      "epoch 14; iter: 0; batch classifier loss: 0.494258; batch adversarial loss: 0.652072\n",
      "epoch 14; iter: 200; batch classifier loss: 0.326329; batch adversarial loss: 0.658985\n",
      "epoch 14; iter: 400; batch classifier loss: 0.435789; batch adversarial loss: 0.644106\n",
      "epoch 15; iter: 0; batch classifier loss: 0.260268; batch adversarial loss: 0.603719\n",
      "epoch 15; iter: 200; batch classifier loss: 0.377123; batch adversarial loss: 0.627487\n",
      "epoch 15; iter: 400; batch classifier loss: 0.330738; batch adversarial loss: 0.614645\n",
      "epoch 16; iter: 0; batch classifier loss: 0.534731; batch adversarial loss: 0.634012\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357884; batch adversarial loss: 0.671328\n",
      "epoch 16; iter: 400; batch classifier loss: 0.286420; batch adversarial loss: 0.658698\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466239; batch adversarial loss: 0.668771\n",
      "epoch 17; iter: 200; batch classifier loss: 0.355763; batch adversarial loss: 0.589998\n",
      "epoch 17; iter: 400; batch classifier loss: 0.432645; batch adversarial loss: 0.609728\n",
      "epoch 18; iter: 0; batch classifier loss: 0.498242; batch adversarial loss: 0.706180\n",
      "epoch 18; iter: 200; batch classifier loss: 0.407699; batch adversarial loss: 0.614538\n",
      "epoch 18; iter: 400; batch classifier loss: 0.354108; batch adversarial loss: 0.582736\n",
      "epoch 19; iter: 0; batch classifier loss: 0.489835; batch adversarial loss: 0.712470\n",
      "epoch 19; iter: 200; batch classifier loss: 0.472033; batch adversarial loss: 0.596054\n",
      "epoch 19; iter: 400; batch classifier loss: 0.508952; batch adversarial loss: 0.617420\n",
      "epoch 0; iter: 0; batch classifier loss: 42.856388; batch adversarial loss: 0.801263\n",
      "epoch 0; iter: 200; batch classifier loss: 19.391115; batch adversarial loss: 0.847481\n",
      "epoch 0; iter: 400; batch classifier loss: 10.174974; batch adversarial loss: 0.661762\n",
      "epoch 1; iter: 0; batch classifier loss: 6.328234; batch adversarial loss: 0.646447\n",
      "epoch 1; iter: 200; batch classifier loss: 3.722310; batch adversarial loss: 0.650446\n",
      "epoch 1; iter: 400; batch classifier loss: 11.514902; batch adversarial loss: 0.585508\n",
      "epoch 2; iter: 0; batch classifier loss: 0.777951; batch adversarial loss: 0.608916\n",
      "epoch 2; iter: 200; batch classifier loss: 6.931737; batch adversarial loss: 0.607747\n",
      "epoch 2; iter: 400; batch classifier loss: 5.873505; batch adversarial loss: 0.563645\n",
      "epoch 3; iter: 0; batch classifier loss: 4.938494; batch adversarial loss: 0.597503\n",
      "epoch 3; iter: 200; batch classifier loss: 1.384676; batch adversarial loss: 0.595416\n",
      "epoch 3; iter: 400; batch classifier loss: 2.175324; batch adversarial loss: 0.593295\n",
      "epoch 4; iter: 0; batch classifier loss: 1.460463; batch adversarial loss: 0.606231\n",
      "epoch 4; iter: 200; batch classifier loss: 0.622030; batch adversarial loss: 0.631445\n",
      "epoch 4; iter: 400; batch classifier loss: 5.421404; batch adversarial loss: 0.604963\n",
      "epoch 5; iter: 0; batch classifier loss: 2.348044; batch adversarial loss: 0.613308\n",
      "epoch 5; iter: 200; batch classifier loss: 0.384342; batch adversarial loss: 0.728892\n",
      "epoch 5; iter: 400; batch classifier loss: 0.512556; batch adversarial loss: 0.647024\n",
      "epoch 6; iter: 0; batch classifier loss: 0.841673; batch adversarial loss: 0.615591\n",
      "epoch 6; iter: 200; batch classifier loss: 0.548302; batch adversarial loss: 0.606248\n",
      "epoch 6; iter: 400; batch classifier loss: 0.610829; batch adversarial loss: 0.579205\n",
      "epoch 7; iter: 0; batch classifier loss: 0.471821; batch adversarial loss: 0.642172\n",
      "epoch 7; iter: 200; batch classifier loss: 0.338635; batch adversarial loss: 0.624385\n",
      "epoch 7; iter: 400; batch classifier loss: 0.549377; batch adversarial loss: 0.594038\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404667; batch adversarial loss: 0.563364\n",
      "epoch 8; iter: 200; batch classifier loss: 0.331836; batch adversarial loss: 0.791603\n",
      "epoch 8; iter: 400; batch classifier loss: 0.473364; batch adversarial loss: 0.646877\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512303; batch adversarial loss: 0.585358\n",
      "epoch 9; iter: 200; batch classifier loss: 0.334085; batch adversarial loss: 0.627367\n",
      "epoch 9; iter: 400; batch classifier loss: 0.311147; batch adversarial loss: 0.626322\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397766; batch adversarial loss: 0.681679\n",
      "epoch 10; iter: 200; batch classifier loss: 0.361718; batch adversarial loss: 0.553068\n",
      "epoch 10; iter: 400; batch classifier loss: 0.420970; batch adversarial loss: 0.718796\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366594; batch adversarial loss: 0.662711\n",
      "epoch 11; iter: 200; batch classifier loss: 0.335517; batch adversarial loss: 0.615949\n",
      "epoch 11; iter: 400; batch classifier loss: 0.502334; batch adversarial loss: 0.595570\n",
      "epoch 12; iter: 0; batch classifier loss: 0.321668; batch adversarial loss: 0.725556\n",
      "epoch 12; iter: 200; batch classifier loss: 0.258547; batch adversarial loss: 0.607096\n",
      "epoch 12; iter: 400; batch classifier loss: 0.355648; batch adversarial loss: 0.573179\n",
      "epoch 13; iter: 0; batch classifier loss: 0.270436; batch adversarial loss: 0.675454\n",
      "epoch 13; iter: 200; batch classifier loss: 0.414206; batch adversarial loss: 0.599116\n",
      "epoch 13; iter: 400; batch classifier loss: 0.297082; batch adversarial loss: 0.697866\n",
      "epoch 14; iter: 0; batch classifier loss: 0.313061; batch adversarial loss: 0.616391\n",
      "epoch 14; iter: 200; batch classifier loss: 0.406550; batch adversarial loss: 0.581890\n",
      "epoch 14; iter: 400; batch classifier loss: 0.423670; batch adversarial loss: 0.567917\n",
      "epoch 15; iter: 0; batch classifier loss: 0.467356; batch adversarial loss: 0.589311\n",
      "epoch 15; iter: 200; batch classifier loss: 0.218814; batch adversarial loss: 0.612586\n",
      "epoch 15; iter: 400; batch classifier loss: 0.373523; batch adversarial loss: 0.601750\n",
      "epoch 16; iter: 0; batch classifier loss: 0.298070; batch adversarial loss: 0.677385\n",
      "epoch 16; iter: 200; batch classifier loss: 0.370670; batch adversarial loss: 0.594344\n",
      "epoch 16; iter: 400; batch classifier loss: 0.468768; batch adversarial loss: 0.641500\n",
      "epoch 17; iter: 0; batch classifier loss: 0.415095; batch adversarial loss: 0.635512\n",
      "epoch 17; iter: 200; batch classifier loss: 0.492423; batch adversarial loss: 0.661659\n",
      "epoch 17; iter: 400; batch classifier loss: 0.449671; batch adversarial loss: 0.564386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286064; batch adversarial loss: 0.640201\n",
      "epoch 18; iter: 200; batch classifier loss: 0.365601; batch adversarial loss: 0.582635\n",
      "epoch 18; iter: 400; batch classifier loss: 0.442726; batch adversarial loss: 0.655328\n",
      "epoch 19; iter: 0; batch classifier loss: 0.247651; batch adversarial loss: 0.670674\n",
      "epoch 19; iter: 200; batch classifier loss: 0.373179; batch adversarial loss: 0.634645\n",
      "epoch 19; iter: 400; batch classifier loss: 0.584044; batch adversarial loss: 0.679590\n",
      "epoch 0; iter: 0; batch classifier loss: 35.812614; batch adversarial loss: 0.662388\n",
      "epoch 0; iter: 200; batch classifier loss: 2.613544; batch adversarial loss: 0.665594\n",
      "epoch 0; iter: 400; batch classifier loss: 1.356712; batch adversarial loss: 0.644789\n",
      "epoch 1; iter: 0; batch classifier loss: 3.737632; batch adversarial loss: 0.631264\n",
      "epoch 1; iter: 200; batch classifier loss: 0.375092; batch adversarial loss: 0.648819\n",
      "epoch 1; iter: 400; batch classifier loss: 2.704143; batch adversarial loss: 0.653119\n",
      "epoch 2; iter: 0; batch classifier loss: 2.819221; batch adversarial loss: 0.677959\n",
      "epoch 2; iter: 200; batch classifier loss: 1.532824; batch adversarial loss: 0.624818\n",
      "epoch 2; iter: 400; batch classifier loss: 2.309471; batch adversarial loss: 0.559079\n",
      "epoch 3; iter: 0; batch classifier loss: 1.653060; batch adversarial loss: 0.607777\n",
      "epoch 3; iter: 200; batch classifier loss: 0.988757; batch adversarial loss: 0.617782\n",
      "epoch 3; iter: 400; batch classifier loss: 0.920128; batch adversarial loss: 0.638077\n",
      "epoch 4; iter: 0; batch classifier loss: 0.903249; batch adversarial loss: 0.610445\n",
      "epoch 4; iter: 200; batch classifier loss: 0.826915; batch adversarial loss: 0.612085\n",
      "epoch 4; iter: 400; batch classifier loss: 1.110430; batch adversarial loss: 0.649435\n",
      "epoch 5; iter: 0; batch classifier loss: 0.708835; batch adversarial loss: 0.640806\n",
      "epoch 5; iter: 200; batch classifier loss: 0.498933; batch adversarial loss: 0.647816\n",
      "epoch 5; iter: 400; batch classifier loss: 0.480126; batch adversarial loss: 0.615392\n",
      "epoch 6; iter: 0; batch classifier loss: 0.381974; batch adversarial loss: 0.632213\n",
      "epoch 6; iter: 200; batch classifier loss: 0.382673; batch adversarial loss: 0.636828\n",
      "epoch 6; iter: 400; batch classifier loss: 0.394933; batch adversarial loss: 0.674418\n",
      "epoch 7; iter: 0; batch classifier loss: 0.483025; batch adversarial loss: 0.624093\n",
      "epoch 7; iter: 200; batch classifier loss: 0.603534; batch adversarial loss: 0.610260\n",
      "epoch 7; iter: 400; batch classifier loss: 0.430547; batch adversarial loss: 0.577616\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455439; batch adversarial loss: 0.601538\n",
      "epoch 8; iter: 200; batch classifier loss: 0.397654; batch adversarial loss: 0.751405\n",
      "epoch 8; iter: 400; batch classifier loss: 0.300083; batch adversarial loss: 0.723764\n",
      "epoch 9; iter: 0; batch classifier loss: 0.366550; batch adversarial loss: 0.604532\n",
      "epoch 9; iter: 200; batch classifier loss: 0.389624; batch adversarial loss: 0.619782\n",
      "epoch 9; iter: 400; batch classifier loss: 0.313684; batch adversarial loss: 0.579434\n",
      "epoch 10; iter: 0; batch classifier loss: 0.342481; batch adversarial loss: 0.677544\n",
      "epoch 10; iter: 200; batch classifier loss: 0.327172; batch adversarial loss: 0.521573\n",
      "epoch 10; iter: 400; batch classifier loss: 0.423977; batch adversarial loss: 0.528675\n",
      "epoch 11; iter: 0; batch classifier loss: 0.349435; batch adversarial loss: 0.731220\n",
      "epoch 11; iter: 200; batch classifier loss: 0.380374; batch adversarial loss: 0.613987\n",
      "epoch 11; iter: 400; batch classifier loss: 0.390528; batch adversarial loss: 0.700636\n",
      "epoch 12; iter: 0; batch classifier loss: 0.421650; batch adversarial loss: 0.578763\n",
      "epoch 12; iter: 200; batch classifier loss: 0.373306; batch adversarial loss: 0.573686\n",
      "epoch 12; iter: 400; batch classifier loss: 0.334962; batch adversarial loss: 0.604682\n",
      "epoch 13; iter: 0; batch classifier loss: 0.405719; batch adversarial loss: 0.660248\n",
      "epoch 13; iter: 200; batch classifier loss: 0.502127; batch adversarial loss: 0.661875\n",
      "epoch 13; iter: 400; batch classifier loss: 0.407041; batch adversarial loss: 0.606164\n",
      "epoch 14; iter: 0; batch classifier loss: 0.294136; batch adversarial loss: 0.511470\n",
      "epoch 14; iter: 200; batch classifier loss: 0.457103; batch adversarial loss: 0.512714\n",
      "epoch 14; iter: 400; batch classifier loss: 0.359152; batch adversarial loss: 0.655014\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391786; batch adversarial loss: 0.674589\n",
      "epoch 15; iter: 200; batch classifier loss: 0.393326; batch adversarial loss: 0.650521\n",
      "epoch 15; iter: 400; batch classifier loss: 0.258365; batch adversarial loss: 0.572696\n",
      "epoch 16; iter: 0; batch classifier loss: 0.332103; batch adversarial loss: 0.654689\n",
      "epoch 16; iter: 200; batch classifier loss: 0.344116; batch adversarial loss: 0.623986\n",
      "epoch 16; iter: 400; batch classifier loss: 0.440084; batch adversarial loss: 0.645430\n",
      "epoch 17; iter: 0; batch classifier loss: 0.388087; batch adversarial loss: 0.617257\n",
      "epoch 17; iter: 200; batch classifier loss: 0.289332; batch adversarial loss: 0.632104\n",
      "epoch 17; iter: 400; batch classifier loss: 0.413811; batch adversarial loss: 0.622091\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370881; batch adversarial loss: 0.592599\n",
      "epoch 18; iter: 200; batch classifier loss: 0.348981; batch adversarial loss: 0.592995\n",
      "epoch 18; iter: 400; batch classifier loss: 0.271633; batch adversarial loss: 0.665138\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325736; batch adversarial loss: 0.649593\n",
      "epoch 19; iter: 200; batch classifier loss: 0.357785; batch adversarial loss: 0.600767\n",
      "epoch 19; iter: 400; batch classifier loss: 0.236644; batch adversarial loss: 0.669863\n",
      "epoch 0; iter: 0; batch classifier loss: 87.464424; batch adversarial loss: 0.579201\n",
      "epoch 0; iter: 200; batch classifier loss: 11.276548; batch adversarial loss: 0.778917\n",
      "epoch 0; iter: 400; batch classifier loss: 1.939694; batch adversarial loss: 0.801204\n",
      "epoch 1; iter: 0; batch classifier loss: 0.679421; batch adversarial loss: 0.806469\n",
      "epoch 1; iter: 200; batch classifier loss: 8.462298; batch adversarial loss: 0.728712\n",
      "epoch 1; iter: 400; batch classifier loss: 11.366699; batch adversarial loss: 0.634157\n",
      "epoch 2; iter: 0; batch classifier loss: 2.129100; batch adversarial loss: 0.636821\n",
      "epoch 2; iter: 200; batch classifier loss: 3.120046; batch adversarial loss: 0.614206\n",
      "epoch 2; iter: 400; batch classifier loss: 1.933424; batch adversarial loss: 0.622426\n",
      "epoch 3; iter: 0; batch classifier loss: 4.920245; batch adversarial loss: 0.645417\n",
      "epoch 3; iter: 200; batch classifier loss: 5.308388; batch adversarial loss: 0.588604\n",
      "epoch 3; iter: 400; batch classifier loss: 1.775409; batch adversarial loss: 0.686125\n",
      "epoch 4; iter: 0; batch classifier loss: 2.058276; batch adversarial loss: 0.598667\n",
      "epoch 4; iter: 200; batch classifier loss: 1.667287; batch adversarial loss: 0.542317\n",
      "epoch 4; iter: 400; batch classifier loss: 0.414820; batch adversarial loss: 0.733132\n",
      "epoch 5; iter: 0; batch classifier loss: 1.687978; batch adversarial loss: 0.626149\n",
      "epoch 5; iter: 200; batch classifier loss: 0.846698; batch adversarial loss: 0.639916\n",
      "epoch 5; iter: 400; batch classifier loss: 0.875182; batch adversarial loss: 0.660093\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541103; batch adversarial loss: 0.681718\n",
      "epoch 6; iter: 200; batch classifier loss: 0.396411; batch adversarial loss: 0.677835\n",
      "epoch 6; iter: 400; batch classifier loss: 1.108622; batch adversarial loss: 0.615362\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494254; batch adversarial loss: 0.612181\n",
      "epoch 7; iter: 200; batch classifier loss: 0.601814; batch adversarial loss: 0.614566\n",
      "epoch 7; iter: 400; batch classifier loss: 0.461269; batch adversarial loss: 0.553427\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465534; batch adversarial loss: 0.575005\n",
      "epoch 8; iter: 200; batch classifier loss: 0.378290; batch adversarial loss: 0.639793\n",
      "epoch 8; iter: 400; batch classifier loss: 0.505695; batch adversarial loss: 0.559427\n",
      "epoch 9; iter: 0; batch classifier loss: 0.375529; batch adversarial loss: 0.524130\n",
      "epoch 9; iter: 200; batch classifier loss: 0.536460; batch adversarial loss: 0.594919\n",
      "epoch 9; iter: 400; batch classifier loss: 0.429617; batch adversarial loss: 0.630792\n",
      "epoch 10; iter: 0; batch classifier loss: 0.327744; batch adversarial loss: 0.660829\n",
      "epoch 10; iter: 200; batch classifier loss: 0.318321; batch adversarial loss: 0.664153\n",
      "epoch 10; iter: 400; batch classifier loss: 0.337145; batch adversarial loss: 0.632057\n",
      "epoch 11; iter: 0; batch classifier loss: 0.326736; batch adversarial loss: 0.586772\n",
      "epoch 11; iter: 200; batch classifier loss: 0.380878; batch adversarial loss: 0.524489\n",
      "epoch 11; iter: 400; batch classifier loss: 0.341859; batch adversarial loss: 0.542714\n",
      "epoch 12; iter: 0; batch classifier loss: 0.308679; batch adversarial loss: 0.602154\n",
      "epoch 12; iter: 200; batch classifier loss: 0.311608; batch adversarial loss: 0.636009\n",
      "epoch 12; iter: 400; batch classifier loss: 0.258136; batch adversarial loss: 0.588593\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369320; batch adversarial loss: 0.594791\n",
      "epoch 13; iter: 200; batch classifier loss: 0.390659; batch adversarial loss: 0.724639\n",
      "epoch 13; iter: 400; batch classifier loss: 0.438564; batch adversarial loss: 0.695731\n",
      "epoch 14; iter: 0; batch classifier loss: 0.380859; batch adversarial loss: 0.618376\n",
      "epoch 14; iter: 200; batch classifier loss: 0.264866; batch adversarial loss: 0.678902\n",
      "epoch 14; iter: 400; batch classifier loss: 0.337722; batch adversarial loss: 0.645258\n",
      "epoch 15; iter: 0; batch classifier loss: 0.424884; batch adversarial loss: 0.616413\n",
      "epoch 15; iter: 200; batch classifier loss: 0.370751; batch adversarial loss: 0.581494\n",
      "epoch 15; iter: 400; batch classifier loss: 0.344615; batch adversarial loss: 0.614395\n",
      "epoch 16; iter: 0; batch classifier loss: 0.525235; batch adversarial loss: 0.605946\n",
      "epoch 16; iter: 200; batch classifier loss: 0.390366; batch adversarial loss: 0.625358\n",
      "epoch 16; iter: 400; batch classifier loss: 0.492916; batch adversarial loss: 0.605051\n",
      "epoch 17; iter: 0; batch classifier loss: 0.217965; batch adversarial loss: 0.661954\n",
      "epoch 17; iter: 200; batch classifier loss: 0.416599; batch adversarial loss: 0.564744\n",
      "epoch 17; iter: 400; batch classifier loss: 0.328480; batch adversarial loss: 0.586686\n",
      "epoch 18; iter: 0; batch classifier loss: 0.411098; batch adversarial loss: 0.515696\n",
      "epoch 18; iter: 200; batch classifier loss: 0.499059; batch adversarial loss: 0.741505\n",
      "epoch 18; iter: 400; batch classifier loss: 0.243103; batch adversarial loss: 0.624497\n",
      "epoch 19; iter: 0; batch classifier loss: 0.307481; batch adversarial loss: 0.574536\n",
      "epoch 19; iter: 200; batch classifier loss: 0.558613; batch adversarial loss: 0.606457\n",
      "epoch 19; iter: 400; batch classifier loss: 0.554798; batch adversarial loss: 0.586062\n",
      "epoch 0; iter: 0; batch classifier loss: 1.585474; batch adversarial loss: 0.678511\n",
      "epoch 0; iter: 200; batch classifier loss: 14.629824; batch adversarial loss: 0.691362\n",
      "epoch 0; iter: 400; batch classifier loss: 10.887420; batch adversarial loss: 0.802668\n",
      "epoch 1; iter: 0; batch classifier loss: 13.770888; batch adversarial loss: 0.688318\n",
      "epoch 1; iter: 200; batch classifier loss: 21.454113; batch adversarial loss: 0.663846\n",
      "epoch 1; iter: 400; batch classifier loss: 15.795415; batch adversarial loss: 0.669928\n",
      "epoch 2; iter: 0; batch classifier loss: 0.881716; batch adversarial loss: 0.627343\n",
      "epoch 2; iter: 200; batch classifier loss: 17.914207; batch adversarial loss: 0.640297\n",
      "epoch 2; iter: 400; batch classifier loss: 6.548439; batch adversarial loss: 0.566265\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400291; batch adversarial loss: 0.633728\n",
      "epoch 3; iter: 200; batch classifier loss: 3.188591; batch adversarial loss: 0.680652\n",
      "epoch 3; iter: 400; batch classifier loss: 3.812988; batch adversarial loss: 0.627206\n",
      "epoch 4; iter: 0; batch classifier loss: 0.678700; batch adversarial loss: 0.662616\n",
      "epoch 4; iter: 200; batch classifier loss: 1.542744; batch adversarial loss: 0.609403\n",
      "epoch 4; iter: 400; batch classifier loss: 3.074456; batch adversarial loss: 0.609337\n",
      "epoch 5; iter: 0; batch classifier loss: 0.908005; batch adversarial loss: 0.641695\n",
      "epoch 5; iter: 200; batch classifier loss: 1.402477; batch adversarial loss: 0.643092\n",
      "epoch 5; iter: 400; batch classifier loss: 1.076159; batch adversarial loss: 0.567348\n",
      "epoch 6; iter: 0; batch classifier loss: 0.609135; batch adversarial loss: 0.620631\n",
      "epoch 6; iter: 200; batch classifier loss: 0.231379; batch adversarial loss: 0.696056\n",
      "epoch 6; iter: 400; batch classifier loss: 0.465109; batch adversarial loss: 0.494762\n",
      "epoch 7; iter: 0; batch classifier loss: 0.661543; batch adversarial loss: 0.628086\n",
      "epoch 7; iter: 200; batch classifier loss: 0.606752; batch adversarial loss: 0.557863\n",
      "epoch 7; iter: 400; batch classifier loss: 0.494460; batch adversarial loss: 0.700231\n",
      "epoch 8; iter: 0; batch classifier loss: 0.524335; batch adversarial loss: 0.622213\n",
      "epoch 8; iter: 200; batch classifier loss: 0.443649; batch adversarial loss: 0.621034\n",
      "epoch 8; iter: 400; batch classifier loss: 0.525270; batch adversarial loss: 0.631906\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440772; batch adversarial loss: 0.552095\n",
      "epoch 9; iter: 200; batch classifier loss: 0.479715; batch adversarial loss: 0.648277\n",
      "epoch 9; iter: 400; batch classifier loss: 0.380339; batch adversarial loss: 0.591155\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468323; batch adversarial loss: 0.603291\n",
      "epoch 10; iter: 200; batch classifier loss: 0.341117; batch adversarial loss: 0.624221\n",
      "epoch 10; iter: 400; batch classifier loss: 0.421433; batch adversarial loss: 0.603159\n",
      "epoch 11; iter: 0; batch classifier loss: 0.349365; batch adversarial loss: 0.609953\n",
      "epoch 11; iter: 200; batch classifier loss: 0.385351; batch adversarial loss: 0.718169\n",
      "epoch 11; iter: 400; batch classifier loss: 0.485991; batch adversarial loss: 0.566879\n",
      "epoch 12; iter: 0; batch classifier loss: 0.391578; batch adversarial loss: 0.585887\n",
      "epoch 12; iter: 200; batch classifier loss: 0.318238; batch adversarial loss: 0.587176\n",
      "epoch 12; iter: 400; batch classifier loss: 0.270562; batch adversarial loss: 0.676026\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439708; batch adversarial loss: 0.676263\n",
      "epoch 13; iter: 200; batch classifier loss: 0.377215; batch adversarial loss: 0.652998\n",
      "epoch 13; iter: 400; batch classifier loss: 0.317499; batch adversarial loss: 0.645210\n",
      "epoch 14; iter: 0; batch classifier loss: 0.391842; batch adversarial loss: 0.690112\n",
      "epoch 14; iter: 200; batch classifier loss: 0.264749; batch adversarial loss: 0.636925\n",
      "epoch 14; iter: 400; batch classifier loss: 0.418963; batch adversarial loss: 0.652226\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297091; batch adversarial loss: 0.578053\n",
      "epoch 15; iter: 200; batch classifier loss: 0.351577; batch adversarial loss: 0.571846\n",
      "epoch 15; iter: 400; batch classifier loss: 0.423054; batch adversarial loss: 0.645677\n",
      "epoch 16; iter: 0; batch classifier loss: 0.438023; batch adversarial loss: 0.650737\n",
      "epoch 16; iter: 200; batch classifier loss: 0.402379; batch adversarial loss: 0.579406\n",
      "epoch 16; iter: 400; batch classifier loss: 0.341886; batch adversarial loss: 0.536915\n",
      "epoch 17; iter: 0; batch classifier loss: 0.403231; batch adversarial loss: 0.658060\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339583; batch adversarial loss: 0.700908\n",
      "epoch 17; iter: 400; batch classifier loss: 0.412743; batch adversarial loss: 0.598214\n",
      "epoch 18; iter: 0; batch classifier loss: 0.573050; batch adversarial loss: 0.590980\n",
      "epoch 18; iter: 200; batch classifier loss: 0.314968; batch adversarial loss: 0.613719\n",
      "epoch 18; iter: 400; batch classifier loss: 0.402247; batch adversarial loss: 0.553125\n",
      "epoch 19; iter: 0; batch classifier loss: 0.449238; batch adversarial loss: 0.540974\n",
      "epoch 19; iter: 200; batch classifier loss: 0.404568; batch adversarial loss: 0.614425\n",
      "epoch 19; iter: 400; batch classifier loss: 0.514185; batch adversarial loss: 0.683307\n",
      "epoch 0; iter: 0; batch classifier loss: 254.349640; batch adversarial loss: 0.679443\n",
      "epoch 0; iter: 200; batch classifier loss: 9.698995; batch adversarial loss: 0.686688\n",
      "epoch 0; iter: 400; batch classifier loss: 6.575518; batch adversarial loss: 0.602652\n",
      "epoch 1; iter: 0; batch classifier loss: 17.197899; batch adversarial loss: 0.586926\n",
      "epoch 1; iter: 200; batch classifier loss: 7.817584; batch adversarial loss: 0.722667\n",
      "epoch 1; iter: 400; batch classifier loss: 3.772018; batch adversarial loss: 0.630857\n",
      "epoch 2; iter: 0; batch classifier loss: 0.513790; batch adversarial loss: 0.650236\n",
      "epoch 2; iter: 200; batch classifier loss: 4.393020; batch adversarial loss: 0.625586\n",
      "epoch 2; iter: 400; batch classifier loss: 3.583202; batch adversarial loss: 0.577348\n",
      "epoch 3; iter: 0; batch classifier loss: 3.571726; batch adversarial loss: 0.615369\n",
      "epoch 3; iter: 200; batch classifier loss: 1.306035; batch adversarial loss: 0.645190\n",
      "epoch 3; iter: 400; batch classifier loss: 4.948124; batch adversarial loss: 0.607295\n",
      "epoch 4; iter: 0; batch classifier loss: 1.714091; batch adversarial loss: 0.616000\n",
      "epoch 4; iter: 200; batch classifier loss: 2.629551; batch adversarial loss: 0.623606\n",
      "epoch 4; iter: 400; batch classifier loss: 1.696581; batch adversarial loss: 0.573551\n",
      "epoch 5; iter: 0; batch classifier loss: 2.000261; batch adversarial loss: 0.680304\n",
      "epoch 5; iter: 200; batch classifier loss: 0.751915; batch adversarial loss: 0.658215\n",
      "epoch 5; iter: 400; batch classifier loss: 0.359684; batch adversarial loss: 0.714385\n",
      "epoch 6; iter: 0; batch classifier loss: 0.713283; batch adversarial loss: 0.642380\n",
      "epoch 6; iter: 200; batch classifier loss: 1.134409; batch adversarial loss: 0.612373\n",
      "epoch 6; iter: 400; batch classifier loss: 1.093911; batch adversarial loss: 0.622880\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548868; batch adversarial loss: 0.552013\n",
      "epoch 7; iter: 200; batch classifier loss: 0.842206; batch adversarial loss: 0.689331\n",
      "epoch 7; iter: 400; batch classifier loss: 0.450373; batch adversarial loss: 0.569923\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451861; batch adversarial loss: 0.659499\n",
      "epoch 8; iter: 200; batch classifier loss: 0.524244; batch adversarial loss: 0.631024\n",
      "epoch 8; iter: 400; batch classifier loss: 0.572595; batch adversarial loss: 0.574667\n",
      "epoch 9; iter: 0; batch classifier loss: 0.579316; batch adversarial loss: 0.639136\n",
      "epoch 9; iter: 200; batch classifier loss: 0.435733; batch adversarial loss: 0.697942\n",
      "epoch 9; iter: 400; batch classifier loss: 0.451687; batch adversarial loss: 0.645268\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371263; batch adversarial loss: 0.630469\n",
      "epoch 10; iter: 200; batch classifier loss: 0.410768; batch adversarial loss: 0.607942\n",
      "epoch 10; iter: 400; batch classifier loss: 0.417070; batch adversarial loss: 0.560941\n",
      "epoch 11; iter: 0; batch classifier loss: 0.574081; batch adversarial loss: 0.634731\n",
      "epoch 11; iter: 200; batch classifier loss: 0.414568; batch adversarial loss: 0.571017\n",
      "epoch 11; iter: 400; batch classifier loss: 0.362585; batch adversarial loss: 0.590691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.451046; batch adversarial loss: 0.598749\n",
      "epoch 12; iter: 200; batch classifier loss: 0.259163; batch adversarial loss: 0.655731\n",
      "epoch 12; iter: 400; batch classifier loss: 0.422639; batch adversarial loss: 0.589127\n",
      "epoch 13; iter: 0; batch classifier loss: 0.350585; batch adversarial loss: 0.595234\n",
      "epoch 13; iter: 200; batch classifier loss: 0.402216; batch adversarial loss: 0.586808\n",
      "epoch 13; iter: 400; batch classifier loss: 0.288163; batch adversarial loss: 0.634566\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368992; batch adversarial loss: 0.636864\n",
      "epoch 14; iter: 200; batch classifier loss: 0.198946; batch adversarial loss: 0.597483\n",
      "epoch 14; iter: 400; batch classifier loss: 0.304766; batch adversarial loss: 0.673595\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500624; batch adversarial loss: 0.655856\n",
      "epoch 15; iter: 200; batch classifier loss: 0.434999; batch adversarial loss: 0.683157\n",
      "epoch 15; iter: 400; batch classifier loss: 0.366121; batch adversarial loss: 0.607582\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385929; batch adversarial loss: 0.647047\n",
      "epoch 16; iter: 200; batch classifier loss: 0.486851; batch adversarial loss: 0.643295\n",
      "epoch 16; iter: 400; batch classifier loss: 0.745882; batch adversarial loss: 0.607529\n",
      "epoch 17; iter: 0; batch classifier loss: 0.416213; batch adversarial loss: 0.621521\n",
      "epoch 17; iter: 200; batch classifier loss: 0.441497; batch adversarial loss: 0.640992\n",
      "epoch 17; iter: 400; batch classifier loss: 0.494667; batch adversarial loss: 0.702239\n",
      "epoch 18; iter: 0; batch classifier loss: 0.331693; batch adversarial loss: 0.674295\n",
      "epoch 18; iter: 200; batch classifier loss: 0.343597; batch adversarial loss: 0.627807\n",
      "epoch 18; iter: 400; batch classifier loss: 0.427456; batch adversarial loss: 0.614423\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408049; batch adversarial loss: 0.637958\n",
      "epoch 19; iter: 200; batch classifier loss: 0.366754; batch adversarial loss: 0.638758\n",
      "epoch 19; iter: 400; batch classifier loss: 0.511872; batch adversarial loss: 0.636339\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 64, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 16.452837; batch adversarial loss: 0.754008\n",
      "epoch 0; iter: 200; batch classifier loss: 11.497711; batch adversarial loss: 0.714288\n",
      "epoch 0; iter: 400; batch classifier loss: 5.820632; batch adversarial loss: 0.684491\n",
      "epoch 1; iter: 0; batch classifier loss: 1.777097; batch adversarial loss: 0.661250\n",
      "epoch 1; iter: 200; batch classifier loss: 1.135346; batch adversarial loss: 0.676454\n",
      "epoch 1; iter: 400; batch classifier loss: 2.673775; batch adversarial loss: 0.612745\n",
      "epoch 2; iter: 0; batch classifier loss: 2.227414; batch adversarial loss: 0.637960\n",
      "epoch 2; iter: 200; batch classifier loss: 2.496587; batch adversarial loss: 0.650428\n",
      "epoch 2; iter: 400; batch classifier loss: 3.381624; batch adversarial loss: 0.618296\n",
      "epoch 3; iter: 0; batch classifier loss: 1.526485; batch adversarial loss: 0.632221\n",
      "epoch 3; iter: 200; batch classifier loss: 4.550666; batch adversarial loss: 0.650137\n",
      "epoch 3; iter: 400; batch classifier loss: 2.934333; batch adversarial loss: 0.634854\n",
      "epoch 4; iter: 0; batch classifier loss: 1.860018; batch adversarial loss: 0.637948\n",
      "epoch 4; iter: 200; batch classifier loss: 2.327151; batch adversarial loss: 0.582380\n",
      "epoch 4; iter: 400; batch classifier loss: 0.513970; batch adversarial loss: 0.635956\n",
      "epoch 5; iter: 0; batch classifier loss: 0.950375; batch adversarial loss: 0.597622\n",
      "epoch 5; iter: 200; batch classifier loss: 0.504250; batch adversarial loss: 0.567514\n",
      "epoch 5; iter: 400; batch classifier loss: 1.748506; batch adversarial loss: 0.539162\n",
      "epoch 6; iter: 0; batch classifier loss: 0.578112; batch adversarial loss: 0.633307\n",
      "epoch 6; iter: 200; batch classifier loss: 1.043956; batch adversarial loss: 0.675851\n",
      "epoch 6; iter: 400; batch classifier loss: 1.686710; batch adversarial loss: 0.570606\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410769; batch adversarial loss: 0.669759\n",
      "epoch 7; iter: 200; batch classifier loss: 0.413673; batch adversarial loss: 0.697115\n",
      "epoch 7; iter: 400; batch classifier loss: 0.423158; batch adversarial loss: 0.607578\n",
      "epoch 8; iter: 0; batch classifier loss: 0.341507; batch adversarial loss: 0.627383\n",
      "epoch 8; iter: 200; batch classifier loss: 0.347616; batch adversarial loss: 0.673342\n",
      "epoch 8; iter: 400; batch classifier loss: 0.588955; batch adversarial loss: 0.669410\n",
      "epoch 9; iter: 0; batch classifier loss: 0.485859; batch adversarial loss: 0.561830\n",
      "epoch 9; iter: 200; batch classifier loss: 0.379476; batch adversarial loss: 0.630699\n",
      "epoch 9; iter: 400; batch classifier loss: 0.494558; batch adversarial loss: 0.621485\n",
      "epoch 10; iter: 0; batch classifier loss: 0.314441; batch adversarial loss: 0.605053\n",
      "epoch 10; iter: 200; batch classifier loss: 0.422352; batch adversarial loss: 0.593297\n",
      "epoch 10; iter: 400; batch classifier loss: 0.278258; batch adversarial loss: 0.535912\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413210; batch adversarial loss: 0.623348\n",
      "epoch 11; iter: 200; batch classifier loss: 0.286808; batch adversarial loss: 0.603690\n",
      "epoch 11; iter: 400; batch classifier loss: 0.311773; batch adversarial loss: 0.668098\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352412; batch adversarial loss: 0.574689\n",
      "epoch 12; iter: 200; batch classifier loss: 0.366514; batch adversarial loss: 0.638605\n",
      "epoch 12; iter: 400; batch classifier loss: 0.278821; batch adversarial loss: 0.691794\n",
      "epoch 13; iter: 0; batch classifier loss: 0.346636; batch adversarial loss: 0.721819\n",
      "epoch 13; iter: 200; batch classifier loss: 0.309966; batch adversarial loss: 0.617140\n",
      "epoch 13; iter: 400; batch classifier loss: 0.434238; batch adversarial loss: 0.619940\n",
      "epoch 14; iter: 0; batch classifier loss: 0.357435; batch adversarial loss: 0.628256\n",
      "epoch 14; iter: 200; batch classifier loss: 0.386792; batch adversarial loss: 0.583638\n",
      "epoch 14; iter: 400; batch classifier loss: 0.312740; batch adversarial loss: 0.568031\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379263; batch adversarial loss: 0.608882\n",
      "epoch 15; iter: 200; batch classifier loss: 0.663343; batch adversarial loss: 0.527835\n",
      "epoch 15; iter: 400; batch classifier loss: 0.256096; batch adversarial loss: 0.579005\n",
      "epoch 16; iter: 0; batch classifier loss: 0.352315; batch adversarial loss: 0.632816\n",
      "epoch 16; iter: 200; batch classifier loss: 0.249682; batch adversarial loss: 0.649404\n",
      "epoch 16; iter: 400; batch classifier loss: 0.382115; batch adversarial loss: 0.564322\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373411; batch adversarial loss: 0.602222\n",
      "epoch 17; iter: 200; batch classifier loss: 0.334322; batch adversarial loss: 0.673787\n",
      "epoch 17; iter: 400; batch classifier loss: 0.245592; batch adversarial loss: 0.608593\n",
      "epoch 18; iter: 0; batch classifier loss: 0.293871; batch adversarial loss: 0.656750\n",
      "epoch 18; iter: 200; batch classifier loss: 0.491717; batch adversarial loss: 0.598489\n",
      "epoch 18; iter: 400; batch classifier loss: 0.454392; batch adversarial loss: 0.610646\n",
      "epoch 19; iter: 0; batch classifier loss: 0.565455; batch adversarial loss: 0.577638\n",
      "epoch 19; iter: 200; batch classifier loss: 0.343934; batch adversarial loss: 0.616772\n",
      "epoch 19; iter: 400; batch classifier loss: 0.445719; batch adversarial loss: 0.547495\n",
      "epoch 20; iter: 0; batch classifier loss: 0.389803; batch adversarial loss: 0.638883\n",
      "epoch 20; iter: 200; batch classifier loss: 0.377173; batch adversarial loss: 0.719958\n",
      "epoch 20; iter: 400; batch classifier loss: 0.419533; batch adversarial loss: 0.637756\n",
      "epoch 21; iter: 0; batch classifier loss: 0.332380; batch adversarial loss: 0.572852\n",
      "epoch 21; iter: 200; batch classifier loss: 0.402493; batch adversarial loss: 0.663782\n",
      "epoch 21; iter: 400; batch classifier loss: 0.476378; batch adversarial loss: 0.605154\n",
      "epoch 22; iter: 0; batch classifier loss: 0.316202; batch adversarial loss: 0.539115\n",
      "epoch 22; iter: 200; batch classifier loss: 0.376243; batch adversarial loss: 0.669133\n",
      "epoch 22; iter: 400; batch classifier loss: 0.316949; batch adversarial loss: 0.616806\n",
      "epoch 23; iter: 0; batch classifier loss: 0.573637; batch adversarial loss: 0.703175\n",
      "epoch 23; iter: 200; batch classifier loss: 0.263051; batch adversarial loss: 0.620919\n",
      "epoch 23; iter: 400; batch classifier loss: 0.326463; batch adversarial loss: 0.569387\n",
      "epoch 24; iter: 0; batch classifier loss: 0.263973; batch adversarial loss: 0.641660\n",
      "epoch 24; iter: 200; batch classifier loss: 0.370889; batch adversarial loss: 0.600047\n",
      "epoch 24; iter: 400; batch classifier loss: 0.378198; batch adversarial loss: 0.647796\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402140; batch adversarial loss: 0.618715\n",
      "epoch 25; iter: 200; batch classifier loss: 0.508145; batch adversarial loss: 0.577894\n",
      "epoch 25; iter: 400; batch classifier loss: 0.507223; batch adversarial loss: 0.663206\n",
      "epoch 26; iter: 0; batch classifier loss: 0.328361; batch adversarial loss: 0.698626\n",
      "epoch 26; iter: 200; batch classifier loss: 0.309663; batch adversarial loss: 0.613798\n",
      "epoch 26; iter: 400; batch classifier loss: 0.404223; batch adversarial loss: 0.646719\n",
      "epoch 27; iter: 0; batch classifier loss: 0.494547; batch adversarial loss: 0.691549\n",
      "epoch 27; iter: 200; batch classifier loss: 0.481118; batch adversarial loss: 0.598364\n",
      "epoch 27; iter: 400; batch classifier loss: 0.303006; batch adversarial loss: 0.633290\n",
      "epoch 28; iter: 0; batch classifier loss: 0.594515; batch adversarial loss: 0.677553\n",
      "epoch 28; iter: 200; batch classifier loss: 0.334338; batch adversarial loss: 0.610496\n",
      "epoch 28; iter: 400; batch classifier loss: 0.290745; batch adversarial loss: 0.640418\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386416; batch adversarial loss: 0.571091\n",
      "epoch 29; iter: 200; batch classifier loss: 0.398437; batch adversarial loss: 0.583671\n",
      "epoch 29; iter: 400; batch classifier loss: 0.348591; batch adversarial loss: 0.589677\n",
      "epoch 30; iter: 0; batch classifier loss: 0.309736; batch adversarial loss: 0.599197\n",
      "epoch 30; iter: 200; batch classifier loss: 0.332727; batch adversarial loss: 0.627270\n",
      "epoch 30; iter: 400; batch classifier loss: 0.435909; batch adversarial loss: 0.712159\n",
      "epoch 31; iter: 0; batch classifier loss: 0.323993; batch adversarial loss: 0.607830\n",
      "epoch 31; iter: 200; batch classifier loss: 0.601138; batch adversarial loss: 0.723322\n",
      "epoch 31; iter: 400; batch classifier loss: 0.454414; batch adversarial loss: 0.708883\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461933; batch adversarial loss: 0.566598\n",
      "epoch 32; iter: 200; batch classifier loss: 0.367832; batch adversarial loss: 0.635447\n",
      "epoch 32; iter: 400; batch classifier loss: 0.488634; batch adversarial loss: 0.644915\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370682; batch adversarial loss: 0.619708\n",
      "epoch 33; iter: 200; batch classifier loss: 0.351232; batch adversarial loss: 0.615725\n",
      "epoch 33; iter: 400; batch classifier loss: 0.649442; batch adversarial loss: 0.581181\n",
      "epoch 34; iter: 0; batch classifier loss: 0.521946; batch adversarial loss: 0.656981\n",
      "epoch 34; iter: 200; batch classifier loss: 0.639227; batch adversarial loss: 0.591073\n",
      "epoch 34; iter: 400; batch classifier loss: 0.381097; batch adversarial loss: 0.642608\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465865; batch adversarial loss: 0.664667\n",
      "epoch 35; iter: 200; batch classifier loss: 0.460833; batch adversarial loss: 0.597022\n",
      "epoch 35; iter: 400; batch classifier loss: 0.409030; batch adversarial loss: 0.578776\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366323; batch adversarial loss: 0.656052\n",
      "epoch 36; iter: 200; batch classifier loss: 0.399386; batch adversarial loss: 0.575275\n",
      "epoch 36; iter: 400; batch classifier loss: 0.618806; batch adversarial loss: 0.617960\n",
      "epoch 37; iter: 0; batch classifier loss: 0.606918; batch adversarial loss: 0.627820\n",
      "epoch 37; iter: 200; batch classifier loss: 0.371365; batch adversarial loss: 0.535275\n",
      "epoch 37; iter: 400; batch classifier loss: 0.412384; batch adversarial loss: 0.619206\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419103; batch adversarial loss: 0.630082\n",
      "epoch 38; iter: 200; batch classifier loss: 0.511540; batch adversarial loss: 0.633109\n",
      "epoch 38; iter: 400; batch classifier loss: 0.785016; batch adversarial loss: 0.622221\n",
      "epoch 39; iter: 0; batch classifier loss: 0.374170; batch adversarial loss: 0.601641\n",
      "epoch 39; iter: 200; batch classifier loss: 0.704611; batch adversarial loss: 0.649433\n",
      "epoch 39; iter: 400; batch classifier loss: 0.441190; batch adversarial loss: 0.548046\n",
      "epoch 40; iter: 0; batch classifier loss: 0.611108; batch adversarial loss: 0.556384\n",
      "epoch 40; iter: 200; batch classifier loss: 0.454300; batch adversarial loss: 0.584444\n",
      "epoch 40; iter: 400; batch classifier loss: 0.463576; batch adversarial loss: 0.681590\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265380; batch adversarial loss: 0.603278\n",
      "epoch 41; iter: 200; batch classifier loss: 0.509681; batch adversarial loss: 0.620613\n",
      "epoch 41; iter: 400; batch classifier loss: 0.555046; batch adversarial loss: 0.651827\n",
      "epoch 42; iter: 0; batch classifier loss: 0.521649; batch adversarial loss: 0.624843\n",
      "epoch 42; iter: 200; batch classifier loss: 0.593234; batch adversarial loss: 0.629488\n",
      "epoch 42; iter: 400; batch classifier loss: 0.488957; batch adversarial loss: 0.649202\n",
      "epoch 43; iter: 0; batch classifier loss: 0.482885; batch adversarial loss: 0.700508\n",
      "epoch 43; iter: 200; batch classifier loss: 0.474278; batch adversarial loss: 0.568422\n",
      "epoch 43; iter: 400; batch classifier loss: 0.697532; batch adversarial loss: 0.653708\n",
      "epoch 44; iter: 0; batch classifier loss: 0.525710; batch adversarial loss: 0.622518\n",
      "epoch 44; iter: 200; batch classifier loss: 0.361031; batch adversarial loss: 0.720841\n",
      "epoch 44; iter: 400; batch classifier loss: 0.413837; batch adversarial loss: 0.658962\n",
      "epoch 45; iter: 0; batch classifier loss: 0.319673; batch adversarial loss: 0.650966\n",
      "epoch 45; iter: 200; batch classifier loss: 0.424443; batch adversarial loss: 0.646746\n",
      "epoch 45; iter: 400; batch classifier loss: 0.582407; batch adversarial loss: 0.617643\n",
      "epoch 46; iter: 0; batch classifier loss: 0.373251; batch adversarial loss: 0.645198\n",
      "epoch 46; iter: 200; batch classifier loss: 0.415218; batch adversarial loss: 0.669799\n",
      "epoch 46; iter: 400; batch classifier loss: 0.555881; batch adversarial loss: 0.709792\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462294; batch adversarial loss: 0.629682\n",
      "epoch 47; iter: 200; batch classifier loss: 0.380741; batch adversarial loss: 0.689803\n",
      "epoch 47; iter: 400; batch classifier loss: 0.552459; batch adversarial loss: 0.680597\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347457; batch adversarial loss: 0.657327\n",
      "epoch 48; iter: 200; batch classifier loss: 0.603149; batch adversarial loss: 0.615629\n",
      "epoch 48; iter: 400; batch classifier loss: 0.278416; batch adversarial loss: 0.645740\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428730; batch adversarial loss: 0.616616\n",
      "epoch 49; iter: 200; batch classifier loss: 0.499792; batch adversarial loss: 0.605891\n",
      "epoch 49; iter: 400; batch classifier loss: 0.470779; batch adversarial loss: 0.605861\n",
      "epoch 0; iter: 0; batch classifier loss: 5.673366; batch adversarial loss: 0.651064\n",
      "epoch 0; iter: 200; batch classifier loss: 14.585642; batch adversarial loss: 0.605035\n",
      "epoch 0; iter: 400; batch classifier loss: 3.457675; batch adversarial loss: 0.696939\n",
      "epoch 1; iter: 0; batch classifier loss: 9.018504; batch adversarial loss: 0.637700\n",
      "epoch 1; iter: 200; batch classifier loss: 7.704619; batch adversarial loss: 0.569955\n",
      "epoch 1; iter: 400; batch classifier loss: 3.244121; batch adversarial loss: 0.671672\n",
      "epoch 2; iter: 0; batch classifier loss: 0.632297; batch adversarial loss: 0.630494\n",
      "epoch 2; iter: 200; batch classifier loss: 1.603966; batch adversarial loss: 0.625214\n",
      "epoch 2; iter: 400; batch classifier loss: 2.170076; batch adversarial loss: 0.666483\n",
      "epoch 3; iter: 0; batch classifier loss: 5.688688; batch adversarial loss: 0.646843\n",
      "epoch 3; iter: 200; batch classifier loss: 3.238769; batch adversarial loss: 0.668059\n",
      "epoch 3; iter: 400; batch classifier loss: 1.271923; batch adversarial loss: 0.616760\n",
      "epoch 4; iter: 0; batch classifier loss: 1.009617; batch adversarial loss: 0.629389\n",
      "epoch 4; iter: 200; batch classifier loss: 0.391917; batch adversarial loss: 0.627203\n",
      "epoch 4; iter: 400; batch classifier loss: 1.498253; batch adversarial loss: 0.591628\n",
      "epoch 5; iter: 0; batch classifier loss: 1.005287; batch adversarial loss: 0.651326\n",
      "epoch 5; iter: 200; batch classifier loss: 0.709353; batch adversarial loss: 0.627632\n",
      "epoch 5; iter: 400; batch classifier loss: 2.182792; batch adversarial loss: 0.571869\n",
      "epoch 6; iter: 0; batch classifier loss: 0.801317; batch adversarial loss: 0.730910\n",
      "epoch 6; iter: 200; batch classifier loss: 0.389611; batch adversarial loss: 0.530548\n",
      "epoch 6; iter: 400; batch classifier loss: 0.506938; batch adversarial loss: 0.574739\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535139; batch adversarial loss: 0.572887\n",
      "epoch 7; iter: 200; batch classifier loss: 0.882835; batch adversarial loss: 0.682728\n",
      "epoch 7; iter: 400; batch classifier loss: 0.958497; batch adversarial loss: 0.550960\n",
      "epoch 8; iter: 0; batch classifier loss: 0.364804; batch adversarial loss: 0.608368\n",
      "epoch 8; iter: 200; batch classifier loss: 0.333087; batch adversarial loss: 0.657988\n",
      "epoch 8; iter: 400; batch classifier loss: 0.331535; batch adversarial loss: 0.658758\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364098; batch adversarial loss: 0.606028\n",
      "epoch 9; iter: 200; batch classifier loss: 0.581277; batch adversarial loss: 0.685536\n",
      "epoch 9; iter: 400; batch classifier loss: 0.364047; batch adversarial loss: 0.584244\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464677; batch adversarial loss: 0.614649\n",
      "epoch 10; iter: 200; batch classifier loss: 0.361224; batch adversarial loss: 0.597126\n",
      "epoch 10; iter: 400; batch classifier loss: 0.406624; batch adversarial loss: 0.648430\n",
      "epoch 11; iter: 0; batch classifier loss: 0.318261; batch adversarial loss: 0.655042\n",
      "epoch 11; iter: 200; batch classifier loss: 0.355759; batch adversarial loss: 0.661886\n",
      "epoch 11; iter: 400; batch classifier loss: 0.332755; batch adversarial loss: 0.609556\n",
      "epoch 12; iter: 0; batch classifier loss: 0.801405; batch adversarial loss: 0.594877\n",
      "epoch 12; iter: 200; batch classifier loss: 0.246474; batch adversarial loss: 0.677828\n",
      "epoch 12; iter: 400; batch classifier loss: 0.314516; batch adversarial loss: 0.656178\n",
      "epoch 13; iter: 0; batch classifier loss: 0.285000; batch adversarial loss: 0.658525\n",
      "epoch 13; iter: 200; batch classifier loss: 0.284038; batch adversarial loss: 0.642969\n",
      "epoch 13; iter: 400; batch classifier loss: 0.387322; batch adversarial loss: 0.653136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368091; batch adversarial loss: 0.721439\n",
      "epoch 14; iter: 200; batch classifier loss: 0.367236; batch adversarial loss: 0.630944\n",
      "epoch 14; iter: 400; batch classifier loss: 0.321696; batch adversarial loss: 0.678220\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376812; batch adversarial loss: 0.631274\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353099; batch adversarial loss: 0.631249\n",
      "epoch 15; iter: 400; batch classifier loss: 0.399243; batch adversarial loss: 0.645179\n",
      "epoch 16; iter: 0; batch classifier loss: 0.501583; batch adversarial loss: 0.590979\n",
      "epoch 16; iter: 200; batch classifier loss: 0.426614; batch adversarial loss: 0.653240\n",
      "epoch 16; iter: 400; batch classifier loss: 0.542466; batch adversarial loss: 0.647384\n",
      "epoch 17; iter: 0; batch classifier loss: 0.421972; batch adversarial loss: 0.558046\n",
      "epoch 17; iter: 200; batch classifier loss: 0.399165; batch adversarial loss: 0.620772\n",
      "epoch 17; iter: 400; batch classifier loss: 0.584129; batch adversarial loss: 0.583051\n",
      "epoch 18; iter: 0; batch classifier loss: 0.233919; batch adversarial loss: 0.629324\n",
      "epoch 18; iter: 200; batch classifier loss: 0.348070; batch adversarial loss: 0.639128\n",
      "epoch 18; iter: 400; batch classifier loss: 0.363425; batch adversarial loss: 0.620672\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457693; batch adversarial loss: 0.607683\n",
      "epoch 19; iter: 200; batch classifier loss: 0.293505; batch adversarial loss: 0.548924\n",
      "epoch 19; iter: 400; batch classifier loss: 0.345180; batch adversarial loss: 0.550170\n",
      "epoch 20; iter: 0; batch classifier loss: 0.333832; batch adversarial loss: 0.712998\n",
      "epoch 20; iter: 200; batch classifier loss: 0.380965; batch adversarial loss: 0.690530\n",
      "epoch 20; iter: 400; batch classifier loss: 0.345721; batch adversarial loss: 0.648501\n",
      "epoch 21; iter: 0; batch classifier loss: 0.469706; batch adversarial loss: 0.670109\n",
      "epoch 21; iter: 200; batch classifier loss: 0.362251; batch adversarial loss: 0.545492\n",
      "epoch 21; iter: 400; batch classifier loss: 0.514020; batch adversarial loss: 0.699437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465799; batch adversarial loss: 0.666716\n",
      "epoch 22; iter: 200; batch classifier loss: 0.365689; batch adversarial loss: 0.680851\n",
      "epoch 22; iter: 400; batch classifier loss: 0.362225; batch adversarial loss: 0.564004\n",
      "epoch 23; iter: 0; batch classifier loss: 0.571203; batch adversarial loss: 0.591913\n",
      "epoch 23; iter: 200; batch classifier loss: 0.462588; batch adversarial loss: 0.638159\n",
      "epoch 23; iter: 400; batch classifier loss: 0.283240; batch adversarial loss: 0.610429\n",
      "epoch 24; iter: 0; batch classifier loss: 0.269504; batch adversarial loss: 0.599807\n",
      "epoch 24; iter: 200; batch classifier loss: 0.292339; batch adversarial loss: 0.674487\n",
      "epoch 24; iter: 400; batch classifier loss: 0.337782; batch adversarial loss: 0.685240\n",
      "epoch 25; iter: 0; batch classifier loss: 0.595359; batch adversarial loss: 0.595971\n",
      "epoch 25; iter: 200; batch classifier loss: 0.293263; batch adversarial loss: 0.657348\n",
      "epoch 25; iter: 400; batch classifier loss: 0.680493; batch adversarial loss: 0.608866\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438951; batch adversarial loss: 0.546155\n",
      "epoch 26; iter: 200; batch classifier loss: 0.289288; batch adversarial loss: 0.694274\n",
      "epoch 26; iter: 400; batch classifier loss: 0.419491; batch adversarial loss: 0.656008\n",
      "epoch 27; iter: 0; batch classifier loss: 0.491520; batch adversarial loss: 0.597314\n",
      "epoch 27; iter: 200; batch classifier loss: 0.410898; batch adversarial loss: 0.627582\n",
      "epoch 27; iter: 400; batch classifier loss: 0.293552; batch adversarial loss: 0.553297\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342833; batch adversarial loss: 0.680928\n",
      "epoch 28; iter: 200; batch classifier loss: 0.357708; batch adversarial loss: 0.640904\n",
      "epoch 28; iter: 400; batch classifier loss: 0.445504; batch adversarial loss: 0.623667\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462361; batch adversarial loss: 0.646544\n",
      "epoch 29; iter: 200; batch classifier loss: 0.474998; batch adversarial loss: 0.564010\n",
      "epoch 29; iter: 400; batch classifier loss: 0.658343; batch adversarial loss: 0.597778\n",
      "epoch 30; iter: 0; batch classifier loss: 0.530471; batch adversarial loss: 0.572676\n",
      "epoch 30; iter: 200; batch classifier loss: 0.365192; batch adversarial loss: 0.657699\n",
      "epoch 30; iter: 400; batch classifier loss: 0.374289; batch adversarial loss: 0.653216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402962; batch adversarial loss: 0.658038\n",
      "epoch 31; iter: 200; batch classifier loss: 0.488501; batch adversarial loss: 0.584292\n",
      "epoch 31; iter: 400; batch classifier loss: 0.576366; batch adversarial loss: 0.614085\n",
      "epoch 32; iter: 0; batch classifier loss: 0.298671; batch adversarial loss: 0.711126\n",
      "epoch 32; iter: 200; batch classifier loss: 0.421931; batch adversarial loss: 0.661316\n",
      "epoch 32; iter: 400; batch classifier loss: 0.404529; batch adversarial loss: 0.625387\n",
      "epoch 33; iter: 0; batch classifier loss: 0.305408; batch adversarial loss: 0.687702\n",
      "epoch 33; iter: 200; batch classifier loss: 0.460756; batch adversarial loss: 0.620758\n",
      "epoch 33; iter: 400; batch classifier loss: 0.524655; batch adversarial loss: 0.747282\n",
      "epoch 34; iter: 0; batch classifier loss: 0.740211; batch adversarial loss: 0.630215\n",
      "epoch 34; iter: 200; batch classifier loss: 0.341362; batch adversarial loss: 0.578887\n",
      "epoch 34; iter: 400; batch classifier loss: 0.330022; batch adversarial loss: 0.665458\n",
      "epoch 35; iter: 0; batch classifier loss: 0.454139; batch adversarial loss: 0.644697\n",
      "epoch 35; iter: 200; batch classifier loss: 0.405285; batch adversarial loss: 0.588489\n",
      "epoch 35; iter: 400; batch classifier loss: 0.593540; batch adversarial loss: 0.664597\n",
      "epoch 36; iter: 0; batch classifier loss: 0.329654; batch adversarial loss: 0.624250\n",
      "epoch 36; iter: 200; batch classifier loss: 0.561130; batch adversarial loss: 0.618231\n",
      "epoch 36; iter: 400; batch classifier loss: 0.404407; batch adversarial loss: 0.655440\n",
      "epoch 37; iter: 0; batch classifier loss: 0.194193; batch adversarial loss: 0.623698\n",
      "epoch 37; iter: 200; batch classifier loss: 0.527250; batch adversarial loss: 0.654763\n",
      "epoch 37; iter: 400; batch classifier loss: 0.372147; batch adversarial loss: 0.686390\n",
      "epoch 38; iter: 0; batch classifier loss: 0.285185; batch adversarial loss: 0.682380\n",
      "epoch 38; iter: 200; batch classifier loss: 0.498704; batch adversarial loss: 0.639609\n",
      "epoch 38; iter: 400; batch classifier loss: 0.493503; batch adversarial loss: 0.662114\n",
      "epoch 39; iter: 0; batch classifier loss: 0.679050; batch adversarial loss: 0.606379\n",
      "epoch 39; iter: 200; batch classifier loss: 0.557617; batch adversarial loss: 0.658220\n",
      "epoch 39; iter: 400; batch classifier loss: 0.595408; batch adversarial loss: 0.657082\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446764; batch adversarial loss: 0.559060\n",
      "epoch 40; iter: 200; batch classifier loss: 0.478740; batch adversarial loss: 0.622319\n",
      "epoch 40; iter: 400; batch classifier loss: 0.398083; batch adversarial loss: 0.585296\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425138; batch adversarial loss: 0.608026\n",
      "epoch 41; iter: 200; batch classifier loss: 0.337239; batch adversarial loss: 0.643354\n",
      "epoch 41; iter: 400; batch classifier loss: 0.456014; batch adversarial loss: 0.604136\n",
      "epoch 42; iter: 0; batch classifier loss: 0.352552; batch adversarial loss: 0.680238\n",
      "epoch 42; iter: 200; batch classifier loss: 0.357994; batch adversarial loss: 0.603560\n",
      "epoch 42; iter: 400; batch classifier loss: 0.630937; batch adversarial loss: 0.642782\n",
      "epoch 43; iter: 0; batch classifier loss: 0.615974; batch adversarial loss: 0.679660\n",
      "epoch 43; iter: 200; batch classifier loss: 0.371753; batch adversarial loss: 0.625217\n",
      "epoch 43; iter: 400; batch classifier loss: 0.406274; batch adversarial loss: 0.674083\n",
      "epoch 44; iter: 0; batch classifier loss: 0.407533; batch adversarial loss: 0.550163\n",
      "epoch 44; iter: 200; batch classifier loss: 0.522781; batch adversarial loss: 0.560330\n",
      "epoch 44; iter: 400; batch classifier loss: 0.552632; batch adversarial loss: 0.660872\n",
      "epoch 45; iter: 0; batch classifier loss: 0.355358; batch adversarial loss: 0.705270\n",
      "epoch 45; iter: 200; batch classifier loss: 0.594310; batch adversarial loss: 0.623133\n",
      "epoch 45; iter: 400; batch classifier loss: 0.492170; batch adversarial loss: 0.621080\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377746; batch adversarial loss: 0.715417\n",
      "epoch 46; iter: 200; batch classifier loss: 0.386520; batch adversarial loss: 0.591428\n",
      "epoch 46; iter: 400; batch classifier loss: 0.345274; batch adversarial loss: 0.603507\n",
      "epoch 47; iter: 0; batch classifier loss: 0.287956; batch adversarial loss: 0.635589\n",
      "epoch 47; iter: 200; batch classifier loss: 0.427269; batch adversarial loss: 0.605254\n",
      "epoch 47; iter: 400; batch classifier loss: 0.569565; batch adversarial loss: 0.612371\n",
      "epoch 48; iter: 0; batch classifier loss: 0.523117; batch adversarial loss: 0.554181\n",
      "epoch 48; iter: 200; batch classifier loss: 0.564420; batch adversarial loss: 0.713449\n",
      "epoch 48; iter: 400; batch classifier loss: 0.245873; batch adversarial loss: 0.623091\n",
      "epoch 49; iter: 0; batch classifier loss: 0.395231; batch adversarial loss: 0.611019\n",
      "epoch 49; iter: 200; batch classifier loss: 0.507214; batch adversarial loss: 0.636247\n",
      "epoch 49; iter: 400; batch classifier loss: 0.605426; batch adversarial loss: 0.684499\n",
      "epoch 0; iter: 0; batch classifier loss: 2.599768; batch adversarial loss: 0.687840\n",
      "epoch 0; iter: 200; batch classifier loss: 3.433020; batch adversarial loss: 0.685605\n",
      "epoch 0; iter: 400; batch classifier loss: 6.934089; batch adversarial loss: 0.621114\n",
      "epoch 1; iter: 0; batch classifier loss: 4.870952; batch adversarial loss: 0.640702\n",
      "epoch 1; iter: 200; batch classifier loss: 0.817518; batch adversarial loss: 0.604234\n",
      "epoch 1; iter: 400; batch classifier loss: 5.562351; batch adversarial loss: 0.702572\n",
      "epoch 2; iter: 0; batch classifier loss: 2.432503; batch adversarial loss: 0.584553\n",
      "epoch 2; iter: 200; batch classifier loss: 2.143011; batch adversarial loss: 0.736397\n",
      "epoch 2; iter: 400; batch classifier loss: 1.762256; batch adversarial loss: 0.595036\n",
      "epoch 3; iter: 0; batch classifier loss: 0.697040; batch adversarial loss: 0.619879\n",
      "epoch 3; iter: 200; batch classifier loss: 5.968219; batch adversarial loss: 0.639977\n",
      "epoch 3; iter: 400; batch classifier loss: 0.355043; batch adversarial loss: 0.588672\n",
      "epoch 4; iter: 0; batch classifier loss: 0.433699; batch adversarial loss: 0.561537\n",
      "epoch 4; iter: 200; batch classifier loss: 0.471734; batch adversarial loss: 0.650892\n",
      "epoch 4; iter: 400; batch classifier loss: 0.999682; batch adversarial loss: 0.615829\n",
      "epoch 5; iter: 0; batch classifier loss: 0.454412; batch adversarial loss: 0.590385\n",
      "epoch 5; iter: 200; batch classifier loss: 0.491187; batch adversarial loss: 0.616090\n",
      "epoch 5; iter: 400; batch classifier loss: 0.320515; batch adversarial loss: 0.664620\n",
      "epoch 6; iter: 0; batch classifier loss: 0.335492; batch adversarial loss: 0.605116\n",
      "epoch 6; iter: 200; batch classifier loss: 0.591371; batch adversarial loss: 0.575503\n",
      "epoch 6; iter: 400; batch classifier loss: 0.434245; batch adversarial loss: 0.547258\n",
      "epoch 7; iter: 0; batch classifier loss: 0.409632; batch adversarial loss: 0.644116\n",
      "epoch 7; iter: 200; batch classifier loss: 0.341269; batch adversarial loss: 0.662303\n",
      "epoch 7; iter: 400; batch classifier loss: 0.574113; batch adversarial loss: 0.639368\n",
      "epoch 8; iter: 0; batch classifier loss: 0.395158; batch adversarial loss: 0.649466\n",
      "epoch 8; iter: 200; batch classifier loss: 0.453380; batch adversarial loss: 0.608415\n",
      "epoch 8; iter: 400; batch classifier loss: 0.339750; batch adversarial loss: 0.618721\n",
      "epoch 9; iter: 0; batch classifier loss: 0.697369; batch adversarial loss: 0.618708\n",
      "epoch 9; iter: 200; batch classifier loss: 0.445128; batch adversarial loss: 0.548731\n",
      "epoch 9; iter: 400; batch classifier loss: 0.353631; batch adversarial loss: 0.641849\n",
      "epoch 10; iter: 0; batch classifier loss: 0.355067; batch adversarial loss: 0.676376\n",
      "epoch 10; iter: 200; batch classifier loss: 0.430383; batch adversarial loss: 0.536639\n",
      "epoch 10; iter: 400; batch classifier loss: 0.370546; batch adversarial loss: 0.620837\n",
      "epoch 11; iter: 0; batch classifier loss: 0.324320; batch adversarial loss: 0.578974\n",
      "epoch 11; iter: 200; batch classifier loss: 0.408299; batch adversarial loss: 0.570494\n",
      "epoch 11; iter: 400; batch classifier loss: 0.290490; batch adversarial loss: 0.683126\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396516; batch adversarial loss: 0.552363\n",
      "epoch 12; iter: 200; batch classifier loss: 0.455121; batch adversarial loss: 0.610936\n",
      "epoch 12; iter: 400; batch classifier loss: 0.333443; batch adversarial loss: 0.614363\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384368; batch adversarial loss: 0.611308\n",
      "epoch 13; iter: 200; batch classifier loss: 0.247768; batch adversarial loss: 0.710377\n",
      "epoch 13; iter: 400; batch classifier loss: 0.388292; batch adversarial loss: 0.624473\n",
      "epoch 14; iter: 0; batch classifier loss: 0.463831; batch adversarial loss: 0.623293\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388987; batch adversarial loss: 0.622957\n",
      "epoch 14; iter: 400; batch classifier loss: 0.385615; batch adversarial loss: 0.673454\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409770; batch adversarial loss: 0.632528\n",
      "epoch 15; iter: 200; batch classifier loss: 0.453892; batch adversarial loss: 0.645680\n",
      "epoch 15; iter: 400; batch classifier loss: 0.354281; batch adversarial loss: 0.584605\n",
      "epoch 16; iter: 0; batch classifier loss: 0.467105; batch adversarial loss: 0.606719\n",
      "epoch 16; iter: 200; batch classifier loss: 0.404906; batch adversarial loss: 0.686329\n",
      "epoch 16; iter: 400; batch classifier loss: 0.517870; batch adversarial loss: 0.584968\n",
      "epoch 17; iter: 0; batch classifier loss: 0.322370; batch adversarial loss: 0.561691\n",
      "epoch 17; iter: 200; batch classifier loss: 0.545900; batch adversarial loss: 0.560423\n",
      "epoch 17; iter: 400; batch classifier loss: 0.413597; batch adversarial loss: 0.618922\n",
      "epoch 18; iter: 0; batch classifier loss: 0.324749; batch adversarial loss: 0.645459\n",
      "epoch 18; iter: 200; batch classifier loss: 0.373927; batch adversarial loss: 0.603197\n",
      "epoch 18; iter: 400; batch classifier loss: 0.320001; batch adversarial loss: 0.669525\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471793; batch adversarial loss: 0.534640\n",
      "epoch 19; iter: 200; batch classifier loss: 0.347836; batch adversarial loss: 0.649832\n",
      "epoch 19; iter: 400; batch classifier loss: 0.384472; batch adversarial loss: 0.636670\n",
      "epoch 20; iter: 0; batch classifier loss: 0.312357; batch adversarial loss: 0.573117\n",
      "epoch 20; iter: 200; batch classifier loss: 0.461764; batch adversarial loss: 0.725468\n",
      "epoch 20; iter: 400; batch classifier loss: 0.353851; batch adversarial loss: 0.578045\n",
      "epoch 21; iter: 0; batch classifier loss: 0.266785; batch adversarial loss: 0.708155\n",
      "epoch 21; iter: 200; batch classifier loss: 0.269565; batch adversarial loss: 0.684501\n",
      "epoch 21; iter: 400; batch classifier loss: 0.382037; batch adversarial loss: 0.605968\n",
      "epoch 22; iter: 0; batch classifier loss: 0.589806; batch adversarial loss: 0.594537\n",
      "epoch 22; iter: 200; batch classifier loss: 0.384756; batch adversarial loss: 0.607203\n",
      "epoch 22; iter: 400; batch classifier loss: 0.306805; batch adversarial loss: 0.639447\n",
      "epoch 23; iter: 0; batch classifier loss: 0.572895; batch adversarial loss: 0.634439\n",
      "epoch 23; iter: 200; batch classifier loss: 0.610717; batch adversarial loss: 0.652899\n",
      "epoch 23; iter: 400; batch classifier loss: 0.305383; batch adversarial loss: 0.646679\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360180; batch adversarial loss: 0.694184\n",
      "epoch 24; iter: 200; batch classifier loss: 0.372274; batch adversarial loss: 0.650299\n",
      "epoch 24; iter: 400; batch classifier loss: 0.489969; batch adversarial loss: 0.691455\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326086; batch adversarial loss: 0.702222\n",
      "epoch 25; iter: 200; batch classifier loss: 0.435594; batch adversarial loss: 0.661743\n",
      "epoch 25; iter: 400; batch classifier loss: 0.416069; batch adversarial loss: 0.589931\n",
      "epoch 26; iter: 0; batch classifier loss: 0.482982; batch adversarial loss: 0.623230\n",
      "epoch 26; iter: 200; batch classifier loss: 0.403377; batch adversarial loss: 0.651598\n",
      "epoch 26; iter: 400; batch classifier loss: 0.547992; batch adversarial loss: 0.652413\n",
      "epoch 27; iter: 0; batch classifier loss: 0.404794; batch adversarial loss: 0.626335\n",
      "epoch 27; iter: 200; batch classifier loss: 0.446621; batch adversarial loss: 0.538184\n",
      "epoch 27; iter: 400; batch classifier loss: 0.584469; batch adversarial loss: 0.668549\n",
      "epoch 28; iter: 0; batch classifier loss: 0.567055; batch adversarial loss: 0.566495\n",
      "epoch 28; iter: 200; batch classifier loss: 0.392548; batch adversarial loss: 0.637042\n",
      "epoch 28; iter: 400; batch classifier loss: 0.361102; batch adversarial loss: 0.587430\n",
      "epoch 29; iter: 0; batch classifier loss: 0.302793; batch adversarial loss: 0.628279\n",
      "epoch 29; iter: 200; batch classifier loss: 0.397104; batch adversarial loss: 0.618204\n",
      "epoch 29; iter: 400; batch classifier loss: 0.340320; batch adversarial loss: 0.628010\n",
      "epoch 30; iter: 0; batch classifier loss: 0.356204; batch adversarial loss: 0.578616\n",
      "epoch 30; iter: 200; batch classifier loss: 0.788460; batch adversarial loss: 0.721253\n",
      "epoch 30; iter: 400; batch classifier loss: 0.378769; batch adversarial loss: 0.675320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.536358; batch adversarial loss: 0.652334\n",
      "epoch 31; iter: 200; batch classifier loss: 0.705477; batch adversarial loss: 0.624033\n",
      "epoch 31; iter: 400; batch classifier loss: 0.509787; batch adversarial loss: 0.649726\n",
      "epoch 32; iter: 0; batch classifier loss: 0.382122; batch adversarial loss: 0.595050\n",
      "epoch 32; iter: 200; batch classifier loss: 0.594746; batch adversarial loss: 0.543228\n",
      "epoch 32; iter: 400; batch classifier loss: 0.390520; batch adversarial loss: 0.654638\n",
      "epoch 33; iter: 0; batch classifier loss: 0.391721; batch adversarial loss: 0.682446\n",
      "epoch 33; iter: 200; batch classifier loss: 0.386644; batch adversarial loss: 0.633405\n",
      "epoch 33; iter: 400; batch classifier loss: 0.377617; batch adversarial loss: 0.578240\n",
      "epoch 34; iter: 0; batch classifier loss: 0.515526; batch adversarial loss: 0.603078\n",
      "epoch 34; iter: 200; batch classifier loss: 0.271230; batch adversarial loss: 0.702417\n",
      "epoch 34; iter: 400; batch classifier loss: 0.291612; batch adversarial loss: 0.610006\n",
      "epoch 35; iter: 0; batch classifier loss: 0.556530; batch adversarial loss: 0.627477\n",
      "epoch 35; iter: 200; batch classifier loss: 0.353163; batch adversarial loss: 0.638267\n",
      "epoch 35; iter: 400; batch classifier loss: 0.801461; batch adversarial loss: 0.578710\n",
      "epoch 36; iter: 0; batch classifier loss: 0.629099; batch adversarial loss: 0.630802\n",
      "epoch 36; iter: 200; batch classifier loss: 0.488023; batch adversarial loss: 0.647210\n",
      "epoch 36; iter: 400; batch classifier loss: 0.524219; batch adversarial loss: 0.602454\n",
      "epoch 37; iter: 0; batch classifier loss: 0.364401; batch adversarial loss: 0.584706\n",
      "epoch 37; iter: 200; batch classifier loss: 0.361011; batch adversarial loss: 0.675004\n",
      "epoch 37; iter: 400; batch classifier loss: 0.703971; batch adversarial loss: 0.621990\n",
      "epoch 38; iter: 0; batch classifier loss: 0.606700; batch adversarial loss: 0.588003\n",
      "epoch 38; iter: 200; batch classifier loss: 0.532310; batch adversarial loss: 0.559019\n",
      "epoch 38; iter: 400; batch classifier loss: 0.302837; batch adversarial loss: 0.652096\n",
      "epoch 39; iter: 0; batch classifier loss: 0.336116; batch adversarial loss: 0.652270\n",
      "epoch 39; iter: 200; batch classifier loss: 0.581582; batch adversarial loss: 0.617872\n",
      "epoch 39; iter: 400; batch classifier loss: 0.484306; batch adversarial loss: 0.643595\n",
      "epoch 40; iter: 0; batch classifier loss: 0.464764; batch adversarial loss: 0.709141\n",
      "epoch 40; iter: 200; batch classifier loss: 0.432390; batch adversarial loss: 0.607323\n",
      "epoch 40; iter: 400; batch classifier loss: 0.612097; batch adversarial loss: 0.658713\n",
      "epoch 41; iter: 0; batch classifier loss: 0.520012; batch adversarial loss: 0.626565\n",
      "epoch 41; iter: 200; batch classifier loss: 0.233462; batch adversarial loss: 0.651942\n",
      "epoch 41; iter: 400; batch classifier loss: 0.246956; batch adversarial loss: 0.662462\n",
      "epoch 42; iter: 0; batch classifier loss: 0.517099; batch adversarial loss: 0.676293\n",
      "epoch 42; iter: 200; batch classifier loss: 0.278741; batch adversarial loss: 0.623613\n",
      "epoch 42; iter: 400; batch classifier loss: 0.503078; batch adversarial loss: 0.616284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458388; batch adversarial loss: 0.560777\n",
      "epoch 43; iter: 200; batch classifier loss: 0.434510; batch adversarial loss: 0.629705\n",
      "epoch 43; iter: 400; batch classifier loss: 0.729724; batch adversarial loss: 0.676471\n",
      "epoch 44; iter: 0; batch classifier loss: 0.808907; batch adversarial loss: 0.570612\n",
      "epoch 44; iter: 200; batch classifier loss: 0.483200; batch adversarial loss: 0.524569\n",
      "epoch 44; iter: 400; batch classifier loss: 0.390990; batch adversarial loss: 0.656343\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402534; batch adversarial loss: 0.556462\n",
      "epoch 45; iter: 200; batch classifier loss: 0.924498; batch adversarial loss: 0.590217\n",
      "epoch 45; iter: 400; batch classifier loss: 0.474688; batch adversarial loss: 0.685640\n",
      "epoch 46; iter: 0; batch classifier loss: 0.592608; batch adversarial loss: 0.601422\n",
      "epoch 46; iter: 200; batch classifier loss: 0.912522; batch adversarial loss: 0.624195\n",
      "epoch 46; iter: 400; batch classifier loss: 0.422291; batch adversarial loss: 0.614683\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475318; batch adversarial loss: 0.656460\n",
      "epoch 47; iter: 200; batch classifier loss: 0.397427; batch adversarial loss: 0.685646\n",
      "epoch 47; iter: 400; batch classifier loss: 0.845539; batch adversarial loss: 0.605289\n",
      "epoch 48; iter: 0; batch classifier loss: 0.447045; batch adversarial loss: 0.629483\n",
      "epoch 48; iter: 200; batch classifier loss: 0.655452; batch adversarial loss: 0.617534\n",
      "epoch 48; iter: 400; batch classifier loss: 0.408974; batch adversarial loss: 0.631587\n",
      "epoch 49; iter: 0; batch classifier loss: 1.673403; batch adversarial loss: 0.705790\n",
      "epoch 49; iter: 200; batch classifier loss: 0.343362; batch adversarial loss: 0.591036\n",
      "epoch 49; iter: 400; batch classifier loss: 0.580519; batch adversarial loss: 0.551436\n",
      "epoch 0; iter: 0; batch classifier loss: 10.359209; batch adversarial loss: 0.745312\n",
      "epoch 0; iter: 200; batch classifier loss: 0.850842; batch adversarial loss: 0.670173\n",
      "epoch 0; iter: 400; batch classifier loss: 13.411996; batch adversarial loss: 0.671501\n",
      "epoch 1; iter: 0; batch classifier loss: 5.819152; batch adversarial loss: 0.654032\n",
      "epoch 1; iter: 200; batch classifier loss: 10.383595; batch adversarial loss: 0.663209\n",
      "epoch 1; iter: 400; batch classifier loss: 11.456005; batch adversarial loss: 0.586933\n",
      "epoch 2; iter: 0; batch classifier loss: 12.893878; batch adversarial loss: 0.658198\n",
      "epoch 2; iter: 200; batch classifier loss: 1.804400; batch adversarial loss: 0.652422\n",
      "epoch 2; iter: 400; batch classifier loss: 4.633480; batch adversarial loss: 0.599508\n",
      "epoch 3; iter: 0; batch classifier loss: 3.680524; batch adversarial loss: 0.611196\n",
      "epoch 3; iter: 200; batch classifier loss: 2.319885; batch adversarial loss: 0.667571\n",
      "epoch 3; iter: 400; batch classifier loss: 3.252637; batch adversarial loss: 0.701478\n",
      "epoch 4; iter: 0; batch classifier loss: 1.677006; batch adversarial loss: 0.625033\n",
      "epoch 4; iter: 200; batch classifier loss: 1.675971; batch adversarial loss: 0.730016\n",
      "epoch 4; iter: 400; batch classifier loss: 0.425189; batch adversarial loss: 0.632713\n",
      "epoch 5; iter: 0; batch classifier loss: 1.825363; batch adversarial loss: 0.706298\n",
      "epoch 5; iter: 200; batch classifier loss: 1.128028; batch adversarial loss: 0.666402\n",
      "epoch 5; iter: 400; batch classifier loss: 0.594474; batch adversarial loss: 0.660346\n",
      "epoch 6; iter: 0; batch classifier loss: 1.057482; batch adversarial loss: 0.695009\n",
      "epoch 6; iter: 200; batch classifier loss: 0.826485; batch adversarial loss: 0.620111\n",
      "epoch 6; iter: 400; batch classifier loss: 0.521492; batch adversarial loss: 0.596178\n",
      "epoch 7; iter: 0; batch classifier loss: 0.644182; batch adversarial loss: 0.572095\n",
      "epoch 7; iter: 200; batch classifier loss: 0.397349; batch adversarial loss: 0.692224\n",
      "epoch 7; iter: 400; batch classifier loss: 0.985687; batch adversarial loss: 0.589451\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512559; batch adversarial loss: 0.648692\n",
      "epoch 8; iter: 200; batch classifier loss: 0.572545; batch adversarial loss: 0.675092\n",
      "epoch 8; iter: 400; batch classifier loss: 0.449431; batch adversarial loss: 0.608714\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577872; batch adversarial loss: 0.593611\n",
      "epoch 9; iter: 200; batch classifier loss: 0.606652; batch adversarial loss: 0.654043\n",
      "epoch 9; iter: 400; batch classifier loss: 0.362203; batch adversarial loss: 0.609081\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335978; batch adversarial loss: 0.641743\n",
      "epoch 10; iter: 200; batch classifier loss: 0.259007; batch adversarial loss: 0.699880\n",
      "epoch 10; iter: 400; batch classifier loss: 0.388459; batch adversarial loss: 0.618088\n",
      "epoch 11; iter: 0; batch classifier loss: 0.292827; batch adversarial loss: 0.572894\n",
      "epoch 11; iter: 200; batch classifier loss: 0.318087; batch adversarial loss: 0.572122\n",
      "epoch 11; iter: 400; batch classifier loss: 0.322832; batch adversarial loss: 0.616701\n",
      "epoch 12; iter: 0; batch classifier loss: 0.240360; batch adversarial loss: 0.713256\n",
      "epoch 12; iter: 200; batch classifier loss: 0.342373; batch adversarial loss: 0.651101\n",
      "epoch 12; iter: 400; batch classifier loss: 0.366378; batch adversarial loss: 0.697338\n",
      "epoch 13; iter: 0; batch classifier loss: 0.385604; batch adversarial loss: 0.613970\n",
      "epoch 13; iter: 200; batch classifier loss: 0.455449; batch adversarial loss: 0.634395\n",
      "epoch 13; iter: 400; batch classifier loss: 0.377997; batch adversarial loss: 0.624007\n",
      "epoch 14; iter: 0; batch classifier loss: 0.328086; batch adversarial loss: 0.666050\n",
      "epoch 14; iter: 200; batch classifier loss: 0.369007; batch adversarial loss: 0.637961\n",
      "epoch 14; iter: 400; batch classifier loss: 0.394334; batch adversarial loss: 0.667245\n",
      "epoch 15; iter: 0; batch classifier loss: 0.281036; batch adversarial loss: 0.616916\n",
      "epoch 15; iter: 200; batch classifier loss: 0.485939; batch adversarial loss: 0.576267\n",
      "epoch 15; iter: 400; batch classifier loss: 0.378320; batch adversarial loss: 0.613816\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335849; batch adversarial loss: 0.700165\n",
      "epoch 16; iter: 200; batch classifier loss: 0.330479; batch adversarial loss: 0.680076\n",
      "epoch 16; iter: 400; batch classifier loss: 0.471830; batch adversarial loss: 0.620403\n",
      "epoch 17; iter: 0; batch classifier loss: 0.588037; batch adversarial loss: 0.588265\n",
      "epoch 17; iter: 200; batch classifier loss: 0.337856; batch adversarial loss: 0.735322\n",
      "epoch 17; iter: 400; batch classifier loss: 0.400203; batch adversarial loss: 0.620102\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505853; batch adversarial loss: 0.562556\n",
      "epoch 18; iter: 200; batch classifier loss: 0.466020; batch adversarial loss: 0.615611\n",
      "epoch 18; iter: 400; batch classifier loss: 0.306716; batch adversarial loss: 0.654275\n",
      "epoch 19; iter: 0; batch classifier loss: 0.985740; batch adversarial loss: 0.576906\n",
      "epoch 19; iter: 200; batch classifier loss: 0.260310; batch adversarial loss: 0.692174\n",
      "epoch 19; iter: 400; batch classifier loss: 0.336102; batch adversarial loss: 0.552220\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385536; batch adversarial loss: 0.747947\n",
      "epoch 20; iter: 200; batch classifier loss: 0.375917; batch adversarial loss: 0.584318\n",
      "epoch 20; iter: 400; batch classifier loss: 0.249980; batch adversarial loss: 0.694542\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482845; batch adversarial loss: 0.568063\n",
      "epoch 21; iter: 200; batch classifier loss: 0.385990; batch adversarial loss: 0.632302\n",
      "epoch 21; iter: 400; batch classifier loss: 0.319662; batch adversarial loss: 0.594021\n",
      "epoch 22; iter: 0; batch classifier loss: 0.503906; batch adversarial loss: 0.618352\n",
      "epoch 22; iter: 200; batch classifier loss: 0.498455; batch adversarial loss: 0.619567\n",
      "epoch 22; iter: 400; batch classifier loss: 0.305012; batch adversarial loss: 0.626306\n",
      "epoch 23; iter: 0; batch classifier loss: 0.384890; batch adversarial loss: 0.618632\n",
      "epoch 23; iter: 200; batch classifier loss: 0.410828; batch adversarial loss: 0.644845\n",
      "epoch 23; iter: 400; batch classifier loss: 0.321767; batch adversarial loss: 0.684311\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362071; batch adversarial loss: 0.585930\n",
      "epoch 24; iter: 200; batch classifier loss: 0.489312; batch adversarial loss: 0.595525\n",
      "epoch 24; iter: 400; batch classifier loss: 0.548801; batch adversarial loss: 0.634791\n",
      "epoch 25; iter: 0; batch classifier loss: 0.426664; batch adversarial loss: 0.614454\n",
      "epoch 25; iter: 200; batch classifier loss: 0.292721; batch adversarial loss: 0.636834\n",
      "epoch 25; iter: 400; batch classifier loss: 0.359345; batch adversarial loss: 0.565299\n",
      "epoch 26; iter: 0; batch classifier loss: 0.392332; batch adversarial loss: 0.607834\n",
      "epoch 26; iter: 200; batch classifier loss: 0.383361; batch adversarial loss: 0.630753\n",
      "epoch 26; iter: 400; batch classifier loss: 0.324380; batch adversarial loss: 0.711016\n",
      "epoch 27; iter: 0; batch classifier loss: 0.519701; batch adversarial loss: 0.587029\n",
      "epoch 27; iter: 200; batch classifier loss: 0.539243; batch adversarial loss: 0.607336\n",
      "epoch 27; iter: 400; batch classifier loss: 0.489507; batch adversarial loss: 0.643552\n",
      "epoch 28; iter: 0; batch classifier loss: 0.597873; batch adversarial loss: 0.612669\n",
      "epoch 28; iter: 200; batch classifier loss: 0.652384; batch adversarial loss: 0.637061\n",
      "epoch 28; iter: 400; batch classifier loss: 0.551854; batch adversarial loss: 0.558113\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486687; batch adversarial loss: 0.572513\n",
      "epoch 29; iter: 200; batch classifier loss: 0.296199; batch adversarial loss: 0.608624\n",
      "epoch 29; iter: 400; batch classifier loss: 0.727046; batch adversarial loss: 0.608023\n",
      "epoch 30; iter: 0; batch classifier loss: 0.487773; batch adversarial loss: 0.725478\n",
      "epoch 30; iter: 200; batch classifier loss: 0.582726; batch adversarial loss: 0.599557\n",
      "epoch 30; iter: 400; batch classifier loss: 0.414817; batch adversarial loss: 0.572827\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605670; batch adversarial loss: 0.632800\n",
      "epoch 31; iter: 200; batch classifier loss: 0.723382; batch adversarial loss: 0.597527\n",
      "epoch 31; iter: 400; batch classifier loss: 0.574684; batch adversarial loss: 0.563239\n",
      "epoch 32; iter: 0; batch classifier loss: 0.388359; batch adversarial loss: 0.617412\n",
      "epoch 32; iter: 200; batch classifier loss: 0.427066; batch adversarial loss: 0.595950\n",
      "epoch 32; iter: 400; batch classifier loss: 0.452997; batch adversarial loss: 0.597393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.637955; batch adversarial loss: 0.550086\n",
      "epoch 33; iter: 200; batch classifier loss: 0.841271; batch adversarial loss: 0.554035\n",
      "epoch 33; iter: 400; batch classifier loss: 0.620745; batch adversarial loss: 0.597880\n",
      "epoch 34; iter: 0; batch classifier loss: 0.349835; batch adversarial loss: 0.586546\n",
      "epoch 34; iter: 200; batch classifier loss: 0.383266; batch adversarial loss: 0.595692\n",
      "epoch 34; iter: 400; batch classifier loss: 0.342668; batch adversarial loss: 0.633534\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419712; batch adversarial loss: 0.653317\n",
      "epoch 35; iter: 200; batch classifier loss: 0.488913; batch adversarial loss: 0.681064\n",
      "epoch 35; iter: 400; batch classifier loss: 0.348674; batch adversarial loss: 0.528292\n",
      "epoch 36; iter: 0; batch classifier loss: 0.607485; batch adversarial loss: 0.514859\n",
      "epoch 36; iter: 200; batch classifier loss: 0.539600; batch adversarial loss: 0.618948\n",
      "epoch 36; iter: 400; batch classifier loss: 0.565274; batch adversarial loss: 0.626290\n",
      "epoch 37; iter: 0; batch classifier loss: 0.783764; batch adversarial loss: 0.599683\n",
      "epoch 37; iter: 200; batch classifier loss: 0.284241; batch adversarial loss: 0.619784\n",
      "epoch 37; iter: 400; batch classifier loss: 0.504424; batch adversarial loss: 0.598193\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459679; batch adversarial loss: 0.664552\n",
      "epoch 38; iter: 200; batch classifier loss: 0.385252; batch adversarial loss: 0.619713\n",
      "epoch 38; iter: 400; batch classifier loss: 0.534437; batch adversarial loss: 0.602493\n",
      "epoch 39; iter: 0; batch classifier loss: 0.611573; batch adversarial loss: 0.701184\n",
      "epoch 39; iter: 200; batch classifier loss: 0.661033; batch adversarial loss: 0.713464\n",
      "epoch 39; iter: 400; batch classifier loss: 0.816766; batch adversarial loss: 0.626705\n",
      "epoch 40; iter: 0; batch classifier loss: 0.530265; batch adversarial loss: 0.565890\n",
      "epoch 40; iter: 200; batch classifier loss: 0.347380; batch adversarial loss: 0.612455\n",
      "epoch 40; iter: 400; batch classifier loss: 0.338339; batch adversarial loss: 0.639983\n",
      "epoch 41; iter: 0; batch classifier loss: 0.459364; batch adversarial loss: 0.670737\n",
      "epoch 41; iter: 200; batch classifier loss: 0.512789; batch adversarial loss: 0.610746\n",
      "epoch 41; iter: 400; batch classifier loss: 0.449902; batch adversarial loss: 0.664750\n",
      "epoch 42; iter: 0; batch classifier loss: 0.579398; batch adversarial loss: 0.696661\n",
      "epoch 42; iter: 200; batch classifier loss: 0.540813; batch adversarial loss: 0.672625\n",
      "epoch 42; iter: 400; batch classifier loss: 0.495914; batch adversarial loss: 0.590733\n",
      "epoch 43; iter: 0; batch classifier loss: 0.837579; batch adversarial loss: 0.626801\n",
      "epoch 43; iter: 200; batch classifier loss: 0.536174; batch adversarial loss: 0.703366\n",
      "epoch 43; iter: 400; batch classifier loss: 0.770822; batch adversarial loss: 0.658596\n",
      "epoch 44; iter: 0; batch classifier loss: 0.391012; batch adversarial loss: 0.677230\n",
      "epoch 44; iter: 200; batch classifier loss: 0.758035; batch adversarial loss: 0.597174\n",
      "epoch 44; iter: 400; batch classifier loss: 0.618716; batch adversarial loss: 0.619513\n",
      "epoch 45; iter: 0; batch classifier loss: 0.508127; batch adversarial loss: 0.592373\n",
      "epoch 45; iter: 200; batch classifier loss: 0.387263; batch adversarial loss: 0.681747\n",
      "epoch 45; iter: 400; batch classifier loss: 0.625929; batch adversarial loss: 0.669868\n",
      "epoch 46; iter: 0; batch classifier loss: 0.660007; batch adversarial loss: 0.561856\n",
      "epoch 46; iter: 200; batch classifier loss: 0.514449; batch adversarial loss: 0.751709\n",
      "epoch 46; iter: 400; batch classifier loss: 0.593963; batch adversarial loss: 0.619128\n",
      "epoch 47; iter: 0; batch classifier loss: 0.762457; batch adversarial loss: 0.677239\n",
      "epoch 47; iter: 200; batch classifier loss: 0.359911; batch adversarial loss: 0.639454\n",
      "epoch 47; iter: 400; batch classifier loss: 0.556933; batch adversarial loss: 0.693097\n",
      "epoch 48; iter: 0; batch classifier loss: 0.580396; batch adversarial loss: 0.622321\n",
      "epoch 48; iter: 200; batch classifier loss: 0.728707; batch adversarial loss: 0.703017\n",
      "epoch 48; iter: 400; batch classifier loss: 0.385564; batch adversarial loss: 0.639616\n",
      "epoch 49; iter: 0; batch classifier loss: 0.720405; batch adversarial loss: 0.627855\n",
      "epoch 49; iter: 200; batch classifier loss: 0.674931; batch adversarial loss: 0.610951\n",
      "epoch 49; iter: 400; batch classifier loss: 0.389355; batch adversarial loss: 0.669149\n",
      "epoch 0; iter: 0; batch classifier loss: 40.523743; batch adversarial loss: 0.689395\n",
      "epoch 0; iter: 200; batch classifier loss: 16.011354; batch adversarial loss: 0.646748\n",
      "epoch 0; iter: 400; batch classifier loss: 8.880135; batch adversarial loss: 0.625176\n",
      "epoch 1; iter: 0; batch classifier loss: 5.684994; batch adversarial loss: 0.612581\n",
      "epoch 1; iter: 200; batch classifier loss: 6.775836; batch adversarial loss: 0.597440\n",
      "epoch 1; iter: 400; batch classifier loss: 14.649583; batch adversarial loss: 0.626524\n",
      "epoch 2; iter: 0; batch classifier loss: 0.510129; batch adversarial loss: 0.653073\n",
      "epoch 2; iter: 200; batch classifier loss: 18.569759; batch adversarial loss: 0.656530\n",
      "epoch 2; iter: 400; batch classifier loss: 0.732623; batch adversarial loss: 0.665147\n",
      "epoch 3; iter: 0; batch classifier loss: 1.075243; batch adversarial loss: 0.628178\n",
      "epoch 3; iter: 200; batch classifier loss: 0.423543; batch adversarial loss: 0.616985\n",
      "epoch 3; iter: 400; batch classifier loss: 1.345597; batch adversarial loss: 0.650151\n",
      "epoch 4; iter: 0; batch classifier loss: 2.588050; batch adversarial loss: 0.626447\n",
      "epoch 4; iter: 200; batch classifier loss: 1.812123; batch adversarial loss: 0.568748\n",
      "epoch 4; iter: 400; batch classifier loss: 5.554897; batch adversarial loss: 0.610059\n",
      "epoch 5; iter: 0; batch classifier loss: 1.417817; batch adversarial loss: 0.659458\n",
      "epoch 5; iter: 200; batch classifier loss: 0.558351; batch adversarial loss: 0.642882\n",
      "epoch 5; iter: 400; batch classifier loss: 2.139000; batch adversarial loss: 0.607282\n",
      "epoch 6; iter: 0; batch classifier loss: 0.593660; batch adversarial loss: 0.602746\n",
      "epoch 6; iter: 200; batch classifier loss: 0.453449; batch adversarial loss: 0.665268\n",
      "epoch 6; iter: 400; batch classifier loss: 0.707306; batch adversarial loss: 0.586998\n",
      "epoch 7; iter: 0; batch classifier loss: 0.482955; batch adversarial loss: 0.639517\n",
      "epoch 7; iter: 200; batch classifier loss: 0.587899; batch adversarial loss: 0.629231\n",
      "epoch 7; iter: 400; batch classifier loss: 0.423049; batch adversarial loss: 0.654406\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619810; batch adversarial loss: 0.595758\n",
      "epoch 8; iter: 200; batch classifier loss: 0.529402; batch adversarial loss: 0.597551\n",
      "epoch 8; iter: 400; batch classifier loss: 0.526292; batch adversarial loss: 0.646013\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347962; batch adversarial loss: 0.516596\n",
      "epoch 9; iter: 200; batch classifier loss: 0.434562; batch adversarial loss: 0.669021\n",
      "epoch 9; iter: 400; batch classifier loss: 0.337092; batch adversarial loss: 0.663089\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419370; batch adversarial loss: 0.657298\n",
      "epoch 10; iter: 200; batch classifier loss: 0.332103; batch adversarial loss: 0.634850\n",
      "epoch 10; iter: 400; batch classifier loss: 0.602314; batch adversarial loss: 0.625178\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429518; batch adversarial loss: 0.634153\n",
      "epoch 11; iter: 200; batch classifier loss: 0.341601; batch adversarial loss: 0.650046\n",
      "epoch 11; iter: 400; batch classifier loss: 0.337663; batch adversarial loss: 0.629248\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300635; batch adversarial loss: 0.599114\n",
      "epoch 12; iter: 200; batch classifier loss: 0.324443; batch adversarial loss: 0.642579\n",
      "epoch 12; iter: 400; batch classifier loss: 0.395949; batch adversarial loss: 0.642349\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500282; batch adversarial loss: 0.550268\n",
      "epoch 13; iter: 200; batch classifier loss: 0.325134; batch adversarial loss: 0.635664\n",
      "epoch 13; iter: 400; batch classifier loss: 0.301617; batch adversarial loss: 0.682043\n",
      "epoch 14; iter: 0; batch classifier loss: 0.377515; batch adversarial loss: 0.598888\n",
      "epoch 14; iter: 200; batch classifier loss: 0.509272; batch adversarial loss: 0.617714\n",
      "epoch 14; iter: 400; batch classifier loss: 0.263593; batch adversarial loss: 0.646082\n",
      "epoch 15; iter: 0; batch classifier loss: 0.386224; batch adversarial loss: 0.634693\n",
      "epoch 15; iter: 200; batch classifier loss: 0.423232; batch adversarial loss: 0.639979\n",
      "epoch 15; iter: 400; batch classifier loss: 0.424167; batch adversarial loss: 0.580866\n",
      "epoch 16; iter: 0; batch classifier loss: 0.191076; batch adversarial loss: 0.661546\n",
      "epoch 16; iter: 200; batch classifier loss: 0.450599; batch adversarial loss: 0.591792\n",
      "epoch 16; iter: 400; batch classifier loss: 0.471475; batch adversarial loss: 0.608280\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472335; batch adversarial loss: 0.607304\n",
      "epoch 17; iter: 200; batch classifier loss: 0.307020; batch adversarial loss: 0.661607\n",
      "epoch 17; iter: 400; batch classifier loss: 0.409088; batch adversarial loss: 0.615538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.405943; batch adversarial loss: 0.639414\n",
      "epoch 18; iter: 200; batch classifier loss: 0.544815; batch adversarial loss: 0.643681\n",
      "epoch 18; iter: 400; batch classifier loss: 0.375833; batch adversarial loss: 0.621907\n",
      "epoch 19; iter: 0; batch classifier loss: 0.366307; batch adversarial loss: 0.638011\n",
      "epoch 19; iter: 200; batch classifier loss: 0.509908; batch adversarial loss: 0.674676\n",
      "epoch 19; iter: 400; batch classifier loss: 0.352206; batch adversarial loss: 0.597499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532588; batch adversarial loss: 0.587952\n",
      "epoch 20; iter: 200; batch classifier loss: 0.423006; batch adversarial loss: 0.669978\n",
      "epoch 20; iter: 400; batch classifier loss: 0.510745; batch adversarial loss: 0.581731\n",
      "epoch 21; iter: 0; batch classifier loss: 0.282468; batch adversarial loss: 0.698962\n",
      "epoch 21; iter: 200; batch classifier loss: 0.354901; batch adversarial loss: 0.629429\n",
      "epoch 21; iter: 400; batch classifier loss: 0.342814; batch adversarial loss: 0.625508\n",
      "epoch 22; iter: 0; batch classifier loss: 0.569385; batch adversarial loss: 0.581982\n",
      "epoch 22; iter: 200; batch classifier loss: 0.308997; batch adversarial loss: 0.692720\n",
      "epoch 22; iter: 400; batch classifier loss: 0.388907; batch adversarial loss: 0.673222\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418506; batch adversarial loss: 0.616778\n",
      "epoch 23; iter: 200; batch classifier loss: 0.470151; batch adversarial loss: 0.624946\n",
      "epoch 23; iter: 400; batch classifier loss: 0.408512; batch adversarial loss: 0.648530\n",
      "epoch 24; iter: 0; batch classifier loss: 0.314209; batch adversarial loss: 0.648776\n",
      "epoch 24; iter: 200; batch classifier loss: 0.346297; batch adversarial loss: 0.661551\n",
      "epoch 24; iter: 400; batch classifier loss: 0.308222; batch adversarial loss: 0.636934\n",
      "epoch 25; iter: 0; batch classifier loss: 0.251642; batch adversarial loss: 0.630281\n",
      "epoch 25; iter: 200; batch classifier loss: 0.515188; batch adversarial loss: 0.593256\n",
      "epoch 25; iter: 400; batch classifier loss: 0.539162; batch adversarial loss: 0.565724\n",
      "epoch 26; iter: 0; batch classifier loss: 0.360593; batch adversarial loss: 0.631604\n",
      "epoch 26; iter: 200; batch classifier loss: 0.646994; batch adversarial loss: 0.571896\n",
      "epoch 26; iter: 400; batch classifier loss: 0.295925; batch adversarial loss: 0.667155\n",
      "epoch 27; iter: 0; batch classifier loss: 0.540757; batch adversarial loss: 0.616861\n",
      "epoch 27; iter: 200; batch classifier loss: 0.379122; batch adversarial loss: 0.649389\n",
      "epoch 27; iter: 400; batch classifier loss: 0.579962; batch adversarial loss: 0.618446\n",
      "epoch 28; iter: 0; batch classifier loss: 0.444102; batch adversarial loss: 0.655202\n",
      "epoch 28; iter: 200; batch classifier loss: 0.454719; batch adversarial loss: 0.639535\n",
      "epoch 28; iter: 400; batch classifier loss: 0.471824; batch adversarial loss: 0.640577\n",
      "epoch 29; iter: 0; batch classifier loss: 0.305326; batch adversarial loss: 0.658542\n",
      "epoch 29; iter: 200; batch classifier loss: 0.480853; batch adversarial loss: 0.599469\n",
      "epoch 29; iter: 400; batch classifier loss: 0.444387; batch adversarial loss: 0.602423\n",
      "epoch 30; iter: 0; batch classifier loss: 0.521688; batch adversarial loss: 0.582837\n",
      "epoch 30; iter: 200; batch classifier loss: 0.578782; batch adversarial loss: 0.650759\n",
      "epoch 30; iter: 400; batch classifier loss: 0.432894; batch adversarial loss: 0.619616\n",
      "epoch 31; iter: 0; batch classifier loss: 0.308045; batch adversarial loss: 0.680755\n",
      "epoch 31; iter: 200; batch classifier loss: 0.474687; batch adversarial loss: 0.593425\n",
      "epoch 31; iter: 400; batch classifier loss: 0.552895; batch adversarial loss: 0.665317\n",
      "epoch 32; iter: 0; batch classifier loss: 0.518478; batch adversarial loss: 0.623197\n",
      "epoch 32; iter: 200; batch classifier loss: 0.432444; batch adversarial loss: 0.608973\n",
      "epoch 32; iter: 400; batch classifier loss: 0.452060; batch adversarial loss: 0.583927\n",
      "epoch 33; iter: 0; batch classifier loss: 0.416755; batch adversarial loss: 0.706183\n",
      "epoch 33; iter: 200; batch classifier loss: 0.304997; batch adversarial loss: 0.634748\n",
      "epoch 33; iter: 400; batch classifier loss: 0.646086; batch adversarial loss: 0.611103\n",
      "epoch 34; iter: 0; batch classifier loss: 0.232942; batch adversarial loss: 0.717853\n",
      "epoch 34; iter: 200; batch classifier loss: 0.638486; batch adversarial loss: 0.633813\n",
      "epoch 34; iter: 400; batch classifier loss: 0.449203; batch adversarial loss: 0.697575\n",
      "epoch 35; iter: 0; batch classifier loss: 0.600052; batch adversarial loss: 0.628344\n",
      "epoch 35; iter: 200; batch classifier loss: 0.563929; batch adversarial loss: 0.602243\n",
      "epoch 35; iter: 400; batch classifier loss: 0.622069; batch adversarial loss: 0.642908\n",
      "epoch 36; iter: 0; batch classifier loss: 0.460195; batch adversarial loss: 0.565082\n",
      "epoch 36; iter: 200; batch classifier loss: 0.716338; batch adversarial loss: 0.626429\n",
      "epoch 36; iter: 400; batch classifier loss: 0.563701; batch adversarial loss: 0.674422\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444951; batch adversarial loss: 0.693234\n",
      "epoch 37; iter: 200; batch classifier loss: 0.675479; batch adversarial loss: 0.594197\n",
      "epoch 37; iter: 400; batch classifier loss: 0.339226; batch adversarial loss: 0.599169\n",
      "epoch 38; iter: 0; batch classifier loss: 0.642426; batch adversarial loss: 0.649751\n",
      "epoch 38; iter: 200; batch classifier loss: 0.501818; batch adversarial loss: 0.606319\n",
      "epoch 38; iter: 400; batch classifier loss: 0.690684; batch adversarial loss: 0.630388\n",
      "epoch 39; iter: 0; batch classifier loss: 0.378904; batch adversarial loss: 0.615612\n",
      "epoch 39; iter: 200; batch classifier loss: 0.597894; batch adversarial loss: 0.636418\n",
      "epoch 39; iter: 400; batch classifier loss: 0.469133; batch adversarial loss: 0.599079\n",
      "epoch 40; iter: 0; batch classifier loss: 0.588899; batch adversarial loss: 0.693771\n",
      "epoch 40; iter: 200; batch classifier loss: 0.328176; batch adversarial loss: 0.607166\n",
      "epoch 40; iter: 400; batch classifier loss: 0.575934; batch adversarial loss: 0.564358\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402615; batch adversarial loss: 0.639830\n",
      "epoch 41; iter: 200; batch classifier loss: 0.488865; batch adversarial loss: 0.583098\n",
      "epoch 41; iter: 400; batch classifier loss: 0.299257; batch adversarial loss: 0.666120\n",
      "epoch 42; iter: 0; batch classifier loss: 0.759483; batch adversarial loss: 0.671491\n",
      "epoch 42; iter: 200; batch classifier loss: 0.517357; batch adversarial loss: 0.652469\n",
      "epoch 42; iter: 400; batch classifier loss: 0.645459; batch adversarial loss: 0.648750\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407587; batch adversarial loss: 0.629408\n",
      "epoch 43; iter: 200; batch classifier loss: 0.452338; batch adversarial loss: 0.659448\n",
      "epoch 43; iter: 400; batch classifier loss: 0.522691; batch adversarial loss: 0.669741\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438746; batch adversarial loss: 0.590024\n",
      "epoch 44; iter: 200; batch classifier loss: 0.528390; batch adversarial loss: 0.675658\n",
      "epoch 44; iter: 400; batch classifier loss: 0.519773; batch adversarial loss: 0.674841\n",
      "epoch 45; iter: 0; batch classifier loss: 0.499816; batch adversarial loss: 0.699380\n",
      "epoch 45; iter: 200; batch classifier loss: 0.426185; batch adversarial loss: 0.606719\n",
      "epoch 45; iter: 400; batch classifier loss: 0.681159; batch adversarial loss: 0.663620\n",
      "epoch 46; iter: 0; batch classifier loss: 0.327702; batch adversarial loss: 0.576138\n",
      "epoch 46; iter: 200; batch classifier loss: 0.574777; batch adversarial loss: 0.592804\n",
      "epoch 46; iter: 400; batch classifier loss: 0.561773; batch adversarial loss: 0.599622\n",
      "epoch 47; iter: 0; batch classifier loss: 0.546951; batch adversarial loss: 0.650131\n",
      "epoch 47; iter: 200; batch classifier loss: 0.485311; batch adversarial loss: 0.692022\n",
      "epoch 47; iter: 400; batch classifier loss: 0.637518; batch adversarial loss: 0.600416\n",
      "epoch 48; iter: 0; batch classifier loss: 0.732662; batch adversarial loss: 0.757171\n",
      "epoch 48; iter: 200; batch classifier loss: 0.615306; batch adversarial loss: 0.637125\n",
      "epoch 48; iter: 400; batch classifier loss: 0.326058; batch adversarial loss: 0.596786\n",
      "epoch 49; iter: 0; batch classifier loss: 0.565022; batch adversarial loss: 0.615517\n",
      "epoch 49; iter: 200; batch classifier loss: 0.581314; batch adversarial loss: 0.637728\n",
      "epoch 49; iter: 400; batch classifier loss: 0.479782; batch adversarial loss: 0.655013\n",
      "epoch 0; iter: 0; batch classifier loss: 32.847298; batch adversarial loss: 0.661699\n",
      "epoch 0; iter: 200; batch classifier loss: 3.099981; batch adversarial loss: 0.696667\n",
      "epoch 0; iter: 400; batch classifier loss: 2.440457; batch adversarial loss: 0.613420\n",
      "epoch 1; iter: 0; batch classifier loss: 18.226267; batch adversarial loss: 0.697137\n",
      "epoch 1; iter: 200; batch classifier loss: 5.296492; batch adversarial loss: 0.571344\n",
      "epoch 1; iter: 400; batch classifier loss: 7.802173; batch adversarial loss: 0.665193\n",
      "epoch 2; iter: 0; batch classifier loss: 4.619824; batch adversarial loss: 0.602023\n",
      "epoch 2; iter: 200; batch classifier loss: 8.652787; batch adversarial loss: 0.625665\n",
      "epoch 2; iter: 400; batch classifier loss: 7.953383; batch adversarial loss: 0.584150\n",
      "epoch 3; iter: 0; batch classifier loss: 7.536723; batch adversarial loss: 0.668502\n",
      "epoch 3; iter: 200; batch classifier loss: 4.875450; batch adversarial loss: 0.666269\n",
      "epoch 3; iter: 400; batch classifier loss: 3.076997; batch adversarial loss: 0.594677\n",
      "epoch 4; iter: 0; batch classifier loss: 0.401359; batch adversarial loss: 0.663198\n",
      "epoch 4; iter: 200; batch classifier loss: 1.354887; batch adversarial loss: 0.528507\n",
      "epoch 4; iter: 400; batch classifier loss: 0.941359; batch adversarial loss: 0.585153\n",
      "epoch 5; iter: 0; batch classifier loss: 1.229377; batch adversarial loss: 0.597425\n",
      "epoch 5; iter: 200; batch classifier loss: 0.890474; batch adversarial loss: 0.577755\n",
      "epoch 5; iter: 400; batch classifier loss: 0.574353; batch adversarial loss: 0.683165\n",
      "epoch 6; iter: 0; batch classifier loss: 1.005718; batch adversarial loss: 0.742944\n",
      "epoch 6; iter: 200; batch classifier loss: 0.392596; batch adversarial loss: 0.602996\n",
      "epoch 6; iter: 400; batch classifier loss: 0.482536; batch adversarial loss: 0.526278\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481552; batch adversarial loss: 0.604590\n",
      "epoch 7; iter: 200; batch classifier loss: 0.533918; batch adversarial loss: 0.590248\n",
      "epoch 7; iter: 400; batch classifier loss: 0.451303; batch adversarial loss: 0.622237\n",
      "epoch 8; iter: 0; batch classifier loss: 0.399009; batch adversarial loss: 0.620153\n",
      "epoch 8; iter: 200; batch classifier loss: 0.409591; batch adversarial loss: 0.583323\n",
      "epoch 8; iter: 400; batch classifier loss: 0.327736; batch adversarial loss: 0.624100\n",
      "epoch 9; iter: 0; batch classifier loss: 0.424721; batch adversarial loss: 0.576831\n",
      "epoch 9; iter: 200; batch classifier loss: 0.355981; batch adversarial loss: 0.625936\n",
      "epoch 9; iter: 400; batch classifier loss: 0.324300; batch adversarial loss: 0.596386\n",
      "epoch 10; iter: 0; batch classifier loss: 0.411347; batch adversarial loss: 0.665630\n",
      "epoch 10; iter: 200; batch classifier loss: 0.433765; batch adversarial loss: 0.571590\n",
      "epoch 10; iter: 400; batch classifier loss: 0.515030; batch adversarial loss: 0.635446\n",
      "epoch 11; iter: 0; batch classifier loss: 0.378084; batch adversarial loss: 0.636250\n",
      "epoch 11; iter: 200; batch classifier loss: 0.494461; batch adversarial loss: 0.542916\n",
      "epoch 11; iter: 400; batch classifier loss: 0.304456; batch adversarial loss: 0.597306\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460369; batch adversarial loss: 0.653080\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391146; batch adversarial loss: 0.545346\n",
      "epoch 12; iter: 400; batch classifier loss: 0.261505; batch adversarial loss: 0.638136\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370509; batch adversarial loss: 0.570670\n",
      "epoch 13; iter: 200; batch classifier loss: 0.347405; batch adversarial loss: 0.628410\n",
      "epoch 13; iter: 400; batch classifier loss: 0.430165; batch adversarial loss: 0.661113\n",
      "epoch 14; iter: 0; batch classifier loss: 0.873436; batch adversarial loss: 0.634725\n",
      "epoch 14; iter: 200; batch classifier loss: 0.326027; batch adversarial loss: 0.607287\n",
      "epoch 14; iter: 400; batch classifier loss: 0.436369; batch adversarial loss: 0.570035\n",
      "epoch 15; iter: 0; batch classifier loss: 0.345458; batch adversarial loss: 0.676714\n",
      "epoch 15; iter: 200; batch classifier loss: 0.311713; batch adversarial loss: 0.663104\n",
      "epoch 15; iter: 400; batch classifier loss: 0.314317; batch adversarial loss: 0.718129\n",
      "epoch 16; iter: 0; batch classifier loss: 0.522433; batch adversarial loss: 0.684637\n",
      "epoch 16; iter: 200; batch classifier loss: 0.427009; batch adversarial loss: 0.575258\n",
      "epoch 16; iter: 400; batch classifier loss: 0.330669; batch adversarial loss: 0.566306\n",
      "epoch 17; iter: 0; batch classifier loss: 0.436957; batch adversarial loss: 0.594605\n",
      "epoch 17; iter: 200; batch classifier loss: 0.266995; batch adversarial loss: 0.624483\n",
      "epoch 17; iter: 400; batch classifier loss: 0.345866; batch adversarial loss: 0.602151\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361994; batch adversarial loss: 0.651624\n",
      "epoch 18; iter: 200; batch classifier loss: 0.350810; batch adversarial loss: 0.656030\n",
      "epoch 18; iter: 400; batch classifier loss: 0.377579; batch adversarial loss: 0.613872\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478087; batch adversarial loss: 0.523493\n",
      "epoch 19; iter: 200; batch classifier loss: 0.367663; batch adversarial loss: 0.624739\n",
      "epoch 19; iter: 400; batch classifier loss: 0.429892; batch adversarial loss: 0.625341\n",
      "epoch 20; iter: 0; batch classifier loss: 1.095602; batch adversarial loss: 0.569681\n",
      "epoch 20; iter: 200; batch classifier loss: 0.419307; batch adversarial loss: 0.629616\n",
      "epoch 20; iter: 400; batch classifier loss: 0.451221; batch adversarial loss: 0.560046\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478238; batch adversarial loss: 0.616302\n",
      "epoch 21; iter: 200; batch classifier loss: 0.406806; batch adversarial loss: 0.674701\n",
      "epoch 21; iter: 400; batch classifier loss: 0.212233; batch adversarial loss: 0.671040\n",
      "epoch 22; iter: 0; batch classifier loss: 0.369323; batch adversarial loss: 0.698541\n",
      "epoch 22; iter: 200; batch classifier loss: 0.231411; batch adversarial loss: 0.614915\n",
      "epoch 22; iter: 400; batch classifier loss: 0.399683; batch adversarial loss: 0.659707\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381585; batch adversarial loss: 0.639403\n",
      "epoch 23; iter: 200; batch classifier loss: 0.542738; batch adversarial loss: 0.653117\n",
      "epoch 23; iter: 400; batch classifier loss: 0.319223; batch adversarial loss: 0.650350\n",
      "epoch 24; iter: 0; batch classifier loss: 0.302933; batch adversarial loss: 0.678388\n",
      "epoch 24; iter: 200; batch classifier loss: 0.259431; batch adversarial loss: 0.666079\n",
      "epoch 24; iter: 400; batch classifier loss: 0.577103; batch adversarial loss: 0.620406\n",
      "epoch 25; iter: 0; batch classifier loss: 0.542110; batch adversarial loss: 0.611600\n",
      "epoch 25; iter: 200; batch classifier loss: 0.384483; batch adversarial loss: 0.620462\n",
      "epoch 25; iter: 400; batch classifier loss: 0.694453; batch adversarial loss: 0.599395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.551867; batch adversarial loss: 0.609388\n",
      "epoch 26; iter: 200; batch classifier loss: 0.340895; batch adversarial loss: 0.665930\n",
      "epoch 26; iter: 400; batch classifier loss: 0.436137; batch adversarial loss: 0.639177\n",
      "epoch 27; iter: 0; batch classifier loss: 0.334840; batch adversarial loss: 0.660882\n",
      "epoch 27; iter: 200; batch classifier loss: 0.272118; batch adversarial loss: 0.662968\n",
      "epoch 27; iter: 400; batch classifier loss: 0.378001; batch adversarial loss: 0.633635\n",
      "epoch 28; iter: 0; batch classifier loss: 0.566737; batch adversarial loss: 0.573144\n",
      "epoch 28; iter: 200; batch classifier loss: 0.386427; batch adversarial loss: 0.593783\n",
      "epoch 28; iter: 400; batch classifier loss: 0.354275; batch adversarial loss: 0.627432\n",
      "epoch 29; iter: 0; batch classifier loss: 0.532910; batch adversarial loss: 0.587122\n",
      "epoch 29; iter: 200; batch classifier loss: 0.535204; batch adversarial loss: 0.597585\n",
      "epoch 29; iter: 400; batch classifier loss: 0.537666; batch adversarial loss: 0.588108\n",
      "epoch 30; iter: 0; batch classifier loss: 0.617024; batch adversarial loss: 0.694084\n",
      "epoch 30; iter: 200; batch classifier loss: 0.379162; batch adversarial loss: 0.697614\n",
      "epoch 30; iter: 400; batch classifier loss: 0.408488; batch adversarial loss: 0.614474\n",
      "epoch 31; iter: 0; batch classifier loss: 0.559978; batch adversarial loss: 0.635165\n",
      "epoch 31; iter: 200; batch classifier loss: 0.326183; batch adversarial loss: 0.648797\n",
      "epoch 31; iter: 400; batch classifier loss: 0.360412; batch adversarial loss: 0.696785\n",
      "epoch 32; iter: 0; batch classifier loss: 0.318631; batch adversarial loss: 0.621374\n",
      "epoch 32; iter: 200; batch classifier loss: 0.374494; batch adversarial loss: 0.675092\n",
      "epoch 32; iter: 400; batch classifier loss: 0.832399; batch adversarial loss: 0.628263\n",
      "epoch 33; iter: 0; batch classifier loss: 0.743008; batch adversarial loss: 0.588858\n",
      "epoch 33; iter: 200; batch classifier loss: 0.547723; batch adversarial loss: 0.554109\n",
      "epoch 33; iter: 400; batch classifier loss: 0.705518; batch adversarial loss: 0.559995\n",
      "epoch 34; iter: 0; batch classifier loss: 0.527793; batch adversarial loss: 0.599969\n",
      "epoch 34; iter: 200; batch classifier loss: 0.399089; batch adversarial loss: 0.616298\n",
      "epoch 34; iter: 400; batch classifier loss: 0.473499; batch adversarial loss: 0.604715\n",
      "epoch 35; iter: 0; batch classifier loss: 0.559952; batch adversarial loss: 0.614027\n",
      "epoch 35; iter: 200; batch classifier loss: 0.929326; batch adversarial loss: 0.698211\n",
      "epoch 35; iter: 400; batch classifier loss: 0.311474; batch adversarial loss: 0.687298\n",
      "epoch 36; iter: 0; batch classifier loss: 0.531908; batch adversarial loss: 0.585894\n",
      "epoch 36; iter: 200; batch classifier loss: 0.485350; batch adversarial loss: 0.665727\n",
      "epoch 36; iter: 400; batch classifier loss: 0.232739; batch adversarial loss: 0.628604\n",
      "epoch 37; iter: 0; batch classifier loss: 0.475667; batch adversarial loss: 0.598702\n",
      "epoch 37; iter: 200; batch classifier loss: 0.432792; batch adversarial loss: 0.680958\n",
      "epoch 37; iter: 400; batch classifier loss: 0.671766; batch adversarial loss: 0.606057\n",
      "epoch 38; iter: 0; batch classifier loss: 0.189877; batch adversarial loss: 0.663352\n",
      "epoch 38; iter: 200; batch classifier loss: 0.384755; batch adversarial loss: 0.659840\n",
      "epoch 38; iter: 400; batch classifier loss: 0.538632; batch adversarial loss: 0.585985\n",
      "epoch 39; iter: 0; batch classifier loss: 0.508513; batch adversarial loss: 0.659194\n",
      "epoch 39; iter: 200; batch classifier loss: 0.386804; batch adversarial loss: 0.611879\n",
      "epoch 39; iter: 400; batch classifier loss: 0.550791; batch adversarial loss: 0.609830\n",
      "epoch 40; iter: 0; batch classifier loss: 0.573132; batch adversarial loss: 0.654343\n",
      "epoch 40; iter: 200; batch classifier loss: 0.420265; batch adversarial loss: 0.623476\n",
      "epoch 40; iter: 400; batch classifier loss: 0.513672; batch adversarial loss: 0.653418\n",
      "epoch 41; iter: 0; batch classifier loss: 0.392254; batch adversarial loss: 0.641327\n",
      "epoch 41; iter: 200; batch classifier loss: 0.564792; batch adversarial loss: 0.608587\n",
      "epoch 41; iter: 400; batch classifier loss: 0.564906; batch adversarial loss: 0.604986\n",
      "epoch 42; iter: 0; batch classifier loss: 0.335010; batch adversarial loss: 0.606873\n",
      "epoch 42; iter: 200; batch classifier loss: 0.340427; batch adversarial loss: 0.581639\n",
      "epoch 42; iter: 400; batch classifier loss: 0.535618; batch adversarial loss: 0.622851\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492127; batch adversarial loss: 0.632120\n",
      "epoch 43; iter: 200; batch classifier loss: 0.486740; batch adversarial loss: 0.605068\n",
      "epoch 43; iter: 400; batch classifier loss: 0.444661; batch adversarial loss: 0.620269\n",
      "epoch 44; iter: 0; batch classifier loss: 0.348414; batch adversarial loss: 0.590577\n",
      "epoch 44; iter: 200; batch classifier loss: 0.462396; batch adversarial loss: 0.581026\n",
      "epoch 44; iter: 400; batch classifier loss: 0.528057; batch adversarial loss: 0.699232\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336273; batch adversarial loss: 0.600827\n",
      "epoch 45; iter: 200; batch classifier loss: 0.589166; batch adversarial loss: 0.619642\n",
      "epoch 45; iter: 400; batch classifier loss: 0.383437; batch adversarial loss: 0.627363\n",
      "epoch 46; iter: 0; batch classifier loss: 0.446484; batch adversarial loss: 0.618713\n",
      "epoch 46; iter: 200; batch classifier loss: 0.435126; batch adversarial loss: 0.596972\n",
      "epoch 46; iter: 400; batch classifier loss: 0.465874; batch adversarial loss: 0.663767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472675; batch adversarial loss: 0.701204\n",
      "epoch 47; iter: 200; batch classifier loss: 0.322922; batch adversarial loss: 0.631689\n",
      "epoch 47; iter: 400; batch classifier loss: 0.233883; batch adversarial loss: 0.688702\n",
      "epoch 48; iter: 0; batch classifier loss: 0.282261; batch adversarial loss: 0.657133\n",
      "epoch 48; iter: 200; batch classifier loss: 0.501584; batch adversarial loss: 0.617715\n",
      "epoch 48; iter: 400; batch classifier loss: 0.277101; batch adversarial loss: 0.638122\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503890; batch adversarial loss: 0.707247\n",
      "epoch 49; iter: 200; batch classifier loss: 0.300623; batch adversarial loss: 0.587792\n",
      "epoch 49; iter: 400; batch classifier loss: 0.322829; batch adversarial loss: 0.644058\n",
      "epoch 0; iter: 0; batch classifier loss: 16.660593; batch adversarial loss: 0.697478\n",
      "epoch 0; iter: 200; batch classifier loss: 7.361383; batch adversarial loss: 0.672809\n",
      "epoch 0; iter: 400; batch classifier loss: 10.844665; batch adversarial loss: 0.605652\n",
      "epoch 1; iter: 0; batch classifier loss: 0.950193; batch adversarial loss: 0.661097\n",
      "epoch 1; iter: 200; batch classifier loss: 2.591602; batch adversarial loss: 0.653931\n",
      "epoch 1; iter: 400; batch classifier loss: 3.025522; batch adversarial loss: 0.659541\n",
      "epoch 2; iter: 0; batch classifier loss: 10.388796; batch adversarial loss: 0.734302\n",
      "epoch 2; iter: 200; batch classifier loss: 4.729272; batch adversarial loss: 0.685002\n",
      "epoch 2; iter: 400; batch classifier loss: 0.416850; batch adversarial loss: 0.678725\n",
      "epoch 3; iter: 0; batch classifier loss: 0.462445; batch adversarial loss: 0.643258\n",
      "epoch 3; iter: 200; batch classifier loss: 3.629333; batch adversarial loss: 0.645389\n",
      "epoch 3; iter: 400; batch classifier loss: 0.380263; batch adversarial loss: 0.573609\n",
      "epoch 4; iter: 0; batch classifier loss: 1.306041; batch adversarial loss: 0.577183\n",
      "epoch 4; iter: 200; batch classifier loss: 0.460164; batch adversarial loss: 0.656746\n",
      "epoch 4; iter: 400; batch classifier loss: 1.288633; batch adversarial loss: 0.660581\n",
      "epoch 5; iter: 0; batch classifier loss: 2.186999; batch adversarial loss: 0.601830\n",
      "epoch 5; iter: 200; batch classifier loss: 0.738996; batch adversarial loss: 0.696743\n",
      "epoch 5; iter: 400; batch classifier loss: 0.520160; batch adversarial loss: 0.679697\n",
      "epoch 6; iter: 0; batch classifier loss: 1.470349; batch adversarial loss: 0.603474\n",
      "epoch 6; iter: 200; batch classifier loss: 0.944005; batch adversarial loss: 0.627190\n",
      "epoch 6; iter: 400; batch classifier loss: 0.870269; batch adversarial loss: 0.616294\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529400; batch adversarial loss: 0.561895\n",
      "epoch 7; iter: 200; batch classifier loss: 0.608747; batch adversarial loss: 0.568244\n",
      "epoch 7; iter: 400; batch classifier loss: 0.532669; batch adversarial loss: 0.606577\n",
      "epoch 8; iter: 0; batch classifier loss: 0.354066; batch adversarial loss: 0.606087\n",
      "epoch 8; iter: 200; batch classifier loss: 0.403432; batch adversarial loss: 0.534456\n",
      "epoch 8; iter: 400; batch classifier loss: 0.291140; batch adversarial loss: 0.583726\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527098; batch adversarial loss: 0.638794\n",
      "epoch 9; iter: 200; batch classifier loss: 0.619229; batch adversarial loss: 0.551959\n",
      "epoch 9; iter: 400; batch classifier loss: 0.429322; batch adversarial loss: 0.615553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288015; batch adversarial loss: 0.584241\n",
      "epoch 10; iter: 200; batch classifier loss: 0.397287; batch adversarial loss: 0.639671\n",
      "epoch 10; iter: 400; batch classifier loss: 0.442170; batch adversarial loss: 0.648433\n",
      "epoch 11; iter: 0; batch classifier loss: 0.297587; batch adversarial loss: 0.705962\n",
      "epoch 11; iter: 200; batch classifier loss: 0.344211; batch adversarial loss: 0.601185\n",
      "epoch 11; iter: 400; batch classifier loss: 0.363139; batch adversarial loss: 0.617592\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428650; batch adversarial loss: 0.564622\n",
      "epoch 12; iter: 200; batch classifier loss: 0.311299; batch adversarial loss: 0.659807\n",
      "epoch 12; iter: 400; batch classifier loss: 0.354631; batch adversarial loss: 0.589134\n",
      "epoch 13; iter: 0; batch classifier loss: 0.332215; batch adversarial loss: 0.579023\n",
      "epoch 13; iter: 200; batch classifier loss: 0.305033; batch adversarial loss: 0.570581\n",
      "epoch 13; iter: 400; batch classifier loss: 0.238908; batch adversarial loss: 0.613668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.378020; batch adversarial loss: 0.593049\n",
      "epoch 14; iter: 200; batch classifier loss: 0.278226; batch adversarial loss: 0.663432\n",
      "epoch 14; iter: 400; batch classifier loss: 0.309629; batch adversarial loss: 0.564995\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385140; batch adversarial loss: 0.588541\n",
      "epoch 15; iter: 200; batch classifier loss: 0.318889; batch adversarial loss: 0.637827\n",
      "epoch 15; iter: 400; batch classifier loss: 0.347980; batch adversarial loss: 0.584823\n",
      "epoch 16; iter: 0; batch classifier loss: 0.233559; batch adversarial loss: 0.611008\n",
      "epoch 16; iter: 200; batch classifier loss: 0.357388; batch adversarial loss: 0.604586\n",
      "epoch 16; iter: 400; batch classifier loss: 0.422735; batch adversarial loss: 0.587018\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327486; batch adversarial loss: 0.666507\n",
      "epoch 17; iter: 200; batch classifier loss: 0.445431; batch adversarial loss: 0.666589\n",
      "epoch 17; iter: 400; batch classifier loss: 0.278369; batch adversarial loss: 0.638351\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414640; batch adversarial loss: 0.544207\n",
      "epoch 18; iter: 200; batch classifier loss: 0.353262; batch adversarial loss: 0.639048\n",
      "epoch 18; iter: 400; batch classifier loss: 0.550727; batch adversarial loss: 0.581512\n",
      "epoch 19; iter: 0; batch classifier loss: 0.421856; batch adversarial loss: 0.623567\n",
      "epoch 19; iter: 200; batch classifier loss: 0.407270; batch adversarial loss: 0.653936\n",
      "epoch 19; iter: 400; batch classifier loss: 0.357656; batch adversarial loss: 0.627708\n",
      "epoch 20; iter: 0; batch classifier loss: 0.562553; batch adversarial loss: 0.646170\n",
      "epoch 20; iter: 200; batch classifier loss: 0.499669; batch adversarial loss: 0.648437\n",
      "epoch 20; iter: 400; batch classifier loss: 0.381710; batch adversarial loss: 0.697033\n",
      "epoch 21; iter: 0; batch classifier loss: 0.326550; batch adversarial loss: 0.732750\n",
      "epoch 21; iter: 200; batch classifier loss: 0.340756; batch adversarial loss: 0.665163\n",
      "epoch 21; iter: 400; batch classifier loss: 0.514283; batch adversarial loss: 0.651217\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423376; batch adversarial loss: 0.664318\n",
      "epoch 22; iter: 200; batch classifier loss: 0.600772; batch adversarial loss: 0.632842\n",
      "epoch 22; iter: 400; batch classifier loss: 0.428955; batch adversarial loss: 0.593038\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439513; batch adversarial loss: 0.603438\n",
      "epoch 23; iter: 200; batch classifier loss: 0.313405; batch adversarial loss: 0.633441\n",
      "epoch 23; iter: 400; batch classifier loss: 0.658563; batch adversarial loss: 0.608689\n",
      "epoch 24; iter: 0; batch classifier loss: 0.384380; batch adversarial loss: 0.607157\n",
      "epoch 24; iter: 200; batch classifier loss: 0.331641; batch adversarial loss: 0.623484\n",
      "epoch 24; iter: 400; batch classifier loss: 0.210467; batch adversarial loss: 0.648346\n",
      "epoch 25; iter: 0; batch classifier loss: 0.304094; batch adversarial loss: 0.747426\n",
      "epoch 25; iter: 200; batch classifier loss: 0.401966; batch adversarial loss: 0.576174\n",
      "epoch 25; iter: 400; batch classifier loss: 0.437028; batch adversarial loss: 0.639269\n",
      "epoch 26; iter: 0; batch classifier loss: 0.222607; batch adversarial loss: 0.641408\n",
      "epoch 26; iter: 200; batch classifier loss: 0.538374; batch adversarial loss: 0.634763\n",
      "epoch 26; iter: 400; batch classifier loss: 0.247277; batch adversarial loss: 0.689064\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413255; batch adversarial loss: 0.674329\n",
      "epoch 27; iter: 200; batch classifier loss: 0.453988; batch adversarial loss: 0.613894\n",
      "epoch 27; iter: 400; batch classifier loss: 0.405137; batch adversarial loss: 0.745301\n",
      "epoch 28; iter: 0; batch classifier loss: 0.390852; batch adversarial loss: 0.653975\n",
      "epoch 28; iter: 200; batch classifier loss: 0.385054; batch adversarial loss: 0.659210\n",
      "epoch 28; iter: 400; batch classifier loss: 0.738609; batch adversarial loss: 0.613798\n",
      "epoch 29; iter: 0; batch classifier loss: 0.527432; batch adversarial loss: 0.616277\n",
      "epoch 29; iter: 200; batch classifier loss: 0.543324; batch adversarial loss: 0.651497\n",
      "epoch 29; iter: 400; batch classifier loss: 0.611066; batch adversarial loss: 0.652607\n",
      "epoch 30; iter: 0; batch classifier loss: 0.454966; batch adversarial loss: 0.705543\n",
      "epoch 30; iter: 200; batch classifier loss: 0.572552; batch adversarial loss: 0.590141\n",
      "epoch 30; iter: 400; batch classifier loss: 0.460256; batch adversarial loss: 0.595006\n",
      "epoch 31; iter: 0; batch classifier loss: 0.264987; batch adversarial loss: 0.688169\n",
      "epoch 31; iter: 200; batch classifier loss: 0.357194; batch adversarial loss: 0.665530\n",
      "epoch 31; iter: 400; batch classifier loss: 0.501549; batch adversarial loss: 0.598545\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431103; batch adversarial loss: 0.574966\n",
      "epoch 32; iter: 200; batch classifier loss: 0.548251; batch adversarial loss: 0.643915\n",
      "epoch 32; iter: 400; batch classifier loss: 0.850051; batch adversarial loss: 0.630063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.451318; batch adversarial loss: 0.651744\n",
      "epoch 33; iter: 200; batch classifier loss: 0.284959; batch adversarial loss: 0.591567\n",
      "epoch 33; iter: 400; batch classifier loss: 0.378507; batch adversarial loss: 0.632669\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363177; batch adversarial loss: 0.581293\n",
      "epoch 34; iter: 200; batch classifier loss: 0.406193; batch adversarial loss: 0.649151\n",
      "epoch 34; iter: 400; batch classifier loss: 0.452429; batch adversarial loss: 0.594813\n",
      "epoch 35; iter: 0; batch classifier loss: 0.503643; batch adversarial loss: 0.565510\n",
      "epoch 35; iter: 200; batch classifier loss: 0.789565; batch adversarial loss: 0.622144\n",
      "epoch 35; iter: 400; batch classifier loss: 0.537700; batch adversarial loss: 0.559538\n",
      "epoch 36; iter: 0; batch classifier loss: 0.345230; batch adversarial loss: 0.616234\n",
      "epoch 36; iter: 200; batch classifier loss: 0.431559; batch adversarial loss: 0.624949\n",
      "epoch 36; iter: 400; batch classifier loss: 0.602299; batch adversarial loss: 0.626031\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442464; batch adversarial loss: 0.600675\n",
      "epoch 37; iter: 200; batch classifier loss: 0.433820; batch adversarial loss: 0.541147\n",
      "epoch 37; iter: 400; batch classifier loss: 0.376215; batch adversarial loss: 0.673277\n",
      "epoch 38; iter: 0; batch classifier loss: 0.630949; batch adversarial loss: 0.611443\n",
      "epoch 38; iter: 200; batch classifier loss: 0.538299; batch adversarial loss: 0.706156\n",
      "epoch 38; iter: 400; batch classifier loss: 0.732990; batch adversarial loss: 0.687449\n",
      "epoch 39; iter: 0; batch classifier loss: 0.689854; batch adversarial loss: 0.617194\n",
      "epoch 39; iter: 200; batch classifier loss: 0.631338; batch adversarial loss: 0.548864\n",
      "epoch 39; iter: 400; batch classifier loss: 0.389098; batch adversarial loss: 0.716171\n",
      "epoch 40; iter: 0; batch classifier loss: 0.881881; batch adversarial loss: 0.614566\n",
      "epoch 40; iter: 200; batch classifier loss: 0.667259; batch adversarial loss: 0.576715\n",
      "epoch 40; iter: 400; batch classifier loss: 0.320663; batch adversarial loss: 0.664872\n",
      "epoch 41; iter: 0; batch classifier loss: 0.456776; batch adversarial loss: 0.610382\n",
      "epoch 41; iter: 200; batch classifier loss: 0.346259; batch adversarial loss: 0.666094\n",
      "epoch 41; iter: 400; batch classifier loss: 0.571358; batch adversarial loss: 0.641237\n",
      "epoch 42; iter: 0; batch classifier loss: 0.542626; batch adversarial loss: 0.669382\n",
      "epoch 42; iter: 200; batch classifier loss: 0.547232; batch adversarial loss: 0.691022\n",
      "epoch 42; iter: 400; batch classifier loss: 0.444302; batch adversarial loss: 0.622158\n",
      "epoch 43; iter: 0; batch classifier loss: 0.613079; batch adversarial loss: 0.533258\n",
      "epoch 43; iter: 200; batch classifier loss: 0.396839; batch adversarial loss: 0.604873\n",
      "epoch 43; iter: 400; batch classifier loss: 0.671116; batch adversarial loss: 0.596259\n",
      "epoch 44; iter: 0; batch classifier loss: 0.493052; batch adversarial loss: 0.640726\n",
      "epoch 44; iter: 200; batch classifier loss: 0.494976; batch adversarial loss: 0.658922\n",
      "epoch 44; iter: 400; batch classifier loss: 0.659852; batch adversarial loss: 0.577982\n",
      "epoch 45; iter: 0; batch classifier loss: 0.534620; batch adversarial loss: 0.622666\n",
      "epoch 45; iter: 200; batch classifier loss: 0.585618; batch adversarial loss: 0.613093\n",
      "epoch 45; iter: 400; batch classifier loss: 0.381582; batch adversarial loss: 0.610641\n",
      "epoch 46; iter: 0; batch classifier loss: 0.374484; batch adversarial loss: 0.579996\n",
      "epoch 46; iter: 200; batch classifier loss: 0.611211; batch adversarial loss: 0.617998\n",
      "epoch 46; iter: 400; batch classifier loss: 0.402880; batch adversarial loss: 0.684760\n",
      "epoch 47; iter: 0; batch classifier loss: 0.533728; batch adversarial loss: 0.605097\n",
      "epoch 47; iter: 200; batch classifier loss: 0.447486; batch adversarial loss: 0.662490\n",
      "epoch 47; iter: 400; batch classifier loss: 0.384086; batch adversarial loss: 0.668799\n",
      "epoch 48; iter: 0; batch classifier loss: 0.634181; batch adversarial loss: 0.614153\n",
      "epoch 48; iter: 200; batch classifier loss: 0.357027; batch adversarial loss: 0.597667\n",
      "epoch 48; iter: 400; batch classifier loss: 0.435878; batch adversarial loss: 0.642942\n",
      "epoch 49; iter: 0; batch classifier loss: 0.435988; batch adversarial loss: 0.607622\n",
      "epoch 49; iter: 200; batch classifier loss: 0.246784; batch adversarial loss: 0.600939\n",
      "epoch 49; iter: 400; batch classifier loss: 0.388203; batch adversarial loss: 0.651796\n",
      "epoch 0; iter: 0; batch classifier loss: 131.711212; batch adversarial loss: 0.657045\n",
      "epoch 0; iter: 200; batch classifier loss: 0.670844; batch adversarial loss: 0.599003\n",
      "epoch 0; iter: 400; batch classifier loss: 3.511860; batch adversarial loss: 0.659165\n",
      "epoch 1; iter: 0; batch classifier loss: 10.259068; batch adversarial loss: 0.626191\n",
      "epoch 1; iter: 200; batch classifier loss: 7.674817; batch adversarial loss: 0.504724\n",
      "epoch 1; iter: 400; batch classifier loss: 3.797200; batch adversarial loss: 0.656040\n",
      "epoch 2; iter: 0; batch classifier loss: 4.674824; batch adversarial loss: 0.648843\n",
      "epoch 2; iter: 200; batch classifier loss: 2.207671; batch adversarial loss: 0.609328\n",
      "epoch 2; iter: 400; batch classifier loss: 8.986685; batch adversarial loss: 0.644294\n",
      "epoch 3; iter: 0; batch classifier loss: 0.718685; batch adversarial loss: 0.633100\n",
      "epoch 3; iter: 200; batch classifier loss: 1.996929; batch adversarial loss: 0.601816\n",
      "epoch 3; iter: 400; batch classifier loss: 0.904035; batch adversarial loss: 0.635381\n",
      "epoch 4; iter: 0; batch classifier loss: 0.451964; batch adversarial loss: 0.540210\n",
      "epoch 4; iter: 200; batch classifier loss: 2.471216; batch adversarial loss: 0.545766\n",
      "epoch 4; iter: 400; batch classifier loss: 0.897081; batch adversarial loss: 0.626262\n",
      "epoch 5; iter: 0; batch classifier loss: 3.879751; batch adversarial loss: 0.591349\n",
      "epoch 5; iter: 200; batch classifier loss: 1.323457; batch adversarial loss: 0.635079\n",
      "epoch 5; iter: 400; batch classifier loss: 0.668152; batch adversarial loss: 0.638660\n",
      "epoch 6; iter: 0; batch classifier loss: 1.369049; batch adversarial loss: 0.580944\n",
      "epoch 6; iter: 200; batch classifier loss: 0.540735; batch adversarial loss: 0.573581\n",
      "epoch 6; iter: 400; batch classifier loss: 0.458685; batch adversarial loss: 0.556923\n",
      "epoch 7; iter: 0; batch classifier loss: 0.760335; batch adversarial loss: 0.609729\n",
      "epoch 7; iter: 200; batch classifier loss: 0.515600; batch adversarial loss: 0.583517\n",
      "epoch 7; iter: 400; batch classifier loss: 0.758785; batch adversarial loss: 0.617214\n",
      "epoch 8; iter: 0; batch classifier loss: 0.653008; batch adversarial loss: 0.504214\n",
      "epoch 8; iter: 200; batch classifier loss: 0.705990; batch adversarial loss: 0.617161\n",
      "epoch 8; iter: 400; batch classifier loss: 0.301564; batch adversarial loss: 0.614071\n",
      "epoch 9; iter: 0; batch classifier loss: 0.337682; batch adversarial loss: 0.601763\n",
      "epoch 9; iter: 200; batch classifier loss: 0.594770; batch adversarial loss: 0.653219\n",
      "epoch 9; iter: 400; batch classifier loss: 0.542993; batch adversarial loss: 0.567838\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461215; batch adversarial loss: 0.686049\n",
      "epoch 10; iter: 200; batch classifier loss: 0.264267; batch adversarial loss: 0.713930\n",
      "epoch 10; iter: 400; batch classifier loss: 0.337215; batch adversarial loss: 0.634221\n",
      "epoch 11; iter: 0; batch classifier loss: 0.513831; batch adversarial loss: 0.577231\n",
      "epoch 11; iter: 200; batch classifier loss: 0.576525; batch adversarial loss: 0.488248\n",
      "epoch 11; iter: 400; batch classifier loss: 0.320280; batch adversarial loss: 0.624782\n",
      "epoch 12; iter: 0; batch classifier loss: 0.540873; batch adversarial loss: 0.617362\n",
      "epoch 12; iter: 200; batch classifier loss: 0.371390; batch adversarial loss: 0.587181\n",
      "epoch 12; iter: 400; batch classifier loss: 0.293044; batch adversarial loss: 0.722846\n",
      "epoch 13; iter: 0; batch classifier loss: 0.265424; batch adversarial loss: 0.580001\n",
      "epoch 13; iter: 200; batch classifier loss: 0.294263; batch adversarial loss: 0.629983\n",
      "epoch 13; iter: 400; batch classifier loss: 0.454582; batch adversarial loss: 0.577068\n",
      "epoch 14; iter: 0; batch classifier loss: 0.235017; batch adversarial loss: 0.673781\n",
      "epoch 14; iter: 200; batch classifier loss: 0.319401; batch adversarial loss: 0.644963\n",
      "epoch 14; iter: 400; batch classifier loss: 0.285225; batch adversarial loss: 0.689250\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334199; batch adversarial loss: 0.647650\n",
      "epoch 15; iter: 200; batch classifier loss: 0.255351; batch adversarial loss: 0.625257\n",
      "epoch 15; iter: 400; batch classifier loss: 0.350190; batch adversarial loss: 0.647160\n",
      "epoch 16; iter: 0; batch classifier loss: 0.456546; batch adversarial loss: 0.690574\n",
      "epoch 16; iter: 200; batch classifier loss: 0.518667; batch adversarial loss: 0.577376\n",
      "epoch 16; iter: 400; batch classifier loss: 0.390187; batch adversarial loss: 0.604962\n",
      "epoch 17; iter: 0; batch classifier loss: 0.298683; batch adversarial loss: 0.649552\n",
      "epoch 17; iter: 200; batch classifier loss: 0.310325; batch adversarial loss: 0.574281\n",
      "epoch 17; iter: 400; batch classifier loss: 0.257397; batch adversarial loss: 0.628201\n",
      "epoch 18; iter: 0; batch classifier loss: 0.301541; batch adversarial loss: 0.564472\n",
      "epoch 18; iter: 200; batch classifier loss: 0.465386; batch adversarial loss: 0.641040\n",
      "epoch 18; iter: 400; batch classifier loss: 0.238451; batch adversarial loss: 0.631590\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344767; batch adversarial loss: 0.618330\n",
      "epoch 19; iter: 200; batch classifier loss: 0.533752; batch adversarial loss: 0.607886\n",
      "epoch 19; iter: 400; batch classifier loss: 0.572365; batch adversarial loss: 0.655380\n",
      "epoch 20; iter: 0; batch classifier loss: 0.280441; batch adversarial loss: 0.623525\n",
      "epoch 20; iter: 200; batch classifier loss: 0.317974; batch adversarial loss: 0.679120\n",
      "epoch 20; iter: 400; batch classifier loss: 0.380912; batch adversarial loss: 0.643982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387340; batch adversarial loss: 0.613924\n",
      "epoch 21; iter: 200; batch classifier loss: 0.378066; batch adversarial loss: 0.586368\n",
      "epoch 21; iter: 400; batch classifier loss: 0.495761; batch adversarial loss: 0.536869\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529847; batch adversarial loss: 0.543410\n",
      "epoch 22; iter: 200; batch classifier loss: 0.335218; batch adversarial loss: 0.591085\n",
      "epoch 22; iter: 400; batch classifier loss: 0.337184; batch adversarial loss: 0.670825\n",
      "epoch 23; iter: 0; batch classifier loss: 0.360016; batch adversarial loss: 0.595301\n",
      "epoch 23; iter: 200; batch classifier loss: 0.434947; batch adversarial loss: 0.652286\n",
      "epoch 23; iter: 400; batch classifier loss: 0.358604; batch adversarial loss: 0.578272\n",
      "epoch 24; iter: 0; batch classifier loss: 0.233575; batch adversarial loss: 0.573864\n",
      "epoch 24; iter: 200; batch classifier loss: 0.461090; batch adversarial loss: 0.597785\n",
      "epoch 24; iter: 400; batch classifier loss: 0.360639; batch adversarial loss: 0.697255\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438599; batch adversarial loss: 0.643897\n",
      "epoch 25; iter: 200; batch classifier loss: 0.469360; batch adversarial loss: 0.628935\n",
      "epoch 25; iter: 400; batch classifier loss: 0.487079; batch adversarial loss: 0.652456\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413735; batch adversarial loss: 0.538043\n",
      "epoch 26; iter: 200; batch classifier loss: 0.342483; batch adversarial loss: 0.593443\n",
      "epoch 26; iter: 400; batch classifier loss: 0.321809; batch adversarial loss: 0.703313\n",
      "epoch 27; iter: 0; batch classifier loss: 0.407936; batch adversarial loss: 0.728166\n",
      "epoch 27; iter: 200; batch classifier loss: 0.361861; batch adversarial loss: 0.584166\n",
      "epoch 27; iter: 400; batch classifier loss: 0.571762; batch adversarial loss: 0.604908\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481842; batch adversarial loss: 0.590764\n",
      "epoch 28; iter: 200; batch classifier loss: 0.520125; batch adversarial loss: 0.560948\n",
      "epoch 28; iter: 400; batch classifier loss: 0.317156; batch adversarial loss: 0.625701\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471510; batch adversarial loss: 0.606062\n",
      "epoch 29; iter: 200; batch classifier loss: 0.310926; batch adversarial loss: 0.570712\n",
      "epoch 29; iter: 400; batch classifier loss: 0.413253; batch adversarial loss: 0.532972\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315855; batch adversarial loss: 0.681642\n",
      "epoch 30; iter: 200; batch classifier loss: 0.697602; batch adversarial loss: 0.587960\n",
      "epoch 30; iter: 400; batch classifier loss: 0.735860; batch adversarial loss: 0.590698\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463858; batch adversarial loss: 0.651918\n",
      "epoch 31; iter: 200; batch classifier loss: 0.420517; batch adversarial loss: 0.589822\n",
      "epoch 31; iter: 400; batch classifier loss: 0.296695; batch adversarial loss: 0.652373\n",
      "epoch 32; iter: 0; batch classifier loss: 0.279666; batch adversarial loss: 0.601037\n",
      "epoch 32; iter: 200; batch classifier loss: 0.403839; batch adversarial loss: 0.621262\n",
      "epoch 32; iter: 400; batch classifier loss: 0.346264; batch adversarial loss: 0.582973\n",
      "epoch 33; iter: 0; batch classifier loss: 0.647067; batch adversarial loss: 0.566644\n",
      "epoch 33; iter: 200; batch classifier loss: 0.197180; batch adversarial loss: 0.625341\n",
      "epoch 33; iter: 400; batch classifier loss: 0.466772; batch adversarial loss: 0.579340\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468059; batch adversarial loss: 0.591779\n",
      "epoch 34; iter: 200; batch classifier loss: 0.425261; batch adversarial loss: 0.680562\n",
      "epoch 34; iter: 400; batch classifier loss: 0.317465; batch adversarial loss: 0.646563\n",
      "epoch 35; iter: 0; batch classifier loss: 0.470045; batch adversarial loss: 0.618510\n",
      "epoch 35; iter: 200; batch classifier loss: 0.481686; batch adversarial loss: 0.617511\n",
      "epoch 35; iter: 400; batch classifier loss: 0.312797; batch adversarial loss: 0.608113\n",
      "epoch 36; iter: 0; batch classifier loss: 0.250790; batch adversarial loss: 0.637839\n",
      "epoch 36; iter: 200; batch classifier loss: 0.557098; batch adversarial loss: 0.625798\n",
      "epoch 36; iter: 400; batch classifier loss: 0.493480; batch adversarial loss: 0.635353\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402611; batch adversarial loss: 0.699069\n",
      "epoch 37; iter: 200; batch classifier loss: 0.616624; batch adversarial loss: 0.600506\n",
      "epoch 37; iter: 400; batch classifier loss: 0.706373; batch adversarial loss: 0.607447\n",
      "epoch 38; iter: 0; batch classifier loss: 0.414175; batch adversarial loss: 0.675078\n",
      "epoch 38; iter: 200; batch classifier loss: 0.510387; batch adversarial loss: 0.610494\n",
      "epoch 38; iter: 400; batch classifier loss: 0.575070; batch adversarial loss: 0.636343\n",
      "epoch 39; iter: 0; batch classifier loss: 0.591840; batch adversarial loss: 0.613262\n",
      "epoch 39; iter: 200; batch classifier loss: 0.457196; batch adversarial loss: 0.591319\n",
      "epoch 39; iter: 400; batch classifier loss: 0.461892; batch adversarial loss: 0.624948\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423586; batch adversarial loss: 0.624538\n",
      "epoch 40; iter: 200; batch classifier loss: 0.367663; batch adversarial loss: 0.621361\n",
      "epoch 40; iter: 400; batch classifier loss: 0.674146; batch adversarial loss: 0.610872\n",
      "epoch 41; iter: 0; batch classifier loss: 0.517201; batch adversarial loss: 0.607361\n",
      "epoch 41; iter: 200; batch classifier loss: 0.456588; batch adversarial loss: 0.614946\n",
      "epoch 41; iter: 400; batch classifier loss: 0.509557; batch adversarial loss: 0.604393\n",
      "epoch 42; iter: 0; batch classifier loss: 0.606198; batch adversarial loss: 0.588905\n",
      "epoch 42; iter: 200; batch classifier loss: 0.455481; batch adversarial loss: 0.632419\n",
      "epoch 42; iter: 400; batch classifier loss: 0.476037; batch adversarial loss: 0.646095\n",
      "epoch 43; iter: 0; batch classifier loss: 0.505054; batch adversarial loss: 0.717119\n",
      "epoch 43; iter: 200; batch classifier loss: 0.426116; batch adversarial loss: 0.529045\n",
      "epoch 43; iter: 400; batch classifier loss: 0.528789; batch adversarial loss: 0.593426\n",
      "epoch 44; iter: 0; batch classifier loss: 0.341761; batch adversarial loss: 0.614460\n",
      "epoch 44; iter: 200; batch classifier loss: 0.543202; batch adversarial loss: 0.611789\n",
      "epoch 44; iter: 400; batch classifier loss: 0.533125; batch adversarial loss: 0.618935\n",
      "epoch 45; iter: 0; batch classifier loss: 0.582308; batch adversarial loss: 0.658597\n",
      "epoch 45; iter: 200; batch classifier loss: 0.423132; batch adversarial loss: 0.574412\n",
      "epoch 45; iter: 400; batch classifier loss: 0.402566; batch adversarial loss: 0.602349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.527152; batch adversarial loss: 0.697810\n",
      "epoch 46; iter: 200; batch classifier loss: 0.517473; batch adversarial loss: 0.665651\n",
      "epoch 46; iter: 400; batch classifier loss: 0.739944; batch adversarial loss: 0.604984\n",
      "epoch 47; iter: 0; batch classifier loss: 0.286027; batch adversarial loss: 0.619836\n",
      "epoch 47; iter: 200; batch classifier loss: 0.404533; batch adversarial loss: 0.628272\n",
      "epoch 47; iter: 400; batch classifier loss: 0.346178; batch adversarial loss: 0.642356\n",
      "epoch 48; iter: 0; batch classifier loss: 0.651221; batch adversarial loss: 0.593380\n",
      "epoch 48; iter: 200; batch classifier loss: 0.470866; batch adversarial loss: 0.654901\n",
      "epoch 48; iter: 400; batch classifier loss: 0.398407; batch adversarial loss: 0.631642\n",
      "epoch 49; iter: 0; batch classifier loss: 0.685966; batch adversarial loss: 0.608071\n",
      "epoch 49; iter: 200; batch classifier loss: 0.457766; batch adversarial loss: 0.630621\n",
      "epoch 49; iter: 400; batch classifier loss: 1.013231; batch adversarial loss: 0.670036\n",
      "epoch 0; iter: 0; batch classifier loss: 9.947202; batch adversarial loss: 0.719275\n",
      "epoch 0; iter: 200; batch classifier loss: 10.677108; batch adversarial loss: 0.653718\n",
      "epoch 0; iter: 400; batch classifier loss: 4.576022; batch adversarial loss: 0.601753\n",
      "epoch 1; iter: 0; batch classifier loss: 11.308794; batch adversarial loss: 0.613719\n",
      "epoch 1; iter: 200; batch classifier loss: 7.848076; batch adversarial loss: 0.706402\n",
      "epoch 1; iter: 400; batch classifier loss: 11.460556; batch adversarial loss: 0.633618\n",
      "epoch 2; iter: 0; batch classifier loss: 6.424778; batch adversarial loss: 0.707183\n",
      "epoch 2; iter: 200; batch classifier loss: 4.106064; batch adversarial loss: 0.623631\n",
      "epoch 2; iter: 400; batch classifier loss: 6.997394; batch adversarial loss: 0.629131\n",
      "epoch 3; iter: 0; batch classifier loss: 5.187466; batch adversarial loss: 0.607514\n",
      "epoch 3; iter: 200; batch classifier loss: 5.407338; batch adversarial loss: 0.603316\n",
      "epoch 3; iter: 400; batch classifier loss: 4.195010; batch adversarial loss: 0.572957\n",
      "epoch 4; iter: 0; batch classifier loss: 0.964947; batch adversarial loss: 0.644672\n",
      "epoch 4; iter: 200; batch classifier loss: 3.898736; batch adversarial loss: 0.637079\n",
      "epoch 4; iter: 400; batch classifier loss: 0.731777; batch adversarial loss: 0.621559\n",
      "epoch 5; iter: 0; batch classifier loss: 1.020638; batch adversarial loss: 0.603754\n",
      "epoch 5; iter: 200; batch classifier loss: 0.929301; batch adversarial loss: 0.534539\n",
      "epoch 5; iter: 400; batch classifier loss: 1.103534; batch adversarial loss: 0.577249\n",
      "epoch 6; iter: 0; batch classifier loss: 0.826983; batch adversarial loss: 0.582563\n",
      "epoch 6; iter: 200; batch classifier loss: 0.309889; batch adversarial loss: 0.675755\n",
      "epoch 6; iter: 400; batch classifier loss: 0.575430; batch adversarial loss: 0.667893\n",
      "epoch 7; iter: 0; batch classifier loss: 0.638251; batch adversarial loss: 0.671705\n",
      "epoch 7; iter: 200; batch classifier loss: 0.351628; batch adversarial loss: 0.684239\n",
      "epoch 7; iter: 400; batch classifier loss: 0.512994; batch adversarial loss: 0.588729\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476569; batch adversarial loss: 0.632444\n",
      "epoch 8; iter: 200; batch classifier loss: 0.450037; batch adversarial loss: 0.628668\n",
      "epoch 8; iter: 400; batch classifier loss: 0.502928; batch adversarial loss: 0.593798\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513347; batch adversarial loss: 0.521259\n",
      "epoch 9; iter: 200; batch classifier loss: 0.341899; batch adversarial loss: 0.654891\n",
      "epoch 9; iter: 400; batch classifier loss: 0.317833; batch adversarial loss: 0.544282\n",
      "epoch 10; iter: 0; batch classifier loss: 0.387526; batch adversarial loss: 0.671980\n",
      "epoch 10; iter: 200; batch classifier loss: 0.363538; batch adversarial loss: 0.608373\n",
      "epoch 10; iter: 400; batch classifier loss: 0.314670; batch adversarial loss: 0.600319\n",
      "epoch 11; iter: 0; batch classifier loss: 0.454495; batch adversarial loss: 0.647685\n",
      "epoch 11; iter: 200; batch classifier loss: 0.311977; batch adversarial loss: 0.636900\n",
      "epoch 11; iter: 400; batch classifier loss: 0.396170; batch adversarial loss: 0.598954\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325818; batch adversarial loss: 0.647595\n",
      "epoch 12; iter: 200; batch classifier loss: 0.314514; batch adversarial loss: 0.617285\n",
      "epoch 12; iter: 400; batch classifier loss: 0.345022; batch adversarial loss: 0.664458\n",
      "epoch 13; iter: 0; batch classifier loss: 0.364276; batch adversarial loss: 0.643793\n",
      "epoch 13; iter: 200; batch classifier loss: 0.366894; batch adversarial loss: 0.617562\n",
      "epoch 13; iter: 400; batch classifier loss: 0.363168; batch adversarial loss: 0.607820\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352493; batch adversarial loss: 0.684504\n",
      "epoch 14; iter: 200; batch classifier loss: 0.334860; batch adversarial loss: 0.698119\n",
      "epoch 14; iter: 400; batch classifier loss: 0.449245; batch adversarial loss: 0.629493\n",
      "epoch 15; iter: 0; batch classifier loss: 0.341644; batch adversarial loss: 0.601308\n",
      "epoch 15; iter: 200; batch classifier loss: 0.332192; batch adversarial loss: 0.584358\n",
      "epoch 15; iter: 400; batch classifier loss: 0.238071; batch adversarial loss: 0.646019\n",
      "epoch 16; iter: 0; batch classifier loss: 0.432847; batch adversarial loss: 0.675895\n",
      "epoch 16; iter: 200; batch classifier loss: 0.427271; batch adversarial loss: 0.671329\n",
      "epoch 16; iter: 400; batch classifier loss: 0.510432; batch adversarial loss: 0.631790\n",
      "epoch 17; iter: 0; batch classifier loss: 0.328486; batch adversarial loss: 0.549358\n",
      "epoch 17; iter: 200; batch classifier loss: 0.415780; batch adversarial loss: 0.571644\n",
      "epoch 17; iter: 400; batch classifier loss: 0.226619; batch adversarial loss: 0.703766\n",
      "epoch 18; iter: 0; batch classifier loss: 0.340089; batch adversarial loss: 0.701064\n",
      "epoch 18; iter: 200; batch classifier loss: 0.322577; batch adversarial loss: 0.650578\n",
      "epoch 18; iter: 400; batch classifier loss: 0.472012; batch adversarial loss: 0.636477\n",
      "epoch 19; iter: 0; batch classifier loss: 0.386677; batch adversarial loss: 0.615007\n",
      "epoch 19; iter: 200; batch classifier loss: 0.426098; batch adversarial loss: 0.628610\n",
      "epoch 19; iter: 400; batch classifier loss: 0.437879; batch adversarial loss: 0.665777\n",
      "epoch 20; iter: 0; batch classifier loss: 0.331858; batch adversarial loss: 0.702139\n",
      "epoch 20; iter: 200; batch classifier loss: 0.257304; batch adversarial loss: 0.554806\n",
      "epoch 20; iter: 400; batch classifier loss: 0.364456; batch adversarial loss: 0.686556\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291136; batch adversarial loss: 0.540029\n",
      "epoch 21; iter: 200; batch classifier loss: 0.266635; batch adversarial loss: 0.623709\n",
      "epoch 21; iter: 400; batch classifier loss: 0.353163; batch adversarial loss: 0.681312\n",
      "epoch 22; iter: 0; batch classifier loss: 0.500077; batch adversarial loss: 0.606127\n",
      "epoch 22; iter: 200; batch classifier loss: 0.292661; batch adversarial loss: 0.625527\n",
      "epoch 22; iter: 400; batch classifier loss: 0.365118; batch adversarial loss: 0.658116\n",
      "epoch 23; iter: 0; batch classifier loss: 0.521903; batch adversarial loss: 0.642843\n",
      "epoch 23; iter: 200; batch classifier loss: 0.510777; batch adversarial loss: 0.612248\n",
      "epoch 23; iter: 400; batch classifier loss: 0.334468; batch adversarial loss: 0.670579\n",
      "epoch 24; iter: 0; batch classifier loss: 0.521864; batch adversarial loss: 0.547063\n",
      "epoch 24; iter: 200; batch classifier loss: 0.396490; batch adversarial loss: 0.608629\n",
      "epoch 24; iter: 400; batch classifier loss: 0.820338; batch adversarial loss: 0.597612\n",
      "epoch 25; iter: 0; batch classifier loss: 0.617763; batch adversarial loss: 0.549004\n",
      "epoch 25; iter: 200; batch classifier loss: 0.201406; batch adversarial loss: 0.685705\n",
      "epoch 25; iter: 400; batch classifier loss: 0.476075; batch adversarial loss: 0.689461\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424038; batch adversarial loss: 0.575795\n",
      "epoch 26; iter: 200; batch classifier loss: 0.385024; batch adversarial loss: 0.636095\n",
      "epoch 26; iter: 400; batch classifier loss: 0.432030; batch adversarial loss: 0.600484\n",
      "epoch 27; iter: 0; batch classifier loss: 0.203466; batch adversarial loss: 0.633218\n",
      "epoch 27; iter: 200; batch classifier loss: 0.403721; batch adversarial loss: 0.597181\n",
      "epoch 27; iter: 400; batch classifier loss: 0.340227; batch adversarial loss: 0.662482\n",
      "epoch 28; iter: 0; batch classifier loss: 0.364322; batch adversarial loss: 0.658298\n",
      "epoch 28; iter: 200; batch classifier loss: 0.300915; batch adversarial loss: 0.673702\n",
      "epoch 28; iter: 400; batch classifier loss: 0.547682; batch adversarial loss: 0.668943\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462545; batch adversarial loss: 0.660577\n",
      "epoch 29; iter: 200; batch classifier loss: 0.498371; batch adversarial loss: 0.576703\n",
      "epoch 29; iter: 400; batch classifier loss: 0.497614; batch adversarial loss: 0.552863\n",
      "epoch 30; iter: 0; batch classifier loss: 0.421400; batch adversarial loss: 0.633141\n",
      "epoch 30; iter: 200; batch classifier loss: 0.379501; batch adversarial loss: 0.608497\n",
      "epoch 30; iter: 400; batch classifier loss: 0.600147; batch adversarial loss: 0.614737\n",
      "epoch 31; iter: 0; batch classifier loss: 0.509828; batch adversarial loss: 0.587673\n",
      "epoch 31; iter: 200; batch classifier loss: 0.370924; batch adversarial loss: 0.613784\n",
      "epoch 31; iter: 400; batch classifier loss: 0.535093; batch adversarial loss: 0.684774\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421758; batch adversarial loss: 0.606417\n",
      "epoch 32; iter: 200; batch classifier loss: 0.467110; batch adversarial loss: 0.578634\n",
      "epoch 32; iter: 400; batch classifier loss: 0.460869; batch adversarial loss: 0.584934\n",
      "epoch 33; iter: 0; batch classifier loss: 0.537643; batch adversarial loss: 0.549260\n",
      "epoch 33; iter: 200; batch classifier loss: 0.449389; batch adversarial loss: 0.619768\n",
      "epoch 33; iter: 400; batch classifier loss: 0.317075; batch adversarial loss: 0.649416\n",
      "epoch 34; iter: 0; batch classifier loss: 0.438182; batch adversarial loss: 0.638541\n",
      "epoch 34; iter: 200; batch classifier loss: 0.480655; batch adversarial loss: 0.652789\n",
      "epoch 34; iter: 400; batch classifier loss: 0.509668; batch adversarial loss: 0.633262\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254497; batch adversarial loss: 0.700716\n",
      "epoch 35; iter: 200; batch classifier loss: 0.413872; batch adversarial loss: 0.559222\n",
      "epoch 35; iter: 400; batch classifier loss: 0.424501; batch adversarial loss: 0.614307\n",
      "epoch 36; iter: 0; batch classifier loss: 0.480833; batch adversarial loss: 0.629555\n",
      "epoch 36; iter: 200; batch classifier loss: 1.664982; batch adversarial loss: 0.567355\n",
      "epoch 36; iter: 400; batch classifier loss: 0.556902; batch adversarial loss: 0.602262\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489660; batch adversarial loss: 0.604306\n",
      "epoch 37; iter: 200; batch classifier loss: 0.467333; batch adversarial loss: 0.550161\n",
      "epoch 37; iter: 400; batch classifier loss: 0.378962; batch adversarial loss: 0.623197\n",
      "epoch 38; iter: 0; batch classifier loss: 0.527482; batch adversarial loss: 0.542178\n",
      "epoch 38; iter: 200; batch classifier loss: 0.266845; batch adversarial loss: 0.662762\n",
      "epoch 38; iter: 400; batch classifier loss: 0.469465; batch adversarial loss: 0.623139\n",
      "epoch 39; iter: 0; batch classifier loss: 0.556212; batch adversarial loss: 0.585199\n",
      "epoch 39; iter: 200; batch classifier loss: 0.697368; batch adversarial loss: 0.686441\n",
      "epoch 39; iter: 400; batch classifier loss: 0.385587; batch adversarial loss: 0.579617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.465882; batch adversarial loss: 0.627574\n",
      "epoch 40; iter: 200; batch classifier loss: 0.589732; batch adversarial loss: 0.701052\n",
      "epoch 40; iter: 400; batch classifier loss: 0.414918; batch adversarial loss: 0.619721\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466230; batch adversarial loss: 0.534598\n",
      "epoch 41; iter: 200; batch classifier loss: 0.570054; batch adversarial loss: 0.668611\n",
      "epoch 41; iter: 400; batch classifier loss: 0.488790; batch adversarial loss: 0.573729\n",
      "epoch 42; iter: 0; batch classifier loss: 1.427513; batch adversarial loss: 0.649986\n",
      "epoch 42; iter: 200; batch classifier loss: 0.500162; batch adversarial loss: 0.637700\n",
      "epoch 42; iter: 400; batch classifier loss: 0.501893; batch adversarial loss: 0.571202\n",
      "epoch 43; iter: 0; batch classifier loss: 0.551539; batch adversarial loss: 0.578059\n",
      "epoch 43; iter: 200; batch classifier loss: 0.444526; batch adversarial loss: 0.607847\n",
      "epoch 43; iter: 400; batch classifier loss: 0.291844; batch adversarial loss: 0.672899\n",
      "epoch 44; iter: 0; batch classifier loss: 0.677714; batch adversarial loss: 0.589642\n",
      "epoch 44; iter: 200; batch classifier loss: 0.512253; batch adversarial loss: 0.657232\n",
      "epoch 44; iter: 400; batch classifier loss: 0.665963; batch adversarial loss: 0.598231\n",
      "epoch 45; iter: 0; batch classifier loss: 0.596498; batch adversarial loss: 0.556359\n",
      "epoch 45; iter: 200; batch classifier loss: 0.301462; batch adversarial loss: 0.699795\n",
      "epoch 45; iter: 400; batch classifier loss: 0.596129; batch adversarial loss: 0.600468\n",
      "epoch 46; iter: 0; batch classifier loss: 0.463421; batch adversarial loss: 0.534729\n",
      "epoch 46; iter: 200; batch classifier loss: 0.485706; batch adversarial loss: 0.619887\n",
      "epoch 46; iter: 400; batch classifier loss: 0.697197; batch adversarial loss: 0.622050\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520704; batch adversarial loss: 0.670590\n",
      "epoch 47; iter: 200; batch classifier loss: 0.327930; batch adversarial loss: 0.658933\n",
      "epoch 47; iter: 400; batch classifier loss: 0.249694; batch adversarial loss: 0.700321\n",
      "epoch 48; iter: 0; batch classifier loss: 0.213997; batch adversarial loss: 0.617348\n",
      "epoch 48; iter: 200; batch classifier loss: 0.782445; batch adversarial loss: 0.643357\n",
      "epoch 48; iter: 400; batch classifier loss: 0.353904; batch adversarial loss: 0.627058\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403522; batch adversarial loss: 0.581652\n",
      "epoch 49; iter: 200; batch classifier loss: 0.456772; batch adversarial loss: 0.571460\n",
      "epoch 49; iter: 400; batch classifier loss: 0.229686; batch adversarial loss: 0.583382\n",
      "epoch 0; iter: 0; batch classifier loss: 1.170267; batch adversarial loss: 0.684493\n",
      "epoch 0; iter: 200; batch classifier loss: 7.672609; batch adversarial loss: 0.661593\n",
      "epoch 0; iter: 400; batch classifier loss: 3.953308; batch adversarial loss: 0.696702\n",
      "epoch 1; iter: 0; batch classifier loss: 25.248873; batch adversarial loss: 0.660118\n",
      "epoch 1; iter: 200; batch classifier loss: 9.917849; batch adversarial loss: 0.690270\n",
      "epoch 1; iter: 400; batch classifier loss: 8.757279; batch adversarial loss: 0.615074\n",
      "epoch 2; iter: 0; batch classifier loss: 6.767877; batch adversarial loss: 0.599123\n",
      "epoch 2; iter: 200; batch classifier loss: 3.531381; batch adversarial loss: 0.631808\n",
      "epoch 2; iter: 400; batch classifier loss: 3.420807; batch adversarial loss: 0.606014\n",
      "epoch 3; iter: 0; batch classifier loss: 4.250649; batch adversarial loss: 0.582250\n",
      "epoch 3; iter: 200; batch classifier loss: 2.407883; batch adversarial loss: 0.624851\n",
      "epoch 3; iter: 400; batch classifier loss: 6.170085; batch adversarial loss: 0.594298\n",
      "epoch 4; iter: 0; batch classifier loss: 2.105939; batch adversarial loss: 0.654485\n",
      "epoch 4; iter: 200; batch classifier loss: 0.775139; batch adversarial loss: 0.621197\n",
      "epoch 4; iter: 400; batch classifier loss: 0.572838; batch adversarial loss: 0.574500\n",
      "epoch 5; iter: 0; batch classifier loss: 0.852210; batch adversarial loss: 0.593546\n",
      "epoch 5; iter: 200; batch classifier loss: 0.705539; batch adversarial loss: 0.585413\n",
      "epoch 5; iter: 400; batch classifier loss: 0.518405; batch adversarial loss: 0.582479\n",
      "epoch 6; iter: 0; batch classifier loss: 0.960113; batch adversarial loss: 0.688571\n",
      "epoch 6; iter: 200; batch classifier loss: 0.467579; batch adversarial loss: 0.692663\n",
      "epoch 6; iter: 400; batch classifier loss: 0.474208; batch adversarial loss: 0.558946\n",
      "epoch 7; iter: 0; batch classifier loss: 0.610470; batch adversarial loss: 0.680208\n",
      "epoch 7; iter: 200; batch classifier loss: 0.457186; batch adversarial loss: 0.596007\n",
      "epoch 7; iter: 400; batch classifier loss: 0.423852; batch adversarial loss: 0.727512\n",
      "epoch 8; iter: 0; batch classifier loss: 0.772902; batch adversarial loss: 0.688525\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401760; batch adversarial loss: 0.549926\n",
      "epoch 8; iter: 400; batch classifier loss: 0.302235; batch adversarial loss: 0.592921\n",
      "epoch 9; iter: 0; batch classifier loss: 0.279142; batch adversarial loss: 0.616793\n",
      "epoch 9; iter: 200; batch classifier loss: 0.443322; batch adversarial loss: 0.751146\n",
      "epoch 9; iter: 400; batch classifier loss: 0.400215; batch adversarial loss: 0.613688\n",
      "epoch 10; iter: 0; batch classifier loss: 0.315247; batch adversarial loss: 0.603108\n",
      "epoch 10; iter: 200; batch classifier loss: 0.303429; batch adversarial loss: 0.611190\n",
      "epoch 10; iter: 400; batch classifier loss: 0.496302; batch adversarial loss: 0.680765\n",
      "epoch 11; iter: 0; batch classifier loss: 0.471479; batch adversarial loss: 0.587008\n",
      "epoch 11; iter: 200; batch classifier loss: 0.394306; batch adversarial loss: 0.663855\n",
      "epoch 11; iter: 400; batch classifier loss: 0.332893; batch adversarial loss: 0.614478\n",
      "epoch 12; iter: 0; batch classifier loss: 0.384294; batch adversarial loss: 0.581009\n",
      "epoch 12; iter: 200; batch classifier loss: 0.329672; batch adversarial loss: 0.571497\n",
      "epoch 12; iter: 400; batch classifier loss: 0.302885; batch adversarial loss: 0.582847\n",
      "epoch 13; iter: 0; batch classifier loss: 0.307139; batch adversarial loss: 0.630629\n",
      "epoch 13; iter: 200; batch classifier loss: 0.466729; batch adversarial loss: 0.621120\n",
      "epoch 13; iter: 400; batch classifier loss: 0.408931; batch adversarial loss: 0.600171\n",
      "epoch 14; iter: 0; batch classifier loss: 0.229259; batch adversarial loss: 0.633405\n",
      "epoch 14; iter: 200; batch classifier loss: 0.314255; batch adversarial loss: 0.647561\n",
      "epoch 14; iter: 400; batch classifier loss: 0.296689; batch adversarial loss: 0.651932\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391171; batch adversarial loss: 0.621751\n",
      "epoch 15; iter: 200; batch classifier loss: 0.201680; batch adversarial loss: 0.621555\n",
      "epoch 15; iter: 400; batch classifier loss: 0.319396; batch adversarial loss: 0.682920\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337586; batch adversarial loss: 0.615255\n",
      "epoch 16; iter: 200; batch classifier loss: 0.409674; batch adversarial loss: 0.636271\n",
      "epoch 16; iter: 400; batch classifier loss: 0.261070; batch adversarial loss: 0.632421\n",
      "epoch 17; iter: 0; batch classifier loss: 0.326747; batch adversarial loss: 0.615976\n",
      "epoch 17; iter: 200; batch classifier loss: 0.420051; batch adversarial loss: 0.621743\n",
      "epoch 17; iter: 400; batch classifier loss: 0.444991; batch adversarial loss: 0.546713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452761; batch adversarial loss: 0.627115\n",
      "epoch 18; iter: 200; batch classifier loss: 0.424629; batch adversarial loss: 0.582452\n",
      "epoch 18; iter: 400; batch classifier loss: 0.388449; batch adversarial loss: 0.646985\n",
      "epoch 19; iter: 0; batch classifier loss: 0.286176; batch adversarial loss: 0.607542\n",
      "epoch 19; iter: 200; batch classifier loss: 0.328247; batch adversarial loss: 0.605233\n",
      "epoch 19; iter: 400; batch classifier loss: 0.333956; batch adversarial loss: 0.616839\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295777; batch adversarial loss: 0.635540\n",
      "epoch 20; iter: 200; batch classifier loss: 0.869768; batch adversarial loss: 0.656164\n",
      "epoch 20; iter: 400; batch classifier loss: 0.414327; batch adversarial loss: 0.571044\n",
      "epoch 21; iter: 0; batch classifier loss: 0.255361; batch adversarial loss: 0.575881\n",
      "epoch 21; iter: 200; batch classifier loss: 0.416095; batch adversarial loss: 0.665725\n",
      "epoch 21; iter: 400; batch classifier loss: 0.311095; batch adversarial loss: 0.616811\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415699; batch adversarial loss: 0.557501\n",
      "epoch 22; iter: 200; batch classifier loss: 0.509986; batch adversarial loss: 0.681691\n",
      "epoch 22; iter: 400; batch classifier loss: 0.385472; batch adversarial loss: 0.618380\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414480; batch adversarial loss: 0.601516\n",
      "epoch 23; iter: 200; batch classifier loss: 0.770459; batch adversarial loss: 0.603578\n",
      "epoch 23; iter: 400; batch classifier loss: 0.371012; batch adversarial loss: 0.645687\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422318; batch adversarial loss: 0.570990\n",
      "epoch 24; iter: 200; batch classifier loss: 0.432364; batch adversarial loss: 0.596267\n",
      "epoch 24; iter: 400; batch classifier loss: 0.323745; batch adversarial loss: 0.712543\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402996; batch adversarial loss: 0.642480\n",
      "epoch 25; iter: 200; batch classifier loss: 0.283000; batch adversarial loss: 0.650656\n",
      "epoch 25; iter: 400; batch classifier loss: 0.335931; batch adversarial loss: 0.627225\n",
      "epoch 26; iter: 0; batch classifier loss: 0.610941; batch adversarial loss: 0.572581\n",
      "epoch 26; iter: 200; batch classifier loss: 0.674776; batch adversarial loss: 0.530451\n",
      "epoch 26; iter: 400; batch classifier loss: 0.573631; batch adversarial loss: 0.549276\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538760; batch adversarial loss: 0.679643\n",
      "epoch 27; iter: 200; batch classifier loss: 0.403967; batch adversarial loss: 0.623004\n",
      "epoch 27; iter: 400; batch classifier loss: 0.416232; batch adversarial loss: 0.624617\n",
      "epoch 28; iter: 0; batch classifier loss: 0.741282; batch adversarial loss: 0.674013\n",
      "epoch 28; iter: 200; batch classifier loss: 0.509436; batch adversarial loss: 0.652585\n",
      "epoch 28; iter: 400; batch classifier loss: 0.492916; batch adversarial loss: 0.645622\n",
      "epoch 29; iter: 0; batch classifier loss: 0.534792; batch adversarial loss: 0.521739\n",
      "epoch 29; iter: 200; batch classifier loss: 0.485784; batch adversarial loss: 0.681183\n",
      "epoch 29; iter: 400; batch classifier loss: 0.427461; batch adversarial loss: 0.609824\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463574; batch adversarial loss: 0.596479\n",
      "epoch 30; iter: 200; batch classifier loss: 0.633610; batch adversarial loss: 0.610570\n",
      "epoch 30; iter: 400; batch classifier loss: 0.516334; batch adversarial loss: 0.652176\n",
      "epoch 31; iter: 0; batch classifier loss: 0.547583; batch adversarial loss: 0.586795\n",
      "epoch 31; iter: 200; batch classifier loss: 0.319673; batch adversarial loss: 0.699025\n",
      "epoch 31; iter: 400; batch classifier loss: 0.542799; batch adversarial loss: 0.601969\n",
      "epoch 32; iter: 0; batch classifier loss: 0.637194; batch adversarial loss: 0.611879\n",
      "epoch 32; iter: 200; batch classifier loss: 0.296957; batch adversarial loss: 0.681315\n",
      "epoch 32; iter: 400; batch classifier loss: 0.473637; batch adversarial loss: 0.687749\n",
      "epoch 33; iter: 0; batch classifier loss: 0.518976; batch adversarial loss: 0.688109\n",
      "epoch 33; iter: 200; batch classifier loss: 0.534903; batch adversarial loss: 0.602560\n",
      "epoch 33; iter: 400; batch classifier loss: 0.555198; batch adversarial loss: 0.641804\n",
      "epoch 34; iter: 0; batch classifier loss: 0.278346; batch adversarial loss: 0.626469\n",
      "epoch 34; iter: 200; batch classifier loss: 0.314110; batch adversarial loss: 0.617971\n",
      "epoch 34; iter: 400; batch classifier loss: 0.654849; batch adversarial loss: 0.566793\n",
      "epoch 35; iter: 0; batch classifier loss: 0.434070; batch adversarial loss: 0.620814\n",
      "epoch 35; iter: 200; batch classifier loss: 0.282466; batch adversarial loss: 0.637780\n",
      "epoch 35; iter: 400; batch classifier loss: 0.507128; batch adversarial loss: 0.659400\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401952; batch adversarial loss: 0.586246\n",
      "epoch 36; iter: 200; batch classifier loss: 0.325546; batch adversarial loss: 0.611657\n",
      "epoch 36; iter: 400; batch classifier loss: 0.420472; batch adversarial loss: 0.627674\n",
      "epoch 37; iter: 0; batch classifier loss: 0.347322; batch adversarial loss: 0.624181\n",
      "epoch 37; iter: 200; batch classifier loss: 0.566809; batch adversarial loss: 0.621644\n",
      "epoch 37; iter: 400; batch classifier loss: 0.374582; batch adversarial loss: 0.664944\n",
      "epoch 38; iter: 0; batch classifier loss: 0.486065; batch adversarial loss: 0.547387\n",
      "epoch 38; iter: 200; batch classifier loss: 0.240099; batch adversarial loss: 0.611028\n",
      "epoch 38; iter: 400; batch classifier loss: 0.419623; batch adversarial loss: 0.581171\n",
      "epoch 39; iter: 0; batch classifier loss: 0.578080; batch adversarial loss: 0.587303\n",
      "epoch 39; iter: 200; batch classifier loss: 0.358572; batch adversarial loss: 0.653734\n",
      "epoch 39; iter: 400; batch classifier loss: 0.467887; batch adversarial loss: 0.642612\n",
      "epoch 40; iter: 0; batch classifier loss: 0.660713; batch adversarial loss: 0.611335\n",
      "epoch 40; iter: 200; batch classifier loss: 0.210941; batch adversarial loss: 0.588522\n",
      "epoch 40; iter: 400; batch classifier loss: 0.681058; batch adversarial loss: 0.627975\n",
      "epoch 41; iter: 0; batch classifier loss: 0.624442; batch adversarial loss: 0.628176\n",
      "epoch 41; iter: 200; batch classifier loss: 0.419340; batch adversarial loss: 0.661382\n",
      "epoch 41; iter: 400; batch classifier loss: 0.539798; batch adversarial loss: 0.594922\n",
      "epoch 42; iter: 0; batch classifier loss: 0.327811; batch adversarial loss: 0.702919\n",
      "epoch 42; iter: 200; batch classifier loss: 0.500664; batch adversarial loss: 0.708582\n",
      "epoch 42; iter: 400; batch classifier loss: 0.234632; batch adversarial loss: 0.712768\n",
      "epoch 43; iter: 0; batch classifier loss: 0.523961; batch adversarial loss: 0.666230\n",
      "epoch 43; iter: 200; batch classifier loss: 0.622969; batch adversarial loss: 0.575217\n",
      "epoch 43; iter: 400; batch classifier loss: 0.520610; batch adversarial loss: 0.653111\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406048; batch adversarial loss: 0.655670\n",
      "epoch 44; iter: 200; batch classifier loss: 0.768727; batch adversarial loss: 0.636913\n",
      "epoch 44; iter: 400; batch classifier loss: 0.384334; batch adversarial loss: 0.643136\n",
      "epoch 45; iter: 0; batch classifier loss: 0.326989; batch adversarial loss: 0.723218\n",
      "epoch 45; iter: 200; batch classifier loss: 0.404480; batch adversarial loss: 0.654592\n",
      "epoch 45; iter: 400; batch classifier loss: 0.243429; batch adversarial loss: 0.682949\n",
      "epoch 46; iter: 0; batch classifier loss: 0.306659; batch adversarial loss: 0.647557\n",
      "epoch 46; iter: 200; batch classifier loss: 0.626848; batch adversarial loss: 0.652875\n",
      "epoch 46; iter: 400; batch classifier loss: 0.323771; batch adversarial loss: 0.660715\n",
      "epoch 47; iter: 0; batch classifier loss: 0.484202; batch adversarial loss: 0.695759\n",
      "epoch 47; iter: 200; batch classifier loss: 0.655396; batch adversarial loss: 0.559815\n",
      "epoch 47; iter: 400; batch classifier loss: 0.539072; batch adversarial loss: 0.662946\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375070; batch adversarial loss: 0.622656\n",
      "epoch 48; iter: 200; batch classifier loss: 0.585725; batch adversarial loss: 0.555050\n",
      "epoch 48; iter: 400; batch classifier loss: 0.682710; batch adversarial loss: 0.633825\n",
      "epoch 49; iter: 0; batch classifier loss: 0.550546; batch adversarial loss: 0.647194\n",
      "epoch 49; iter: 200; batch classifier loss: 0.878618; batch adversarial loss: 0.616653\n",
      "epoch 49; iter: 400; batch classifier loss: 0.341958; batch adversarial loss: 0.662877\n",
      "epoch 0; iter: 0; batch classifier loss: 27.184599; batch adversarial loss: 0.740371\n",
      "epoch 0; iter: 200; batch classifier loss: 57.501881; batch adversarial loss: 0.717614\n",
      "epoch 0; iter: 400; batch classifier loss: 1.102018; batch adversarial loss: 0.707228\n",
      "epoch 1; iter: 0; batch classifier loss: 6.413258; batch adversarial loss: 0.694797\n",
      "epoch 1; iter: 200; batch classifier loss: 17.442053; batch adversarial loss: 0.623003\n",
      "epoch 1; iter: 400; batch classifier loss: 9.610000; batch adversarial loss: 0.615637\n",
      "epoch 2; iter: 0; batch classifier loss: 2.007986; batch adversarial loss: 0.648149\n",
      "epoch 2; iter: 200; batch classifier loss: 36.704975; batch adversarial loss: 0.596690\n",
      "epoch 2; iter: 400; batch classifier loss: 0.530556; batch adversarial loss: 0.624124\n",
      "epoch 3; iter: 0; batch classifier loss: 3.854214; batch adversarial loss: 0.546536\n",
      "epoch 3; iter: 200; batch classifier loss: 5.164012; batch adversarial loss: 0.508561\n",
      "epoch 3; iter: 400; batch classifier loss: 4.960412; batch adversarial loss: 0.610334\n",
      "epoch 4; iter: 0; batch classifier loss: 1.653762; batch adversarial loss: 0.589481\n",
      "epoch 4; iter: 200; batch classifier loss: 4.421685; batch adversarial loss: 0.546986\n",
      "epoch 4; iter: 400; batch classifier loss: 0.401667; batch adversarial loss: 0.689198\n",
      "epoch 5; iter: 0; batch classifier loss: 0.732111; batch adversarial loss: 0.632061\n",
      "epoch 5; iter: 200; batch classifier loss: 1.274579; batch adversarial loss: 0.678108\n",
      "epoch 5; iter: 400; batch classifier loss: 0.513744; batch adversarial loss: 0.601531\n",
      "epoch 6; iter: 0; batch classifier loss: 2.924420; batch adversarial loss: 0.537385\n",
      "epoch 6; iter: 200; batch classifier loss: 1.315660; batch adversarial loss: 0.673660\n",
      "epoch 6; iter: 400; batch classifier loss: 0.618442; batch adversarial loss: 0.610274\n",
      "epoch 7; iter: 0; batch classifier loss: 0.731670; batch adversarial loss: 0.581340\n",
      "epoch 7; iter: 200; batch classifier loss: 0.395349; batch adversarial loss: 0.560938\n",
      "epoch 7; iter: 400; batch classifier loss: 0.498413; batch adversarial loss: 0.599456\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435034; batch adversarial loss: 0.664391\n",
      "epoch 8; iter: 200; batch classifier loss: 0.364455; batch adversarial loss: 0.630180\n",
      "epoch 8; iter: 400; batch classifier loss: 0.470920; batch adversarial loss: 0.553458\n",
      "epoch 9; iter: 0; batch classifier loss: 0.663210; batch adversarial loss: 0.672183\n",
      "epoch 9; iter: 200; batch classifier loss: 0.706600; batch adversarial loss: 0.669946\n",
      "epoch 9; iter: 400; batch classifier loss: 0.418969; batch adversarial loss: 0.581910\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363227; batch adversarial loss: 0.662794\n",
      "epoch 10; iter: 200; batch classifier loss: 0.256298; batch adversarial loss: 0.699833\n",
      "epoch 10; iter: 400; batch classifier loss: 0.636290; batch adversarial loss: 0.641200\n",
      "epoch 11; iter: 0; batch classifier loss: 0.418014; batch adversarial loss: 0.615112\n",
      "epoch 11; iter: 200; batch classifier loss: 0.576457; batch adversarial loss: 0.617697\n",
      "epoch 11; iter: 400; batch classifier loss: 0.222870; batch adversarial loss: 0.631556\n",
      "epoch 12; iter: 0; batch classifier loss: 0.462306; batch adversarial loss: 0.549824\n",
      "epoch 12; iter: 200; batch classifier loss: 0.420694; batch adversarial loss: 0.646698\n",
      "epoch 12; iter: 400; batch classifier loss: 0.517155; batch adversarial loss: 0.583611\n",
      "epoch 13; iter: 0; batch classifier loss: 0.266940; batch adversarial loss: 0.685172\n",
      "epoch 13; iter: 200; batch classifier loss: 0.507799; batch adversarial loss: 0.612182\n",
      "epoch 13; iter: 400; batch classifier loss: 0.342735; batch adversarial loss: 0.565552\n",
      "epoch 14; iter: 0; batch classifier loss: 0.376793; batch adversarial loss: 0.551331\n",
      "epoch 14; iter: 200; batch classifier loss: 0.381095; batch adversarial loss: 0.637879\n",
      "epoch 14; iter: 400; batch classifier loss: 0.320122; batch adversarial loss: 0.680252\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373851; batch adversarial loss: 0.715895\n",
      "epoch 15; iter: 200; batch classifier loss: 0.437720; batch adversarial loss: 0.618363\n",
      "epoch 15; iter: 400; batch classifier loss: 0.247954; batch adversarial loss: 0.586253\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363876; batch adversarial loss: 0.577130\n",
      "epoch 16; iter: 200; batch classifier loss: 0.243230; batch adversarial loss: 0.611343\n",
      "epoch 16; iter: 400; batch classifier loss: 0.405542; batch adversarial loss: 0.638858\n",
      "epoch 17; iter: 0; batch classifier loss: 0.285053; batch adversarial loss: 0.651115\n",
      "epoch 17; iter: 200; batch classifier loss: 0.362652; batch adversarial loss: 0.702937\n",
      "epoch 17; iter: 400; batch classifier loss: 0.324869; batch adversarial loss: 0.610068\n",
      "epoch 18; iter: 0; batch classifier loss: 0.415302; batch adversarial loss: 0.630585\n",
      "epoch 18; iter: 200; batch classifier loss: 0.551220; batch adversarial loss: 0.602317\n",
      "epoch 18; iter: 400; batch classifier loss: 0.373392; batch adversarial loss: 0.670799\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484279; batch adversarial loss: 0.763042\n",
      "epoch 19; iter: 200; batch classifier loss: 0.289863; batch adversarial loss: 0.591303\n",
      "epoch 19; iter: 400; batch classifier loss: 0.423712; batch adversarial loss: 0.540234\n",
      "epoch 20; iter: 0; batch classifier loss: 0.486114; batch adversarial loss: 0.615228\n",
      "epoch 20; iter: 200; batch classifier loss: 0.292127; batch adversarial loss: 0.707429\n",
      "epoch 20; iter: 400; batch classifier loss: 0.334706; batch adversarial loss: 0.602995\n",
      "epoch 21; iter: 0; batch classifier loss: 0.716508; batch adversarial loss: 0.601765\n",
      "epoch 21; iter: 200; batch classifier loss: 0.344281; batch adversarial loss: 0.582734\n",
      "epoch 21; iter: 400; batch classifier loss: 0.406099; batch adversarial loss: 0.647851\n",
      "epoch 22; iter: 0; batch classifier loss: 0.241408; batch adversarial loss: 0.593949\n",
      "epoch 22; iter: 200; batch classifier loss: 0.238599; batch adversarial loss: 0.578121\n",
      "epoch 22; iter: 400; batch classifier loss: 0.203433; batch adversarial loss: 0.683202\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520810; batch adversarial loss: 0.642032\n",
      "epoch 23; iter: 200; batch classifier loss: 0.357455; batch adversarial loss: 0.640664\n",
      "epoch 23; iter: 400; batch classifier loss: 0.283532; batch adversarial loss: 0.617630\n",
      "epoch 24; iter: 0; batch classifier loss: 0.417259; batch adversarial loss: 0.637349\n",
      "epoch 24; iter: 200; batch classifier loss: 0.326277; batch adversarial loss: 0.584966\n",
      "epoch 24; iter: 400; batch classifier loss: 0.398778; batch adversarial loss: 0.620446\n",
      "epoch 25; iter: 0; batch classifier loss: 0.594230; batch adversarial loss: 0.576787\n",
      "epoch 25; iter: 200; batch classifier loss: 0.390260; batch adversarial loss: 0.550952\n",
      "epoch 25; iter: 400; batch classifier loss: 0.486011; batch adversarial loss: 0.569232\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498312; batch adversarial loss: 0.573254\n",
      "epoch 26; iter: 200; batch classifier loss: 0.466699; batch adversarial loss: 0.652875\n",
      "epoch 26; iter: 400; batch classifier loss: 0.604260; batch adversarial loss: 0.657211\n",
      "epoch 27; iter: 0; batch classifier loss: 0.558372; batch adversarial loss: 0.620245\n",
      "epoch 27; iter: 200; batch classifier loss: 0.492160; batch adversarial loss: 0.656651\n",
      "epoch 27; iter: 400; batch classifier loss: 0.623670; batch adversarial loss: 0.621585\n",
      "epoch 28; iter: 0; batch classifier loss: 0.274660; batch adversarial loss: 0.687563\n",
      "epoch 28; iter: 200; batch classifier loss: 0.328139; batch adversarial loss: 0.665643\n",
      "epoch 28; iter: 400; batch classifier loss: 0.438501; batch adversarial loss: 0.647494\n",
      "epoch 29; iter: 0; batch classifier loss: 0.629594; batch adversarial loss: 0.655503\n",
      "epoch 29; iter: 200; batch classifier loss: 0.387587; batch adversarial loss: 0.652101\n",
      "epoch 29; iter: 400; batch classifier loss: 0.435792; batch adversarial loss: 0.654416\n",
      "epoch 30; iter: 0; batch classifier loss: 0.325220; batch adversarial loss: 0.594830\n",
      "epoch 30; iter: 200; batch classifier loss: 0.581686; batch adversarial loss: 0.535532\n",
      "epoch 30; iter: 400; batch classifier loss: 0.372628; batch adversarial loss: 0.590985\n",
      "epoch 31; iter: 0; batch classifier loss: 0.568403; batch adversarial loss: 0.653052\n",
      "epoch 31; iter: 200; batch classifier loss: 0.483288; batch adversarial loss: 0.596759\n",
      "epoch 31; iter: 400; batch classifier loss: 0.400025; batch adversarial loss: 0.636443\n",
      "epoch 32; iter: 0; batch classifier loss: 0.504765; batch adversarial loss: 0.632352\n",
      "epoch 32; iter: 200; batch classifier loss: 0.288715; batch adversarial loss: 0.662312\n",
      "epoch 32; iter: 400; batch classifier loss: 0.314449; batch adversarial loss: 0.603716\n",
      "epoch 33; iter: 0; batch classifier loss: 0.326089; batch adversarial loss: 0.668442\n",
      "epoch 33; iter: 200; batch classifier loss: 0.469775; batch adversarial loss: 0.597503\n",
      "epoch 33; iter: 400; batch classifier loss: 0.269331; batch adversarial loss: 0.707176\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408401; batch adversarial loss: 0.618026\n",
      "epoch 34; iter: 200; batch classifier loss: 0.917232; batch adversarial loss: 0.559008\n",
      "epoch 34; iter: 400; batch classifier loss: 0.537960; batch adversarial loss: 0.638424\n",
      "epoch 35; iter: 0; batch classifier loss: 0.568461; batch adversarial loss: 0.692245\n",
      "epoch 35; iter: 200; batch classifier loss: 0.408397; batch adversarial loss: 0.634256\n",
      "epoch 35; iter: 400; batch classifier loss: 1.274686; batch adversarial loss: 0.616182\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403658; batch adversarial loss: 0.675591\n",
      "epoch 36; iter: 200; batch classifier loss: 0.686590; batch adversarial loss: 0.568862\n",
      "epoch 36; iter: 400; batch classifier loss: 0.493948; batch adversarial loss: 0.662644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.300645; batch adversarial loss: 0.624444\n",
      "epoch 37; iter: 200; batch classifier loss: 0.490783; batch adversarial loss: 0.694768\n",
      "epoch 37; iter: 400; batch classifier loss: 0.575043; batch adversarial loss: 0.563780\n",
      "epoch 38; iter: 0; batch classifier loss: 0.592276; batch adversarial loss: 0.587617\n",
      "epoch 38; iter: 200; batch classifier loss: 0.555990; batch adversarial loss: 0.664890\n",
      "epoch 38; iter: 400; batch classifier loss: 0.652525; batch adversarial loss: 0.584057\n",
      "epoch 39; iter: 0; batch classifier loss: 0.427104; batch adversarial loss: 0.594120\n",
      "epoch 39; iter: 200; batch classifier loss: 0.250141; batch adversarial loss: 0.670406\n",
      "epoch 39; iter: 400; batch classifier loss: 0.358806; batch adversarial loss: 0.647800\n",
      "epoch 40; iter: 0; batch classifier loss: 0.320699; batch adversarial loss: 0.607364\n",
      "epoch 40; iter: 200; batch classifier loss: 0.537087; batch adversarial loss: 0.619038\n",
      "epoch 40; iter: 400; batch classifier loss: 0.315929; batch adversarial loss: 0.727923\n",
      "epoch 41; iter: 0; batch classifier loss: 0.381705; batch adversarial loss: 0.594806\n",
      "epoch 41; iter: 200; batch classifier loss: 0.635227; batch adversarial loss: 0.617261\n",
      "epoch 41; iter: 400; batch classifier loss: 0.471619; batch adversarial loss: 0.667478\n",
      "epoch 42; iter: 0; batch classifier loss: 0.302742; batch adversarial loss: 0.657206\n",
      "epoch 42; iter: 200; batch classifier loss: 0.396126; batch adversarial loss: 0.622866\n",
      "epoch 42; iter: 400; batch classifier loss: 0.468486; batch adversarial loss: 0.678841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.379855; batch adversarial loss: 0.672171\n",
      "epoch 43; iter: 200; batch classifier loss: 0.281065; batch adversarial loss: 0.676025\n",
      "epoch 43; iter: 400; batch classifier loss: 0.520269; batch adversarial loss: 0.635651\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462180; batch adversarial loss: 0.679038\n",
      "epoch 44; iter: 200; batch classifier loss: 0.305209; batch adversarial loss: 0.668557\n",
      "epoch 44; iter: 400; batch classifier loss: 0.696092; batch adversarial loss: 0.577893\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424817; batch adversarial loss: 0.653214\n",
      "epoch 45; iter: 200; batch classifier loss: 0.500757; batch adversarial loss: 0.692666\n",
      "epoch 45; iter: 400; batch classifier loss: 0.255597; batch adversarial loss: 0.661277\n",
      "epoch 46; iter: 0; batch classifier loss: 0.692105; batch adversarial loss: 0.572228\n",
      "epoch 46; iter: 200; batch classifier loss: 0.421502; batch adversarial loss: 0.645411\n",
      "epoch 46; iter: 400; batch classifier loss: 0.160229; batch adversarial loss: 0.638111\n",
      "epoch 47; iter: 0; batch classifier loss: 0.538414; batch adversarial loss: 0.607053\n",
      "epoch 47; iter: 200; batch classifier loss: 0.350307; batch adversarial loss: 0.674618\n",
      "epoch 47; iter: 400; batch classifier loss: 0.469763; batch adversarial loss: 0.642904\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335181; batch adversarial loss: 0.608740\n",
      "epoch 48; iter: 200; batch classifier loss: 0.786722; batch adversarial loss: 0.585379\n",
      "epoch 48; iter: 400; batch classifier loss: 0.199098; batch adversarial loss: 0.693043\n",
      "epoch 49; iter: 0; batch classifier loss: 0.475322; batch adversarial loss: 0.625320\n",
      "epoch 49; iter: 200; batch classifier loss: 0.517482; batch adversarial loss: 0.660998\n",
      "epoch 49; iter: 400; batch classifier loss: 0.475354; batch adversarial loss: 0.629081\n",
      "epoch 0; iter: 0; batch classifier loss: 33.753300; batch adversarial loss: 0.618107\n",
      "epoch 0; iter: 200; batch classifier loss: 6.062683; batch adversarial loss: 0.682810\n",
      "epoch 0; iter: 400; batch classifier loss: 12.031130; batch adversarial loss: 0.578190\n",
      "epoch 1; iter: 0; batch classifier loss: 2.148245; batch adversarial loss: 0.644724\n",
      "epoch 1; iter: 200; batch classifier loss: 4.545582; batch adversarial loss: 0.633126\n",
      "epoch 1; iter: 400; batch classifier loss: 1.722863; batch adversarial loss: 0.658865\n",
      "epoch 2; iter: 0; batch classifier loss: 4.289612; batch adversarial loss: 0.628332\n",
      "epoch 2; iter: 200; batch classifier loss: 3.272650; batch adversarial loss: 0.636785\n",
      "epoch 2; iter: 400; batch classifier loss: 3.374463; batch adversarial loss: 0.597433\n",
      "epoch 3; iter: 0; batch classifier loss: 5.745837; batch adversarial loss: 0.590482\n",
      "epoch 3; iter: 200; batch classifier loss: 2.507260; batch adversarial loss: 0.630211\n",
      "epoch 3; iter: 400; batch classifier loss: 3.651168; batch adversarial loss: 0.685188\n",
      "epoch 4; iter: 0; batch classifier loss: 2.255241; batch adversarial loss: 0.697727\n",
      "epoch 4; iter: 200; batch classifier loss: 1.682002; batch adversarial loss: 0.593425\n",
      "epoch 4; iter: 400; batch classifier loss: 0.831263; batch adversarial loss: 0.589674\n",
      "epoch 5; iter: 0; batch classifier loss: 1.137107; batch adversarial loss: 0.611551\n",
      "epoch 5; iter: 200; batch classifier loss: 0.417242; batch adversarial loss: 0.606364\n",
      "epoch 5; iter: 400; batch classifier loss: 1.559562; batch adversarial loss: 0.591796\n",
      "epoch 6; iter: 0; batch classifier loss: 0.587983; batch adversarial loss: 0.644141\n",
      "epoch 6; iter: 200; batch classifier loss: 1.047962; batch adversarial loss: 0.701451\n",
      "epoch 6; iter: 400; batch classifier loss: 0.491159; batch adversarial loss: 0.606913\n",
      "epoch 7; iter: 0; batch classifier loss: 0.495643; batch adversarial loss: 0.614501\n",
      "epoch 7; iter: 200; batch classifier loss: 0.366802; batch adversarial loss: 0.572796\n",
      "epoch 7; iter: 400; batch classifier loss: 0.409015; batch adversarial loss: 0.543207\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523567; batch adversarial loss: 0.661039\n",
      "epoch 8; iter: 200; batch classifier loss: 0.518261; batch adversarial loss: 0.597954\n",
      "epoch 8; iter: 400; batch classifier loss: 0.476280; batch adversarial loss: 0.657729\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556253; batch adversarial loss: 0.571797\n",
      "epoch 9; iter: 200; batch classifier loss: 0.470189; batch adversarial loss: 0.611278\n",
      "epoch 9; iter: 400; batch classifier loss: 0.323950; batch adversarial loss: 0.655006\n",
      "epoch 10; iter: 0; batch classifier loss: 0.384049; batch adversarial loss: 0.591533\n",
      "epoch 10; iter: 200; batch classifier loss: 0.441615; batch adversarial loss: 0.628438\n",
      "epoch 10; iter: 400; batch classifier loss: 0.360863; batch adversarial loss: 0.604081\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388606; batch adversarial loss: 0.630218\n",
      "epoch 11; iter: 200; batch classifier loss: 0.379466; batch adversarial loss: 0.658765\n",
      "epoch 11; iter: 400; batch classifier loss: 0.288999; batch adversarial loss: 0.602804\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457919; batch adversarial loss: 0.615273\n",
      "epoch 12; iter: 200; batch classifier loss: 0.288693; batch adversarial loss: 0.582930\n",
      "epoch 12; iter: 400; batch classifier loss: 0.320621; batch adversarial loss: 0.625303\n",
      "epoch 13; iter: 0; batch classifier loss: 0.329304; batch adversarial loss: 0.550243\n",
      "epoch 13; iter: 200; batch classifier loss: 0.282603; batch adversarial loss: 0.709777\n",
      "epoch 13; iter: 400; batch classifier loss: 0.332956; batch adversarial loss: 0.633660\n",
      "epoch 14; iter: 0; batch classifier loss: 0.416424; batch adversarial loss: 0.617185\n",
      "epoch 14; iter: 200; batch classifier loss: 0.459918; batch adversarial loss: 0.618063\n",
      "epoch 14; iter: 400; batch classifier loss: 0.252825; batch adversarial loss: 0.638865\n",
      "epoch 15; iter: 0; batch classifier loss: 0.267917; batch adversarial loss: 0.729917\n",
      "epoch 15; iter: 200; batch classifier loss: 0.353707; batch adversarial loss: 0.625975\n",
      "epoch 15; iter: 400; batch classifier loss: 0.436534; batch adversarial loss: 0.611703\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489168; batch adversarial loss: 0.671270\n",
      "epoch 16; iter: 200; batch classifier loss: 0.417933; batch adversarial loss: 0.657346\n",
      "epoch 16; iter: 400; batch classifier loss: 0.327408; batch adversarial loss: 0.674682\n",
      "epoch 17; iter: 0; batch classifier loss: 0.550688; batch adversarial loss: 0.606368\n",
      "epoch 17; iter: 200; batch classifier loss: 0.305931; batch adversarial loss: 0.657623\n",
      "epoch 17; iter: 400; batch classifier loss: 0.377395; batch adversarial loss: 0.602669\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345951; batch adversarial loss: 0.561412\n",
      "epoch 18; iter: 200; batch classifier loss: 0.442002; batch adversarial loss: 0.687544\n",
      "epoch 18; iter: 400; batch classifier loss: 0.393927; batch adversarial loss: 0.609959\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483048; batch adversarial loss: 0.668122\n",
      "epoch 19; iter: 200; batch classifier loss: 0.372485; batch adversarial loss: 0.585714\n",
      "epoch 19; iter: 400; batch classifier loss: 0.262242; batch adversarial loss: 0.555868\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342020; batch adversarial loss: 0.674135\n",
      "epoch 20; iter: 200; batch classifier loss: 0.396346; batch adversarial loss: 0.633474\n",
      "epoch 20; iter: 400; batch classifier loss: 0.436222; batch adversarial loss: 0.596984\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484333; batch adversarial loss: 0.682463\n",
      "epoch 21; iter: 200; batch classifier loss: 0.375601; batch adversarial loss: 0.572069\n",
      "epoch 21; iter: 400; batch classifier loss: 0.635406; batch adversarial loss: 0.646229\n",
      "epoch 22; iter: 0; batch classifier loss: 0.368567; batch adversarial loss: 0.611126\n",
      "epoch 22; iter: 200; batch classifier loss: 0.352702; batch adversarial loss: 0.611366\n",
      "epoch 22; iter: 400; batch classifier loss: 0.440175; batch adversarial loss: 0.632449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.650739; batch adversarial loss: 0.625327\n",
      "epoch 23; iter: 200; batch classifier loss: 0.403170; batch adversarial loss: 0.532386\n",
      "epoch 23; iter: 400; batch classifier loss: 0.413109; batch adversarial loss: 0.620651\n",
      "epoch 24; iter: 0; batch classifier loss: 0.423660; batch adversarial loss: 0.763075\n",
      "epoch 24; iter: 200; batch classifier loss: 0.498583; batch adversarial loss: 0.547224\n",
      "epoch 24; iter: 400; batch classifier loss: 0.616873; batch adversarial loss: 0.588596\n",
      "epoch 25; iter: 0; batch classifier loss: 0.530283; batch adversarial loss: 0.619747\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360719; batch adversarial loss: 0.643079\n",
      "epoch 25; iter: 400; batch classifier loss: 0.352246; batch adversarial loss: 0.662718\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476959; batch adversarial loss: 0.613612\n",
      "epoch 26; iter: 200; batch classifier loss: 0.443010; batch adversarial loss: 0.587546\n",
      "epoch 26; iter: 400; batch classifier loss: 0.553582; batch adversarial loss: 0.658614\n",
      "epoch 27; iter: 0; batch classifier loss: 0.349068; batch adversarial loss: 0.638973\n",
      "epoch 27; iter: 200; batch classifier loss: 0.346022; batch adversarial loss: 0.607952\n",
      "epoch 27; iter: 400; batch classifier loss: 0.391911; batch adversarial loss: 0.631722\n",
      "epoch 28; iter: 0; batch classifier loss: 0.321937; batch adversarial loss: 0.631006\n",
      "epoch 28; iter: 200; batch classifier loss: 0.469559; batch adversarial loss: 0.718929\n",
      "epoch 28; iter: 400; batch classifier loss: 0.422547; batch adversarial loss: 0.640657\n",
      "epoch 29; iter: 0; batch classifier loss: 0.457633; batch adversarial loss: 0.664250\n",
      "epoch 29; iter: 200; batch classifier loss: 0.265230; batch adversarial loss: 0.704251\n",
      "epoch 29; iter: 400; batch classifier loss: 0.476347; batch adversarial loss: 0.657305\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449569; batch adversarial loss: 0.655432\n",
      "epoch 30; iter: 200; batch classifier loss: 0.746152; batch adversarial loss: 0.672264\n",
      "epoch 30; iter: 400; batch classifier loss: 0.400075; batch adversarial loss: 0.603208\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469365; batch adversarial loss: 0.619980\n",
      "epoch 31; iter: 200; batch classifier loss: 0.295072; batch adversarial loss: 0.560619\n",
      "epoch 31; iter: 400; batch classifier loss: 0.328583; batch adversarial loss: 0.649498\n",
      "epoch 32; iter: 0; batch classifier loss: 0.661197; batch adversarial loss: 0.636077\n",
      "epoch 32; iter: 200; batch classifier loss: 0.245934; batch adversarial loss: 0.685319\n",
      "epoch 32; iter: 400; batch classifier loss: 0.915748; batch adversarial loss: 0.592764\n",
      "epoch 33; iter: 0; batch classifier loss: 0.678190; batch adversarial loss: 0.668400\n",
      "epoch 33; iter: 200; batch classifier loss: 0.503704; batch adversarial loss: 0.573224\n",
      "epoch 33; iter: 400; batch classifier loss: 0.857230; batch adversarial loss: 0.645965\n",
      "epoch 34; iter: 0; batch classifier loss: 0.683863; batch adversarial loss: 0.714170\n",
      "epoch 34; iter: 200; batch classifier loss: 0.669740; batch adversarial loss: 0.661796\n",
      "epoch 34; iter: 400; batch classifier loss: 0.353509; batch adversarial loss: 0.594527\n",
      "epoch 35; iter: 0; batch classifier loss: 0.385069; batch adversarial loss: 0.676488\n",
      "epoch 35; iter: 200; batch classifier loss: 0.446450; batch adversarial loss: 0.631228\n",
      "epoch 35; iter: 400; batch classifier loss: 0.606414; batch adversarial loss: 0.571702\n",
      "epoch 36; iter: 0; batch classifier loss: 0.893251; batch adversarial loss: 0.589382\n",
      "epoch 36; iter: 200; batch classifier loss: 0.471339; batch adversarial loss: 0.644763\n",
      "epoch 36; iter: 400; batch classifier loss: 0.290526; batch adversarial loss: 0.648403\n",
      "epoch 37; iter: 0; batch classifier loss: 0.550620; batch adversarial loss: 0.629446\n",
      "epoch 37; iter: 200; batch classifier loss: 0.229597; batch adversarial loss: 0.548243\n",
      "epoch 37; iter: 400; batch classifier loss: 0.396724; batch adversarial loss: 0.642298\n",
      "epoch 38; iter: 0; batch classifier loss: 0.474189; batch adversarial loss: 0.718477\n",
      "epoch 38; iter: 200; batch classifier loss: 0.584472; batch adversarial loss: 0.626453\n",
      "epoch 38; iter: 400; batch classifier loss: 0.486088; batch adversarial loss: 0.768452\n",
      "epoch 39; iter: 0; batch classifier loss: 0.319191; batch adversarial loss: 0.640812\n",
      "epoch 39; iter: 200; batch classifier loss: 1.799646; batch adversarial loss: 0.626454\n",
      "epoch 39; iter: 400; batch classifier loss: 0.425099; batch adversarial loss: 0.566234\n",
      "epoch 40; iter: 0; batch classifier loss: 0.481693; batch adversarial loss: 0.574418\n",
      "epoch 40; iter: 200; batch classifier loss: 0.401992; batch adversarial loss: 0.603760\n",
      "epoch 40; iter: 400; batch classifier loss: 0.458784; batch adversarial loss: 0.690019\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562521; batch adversarial loss: 0.681965\n",
      "epoch 41; iter: 200; batch classifier loss: 0.340311; batch adversarial loss: 0.566207\n",
      "epoch 41; iter: 400; batch classifier loss: 0.229302; batch adversarial loss: 0.659467\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443618; batch adversarial loss: 0.608593\n",
      "epoch 42; iter: 200; batch classifier loss: 0.337791; batch adversarial loss: 0.630007\n",
      "epoch 42; iter: 400; batch classifier loss: 0.462112; batch adversarial loss: 0.642696\n",
      "epoch 43; iter: 0; batch classifier loss: 0.426099; batch adversarial loss: 0.630216\n",
      "epoch 43; iter: 200; batch classifier loss: 0.356929; batch adversarial loss: 0.597584\n",
      "epoch 43; iter: 400; batch classifier loss: 0.387691; batch adversarial loss: 0.605220\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388387; batch adversarial loss: 0.720718\n",
      "epoch 44; iter: 200; batch classifier loss: 0.883190; batch adversarial loss: 0.636358\n",
      "epoch 44; iter: 400; batch classifier loss: 1.141213; batch adversarial loss: 0.670395\n",
      "epoch 45; iter: 0; batch classifier loss: 0.622746; batch adversarial loss: 0.561449\n",
      "epoch 45; iter: 200; batch classifier loss: 0.580891; batch adversarial loss: 0.589642\n",
      "epoch 45; iter: 400; batch classifier loss: 0.567832; batch adversarial loss: 0.647948\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370431; batch adversarial loss: 0.642983\n",
      "epoch 46; iter: 200; batch classifier loss: 0.294207; batch adversarial loss: 0.660747\n",
      "epoch 46; iter: 400; batch classifier loss: 0.592010; batch adversarial loss: 0.615196\n",
      "epoch 47; iter: 0; batch classifier loss: 0.655625; batch adversarial loss: 0.677921\n",
      "epoch 47; iter: 200; batch classifier loss: 0.510917; batch adversarial loss: 0.545917\n",
      "epoch 47; iter: 400; batch classifier loss: 0.441940; batch adversarial loss: 0.637314\n",
      "epoch 48; iter: 0; batch classifier loss: 0.498764; batch adversarial loss: 0.651280\n",
      "epoch 48; iter: 200; batch classifier loss: 0.290995; batch adversarial loss: 0.563020\n",
      "epoch 48; iter: 400; batch classifier loss: 0.481948; batch adversarial loss: 0.718734\n",
      "epoch 49; iter: 0; batch classifier loss: 0.545207; batch adversarial loss: 0.708694\n",
      "epoch 49; iter: 200; batch classifier loss: 0.953134; batch adversarial loss: 0.635130\n",
      "epoch 49; iter: 400; batch classifier loss: 0.279982; batch adversarial loss: 0.632278\n",
      "epoch 0; iter: 0; batch classifier loss: 8.163649; batch adversarial loss: 0.604690\n",
      "epoch 0; iter: 200; batch classifier loss: 4.505268; batch adversarial loss: 0.605552\n",
      "epoch 0; iter: 400; batch classifier loss: 0.386910; batch adversarial loss: 0.591797\n",
      "epoch 1; iter: 0; batch classifier loss: 7.261654; batch adversarial loss: 0.568848\n",
      "epoch 1; iter: 200; batch classifier loss: 5.964025; batch adversarial loss: 0.607672\n",
      "epoch 1; iter: 400; batch classifier loss: 8.732595; batch adversarial loss: 0.582990\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563195; batch adversarial loss: 0.539693\n",
      "epoch 2; iter: 200; batch classifier loss: 3.125423; batch adversarial loss: 0.635705\n",
      "epoch 2; iter: 400; batch classifier loss: 1.520127; batch adversarial loss: 0.576675\n",
      "epoch 3; iter: 0; batch classifier loss: 0.373314; batch adversarial loss: 0.576025\n",
      "epoch 3; iter: 200; batch classifier loss: 2.356728; batch adversarial loss: 0.598086\n",
      "epoch 3; iter: 400; batch classifier loss: 1.679397; batch adversarial loss: 0.657206\n",
      "epoch 4; iter: 0; batch classifier loss: 3.349697; batch adversarial loss: 0.542931\n",
      "epoch 4; iter: 200; batch classifier loss: 0.747766; batch adversarial loss: 0.593642\n",
      "epoch 4; iter: 400; batch classifier loss: 1.301363; batch adversarial loss: 0.606593\n",
      "epoch 5; iter: 0; batch classifier loss: 1.077090; batch adversarial loss: 0.700596\n",
      "epoch 5; iter: 200; batch classifier loss: 3.080374; batch adversarial loss: 0.671003\n",
      "epoch 5; iter: 400; batch classifier loss: 0.425730; batch adversarial loss: 0.624840\n",
      "epoch 6; iter: 0; batch classifier loss: 0.445245; batch adversarial loss: 0.598156\n",
      "epoch 6; iter: 200; batch classifier loss: 0.539093; batch adversarial loss: 0.603042\n",
      "epoch 6; iter: 400; batch classifier loss: 0.431906; batch adversarial loss: 0.550793\n",
      "epoch 7; iter: 0; batch classifier loss: 0.424669; batch adversarial loss: 0.667386\n",
      "epoch 7; iter: 200; batch classifier loss: 0.510553; batch adversarial loss: 0.630575\n",
      "epoch 7; iter: 400; batch classifier loss: 0.497285; batch adversarial loss: 0.585645\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549011; batch adversarial loss: 0.607847\n",
      "epoch 8; iter: 200; batch classifier loss: 0.384325; batch adversarial loss: 0.638238\n",
      "epoch 8; iter: 400; batch classifier loss: 0.431860; batch adversarial loss: 0.716550\n",
      "epoch 9; iter: 0; batch classifier loss: 0.427044; batch adversarial loss: 0.630616\n",
      "epoch 9; iter: 200; batch classifier loss: 0.415367; batch adversarial loss: 0.548413\n",
      "epoch 9; iter: 400; batch classifier loss: 0.334172; batch adversarial loss: 0.566234\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455679; batch adversarial loss: 0.622120\n",
      "epoch 10; iter: 200; batch classifier loss: 0.313688; batch adversarial loss: 0.677831\n",
      "epoch 10; iter: 400; batch classifier loss: 0.501675; batch adversarial loss: 0.635267\n",
      "epoch 11; iter: 0; batch classifier loss: 0.307417; batch adversarial loss: 0.683287\n",
      "epoch 11; iter: 200; batch classifier loss: 0.370825; batch adversarial loss: 0.652214\n",
      "epoch 11; iter: 400; batch classifier loss: 0.339196; batch adversarial loss: 0.588771\n",
      "epoch 12; iter: 0; batch classifier loss: 0.315483; batch adversarial loss: 0.581018\n",
      "epoch 12; iter: 200; batch classifier loss: 0.408746; batch adversarial loss: 0.714865\n",
      "epoch 12; iter: 400; batch classifier loss: 0.349853; batch adversarial loss: 0.639808\n",
      "epoch 13; iter: 0; batch classifier loss: 0.311370; batch adversarial loss: 0.633739\n",
      "epoch 13; iter: 200; batch classifier loss: 0.475971; batch adversarial loss: 0.611672\n",
      "epoch 13; iter: 400; batch classifier loss: 0.320144; batch adversarial loss: 0.605284\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350210; batch adversarial loss: 0.516333\n",
      "epoch 14; iter: 200; batch classifier loss: 0.283762; batch adversarial loss: 0.638641\n",
      "epoch 14; iter: 400; batch classifier loss: 0.371037; batch adversarial loss: 0.572907\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297085; batch adversarial loss: 0.673305\n",
      "epoch 15; iter: 200; batch classifier loss: 0.354534; batch adversarial loss: 0.627048\n",
      "epoch 15; iter: 400; batch classifier loss: 0.507810; batch adversarial loss: 0.644361\n",
      "epoch 16; iter: 0; batch classifier loss: 0.209014; batch adversarial loss: 0.584002\n",
      "epoch 16; iter: 200; batch classifier loss: 0.321088; batch adversarial loss: 0.689823\n",
      "epoch 16; iter: 400; batch classifier loss: 0.200607; batch adversarial loss: 0.632914\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397721; batch adversarial loss: 0.649029\n",
      "epoch 17; iter: 200; batch classifier loss: 0.407752; batch adversarial loss: 0.626418\n",
      "epoch 17; iter: 400; batch classifier loss: 0.392192; batch adversarial loss: 0.609333\n",
      "epoch 18; iter: 0; batch classifier loss: 0.428073; batch adversarial loss: 0.588662\n",
      "epoch 18; iter: 200; batch classifier loss: 0.593597; batch adversarial loss: 0.631871\n",
      "epoch 18; iter: 400; batch classifier loss: 0.388729; batch adversarial loss: 0.609315\n",
      "epoch 19; iter: 0; batch classifier loss: 0.371449; batch adversarial loss: 0.562343\n",
      "epoch 19; iter: 200; batch classifier loss: 0.273650; batch adversarial loss: 0.662893\n",
      "epoch 19; iter: 400; batch classifier loss: 0.501356; batch adversarial loss: 0.581016\n",
      "epoch 20; iter: 0; batch classifier loss: 0.346227; batch adversarial loss: 0.600919\n",
      "epoch 20; iter: 200; batch classifier loss: 0.380885; batch adversarial loss: 0.643451\n",
      "epoch 20; iter: 400; batch classifier loss: 0.426110; batch adversarial loss: 0.640725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369896; batch adversarial loss: 0.696377\n",
      "epoch 21; iter: 200; batch classifier loss: 0.439367; batch adversarial loss: 0.628052\n",
      "epoch 21; iter: 400; batch classifier loss: 0.384141; batch adversarial loss: 0.711652\n",
      "epoch 22; iter: 0; batch classifier loss: 0.490693; batch adversarial loss: 0.546277\n",
      "epoch 22; iter: 200; batch classifier loss: 0.426452; batch adversarial loss: 0.601355\n",
      "epoch 22; iter: 400; batch classifier loss: 0.567119; batch adversarial loss: 0.646944\n",
      "epoch 23; iter: 0; batch classifier loss: 0.520472; batch adversarial loss: 0.628417\n",
      "epoch 23; iter: 200; batch classifier loss: 0.404950; batch adversarial loss: 0.628945\n",
      "epoch 23; iter: 400; batch classifier loss: 0.316043; batch adversarial loss: 0.631125\n",
      "epoch 24; iter: 0; batch classifier loss: 0.776737; batch adversarial loss: 0.640195\n",
      "epoch 24; iter: 200; batch classifier loss: 0.599433; batch adversarial loss: 0.606215\n",
      "epoch 24; iter: 400; batch classifier loss: 0.621582; batch adversarial loss: 0.631160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.484939; batch adversarial loss: 0.660518\n",
      "epoch 25; iter: 200; batch classifier loss: 0.384645; batch adversarial loss: 0.660846\n",
      "epoch 25; iter: 400; batch classifier loss: 0.319641; batch adversarial loss: 0.654421\n",
      "epoch 26; iter: 0; batch classifier loss: 0.574297; batch adversarial loss: 0.635980\n",
      "epoch 26; iter: 200; batch classifier loss: 0.378356; batch adversarial loss: 0.620641\n",
      "epoch 26; iter: 400; batch classifier loss: 0.567237; batch adversarial loss: 0.635886\n",
      "epoch 27; iter: 0; batch classifier loss: 0.417072; batch adversarial loss: 0.689342\n",
      "epoch 27; iter: 200; batch classifier loss: 0.714141; batch adversarial loss: 0.671562\n",
      "epoch 27; iter: 400; batch classifier loss: 0.456030; batch adversarial loss: 0.654668\n",
      "epoch 28; iter: 0; batch classifier loss: 0.341871; batch adversarial loss: 0.665147\n",
      "epoch 28; iter: 200; batch classifier loss: 0.350573; batch adversarial loss: 0.620113\n",
      "epoch 28; iter: 400; batch classifier loss: 0.456132; batch adversarial loss: 0.591709\n",
      "epoch 29; iter: 0; batch classifier loss: 0.430198; batch adversarial loss: 0.667334\n",
      "epoch 29; iter: 200; batch classifier loss: 0.493254; batch adversarial loss: 0.545041\n",
      "epoch 29; iter: 400; batch classifier loss: 0.406649; batch adversarial loss: 0.583833\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430220; batch adversarial loss: 0.621315\n",
      "epoch 30; iter: 200; batch classifier loss: 0.507611; batch adversarial loss: 0.616794\n",
      "epoch 30; iter: 400; batch classifier loss: 0.417472; batch adversarial loss: 0.570282\n",
      "epoch 31; iter: 0; batch classifier loss: 0.500573; batch adversarial loss: 0.594782\n",
      "epoch 31; iter: 200; batch classifier loss: 0.427297; batch adversarial loss: 0.625832\n",
      "epoch 31; iter: 400; batch classifier loss: 0.319826; batch adversarial loss: 0.663478\n",
      "epoch 32; iter: 0; batch classifier loss: 0.532380; batch adversarial loss: 0.595982\n",
      "epoch 32; iter: 200; batch classifier loss: 0.464513; batch adversarial loss: 0.641400\n",
      "epoch 32; iter: 400; batch classifier loss: 0.595248; batch adversarial loss: 0.617069\n",
      "epoch 33; iter: 0; batch classifier loss: 0.798924; batch adversarial loss: 0.590816\n",
      "epoch 33; iter: 200; batch classifier loss: 0.428397; batch adversarial loss: 0.628617\n",
      "epoch 33; iter: 400; batch classifier loss: 0.291929; batch adversarial loss: 0.669416\n",
      "epoch 34; iter: 0; batch classifier loss: 0.463999; batch adversarial loss: 0.656083\n",
      "epoch 34; iter: 200; batch classifier loss: 0.659947; batch adversarial loss: 0.629826\n",
      "epoch 34; iter: 400; batch classifier loss: 0.396800; batch adversarial loss: 0.691486\n",
      "epoch 35; iter: 0; batch classifier loss: 1.191591; batch adversarial loss: 0.606896\n",
      "epoch 35; iter: 200; batch classifier loss: 0.278982; batch adversarial loss: 0.673359\n",
      "epoch 35; iter: 400; batch classifier loss: 0.479661; batch adversarial loss: 0.721077\n",
      "epoch 36; iter: 0; batch classifier loss: 0.492401; batch adversarial loss: 0.584686\n",
      "epoch 36; iter: 200; batch classifier loss: 0.269720; batch adversarial loss: 0.622466\n",
      "epoch 36; iter: 400; batch classifier loss: 1.230101; batch adversarial loss: 0.727373\n",
      "epoch 37; iter: 0; batch classifier loss: 0.403098; batch adversarial loss: 0.623956\n",
      "epoch 37; iter: 200; batch classifier loss: 0.670406; batch adversarial loss: 0.718339\n",
      "epoch 37; iter: 400; batch classifier loss: 0.587743; batch adversarial loss: 0.558184\n",
      "epoch 38; iter: 0; batch classifier loss: 0.249888; batch adversarial loss: 0.670394\n",
      "epoch 38; iter: 200; batch classifier loss: 0.485278; batch adversarial loss: 0.684496\n",
      "epoch 38; iter: 400; batch classifier loss: 0.288834; batch adversarial loss: 0.655172\n",
      "epoch 39; iter: 0; batch classifier loss: 0.494166; batch adversarial loss: 0.562867\n",
      "epoch 39; iter: 200; batch classifier loss: 0.381468; batch adversarial loss: 0.641684\n",
      "epoch 39; iter: 400; batch classifier loss: 0.401600; batch adversarial loss: 0.613924\n",
      "epoch 40; iter: 0; batch classifier loss: 0.254791; batch adversarial loss: 0.582386\n",
      "epoch 40; iter: 200; batch classifier loss: 0.635676; batch adversarial loss: 0.553728\n",
      "epoch 40; iter: 400; batch classifier loss: 0.263634; batch adversarial loss: 0.658083\n",
      "epoch 41; iter: 0; batch classifier loss: 0.388284; batch adversarial loss: 0.657939\n",
      "epoch 41; iter: 200; batch classifier loss: 0.512459; batch adversarial loss: 0.637749\n",
      "epoch 41; iter: 400; batch classifier loss: 0.258461; batch adversarial loss: 0.682984\n",
      "epoch 42; iter: 0; batch classifier loss: 0.540971; batch adversarial loss: 0.600965\n",
      "epoch 42; iter: 200; batch classifier loss: 0.710977; batch adversarial loss: 0.675446\n",
      "epoch 42; iter: 400; batch classifier loss: 0.412614; batch adversarial loss: 0.618269\n",
      "epoch 43; iter: 0; batch classifier loss: 0.650378; batch adversarial loss: 0.542465\n",
      "epoch 43; iter: 200; batch classifier loss: 0.691399; batch adversarial loss: 0.561386\n",
      "epoch 43; iter: 400; batch classifier loss: 0.417466; batch adversarial loss: 0.686354\n",
      "epoch 44; iter: 0; batch classifier loss: 0.562891; batch adversarial loss: 0.605797\n",
      "epoch 44; iter: 200; batch classifier loss: 0.442267; batch adversarial loss: 0.641887\n",
      "epoch 44; iter: 400; batch classifier loss: 0.635369; batch adversarial loss: 0.669175\n",
      "epoch 45; iter: 0; batch classifier loss: 1.582442; batch adversarial loss: 0.570068\n",
      "epoch 45; iter: 200; batch classifier loss: 0.641553; batch adversarial loss: 0.668193\n",
      "epoch 45; iter: 400; batch classifier loss: 0.253208; batch adversarial loss: 0.578729\n",
      "epoch 46; iter: 0; batch classifier loss: 0.352282; batch adversarial loss: 0.699448\n",
      "epoch 46; iter: 200; batch classifier loss: 0.351938; batch adversarial loss: 0.593261\n",
      "epoch 46; iter: 400; batch classifier loss: 0.941207; batch adversarial loss: 0.634362\n",
      "epoch 47; iter: 0; batch classifier loss: 0.581951; batch adversarial loss: 0.559685\n",
      "epoch 47; iter: 200; batch classifier loss: 0.301866; batch adversarial loss: 0.666864\n",
      "epoch 47; iter: 400; batch classifier loss: 0.530935; batch adversarial loss: 0.597081\n",
      "epoch 48; iter: 0; batch classifier loss: 0.440786; batch adversarial loss: 0.619007\n",
      "epoch 48; iter: 200; batch classifier loss: 0.553752; batch adversarial loss: 0.663704\n",
      "epoch 48; iter: 400; batch classifier loss: 0.408785; batch adversarial loss: 0.708027\n",
      "epoch 49; iter: 0; batch classifier loss: 0.664918; batch adversarial loss: 0.632928\n",
      "epoch 49; iter: 200; batch classifier loss: 0.591616; batch adversarial loss: 0.595456\n",
      "epoch 49; iter: 400; batch classifier loss: 0.637510; batch adversarial loss: 0.629322\n",
      "epoch 0; iter: 0; batch classifier loss: 9.641916; batch adversarial loss: 0.615890\n",
      "epoch 0; iter: 200; batch classifier loss: 12.743536; batch adversarial loss: 0.661058\n",
      "epoch 0; iter: 400; batch classifier loss: 5.449357; batch adversarial loss: 0.639472\n",
      "epoch 1; iter: 0; batch classifier loss: 5.208370; batch adversarial loss: 0.643508\n",
      "epoch 1; iter: 200; batch classifier loss: 7.868709; batch adversarial loss: 0.629911\n",
      "epoch 1; iter: 400; batch classifier loss: 4.033425; batch adversarial loss: 0.587479\n",
      "epoch 2; iter: 0; batch classifier loss: 0.857856; batch adversarial loss: 0.548615\n",
      "epoch 2; iter: 200; batch classifier loss: 2.074779; batch adversarial loss: 0.649013\n",
      "epoch 2; iter: 400; batch classifier loss: 3.473139; batch adversarial loss: 0.613427\n",
      "epoch 3; iter: 0; batch classifier loss: 11.780779; batch adversarial loss: 0.626981\n",
      "epoch 3; iter: 200; batch classifier loss: 2.490417; batch adversarial loss: 0.644712\n",
      "epoch 3; iter: 400; batch classifier loss: 1.622865; batch adversarial loss: 0.564261\n",
      "epoch 4; iter: 0; batch classifier loss: 3.769976; batch adversarial loss: 0.636082\n",
      "epoch 4; iter: 200; batch classifier loss: 1.288509; batch adversarial loss: 0.537870\n",
      "epoch 4; iter: 400; batch classifier loss: 1.623652; batch adversarial loss: 0.596392\n",
      "epoch 5; iter: 0; batch classifier loss: 0.884280; batch adversarial loss: 0.646846\n",
      "epoch 5; iter: 200; batch classifier loss: 0.340401; batch adversarial loss: 0.558863\n",
      "epoch 5; iter: 400; batch classifier loss: 0.479177; batch adversarial loss: 0.619608\n",
      "epoch 6; iter: 0; batch classifier loss: 0.655599; batch adversarial loss: 0.628536\n",
      "epoch 6; iter: 200; batch classifier loss: 0.391878; batch adversarial loss: 0.577090\n",
      "epoch 6; iter: 400; batch classifier loss: 0.453071; batch adversarial loss: 0.628644\n",
      "epoch 7; iter: 0; batch classifier loss: 0.373261; batch adversarial loss: 0.660821\n",
      "epoch 7; iter: 200; batch classifier loss: 0.421239; batch adversarial loss: 0.627390\n",
      "epoch 7; iter: 400; batch classifier loss: 0.539277; batch adversarial loss: 0.538372\n",
      "epoch 8; iter: 0; batch classifier loss: 0.805682; batch adversarial loss: 0.605393\n",
      "epoch 8; iter: 200; batch classifier loss: 0.346864; batch adversarial loss: 0.621859\n",
      "epoch 8; iter: 400; batch classifier loss: 0.343496; batch adversarial loss: 0.550647\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402877; batch adversarial loss: 0.562644\n",
      "epoch 9; iter: 200; batch classifier loss: 0.412485; batch adversarial loss: 0.652514\n",
      "epoch 9; iter: 400; batch classifier loss: 0.435500; batch adversarial loss: 0.596478\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305449; batch adversarial loss: 0.601706\n",
      "epoch 10; iter: 200; batch classifier loss: 0.305299; batch adversarial loss: 0.597090\n",
      "epoch 10; iter: 400; batch classifier loss: 0.310049; batch adversarial loss: 0.573095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.362659; batch adversarial loss: 0.662223\n",
      "epoch 11; iter: 200; batch classifier loss: 0.474647; batch adversarial loss: 0.646052\n",
      "epoch 11; iter: 400; batch classifier loss: 0.420058; batch adversarial loss: 0.612276\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350367; batch adversarial loss: 0.589842\n",
      "epoch 12; iter: 200; batch classifier loss: 0.269751; batch adversarial loss: 0.649125\n",
      "epoch 12; iter: 400; batch classifier loss: 0.320754; batch adversarial loss: 0.572992\n",
      "epoch 13; iter: 0; batch classifier loss: 0.424214; batch adversarial loss: 0.590644\n",
      "epoch 13; iter: 200; batch classifier loss: 0.245705; batch adversarial loss: 0.659144\n",
      "epoch 13; iter: 400; batch classifier loss: 0.430922; batch adversarial loss: 0.573486\n",
      "epoch 14; iter: 0; batch classifier loss: 0.293870; batch adversarial loss: 0.685321\n",
      "epoch 14; iter: 200; batch classifier loss: 0.355495; batch adversarial loss: 0.650036\n",
      "epoch 14; iter: 400; batch classifier loss: 0.307848; batch adversarial loss: 0.661984\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391775; batch adversarial loss: 0.623840\n",
      "epoch 15; iter: 200; batch classifier loss: 0.293196; batch adversarial loss: 0.667792\n",
      "epoch 15; iter: 400; batch classifier loss: 0.226397; batch adversarial loss: 0.656504\n",
      "epoch 16; iter: 0; batch classifier loss: 0.396874; batch adversarial loss: 0.614151\n",
      "epoch 16; iter: 200; batch classifier loss: 0.319262; batch adversarial loss: 0.601299\n",
      "epoch 16; iter: 400; batch classifier loss: 0.234243; batch adversarial loss: 0.617502\n",
      "epoch 17; iter: 0; batch classifier loss: 0.417868; batch adversarial loss: 0.604966\n",
      "epoch 17; iter: 200; batch classifier loss: 0.362395; batch adversarial loss: 0.532823\n",
      "epoch 17; iter: 400; batch classifier loss: 0.344899; batch adversarial loss: 0.541849\n",
      "epoch 18; iter: 0; batch classifier loss: 0.330007; batch adversarial loss: 0.592050\n",
      "epoch 18; iter: 200; batch classifier loss: 0.535566; batch adversarial loss: 0.699102\n",
      "epoch 18; iter: 400; batch classifier loss: 0.360311; batch adversarial loss: 0.632804\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299955; batch adversarial loss: 0.660373\n",
      "epoch 19; iter: 200; batch classifier loss: 0.365627; batch adversarial loss: 0.645839\n",
      "epoch 19; iter: 400; batch classifier loss: 0.198552; batch adversarial loss: 0.553764\n",
      "epoch 20; iter: 0; batch classifier loss: 0.353754; batch adversarial loss: 0.686781\n",
      "epoch 20; iter: 200; batch classifier loss: 0.467927; batch adversarial loss: 0.602404\n",
      "epoch 20; iter: 400; batch classifier loss: 0.365080; batch adversarial loss: 0.665838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.382185; batch adversarial loss: 0.596933\n",
      "epoch 21; iter: 200; batch classifier loss: 0.357448; batch adversarial loss: 0.668758\n",
      "epoch 21; iter: 400; batch classifier loss: 0.439089; batch adversarial loss: 0.629781\n",
      "epoch 22; iter: 0; batch classifier loss: 0.400966; batch adversarial loss: 0.688696\n",
      "epoch 22; iter: 200; batch classifier loss: 0.481584; batch adversarial loss: 0.669484\n",
      "epoch 22; iter: 400; batch classifier loss: 0.555646; batch adversarial loss: 0.531429\n",
      "epoch 23; iter: 0; batch classifier loss: 0.478861; batch adversarial loss: 0.637196\n",
      "epoch 23; iter: 200; batch classifier loss: 0.503918; batch adversarial loss: 0.619931\n",
      "epoch 23; iter: 400; batch classifier loss: 0.843497; batch adversarial loss: 0.637191\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292638; batch adversarial loss: 0.611187\n",
      "epoch 24; iter: 200; batch classifier loss: 0.508399; batch adversarial loss: 0.567648\n",
      "epoch 24; iter: 400; batch classifier loss: 0.373026; batch adversarial loss: 0.549123\n",
      "epoch 25; iter: 0; batch classifier loss: 0.421969; batch adversarial loss: 0.700450\n",
      "epoch 25; iter: 200; batch classifier loss: 0.389610; batch adversarial loss: 0.645227\n",
      "epoch 25; iter: 400; batch classifier loss: 0.408287; batch adversarial loss: 0.553633\n",
      "epoch 26; iter: 0; batch classifier loss: 0.411563; batch adversarial loss: 0.644679\n",
      "epoch 26; iter: 200; batch classifier loss: 0.572990; batch adversarial loss: 0.606670\n",
      "epoch 26; iter: 400; batch classifier loss: 0.453624; batch adversarial loss: 0.613054\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475769; batch adversarial loss: 0.639648\n",
      "epoch 27; iter: 200; batch classifier loss: 0.462431; batch adversarial loss: 0.661060\n",
      "epoch 27; iter: 400; batch classifier loss: 0.350912; batch adversarial loss: 0.622631\n",
      "epoch 28; iter: 0; batch classifier loss: 0.392544; batch adversarial loss: 0.679687\n",
      "epoch 28; iter: 200; batch classifier loss: 0.417550; batch adversarial loss: 0.693695\n",
      "epoch 28; iter: 400; batch classifier loss: 0.360787; batch adversarial loss: 0.623081\n",
      "epoch 29; iter: 0; batch classifier loss: 0.465384; batch adversarial loss: 0.610487\n",
      "epoch 29; iter: 200; batch classifier loss: 0.549633; batch adversarial loss: 0.607099\n",
      "epoch 29; iter: 400; batch classifier loss: 0.188516; batch adversarial loss: 0.664131\n",
      "epoch 30; iter: 0; batch classifier loss: 0.331958; batch adversarial loss: 0.622250\n",
      "epoch 30; iter: 200; batch classifier loss: 0.486832; batch adversarial loss: 0.593160\n",
      "epoch 30; iter: 400; batch classifier loss: 0.589358; batch adversarial loss: 0.580287\n",
      "epoch 31; iter: 0; batch classifier loss: 0.586242; batch adversarial loss: 0.499210\n",
      "epoch 31; iter: 200; batch classifier loss: 0.422543; batch adversarial loss: 0.653514\n",
      "epoch 31; iter: 400; batch classifier loss: 0.556295; batch adversarial loss: 0.776102\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423150; batch adversarial loss: 0.642969\n",
      "epoch 32; iter: 200; batch classifier loss: 0.389598; batch adversarial loss: 0.689514\n",
      "epoch 32; iter: 400; batch classifier loss: 0.514817; batch adversarial loss: 0.636834\n",
      "epoch 33; iter: 0; batch classifier loss: 0.334694; batch adversarial loss: 0.605256\n",
      "epoch 33; iter: 200; batch classifier loss: 0.428561; batch adversarial loss: 0.655194\n",
      "epoch 33; iter: 400; batch classifier loss: 0.543312; batch adversarial loss: 0.644542\n",
      "epoch 34; iter: 0; batch classifier loss: 0.395876; batch adversarial loss: 0.648511\n",
      "epoch 34; iter: 200; batch classifier loss: 0.362897; batch adversarial loss: 0.617375\n",
      "epoch 34; iter: 400; batch classifier loss: 0.372048; batch adversarial loss: 0.671756\n",
      "epoch 35; iter: 0; batch classifier loss: 0.283571; batch adversarial loss: 0.660232\n",
      "epoch 35; iter: 200; batch classifier loss: 0.532258; batch adversarial loss: 0.591471\n",
      "epoch 35; iter: 400; batch classifier loss: 0.521021; batch adversarial loss: 0.698502\n",
      "epoch 36; iter: 0; batch classifier loss: 0.348502; batch adversarial loss: 0.602095\n",
      "epoch 36; iter: 200; batch classifier loss: 0.266070; batch adversarial loss: 0.644170\n",
      "epoch 36; iter: 400; batch classifier loss: 0.441825; batch adversarial loss: 0.647184\n",
      "epoch 37; iter: 0; batch classifier loss: 0.570864; batch adversarial loss: 0.619368\n",
      "epoch 37; iter: 200; batch classifier loss: 0.568230; batch adversarial loss: 0.637542\n",
      "epoch 37; iter: 400; batch classifier loss: 0.217222; batch adversarial loss: 0.657711\n",
      "epoch 38; iter: 0; batch classifier loss: 0.704907; batch adversarial loss: 0.563814\n",
      "epoch 38; iter: 200; batch classifier loss: 0.500722; batch adversarial loss: 0.657201\n",
      "epoch 38; iter: 400; batch classifier loss: 0.368555; batch adversarial loss: 0.618696\n",
      "epoch 39; iter: 0; batch classifier loss: 0.359863; batch adversarial loss: 0.674457\n",
      "epoch 39; iter: 200; batch classifier loss: 0.215548; batch adversarial loss: 0.585419\n",
      "epoch 39; iter: 400; batch classifier loss: 0.567796; batch adversarial loss: 0.597516\n",
      "epoch 40; iter: 0; batch classifier loss: 0.559102; batch adversarial loss: 0.668966\n",
      "epoch 40; iter: 200; batch classifier loss: 1.875694; batch adversarial loss: 0.585815\n",
      "epoch 40; iter: 400; batch classifier loss: 0.325020; batch adversarial loss: 0.726254\n",
      "epoch 41; iter: 0; batch classifier loss: 0.806243; batch adversarial loss: 0.583201\n",
      "epoch 41; iter: 200; batch classifier loss: 0.279770; batch adversarial loss: 0.603997\n",
      "epoch 41; iter: 400; batch classifier loss: 0.828092; batch adversarial loss: 0.607735\n",
      "epoch 42; iter: 0; batch classifier loss: 0.596316; batch adversarial loss: 0.646188\n",
      "epoch 42; iter: 200; batch classifier loss: 0.574325; batch adversarial loss: 0.583275\n",
      "epoch 42; iter: 400; batch classifier loss: 0.374977; batch adversarial loss: 0.651466\n",
      "epoch 43; iter: 0; batch classifier loss: 0.238916; batch adversarial loss: 0.645514\n",
      "epoch 43; iter: 200; batch classifier loss: 0.557232; batch adversarial loss: 0.672503\n",
      "epoch 43; iter: 400; batch classifier loss: 0.325452; batch adversarial loss: 0.628866\n",
      "epoch 44; iter: 0; batch classifier loss: 0.590599; batch adversarial loss: 0.643134\n",
      "epoch 44; iter: 200; batch classifier loss: 0.619492; batch adversarial loss: 0.573372\n",
      "epoch 44; iter: 400; batch classifier loss: 0.283104; batch adversarial loss: 0.644549\n",
      "epoch 45; iter: 0; batch classifier loss: 0.638344; batch adversarial loss: 0.664950\n",
      "epoch 45; iter: 200; batch classifier loss: 0.554741; batch adversarial loss: 0.621506\n",
      "epoch 45; iter: 400; batch classifier loss: 0.485417; batch adversarial loss: 0.607342\n",
      "epoch 46; iter: 0; batch classifier loss: 0.595783; batch adversarial loss: 0.638031\n",
      "epoch 46; iter: 200; batch classifier loss: 0.449609; batch adversarial loss: 0.634261\n",
      "epoch 46; iter: 400; batch classifier loss: 0.253953; batch adversarial loss: 0.617413\n",
      "epoch 47; iter: 0; batch classifier loss: 0.751376; batch adversarial loss: 0.717451\n",
      "epoch 47; iter: 200; batch classifier loss: 0.592168; batch adversarial loss: 0.663284\n",
      "epoch 47; iter: 400; batch classifier loss: 0.566944; batch adversarial loss: 0.691854\n",
      "epoch 48; iter: 0; batch classifier loss: 0.485530; batch adversarial loss: 0.639672\n",
      "epoch 48; iter: 200; batch classifier loss: 0.324248; batch adversarial loss: 0.663815\n",
      "epoch 48; iter: 400; batch classifier loss: 0.494824; batch adversarial loss: 0.581385\n",
      "epoch 49; iter: 0; batch classifier loss: 0.544568; batch adversarial loss: 0.702579\n",
      "epoch 49; iter: 200; batch classifier loss: 0.314256; batch adversarial loss: 0.668582\n",
      "epoch 49; iter: 400; batch classifier loss: 0.320982; batch adversarial loss: 0.577601\n",
      "epoch 0; iter: 0; batch classifier loss: 5.607921; batch adversarial loss: 0.715382\n",
      "epoch 0; iter: 200; batch classifier loss: 7.630888; batch adversarial loss: 0.660959\n",
      "epoch 0; iter: 400; batch classifier loss: 8.303095; batch adversarial loss: 0.590734\n",
      "epoch 1; iter: 0; batch classifier loss: 1.863280; batch adversarial loss: 0.638610\n",
      "epoch 1; iter: 200; batch classifier loss: 6.444265; batch adversarial loss: 0.614312\n",
      "epoch 1; iter: 400; batch classifier loss: 2.821286; batch adversarial loss: 0.633557\n",
      "epoch 2; iter: 0; batch classifier loss: 4.422589; batch adversarial loss: 0.658634\n",
      "epoch 2; iter: 200; batch classifier loss: 1.824430; batch adversarial loss: 0.579629\n",
      "epoch 2; iter: 400; batch classifier loss: 9.356465; batch adversarial loss: 0.690964\n",
      "epoch 3; iter: 0; batch classifier loss: 4.322662; batch adversarial loss: 0.627043\n",
      "epoch 3; iter: 200; batch classifier loss: 0.976676; batch adversarial loss: 0.681283\n",
      "epoch 3; iter: 400; batch classifier loss: 0.486098; batch adversarial loss: 0.632742\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634043; batch adversarial loss: 0.614002\n",
      "epoch 4; iter: 200; batch classifier loss: 1.709118; batch adversarial loss: 0.583568\n",
      "epoch 4; iter: 400; batch classifier loss: 1.210692; batch adversarial loss: 0.611048\n",
      "epoch 5; iter: 0; batch classifier loss: 1.148903; batch adversarial loss: 0.551756\n",
      "epoch 5; iter: 200; batch classifier loss: 1.609294; batch adversarial loss: 0.596176\n",
      "epoch 5; iter: 400; batch classifier loss: 2.008364; batch adversarial loss: 0.587592\n",
      "epoch 6; iter: 0; batch classifier loss: 1.889609; batch adversarial loss: 0.597117\n",
      "epoch 6; iter: 200; batch classifier loss: 0.628578; batch adversarial loss: 0.691248\n",
      "epoch 6; iter: 400; batch classifier loss: 0.382646; batch adversarial loss: 0.580963\n",
      "epoch 7; iter: 0; batch classifier loss: 0.465747; batch adversarial loss: 0.579454\n",
      "epoch 7; iter: 200; batch classifier loss: 0.423850; batch adversarial loss: 0.596819\n",
      "epoch 7; iter: 400; batch classifier loss: 0.750180; batch adversarial loss: 0.626183\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532329; batch adversarial loss: 0.632160\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452916; batch adversarial loss: 0.638294\n",
      "epoch 8; iter: 400; batch classifier loss: 0.525368; batch adversarial loss: 0.660126\n",
      "epoch 9; iter: 0; batch classifier loss: 0.456807; batch adversarial loss: 0.694459\n",
      "epoch 9; iter: 200; batch classifier loss: 0.442450; batch adversarial loss: 0.669349\n",
      "epoch 9; iter: 400; batch classifier loss: 0.411732; batch adversarial loss: 0.599992\n",
      "epoch 10; iter: 0; batch classifier loss: 0.370634; batch adversarial loss: 0.608315\n",
      "epoch 10; iter: 200; batch classifier loss: 0.340383; batch adversarial loss: 0.570962\n",
      "epoch 10; iter: 400; batch classifier loss: 0.340434; batch adversarial loss: 0.625149\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403910; batch adversarial loss: 0.730188\n",
      "epoch 11; iter: 200; batch classifier loss: 0.416355; batch adversarial loss: 0.554622\n",
      "epoch 11; iter: 400; batch classifier loss: 0.434487; batch adversarial loss: 0.605160\n",
      "epoch 12; iter: 0; batch classifier loss: 0.411784; batch adversarial loss: 0.563085\n",
      "epoch 12; iter: 200; batch classifier loss: 0.352089; batch adversarial loss: 0.700823\n",
      "epoch 12; iter: 400; batch classifier loss: 0.424533; batch adversarial loss: 0.684689\n",
      "epoch 13; iter: 0; batch classifier loss: 0.317133; batch adversarial loss: 0.601990\n",
      "epoch 13; iter: 200; batch classifier loss: 0.341664; batch adversarial loss: 0.609630\n",
      "epoch 13; iter: 400; batch classifier loss: 0.206856; batch adversarial loss: 0.651027\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371697; batch adversarial loss: 0.570041\n",
      "epoch 14; iter: 200; batch classifier loss: 0.279546; batch adversarial loss: 0.699333\n",
      "epoch 14; iter: 400; batch classifier loss: 0.352251; batch adversarial loss: 0.645169\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428259; batch adversarial loss: 0.583044\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333109; batch adversarial loss: 0.580479\n",
      "epoch 15; iter: 400; batch classifier loss: 0.214033; batch adversarial loss: 0.606911\n",
      "epoch 16; iter: 0; batch classifier loss: 0.367106; batch adversarial loss: 0.636119\n",
      "epoch 16; iter: 200; batch classifier loss: 0.316887; batch adversarial loss: 0.643617\n",
      "epoch 16; iter: 400; batch classifier loss: 0.340017; batch adversarial loss: 0.643540\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367808; batch adversarial loss: 0.528665\n",
      "epoch 17; iter: 200; batch classifier loss: 0.412703; batch adversarial loss: 0.596829\n",
      "epoch 17; iter: 400; batch classifier loss: 0.359310; batch adversarial loss: 0.691018\n",
      "epoch 18; iter: 0; batch classifier loss: 0.295992; batch adversarial loss: 0.618958\n",
      "epoch 18; iter: 200; batch classifier loss: 0.517190; batch adversarial loss: 0.660242\n",
      "epoch 18; iter: 400; batch classifier loss: 0.730624; batch adversarial loss: 0.596266\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375443; batch adversarial loss: 0.580013\n",
      "epoch 19; iter: 200; batch classifier loss: 0.430199; batch adversarial loss: 0.585484\n",
      "epoch 19; iter: 400; batch classifier loss: 0.413986; batch adversarial loss: 0.636059\n",
      "epoch 20; iter: 0; batch classifier loss: 0.477783; batch adversarial loss: 0.685881\n",
      "epoch 20; iter: 200; batch classifier loss: 0.478407; batch adversarial loss: 0.630510\n",
      "epoch 20; iter: 400; batch classifier loss: 0.272886; batch adversarial loss: 0.618601\n",
      "epoch 21; iter: 0; batch classifier loss: 0.426970; batch adversarial loss: 0.592992\n",
      "epoch 21; iter: 200; batch classifier loss: 0.389469; batch adversarial loss: 0.551978\n",
      "epoch 21; iter: 400; batch classifier loss: 0.387913; batch adversarial loss: 0.602516\n",
      "epoch 22; iter: 0; batch classifier loss: 0.425027; batch adversarial loss: 0.625233\n",
      "epoch 22; iter: 200; batch classifier loss: 0.503298; batch adversarial loss: 0.617347\n",
      "epoch 22; iter: 400; batch classifier loss: 0.385616; batch adversarial loss: 0.617530\n",
      "epoch 23; iter: 0; batch classifier loss: 0.294405; batch adversarial loss: 0.683599\n",
      "epoch 23; iter: 200; batch classifier loss: 0.413486; batch adversarial loss: 0.640853\n",
      "epoch 23; iter: 400; batch classifier loss: 0.535199; batch adversarial loss: 0.596110\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403727; batch adversarial loss: 0.591677\n",
      "epoch 24; iter: 200; batch classifier loss: 0.489140; batch adversarial loss: 0.589969\n",
      "epoch 24; iter: 400; batch classifier loss: 0.321619; batch adversarial loss: 0.646519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525546; batch adversarial loss: 0.637436\n",
      "epoch 25; iter: 200; batch classifier loss: 0.397027; batch adversarial loss: 0.640618\n",
      "epoch 25; iter: 400; batch classifier loss: 0.361126; batch adversarial loss: 0.718789\n",
      "epoch 26; iter: 0; batch classifier loss: 0.247458; batch adversarial loss: 0.727961\n",
      "epoch 26; iter: 200; batch classifier loss: 0.429005; batch adversarial loss: 0.674160\n",
      "epoch 26; iter: 400; batch classifier loss: 0.531228; batch adversarial loss: 0.599311\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441851; batch adversarial loss: 0.702566\n",
      "epoch 27; iter: 200; batch classifier loss: 0.633004; batch adversarial loss: 0.693202\n",
      "epoch 27; iter: 400; batch classifier loss: 0.403359; batch adversarial loss: 0.669004\n",
      "epoch 28; iter: 0; batch classifier loss: 0.282001; batch adversarial loss: 0.635797\n",
      "epoch 28; iter: 200; batch classifier loss: 0.258804; batch adversarial loss: 0.604865\n",
      "epoch 28; iter: 400; batch classifier loss: 0.336326; batch adversarial loss: 0.676716\n",
      "epoch 29; iter: 0; batch classifier loss: 0.235162; batch adversarial loss: 0.687632\n",
      "epoch 29; iter: 200; batch classifier loss: 0.614831; batch adversarial loss: 0.595980\n",
      "epoch 29; iter: 400; batch classifier loss: 0.351675; batch adversarial loss: 0.661370\n",
      "epoch 30; iter: 0; batch classifier loss: 0.653784; batch adversarial loss: 0.637661\n",
      "epoch 30; iter: 200; batch classifier loss: 0.351743; batch adversarial loss: 0.646491\n",
      "epoch 30; iter: 400; batch classifier loss: 0.502653; batch adversarial loss: 0.590514\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523412; batch adversarial loss: 0.578310\n",
      "epoch 31; iter: 200; batch classifier loss: 0.462170; batch adversarial loss: 0.595037\n",
      "epoch 31; iter: 400; batch classifier loss: 0.431594; batch adversarial loss: 0.647354\n",
      "epoch 32; iter: 0; batch classifier loss: 0.356840; batch adversarial loss: 0.614810\n",
      "epoch 32; iter: 200; batch classifier loss: 0.446791; batch adversarial loss: 0.672962\n",
      "epoch 32; iter: 400; batch classifier loss: 0.497518; batch adversarial loss: 0.645173\n",
      "epoch 33; iter: 0; batch classifier loss: 0.987448; batch adversarial loss: 0.629290\n",
      "epoch 33; iter: 200; batch classifier loss: 0.412134; batch adversarial loss: 0.590232\n",
      "epoch 33; iter: 400; batch classifier loss: 0.536589; batch adversarial loss: 0.669443\n",
      "epoch 34; iter: 0; batch classifier loss: 0.643614; batch adversarial loss: 0.605674\n",
      "epoch 34; iter: 200; batch classifier loss: 0.324060; batch adversarial loss: 0.678955\n",
      "epoch 34; iter: 400; batch classifier loss: 0.405435; batch adversarial loss: 0.731243\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465828; batch adversarial loss: 0.700278\n",
      "epoch 35; iter: 200; batch classifier loss: 0.465856; batch adversarial loss: 0.598149\n",
      "epoch 35; iter: 400; batch classifier loss: 0.456649; batch adversarial loss: 0.629452\n",
      "epoch 36; iter: 0; batch classifier loss: 0.481429; batch adversarial loss: 0.659754\n",
      "epoch 36; iter: 200; batch classifier loss: 0.407684; batch adversarial loss: 0.636073\n",
      "epoch 36; iter: 400; batch classifier loss: 0.362341; batch adversarial loss: 0.642508\n",
      "epoch 37; iter: 0; batch classifier loss: 0.376397; batch adversarial loss: 0.619359\n",
      "epoch 37; iter: 200; batch classifier loss: 0.714663; batch adversarial loss: 0.594787\n",
      "epoch 37; iter: 400; batch classifier loss: 0.618102; batch adversarial loss: 0.576521\n",
      "epoch 38; iter: 0; batch classifier loss: 0.310773; batch adversarial loss: 0.672211\n",
      "epoch 38; iter: 200; batch classifier loss: 0.400424; batch adversarial loss: 0.678036\n",
      "epoch 38; iter: 400; batch classifier loss: 0.638340; batch adversarial loss: 0.600866\n",
      "epoch 39; iter: 0; batch classifier loss: 0.443099; batch adversarial loss: 0.596567\n",
      "epoch 39; iter: 200; batch classifier loss: 0.457860; batch adversarial loss: 0.567548\n",
      "epoch 39; iter: 400; batch classifier loss: 0.375823; batch adversarial loss: 0.681226\n",
      "epoch 40; iter: 0; batch classifier loss: 0.346227; batch adversarial loss: 0.704549\n",
      "epoch 40; iter: 200; batch classifier loss: 0.434849; batch adversarial loss: 0.665624\n",
      "epoch 40; iter: 400; batch classifier loss: 0.438192; batch adversarial loss: 0.659962\n",
      "epoch 41; iter: 0; batch classifier loss: 0.599949; batch adversarial loss: 0.599437\n",
      "epoch 41; iter: 200; batch classifier loss: 0.409712; batch adversarial loss: 0.633728\n",
      "epoch 41; iter: 400; batch classifier loss: 0.517142; batch adversarial loss: 0.625049\n",
      "epoch 42; iter: 0; batch classifier loss: 0.729655; batch adversarial loss: 0.609405\n",
      "epoch 42; iter: 200; batch classifier loss: 0.509712; batch adversarial loss: 0.627415\n",
      "epoch 42; iter: 400; batch classifier loss: 0.526503; batch adversarial loss: 0.581578\n",
      "epoch 43; iter: 0; batch classifier loss: 0.627973; batch adversarial loss: 0.588722\n",
      "epoch 43; iter: 200; batch classifier loss: 0.603535; batch adversarial loss: 0.660771\n",
      "epoch 43; iter: 400; batch classifier loss: 0.520013; batch adversarial loss: 0.684732\n",
      "epoch 44; iter: 0; batch classifier loss: 0.438148; batch adversarial loss: 0.590418\n",
      "epoch 44; iter: 200; batch classifier loss: 0.642866; batch adversarial loss: 0.539328\n",
      "epoch 44; iter: 400; batch classifier loss: 0.385182; batch adversarial loss: 0.603948\n",
      "epoch 45; iter: 0; batch classifier loss: 0.524058; batch adversarial loss: 0.609754\n",
      "epoch 45; iter: 200; batch classifier loss: 0.562557; batch adversarial loss: 0.654267\n",
      "epoch 45; iter: 400; batch classifier loss: 0.359553; batch adversarial loss: 0.654583\n",
      "epoch 46; iter: 0; batch classifier loss: 0.645366; batch adversarial loss: 0.702484\n",
      "epoch 46; iter: 200; batch classifier loss: 0.477695; batch adversarial loss: 0.556391\n",
      "epoch 46; iter: 400; batch classifier loss: 0.304575; batch adversarial loss: 0.597538\n",
      "epoch 47; iter: 0; batch classifier loss: 0.480527; batch adversarial loss: 0.611911\n",
      "epoch 47; iter: 200; batch classifier loss: 0.408544; batch adversarial loss: 0.616684\n",
      "epoch 47; iter: 400; batch classifier loss: 0.637058; batch adversarial loss: 0.587482\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410569; batch adversarial loss: 0.574829\n",
      "epoch 48; iter: 200; batch classifier loss: 0.545548; batch adversarial loss: 0.613865\n",
      "epoch 48; iter: 400; batch classifier loss: 0.398943; batch adversarial loss: 0.665067\n",
      "epoch 49; iter: 0; batch classifier loss: 0.666404; batch adversarial loss: 0.612248\n",
      "epoch 49; iter: 200; batch classifier loss: 0.358520; batch adversarial loss: 0.687024\n",
      "epoch 49; iter: 400; batch classifier loss: 0.285718; batch adversarial loss: 0.681586\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 10}\n",
      "epoch 0; iter: 0; batch classifier loss: 122.433800; batch adversarial loss: 0.630812\n",
      "epoch 0; iter: 200; batch classifier loss: 51.550209; batch adversarial loss: 0.647118\n",
      "epoch 1; iter: 0; batch classifier loss: 3.022707; batch adversarial loss: 0.654338\n",
      "epoch 1; iter: 200; batch classifier loss: 6.985971; batch adversarial loss: 0.631747\n",
      "epoch 2; iter: 0; batch classifier loss: 7.243031; batch adversarial loss: 0.603812\n",
      "epoch 2; iter: 200; batch classifier loss: 7.022836; batch adversarial loss: 0.651432\n",
      "epoch 3; iter: 0; batch classifier loss: 4.829587; batch adversarial loss: 0.633152\n",
      "epoch 3; iter: 200; batch classifier loss: 4.284873; batch adversarial loss: 0.607098\n",
      "epoch 4; iter: 0; batch classifier loss: 3.692602; batch adversarial loss: 0.608836\n",
      "epoch 4; iter: 200; batch classifier loss: 1.762898; batch adversarial loss: 0.632533\n",
      "epoch 5; iter: 0; batch classifier loss: 4.635032; batch adversarial loss: 0.628252\n",
      "epoch 5; iter: 200; batch classifier loss: 2.496880; batch adversarial loss: 0.655352\n",
      "epoch 6; iter: 0; batch classifier loss: 1.750464; batch adversarial loss: 0.634064\n",
      "epoch 6; iter: 200; batch classifier loss: 2.109082; batch adversarial loss: 0.640321\n",
      "epoch 7; iter: 0; batch classifier loss: 4.547024; batch adversarial loss: 0.625351\n",
      "epoch 7; iter: 200; batch classifier loss: 0.408645; batch adversarial loss: 0.574760\n",
      "epoch 8; iter: 0; batch classifier loss: 0.544839; batch adversarial loss: 0.611339\n",
      "epoch 8; iter: 200; batch classifier loss: 0.935561; batch adversarial loss: 0.632948\n",
      "epoch 9; iter: 0; batch classifier loss: 2.064705; batch adversarial loss: 0.653887\n",
      "epoch 9; iter: 200; batch classifier loss: 0.720228; batch adversarial loss: 0.640715\n",
      "epoch 0; iter: 0; batch classifier loss: 36.105682; batch adversarial loss: 0.626354\n",
      "epoch 0; iter: 200; batch classifier loss: 5.409575; batch adversarial loss: 0.692548\n",
      "epoch 1; iter: 0; batch classifier loss: 4.888703; batch adversarial loss: 0.679849\n",
      "epoch 1; iter: 200; batch classifier loss: 7.210169; batch adversarial loss: 0.602699\n",
      "epoch 2; iter: 0; batch classifier loss: 2.696353; batch adversarial loss: 0.607984\n",
      "epoch 2; iter: 200; batch classifier loss: 3.960177; batch adversarial loss: 0.633126\n",
      "epoch 3; iter: 0; batch classifier loss: 1.912221; batch adversarial loss: 0.623606\n",
      "epoch 3; iter: 200; batch classifier loss: 3.463925; batch adversarial loss: 0.622213\n",
      "epoch 4; iter: 0; batch classifier loss: 4.573184; batch adversarial loss: 0.630561\n",
      "epoch 4; iter: 200; batch classifier loss: 0.871262; batch adversarial loss: 0.592345\n",
      "epoch 5; iter: 0; batch classifier loss: 2.221026; batch adversarial loss: 0.628238\n",
      "epoch 5; iter: 200; batch classifier loss: 2.051504; batch adversarial loss: 0.615399\n",
      "epoch 6; iter: 0; batch classifier loss: 1.441684; batch adversarial loss: 0.630971\n",
      "epoch 6; iter: 200; batch classifier loss: 0.444611; batch adversarial loss: 0.664419\n",
      "epoch 7; iter: 0; batch classifier loss: 0.800516; batch adversarial loss: 0.715183\n",
      "epoch 7; iter: 200; batch classifier loss: 0.615333; batch adversarial loss: 0.576890\n",
      "epoch 8; iter: 0; batch classifier loss: 2.367902; batch adversarial loss: 0.620809\n",
      "epoch 8; iter: 200; batch classifier loss: 0.790577; batch adversarial loss: 0.596612\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492732; batch adversarial loss: 0.619442\n",
      "epoch 9; iter: 200; batch classifier loss: 0.609958; batch adversarial loss: 0.629372\n",
      "epoch 0; iter: 0; batch classifier loss: 8.446466; batch adversarial loss: 0.641135\n",
      "epoch 0; iter: 200; batch classifier loss: 6.335302; batch adversarial loss: 0.649246\n",
      "epoch 1; iter: 0; batch classifier loss: 1.713391; batch adversarial loss: 0.619369\n",
      "epoch 1; iter: 200; batch classifier loss: 12.073416; batch adversarial loss: 0.684737\n",
      "epoch 2; iter: 0; batch classifier loss: 7.751177; batch adversarial loss: 0.657866\n",
      "epoch 2; iter: 200; batch classifier loss: 3.318439; batch adversarial loss: 0.564063\n",
      "epoch 3; iter: 0; batch classifier loss: 9.148348; batch adversarial loss: 0.670347\n",
      "epoch 3; iter: 200; batch classifier loss: 1.250927; batch adversarial loss: 0.622422\n",
      "epoch 4; iter: 0; batch classifier loss: 0.842716; batch adversarial loss: 0.608963\n",
      "epoch 4; iter: 200; batch classifier loss: 3.498797; batch adversarial loss: 0.604703\n",
      "epoch 5; iter: 0; batch classifier loss: 1.620514; batch adversarial loss: 0.664859\n",
      "epoch 5; iter: 200; batch classifier loss: 1.016623; batch adversarial loss: 0.605016\n",
      "epoch 6; iter: 0; batch classifier loss: 2.679896; batch adversarial loss: 0.611502\n",
      "epoch 6; iter: 200; batch classifier loss: 0.783960; batch adversarial loss: 0.597303\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606065; batch adversarial loss: 0.614311\n",
      "epoch 7; iter: 200; batch classifier loss: 1.031738; batch adversarial loss: 0.637954\n",
      "epoch 8; iter: 0; batch classifier loss: 0.768899; batch adversarial loss: 0.655379\n",
      "epoch 8; iter: 200; batch classifier loss: 0.962146; batch adversarial loss: 0.614961\n",
      "epoch 9; iter: 0; batch classifier loss: 0.692580; batch adversarial loss: 0.616425\n",
      "epoch 9; iter: 200; batch classifier loss: 0.452486; batch adversarial loss: 0.670200\n",
      "epoch 0; iter: 0; batch classifier loss: 54.928894; batch adversarial loss: 0.673095\n",
      "epoch 0; iter: 200; batch classifier loss: 11.160696; batch adversarial loss: 0.676746\n",
      "epoch 1; iter: 0; batch classifier loss: 8.454272; batch adversarial loss: 0.663138\n",
      "epoch 1; iter: 200; batch classifier loss: 18.427420; batch adversarial loss: 0.630959\n",
      "epoch 2; iter: 0; batch classifier loss: 7.786401; batch adversarial loss: 0.646915\n",
      "epoch 2; iter: 200; batch classifier loss: 8.097669; batch adversarial loss: 0.687168\n",
      "epoch 3; iter: 0; batch classifier loss: 4.198770; batch adversarial loss: 0.662091\n",
      "epoch 3; iter: 200; batch classifier loss: 6.615196; batch adversarial loss: 0.646026\n",
      "epoch 4; iter: 0; batch classifier loss: 16.708540; batch adversarial loss: 0.611045\n",
      "epoch 4; iter: 200; batch classifier loss: 3.229226; batch adversarial loss: 0.617026\n",
      "epoch 5; iter: 0; batch classifier loss: 3.058303; batch adversarial loss: 0.627012\n",
      "epoch 5; iter: 200; batch classifier loss: 2.136601; batch adversarial loss: 0.640685\n",
      "epoch 6; iter: 0; batch classifier loss: 3.267282; batch adversarial loss: 0.613735\n",
      "epoch 6; iter: 200; batch classifier loss: 2.252114; batch adversarial loss: 0.627335\n",
      "epoch 7; iter: 0; batch classifier loss: 1.237732; batch adversarial loss: 0.626647\n",
      "epoch 7; iter: 200; batch classifier loss: 1.989173; batch adversarial loss: 0.588949\n",
      "epoch 8; iter: 0; batch classifier loss: 0.663073; batch adversarial loss: 0.651988\n",
      "epoch 8; iter: 200; batch classifier loss: 0.687506; batch adversarial loss: 0.700795\n",
      "epoch 9; iter: 0; batch classifier loss: 0.945675; batch adversarial loss: 0.637554\n",
      "epoch 9; iter: 200; batch classifier loss: 0.760719; batch adversarial loss: 0.609828\n",
      "epoch 0; iter: 0; batch classifier loss: 28.359137; batch adversarial loss: 0.628784\n",
      "epoch 0; iter: 200; batch classifier loss: 14.049839; batch adversarial loss: 0.676246\n",
      "epoch 1; iter: 0; batch classifier loss: 25.538427; batch adversarial loss: 0.656363\n",
      "epoch 1; iter: 200; batch classifier loss: 3.352327; batch adversarial loss: 0.645274\n",
      "epoch 2; iter: 0; batch classifier loss: 6.033411; batch adversarial loss: 0.639222\n",
      "epoch 2; iter: 200; batch classifier loss: 9.644413; batch adversarial loss: 0.596408\n",
      "epoch 3; iter: 0; batch classifier loss: 3.753321; batch adversarial loss: 0.601357\n",
      "epoch 3; iter: 200; batch classifier loss: 5.200638; batch adversarial loss: 0.628772\n",
      "epoch 4; iter: 0; batch classifier loss: 2.059414; batch adversarial loss: 0.639201\n",
      "epoch 4; iter: 200; batch classifier loss: 2.638812; batch adversarial loss: 0.629397\n",
      "epoch 5; iter: 0; batch classifier loss: 4.388170; batch adversarial loss: 0.631277\n",
      "epoch 5; iter: 200; batch classifier loss: 5.613520; batch adversarial loss: 0.669613\n",
      "epoch 6; iter: 0; batch classifier loss: 1.307122; batch adversarial loss: 0.600585\n",
      "epoch 6; iter: 200; batch classifier loss: 1.043328; batch adversarial loss: 0.652125\n",
      "epoch 7; iter: 0; batch classifier loss: 1.076575; batch adversarial loss: 0.616781\n",
      "epoch 7; iter: 200; batch classifier loss: 1.585600; batch adversarial loss: 0.637818\n",
      "epoch 8; iter: 0; batch classifier loss: 0.470661; batch adversarial loss: 0.573253\n",
      "epoch 8; iter: 200; batch classifier loss: 0.876470; batch adversarial loss: 0.610083\n",
      "epoch 9; iter: 0; batch classifier loss: 0.551991; batch adversarial loss: 0.668634\n",
      "epoch 9; iter: 200; batch classifier loss: 0.883820; batch adversarial loss: 0.667701\n",
      "epoch 0; iter: 0; batch classifier loss: 24.187626; batch adversarial loss: 0.654410\n",
      "epoch 0; iter: 200; batch classifier loss: 18.697323; batch adversarial loss: 0.617907\n",
      "epoch 1; iter: 0; batch classifier loss: 5.379856; batch adversarial loss: 0.590295\n",
      "epoch 1; iter: 200; batch classifier loss: 12.935890; batch adversarial loss: 0.627683\n",
      "epoch 2; iter: 0; batch classifier loss: 4.967782; batch adversarial loss: 0.579810\n",
      "epoch 2; iter: 200; batch classifier loss: 4.580329; batch adversarial loss: 0.638555\n",
      "epoch 3; iter: 0; batch classifier loss: 26.961973; batch adversarial loss: 0.616807\n",
      "epoch 3; iter: 200; batch classifier loss: 0.679082; batch adversarial loss: 0.634358\n",
      "epoch 4; iter: 0; batch classifier loss: 3.294689; batch adversarial loss: 0.632207\n",
      "epoch 4; iter: 200; batch classifier loss: 0.882026; batch adversarial loss: 0.599468\n",
      "epoch 5; iter: 0; batch classifier loss: 1.109282; batch adversarial loss: 0.608231\n",
      "epoch 5; iter: 200; batch classifier loss: 0.438785; batch adversarial loss: 0.670704\n",
      "epoch 6; iter: 0; batch classifier loss: 1.248789; batch adversarial loss: 0.601721\n",
      "epoch 6; iter: 200; batch classifier loss: 0.708088; batch adversarial loss: 0.664085\n",
      "epoch 7; iter: 0; batch classifier loss: 1.232232; batch adversarial loss: 0.573007\n",
      "epoch 7; iter: 200; batch classifier loss: 0.611462; batch adversarial loss: 0.652309\n",
      "epoch 8; iter: 0; batch classifier loss: 1.331722; batch adversarial loss: 0.626298\n",
      "epoch 8; iter: 200; batch classifier loss: 0.471493; batch adversarial loss: 0.653264\n",
      "epoch 9; iter: 0; batch classifier loss: 0.676499; batch adversarial loss: 0.638813\n",
      "epoch 9; iter: 200; batch classifier loss: 0.511094; batch adversarial loss: 0.646062\n",
      "epoch 0; iter: 0; batch classifier loss: 291.045410; batch adversarial loss: 0.899145\n",
      "epoch 0; iter: 200; batch classifier loss: 6.497665; batch adversarial loss: 0.949542\n",
      "epoch 1; iter: 0; batch classifier loss: 5.687085; batch adversarial loss: 0.954053\n",
      "epoch 1; iter: 200; batch classifier loss: 3.150207; batch adversarial loss: 0.803228\n",
      "epoch 2; iter: 0; batch classifier loss: 6.300995; batch adversarial loss: 0.780339\n",
      "epoch 2; iter: 200; batch classifier loss: 9.312142; batch adversarial loss: 0.691369\n",
      "epoch 3; iter: 0; batch classifier loss: 2.563967; batch adversarial loss: 0.635685\n",
      "epoch 3; iter: 200; batch classifier loss: 4.563097; batch adversarial loss: 0.643343\n",
      "epoch 4; iter: 0; batch classifier loss: 8.857981; batch adversarial loss: 0.658914\n",
      "epoch 4; iter: 200; batch classifier loss: 2.746031; batch adversarial loss: 0.654449\n",
      "epoch 5; iter: 0; batch classifier loss: 3.903086; batch adversarial loss: 0.635271\n",
      "epoch 5; iter: 200; batch classifier loss: 1.825271; batch adversarial loss: 0.679638\n",
      "epoch 6; iter: 0; batch classifier loss: 3.693182; batch adversarial loss: 0.664752\n",
      "epoch 6; iter: 200; batch classifier loss: 1.776863; batch adversarial loss: 0.691807\n",
      "epoch 7; iter: 0; batch classifier loss: 1.130803; batch adversarial loss: 0.591325\n",
      "epoch 7; iter: 200; batch classifier loss: 1.305375; batch adversarial loss: 0.611848\n",
      "epoch 8; iter: 0; batch classifier loss: 0.743240; batch adversarial loss: 0.636622\n",
      "epoch 8; iter: 200; batch classifier loss: 0.454986; batch adversarial loss: 0.613964\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492988; batch adversarial loss: 0.614869\n",
      "epoch 9; iter: 200; batch classifier loss: 0.470295; batch adversarial loss: 0.623497\n",
      "epoch 0; iter: 0; batch classifier loss: 156.402832; batch adversarial loss: 0.749275\n",
      "epoch 0; iter: 200; batch classifier loss: 17.603992; batch adversarial loss: 0.694153\n",
      "epoch 1; iter: 0; batch classifier loss: 3.477591; batch adversarial loss: 0.686476\n",
      "epoch 1; iter: 200; batch classifier loss: 2.615683; batch adversarial loss: 0.652215\n",
      "epoch 2; iter: 0; batch classifier loss: 1.425400; batch adversarial loss: 0.640133\n",
      "epoch 2; iter: 200; batch classifier loss: 7.803260; batch adversarial loss: 0.604730\n",
      "epoch 3; iter: 0; batch classifier loss: 5.769579; batch adversarial loss: 0.645342\n",
      "epoch 3; iter: 200; batch classifier loss: 26.400606; batch adversarial loss: 0.611162\n",
      "epoch 4; iter: 0; batch classifier loss: 4.639972; batch adversarial loss: 0.645672\n",
      "epoch 4; iter: 200; batch classifier loss: 4.539317; batch adversarial loss: 0.650551\n",
      "epoch 5; iter: 0; batch classifier loss: 1.499578; batch adversarial loss: 0.574513\n",
      "epoch 5; iter: 200; batch classifier loss: 1.091347; batch adversarial loss: 0.613397\n",
      "epoch 6; iter: 0; batch classifier loss: 2.752238; batch adversarial loss: 0.608035\n",
      "epoch 6; iter: 200; batch classifier loss: 1.473414; batch adversarial loss: 0.604960\n",
      "epoch 7; iter: 0; batch classifier loss: 1.874332; batch adversarial loss: 0.585917\n",
      "epoch 7; iter: 200; batch classifier loss: 0.622258; batch adversarial loss: 0.576417\n",
      "epoch 8; iter: 0; batch classifier loss: 0.827719; batch adversarial loss: 0.633601\n",
      "epoch 8; iter: 200; batch classifier loss: 0.471214; batch adversarial loss: 0.627397\n",
      "epoch 9; iter: 0; batch classifier loss: 0.888611; batch adversarial loss: 0.661658\n",
      "epoch 9; iter: 200; batch classifier loss: 0.604372; batch adversarial loss: 0.668759\n",
      "epoch 0; iter: 0; batch classifier loss: 7.482307; batch adversarial loss: 0.775658\n",
      "epoch 0; iter: 200; batch classifier loss: 2.943607; batch adversarial loss: 0.727255\n",
      "epoch 1; iter: 0; batch classifier loss: 1.417812; batch adversarial loss: 0.686735\n",
      "epoch 1; iter: 200; batch classifier loss: 1.298826; batch adversarial loss: 0.650584\n",
      "epoch 2; iter: 0; batch classifier loss: 2.059509; batch adversarial loss: 0.632193\n",
      "epoch 2; iter: 200; batch classifier loss: 3.129030; batch adversarial loss: 0.638493\n",
      "epoch 3; iter: 0; batch classifier loss: 2.371377; batch adversarial loss: 0.623861\n",
      "epoch 3; iter: 200; batch classifier loss: 3.981154; batch adversarial loss: 0.604271\n",
      "epoch 4; iter: 0; batch classifier loss: 4.237287; batch adversarial loss: 0.672754\n",
      "epoch 4; iter: 200; batch classifier loss: 2.308627; batch adversarial loss: 0.580423\n",
      "epoch 5; iter: 0; batch classifier loss: 3.734890; batch adversarial loss: 0.637442\n",
      "epoch 5; iter: 200; batch classifier loss: 0.737587; batch adversarial loss: 0.661614\n",
      "epoch 6; iter: 0; batch classifier loss: 0.998224; batch adversarial loss: 0.618667\n",
      "epoch 6; iter: 200; batch classifier loss: 0.614999; batch adversarial loss: 0.613751\n",
      "epoch 7; iter: 0; batch classifier loss: 2.669137; batch adversarial loss: 0.645177\n",
      "epoch 7; iter: 200; batch classifier loss: 0.757172; batch adversarial loss: 0.636357\n",
      "epoch 8; iter: 0; batch classifier loss: 0.701559; batch adversarial loss: 0.635434\n",
      "epoch 8; iter: 200; batch classifier loss: 1.372740; batch adversarial loss: 0.538822\n",
      "epoch 9; iter: 0; batch classifier loss: 0.617183; batch adversarial loss: 0.580139\n",
      "epoch 9; iter: 200; batch classifier loss: 0.837400; batch adversarial loss: 0.572123\n",
      "epoch 0; iter: 0; batch classifier loss: 9.340229; batch adversarial loss: 0.669029\n",
      "epoch 0; iter: 200; batch classifier loss: 4.955168; batch adversarial loss: 0.714377\n",
      "epoch 1; iter: 0; batch classifier loss: 15.078360; batch adversarial loss: 0.706889\n",
      "epoch 1; iter: 200; batch classifier loss: 14.900334; batch adversarial loss: 0.672384\n",
      "epoch 2; iter: 0; batch classifier loss: 9.134720; batch adversarial loss: 0.651019\n",
      "epoch 2; iter: 200; batch classifier loss: 6.162206; batch adversarial loss: 0.610139\n",
      "epoch 3; iter: 0; batch classifier loss: 4.417634; batch adversarial loss: 0.622538\n",
      "epoch 3; iter: 200; batch classifier loss: 4.000365; batch adversarial loss: 0.584200\n",
      "epoch 4; iter: 0; batch classifier loss: 1.434441; batch adversarial loss: 0.569630\n",
      "epoch 4; iter: 200; batch classifier loss: 1.497962; batch adversarial loss: 0.605126\n",
      "epoch 5; iter: 0; batch classifier loss: 1.389318; batch adversarial loss: 0.631891\n",
      "epoch 5; iter: 200; batch classifier loss: 1.785631; batch adversarial loss: 0.632753\n",
      "epoch 6; iter: 0; batch classifier loss: 1.976943; batch adversarial loss: 0.615754\n",
      "epoch 6; iter: 200; batch classifier loss: 0.718966; batch adversarial loss: 0.614474\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566798; batch adversarial loss: 0.625742\n",
      "epoch 7; iter: 200; batch classifier loss: 0.688280; batch adversarial loss: 0.600080\n",
      "epoch 8; iter: 0; batch classifier loss: 0.637190; batch adversarial loss: 0.669680\n",
      "epoch 8; iter: 200; batch classifier loss: 0.403015; batch adversarial loss: 0.696408\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581745; batch adversarial loss: 0.644041\n",
      "epoch 9; iter: 200; batch classifier loss: 0.400316; batch adversarial loss: 0.663209\n",
      "epoch 0; iter: 0; batch classifier loss: 71.053230; batch adversarial loss: 0.667411\n",
      "epoch 0; iter: 200; batch classifier loss: 6.124185; batch adversarial loss: 0.608365\n",
      "epoch 1; iter: 0; batch classifier loss: 11.512857; batch adversarial loss: 0.602684\n",
      "epoch 1; iter: 200; batch classifier loss: 7.136731; batch adversarial loss: 0.553349\n",
      "epoch 2; iter: 0; batch classifier loss: 2.030843; batch adversarial loss: 0.595672\n",
      "epoch 2; iter: 200; batch classifier loss: 3.992752; batch adversarial loss: 0.608002\n",
      "epoch 3; iter: 0; batch classifier loss: 2.537924; batch adversarial loss: 0.606302\n",
      "epoch 3; iter: 200; batch classifier loss: 6.956386; batch adversarial loss: 0.670441\n",
      "epoch 4; iter: 0; batch classifier loss: 3.228337; batch adversarial loss: 0.732207\n",
      "epoch 4; iter: 200; batch classifier loss: 1.720817; batch adversarial loss: 0.622900\n",
      "epoch 5; iter: 0; batch classifier loss: 4.177870; batch adversarial loss: 0.608531\n",
      "epoch 5; iter: 200; batch classifier loss: 3.753374; batch adversarial loss: 0.604311\n",
      "epoch 6; iter: 0; batch classifier loss: 1.411067; batch adversarial loss: 0.625194\n",
      "epoch 6; iter: 200; batch classifier loss: 1.066660; batch adversarial loss: 0.660556\n",
      "epoch 7; iter: 0; batch classifier loss: 0.979118; batch adversarial loss: 0.639847\n",
      "epoch 7; iter: 200; batch classifier loss: 0.617332; batch adversarial loss: 0.613647\n",
      "epoch 8; iter: 0; batch classifier loss: 0.457671; batch adversarial loss: 0.636098\n",
      "epoch 8; iter: 200; batch classifier loss: 0.668639; batch adversarial loss: 0.599958\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512919; batch adversarial loss: 0.527489\n",
      "epoch 9; iter: 200; batch classifier loss: 0.524809; batch adversarial loss: 0.630759\n",
      "epoch 0; iter: 0; batch classifier loss: 25.312218; batch adversarial loss: 0.674246\n",
      "epoch 0; iter: 200; batch classifier loss: 1.489092; batch adversarial loss: 0.649443\n",
      "epoch 1; iter: 0; batch classifier loss: 8.367790; batch adversarial loss: 0.659052\n",
      "epoch 1; iter: 200; batch classifier loss: 4.962701; batch adversarial loss: 0.772728\n",
      "epoch 2; iter: 0; batch classifier loss: 6.079840; batch adversarial loss: 0.721870\n",
      "epoch 2; iter: 200; batch classifier loss: 1.240813; batch adversarial loss: 0.648243\n",
      "epoch 3; iter: 0; batch classifier loss: 5.857301; batch adversarial loss: 0.652081\n",
      "epoch 3; iter: 200; batch classifier loss: 3.406702; batch adversarial loss: 0.655313\n",
      "epoch 4; iter: 0; batch classifier loss: 3.553460; batch adversarial loss: 0.585549\n",
      "epoch 4; iter: 200; batch classifier loss: 4.556158; batch adversarial loss: 0.659789\n",
      "epoch 5; iter: 0; batch classifier loss: 2.026090; batch adversarial loss: 0.626041\n",
      "epoch 5; iter: 200; batch classifier loss: 2.411926; batch adversarial loss: 0.615649\n",
      "epoch 6; iter: 0; batch classifier loss: 1.816040; batch adversarial loss: 0.624636\n",
      "epoch 6; iter: 200; batch classifier loss: 3.073822; batch adversarial loss: 0.626004\n",
      "epoch 7; iter: 0; batch classifier loss: 2.910227; batch adversarial loss: 0.574766\n",
      "epoch 7; iter: 200; batch classifier loss: 0.910108; batch adversarial loss: 0.641342\n",
      "epoch 8; iter: 0; batch classifier loss: 0.434829; batch adversarial loss: 0.653810\n",
      "epoch 8; iter: 200; batch classifier loss: 0.624941; batch adversarial loss: 0.627101\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486637; batch adversarial loss: 0.622093\n",
      "epoch 9; iter: 200; batch classifier loss: 0.460553; batch adversarial loss: 0.686852\n",
      "epoch 0; iter: 0; batch classifier loss: 121.802383; batch adversarial loss: 0.691339\n",
      "epoch 0; iter: 200; batch classifier loss: 7.973092; batch adversarial loss: 0.686933\n",
      "epoch 1; iter: 0; batch classifier loss: 4.032715; batch adversarial loss: 0.658263\n",
      "epoch 1; iter: 200; batch classifier loss: 13.289352; batch adversarial loss: 0.688355\n",
      "epoch 2; iter: 0; batch classifier loss: 4.170013; batch adversarial loss: 0.649821\n",
      "epoch 2; iter: 200; batch classifier loss: 2.614600; batch adversarial loss: 0.625796\n",
      "epoch 3; iter: 0; batch classifier loss: 2.560241; batch adversarial loss: 0.673619\n",
      "epoch 3; iter: 200; batch classifier loss: 2.004029; batch adversarial loss: 0.587472\n",
      "epoch 4; iter: 0; batch classifier loss: 1.978301; batch adversarial loss: 0.624241\n",
      "epoch 4; iter: 200; batch classifier loss: 1.338948; batch adversarial loss: 0.536570\n",
      "epoch 5; iter: 0; batch classifier loss: 2.878222; batch adversarial loss: 0.643797\n",
      "epoch 5; iter: 200; batch classifier loss: 0.940463; batch adversarial loss: 0.593891\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497307; batch adversarial loss: 0.614542\n",
      "epoch 6; iter: 200; batch classifier loss: 0.545181; batch adversarial loss: 0.623960\n",
      "epoch 7; iter: 0; batch classifier loss: 0.759697; batch adversarial loss: 0.676320\n",
      "epoch 7; iter: 200; batch classifier loss: 0.594629; batch adversarial loss: 0.579466\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451848; batch adversarial loss: 0.632146\n",
      "epoch 8; iter: 200; batch classifier loss: 0.466227; batch adversarial loss: 0.589993\n",
      "epoch 9; iter: 0; batch classifier loss: 0.514513; batch adversarial loss: 0.671080\n",
      "epoch 9; iter: 200; batch classifier loss: 0.463529; batch adversarial loss: 0.633389\n",
      "epoch 0; iter: 0; batch classifier loss: 131.311249; batch adversarial loss: 0.737262\n",
      "epoch 0; iter: 200; batch classifier loss: 5.608796; batch adversarial loss: 0.682308\n",
      "epoch 1; iter: 0; batch classifier loss: 5.759590; batch adversarial loss: 0.663182\n",
      "epoch 1; iter: 200; batch classifier loss: 8.173224; batch adversarial loss: 0.640108\n",
      "epoch 2; iter: 0; batch classifier loss: 2.277414; batch adversarial loss: 0.637806\n",
      "epoch 2; iter: 200; batch classifier loss: 4.995797; batch adversarial loss: 0.659397\n",
      "epoch 3; iter: 0; batch classifier loss: 2.432675; batch adversarial loss: 0.624887\n",
      "epoch 3; iter: 200; batch classifier loss: 5.485123; batch adversarial loss: 0.575399\n",
      "epoch 4; iter: 0; batch classifier loss: 5.671295; batch adversarial loss: 0.627276\n",
      "epoch 4; iter: 200; batch classifier loss: 3.374041; batch adversarial loss: 0.662304\n",
      "epoch 5; iter: 0; batch classifier loss: 2.243771; batch adversarial loss: 0.678094\n",
      "epoch 5; iter: 200; batch classifier loss: 0.569343; batch adversarial loss: 0.653774\n",
      "epoch 6; iter: 0; batch classifier loss: 1.734034; batch adversarial loss: 0.588204\n",
      "epoch 6; iter: 200; batch classifier loss: 0.807998; batch adversarial loss: 0.598302\n",
      "epoch 7; iter: 0; batch classifier loss: 0.738410; batch adversarial loss: 0.604581\n",
      "epoch 7; iter: 200; batch classifier loss: 1.958274; batch adversarial loss: 0.644368\n",
      "epoch 8; iter: 0; batch classifier loss: 0.448079; batch adversarial loss: 0.572368\n",
      "epoch 8; iter: 200; batch classifier loss: 1.052911; batch adversarial loss: 0.637802\n",
      "epoch 9; iter: 0; batch classifier loss: 0.620396; batch adversarial loss: 0.638152\n",
      "epoch 9; iter: 200; batch classifier loss: 1.074904; batch adversarial loss: 0.685464\n",
      "epoch 0; iter: 0; batch classifier loss: 249.965546; batch adversarial loss: 0.640727\n",
      "epoch 0; iter: 200; batch classifier loss: 7.835339; batch adversarial loss: 0.611004\n",
      "epoch 1; iter: 0; batch classifier loss: 10.743979; batch adversarial loss: 0.677920\n",
      "epoch 1; iter: 200; batch classifier loss: 2.740723; batch adversarial loss: 0.665380\n",
      "epoch 2; iter: 0; batch classifier loss: 10.148540; batch adversarial loss: 0.717114\n",
      "epoch 2; iter: 200; batch classifier loss: 13.013024; batch adversarial loss: 0.697385\n",
      "epoch 3; iter: 0; batch classifier loss: 6.541362; batch adversarial loss: 0.590277\n",
      "epoch 3; iter: 200; batch classifier loss: 8.725547; batch adversarial loss: 0.557185\n",
      "epoch 4; iter: 0; batch classifier loss: 8.987825; batch adversarial loss: 0.622209\n",
      "epoch 4; iter: 200; batch classifier loss: 2.140656; batch adversarial loss: 0.606777\n",
      "epoch 5; iter: 0; batch classifier loss: 2.730023; batch adversarial loss: 0.648961\n",
      "epoch 5; iter: 200; batch classifier loss: 2.671647; batch adversarial loss: 0.595517\n",
      "epoch 6; iter: 0; batch classifier loss: 0.429612; batch adversarial loss: 0.612401\n",
      "epoch 6; iter: 200; batch classifier loss: 0.510161; batch adversarial loss: 0.622581\n",
      "epoch 7; iter: 0; batch classifier loss: 2.711030; batch adversarial loss: 0.611082\n",
      "epoch 7; iter: 200; batch classifier loss: 1.809277; batch adversarial loss: 0.652639\n",
      "epoch 8; iter: 0; batch classifier loss: 1.083672; batch adversarial loss: 0.605246\n",
      "epoch 8; iter: 200; batch classifier loss: 1.396703; batch adversarial loss: 0.648479\n",
      "epoch 9; iter: 0; batch classifier loss: 0.799628; batch adversarial loss: 0.660568\n",
      "epoch 9; iter: 200; batch classifier loss: 0.757702; batch adversarial loss: 0.691473\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 20}\n",
      "epoch 0; iter: 0; batch classifier loss: 10.297927; batch adversarial loss: 0.678783\n",
      "epoch 0; iter: 200; batch classifier loss: 18.800949; batch adversarial loss: 0.700595\n",
      "epoch 1; iter: 0; batch classifier loss: 15.180962; batch adversarial loss: 0.640417\n",
      "epoch 1; iter: 200; batch classifier loss: 11.296215; batch adversarial loss: 0.627545\n",
      "epoch 2; iter: 0; batch classifier loss: 2.010459; batch adversarial loss: 0.620072\n",
      "epoch 2; iter: 200; batch classifier loss: 2.443026; batch adversarial loss: 0.633613\n",
      "epoch 3; iter: 0; batch classifier loss: 3.523409; batch adversarial loss: 0.611689\n",
      "epoch 3; iter: 200; batch classifier loss: 2.317263; batch adversarial loss: 0.688124\n",
      "epoch 4; iter: 0; batch classifier loss: 3.325881; batch adversarial loss: 0.611496\n",
      "epoch 4; iter: 200; batch classifier loss: 2.281641; batch adversarial loss: 0.656211\n",
      "epoch 5; iter: 0; batch classifier loss: 3.598052; batch adversarial loss: 0.620528\n",
      "epoch 5; iter: 200; batch classifier loss: 0.579073; batch adversarial loss: 0.603890\n",
      "epoch 6; iter: 0; batch classifier loss: 2.688100; batch adversarial loss: 0.620924\n",
      "epoch 6; iter: 200; batch classifier loss: 1.259222; batch adversarial loss: 0.676379\n",
      "epoch 7; iter: 0; batch classifier loss: 1.037130; batch adversarial loss: 0.613263\n",
      "epoch 7; iter: 200; batch classifier loss: 0.783154; batch adversarial loss: 0.620675\n",
      "epoch 8; iter: 0; batch classifier loss: 0.874512; batch adversarial loss: 0.622901\n",
      "epoch 8; iter: 200; batch classifier loss: 0.562443; batch adversarial loss: 0.693917\n",
      "epoch 9; iter: 0; batch classifier loss: 0.649928; batch adversarial loss: 0.665731\n",
      "epoch 9; iter: 200; batch classifier loss: 0.495059; batch adversarial loss: 0.631029\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462725; batch adversarial loss: 0.604199\n",
      "epoch 10; iter: 200; batch classifier loss: 0.500744; batch adversarial loss: 0.662854\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541019; batch adversarial loss: 0.651447\n",
      "epoch 11; iter: 200; batch classifier loss: 0.413915; batch adversarial loss: 0.664362\n",
      "epoch 12; iter: 0; batch classifier loss: 0.411810; batch adversarial loss: 0.600552\n",
      "epoch 12; iter: 200; batch classifier loss: 0.467359; batch adversarial loss: 0.608864\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439476; batch adversarial loss: 0.707694\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404744; batch adversarial loss: 0.651535\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538903; batch adversarial loss: 0.559056\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351794; batch adversarial loss: 0.672444\n",
      "epoch 15; iter: 0; batch classifier loss: 0.444390; batch adversarial loss: 0.627632\n",
      "epoch 15; iter: 200; batch classifier loss: 0.304187; batch adversarial loss: 0.581139\n",
      "epoch 16; iter: 0; batch classifier loss: 0.337703; batch adversarial loss: 0.600695\n",
      "epoch 16; iter: 200; batch classifier loss: 0.419968; batch adversarial loss: 0.656089\n",
      "epoch 17; iter: 0; batch classifier loss: 0.427743; batch adversarial loss: 0.654133\n",
      "epoch 17; iter: 200; batch classifier loss: 0.373542; batch adversarial loss: 0.650094\n",
      "epoch 18; iter: 0; batch classifier loss: 0.323395; batch adversarial loss: 0.616484\n",
      "epoch 18; iter: 200; batch classifier loss: 0.340572; batch adversarial loss: 0.618944\n",
      "epoch 19; iter: 0; batch classifier loss: 0.317939; batch adversarial loss: 0.571613\n",
      "epoch 19; iter: 200; batch classifier loss: 0.344069; batch adversarial loss: 0.593147\n",
      "epoch 0; iter: 0; batch classifier loss: 38.698368; batch adversarial loss: 1.035481\n",
      "epoch 0; iter: 200; batch classifier loss: 17.637390; batch adversarial loss: 1.007712\n",
      "epoch 1; iter: 0; batch classifier loss: 4.731832; batch adversarial loss: 0.896009\n",
      "epoch 1; iter: 200; batch classifier loss: 7.545686; batch adversarial loss: 0.792714\n",
      "epoch 2; iter: 0; batch classifier loss: 4.919294; batch adversarial loss: 0.796939\n",
      "epoch 2; iter: 200; batch classifier loss: 2.312404; batch adversarial loss: 0.669569\n",
      "epoch 3; iter: 0; batch classifier loss: 6.777053; batch adversarial loss: 0.631265\n",
      "epoch 3; iter: 200; batch classifier loss: 3.731565; batch adversarial loss: 0.652245\n",
      "epoch 4; iter: 0; batch classifier loss: 5.726645; batch adversarial loss: 0.649523\n",
      "epoch 4; iter: 200; batch classifier loss: 1.561088; batch adversarial loss: 0.679850\n",
      "epoch 5; iter: 0; batch classifier loss: 3.555408; batch adversarial loss: 0.518916\n",
      "epoch 5; iter: 200; batch classifier loss: 1.395772; batch adversarial loss: 0.582191\n",
      "epoch 6; iter: 0; batch classifier loss: 1.577404; batch adversarial loss: 0.571751\n",
      "epoch 6; iter: 200; batch classifier loss: 2.167554; batch adversarial loss: 0.669579\n",
      "epoch 7; iter: 0; batch classifier loss: 2.263459; batch adversarial loss: 0.565537\n",
      "epoch 7; iter: 200; batch classifier loss: 1.675668; batch adversarial loss: 0.601082\n",
      "epoch 8; iter: 0; batch classifier loss: 1.133203; batch adversarial loss: 0.609993\n",
      "epoch 8; iter: 200; batch classifier loss: 0.543015; batch adversarial loss: 0.583785\n",
      "epoch 9; iter: 0; batch classifier loss: 0.597503; batch adversarial loss: 0.652749\n",
      "epoch 9; iter: 200; batch classifier loss: 0.608932; batch adversarial loss: 0.601657\n",
      "epoch 10; iter: 0; batch classifier loss: 0.514214; batch adversarial loss: 0.575288\n",
      "epoch 10; iter: 200; batch classifier loss: 0.431113; batch adversarial loss: 0.699505\n",
      "epoch 11; iter: 0; batch classifier loss: 0.612268; batch adversarial loss: 0.664463\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383732; batch adversarial loss: 0.676780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489934; batch adversarial loss: 0.641758\n",
      "epoch 12; iter: 200; batch classifier loss: 0.428034; batch adversarial loss: 0.605644\n",
      "epoch 13; iter: 0; batch classifier loss: 0.391949; batch adversarial loss: 0.587003\n",
      "epoch 13; iter: 200; batch classifier loss: 0.446968; batch adversarial loss: 0.625107\n",
      "epoch 14; iter: 0; batch classifier loss: 0.445709; batch adversarial loss: 0.603926\n",
      "epoch 14; iter: 200; batch classifier loss: 0.559196; batch adversarial loss: 0.594563\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396062; batch adversarial loss: 0.629776\n",
      "epoch 15; iter: 200; batch classifier loss: 0.403404; batch adversarial loss: 0.632600\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387691; batch adversarial loss: 0.590141\n",
      "epoch 16; iter: 200; batch classifier loss: 0.404141; batch adversarial loss: 0.593705\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397893; batch adversarial loss: 0.615408\n",
      "epoch 17; iter: 200; batch classifier loss: 0.328122; batch adversarial loss: 0.627436\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343538; batch adversarial loss: 0.627624\n",
      "epoch 18; iter: 200; batch classifier loss: 0.414703; batch adversarial loss: 0.674816\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408592; batch adversarial loss: 0.599055\n",
      "epoch 19; iter: 200; batch classifier loss: 0.299738; batch adversarial loss: 0.672471\n",
      "epoch 0; iter: 0; batch classifier loss: 14.151849; batch adversarial loss: 0.752131\n",
      "epoch 0; iter: 200; batch classifier loss: 5.808815; batch adversarial loss: 0.773538\n",
      "epoch 1; iter: 0; batch classifier loss: 3.666700; batch adversarial loss: 0.734140\n",
      "epoch 1; iter: 200; batch classifier loss: 5.563511; batch adversarial loss: 0.653218\n",
      "epoch 2; iter: 0; batch classifier loss: 2.050602; batch adversarial loss: 0.643760\n",
      "epoch 2; iter: 200; batch classifier loss: 1.077184; batch adversarial loss: 0.642023\n",
      "epoch 3; iter: 0; batch classifier loss: 0.639024; batch adversarial loss: 0.655089\n",
      "epoch 3; iter: 200; batch classifier loss: 1.401277; batch adversarial loss: 0.596086\n",
      "epoch 4; iter: 0; batch classifier loss: 11.580812; batch adversarial loss: 0.640013\n",
      "epoch 4; iter: 200; batch classifier loss: 2.028525; batch adversarial loss: 0.589566\n",
      "epoch 5; iter: 0; batch classifier loss: 2.942738; batch adversarial loss: 0.634431\n",
      "epoch 5; iter: 200; batch classifier loss: 2.916008; batch adversarial loss: 0.627728\n",
      "epoch 6; iter: 0; batch classifier loss: 0.884101; batch adversarial loss: 0.550420\n",
      "epoch 6; iter: 200; batch classifier loss: 0.450529; batch adversarial loss: 0.627411\n",
      "epoch 7; iter: 0; batch classifier loss: 1.227807; batch adversarial loss: 0.655811\n",
      "epoch 7; iter: 200; batch classifier loss: 0.388000; batch adversarial loss: 0.631296\n",
      "epoch 8; iter: 0; batch classifier loss: 0.699661; batch adversarial loss: 0.623417\n",
      "epoch 8; iter: 200; batch classifier loss: 0.506521; batch adversarial loss: 0.665676\n",
      "epoch 9; iter: 0; batch classifier loss: 0.615146; batch adversarial loss: 0.595631\n",
      "epoch 9; iter: 200; batch classifier loss: 0.524887; batch adversarial loss: 0.598675\n",
      "epoch 10; iter: 0; batch classifier loss: 0.423626; batch adversarial loss: 0.631433\n",
      "epoch 10; iter: 200; batch classifier loss: 0.322665; batch adversarial loss: 0.630189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.373638; batch adversarial loss: 0.649666\n",
      "epoch 11; iter: 200; batch classifier loss: 0.459038; batch adversarial loss: 0.663869\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457832; batch adversarial loss: 0.604305\n",
      "epoch 12; iter: 200; batch classifier loss: 0.423835; batch adversarial loss: 0.635475\n",
      "epoch 13; iter: 0; batch classifier loss: 0.591153; batch adversarial loss: 0.595512\n",
      "epoch 13; iter: 200; batch classifier loss: 0.462978; batch adversarial loss: 0.631345\n",
      "epoch 14; iter: 0; batch classifier loss: 0.443764; batch adversarial loss: 0.695761\n",
      "epoch 14; iter: 200; batch classifier loss: 0.521446; batch adversarial loss: 0.625028\n",
      "epoch 15; iter: 0; batch classifier loss: 0.354311; batch adversarial loss: 0.582885\n",
      "epoch 15; iter: 200; batch classifier loss: 0.361555; batch adversarial loss: 0.634087\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327331; batch adversarial loss: 0.646054\n",
      "epoch 16; iter: 200; batch classifier loss: 0.289118; batch adversarial loss: 0.638202\n",
      "epoch 17; iter: 0; batch classifier loss: 0.451751; batch adversarial loss: 0.568213\n",
      "epoch 17; iter: 200; batch classifier loss: 0.279589; batch adversarial loss: 0.622777\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345875; batch adversarial loss: 0.681437\n",
      "epoch 18; iter: 200; batch classifier loss: 0.466288; batch adversarial loss: 0.609069\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426255; batch adversarial loss: 0.589752\n",
      "epoch 19; iter: 200; batch classifier loss: 0.398025; batch adversarial loss: 0.647533\n",
      "epoch 0; iter: 0; batch classifier loss: 7.317644; batch adversarial loss: 0.750759\n",
      "epoch 0; iter: 200; batch classifier loss: 3.039009; batch adversarial loss: 0.697137\n",
      "epoch 1; iter: 0; batch classifier loss: 2.834038; batch adversarial loss: 0.684761\n",
      "epoch 1; iter: 200; batch classifier loss: 9.219202; batch adversarial loss: 0.651192\n",
      "epoch 2; iter: 0; batch classifier loss: 2.442270; batch adversarial loss: 0.642747\n",
      "epoch 2; iter: 200; batch classifier loss: 6.078620; batch adversarial loss: 0.637796\n",
      "epoch 3; iter: 0; batch classifier loss: 2.738110; batch adversarial loss: 0.653547\n",
      "epoch 3; iter: 200; batch classifier loss: 3.398248; batch adversarial loss: 0.623254\n",
      "epoch 4; iter: 0; batch classifier loss: 2.366055; batch adversarial loss: 0.605622\n",
      "epoch 4; iter: 200; batch classifier loss: 1.062066; batch adversarial loss: 0.618009\n",
      "epoch 5; iter: 0; batch classifier loss: 3.658652; batch adversarial loss: 0.622230\n",
      "epoch 5; iter: 200; batch classifier loss: 2.827240; batch adversarial loss: 0.642337\n",
      "epoch 6; iter: 0; batch classifier loss: 2.595532; batch adversarial loss: 0.614989\n",
      "epoch 6; iter: 200; batch classifier loss: 1.854389; batch adversarial loss: 0.583880\n",
      "epoch 7; iter: 0; batch classifier loss: 0.723936; batch adversarial loss: 0.622214\n",
      "epoch 7; iter: 200; batch classifier loss: 0.860361; batch adversarial loss: 0.590001\n",
      "epoch 8; iter: 0; batch classifier loss: 0.918084; batch adversarial loss: 0.583222\n",
      "epoch 8; iter: 200; batch classifier loss: 0.784210; batch adversarial loss: 0.659508\n",
      "epoch 9; iter: 0; batch classifier loss: 0.837128; batch adversarial loss: 0.599702\n",
      "epoch 9; iter: 200; batch classifier loss: 0.571908; batch adversarial loss: 0.632393\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576842; batch adversarial loss: 0.602418\n",
      "epoch 10; iter: 200; batch classifier loss: 0.529809; batch adversarial loss: 0.596048\n",
      "epoch 11; iter: 0; batch classifier loss: 0.467542; batch adversarial loss: 0.617498\n",
      "epoch 11; iter: 200; batch classifier loss: 0.506423; batch adversarial loss: 0.623035\n",
      "epoch 12; iter: 0; batch classifier loss: 1.302540; batch adversarial loss: 0.626012\n",
      "epoch 12; iter: 200; batch classifier loss: 0.457158; batch adversarial loss: 0.630098\n",
      "epoch 13; iter: 0; batch classifier loss: 0.612019; batch adversarial loss: 0.535636\n",
      "epoch 13; iter: 200; batch classifier loss: 0.502094; batch adversarial loss: 0.635506\n",
      "epoch 14; iter: 0; batch classifier loss: 0.425560; batch adversarial loss: 0.567351\n",
      "epoch 14; iter: 200; batch classifier loss: 0.411462; batch adversarial loss: 0.671312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476134; batch adversarial loss: 0.667362\n",
      "epoch 15; iter: 200; batch classifier loss: 0.338561; batch adversarial loss: 0.593608\n",
      "epoch 16; iter: 0; batch classifier loss: 0.500613; batch adversarial loss: 0.618143\n",
      "epoch 16; iter: 200; batch classifier loss: 0.324450; batch adversarial loss: 0.610754\n",
      "epoch 17; iter: 0; batch classifier loss: 0.368005; batch adversarial loss: 0.622446\n",
      "epoch 17; iter: 200; batch classifier loss: 0.322020; batch adversarial loss: 0.651662\n",
      "epoch 18; iter: 0; batch classifier loss: 0.517154; batch adversarial loss: 0.587476\n",
      "epoch 18; iter: 200; batch classifier loss: 0.339549; batch adversarial loss: 0.644786\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438545; batch adversarial loss: 0.628584\n",
      "epoch 19; iter: 200; batch classifier loss: 0.418485; batch adversarial loss: 0.659155\n",
      "epoch 0; iter: 0; batch classifier loss: 66.647079; batch adversarial loss: 0.724535\n",
      "epoch 0; iter: 200; batch classifier loss: 6.303877; batch adversarial loss: 0.680501\n",
      "epoch 1; iter: 0; batch classifier loss: 2.601964; batch adversarial loss: 0.657258\n",
      "epoch 1; iter: 200; batch classifier loss: 6.415017; batch adversarial loss: 0.618216\n",
      "epoch 2; iter: 0; batch classifier loss: 3.495806; batch adversarial loss: 0.620211\n",
      "epoch 2; iter: 200; batch classifier loss: 4.693135; batch adversarial loss: 0.643003\n",
      "epoch 3; iter: 0; batch classifier loss: 3.018104; batch adversarial loss: 0.621355\n",
      "epoch 3; iter: 200; batch classifier loss: 2.856075; batch adversarial loss: 0.604189\n",
      "epoch 4; iter: 0; batch classifier loss: 7.385192; batch adversarial loss: 0.586232\n",
      "epoch 4; iter: 200; batch classifier loss: 2.638036; batch adversarial loss: 0.642047\n",
      "epoch 5; iter: 0; batch classifier loss: 1.309123; batch adversarial loss: 0.662667\n",
      "epoch 5; iter: 200; batch classifier loss: 0.597570; batch adversarial loss: 0.581961\n",
      "epoch 6; iter: 0; batch classifier loss: 2.366205; batch adversarial loss: 0.652923\n",
      "epoch 6; iter: 200; batch classifier loss: 0.694783; batch adversarial loss: 0.665364\n",
      "epoch 7; iter: 0; batch classifier loss: 2.003822; batch adversarial loss: 0.614645\n",
      "epoch 7; iter: 200; batch classifier loss: 0.823381; batch adversarial loss: 0.579442\n",
      "epoch 8; iter: 0; batch classifier loss: 0.664870; batch adversarial loss: 0.632051\n",
      "epoch 8; iter: 200; batch classifier loss: 0.594333; batch adversarial loss: 0.645931\n",
      "epoch 9; iter: 0; batch classifier loss: 0.486454; batch adversarial loss: 0.633409\n",
      "epoch 9; iter: 200; batch classifier loss: 0.660057; batch adversarial loss: 0.601800\n",
      "epoch 10; iter: 0; batch classifier loss: 0.421169; batch adversarial loss: 0.646859\n",
      "epoch 10; iter: 200; batch classifier loss: 0.428363; batch adversarial loss: 0.655422\n",
      "epoch 11; iter: 0; batch classifier loss: 0.343035; batch adversarial loss: 0.591978\n",
      "epoch 11; iter: 200; batch classifier loss: 0.398061; batch adversarial loss: 0.608753\n",
      "epoch 12; iter: 0; batch classifier loss: 0.476241; batch adversarial loss: 0.631757\n",
      "epoch 12; iter: 200; batch classifier loss: 0.467989; batch adversarial loss: 0.617706\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372026; batch adversarial loss: 0.580091\n",
      "epoch 13; iter: 200; batch classifier loss: 0.409703; batch adversarial loss: 0.634097\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469630; batch adversarial loss: 0.642694\n",
      "epoch 14; iter: 200; batch classifier loss: 0.471230; batch adversarial loss: 0.627015\n",
      "epoch 15; iter: 0; batch classifier loss: 0.417625; batch adversarial loss: 0.570009\n",
      "epoch 15; iter: 200; batch classifier loss: 0.414138; batch adversarial loss: 0.593429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.381015; batch adversarial loss: 0.656630\n",
      "epoch 16; iter: 200; batch classifier loss: 0.421602; batch adversarial loss: 0.658363\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377691; batch adversarial loss: 0.571813\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349360; batch adversarial loss: 0.632836\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345200; batch adversarial loss: 0.625849\n",
      "epoch 18; iter: 200; batch classifier loss: 0.256921; batch adversarial loss: 0.672040\n",
      "epoch 19; iter: 0; batch classifier loss: 0.360398; batch adversarial loss: 0.627402\n",
      "epoch 19; iter: 200; batch classifier loss: 0.418001; batch adversarial loss: 0.674397\n",
      "epoch 0; iter: 0; batch classifier loss: 126.415802; batch adversarial loss: 0.666283\n",
      "epoch 0; iter: 200; batch classifier loss: 9.684045; batch adversarial loss: 0.682596\n",
      "epoch 1; iter: 0; batch classifier loss: 9.662957; batch adversarial loss: 0.706552\n",
      "epoch 1; iter: 200; batch classifier loss: 1.534383; batch adversarial loss: 0.667712\n",
      "epoch 2; iter: 0; batch classifier loss: 10.621664; batch adversarial loss: 0.650073\n",
      "epoch 2; iter: 200; batch classifier loss: 16.057568; batch adversarial loss: 0.669132\n",
      "epoch 3; iter: 0; batch classifier loss: 4.726741; batch adversarial loss: 0.624335\n",
      "epoch 3; iter: 200; batch classifier loss: 0.901604; batch adversarial loss: 0.644809\n",
      "epoch 4; iter: 0; batch classifier loss: 5.701205; batch adversarial loss: 0.613225\n",
      "epoch 4; iter: 200; batch classifier loss: 2.365663; batch adversarial loss: 0.593185\n",
      "epoch 5; iter: 0; batch classifier loss: 2.649724; batch adversarial loss: 0.663910\n",
      "epoch 5; iter: 200; batch classifier loss: 3.521725; batch adversarial loss: 0.647284\n",
      "epoch 6; iter: 0; batch classifier loss: 6.396625; batch adversarial loss: 0.659148\n",
      "epoch 6; iter: 200; batch classifier loss: 1.911269; batch adversarial loss: 0.597416\n",
      "epoch 7; iter: 0; batch classifier loss: 5.529165; batch adversarial loss: 0.584938\n",
      "epoch 7; iter: 200; batch classifier loss: 0.593712; batch adversarial loss: 0.527179\n",
      "epoch 8; iter: 0; batch classifier loss: 0.472494; batch adversarial loss: 0.626595\n",
      "epoch 8; iter: 200; batch classifier loss: 0.571834; batch adversarial loss: 0.571152\n",
      "epoch 9; iter: 0; batch classifier loss: 0.596751; batch adversarial loss: 0.605683\n",
      "epoch 9; iter: 200; batch classifier loss: 0.479041; batch adversarial loss: 0.609872\n",
      "epoch 10; iter: 0; batch classifier loss: 0.419313; batch adversarial loss: 0.601677\n",
      "epoch 10; iter: 200; batch classifier loss: 0.841045; batch adversarial loss: 0.610329\n",
      "epoch 11; iter: 0; batch classifier loss: 0.409236; batch adversarial loss: 0.606640\n",
      "epoch 11; iter: 200; batch classifier loss: 0.546203; batch adversarial loss: 0.614923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.341497; batch adversarial loss: 0.607997\n",
      "epoch 12; iter: 200; batch classifier loss: 0.414902; batch adversarial loss: 0.614831\n",
      "epoch 13; iter: 0; batch classifier loss: 0.403137; batch adversarial loss: 0.589636\n",
      "epoch 13; iter: 200; batch classifier loss: 0.358505; batch adversarial loss: 0.607304\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371834; batch adversarial loss: 0.603249\n",
      "epoch 14; iter: 200; batch classifier loss: 0.406175; batch adversarial loss: 0.629362\n",
      "epoch 15; iter: 0; batch classifier loss: 0.289709; batch adversarial loss: 0.536777\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387673; batch adversarial loss: 0.619169\n",
      "epoch 16; iter: 0; batch classifier loss: 0.386662; batch adversarial loss: 0.639931\n",
      "epoch 16; iter: 200; batch classifier loss: 0.319480; batch adversarial loss: 0.657076\n",
      "epoch 17; iter: 0; batch classifier loss: 0.442425; batch adversarial loss: 0.588420\n",
      "epoch 17; iter: 200; batch classifier loss: 0.369336; batch adversarial loss: 0.586024\n",
      "epoch 18; iter: 0; batch classifier loss: 0.383279; batch adversarial loss: 0.621865\n",
      "epoch 18; iter: 200; batch classifier loss: 0.397527; batch adversarial loss: 0.613573\n",
      "epoch 19; iter: 0; batch classifier loss: 0.329406; batch adversarial loss: 0.606876\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387830; batch adversarial loss: 0.609272\n",
      "epoch 0; iter: 0; batch classifier loss: 45.952057; batch adversarial loss: 0.655563\n",
      "epoch 0; iter: 200; batch classifier loss: 7.838868; batch adversarial loss: 0.720641\n",
      "epoch 1; iter: 0; batch classifier loss: 8.119761; batch adversarial loss: 0.678914\n",
      "epoch 1; iter: 200; batch classifier loss: 9.060671; batch adversarial loss: 0.660013\n",
      "epoch 2; iter: 0; batch classifier loss: 7.383411; batch adversarial loss: 0.645977\n",
      "epoch 2; iter: 200; batch classifier loss: 2.862101; batch adversarial loss: 0.643716\n",
      "epoch 3; iter: 0; batch classifier loss: 6.077572; batch adversarial loss: 0.658957\n",
      "epoch 3; iter: 200; batch classifier loss: 1.422052; batch adversarial loss: 0.621535\n",
      "epoch 4; iter: 0; batch classifier loss: 1.200398; batch adversarial loss: 0.581885\n",
      "epoch 4; iter: 200; batch classifier loss: 4.186759; batch adversarial loss: 0.626591\n",
      "epoch 5; iter: 0; batch classifier loss: 3.124910; batch adversarial loss: 0.677974\n",
      "epoch 5; iter: 200; batch classifier loss: 2.191646; batch adversarial loss: 0.579974\n",
      "epoch 6; iter: 0; batch classifier loss: 2.980028; batch adversarial loss: 0.633092\n",
      "epoch 6; iter: 200; batch classifier loss: 1.102320; batch adversarial loss: 0.652657\n",
      "epoch 7; iter: 0; batch classifier loss: 1.141286; batch adversarial loss: 0.662416\n",
      "epoch 7; iter: 200; batch classifier loss: 1.224969; batch adversarial loss: 0.692720\n",
      "epoch 8; iter: 0; batch classifier loss: 1.193949; batch adversarial loss: 0.648439\n",
      "epoch 8; iter: 200; batch classifier loss: 0.782140; batch adversarial loss: 0.586864\n",
      "epoch 9; iter: 0; batch classifier loss: 0.593565; batch adversarial loss: 0.583659\n",
      "epoch 9; iter: 200; batch classifier loss: 0.581283; batch adversarial loss: 0.558056\n",
      "epoch 10; iter: 0; batch classifier loss: 0.889625; batch adversarial loss: 0.684620\n",
      "epoch 10; iter: 200; batch classifier loss: 0.417985; batch adversarial loss: 0.577597\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560870; batch adversarial loss: 0.690481\n",
      "epoch 11; iter: 200; batch classifier loss: 0.806674; batch adversarial loss: 0.582471\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418475; batch adversarial loss: 0.610504\n",
      "epoch 12; iter: 200; batch classifier loss: 0.430803; batch adversarial loss: 0.630043\n",
      "epoch 13; iter: 0; batch classifier loss: 0.376610; batch adversarial loss: 0.610756\n",
      "epoch 13; iter: 200; batch classifier loss: 0.434124; batch adversarial loss: 0.591238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480061; batch adversarial loss: 0.608845\n",
      "epoch 14; iter: 200; batch classifier loss: 0.430562; batch adversarial loss: 0.663553\n",
      "epoch 15; iter: 0; batch classifier loss: 0.366639; batch adversarial loss: 0.641773\n",
      "epoch 15; iter: 200; batch classifier loss: 0.333911; batch adversarial loss: 0.591409\n",
      "epoch 16; iter: 0; batch classifier loss: 0.436878; batch adversarial loss: 0.595367\n",
      "epoch 16; iter: 200; batch classifier loss: 0.613450; batch adversarial loss: 0.640747\n",
      "epoch 17; iter: 0; batch classifier loss: 0.337783; batch adversarial loss: 0.669325\n",
      "epoch 17; iter: 200; batch classifier loss: 0.388802; batch adversarial loss: 0.586823\n",
      "epoch 18; iter: 0; batch classifier loss: 0.394432; batch adversarial loss: 0.596146\n",
      "epoch 18; iter: 200; batch classifier loss: 0.378922; batch adversarial loss: 0.633874\n",
      "epoch 19; iter: 0; batch classifier loss: 0.309064; batch adversarial loss: 0.605543\n",
      "epoch 19; iter: 200; batch classifier loss: 0.350354; batch adversarial loss: 0.611609\n",
      "epoch 0; iter: 0; batch classifier loss: 85.949661; batch adversarial loss: 0.564829\n",
      "epoch 0; iter: 200; batch classifier loss: 8.054079; batch adversarial loss: 0.650636\n",
      "epoch 1; iter: 0; batch classifier loss: 4.755973; batch adversarial loss: 0.698588\n",
      "epoch 1; iter: 200; batch classifier loss: 5.937385; batch adversarial loss: 0.591426\n",
      "epoch 2; iter: 0; batch classifier loss: 5.785370; batch adversarial loss: 0.612096\n",
      "epoch 2; iter: 200; batch classifier loss: 4.749177; batch adversarial loss: 0.651824\n",
      "epoch 3; iter: 0; batch classifier loss: 5.459600; batch adversarial loss: 0.613611\n",
      "epoch 3; iter: 200; batch classifier loss: 2.611661; batch adversarial loss: 0.668712\n",
      "epoch 4; iter: 0; batch classifier loss: 2.021138; batch adversarial loss: 0.665484\n",
      "epoch 4; iter: 200; batch classifier loss: 4.073804; batch adversarial loss: 0.641042\n",
      "epoch 5; iter: 0; batch classifier loss: 2.327040; batch adversarial loss: 0.580202\n",
      "epoch 5; iter: 200; batch classifier loss: 1.869209; batch adversarial loss: 0.598855\n",
      "epoch 6; iter: 0; batch classifier loss: 5.750962; batch adversarial loss: 0.612237\n",
      "epoch 6; iter: 200; batch classifier loss: 1.106172; batch adversarial loss: 0.715051\n",
      "epoch 7; iter: 0; batch classifier loss: 1.318453; batch adversarial loss: 0.633864\n",
      "epoch 7; iter: 200; batch classifier loss: 0.523700; batch adversarial loss: 0.618910\n",
      "epoch 8; iter: 0; batch classifier loss: 0.868027; batch adversarial loss: 0.613408\n",
      "epoch 8; iter: 200; batch classifier loss: 0.608720; batch adversarial loss: 0.591901\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543710; batch adversarial loss: 0.654702\n",
      "epoch 9; iter: 200; batch classifier loss: 0.564582; batch adversarial loss: 0.626778\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558268; batch adversarial loss: 0.611598\n",
      "epoch 10; iter: 200; batch classifier loss: 0.645301; batch adversarial loss: 0.609887\n",
      "epoch 11; iter: 0; batch classifier loss: 0.494322; batch adversarial loss: 0.671044\n",
      "epoch 11; iter: 200; batch classifier loss: 0.468082; batch adversarial loss: 0.678154\n",
      "epoch 12; iter: 0; batch classifier loss: 0.881014; batch adversarial loss: 0.606720\n",
      "epoch 12; iter: 200; batch classifier loss: 0.386138; batch adversarial loss: 0.698960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.429763; batch adversarial loss: 0.561712\n",
      "epoch 13; iter: 200; batch classifier loss: 0.605418; batch adversarial loss: 0.641727\n",
      "epoch 14; iter: 0; batch classifier loss: 0.288677; batch adversarial loss: 0.681551\n",
      "epoch 14; iter: 200; batch classifier loss: 0.384158; batch adversarial loss: 0.669380\n",
      "epoch 15; iter: 0; batch classifier loss: 0.679183; batch adversarial loss: 0.621176\n",
      "epoch 15; iter: 200; batch classifier loss: 0.375093; batch adversarial loss: 0.603607\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394194; batch adversarial loss: 0.616614\n",
      "epoch 16; iter: 200; batch classifier loss: 0.314349; batch adversarial loss: 0.622026\n",
      "epoch 17; iter: 0; batch classifier loss: 0.306468; batch adversarial loss: 0.641679\n",
      "epoch 17; iter: 200; batch classifier loss: 0.341609; batch adversarial loss: 0.704764\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343278; batch adversarial loss: 0.641641\n",
      "epoch 18; iter: 200; batch classifier loss: 0.282840; batch adversarial loss: 0.607512\n",
      "epoch 19; iter: 0; batch classifier loss: 0.405111; batch adversarial loss: 0.609862\n",
      "epoch 19; iter: 200; batch classifier loss: 0.325448; batch adversarial loss: 0.669741\n",
      "epoch 0; iter: 0; batch classifier loss: 29.779949; batch adversarial loss: 0.652352\n",
      "epoch 0; iter: 200; batch classifier loss: 12.912409; batch adversarial loss: 0.692776\n",
      "epoch 1; iter: 0; batch classifier loss: 16.516022; batch adversarial loss: 0.707861\n",
      "epoch 1; iter: 200; batch classifier loss: 5.087355; batch adversarial loss: 0.628379\n",
      "epoch 2; iter: 0; batch classifier loss: 15.380541; batch adversarial loss: 0.616523\n",
      "epoch 2; iter: 200; batch classifier loss: 7.240526; batch adversarial loss: 0.605195\n",
      "epoch 3; iter: 0; batch classifier loss: 6.256814; batch adversarial loss: 0.600399\n",
      "epoch 3; iter: 200; batch classifier loss: 4.368563; batch adversarial loss: 0.612877\n",
      "epoch 4; iter: 0; batch classifier loss: 4.466527; batch adversarial loss: 0.586807\n",
      "epoch 4; iter: 200; batch classifier loss: 4.804032; batch adversarial loss: 0.639208\n",
      "epoch 5; iter: 0; batch classifier loss: 1.617097; batch adversarial loss: 0.639591\n",
      "epoch 5; iter: 200; batch classifier loss: 2.569541; batch adversarial loss: 0.615497\n",
      "epoch 6; iter: 0; batch classifier loss: 1.248682; batch adversarial loss: 0.660573\n",
      "epoch 6; iter: 200; batch classifier loss: 0.818954; batch adversarial loss: 0.620824\n",
      "epoch 7; iter: 0; batch classifier loss: 5.142210; batch adversarial loss: 0.627093\n",
      "epoch 7; iter: 200; batch classifier loss: 1.973382; batch adversarial loss: 0.616545\n",
      "epoch 8; iter: 0; batch classifier loss: 1.099834; batch adversarial loss: 0.590306\n",
      "epoch 8; iter: 200; batch classifier loss: 0.832626; batch adversarial loss: 0.674295\n",
      "epoch 9; iter: 0; batch classifier loss: 1.373260; batch adversarial loss: 0.616533\n",
      "epoch 9; iter: 200; batch classifier loss: 0.520343; batch adversarial loss: 0.578861\n",
      "epoch 10; iter: 0; batch classifier loss: 0.611572; batch adversarial loss: 0.651948\n",
      "epoch 10; iter: 200; batch classifier loss: 0.502532; batch adversarial loss: 0.672718\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448986; batch adversarial loss: 0.650688\n",
      "epoch 11; iter: 200; batch classifier loss: 0.474336; batch adversarial loss: 0.633780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402403; batch adversarial loss: 0.610078\n",
      "epoch 12; iter: 200; batch classifier loss: 0.576162; batch adversarial loss: 0.659139\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481901; batch adversarial loss: 0.600148\n",
      "epoch 13; iter: 200; batch classifier loss: 0.372283; batch adversarial loss: 0.650889\n",
      "epoch 14; iter: 0; batch classifier loss: 0.665224; batch adversarial loss: 0.716102\n",
      "epoch 14; iter: 200; batch classifier loss: 0.414307; batch adversarial loss: 0.595349\n",
      "epoch 15; iter: 0; batch classifier loss: 0.463792; batch adversarial loss: 0.720504\n",
      "epoch 15; iter: 200; batch classifier loss: 0.371988; batch adversarial loss: 0.579772\n",
      "epoch 16; iter: 0; batch classifier loss: 0.532829; batch adversarial loss: 0.606328\n",
      "epoch 16; iter: 200; batch classifier loss: 0.412888; batch adversarial loss: 0.611317\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488471; batch adversarial loss: 0.576133\n",
      "epoch 17; iter: 200; batch classifier loss: 0.384497; batch adversarial loss: 0.637110\n",
      "epoch 18; iter: 0; batch classifier loss: 0.365831; batch adversarial loss: 0.613890\n",
      "epoch 18; iter: 200; batch classifier loss: 0.311921; batch adversarial loss: 0.667185\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325641; batch adversarial loss: 0.670268\n",
      "epoch 19; iter: 200; batch classifier loss: 0.394123; batch adversarial loss: 0.568256\n",
      "epoch 0; iter: 0; batch classifier loss: 23.484169; batch adversarial loss: 0.810937\n",
      "epoch 0; iter: 200; batch classifier loss: 6.995714; batch adversarial loss: 0.817192\n",
      "epoch 1; iter: 0; batch classifier loss: 19.976440; batch adversarial loss: 0.721722\n",
      "epoch 1; iter: 200; batch classifier loss: 7.256488; batch adversarial loss: 0.668119\n",
      "epoch 2; iter: 0; batch classifier loss: 24.715378; batch adversarial loss: 0.675625\n",
      "epoch 2; iter: 200; batch classifier loss: 3.882848; batch adversarial loss: 0.649764\n",
      "epoch 3; iter: 0; batch classifier loss: 2.179468; batch adversarial loss: 0.658276\n",
      "epoch 3; iter: 200; batch classifier loss: 3.775795; batch adversarial loss: 0.649458\n",
      "epoch 4; iter: 0; batch classifier loss: 1.902942; batch adversarial loss: 0.619322\n",
      "epoch 4; iter: 200; batch classifier loss: 1.791174; batch adversarial loss: 0.667155\n",
      "epoch 5; iter: 0; batch classifier loss: 1.729844; batch adversarial loss: 0.636754\n",
      "epoch 5; iter: 200; batch classifier loss: 0.989206; batch adversarial loss: 0.623132\n",
      "epoch 6; iter: 0; batch classifier loss: 1.355406; batch adversarial loss: 0.614747\n",
      "epoch 6; iter: 200; batch classifier loss: 0.731168; batch adversarial loss: 0.649922\n",
      "epoch 7; iter: 0; batch classifier loss: 1.173041; batch adversarial loss: 0.643391\n",
      "epoch 7; iter: 200; batch classifier loss: 0.982756; batch adversarial loss: 0.607795\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564389; batch adversarial loss: 0.624919\n",
      "epoch 8; iter: 200; batch classifier loss: 0.450573; batch adversarial loss: 0.637396\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576783; batch adversarial loss: 0.634250\n",
      "epoch 9; iter: 200; batch classifier loss: 0.434410; batch adversarial loss: 0.634181\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575515; batch adversarial loss: 0.583395\n",
      "epoch 10; iter: 200; batch classifier loss: 0.489035; batch adversarial loss: 0.644479\n",
      "epoch 11; iter: 0; batch classifier loss: 0.881402; batch adversarial loss: 0.610768\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383277; batch adversarial loss: 0.601000\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491292; batch adversarial loss: 0.597276\n",
      "epoch 12; iter: 200; batch classifier loss: 0.443407; batch adversarial loss: 0.642286\n",
      "epoch 13; iter: 0; batch classifier loss: 0.576777; batch adversarial loss: 0.622126\n",
      "epoch 13; iter: 200; batch classifier loss: 0.400719; batch adversarial loss: 0.620861\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540004; batch adversarial loss: 0.581055\n",
      "epoch 14; iter: 200; batch classifier loss: 0.858800; batch adversarial loss: 0.653978\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401940; batch adversarial loss: 0.584762\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366904; batch adversarial loss: 0.615061\n",
      "epoch 16; iter: 0; batch classifier loss: 0.428797; batch adversarial loss: 0.621296\n",
      "epoch 16; iter: 200; batch classifier loss: 0.368763; batch adversarial loss: 0.597356\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294129; batch adversarial loss: 0.625045\n",
      "epoch 17; iter: 200; batch classifier loss: 0.367238; batch adversarial loss: 0.637749\n",
      "epoch 18; iter: 0; batch classifier loss: 0.408496; batch adversarial loss: 0.635874\n",
      "epoch 18; iter: 200; batch classifier loss: 0.358914; batch adversarial loss: 0.611578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344781; batch adversarial loss: 0.614474\n",
      "epoch 19; iter: 200; batch classifier loss: 0.434318; batch adversarial loss: 0.608928\n",
      "epoch 0; iter: 0; batch classifier loss: 11.166626; batch adversarial loss: 0.658791\n",
      "epoch 0; iter: 200; batch classifier loss: 5.740737; batch adversarial loss: 0.661246\n",
      "epoch 1; iter: 0; batch classifier loss: 3.536093; batch adversarial loss: 0.682617\n",
      "epoch 1; iter: 200; batch classifier loss: 6.809106; batch adversarial loss: 0.642684\n",
      "epoch 2; iter: 0; batch classifier loss: 3.413743; batch adversarial loss: 0.601529\n",
      "epoch 2; iter: 200; batch classifier loss: 1.676052; batch adversarial loss: 0.629380\n",
      "epoch 3; iter: 0; batch classifier loss: 3.105345; batch adversarial loss: 0.612286\n",
      "epoch 3; iter: 200; batch classifier loss: 3.156059; batch adversarial loss: 0.619560\n",
      "epoch 4; iter: 0; batch classifier loss: 2.511302; batch adversarial loss: 0.646852\n",
      "epoch 4; iter: 200; batch classifier loss: 1.065421; batch adversarial loss: 0.635594\n",
      "epoch 5; iter: 0; batch classifier loss: 1.130931; batch adversarial loss: 0.661324\n",
      "epoch 5; iter: 200; batch classifier loss: 1.890792; batch adversarial loss: 0.605038\n",
      "epoch 6; iter: 0; batch classifier loss: 0.898883; batch adversarial loss: 0.559792\n",
      "epoch 6; iter: 200; batch classifier loss: 0.770396; batch adversarial loss: 0.630106\n",
      "epoch 7; iter: 0; batch classifier loss: 0.917694; batch adversarial loss: 0.626465\n",
      "epoch 7; iter: 200; batch classifier loss: 1.113226; batch adversarial loss: 0.594160\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455404; batch adversarial loss: 0.627800\n",
      "epoch 8; iter: 200; batch classifier loss: 0.494558; batch adversarial loss: 0.665627\n",
      "epoch 9; iter: 0; batch classifier loss: 0.378812; batch adversarial loss: 0.690862\n",
      "epoch 9; iter: 200; batch classifier loss: 0.693973; batch adversarial loss: 0.600378\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480620; batch adversarial loss: 0.634794\n",
      "epoch 10; iter: 200; batch classifier loss: 0.368454; batch adversarial loss: 0.561516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.466244; batch adversarial loss: 0.629970\n",
      "epoch 11; iter: 200; batch classifier loss: 0.503211; batch adversarial loss: 0.632474\n",
      "epoch 12; iter: 0; batch classifier loss: 0.439890; batch adversarial loss: 0.684428\n",
      "epoch 12; iter: 200; batch classifier loss: 0.337812; batch adversarial loss: 0.620219\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513884; batch adversarial loss: 0.597734\n",
      "epoch 13; iter: 200; batch classifier loss: 0.322947; batch adversarial loss: 0.630869\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352479; batch adversarial loss: 0.693423\n",
      "epoch 14; iter: 200; batch classifier loss: 0.476285; batch adversarial loss: 0.618144\n",
      "epoch 15; iter: 0; batch classifier loss: 0.391572; batch adversarial loss: 0.547502\n",
      "epoch 15; iter: 200; batch classifier loss: 0.335642; batch adversarial loss: 0.524352\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423632; batch adversarial loss: 0.635991\n",
      "epoch 16; iter: 200; batch classifier loss: 0.435970; batch adversarial loss: 0.614200\n",
      "epoch 17; iter: 0; batch classifier loss: 0.494213; batch adversarial loss: 0.585055\n",
      "epoch 17; iter: 200; batch classifier loss: 0.522700; batch adversarial loss: 0.604452\n",
      "epoch 18; iter: 0; batch classifier loss: 0.343383; batch adversarial loss: 0.637571\n",
      "epoch 18; iter: 200; batch classifier loss: 0.265029; batch adversarial loss: 0.636670\n",
      "epoch 19; iter: 0; batch classifier loss: 0.417843; batch adversarial loss: 0.641510\n",
      "epoch 19; iter: 200; batch classifier loss: 0.345394; batch adversarial loss: 0.625075\n",
      "epoch 0; iter: 0; batch classifier loss: 3.210065; batch adversarial loss: 0.687324\n",
      "epoch 0; iter: 200; batch classifier loss: 5.308115; batch adversarial loss: 0.650496\n",
      "epoch 1; iter: 0; batch classifier loss: 9.350119; batch adversarial loss: 0.644846\n",
      "epoch 1; iter: 200; batch classifier loss: 3.870561; batch adversarial loss: 0.615815\n",
      "epoch 2; iter: 0; batch classifier loss: 7.752778; batch adversarial loss: 0.592900\n",
      "epoch 2; iter: 200; batch classifier loss: 2.580904; batch adversarial loss: 0.645502\n",
      "epoch 3; iter: 0; batch classifier loss: 2.844066; batch adversarial loss: 0.641358\n",
      "epoch 3; iter: 200; batch classifier loss: 2.462109; batch adversarial loss: 0.628934\n",
      "epoch 4; iter: 0; batch classifier loss: 2.560111; batch adversarial loss: 0.659817\n",
      "epoch 4; iter: 200; batch classifier loss: 1.020732; batch adversarial loss: 0.607018\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566267; batch adversarial loss: 0.627753\n",
      "epoch 5; iter: 200; batch classifier loss: 1.215180; batch adversarial loss: 0.617735\n",
      "epoch 6; iter: 0; batch classifier loss: 0.756793; batch adversarial loss: 0.645747\n",
      "epoch 6; iter: 200; batch classifier loss: 0.555501; batch adversarial loss: 0.609980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.934687; batch adversarial loss: 0.636055\n",
      "epoch 7; iter: 200; batch classifier loss: 0.675128; batch adversarial loss: 0.654521\n",
      "epoch 8; iter: 0; batch classifier loss: 0.429799; batch adversarial loss: 0.612230\n",
      "epoch 8; iter: 200; batch classifier loss: 0.711789; batch adversarial loss: 0.589287\n",
      "epoch 9; iter: 0; batch classifier loss: 0.402352; batch adversarial loss: 0.660926\n",
      "epoch 9; iter: 200; batch classifier loss: 0.534026; batch adversarial loss: 0.638640\n",
      "epoch 10; iter: 0; batch classifier loss: 0.437492; batch adversarial loss: 0.601622\n",
      "epoch 10; iter: 200; batch classifier loss: 0.382418; batch adversarial loss: 0.648227\n",
      "epoch 11; iter: 0; batch classifier loss: 0.522855; batch adversarial loss: 0.574251\n",
      "epoch 11; iter: 200; batch classifier loss: 0.371892; batch adversarial loss: 0.633934\n",
      "epoch 12; iter: 0; batch classifier loss: 0.401767; batch adversarial loss: 0.657479\n",
      "epoch 12; iter: 200; batch classifier loss: 0.380237; batch adversarial loss: 0.617991\n",
      "epoch 13; iter: 0; batch classifier loss: 0.320645; batch adversarial loss: 0.649709\n",
      "epoch 13; iter: 200; batch classifier loss: 0.436412; batch adversarial loss: 0.577508\n",
      "epoch 14; iter: 0; batch classifier loss: 0.416259; batch adversarial loss: 0.569339\n",
      "epoch 14; iter: 200; batch classifier loss: 0.421934; batch adversarial loss: 0.651584\n",
      "epoch 15; iter: 0; batch classifier loss: 0.297359; batch adversarial loss: 0.616642\n",
      "epoch 15; iter: 200; batch classifier loss: 0.318410; batch adversarial loss: 0.602277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382160; batch adversarial loss: 0.610554\n",
      "epoch 16; iter: 200; batch classifier loss: 0.409691; batch adversarial loss: 0.660035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512268; batch adversarial loss: 0.567588\n",
      "epoch 17; iter: 200; batch classifier loss: 0.361807; batch adversarial loss: 0.587574\n",
      "epoch 18; iter: 0; batch classifier loss: 0.403105; batch adversarial loss: 0.559935\n",
      "epoch 18; iter: 200; batch classifier loss: 0.345210; batch adversarial loss: 0.606031\n",
      "epoch 19; iter: 0; batch classifier loss: 0.336547; batch adversarial loss: 0.643899\n",
      "epoch 19; iter: 200; batch classifier loss: 0.305095; batch adversarial loss: 0.663962\n",
      "epoch 0; iter: 0; batch classifier loss: 10.049324; batch adversarial loss: 0.655169\n",
      "epoch 0; iter: 200; batch classifier loss: 8.625456; batch adversarial loss: 0.618076\n",
      "epoch 1; iter: 0; batch classifier loss: 0.375555; batch adversarial loss: 0.618914\n",
      "epoch 1; iter: 200; batch classifier loss: 4.265319; batch adversarial loss: 0.599244\n",
      "epoch 2; iter: 0; batch classifier loss: 2.688540; batch adversarial loss: 0.647984\n",
      "epoch 2; iter: 200; batch classifier loss: 11.315630; batch adversarial loss: 0.643319\n",
      "epoch 3; iter: 0; batch classifier loss: 2.306817; batch adversarial loss: 0.552491\n",
      "epoch 3; iter: 200; batch classifier loss: 3.231128; batch adversarial loss: 0.589846\n",
      "epoch 4; iter: 0; batch classifier loss: 6.110607; batch adversarial loss: 0.593696\n",
      "epoch 4; iter: 200; batch classifier loss: 1.502757; batch adversarial loss: 0.642696\n",
      "epoch 5; iter: 0; batch classifier loss: 1.031996; batch adversarial loss: 0.635454\n",
      "epoch 5; iter: 200; batch classifier loss: 2.476002; batch adversarial loss: 0.643783\n",
      "epoch 6; iter: 0; batch classifier loss: 0.784435; batch adversarial loss: 0.660052\n",
      "epoch 6; iter: 200; batch classifier loss: 0.699873; batch adversarial loss: 0.626894\n",
      "epoch 7; iter: 0; batch classifier loss: 0.858945; batch adversarial loss: 0.606231\n",
      "epoch 7; iter: 200; batch classifier loss: 0.506202; batch adversarial loss: 0.613403\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577989; batch adversarial loss: 0.658037\n",
      "epoch 8; iter: 200; batch classifier loss: 0.695521; batch adversarial loss: 0.610382\n",
      "epoch 9; iter: 0; batch classifier loss: 0.774699; batch adversarial loss: 0.606637\n",
      "epoch 9; iter: 200; batch classifier loss: 0.569951; batch adversarial loss: 0.625950\n",
      "epoch 10; iter: 0; batch classifier loss: 0.424598; batch adversarial loss: 0.625905\n",
      "epoch 10; iter: 200; batch classifier loss: 0.461575; batch adversarial loss: 0.593716\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420180; batch adversarial loss: 0.558785\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449371; batch adversarial loss: 0.560281\n",
      "epoch 12; iter: 0; batch classifier loss: 0.637982; batch adversarial loss: 0.650227\n",
      "epoch 12; iter: 200; batch classifier loss: 0.398209; batch adversarial loss: 0.624422\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511890; batch adversarial loss: 0.636445\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404062; batch adversarial loss: 0.583597\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339700; batch adversarial loss: 0.599909\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352149; batch adversarial loss: 0.608056\n",
      "epoch 15; iter: 0; batch classifier loss: 0.420600; batch adversarial loss: 0.630335\n",
      "epoch 15; iter: 200; batch classifier loss: 0.428796; batch adversarial loss: 0.629633\n",
      "epoch 16; iter: 0; batch classifier loss: 0.384867; batch adversarial loss: 0.595273\n",
      "epoch 16; iter: 200; batch classifier loss: 0.362898; batch adversarial loss: 0.611363\n",
      "epoch 17; iter: 0; batch classifier loss: 0.402819; batch adversarial loss: 0.609962\n",
      "epoch 17; iter: 200; batch classifier loss: 0.280350; batch adversarial loss: 0.627841\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349065; batch adversarial loss: 0.600027\n",
      "epoch 18; iter: 200; batch classifier loss: 0.383216; batch adversarial loss: 0.636853\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378726; batch adversarial loss: 0.568550\n",
      "epoch 19; iter: 200; batch classifier loss: 0.311057; batch adversarial loss: 0.610591\n",
      "epoch 0; iter: 0; batch classifier loss: 24.753426; batch adversarial loss: 0.899465\n",
      "epoch 0; iter: 200; batch classifier loss: 10.007296; batch adversarial loss: 0.829752\n",
      "epoch 1; iter: 0; batch classifier loss: 0.761688; batch adversarial loss: 0.858728\n",
      "epoch 1; iter: 200; batch classifier loss: 12.255362; batch adversarial loss: 0.733562\n",
      "epoch 2; iter: 0; batch classifier loss: 5.330156; batch adversarial loss: 0.658099\n",
      "epoch 2; iter: 200; batch classifier loss: 9.130087; batch adversarial loss: 0.693959\n",
      "epoch 3; iter: 0; batch classifier loss: 1.467101; batch adversarial loss: 0.718661\n",
      "epoch 3; iter: 200; batch classifier loss: 1.410734; batch adversarial loss: 0.692444\n",
      "epoch 4; iter: 0; batch classifier loss: 3.064481; batch adversarial loss: 0.690790\n",
      "epoch 4; iter: 200; batch classifier loss: 1.478671; batch adversarial loss: 0.672318\n",
      "epoch 5; iter: 0; batch classifier loss: 2.635453; batch adversarial loss: 0.633919\n",
      "epoch 5; iter: 200; batch classifier loss: 1.336160; batch adversarial loss: 0.629015\n",
      "epoch 6; iter: 0; batch classifier loss: 1.292339; batch adversarial loss: 0.676393\n",
      "epoch 6; iter: 200; batch classifier loss: 1.040224; batch adversarial loss: 0.602658\n",
      "epoch 7; iter: 0; batch classifier loss: 0.894032; batch adversarial loss: 0.591819\n",
      "epoch 7; iter: 200; batch classifier loss: 1.053333; batch adversarial loss: 0.675360\n",
      "epoch 8; iter: 0; batch classifier loss: 0.547025; batch adversarial loss: 0.534967\n",
      "epoch 8; iter: 200; batch classifier loss: 1.147423; batch adversarial loss: 0.637720\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488305; batch adversarial loss: 0.622139\n",
      "epoch 9; iter: 200; batch classifier loss: 0.449360; batch adversarial loss: 0.601525\n",
      "epoch 10; iter: 0; batch classifier loss: 0.478260; batch adversarial loss: 0.576230\n",
      "epoch 10; iter: 200; batch classifier loss: 0.476023; batch adversarial loss: 0.562320\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546980; batch adversarial loss: 0.599790\n",
      "epoch 11; iter: 200; batch classifier loss: 0.345159; batch adversarial loss: 0.654502\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487844; batch adversarial loss: 0.699887\n",
      "epoch 12; iter: 200; batch classifier loss: 0.399429; batch adversarial loss: 0.626716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.416922; batch adversarial loss: 0.670709\n",
      "epoch 13; iter: 200; batch classifier loss: 0.386407; batch adversarial loss: 0.643001\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479069; batch adversarial loss: 0.656693\n",
      "epoch 14; iter: 200; batch classifier loss: 0.487027; batch adversarial loss: 0.601900\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427381; batch adversarial loss: 0.592039\n",
      "epoch 15; iter: 200; batch classifier loss: 0.559343; batch adversarial loss: 0.696451\n",
      "epoch 16; iter: 0; batch classifier loss: 0.675371; batch adversarial loss: 0.653973\n",
      "epoch 16; iter: 200; batch classifier loss: 0.519931; batch adversarial loss: 0.600238\n",
      "epoch 17; iter: 0; batch classifier loss: 0.445975; batch adversarial loss: 0.598279\n",
      "epoch 17; iter: 200; batch classifier loss: 0.408101; batch adversarial loss: 0.635880\n",
      "epoch 18; iter: 0; batch classifier loss: 0.363379; batch adversarial loss: 0.607319\n",
      "epoch 18; iter: 200; batch classifier loss: 0.443198; batch adversarial loss: 0.599755\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427762; batch adversarial loss: 0.578759\n",
      "epoch 19; iter: 200; batch classifier loss: 0.423249; batch adversarial loss: 0.658981\n",
      "epoch 0; iter: 0; batch classifier loss: 5.216940; batch adversarial loss: 0.708122\n",
      "epoch 0; iter: 200; batch classifier loss: 5.428782; batch adversarial loss: 0.679153\n",
      "epoch 1; iter: 0; batch classifier loss: 6.917504; batch adversarial loss: 0.633795\n",
      "epoch 1; iter: 200; batch classifier loss: 23.489077; batch adversarial loss: 0.640687\n",
      "epoch 2; iter: 0; batch classifier loss: 7.044076; batch adversarial loss: 0.626576\n",
      "epoch 2; iter: 200; batch classifier loss: 2.151988; batch adversarial loss: 0.616989\n",
      "epoch 3; iter: 0; batch classifier loss: 2.453043; batch adversarial loss: 0.608791\n",
      "epoch 3; iter: 200; batch classifier loss: 5.785508; batch adversarial loss: 0.613181\n",
      "epoch 4; iter: 0; batch classifier loss: 3.217095; batch adversarial loss: 0.623718\n",
      "epoch 4; iter: 200; batch classifier loss: 1.303655; batch adversarial loss: 0.637610\n",
      "epoch 5; iter: 0; batch classifier loss: 2.524724; batch adversarial loss: 0.632782\n",
      "epoch 5; iter: 200; batch classifier loss: 0.786783; batch adversarial loss: 0.599571\n",
      "epoch 6; iter: 0; batch classifier loss: 0.952241; batch adversarial loss: 0.627276\n",
      "epoch 6; iter: 200; batch classifier loss: 1.252086; batch adversarial loss: 0.638397\n",
      "epoch 7; iter: 0; batch classifier loss: 1.799312; batch adversarial loss: 0.676138\n",
      "epoch 7; iter: 200; batch classifier loss: 1.426303; batch adversarial loss: 0.636414\n",
      "epoch 8; iter: 0; batch classifier loss: 0.657134; batch adversarial loss: 0.556646\n",
      "epoch 8; iter: 200; batch classifier loss: 0.740451; batch adversarial loss: 0.612674\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558199; batch adversarial loss: 0.646764\n",
      "epoch 9; iter: 200; batch classifier loss: 0.552544; batch adversarial loss: 0.633795\n",
      "epoch 10; iter: 0; batch classifier loss: 1.239189; batch adversarial loss: 0.611693\n",
      "epoch 10; iter: 200; batch classifier loss: 0.625299; batch adversarial loss: 0.595517\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562095; batch adversarial loss: 0.626931\n",
      "epoch 11; iter: 200; batch classifier loss: 0.657532; batch adversarial loss: 0.630403\n",
      "epoch 12; iter: 0; batch classifier loss: 0.677387; batch adversarial loss: 0.605890\n",
      "epoch 12; iter: 200; batch classifier loss: 0.705569; batch adversarial loss: 0.649100\n",
      "epoch 13; iter: 0; batch classifier loss: 0.377598; batch adversarial loss: 0.626196\n",
      "epoch 13; iter: 200; batch classifier loss: 0.459032; batch adversarial loss: 0.648179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.420762; batch adversarial loss: 0.612758\n",
      "epoch 14; iter: 200; batch classifier loss: 0.337869; batch adversarial loss: 0.654859\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375561; batch adversarial loss: 0.615907\n",
      "epoch 15; iter: 200; batch classifier loss: 0.414731; batch adversarial loss: 0.633433\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371043; batch adversarial loss: 0.621778\n",
      "epoch 16; iter: 200; batch classifier loss: 0.393030; batch adversarial loss: 0.635250\n",
      "epoch 17; iter: 0; batch classifier loss: 0.376497; batch adversarial loss: 0.627339\n",
      "epoch 17; iter: 200; batch classifier loss: 0.438943; batch adversarial loss: 0.632964\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348341; batch adversarial loss: 0.670045\n",
      "epoch 18; iter: 200; batch classifier loss: 0.473500; batch adversarial loss: 0.588312\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302726; batch adversarial loss: 0.595742\n",
      "epoch 19; iter: 200; batch classifier loss: 0.390637; batch adversarial loss: 0.590964\n",
      "Testing config: {'adversary_loss_weight': 1.0, 'batch_size': 128, 'num_epochs': 50}\n",
      "epoch 0; iter: 0; batch classifier loss: 3.089257; batch adversarial loss: 0.611454\n",
      "epoch 0; iter: 200; batch classifier loss: 9.671060; batch adversarial loss: 0.622343\n",
      "epoch 1; iter: 0; batch classifier loss: 2.698359; batch adversarial loss: 0.655985\n",
      "epoch 1; iter: 200; batch classifier loss: 4.424379; batch adversarial loss: 0.618605\n",
      "epoch 2; iter: 0; batch classifier loss: 4.243270; batch adversarial loss: 0.645186\n",
      "epoch 2; iter: 200; batch classifier loss: 2.864232; batch adversarial loss: 0.647173\n",
      "epoch 3; iter: 0; batch classifier loss: 2.112662; batch adversarial loss: 0.587833\n",
      "epoch 3; iter: 200; batch classifier loss: 3.345337; batch adversarial loss: 0.629499\n",
      "epoch 4; iter: 0; batch classifier loss: 1.235242; batch adversarial loss: 0.602912\n",
      "epoch 4; iter: 200; batch classifier loss: 0.825274; batch adversarial loss: 0.601835\n",
      "epoch 5; iter: 0; batch classifier loss: 3.429549; batch adversarial loss: 0.652872\n",
      "epoch 5; iter: 200; batch classifier loss: 1.398955; batch adversarial loss: 0.620902\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504303; batch adversarial loss: 0.660863\n",
      "epoch 6; iter: 200; batch classifier loss: 1.597314; batch adversarial loss: 0.609342\n",
      "epoch 7; iter: 0; batch classifier loss: 0.967640; batch adversarial loss: 0.634666\n",
      "epoch 7; iter: 200; batch classifier loss: 0.486536; batch adversarial loss: 0.603591\n",
      "epoch 8; iter: 0; batch classifier loss: 1.090796; batch adversarial loss: 0.643792\n",
      "epoch 8; iter: 200; batch classifier loss: 0.499977; batch adversarial loss: 0.661053\n",
      "epoch 9; iter: 0; batch classifier loss: 1.128610; batch adversarial loss: 0.599769\n",
      "epoch 9; iter: 200; batch classifier loss: 0.496525; batch adversarial loss: 0.653518\n",
      "epoch 10; iter: 0; batch classifier loss: 0.460632; batch adversarial loss: 0.627908\n",
      "epoch 10; iter: 200; batch classifier loss: 0.476852; batch adversarial loss: 0.628271\n",
      "epoch 11; iter: 0; batch classifier loss: 0.546186; batch adversarial loss: 0.629373\n",
      "epoch 11; iter: 200; batch classifier loss: 0.647551; batch adversarial loss: 0.627228\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452586; batch adversarial loss: 0.583228\n",
      "epoch 12; iter: 200; batch classifier loss: 0.393818; batch adversarial loss: 0.659952\n",
      "epoch 13; iter: 0; batch classifier loss: 0.450100; batch adversarial loss: 0.617869\n",
      "epoch 13; iter: 200; batch classifier loss: 0.440057; batch adversarial loss: 0.658844\n",
      "epoch 14; iter: 0; batch classifier loss: 0.400962; batch adversarial loss: 0.599807\n",
      "epoch 14; iter: 200; batch classifier loss: 0.411123; batch adversarial loss: 0.644417\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329565; batch adversarial loss: 0.672861\n",
      "epoch 15; iter: 200; batch classifier loss: 0.435214; batch adversarial loss: 0.578604\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402367; batch adversarial loss: 0.669896\n",
      "epoch 16; iter: 200; batch classifier loss: 0.375858; batch adversarial loss: 0.629545\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352713; batch adversarial loss: 0.575799\n",
      "epoch 17; iter: 200; batch classifier loss: 0.369464; batch adversarial loss: 0.552570\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367667; batch adversarial loss: 0.593658\n",
      "epoch 18; iter: 200; batch classifier loss: 0.545449; batch adversarial loss: 0.655268\n",
      "epoch 19; iter: 0; batch classifier loss: 0.293607; batch adversarial loss: 0.598461\n",
      "epoch 19; iter: 200; batch classifier loss: 0.386765; batch adversarial loss: 0.620121\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456269; batch adversarial loss: 0.600883\n",
      "epoch 20; iter: 200; batch classifier loss: 0.228811; batch adversarial loss: 0.600072\n",
      "epoch 21; iter: 0; batch classifier loss: 0.370540; batch adversarial loss: 0.685963\n",
      "epoch 21; iter: 200; batch classifier loss: 0.389327; batch adversarial loss: 0.623934\n",
      "epoch 22; iter: 0; batch classifier loss: 0.353723; batch adversarial loss: 0.638549\n",
      "epoch 22; iter: 200; batch classifier loss: 0.362292; batch adversarial loss: 0.604437\n",
      "epoch 23; iter: 0; batch classifier loss: 0.403071; batch adversarial loss: 0.594614\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374203; batch adversarial loss: 0.599804\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421680; batch adversarial loss: 0.591130\n",
      "epoch 24; iter: 200; batch classifier loss: 0.405566; batch adversarial loss: 0.640836\n",
      "epoch 25; iter: 0; batch classifier loss: 0.287758; batch adversarial loss: 0.638977\n",
      "epoch 25; iter: 200; batch classifier loss: 0.357646; batch adversarial loss: 0.638543\n",
      "epoch 26; iter: 0; batch classifier loss: 0.333368; batch adversarial loss: 0.595810\n",
      "epoch 26; iter: 200; batch classifier loss: 0.389584; batch adversarial loss: 0.576572\n",
      "epoch 27; iter: 0; batch classifier loss: 0.366166; batch adversarial loss: 0.576630\n",
      "epoch 27; iter: 200; batch classifier loss: 0.354036; batch adversarial loss: 0.636174\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369575; batch adversarial loss: 0.606153\n",
      "epoch 28; iter: 200; batch classifier loss: 0.267986; batch adversarial loss: 0.638989\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386912; batch adversarial loss: 0.593258\n",
      "epoch 29; iter: 200; batch classifier loss: 0.322979; batch adversarial loss: 0.658103\n",
      "epoch 30; iter: 0; batch classifier loss: 0.257759; batch adversarial loss: 0.639626\n",
      "epoch 30; iter: 200; batch classifier loss: 0.398813; batch adversarial loss: 0.554509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410978; batch adversarial loss: 0.589946\n",
      "epoch 31; iter: 200; batch classifier loss: 0.349704; batch adversarial loss: 0.584513\n",
      "epoch 32; iter: 0; batch classifier loss: 0.403590; batch adversarial loss: 0.663266\n",
      "epoch 32; iter: 200; batch classifier loss: 0.369315; batch adversarial loss: 0.555731\n",
      "epoch 33; iter: 0; batch classifier loss: 0.389685; batch adversarial loss: 0.602969\n",
      "epoch 33; iter: 200; batch classifier loss: 0.307870; batch adversarial loss: 0.581605\n",
      "epoch 34; iter: 0; batch classifier loss: 0.308446; batch adversarial loss: 0.654300\n",
      "epoch 34; iter: 200; batch classifier loss: 0.624572; batch adversarial loss: 0.643219\n",
      "epoch 35; iter: 0; batch classifier loss: 0.371101; batch adversarial loss: 0.598103\n",
      "epoch 35; iter: 200; batch classifier loss: 0.351490; batch adversarial loss: 0.608402\n",
      "epoch 36; iter: 0; batch classifier loss: 0.324019; batch adversarial loss: 0.577572\n",
      "epoch 36; iter: 200; batch classifier loss: 0.368503; batch adversarial loss: 0.582032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.332173; batch adversarial loss: 0.581960\n",
      "epoch 37; iter: 200; batch classifier loss: 0.410354; batch adversarial loss: 0.635285\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412139; batch adversarial loss: 0.608293\n",
      "epoch 38; iter: 200; batch classifier loss: 0.568555; batch adversarial loss: 0.582320\n",
      "epoch 39; iter: 0; batch classifier loss: 0.312488; batch adversarial loss: 0.619030\n",
      "epoch 39; iter: 200; batch classifier loss: 0.425394; batch adversarial loss: 0.566159\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429210; batch adversarial loss: 0.662663\n",
      "epoch 40; iter: 200; batch classifier loss: 0.331712; batch adversarial loss: 0.658663\n",
      "epoch 41; iter: 0; batch classifier loss: 0.336359; batch adversarial loss: 0.616573\n",
      "epoch 41; iter: 200; batch classifier loss: 0.356856; batch adversarial loss: 0.619499\n",
      "epoch 42; iter: 0; batch classifier loss: 0.299860; batch adversarial loss: 0.691369\n",
      "epoch 42; iter: 200; batch classifier loss: 0.381248; batch adversarial loss: 0.638154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.275221; batch adversarial loss: 0.619251\n",
      "epoch 43; iter: 200; batch classifier loss: 0.329843; batch adversarial loss: 0.593190\n",
      "epoch 44; iter: 0; batch classifier loss: 0.387752; batch adversarial loss: 0.646641\n",
      "epoch 44; iter: 200; batch classifier loss: 0.348640; batch adversarial loss: 0.602913\n",
      "epoch 45; iter: 0; batch classifier loss: 0.441469; batch adversarial loss: 0.662638\n",
      "epoch 45; iter: 200; batch classifier loss: 0.402955; batch adversarial loss: 0.610688\n",
      "epoch 46; iter: 0; batch classifier loss: 0.366792; batch adversarial loss: 0.661474\n",
      "epoch 46; iter: 200; batch classifier loss: 0.438285; batch adversarial loss: 0.630283\n",
      "epoch 47; iter: 0; batch classifier loss: 0.284966; batch adversarial loss: 0.652421\n",
      "epoch 47; iter: 200; batch classifier loss: 0.327804; batch adversarial loss: 0.602515\n",
      "epoch 48; iter: 0; batch classifier loss: 0.365333; batch adversarial loss: 0.595111\n",
      "epoch 48; iter: 200; batch classifier loss: 0.281153; batch adversarial loss: 0.650030\n",
      "epoch 49; iter: 0; batch classifier loss: 0.424437; batch adversarial loss: 0.667903\n",
      "epoch 49; iter: 200; batch classifier loss: 0.417976; batch adversarial loss: 0.603184\n",
      "epoch 0; iter: 0; batch classifier loss: 5.276907; batch adversarial loss: 0.904937\n",
      "epoch 0; iter: 200; batch classifier loss: 4.911129; batch adversarial loss: 0.926723\n",
      "epoch 1; iter: 0; batch classifier loss: 10.995372; batch adversarial loss: 0.878979\n",
      "epoch 1; iter: 200; batch classifier loss: 7.855609; batch adversarial loss: 0.760273\n",
      "epoch 2; iter: 0; batch classifier loss: 5.081238; batch adversarial loss: 0.720178\n",
      "epoch 2; iter: 200; batch classifier loss: 3.668804; batch adversarial loss: 0.639550\n",
      "epoch 3; iter: 0; batch classifier loss: 2.193917; batch adversarial loss: 0.676309\n",
      "epoch 3; iter: 200; batch classifier loss: 2.822246; batch adversarial loss: 0.663139\n",
      "epoch 4; iter: 0; batch classifier loss: 1.201218; batch adversarial loss: 0.643961\n",
      "epoch 4; iter: 200; batch classifier loss: 2.634618; batch adversarial loss: 0.628015\n",
      "epoch 5; iter: 0; batch classifier loss: 2.470772; batch adversarial loss: 0.624456\n",
      "epoch 5; iter: 200; batch classifier loss: 0.448490; batch adversarial loss: 0.627598\n",
      "epoch 6; iter: 0; batch classifier loss: 1.828480; batch adversarial loss: 0.648872\n",
      "epoch 6; iter: 200; batch classifier loss: 1.159564; batch adversarial loss: 0.607259\n",
      "epoch 7; iter: 0; batch classifier loss: 1.467127; batch adversarial loss: 0.633713\n",
      "epoch 7; iter: 200; batch classifier loss: 0.777006; batch adversarial loss: 0.630345\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490489; batch adversarial loss: 0.638697\n",
      "epoch 8; iter: 200; batch classifier loss: 0.832628; batch adversarial loss: 0.558997\n",
      "epoch 9; iter: 0; batch classifier loss: 0.534533; batch adversarial loss: 0.596668\n",
      "epoch 9; iter: 200; batch classifier loss: 0.759259; batch adversarial loss: 0.619957\n",
      "epoch 10; iter: 0; batch classifier loss: 0.415557; batch adversarial loss: 0.656108\n",
      "epoch 10; iter: 200; batch classifier loss: 0.409634; batch adversarial loss: 0.646468\n",
      "epoch 11; iter: 0; batch classifier loss: 0.473408; batch adversarial loss: 0.638148\n",
      "epoch 11; iter: 200; batch classifier loss: 0.461698; batch adversarial loss: 0.620401\n",
      "epoch 12; iter: 0; batch classifier loss: 0.718825; batch adversarial loss: 0.640589\n",
      "epoch 12; iter: 200; batch classifier loss: 0.424915; batch adversarial loss: 0.611247\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567140; batch adversarial loss: 0.671800\n",
      "epoch 13; iter: 200; batch classifier loss: 0.351315; batch adversarial loss: 0.647136\n",
      "epoch 14; iter: 0; batch classifier loss: 0.328241; batch adversarial loss: 0.541366\n",
      "epoch 14; iter: 200; batch classifier loss: 0.440795; batch adversarial loss: 0.584861\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375828; batch adversarial loss: 0.649588\n",
      "epoch 15; iter: 200; batch classifier loss: 0.395893; batch adversarial loss: 0.618261\n",
      "epoch 16; iter: 0; batch classifier loss: 0.405768; batch adversarial loss: 0.640055\n",
      "epoch 16; iter: 200; batch classifier loss: 0.418407; batch adversarial loss: 0.591530\n",
      "epoch 17; iter: 0; batch classifier loss: 0.265268; batch adversarial loss: 0.720117\n",
      "epoch 17; iter: 200; batch classifier loss: 0.355637; batch adversarial loss: 0.602513\n",
      "epoch 18; iter: 0; batch classifier loss: 0.302614; batch adversarial loss: 0.628474\n",
      "epoch 18; iter: 200; batch classifier loss: 0.446755; batch adversarial loss: 0.604145\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469072; batch adversarial loss: 0.588938\n",
      "epoch 19; iter: 200; batch classifier loss: 0.304897; batch adversarial loss: 0.574869\n",
      "epoch 20; iter: 0; batch classifier loss: 0.352478; batch adversarial loss: 0.631447\n",
      "epoch 20; iter: 200; batch classifier loss: 0.375403; batch adversarial loss: 0.555577\n",
      "epoch 21; iter: 0; batch classifier loss: 0.347250; batch adversarial loss: 0.603140\n",
      "epoch 21; iter: 200; batch classifier loss: 0.391536; batch adversarial loss: 0.568380\n",
      "epoch 22; iter: 0; batch classifier loss: 0.307893; batch adversarial loss: 0.569042\n",
      "epoch 22; iter: 200; batch classifier loss: 0.289780; batch adversarial loss: 0.588124\n",
      "epoch 23; iter: 0; batch classifier loss: 0.326448; batch adversarial loss: 0.610726\n",
      "epoch 23; iter: 200; batch classifier loss: 0.450987; batch adversarial loss: 0.578980\n",
      "epoch 24; iter: 0; batch classifier loss: 0.399375; batch adversarial loss: 0.590676\n",
      "epoch 24; iter: 200; batch classifier loss: 0.332192; batch adversarial loss: 0.633335\n",
      "epoch 25; iter: 0; batch classifier loss: 0.399630; batch adversarial loss: 0.602908\n",
      "epoch 25; iter: 200; batch classifier loss: 0.427701; batch adversarial loss: 0.605423\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340847; batch adversarial loss: 0.613433\n",
      "epoch 26; iter: 200; batch classifier loss: 0.411029; batch adversarial loss: 0.586177\n",
      "epoch 27; iter: 0; batch classifier loss: 0.315424; batch adversarial loss: 0.607982\n",
      "epoch 27; iter: 200; batch classifier loss: 0.312115; batch adversarial loss: 0.611838\n",
      "epoch 28; iter: 0; batch classifier loss: 0.367637; batch adversarial loss: 0.653519\n",
      "epoch 28; iter: 200; batch classifier loss: 0.308239; batch adversarial loss: 0.662090\n",
      "epoch 29; iter: 0; batch classifier loss: 0.350688; batch adversarial loss: 0.585236\n",
      "epoch 29; iter: 200; batch classifier loss: 0.356365; batch adversarial loss: 0.649869\n",
      "epoch 30; iter: 0; batch classifier loss: 0.371883; batch adversarial loss: 0.596377\n",
      "epoch 30; iter: 200; batch classifier loss: 0.414632; batch adversarial loss: 0.561179\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402511; batch adversarial loss: 0.621205\n",
      "epoch 31; iter: 200; batch classifier loss: 0.310386; batch adversarial loss: 0.629639\n",
      "epoch 32; iter: 0; batch classifier loss: 0.347142; batch adversarial loss: 0.624525\n",
      "epoch 32; iter: 200; batch classifier loss: 0.409100; batch adversarial loss: 0.579897\n",
      "epoch 33; iter: 0; batch classifier loss: 0.399573; batch adversarial loss: 0.608651\n",
      "epoch 33; iter: 200; batch classifier loss: 0.280006; batch adversarial loss: 0.608421\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331148; batch adversarial loss: 0.604829\n",
      "epoch 34; iter: 200; batch classifier loss: 0.395351; batch adversarial loss: 0.610098\n",
      "epoch 35; iter: 0; batch classifier loss: 0.304257; batch adversarial loss: 0.610756\n",
      "epoch 35; iter: 200; batch classifier loss: 0.451139; batch adversarial loss: 0.601820\n",
      "epoch 36; iter: 0; batch classifier loss: 0.370452; batch adversarial loss: 0.634196\n",
      "epoch 36; iter: 200; batch classifier loss: 0.315500; batch adversarial loss: 0.735985\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394343; batch adversarial loss: 0.617621\n",
      "epoch 37; iter: 200; batch classifier loss: 0.372328; batch adversarial loss: 0.609914\n",
      "epoch 38; iter: 0; batch classifier loss: 0.388341; batch adversarial loss: 0.601475\n",
      "epoch 38; iter: 200; batch classifier loss: 0.391113; batch adversarial loss: 0.604573\n",
      "epoch 39; iter: 0; batch classifier loss: 0.403610; batch adversarial loss: 0.559948\n",
      "epoch 39; iter: 200; batch classifier loss: 0.334424; batch adversarial loss: 0.661383\n",
      "epoch 40; iter: 0; batch classifier loss: 0.352246; batch adversarial loss: 0.629534\n",
      "epoch 40; iter: 200; batch classifier loss: 0.366576; batch adversarial loss: 0.600881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.309979; batch adversarial loss: 0.656622\n",
      "epoch 41; iter: 200; batch classifier loss: 0.386584; batch adversarial loss: 0.645959\n",
      "epoch 42; iter: 0; batch classifier loss: 0.341616; batch adversarial loss: 0.642967\n",
      "epoch 42; iter: 200; batch classifier loss: 0.261971; batch adversarial loss: 0.636446\n",
      "epoch 43; iter: 0; batch classifier loss: 0.305563; batch adversarial loss: 0.646035\n",
      "epoch 43; iter: 200; batch classifier loss: 0.271493; batch adversarial loss: 0.655669\n",
      "epoch 44; iter: 0; batch classifier loss: 0.356331; batch adversarial loss: 0.656693\n",
      "epoch 44; iter: 200; batch classifier loss: 0.342204; batch adversarial loss: 0.586965\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419060; batch adversarial loss: 0.632563\n",
      "epoch 45; iter: 200; batch classifier loss: 0.415138; batch adversarial loss: 0.671722\n",
      "epoch 46; iter: 0; batch classifier loss: 0.322856; batch adversarial loss: 0.651972\n",
      "epoch 46; iter: 200; batch classifier loss: 0.368380; batch adversarial loss: 0.615304\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375842; batch adversarial loss: 0.653296\n",
      "epoch 47; iter: 200; batch classifier loss: 0.354723; batch adversarial loss: 0.590086\n",
      "epoch 48; iter: 0; batch classifier loss: 0.382263; batch adversarial loss: 0.592959\n",
      "epoch 48; iter: 200; batch classifier loss: 0.290325; batch adversarial loss: 0.687893\n",
      "epoch 49; iter: 0; batch classifier loss: 0.387426; batch adversarial loss: 0.619792\n",
      "epoch 49; iter: 200; batch classifier loss: 0.306962; batch adversarial loss: 0.637819\n",
      "epoch 0; iter: 0; batch classifier loss: 13.742162; batch adversarial loss: 0.638135\n",
      "epoch 0; iter: 200; batch classifier loss: 19.711016; batch adversarial loss: 0.685717\n",
      "epoch 1; iter: 0; batch classifier loss: 7.469312; batch adversarial loss: 0.652632\n",
      "epoch 1; iter: 200; batch classifier loss: 6.990502; batch adversarial loss: 0.654025\n",
      "epoch 2; iter: 0; batch classifier loss: 2.583996; batch adversarial loss: 0.615097\n",
      "epoch 2; iter: 200; batch classifier loss: 4.987973; batch adversarial loss: 0.642848\n",
      "epoch 3; iter: 0; batch classifier loss: 4.402871; batch adversarial loss: 0.623394\n",
      "epoch 3; iter: 200; batch classifier loss: 3.608798; batch adversarial loss: 0.621823\n",
      "epoch 4; iter: 0; batch classifier loss: 4.307774; batch adversarial loss: 0.654824\n",
      "epoch 4; iter: 200; batch classifier loss: 2.518438; batch adversarial loss: 0.679398\n",
      "epoch 5; iter: 0; batch classifier loss: 6.565767; batch adversarial loss: 0.612668\n",
      "epoch 5; iter: 200; batch classifier loss: 1.857529; batch adversarial loss: 0.607728\n",
      "epoch 6; iter: 0; batch classifier loss: 1.125035; batch adversarial loss: 0.604453\n",
      "epoch 6; iter: 200; batch classifier loss: 1.191013; batch adversarial loss: 0.618643\n",
      "epoch 7; iter: 0; batch classifier loss: 1.231566; batch adversarial loss: 0.616577\n",
      "epoch 7; iter: 200; batch classifier loss: 0.901955; batch adversarial loss: 0.586182\n",
      "epoch 8; iter: 0; batch classifier loss: 0.653882; batch adversarial loss: 0.609941\n",
      "epoch 8; iter: 200; batch classifier loss: 0.941670; batch adversarial loss: 0.595185\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449241; batch adversarial loss: 0.613887\n",
      "epoch 9; iter: 200; batch classifier loss: 0.576687; batch adversarial loss: 0.610192\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471691; batch adversarial loss: 0.644307\n",
      "epoch 10; iter: 200; batch classifier loss: 0.580695; batch adversarial loss: 0.653455\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457970; batch adversarial loss: 0.655119\n",
      "epoch 11; iter: 200; batch classifier loss: 0.410963; batch adversarial loss: 0.607157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.409956; batch adversarial loss: 0.649059\n",
      "epoch 12; iter: 200; batch classifier loss: 0.446882; batch adversarial loss: 0.617943\n",
      "epoch 13; iter: 0; batch classifier loss: 0.414004; batch adversarial loss: 0.607276\n",
      "epoch 13; iter: 200; batch classifier loss: 0.404561; batch adversarial loss: 0.659124\n",
      "epoch 14; iter: 0; batch classifier loss: 0.300698; batch adversarial loss: 0.602333\n",
      "epoch 14; iter: 200; batch classifier loss: 0.336023; batch adversarial loss: 0.630887\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415019; batch adversarial loss: 0.651506\n",
      "epoch 15; iter: 200; batch classifier loss: 0.413881; batch adversarial loss: 0.592314\n",
      "epoch 16; iter: 0; batch classifier loss: 0.397907; batch adversarial loss: 0.580672\n",
      "epoch 16; iter: 200; batch classifier loss: 0.334483; batch adversarial loss: 0.677619\n",
      "epoch 17; iter: 0; batch classifier loss: 0.389607; batch adversarial loss: 0.584940\n",
      "epoch 17; iter: 200; batch classifier loss: 0.358760; batch adversarial loss: 0.584188\n",
      "epoch 18; iter: 0; batch classifier loss: 0.340612; batch adversarial loss: 0.652885\n",
      "epoch 18; iter: 200; batch classifier loss: 0.341006; batch adversarial loss: 0.643446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408501; batch adversarial loss: 0.671883\n",
      "epoch 19; iter: 200; batch classifier loss: 0.288105; batch adversarial loss: 0.640448\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279099; batch adversarial loss: 0.668129\n",
      "epoch 20; iter: 200; batch classifier loss: 0.283110; batch adversarial loss: 0.597824\n",
      "epoch 21; iter: 0; batch classifier loss: 0.317505; batch adversarial loss: 0.614282\n",
      "epoch 21; iter: 200; batch classifier loss: 0.389764; batch adversarial loss: 0.581267\n",
      "epoch 22; iter: 0; batch classifier loss: 0.277667; batch adversarial loss: 0.590121\n",
      "epoch 22; iter: 200; batch classifier loss: 0.314752; batch adversarial loss: 0.637359\n",
      "epoch 23; iter: 0; batch classifier loss: 0.391614; batch adversarial loss: 0.646592\n",
      "epoch 23; iter: 200; batch classifier loss: 0.376132; batch adversarial loss: 0.599286\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512673; batch adversarial loss: 0.596730\n",
      "epoch 24; iter: 200; batch classifier loss: 0.352627; batch adversarial loss: 0.643293\n",
      "epoch 25; iter: 0; batch classifier loss: 0.385381; batch adversarial loss: 0.669306\n",
      "epoch 25; iter: 200; batch classifier loss: 0.351287; batch adversarial loss: 0.657285\n",
      "epoch 26; iter: 0; batch classifier loss: 0.403647; batch adversarial loss: 0.592145\n",
      "epoch 26; iter: 200; batch classifier loss: 0.308498; batch adversarial loss: 0.640470\n",
      "epoch 27; iter: 0; batch classifier loss: 0.366593; batch adversarial loss: 0.684244\n",
      "epoch 27; iter: 200; batch classifier loss: 0.425745; batch adversarial loss: 0.686665\n",
      "epoch 28; iter: 0; batch classifier loss: 0.320172; batch adversarial loss: 0.639440\n",
      "epoch 28; iter: 200; batch classifier loss: 0.322767; batch adversarial loss: 0.628569\n",
      "epoch 29; iter: 0; batch classifier loss: 0.341216; batch adversarial loss: 0.635453\n",
      "epoch 29; iter: 200; batch classifier loss: 0.256926; batch adversarial loss: 0.663725\n",
      "epoch 30; iter: 0; batch classifier loss: 0.445993; batch adversarial loss: 0.627774\n",
      "epoch 30; iter: 200; batch classifier loss: 0.291665; batch adversarial loss: 0.582743\n",
      "epoch 31; iter: 0; batch classifier loss: 0.477327; batch adversarial loss: 0.663077\n",
      "epoch 31; iter: 200; batch classifier loss: 0.450398; batch adversarial loss: 0.567847\n",
      "epoch 32; iter: 0; batch classifier loss: 0.305676; batch adversarial loss: 0.575983\n",
      "epoch 32; iter: 200; batch classifier loss: 0.278128; batch adversarial loss: 0.642278\n",
      "epoch 33; iter: 0; batch classifier loss: 0.399662; batch adversarial loss: 0.614783\n",
      "epoch 33; iter: 200; batch classifier loss: 0.424553; batch adversarial loss: 0.585143\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418818; batch adversarial loss: 0.615082\n",
      "epoch 34; iter: 200; batch classifier loss: 0.363648; batch adversarial loss: 0.671431\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429654; batch adversarial loss: 0.599523\n",
      "epoch 35; iter: 200; batch classifier loss: 0.357078; batch adversarial loss: 0.625625\n",
      "epoch 36; iter: 0; batch classifier loss: 0.279621; batch adversarial loss: 0.601931\n",
      "epoch 36; iter: 200; batch classifier loss: 0.403758; batch adversarial loss: 0.570849\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394074; batch adversarial loss: 0.628868\n",
      "epoch 37; iter: 200; batch classifier loss: 0.399906; batch adversarial loss: 0.610874\n",
      "epoch 38; iter: 0; batch classifier loss: 0.375683; batch adversarial loss: 0.681130\n",
      "epoch 38; iter: 200; batch classifier loss: 0.325379; batch adversarial loss: 0.618083\n",
      "epoch 39; iter: 0; batch classifier loss: 0.312749; batch adversarial loss: 0.669605\n",
      "epoch 39; iter: 200; batch classifier loss: 0.312290; batch adversarial loss: 0.612310\n",
      "epoch 40; iter: 0; batch classifier loss: 0.301710; batch adversarial loss: 0.632335\n",
      "epoch 40; iter: 200; batch classifier loss: 0.287378; batch adversarial loss: 0.613624\n",
      "epoch 41; iter: 0; batch classifier loss: 0.318394; batch adversarial loss: 0.656046\n",
      "epoch 41; iter: 200; batch classifier loss: 0.400533; batch adversarial loss: 0.626664\n",
      "epoch 42; iter: 0; batch classifier loss: 0.349159; batch adversarial loss: 0.684671\n",
      "epoch 42; iter: 200; batch classifier loss: 0.408127; batch adversarial loss: 0.655898\n",
      "epoch 43; iter: 0; batch classifier loss: 0.400595; batch adversarial loss: 0.648874\n",
      "epoch 43; iter: 200; batch classifier loss: 0.433911; batch adversarial loss: 0.629238\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369987; batch adversarial loss: 0.599199\n",
      "epoch 44; iter: 200; batch classifier loss: 0.305192; batch adversarial loss: 0.662039\n",
      "epoch 45; iter: 0; batch classifier loss: 0.272948; batch adversarial loss: 0.665852\n",
      "epoch 45; iter: 200; batch classifier loss: 0.284763; batch adversarial loss: 0.627300\n",
      "epoch 46; iter: 0; batch classifier loss: 0.357869; batch adversarial loss: 0.682842\n",
      "epoch 46; iter: 200; batch classifier loss: 0.351056; batch adversarial loss: 0.647354\n",
      "epoch 47; iter: 0; batch classifier loss: 0.415844; batch adversarial loss: 0.663824\n",
      "epoch 47; iter: 200; batch classifier loss: 0.430853; batch adversarial loss: 0.558486\n",
      "epoch 48; iter: 0; batch classifier loss: 0.360363; batch adversarial loss: 0.612094\n",
      "epoch 48; iter: 200; batch classifier loss: 0.328597; batch adversarial loss: 0.591995\n",
      "epoch 49; iter: 0; batch classifier loss: 0.289977; batch adversarial loss: 0.614626\n",
      "epoch 49; iter: 200; batch classifier loss: 0.446441; batch adversarial loss: 0.629735\n",
      "epoch 0; iter: 0; batch classifier loss: 16.082623; batch adversarial loss: 0.802283\n",
      "epoch 0; iter: 200; batch classifier loss: 10.415980; batch adversarial loss: 0.730224\n",
      "epoch 1; iter: 0; batch classifier loss: 7.994493; batch adversarial loss: 0.702488\n",
      "epoch 1; iter: 200; batch classifier loss: 4.146662; batch adversarial loss: 0.665615\n",
      "epoch 2; iter: 0; batch classifier loss: 3.276413; batch adversarial loss: 0.653578\n",
      "epoch 2; iter: 200; batch classifier loss: 3.351163; batch adversarial loss: 0.638557\n",
      "epoch 3; iter: 0; batch classifier loss: 2.040865; batch adversarial loss: 0.573476\n",
      "epoch 3; iter: 200; batch classifier loss: 0.961245; batch adversarial loss: 0.594157\n",
      "epoch 4; iter: 0; batch classifier loss: 6.072702; batch adversarial loss: 0.676793\n",
      "epoch 4; iter: 200; batch classifier loss: 4.309747; batch adversarial loss: 0.611762\n",
      "epoch 5; iter: 0; batch classifier loss: 3.275425; batch adversarial loss: 0.624573\n",
      "epoch 5; iter: 200; batch classifier loss: 1.763533; batch adversarial loss: 0.565658\n",
      "epoch 6; iter: 0; batch classifier loss: 4.043687; batch adversarial loss: 0.639023\n",
      "epoch 6; iter: 200; batch classifier loss: 1.742043; batch adversarial loss: 0.628712\n",
      "epoch 7; iter: 0; batch classifier loss: 4.242653; batch adversarial loss: 0.578131\n",
      "epoch 7; iter: 200; batch classifier loss: 3.794005; batch adversarial loss: 0.650122\n",
      "epoch 8; iter: 0; batch classifier loss: 2.858458; batch adversarial loss: 0.610701\n",
      "epoch 8; iter: 200; batch classifier loss: 0.593567; batch adversarial loss: 0.644364\n",
      "epoch 9; iter: 0; batch classifier loss: 0.852063; batch adversarial loss: 0.601363\n",
      "epoch 9; iter: 200; batch classifier loss: 0.795231; batch adversarial loss: 0.612875\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516357; batch adversarial loss: 0.650613\n",
      "epoch 10; iter: 200; batch classifier loss: 0.455755; batch adversarial loss: 0.601746\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489007; batch adversarial loss: 0.616538\n",
      "epoch 11; iter: 200; batch classifier loss: 0.450528; batch adversarial loss: 0.659364\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509805; batch adversarial loss: 0.657242\n",
      "epoch 12; iter: 200; batch classifier loss: 0.465386; batch adversarial loss: 0.683205\n",
      "epoch 13; iter: 0; batch classifier loss: 0.398600; batch adversarial loss: 0.572584\n",
      "epoch 13; iter: 200; batch classifier loss: 0.536365; batch adversarial loss: 0.617676\n",
      "epoch 14; iter: 0; batch classifier loss: 0.410401; batch adversarial loss: 0.637684\n",
      "epoch 14; iter: 200; batch classifier loss: 0.392435; batch adversarial loss: 0.607112\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510081; batch adversarial loss: 0.586618\n",
      "epoch 15; iter: 200; batch classifier loss: 0.436501; batch adversarial loss: 0.618789\n",
      "epoch 16; iter: 0; batch classifier loss: 0.396724; batch adversarial loss: 0.648332\n",
      "epoch 16; iter: 200; batch classifier loss: 0.383379; batch adversarial loss: 0.624349\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345531; batch adversarial loss: 0.644810\n",
      "epoch 17; iter: 200; batch classifier loss: 0.406298; batch adversarial loss: 0.567317\n",
      "epoch 18; iter: 0; batch classifier loss: 0.416386; batch adversarial loss: 0.684726\n",
      "epoch 18; iter: 200; batch classifier loss: 0.327700; batch adversarial loss: 0.599654\n",
      "epoch 19; iter: 0; batch classifier loss: 0.407505; batch adversarial loss: 0.593372\n",
      "epoch 19; iter: 200; batch classifier loss: 0.333050; batch adversarial loss: 0.632560\n",
      "epoch 20; iter: 0; batch classifier loss: 0.315773; batch adversarial loss: 0.674112\n",
      "epoch 20; iter: 200; batch classifier loss: 0.398122; batch adversarial loss: 0.642412\n",
      "epoch 21; iter: 0; batch classifier loss: 0.283759; batch adversarial loss: 0.631481\n",
      "epoch 21; iter: 200; batch classifier loss: 0.456290; batch adversarial loss: 0.554071\n",
      "epoch 22; iter: 0; batch classifier loss: 0.443507; batch adversarial loss: 0.584895\n",
      "epoch 22; iter: 200; batch classifier loss: 0.258669; batch adversarial loss: 0.592882\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396560; batch adversarial loss: 0.605714\n",
      "epoch 23; iter: 200; batch classifier loss: 0.400568; batch adversarial loss: 0.588241\n",
      "epoch 24; iter: 0; batch classifier loss: 0.393798; batch adversarial loss: 0.590536\n",
      "epoch 24; iter: 200; batch classifier loss: 0.339604; batch adversarial loss: 0.564964\n",
      "epoch 25; iter: 0; batch classifier loss: 0.250663; batch adversarial loss: 0.614756\n",
      "epoch 25; iter: 200; batch classifier loss: 0.381649; batch adversarial loss: 0.626422\n",
      "epoch 26; iter: 0; batch classifier loss: 0.431392; batch adversarial loss: 0.616377\n",
      "epoch 26; iter: 200; batch classifier loss: 0.357370; batch adversarial loss: 0.652084\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352090; batch adversarial loss: 0.561035\n",
      "epoch 27; iter: 200; batch classifier loss: 0.378285; batch adversarial loss: 0.626734\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368292; batch adversarial loss: 0.696046\n",
      "epoch 28; iter: 200; batch classifier loss: 0.376045; batch adversarial loss: 0.660245\n",
      "epoch 29; iter: 0; batch classifier loss: 0.309039; batch adversarial loss: 0.639159\n",
      "epoch 29; iter: 200; batch classifier loss: 0.522497; batch adversarial loss: 0.617590\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342182; batch adversarial loss: 0.613899\n",
      "epoch 30; iter: 200; batch classifier loss: 0.311841; batch adversarial loss: 0.620450\n",
      "epoch 31; iter: 0; batch classifier loss: 0.435106; batch adversarial loss: 0.644939\n",
      "epoch 31; iter: 200; batch classifier loss: 0.290829; batch adversarial loss: 0.598517\n",
      "epoch 32; iter: 0; batch classifier loss: 0.351636; batch adversarial loss: 0.564195\n",
      "epoch 32; iter: 200; batch classifier loss: 0.429849; batch adversarial loss: 0.574231\n",
      "epoch 33; iter: 0; batch classifier loss: 0.235508; batch adversarial loss: 0.696349\n",
      "epoch 33; iter: 200; batch classifier loss: 0.325202; batch adversarial loss: 0.649604\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427260; batch adversarial loss: 0.600155\n",
      "epoch 34; iter: 200; batch classifier loss: 0.369763; batch adversarial loss: 0.584436\n",
      "epoch 35; iter: 0; batch classifier loss: 0.352325; batch adversarial loss: 0.653429\n",
      "epoch 35; iter: 200; batch classifier loss: 0.325013; batch adversarial loss: 0.616047\n",
      "epoch 36; iter: 0; batch classifier loss: 0.408642; batch adversarial loss: 0.631520\n",
      "epoch 36; iter: 200; batch classifier loss: 0.410833; batch adversarial loss: 0.660613\n",
      "epoch 37; iter: 0; batch classifier loss: 0.470441; batch adversarial loss: 0.614614\n",
      "epoch 37; iter: 200; batch classifier loss: 0.443321; batch adversarial loss: 0.678334\n",
      "epoch 38; iter: 0; batch classifier loss: 0.348235; batch adversarial loss: 0.595839\n",
      "epoch 38; iter: 200; batch classifier loss: 0.319938; batch adversarial loss: 0.628114\n",
      "epoch 39; iter: 0; batch classifier loss: 0.308746; batch adversarial loss: 0.661212\n",
      "epoch 39; iter: 200; batch classifier loss: 0.359877; batch adversarial loss: 0.637661\n",
      "epoch 40; iter: 0; batch classifier loss: 0.330056; batch adversarial loss: 0.620316\n",
      "epoch 40; iter: 200; batch classifier loss: 0.333507; batch adversarial loss: 0.608447\n",
      "epoch 41; iter: 0; batch classifier loss: 0.425765; batch adversarial loss: 0.633578\n",
      "epoch 41; iter: 200; batch classifier loss: 0.438625; batch adversarial loss: 0.614786\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405980; batch adversarial loss: 0.621358\n",
      "epoch 42; iter: 200; batch classifier loss: 0.460489; batch adversarial loss: 0.606423\n",
      "epoch 43; iter: 0; batch classifier loss: 0.338224; batch adversarial loss: 0.706960\n",
      "epoch 43; iter: 200; batch classifier loss: 0.318055; batch adversarial loss: 0.625965\n",
      "epoch 44; iter: 0; batch classifier loss: 0.455509; batch adversarial loss: 0.616693\n",
      "epoch 44; iter: 200; batch classifier loss: 0.424129; batch adversarial loss: 0.623080\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414129; batch adversarial loss: 0.587842\n",
      "epoch 45; iter: 200; batch classifier loss: 0.386181; batch adversarial loss: 0.600099\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388313; batch adversarial loss: 0.672713\n",
      "epoch 46; iter: 200; batch classifier loss: 0.363044; batch adversarial loss: 0.564252\n",
      "epoch 47; iter: 0; batch classifier loss: 0.280406; batch adversarial loss: 0.585139\n",
      "epoch 47; iter: 200; batch classifier loss: 0.483524; batch adversarial loss: 0.630935\n",
      "epoch 48; iter: 0; batch classifier loss: 0.346463; batch adversarial loss: 0.620456\n",
      "epoch 48; iter: 200; batch classifier loss: 0.404963; batch adversarial loss: 0.635865\n",
      "epoch 49; iter: 0; batch classifier loss: 0.287501; batch adversarial loss: 0.680984\n",
      "epoch 49; iter: 200; batch classifier loss: 0.420130; batch adversarial loss: 0.661827\n",
      "epoch 0; iter: 0; batch classifier loss: 122.328430; batch adversarial loss: 0.747253\n",
      "epoch 0; iter: 200; batch classifier loss: 3.842283; batch adversarial loss: 0.690974\n",
      "epoch 1; iter: 0; batch classifier loss: 3.332760; batch adversarial loss: 0.662195\n",
      "epoch 1; iter: 200; batch classifier loss: 3.287538; batch adversarial loss: 0.648391\n",
      "epoch 2; iter: 0; batch classifier loss: 4.181852; batch adversarial loss: 0.616161\n",
      "epoch 2; iter: 200; batch classifier loss: 7.700064; batch adversarial loss: 0.664623\n",
      "epoch 3; iter: 0; batch classifier loss: 4.215015; batch adversarial loss: 0.688495\n",
      "epoch 3; iter: 200; batch classifier loss: 2.758403; batch adversarial loss: 0.600933\n",
      "epoch 4; iter: 0; batch classifier loss: 2.433830; batch adversarial loss: 0.619832\n",
      "epoch 4; iter: 200; batch classifier loss: 4.459514; batch adversarial loss: 0.626952\n",
      "epoch 5; iter: 0; batch classifier loss: 1.756497; batch adversarial loss: 0.593371\n",
      "epoch 5; iter: 200; batch classifier loss: 1.734105; batch adversarial loss: 0.611807\n",
      "epoch 6; iter: 0; batch classifier loss: 1.406060; batch adversarial loss: 0.615485\n",
      "epoch 6; iter: 200; batch classifier loss: 1.618380; batch adversarial loss: 0.675142\n",
      "epoch 7; iter: 0; batch classifier loss: 1.316472; batch adversarial loss: 0.640542\n",
      "epoch 7; iter: 200; batch classifier loss: 0.800201; batch adversarial loss: 0.606057\n",
      "epoch 8; iter: 0; batch classifier loss: 0.668801; batch adversarial loss: 0.595726\n",
      "epoch 8; iter: 200; batch classifier loss: 0.525659; batch adversarial loss: 0.630323\n",
      "epoch 9; iter: 0; batch classifier loss: 0.477154; batch adversarial loss: 0.622147\n",
      "epoch 9; iter: 200; batch classifier loss: 1.046855; batch adversarial loss: 0.624980\n",
      "epoch 10; iter: 0; batch classifier loss: 0.738674; batch adversarial loss: 0.643770\n",
      "epoch 10; iter: 200; batch classifier loss: 0.586868; batch adversarial loss: 0.651079\n",
      "epoch 11; iter: 0; batch classifier loss: 0.474557; batch adversarial loss: 0.615796\n",
      "epoch 11; iter: 200; batch classifier loss: 0.491240; batch adversarial loss: 0.575847\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578857; batch adversarial loss: 0.638241\n",
      "epoch 12; iter: 200; batch classifier loss: 0.546410; batch adversarial loss: 0.637975\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457224; batch adversarial loss: 0.635784\n",
      "epoch 13; iter: 200; batch classifier loss: 0.458457; batch adversarial loss: 0.621232\n",
      "epoch 14; iter: 0; batch classifier loss: 0.711506; batch adversarial loss: 0.625511\n",
      "epoch 14; iter: 200; batch classifier loss: 0.296942; batch adversarial loss: 0.689647\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396452; batch adversarial loss: 0.630674\n",
      "epoch 15; iter: 200; batch classifier loss: 0.314867; batch adversarial loss: 0.617717\n",
      "epoch 16; iter: 0; batch classifier loss: 0.431296; batch adversarial loss: 0.610956\n",
      "epoch 16; iter: 200; batch classifier loss: 0.413484; batch adversarial loss: 0.617997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.433948; batch adversarial loss: 0.579811\n",
      "epoch 17; iter: 200; batch classifier loss: 0.360557; batch adversarial loss: 0.645607\n",
      "epoch 18; iter: 0; batch classifier loss: 0.368478; batch adversarial loss: 0.648036\n",
      "epoch 18; iter: 200; batch classifier loss: 0.284556; batch adversarial loss: 0.612062\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379372; batch adversarial loss: 0.623272\n",
      "epoch 19; iter: 200; batch classifier loss: 0.366236; batch adversarial loss: 0.661805\n",
      "epoch 20; iter: 0; batch classifier loss: 0.412302; batch adversarial loss: 0.647799\n",
      "epoch 20; iter: 200; batch classifier loss: 0.370649; batch adversarial loss: 0.632347\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526212; batch adversarial loss: 0.646099\n",
      "epoch 21; iter: 200; batch classifier loss: 0.294254; batch adversarial loss: 0.620076\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437008; batch adversarial loss: 0.669235\n",
      "epoch 22; iter: 200; batch classifier loss: 0.337524; batch adversarial loss: 0.632133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.339264; batch adversarial loss: 0.620524\n",
      "epoch 23; iter: 200; batch classifier loss: 0.459922; batch adversarial loss: 0.597783\n",
      "epoch 24; iter: 0; batch classifier loss: 0.340473; batch adversarial loss: 0.610061\n",
      "epoch 24; iter: 200; batch classifier loss: 0.363199; batch adversarial loss: 0.583888\n",
      "epoch 25; iter: 0; batch classifier loss: 0.364049; batch adversarial loss: 0.630169\n",
      "epoch 25; iter: 200; batch classifier loss: 0.295292; batch adversarial loss: 0.633211\n",
      "epoch 26; iter: 0; batch classifier loss: 0.282908; batch adversarial loss: 0.621856\n",
      "epoch 26; iter: 200; batch classifier loss: 0.401219; batch adversarial loss: 0.601257\n",
      "epoch 27; iter: 0; batch classifier loss: 0.385627; batch adversarial loss: 0.666278\n",
      "epoch 27; iter: 200; batch classifier loss: 0.263787; batch adversarial loss: 0.648058\n",
      "epoch 28; iter: 0; batch classifier loss: 0.423429; batch adversarial loss: 0.593986\n",
      "epoch 28; iter: 200; batch classifier loss: 0.311775; batch adversarial loss: 0.550214\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315903; batch adversarial loss: 0.656110\n",
      "epoch 29; iter: 200; batch classifier loss: 0.469478; batch adversarial loss: 0.644600\n",
      "epoch 30; iter: 0; batch classifier loss: 0.346014; batch adversarial loss: 0.591431\n",
      "epoch 30; iter: 200; batch classifier loss: 0.383031; batch adversarial loss: 0.583720\n",
      "epoch 31; iter: 0; batch classifier loss: 0.335850; batch adversarial loss: 0.614769\n",
      "epoch 31; iter: 200; batch classifier loss: 0.314548; batch adversarial loss: 0.665810\n",
      "epoch 32; iter: 0; batch classifier loss: 0.351848; batch adversarial loss: 0.652400\n",
      "epoch 32; iter: 200; batch classifier loss: 0.356828; batch adversarial loss: 0.680511\n",
      "epoch 33; iter: 0; batch classifier loss: 0.246443; batch adversarial loss: 0.608334\n",
      "epoch 33; iter: 200; batch classifier loss: 0.376329; batch adversarial loss: 0.634396\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331768; batch adversarial loss: 0.686882\n",
      "epoch 34; iter: 200; batch classifier loss: 0.413673; batch adversarial loss: 0.683236\n",
      "epoch 35; iter: 0; batch classifier loss: 0.424479; batch adversarial loss: 0.619237\n",
      "epoch 35; iter: 200; batch classifier loss: 0.350071; batch adversarial loss: 0.622937\n",
      "epoch 36; iter: 0; batch classifier loss: 0.321728; batch adversarial loss: 0.605543\n",
      "epoch 36; iter: 200; batch classifier loss: 0.423648; batch adversarial loss: 0.612056\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386854; batch adversarial loss: 0.658554\n",
      "epoch 37; iter: 200; batch classifier loss: 0.388797; batch adversarial loss: 0.618040\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412869; batch adversarial loss: 0.630491\n",
      "epoch 38; iter: 200; batch classifier loss: 0.407575; batch adversarial loss: 0.650412\n",
      "epoch 39; iter: 0; batch classifier loss: 0.383730; batch adversarial loss: 0.640365\n",
      "epoch 39; iter: 200; batch classifier loss: 0.368325; batch adversarial loss: 0.640804\n",
      "epoch 40; iter: 0; batch classifier loss: 0.431834; batch adversarial loss: 0.673105\n",
      "epoch 40; iter: 200; batch classifier loss: 0.408225; batch adversarial loss: 0.625252\n",
      "epoch 41; iter: 0; batch classifier loss: 0.372109; batch adversarial loss: 0.578460\n",
      "epoch 41; iter: 200; batch classifier loss: 0.555323; batch adversarial loss: 0.704426\n",
      "epoch 42; iter: 0; batch classifier loss: 0.356495; batch adversarial loss: 0.681721\n",
      "epoch 42; iter: 200; batch classifier loss: 0.335537; batch adversarial loss: 0.621375\n",
      "epoch 43; iter: 0; batch classifier loss: 0.304402; batch adversarial loss: 0.584526\n",
      "epoch 43; iter: 200; batch classifier loss: 0.318058; batch adversarial loss: 0.638886\n",
      "epoch 44; iter: 0; batch classifier loss: 0.331127; batch adversarial loss: 0.636750\n",
      "epoch 44; iter: 200; batch classifier loss: 0.431031; batch adversarial loss: 0.640995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.715036; batch adversarial loss: 0.630649\n",
      "epoch 45; iter: 200; batch classifier loss: 0.460739; batch adversarial loss: 0.673760\n",
      "epoch 46; iter: 0; batch classifier loss: 0.494892; batch adversarial loss: 0.627944\n",
      "epoch 46; iter: 200; batch classifier loss: 0.599070; batch adversarial loss: 0.585342\n",
      "epoch 47; iter: 0; batch classifier loss: 0.551843; batch adversarial loss: 0.586255\n",
      "epoch 47; iter: 200; batch classifier loss: 0.466537; batch adversarial loss: 0.627884\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379292; batch adversarial loss: 0.589281\n",
      "epoch 48; iter: 200; batch classifier loss: 0.372438; batch adversarial loss: 0.617285\n",
      "epoch 49; iter: 0; batch classifier loss: 0.395192; batch adversarial loss: 0.589437\n",
      "epoch 49; iter: 200; batch classifier loss: 0.389596; batch adversarial loss: 0.605508\n",
      "epoch 0; iter: 0; batch classifier loss: 56.134254; batch adversarial loss: 0.660332\n",
      "epoch 0; iter: 200; batch classifier loss: 9.238841; batch adversarial loss: 0.645027\n",
      "epoch 1; iter: 0; batch classifier loss: 9.104897; batch adversarial loss: 0.638089\n",
      "epoch 1; iter: 200; batch classifier loss: 3.403853; batch adversarial loss: 0.608949\n",
      "epoch 2; iter: 0; batch classifier loss: 1.150012; batch adversarial loss: 0.644154\n",
      "epoch 2; iter: 200; batch classifier loss: 5.234962; batch adversarial loss: 0.616814\n",
      "epoch 3; iter: 0; batch classifier loss: 3.329962; batch adversarial loss: 0.588525\n",
      "epoch 3; iter: 200; batch classifier loss: 4.353988; batch adversarial loss: 0.636619\n",
      "epoch 4; iter: 0; batch classifier loss: 2.809129; batch adversarial loss: 0.621033\n",
      "epoch 4; iter: 200; batch classifier loss: 11.181289; batch adversarial loss: 0.581101\n",
      "epoch 5; iter: 0; batch classifier loss: 0.934934; batch adversarial loss: 0.610441\n",
      "epoch 5; iter: 200; batch classifier loss: 1.806554; batch adversarial loss: 0.608734\n",
      "epoch 6; iter: 0; batch classifier loss: 2.648105; batch adversarial loss: 0.692392\n",
      "epoch 6; iter: 200; batch classifier loss: 1.023623; batch adversarial loss: 0.564026\n",
      "epoch 7; iter: 0; batch classifier loss: 1.269555; batch adversarial loss: 0.600256\n",
      "epoch 7; iter: 200; batch classifier loss: 0.923215; batch adversarial loss: 0.623386\n",
      "epoch 8; iter: 0; batch classifier loss: 0.874379; batch adversarial loss: 0.588484\n",
      "epoch 8; iter: 200; batch classifier loss: 0.528105; batch adversarial loss: 0.655688\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519975; batch adversarial loss: 0.613512\n",
      "epoch 9; iter: 200; batch classifier loss: 0.324886; batch adversarial loss: 0.603026\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479007; batch adversarial loss: 0.649183\n",
      "epoch 10; iter: 200; batch classifier loss: 0.440041; batch adversarial loss: 0.610351\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360245; batch adversarial loss: 0.613709\n",
      "epoch 11; iter: 200; batch classifier loss: 0.470631; batch adversarial loss: 0.632580\n",
      "epoch 12; iter: 0; batch classifier loss: 0.393047; batch adversarial loss: 0.654302\n",
      "epoch 12; iter: 200; batch classifier loss: 0.386686; batch adversarial loss: 0.692766\n",
      "epoch 13; iter: 0; batch classifier loss: 0.358672; batch adversarial loss: 0.673697\n",
      "epoch 13; iter: 200; batch classifier loss: 0.790436; batch adversarial loss: 0.631524\n",
      "epoch 14; iter: 0; batch classifier loss: 0.372738; batch adversarial loss: 0.587032\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351288; batch adversarial loss: 0.572594\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554711; batch adversarial loss: 0.620531\n",
      "epoch 15; iter: 200; batch classifier loss: 0.389276; batch adversarial loss: 0.616384\n",
      "epoch 16; iter: 0; batch classifier loss: 0.370415; batch adversarial loss: 0.617050\n",
      "epoch 16; iter: 200; batch classifier loss: 0.432684; batch adversarial loss: 0.642310\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529617; batch adversarial loss: 0.602746\n",
      "epoch 17; iter: 200; batch classifier loss: 0.345821; batch adversarial loss: 0.638433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.246620; batch adversarial loss: 0.619886\n",
      "epoch 18; iter: 200; batch classifier loss: 0.441786; batch adversarial loss: 0.656377\n",
      "epoch 19; iter: 0; batch classifier loss: 0.302074; batch adversarial loss: 0.624220\n",
      "epoch 19; iter: 200; batch classifier loss: 0.412250; batch adversarial loss: 0.591865\n",
      "epoch 20; iter: 0; batch classifier loss: 0.552905; batch adversarial loss: 0.666975\n",
      "epoch 20; iter: 200; batch classifier loss: 0.362802; batch adversarial loss: 0.616802\n",
      "epoch 21; iter: 0; batch classifier loss: 0.342818; batch adversarial loss: 0.608201\n",
      "epoch 21; iter: 200; batch classifier loss: 0.367114; batch adversarial loss: 0.657043\n",
      "epoch 22; iter: 0; batch classifier loss: 0.349317; batch adversarial loss: 0.598435\n",
      "epoch 22; iter: 200; batch classifier loss: 0.419544; batch adversarial loss: 0.585780\n",
      "epoch 23; iter: 0; batch classifier loss: 0.275050; batch adversarial loss: 0.664118\n",
      "epoch 23; iter: 200; batch classifier loss: 0.234693; batch adversarial loss: 0.709640\n",
      "epoch 24; iter: 0; batch classifier loss: 0.373913; batch adversarial loss: 0.599374\n",
      "epoch 24; iter: 200; batch classifier loss: 0.402942; batch adversarial loss: 0.604972\n",
      "epoch 25; iter: 0; batch classifier loss: 0.388330; batch adversarial loss: 0.608234\n",
      "epoch 25; iter: 200; batch classifier loss: 0.321356; batch adversarial loss: 0.670669\n",
      "epoch 26; iter: 0; batch classifier loss: 0.322270; batch adversarial loss: 0.657150\n",
      "epoch 26; iter: 200; batch classifier loss: 0.333575; batch adversarial loss: 0.577294\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390936; batch adversarial loss: 0.602535\n",
      "epoch 27; iter: 200; batch classifier loss: 0.380353; batch adversarial loss: 0.644007\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375070; batch adversarial loss: 0.613872\n",
      "epoch 28; iter: 200; batch classifier loss: 0.436382; batch adversarial loss: 0.617139\n",
      "epoch 29; iter: 0; batch classifier loss: 0.337345; batch adversarial loss: 0.595905\n",
      "epoch 29; iter: 200; batch classifier loss: 0.353623; batch adversarial loss: 0.593910\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264946; batch adversarial loss: 0.700449\n",
      "epoch 30; iter: 200; batch classifier loss: 0.395065; batch adversarial loss: 0.628911\n",
      "epoch 31; iter: 0; batch classifier loss: 0.357593; batch adversarial loss: 0.613816\n",
      "epoch 31; iter: 200; batch classifier loss: 0.321826; batch adversarial loss: 0.632955\n",
      "epoch 32; iter: 0; batch classifier loss: 0.380881; batch adversarial loss: 0.628591\n",
      "epoch 32; iter: 200; batch classifier loss: 0.413021; batch adversarial loss: 0.622108\n",
      "epoch 33; iter: 0; batch classifier loss: 0.332170; batch adversarial loss: 0.587305\n",
      "epoch 33; iter: 200; batch classifier loss: 0.416142; batch adversarial loss: 0.604799\n",
      "epoch 34; iter: 0; batch classifier loss: 0.381956; batch adversarial loss: 0.633017\n",
      "epoch 34; iter: 200; batch classifier loss: 0.235093; batch adversarial loss: 0.645723\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372259; batch adversarial loss: 0.594631\n",
      "epoch 35; iter: 200; batch classifier loss: 0.351309; batch adversarial loss: 0.619538\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389261; batch adversarial loss: 0.659262\n",
      "epoch 36; iter: 200; batch classifier loss: 0.422830; batch adversarial loss: 0.647650\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399880; batch adversarial loss: 0.656881\n",
      "epoch 37; iter: 200; batch classifier loss: 0.293911; batch adversarial loss: 0.599349\n",
      "epoch 38; iter: 0; batch classifier loss: 0.289196; batch adversarial loss: 0.607687\n",
      "epoch 38; iter: 200; batch classifier loss: 0.378359; batch adversarial loss: 0.588851\n",
      "epoch 39; iter: 0; batch classifier loss: 0.383842; batch adversarial loss: 0.699804\n",
      "epoch 39; iter: 200; batch classifier loss: 0.374652; batch adversarial loss: 0.597950\n",
      "epoch 40; iter: 0; batch classifier loss: 0.372874; batch adversarial loss: 0.588877\n",
      "epoch 40; iter: 200; batch classifier loss: 0.435605; batch adversarial loss: 0.616154\n",
      "epoch 41; iter: 0; batch classifier loss: 0.362193; batch adversarial loss: 0.597855\n",
      "epoch 41; iter: 200; batch classifier loss: 0.440404; batch adversarial loss: 0.604739\n",
      "epoch 42; iter: 0; batch classifier loss: 0.495316; batch adversarial loss: 0.662894\n",
      "epoch 42; iter: 200; batch classifier loss: 0.315141; batch adversarial loss: 0.642720\n",
      "epoch 43; iter: 0; batch classifier loss: 0.336837; batch adversarial loss: 0.608882\n",
      "epoch 43; iter: 200; batch classifier loss: 0.299395; batch adversarial loss: 0.573864\n",
      "epoch 44; iter: 0; batch classifier loss: 0.379240; batch adversarial loss: 0.634652\n",
      "epoch 44; iter: 200; batch classifier loss: 0.927073; batch adversarial loss: 0.657832\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444994; batch adversarial loss: 0.638575\n",
      "epoch 45; iter: 200; batch classifier loss: 0.979748; batch adversarial loss: 0.630700\n",
      "epoch 46; iter: 0; batch classifier loss: 0.438941; batch adversarial loss: 0.637870\n",
      "epoch 46; iter: 200; batch classifier loss: 0.395404; batch adversarial loss: 0.618273\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431630; batch adversarial loss: 0.676436\n",
      "epoch 47; iter: 200; batch classifier loss: 0.398272; batch adversarial loss: 0.569582\n",
      "epoch 48; iter: 0; batch classifier loss: 0.428937; batch adversarial loss: 0.639614\n",
      "epoch 48; iter: 200; batch classifier loss: 0.332817; batch adversarial loss: 0.651077\n",
      "epoch 49; iter: 0; batch classifier loss: 0.416297; batch adversarial loss: 0.659304\n",
      "epoch 49; iter: 200; batch classifier loss: 0.529985; batch adversarial loss: 0.572050\n",
      "epoch 0; iter: 0; batch classifier loss: 20.112244; batch adversarial loss: 0.678246\n",
      "epoch 0; iter: 200; batch classifier loss: 8.241394; batch adversarial loss: 0.682686\n",
      "epoch 1; iter: 0; batch classifier loss: 8.306616; batch adversarial loss: 0.647465\n",
      "epoch 1; iter: 200; batch classifier loss: 7.473288; batch adversarial loss: 0.663636\n",
      "epoch 2; iter: 0; batch classifier loss: 5.334216; batch adversarial loss: 0.626931\n",
      "epoch 2; iter: 200; batch classifier loss: 1.161336; batch adversarial loss: 0.592188\n",
      "epoch 3; iter: 0; batch classifier loss: 8.367943; batch adversarial loss: 0.615788\n",
      "epoch 3; iter: 200; batch classifier loss: 3.031848; batch adversarial loss: 0.656632\n",
      "epoch 4; iter: 0; batch classifier loss: 1.329440; batch adversarial loss: 0.639790\n",
      "epoch 4; iter: 200; batch classifier loss: 2.085902; batch adversarial loss: 0.626264\n",
      "epoch 5; iter: 0; batch classifier loss: 2.389994; batch adversarial loss: 0.613225\n",
      "epoch 5; iter: 200; batch classifier loss: 1.579039; batch adversarial loss: 0.618641\n",
      "epoch 6; iter: 0; batch classifier loss: 2.798946; batch adversarial loss: 0.590630\n",
      "epoch 6; iter: 200; batch classifier loss: 1.161938; batch adversarial loss: 0.644757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.428070; batch adversarial loss: 0.610343\n",
      "epoch 7; iter: 200; batch classifier loss: 0.863812; batch adversarial loss: 0.598230\n",
      "epoch 8; iter: 0; batch classifier loss: 0.930783; batch adversarial loss: 0.667758\n",
      "epoch 8; iter: 200; batch classifier loss: 0.493928; batch adversarial loss: 0.665354\n",
      "epoch 9; iter: 0; batch classifier loss: 0.532389; batch adversarial loss: 0.622647\n",
      "epoch 9; iter: 200; batch classifier loss: 0.429694; batch adversarial loss: 0.641228\n",
      "epoch 10; iter: 0; batch classifier loss: 0.482448; batch adversarial loss: 0.635309\n",
      "epoch 10; iter: 200; batch classifier loss: 0.450706; batch adversarial loss: 0.634749\n",
      "epoch 11; iter: 0; batch classifier loss: 0.691160; batch adversarial loss: 0.650325\n",
      "epoch 11; iter: 200; batch classifier loss: 0.472304; batch adversarial loss: 0.655770\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405215; batch adversarial loss: 0.619249\n",
      "epoch 12; iter: 200; batch classifier loss: 0.401031; batch adversarial loss: 0.609902\n",
      "epoch 13; iter: 0; batch classifier loss: 0.351591; batch adversarial loss: 0.670587\n",
      "epoch 13; iter: 200; batch classifier loss: 0.310514; batch adversarial loss: 0.664425\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476950; batch adversarial loss: 0.639999\n",
      "epoch 14; iter: 200; batch classifier loss: 0.366434; batch adversarial loss: 0.668703\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435295; batch adversarial loss: 0.642807\n",
      "epoch 15; iter: 200; batch classifier loss: 0.380502; batch adversarial loss: 0.633944\n",
      "epoch 16; iter: 0; batch classifier loss: 0.396275; batch adversarial loss: 0.611167\n",
      "epoch 16; iter: 200; batch classifier loss: 0.355714; batch adversarial loss: 0.592993\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409579; batch adversarial loss: 0.600677\n",
      "epoch 17; iter: 200; batch classifier loss: 0.364779; batch adversarial loss: 0.652300\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437248; batch adversarial loss: 0.657641\n",
      "epoch 18; iter: 200; batch classifier loss: 0.305726; batch adversarial loss: 0.620887\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374676; batch adversarial loss: 0.664704\n",
      "epoch 19; iter: 200; batch classifier loss: 0.380316; batch adversarial loss: 0.606297\n",
      "epoch 20; iter: 0; batch classifier loss: 0.392174; batch adversarial loss: 0.633285\n",
      "epoch 20; iter: 200; batch classifier loss: 0.399089; batch adversarial loss: 0.624545\n",
      "epoch 21; iter: 0; batch classifier loss: 0.444771; batch adversarial loss: 0.608001\n",
      "epoch 21; iter: 200; batch classifier loss: 0.356856; batch adversarial loss: 0.630685\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451190; batch adversarial loss: 0.592442\n",
      "epoch 22; iter: 200; batch classifier loss: 0.469889; batch adversarial loss: 0.587820\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423451; batch adversarial loss: 0.575585\n",
      "epoch 23; iter: 200; batch classifier loss: 0.411558; batch adversarial loss: 0.597013\n",
      "epoch 24; iter: 0; batch classifier loss: 0.392211; batch adversarial loss: 0.643431\n",
      "epoch 24; iter: 200; batch classifier loss: 0.260536; batch adversarial loss: 0.593177\n",
      "epoch 25; iter: 0; batch classifier loss: 0.340371; batch adversarial loss: 0.608933\n",
      "epoch 25; iter: 200; batch classifier loss: 0.394044; batch adversarial loss: 0.663075\n",
      "epoch 26; iter: 0; batch classifier loss: 0.318169; batch adversarial loss: 0.649755\n",
      "epoch 26; iter: 200; batch classifier loss: 0.521485; batch adversarial loss: 0.632646\n",
      "epoch 27; iter: 0; batch classifier loss: 0.364081; batch adversarial loss: 0.584072\n",
      "epoch 27; iter: 200; batch classifier loss: 0.458491; batch adversarial loss: 0.588063\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422519; batch adversarial loss: 0.650340\n",
      "epoch 28; iter: 200; batch classifier loss: 0.319432; batch adversarial loss: 0.554995\n",
      "epoch 29; iter: 0; batch classifier loss: 0.489421; batch adversarial loss: 0.604570\n",
      "epoch 29; iter: 200; batch classifier loss: 0.395020; batch adversarial loss: 0.612580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.339257; batch adversarial loss: 0.628366\n",
      "epoch 30; iter: 200; batch classifier loss: 0.475090; batch adversarial loss: 0.626018\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398205; batch adversarial loss: 0.605076\n",
      "epoch 31; iter: 200; batch classifier loss: 0.443805; batch adversarial loss: 0.608510\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448723; batch adversarial loss: 0.680243\n",
      "epoch 32; iter: 200; batch classifier loss: 0.292049; batch adversarial loss: 0.656168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424054; batch adversarial loss: 0.666085\n",
      "epoch 33; iter: 200; batch classifier loss: 0.476331; batch adversarial loss: 0.594504\n",
      "epoch 34; iter: 0; batch classifier loss: 0.338933; batch adversarial loss: 0.666327\n",
      "epoch 34; iter: 200; batch classifier loss: 0.466404; batch adversarial loss: 0.639304\n",
      "epoch 35; iter: 0; batch classifier loss: 0.277072; batch adversarial loss: 0.685563\n",
      "epoch 35; iter: 200; batch classifier loss: 0.388705; batch adversarial loss: 0.637873\n",
      "epoch 36; iter: 0; batch classifier loss: 0.356822; batch adversarial loss: 0.608215\n",
      "epoch 36; iter: 200; batch classifier loss: 0.418841; batch adversarial loss: 0.675083\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343254; batch adversarial loss: 0.634554\n",
      "epoch 37; iter: 200; batch classifier loss: 0.470477; batch adversarial loss: 0.667366\n",
      "epoch 38; iter: 0; batch classifier loss: 0.263812; batch adversarial loss: 0.677164\n",
      "epoch 38; iter: 200; batch classifier loss: 0.470275; batch adversarial loss: 0.652038\n",
      "epoch 39; iter: 0; batch classifier loss: 0.393783; batch adversarial loss: 0.685381\n",
      "epoch 39; iter: 200; batch classifier loss: 0.274183; batch adversarial loss: 0.681471\n",
      "epoch 40; iter: 0; batch classifier loss: 0.429392; batch adversarial loss: 0.659697\n",
      "epoch 40; iter: 200; batch classifier loss: 0.343819; batch adversarial loss: 0.641919\n",
      "epoch 41; iter: 0; batch classifier loss: 0.466520; batch adversarial loss: 0.624879\n",
      "epoch 41; iter: 200; batch classifier loss: 0.379183; batch adversarial loss: 0.632139\n",
      "epoch 42; iter: 0; batch classifier loss: 0.382207; batch adversarial loss: 0.680750\n",
      "epoch 42; iter: 200; batch classifier loss: 0.614635; batch adversarial loss: 0.642100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380485; batch adversarial loss: 0.678699\n",
      "epoch 43; iter: 200; batch classifier loss: 0.365897; batch adversarial loss: 0.583950\n",
      "epoch 44; iter: 0; batch classifier loss: 0.302792; batch adversarial loss: 0.588890\n",
      "epoch 44; iter: 200; batch classifier loss: 0.261509; batch adversarial loss: 0.628022\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436322; batch adversarial loss: 0.623021\n",
      "epoch 45; iter: 200; batch classifier loss: 0.373114; batch adversarial loss: 0.664204\n",
      "epoch 46; iter: 0; batch classifier loss: 0.529985; batch adversarial loss: 0.631494\n",
      "epoch 46; iter: 200; batch classifier loss: 0.372461; batch adversarial loss: 0.619903\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348024; batch adversarial loss: 0.595728\n",
      "epoch 47; iter: 200; batch classifier loss: 0.455544; batch adversarial loss: 0.639673\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347434; batch adversarial loss: 0.588839\n",
      "epoch 48; iter: 200; batch classifier loss: 0.444005; batch adversarial loss: 0.660201\n",
      "epoch 49; iter: 0; batch classifier loss: 0.353504; batch adversarial loss: 0.645630\n",
      "epoch 49; iter: 200; batch classifier loss: 0.447056; batch adversarial loss: 0.634582\n",
      "epoch 0; iter: 0; batch classifier loss: 59.670567; batch adversarial loss: 0.739936\n",
      "epoch 0; iter: 200; batch classifier loss: 12.508440; batch adversarial loss: 0.662929\n",
      "epoch 1; iter: 0; batch classifier loss: 5.199493; batch adversarial loss: 0.669709\n",
      "epoch 1; iter: 200; batch classifier loss: 22.881279; batch adversarial loss: 0.629208\n",
      "epoch 2; iter: 0; batch classifier loss: 11.462864; batch adversarial loss: 0.627033\n",
      "epoch 2; iter: 200; batch classifier loss: 2.698643; batch adversarial loss: 0.604095\n",
      "epoch 3; iter: 0; batch classifier loss: 3.021677; batch adversarial loss: 0.637229\n",
      "epoch 3; iter: 200; batch classifier loss: 4.221648; batch adversarial loss: 0.625785\n",
      "epoch 4; iter: 0; batch classifier loss: 1.962186; batch adversarial loss: 0.665302\n",
      "epoch 4; iter: 200; batch classifier loss: 0.785297; batch adversarial loss: 0.649347\n",
      "epoch 5; iter: 0; batch classifier loss: 11.723344; batch adversarial loss: 0.648910\n",
      "epoch 5; iter: 200; batch classifier loss: 1.042854; batch adversarial loss: 0.619336\n",
      "epoch 6; iter: 0; batch classifier loss: 2.553180; batch adversarial loss: 0.574314\n",
      "epoch 6; iter: 200; batch classifier loss: 0.936986; batch adversarial loss: 0.639802\n",
      "epoch 7; iter: 0; batch classifier loss: 0.984432; batch adversarial loss: 0.628391\n",
      "epoch 7; iter: 200; batch classifier loss: 0.942463; batch adversarial loss: 0.626931\n",
      "epoch 8; iter: 0; batch classifier loss: 1.725243; batch adversarial loss: 0.575977\n",
      "epoch 8; iter: 200; batch classifier loss: 1.961826; batch adversarial loss: 0.645953\n",
      "epoch 9; iter: 0; batch classifier loss: 0.808474; batch adversarial loss: 0.604171\n",
      "epoch 9; iter: 200; batch classifier loss: 0.683961; batch adversarial loss: 0.687609\n",
      "epoch 10; iter: 0; batch classifier loss: 1.244952; batch adversarial loss: 0.638645\n",
      "epoch 10; iter: 200; batch classifier loss: 0.443058; batch adversarial loss: 0.657443\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548630; batch adversarial loss: 0.616546\n",
      "epoch 11; iter: 200; batch classifier loss: 0.533737; batch adversarial loss: 0.631129\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526516; batch adversarial loss: 0.583707\n",
      "epoch 12; iter: 200; batch classifier loss: 0.417122; batch adversarial loss: 0.601700\n",
      "epoch 13; iter: 0; batch classifier loss: 0.537699; batch adversarial loss: 0.627037\n",
      "epoch 13; iter: 200; batch classifier loss: 0.611031; batch adversarial loss: 0.625720\n",
      "epoch 14; iter: 0; batch classifier loss: 0.636433; batch adversarial loss: 0.654340\n",
      "epoch 14; iter: 200; batch classifier loss: 0.475580; batch adversarial loss: 0.581064\n",
      "epoch 15; iter: 0; batch classifier loss: 0.500619; batch adversarial loss: 0.576795\n",
      "epoch 15; iter: 200; batch classifier loss: 0.371804; batch adversarial loss: 0.699762\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465561; batch adversarial loss: 0.612824\n",
      "epoch 16; iter: 200; batch classifier loss: 0.376135; batch adversarial loss: 0.587048\n",
      "epoch 17; iter: 0; batch classifier loss: 0.375212; batch adversarial loss: 0.656511\n",
      "epoch 17; iter: 200; batch classifier loss: 0.319455; batch adversarial loss: 0.630538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.390315; batch adversarial loss: 0.602715\n",
      "epoch 18; iter: 200; batch classifier loss: 0.259876; batch adversarial loss: 0.706668\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338602; batch adversarial loss: 0.571035\n",
      "epoch 19; iter: 200; batch classifier loss: 0.362230; batch adversarial loss: 0.578930\n",
      "epoch 20; iter: 0; batch classifier loss: 0.404592; batch adversarial loss: 0.597013\n",
      "epoch 20; iter: 200; batch classifier loss: 0.397559; batch adversarial loss: 0.647464\n",
      "epoch 21; iter: 0; batch classifier loss: 0.327450; batch adversarial loss: 0.639934\n",
      "epoch 21; iter: 200; batch classifier loss: 0.452619; batch adversarial loss: 0.560856\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411695; batch adversarial loss: 0.611720\n",
      "epoch 22; iter: 200; batch classifier loss: 0.316531; batch adversarial loss: 0.638241\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450496; batch adversarial loss: 0.609466\n",
      "epoch 23; iter: 200; batch classifier loss: 0.292513; batch adversarial loss: 0.565461\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483417; batch adversarial loss: 0.583909\n",
      "epoch 24; iter: 200; batch classifier loss: 0.366014; batch adversarial loss: 0.627546\n",
      "epoch 25; iter: 0; batch classifier loss: 0.389470; batch adversarial loss: 0.578681\n",
      "epoch 25; iter: 200; batch classifier loss: 0.324042; batch adversarial loss: 0.610020\n",
      "epoch 26; iter: 0; batch classifier loss: 0.286611; batch adversarial loss: 0.656624\n",
      "epoch 26; iter: 200; batch classifier loss: 0.286960; batch adversarial loss: 0.622298\n",
      "epoch 27; iter: 0; batch classifier loss: 0.341146; batch adversarial loss: 0.607208\n",
      "epoch 27; iter: 200; batch classifier loss: 0.290288; batch adversarial loss: 0.647700\n",
      "epoch 28; iter: 0; batch classifier loss: 0.348357; batch adversarial loss: 0.607790\n",
      "epoch 28; iter: 200; batch classifier loss: 0.441561; batch adversarial loss: 0.584558\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394395; batch adversarial loss: 0.641210\n",
      "epoch 29; iter: 200; batch classifier loss: 0.324907; batch adversarial loss: 0.610231\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324130; batch adversarial loss: 0.538278\n",
      "epoch 30; iter: 200; batch classifier loss: 0.321636; batch adversarial loss: 0.623632\n",
      "epoch 31; iter: 0; batch classifier loss: 0.290087; batch adversarial loss: 0.658441\n",
      "epoch 31; iter: 200; batch classifier loss: 0.408513; batch adversarial loss: 0.626965\n",
      "epoch 32; iter: 0; batch classifier loss: 0.352821; batch adversarial loss: 0.635685\n",
      "epoch 32; iter: 200; batch classifier loss: 0.251639; batch adversarial loss: 0.634505\n",
      "epoch 33; iter: 0; batch classifier loss: 0.312734; batch adversarial loss: 0.561578\n",
      "epoch 33; iter: 200; batch classifier loss: 0.340838; batch adversarial loss: 0.648831\n",
      "epoch 34; iter: 0; batch classifier loss: 0.378495; batch adversarial loss: 0.635760\n",
      "epoch 34; iter: 200; batch classifier loss: 0.407971; batch adversarial loss: 0.592360\n",
      "epoch 35; iter: 0; batch classifier loss: 0.348448; batch adversarial loss: 0.631087\n",
      "epoch 35; iter: 200; batch classifier loss: 0.333362; batch adversarial loss: 0.626789\n",
      "epoch 36; iter: 0; batch classifier loss: 0.348892; batch adversarial loss: 0.667912\n",
      "epoch 36; iter: 200; batch classifier loss: 0.490758; batch adversarial loss: 0.602504\n",
      "epoch 37; iter: 0; batch classifier loss: 0.351266; batch adversarial loss: 0.673812\n",
      "epoch 37; iter: 200; batch classifier loss: 0.318898; batch adversarial loss: 0.580539\n",
      "epoch 38; iter: 0; batch classifier loss: 0.411786; batch adversarial loss: 0.657807\n",
      "epoch 38; iter: 200; batch classifier loss: 0.335527; batch adversarial loss: 0.597977\n",
      "epoch 39; iter: 0; batch classifier loss: 0.356488; batch adversarial loss: 0.615826\n",
      "epoch 39; iter: 200; batch classifier loss: 0.354675; batch adversarial loss: 0.599254\n",
      "epoch 40; iter: 0; batch classifier loss: 0.415614; batch adversarial loss: 0.622176\n",
      "epoch 40; iter: 200; batch classifier loss: 0.474677; batch adversarial loss: 0.626873\n",
      "epoch 41; iter: 0; batch classifier loss: 0.288347; batch adversarial loss: 0.646999\n",
      "epoch 41; iter: 200; batch classifier loss: 0.475956; batch adversarial loss: 0.574415\n",
      "epoch 42; iter: 0; batch classifier loss: 0.369052; batch adversarial loss: 0.656276\n",
      "epoch 42; iter: 200; batch classifier loss: 0.402436; batch adversarial loss: 0.639874\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427061; batch adversarial loss: 0.665244\n",
      "epoch 43; iter: 200; batch classifier loss: 0.232144; batch adversarial loss: 0.604349\n",
      "epoch 44; iter: 0; batch classifier loss: 0.409333; batch adversarial loss: 0.621086\n",
      "epoch 44; iter: 200; batch classifier loss: 0.359434; batch adversarial loss: 0.647636\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383601; batch adversarial loss: 0.624228\n",
      "epoch 45; iter: 200; batch classifier loss: 0.459766; batch adversarial loss: 0.632034\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428526; batch adversarial loss: 0.605233\n",
      "epoch 46; iter: 200; batch classifier loss: 0.431824; batch adversarial loss: 0.604619\n",
      "epoch 47; iter: 0; batch classifier loss: 0.381213; batch adversarial loss: 0.579169\n",
      "epoch 47; iter: 200; batch classifier loss: 0.418011; batch adversarial loss: 0.613298\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421772; batch adversarial loss: 0.604185\n",
      "epoch 48; iter: 200; batch classifier loss: 0.496795; batch adversarial loss: 0.615689\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437421; batch adversarial loss: 0.615295\n",
      "epoch 49; iter: 200; batch classifier loss: 0.481937; batch adversarial loss: 0.610187\n",
      "epoch 0; iter: 0; batch classifier loss: 21.208220; batch adversarial loss: 0.677458\n",
      "epoch 0; iter: 200; batch classifier loss: 10.383593; batch adversarial loss: 0.628368\n",
      "epoch 1; iter: 0; batch classifier loss: 14.495720; batch adversarial loss: 0.654366\n",
      "epoch 1; iter: 200; batch classifier loss: 21.426983; batch adversarial loss: 0.641785\n",
      "epoch 2; iter: 0; batch classifier loss: 2.524067; batch adversarial loss: 0.626101\n",
      "epoch 2; iter: 200; batch classifier loss: 7.664784; batch adversarial loss: 0.624655\n",
      "epoch 3; iter: 0; batch classifier loss: 5.255830; batch adversarial loss: 0.618416\n",
      "epoch 3; iter: 200; batch classifier loss: 19.153582; batch adversarial loss: 0.644654\n",
      "epoch 4; iter: 0; batch classifier loss: 6.340170; batch adversarial loss: 0.618366\n",
      "epoch 4; iter: 200; batch classifier loss: 1.907194; batch adversarial loss: 0.582951\n",
      "epoch 5; iter: 0; batch classifier loss: 2.983782; batch adversarial loss: 0.557716\n",
      "epoch 5; iter: 200; batch classifier loss: 1.017112; batch adversarial loss: 0.663171\n",
      "epoch 6; iter: 0; batch classifier loss: 1.403491; batch adversarial loss: 0.574267\n",
      "epoch 6; iter: 200; batch classifier loss: 1.195764; batch adversarial loss: 0.613131\n",
      "epoch 7; iter: 0; batch classifier loss: 0.896869; batch adversarial loss: 0.665999\n",
      "epoch 7; iter: 200; batch classifier loss: 0.579566; batch adversarial loss: 0.621143\n",
      "epoch 8; iter: 0; batch classifier loss: 0.965604; batch adversarial loss: 0.596325\n",
      "epoch 8; iter: 200; batch classifier loss: 0.585436; batch adversarial loss: 0.534392\n",
      "epoch 9; iter: 0; batch classifier loss: 0.696232; batch adversarial loss: 0.626187\n",
      "epoch 9; iter: 200; batch classifier loss: 0.497336; batch adversarial loss: 0.607321\n",
      "epoch 10; iter: 0; batch classifier loss: 0.921223; batch adversarial loss: 0.576413\n",
      "epoch 10; iter: 200; batch classifier loss: 0.410147; batch adversarial loss: 0.630304\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607591; batch adversarial loss: 0.581252\n",
      "epoch 11; iter: 200; batch classifier loss: 0.887785; batch adversarial loss: 0.552922\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348288; batch adversarial loss: 0.639447\n",
      "epoch 12; iter: 200; batch classifier loss: 0.477578; batch adversarial loss: 0.614046\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439766; batch adversarial loss: 0.635105\n",
      "epoch 13; iter: 200; batch classifier loss: 0.362719; batch adversarial loss: 0.545167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.365497; batch adversarial loss: 0.656570\n",
      "epoch 14; iter: 200; batch classifier loss: 0.556984; batch adversarial loss: 0.576943\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379798; batch adversarial loss: 0.651123\n",
      "epoch 15; iter: 200; batch classifier loss: 0.323727; batch adversarial loss: 0.628574\n",
      "epoch 16; iter: 0; batch classifier loss: 0.388514; batch adversarial loss: 0.600934\n",
      "epoch 16; iter: 200; batch classifier loss: 0.408166; batch adversarial loss: 0.644521\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473155; batch adversarial loss: 0.616847\n",
      "epoch 17; iter: 200; batch classifier loss: 0.321964; batch adversarial loss: 0.625815\n",
      "epoch 18; iter: 0; batch classifier loss: 0.300241; batch adversarial loss: 0.615285\n",
      "epoch 18; iter: 200; batch classifier loss: 0.257015; batch adversarial loss: 0.610566\n",
      "epoch 19; iter: 0; batch classifier loss: 0.359265; batch adversarial loss: 0.577767\n",
      "epoch 19; iter: 200; batch classifier loss: 0.436448; batch adversarial loss: 0.586992\n",
      "epoch 20; iter: 0; batch classifier loss: 0.392262; batch adversarial loss: 0.559667\n",
      "epoch 20; iter: 200; batch classifier loss: 0.395772; batch adversarial loss: 0.611821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.401977; batch adversarial loss: 0.687300\n",
      "epoch 21; iter: 200; batch classifier loss: 0.361429; batch adversarial loss: 0.675034\n",
      "epoch 22; iter: 0; batch classifier loss: 0.310803; batch adversarial loss: 0.624967\n",
      "epoch 22; iter: 200; batch classifier loss: 0.396989; batch adversarial loss: 0.616367\n",
      "epoch 23; iter: 0; batch classifier loss: 0.341352; batch adversarial loss: 0.587661\n",
      "epoch 23; iter: 200; batch classifier loss: 0.365754; batch adversarial loss: 0.618940\n",
      "epoch 24; iter: 0; batch classifier loss: 0.350173; batch adversarial loss: 0.668983\n",
      "epoch 24; iter: 200; batch classifier loss: 0.409617; batch adversarial loss: 0.612958\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474567; batch adversarial loss: 0.639669\n",
      "epoch 25; iter: 200; batch classifier loss: 0.376750; batch adversarial loss: 0.671930\n",
      "epoch 26; iter: 0; batch classifier loss: 0.391562; batch adversarial loss: 0.617160\n",
      "epoch 26; iter: 200; batch classifier loss: 0.245567; batch adversarial loss: 0.609877\n",
      "epoch 27; iter: 0; batch classifier loss: 0.327497; batch adversarial loss: 0.583616\n",
      "epoch 27; iter: 200; batch classifier loss: 0.327971; batch adversarial loss: 0.620317\n",
      "epoch 28; iter: 0; batch classifier loss: 0.378336; batch adversarial loss: 0.635689\n",
      "epoch 28; iter: 200; batch classifier loss: 0.272932; batch adversarial loss: 0.636197\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398687; batch adversarial loss: 0.618565\n",
      "epoch 29; iter: 200; batch classifier loss: 0.397372; batch adversarial loss: 0.653654\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329104; batch adversarial loss: 0.587526\n",
      "epoch 30; iter: 200; batch classifier loss: 0.377539; batch adversarial loss: 0.648006\n",
      "epoch 31; iter: 0; batch classifier loss: 0.364567; batch adversarial loss: 0.643261\n",
      "epoch 31; iter: 200; batch classifier loss: 0.392918; batch adversarial loss: 0.676043\n",
      "epoch 32; iter: 0; batch classifier loss: 0.392843; batch adversarial loss: 0.596603\n",
      "epoch 32; iter: 200; batch classifier loss: 0.359207; batch adversarial loss: 0.600791\n",
      "epoch 33; iter: 0; batch classifier loss: 0.376651; batch adversarial loss: 0.632573\n",
      "epoch 33; iter: 200; batch classifier loss: 0.284263; batch adversarial loss: 0.641948\n",
      "epoch 34; iter: 0; batch classifier loss: 0.252871; batch adversarial loss: 0.608443\n",
      "epoch 34; iter: 200; batch classifier loss: 0.419218; batch adversarial loss: 0.568948\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419705; batch adversarial loss: 0.579596\n",
      "epoch 35; iter: 200; batch classifier loss: 0.316409; batch adversarial loss: 0.635910\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439888; batch adversarial loss: 0.657266\n",
      "epoch 36; iter: 200; batch classifier loss: 0.368525; batch adversarial loss: 0.641336\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417661; batch adversarial loss: 0.592405\n",
      "epoch 37; iter: 200; batch classifier loss: 0.387638; batch adversarial loss: 0.594109\n",
      "epoch 38; iter: 0; batch classifier loss: 0.470173; batch adversarial loss: 0.613050\n",
      "epoch 38; iter: 200; batch classifier loss: 0.377272; batch adversarial loss: 0.640384\n",
      "epoch 39; iter: 0; batch classifier loss: 0.358683; batch adversarial loss: 0.530937\n",
      "epoch 39; iter: 200; batch classifier loss: 0.379320; batch adversarial loss: 0.618179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.387278; batch adversarial loss: 0.631321\n",
      "epoch 40; iter: 200; batch classifier loss: 0.395615; batch adversarial loss: 0.600602\n",
      "epoch 41; iter: 0; batch classifier loss: 0.312385; batch adversarial loss: 0.633944\n",
      "epoch 41; iter: 200; batch classifier loss: 0.294080; batch adversarial loss: 0.644930\n",
      "epoch 42; iter: 0; batch classifier loss: 0.302665; batch adversarial loss: 0.662391\n",
      "epoch 42; iter: 200; batch classifier loss: 0.280553; batch adversarial loss: 0.643530\n",
      "epoch 43; iter: 0; batch classifier loss: 0.355603; batch adversarial loss: 0.613997\n",
      "epoch 43; iter: 200; batch classifier loss: 0.293330; batch adversarial loss: 0.581860\n",
      "epoch 44; iter: 0; batch classifier loss: 0.461443; batch adversarial loss: 0.620730\n",
      "epoch 44; iter: 200; batch classifier loss: 0.350740; batch adversarial loss: 0.655834\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397743; batch adversarial loss: 0.687869\n",
      "epoch 45; iter: 200; batch classifier loss: 0.434915; batch adversarial loss: 0.658139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.361741; batch adversarial loss: 0.668915\n",
      "epoch 46; iter: 200; batch classifier loss: 0.323857; batch adversarial loss: 0.627006\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455713; batch adversarial loss: 0.626578\n",
      "epoch 47; iter: 200; batch classifier loss: 0.332681; batch adversarial loss: 0.562494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.446352; batch adversarial loss: 0.639437\n",
      "epoch 48; iter: 200; batch classifier loss: 0.367384; batch adversarial loss: 0.636595\n",
      "epoch 49; iter: 0; batch classifier loss: 0.534774; batch adversarial loss: 0.619872\n",
      "epoch 49; iter: 200; batch classifier loss: 0.439597; batch adversarial loss: 0.597578\n",
      "epoch 0; iter: 0; batch classifier loss: 6.098330; batch adversarial loss: 0.643398\n",
      "epoch 0; iter: 200; batch classifier loss: 5.292901; batch adversarial loss: 0.668181\n",
      "epoch 1; iter: 0; batch classifier loss: 4.096419; batch adversarial loss: 0.632887\n",
      "epoch 1; iter: 200; batch classifier loss: 4.597775; batch adversarial loss: 0.590273\n",
      "epoch 2; iter: 0; batch classifier loss: 3.623177; batch adversarial loss: 0.621185\n",
      "epoch 2; iter: 200; batch classifier loss: 7.748160; batch adversarial loss: 0.648620\n",
      "epoch 3; iter: 0; batch classifier loss: 2.597901; batch adversarial loss: 0.636632\n",
      "epoch 3; iter: 200; batch classifier loss: 11.165473; batch adversarial loss: 0.612112\n",
      "epoch 4; iter: 0; batch classifier loss: 3.616061; batch adversarial loss: 0.635396\n",
      "epoch 4; iter: 200; batch classifier loss: 1.818674; batch adversarial loss: 0.592067\n",
      "epoch 5; iter: 0; batch classifier loss: 2.701270; batch adversarial loss: 0.622349\n",
      "epoch 5; iter: 200; batch classifier loss: 2.411091; batch adversarial loss: 0.639147\n",
      "epoch 6; iter: 0; batch classifier loss: 1.771454; batch adversarial loss: 0.649099\n",
      "epoch 6; iter: 200; batch classifier loss: 0.497567; batch adversarial loss: 0.561296\n",
      "epoch 7; iter: 0; batch classifier loss: 0.724602; batch adversarial loss: 0.688997\n",
      "epoch 7; iter: 200; batch classifier loss: 0.902304; batch adversarial loss: 0.637275\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525896; batch adversarial loss: 0.656322\n",
      "epoch 8; iter: 200; batch classifier loss: 0.420437; batch adversarial loss: 0.607852\n",
      "epoch 9; iter: 0; batch classifier loss: 0.549054; batch adversarial loss: 0.571975\n",
      "epoch 9; iter: 200; batch classifier loss: 0.470437; batch adversarial loss: 0.638426\n",
      "epoch 10; iter: 0; batch classifier loss: 0.476908; batch adversarial loss: 0.656503\n",
      "epoch 10; iter: 200; batch classifier loss: 0.404163; batch adversarial loss: 0.641636\n",
      "epoch 11; iter: 0; batch classifier loss: 0.510730; batch adversarial loss: 0.559993\n",
      "epoch 11; iter: 200; batch classifier loss: 0.322892; batch adversarial loss: 0.645596\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385398; batch adversarial loss: 0.687281\n",
      "epoch 12; iter: 200; batch classifier loss: 0.424406; batch adversarial loss: 0.586084\n",
      "epoch 13; iter: 0; batch classifier loss: 0.327991; batch adversarial loss: 0.614397\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353708; batch adversarial loss: 0.592664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.379458; batch adversarial loss: 0.592983\n",
      "epoch 14; iter: 200; batch classifier loss: 0.372893; batch adversarial loss: 0.600917\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580512; batch adversarial loss: 0.640720\n",
      "epoch 15; iter: 200; batch classifier loss: 0.397700; batch adversarial loss: 0.646230\n",
      "epoch 16; iter: 0; batch classifier loss: 0.309156; batch adversarial loss: 0.643851\n",
      "epoch 16; iter: 200; batch classifier loss: 0.344270; batch adversarial loss: 0.639244\n",
      "epoch 17; iter: 0; batch classifier loss: 0.693349; batch adversarial loss: 0.586038\n",
      "epoch 17; iter: 200; batch classifier loss: 0.376253; batch adversarial loss: 0.600850\n",
      "epoch 18; iter: 0; batch classifier loss: 0.308959; batch adversarial loss: 0.608770\n",
      "epoch 18; iter: 200; batch classifier loss: 0.287545; batch adversarial loss: 0.590455\n",
      "epoch 19; iter: 0; batch classifier loss: 0.231665; batch adversarial loss: 0.621209\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387681; batch adversarial loss: 0.640469\n",
      "epoch 20; iter: 0; batch classifier loss: 0.210145; batch adversarial loss: 0.637219\n",
      "epoch 20; iter: 200; batch classifier loss: 0.323813; batch adversarial loss: 0.663142\n",
      "epoch 21; iter: 0; batch classifier loss: 0.338152; batch adversarial loss: 0.600244\n",
      "epoch 21; iter: 200; batch classifier loss: 0.384367; batch adversarial loss: 0.594409\n",
      "epoch 22; iter: 0; batch classifier loss: 0.358316; batch adversarial loss: 0.614444\n",
      "epoch 22; iter: 200; batch classifier loss: 0.428055; batch adversarial loss: 0.571956\n",
      "epoch 23; iter: 0; batch classifier loss: 0.303000; batch adversarial loss: 0.576183\n",
      "epoch 23; iter: 200; batch classifier loss: 0.269457; batch adversarial loss: 0.643729\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452545; batch adversarial loss: 0.671620\n",
      "epoch 24; iter: 200; batch classifier loss: 0.345830; batch adversarial loss: 0.582281\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424935; batch adversarial loss: 0.642557\n",
      "epoch 25; iter: 200; batch classifier loss: 0.272310; batch adversarial loss: 0.608153\n",
      "epoch 26; iter: 0; batch classifier loss: 0.273858; batch adversarial loss: 0.665007\n",
      "epoch 26; iter: 200; batch classifier loss: 0.420719; batch adversarial loss: 0.622909\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383030; batch adversarial loss: 0.614600\n",
      "epoch 27; iter: 200; batch classifier loss: 0.325826; batch adversarial loss: 0.613023\n",
      "epoch 28; iter: 0; batch classifier loss: 0.336901; batch adversarial loss: 0.630432\n",
      "epoch 28; iter: 200; batch classifier loss: 0.375743; batch adversarial loss: 0.609787\n",
      "epoch 29; iter: 0; batch classifier loss: 0.400873; batch adversarial loss: 0.567288\n",
      "epoch 29; iter: 200; batch classifier loss: 0.364952; batch adversarial loss: 0.620113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.344389; batch adversarial loss: 0.608062\n",
      "epoch 30; iter: 200; batch classifier loss: 0.446997; batch adversarial loss: 0.644020\n",
      "epoch 31; iter: 0; batch classifier loss: 0.361837; batch adversarial loss: 0.662689\n",
      "epoch 31; iter: 200; batch classifier loss: 0.343628; batch adversarial loss: 0.643452\n",
      "epoch 32; iter: 0; batch classifier loss: 0.290363; batch adversarial loss: 0.641339\n",
      "epoch 32; iter: 200; batch classifier loss: 0.379945; batch adversarial loss: 0.554203\n",
      "epoch 33; iter: 0; batch classifier loss: 0.322930; batch adversarial loss: 0.623891\n",
      "epoch 33; iter: 200; batch classifier loss: 0.303392; batch adversarial loss: 0.640281\n",
      "epoch 34; iter: 0; batch classifier loss: 0.340885; batch adversarial loss: 0.600918\n",
      "epoch 34; iter: 200; batch classifier loss: 0.366687; batch adversarial loss: 0.594400\n",
      "epoch 35; iter: 0; batch classifier loss: 0.354778; batch adversarial loss: 0.589847\n",
      "epoch 35; iter: 200; batch classifier loss: 0.348186; batch adversarial loss: 0.590582\n",
      "epoch 36; iter: 0; batch classifier loss: 0.351634; batch adversarial loss: 0.672916\n",
      "epoch 36; iter: 200; batch classifier loss: 0.302250; batch adversarial loss: 0.585756\n",
      "epoch 37; iter: 0; batch classifier loss: 0.350325; batch adversarial loss: 0.597324\n",
      "epoch 37; iter: 200; batch classifier loss: 0.706065; batch adversarial loss: 0.603240\n",
      "epoch 38; iter: 0; batch classifier loss: 0.355083; batch adversarial loss: 0.656181\n",
      "epoch 38; iter: 200; batch classifier loss: 0.398272; batch adversarial loss: 0.584451\n",
      "epoch 39; iter: 0; batch classifier loss: 0.400659; batch adversarial loss: 0.614302\n",
      "epoch 39; iter: 200; batch classifier loss: 0.335351; batch adversarial loss: 0.608928\n",
      "epoch 40; iter: 0; batch classifier loss: 0.302480; batch adversarial loss: 0.614153\n",
      "epoch 40; iter: 200; batch classifier loss: 0.508064; batch adversarial loss: 0.579301\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397152; batch adversarial loss: 0.643434\n",
      "epoch 41; iter: 200; batch classifier loss: 0.442623; batch adversarial loss: 0.626889\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449742; batch adversarial loss: 0.622581\n",
      "epoch 42; iter: 200; batch classifier loss: 0.319100; batch adversarial loss: 0.644580\n",
      "epoch 43; iter: 0; batch classifier loss: 0.395718; batch adversarial loss: 0.612802\n",
      "epoch 43; iter: 200; batch classifier loss: 0.324440; batch adversarial loss: 0.657550\n",
      "epoch 44; iter: 0; batch classifier loss: 0.530546; batch adversarial loss: 0.605174\n",
      "epoch 44; iter: 200; batch classifier loss: 0.292648; batch adversarial loss: 0.700440\n",
      "epoch 45; iter: 0; batch classifier loss: 0.365829; batch adversarial loss: 0.699463\n",
      "epoch 45; iter: 200; batch classifier loss: 0.418221; batch adversarial loss: 0.601500\n",
      "epoch 46; iter: 0; batch classifier loss: 0.656194; batch adversarial loss: 0.616758\n",
      "epoch 46; iter: 200; batch classifier loss: 0.469867; batch adversarial loss: 0.677037\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520795; batch adversarial loss: 0.610913\n",
      "epoch 47; iter: 200; batch classifier loss: 0.301312; batch adversarial loss: 0.605495\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452185; batch adversarial loss: 0.621851\n",
      "epoch 48; iter: 200; batch classifier loss: 0.476110; batch adversarial loss: 0.680725\n",
      "epoch 49; iter: 0; batch classifier loss: 0.381316; batch adversarial loss: 0.579711\n",
      "epoch 49; iter: 200; batch classifier loss: 0.475537; batch adversarial loss: 0.591618\n",
      "epoch 0; iter: 0; batch classifier loss: 9.682523; batch adversarial loss: 0.701476\n",
      "epoch 0; iter: 200; batch classifier loss: 9.052194; batch adversarial loss: 0.659624\n",
      "epoch 1; iter: 0; batch classifier loss: 9.364428; batch adversarial loss: 0.642405\n",
      "epoch 1; iter: 200; batch classifier loss: 7.263149; batch adversarial loss: 0.633577\n",
      "epoch 2; iter: 0; batch classifier loss: 4.684462; batch adversarial loss: 0.631684\n",
      "epoch 2; iter: 200; batch classifier loss: 5.058325; batch adversarial loss: 0.634869\n",
      "epoch 3; iter: 0; batch classifier loss: 4.049905; batch adversarial loss: 0.608466\n",
      "epoch 3; iter: 200; batch classifier loss: 5.621856; batch adversarial loss: 0.617217\n",
      "epoch 4; iter: 0; batch classifier loss: 3.203594; batch adversarial loss: 0.707574\n",
      "epoch 4; iter: 200; batch classifier loss: 4.912916; batch adversarial loss: 0.667734\n",
      "epoch 5; iter: 0; batch classifier loss: 3.062289; batch adversarial loss: 0.658030\n",
      "epoch 5; iter: 200; batch classifier loss: 1.518046; batch adversarial loss: 0.632878\n",
      "epoch 6; iter: 0; batch classifier loss: 2.321508; batch adversarial loss: 0.631640\n",
      "epoch 6; iter: 200; batch classifier loss: 0.944180; batch adversarial loss: 0.622338\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587269; batch adversarial loss: 0.589334\n",
      "epoch 7; iter: 200; batch classifier loss: 0.551211; batch adversarial loss: 0.645420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.377443; batch adversarial loss: 0.637189\n",
      "epoch 8; iter: 200; batch classifier loss: 0.488915; batch adversarial loss: 0.652099\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526767; batch adversarial loss: 0.660461\n",
      "epoch 9; iter: 200; batch classifier loss: 0.440301; batch adversarial loss: 0.603450\n",
      "epoch 10; iter: 0; batch classifier loss: 0.692671; batch adversarial loss: 0.556097\n",
      "epoch 10; iter: 200; batch classifier loss: 0.398976; batch adversarial loss: 0.576013\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596457; batch adversarial loss: 0.653845\n",
      "epoch 11; iter: 200; batch classifier loss: 0.410338; batch adversarial loss: 0.646246\n",
      "epoch 12; iter: 0; batch classifier loss: 0.393123; batch adversarial loss: 0.630751\n",
      "epoch 12; iter: 200; batch classifier loss: 0.339920; batch adversarial loss: 0.632766\n",
      "epoch 13; iter: 0; batch classifier loss: 0.440237; batch adversarial loss: 0.608248\n",
      "epoch 13; iter: 200; batch classifier loss: 0.474683; batch adversarial loss: 0.617952\n",
      "epoch 14; iter: 0; batch classifier loss: 0.421067; batch adversarial loss: 0.598131\n",
      "epoch 14; iter: 200; batch classifier loss: 0.491335; batch adversarial loss: 0.581506\n",
      "epoch 15; iter: 0; batch classifier loss: 0.361525; batch adversarial loss: 0.624810\n",
      "epoch 15; iter: 200; batch classifier loss: 0.489921; batch adversarial loss: 0.595772\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376527; batch adversarial loss: 0.673202\n",
      "epoch 16; iter: 200; batch classifier loss: 0.351870; batch adversarial loss: 0.643565\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391840; batch adversarial loss: 0.566717\n",
      "epoch 17; iter: 200; batch classifier loss: 0.287613; batch adversarial loss: 0.625167\n",
      "epoch 18; iter: 0; batch classifier loss: 0.351963; batch adversarial loss: 0.686145\n",
      "epoch 18; iter: 200; batch classifier loss: 0.397113; batch adversarial loss: 0.622327\n",
      "epoch 19; iter: 0; batch classifier loss: 0.392960; batch adversarial loss: 0.644007\n",
      "epoch 19; iter: 200; batch classifier loss: 0.429658; batch adversarial loss: 0.538245\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378079; batch adversarial loss: 0.636318\n",
      "epoch 20; iter: 200; batch classifier loss: 0.376693; batch adversarial loss: 0.605018\n",
      "epoch 21; iter: 0; batch classifier loss: 0.350414; batch adversarial loss: 0.601898\n",
      "epoch 21; iter: 200; batch classifier loss: 0.246782; batch adversarial loss: 0.617508\n",
      "epoch 22; iter: 0; batch classifier loss: 0.364593; batch adversarial loss: 0.599286\n",
      "epoch 22; iter: 200; batch classifier loss: 0.451379; batch adversarial loss: 0.587800\n",
      "epoch 23; iter: 0; batch classifier loss: 0.419175; batch adversarial loss: 0.574628\n",
      "epoch 23; iter: 200; batch classifier loss: 0.334949; batch adversarial loss: 0.629097\n",
      "epoch 24; iter: 0; batch classifier loss: 0.281274; batch adversarial loss: 0.600641\n",
      "epoch 24; iter: 200; batch classifier loss: 0.376470; batch adversarial loss: 0.628069\n",
      "epoch 25; iter: 0; batch classifier loss: 0.304928; batch adversarial loss: 0.645513\n",
      "epoch 25; iter: 200; batch classifier loss: 0.396971; batch adversarial loss: 0.616969\n",
      "epoch 26; iter: 0; batch classifier loss: 0.360550; batch adversarial loss: 0.651120\n",
      "epoch 26; iter: 200; batch classifier loss: 0.336417; batch adversarial loss: 0.636314\n",
      "epoch 27; iter: 0; batch classifier loss: 0.353712; batch adversarial loss: 0.561336\n",
      "epoch 27; iter: 200; batch classifier loss: 0.303386; batch adversarial loss: 0.641396\n",
      "epoch 28; iter: 0; batch classifier loss: 0.406858; batch adversarial loss: 0.649504\n",
      "epoch 28; iter: 200; batch classifier loss: 0.418115; batch adversarial loss: 0.712324\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315752; batch adversarial loss: 0.634533\n",
      "epoch 29; iter: 200; batch classifier loss: 0.413324; batch adversarial loss: 0.691248\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488806; batch adversarial loss: 0.618945\n",
      "epoch 30; iter: 200; batch classifier loss: 0.450794; batch adversarial loss: 0.649009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.318780; batch adversarial loss: 0.632497\n",
      "epoch 31; iter: 200; batch classifier loss: 0.390051; batch adversarial loss: 0.594859\n",
      "epoch 32; iter: 0; batch classifier loss: 0.312729; batch adversarial loss: 0.660270\n",
      "epoch 32; iter: 200; batch classifier loss: 0.376091; batch adversarial loss: 0.618794\n",
      "epoch 33; iter: 0; batch classifier loss: 0.314478; batch adversarial loss: 0.627846\n",
      "epoch 33; iter: 200; batch classifier loss: 0.389946; batch adversarial loss: 0.629477\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310619; batch adversarial loss: 0.617915\n",
      "epoch 34; iter: 200; batch classifier loss: 0.313192; batch adversarial loss: 0.659674\n",
      "epoch 35; iter: 0; batch classifier loss: 0.448446; batch adversarial loss: 0.680678\n",
      "epoch 35; iter: 200; batch classifier loss: 0.351424; batch adversarial loss: 0.611199\n",
      "epoch 36; iter: 0; batch classifier loss: 0.317866; batch adversarial loss: 0.559098\n",
      "epoch 36; iter: 200; batch classifier loss: 0.301813; batch adversarial loss: 0.642496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.721340; batch adversarial loss: 0.574821\n",
      "epoch 37; iter: 200; batch classifier loss: 0.400836; batch adversarial loss: 0.626212\n",
      "epoch 38; iter: 0; batch classifier loss: 0.371820; batch adversarial loss: 0.647043\n",
      "epoch 38; iter: 200; batch classifier loss: 0.271750; batch adversarial loss: 0.583425\n",
      "epoch 39; iter: 0; batch classifier loss: 0.459962; batch adversarial loss: 0.597877\n",
      "epoch 39; iter: 200; batch classifier loss: 0.284066; batch adversarial loss: 0.666685\n",
      "epoch 40; iter: 0; batch classifier loss: 0.520245; batch adversarial loss: 0.672381\n",
      "epoch 40; iter: 200; batch classifier loss: 0.545038; batch adversarial loss: 0.677573\n",
      "epoch 41; iter: 0; batch classifier loss: 0.354513; batch adversarial loss: 0.558570\n",
      "epoch 41; iter: 200; batch classifier loss: 0.344198; batch adversarial loss: 0.658823\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427578; batch adversarial loss: 0.661961\n",
      "epoch 42; iter: 200; batch classifier loss: 0.589486; batch adversarial loss: 0.609357\n",
      "epoch 43; iter: 0; batch classifier loss: 0.271125; batch adversarial loss: 0.562850\n",
      "epoch 43; iter: 200; batch classifier loss: 0.390279; batch adversarial loss: 0.661949\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382170; batch adversarial loss: 0.639298\n",
      "epoch 44; iter: 200; batch classifier loss: 0.429659; batch adversarial loss: 0.645330\n",
      "epoch 45; iter: 0; batch classifier loss: 0.357984; batch adversarial loss: 0.605884\n",
      "epoch 45; iter: 200; batch classifier loss: 0.397498; batch adversarial loss: 0.615868\n",
      "epoch 46; iter: 0; batch classifier loss: 0.336193; batch adversarial loss: 0.713612\n",
      "epoch 46; iter: 200; batch classifier loss: 0.482097; batch adversarial loss: 0.660674\n",
      "epoch 47; iter: 0; batch classifier loss: 0.450384; batch adversarial loss: 0.607747\n",
      "epoch 47; iter: 200; batch classifier loss: 0.528224; batch adversarial loss: 0.647913\n",
      "epoch 48; iter: 0; batch classifier loss: 0.314328; batch adversarial loss: 0.630457\n",
      "epoch 48; iter: 200; batch classifier loss: 0.436814; batch adversarial loss: 0.591720\n",
      "epoch 49; iter: 0; batch classifier loss: 0.463460; batch adversarial loss: 0.659286\n",
      "epoch 49; iter: 200; batch classifier loss: 0.364418; batch adversarial loss: 0.640051\n",
      "epoch 0; iter: 0; batch classifier loss: 186.454102; batch adversarial loss: 0.665345\n",
      "epoch 0; iter: 200; batch classifier loss: 31.836582; batch adversarial loss: 0.705738\n",
      "epoch 1; iter: 0; batch classifier loss: 8.683566; batch adversarial loss: 0.653541\n",
      "epoch 1; iter: 200; batch classifier loss: 3.541795; batch adversarial loss: 0.645837\n",
      "epoch 2; iter: 0; batch classifier loss: 18.361458; batch adversarial loss: 0.668877\n",
      "epoch 2; iter: 200; batch classifier loss: 4.347383; batch adversarial loss: 0.647116\n",
      "epoch 3; iter: 0; batch classifier loss: 2.145895; batch adversarial loss: 0.657400\n",
      "epoch 3; iter: 200; batch classifier loss: 1.036180; batch adversarial loss: 0.595213\n",
      "epoch 4; iter: 0; batch classifier loss: 3.880197; batch adversarial loss: 0.599212\n",
      "epoch 4; iter: 200; batch classifier loss: 1.112158; batch adversarial loss: 0.635534\n",
      "epoch 5; iter: 0; batch classifier loss: 1.976846; batch adversarial loss: 0.591260\n",
      "epoch 5; iter: 200; batch classifier loss: 1.946807; batch adversarial loss: 0.598253\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569265; batch adversarial loss: 0.598734\n",
      "epoch 6; iter: 200; batch classifier loss: 1.203677; batch adversarial loss: 0.635245\n",
      "epoch 7; iter: 0; batch classifier loss: 0.837203; batch adversarial loss: 0.624736\n",
      "epoch 7; iter: 200; batch classifier loss: 1.669980; batch adversarial loss: 0.619768\n",
      "epoch 8; iter: 0; batch classifier loss: 0.576439; batch adversarial loss: 0.632432\n",
      "epoch 8; iter: 200; batch classifier loss: 1.251548; batch adversarial loss: 0.598039\n",
      "epoch 9; iter: 0; batch classifier loss: 0.768501; batch adversarial loss: 0.600507\n",
      "epoch 9; iter: 200; batch classifier loss: 0.462805; batch adversarial loss: 0.630289\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533350; batch adversarial loss: 0.568998\n",
      "epoch 10; iter: 200; batch classifier loss: 0.634813; batch adversarial loss: 0.587825\n",
      "epoch 11; iter: 0; batch classifier loss: 0.565477; batch adversarial loss: 0.625541\n",
      "epoch 11; iter: 200; batch classifier loss: 0.547537; batch adversarial loss: 0.653613\n",
      "epoch 12; iter: 0; batch classifier loss: 0.522613; batch adversarial loss: 0.597132\n",
      "epoch 12; iter: 200; batch classifier loss: 0.403484; batch adversarial loss: 0.691304\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457691; batch adversarial loss: 0.605163\n",
      "epoch 13; iter: 200; batch classifier loss: 0.490789; batch adversarial loss: 0.650371\n",
      "epoch 14; iter: 0; batch classifier loss: 0.399436; batch adversarial loss: 0.602273\n",
      "epoch 14; iter: 200; batch classifier loss: 0.737633; batch adversarial loss: 0.571299\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409249; batch adversarial loss: 0.638614\n",
      "epoch 15; iter: 200; batch classifier loss: 0.408977; batch adversarial loss: 0.613656\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335724; batch adversarial loss: 0.622765\n",
      "epoch 16; iter: 200; batch classifier loss: 0.337289; batch adversarial loss: 0.621758\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398492; batch adversarial loss: 0.649737\n",
      "epoch 17; iter: 200; batch classifier loss: 0.354551; batch adversarial loss: 0.597441\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339581; batch adversarial loss: 0.585278\n",
      "epoch 18; iter: 200; batch classifier loss: 0.337522; batch adversarial loss: 0.598966\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334112; batch adversarial loss: 0.633915\n",
      "epoch 19; iter: 200; batch classifier loss: 0.393459; batch adversarial loss: 0.643552\n",
      "epoch 20; iter: 0; batch classifier loss: 0.388010; batch adversarial loss: 0.557461\n",
      "epoch 20; iter: 200; batch classifier loss: 0.355348; batch adversarial loss: 0.641708\n",
      "epoch 21; iter: 0; batch classifier loss: 0.318090; batch adversarial loss: 0.611707\n",
      "epoch 21; iter: 200; batch classifier loss: 0.443270; batch adversarial loss: 0.612744\n",
      "epoch 22; iter: 0; batch classifier loss: 0.347013; batch adversarial loss: 0.665249\n",
      "epoch 22; iter: 200; batch classifier loss: 0.395034; batch adversarial loss: 0.626432\n",
      "epoch 23; iter: 0; batch classifier loss: 0.373305; batch adversarial loss: 0.613054\n",
      "epoch 23; iter: 200; batch classifier loss: 0.348857; batch adversarial loss: 0.654713\n",
      "epoch 24; iter: 0; batch classifier loss: 0.331681; batch adversarial loss: 0.633138\n",
      "epoch 24; iter: 200; batch classifier loss: 0.365162; batch adversarial loss: 0.653364\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417633; batch adversarial loss: 0.640928\n",
      "epoch 25; iter: 200; batch classifier loss: 0.493541; batch adversarial loss: 0.582346\n",
      "epoch 26; iter: 0; batch classifier loss: 0.416642; batch adversarial loss: 0.608214\n",
      "epoch 26; iter: 200; batch classifier loss: 0.362466; batch adversarial loss: 0.602261\n",
      "epoch 27; iter: 0; batch classifier loss: 0.282685; batch adversarial loss: 0.604820\n",
      "epoch 27; iter: 200; batch classifier loss: 0.341843; batch adversarial loss: 0.644492\n",
      "epoch 28; iter: 0; batch classifier loss: 0.339315; batch adversarial loss: 0.673504\n",
      "epoch 28; iter: 200; batch classifier loss: 0.331983; batch adversarial loss: 0.643998\n",
      "epoch 29; iter: 0; batch classifier loss: 0.265847; batch adversarial loss: 0.606596\n",
      "epoch 29; iter: 200; batch classifier loss: 0.325796; batch adversarial loss: 0.593405\n",
      "epoch 30; iter: 0; batch classifier loss: 0.370905; batch adversarial loss: 0.628337\n",
      "epoch 30; iter: 200; batch classifier loss: 0.303246; batch adversarial loss: 0.653319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.383070; batch adversarial loss: 0.667813\n",
      "epoch 31; iter: 200; batch classifier loss: 0.368945; batch adversarial loss: 0.616288\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320754; batch adversarial loss: 0.646284\n",
      "epoch 32; iter: 200; batch classifier loss: 0.333150; batch adversarial loss: 0.695435\n",
      "epoch 33; iter: 0; batch classifier loss: 0.357266; batch adversarial loss: 0.575270\n",
      "epoch 33; iter: 200; batch classifier loss: 0.315816; batch adversarial loss: 0.635511\n",
      "epoch 34; iter: 0; batch classifier loss: 0.302556; batch adversarial loss: 0.551359\n",
      "epoch 34; iter: 200; batch classifier loss: 0.268801; batch adversarial loss: 0.624636\n",
      "epoch 35; iter: 0; batch classifier loss: 0.346657; batch adversarial loss: 0.646259\n",
      "epoch 35; iter: 200; batch classifier loss: 0.440096; batch adversarial loss: 0.623195\n",
      "epoch 36; iter: 0; batch classifier loss: 0.277734; batch adversarial loss: 0.637799\n",
      "epoch 36; iter: 200; batch classifier loss: 0.276092; batch adversarial loss: 0.637791\n",
      "epoch 37; iter: 0; batch classifier loss: 0.588967; batch adversarial loss: 0.636738\n",
      "epoch 37; iter: 200; batch classifier loss: 0.371331; batch adversarial loss: 0.609678\n",
      "epoch 38; iter: 0; batch classifier loss: 0.550615; batch adversarial loss: 0.642582\n",
      "epoch 38; iter: 200; batch classifier loss: 0.263035; batch adversarial loss: 0.677613\n",
      "epoch 39; iter: 0; batch classifier loss: 0.431431; batch adversarial loss: 0.612814\n",
      "epoch 39; iter: 200; batch classifier loss: 0.348688; batch adversarial loss: 0.679646\n",
      "epoch 40; iter: 0; batch classifier loss: 0.428168; batch adversarial loss: 0.646810\n",
      "epoch 40; iter: 200; batch classifier loss: 0.298079; batch adversarial loss: 0.642146\n",
      "epoch 41; iter: 0; batch classifier loss: 0.359026; batch adversarial loss: 0.632266\n",
      "epoch 41; iter: 200; batch classifier loss: 0.352915; batch adversarial loss: 0.626210\n",
      "epoch 42; iter: 0; batch classifier loss: 0.355445; batch adversarial loss: 0.623748\n",
      "epoch 42; iter: 200; batch classifier loss: 0.346085; batch adversarial loss: 0.718939\n",
      "epoch 43; iter: 0; batch classifier loss: 0.390527; batch adversarial loss: 0.583698\n",
      "epoch 43; iter: 200; batch classifier loss: 0.322375; batch adversarial loss: 0.640854\n",
      "epoch 44; iter: 0; batch classifier loss: 0.379735; batch adversarial loss: 0.647157\n",
      "epoch 44; iter: 200; batch classifier loss: 0.479633; batch adversarial loss: 0.624774\n",
      "epoch 45; iter: 0; batch classifier loss: 0.532387; batch adversarial loss: 0.612856\n",
      "epoch 45; iter: 200; batch classifier loss: 0.340386; batch adversarial loss: 0.622966\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419178; batch adversarial loss: 0.592611\n",
      "epoch 46; iter: 200; batch classifier loss: 0.388510; batch adversarial loss: 0.610786\n",
      "epoch 47; iter: 0; batch classifier loss: 0.358910; batch adversarial loss: 0.579334\n",
      "epoch 47; iter: 200; batch classifier loss: 0.410087; batch adversarial loss: 0.641393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416076; batch adversarial loss: 0.570497\n",
      "epoch 48; iter: 200; batch classifier loss: 0.330324; batch adversarial loss: 0.677757\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366052; batch adversarial loss: 0.643987\n",
      "epoch 49; iter: 200; batch classifier loss: 0.285842; batch adversarial loss: 0.672331\n",
      "epoch 0; iter: 0; batch classifier loss: 46.873646; batch adversarial loss: 0.775790\n",
      "epoch 0; iter: 200; batch classifier loss: 8.370337; batch adversarial loss: 0.740655\n",
      "epoch 1; iter: 0; batch classifier loss: 7.754611; batch adversarial loss: 0.704374\n",
      "epoch 1; iter: 200; batch classifier loss: 1.965402; batch adversarial loss: 0.641272\n",
      "epoch 2; iter: 0; batch classifier loss: 7.588746; batch adversarial loss: 0.630992\n",
      "epoch 2; iter: 200; batch classifier loss: 1.228097; batch adversarial loss: 0.641253\n",
      "epoch 3; iter: 0; batch classifier loss: 7.635227; batch adversarial loss: 0.648084\n",
      "epoch 3; iter: 200; batch classifier loss: 8.935356; batch adversarial loss: 0.640873\n",
      "epoch 4; iter: 0; batch classifier loss: 2.382093; batch adversarial loss: 0.625583\n",
      "epoch 4; iter: 200; batch classifier loss: 1.789291; batch adversarial loss: 0.618093\n",
      "epoch 5; iter: 0; batch classifier loss: 1.052373; batch adversarial loss: 0.577328\n",
      "epoch 5; iter: 200; batch classifier loss: 1.841266; batch adversarial loss: 0.650489\n",
      "epoch 6; iter: 0; batch classifier loss: 0.872422; batch adversarial loss: 0.558671\n",
      "epoch 6; iter: 200; batch classifier loss: 1.479277; batch adversarial loss: 0.617441\n",
      "epoch 7; iter: 0; batch classifier loss: 1.430517; batch adversarial loss: 0.651636\n",
      "epoch 7; iter: 200; batch classifier loss: 0.922835; batch adversarial loss: 0.607586\n",
      "epoch 8; iter: 0; batch classifier loss: 0.668076; batch adversarial loss: 0.618245\n",
      "epoch 8; iter: 200; batch classifier loss: 0.750982; batch adversarial loss: 0.622021\n",
      "epoch 9; iter: 0; batch classifier loss: 0.615233; batch adversarial loss: 0.612660\n",
      "epoch 9; iter: 200; batch classifier loss: 0.379353; batch adversarial loss: 0.630650\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413478; batch adversarial loss: 0.671594\n",
      "epoch 10; iter: 200; batch classifier loss: 0.641219; batch adversarial loss: 0.629045\n",
      "epoch 11; iter: 0; batch classifier loss: 0.480785; batch adversarial loss: 0.678877\n",
      "epoch 11; iter: 200; batch classifier loss: 0.492211; batch adversarial loss: 0.623922\n",
      "epoch 12; iter: 0; batch classifier loss: 0.553513; batch adversarial loss: 0.695941\n",
      "epoch 12; iter: 200; batch classifier loss: 0.454123; batch adversarial loss: 0.637667\n",
      "epoch 13; iter: 0; batch classifier loss: 0.492021; batch adversarial loss: 0.646007\n",
      "epoch 13; iter: 200; batch classifier loss: 0.372457; batch adversarial loss: 0.625244\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556666; batch adversarial loss: 0.693754\n",
      "epoch 14; iter: 200; batch classifier loss: 0.413974; batch adversarial loss: 0.624625\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428838; batch adversarial loss: 0.631474\n",
      "epoch 15; iter: 200; batch classifier loss: 0.443276; batch adversarial loss: 0.636703\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459503; batch adversarial loss: 0.659073\n",
      "epoch 16; iter: 200; batch classifier loss: 0.351121; batch adversarial loss: 0.601337\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374264; batch adversarial loss: 0.610894\n",
      "epoch 17; iter: 200; batch classifier loss: 0.409573; batch adversarial loss: 0.637326\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378812; batch adversarial loss: 0.636413\n",
      "epoch 18; iter: 200; batch classifier loss: 0.362213; batch adversarial loss: 0.633705\n",
      "epoch 19; iter: 0; batch classifier loss: 0.373885; batch adversarial loss: 0.636313\n",
      "epoch 19; iter: 200; batch classifier loss: 0.440285; batch adversarial loss: 0.552786\n",
      "epoch 20; iter: 0; batch classifier loss: 0.318680; batch adversarial loss: 0.620521\n",
      "epoch 20; iter: 200; batch classifier loss: 0.372006; batch adversarial loss: 0.616399\n",
      "epoch 21; iter: 0; batch classifier loss: 0.341483; batch adversarial loss: 0.643035\n",
      "epoch 21; iter: 200; batch classifier loss: 0.275247; batch adversarial loss: 0.632042\n",
      "epoch 22; iter: 0; batch classifier loss: 0.327261; batch adversarial loss: 0.588225\n",
      "epoch 22; iter: 200; batch classifier loss: 0.374687; batch adversarial loss: 0.703928\n",
      "epoch 23; iter: 0; batch classifier loss: 0.360172; batch adversarial loss: 0.690742\n",
      "epoch 23; iter: 200; batch classifier loss: 0.342621; batch adversarial loss: 0.627465\n",
      "epoch 24; iter: 0; batch classifier loss: 0.367816; batch adversarial loss: 0.597443\n",
      "epoch 24; iter: 200; batch classifier loss: 0.379297; batch adversarial loss: 0.665587\n",
      "epoch 25; iter: 0; batch classifier loss: 0.388148; batch adversarial loss: 0.613995\n",
      "epoch 25; iter: 200; batch classifier loss: 0.432236; batch adversarial loss: 0.551709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.308887; batch adversarial loss: 0.648721\n",
      "epoch 26; iter: 200; batch classifier loss: 0.372479; batch adversarial loss: 0.594876\n",
      "epoch 27; iter: 0; batch classifier loss: 0.351728; batch adversarial loss: 0.593275\n",
      "epoch 27; iter: 200; batch classifier loss: 0.407494; batch adversarial loss: 0.582699\n",
      "epoch 28; iter: 0; batch classifier loss: 0.350594; batch adversarial loss: 0.628046\n",
      "epoch 28; iter: 200; batch classifier loss: 0.429068; batch adversarial loss: 0.595393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.335635; batch adversarial loss: 0.640153\n",
      "epoch 29; iter: 200; batch classifier loss: 0.334860; batch adversarial loss: 0.606707\n",
      "epoch 30; iter: 0; batch classifier loss: 0.311530; batch adversarial loss: 0.634328\n",
      "epoch 30; iter: 200; batch classifier loss: 0.360716; batch adversarial loss: 0.619186\n",
      "epoch 31; iter: 0; batch classifier loss: 0.424787; batch adversarial loss: 0.597311\n",
      "epoch 31; iter: 200; batch classifier loss: 0.298024; batch adversarial loss: 0.692153\n",
      "epoch 32; iter: 0; batch classifier loss: 0.248051; batch adversarial loss: 0.713306\n",
      "epoch 32; iter: 200; batch classifier loss: 0.319622; batch adversarial loss: 0.653777\n",
      "epoch 33; iter: 0; batch classifier loss: 0.348000; batch adversarial loss: 0.560093\n",
      "epoch 33; iter: 200; batch classifier loss: 0.328046; batch adversarial loss: 0.659241\n",
      "epoch 34; iter: 0; batch classifier loss: 0.370002; batch adversarial loss: 0.604238\n",
      "epoch 34; iter: 200; batch classifier loss: 0.337985; batch adversarial loss: 0.641248\n",
      "epoch 35; iter: 0; batch classifier loss: 0.356451; batch adversarial loss: 0.658841\n",
      "epoch 35; iter: 200; batch classifier loss: 0.392827; batch adversarial loss: 0.614385\n",
      "epoch 36; iter: 0; batch classifier loss: 0.338735; batch adversarial loss: 0.611412\n",
      "epoch 36; iter: 200; batch classifier loss: 0.351378; batch adversarial loss: 0.598556\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387410; batch adversarial loss: 0.649526\n",
      "epoch 37; iter: 200; batch classifier loss: 0.346865; batch adversarial loss: 0.628226\n",
      "epoch 38; iter: 0; batch classifier loss: 0.320995; batch adversarial loss: 0.610953\n",
      "epoch 38; iter: 200; batch classifier loss: 0.391060; batch adversarial loss: 0.617260\n",
      "epoch 39; iter: 0; batch classifier loss: 0.289453; batch adversarial loss: 0.732051\n",
      "epoch 39; iter: 200; batch classifier loss: 0.342433; batch adversarial loss: 0.638531\n",
      "epoch 40; iter: 0; batch classifier loss: 0.672900; batch adversarial loss: 0.639271\n",
      "epoch 40; iter: 200; batch classifier loss: 0.493463; batch adversarial loss: 0.638361\n",
      "epoch 41; iter: 0; batch classifier loss: 0.338851; batch adversarial loss: 0.618511\n",
      "epoch 41; iter: 200; batch classifier loss: 0.516514; batch adversarial loss: 0.596710\n",
      "epoch 42; iter: 0; batch classifier loss: 0.597054; batch adversarial loss: 0.641136\n",
      "epoch 42; iter: 200; batch classifier loss: 0.399013; batch adversarial loss: 0.643911\n",
      "epoch 43; iter: 0; batch classifier loss: 0.458076; batch adversarial loss: 0.615097\n",
      "epoch 43; iter: 200; batch classifier loss: 0.358530; batch adversarial loss: 0.642464\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393871; batch adversarial loss: 0.628466\n",
      "epoch 44; iter: 200; batch classifier loss: 0.363293; batch adversarial loss: 0.586579\n",
      "epoch 45; iter: 0; batch classifier loss: 0.384264; batch adversarial loss: 0.624159\n",
      "epoch 45; iter: 200; batch classifier loss: 0.315301; batch adversarial loss: 0.674418\n",
      "epoch 46; iter: 0; batch classifier loss: 0.508725; batch adversarial loss: 0.641833\n",
      "epoch 46; iter: 200; batch classifier loss: 0.425712; batch adversarial loss: 0.607818\n",
      "epoch 47; iter: 0; batch classifier loss: 0.728374; batch adversarial loss: 0.612793\n",
      "epoch 47; iter: 200; batch classifier loss: 0.290401; batch adversarial loss: 0.633662\n",
      "epoch 48; iter: 0; batch classifier loss: 0.327236; batch adversarial loss: 0.646379\n",
      "epoch 48; iter: 200; batch classifier loss: 0.340474; batch adversarial loss: 0.563247\n",
      "epoch 49; iter: 0; batch classifier loss: 0.313751; batch adversarial loss: 0.611802\n",
      "epoch 49; iter: 200; batch classifier loss: 0.413726; batch adversarial loss: 0.641234\n",
      "epoch 0; iter: 0; batch classifier loss: 7.115432; batch adversarial loss: 0.782162\n",
      "epoch 0; iter: 200; batch classifier loss: 3.243224; batch adversarial loss: 0.804815\n",
      "epoch 1; iter: 0; batch classifier loss: 3.275845; batch adversarial loss: 0.764721\n",
      "epoch 1; iter: 200; batch classifier loss: 6.468978; batch adversarial loss: 0.681001\n",
      "epoch 2; iter: 0; batch classifier loss: 5.552881; batch adversarial loss: 0.656662\n",
      "epoch 2; iter: 200; batch classifier loss: 2.604069; batch adversarial loss: 0.639369\n",
      "epoch 3; iter: 0; batch classifier loss: 2.327494; batch adversarial loss: 0.658786\n",
      "epoch 3; iter: 200; batch classifier loss: 3.009018; batch adversarial loss: 0.600240\n",
      "epoch 4; iter: 0; batch classifier loss: 3.330254; batch adversarial loss: 0.595761\n",
      "epoch 4; iter: 200; batch classifier loss: 1.442992; batch adversarial loss: 0.604557\n",
      "epoch 5; iter: 0; batch classifier loss: 5.006634; batch adversarial loss: 0.580831\n",
      "epoch 5; iter: 200; batch classifier loss: 2.815290; batch adversarial loss: 0.612303\n",
      "epoch 6; iter: 0; batch classifier loss: 1.038937; batch adversarial loss: 0.683430\n",
      "epoch 6; iter: 200; batch classifier loss: 0.959678; batch adversarial loss: 0.617934\n",
      "epoch 7; iter: 0; batch classifier loss: 0.899986; batch adversarial loss: 0.645146\n",
      "epoch 7; iter: 200; batch classifier loss: 0.856875; batch adversarial loss: 0.652001\n",
      "epoch 8; iter: 0; batch classifier loss: 0.732144; batch adversarial loss: 0.597009\n",
      "epoch 8; iter: 200; batch classifier loss: 0.678248; batch adversarial loss: 0.611444\n",
      "epoch 9; iter: 0; batch classifier loss: 0.851901; batch adversarial loss: 0.645848\n",
      "epoch 9; iter: 200; batch classifier loss: 0.748231; batch adversarial loss: 0.624614\n",
      "epoch 10; iter: 0; batch classifier loss: 0.641174; batch adversarial loss: 0.645979\n",
      "epoch 10; iter: 200; batch classifier loss: 0.574699; batch adversarial loss: 0.575138\n",
      "epoch 11; iter: 0; batch classifier loss: 0.450137; batch adversarial loss: 0.598247\n",
      "epoch 11; iter: 200; batch classifier loss: 0.681218; batch adversarial loss: 0.656759\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552120; batch adversarial loss: 0.577451\n",
      "epoch 12; iter: 200; batch classifier loss: 0.496827; batch adversarial loss: 0.622542\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473359; batch adversarial loss: 0.633478\n",
      "epoch 13; iter: 200; batch classifier loss: 0.468541; batch adversarial loss: 0.644677\n",
      "epoch 14; iter: 0; batch classifier loss: 0.703893; batch adversarial loss: 0.594491\n",
      "epoch 14; iter: 200; batch classifier loss: 0.457613; batch adversarial loss: 0.642940\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382017; batch adversarial loss: 0.620438\n",
      "epoch 15; iter: 200; batch classifier loss: 0.469895; batch adversarial loss: 0.607189\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377691; batch adversarial loss: 0.626691\n",
      "epoch 16; iter: 200; batch classifier loss: 0.386782; batch adversarial loss: 0.564605\n",
      "epoch 17; iter: 0; batch classifier loss: 0.319397; batch adversarial loss: 0.646222\n",
      "epoch 17; iter: 200; batch classifier loss: 0.305344; batch adversarial loss: 0.665764\n",
      "epoch 18; iter: 0; batch classifier loss: 0.457355; batch adversarial loss: 0.564183\n",
      "epoch 18; iter: 200; batch classifier loss: 0.407174; batch adversarial loss: 0.678592\n",
      "epoch 19; iter: 0; batch classifier loss: 0.312647; batch adversarial loss: 0.567280\n",
      "epoch 19; iter: 200; batch classifier loss: 0.309772; batch adversarial loss: 0.577569\n",
      "epoch 20; iter: 0; batch classifier loss: 0.336092; batch adversarial loss: 0.596932\n",
      "epoch 20; iter: 200; batch classifier loss: 0.361863; batch adversarial loss: 0.590305\n",
      "epoch 21; iter: 0; batch classifier loss: 0.401457; batch adversarial loss: 0.603781\n",
      "epoch 21; iter: 200; batch classifier loss: 0.331097; batch adversarial loss: 0.661784\n",
      "epoch 22; iter: 0; batch classifier loss: 0.330298; batch adversarial loss: 0.660196\n",
      "epoch 22; iter: 200; batch classifier loss: 0.411251; batch adversarial loss: 0.582342\n",
      "epoch 23; iter: 0; batch classifier loss: 0.358403; batch adversarial loss: 0.626273\n",
      "epoch 23; iter: 200; batch classifier loss: 0.339687; batch adversarial loss: 0.542879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315863; batch adversarial loss: 0.582953\n",
      "epoch 24; iter: 200; batch classifier loss: 0.384799; batch adversarial loss: 0.653577\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297785; batch adversarial loss: 0.619918\n",
      "epoch 25; iter: 200; batch classifier loss: 0.285714; batch adversarial loss: 0.677746\n",
      "epoch 26; iter: 0; batch classifier loss: 0.296328; batch adversarial loss: 0.610535\n",
      "epoch 26; iter: 200; batch classifier loss: 0.416118; batch adversarial loss: 0.628888\n",
      "epoch 27; iter: 0; batch classifier loss: 0.468533; batch adversarial loss: 0.622375\n",
      "epoch 27; iter: 200; batch classifier loss: 0.348029; batch adversarial loss: 0.612834\n",
      "epoch 28; iter: 0; batch classifier loss: 0.311617; batch adversarial loss: 0.566934\n",
      "epoch 28; iter: 200; batch classifier loss: 0.255456; batch adversarial loss: 0.688899\n",
      "epoch 29; iter: 0; batch classifier loss: 0.308338; batch adversarial loss: 0.571620\n",
      "epoch 29; iter: 200; batch classifier loss: 0.360751; batch adversarial loss: 0.609382\n",
      "epoch 30; iter: 0; batch classifier loss: 0.310488; batch adversarial loss: 0.573526\n",
      "epoch 30; iter: 200; batch classifier loss: 0.377843; batch adversarial loss: 0.593223\n",
      "epoch 31; iter: 0; batch classifier loss: 0.315449; batch adversarial loss: 0.605204\n",
      "epoch 31; iter: 200; batch classifier loss: 0.387604; batch adversarial loss: 0.564654\n",
      "epoch 32; iter: 0; batch classifier loss: 0.477934; batch adversarial loss: 0.647475\n",
      "epoch 32; iter: 200; batch classifier loss: 0.423225; batch adversarial loss: 0.566500\n",
      "epoch 33; iter: 0; batch classifier loss: 0.372821; batch adversarial loss: 0.690909\n",
      "epoch 33; iter: 200; batch classifier loss: 0.310984; batch adversarial loss: 0.658496\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408345; batch adversarial loss: 0.620879\n",
      "epoch 34; iter: 200; batch classifier loss: 0.534866; batch adversarial loss: 0.671409\n",
      "epoch 35; iter: 0; batch classifier loss: 0.347581; batch adversarial loss: 0.633972\n",
      "epoch 35; iter: 200; batch classifier loss: 0.279907; batch adversarial loss: 0.576753\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439804; batch adversarial loss: 0.600468\n",
      "epoch 36; iter: 200; batch classifier loss: 0.337959; batch adversarial loss: 0.612904\n",
      "epoch 37; iter: 0; batch classifier loss: 0.474402; batch adversarial loss: 0.650217\n",
      "epoch 37; iter: 200; batch classifier loss: 0.315356; batch adversarial loss: 0.634715\n",
      "epoch 38; iter: 0; batch classifier loss: 0.360415; batch adversarial loss: 0.645535\n",
      "epoch 38; iter: 200; batch classifier loss: 0.429671; batch adversarial loss: 0.635587\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446942; batch adversarial loss: 0.644743\n",
      "epoch 39; iter: 200; batch classifier loss: 0.408907; batch adversarial loss: 0.676771\n",
      "epoch 40; iter: 0; batch classifier loss: 0.374447; batch adversarial loss: 0.600860\n",
      "epoch 40; iter: 200; batch classifier loss: 0.309936; batch adversarial loss: 0.665042\n",
      "epoch 41; iter: 0; batch classifier loss: 0.340217; batch adversarial loss: 0.625494\n",
      "epoch 41; iter: 200; batch classifier loss: 0.380475; batch adversarial loss: 0.590426\n",
      "epoch 42; iter: 0; batch classifier loss: 0.382853; batch adversarial loss: 0.597150\n",
      "epoch 42; iter: 200; batch classifier loss: 0.384705; batch adversarial loss: 0.625785\n",
      "epoch 43; iter: 0; batch classifier loss: 0.376591; batch adversarial loss: 0.632701\n",
      "epoch 43; iter: 200; batch classifier loss: 0.374679; batch adversarial loss: 0.596906\n",
      "epoch 44; iter: 0; batch classifier loss: 0.375072; batch adversarial loss: 0.605508\n",
      "epoch 44; iter: 200; batch classifier loss: 0.616006; batch adversarial loss: 0.557698\n",
      "epoch 45; iter: 0; batch classifier loss: 0.506210; batch adversarial loss: 0.636896\n",
      "epoch 45; iter: 200; batch classifier loss: 0.302150; batch adversarial loss: 0.629891\n",
      "epoch 46; iter: 0; batch classifier loss: 0.389140; batch adversarial loss: 0.619806\n",
      "epoch 46; iter: 200; batch classifier loss: 0.440144; batch adversarial loss: 0.621540\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443102; batch adversarial loss: 0.590448\n",
      "epoch 47; iter: 200; batch classifier loss: 0.285103; batch adversarial loss: 0.624230\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399568; batch adversarial loss: 0.656762\n",
      "epoch 48; iter: 200; batch classifier loss: 0.500913; batch adversarial loss: 0.619559\n",
      "epoch 49; iter: 0; batch classifier loss: 0.547442; batch adversarial loss: 0.624290\n",
      "epoch 49; iter: 200; batch classifier loss: 0.506756; batch adversarial loss: 0.686553\n",
      "epoch 0; iter: 0; batch classifier loss: 7.036632; batch adversarial loss: 0.766975\n",
      "epoch 0; iter: 200; batch classifier loss: 6.526291; batch adversarial loss: 0.752332\n",
      "epoch 1; iter: 0; batch classifier loss: 2.570266; batch adversarial loss: 0.700597\n",
      "epoch 1; iter: 200; batch classifier loss: 6.386506; batch adversarial loss: 0.645785\n",
      "epoch 2; iter: 0; batch classifier loss: 6.500096; batch adversarial loss: 0.650178\n",
      "epoch 2; iter: 200; batch classifier loss: 3.255770; batch adversarial loss: 0.652503\n",
      "epoch 3; iter: 0; batch classifier loss: 1.039797; batch adversarial loss: 0.618609\n",
      "epoch 3; iter: 200; batch classifier loss: 2.410624; batch adversarial loss: 0.646979\n",
      "epoch 4; iter: 0; batch classifier loss: 2.465906; batch adversarial loss: 0.624185\n",
      "epoch 4; iter: 200; batch classifier loss: 1.036921; batch adversarial loss: 0.614032\n",
      "epoch 5; iter: 0; batch classifier loss: 2.215439; batch adversarial loss: 0.651720\n",
      "epoch 5; iter: 200; batch classifier loss: 1.456722; batch adversarial loss: 0.607768\n",
      "epoch 6; iter: 0; batch classifier loss: 1.574484; batch adversarial loss: 0.609415\n",
      "epoch 6; iter: 200; batch classifier loss: 0.777469; batch adversarial loss: 0.646270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.816474; batch adversarial loss: 0.629232\n",
      "epoch 7; iter: 200; batch classifier loss: 0.743228; batch adversarial loss: 0.617597\n",
      "epoch 8; iter: 0; batch classifier loss: 0.857555; batch adversarial loss: 0.639183\n",
      "epoch 8; iter: 200; batch classifier loss: 0.725267; batch adversarial loss: 0.615021\n",
      "epoch 9; iter: 0; batch classifier loss: 0.816462; batch adversarial loss: 0.615337\n",
      "epoch 9; iter: 200; batch classifier loss: 0.465581; batch adversarial loss: 0.667393\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550889; batch adversarial loss: 0.632164\n",
      "epoch 10; iter: 200; batch classifier loss: 0.368254; batch adversarial loss: 0.637746\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428349; batch adversarial loss: 0.675326\n",
      "epoch 11; iter: 200; batch classifier loss: 2.633259; batch adversarial loss: 0.662313\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468574; batch adversarial loss: 0.670109\n",
      "epoch 12; iter: 200; batch classifier loss: 0.412192; batch adversarial loss: 0.604066\n",
      "epoch 13; iter: 0; batch classifier loss: 0.535342; batch adversarial loss: 0.602891\n",
      "epoch 13; iter: 200; batch classifier loss: 0.347236; batch adversarial loss: 0.666642\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345716; batch adversarial loss: 0.587142\n",
      "epoch 14; iter: 200; batch classifier loss: 0.400797; batch adversarial loss: 0.708601\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377287; batch adversarial loss: 0.559911\n",
      "epoch 15; iter: 200; batch classifier loss: 0.368910; batch adversarial loss: 0.590327\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419694; batch adversarial loss: 0.625805\n",
      "epoch 16; iter: 200; batch classifier loss: 0.421213; batch adversarial loss: 0.647623\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486111; batch adversarial loss: 0.623260\n",
      "epoch 17; iter: 200; batch classifier loss: 0.399063; batch adversarial loss: 0.631739\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370513; batch adversarial loss: 0.648518\n",
      "epoch 18; iter: 200; batch classifier loss: 0.497772; batch adversarial loss: 0.580347\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408250; batch adversarial loss: 0.583403\n",
      "epoch 19; iter: 200; batch classifier loss: 0.396486; batch adversarial loss: 0.638179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.397348; batch adversarial loss: 0.666300\n",
      "epoch 20; iter: 200; batch classifier loss: 0.272664; batch adversarial loss: 0.609105\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429544; batch adversarial loss: 0.579885\n",
      "epoch 21; iter: 200; batch classifier loss: 0.349093; batch adversarial loss: 0.638087\n",
      "epoch 22; iter: 0; batch classifier loss: 0.327062; batch adversarial loss: 0.584535\n",
      "epoch 22; iter: 200; batch classifier loss: 0.332355; batch adversarial loss: 0.590305\n",
      "epoch 23; iter: 0; batch classifier loss: 0.288249; batch adversarial loss: 0.581784\n",
      "epoch 23; iter: 200; batch classifier loss: 0.283285; batch adversarial loss: 0.631147\n",
      "epoch 24; iter: 0; batch classifier loss: 0.347649; batch adversarial loss: 0.627289\n",
      "epoch 24; iter: 200; batch classifier loss: 0.321533; batch adversarial loss: 0.628677\n",
      "epoch 25; iter: 0; batch classifier loss: 0.306586; batch adversarial loss: 0.611841\n",
      "epoch 25; iter: 200; batch classifier loss: 0.348684; batch adversarial loss: 0.643318\n",
      "epoch 26; iter: 0; batch classifier loss: 0.329675; batch adversarial loss: 0.644977\n",
      "epoch 26; iter: 200; batch classifier loss: 0.299390; batch adversarial loss: 0.654415\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424069; batch adversarial loss: 0.635094\n",
      "epoch 27; iter: 200; batch classifier loss: 0.347366; batch adversarial loss: 0.679825\n",
      "epoch 28; iter: 0; batch classifier loss: 0.370419; batch adversarial loss: 0.557278\n",
      "epoch 28; iter: 200; batch classifier loss: 0.354120; batch adversarial loss: 0.601003\n",
      "epoch 29; iter: 0; batch classifier loss: 0.337770; batch adversarial loss: 0.607894\n",
      "epoch 29; iter: 200; batch classifier loss: 0.330811; batch adversarial loss: 0.663351\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365304; batch adversarial loss: 0.673049\n",
      "epoch 30; iter: 200; batch classifier loss: 0.321383; batch adversarial loss: 0.671036\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475403; batch adversarial loss: 0.579535\n",
      "epoch 31; iter: 200; batch classifier loss: 0.492382; batch adversarial loss: 0.624459\n",
      "epoch 32; iter: 0; batch classifier loss: 0.372807; batch adversarial loss: 0.647104\n",
      "epoch 32; iter: 200; batch classifier loss: 0.374848; batch adversarial loss: 0.668547\n",
      "epoch 33; iter: 0; batch classifier loss: 0.399779; batch adversarial loss: 0.587005\n",
      "epoch 33; iter: 200; batch classifier loss: 0.363345; batch adversarial loss: 0.622431\n",
      "epoch 34; iter: 0; batch classifier loss: 0.348317; batch adversarial loss: 0.613720\n",
      "epoch 34; iter: 200; batch classifier loss: 0.344928; batch adversarial loss: 0.632656\n",
      "epoch 35; iter: 0; batch classifier loss: 0.390831; batch adversarial loss: 0.634388\n",
      "epoch 35; iter: 200; batch classifier loss: 0.328669; batch adversarial loss: 0.625334\n",
      "epoch 36; iter: 0; batch classifier loss: 0.415439; batch adversarial loss: 0.620711\n",
      "epoch 36; iter: 200; batch classifier loss: 0.391295; batch adversarial loss: 0.624884\n",
      "epoch 37; iter: 0; batch classifier loss: 0.380995; batch adversarial loss: 0.613646\n",
      "epoch 37; iter: 200; batch classifier loss: 0.408080; batch adversarial loss: 0.639670\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382003; batch adversarial loss: 0.639334\n",
      "epoch 38; iter: 200; batch classifier loss: 0.448159; batch adversarial loss: 0.575455\n",
      "epoch 39; iter: 0; batch classifier loss: 0.473494; batch adversarial loss: 0.595939\n",
      "epoch 39; iter: 200; batch classifier loss: 0.384413; batch adversarial loss: 0.557868\n",
      "epoch 40; iter: 0; batch classifier loss: 0.323339; batch adversarial loss: 0.708046\n",
      "epoch 40; iter: 200; batch classifier loss: 0.363190; batch adversarial loss: 0.596165\n",
      "epoch 41; iter: 0; batch classifier loss: 0.653008; batch adversarial loss: 0.591156\n",
      "epoch 41; iter: 200; batch classifier loss: 0.287972; batch adversarial loss: 0.583104\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427069; batch adversarial loss: 0.674122\n",
      "epoch 42; iter: 200; batch classifier loss: 0.358739; batch adversarial loss: 0.658446\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415325; batch adversarial loss: 0.638195\n",
      "epoch 43; iter: 200; batch classifier loss: 0.349559; batch adversarial loss: 0.650690\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382120; batch adversarial loss: 0.602737\n",
      "epoch 44; iter: 200; batch classifier loss: 0.343421; batch adversarial loss: 0.712239\n",
      "epoch 45; iter: 0; batch classifier loss: 0.402047; batch adversarial loss: 0.642653\n",
      "epoch 45; iter: 200; batch classifier loss: 0.638793; batch adversarial loss: 0.601749\n",
      "epoch 46; iter: 0; batch classifier loss: 0.429915; batch adversarial loss: 0.654796\n",
      "epoch 46; iter: 200; batch classifier loss: 0.407239; batch adversarial loss: 0.652721\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371267; batch adversarial loss: 0.620070\n",
      "epoch 47; iter: 200; batch classifier loss: 0.481590; batch adversarial loss: 0.594346\n",
      "epoch 48; iter: 0; batch classifier loss: 0.407690; batch adversarial loss: 0.661174\n",
      "epoch 48; iter: 200; batch classifier loss: 0.361244; batch adversarial loss: 0.653655\n",
      "epoch 49; iter: 0; batch classifier loss: 0.401879; batch adversarial loss: 0.640719\n",
      "epoch 49; iter: 200; batch classifier loss: 0.454159; batch adversarial loss: 0.630260\n",
      "Best parameters: adversary_loss_weight     1.000000\n",
      "batch_size               64.000000\n",
      "num_epochs               20.000000\n",
      "acc_mean                  0.817120\n",
      "acc_std                   0.015895\n",
      "f1_mean                   0.484998\n",
      "f1_std                    0.081716\n",
      "SPD_mean                 -0.002761\n",
      "SPD_std                   0.029958\n",
      "DI_mean                   1.070321\n",
      "DI_std                    0.398851\n",
      "EOD_mean                  0.263040\n",
      "EOD_std                   0.058502\n",
      "AOD_mean                  0.145994\n",
      "AOD_std                   0.034533\n",
      "fairness_score            0.073081\n",
      "Name: 7, dtype: float64\n",
      "epoch 0; iter: 0; batch classifier loss: 412.985260; batch adversarial loss: 0.620087\n",
      "epoch 0; iter: 200; batch classifier loss: 0.507897; batch adversarial loss: 0.612846\n",
      "epoch 0; iter: 400; batch classifier loss: 2.560607; batch adversarial loss: 0.619275\n",
      "epoch 0; iter: 600; batch classifier loss: 8.295945; batch adversarial loss: 0.563271\n",
      "epoch 1; iter: 0; batch classifier loss: 9.609677; batch adversarial loss: 0.673013\n",
      "epoch 1; iter: 200; batch classifier loss: 0.299068; batch adversarial loss: 0.635018\n",
      "epoch 1; iter: 400; batch classifier loss: 15.132570; batch adversarial loss: 0.628574\n",
      "epoch 1; iter: 600; batch classifier loss: 23.314304; batch adversarial loss: 0.600612\n",
      "epoch 2; iter: 0; batch classifier loss: 0.383861; batch adversarial loss: 0.621981\n",
      "epoch 2; iter: 200; batch classifier loss: 2.567941; batch adversarial loss: 0.648119\n",
      "epoch 2; iter: 400; batch classifier loss: 2.187107; batch adversarial loss: 0.610669\n",
      "epoch 2; iter: 600; batch classifier loss: 0.596214; batch adversarial loss: 0.593578\n",
      "epoch 3; iter: 0; batch classifier loss: 0.408704; batch adversarial loss: 0.616003\n",
      "epoch 3; iter: 200; batch classifier loss: 0.833609; batch adversarial loss: 0.665963\n",
      "epoch 3; iter: 400; batch classifier loss: 0.852278; batch adversarial loss: 0.653609\n",
      "epoch 3; iter: 600; batch classifier loss: 0.537219; batch adversarial loss: 0.609292\n",
      "epoch 4; iter: 0; batch classifier loss: 1.020980; batch adversarial loss: 0.625159\n",
      "epoch 4; iter: 200; batch classifier loss: 2.244531; batch adversarial loss: 0.586461\n",
      "epoch 4; iter: 400; batch classifier loss: 0.719174; batch adversarial loss: 0.692720\n",
      "epoch 4; iter: 600; batch classifier loss: 0.612081; batch adversarial loss: 0.590525\n",
      "epoch 5; iter: 0; batch classifier loss: 0.485121; batch adversarial loss: 0.691319\n",
      "epoch 5; iter: 200; batch classifier loss: 0.410342; batch adversarial loss: 0.655523\n",
      "epoch 5; iter: 400; batch classifier loss: 0.596488; batch adversarial loss: 0.616481\n",
      "epoch 5; iter: 600; batch classifier loss: 0.524765; batch adversarial loss: 0.648159\n",
      "epoch 6; iter: 0; batch classifier loss: 0.605587; batch adversarial loss: 0.590268\n",
      "epoch 6; iter: 200; batch classifier loss: 0.311056; batch adversarial loss: 0.677467\n",
      "epoch 6; iter: 400; batch classifier loss: 0.262254; batch adversarial loss: 0.624162\n",
      "epoch 6; iter: 600; batch classifier loss: 0.530626; batch adversarial loss: 0.670877\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453138; batch adversarial loss: 0.611966\n",
      "epoch 7; iter: 200; batch classifier loss: 0.427348; batch adversarial loss: 0.601548\n",
      "epoch 7; iter: 400; batch classifier loss: 0.405529; batch adversarial loss: 0.618466\n",
      "epoch 7; iter: 600; batch classifier loss: 0.383985; batch adversarial loss: 0.612871\n",
      "epoch 8; iter: 0; batch classifier loss: 0.313577; batch adversarial loss: 0.531007\n",
      "epoch 8; iter: 200; batch classifier loss: 0.610234; batch adversarial loss: 0.732293\n",
      "epoch 8; iter: 400; batch classifier loss: 0.343489; batch adversarial loss: 0.612422\n",
      "epoch 8; iter: 600; batch classifier loss: 0.529241; batch adversarial loss: 0.545969\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347268; batch adversarial loss: 0.626453\n",
      "epoch 9; iter: 200; batch classifier loss: 0.267195; batch adversarial loss: 0.597977\n",
      "epoch 9; iter: 400; batch classifier loss: 0.360369; batch adversarial loss: 0.651357\n",
      "epoch 9; iter: 600; batch classifier loss: 0.421130; batch adversarial loss: 0.600836\n",
      "epoch 10; iter: 0; batch classifier loss: 0.280623; batch adversarial loss: 0.570032\n",
      "epoch 10; iter: 200; batch classifier loss: 0.262862; batch adversarial loss: 0.618229\n",
      "epoch 10; iter: 400; batch classifier loss: 0.307047; batch adversarial loss: 0.625134\n",
      "epoch 10; iter: 600; batch classifier loss: 0.343368; batch adversarial loss: 0.634041\n",
      "epoch 11; iter: 0; batch classifier loss: 0.274031; batch adversarial loss: 0.628605\n",
      "epoch 11; iter: 200; batch classifier loss: 0.444843; batch adversarial loss: 0.641163\n",
      "epoch 11; iter: 400; batch classifier loss: 0.341801; batch adversarial loss: 0.588465\n",
      "epoch 11; iter: 600; batch classifier loss: 0.297802; batch adversarial loss: 0.647972\n",
      "epoch 12; iter: 0; batch classifier loss: 0.343850; batch adversarial loss: 0.685768\n",
      "epoch 12; iter: 200; batch classifier loss: 0.429147; batch adversarial loss: 0.573107\n",
      "epoch 12; iter: 400; batch classifier loss: 0.287655; batch adversarial loss: 0.727640\n",
      "epoch 12; iter: 600; batch classifier loss: 0.429669; batch adversarial loss: 0.586152\n",
      "epoch 13; iter: 0; batch classifier loss: 0.319504; batch adversarial loss: 0.684293\n",
      "epoch 13; iter: 200; batch classifier loss: 0.448775; batch adversarial loss: 0.585691\n",
      "epoch 13; iter: 400; batch classifier loss: 0.345434; batch adversarial loss: 0.651971\n",
      "epoch 13; iter: 600; batch classifier loss: 0.269197; batch adversarial loss: 0.637530\n",
      "epoch 14; iter: 0; batch classifier loss: 0.326680; batch adversarial loss: 0.607243\n",
      "epoch 14; iter: 200; batch classifier loss: 0.267043; batch adversarial loss: 0.637777\n",
      "epoch 14; iter: 400; batch classifier loss: 0.449551; batch adversarial loss: 0.579369\n",
      "epoch 14; iter: 600; batch classifier loss: 0.443204; batch adversarial loss: 0.596415\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358347; batch adversarial loss: 0.644178\n",
      "epoch 15; iter: 200; batch classifier loss: 0.257015; batch adversarial loss: 0.690354\n",
      "epoch 15; iter: 400; batch classifier loss: 0.522138; batch adversarial loss: 0.618888\n",
      "epoch 15; iter: 600; batch classifier loss: 0.226939; batch adversarial loss: 0.695950\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341808; batch adversarial loss: 0.641202\n",
      "epoch 16; iter: 200; batch classifier loss: 0.240885; batch adversarial loss: 0.649458\n",
      "epoch 16; iter: 400; batch classifier loss: 0.439201; batch adversarial loss: 0.580676\n",
      "epoch 16; iter: 600; batch classifier loss: 0.512628; batch adversarial loss: 0.600073\n",
      "epoch 17; iter: 0; batch classifier loss: 0.302145; batch adversarial loss: 0.609173\n",
      "epoch 17; iter: 200; batch classifier loss: 0.352231; batch adversarial loss: 0.598058\n",
      "epoch 17; iter: 400; batch classifier loss: 0.518149; batch adversarial loss: 0.568765\n",
      "epoch 17; iter: 600; batch classifier loss: 0.269057; batch adversarial loss: 0.641972\n",
      "epoch 18; iter: 0; batch classifier loss: 0.431847; batch adversarial loss: 0.579417\n",
      "epoch 18; iter: 200; batch classifier loss: 0.394286; batch adversarial loss: 0.695876\n",
      "epoch 18; iter: 400; batch classifier loss: 0.490427; batch adversarial loss: 0.611405\n",
      "epoch 18; iter: 600; batch classifier loss: 0.376628; batch adversarial loss: 0.608358\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425293; batch adversarial loss: 0.686733\n",
      "epoch 19; iter: 200; batch classifier loss: 0.424359; batch adversarial loss: 0.695362\n",
      "epoch 19; iter: 400; batch classifier loss: 0.275649; batch adversarial loss: 0.750922\n",
      "epoch 19; iter: 600; batch classifier loss: 0.460108; batch adversarial loss: 0.680663\n",
      "epoch 0; iter: 0; batch classifier loss: 21.584007; batch adversarial loss: 0.709894\n",
      "epoch 0; iter: 200; batch classifier loss: 4.957062; batch adversarial loss: 0.681278\n",
      "epoch 0; iter: 400; batch classifier loss: 7.759350; batch adversarial loss: 0.613056\n",
      "epoch 0; iter: 600; batch classifier loss: 4.547863; batch adversarial loss: 0.597057\n",
      "epoch 1; iter: 0; batch classifier loss: 14.180385; batch adversarial loss: 0.615715\n",
      "epoch 1; iter: 200; batch classifier loss: 2.487257; batch adversarial loss: 0.664074\n",
      "epoch 1; iter: 400; batch classifier loss: 1.516154; batch adversarial loss: 0.624765\n",
      "epoch 1; iter: 600; batch classifier loss: 2.872115; batch adversarial loss: 0.600870\n",
      "epoch 2; iter: 0; batch classifier loss: 1.726835; batch adversarial loss: 0.617893\n",
      "epoch 2; iter: 200; batch classifier loss: 0.848579; batch adversarial loss: 0.672575\n",
      "epoch 2; iter: 400; batch classifier loss: 2.544963; batch adversarial loss: 0.595633\n",
      "epoch 2; iter: 600; batch classifier loss: 2.918222; batch adversarial loss: 0.615274\n",
      "epoch 3; iter: 0; batch classifier loss: 1.020453; batch adversarial loss: 0.654710\n",
      "epoch 3; iter: 200; batch classifier loss: 1.451592; batch adversarial loss: 0.644015\n",
      "epoch 3; iter: 400; batch classifier loss: 0.824404; batch adversarial loss: 0.716905\n",
      "epoch 3; iter: 600; batch classifier loss: 1.183892; batch adversarial loss: 0.641287\n",
      "epoch 4; iter: 0; batch classifier loss: 1.021280; batch adversarial loss: 0.609236\n",
      "epoch 4; iter: 200; batch classifier loss: 0.658165; batch adversarial loss: 0.616369\n",
      "epoch 4; iter: 400; batch classifier loss: 0.755839; batch adversarial loss: 0.572748\n",
      "epoch 4; iter: 600; batch classifier loss: 0.529612; batch adversarial loss: 0.517461\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409287; batch adversarial loss: 0.675740\n",
      "epoch 5; iter: 200; batch classifier loss: 0.250292; batch adversarial loss: 0.665922\n",
      "epoch 5; iter: 400; batch classifier loss: 0.675462; batch adversarial loss: 0.576211\n",
      "epoch 5; iter: 600; batch classifier loss: 0.628333; batch adversarial loss: 0.625701\n",
      "epoch 6; iter: 0; batch classifier loss: 0.624920; batch adversarial loss: 0.519138\n",
      "epoch 6; iter: 200; batch classifier loss: 0.470126; batch adversarial loss: 0.630421\n",
      "epoch 6; iter: 400; batch classifier loss: 0.418065; batch adversarial loss: 0.497323\n",
      "epoch 6; iter: 600; batch classifier loss: 0.514755; batch adversarial loss: 0.587330\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595023; batch adversarial loss: 0.627795\n",
      "epoch 7; iter: 200; batch classifier loss: 0.461277; batch adversarial loss: 0.533769\n",
      "epoch 7; iter: 400; batch classifier loss: 0.528866; batch adversarial loss: 0.709269\n",
      "epoch 7; iter: 600; batch classifier loss: 0.318704; batch adversarial loss: 0.611906\n",
      "epoch 8; iter: 0; batch classifier loss: 0.312769; batch adversarial loss: 0.702734\n",
      "epoch 8; iter: 200; batch classifier loss: 0.454079; batch adversarial loss: 0.656507\n",
      "epoch 8; iter: 400; batch classifier loss: 0.433543; batch adversarial loss: 0.659449\n",
      "epoch 8; iter: 600; batch classifier loss: 0.297641; batch adversarial loss: 0.619695\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338131; batch adversarial loss: 0.639825\n",
      "epoch 9; iter: 200; batch classifier loss: 0.337639; batch adversarial loss: 0.609600\n",
      "epoch 9; iter: 400; batch classifier loss: 0.333417; batch adversarial loss: 0.615473\n",
      "epoch 9; iter: 600; batch classifier loss: 0.387023; batch adversarial loss: 0.705039\n",
      "epoch 10; iter: 0; batch classifier loss: 0.310757; batch adversarial loss: 0.612462\n",
      "epoch 10; iter: 200; batch classifier loss: 0.328546; batch adversarial loss: 0.599185\n",
      "epoch 10; iter: 400; batch classifier loss: 0.318429; batch adversarial loss: 0.670688\n",
      "epoch 10; iter: 600; batch classifier loss: 0.478209; batch adversarial loss: 0.581860\n",
      "epoch 11; iter: 0; batch classifier loss: 0.485271; batch adversarial loss: 0.593691\n",
      "epoch 11; iter: 200; batch classifier loss: 0.465688; batch adversarial loss: 0.567234\n",
      "epoch 11; iter: 400; batch classifier loss: 0.397242; batch adversarial loss: 0.643129\n",
      "epoch 11; iter: 600; batch classifier loss: 0.415661; batch adversarial loss: 0.736733\n",
      "epoch 12; iter: 0; batch classifier loss: 0.423297; batch adversarial loss: 0.606507\n",
      "epoch 12; iter: 200; batch classifier loss: 0.468917; batch adversarial loss: 0.589539\n",
      "epoch 12; iter: 400; batch classifier loss: 0.279869; batch adversarial loss: 0.687548\n",
      "epoch 12; iter: 600; batch classifier loss: 0.307680; batch adversarial loss: 0.650876\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419062; batch adversarial loss: 0.645066\n",
      "epoch 13; iter: 200; batch classifier loss: 0.477767; batch adversarial loss: 0.695859\n",
      "epoch 13; iter: 400; batch classifier loss: 0.198779; batch adversarial loss: 0.598852\n",
      "epoch 13; iter: 600; batch classifier loss: 0.544623; batch adversarial loss: 0.509320\n",
      "epoch 14; iter: 0; batch classifier loss: 0.286843; batch adversarial loss: 0.621970\n",
      "epoch 14; iter: 200; batch classifier loss: 0.490635; batch adversarial loss: 0.567592\n",
      "epoch 14; iter: 400; batch classifier loss: 0.311966; batch adversarial loss: 0.607787\n",
      "epoch 14; iter: 600; batch classifier loss: 0.443171; batch adversarial loss: 0.608884\n",
      "epoch 15; iter: 0; batch classifier loss: 0.352476; batch adversarial loss: 0.630213\n",
      "epoch 15; iter: 200; batch classifier loss: 0.451101; batch adversarial loss: 0.635748\n",
      "epoch 15; iter: 400; batch classifier loss: 0.346720; batch adversarial loss: 0.556219\n",
      "epoch 15; iter: 600; batch classifier loss: 0.226615; batch adversarial loss: 0.695960\n",
      "epoch 16; iter: 0; batch classifier loss: 0.457367; batch adversarial loss: 0.649718\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399383; batch adversarial loss: 0.645800\n",
      "epoch 16; iter: 400; batch classifier loss: 0.411730; batch adversarial loss: 0.570734\n",
      "epoch 16; iter: 600; batch classifier loss: 0.474182; batch adversarial loss: 0.665213\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352752; batch adversarial loss: 0.627545\n",
      "epoch 17; iter: 200; batch classifier loss: 0.469550; batch adversarial loss: 0.574215\n",
      "epoch 17; iter: 400; batch classifier loss: 0.298216; batch adversarial loss: 0.733196\n",
      "epoch 17; iter: 600; batch classifier loss: 0.487664; batch adversarial loss: 0.584734\n",
      "epoch 18; iter: 0; batch classifier loss: 0.409207; batch adversarial loss: 0.562771\n",
      "epoch 18; iter: 200; batch classifier loss: 0.321078; batch adversarial loss: 0.605787\n",
      "epoch 18; iter: 400; batch classifier loss: 0.265121; batch adversarial loss: 0.627507\n",
      "epoch 18; iter: 600; batch classifier loss: 1.101038; batch adversarial loss: 0.580016\n",
      "epoch 19; iter: 0; batch classifier loss: 0.613068; batch adversarial loss: 0.685240\n",
      "epoch 19; iter: 200; batch classifier loss: 0.344631; batch adversarial loss: 0.622243\n",
      "epoch 19; iter: 400; batch classifier loss: 0.195279; batch adversarial loss: 0.600726\n",
      "epoch 19; iter: 600; batch classifier loss: 0.333116; batch adversarial loss: 0.633272\n",
      "epoch 0; iter: 0; batch classifier loss: 14.812493; batch adversarial loss: 0.963179\n",
      "epoch 0; iter: 200; batch classifier loss: 10.750130; batch adversarial loss: 0.832932\n",
      "epoch 0; iter: 400; batch classifier loss: 1.188779; batch adversarial loss: 0.760868\n",
      "epoch 0; iter: 600; batch classifier loss: 0.903644; batch adversarial loss: 0.756977\n",
      "epoch 1; iter: 0; batch classifier loss: 6.056219; batch adversarial loss: 0.703969\n",
      "epoch 1; iter: 200; batch classifier loss: 1.654336; batch adversarial loss: 0.690051\n",
      "epoch 1; iter: 400; batch classifier loss: 3.656112; batch adversarial loss: 0.626497\n",
      "epoch 1; iter: 600; batch classifier loss: 2.870694; batch adversarial loss: 0.664909\n",
      "epoch 2; iter: 0; batch classifier loss: 1.803449; batch adversarial loss: 0.664077\n",
      "epoch 2; iter: 200; batch classifier loss: 2.997753; batch adversarial loss: 0.587659\n",
      "epoch 2; iter: 400; batch classifier loss: 0.624102; batch adversarial loss: 0.576491\n",
      "epoch 2; iter: 600; batch classifier loss: 1.955057; batch adversarial loss: 0.605762\n",
      "epoch 3; iter: 0; batch classifier loss: 1.033759; batch adversarial loss: 0.652459\n",
      "epoch 3; iter: 200; batch classifier loss: 1.721538; batch adversarial loss: 0.604616\n",
      "epoch 3; iter: 400; batch classifier loss: 1.012852; batch adversarial loss: 0.652581\n",
      "epoch 3; iter: 600; batch classifier loss: 0.798001; batch adversarial loss: 0.638537\n",
      "epoch 4; iter: 0; batch classifier loss: 1.307333; batch adversarial loss: 0.669465\n",
      "epoch 4; iter: 200; batch classifier loss: 0.812249; batch adversarial loss: 0.621228\n",
      "epoch 4; iter: 400; batch classifier loss: 0.796999; batch adversarial loss: 0.665854\n",
      "epoch 4; iter: 600; batch classifier loss: 1.338752; batch adversarial loss: 0.608216\n",
      "epoch 5; iter: 0; batch classifier loss: 0.622961; batch adversarial loss: 0.699825\n",
      "epoch 5; iter: 200; batch classifier loss: 0.689492; batch adversarial loss: 0.591260\n",
      "epoch 5; iter: 400; batch classifier loss: 0.483051; batch adversarial loss: 0.646689\n",
      "epoch 5; iter: 600; batch classifier loss: 0.446073; batch adversarial loss: 0.610838\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497027; batch adversarial loss: 0.648064\n",
      "epoch 6; iter: 200; batch classifier loss: 0.520645; batch adversarial loss: 0.599536\n",
      "epoch 6; iter: 400; batch classifier loss: 0.404630; batch adversarial loss: 0.546508\n",
      "epoch 6; iter: 600; batch classifier loss: 0.343749; batch adversarial loss: 0.581701\n",
      "epoch 7; iter: 0; batch classifier loss: 0.393345; batch adversarial loss: 0.558775\n",
      "epoch 7; iter: 200; batch classifier loss: 0.338316; batch adversarial loss: 0.630593\n",
      "epoch 7; iter: 400; batch classifier loss: 0.452953; batch adversarial loss: 0.643161\n",
      "epoch 7; iter: 600; batch classifier loss: 0.494777; batch adversarial loss: 0.576070\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404849; batch adversarial loss: 0.691499\n",
      "epoch 8; iter: 200; batch classifier loss: 0.368026; batch adversarial loss: 0.609384\n",
      "epoch 8; iter: 400; batch classifier loss: 0.374685; batch adversarial loss: 0.591077\n",
      "epoch 8; iter: 600; batch classifier loss: 0.337154; batch adversarial loss: 0.586974\n",
      "epoch 9; iter: 0; batch classifier loss: 0.388381; batch adversarial loss: 0.592247\n",
      "epoch 9; iter: 200; batch classifier loss: 0.409724; batch adversarial loss: 0.577874\n",
      "epoch 9; iter: 400; batch classifier loss: 0.200818; batch adversarial loss: 0.605271\n",
      "epoch 9; iter: 600; batch classifier loss: 0.320969; batch adversarial loss: 0.582238\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372231; batch adversarial loss: 0.600052\n",
      "epoch 10; iter: 200; batch classifier loss: 0.444077; batch adversarial loss: 0.580218\n",
      "epoch 10; iter: 400; batch classifier loss: 0.407581; batch adversarial loss: 0.628214\n",
      "epoch 10; iter: 600; batch classifier loss: 0.183584; batch adversarial loss: 0.642573\n",
      "epoch 11; iter: 0; batch classifier loss: 0.239823; batch adversarial loss: 0.701874\n",
      "epoch 11; iter: 200; batch classifier loss: 0.369119; batch adversarial loss: 0.648838\n",
      "epoch 11; iter: 400; batch classifier loss: 0.321033; batch adversarial loss: 0.652248\n",
      "epoch 11; iter: 600; batch classifier loss: 0.335021; batch adversarial loss: 0.654138\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348284; batch adversarial loss: 0.724455\n",
      "epoch 12; iter: 200; batch classifier loss: 0.358287; batch adversarial loss: 0.610781\n",
      "epoch 12; iter: 400; batch classifier loss: 0.360406; batch adversarial loss: 0.648832\n",
      "epoch 12; iter: 600; batch classifier loss: 0.316430; batch adversarial loss: 0.605265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420263; batch adversarial loss: 0.654313\n",
      "epoch 13; iter: 200; batch classifier loss: 0.350409; batch adversarial loss: 0.621721\n",
      "epoch 13; iter: 400; batch classifier loss: 0.405257; batch adversarial loss: 0.577158\n",
      "epoch 13; iter: 600; batch classifier loss: 0.300769; batch adversarial loss: 0.643164\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290503; batch adversarial loss: 0.594921\n",
      "epoch 14; iter: 200; batch classifier loss: 0.332727; batch adversarial loss: 0.566888\n",
      "epoch 14; iter: 400; batch classifier loss: 0.332110; batch adversarial loss: 0.646942\n",
      "epoch 14; iter: 600; batch classifier loss: 0.222772; batch adversarial loss: 0.684848\n",
      "epoch 15; iter: 0; batch classifier loss: 0.343298; batch adversarial loss: 0.615770\n",
      "epoch 15; iter: 200; batch classifier loss: 0.355185; batch adversarial loss: 0.624414\n",
      "epoch 15; iter: 400; batch classifier loss: 0.405201; batch adversarial loss: 0.594562\n",
      "epoch 15; iter: 600; batch classifier loss: 0.491352; batch adversarial loss: 0.660277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.363184; batch adversarial loss: 0.618704\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380206; batch adversarial loss: 0.674707\n",
      "epoch 16; iter: 400; batch classifier loss: 0.419955; batch adversarial loss: 0.627931\n",
      "epoch 16; iter: 600; batch classifier loss: 0.467798; batch adversarial loss: 0.639325\n",
      "epoch 17; iter: 0; batch classifier loss: 0.399703; batch adversarial loss: 0.592863\n",
      "epoch 17; iter: 200; batch classifier loss: 0.440799; batch adversarial loss: 0.696008\n",
      "epoch 17; iter: 400; batch classifier loss: 0.314891; batch adversarial loss: 0.725870\n",
      "epoch 17; iter: 600; batch classifier loss: 0.377918; batch adversarial loss: 0.642950\n",
      "epoch 18; iter: 0; batch classifier loss: 0.296669; batch adversarial loss: 0.647339\n",
      "epoch 18; iter: 200; batch classifier loss: 0.400741; batch adversarial loss: 0.607369\n",
      "epoch 18; iter: 400; batch classifier loss: 0.452476; batch adversarial loss: 0.538016\n",
      "epoch 18; iter: 600; batch classifier loss: 0.273559; batch adversarial loss: 0.678076\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505728; batch adversarial loss: 0.508511\n",
      "epoch 19; iter: 200; batch classifier loss: 0.407150; batch adversarial loss: 0.628003\n",
      "epoch 19; iter: 400; batch classifier loss: 0.468185; batch adversarial loss: 0.584304\n",
      "epoch 19; iter: 600; batch classifier loss: 0.257457; batch adversarial loss: 0.650009\n",
      "epoch 0; iter: 0; batch classifier loss: 154.858429; batch adversarial loss: 0.757244\n",
      "epoch 0; iter: 200; batch classifier loss: 8.578992; batch adversarial loss: 0.658616\n",
      "epoch 0; iter: 400; batch classifier loss: 2.473853; batch adversarial loss: 0.709407\n",
      "epoch 0; iter: 600; batch classifier loss: 1.704151; batch adversarial loss: 0.643667\n",
      "epoch 1; iter: 0; batch classifier loss: 13.043291; batch adversarial loss: 0.546130\n",
      "epoch 1; iter: 200; batch classifier loss: 2.785912; batch adversarial loss: 0.631058\n",
      "epoch 1; iter: 400; batch classifier loss: 0.668113; batch adversarial loss: 0.689990\n",
      "epoch 1; iter: 600; batch classifier loss: 3.072441; batch adversarial loss: 0.631221\n",
      "epoch 2; iter: 0; batch classifier loss: 0.815419; batch adversarial loss: 0.679811\n",
      "epoch 2; iter: 200; batch classifier loss: 3.922267; batch adversarial loss: 0.597997\n",
      "epoch 2; iter: 400; batch classifier loss: 3.222887; batch adversarial loss: 0.645375\n",
      "epoch 2; iter: 600; batch classifier loss: 5.089339; batch adversarial loss: 0.602758\n",
      "epoch 3; iter: 0; batch classifier loss: 4.478028; batch adversarial loss: 0.571915\n",
      "epoch 3; iter: 200; batch classifier loss: 1.477235; batch adversarial loss: 0.648431\n",
      "epoch 3; iter: 400; batch classifier loss: 1.180463; batch adversarial loss: 0.573986\n",
      "epoch 3; iter: 600; batch classifier loss: 1.620370; batch adversarial loss: 0.659186\n",
      "epoch 4; iter: 0; batch classifier loss: 0.757727; batch adversarial loss: 0.635401\n",
      "epoch 4; iter: 200; batch classifier loss: 0.787207; batch adversarial loss: 0.548746\n",
      "epoch 4; iter: 400; batch classifier loss: 0.525434; batch adversarial loss: 0.571602\n",
      "epoch 4; iter: 600; batch classifier loss: 0.735769; batch adversarial loss: 0.555770\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637908; batch adversarial loss: 0.642158\n",
      "epoch 5; iter: 200; batch classifier loss: 0.940679; batch adversarial loss: 0.603096\n",
      "epoch 5; iter: 400; batch classifier loss: 0.539685; batch adversarial loss: 0.655881\n",
      "epoch 5; iter: 600; batch classifier loss: 0.547364; batch adversarial loss: 0.617450\n",
      "epoch 6; iter: 0; batch classifier loss: 1.747052; batch adversarial loss: 0.594587\n",
      "epoch 6; iter: 200; batch classifier loss: 0.536276; batch adversarial loss: 0.656713\n",
      "epoch 6; iter: 400; batch classifier loss: 0.340771; batch adversarial loss: 0.684212\n",
      "epoch 6; iter: 600; batch classifier loss: 0.316666; batch adversarial loss: 0.562090\n",
      "epoch 7; iter: 0; batch classifier loss: 0.342635; batch adversarial loss: 0.552335\n",
      "epoch 7; iter: 200; batch classifier loss: 0.392730; batch adversarial loss: 0.564814\n",
      "epoch 7; iter: 400; batch classifier loss: 0.484071; batch adversarial loss: 0.662857\n",
      "epoch 7; iter: 600; batch classifier loss: 0.421431; batch adversarial loss: 0.619091\n",
      "epoch 8; iter: 0; batch classifier loss: 0.314458; batch adversarial loss: 0.737257\n",
      "epoch 8; iter: 200; batch classifier loss: 0.334758; batch adversarial loss: 0.586172\n",
      "epoch 8; iter: 400; batch classifier loss: 0.378404; batch adversarial loss: 0.692582\n",
      "epoch 8; iter: 600; batch classifier loss: 0.374557; batch adversarial loss: 0.587752\n",
      "epoch 9; iter: 0; batch classifier loss: 0.297577; batch adversarial loss: 0.562680\n",
      "epoch 9; iter: 200; batch classifier loss: 0.416868; batch adversarial loss: 0.624433\n",
      "epoch 9; iter: 400; batch classifier loss: 0.509916; batch adversarial loss: 0.602723\n",
      "epoch 9; iter: 600; batch classifier loss: 0.295786; batch adversarial loss: 0.615510\n",
      "epoch 10; iter: 0; batch classifier loss: 0.301214; batch adversarial loss: 0.573236\n",
      "epoch 10; iter: 200; batch classifier loss: 0.206780; batch adversarial loss: 0.602974\n",
      "epoch 10; iter: 400; batch classifier loss: 0.376960; batch adversarial loss: 0.605006\n",
      "epoch 10; iter: 600; batch classifier loss: 0.426529; batch adversarial loss: 0.577568\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371915; batch adversarial loss: 0.577958\n",
      "epoch 11; iter: 200; batch classifier loss: 0.353649; batch adversarial loss: 0.545899\n",
      "epoch 11; iter: 400; batch classifier loss: 0.475727; batch adversarial loss: 0.669008\n",
      "epoch 11; iter: 600; batch classifier loss: 0.336922; batch adversarial loss: 0.681841\n",
      "epoch 12; iter: 0; batch classifier loss: 0.313981; batch adversarial loss: 0.628813\n",
      "epoch 12; iter: 200; batch classifier loss: 0.348720; batch adversarial loss: 0.616589\n",
      "epoch 12; iter: 400; batch classifier loss: 0.469175; batch adversarial loss: 0.618762\n",
      "epoch 12; iter: 600; batch classifier loss: 0.350455; batch adversarial loss: 0.605142\n",
      "epoch 13; iter: 0; batch classifier loss: 0.199426; batch adversarial loss: 0.590444\n",
      "epoch 13; iter: 200; batch classifier loss: 0.457475; batch adversarial loss: 0.675047\n",
      "epoch 13; iter: 400; batch classifier loss: 0.368175; batch adversarial loss: 0.582280\n",
      "epoch 13; iter: 600; batch classifier loss: 0.441032; batch adversarial loss: 0.655754\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308625; batch adversarial loss: 0.742634\n",
      "epoch 14; iter: 200; batch classifier loss: 0.206596; batch adversarial loss: 0.608598\n",
      "epoch 14; iter: 400; batch classifier loss: 0.345640; batch adversarial loss: 0.615318\n",
      "epoch 14; iter: 600; batch classifier loss: 0.336058; batch adversarial loss: 0.684459\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401085; batch adversarial loss: 0.681712\n",
      "epoch 15; iter: 200; batch classifier loss: 0.505087; batch adversarial loss: 0.678787\n",
      "epoch 15; iter: 400; batch classifier loss: 0.270552; batch adversarial loss: 0.589074\n",
      "epoch 15; iter: 600; batch classifier loss: 0.167433; batch adversarial loss: 0.584906\n",
      "epoch 16; iter: 0; batch classifier loss: 0.386556; batch adversarial loss: 0.599032\n",
      "epoch 16; iter: 200; batch classifier loss: 0.328343; batch adversarial loss: 0.581725\n",
      "epoch 16; iter: 400; batch classifier loss: 0.513695; batch adversarial loss: 0.619279\n",
      "epoch 16; iter: 600; batch classifier loss: 0.383476; batch adversarial loss: 0.623757\n",
      "epoch 17; iter: 0; batch classifier loss: 0.414920; batch adversarial loss: 0.671342\n",
      "epoch 17; iter: 200; batch classifier loss: 0.612630; batch adversarial loss: 0.579531\n",
      "epoch 17; iter: 400; batch classifier loss: 0.332739; batch adversarial loss: 0.637954\n",
      "epoch 17; iter: 600; batch classifier loss: 0.370930; batch adversarial loss: 0.649013\n",
      "epoch 18; iter: 0; batch classifier loss: 0.421391; batch adversarial loss: 0.612438\n",
      "epoch 18; iter: 200; batch classifier loss: 0.432240; batch adversarial loss: 0.635021\n",
      "epoch 18; iter: 400; batch classifier loss: 0.612914; batch adversarial loss: 0.575845\n",
      "epoch 18; iter: 600; batch classifier loss: 0.579094; batch adversarial loss: 0.576259\n",
      "epoch 19; iter: 0; batch classifier loss: 0.368475; batch adversarial loss: 0.599980\n",
      "epoch 19; iter: 200; batch classifier loss: 0.414642; batch adversarial loss: 0.623534\n",
      "epoch 19; iter: 400; batch classifier loss: 0.357328; batch adversarial loss: 0.709828\n",
      "epoch 19; iter: 600; batch classifier loss: 0.368135; batch adversarial loss: 0.667519\n",
      "epoch 0; iter: 0; batch classifier loss: 36.708023; batch adversarial loss: 0.643404\n",
      "epoch 0; iter: 200; batch classifier loss: 5.261304; batch adversarial loss: 0.599862\n",
      "epoch 0; iter: 400; batch classifier loss: 4.693090; batch adversarial loss: 0.668469\n",
      "epoch 0; iter: 600; batch classifier loss: 12.854479; batch adversarial loss: 0.624478\n",
      "epoch 1; iter: 0; batch classifier loss: 0.448882; batch adversarial loss: 0.645752\n",
      "epoch 1; iter: 200; batch classifier loss: 3.550389; batch adversarial loss: 0.634304\n",
      "epoch 1; iter: 400; batch classifier loss: 5.359431; batch adversarial loss: 0.669600\n",
      "epoch 1; iter: 600; batch classifier loss: 5.827213; batch adversarial loss: 0.698444\n",
      "epoch 2; iter: 0; batch classifier loss: 3.590028; batch adversarial loss: 0.567709\n",
      "epoch 2; iter: 200; batch classifier loss: 4.043372; batch adversarial loss: 0.552922\n",
      "epoch 2; iter: 400; batch classifier loss: 3.331491; batch adversarial loss: 0.649932\n",
      "epoch 2; iter: 600; batch classifier loss: 1.111215; batch adversarial loss: 0.596229\n",
      "epoch 3; iter: 0; batch classifier loss: 0.959903; batch adversarial loss: 0.595561\n",
      "epoch 3; iter: 200; batch classifier loss: 2.463481; batch adversarial loss: 0.614762\n",
      "epoch 3; iter: 400; batch classifier loss: 1.560808; batch adversarial loss: 0.587167\n",
      "epoch 3; iter: 600; batch classifier loss: 0.595017; batch adversarial loss: 0.620980\n",
      "epoch 4; iter: 0; batch classifier loss: 1.421751; batch adversarial loss: 0.627137\n",
      "epoch 4; iter: 200; batch classifier loss: 0.739272; batch adversarial loss: 0.524220\n",
      "epoch 4; iter: 400; batch classifier loss: 0.741338; batch adversarial loss: 0.583025\n",
      "epoch 4; iter: 600; batch classifier loss: 0.681158; batch adversarial loss: 0.607958\n",
      "epoch 5; iter: 0; batch classifier loss: 0.380298; batch adversarial loss: 0.610317\n",
      "epoch 5; iter: 200; batch classifier loss: 0.458013; batch adversarial loss: 0.600730\n",
      "epoch 5; iter: 400; batch classifier loss: 0.572871; batch adversarial loss: 0.595057\n",
      "epoch 5; iter: 600; batch classifier loss: 0.471476; batch adversarial loss: 0.562586\n",
      "epoch 6; iter: 0; batch classifier loss: 0.341427; batch adversarial loss: 0.589588\n",
      "epoch 6; iter: 200; batch classifier loss: 0.381551; batch adversarial loss: 0.678135\n",
      "epoch 6; iter: 400; batch classifier loss: 0.319748; batch adversarial loss: 0.662751\n",
      "epoch 6; iter: 600; batch classifier loss: 0.313876; batch adversarial loss: 0.717006\n",
      "epoch 7; iter: 0; batch classifier loss: 0.572104; batch adversarial loss: 0.650807\n",
      "epoch 7; iter: 200; batch classifier loss: 0.430795; batch adversarial loss: 0.619981\n",
      "epoch 7; iter: 400; batch classifier loss: 0.435542; batch adversarial loss: 0.580407\n",
      "epoch 7; iter: 600; batch classifier loss: 0.433477; batch adversarial loss: 0.620746\n",
      "epoch 8; iter: 0; batch classifier loss: 0.274172; batch adversarial loss: 0.579178\n",
      "epoch 8; iter: 200; batch classifier loss: 0.336072; batch adversarial loss: 0.595558\n",
      "epoch 8; iter: 400; batch classifier loss: 0.351871; batch adversarial loss: 0.569309\n",
      "epoch 8; iter: 600; batch classifier loss: 0.326132; batch adversarial loss: 0.716365\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435925; batch adversarial loss: 0.554035\n",
      "epoch 9; iter: 200; batch classifier loss: 0.311160; batch adversarial loss: 0.592407\n",
      "epoch 9; iter: 400; batch classifier loss: 0.356355; batch adversarial loss: 0.662192\n",
      "epoch 9; iter: 600; batch classifier loss: 0.442122; batch adversarial loss: 0.509616\n",
      "epoch 10; iter: 0; batch classifier loss: 0.577450; batch adversarial loss: 0.531943\n",
      "epoch 10; iter: 200; batch classifier loss: 0.433807; batch adversarial loss: 0.585642\n",
      "epoch 10; iter: 400; batch classifier loss: 0.351155; batch adversarial loss: 0.617342\n",
      "epoch 10; iter: 600; batch classifier loss: 0.284286; batch adversarial loss: 0.559312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389340; batch adversarial loss: 0.594075\n",
      "epoch 11; iter: 200; batch classifier loss: 0.486656; batch adversarial loss: 0.579127\n",
      "epoch 11; iter: 400; batch classifier loss: 0.398908; batch adversarial loss: 0.620254\n",
      "epoch 11; iter: 600; batch classifier loss: 0.397045; batch adversarial loss: 0.642614\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404812; batch adversarial loss: 0.580767\n",
      "epoch 12; iter: 200; batch classifier loss: 0.285195; batch adversarial loss: 0.711304\n",
      "epoch 12; iter: 400; batch classifier loss: 0.419810; batch adversarial loss: 0.617837\n",
      "epoch 12; iter: 600; batch classifier loss: 0.357327; batch adversarial loss: 0.665466\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448080; batch adversarial loss: 0.701620\n",
      "epoch 13; iter: 200; batch classifier loss: 0.345152; batch adversarial loss: 0.637733\n",
      "epoch 13; iter: 400; batch classifier loss: 0.394835; batch adversarial loss: 0.637571\n",
      "epoch 13; iter: 600; batch classifier loss: 0.338118; batch adversarial loss: 0.655487\n",
      "epoch 14; iter: 0; batch classifier loss: 0.554033; batch adversarial loss: 0.565068\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352675; batch adversarial loss: 0.645385\n",
      "epoch 14; iter: 400; batch classifier loss: 0.331047; batch adversarial loss: 0.605322\n",
      "epoch 14; iter: 600; batch classifier loss: 0.441952; batch adversarial loss: 0.581108\n",
      "epoch 15; iter: 0; batch classifier loss: 0.419839; batch adversarial loss: 0.593602\n",
      "epoch 15; iter: 200; batch classifier loss: 0.408919; batch adversarial loss: 0.728207\n",
      "epoch 15; iter: 400; batch classifier loss: 0.479443; batch adversarial loss: 0.655458\n",
      "epoch 15; iter: 600; batch classifier loss: 0.345693; batch adversarial loss: 0.714216\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454593; batch adversarial loss: 0.642313\n",
      "epoch 16; iter: 200; batch classifier loss: 0.535723; batch adversarial loss: 0.608858\n",
      "epoch 16; iter: 400; batch classifier loss: 0.359686; batch adversarial loss: 0.604393\n",
      "epoch 16; iter: 600; batch classifier loss: 0.320940; batch adversarial loss: 0.575715\n",
      "epoch 17; iter: 0; batch classifier loss: 0.352977; batch adversarial loss: 0.658387\n",
      "epoch 17; iter: 200; batch classifier loss: 0.320679; batch adversarial loss: 0.685620\n",
      "epoch 17; iter: 400; batch classifier loss: 0.453583; batch adversarial loss: 0.735755\n",
      "epoch 17; iter: 600; batch classifier loss: 0.321785; batch adversarial loss: 0.634246\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557615; batch adversarial loss: 0.639159\n",
      "epoch 18; iter: 200; batch classifier loss: 0.485561; batch adversarial loss: 0.530580\n",
      "epoch 18; iter: 400; batch classifier loss: 0.363909; batch adversarial loss: 0.662831\n",
      "epoch 18; iter: 600; batch classifier loss: 0.474409; batch adversarial loss: 0.647776\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510165; batch adversarial loss: 0.630349\n",
      "epoch 19; iter: 200; batch classifier loss: 0.590538; batch adversarial loss: 0.661697\n",
      "epoch 19; iter: 400; batch classifier loss: 0.551238; batch adversarial loss: 0.612641\n",
      "epoch 19; iter: 600; batch classifier loss: 0.383330; batch adversarial loss: 0.656020\n",
      "epoch 0; iter: 0; batch classifier loss: 62.383522; batch adversarial loss: 0.674475\n",
      "epoch 0; iter: 200; batch classifier loss: 8.996933; batch adversarial loss: 0.596872\n",
      "epoch 0; iter: 400; batch classifier loss: 28.983620; batch adversarial loss: 0.666270\n",
      "epoch 0; iter: 600; batch classifier loss: 11.328512; batch adversarial loss: 0.622811\n",
      "epoch 1; iter: 0; batch classifier loss: 14.302714; batch adversarial loss: 0.576246\n",
      "epoch 1; iter: 200; batch classifier loss: 5.454584; batch adversarial loss: 0.652322\n",
      "epoch 1; iter: 400; batch classifier loss: 9.940518; batch adversarial loss: 0.687770\n",
      "epoch 1; iter: 600; batch classifier loss: 10.026158; batch adversarial loss: 0.670271\n",
      "epoch 2; iter: 0; batch classifier loss: 3.939764; batch adversarial loss: 0.658213\n",
      "epoch 2; iter: 200; batch classifier loss: 2.926194; batch adversarial loss: 0.623398\n",
      "epoch 2; iter: 400; batch classifier loss: 6.645893; batch adversarial loss: 0.643203\n",
      "epoch 2; iter: 600; batch classifier loss: 0.327121; batch adversarial loss: 0.609789\n",
      "epoch 3; iter: 0; batch classifier loss: 0.406595; batch adversarial loss: 0.642017\n",
      "epoch 3; iter: 200; batch classifier loss: 5.644814; batch adversarial loss: 0.575487\n",
      "epoch 3; iter: 400; batch classifier loss: 2.338252; batch adversarial loss: 0.680853\n",
      "epoch 3; iter: 600; batch classifier loss: 0.433954; batch adversarial loss: 0.682585\n",
      "epoch 4; iter: 0; batch classifier loss: 0.673015; batch adversarial loss: 0.543941\n",
      "epoch 4; iter: 200; batch classifier loss: 0.497443; batch adversarial loss: 0.699443\n",
      "epoch 4; iter: 400; batch classifier loss: 1.496393; batch adversarial loss: 0.657778\n",
      "epoch 4; iter: 600; batch classifier loss: 0.321800; batch adversarial loss: 0.670260\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595881; batch adversarial loss: 0.654866\n",
      "epoch 5; iter: 200; batch classifier loss: 0.704554; batch adversarial loss: 0.608378\n",
      "epoch 5; iter: 400; batch classifier loss: 0.367594; batch adversarial loss: 0.556098\n",
      "epoch 5; iter: 600; batch classifier loss: 0.437730; batch adversarial loss: 0.559005\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492644; batch adversarial loss: 0.566901\n",
      "epoch 6; iter: 200; batch classifier loss: 0.383460; batch adversarial loss: 0.649183\n",
      "epoch 6; iter: 400; batch classifier loss: 0.434425; batch adversarial loss: 0.634799\n",
      "epoch 6; iter: 600; batch classifier loss: 0.333605; batch adversarial loss: 0.647679\n",
      "epoch 7; iter: 0; batch classifier loss: 0.428061; batch adversarial loss: 0.616868\n",
      "epoch 7; iter: 200; batch classifier loss: 0.349281; batch adversarial loss: 0.589414\n",
      "epoch 7; iter: 400; batch classifier loss: 0.396118; batch adversarial loss: 0.628193\n",
      "epoch 7; iter: 600; batch classifier loss: 0.394942; batch adversarial loss: 0.546647\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486525; batch adversarial loss: 0.664659\n",
      "epoch 8; iter: 200; batch classifier loss: 0.388887; batch adversarial loss: 0.666960\n",
      "epoch 8; iter: 400; batch classifier loss: 0.407235; batch adversarial loss: 0.574950\n",
      "epoch 8; iter: 600; batch classifier loss: 0.329025; batch adversarial loss: 0.631484\n",
      "epoch 9; iter: 0; batch classifier loss: 0.319611; batch adversarial loss: 0.677149\n",
      "epoch 9; iter: 200; batch classifier loss: 0.392386; batch adversarial loss: 0.617551\n",
      "epoch 9; iter: 400; batch classifier loss: 0.343838; batch adversarial loss: 0.657584\n",
      "epoch 9; iter: 600; batch classifier loss: 0.358484; batch adversarial loss: 0.630677\n",
      "epoch 10; iter: 0; batch classifier loss: 0.381524; batch adversarial loss: 0.664141\n",
      "epoch 10; iter: 200; batch classifier loss: 0.531365; batch adversarial loss: 0.572551\n",
      "epoch 10; iter: 400; batch classifier loss: 0.353755; batch adversarial loss: 0.701834\n",
      "epoch 10; iter: 600; batch classifier loss: 0.555061; batch adversarial loss: 0.617734\n",
      "epoch 11; iter: 0; batch classifier loss: 0.339595; batch adversarial loss: 0.627423\n",
      "epoch 11; iter: 200; batch classifier loss: 0.250529; batch adversarial loss: 0.714115\n",
      "epoch 11; iter: 400; batch classifier loss: 0.465725; batch adversarial loss: 0.618382\n",
      "epoch 11; iter: 600; batch classifier loss: 0.503018; batch adversarial loss: 0.622861\n",
      "epoch 12; iter: 0; batch classifier loss: 0.388938; batch adversarial loss: 0.593413\n",
      "epoch 12; iter: 200; batch classifier loss: 0.410843; batch adversarial loss: 0.622118\n",
      "epoch 12; iter: 400; batch classifier loss: 0.373210; batch adversarial loss: 0.642291\n",
      "epoch 12; iter: 600; batch classifier loss: 0.370336; batch adversarial loss: 0.612747\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457751; batch adversarial loss: 0.656752\n",
      "epoch 13; iter: 200; batch classifier loss: 0.464461; batch adversarial loss: 0.636093\n",
      "epoch 13; iter: 400; batch classifier loss: 0.536640; batch adversarial loss: 0.629279\n",
      "epoch 13; iter: 600; batch classifier loss: 0.418992; batch adversarial loss: 0.561619\n",
      "epoch 14; iter: 0; batch classifier loss: 0.353216; batch adversarial loss: 0.739363\n",
      "epoch 14; iter: 200; batch classifier loss: 0.453256; batch adversarial loss: 0.644846\n",
      "epoch 14; iter: 400; batch classifier loss: 0.303241; batch adversarial loss: 0.656029\n",
      "epoch 14; iter: 600; batch classifier loss: 0.315257; batch adversarial loss: 0.613028\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561614; batch adversarial loss: 0.612356\n",
      "epoch 15; iter: 200; batch classifier loss: 0.480701; batch adversarial loss: 0.607420\n",
      "epoch 15; iter: 400; batch classifier loss: 0.307237; batch adversarial loss: 0.569962\n",
      "epoch 15; iter: 600; batch classifier loss: 0.510344; batch adversarial loss: 0.567383\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423950; batch adversarial loss: 0.597910\n",
      "epoch 16; iter: 200; batch classifier loss: 0.430993; batch adversarial loss: 0.697105\n",
      "epoch 16; iter: 400; batch classifier loss: 0.318867; batch adversarial loss: 0.647010\n",
      "epoch 16; iter: 600; batch classifier loss: 0.374459; batch adversarial loss: 0.730814\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420677; batch adversarial loss: 0.549301\n",
      "epoch 17; iter: 200; batch classifier loss: 0.389805; batch adversarial loss: 0.616982\n",
      "epoch 17; iter: 400; batch classifier loss: 0.409966; batch adversarial loss: 0.584774\n",
      "epoch 17; iter: 600; batch classifier loss: 0.476412; batch adversarial loss: 0.674133\n",
      "epoch 18; iter: 0; batch classifier loss: 0.454387; batch adversarial loss: 0.723439\n",
      "epoch 18; iter: 200; batch classifier loss: 0.468581; batch adversarial loss: 0.565270\n",
      "epoch 18; iter: 400; batch classifier loss: 0.410977; batch adversarial loss: 0.608964\n",
      "epoch 18; iter: 600; batch classifier loss: 0.606688; batch adversarial loss: 0.657839\n",
      "epoch 19; iter: 0; batch classifier loss: 0.347496; batch adversarial loss: 0.606348\n",
      "epoch 19; iter: 200; batch classifier loss: 0.362078; batch adversarial loss: 0.637089\n",
      "epoch 19; iter: 400; batch classifier loss: 0.590510; batch adversarial loss: 0.642736\n",
      "epoch 19; iter: 600; batch classifier loss: 0.438956; batch adversarial loss: 0.678819\n",
      "epoch 0; iter: 0; batch classifier loss: 6.002078; batch adversarial loss: 0.724723\n",
      "epoch 0; iter: 200; batch classifier loss: 27.279325; batch adversarial loss: 0.671507\n",
      "epoch 0; iter: 400; batch classifier loss: 8.604666; batch adversarial loss: 0.615236\n",
      "epoch 0; iter: 600; batch classifier loss: 4.007715; batch adversarial loss: 0.600078\n",
      "epoch 1; iter: 0; batch classifier loss: 13.292196; batch adversarial loss: 0.587231\n",
      "epoch 1; iter: 200; batch classifier loss: 0.258075; batch adversarial loss: 0.604924\n",
      "epoch 1; iter: 400; batch classifier loss: 5.987136; batch adversarial loss: 0.647768\n",
      "epoch 1; iter: 600; batch classifier loss: 3.957654; batch adversarial loss: 0.658347\n",
      "epoch 2; iter: 0; batch classifier loss: 6.954075; batch adversarial loss: 0.638229\n",
      "epoch 2; iter: 200; batch classifier loss: 2.611981; batch adversarial loss: 0.686920\n",
      "epoch 2; iter: 400; batch classifier loss: 2.814425; batch adversarial loss: 0.678653\n",
      "epoch 2; iter: 600; batch classifier loss: 1.978094; batch adversarial loss: 0.698581\n",
      "epoch 3; iter: 0; batch classifier loss: 1.045190; batch adversarial loss: 0.655983\n",
      "epoch 3; iter: 200; batch classifier loss: 0.885687; batch adversarial loss: 0.620881\n",
      "epoch 3; iter: 400; batch classifier loss: 3.070967; batch adversarial loss: 0.628414\n",
      "epoch 3; iter: 600; batch classifier loss: 0.555978; batch adversarial loss: 0.606622\n",
      "epoch 4; iter: 0; batch classifier loss: 1.359850; batch adversarial loss: 0.644484\n",
      "epoch 4; iter: 200; batch classifier loss: 0.889596; batch adversarial loss: 0.674821\n",
      "epoch 4; iter: 400; batch classifier loss: 0.604382; batch adversarial loss: 0.563306\n",
      "epoch 4; iter: 600; batch classifier loss: 0.670946; batch adversarial loss: 0.652448\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587237; batch adversarial loss: 0.595322\n",
      "epoch 5; iter: 200; batch classifier loss: 0.628106; batch adversarial loss: 0.562590\n",
      "epoch 5; iter: 400; batch classifier loss: 0.431589; batch adversarial loss: 0.666166\n",
      "epoch 5; iter: 600; batch classifier loss: 0.583025; batch adversarial loss: 0.653682\n",
      "epoch 6; iter: 0; batch classifier loss: 0.409893; batch adversarial loss: 0.617424\n",
      "epoch 6; iter: 200; batch classifier loss: 0.500684; batch adversarial loss: 0.646967\n",
      "epoch 6; iter: 400; batch classifier loss: 0.485523; batch adversarial loss: 0.609400\n",
      "epoch 6; iter: 600; batch classifier loss: 0.458257; batch adversarial loss: 0.665891\n",
      "epoch 7; iter: 0; batch classifier loss: 0.374114; batch adversarial loss: 0.602197\n",
      "epoch 7; iter: 200; batch classifier loss: 0.362875; batch adversarial loss: 0.572258\n",
      "epoch 7; iter: 400; batch classifier loss: 0.359359; batch adversarial loss: 0.623573\n",
      "epoch 7; iter: 600; batch classifier loss: 0.355979; batch adversarial loss: 0.616405\n",
      "epoch 8; iter: 0; batch classifier loss: 0.487496; batch adversarial loss: 0.646855\n",
      "epoch 8; iter: 200; batch classifier loss: 0.375390; batch adversarial loss: 0.701163\n",
      "epoch 8; iter: 400; batch classifier loss: 0.434688; batch adversarial loss: 0.653735\n",
      "epoch 8; iter: 600; batch classifier loss: 0.328845; batch adversarial loss: 0.649554\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460751; batch adversarial loss: 0.627776\n",
      "epoch 9; iter: 200; batch classifier loss: 0.459466; batch adversarial loss: 0.593979\n",
      "epoch 9; iter: 400; batch classifier loss: 0.294274; batch adversarial loss: 0.669738\n",
      "epoch 9; iter: 600; batch classifier loss: 0.305601; batch adversarial loss: 0.622471\n",
      "epoch 10; iter: 0; batch classifier loss: 0.251897; batch adversarial loss: 0.676285\n",
      "epoch 10; iter: 200; batch classifier loss: 0.268280; batch adversarial loss: 0.630544\n",
      "epoch 10; iter: 400; batch classifier loss: 0.372545; batch adversarial loss: 0.595069\n",
      "epoch 10; iter: 600; batch classifier loss: 0.224830; batch adversarial loss: 0.676312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.281271; batch adversarial loss: 0.667998\n",
      "epoch 11; iter: 200; batch classifier loss: 0.280018; batch adversarial loss: 0.671878\n",
      "epoch 11; iter: 400; batch classifier loss: 0.416318; batch adversarial loss: 0.631018\n",
      "epoch 11; iter: 600; batch classifier loss: 0.402811; batch adversarial loss: 0.711261\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326321; batch adversarial loss: 0.605409\n",
      "epoch 12; iter: 200; batch classifier loss: 0.439768; batch adversarial loss: 0.587186\n",
      "epoch 12; iter: 400; batch classifier loss: 0.383005; batch adversarial loss: 0.603470\n",
      "epoch 12; iter: 600; batch classifier loss: 0.351612; batch adversarial loss: 0.532264\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361678; batch adversarial loss: 0.627123\n",
      "epoch 13; iter: 200; batch classifier loss: 0.362798; batch adversarial loss: 0.608189\n",
      "epoch 13; iter: 400; batch classifier loss: 0.511615; batch adversarial loss: 0.622411\n",
      "epoch 13; iter: 600; batch classifier loss: 0.500098; batch adversarial loss: 0.608678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.367174; batch adversarial loss: 0.591900\n",
      "epoch 14; iter: 200; batch classifier loss: 0.375586; batch adversarial loss: 0.644075\n",
      "epoch 14; iter: 400; batch classifier loss: 0.332401; batch adversarial loss: 0.578930\n",
      "epoch 14; iter: 600; batch classifier loss: 0.266562; batch adversarial loss: 0.675133\n",
      "epoch 15; iter: 0; batch classifier loss: 0.301562; batch adversarial loss: 0.623650\n",
      "epoch 15; iter: 200; batch classifier loss: 0.388068; batch adversarial loss: 0.609822\n",
      "epoch 15; iter: 400; batch classifier loss: 0.342932; batch adversarial loss: 0.671734\n",
      "epoch 15; iter: 600; batch classifier loss: 0.464113; batch adversarial loss: 0.614969\n",
      "epoch 16; iter: 0; batch classifier loss: 0.409286; batch adversarial loss: 0.650587\n",
      "epoch 16; iter: 200; batch classifier loss: 0.339627; batch adversarial loss: 0.723990\n",
      "epoch 16; iter: 400; batch classifier loss: 0.469351; batch adversarial loss: 0.614486\n",
      "epoch 16; iter: 600; batch classifier loss: 0.465751; batch adversarial loss: 0.574573\n",
      "epoch 17; iter: 0; batch classifier loss: 0.396643; batch adversarial loss: 0.615368\n",
      "epoch 17; iter: 200; batch classifier loss: 0.412737; batch adversarial loss: 0.664786\n",
      "epoch 17; iter: 400; batch classifier loss: 0.564389; batch adversarial loss: 0.561178\n",
      "epoch 17; iter: 600; batch classifier loss: 0.559894; batch adversarial loss: 0.636460\n",
      "epoch 18; iter: 0; batch classifier loss: 0.407900; batch adversarial loss: 0.579007\n",
      "epoch 18; iter: 200; batch classifier loss: 0.351022; batch adversarial loss: 0.694583\n",
      "epoch 18; iter: 400; batch classifier loss: 0.338985; batch adversarial loss: 0.648649\n",
      "epoch 18; iter: 600; batch classifier loss: 0.473455; batch adversarial loss: 0.680833\n",
      "epoch 19; iter: 0; batch classifier loss: 0.668878; batch adversarial loss: 0.565561\n",
      "epoch 19; iter: 200; batch classifier loss: 0.381468; batch adversarial loss: 0.629375\n",
      "epoch 19; iter: 400; batch classifier loss: 0.322671; batch adversarial loss: 0.613784\n",
      "epoch 19; iter: 600; batch classifier loss: 0.449536; batch adversarial loss: 0.629379\n",
      "epoch 0; iter: 0; batch classifier loss: 11.960739; batch adversarial loss: 0.715862\n",
      "epoch 0; iter: 200; batch classifier loss: 11.583081; batch adversarial loss: 0.673809\n",
      "epoch 0; iter: 400; batch classifier loss: 2.619919; batch adversarial loss: 0.624594\n",
      "epoch 0; iter: 600; batch classifier loss: 7.520866; batch adversarial loss: 0.646332\n",
      "epoch 1; iter: 0; batch classifier loss: 8.607365; batch adversarial loss: 0.585439\n",
      "epoch 1; iter: 200; batch classifier loss: 6.438956; batch adversarial loss: 0.602271\n",
      "epoch 1; iter: 400; batch classifier loss: 1.031383; batch adversarial loss: 0.582579\n",
      "epoch 1; iter: 600; batch classifier loss: 2.829246; batch adversarial loss: 0.696114\n",
      "epoch 2; iter: 0; batch classifier loss: 5.418560; batch adversarial loss: 0.658348\n",
      "epoch 2; iter: 200; batch classifier loss: 1.288365; batch adversarial loss: 0.544236\n",
      "epoch 2; iter: 400; batch classifier loss: 3.773156; batch adversarial loss: 0.629783\n",
      "epoch 2; iter: 600; batch classifier loss: 1.788922; batch adversarial loss: 0.571606\n",
      "epoch 3; iter: 0; batch classifier loss: 0.930029; batch adversarial loss: 0.620580\n",
      "epoch 3; iter: 200; batch classifier loss: 0.584168; batch adversarial loss: 0.657676\n",
      "epoch 3; iter: 400; batch classifier loss: 0.441817; batch adversarial loss: 0.611963\n",
      "epoch 3; iter: 600; batch classifier loss: 0.451533; batch adversarial loss: 0.599403\n",
      "epoch 4; iter: 0; batch classifier loss: 0.875057; batch adversarial loss: 0.633449\n",
      "epoch 4; iter: 200; batch classifier loss: 1.364738; batch adversarial loss: 0.592434\n",
      "epoch 4; iter: 400; batch classifier loss: 0.643670; batch adversarial loss: 0.709977\n",
      "epoch 4; iter: 600; batch classifier loss: 0.782859; batch adversarial loss: 0.555819\n",
      "epoch 5; iter: 0; batch classifier loss: 0.484409; batch adversarial loss: 0.602955\n",
      "epoch 5; iter: 200; batch classifier loss: 0.422610; batch adversarial loss: 0.660941\n",
      "epoch 5; iter: 400; batch classifier loss: 0.394482; batch adversarial loss: 0.607680\n",
      "epoch 5; iter: 600; batch classifier loss: 0.507886; batch adversarial loss: 0.599414\n",
      "epoch 6; iter: 0; batch classifier loss: 0.322088; batch adversarial loss: 0.585219\n",
      "epoch 6; iter: 200; batch classifier loss: 0.421389; batch adversarial loss: 0.625698\n",
      "epoch 6; iter: 400; batch classifier loss: 0.420061; batch adversarial loss: 0.699938\n",
      "epoch 6; iter: 600; batch classifier loss: 0.603245; batch adversarial loss: 0.651806\n",
      "epoch 7; iter: 0; batch classifier loss: 0.387414; batch adversarial loss: 0.638572\n",
      "epoch 7; iter: 200; batch classifier loss: 0.592262; batch adversarial loss: 0.592879\n",
      "epoch 7; iter: 400; batch classifier loss: 0.255984; batch adversarial loss: 0.639688\n",
      "epoch 7; iter: 600; batch classifier loss: 0.260321; batch adversarial loss: 0.596480\n",
      "epoch 8; iter: 0; batch classifier loss: 0.332515; batch adversarial loss: 0.634499\n",
      "epoch 8; iter: 200; batch classifier loss: 0.446263; batch adversarial loss: 0.563325\n",
      "epoch 8; iter: 400; batch classifier loss: 0.321700; batch adversarial loss: 0.565162\n",
      "epoch 8; iter: 600; batch classifier loss: 0.270395; batch adversarial loss: 0.629399\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474925; batch adversarial loss: 0.514197\n",
      "epoch 9; iter: 200; batch classifier loss: 0.276699; batch adversarial loss: 0.627475\n",
      "epoch 9; iter: 400; batch classifier loss: 0.327583; batch adversarial loss: 0.604103\n",
      "epoch 9; iter: 600; batch classifier loss: 0.433397; batch adversarial loss: 0.641617\n",
      "epoch 10; iter: 0; batch classifier loss: 0.321929; batch adversarial loss: 0.695340\n",
      "epoch 10; iter: 200; batch classifier loss: 0.327130; batch adversarial loss: 0.638720\n",
      "epoch 10; iter: 400; batch classifier loss: 0.426782; batch adversarial loss: 0.573532\n",
      "epoch 10; iter: 600; batch classifier loss: 0.325094; batch adversarial loss: 0.661708\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441305; batch adversarial loss: 0.738163\n",
      "epoch 11; iter: 200; batch classifier loss: 0.267945; batch adversarial loss: 0.600767\n",
      "epoch 11; iter: 400; batch classifier loss: 0.353802; batch adversarial loss: 0.621368\n",
      "epoch 11; iter: 600; batch classifier loss: 0.473849; batch adversarial loss: 0.551918\n",
      "epoch 12; iter: 0; batch classifier loss: 0.311913; batch adversarial loss: 0.631396\n",
      "epoch 12; iter: 200; batch classifier loss: 0.366508; batch adversarial loss: 0.682790\n",
      "epoch 12; iter: 400; batch classifier loss: 0.309587; batch adversarial loss: 0.623896\n",
      "epoch 12; iter: 600; batch classifier loss: 0.499410; batch adversarial loss: 0.580971\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335404; batch adversarial loss: 0.628049\n",
      "epoch 13; iter: 200; batch classifier loss: 0.398331; batch adversarial loss: 0.642570\n",
      "epoch 13; iter: 400; batch classifier loss: 0.441892; batch adversarial loss: 0.546717\n",
      "epoch 13; iter: 600; batch classifier loss: 0.505256; batch adversarial loss: 0.669263\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495614; batch adversarial loss: 0.634715\n",
      "epoch 14; iter: 200; batch classifier loss: 0.379249; batch adversarial loss: 0.673243\n",
      "epoch 14; iter: 400; batch classifier loss: 0.345342; batch adversarial loss: 0.610219\n",
      "epoch 14; iter: 600; batch classifier loss: 0.448796; batch adversarial loss: 0.561346\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473381; batch adversarial loss: 0.670695\n",
      "epoch 15; iter: 200; batch classifier loss: 0.346005; batch adversarial loss: 0.637479\n",
      "epoch 15; iter: 400; batch classifier loss: 0.412200; batch adversarial loss: 0.676375\n",
      "epoch 15; iter: 600; batch classifier loss: 0.245414; batch adversarial loss: 0.613385\n",
      "epoch 16; iter: 0; batch classifier loss: 0.427418; batch adversarial loss: 0.583314\n",
      "epoch 16; iter: 200; batch classifier loss: 0.423237; batch adversarial loss: 0.604698\n",
      "epoch 16; iter: 400; batch classifier loss: 0.336049; batch adversarial loss: 0.728183\n",
      "epoch 16; iter: 600; batch classifier loss: 0.443567; batch adversarial loss: 0.600352\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367618; batch adversarial loss: 0.622550\n",
      "epoch 17; iter: 200; batch classifier loss: 0.274945; batch adversarial loss: 0.715597\n",
      "epoch 17; iter: 400; batch classifier loss: 0.392786; batch adversarial loss: 0.609914\n",
      "epoch 17; iter: 600; batch classifier loss: 0.390350; batch adversarial loss: 0.612257\n",
      "epoch 18; iter: 0; batch classifier loss: 0.493989; batch adversarial loss: 0.650717\n",
      "epoch 18; iter: 200; batch classifier loss: 0.348472; batch adversarial loss: 0.653354\n",
      "epoch 18; iter: 400; batch classifier loss: 0.412751; batch adversarial loss: 0.592736\n",
      "epoch 18; iter: 600; batch classifier loss: 0.316726; batch adversarial loss: 0.634352\n",
      "epoch 19; iter: 0; batch classifier loss: 0.534168; batch adversarial loss: 0.712382\n",
      "epoch 19; iter: 200; batch classifier loss: 0.408132; batch adversarial loss: 0.662929\n",
      "epoch 19; iter: 400; batch classifier loss: 0.263394; batch adversarial loss: 0.577154\n",
      "epoch 19; iter: 600; batch classifier loss: 0.569712; batch adversarial loss: 0.588372\n",
      "epoch 0; iter: 0; batch classifier loss: 87.009659; batch adversarial loss: 0.725677\n",
      "epoch 0; iter: 200; batch classifier loss: 11.969657; batch adversarial loss: 0.782166\n",
      "epoch 0; iter: 400; batch classifier loss: 2.389417; batch adversarial loss: 0.710422\n",
      "epoch 0; iter: 600; batch classifier loss: 10.603462; batch adversarial loss: 0.625853\n",
      "epoch 1; iter: 0; batch classifier loss: 6.563057; batch adversarial loss: 0.647047\n",
      "epoch 1; iter: 200; batch classifier loss: 25.751007; batch adversarial loss: 0.642278\n",
      "epoch 1; iter: 400; batch classifier loss: 1.147733; batch adversarial loss: 0.675511\n",
      "epoch 1; iter: 600; batch classifier loss: 4.522045; batch adversarial loss: 0.573615\n",
      "epoch 2; iter: 0; batch classifier loss: 6.174995; batch adversarial loss: 0.608382\n",
      "epoch 2; iter: 200; batch classifier loss: 2.776698; batch adversarial loss: 0.611689\n",
      "epoch 2; iter: 400; batch classifier loss: 5.755555; batch adversarial loss: 0.573440\n",
      "epoch 2; iter: 600; batch classifier loss: 5.165702; batch adversarial loss: 0.604415\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559151; batch adversarial loss: 0.637619\n",
      "epoch 3; iter: 200; batch classifier loss: 1.759420; batch adversarial loss: 0.613483\n",
      "epoch 3; iter: 400; batch classifier loss: 1.301350; batch adversarial loss: 0.621047\n",
      "epoch 3; iter: 600; batch classifier loss: 1.143014; batch adversarial loss: 0.572889\n",
      "epoch 4; iter: 0; batch classifier loss: 1.059723; batch adversarial loss: 0.577659\n",
      "epoch 4; iter: 200; batch classifier loss: 2.320926; batch adversarial loss: 0.584566\n",
      "epoch 4; iter: 400; batch classifier loss: 0.471893; batch adversarial loss: 0.662546\n",
      "epoch 4; iter: 600; batch classifier loss: 0.483366; batch adversarial loss: 0.656793\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582443; batch adversarial loss: 0.530508\n",
      "epoch 5; iter: 200; batch classifier loss: 0.738496; batch adversarial loss: 0.599664\n",
      "epoch 5; iter: 400; batch classifier loss: 0.479782; batch adversarial loss: 0.644932\n",
      "epoch 5; iter: 600; batch classifier loss: 0.507522; batch adversarial loss: 0.645594\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451641; batch adversarial loss: 0.585737\n",
      "epoch 6; iter: 200; batch classifier loss: 0.461271; batch adversarial loss: 0.554843\n",
      "epoch 6; iter: 400; batch classifier loss: 0.453357; batch adversarial loss: 0.574471\n",
      "epoch 6; iter: 600; batch classifier loss: 0.382169; batch adversarial loss: 0.644269\n",
      "epoch 7; iter: 0; batch classifier loss: 0.490599; batch adversarial loss: 0.618001\n",
      "epoch 7; iter: 200; batch classifier loss: 0.335562; batch adversarial loss: 0.613311\n",
      "epoch 7; iter: 400; batch classifier loss: 0.403849; batch adversarial loss: 0.621876\n",
      "epoch 7; iter: 600; batch classifier loss: 0.417420; batch adversarial loss: 0.628999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.382819; batch adversarial loss: 0.612265\n",
      "epoch 8; iter: 200; batch classifier loss: 0.322351; batch adversarial loss: 0.549287\n",
      "epoch 8; iter: 400; batch classifier loss: 0.331242; batch adversarial loss: 0.519968\n",
      "epoch 8; iter: 600; batch classifier loss: 0.458055; batch adversarial loss: 0.722259\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320989; batch adversarial loss: 0.651649\n",
      "epoch 9; iter: 200; batch classifier loss: 0.358493; batch adversarial loss: 0.602034\n",
      "epoch 9; iter: 400; batch classifier loss: 0.390835; batch adversarial loss: 0.643117\n",
      "epoch 9; iter: 600; batch classifier loss: 0.388966; batch adversarial loss: 0.613274\n",
      "epoch 10; iter: 0; batch classifier loss: 0.316928; batch adversarial loss: 0.616005\n",
      "epoch 10; iter: 200; batch classifier loss: 0.260891; batch adversarial loss: 0.641575\n",
      "epoch 10; iter: 400; batch classifier loss: 0.388864; batch adversarial loss: 0.599632\n",
      "epoch 10; iter: 600; batch classifier loss: 0.448389; batch adversarial loss: 0.595105\n",
      "epoch 11; iter: 0; batch classifier loss: 0.341263; batch adversarial loss: 0.681253\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383303; batch adversarial loss: 0.592819\n",
      "epoch 11; iter: 400; batch classifier loss: 0.331391; batch adversarial loss: 0.655870\n",
      "epoch 11; iter: 600; batch classifier loss: 0.338485; batch adversarial loss: 0.564342\n",
      "epoch 12; iter: 0; batch classifier loss: 0.386986; batch adversarial loss: 0.620346\n",
      "epoch 12; iter: 200; batch classifier loss: 0.265575; batch adversarial loss: 0.673097\n",
      "epoch 12; iter: 400; batch classifier loss: 0.473901; batch adversarial loss: 0.626659\n",
      "epoch 12; iter: 600; batch classifier loss: 0.772301; batch adversarial loss: 0.663470\n",
      "epoch 13; iter: 0; batch classifier loss: 0.257870; batch adversarial loss: 0.729600\n",
      "epoch 13; iter: 200; batch classifier loss: 0.340192; batch adversarial loss: 0.632771\n",
      "epoch 13; iter: 400; batch classifier loss: 0.410163; batch adversarial loss: 0.604634\n",
      "epoch 13; iter: 600; batch classifier loss: 0.401009; batch adversarial loss: 0.667983\n",
      "epoch 14; iter: 0; batch classifier loss: 0.275630; batch adversarial loss: 0.659038\n",
      "epoch 14; iter: 200; batch classifier loss: 0.485599; batch adversarial loss: 0.529357\n",
      "epoch 14; iter: 400; batch classifier loss: 0.343946; batch adversarial loss: 0.530628\n",
      "epoch 14; iter: 600; batch classifier loss: 0.397429; batch adversarial loss: 0.575506\n",
      "epoch 15; iter: 0; batch classifier loss: 0.332251; batch adversarial loss: 0.671793\n",
      "epoch 15; iter: 200; batch classifier loss: 0.436640; batch adversarial loss: 0.684122\n",
      "epoch 15; iter: 400; batch classifier loss: 0.325897; batch adversarial loss: 0.623891\n",
      "epoch 15; iter: 600; batch classifier loss: 0.464887; batch adversarial loss: 0.618935\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475152; batch adversarial loss: 0.642389\n",
      "epoch 16; iter: 200; batch classifier loss: 0.328310; batch adversarial loss: 0.672842\n",
      "epoch 16; iter: 400; batch classifier loss: 0.270606; batch adversarial loss: 0.648929\n",
      "epoch 16; iter: 600; batch classifier loss: 0.375443; batch adversarial loss: 0.601910\n",
      "epoch 17; iter: 0; batch classifier loss: 0.555555; batch adversarial loss: 0.600641\n",
      "epoch 17; iter: 200; batch classifier loss: 0.298346; batch adversarial loss: 0.651725\n",
      "epoch 17; iter: 400; batch classifier loss: 0.443041; batch adversarial loss: 0.611825\n",
      "epoch 17; iter: 600; batch classifier loss: 0.603857; batch adversarial loss: 0.638290\n",
      "epoch 18; iter: 0; batch classifier loss: 0.478689; batch adversarial loss: 0.607107\n",
      "epoch 18; iter: 200; batch classifier loss: 0.439913; batch adversarial loss: 0.551054\n",
      "epoch 18; iter: 400; batch classifier loss: 0.433466; batch adversarial loss: 0.635388\n",
      "epoch 18; iter: 600; batch classifier loss: 0.348694; batch adversarial loss: 0.588047\n",
      "epoch 19; iter: 0; batch classifier loss: 0.413256; batch adversarial loss: 0.621861\n",
      "epoch 19; iter: 200; batch classifier loss: 0.585126; batch adversarial loss: 0.570206\n",
      "epoch 19; iter: 400; batch classifier loss: 0.562968; batch adversarial loss: 0.578271\n",
      "epoch 19; iter: 600; batch classifier loss: 0.289480; batch adversarial loss: 0.631824\n",
      "epoch 0; iter: 0; batch classifier loss: 10.025748; batch adversarial loss: 0.683266\n",
      "epoch 0; iter: 200; batch classifier loss: 45.614182; batch adversarial loss: 0.627402\n",
      "epoch 0; iter: 400; batch classifier loss: 1.606749; batch adversarial loss: 0.622680\n",
      "epoch 0; iter: 600; batch classifier loss: 7.744865; batch adversarial loss: 0.652238\n",
      "epoch 1; iter: 0; batch classifier loss: 7.928212; batch adversarial loss: 0.608337\n",
      "epoch 1; iter: 200; batch classifier loss: 7.965200; batch adversarial loss: 0.615427\n",
      "epoch 1; iter: 400; batch classifier loss: 6.684179; batch adversarial loss: 0.598850\n",
      "epoch 1; iter: 600; batch classifier loss: 2.902599; batch adversarial loss: 0.768107\n",
      "epoch 2; iter: 0; batch classifier loss: 13.383841; batch adversarial loss: 0.598761\n",
      "epoch 2; iter: 200; batch classifier loss: 3.967461; batch adversarial loss: 0.652549\n",
      "epoch 2; iter: 400; batch classifier loss: 1.393602; batch adversarial loss: 0.608572\n",
      "epoch 2; iter: 600; batch classifier loss: 2.729826; batch adversarial loss: 0.601794\n",
      "epoch 3; iter: 0; batch classifier loss: 2.507068; batch adversarial loss: 0.653130\n",
      "epoch 3; iter: 200; batch classifier loss: 1.206932; batch adversarial loss: 0.609167\n",
      "epoch 3; iter: 400; batch classifier loss: 2.994815; batch adversarial loss: 0.694835\n",
      "epoch 3; iter: 600; batch classifier loss: 0.926001; batch adversarial loss: 0.603277\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574148; batch adversarial loss: 0.649078\n",
      "epoch 4; iter: 200; batch classifier loss: 0.533013; batch adversarial loss: 0.618694\n",
      "epoch 4; iter: 400; batch classifier loss: 0.343345; batch adversarial loss: 0.709164\n",
      "epoch 4; iter: 600; batch classifier loss: 0.490561; batch adversarial loss: 0.652321\n",
      "epoch 5; iter: 0; batch classifier loss: 0.723931; batch adversarial loss: 0.586313\n",
      "epoch 5; iter: 200; batch classifier loss: 0.540946; batch adversarial loss: 0.568956\n",
      "epoch 5; iter: 400; batch classifier loss: 0.414281; batch adversarial loss: 0.690146\n",
      "epoch 5; iter: 600; batch classifier loss: 0.475403; batch adversarial loss: 0.632767\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496415; batch adversarial loss: 0.745390\n",
      "epoch 6; iter: 200; batch classifier loss: 0.785181; batch adversarial loss: 0.567489\n",
      "epoch 6; iter: 400; batch classifier loss: 0.430777; batch adversarial loss: 0.572994\n",
      "epoch 6; iter: 600; batch classifier loss: 0.361229; batch adversarial loss: 0.588509\n",
      "epoch 7; iter: 0; batch classifier loss: 0.294836; batch adversarial loss: 0.763666\n",
      "epoch 7; iter: 200; batch classifier loss: 0.300592; batch adversarial loss: 0.551399\n",
      "epoch 7; iter: 400; batch classifier loss: 0.358816; batch adversarial loss: 0.562106\n",
      "epoch 7; iter: 600; batch classifier loss: 0.390610; batch adversarial loss: 0.604658\n",
      "epoch 8; iter: 0; batch classifier loss: 0.249347; batch adversarial loss: 0.663200\n",
      "epoch 8; iter: 200; batch classifier loss: 0.424137; batch adversarial loss: 0.593324\n",
      "epoch 8; iter: 400; batch classifier loss: 0.465547; batch adversarial loss: 0.520206\n",
      "epoch 8; iter: 600; batch classifier loss: 0.308078; batch adversarial loss: 0.730452\n",
      "epoch 9; iter: 0; batch classifier loss: 0.354505; batch adversarial loss: 0.626924\n",
      "epoch 9; iter: 200; batch classifier loss: 0.247341; batch adversarial loss: 0.616840\n",
      "epoch 9; iter: 400; batch classifier loss: 0.422922; batch adversarial loss: 0.668802\n",
      "epoch 9; iter: 600; batch classifier loss: 0.760689; batch adversarial loss: 0.581162\n",
      "epoch 10; iter: 0; batch classifier loss: 0.383644; batch adversarial loss: 0.655635\n",
      "epoch 10; iter: 200; batch classifier loss: 0.462097; batch adversarial loss: 0.642942\n",
      "epoch 10; iter: 400; batch classifier loss: 0.356778; batch adversarial loss: 0.645407\n",
      "epoch 10; iter: 600; batch classifier loss: 0.293171; batch adversarial loss: 0.658473\n",
      "epoch 11; iter: 0; batch classifier loss: 0.439704; batch adversarial loss: 0.614286\n",
      "epoch 11; iter: 200; batch classifier loss: 0.459477; batch adversarial loss: 0.589972\n",
      "epoch 11; iter: 400; batch classifier loss: 0.440358; batch adversarial loss: 0.581714\n",
      "epoch 11; iter: 600; batch classifier loss: 0.402303; batch adversarial loss: 0.608594\n",
      "epoch 12; iter: 0; batch classifier loss: 0.251118; batch adversarial loss: 0.642053\n",
      "epoch 12; iter: 200; batch classifier loss: 0.428677; batch adversarial loss: 0.589041\n",
      "epoch 12; iter: 400; batch classifier loss: 0.364773; batch adversarial loss: 0.674034\n",
      "epoch 12; iter: 600; batch classifier loss: 0.227846; batch adversarial loss: 0.547313\n",
      "epoch 13; iter: 0; batch classifier loss: 0.302978; batch adversarial loss: 0.597384\n",
      "epoch 13; iter: 200; batch classifier loss: 0.271892; batch adversarial loss: 0.595920\n",
      "epoch 13; iter: 400; batch classifier loss: 0.535695; batch adversarial loss: 0.645316\n",
      "epoch 13; iter: 600; batch classifier loss: 0.494010; batch adversarial loss: 0.557670\n",
      "epoch 14; iter: 0; batch classifier loss: 0.420464; batch adversarial loss: 0.652580\n",
      "epoch 14; iter: 200; batch classifier loss: 0.380179; batch adversarial loss: 0.638191\n",
      "epoch 14; iter: 400; batch classifier loss: 0.364724; batch adversarial loss: 0.695677\n",
      "epoch 14; iter: 600; batch classifier loss: 0.433695; batch adversarial loss: 0.649524\n",
      "epoch 15; iter: 0; batch classifier loss: 0.298891; batch adversarial loss: 0.634966\n",
      "epoch 15; iter: 200; batch classifier loss: 0.490483; batch adversarial loss: 0.608524\n",
      "epoch 15; iter: 400; batch classifier loss: 0.326613; batch adversarial loss: 0.595517\n",
      "epoch 15; iter: 600; batch classifier loss: 0.518169; batch adversarial loss: 0.702920\n",
      "epoch 16; iter: 0; batch classifier loss: 0.418077; batch adversarial loss: 0.606933\n",
      "epoch 16; iter: 200; batch classifier loss: 0.673444; batch adversarial loss: 0.572119\n",
      "epoch 16; iter: 400; batch classifier loss: 0.297821; batch adversarial loss: 0.670968\n",
      "epoch 16; iter: 600; batch classifier loss: 0.562249; batch adversarial loss: 0.613430\n",
      "epoch 17; iter: 0; batch classifier loss: 0.251062; batch adversarial loss: 0.675663\n",
      "epoch 17; iter: 200; batch classifier loss: 0.253155; batch adversarial loss: 0.621684\n",
      "epoch 17; iter: 400; batch classifier loss: 0.450468; batch adversarial loss: 0.581306\n",
      "epoch 17; iter: 600; batch classifier loss: 0.526142; batch adversarial loss: 0.644473\n",
      "epoch 18; iter: 0; batch classifier loss: 0.294778; batch adversarial loss: 0.689320\n",
      "epoch 18; iter: 200; batch classifier loss: 0.358619; batch adversarial loss: 0.567146\n",
      "epoch 18; iter: 400; batch classifier loss: 0.471392; batch adversarial loss: 0.633597\n",
      "epoch 18; iter: 600; batch classifier loss: 0.609417; batch adversarial loss: 0.575395\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462852; batch adversarial loss: 0.651452\n",
      "epoch 19; iter: 200; batch classifier loss: 0.409057; batch adversarial loss: 0.637440\n",
      "epoch 19; iter: 400; batch classifier loss: 0.583183; batch adversarial loss: 0.762426\n",
      "epoch 19; iter: 600; batch classifier loss: 0.325737; batch adversarial loss: 0.625855\n",
      "epoch 0; iter: 0; batch classifier loss: 6.834121; batch adversarial loss: 0.693381\n",
      "epoch 0; iter: 200; batch classifier loss: 7.201898; batch adversarial loss: 0.641954\n",
      "epoch 0; iter: 400; batch classifier loss: 12.829220; batch adversarial loss: 0.663882\n",
      "epoch 0; iter: 600; batch classifier loss: 0.955826; batch adversarial loss: 0.612898\n",
      "epoch 1; iter: 0; batch classifier loss: 5.732131; batch adversarial loss: 0.638486\n",
      "epoch 1; iter: 200; batch classifier loss: 8.546108; batch adversarial loss: 0.579981\n",
      "epoch 1; iter: 400; batch classifier loss: 5.143913; batch adversarial loss: 0.630150\n",
      "epoch 1; iter: 600; batch classifier loss: 4.387454; batch adversarial loss: 0.620873\n",
      "epoch 2; iter: 0; batch classifier loss: 2.108375; batch adversarial loss: 0.647473\n",
      "epoch 2; iter: 200; batch classifier loss: 11.339998; batch adversarial loss: 0.620608\n",
      "epoch 2; iter: 400; batch classifier loss: 9.573986; batch adversarial loss: 0.619323\n",
      "epoch 2; iter: 600; batch classifier loss: 1.112261; batch adversarial loss: 0.599242\n",
      "epoch 3; iter: 0; batch classifier loss: 3.713379; batch adversarial loss: 0.647704\n",
      "epoch 3; iter: 200; batch classifier loss: 1.238091; batch adversarial loss: 0.658642\n",
      "epoch 3; iter: 400; batch classifier loss: 1.336302; batch adversarial loss: 0.678605\n",
      "epoch 3; iter: 600; batch classifier loss: 1.540095; batch adversarial loss: 0.620492\n",
      "epoch 4; iter: 0; batch classifier loss: 2.629548; batch adversarial loss: 0.668185\n",
      "epoch 4; iter: 200; batch classifier loss: 0.871660; batch adversarial loss: 0.542798\n",
      "epoch 4; iter: 400; batch classifier loss: 0.628164; batch adversarial loss: 0.588523\n",
      "epoch 4; iter: 600; batch classifier loss: 0.388102; batch adversarial loss: 0.641400\n",
      "epoch 5; iter: 0; batch classifier loss: 0.435347; batch adversarial loss: 0.547218\n",
      "epoch 5; iter: 200; batch classifier loss: 0.519674; batch adversarial loss: 0.583941\n",
      "epoch 5; iter: 400; batch classifier loss: 0.666561; batch adversarial loss: 0.592221\n",
      "epoch 5; iter: 600; batch classifier loss: 0.425195; batch adversarial loss: 0.618150\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402545; batch adversarial loss: 0.581857\n",
      "epoch 6; iter: 200; batch classifier loss: 0.321130; batch adversarial loss: 0.719867\n",
      "epoch 6; iter: 400; batch classifier loss: 0.346019; batch adversarial loss: 0.673528\n",
      "epoch 6; iter: 600; batch classifier loss: 0.404207; batch adversarial loss: 0.669599\n",
      "epoch 7; iter: 0; batch classifier loss: 0.392522; batch adversarial loss: 0.610066\n",
      "epoch 7; iter: 200; batch classifier loss: 0.594387; batch adversarial loss: 0.612132\n",
      "epoch 7; iter: 400; batch classifier loss: 0.447050; batch adversarial loss: 0.570124\n",
      "epoch 7; iter: 600; batch classifier loss: 0.392575; batch adversarial loss: 0.630468\n",
      "epoch 8; iter: 0; batch classifier loss: 0.216278; batch adversarial loss: 0.713497\n",
      "epoch 8; iter: 200; batch classifier loss: 0.306640; batch adversarial loss: 0.604687\n",
      "epoch 8; iter: 400; batch classifier loss: 0.351357; batch adversarial loss: 0.607061\n",
      "epoch 8; iter: 600; batch classifier loss: 0.445786; batch adversarial loss: 0.636293\n",
      "epoch 9; iter: 0; batch classifier loss: 0.356574; batch adversarial loss: 0.611884\n",
      "epoch 9; iter: 200; batch classifier loss: 0.397670; batch adversarial loss: 0.573124\n",
      "epoch 9; iter: 400; batch classifier loss: 0.314942; batch adversarial loss: 0.630349\n",
      "epoch 9; iter: 600; batch classifier loss: 0.295567; batch adversarial loss: 0.569778\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407833; batch adversarial loss: 0.619129\n",
      "epoch 10; iter: 200; batch classifier loss: 0.191399; batch adversarial loss: 0.710500\n",
      "epoch 10; iter: 400; batch classifier loss: 0.564095; batch adversarial loss: 0.659344\n",
      "epoch 10; iter: 600; batch classifier loss: 0.282370; batch adversarial loss: 0.705537\n",
      "epoch 11; iter: 0; batch classifier loss: 0.275409; batch adversarial loss: 0.550156\n",
      "epoch 11; iter: 200; batch classifier loss: 0.479505; batch adversarial loss: 0.645765\n",
      "epoch 11; iter: 400; batch classifier loss: 0.401063; batch adversarial loss: 0.612738\n",
      "epoch 11; iter: 600; batch classifier loss: 0.423896; batch adversarial loss: 0.618953\n",
      "epoch 12; iter: 0; batch classifier loss: 0.326244; batch adversarial loss: 0.719238\n",
      "epoch 12; iter: 200; batch classifier loss: 0.522144; batch adversarial loss: 0.499812\n",
      "epoch 12; iter: 400; batch classifier loss: 0.281477; batch adversarial loss: 0.665643\n",
      "epoch 12; iter: 600; batch classifier loss: 0.244345; batch adversarial loss: 0.665837\n",
      "epoch 13; iter: 0; batch classifier loss: 0.617493; batch adversarial loss: 0.614311\n",
      "epoch 13; iter: 200; batch classifier loss: 0.406706; batch adversarial loss: 0.589631\n",
      "epoch 13; iter: 400; batch classifier loss: 0.355654; batch adversarial loss: 0.624859\n",
      "epoch 13; iter: 600; batch classifier loss: 0.306588; batch adversarial loss: 0.587173\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325492; batch adversarial loss: 0.690574\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388151; batch adversarial loss: 0.731367\n",
      "epoch 14; iter: 400; batch classifier loss: 0.260330; batch adversarial loss: 0.718316\n",
      "epoch 14; iter: 600; batch classifier loss: 0.379016; batch adversarial loss: 0.610645\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541412; batch adversarial loss: 0.657961\n",
      "epoch 15; iter: 200; batch classifier loss: 0.410949; batch adversarial loss: 0.649463\n",
      "epoch 15; iter: 400; batch classifier loss: 0.512991; batch adversarial loss: 0.626097\n",
      "epoch 15; iter: 600; batch classifier loss: 0.272541; batch adversarial loss: 0.682759\n",
      "epoch 16; iter: 0; batch classifier loss: 0.270647; batch adversarial loss: 0.677136\n",
      "epoch 16; iter: 200; batch classifier loss: 0.342821; batch adversarial loss: 0.644307\n",
      "epoch 16; iter: 400; batch classifier loss: 0.392368; batch adversarial loss: 0.624681\n",
      "epoch 16; iter: 600; batch classifier loss: 0.439142; batch adversarial loss: 0.642024\n",
      "epoch 17; iter: 0; batch classifier loss: 0.286577; batch adversarial loss: 0.720178\n",
      "epoch 17; iter: 200; batch classifier loss: 0.357183; batch adversarial loss: 0.631910\n",
      "epoch 17; iter: 400; batch classifier loss: 0.398812; batch adversarial loss: 0.591985\n",
      "epoch 17; iter: 600; batch classifier loss: 0.492969; batch adversarial loss: 0.591424\n",
      "epoch 18; iter: 0; batch classifier loss: 0.628213; batch adversarial loss: 0.623853\n",
      "epoch 18; iter: 200; batch classifier loss: 0.327525; batch adversarial loss: 0.642009\n",
      "epoch 18; iter: 400; batch classifier loss: 0.497099; batch adversarial loss: 0.624793\n",
      "epoch 18; iter: 600; batch classifier loss: 0.271546; batch adversarial loss: 0.570058\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481029; batch adversarial loss: 0.639597\n",
      "epoch 19; iter: 200; batch classifier loss: 0.334956; batch adversarial loss: 0.639912\n",
      "epoch 19; iter: 400; batch classifier loss: 0.450854; batch adversarial loss: 0.678153\n",
      "epoch 19; iter: 600; batch classifier loss: 0.383567; batch adversarial loss: 0.622155\n",
      "epoch 0; iter: 0; batch classifier loss: 214.714050; batch adversarial loss: 0.710041\n",
      "epoch 0; iter: 200; batch classifier loss: 3.863515; batch adversarial loss: 0.681109\n",
      "epoch 0; iter: 400; batch classifier loss: 5.589456; batch adversarial loss: 0.659657\n",
      "epoch 0; iter: 600; batch classifier loss: 0.433649; batch adversarial loss: 0.634664\n",
      "epoch 1; iter: 0; batch classifier loss: 13.851988; batch adversarial loss: 0.621893\n",
      "epoch 1; iter: 200; batch classifier loss: 7.072416; batch adversarial loss: 0.640763\n",
      "epoch 1; iter: 400; batch classifier loss: 3.716528; batch adversarial loss: 0.576867\n",
      "epoch 1; iter: 600; batch classifier loss: 1.935082; batch adversarial loss: 0.670453\n",
      "epoch 2; iter: 0; batch classifier loss: 5.861907; batch adversarial loss: 0.587825\n",
      "epoch 2; iter: 200; batch classifier loss: 6.645288; batch adversarial loss: 0.694004\n",
      "epoch 2; iter: 400; batch classifier loss: 0.332984; batch adversarial loss: 0.673255\n",
      "epoch 2; iter: 600; batch classifier loss: 2.204834; batch adversarial loss: 0.625220\n",
      "epoch 3; iter: 0; batch classifier loss: 0.685231; batch adversarial loss: 0.613842\n",
      "epoch 3; iter: 200; batch classifier loss: 1.515962; batch adversarial loss: 0.648130\n",
      "epoch 3; iter: 400; batch classifier loss: 3.389013; batch adversarial loss: 0.599415\n",
      "epoch 3; iter: 600; batch classifier loss: 1.279619; batch adversarial loss: 0.612666\n",
      "epoch 4; iter: 0; batch classifier loss: 1.410281; batch adversarial loss: 0.594293\n",
      "epoch 4; iter: 200; batch classifier loss: 0.677439; batch adversarial loss: 0.587051\n",
      "epoch 4; iter: 400; batch classifier loss: 0.894780; batch adversarial loss: 0.697488\n",
      "epoch 4; iter: 600; batch classifier loss: 0.416444; batch adversarial loss: 0.638570\n",
      "epoch 5; iter: 0; batch classifier loss: 0.503833; batch adversarial loss: 0.583751\n",
      "epoch 5; iter: 200; batch classifier loss: 0.423278; batch adversarial loss: 0.557160\n",
      "epoch 5; iter: 400; batch classifier loss: 0.336605; batch adversarial loss: 0.559909\n",
      "epoch 5; iter: 600; batch classifier loss: 0.368453; batch adversarial loss: 0.603364\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521390; batch adversarial loss: 0.616243\n",
      "epoch 6; iter: 200; batch classifier loss: 0.441566; batch adversarial loss: 0.613639\n",
      "epoch 6; iter: 400; batch classifier loss: 0.380316; batch adversarial loss: 0.538779\n",
      "epoch 6; iter: 600; batch classifier loss: 0.272233; batch adversarial loss: 0.657935\n",
      "epoch 7; iter: 0; batch classifier loss: 0.428989; batch adversarial loss: 0.647889\n",
      "epoch 7; iter: 200; batch classifier loss: 0.402748; batch adversarial loss: 0.669290\n",
      "epoch 7; iter: 400; batch classifier loss: 0.354468; batch adversarial loss: 0.626968\n",
      "epoch 7; iter: 600; batch classifier loss: 0.397336; batch adversarial loss: 0.687420\n",
      "epoch 8; iter: 0; batch classifier loss: 0.292057; batch adversarial loss: 0.681442\n",
      "epoch 8; iter: 200; batch classifier loss: 0.560392; batch adversarial loss: 0.684201\n",
      "epoch 8; iter: 400; batch classifier loss: 0.385575; batch adversarial loss: 0.660765\n",
      "epoch 8; iter: 600; batch classifier loss: 0.318947; batch adversarial loss: 0.599955\n",
      "epoch 9; iter: 0; batch classifier loss: 0.332263; batch adversarial loss: 0.614368\n",
      "epoch 9; iter: 200; batch classifier loss: 0.397149; batch adversarial loss: 0.655279\n",
      "epoch 9; iter: 400; batch classifier loss: 0.320074; batch adversarial loss: 0.541626\n",
      "epoch 9; iter: 600; batch classifier loss: 0.294866; batch adversarial loss: 0.622185\n",
      "epoch 10; iter: 0; batch classifier loss: 0.262038; batch adversarial loss: 0.676779\n",
      "epoch 10; iter: 200; batch classifier loss: 0.260068; batch adversarial loss: 0.660452\n",
      "epoch 10; iter: 400; batch classifier loss: 0.401100; batch adversarial loss: 0.517079\n",
      "epoch 10; iter: 600; batch classifier loss: 0.265324; batch adversarial loss: 0.627301\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424497; batch adversarial loss: 0.591620\n",
      "epoch 11; iter: 200; batch classifier loss: 0.463477; batch adversarial loss: 0.621555\n",
      "epoch 11; iter: 400; batch classifier loss: 0.363392; batch adversarial loss: 0.610396\n",
      "epoch 11; iter: 600; batch classifier loss: 0.349183; batch adversarial loss: 0.664083\n",
      "epoch 12; iter: 0; batch classifier loss: 0.454838; batch adversarial loss: 0.696199\n",
      "epoch 12; iter: 200; batch classifier loss: 0.330630; batch adversarial loss: 0.630174\n",
      "epoch 12; iter: 400; batch classifier loss: 0.362738; batch adversarial loss: 0.566966\n",
      "epoch 12; iter: 600; batch classifier loss: 0.245460; batch adversarial loss: 0.664074\n",
      "epoch 13; iter: 0; batch classifier loss: 0.292311; batch adversarial loss: 0.641362\n",
      "epoch 13; iter: 200; batch classifier loss: 0.397233; batch adversarial loss: 0.682618\n",
      "epoch 13; iter: 400; batch classifier loss: 0.359890; batch adversarial loss: 0.618461\n",
      "epoch 13; iter: 600; batch classifier loss: 0.413531; batch adversarial loss: 0.654798\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432507; batch adversarial loss: 0.600980\n",
      "epoch 14; iter: 200; batch classifier loss: 0.287548; batch adversarial loss: 0.720219\n",
      "epoch 14; iter: 400; batch classifier loss: 0.383273; batch adversarial loss: 0.728458\n",
      "epoch 14; iter: 600; batch classifier loss: 0.303326; batch adversarial loss: 0.655137\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442698; batch adversarial loss: 0.584964\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430963; batch adversarial loss: 0.724623\n",
      "epoch 15; iter: 400; batch classifier loss: 0.420125; batch adversarial loss: 0.660602\n",
      "epoch 15; iter: 600; batch classifier loss: 0.340985; batch adversarial loss: 0.548236\n",
      "epoch 16; iter: 0; batch classifier loss: 0.603664; batch adversarial loss: 0.575369\n",
      "epoch 16; iter: 200; batch classifier loss: 0.333257; batch adversarial loss: 0.639130\n",
      "epoch 16; iter: 400; batch classifier loss: 0.316280; batch adversarial loss: 0.706756\n",
      "epoch 16; iter: 600; batch classifier loss: 0.512465; batch adversarial loss: 0.681221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398079; batch adversarial loss: 0.635762\n",
      "epoch 17; iter: 200; batch classifier loss: 0.316375; batch adversarial loss: 0.665440\n",
      "epoch 17; iter: 400; batch classifier loss: 0.368410; batch adversarial loss: 0.612268\n",
      "epoch 17; iter: 600; batch classifier loss: 0.466425; batch adversarial loss: 0.633276\n",
      "epoch 18; iter: 0; batch classifier loss: 1.035268; batch adversarial loss: 0.635627\n",
      "epoch 18; iter: 200; batch classifier loss: 0.503778; batch adversarial loss: 0.675163\n",
      "epoch 18; iter: 400; batch classifier loss: 0.300593; batch adversarial loss: 0.691650\n",
      "epoch 18; iter: 600; batch classifier loss: 0.612451; batch adversarial loss: 0.648197\n",
      "epoch 19; iter: 0; batch classifier loss: 0.405192; batch adversarial loss: 0.667778\n",
      "epoch 19; iter: 200; batch classifier loss: 0.308489; batch adversarial loss: 0.624537\n",
      "epoch 19; iter: 400; batch classifier loss: 0.339033; batch adversarial loss: 0.582352\n",
      "epoch 19; iter: 600; batch classifier loss: 0.350956; batch adversarial loss: 0.604660\n",
      "epoch 0; iter: 0; batch classifier loss: 42.208862; batch adversarial loss: 0.948193\n",
      "epoch 0; iter: 200; batch classifier loss: 7.621069; batch adversarial loss: 1.089682\n",
      "epoch 0; iter: 400; batch classifier loss: 7.058950; batch adversarial loss: 0.879930\n",
      "epoch 0; iter: 600; batch classifier loss: 0.727469; batch adversarial loss: 0.755755\n",
      "epoch 1; iter: 0; batch classifier loss: 1.674480; batch adversarial loss: 0.750231\n",
      "epoch 1; iter: 200; batch classifier loss: 10.781816; batch adversarial loss: 0.738595\n",
      "epoch 1; iter: 400; batch classifier loss: 0.903798; batch adversarial loss: 0.669198\n",
      "epoch 1; iter: 600; batch classifier loss: 2.016973; batch adversarial loss: 0.661855\n",
      "epoch 2; iter: 0; batch classifier loss: 5.946985; batch adversarial loss: 0.703057\n",
      "epoch 2; iter: 200; batch classifier loss: 0.784517; batch adversarial loss: 0.594863\n",
      "epoch 2; iter: 400; batch classifier loss: 1.604501; batch adversarial loss: 0.605910\n",
      "epoch 2; iter: 600; batch classifier loss: 2.682788; batch adversarial loss: 0.652022\n",
      "epoch 3; iter: 0; batch classifier loss: 0.877505; batch adversarial loss: 0.621846\n",
      "epoch 3; iter: 200; batch classifier loss: 2.838071; batch adversarial loss: 0.630978\n",
      "epoch 3; iter: 400; batch classifier loss: 1.226260; batch adversarial loss: 0.678920\n",
      "epoch 3; iter: 600; batch classifier loss: 0.794096; batch adversarial loss: 0.662251\n",
      "epoch 4; iter: 0; batch classifier loss: 1.158392; batch adversarial loss: 0.596058\n",
      "epoch 4; iter: 200; batch classifier loss: 0.797352; batch adversarial loss: 0.550714\n",
      "epoch 4; iter: 400; batch classifier loss: 0.773657; batch adversarial loss: 0.674343\n",
      "epoch 4; iter: 600; batch classifier loss: 0.592996; batch adversarial loss: 0.671228\n",
      "epoch 5; iter: 0; batch classifier loss: 0.487655; batch adversarial loss: 0.663113\n",
      "epoch 5; iter: 200; batch classifier loss: 0.643060; batch adversarial loss: 0.635904\n",
      "epoch 5; iter: 400; batch classifier loss: 0.717411; batch adversarial loss: 0.637115\n",
      "epoch 5; iter: 600; batch classifier loss: 0.666776; batch adversarial loss: 0.623660\n",
      "epoch 6; iter: 0; batch classifier loss: 0.382581; batch adversarial loss: 0.728880\n",
      "epoch 6; iter: 200; batch classifier loss: 0.439114; batch adversarial loss: 0.628335\n",
      "epoch 6; iter: 400; batch classifier loss: 0.551247; batch adversarial loss: 0.597626\n",
      "epoch 6; iter: 600; batch classifier loss: 0.449543; batch adversarial loss: 0.589293\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491497; batch adversarial loss: 0.641573\n",
      "epoch 7; iter: 200; batch classifier loss: 0.418184; batch adversarial loss: 0.599714\n",
      "epoch 7; iter: 400; batch classifier loss: 0.313496; batch adversarial loss: 0.684200\n",
      "epoch 7; iter: 600; batch classifier loss: 0.554313; batch adversarial loss: 0.622089\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421270; batch adversarial loss: 0.629924\n",
      "epoch 8; iter: 200; batch classifier loss: 0.395792; batch adversarial loss: 0.595498\n",
      "epoch 8; iter: 400; batch classifier loss: 0.444631; batch adversarial loss: 0.628640\n",
      "epoch 8; iter: 600; batch classifier loss: 0.364148; batch adversarial loss: 0.656780\n",
      "epoch 9; iter: 0; batch classifier loss: 0.347805; batch adversarial loss: 0.674987\n",
      "epoch 9; iter: 200; batch classifier loss: 0.348706; batch adversarial loss: 0.520681\n",
      "epoch 9; iter: 400; batch classifier loss: 0.377274; batch adversarial loss: 0.688140\n",
      "epoch 9; iter: 600; batch classifier loss: 0.359115; batch adversarial loss: 0.697764\n",
      "epoch 10; iter: 0; batch classifier loss: 0.443203; batch adversarial loss: 0.590403\n",
      "epoch 10; iter: 200; batch classifier loss: 0.423919; batch adversarial loss: 0.650128\n",
      "epoch 10; iter: 400; batch classifier loss: 0.291069; batch adversarial loss: 0.541713\n",
      "epoch 10; iter: 600; batch classifier loss: 0.339107; batch adversarial loss: 0.629625\n",
      "epoch 11; iter: 0; batch classifier loss: 0.273423; batch adversarial loss: 0.575964\n",
      "epoch 11; iter: 200; batch classifier loss: 0.319071; batch adversarial loss: 0.625032\n",
      "epoch 11; iter: 400; batch classifier loss: 0.440469; batch adversarial loss: 0.619625\n",
      "epoch 11; iter: 600; batch classifier loss: 0.339368; batch adversarial loss: 0.559995\n",
      "epoch 12; iter: 0; batch classifier loss: 0.420257; batch adversarial loss: 0.656899\n",
      "epoch 12; iter: 200; batch classifier loss: 0.418989; batch adversarial loss: 0.693413\n",
      "epoch 12; iter: 400; batch classifier loss: 0.379781; batch adversarial loss: 0.602463\n",
      "epoch 12; iter: 600; batch classifier loss: 0.314754; batch adversarial loss: 0.609724\n",
      "epoch 13; iter: 0; batch classifier loss: 0.336226; batch adversarial loss: 0.610726\n",
      "epoch 13; iter: 200; batch classifier loss: 0.409979; batch adversarial loss: 0.656764\n",
      "epoch 13; iter: 400; batch classifier loss: 0.385935; batch adversarial loss: 0.549767\n",
      "epoch 13; iter: 600; batch classifier loss: 0.438658; batch adversarial loss: 0.547422\n",
      "epoch 14; iter: 0; batch classifier loss: 0.365343; batch adversarial loss: 0.642090\n",
      "epoch 14; iter: 200; batch classifier loss: 0.489096; batch adversarial loss: 0.649624\n",
      "epoch 14; iter: 400; batch classifier loss: 0.484922; batch adversarial loss: 0.588068\n",
      "epoch 14; iter: 600; batch classifier loss: 0.595156; batch adversarial loss: 0.588681\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457241; batch adversarial loss: 0.731662\n",
      "epoch 15; iter: 200; batch classifier loss: 0.423261; batch adversarial loss: 0.564825\n",
      "epoch 15; iter: 400; batch classifier loss: 0.601620; batch adversarial loss: 0.594155\n",
      "epoch 15; iter: 600; batch classifier loss: 0.592936; batch adversarial loss: 0.572167\n",
      "epoch 16; iter: 0; batch classifier loss: 0.434224; batch adversarial loss: 0.660600\n",
      "epoch 16; iter: 200; batch classifier loss: 0.474475; batch adversarial loss: 0.609492\n",
      "epoch 16; iter: 400; batch classifier loss: 0.427747; batch adversarial loss: 0.630125\n",
      "epoch 16; iter: 600; batch classifier loss: 0.499920; batch adversarial loss: 0.604453\n",
      "epoch 17; iter: 0; batch classifier loss: 0.602887; batch adversarial loss: 0.641159\n",
      "epoch 17; iter: 200; batch classifier loss: 0.571515; batch adversarial loss: 0.695431\n",
      "epoch 17; iter: 400; batch classifier loss: 0.410968; batch adversarial loss: 0.612286\n",
      "epoch 17; iter: 600; batch classifier loss: 0.633577; batch adversarial loss: 0.519007\n",
      "epoch 18; iter: 0; batch classifier loss: 0.234369; batch adversarial loss: 0.657180\n",
      "epoch 18; iter: 200; batch classifier loss: 0.668392; batch adversarial loss: 0.672880\n",
      "epoch 18; iter: 400; batch classifier loss: 0.764251; batch adversarial loss: 0.624411\n",
      "epoch 18; iter: 600; batch classifier loss: 0.397837; batch adversarial loss: 0.584788\n",
      "epoch 19; iter: 0; batch classifier loss: 0.679340; batch adversarial loss: 0.695992\n",
      "epoch 19; iter: 200; batch classifier loss: 0.661693; batch adversarial loss: 0.667821\n",
      "epoch 19; iter: 400; batch classifier loss: 0.430691; batch adversarial loss: 0.662549\n",
      "epoch 19; iter: 600; batch classifier loss: 0.626596; batch adversarial loss: 0.700931\n",
      "epoch 0; iter: 0; batch classifier loss: 46.645676; batch adversarial loss: 0.658345\n",
      "epoch 0; iter: 200; batch classifier loss: 9.154077; batch adversarial loss: 0.687659\n",
      "epoch 0; iter: 400; batch classifier loss: 0.702399; batch adversarial loss: 0.640315\n",
      "epoch 0; iter: 600; batch classifier loss: 85.767830; batch adversarial loss: 0.559339\n",
      "epoch 1; iter: 0; batch classifier loss: 3.139320; batch adversarial loss: 0.695384\n",
      "epoch 1; iter: 200; batch classifier loss: 7.197842; batch adversarial loss: 0.675508\n",
      "epoch 1; iter: 400; batch classifier loss: 0.430706; batch adversarial loss: 0.610499\n",
      "epoch 1; iter: 600; batch classifier loss: 2.419381; batch adversarial loss: 0.566650\n",
      "epoch 2; iter: 0; batch classifier loss: 5.287396; batch adversarial loss: 0.641305\n",
      "epoch 2; iter: 200; batch classifier loss: 0.668529; batch adversarial loss: 0.561640\n",
      "epoch 2; iter: 400; batch classifier loss: 1.930768; batch adversarial loss: 0.618151\n",
      "epoch 2; iter: 600; batch classifier loss: 1.421219; batch adversarial loss: 0.667015\n",
      "epoch 3; iter: 0; batch classifier loss: 1.613462; batch adversarial loss: 0.631056\n",
      "epoch 3; iter: 200; batch classifier loss: 2.529511; batch adversarial loss: 0.643714\n",
      "epoch 3; iter: 400; batch classifier loss: 0.578651; batch adversarial loss: 0.646948\n",
      "epoch 3; iter: 600; batch classifier loss: 1.836511; batch adversarial loss: 0.564570\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594724; batch adversarial loss: 0.666978\n",
      "epoch 4; iter: 200; batch classifier loss: 0.872862; batch adversarial loss: 0.578392\n",
      "epoch 4; iter: 400; batch classifier loss: 0.588226; batch adversarial loss: 0.614352\n",
      "epoch 4; iter: 600; batch classifier loss: 0.415961; batch adversarial loss: 0.586659\n",
      "epoch 5; iter: 0; batch classifier loss: 0.419306; batch adversarial loss: 0.546814\n",
      "epoch 5; iter: 200; batch classifier loss: 0.705961; batch adversarial loss: 0.658669\n",
      "epoch 5; iter: 400; batch classifier loss: 0.549813; batch adversarial loss: 0.596965\n",
      "epoch 5; iter: 600; batch classifier loss: 0.427315; batch adversarial loss: 0.677564\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533350; batch adversarial loss: 0.624503\n",
      "epoch 6; iter: 200; batch classifier loss: 0.330622; batch adversarial loss: 0.741769\n",
      "epoch 6; iter: 400; batch classifier loss: 0.471950; batch adversarial loss: 0.614850\n",
      "epoch 6; iter: 600; batch classifier loss: 0.469006; batch adversarial loss: 0.597974\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296809; batch adversarial loss: 0.667061\n",
      "epoch 7; iter: 200; batch classifier loss: 0.262899; batch adversarial loss: 0.552821\n",
      "epoch 7; iter: 400; batch classifier loss: 0.413530; batch adversarial loss: 0.594768\n",
      "epoch 7; iter: 600; batch classifier loss: 0.288840; batch adversarial loss: 0.678640\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428290; batch adversarial loss: 0.678797\n",
      "epoch 8; iter: 200; batch classifier loss: 0.465233; batch adversarial loss: 0.611717\n",
      "epoch 8; iter: 400; batch classifier loss: 0.414548; batch adversarial loss: 0.523707\n",
      "epoch 8; iter: 600; batch classifier loss: 0.404922; batch adversarial loss: 0.597071\n",
      "epoch 9; iter: 0; batch classifier loss: 0.377032; batch adversarial loss: 0.600352\n",
      "epoch 9; iter: 200; batch classifier loss: 0.483022; batch adversarial loss: 0.674158\n",
      "epoch 9; iter: 400; batch classifier loss: 0.365391; batch adversarial loss: 0.575902\n",
      "epoch 9; iter: 600; batch classifier loss: 0.376196; batch adversarial loss: 0.702427\n",
      "epoch 10; iter: 0; batch classifier loss: 0.297455; batch adversarial loss: 0.597401\n",
      "epoch 10; iter: 200; batch classifier loss: 0.392172; batch adversarial loss: 0.652845\n",
      "epoch 10; iter: 400; batch classifier loss: 0.359403; batch adversarial loss: 0.686462\n",
      "epoch 10; iter: 600; batch classifier loss: 0.262681; batch adversarial loss: 0.591320\n",
      "epoch 11; iter: 0; batch classifier loss: 0.207816; batch adversarial loss: 0.608808\n",
      "epoch 11; iter: 200; batch classifier loss: 0.485563; batch adversarial loss: 0.633036\n",
      "epoch 11; iter: 400; batch classifier loss: 0.246418; batch adversarial loss: 0.633273\n",
      "epoch 11; iter: 600; batch classifier loss: 0.478303; batch adversarial loss: 0.585953\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428122; batch adversarial loss: 0.582549\n",
      "epoch 12; iter: 200; batch classifier loss: 0.360139; batch adversarial loss: 0.675923\n",
      "epoch 12; iter: 400; batch classifier loss: 0.356244; batch adversarial loss: 0.577375\n",
      "epoch 12; iter: 600; batch classifier loss: 0.381076; batch adversarial loss: 0.630184\n",
      "epoch 13; iter: 0; batch classifier loss: 0.395345; batch adversarial loss: 0.624623\n",
      "epoch 13; iter: 200; batch classifier loss: 0.380441; batch adversarial loss: 0.616872\n",
      "epoch 13; iter: 400; batch classifier loss: 0.436948; batch adversarial loss: 0.589279\n",
      "epoch 13; iter: 600; batch classifier loss: 0.285360; batch adversarial loss: 0.635400\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290861; batch adversarial loss: 0.545694\n",
      "epoch 14; iter: 200; batch classifier loss: 0.411651; batch adversarial loss: 0.657164\n",
      "epoch 14; iter: 400; batch classifier loss: 0.304075; batch adversarial loss: 0.595656\n",
      "epoch 14; iter: 600; batch classifier loss: 0.438966; batch adversarial loss: 0.647436\n",
      "epoch 15; iter: 0; batch classifier loss: 0.322300; batch adversarial loss: 0.639462\n",
      "epoch 15; iter: 200; batch classifier loss: 0.279643; batch adversarial loss: 0.573205\n",
      "epoch 15; iter: 400; batch classifier loss: 0.363148; batch adversarial loss: 0.660028\n",
      "epoch 15; iter: 600; batch classifier loss: 0.530697; batch adversarial loss: 0.640954\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445007; batch adversarial loss: 0.698338\n",
      "epoch 16; iter: 200; batch classifier loss: 0.360165; batch adversarial loss: 0.611391\n",
      "epoch 16; iter: 400; batch classifier loss: 0.404741; batch adversarial loss: 0.654209\n",
      "epoch 16; iter: 600; batch classifier loss: 0.556125; batch adversarial loss: 0.586873\n",
      "epoch 17; iter: 0; batch classifier loss: 0.600582; batch adversarial loss: 0.647572\n",
      "epoch 17; iter: 200; batch classifier loss: 0.355534; batch adversarial loss: 0.564490\n",
      "epoch 17; iter: 400; batch classifier loss: 0.294418; batch adversarial loss: 0.555521\n",
      "epoch 17; iter: 600; batch classifier loss: 0.533846; batch adversarial loss: 0.596265\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455358; batch adversarial loss: 0.580864\n",
      "epoch 18; iter: 200; batch classifier loss: 0.402874; batch adversarial loss: 0.529692\n",
      "epoch 18; iter: 400; batch classifier loss: 0.494706; batch adversarial loss: 0.605176\n",
      "epoch 18; iter: 600; batch classifier loss: 0.585817; batch adversarial loss: 0.598525\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471710; batch adversarial loss: 0.583665\n",
      "epoch 19; iter: 200; batch classifier loss: 0.490694; batch adversarial loss: 0.638649\n",
      "epoch 19; iter: 400; batch classifier loss: 0.523291; batch adversarial loss: 0.616245\n",
      "epoch 19; iter: 600; batch classifier loss: 0.392900; batch adversarial loss: 0.528430\n",
      "epoch 0; iter: 0; batch classifier loss: 9.212759; batch adversarial loss: 0.681432\n",
      "epoch 0; iter: 200; batch classifier loss: 18.271059; batch adversarial loss: 0.638489\n",
      "epoch 0; iter: 400; batch classifier loss: 1.798102; batch adversarial loss: 0.488843\n",
      "epoch 0; iter: 600; batch classifier loss: 25.499559; batch adversarial loss: 0.593916\n",
      "epoch 1; iter: 0; batch classifier loss: 2.202475; batch adversarial loss: 0.655410\n",
      "epoch 1; iter: 200; batch classifier loss: 6.360460; batch adversarial loss: 0.691471\n",
      "epoch 1; iter: 400; batch classifier loss: 0.776716; batch adversarial loss: 0.556700\n",
      "epoch 1; iter: 600; batch classifier loss: 0.587465; batch adversarial loss: 0.707207\n",
      "epoch 2; iter: 0; batch classifier loss: 1.758177; batch adversarial loss: 0.591847\n",
      "epoch 2; iter: 200; batch classifier loss: 3.686516; batch adversarial loss: 0.753840\n",
      "epoch 2; iter: 400; batch classifier loss: 4.365927; batch adversarial loss: 0.628299\n",
      "epoch 2; iter: 600; batch classifier loss: 1.721503; batch adversarial loss: 0.657380\n",
      "epoch 3; iter: 0; batch classifier loss: 0.358003; batch adversarial loss: 0.630410\n",
      "epoch 3; iter: 200; batch classifier loss: 0.767005; batch adversarial loss: 0.584658\n",
      "epoch 3; iter: 400; batch classifier loss: 0.574020; batch adversarial loss: 0.633218\n",
      "epoch 3; iter: 600; batch classifier loss: 0.918902; batch adversarial loss: 0.657106\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602155; batch adversarial loss: 0.613496\n",
      "epoch 4; iter: 200; batch classifier loss: 0.788394; batch adversarial loss: 0.566760\n",
      "epoch 4; iter: 400; batch classifier loss: 0.519762; batch adversarial loss: 0.612545\n",
      "epoch 4; iter: 600; batch classifier loss: 0.593950; batch adversarial loss: 0.657483\n",
      "epoch 5; iter: 0; batch classifier loss: 0.444540; batch adversarial loss: 0.547930\n",
      "epoch 5; iter: 200; batch classifier loss: 0.452309; batch adversarial loss: 0.615431\n",
      "epoch 5; iter: 400; batch classifier loss: 0.599257; batch adversarial loss: 0.613944\n",
      "epoch 5; iter: 600; batch classifier loss: 0.366851; batch adversarial loss: 0.590917\n",
      "epoch 6; iter: 0; batch classifier loss: 0.462980; batch adversarial loss: 0.747534\n",
      "epoch 6; iter: 200; batch classifier loss: 0.255340; batch adversarial loss: 0.630419\n",
      "epoch 6; iter: 400; batch classifier loss: 0.344561; batch adversarial loss: 0.680046\n",
      "epoch 6; iter: 600; batch classifier loss: 0.378590; batch adversarial loss: 0.641119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461699; batch adversarial loss: 0.646434\n",
      "epoch 7; iter: 200; batch classifier loss: 0.516455; batch adversarial loss: 0.546255\n",
      "epoch 7; iter: 400; batch classifier loss: 0.375020; batch adversarial loss: 0.658743\n",
      "epoch 7; iter: 600; batch classifier loss: 0.327592; batch adversarial loss: 0.589379\n",
      "epoch 8; iter: 0; batch classifier loss: 0.433166; batch adversarial loss: 0.732467\n",
      "epoch 8; iter: 200; batch classifier loss: 0.298563; batch adversarial loss: 0.637174\n",
      "epoch 8; iter: 400; batch classifier loss: 0.335048; batch adversarial loss: 0.593710\n",
      "epoch 8; iter: 600; batch classifier loss: 0.324528; batch adversarial loss: 0.639559\n",
      "epoch 9; iter: 0; batch classifier loss: 0.406890; batch adversarial loss: 0.643040\n",
      "epoch 9; iter: 200; batch classifier loss: 0.338114; batch adversarial loss: 0.605642\n",
      "epoch 9; iter: 400; batch classifier loss: 0.441645; batch adversarial loss: 0.621330\n",
      "epoch 9; iter: 600; batch classifier loss: 0.445727; batch adversarial loss: 0.639744\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407293; batch adversarial loss: 0.639762\n",
      "epoch 10; iter: 200; batch classifier loss: 0.590165; batch adversarial loss: 0.656722\n",
      "epoch 10; iter: 400; batch classifier loss: 0.328570; batch adversarial loss: 0.647318\n",
      "epoch 10; iter: 600; batch classifier loss: 0.645296; batch adversarial loss: 0.537967\n",
      "epoch 11; iter: 0; batch classifier loss: 0.227459; batch adversarial loss: 0.644338\n",
      "epoch 11; iter: 200; batch classifier loss: 0.385765; batch adversarial loss: 0.602951\n",
      "epoch 11; iter: 400; batch classifier loss: 0.350306; batch adversarial loss: 0.669304\n",
      "epoch 11; iter: 600; batch classifier loss: 0.458669; batch adversarial loss: 0.594813\n",
      "epoch 12; iter: 0; batch classifier loss: 0.282758; batch adversarial loss: 0.613788\n",
      "epoch 12; iter: 200; batch classifier loss: 0.381171; batch adversarial loss: 0.654174\n",
      "epoch 12; iter: 400; batch classifier loss: 0.405615; batch adversarial loss: 0.650171\n",
      "epoch 12; iter: 600; batch classifier loss: 0.430424; batch adversarial loss: 0.558338\n",
      "epoch 13; iter: 0; batch classifier loss: 0.275187; batch adversarial loss: 0.564306\n",
      "epoch 13; iter: 200; batch classifier loss: 0.524217; batch adversarial loss: 0.626305\n",
      "epoch 13; iter: 400; batch classifier loss: 0.244622; batch adversarial loss: 0.597244\n",
      "epoch 13; iter: 600; batch classifier loss: 0.440974; batch adversarial loss: 0.587673\n",
      "epoch 14; iter: 0; batch classifier loss: 0.332909; batch adversarial loss: 0.628872\n",
      "epoch 14; iter: 200; batch classifier loss: 0.378166; batch adversarial loss: 0.627386\n",
      "epoch 14; iter: 400; batch classifier loss: 0.258618; batch adversarial loss: 0.670464\n",
      "epoch 14; iter: 600; batch classifier loss: 0.534352; batch adversarial loss: 0.613653\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432089; batch adversarial loss: 0.597332\n",
      "epoch 15; iter: 200; batch classifier loss: 0.461342; batch adversarial loss: 0.662980\n",
      "epoch 15; iter: 400; batch classifier loss: 0.470165; batch adversarial loss: 0.695979\n",
      "epoch 15; iter: 600; batch classifier loss: 0.453162; batch adversarial loss: 0.627587\n",
      "epoch 16; iter: 0; batch classifier loss: 1.205452; batch adversarial loss: 0.569545\n",
      "epoch 16; iter: 200; batch classifier loss: 0.484237; batch adversarial loss: 0.576874\n",
      "epoch 16; iter: 400; batch classifier loss: 0.357446; batch adversarial loss: 0.653247\n",
      "epoch 16; iter: 600; batch classifier loss: 0.256070; batch adversarial loss: 0.684128\n",
      "epoch 17; iter: 0; batch classifier loss: 0.512118; batch adversarial loss: 0.617826\n",
      "epoch 17; iter: 200; batch classifier loss: 0.444463; batch adversarial loss: 0.590559\n",
      "epoch 17; iter: 400; batch classifier loss: 0.283378; batch adversarial loss: 0.690805\n",
      "epoch 17; iter: 600; batch classifier loss: 0.457622; batch adversarial loss: 0.674848\n",
      "epoch 18; iter: 0; batch classifier loss: 0.382524; batch adversarial loss: 0.601535\n",
      "epoch 18; iter: 200; batch classifier loss: 0.291641; batch adversarial loss: 0.666242\n",
      "epoch 18; iter: 400; batch classifier loss: 0.246599; batch adversarial loss: 0.668544\n",
      "epoch 18; iter: 600; batch classifier loss: 0.413419; batch adversarial loss: 0.614233\n",
      "epoch 19; iter: 0; batch classifier loss: 0.549236; batch adversarial loss: 0.667196\n",
      "epoch 19; iter: 200; batch classifier loss: 0.507904; batch adversarial loss: 0.637661\n",
      "epoch 19; iter: 400; batch classifier loss: 0.392568; batch adversarial loss: 0.615963\n",
      "epoch 19; iter: 600; batch classifier loss: 0.562586; batch adversarial loss: 0.658833\n",
      "epoch 0; iter: 0; batch classifier loss: 164.784103; batch adversarial loss: 0.658847\n",
      "epoch 0; iter: 200; batch classifier loss: 4.515096; batch adversarial loss: 0.695545\n",
      "epoch 0; iter: 400; batch classifier loss: 14.593549; batch adversarial loss: 0.695619\n",
      "epoch 0; iter: 600; batch classifier loss: 2.705796; batch adversarial loss: 0.627560\n",
      "epoch 1; iter: 0; batch classifier loss: 0.527566; batch adversarial loss: 0.611984\n",
      "epoch 1; iter: 200; batch classifier loss: 1.364626; batch adversarial loss: 0.560886\n",
      "epoch 1; iter: 400; batch classifier loss: 4.514495; batch adversarial loss: 0.560551\n",
      "epoch 1; iter: 600; batch classifier loss: 1.260223; batch adversarial loss: 0.527021\n",
      "epoch 2; iter: 0; batch classifier loss: 3.467874; batch adversarial loss: 0.514710\n",
      "epoch 2; iter: 200; batch classifier loss: 1.799618; batch adversarial loss: 0.677356\n",
      "epoch 2; iter: 400; batch classifier loss: 0.419160; batch adversarial loss: 0.622881\n",
      "epoch 2; iter: 600; batch classifier loss: 2.547274; batch adversarial loss: 0.676137\n",
      "epoch 3; iter: 0; batch classifier loss: 0.907857; batch adversarial loss: 0.661280\n",
      "epoch 3; iter: 200; batch classifier loss: 0.793857; batch adversarial loss: 0.646657\n",
      "epoch 3; iter: 400; batch classifier loss: 2.697132; batch adversarial loss: 0.671509\n",
      "epoch 3; iter: 600; batch classifier loss: 0.376501; batch adversarial loss: 0.620924\n",
      "epoch 4; iter: 0; batch classifier loss: 1.256044; batch adversarial loss: 0.589282\n",
      "epoch 4; iter: 200; batch classifier loss: 0.443977; batch adversarial loss: 0.647510\n",
      "epoch 4; iter: 400; batch classifier loss: 0.442158; batch adversarial loss: 0.654855\n",
      "epoch 4; iter: 600; batch classifier loss: 0.362945; batch adversarial loss: 0.594382\n",
      "epoch 5; iter: 0; batch classifier loss: 0.759904; batch adversarial loss: 0.562267\n",
      "epoch 5; iter: 200; batch classifier loss: 0.474218; batch adversarial loss: 0.566185\n",
      "epoch 5; iter: 400; batch classifier loss: 0.404075; batch adversarial loss: 0.588271\n",
      "epoch 5; iter: 600; batch classifier loss: 0.337241; batch adversarial loss: 0.614306\n",
      "epoch 6; iter: 0; batch classifier loss: 0.742772; batch adversarial loss: 0.573473\n",
      "epoch 6; iter: 200; batch classifier loss: 0.427200; batch adversarial loss: 0.600837\n",
      "epoch 6; iter: 400; batch classifier loss: 0.444274; batch adversarial loss: 0.658857\n",
      "epoch 6; iter: 600; batch classifier loss: 0.455407; batch adversarial loss: 0.622512\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456846; batch adversarial loss: 0.630691\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416973; batch adversarial loss: 0.663765\n",
      "epoch 7; iter: 400; batch classifier loss: 0.393427; batch adversarial loss: 0.604110\n",
      "epoch 7; iter: 600; batch classifier loss: 0.410135; batch adversarial loss: 0.658980\n",
      "epoch 8; iter: 0; batch classifier loss: 0.367983; batch adversarial loss: 0.566079\n",
      "epoch 8; iter: 200; batch classifier loss: 0.293558; batch adversarial loss: 0.594061\n",
      "epoch 8; iter: 400; batch classifier loss: 0.236185; batch adversarial loss: 0.571869\n",
      "epoch 8; iter: 600; batch classifier loss: 0.415241; batch adversarial loss: 0.617908\n",
      "epoch 9; iter: 0; batch classifier loss: 0.456510; batch adversarial loss: 0.600759\n",
      "epoch 9; iter: 200; batch classifier loss: 0.193315; batch adversarial loss: 0.617368\n",
      "epoch 9; iter: 400; batch classifier loss: 0.308539; batch adversarial loss: 0.593796\n",
      "epoch 9; iter: 600; batch classifier loss: 0.411446; batch adversarial loss: 0.626574\n",
      "epoch 10; iter: 0; batch classifier loss: 0.412842; batch adversarial loss: 0.600200\n",
      "epoch 10; iter: 200; batch classifier loss: 0.374185; batch adversarial loss: 0.610605\n",
      "epoch 10; iter: 400; batch classifier loss: 0.277040; batch adversarial loss: 0.553205\n",
      "epoch 10; iter: 600; batch classifier loss: 0.333419; batch adversarial loss: 0.614947\n",
      "epoch 11; iter: 0; batch classifier loss: 0.388552; batch adversarial loss: 0.640608\n",
      "epoch 11; iter: 200; batch classifier loss: 0.316311; batch adversarial loss: 0.538147\n",
      "epoch 11; iter: 400; batch classifier loss: 0.181127; batch adversarial loss: 0.690477\n",
      "epoch 11; iter: 600; batch classifier loss: 0.313867; batch adversarial loss: 0.643195\n",
      "epoch 12; iter: 0; batch classifier loss: 0.336432; batch adversarial loss: 0.612725\n",
      "epoch 12; iter: 200; batch classifier loss: 0.278827; batch adversarial loss: 0.629828\n",
      "epoch 12; iter: 400; batch classifier loss: 0.233807; batch adversarial loss: 0.625524\n",
      "epoch 12; iter: 600; batch classifier loss: 0.346224; batch adversarial loss: 0.672283\n",
      "epoch 13; iter: 0; batch classifier loss: 0.531242; batch adversarial loss: 0.684383\n",
      "epoch 13; iter: 200; batch classifier loss: 0.284220; batch adversarial loss: 0.679031\n",
      "epoch 13; iter: 400; batch classifier loss: 0.462934; batch adversarial loss: 0.592561\n",
      "epoch 13; iter: 600; batch classifier loss: 0.324517; batch adversarial loss: 0.637209\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548025; batch adversarial loss: 0.635018\n",
      "epoch 14; iter: 200; batch classifier loss: 0.395404; batch adversarial loss: 0.630376\n",
      "epoch 14; iter: 400; batch classifier loss: 0.344069; batch adversarial loss: 0.613381\n",
      "epoch 14; iter: 600; batch classifier loss: 0.602065; batch adversarial loss: 0.602440\n",
      "epoch 15; iter: 0; batch classifier loss: 0.275358; batch adversarial loss: 0.678400\n",
      "epoch 15; iter: 200; batch classifier loss: 0.433820; batch adversarial loss: 0.631590\n",
      "epoch 15; iter: 400; batch classifier loss: 0.457743; batch adversarial loss: 0.571680\n",
      "epoch 15; iter: 600; batch classifier loss: 0.507017; batch adversarial loss: 0.610782\n",
      "epoch 16; iter: 0; batch classifier loss: 0.675529; batch adversarial loss: 0.562231\n",
      "epoch 16; iter: 200; batch classifier loss: 0.373907; batch adversarial loss: 0.617396\n",
      "epoch 16; iter: 400; batch classifier loss: 0.544755; batch adversarial loss: 0.563416\n",
      "epoch 16; iter: 600; batch classifier loss: 0.515214; batch adversarial loss: 0.578704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.460944; batch adversarial loss: 0.646478\n",
      "epoch 17; iter: 200; batch classifier loss: 0.446867; batch adversarial loss: 0.610337\n",
      "epoch 17; iter: 400; batch classifier loss: 0.382176; batch adversarial loss: 0.670605\n",
      "epoch 17; iter: 600; batch classifier loss: 0.422634; batch adversarial loss: 0.654621\n",
      "epoch 18; iter: 0; batch classifier loss: 0.405844; batch adversarial loss: 0.563254\n",
      "epoch 18; iter: 200; batch classifier loss: 0.625952; batch adversarial loss: 0.627766\n",
      "epoch 18; iter: 400; batch classifier loss: 0.456380; batch adversarial loss: 0.648161\n",
      "epoch 18; iter: 600; batch classifier loss: 0.338539; batch adversarial loss: 0.585883\n",
      "epoch 19; iter: 0; batch classifier loss: 0.355112; batch adversarial loss: 0.638613\n",
      "epoch 19; iter: 200; batch classifier loss: 0.433796; batch adversarial loss: 0.604159\n",
      "epoch 19; iter: 400; batch classifier loss: 0.537221; batch adversarial loss: 0.646933\n",
      "epoch 19; iter: 600; batch classifier loss: 0.394159; batch adversarial loss: 0.641828\n",
      "epoch 0; iter: 0; batch classifier loss: 25.502026; batch adversarial loss: 0.684486\n",
      "epoch 0; iter: 200; batch classifier loss: 17.908232; batch adversarial loss: 0.678472\n",
      "epoch 0; iter: 400; batch classifier loss: 6.755414; batch adversarial loss: 0.677209\n",
      "epoch 0; iter: 600; batch classifier loss: 8.047846; batch adversarial loss: 0.565701\n",
      "epoch 1; iter: 0; batch classifier loss: 0.748317; batch adversarial loss: 0.687517\n",
      "epoch 1; iter: 200; batch classifier loss: 13.776680; batch adversarial loss: 0.620797\n",
      "epoch 1; iter: 400; batch classifier loss: 0.664733; batch adversarial loss: 0.688788\n",
      "epoch 1; iter: 600; batch classifier loss: 3.370738; batch adversarial loss: 0.592418\n",
      "epoch 2; iter: 0; batch classifier loss: 2.655420; batch adversarial loss: 0.642686\n",
      "epoch 2; iter: 200; batch classifier loss: 5.779350; batch adversarial loss: 0.615767\n",
      "epoch 2; iter: 400; batch classifier loss: 4.647465; batch adversarial loss: 0.655160\n",
      "epoch 2; iter: 600; batch classifier loss: 2.300272; batch adversarial loss: 0.539590\n",
      "epoch 3; iter: 0; batch classifier loss: 1.866882; batch adversarial loss: 0.535274\n",
      "epoch 3; iter: 200; batch classifier loss: 1.366862; batch adversarial loss: 0.674711\n",
      "epoch 3; iter: 400; batch classifier loss: 0.861418; batch adversarial loss: 0.571607\n",
      "epoch 3; iter: 600; batch classifier loss: 5.203399; batch adversarial loss: 0.552152\n",
      "epoch 4; iter: 0; batch classifier loss: 1.114296; batch adversarial loss: 0.584232\n",
      "epoch 4; iter: 200; batch classifier loss: 0.673370; batch adversarial loss: 0.598777\n",
      "epoch 4; iter: 400; batch classifier loss: 0.598079; batch adversarial loss: 0.647374\n",
      "epoch 4; iter: 600; batch classifier loss: 0.410285; batch adversarial loss: 0.595937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.322990; batch adversarial loss: 0.630726\n",
      "epoch 5; iter: 200; batch classifier loss: 0.405747; batch adversarial loss: 0.658521\n",
      "epoch 5; iter: 400; batch classifier loss: 0.537994; batch adversarial loss: 0.604340\n",
      "epoch 5; iter: 600; batch classifier loss: 0.420034; batch adversarial loss: 0.631793\n",
      "epoch 6; iter: 0; batch classifier loss: 0.443702; batch adversarial loss: 0.558530\n",
      "epoch 6; iter: 200; batch classifier loss: 1.094526; batch adversarial loss: 0.660302\n",
      "epoch 6; iter: 400; batch classifier loss: 0.526744; batch adversarial loss: 0.619796\n",
      "epoch 6; iter: 600; batch classifier loss: 0.523464; batch adversarial loss: 0.617409\n",
      "epoch 7; iter: 0; batch classifier loss: 0.329945; batch adversarial loss: 0.608546\n",
      "epoch 7; iter: 200; batch classifier loss: 0.506608; batch adversarial loss: 0.628163\n",
      "epoch 7; iter: 400; batch classifier loss: 0.376211; batch adversarial loss: 0.543545\n",
      "epoch 7; iter: 600; batch classifier loss: 0.374180; batch adversarial loss: 0.661421\n",
      "epoch 8; iter: 0; batch classifier loss: 0.436599; batch adversarial loss: 0.590763\n",
      "epoch 8; iter: 200; batch classifier loss: 0.325480; batch adversarial loss: 0.602381\n",
      "epoch 8; iter: 400; batch classifier loss: 0.375335; batch adversarial loss: 0.623775\n",
      "epoch 8; iter: 600; batch classifier loss: 0.297049; batch adversarial loss: 0.585502\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346282; batch adversarial loss: 0.682252\n",
      "epoch 9; iter: 200; batch classifier loss: 0.355503; batch adversarial loss: 0.578726\n",
      "epoch 9; iter: 400; batch classifier loss: 0.283073; batch adversarial loss: 0.557018\n",
      "epoch 9; iter: 600; batch classifier loss: 0.372508; batch adversarial loss: 0.679920\n",
      "epoch 10; iter: 0; batch classifier loss: 0.295001; batch adversarial loss: 0.597494\n",
      "epoch 10; iter: 200; batch classifier loss: 0.402705; batch adversarial loss: 0.559762\n",
      "epoch 10; iter: 400; batch classifier loss: 0.390330; batch adversarial loss: 0.598785\n",
      "epoch 10; iter: 600; batch classifier loss: 0.309338; batch adversarial loss: 0.623693\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403924; batch adversarial loss: 0.704165\n",
      "epoch 11; iter: 200; batch classifier loss: 0.293508; batch adversarial loss: 0.727719\n",
      "epoch 11; iter: 400; batch classifier loss: 0.362232; batch adversarial loss: 0.600933\n",
      "epoch 11; iter: 600; batch classifier loss: 0.361549; batch adversarial loss: 0.666089\n",
      "epoch 12; iter: 0; batch classifier loss: 0.318227; batch adversarial loss: 0.623581\n",
      "epoch 12; iter: 200; batch classifier loss: 0.429784; batch adversarial loss: 0.600828\n",
      "epoch 12; iter: 400; batch classifier loss: 0.391431; batch adversarial loss: 0.638498\n",
      "epoch 12; iter: 600; batch classifier loss: 0.349124; batch adversarial loss: 0.608589\n",
      "epoch 13; iter: 0; batch classifier loss: 0.360261; batch adversarial loss: 0.587870\n",
      "epoch 13; iter: 200; batch classifier loss: 0.399798; batch adversarial loss: 0.695338\n",
      "epoch 13; iter: 400; batch classifier loss: 0.422429; batch adversarial loss: 0.605899\n",
      "epoch 13; iter: 600; batch classifier loss: 0.444242; batch adversarial loss: 0.596047\n",
      "epoch 14; iter: 0; batch classifier loss: 0.283851; batch adversarial loss: 0.769811\n",
      "epoch 14; iter: 200; batch classifier loss: 0.400878; batch adversarial loss: 0.608710\n",
      "epoch 14; iter: 400; batch classifier loss: 0.505557; batch adversarial loss: 0.696325\n",
      "epoch 14; iter: 600; batch classifier loss: 0.273923; batch adversarial loss: 0.657291\n",
      "epoch 15; iter: 0; batch classifier loss: 0.460283; batch adversarial loss: 0.687553\n",
      "epoch 15; iter: 200; batch classifier loss: 0.498978; batch adversarial loss: 0.679787\n",
      "epoch 15; iter: 400; batch classifier loss: 0.452126; batch adversarial loss: 0.615298\n",
      "epoch 15; iter: 600; batch classifier loss: 0.352879; batch adversarial loss: 0.664157\n",
      "epoch 16; iter: 0; batch classifier loss: 0.398444; batch adversarial loss: 0.643572\n",
      "epoch 16; iter: 200; batch classifier loss: 0.433161; batch adversarial loss: 0.616096\n",
      "epoch 16; iter: 400; batch classifier loss: 0.357143; batch adversarial loss: 0.665987\n",
      "epoch 16; iter: 600; batch classifier loss: 0.429934; batch adversarial loss: 0.627489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.381286; batch adversarial loss: 0.652838\n",
      "epoch 17; iter: 200; batch classifier loss: 0.396382; batch adversarial loss: 0.679875\n",
      "epoch 17; iter: 400; batch classifier loss: 0.264357; batch adversarial loss: 0.630245\n",
      "epoch 17; iter: 600; batch classifier loss: 0.528337; batch adversarial loss: 0.644512\n",
      "epoch 18; iter: 0; batch classifier loss: 0.312601; batch adversarial loss: 0.585442\n",
      "epoch 18; iter: 200; batch classifier loss: 0.380749; batch adversarial loss: 0.652073\n",
      "epoch 18; iter: 400; batch classifier loss: 0.451255; batch adversarial loss: 0.680689\n",
      "epoch 18; iter: 600; batch classifier loss: 0.458636; batch adversarial loss: 0.662117\n",
      "epoch 19; iter: 0; batch classifier loss: 0.380784; batch adversarial loss: 0.593888\n",
      "epoch 19; iter: 200; batch classifier loss: 0.438477; batch adversarial loss: 0.613089\n",
      "epoch 19; iter: 400; batch classifier loss: 0.356921; batch adversarial loss: 0.637213\n",
      "epoch 19; iter: 600; batch classifier loss: 0.436282; batch adversarial loss: 0.604408\n",
      "epoch 0; iter: 0; batch classifier loss: 20.068377; batch adversarial loss: 0.767549\n",
      "epoch 0; iter: 200; batch classifier loss: 23.020514; batch adversarial loss: 0.731139\n",
      "epoch 0; iter: 400; batch classifier loss: 9.390339; batch adversarial loss: 0.743525\n",
      "epoch 0; iter: 600; batch classifier loss: 0.877307; batch adversarial loss: 0.656071\n",
      "epoch 1; iter: 0; batch classifier loss: 3.012242; batch adversarial loss: 0.610702\n",
      "epoch 1; iter: 200; batch classifier loss: 5.585480; batch adversarial loss: 0.591612\n",
      "epoch 1; iter: 400; batch classifier loss: 2.160485; batch adversarial loss: 0.640392\n",
      "epoch 1; iter: 600; batch classifier loss: 2.411636; batch adversarial loss: 0.595930\n",
      "epoch 2; iter: 0; batch classifier loss: 4.032356; batch adversarial loss: 0.594467\n",
      "epoch 2; iter: 200; batch classifier loss: 1.629601; batch adversarial loss: 0.632975\n",
      "epoch 2; iter: 400; batch classifier loss: 0.905989; batch adversarial loss: 0.652864\n",
      "epoch 2; iter: 600; batch classifier loss: 0.381418; batch adversarial loss: 0.631711\n",
      "epoch 3; iter: 0; batch classifier loss: 12.756901; batch adversarial loss: 0.672040\n",
      "epoch 3; iter: 200; batch classifier loss: 1.464882; batch adversarial loss: 0.567913\n",
      "epoch 3; iter: 400; batch classifier loss: 1.199471; batch adversarial loss: 0.584489\n",
      "epoch 3; iter: 600; batch classifier loss: 0.531733; batch adversarial loss: 0.609823\n",
      "epoch 4; iter: 0; batch classifier loss: 0.417358; batch adversarial loss: 0.647377\n",
      "epoch 4; iter: 200; batch classifier loss: 0.840264; batch adversarial loss: 0.694267\n",
      "epoch 4; iter: 400; batch classifier loss: 0.661827; batch adversarial loss: 0.624299\n",
      "epoch 4; iter: 600; batch classifier loss: 0.484743; batch adversarial loss: 0.614958\n",
      "epoch 5; iter: 0; batch classifier loss: 0.387560; batch adversarial loss: 0.702421\n",
      "epoch 5; iter: 200; batch classifier loss: 0.412707; batch adversarial loss: 0.598507\n",
      "epoch 5; iter: 400; batch classifier loss: 0.393239; batch adversarial loss: 0.621639\n",
      "epoch 5; iter: 600; batch classifier loss: 0.270055; batch adversarial loss: 0.736844\n",
      "epoch 6; iter: 0; batch classifier loss: 0.407656; batch adversarial loss: 0.661645\n",
      "epoch 6; iter: 200; batch classifier loss: 0.549438; batch adversarial loss: 0.581731\n",
      "epoch 6; iter: 400; batch classifier loss: 0.509727; batch adversarial loss: 0.644871\n",
      "epoch 6; iter: 600; batch classifier loss: 0.387421; batch adversarial loss: 0.614859\n",
      "epoch 7; iter: 0; batch classifier loss: 0.433320; batch adversarial loss: 0.604583\n",
      "epoch 7; iter: 200; batch classifier loss: 0.327589; batch adversarial loss: 0.592496\n",
      "epoch 7; iter: 400; batch classifier loss: 0.391382; batch adversarial loss: 0.595362\n",
      "epoch 7; iter: 600; batch classifier loss: 0.405445; batch adversarial loss: 0.649399\n",
      "epoch 8; iter: 0; batch classifier loss: 0.335313; batch adversarial loss: 0.659381\n",
      "epoch 8; iter: 200; batch classifier loss: 0.319746; batch adversarial loss: 0.595896\n",
      "epoch 8; iter: 400; batch classifier loss: 0.349049; batch adversarial loss: 0.636394\n",
      "epoch 8; iter: 600; batch classifier loss: 0.354196; batch adversarial loss: 0.661894\n",
      "epoch 9; iter: 0; batch classifier loss: 0.321807; batch adversarial loss: 0.618232\n",
      "epoch 9; iter: 200; batch classifier loss: 0.310917; batch adversarial loss: 0.553316\n",
      "epoch 9; iter: 400; batch classifier loss: 0.293931; batch adversarial loss: 0.573326\n",
      "epoch 9; iter: 600; batch classifier loss: 0.275725; batch adversarial loss: 0.669186\n",
      "epoch 10; iter: 0; batch classifier loss: 0.276129; batch adversarial loss: 0.640062\n",
      "epoch 10; iter: 200; batch classifier loss: 0.393972; batch adversarial loss: 0.613967\n",
      "epoch 10; iter: 400; batch classifier loss: 0.222199; batch adversarial loss: 0.669256\n",
      "epoch 10; iter: 600; batch classifier loss: 0.321005; batch adversarial loss: 0.574519\n",
      "epoch 11; iter: 0; batch classifier loss: 0.360737; batch adversarial loss: 0.576634\n",
      "epoch 11; iter: 200; batch classifier loss: 0.386818; batch adversarial loss: 0.689503\n",
      "epoch 11; iter: 400; batch classifier loss: 0.488733; batch adversarial loss: 0.595464\n",
      "epoch 11; iter: 600; batch classifier loss: 0.374649; batch adversarial loss: 0.581131\n",
      "epoch 12; iter: 0; batch classifier loss: 0.470178; batch adversarial loss: 0.611269\n",
      "epoch 12; iter: 200; batch classifier loss: 0.241368; batch adversarial loss: 0.716892\n",
      "epoch 12; iter: 400; batch classifier loss: 0.229806; batch adversarial loss: 0.567774\n",
      "epoch 12; iter: 600; batch classifier loss: 0.421453; batch adversarial loss: 0.653274\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269934; batch adversarial loss: 0.661364\n",
      "epoch 13; iter: 200; batch classifier loss: 0.352533; batch adversarial loss: 0.618738\n",
      "epoch 13; iter: 400; batch classifier loss: 0.257665; batch adversarial loss: 0.643240\n",
      "epoch 13; iter: 600; batch classifier loss: 0.354229; batch adversarial loss: 0.493968\n",
      "epoch 14; iter: 0; batch classifier loss: 0.456621; batch adversarial loss: 0.575209\n",
      "epoch 14; iter: 200; batch classifier loss: 0.311060; batch adversarial loss: 0.643126\n",
      "epoch 14; iter: 400; batch classifier loss: 0.291398; batch adversarial loss: 0.608874\n",
      "epoch 14; iter: 600; batch classifier loss: 0.352466; batch adversarial loss: 0.628577\n",
      "epoch 15; iter: 0; batch classifier loss: 0.546097; batch adversarial loss: 0.634236\n",
      "epoch 15; iter: 200; batch classifier loss: 0.275629; batch adversarial loss: 0.632152\n",
      "epoch 15; iter: 400; batch classifier loss: 0.522636; batch adversarial loss: 0.683214\n",
      "epoch 15; iter: 600; batch classifier loss: 0.236751; batch adversarial loss: 0.652321\n",
      "epoch 16; iter: 0; batch classifier loss: 0.318498; batch adversarial loss: 0.611411\n",
      "epoch 16; iter: 200; batch classifier loss: 0.483617; batch adversarial loss: 0.615238\n",
      "epoch 16; iter: 400; batch classifier loss: 0.360360; batch adversarial loss: 0.635136\n",
      "epoch 16; iter: 600; batch classifier loss: 0.325420; batch adversarial loss: 0.637218\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363186; batch adversarial loss: 0.679754\n",
      "epoch 17; iter: 200; batch classifier loss: 0.443353; batch adversarial loss: 0.640720\n",
      "epoch 17; iter: 400; batch classifier loss: 0.614316; batch adversarial loss: 0.619733\n",
      "epoch 17; iter: 600; batch classifier loss: 0.399628; batch adversarial loss: 0.573473\n",
      "epoch 18; iter: 0; batch classifier loss: 0.341918; batch adversarial loss: 0.697849\n",
      "epoch 18; iter: 200; batch classifier loss: 0.459614; batch adversarial loss: 0.646095\n",
      "epoch 18; iter: 400; batch classifier loss: 0.418692; batch adversarial loss: 0.608203\n",
      "epoch 18; iter: 600; batch classifier loss: 0.378679; batch adversarial loss: 0.674915\n",
      "epoch 19; iter: 0; batch classifier loss: 0.923014; batch adversarial loss: 0.619925\n",
      "epoch 19; iter: 200; batch classifier loss: 0.447953; batch adversarial loss: 0.535216\n",
      "epoch 19; iter: 400; batch classifier loss: 0.355505; batch adversarial loss: 0.597355\n",
      "epoch 19; iter: 600; batch classifier loss: 0.394268; batch adversarial loss: 0.732872\n",
      "epoch 0; iter: 0; batch classifier loss: 17.019562; batch adversarial loss: 0.743195\n",
      "epoch 0; iter: 200; batch classifier loss: 8.662829; batch adversarial loss: 0.682604\n",
      "epoch 0; iter: 400; batch classifier loss: 1.629078; batch adversarial loss: 0.634559\n",
      "epoch 0; iter: 600; batch classifier loss: 44.461525; batch adversarial loss: 0.659145\n",
      "epoch 1; iter: 0; batch classifier loss: 4.237139; batch adversarial loss: 0.633842\n",
      "epoch 1; iter: 200; batch classifier loss: 5.156979; batch adversarial loss: 0.658905\n",
      "epoch 1; iter: 400; batch classifier loss: 6.385324; batch adversarial loss: 0.594701\n",
      "epoch 1; iter: 600; batch classifier loss: 7.361012; batch adversarial loss: 0.633150\n",
      "epoch 2; iter: 0; batch classifier loss: 5.105254; batch adversarial loss: 0.626707\n",
      "epoch 2; iter: 200; batch classifier loss: 2.505527; batch adversarial loss: 0.614509\n",
      "epoch 2; iter: 400; batch classifier loss: 0.416078; batch adversarial loss: 0.681097\n",
      "epoch 2; iter: 600; batch classifier loss: 3.103259; batch adversarial loss: 0.561752\n",
      "epoch 3; iter: 0; batch classifier loss: 3.220276; batch adversarial loss: 0.636862\n",
      "epoch 3; iter: 200; batch classifier loss: 2.015206; batch adversarial loss: 0.614274\n",
      "epoch 3; iter: 400; batch classifier loss: 0.599216; batch adversarial loss: 0.662763\n",
      "epoch 3; iter: 600; batch classifier loss: 0.661457; batch adversarial loss: 0.590548\n",
      "epoch 4; iter: 0; batch classifier loss: 1.111722; batch adversarial loss: 0.671275\n",
      "epoch 4; iter: 200; batch classifier loss: 0.923387; batch adversarial loss: 0.584491\n",
      "epoch 4; iter: 400; batch classifier loss: 0.665513; batch adversarial loss: 0.612794\n",
      "epoch 4; iter: 600; batch classifier loss: 1.307343; batch adversarial loss: 0.675626\n",
      "epoch 5; iter: 0; batch classifier loss: 0.795216; batch adversarial loss: 0.670822\n",
      "epoch 5; iter: 200; batch classifier loss: 0.424435; batch adversarial loss: 0.651286\n",
      "epoch 5; iter: 400; batch classifier loss: 0.439814; batch adversarial loss: 0.558154\n",
      "epoch 5; iter: 600; batch classifier loss: 0.442110; batch adversarial loss: 0.598492\n",
      "epoch 6; iter: 0; batch classifier loss: 0.774143; batch adversarial loss: 0.618186\n",
      "epoch 6; iter: 200; batch classifier loss: 0.461653; batch adversarial loss: 0.706477\n",
      "epoch 6; iter: 400; batch classifier loss: 0.447117; batch adversarial loss: 0.588595\n",
      "epoch 6; iter: 600; batch classifier loss: 0.308927; batch adversarial loss: 0.554162\n",
      "epoch 7; iter: 0; batch classifier loss: 0.430140; batch adversarial loss: 0.563642\n",
      "epoch 7; iter: 200; batch classifier loss: 0.417159; batch adversarial loss: 0.591804\n",
      "epoch 7; iter: 400; batch classifier loss: 0.372738; batch adversarial loss: 0.595588\n",
      "epoch 7; iter: 600; batch classifier loss: 0.487148; batch adversarial loss: 0.669756\n",
      "epoch 8; iter: 0; batch classifier loss: 0.367032; batch adversarial loss: 0.563376\n",
      "epoch 8; iter: 200; batch classifier loss: 0.238245; batch adversarial loss: 0.658352\n",
      "epoch 8; iter: 400; batch classifier loss: 0.245769; batch adversarial loss: 0.626966\n",
      "epoch 8; iter: 600; batch classifier loss: 0.889456; batch adversarial loss: 0.551767\n",
      "epoch 9; iter: 0; batch classifier loss: 0.222277; batch adversarial loss: 0.617251\n",
      "epoch 9; iter: 200; batch classifier loss: 0.338885; batch adversarial loss: 0.681223\n",
      "epoch 9; iter: 400; batch classifier loss: 0.454571; batch adversarial loss: 0.603960\n",
      "epoch 9; iter: 600; batch classifier loss: 0.379685; batch adversarial loss: 0.602187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.406357; batch adversarial loss: 0.700096\n",
      "epoch 10; iter: 200; batch classifier loss: 0.313399; batch adversarial loss: 0.601370\n",
      "epoch 10; iter: 400; batch classifier loss: 0.591529; batch adversarial loss: 0.563886\n",
      "epoch 10; iter: 600; batch classifier loss: 0.347029; batch adversarial loss: 0.646860\n",
      "epoch 11; iter: 0; batch classifier loss: 0.369199; batch adversarial loss: 0.640181\n",
      "epoch 11; iter: 200; batch classifier loss: 0.544016; batch adversarial loss: 0.652448\n",
      "epoch 11; iter: 400; batch classifier loss: 0.291481; batch adversarial loss: 0.621385\n",
      "epoch 11; iter: 600; batch classifier loss: 0.332482; batch adversarial loss: 0.668179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.289592; batch adversarial loss: 0.652026\n",
      "epoch 12; iter: 200; batch classifier loss: 0.320976; batch adversarial loss: 0.560348\n",
      "epoch 12; iter: 400; batch classifier loss: 0.386093; batch adversarial loss: 0.634394\n",
      "epoch 12; iter: 600; batch classifier loss: 0.375989; batch adversarial loss: 0.567119\n",
      "epoch 13; iter: 0; batch classifier loss: 0.295020; batch adversarial loss: 0.581701\n",
      "epoch 13; iter: 200; batch classifier loss: 0.319828; batch adversarial loss: 0.680368\n",
      "epoch 13; iter: 400; batch classifier loss: 0.386857; batch adversarial loss: 0.607139\n",
      "epoch 13; iter: 600; batch classifier loss: 0.319148; batch adversarial loss: 0.564713\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479138; batch adversarial loss: 0.583873\n",
      "epoch 14; iter: 200; batch classifier loss: 0.175451; batch adversarial loss: 0.672136\n",
      "epoch 14; iter: 400; batch classifier loss: 0.320312; batch adversarial loss: 0.651854\n",
      "epoch 14; iter: 600; batch classifier loss: 0.415701; batch adversarial loss: 0.630440\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359570; batch adversarial loss: 0.620885\n",
      "epoch 15; iter: 200; batch classifier loss: 0.461146; batch adversarial loss: 0.589302\n",
      "epoch 15; iter: 400; batch classifier loss: 0.425009; batch adversarial loss: 0.599661\n",
      "epoch 15; iter: 600; batch classifier loss: 0.265457; batch adversarial loss: 0.675613\n",
      "epoch 16; iter: 0; batch classifier loss: 0.335247; batch adversarial loss: 0.671748\n",
      "epoch 16; iter: 200; batch classifier loss: 0.495605; batch adversarial loss: 0.630348\n",
      "epoch 16; iter: 400; batch classifier loss: 0.318584; batch adversarial loss: 0.580472\n",
      "epoch 16; iter: 600; batch classifier loss: 0.368455; batch adversarial loss: 0.581395\n",
      "epoch 17; iter: 0; batch classifier loss: 0.395226; batch adversarial loss: 0.678331\n",
      "epoch 17; iter: 200; batch classifier loss: 0.376277; batch adversarial loss: 0.604033\n",
      "epoch 17; iter: 400; batch classifier loss: 0.297423; batch adversarial loss: 0.605089\n",
      "epoch 17; iter: 600; batch classifier loss: 0.521510; batch adversarial loss: 0.661910\n",
      "epoch 18; iter: 0; batch classifier loss: 0.338641; batch adversarial loss: 0.666729\n",
      "epoch 18; iter: 200; batch classifier loss: 0.458634; batch adversarial loss: 0.658034\n",
      "epoch 18; iter: 400; batch classifier loss: 0.427863; batch adversarial loss: 0.669381\n",
      "epoch 18; iter: 600; batch classifier loss: 0.381447; batch adversarial loss: 0.739919\n",
      "epoch 19; iter: 0; batch classifier loss: 0.349763; batch adversarial loss: 0.679503\n",
      "epoch 19; iter: 200; batch classifier loss: 0.499531; batch adversarial loss: 0.561149\n",
      "epoch 19; iter: 400; batch classifier loss: 0.549645; batch adversarial loss: 0.598482\n",
      "epoch 19; iter: 600; batch classifier loss: 0.399635; batch adversarial loss: 0.595139\n",
      "epoch 0; iter: 0; batch classifier loss: 78.597534; batch adversarial loss: 0.663209\n",
      "epoch 0; iter: 200; batch classifier loss: 31.926016; batch adversarial loss: 0.638542\n",
      "epoch 0; iter: 400; batch classifier loss: 5.712564; batch adversarial loss: 0.633877\n",
      "epoch 0; iter: 600; batch classifier loss: 2.083732; batch adversarial loss: 0.575217\n",
      "epoch 1; iter: 0; batch classifier loss: 8.433165; batch adversarial loss: 0.654742\n",
      "epoch 1; iter: 200; batch classifier loss: 7.804382; batch adversarial loss: 0.660074\n",
      "epoch 1; iter: 400; batch classifier loss: 3.311700; batch adversarial loss: 0.608215\n",
      "epoch 1; iter: 600; batch classifier loss: 16.876328; batch adversarial loss: 0.619844\n",
      "epoch 2; iter: 0; batch classifier loss: 6.764623; batch adversarial loss: 0.598421\n",
      "epoch 2; iter: 200; batch classifier loss: 1.018965; batch adversarial loss: 0.581973\n",
      "epoch 2; iter: 400; batch classifier loss: 3.328926; batch adversarial loss: 0.644454\n",
      "epoch 2; iter: 600; batch classifier loss: 5.979731; batch adversarial loss: 0.615024\n",
      "epoch 3; iter: 0; batch classifier loss: 3.175570; batch adversarial loss: 0.688558\n",
      "epoch 3; iter: 200; batch classifier loss: 0.989127; batch adversarial loss: 0.651309\n",
      "epoch 3; iter: 400; batch classifier loss: 1.381356; batch adversarial loss: 0.662749\n",
      "epoch 3; iter: 600; batch classifier loss: 1.605944; batch adversarial loss: 0.638771\n",
      "epoch 4; iter: 0; batch classifier loss: 1.754847; batch adversarial loss: 0.570236\n",
      "epoch 4; iter: 200; batch classifier loss: 0.796918; batch adversarial loss: 0.618976\n",
      "epoch 4; iter: 400; batch classifier loss: 0.765491; batch adversarial loss: 0.581832\n",
      "epoch 4; iter: 600; batch classifier loss: 0.583380; batch adversarial loss: 0.604424\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496090; batch adversarial loss: 0.695542\n",
      "epoch 5; iter: 200; batch classifier loss: 0.415512; batch adversarial loss: 0.615750\n",
      "epoch 5; iter: 400; batch classifier loss: 0.309959; batch adversarial loss: 0.659900\n",
      "epoch 5; iter: 600; batch classifier loss: 0.404385; batch adversarial loss: 0.608723\n",
      "epoch 6; iter: 0; batch classifier loss: 0.281913; batch adversarial loss: 0.665031\n",
      "epoch 6; iter: 200; batch classifier loss: 0.364186; batch adversarial loss: 0.674026\n",
      "epoch 6; iter: 400; batch classifier loss: 0.562159; batch adversarial loss: 0.522862\n",
      "epoch 6; iter: 600; batch classifier loss: 0.392599; batch adversarial loss: 0.713928\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529570; batch adversarial loss: 0.633997\n",
      "epoch 7; iter: 200; batch classifier loss: 0.310598; batch adversarial loss: 0.633817\n",
      "epoch 7; iter: 400; batch classifier loss: 0.427625; batch adversarial loss: 0.621007\n",
      "epoch 7; iter: 600; batch classifier loss: 0.334125; batch adversarial loss: 0.606839\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404258; batch adversarial loss: 0.572320\n",
      "epoch 8; iter: 200; batch classifier loss: 0.494044; batch adversarial loss: 0.597583\n",
      "epoch 8; iter: 400; batch classifier loss: 0.318209; batch adversarial loss: 0.631835\n",
      "epoch 8; iter: 600; batch classifier loss: 0.311324; batch adversarial loss: 0.539021\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409389; batch adversarial loss: 0.590252\n",
      "epoch 9; iter: 200; batch classifier loss: 0.238451; batch adversarial loss: 0.714286\n",
      "epoch 9; iter: 400; batch classifier loss: 0.571998; batch adversarial loss: 0.646435\n",
      "epoch 9; iter: 600; batch classifier loss: 0.309231; batch adversarial loss: 0.712690\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374656; batch adversarial loss: 0.633221\n",
      "epoch 10; iter: 200; batch classifier loss: 0.386134; batch adversarial loss: 0.586219\n",
      "epoch 10; iter: 400; batch classifier loss: 0.387425; batch adversarial loss: 0.606004\n",
      "epoch 10; iter: 600; batch classifier loss: 0.359848; batch adversarial loss: 0.584598\n",
      "epoch 11; iter: 0; batch classifier loss: 0.352307; batch adversarial loss: 0.558407\n",
      "epoch 11; iter: 200; batch classifier loss: 0.291598; batch adversarial loss: 0.697310\n",
      "epoch 11; iter: 400; batch classifier loss: 0.375020; batch adversarial loss: 0.562711\n",
      "epoch 11; iter: 600; batch classifier loss: 0.261303; batch adversarial loss: 0.552559\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327502; batch adversarial loss: 0.616937\n",
      "epoch 12; iter: 200; batch classifier loss: 0.447107; batch adversarial loss: 0.624700\n",
      "epoch 12; iter: 400; batch classifier loss: 0.236844; batch adversarial loss: 0.592878\n",
      "epoch 12; iter: 600; batch classifier loss: 0.313048; batch adversarial loss: 0.763591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340312; batch adversarial loss: 0.607951\n",
      "epoch 13; iter: 200; batch classifier loss: 0.314886; batch adversarial loss: 0.577321\n",
      "epoch 13; iter: 400; batch classifier loss: 0.388688; batch adversarial loss: 0.681504\n",
      "epoch 13; iter: 600; batch classifier loss: 0.392423; batch adversarial loss: 0.593346\n",
      "epoch 14; iter: 0; batch classifier loss: 0.384186; batch adversarial loss: 0.722902\n",
      "epoch 14; iter: 200; batch classifier loss: 0.269629; batch adversarial loss: 0.522653\n",
      "epoch 14; iter: 400; batch classifier loss: 0.384300; batch adversarial loss: 0.602864\n",
      "epoch 14; iter: 600; batch classifier loss: 0.451964; batch adversarial loss: 0.640621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529036; batch adversarial loss: 0.633262\n",
      "epoch 15; iter: 200; batch classifier loss: 0.396101; batch adversarial loss: 0.646872\n",
      "epoch 15; iter: 400; batch classifier loss: 0.308221; batch adversarial loss: 0.648926\n",
      "epoch 15; iter: 600; batch classifier loss: 0.376491; batch adversarial loss: 0.644965\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327352; batch adversarial loss: 0.530522\n",
      "epoch 16; iter: 200; batch classifier loss: 0.446915; batch adversarial loss: 0.711941\n",
      "epoch 16; iter: 400; batch classifier loss: 0.450733; batch adversarial loss: 0.698247\n",
      "epoch 16; iter: 600; batch classifier loss: 0.534545; batch adversarial loss: 0.590487\n",
      "epoch 17; iter: 0; batch classifier loss: 0.410695; batch adversarial loss: 0.667687\n",
      "epoch 17; iter: 200; batch classifier loss: 0.447062; batch adversarial loss: 0.612672\n",
      "epoch 17; iter: 400; batch classifier loss: 0.522684; batch adversarial loss: 0.630682\n",
      "epoch 17; iter: 600; batch classifier loss: 0.491146; batch adversarial loss: 0.637071\n",
      "epoch 18; iter: 0; batch classifier loss: 0.553948; batch adversarial loss: 0.566363\n",
      "epoch 18; iter: 200; batch classifier loss: 0.435410; batch adversarial loss: 0.668790\n",
      "epoch 18; iter: 400; batch classifier loss: 0.629808; batch adversarial loss: 0.628754\n",
      "epoch 18; iter: 600; batch classifier loss: 0.504018; batch adversarial loss: 0.620743\n",
      "epoch 19; iter: 0; batch classifier loss: 0.398495; batch adversarial loss: 0.640096\n",
      "epoch 19; iter: 200; batch classifier loss: 0.381929; batch adversarial loss: 0.628914\n",
      "epoch 19; iter: 400; batch classifier loss: 0.347058; batch adversarial loss: 0.659855\n",
      "epoch 19; iter: 600; batch classifier loss: 0.597350; batch adversarial loss: 0.607451\n",
      "epoch 0; iter: 0; batch classifier loss: 45.188290; batch adversarial loss: 0.780746\n",
      "epoch 0; iter: 200; batch classifier loss: 1.823322; batch adversarial loss: 0.698466\n",
      "epoch 0; iter: 400; batch classifier loss: 13.465376; batch adversarial loss: 0.636184\n",
      "epoch 0; iter: 600; batch classifier loss: 7.940397; batch adversarial loss: 0.638922\n",
      "epoch 1; iter: 0; batch classifier loss: 3.209662; batch adversarial loss: 0.566419\n",
      "epoch 1; iter: 200; batch classifier loss: 8.770717; batch adversarial loss: 0.620781\n",
      "epoch 1; iter: 400; batch classifier loss: 1.241371; batch adversarial loss: 0.588987\n",
      "epoch 1; iter: 600; batch classifier loss: 3.403034; batch adversarial loss: 0.670527\n",
      "epoch 2; iter: 0; batch classifier loss: 0.806555; batch adversarial loss: 0.647944\n",
      "epoch 2; iter: 200; batch classifier loss: 1.657964; batch adversarial loss: 0.659617\n",
      "epoch 2; iter: 400; batch classifier loss: 4.580002; batch adversarial loss: 0.638398\n",
      "epoch 2; iter: 600; batch classifier loss: 0.746834; batch adversarial loss: 0.736837\n",
      "epoch 3; iter: 0; batch classifier loss: 0.507015; batch adversarial loss: 0.576669\n",
      "epoch 3; iter: 200; batch classifier loss: 1.308491; batch adversarial loss: 0.621700\n",
      "epoch 3; iter: 400; batch classifier loss: 0.803065; batch adversarial loss: 0.604902\n",
      "epoch 3; iter: 600; batch classifier loss: 0.975873; batch adversarial loss: 0.591746\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555337; batch adversarial loss: 0.649181\n",
      "epoch 4; iter: 200; batch classifier loss: 0.661956; batch adversarial loss: 0.622521\n",
      "epoch 4; iter: 400; batch classifier loss: 0.366872; batch adversarial loss: 0.642874\n",
      "epoch 4; iter: 600; batch classifier loss: 0.873938; batch adversarial loss: 0.634623\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564751; batch adversarial loss: 0.632794\n",
      "epoch 5; iter: 200; batch classifier loss: 0.593917; batch adversarial loss: 0.529871\n",
      "epoch 5; iter: 400; batch classifier loss: 0.638893; batch adversarial loss: 0.627753\n",
      "epoch 5; iter: 600; batch classifier loss: 0.344567; batch adversarial loss: 0.579905\n",
      "epoch 6; iter: 0; batch classifier loss: 0.475457; batch adversarial loss: 0.627247\n",
      "epoch 6; iter: 200; batch classifier loss: 0.412228; batch adversarial loss: 0.651430\n",
      "epoch 6; iter: 400; batch classifier loss: 0.519223; batch adversarial loss: 0.640549\n",
      "epoch 6; iter: 600; batch classifier loss: 0.478442; batch adversarial loss: 0.575982\n",
      "epoch 7; iter: 0; batch classifier loss: 0.296052; batch adversarial loss: 0.577707\n",
      "epoch 7; iter: 200; batch classifier loss: 0.271837; batch adversarial loss: 0.643150\n",
      "epoch 7; iter: 400; batch classifier loss: 0.320656; batch adversarial loss: 0.708438\n",
      "epoch 7; iter: 600; batch classifier loss: 0.319032; batch adversarial loss: 0.684647\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610972; batch adversarial loss: 0.572294\n",
      "epoch 8; iter: 200; batch classifier loss: 0.424866; batch adversarial loss: 0.552902\n",
      "epoch 8; iter: 400; batch classifier loss: 0.360982; batch adversarial loss: 0.576549\n",
      "epoch 8; iter: 600; batch classifier loss: 0.471709; batch adversarial loss: 0.583799\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426679; batch adversarial loss: 0.645310\n",
      "epoch 9; iter: 200; batch classifier loss: 0.415404; batch adversarial loss: 0.740400\n",
      "epoch 9; iter: 400; batch classifier loss: 0.383264; batch adversarial loss: 0.630315\n",
      "epoch 9; iter: 600; batch classifier loss: 0.328566; batch adversarial loss: 0.597957\n",
      "epoch 10; iter: 0; batch classifier loss: 0.288620; batch adversarial loss: 0.611646\n",
      "epoch 10; iter: 200; batch classifier loss: 0.460910; batch adversarial loss: 0.565202\n",
      "epoch 10; iter: 400; batch classifier loss: 0.413050; batch adversarial loss: 0.576111\n",
      "epoch 10; iter: 600; batch classifier loss: 0.358693; batch adversarial loss: 0.726500\n",
      "epoch 11; iter: 0; batch classifier loss: 0.391319; batch adversarial loss: 0.555705\n",
      "epoch 11; iter: 200; batch classifier loss: 0.357852; batch adversarial loss: 0.599878\n",
      "epoch 11; iter: 400; batch classifier loss: 0.406205; batch adversarial loss: 0.551673\n",
      "epoch 11; iter: 600; batch classifier loss: 0.362693; batch adversarial loss: 0.649788\n",
      "epoch 12; iter: 0; batch classifier loss: 0.269355; batch adversarial loss: 0.704708\n",
      "epoch 12; iter: 200; batch classifier loss: 0.284763; batch adversarial loss: 0.615060\n",
      "epoch 12; iter: 400; batch classifier loss: 0.483248; batch adversarial loss: 0.584796\n",
      "epoch 12; iter: 600; batch classifier loss: 0.426600; batch adversarial loss: 0.605655\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349763; batch adversarial loss: 0.766209\n",
      "epoch 13; iter: 200; batch classifier loss: 0.266248; batch adversarial loss: 0.631210\n",
      "epoch 13; iter: 400; batch classifier loss: 0.373687; batch adversarial loss: 0.513831\n",
      "epoch 13; iter: 600; batch classifier loss: 0.419721; batch adversarial loss: 0.612625\n",
      "epoch 14; iter: 0; batch classifier loss: 0.454448; batch adversarial loss: 0.710154\n",
      "epoch 14; iter: 200; batch classifier loss: 0.351587; batch adversarial loss: 0.633772\n",
      "epoch 14; iter: 400; batch classifier loss: 0.321501; batch adversarial loss: 0.640212\n",
      "epoch 14; iter: 600; batch classifier loss: 0.547880; batch adversarial loss: 0.699481\n",
      "epoch 15; iter: 0; batch classifier loss: 0.410721; batch adversarial loss: 0.662274\n",
      "epoch 15; iter: 200; batch classifier loss: 0.348649; batch adversarial loss: 0.707210\n",
      "epoch 15; iter: 400; batch classifier loss: 0.455616; batch adversarial loss: 0.677705\n",
      "epoch 15; iter: 600; batch classifier loss: 0.482861; batch adversarial loss: 0.566237\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506899; batch adversarial loss: 0.654119\n",
      "epoch 16; iter: 200; batch classifier loss: 0.406065; batch adversarial loss: 0.585579\n",
      "epoch 16; iter: 400; batch classifier loss: 0.414253; batch adversarial loss: 0.630684\n",
      "epoch 16; iter: 600; batch classifier loss: 0.525430; batch adversarial loss: 0.681560\n",
      "epoch 17; iter: 0; batch classifier loss: 0.389667; batch adversarial loss: 0.664716\n",
      "epoch 17; iter: 200; batch classifier loss: 0.418460; batch adversarial loss: 0.667731\n",
      "epoch 17; iter: 400; batch classifier loss: 0.486663; batch adversarial loss: 0.618063\n",
      "epoch 17; iter: 600; batch classifier loss: 0.411473; batch adversarial loss: 0.647723\n",
      "epoch 18; iter: 0; batch classifier loss: 0.674573; batch adversarial loss: 0.591167\n",
      "epoch 18; iter: 200; batch classifier loss: 0.415775; batch adversarial loss: 0.555270\n",
      "epoch 18; iter: 400; batch classifier loss: 0.521056; batch adversarial loss: 0.613803\n",
      "epoch 18; iter: 600; batch classifier loss: 0.494551; batch adversarial loss: 0.678950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.834188; batch adversarial loss: 0.589995\n",
      "epoch 19; iter: 200; batch classifier loss: 0.349425; batch adversarial loss: 0.629370\n",
      "epoch 19; iter: 400; batch classifier loss: 0.383125; batch adversarial loss: 0.647593\n",
      "epoch 19; iter: 600; batch classifier loss: 0.590366; batch adversarial loss: 0.607573\n",
      "epoch 0; iter: 0; batch classifier loss: 5.252107; batch adversarial loss: 0.630390\n",
      "epoch 0; iter: 200; batch classifier loss: 12.068966; batch adversarial loss: 0.625540\n",
      "epoch 0; iter: 400; batch classifier loss: 7.285933; batch adversarial loss: 0.601079\n",
      "epoch 0; iter: 600; batch classifier loss: 16.864273; batch adversarial loss: 0.688160\n",
      "epoch 1; iter: 0; batch classifier loss: 2.566131; batch adversarial loss: 0.607073\n",
      "epoch 1; iter: 200; batch classifier loss: 2.798012; batch adversarial loss: 0.651016\n",
      "epoch 1; iter: 400; batch classifier loss: 1.422249; batch adversarial loss: 0.608817\n",
      "epoch 1; iter: 600; batch classifier loss: 2.746782; batch adversarial loss: 0.524998\n",
      "epoch 2; iter: 0; batch classifier loss: 3.409755; batch adversarial loss: 0.562465\n",
      "epoch 2; iter: 200; batch classifier loss: 2.655084; batch adversarial loss: 0.656006\n",
      "epoch 2; iter: 400; batch classifier loss: 1.342576; batch adversarial loss: 0.560537\n",
      "epoch 2; iter: 600; batch classifier loss: 2.097694; batch adversarial loss: 0.689066\n",
      "epoch 3; iter: 0; batch classifier loss: 0.861066; batch adversarial loss: 0.556389\n",
      "epoch 3; iter: 200; batch classifier loss: 1.345959; batch adversarial loss: 0.659102\n",
      "epoch 3; iter: 400; batch classifier loss: 1.445453; batch adversarial loss: 0.598431\n",
      "epoch 3; iter: 600; batch classifier loss: 0.787997; batch adversarial loss: 0.586179\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501366; batch adversarial loss: 0.557906\n",
      "epoch 4; iter: 200; batch classifier loss: 0.420240; batch adversarial loss: 0.556093\n",
      "epoch 4; iter: 400; batch classifier loss: 0.696466; batch adversarial loss: 0.593711\n",
      "epoch 4; iter: 600; batch classifier loss: 0.719720; batch adversarial loss: 0.552656\n",
      "epoch 5; iter: 0; batch classifier loss: 0.406296; batch adversarial loss: 0.641827\n",
      "epoch 5; iter: 200; batch classifier loss: 0.426648; batch adversarial loss: 0.631418\n",
      "epoch 5; iter: 400; batch classifier loss: 0.424564; batch adversarial loss: 0.660880\n",
      "epoch 5; iter: 600; batch classifier loss: 0.383729; batch adversarial loss: 0.603160\n",
      "epoch 6; iter: 0; batch classifier loss: 0.503700; batch adversarial loss: 0.564421\n",
      "epoch 6; iter: 200; batch classifier loss: 0.377882; batch adversarial loss: 0.606941\n",
      "epoch 6; iter: 400; batch classifier loss: 0.344465; batch adversarial loss: 0.703541\n",
      "epoch 6; iter: 600; batch classifier loss: 0.317150; batch adversarial loss: 0.701431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.337871; batch adversarial loss: 0.655824\n",
      "epoch 7; iter: 200; batch classifier loss: 0.340313; batch adversarial loss: 0.599460\n",
      "epoch 7; iter: 400; batch classifier loss: 0.384548; batch adversarial loss: 0.616502\n",
      "epoch 7; iter: 600; batch classifier loss: 0.376838; batch adversarial loss: 0.617389\n",
      "epoch 8; iter: 0; batch classifier loss: 0.429259; batch adversarial loss: 0.603937\n",
      "epoch 8; iter: 200; batch classifier loss: 0.368142; batch adversarial loss: 0.763914\n",
      "epoch 8; iter: 400; batch classifier loss: 0.300180; batch adversarial loss: 0.591228\n",
      "epoch 8; iter: 600; batch classifier loss: 0.454700; batch adversarial loss: 0.626827\n",
      "epoch 9; iter: 0; batch classifier loss: 0.360950; batch adversarial loss: 0.682292\n",
      "epoch 9; iter: 200; batch classifier loss: 0.248244; batch adversarial loss: 0.662191\n",
      "epoch 9; iter: 400; batch classifier loss: 0.326940; batch adversarial loss: 0.573495\n",
      "epoch 9; iter: 600; batch classifier loss: 0.348978; batch adversarial loss: 0.601120\n",
      "epoch 10; iter: 0; batch classifier loss: 0.304124; batch adversarial loss: 0.639501\n",
      "epoch 10; iter: 200; batch classifier loss: 0.409741; batch adversarial loss: 0.651237\n",
      "epoch 10; iter: 400; batch classifier loss: 0.286027; batch adversarial loss: 0.584537\n",
      "epoch 10; iter: 600; batch classifier loss: 0.375710; batch adversarial loss: 0.600998\n",
      "epoch 11; iter: 0; batch classifier loss: 0.304733; batch adversarial loss: 0.611916\n",
      "epoch 11; iter: 200; batch classifier loss: 0.475240; batch adversarial loss: 0.585960\n",
      "epoch 11; iter: 400; batch classifier loss: 0.494249; batch adversarial loss: 0.551497\n",
      "epoch 11; iter: 600; batch classifier loss: 0.305944; batch adversarial loss: 0.524944\n",
      "epoch 12; iter: 0; batch classifier loss: 0.378304; batch adversarial loss: 0.645337\n",
      "epoch 12; iter: 200; batch classifier loss: 0.396992; batch adversarial loss: 0.627260\n",
      "epoch 12; iter: 400; batch classifier loss: 0.819755; batch adversarial loss: 0.613855\n",
      "epoch 12; iter: 600; batch classifier loss: 0.314585; batch adversarial loss: 0.667427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.369107; batch adversarial loss: 0.634854\n",
      "epoch 13; iter: 200; batch classifier loss: 0.375189; batch adversarial loss: 0.591625\n",
      "epoch 13; iter: 400; batch classifier loss: 0.454715; batch adversarial loss: 0.588898\n",
      "epoch 13; iter: 600; batch classifier loss: 0.341625; batch adversarial loss: 0.524381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.233188; batch adversarial loss: 0.622107\n",
      "epoch 14; iter: 200; batch classifier loss: 0.423696; batch adversarial loss: 0.667709\n",
      "epoch 14; iter: 400; batch classifier loss: 0.560704; batch adversarial loss: 0.694986\n",
      "epoch 14; iter: 600; batch classifier loss: 0.617499; batch adversarial loss: 0.634448\n",
      "epoch 15; iter: 0; batch classifier loss: 0.347177; batch adversarial loss: 0.687776\n",
      "epoch 15; iter: 200; batch classifier loss: 0.474786; batch adversarial loss: 0.641583\n",
      "epoch 15; iter: 400; batch classifier loss: 0.525218; batch adversarial loss: 0.667150\n",
      "epoch 15; iter: 600; batch classifier loss: 0.372278; batch adversarial loss: 0.608169\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413834; batch adversarial loss: 0.521322\n",
      "epoch 16; iter: 200; batch classifier loss: 0.185512; batch adversarial loss: 0.632533\n",
      "epoch 16; iter: 400; batch classifier loss: 0.390004; batch adversarial loss: 0.614815\n",
      "epoch 16; iter: 600; batch classifier loss: 0.610572; batch adversarial loss: 0.696285\n",
      "epoch 17; iter: 0; batch classifier loss: 0.358748; batch adversarial loss: 0.768097\n",
      "epoch 17; iter: 200; batch classifier loss: 0.447556; batch adversarial loss: 0.672274\n",
      "epoch 17; iter: 400; batch classifier loss: 0.359279; batch adversarial loss: 0.535879\n",
      "epoch 17; iter: 600; batch classifier loss: 0.510561; batch adversarial loss: 0.629589\n",
      "epoch 18; iter: 0; batch classifier loss: 0.396861; batch adversarial loss: 0.670650\n",
      "epoch 18; iter: 200; batch classifier loss: 0.347581; batch adversarial loss: 0.617758\n",
      "epoch 18; iter: 400; batch classifier loss: 0.456176; batch adversarial loss: 0.660224\n",
      "epoch 18; iter: 600; batch classifier loss: 0.472135; batch adversarial loss: 0.617253\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471738; batch adversarial loss: 0.592207\n",
      "epoch 19; iter: 200; batch classifier loss: 0.582932; batch adversarial loss: 0.593766\n",
      "epoch 19; iter: 400; batch classifier loss: 0.409508; batch adversarial loss: 0.639059\n",
      "epoch 19; iter: 600; batch classifier loss: 0.426176; batch adversarial loss: 0.568454\n",
      "epoch 0; iter: 0; batch classifier loss: 74.917427; batch adversarial loss: 0.698708\n",
      "epoch 0; iter: 200; batch classifier loss: 1.786163; batch adversarial loss: 0.660949\n",
      "epoch 0; iter: 400; batch classifier loss: 14.006402; batch adversarial loss: 0.601925\n",
      "epoch 0; iter: 600; batch classifier loss: 2.993398; batch adversarial loss: 0.645509\n",
      "epoch 1; iter: 0; batch classifier loss: 3.929636; batch adversarial loss: 0.677161\n",
      "epoch 1; iter: 200; batch classifier loss: 4.370035; batch adversarial loss: 0.664962\n",
      "epoch 1; iter: 400; batch classifier loss: 8.709829; batch adversarial loss: 0.648155\n",
      "epoch 1; iter: 600; batch classifier loss: 8.294741; batch adversarial loss: 0.629192\n",
      "epoch 2; iter: 0; batch classifier loss: 2.885047; batch adversarial loss: 0.643032\n",
      "epoch 2; iter: 200; batch classifier loss: 4.150234; batch adversarial loss: 0.662290\n",
      "epoch 2; iter: 400; batch classifier loss: 3.020673; batch adversarial loss: 0.657205\n",
      "epoch 2; iter: 600; batch classifier loss: 1.627545; batch adversarial loss: 0.610590\n",
      "epoch 3; iter: 0; batch classifier loss: 0.852564; batch adversarial loss: 0.485671\n",
      "epoch 3; iter: 200; batch classifier loss: 0.750129; batch adversarial loss: 0.605663\n",
      "epoch 3; iter: 400; batch classifier loss: 1.172472; batch adversarial loss: 0.631678\n",
      "epoch 3; iter: 600; batch classifier loss: 1.956096; batch adversarial loss: 0.649386\n",
      "epoch 4; iter: 0; batch classifier loss: 0.915704; batch adversarial loss: 0.641039\n",
      "epoch 4; iter: 200; batch classifier loss: 0.899036; batch adversarial loss: 0.601787\n",
      "epoch 4; iter: 400; batch classifier loss: 0.562894; batch adversarial loss: 0.614222\n",
      "epoch 4; iter: 600; batch classifier loss: 0.449300; batch adversarial loss: 0.640048\n",
      "epoch 5; iter: 0; batch classifier loss: 0.663789; batch adversarial loss: 0.529018\n",
      "epoch 5; iter: 200; batch classifier loss: 0.401309; batch adversarial loss: 0.656401\n",
      "epoch 5; iter: 400; batch classifier loss: 0.474380; batch adversarial loss: 0.601060\n",
      "epoch 5; iter: 600; batch classifier loss: 0.319982; batch adversarial loss: 0.687465\n",
      "epoch 6; iter: 0; batch classifier loss: 0.327949; batch adversarial loss: 0.550568\n",
      "epoch 6; iter: 200; batch classifier loss: 0.735504; batch adversarial loss: 0.589414\n",
      "epoch 6; iter: 400; batch classifier loss: 0.600758; batch adversarial loss: 0.618252\n",
      "epoch 6; iter: 600; batch classifier loss: 0.310346; batch adversarial loss: 0.614950\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369703; batch adversarial loss: 0.650119\n",
      "epoch 7; iter: 200; batch classifier loss: 0.395906; batch adversarial loss: 0.567826\n",
      "epoch 7; iter: 400; batch classifier loss: 0.328332; batch adversarial loss: 0.621018\n",
      "epoch 7; iter: 600; batch classifier loss: 0.436722; batch adversarial loss: 0.626229\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404235; batch adversarial loss: 0.620408\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452907; batch adversarial loss: 0.589387\n",
      "epoch 8; iter: 400; batch classifier loss: 0.346890; batch adversarial loss: 0.594222\n",
      "epoch 8; iter: 600; batch classifier loss: 0.375024; batch adversarial loss: 0.565668\n",
      "epoch 9; iter: 0; batch classifier loss: 0.427352; batch adversarial loss: 0.621025\n",
      "epoch 9; iter: 200; batch classifier loss: 0.330525; batch adversarial loss: 0.644161\n",
      "epoch 9; iter: 400; batch classifier loss: 0.277424; batch adversarial loss: 0.654336\n",
      "epoch 9; iter: 600; batch classifier loss: 0.390486; batch adversarial loss: 0.596977\n",
      "epoch 10; iter: 0; batch classifier loss: 0.250790; batch adversarial loss: 0.666247\n",
      "epoch 10; iter: 200; batch classifier loss: 0.275158; batch adversarial loss: 0.658582\n",
      "epoch 10; iter: 400; batch classifier loss: 0.287387; batch adversarial loss: 0.609260\n",
      "epoch 10; iter: 600; batch classifier loss: 0.545648; batch adversarial loss: 0.626833\n",
      "epoch 11; iter: 0; batch classifier loss: 0.462745; batch adversarial loss: 0.564312\n",
      "epoch 11; iter: 200; batch classifier loss: 0.476915; batch adversarial loss: 0.526725\n",
      "epoch 11; iter: 400; batch classifier loss: 0.314384; batch adversarial loss: 0.593551\n",
      "epoch 11; iter: 600; batch classifier loss: 0.332993; batch adversarial loss: 0.629457\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457949; batch adversarial loss: 0.590965\n",
      "epoch 12; iter: 200; batch classifier loss: 0.501750; batch adversarial loss: 0.667001\n",
      "epoch 12; iter: 400; batch classifier loss: 0.477938; batch adversarial loss: 0.611245\n",
      "epoch 12; iter: 600; batch classifier loss: 0.430934; batch adversarial loss: 0.564444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.425085; batch adversarial loss: 0.580732\n",
      "epoch 13; iter: 200; batch classifier loss: 0.353195; batch adversarial loss: 0.649136\n",
      "epoch 13; iter: 400; batch classifier loss: 0.386151; batch adversarial loss: 0.567029\n",
      "epoch 13; iter: 600; batch classifier loss: 0.359472; batch adversarial loss: 0.611010\n",
      "epoch 14; iter: 0; batch classifier loss: 0.334577; batch adversarial loss: 0.643277\n",
      "epoch 14; iter: 200; batch classifier loss: 0.433352; batch adversarial loss: 0.659066\n",
      "epoch 14; iter: 400; batch classifier loss: 0.391950; batch adversarial loss: 0.634017\n",
      "epoch 14; iter: 600; batch classifier loss: 0.422882; batch adversarial loss: 0.695284\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318262; batch adversarial loss: 0.708754\n",
      "epoch 15; iter: 200; batch classifier loss: 0.361420; batch adversarial loss: 0.611547\n",
      "epoch 15; iter: 400; batch classifier loss: 0.332798; batch adversarial loss: 0.642856\n",
      "epoch 15; iter: 600; batch classifier loss: 0.399013; batch adversarial loss: 0.629066\n",
      "epoch 16; iter: 0; batch classifier loss: 0.322608; batch adversarial loss: 0.634426\n",
      "epoch 16; iter: 200; batch classifier loss: 0.398167; batch adversarial loss: 0.730764\n",
      "epoch 16; iter: 400; batch classifier loss: 0.357406; batch adversarial loss: 0.629135\n",
      "epoch 16; iter: 600; batch classifier loss: 0.323379; batch adversarial loss: 0.631844\n",
      "epoch 17; iter: 0; batch classifier loss: 0.324578; batch adversarial loss: 0.582457\n",
      "epoch 17; iter: 200; batch classifier loss: 0.324527; batch adversarial loss: 0.682246\n",
      "epoch 17; iter: 400; batch classifier loss: 0.234791; batch adversarial loss: 0.619926\n",
      "epoch 17; iter: 600; batch classifier loss: 0.293742; batch adversarial loss: 0.649050\n",
      "epoch 18; iter: 0; batch classifier loss: 0.232561; batch adversarial loss: 0.643100\n",
      "epoch 18; iter: 200; batch classifier loss: 0.273524; batch adversarial loss: 0.682970\n",
      "epoch 18; iter: 400; batch classifier loss: 0.394633; batch adversarial loss: 0.687683\n",
      "epoch 18; iter: 600; batch classifier loss: 0.386374; batch adversarial loss: 0.563797\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354157; batch adversarial loss: 0.668288\n",
      "epoch 19; iter: 200; batch classifier loss: 0.560169; batch adversarial loss: 0.560454\n",
      "epoch 19; iter: 400; batch classifier loss: 0.243685; batch adversarial loss: 0.568946\n",
      "epoch 19; iter: 600; batch classifier loss: 0.427523; batch adversarial loss: 0.597924\n",
      "epoch 0; iter: 0; batch classifier loss: 26.709614; batch adversarial loss: 0.779111\n",
      "epoch 0; iter: 200; batch classifier loss: 5.004992; batch adversarial loss: 0.738201\n",
      "epoch 0; iter: 400; batch classifier loss: 10.626337; batch adversarial loss: 0.638877\n",
      "epoch 0; iter: 600; batch classifier loss: 6.834785; batch adversarial loss: 0.680704\n",
      "epoch 1; iter: 0; batch classifier loss: 10.762255; batch adversarial loss: 0.583207\n",
      "epoch 1; iter: 200; batch classifier loss: 3.959510; batch adversarial loss: 0.583653\n",
      "epoch 1; iter: 400; batch classifier loss: 5.161595; batch adversarial loss: 0.601958\n",
      "epoch 1; iter: 600; batch classifier loss: 5.731164; batch adversarial loss: 0.623192\n",
      "epoch 2; iter: 0; batch classifier loss: 1.497244; batch adversarial loss: 0.596370\n",
      "epoch 2; iter: 200; batch classifier loss: 1.391095; batch adversarial loss: 0.681395\n",
      "epoch 2; iter: 400; batch classifier loss: 4.644243; batch adversarial loss: 0.622958\n",
      "epoch 2; iter: 600; batch classifier loss: 1.906628; batch adversarial loss: 0.621150\n",
      "epoch 3; iter: 0; batch classifier loss: 2.133987; batch adversarial loss: 0.625992\n",
      "epoch 3; iter: 200; batch classifier loss: 2.166272; batch adversarial loss: 0.551754\n",
      "epoch 3; iter: 400; batch classifier loss: 0.531097; batch adversarial loss: 0.610196\n",
      "epoch 3; iter: 600; batch classifier loss: 0.868864; batch adversarial loss: 0.652069\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597501; batch adversarial loss: 0.634656\n",
      "epoch 4; iter: 200; batch classifier loss: 0.323017; batch adversarial loss: 0.652149\n",
      "epoch 4; iter: 400; batch classifier loss: 0.514003; batch adversarial loss: 0.602417\n",
      "epoch 4; iter: 600; batch classifier loss: 1.570943; batch adversarial loss: 0.668157\n",
      "epoch 5; iter: 0; batch classifier loss: 0.504485; batch adversarial loss: 0.628529\n",
      "epoch 5; iter: 200; batch classifier loss: 0.520520; batch adversarial loss: 0.585079\n",
      "epoch 5; iter: 400; batch classifier loss: 0.397230; batch adversarial loss: 0.636313\n",
      "epoch 5; iter: 600; batch classifier loss: 0.960407; batch adversarial loss: 0.703638\n",
      "epoch 6; iter: 0; batch classifier loss: 1.032165; batch adversarial loss: 0.596355\n",
      "epoch 6; iter: 200; batch classifier loss: 0.370575; batch adversarial loss: 0.641757\n",
      "epoch 6; iter: 400; batch classifier loss: 0.528512; batch adversarial loss: 0.638413\n",
      "epoch 6; iter: 600; batch classifier loss: 0.649681; batch adversarial loss: 0.585668\n",
      "epoch 7; iter: 0; batch classifier loss: 0.311194; batch adversarial loss: 0.676204\n",
      "epoch 7; iter: 200; batch classifier loss: 0.631334; batch adversarial loss: 0.565771\n",
      "epoch 7; iter: 400; batch classifier loss: 0.442911; batch adversarial loss: 0.670042\n",
      "epoch 7; iter: 600; batch classifier loss: 0.332282; batch adversarial loss: 0.596430\n",
      "epoch 8; iter: 0; batch classifier loss: 0.409724; batch adversarial loss: 0.576923\n",
      "epoch 8; iter: 200; batch classifier loss: 0.467667; batch adversarial loss: 0.559020\n",
      "epoch 8; iter: 400; batch classifier loss: 0.281364; batch adversarial loss: 0.646704\n",
      "epoch 8; iter: 600; batch classifier loss: 0.383717; batch adversarial loss: 0.617163\n",
      "epoch 9; iter: 0; batch classifier loss: 0.286759; batch adversarial loss: 0.596570\n",
      "epoch 9; iter: 200; batch classifier loss: 0.401555; batch adversarial loss: 0.617513\n",
      "epoch 9; iter: 400; batch classifier loss: 0.362431; batch adversarial loss: 0.686668\n",
      "epoch 9; iter: 600; batch classifier loss: 0.475995; batch adversarial loss: 0.569763\n",
      "epoch 10; iter: 0; batch classifier loss: 0.243230; batch adversarial loss: 0.638154\n",
      "epoch 10; iter: 200; batch classifier loss: 0.362933; batch adversarial loss: 0.689386\n",
      "epoch 10; iter: 400; batch classifier loss: 0.451762; batch adversarial loss: 0.576926\n",
      "epoch 10; iter: 600; batch classifier loss: 0.227247; batch adversarial loss: 0.656590\n",
      "epoch 11; iter: 0; batch classifier loss: 0.296468; batch adversarial loss: 0.587098\n",
      "epoch 11; iter: 200; batch classifier loss: 0.258266; batch adversarial loss: 0.630169\n",
      "epoch 11; iter: 400; batch classifier loss: 0.455318; batch adversarial loss: 0.653930\n",
      "epoch 11; iter: 600; batch classifier loss: 0.426716; batch adversarial loss: 0.676289\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385771; batch adversarial loss: 0.586490\n",
      "epoch 12; iter: 200; batch classifier loss: 0.339534; batch adversarial loss: 0.554723\n",
      "epoch 12; iter: 400; batch classifier loss: 0.323908; batch adversarial loss: 0.640814\n",
      "epoch 12; iter: 600; batch classifier loss: 0.417202; batch adversarial loss: 0.599682\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540837; batch adversarial loss: 0.657991\n",
      "epoch 13; iter: 200; batch classifier loss: 0.296283; batch adversarial loss: 0.609983\n",
      "epoch 13; iter: 400; batch classifier loss: 0.354805; batch adversarial loss: 0.603058\n",
      "epoch 13; iter: 600; batch classifier loss: 0.316480; batch adversarial loss: 0.643389\n",
      "epoch 14; iter: 0; batch classifier loss: 0.371617; batch adversarial loss: 0.608294\n",
      "epoch 14; iter: 200; batch classifier loss: 0.344446; batch adversarial loss: 0.581530\n",
      "epoch 14; iter: 400; batch classifier loss: 0.324510; batch adversarial loss: 0.566312\n",
      "epoch 14; iter: 600; batch classifier loss: 0.407557; batch adversarial loss: 0.599040\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396291; batch adversarial loss: 0.683577\n",
      "epoch 15; iter: 200; batch classifier loss: 0.428301; batch adversarial loss: 0.666457\n",
      "epoch 15; iter: 400; batch classifier loss: 0.352707; batch adversarial loss: 0.597097\n",
      "epoch 15; iter: 600; batch classifier loss: 0.313400; batch adversarial loss: 0.605185\n",
      "epoch 16; iter: 0; batch classifier loss: 0.248214; batch adversarial loss: 0.622081\n",
      "epoch 16; iter: 200; batch classifier loss: 0.385701; batch adversarial loss: 0.726227\n",
      "epoch 16; iter: 400; batch classifier loss: 0.464476; batch adversarial loss: 0.652102\n",
      "epoch 16; iter: 600; batch classifier loss: 0.471838; batch adversarial loss: 0.610587\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472914; batch adversarial loss: 0.614514\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349803; batch adversarial loss: 0.542465\n",
      "epoch 17; iter: 400; batch classifier loss: 0.584524; batch adversarial loss: 0.572842\n",
      "epoch 17; iter: 600; batch classifier loss: 0.441029; batch adversarial loss: 0.597541\n",
      "epoch 18; iter: 0; batch classifier loss: 0.349757; batch adversarial loss: 0.679944\n",
      "epoch 18; iter: 200; batch classifier loss: 0.396174; batch adversarial loss: 0.568840\n",
      "epoch 18; iter: 400; batch classifier loss: 0.459708; batch adversarial loss: 0.665646\n",
      "epoch 18; iter: 600; batch classifier loss: 0.304802; batch adversarial loss: 0.670480\n",
      "epoch 19; iter: 0; batch classifier loss: 0.349873; batch adversarial loss: 0.587802\n",
      "epoch 19; iter: 200; batch classifier loss: 0.256326; batch adversarial loss: 0.651287\n",
      "epoch 19; iter: 400; batch classifier loss: 0.431928; batch adversarial loss: 0.582618\n",
      "epoch 19; iter: 600; batch classifier loss: 0.608695; batch adversarial loss: 0.665542\n",
      "epoch 0; iter: 0; batch classifier loss: 5.811082; batch adversarial loss: 0.645673\n",
      "epoch 0; iter: 200; batch classifier loss: 2.751396; batch adversarial loss: 0.670311\n",
      "epoch 0; iter: 400; batch classifier loss: 9.053075; batch adversarial loss: 0.635867\n",
      "epoch 0; iter: 600; batch classifier loss: 15.091001; batch adversarial loss: 0.658367\n",
      "epoch 1; iter: 0; batch classifier loss: 12.715318; batch adversarial loss: 0.661085\n",
      "epoch 1; iter: 200; batch classifier loss: 5.205502; batch adversarial loss: 0.652307\n",
      "epoch 1; iter: 400; batch classifier loss: 2.869470; batch adversarial loss: 0.576039\n",
      "epoch 1; iter: 600; batch classifier loss: 3.387808; batch adversarial loss: 0.530549\n",
      "epoch 2; iter: 0; batch classifier loss: 1.171224; batch adversarial loss: 0.592633\n",
      "epoch 2; iter: 200; batch classifier loss: 3.371038; batch adversarial loss: 0.658274\n",
      "epoch 2; iter: 400; batch classifier loss: 0.470312; batch adversarial loss: 0.547688\n",
      "epoch 2; iter: 600; batch classifier loss: 3.486427; batch adversarial loss: 0.633437\n",
      "epoch 3; iter: 0; batch classifier loss: 1.883410; batch adversarial loss: 0.577249\n",
      "epoch 3; iter: 200; batch classifier loss: 1.956910; batch adversarial loss: 0.601413\n",
      "epoch 3; iter: 400; batch classifier loss: 0.769995; batch adversarial loss: 0.507184\n",
      "epoch 3; iter: 600; batch classifier loss: 0.750895; batch adversarial loss: 0.598521\n",
      "epoch 4; iter: 0; batch classifier loss: 2.473355; batch adversarial loss: 0.559985\n",
      "epoch 4; iter: 200; batch classifier loss: 0.746151; batch adversarial loss: 0.639148\n",
      "epoch 4; iter: 400; batch classifier loss: 1.023618; batch adversarial loss: 0.620198\n",
      "epoch 4; iter: 600; batch classifier loss: 0.406582; batch adversarial loss: 0.764664\n",
      "epoch 5; iter: 0; batch classifier loss: 0.463183; batch adversarial loss: 0.545587\n",
      "epoch 5; iter: 200; batch classifier loss: 0.526418; batch adversarial loss: 0.591358\n",
      "epoch 5; iter: 400; batch classifier loss: 0.354200; batch adversarial loss: 0.577132\n",
      "epoch 5; iter: 600; batch classifier loss: 0.346292; batch adversarial loss: 0.619814\n",
      "epoch 6; iter: 0; batch classifier loss: 0.404322; batch adversarial loss: 0.637865\n",
      "epoch 6; iter: 200; batch classifier loss: 0.415594; batch adversarial loss: 0.546329\n",
      "epoch 6; iter: 400; batch classifier loss: 0.280890; batch adversarial loss: 0.624455\n",
      "epoch 6; iter: 600; batch classifier loss: 0.327096; batch adversarial loss: 0.581950\n",
      "epoch 7; iter: 0; batch classifier loss: 0.324252; batch adversarial loss: 0.659812\n",
      "epoch 7; iter: 200; batch classifier loss: 0.564238; batch adversarial loss: 0.623755\n",
      "epoch 7; iter: 400; batch classifier loss: 0.465426; batch adversarial loss: 0.620772\n",
      "epoch 7; iter: 600; batch classifier loss: 0.448446; batch adversarial loss: 0.596351\n",
      "epoch 8; iter: 0; batch classifier loss: 0.360826; batch adversarial loss: 0.566029\n",
      "epoch 8; iter: 200; batch classifier loss: 0.387325; batch adversarial loss: 0.685568\n",
      "epoch 8; iter: 400; batch classifier loss: 0.675762; batch adversarial loss: 0.645149\n",
      "epoch 8; iter: 600; batch classifier loss: 0.226220; batch adversarial loss: 0.624293\n",
      "epoch 9; iter: 0; batch classifier loss: 0.305098; batch adversarial loss: 0.600360\n",
      "epoch 9; iter: 200; batch classifier loss: 0.297283; batch adversarial loss: 0.612989\n",
      "epoch 9; iter: 400; batch classifier loss: 0.398053; batch adversarial loss: 0.565019\n",
      "epoch 9; iter: 600; batch classifier loss: 0.388239; batch adversarial loss: 0.667696\n",
      "epoch 10; iter: 0; batch classifier loss: 0.312466; batch adversarial loss: 0.617868\n",
      "epoch 10; iter: 200; batch classifier loss: 0.319821; batch adversarial loss: 0.731783\n",
      "epoch 10; iter: 400; batch classifier loss: 0.375218; batch adversarial loss: 0.652148\n",
      "epoch 10; iter: 600; batch classifier loss: 0.404272; batch adversarial loss: 0.585698\n",
      "epoch 11; iter: 0; batch classifier loss: 0.229690; batch adversarial loss: 0.700804\n",
      "epoch 11; iter: 200; batch classifier loss: 0.370318; batch adversarial loss: 0.657444\n",
      "epoch 11; iter: 400; batch classifier loss: 0.328553; batch adversarial loss: 0.666441\n",
      "epoch 11; iter: 600; batch classifier loss: 0.383819; batch adversarial loss: 0.553687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487452; batch adversarial loss: 0.670600\n",
      "epoch 12; iter: 200; batch classifier loss: 0.384009; batch adversarial loss: 0.655349\n",
      "epoch 12; iter: 400; batch classifier loss: 0.457679; batch adversarial loss: 0.680955\n",
      "epoch 12; iter: 600; batch classifier loss: 0.316553; batch adversarial loss: 0.677251\n",
      "epoch 13; iter: 0; batch classifier loss: 0.395555; batch adversarial loss: 0.613440\n",
      "epoch 13; iter: 200; batch classifier loss: 0.426137; batch adversarial loss: 0.606079\n",
      "epoch 13; iter: 400; batch classifier loss: 0.459277; batch adversarial loss: 0.616141\n",
      "epoch 13; iter: 600; batch classifier loss: 0.526324; batch adversarial loss: 0.707296\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402842; batch adversarial loss: 0.710568\n",
      "epoch 14; iter: 200; batch classifier loss: 0.300903; batch adversarial loss: 0.651954\n",
      "epoch 14; iter: 400; batch classifier loss: 0.408065; batch adversarial loss: 0.665738\n",
      "epoch 14; iter: 600; batch classifier loss: 0.382541; batch adversarial loss: 0.655552\n",
      "epoch 15; iter: 0; batch classifier loss: 0.413911; batch adversarial loss: 0.618750\n",
      "epoch 15; iter: 200; batch classifier loss: 0.517362; batch adversarial loss: 0.580452\n",
      "epoch 15; iter: 400; batch classifier loss: 0.392297; batch adversarial loss: 0.615140\n",
      "epoch 15; iter: 600; batch classifier loss: 0.286701; batch adversarial loss: 0.630096\n",
      "epoch 16; iter: 0; batch classifier loss: 0.579321; batch adversarial loss: 0.560872\n",
      "epoch 16; iter: 200; batch classifier loss: 0.460869; batch adversarial loss: 0.572151\n",
      "epoch 16; iter: 400; batch classifier loss: 0.361596; batch adversarial loss: 0.632205\n",
      "epoch 16; iter: 600; batch classifier loss: 0.539291; batch adversarial loss: 0.597140\n",
      "epoch 17; iter: 0; batch classifier loss: 0.575534; batch adversarial loss: 0.623406\n",
      "epoch 17; iter: 200; batch classifier loss: 0.518621; batch adversarial loss: 0.642366\n",
      "epoch 17; iter: 400; batch classifier loss: 0.320616; batch adversarial loss: 0.587442\n",
      "epoch 17; iter: 600; batch classifier loss: 0.559272; batch adversarial loss: 0.560978\n",
      "epoch 18; iter: 0; batch classifier loss: 0.267893; batch adversarial loss: 0.659643\n",
      "epoch 18; iter: 200; batch classifier loss: 0.383844; batch adversarial loss: 0.651327\n",
      "epoch 18; iter: 400; batch classifier loss: 0.290692; batch adversarial loss: 0.649276\n",
      "epoch 18; iter: 600; batch classifier loss: 0.340512; batch adversarial loss: 0.730690\n",
      "epoch 19; iter: 0; batch classifier loss: 0.490720; batch adversarial loss: 0.676009\n",
      "epoch 19; iter: 200; batch classifier loss: 0.571135; batch adversarial loss: 0.529711\n",
      "epoch 19; iter: 400; batch classifier loss: 0.499132; batch adversarial loss: 0.678112\n",
      "epoch 19; iter: 600; batch classifier loss: 0.256936; batch adversarial loss: 0.616692\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.798084  0.368927  0.058089  2.452261  0.418802  0.235824\n",
      "std   0.012127  0.070152  0.027891  2.014709  0.065359  0.038074\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedShuffleSplit, StratifiedKFold\n",
    "from src.metrics import best_hyperparameter_advdeb\n",
    "\n",
    "# 1) Retrieve data\n",
    "protected           = 'sex'\n",
    "privileged_value    = 1.0\n",
    "unprivileged_value  = 0.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_adult_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','sex')]\n",
    "\n",
    "# 2) Hyperparameter Search\n",
    "param_grid = {\n",
    "    'adversary_loss_weight': [0.5, 1.0],\n",
    "    'num_epochs':            [10, 20, 50],\n",
    "    'batch_size':            [64, 128]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "grid_results = []\n",
    "# Perform hyperparameter search with 15 stratified shuffle splits\n",
    "for params in grid:\n",
    "    print(f\"Testing config: {params}\")\n",
    "    fold_metrics = []\n",
    "    sss = StratifiedShuffleSplit(n_splits=15, test_size=0.3, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            privileged_groups, unprivileged_groups,\n",
    "            scope_name='adv',\n",
    "            num_epochs=params['num_epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            adversary_loss_weight=params['adversary_loss_weight']\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "    \n",
    "    df_fm = pd.DataFrame(fold_metrics)\n",
    "    agg = df_fm.agg(['mean', 'std'])\n",
    "\n",
    "    grid_results.append({\n",
    "        **params,\n",
    "        'acc_mean':   agg.loc['mean', 'accuracy'],\n",
    "        'acc_std':    agg.loc['std',  'accuracy'],\n",
    "        'f1_mean':    agg.loc['mean', 'f1_score'],\n",
    "        'f1_std':     agg.loc['std',  'f1_score'],\n",
    "        'SPD_mean':   agg.loc['mean', 'SPD'],\n",
    "        'SPD_std':    agg.loc['std',  'SPD'],\n",
    "        'DI_mean':    agg.loc['mean', 'DI'],\n",
    "        'DI_std':     agg.loc['std',  'DI'],\n",
    "        'EOD_mean':   agg.loc['mean', 'EOD'],\n",
    "        'EOD_std':    agg.loc['std',  'EOD'],\n",
    "        'AOD_mean':   agg.loc['mean', 'AOD'],\n",
    "        'AOD_std':    agg.loc['std',  'AOD'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Hyperparameter Selection\n",
    "best_param = best_hyperparameter_advdeb(results_df)\n",
    "print(f\"Best parameters: {best_param}\")\n",
    "\n",
    "# Final evaluation with StratifiedKFold\n",
    "loss_weight = best_param['adversary_loss_weight']\n",
    "n_epochs    = int(best_param['num_epochs'])\n",
    "batch_sz    = int(best_param['batch_size'])\n",
    "\n",
    "# 4) Run experiment, Evaluate\n",
    "results = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        privileged_groups, unprivileged_groups,\n",
    "        scope_name='adv',\n",
    "        num_epochs=n_epochs,\n",
    "        batch_size=batch_sz,\n",
    "        adversary_loss_weight=loss_weight\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 5) Aggregate results\n",
    "adult_sex_metrics       = pd.DataFrame(results)\n",
    "adult_sex_metrics_agg   = adult_sex_metrics.agg(['mean','std'])\n",
    "print(adult_sex_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2435e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', 'Hyperparametertuned Adversial Debiasing Adult: Baseline - Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d97e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
