{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc82712",
   "metadata": {},
   "source": [
    "## Inprocessing - Prejudice Remover -  Compas Model\n",
    "- for 'sex' and 'race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e1bf050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "from src.data_loading import load_adult_race, load_adult_sex\n",
    "from src.modeling import prejudice_remover_train_and_predict\n",
    "from src.metrics import compute_metrics, compare_viz_metrics_2x3, best_hyperparameter_advdeb, save_agg_metrics, save_raw_metrics\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "498f6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'adult'\n",
    "mitigation_name   = 'prejudice remover'\n",
    "pipeline_stage    = 'inprocessing'  \n",
    "out_dir_plots    = '../../reports/plots_adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d479e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_race_agg = pd.read_csv('../../reports/baseline_agg/adult_race_metrics_agg.csv', index_col=0)\n",
    "baseline_sex_agg = pd.read_csv('../../reports/baseline_agg/adult_sex_metrics_agg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df061c01",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468bb5e5",
   "metadata": {},
   "source": [
    "## default prejudice remover, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load data\n",
    "protected          = 'sex'\n",
    "privileged_value   = 1.0\n",
    "unprivileged_value = 0.0\n",
    "\n",
    "ds, df = load_adult_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label', protected)]\n",
    "\n",
    "# 2) Run experiment and evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for train_idx, test_idx in sss.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = prejudice_remover_train_and_predict(\n",
    "    df, train_idx, test_idx,\n",
    "    protected, privileged_value, unprivileged_value,\n",
    "    eta=25.0\n",
    "    )\n",
    "        \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate results\n",
    "adult_sex_metrics     = pd.DataFrame(results)\n",
    "adult_sex_metrics_agg = adult_sex_metrics.agg(['mean', 'std'])\n",
    "print(adult_sex_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e22c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_title = 'Adult Inprocessing Prejudice Remover: Baseline - Sex'\n",
    "fig = compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', plot_title)\n",
    "fname    = plot_title.replace(' ', '_').replace('(', '').replace(')', '')\n",
    "out_path = os.path.join(out_dir_plots, f'{fname}.png')\n",
    "fig.savefig(out_path)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663fce26",
   "metadata": {},
   "source": [
    "## default prejudice remover, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb730c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load data\n",
    "protected          = 'race'\n",
    "privileged_value   = 1.0\n",
    "unprivileged_value = 0.0\n",
    "\n",
    "ds, df = load_adult_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label', protected)]\n",
    "\n",
    "# 2) Run experiment and evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for train_idx, test_idx in sss.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = prejudice_remover_train_and_predict(\n",
    "    df, train_idx, test_idx,\n",
    "    protected, privileged_value, unprivileged_value,\n",
    "    eta=25.0\n",
    "    ) \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "# 3) Aggregate results\n",
    "adult_race_metrics     = pd.DataFrame(results)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean', 'std'])\n",
    "print(adult_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d40efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', 'Default Prejudice Remover adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1e2ed",
   "metadata": {},
   "source": [
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Save the aggregated metrics \n",
    "save_agg_metrics(\n",
    "    dataset_name      = dataset_name,\n",
    "    mitigation_name   = mitigation_name,\n",
    "    race_agg_df       = adult_race_metrics_agg,\n",
    "    sex_agg_df        = adult_sex_metrics_agg,\n",
    "    pipeline_stage    = pipeline_stage   \n",
    ")\n",
    "\n",
    "# 2) Save the raw metrics\n",
    "save_raw_metrics(\n",
    "    dataset_name      = dataset_name,\n",
    "    mitigation_name   = mitigation_name,\n",
    "    race_raw_df       = adult_race_metrics,\n",
    "    sex_raw_df        = adult_sex_metrics,\n",
    "    pipeline_stage    = pipeline_stage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698dbed",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load data\n",
    "protected          = 'race'\n",
    "privileged_value   = 1.0\n",
    "unprivileged_value = 0.0\n",
    "\n",
    "ds, df = load_adult_race()\n",
    "feature_cols = [c for c in df.columns if c not in ('label', protected)]\n",
    "\n",
    "# 2) Sweep Î· grid\n",
    "eta_grid = [15.0, 25.0, 40.0, 60.0]\n",
    "grid_results = []\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "for eta in eta_grid:\n",
    "    fold_metrics = []\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = prejudice_remover_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            eta=eta\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "\n",
    "    agg = pd.DataFrame(fold_metrics).agg(['mean','std'])\n",
    "    grid_results.append({\n",
    "        'eta':      eta,\n",
    "        'acc_mean': agg.loc['mean','accuracy'],\n",
    "        'SPD_mean': agg.loc['mean','SPD'],\n",
    "        'DI_mean':  agg.loc['mean','DI'],\n",
    "        # add other metrics as needed...\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Pick best\n",
    "best_row = best_hyperparameter_advdeb(results_df)\n",
    "chosen_eta = best_row['eta']\n",
    "print(f\"Chosen eta: {chosen_eta}\")\n",
    "\n",
    "# 4) Final evaluation with PrejudiceRemover\n",
    "final_metrics = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = prejudice_remover_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        eta=chosen_eta\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    final_metrics.append(m)\n",
    "\n",
    "# 5) Aggregate \n",
    "adult_race_metrics     = pd.DataFrame(final_metrics)\n",
    "adult_race_metrics_agg = adult_race_metrics.agg(['mean','std'])\n",
    "print(adult_race_metrics_agg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48455bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, adult_race_metrics_agg, 'Baseline', 'Race', 'Hyperparametertuned Prejudice Remover adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e18511",
   "metadata": {},
   "source": [
    "## hyperparameter search adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4143c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load data\n",
    "protected          = 'sex'\n",
    "privileged_value   = 1.0\n",
    "unprivileged_value = 0.0\n",
    "\n",
    "ds, df = load_adult_sex()\n",
    "feature_cols = [c for c in df.columns if c not in ('label', protected)]\n",
    "\n",
    "# 2) Sweep Î· grid\n",
    "eta_grid = [15.0, 25.0, 40.0, 60.0]\n",
    "grid_results = []\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "for eta in eta_grid:\n",
    "    fold_metrics = []\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = prejudice_remover_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            eta=eta\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "\n",
    "    agg = pd.DataFrame(fold_metrics).agg(['mean','std'])\n",
    "    grid_results.append({\n",
    "        'eta':      eta,\n",
    "        'acc_mean': agg.loc['mean','accuracy'],\n",
    "        'SPD_mean': agg.loc['mean','SPD'],\n",
    "        'DI_mean':  agg.loc['mean','DI'],\n",
    "        # add other metrics as needed...\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)\n",
    "\n",
    "# 3) Pick best\n",
    "best_row = best_hyperparameter_advdeb(results_df)\n",
    "chosen_eta = best_row['eta']\n",
    "print(f\"Chosen eta: {chosen_eta}\")\n",
    "\n",
    "# 4) Final evaluation with PrejudiceRemover\n",
    "final_metrics = []\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = prejudice_remover_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        eta=chosen_eta\n",
    "    )\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    final_metrics.append(m)\n",
    "\n",
    "# 5) Aggregate \n",
    "adult_sex_metrics     = pd.DataFrame(final_metrics)\n",
    "adult_sex_metrics_agg = adult_sex_metrics.agg(['mean','std'])\n",
    "print(adult_sex_metrics_agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f07f63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8782ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_viz_metrics_2x3(baseline_sex_agg, adult_sex_metrics_agg, 'Baseline', 'Sex', 'Hyperparametertuned Prejudice Remover adult: Baseline - Sex')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
