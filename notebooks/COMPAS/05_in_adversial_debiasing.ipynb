{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53b8bcc",
   "metadata": {},
   "source": [
    "## Preprocessing - Adversial Debiasing  -  Compas Model\n",
    "- for 'sex' and 'race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a779c2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/inFairness/utils/ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import reset_default_graph\n",
    "import pandas as pd\n",
    "from src.data_loading import load_compas_sex, load_compas_race\n",
    "from src.modeling import adversial_debiasing_train_and_predict\n",
    "from src.metrics import compute_metrics, viz_metrics_2x3, compare_viz_metrics_2x3\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e97096",
   "metadata": {},
   "source": [
    "## Build up the function using race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e12721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 0.0\n",
    "unprivileged_value  = 1.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "ds, df = load_compas_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    # Reset TF graph - start new session (to avoid \"Variable â€¦ already exists\")\n",
    "    reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    test_df  = df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "    # Wrap into AIF360 \n",
    "    train_bld = BinaryLabelDataset(\n",
    "        df=train_df,\n",
    "        label_names=['label'],\n",
    "        protected_attribute_names=[protected],\n",
    "        favorable_label=1.0,\n",
    "        unfavorable_label=0.0,\n",
    "        privileged_protected_attributes=[[privileged_value]],\n",
    "        unprivileged_protected_attributes=[[unprivileged_value]]\n",
    "    )\n",
    "    test_bld = BinaryLabelDataset(\n",
    "        df=test_df,\n",
    "        label_names=['label'],\n",
    "        protected_attribute_names=[protected],\n",
    "        favorable_label=1.0,\n",
    "        unfavorable_label=0.0,\n",
    "        privileged_protected_attributes=[[privileged_value]],\n",
    "        unprivileged_protected_attributes=[[unprivileged_value]]\n",
    "    )\n",
    "\n",
    "    # Instantiate & train AdversarialDebiasing\n",
    "    adv = AdversarialDebiasing(\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups,\n",
    "        scope_name='adv',             \n",
    "        debias=True,\n",
    "        sess=sess\n",
    "    )\n",
    "    adv.fit(train_bld)\n",
    "\n",
    "    # Predict on test split\n",
    "    pred_bld = adv.predict(test_bld)\n",
    "    y_test   = test_df['label'].values\n",
    "    y_pred   = pred_bld.labels.ravel()\n",
    "\n",
    "    # Compute & store metrics\n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "    sess.close()\n",
    "\n",
    "compas_race_metrics = pd.DataFrame(results)\n",
    "compas_race_metrics_agg = compas_race_metrics.agg(['mean','std'])\n",
    "\n",
    "print(compas_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b6a7b4",
   "metadata": {},
   "source": [
    "## refactor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25799740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 0.0\n",
    "unprivileged_value  = 1.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_compas_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    "    scope_name='adv',           \n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.1)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "compas_race_metrics = pd.DataFrame(results)\n",
    "compas_race_metrics_agg = compas_race_metrics.agg(['mean','std'])\n",
    "\n",
    "print(compas_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08920fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_race_agg = pd.read_csv('../../reports/baseline_agg/compas_race_metrics_agg.csv', index_col=0)\n",
    "baseline_sex_agg = pd.read_csv('../../reports/baseline_agg/compas_sex_metrics_agg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_race_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, compas_race_metrics_agg, 'Baseline', 'Race', 'Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87d6ce",
   "metadata": {},
   "source": [
    "## Hyperparametersearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109369ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'adversary_loss_weight': [0.5, 1.0],\n",
    "    'num_epochs':            [10,20, 50],\n",
    "    'batch_size':            [64, 128]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "# 2) Prepare to collect results\n",
    "grid_results = []\n",
    "\n",
    "# each hyperparam setting\n",
    "for params in grid:\n",
    "    print(f\"Testing config: {params}\")\n",
    "    fold_metrics = []\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in sss.split(df, df['label']):\n",
    "        test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "            df, train_idx, test_idx,\n",
    "            protected, privileged_value, unprivileged_value,\n",
    "            privileged_groups, unprivileged_groups,\n",
    "            scope_name='adv',\n",
    "            num_epochs=params['num_epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            adversary_loss_weight=params['adversary_loss_weight']\n",
    "        )\n",
    "        m = compute_metrics(\n",
    "            test_df, y_test, y_pred,\n",
    "            protected, privileged_value, unprivileged_value\n",
    "        )\n",
    "        fold_metrics.append(m)\n",
    "    \n",
    "    df_fm = pd.DataFrame(fold_metrics)\n",
    "    agg = df_fm.agg(['mean','std'])\n",
    "    \n",
    "    grid_results.append({\n",
    "        **params,\n",
    "        'acc_mean':   agg.loc['mean','accuracy'],\n",
    "        'acc_std':    agg.loc['std', 'accuracy'],\n",
    "        'f1_mean':    agg.loc['mean','f1_score'],\n",
    "        'f1_std':     agg.loc['std', 'f1_score'],\n",
    "        'SPD_mean':   agg.loc['mean','SPD'],\n",
    "        'SPD_std':    agg.loc['std', 'SPD'],\n",
    "        'DI_mean':    agg.loc['mean','DI'],\n",
    "        'DI_std':     agg.loc['std', 'DI'],\n",
    "        'EOD_mean':   agg.loc['mean','EOD'],\n",
    "        'EOD_std':    agg.loc['std', 'EOD'],\n",
    "        'AOD_mean':   agg.loc['mean','AOD'],\n",
    "        'AOD_std':    agg.loc['std', 'AOD'],\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(grid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d52ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds fairness\n",
    "di_min, di_max        = 0.8, 1.25\n",
    "spd_thresh, eod_thresh, aod_thresh = 0.1, 0.1, 0.1\n",
    "\n",
    "# filter for configs that satisfy ALL four fairness bounds\n",
    "fair_configs = results_df[\n",
    "    (results_df['DI_mean']  >= di_min)  & (results_df['DI_mean']  <= di_max)   &\n",
    "    (results_df['SPD_mean'].abs() <= spd_thresh)                              &\n",
    "    (results_df['EOD_mean'].abs() <= eod_thresh)                              &\n",
    "    (results_df['AOD_mean'].abs() <= aod_thresh)\n",
    "]\n",
    "\n",
    "# 3) Sort by (1) acc_mean â†“, (2) acc_std â†‘\n",
    "best = fair_configs.sort_values(\n",
    "    by=['acc_mean','acc_std','DI_std'],\n",
    "    ascending=[False,    True,     True]\n",
    ").iloc[0]\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e8011",
   "metadata": {},
   "source": [
    "- refactor best_hyperparam searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1276d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import best_hyperparameter_advdeb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "best_param = best_hyperparameter_advdeb(results_df)\n",
    "loss_weight = best_param['adversary_loss_weight']\n",
    "n_epochs    = int(best_param['num_epochs'])\n",
    "batch_sz    = int(best_param['batch_size'])\n",
    "\n",
    "folds = StratifiedKFold(n_splits=25, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "for train_idx, test_idx in folds.split(df, df['label']):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "        df, train_idx, test_idx,\n",
    "        protected, privileged_value, unprivileged_value,\n",
    "        privileged_groups, unprivileged_groups,\n",
    "        scope_name='adv',\n",
    "        num_epochs=50,\n",
    "        batch_size=64,\n",
    "        adversary_loss_weight=0.5\n",
    "    )\n",
    "    m = compute_metrics(test_df, y_test, y_pred,\n",
    "                        protected, privileged_value, unprivileged_value)\n",
    "    metrics.append(m)\n",
    "final_df = pd.DataFrame(metrics)\n",
    "print(final_df.agg(['mean','std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, final_df.agg(['mean','std']), 'Baseline', 'Race', 'Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec69a2",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c785d3da",
   "metadata": {},
   "source": [
    "## default adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb0d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_race_agg = pd.read_csv('../../reports/baseline_agg/compas_race_metrics_agg.csv', index_col=0)\n",
    "baseline_sex_agg = pd.read_csv('../../reports/baseline_agg/compas_sex_metrics_agg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4efb8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 16:52:09.010249: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 3.580595; batch adversarial loss: 0.680729\n",
      "epoch 1; iter: 0; batch classifier loss: 0.758753; batch adversarial loss: 0.655623\n",
      "epoch 2; iter: 0; batch classifier loss: 0.884832; batch adversarial loss: 0.653006\n",
      "epoch 3; iter: 0; batch classifier loss: 0.813074; batch adversarial loss: 0.707565\n",
      "epoch 4; iter: 0; batch classifier loss: 0.715178; batch adversarial loss: 0.688805\n",
      "epoch 5; iter: 0; batch classifier loss: 0.701622; batch adversarial loss: 0.650718\n",
      "epoch 6; iter: 0; batch classifier loss: 0.726939; batch adversarial loss: 0.631945\n",
      "epoch 7; iter: 0; batch classifier loss: 0.677722; batch adversarial loss: 0.673688\n",
      "epoch 8; iter: 0; batch classifier loss: 0.622095; batch adversarial loss: 0.625166\n",
      "epoch 9; iter: 0; batch classifier loss: 0.653846; batch adversarial loss: 0.651927\n",
      "epoch 10; iter: 0; batch classifier loss: 0.598986; batch adversarial loss: 0.683974\n",
      "epoch 11; iter: 0; batch classifier loss: 0.630173; batch adversarial loss: 0.661427\n",
      "epoch 12; iter: 0; batch classifier loss: 0.632255; batch adversarial loss: 0.652196\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546473; batch adversarial loss: 0.634221\n",
      "epoch 14; iter: 0; batch classifier loss: 0.616147; batch adversarial loss: 0.640304\n",
      "epoch 15; iter: 0; batch classifier loss: 0.665892; batch adversarial loss: 0.667456\n",
      "epoch 16; iter: 0; batch classifier loss: 0.622838; batch adversarial loss: 0.693739\n",
      "epoch 17; iter: 0; batch classifier loss: 0.666392; batch adversarial loss: 0.689139\n",
      "epoch 18; iter: 0; batch classifier loss: 0.653848; batch adversarial loss: 0.672291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.644579; batch adversarial loss: 0.646871\n",
      "epoch 20; iter: 0; batch classifier loss: 0.594374; batch adversarial loss: 0.678486\n",
      "epoch 21; iter: 0; batch classifier loss: 0.611955; batch adversarial loss: 0.648522\n",
      "epoch 22; iter: 0; batch classifier loss: 0.599723; batch adversarial loss: 0.652449\n",
      "epoch 23; iter: 0; batch classifier loss: 0.637140; batch adversarial loss: 0.626418\n",
      "epoch 24; iter: 0; batch classifier loss: 0.652552; batch adversarial loss: 0.645548\n",
      "epoch 25; iter: 0; batch classifier loss: 0.617680; batch adversarial loss: 0.647132\n",
      "epoch 26; iter: 0; batch classifier loss: 0.626287; batch adversarial loss: 0.689087\n",
      "epoch 27; iter: 0; batch classifier loss: 0.649424; batch adversarial loss: 0.652763\n",
      "epoch 28; iter: 0; batch classifier loss: 0.797145; batch adversarial loss: 0.674550\n",
      "epoch 29; iter: 0; batch classifier loss: 0.539793; batch adversarial loss: 0.658354\n",
      "epoch 30; iter: 0; batch classifier loss: 0.607697; batch adversarial loss: 0.668383\n",
      "epoch 31; iter: 0; batch classifier loss: 0.620393; batch adversarial loss: 0.625324\n",
      "epoch 32; iter: 0; batch classifier loss: 0.610575; batch adversarial loss: 0.679996\n",
      "epoch 33; iter: 0; batch classifier loss: 0.629694; batch adversarial loss: 0.599796\n",
      "epoch 34; iter: 0; batch classifier loss: 0.647981; batch adversarial loss: 0.632643\n",
      "epoch 35; iter: 0; batch classifier loss: 0.585888; batch adversarial loss: 0.650258\n",
      "epoch 36; iter: 0; batch classifier loss: 0.605428; batch adversarial loss: 0.653465\n",
      "epoch 37; iter: 0; batch classifier loss: 0.646701; batch adversarial loss: 0.668332\n",
      "epoch 38; iter: 0; batch classifier loss: 0.579394; batch adversarial loss: 0.600893\n",
      "epoch 39; iter: 0; batch classifier loss: 0.619118; batch adversarial loss: 0.628362\n",
      "epoch 40; iter: 0; batch classifier loss: 0.559289; batch adversarial loss: 0.587623\n",
      "epoch 41; iter: 0; batch classifier loss: 0.648320; batch adversarial loss: 0.655124\n",
      "epoch 42; iter: 0; batch classifier loss: 0.642618; batch adversarial loss: 0.664292\n",
      "epoch 43; iter: 0; batch classifier loss: 0.573034; batch adversarial loss: 0.642296\n",
      "epoch 44; iter: 0; batch classifier loss: 0.560787; batch adversarial loss: 0.589234\n",
      "epoch 45; iter: 0; batch classifier loss: 0.585754; batch adversarial loss: 0.673886\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551299; batch adversarial loss: 0.634938\n",
      "epoch 47; iter: 0; batch classifier loss: 0.558296; batch adversarial loss: 0.613224\n",
      "epoch 48; iter: 0; batch classifier loss: 0.589910; batch adversarial loss: 0.664481\n",
      "epoch 49; iter: 0; batch classifier loss: 0.601676; batch adversarial loss: 0.609620\n",
      "epoch 0; iter: 0; batch classifier loss: 1.050792; batch adversarial loss: 0.739220\n",
      "epoch 1; iter: 0; batch classifier loss: 0.859661; batch adversarial loss: 0.686404\n",
      "epoch 2; iter: 0; batch classifier loss: 0.702381; batch adversarial loss: 0.686406\n",
      "epoch 3; iter: 0; batch classifier loss: 0.736922; batch adversarial loss: 0.670578\n",
      "epoch 4; iter: 0; batch classifier loss: 0.645110; batch adversarial loss: 0.646278\n",
      "epoch 5; iter: 0; batch classifier loss: 0.603288; batch adversarial loss: 0.647517\n",
      "epoch 6; iter: 0; batch classifier loss: 0.624546; batch adversarial loss: 0.651371\n",
      "epoch 7; iter: 0; batch classifier loss: 0.627748; batch adversarial loss: 0.646048\n",
      "epoch 8; iter: 0; batch classifier loss: 0.656225; batch adversarial loss: 0.643984\n",
      "epoch 9; iter: 0; batch classifier loss: 0.628041; batch adversarial loss: 0.612179\n",
      "epoch 10; iter: 0; batch classifier loss: 0.595428; batch adversarial loss: 0.650552\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607146; batch adversarial loss: 0.592086\n",
      "epoch 12; iter: 0; batch classifier loss: 0.635763; batch adversarial loss: 0.614205\n",
      "epoch 13; iter: 0; batch classifier loss: 0.615048; batch adversarial loss: 0.610167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.608732; batch adversarial loss: 0.640969\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566838; batch adversarial loss: 0.642982\n",
      "epoch 16; iter: 0; batch classifier loss: 0.686665; batch adversarial loss: 0.609102\n",
      "epoch 17; iter: 0; batch classifier loss: 0.600372; batch adversarial loss: 0.678499\n",
      "epoch 18; iter: 0; batch classifier loss: 0.599606; batch adversarial loss: 0.636734\n",
      "epoch 19; iter: 0; batch classifier loss: 0.639227; batch adversarial loss: 0.607660\n",
      "epoch 20; iter: 0; batch classifier loss: 0.613091; batch adversarial loss: 0.666003\n",
      "epoch 21; iter: 0; batch classifier loss: 0.608810; batch adversarial loss: 0.667317\n",
      "epoch 22; iter: 0; batch classifier loss: 0.614361; batch adversarial loss: 0.649353\n",
      "epoch 23; iter: 0; batch classifier loss: 0.626082; batch adversarial loss: 0.660205\n",
      "epoch 24; iter: 0; batch classifier loss: 0.583016; batch adversarial loss: 0.644476\n",
      "epoch 25; iter: 0; batch classifier loss: 0.607770; batch adversarial loss: 0.625667\n",
      "epoch 26; iter: 0; batch classifier loss: 0.602697; batch adversarial loss: 0.693272\n",
      "epoch 27; iter: 0; batch classifier loss: 0.626420; batch adversarial loss: 0.653911\n",
      "epoch 28; iter: 0; batch classifier loss: 0.585915; batch adversarial loss: 0.618643\n",
      "epoch 29; iter: 0; batch classifier loss: 0.601200; batch adversarial loss: 0.577887\n",
      "epoch 30; iter: 0; batch classifier loss: 0.584309; batch adversarial loss: 0.615095\n",
      "epoch 31; iter: 0; batch classifier loss: 0.589910; batch adversarial loss: 0.632541\n",
      "epoch 32; iter: 0; batch classifier loss: 0.544564; batch adversarial loss: 0.657168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.610988; batch adversarial loss: 0.609374\n",
      "epoch 34; iter: 0; batch classifier loss: 0.648639; batch adversarial loss: 0.606828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.564314; batch adversarial loss: 0.574466\n",
      "epoch 36; iter: 0; batch classifier loss: 0.587479; batch adversarial loss: 0.646072\n",
      "epoch 37; iter: 0; batch classifier loss: 0.624399; batch adversarial loss: 0.612257\n",
      "epoch 38; iter: 0; batch classifier loss: 0.573570; batch adversarial loss: 0.638515\n",
      "epoch 39; iter: 0; batch classifier loss: 0.593628; batch adversarial loss: 0.648459\n",
      "epoch 40; iter: 0; batch classifier loss: 0.581202; batch adversarial loss: 0.660977\n",
      "epoch 41; iter: 0; batch classifier loss: 0.596283; batch adversarial loss: 0.688291\n",
      "epoch 42; iter: 0; batch classifier loss: 0.599105; batch adversarial loss: 0.626064\n",
      "epoch 43; iter: 0; batch classifier loss: 0.675756; batch adversarial loss: 0.667421\n",
      "epoch 44; iter: 0; batch classifier loss: 0.621000; batch adversarial loss: 0.650001\n",
      "epoch 45; iter: 0; batch classifier loss: 0.619528; batch adversarial loss: 0.607917\n",
      "epoch 46; iter: 0; batch classifier loss: 0.601243; batch adversarial loss: 0.622512\n",
      "epoch 47; iter: 0; batch classifier loss: 0.571873; batch adversarial loss: 0.632807\n",
      "epoch 48; iter: 0; batch classifier loss: 0.637939; batch adversarial loss: 0.680258\n",
      "epoch 49; iter: 0; batch classifier loss: 0.627109; batch adversarial loss: 0.649779\n",
      "epoch 0; iter: 0; batch classifier loss: 3.470306; batch adversarial loss: 0.693103\n",
      "epoch 1; iter: 0; batch classifier loss: 0.912709; batch adversarial loss: 0.695470\n",
      "epoch 2; iter: 0; batch classifier loss: 0.765506; batch adversarial loss: 0.657415\n",
      "epoch 3; iter: 0; batch classifier loss: 0.650382; batch adversarial loss: 0.642541\n",
      "epoch 4; iter: 0; batch classifier loss: 0.698009; batch adversarial loss: 0.697752\n",
      "epoch 5; iter: 0; batch classifier loss: 0.752202; batch adversarial loss: 0.724737\n",
      "epoch 6; iter: 0; batch classifier loss: 0.664314; batch adversarial loss: 0.689163\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596076; batch adversarial loss: 0.706668\n",
      "epoch 8; iter: 0; batch classifier loss: 0.623111; batch adversarial loss: 0.651800\n",
      "epoch 9; iter: 0; batch classifier loss: 0.629329; batch adversarial loss: 0.641538\n",
      "epoch 10; iter: 0; batch classifier loss: 0.671082; batch adversarial loss: 0.645438\n",
      "epoch 11; iter: 0; batch classifier loss: 0.657110; batch adversarial loss: 0.671917\n",
      "epoch 12; iter: 0; batch classifier loss: 0.636439; batch adversarial loss: 0.665277\n",
      "epoch 13; iter: 0; batch classifier loss: 0.651471; batch adversarial loss: 0.667126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548657; batch adversarial loss: 0.699612\n",
      "epoch 15; iter: 0; batch classifier loss: 0.678867; batch adversarial loss: 0.678269\n",
      "epoch 16; iter: 0; batch classifier loss: 0.670505; batch adversarial loss: 0.604614\n",
      "epoch 17; iter: 0; batch classifier loss: 0.586510; batch adversarial loss: 0.647302\n",
      "epoch 18; iter: 0; batch classifier loss: 0.627341; batch adversarial loss: 0.670261\n",
      "epoch 19; iter: 0; batch classifier loss: 0.680363; batch adversarial loss: 0.705760\n",
      "epoch 20; iter: 0; batch classifier loss: 0.564664; batch adversarial loss: 0.627661\n",
      "epoch 21; iter: 0; batch classifier loss: 0.692275; batch adversarial loss: 0.613281\n",
      "epoch 22; iter: 0; batch classifier loss: 0.598429; batch adversarial loss: 0.692881\n",
      "epoch 23; iter: 0; batch classifier loss: 0.695033; batch adversarial loss: 0.613938\n",
      "epoch 24; iter: 0; batch classifier loss: 0.595331; batch adversarial loss: 0.668634\n",
      "epoch 25; iter: 0; batch classifier loss: 0.608452; batch adversarial loss: 0.612645\n",
      "epoch 26; iter: 0; batch classifier loss: 0.524969; batch adversarial loss: 0.628295\n",
      "epoch 27; iter: 0; batch classifier loss: 0.573094; batch adversarial loss: 0.636847\n",
      "epoch 28; iter: 0; batch classifier loss: 0.577369; batch adversarial loss: 0.668922\n",
      "epoch 29; iter: 0; batch classifier loss: 0.611269; batch adversarial loss: 0.615709\n",
      "epoch 30; iter: 0; batch classifier loss: 0.577583; batch adversarial loss: 0.665912\n",
      "epoch 31; iter: 0; batch classifier loss: 0.665122; batch adversarial loss: 0.611533\n",
      "epoch 32; iter: 0; batch classifier loss: 0.605632; batch adversarial loss: 0.661045\n",
      "epoch 33; iter: 0; batch classifier loss: 0.640775; batch adversarial loss: 0.671274\n",
      "epoch 34; iter: 0; batch classifier loss: 0.609883; batch adversarial loss: 0.656514\n",
      "epoch 35; iter: 0; batch classifier loss: 0.622073; batch adversarial loss: 0.604900\n",
      "epoch 36; iter: 0; batch classifier loss: 0.590923; batch adversarial loss: 0.619620\n",
      "epoch 37; iter: 0; batch classifier loss: 0.549888; batch adversarial loss: 0.602553\n",
      "epoch 38; iter: 0; batch classifier loss: 0.627159; batch adversarial loss: 0.651541\n",
      "epoch 39; iter: 0; batch classifier loss: 0.567231; batch adversarial loss: 0.669897\n",
      "epoch 40; iter: 0; batch classifier loss: 0.588433; batch adversarial loss: 0.657862\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592158; batch adversarial loss: 0.614114\n",
      "epoch 42; iter: 0; batch classifier loss: 0.683697; batch adversarial loss: 0.637239\n",
      "epoch 43; iter: 0; batch classifier loss: 0.615694; batch adversarial loss: 0.637814\n",
      "epoch 44; iter: 0; batch classifier loss: 0.657712; batch adversarial loss: 0.610002\n",
      "epoch 45; iter: 0; batch classifier loss: 0.635093; batch adversarial loss: 0.636917\n",
      "epoch 46; iter: 0; batch classifier loss: 0.611302; batch adversarial loss: 0.665225\n",
      "epoch 47; iter: 0; batch classifier loss: 0.613211; batch adversarial loss: 0.659294\n",
      "epoch 48; iter: 0; batch classifier loss: 0.614136; batch adversarial loss: 0.602739\n",
      "epoch 49; iter: 0; batch classifier loss: 0.573993; batch adversarial loss: 0.674889\n",
      "epoch 0; iter: 0; batch classifier loss: 2.344568; batch adversarial loss: 0.721056\n",
      "epoch 1; iter: 0; batch classifier loss: 0.996319; batch adversarial loss: 0.681107\n",
      "epoch 2; iter: 0; batch classifier loss: 0.759455; batch adversarial loss: 0.674627\n",
      "epoch 3; iter: 0; batch classifier loss: 0.686887; batch adversarial loss: 0.661130\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603081; batch adversarial loss: 0.644440\n",
      "epoch 5; iter: 0; batch classifier loss: 0.706314; batch adversarial loss: 0.699584\n",
      "epoch 6; iter: 0; batch classifier loss: 0.696822; batch adversarial loss: 0.667303\n",
      "epoch 7; iter: 0; batch classifier loss: 0.637216; batch adversarial loss: 0.680232\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611062; batch adversarial loss: 0.679358\n",
      "epoch 9; iter: 0; batch classifier loss: 0.650729; batch adversarial loss: 0.680301\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583266; batch adversarial loss: 0.674762\n",
      "epoch 11; iter: 0; batch classifier loss: 0.613772; batch adversarial loss: 0.672338\n",
      "epoch 12; iter: 0; batch classifier loss: 0.618862; batch adversarial loss: 0.657701\n",
      "epoch 13; iter: 0; batch classifier loss: 0.628025; batch adversarial loss: 0.668914\n",
      "epoch 14; iter: 0; batch classifier loss: 0.630199; batch adversarial loss: 0.659328\n",
      "epoch 15; iter: 0; batch classifier loss: 0.603055; batch adversarial loss: 0.623589\n",
      "epoch 16; iter: 0; batch classifier loss: 0.637172; batch adversarial loss: 0.653177\n",
      "epoch 17; iter: 0; batch classifier loss: 0.616515; batch adversarial loss: 0.633034\n",
      "epoch 18; iter: 0; batch classifier loss: 0.598900; batch adversarial loss: 0.649053\n",
      "epoch 19; iter: 0; batch classifier loss: 0.681883; batch adversarial loss: 0.663656\n",
      "epoch 20; iter: 0; batch classifier loss: 0.645832; batch adversarial loss: 0.657843\n",
      "epoch 21; iter: 0; batch classifier loss: 0.604371; batch adversarial loss: 0.706830\n",
      "epoch 22; iter: 0; batch classifier loss: 0.611319; batch adversarial loss: 0.643003\n",
      "epoch 23; iter: 0; batch classifier loss: 0.601884; batch adversarial loss: 0.660530\n",
      "epoch 24; iter: 0; batch classifier loss: 0.615429; batch adversarial loss: 0.621109\n",
      "epoch 25; iter: 0; batch classifier loss: 0.621866; batch adversarial loss: 0.678151\n",
      "epoch 26; iter: 0; batch classifier loss: 0.631560; batch adversarial loss: 0.586731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.571763; batch adversarial loss: 0.642312\n",
      "epoch 28; iter: 0; batch classifier loss: 0.635412; batch adversarial loss: 0.619311\n",
      "epoch 29; iter: 0; batch classifier loss: 0.645548; batch adversarial loss: 0.636070\n",
      "epoch 30; iter: 0; batch classifier loss: 0.600934; batch adversarial loss: 0.663854\n",
      "epoch 31; iter: 0; batch classifier loss: 0.556819; batch adversarial loss: 0.644856\n",
      "epoch 32; iter: 0; batch classifier loss: 0.652715; batch adversarial loss: 0.561043\n",
      "epoch 33; iter: 0; batch classifier loss: 0.579332; batch adversarial loss: 0.625865\n",
      "epoch 34; iter: 0; batch classifier loss: 0.625317; batch adversarial loss: 0.658865\n",
      "epoch 35; iter: 0; batch classifier loss: 0.576488; batch adversarial loss: 0.614151\n",
      "epoch 36; iter: 0; batch classifier loss: 0.593985; batch adversarial loss: 0.629544\n",
      "epoch 37; iter: 0; batch classifier loss: 0.651873; batch adversarial loss: 0.666773\n",
      "epoch 38; iter: 0; batch classifier loss: 0.619434; batch adversarial loss: 0.630673\n",
      "epoch 39; iter: 0; batch classifier loss: 0.599918; batch adversarial loss: 0.598471\n",
      "epoch 40; iter: 0; batch classifier loss: 0.580203; batch adversarial loss: 0.629735\n",
      "epoch 41; iter: 0; batch classifier loss: 0.604829; batch adversarial loss: 0.631372\n",
      "epoch 42; iter: 0; batch classifier loss: 0.632156; batch adversarial loss: 0.651546\n",
      "epoch 43; iter: 0; batch classifier loss: 0.602586; batch adversarial loss: 0.664882\n",
      "epoch 44; iter: 0; batch classifier loss: 0.611500; batch adversarial loss: 0.632341\n",
      "epoch 45; iter: 0; batch classifier loss: 0.619955; batch adversarial loss: 0.675654\n",
      "epoch 46; iter: 0; batch classifier loss: 0.657390; batch adversarial loss: 0.638227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.568248; batch adversarial loss: 0.680969\n",
      "epoch 48; iter: 0; batch classifier loss: 0.622822; batch adversarial loss: 0.646919\n",
      "epoch 49; iter: 0; batch classifier loss: 0.640503; batch adversarial loss: 0.681224\n",
      "epoch 0; iter: 0; batch classifier loss: 1.047726; batch adversarial loss: 0.683593\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718657; batch adversarial loss: 0.713465\n",
      "epoch 2; iter: 0; batch classifier loss: 0.814840; batch adversarial loss: 0.730220\n",
      "epoch 3; iter: 0; batch classifier loss: 0.601538; batch adversarial loss: 0.675121\n",
      "epoch 4; iter: 0; batch classifier loss: 0.666734; batch adversarial loss: 0.666628\n",
      "epoch 5; iter: 0; batch classifier loss: 0.727583; batch adversarial loss: 0.631643\n",
      "epoch 6; iter: 0; batch classifier loss: 0.668183; batch adversarial loss: 0.678446\n",
      "epoch 7; iter: 0; batch classifier loss: 0.666423; batch adversarial loss: 0.724849\n",
      "epoch 8; iter: 0; batch classifier loss: 0.577868; batch adversarial loss: 0.633117\n",
      "epoch 9; iter: 0; batch classifier loss: 0.644739; batch adversarial loss: 0.645576\n",
      "epoch 10; iter: 0; batch classifier loss: 0.792047; batch adversarial loss: 0.580651\n",
      "epoch 11; iter: 0; batch classifier loss: 0.581864; batch adversarial loss: 0.648381\n",
      "epoch 12; iter: 0; batch classifier loss: 0.563985; batch adversarial loss: 0.696326\n",
      "epoch 13; iter: 0; batch classifier loss: 0.636468; batch adversarial loss: 0.615084\n",
      "epoch 14; iter: 0; batch classifier loss: 0.594331; batch adversarial loss: 0.661925\n",
      "epoch 15; iter: 0; batch classifier loss: 0.637316; batch adversarial loss: 0.683921\n",
      "epoch 16; iter: 0; batch classifier loss: 0.641947; batch adversarial loss: 0.627545\n",
      "epoch 17; iter: 0; batch classifier loss: 0.594195; batch adversarial loss: 0.651607\n",
      "epoch 18; iter: 0; batch classifier loss: 0.643793; batch adversarial loss: 0.631714\n",
      "epoch 19; iter: 0; batch classifier loss: 0.561734; batch adversarial loss: 0.650156\n",
      "epoch 20; iter: 0; batch classifier loss: 0.621029; batch adversarial loss: 0.709117\n",
      "epoch 21; iter: 0; batch classifier loss: 0.567657; batch adversarial loss: 0.583694\n",
      "epoch 22; iter: 0; batch classifier loss: 0.645580; batch adversarial loss: 0.642215\n",
      "epoch 23; iter: 0; batch classifier loss: 0.575518; batch adversarial loss: 0.635262\n",
      "epoch 24; iter: 0; batch classifier loss: 0.616795; batch adversarial loss: 0.628592\n",
      "epoch 25; iter: 0; batch classifier loss: 0.626754; batch adversarial loss: 0.619060\n",
      "epoch 26; iter: 0; batch classifier loss: 0.618149; batch adversarial loss: 0.715564\n",
      "epoch 27; iter: 0; batch classifier loss: 0.601977; batch adversarial loss: 0.645530\n",
      "epoch 28; iter: 0; batch classifier loss: 0.544250; batch adversarial loss: 0.622528\n",
      "epoch 29; iter: 0; batch classifier loss: 0.594835; batch adversarial loss: 0.611439\n",
      "epoch 30; iter: 0; batch classifier loss: 0.593570; batch adversarial loss: 0.660847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.584901; batch adversarial loss: 0.685997\n",
      "epoch 32; iter: 0; batch classifier loss: 0.588084; batch adversarial loss: 0.600411\n",
      "epoch 33; iter: 0; batch classifier loss: 0.598391; batch adversarial loss: 0.682590\n",
      "epoch 34; iter: 0; batch classifier loss: 0.699243; batch adversarial loss: 0.622192\n",
      "epoch 35; iter: 0; batch classifier loss: 0.591049; batch adversarial loss: 0.602257\n",
      "epoch 36; iter: 0; batch classifier loss: 0.665758; batch adversarial loss: 0.594780\n",
      "epoch 37; iter: 0; batch classifier loss: 0.556991; batch adversarial loss: 0.607164\n",
      "epoch 38; iter: 0; batch classifier loss: 0.644873; batch adversarial loss: 0.611373\n",
      "epoch 39; iter: 0; batch classifier loss: 0.615650; batch adversarial loss: 0.609173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.548982; batch adversarial loss: 0.610329\n",
      "epoch 41; iter: 0; batch classifier loss: 0.619452; batch adversarial loss: 0.642552\n",
      "epoch 42; iter: 0; batch classifier loss: 0.533510; batch adversarial loss: 0.641610\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537377; batch adversarial loss: 0.571510\n",
      "epoch 44; iter: 0; batch classifier loss: 0.650072; batch adversarial loss: 0.627865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.626374; batch adversarial loss: 0.642741\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551526; batch adversarial loss: 0.626531\n",
      "epoch 47; iter: 0; batch classifier loss: 0.645097; batch adversarial loss: 0.630765\n",
      "epoch 48; iter: 0; batch classifier loss: 0.631296; batch adversarial loss: 0.625053\n",
      "epoch 49; iter: 0; batch classifier loss: 0.631772; batch adversarial loss: 0.620631\n",
      "epoch 0; iter: 0; batch classifier loss: 2.278045; batch adversarial loss: 0.706656\n",
      "epoch 1; iter: 0; batch classifier loss: 0.909570; batch adversarial loss: 0.830145\n",
      "epoch 2; iter: 0; batch classifier loss: 0.955740; batch adversarial loss: 0.932972\n",
      "epoch 3; iter: 0; batch classifier loss: 0.747916; batch adversarial loss: 0.872693\n",
      "epoch 4; iter: 0; batch classifier loss: 0.624733; batch adversarial loss: 0.842800\n",
      "epoch 5; iter: 0; batch classifier loss: 0.769940; batch adversarial loss: 0.844636\n",
      "epoch 6; iter: 0; batch classifier loss: 0.765002; batch adversarial loss: 0.848634\n",
      "epoch 7; iter: 0; batch classifier loss: 0.839744; batch adversarial loss: 0.822919\n",
      "epoch 8; iter: 0; batch classifier loss: 0.756338; batch adversarial loss: 0.783222\n",
      "epoch 9; iter: 0; batch classifier loss: 0.819048; batch adversarial loss: 0.772205\n",
      "epoch 10; iter: 0; batch classifier loss: 0.835337; batch adversarial loss: 0.733924\n",
      "epoch 11; iter: 0; batch classifier loss: 0.661295; batch adversarial loss: 0.701710\n",
      "epoch 12; iter: 0; batch classifier loss: 0.667939; batch adversarial loss: 0.673500\n",
      "epoch 13; iter: 0; batch classifier loss: 0.611714; batch adversarial loss: 0.680071\n",
      "epoch 14; iter: 0; batch classifier loss: 0.621337; batch adversarial loss: 0.650758\n",
      "epoch 15; iter: 0; batch classifier loss: 0.612440; batch adversarial loss: 0.619554\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571564; batch adversarial loss: 0.633693\n",
      "epoch 17; iter: 0; batch classifier loss: 0.643134; batch adversarial loss: 0.657103\n",
      "epoch 18; iter: 0; batch classifier loss: 0.600333; batch adversarial loss: 0.625433\n",
      "epoch 19; iter: 0; batch classifier loss: 0.660784; batch adversarial loss: 0.651871\n",
      "epoch 20; iter: 0; batch classifier loss: 0.615901; batch adversarial loss: 0.642012\n",
      "epoch 21; iter: 0; batch classifier loss: 0.654446; batch adversarial loss: 0.639792\n",
      "epoch 22; iter: 0; batch classifier loss: 0.562051; batch adversarial loss: 0.666234\n",
      "epoch 23; iter: 0; batch classifier loss: 0.637185; batch adversarial loss: 0.670616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.637016; batch adversarial loss: 0.704941\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558273; batch adversarial loss: 0.600760\n",
      "epoch 26; iter: 0; batch classifier loss: 0.667480; batch adversarial loss: 0.642752\n",
      "epoch 27; iter: 0; batch classifier loss: 0.590132; batch adversarial loss: 0.647738\n",
      "epoch 28; iter: 0; batch classifier loss: 0.608410; batch adversarial loss: 0.637015\n",
      "epoch 29; iter: 0; batch classifier loss: 0.622604; batch adversarial loss: 0.609701\n",
      "epoch 30; iter: 0; batch classifier loss: 0.574579; batch adversarial loss: 0.629652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.679344; batch adversarial loss: 0.673503\n",
      "epoch 32; iter: 0; batch classifier loss: 0.551995; batch adversarial loss: 0.566748\n",
      "epoch 33; iter: 0; batch classifier loss: 0.628981; batch adversarial loss: 0.597035\n",
      "epoch 34; iter: 0; batch classifier loss: 0.613334; batch adversarial loss: 0.643784\n",
      "epoch 35; iter: 0; batch classifier loss: 0.670838; batch adversarial loss: 0.655027\n",
      "epoch 36; iter: 0; batch classifier loss: 0.639462; batch adversarial loss: 0.593515\n",
      "epoch 37; iter: 0; batch classifier loss: 0.578605; batch adversarial loss: 0.605042\n",
      "epoch 38; iter: 0; batch classifier loss: 0.642865; batch adversarial loss: 0.672987\n",
      "epoch 39; iter: 0; batch classifier loss: 0.590581; batch adversarial loss: 0.684349\n",
      "epoch 40; iter: 0; batch classifier loss: 0.597351; batch adversarial loss: 0.639682\n",
      "epoch 41; iter: 0; batch classifier loss: 0.629024; batch adversarial loss: 0.587798\n",
      "epoch 42; iter: 0; batch classifier loss: 0.652244; batch adversarial loss: 0.623110\n",
      "epoch 43; iter: 0; batch classifier loss: 0.562495; batch adversarial loss: 0.644982\n",
      "epoch 44; iter: 0; batch classifier loss: 0.604840; batch adversarial loss: 0.640795\n",
      "epoch 45; iter: 0; batch classifier loss: 0.592632; batch adversarial loss: 0.636100\n",
      "epoch 46; iter: 0; batch classifier loss: 0.584265; batch adversarial loss: 0.577105\n",
      "epoch 47; iter: 0; batch classifier loss: 0.593677; batch adversarial loss: 0.633887\n",
      "epoch 48; iter: 0; batch classifier loss: 0.620505; batch adversarial loss: 0.613413\n",
      "epoch 49; iter: 0; batch classifier loss: 0.569938; batch adversarial loss: 0.588005\n",
      "epoch 0; iter: 0; batch classifier loss: 3.750821; batch adversarial loss: 1.047767\n",
      "epoch 1; iter: 0; batch classifier loss: 1.131873; batch adversarial loss: 0.928357\n",
      "epoch 2; iter: 0; batch classifier loss: 0.913724; batch adversarial loss: 0.889681\n",
      "epoch 3; iter: 0; batch classifier loss: 0.684012; batch adversarial loss: 0.862309\n",
      "epoch 4; iter: 0; batch classifier loss: 0.701119; batch adversarial loss: 0.873861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.820483; batch adversarial loss: 0.705290\n",
      "epoch 6; iter: 0; batch classifier loss: 0.608857; batch adversarial loss: 0.776673\n",
      "epoch 7; iter: 0; batch classifier loss: 0.625647; batch adversarial loss: 0.748548\n",
      "epoch 8; iter: 0; batch classifier loss: 0.733455; batch adversarial loss: 0.764047\n",
      "epoch 9; iter: 0; batch classifier loss: 0.633474; batch adversarial loss: 0.735303\n",
      "epoch 10; iter: 0; batch classifier loss: 0.643403; batch adversarial loss: 0.735973\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595963; batch adversarial loss: 0.709301\n",
      "epoch 12; iter: 0; batch classifier loss: 0.703744; batch adversarial loss: 0.701196\n",
      "epoch 13; iter: 0; batch classifier loss: 0.677210; batch adversarial loss: 0.689799\n",
      "epoch 14; iter: 0; batch classifier loss: 0.684625; batch adversarial loss: 0.658662\n",
      "epoch 15; iter: 0; batch classifier loss: 0.597498; batch adversarial loss: 0.693297\n",
      "epoch 16; iter: 0; batch classifier loss: 0.645529; batch adversarial loss: 0.713928\n",
      "epoch 17; iter: 0; batch classifier loss: 0.645592; batch adversarial loss: 0.686682\n",
      "epoch 18; iter: 0; batch classifier loss: 0.573168; batch adversarial loss: 0.699528\n",
      "epoch 19; iter: 0; batch classifier loss: 0.646493; batch adversarial loss: 0.639864\n",
      "epoch 20; iter: 0; batch classifier loss: 0.617721; batch adversarial loss: 0.698917\n",
      "epoch 21; iter: 0; batch classifier loss: 0.621036; batch adversarial loss: 0.712248\n",
      "epoch 22; iter: 0; batch classifier loss: 0.611248; batch adversarial loss: 0.619416\n",
      "epoch 23; iter: 0; batch classifier loss: 0.628829; batch adversarial loss: 0.690129\n",
      "epoch 24; iter: 0; batch classifier loss: 0.599902; batch adversarial loss: 0.626021\n",
      "epoch 25; iter: 0; batch classifier loss: 0.625126; batch adversarial loss: 0.664656\n",
      "epoch 26; iter: 0; batch classifier loss: 0.657343; batch adversarial loss: 0.681360\n",
      "epoch 27; iter: 0; batch classifier loss: 0.646531; batch adversarial loss: 0.634762\n",
      "epoch 28; iter: 0; batch classifier loss: 0.613022; batch adversarial loss: 0.674541\n",
      "epoch 29; iter: 0; batch classifier loss: 0.631664; batch adversarial loss: 0.657822\n",
      "epoch 30; iter: 0; batch classifier loss: 0.639654; batch adversarial loss: 0.647342\n",
      "epoch 31; iter: 0; batch classifier loss: 0.523705; batch adversarial loss: 0.636401\n",
      "epoch 32; iter: 0; batch classifier loss: 0.638933; batch adversarial loss: 0.634648\n",
      "epoch 33; iter: 0; batch classifier loss: 0.621082; batch adversarial loss: 0.638917\n",
      "epoch 34; iter: 0; batch classifier loss: 0.604507; batch adversarial loss: 0.650796\n",
      "epoch 35; iter: 0; batch classifier loss: 0.662819; batch adversarial loss: 0.631316\n",
      "epoch 36; iter: 0; batch classifier loss: 0.658192; batch adversarial loss: 0.625298\n",
      "epoch 37; iter: 0; batch classifier loss: 0.688114; batch adversarial loss: 0.665450\n",
      "epoch 38; iter: 0; batch classifier loss: 0.575986; batch adversarial loss: 0.637250\n",
      "epoch 39; iter: 0; batch classifier loss: 0.600222; batch adversarial loss: 0.682727\n",
      "epoch 40; iter: 0; batch classifier loss: 0.609204; batch adversarial loss: 0.623449\n",
      "epoch 41; iter: 0; batch classifier loss: 0.590662; batch adversarial loss: 0.680941\n",
      "epoch 42; iter: 0; batch classifier loss: 0.657281; batch adversarial loss: 0.606654\n",
      "epoch 43; iter: 0; batch classifier loss: 0.634487; batch adversarial loss: 0.630502\n",
      "epoch 44; iter: 0; batch classifier loss: 0.608849; batch adversarial loss: 0.619219\n",
      "epoch 45; iter: 0; batch classifier loss: 0.609774; batch adversarial loss: 0.643278\n",
      "epoch 46; iter: 0; batch classifier loss: 0.557877; batch adversarial loss: 0.693963\n",
      "epoch 47; iter: 0; batch classifier loss: 0.591322; batch adversarial loss: 0.621470\n",
      "epoch 48; iter: 0; batch classifier loss: 0.597021; batch adversarial loss: 0.597686\n",
      "epoch 49; iter: 0; batch classifier loss: 0.590173; batch adversarial loss: 0.703747\n",
      "epoch 0; iter: 0; batch classifier loss: 1.093032; batch adversarial loss: 0.696152\n",
      "epoch 1; iter: 0; batch classifier loss: 0.744708; batch adversarial loss: 0.690850\n",
      "epoch 2; iter: 0; batch classifier loss: 0.700522; batch adversarial loss: 0.677482\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623972; batch adversarial loss: 0.663324\n",
      "epoch 4; iter: 0; batch classifier loss: 0.698218; batch adversarial loss: 0.658497\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573111; batch adversarial loss: 0.658100\n",
      "epoch 6; iter: 0; batch classifier loss: 0.675284; batch adversarial loss: 0.666637\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626579; batch adversarial loss: 0.642850\n",
      "epoch 8; iter: 0; batch classifier loss: 0.672490; batch adversarial loss: 0.673747\n",
      "epoch 9; iter: 0; batch classifier loss: 0.625650; batch adversarial loss: 0.643388\n",
      "epoch 10; iter: 0; batch classifier loss: 0.582538; batch adversarial loss: 0.671818\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579008; batch adversarial loss: 0.626291\n",
      "epoch 12; iter: 0; batch classifier loss: 0.629528; batch adversarial loss: 0.664129\n",
      "epoch 13; iter: 0; batch classifier loss: 0.561582; batch adversarial loss: 0.668206\n",
      "epoch 14; iter: 0; batch classifier loss: 0.621331; batch adversarial loss: 0.613834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.559442; batch adversarial loss: 0.605014\n",
      "epoch 16; iter: 0; batch classifier loss: 0.618801; batch adversarial loss: 0.630218\n",
      "epoch 17; iter: 0; batch classifier loss: 0.538155; batch adversarial loss: 0.643983\n",
      "epoch 18; iter: 0; batch classifier loss: 0.590131; batch adversarial loss: 0.626806\n",
      "epoch 19; iter: 0; batch classifier loss: 0.568650; batch adversarial loss: 0.633329\n",
      "epoch 20; iter: 0; batch classifier loss: 0.627417; batch adversarial loss: 0.662744\n",
      "epoch 21; iter: 0; batch classifier loss: 0.660805; batch adversarial loss: 0.650771\n",
      "epoch 22; iter: 0; batch classifier loss: 0.631871; batch adversarial loss: 0.648005\n",
      "epoch 23; iter: 0; batch classifier loss: 0.642515; batch adversarial loss: 0.626049\n",
      "epoch 24; iter: 0; batch classifier loss: 0.622274; batch adversarial loss: 0.631558\n",
      "epoch 25; iter: 0; batch classifier loss: 0.641239; batch adversarial loss: 0.609954\n",
      "epoch 26; iter: 0; batch classifier loss: 0.561252; batch adversarial loss: 0.646607\n",
      "epoch 27; iter: 0; batch classifier loss: 0.636236; batch adversarial loss: 0.642785\n",
      "epoch 28; iter: 0; batch classifier loss: 0.561805; batch adversarial loss: 0.587302\n",
      "epoch 29; iter: 0; batch classifier loss: 0.564863; batch adversarial loss: 0.642163\n",
      "epoch 30; iter: 0; batch classifier loss: 0.536351; batch adversarial loss: 0.587829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.583990; batch adversarial loss: 0.660247\n",
      "epoch 32; iter: 0; batch classifier loss: 0.634104; batch adversarial loss: 0.591134\n",
      "epoch 33; iter: 0; batch classifier loss: 0.576808; batch adversarial loss: 0.662788\n",
      "epoch 34; iter: 0; batch classifier loss: 0.643812; batch adversarial loss: 0.664595\n",
      "epoch 35; iter: 0; batch classifier loss: 0.680864; batch adversarial loss: 0.620067\n",
      "epoch 36; iter: 0; batch classifier loss: 0.627997; batch adversarial loss: 0.621145\n",
      "epoch 37; iter: 0; batch classifier loss: 0.687516; batch adversarial loss: 0.707521\n",
      "epoch 38; iter: 0; batch classifier loss: 0.609586; batch adversarial loss: 0.656144\n",
      "epoch 39; iter: 0; batch classifier loss: 0.625434; batch adversarial loss: 0.598199\n",
      "epoch 40; iter: 0; batch classifier loss: 0.602786; batch adversarial loss: 0.616754\n",
      "epoch 41; iter: 0; batch classifier loss: 0.621975; batch adversarial loss: 0.662206\n",
      "epoch 42; iter: 0; batch classifier loss: 0.588237; batch adversarial loss: 0.612707\n",
      "epoch 43; iter: 0; batch classifier loss: 0.583194; batch adversarial loss: 0.632705\n",
      "epoch 44; iter: 0; batch classifier loss: 0.647741; batch adversarial loss: 0.642259\n",
      "epoch 45; iter: 0; batch classifier loss: 0.580077; batch adversarial loss: 0.600635\n",
      "epoch 46; iter: 0; batch classifier loss: 0.638717; batch adversarial loss: 0.655911\n",
      "epoch 47; iter: 0; batch classifier loss: 0.571108; batch adversarial loss: 0.654144\n",
      "epoch 48; iter: 0; batch classifier loss: 0.630144; batch adversarial loss: 0.626135\n",
      "epoch 49; iter: 0; batch classifier loss: 0.536666; batch adversarial loss: 0.586009\n",
      "epoch 0; iter: 0; batch classifier loss: 2.570908; batch adversarial loss: 0.693129\n",
      "epoch 1; iter: 0; batch classifier loss: 0.886540; batch adversarial loss: 0.666266\n",
      "epoch 2; iter: 0; batch classifier loss: 0.785440; batch adversarial loss: 0.670908\n",
      "epoch 3; iter: 0; batch classifier loss: 0.786204; batch adversarial loss: 0.655426\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598750; batch adversarial loss: 0.662018\n",
      "epoch 5; iter: 0; batch classifier loss: 0.653618; batch adversarial loss: 0.647324\n",
      "epoch 6; iter: 0; batch classifier loss: 0.717111; batch adversarial loss: 0.666642\n",
      "epoch 7; iter: 0; batch classifier loss: 0.597062; batch adversarial loss: 0.650736\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634460; batch adversarial loss: 0.631163\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599209; batch adversarial loss: 0.693982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612142; batch adversarial loss: 0.606401\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563212; batch adversarial loss: 0.667360\n",
      "epoch 12; iter: 0; batch classifier loss: 0.664399; batch adversarial loss: 0.579265\n",
      "epoch 13; iter: 0; batch classifier loss: 0.585056; batch adversarial loss: 0.680163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.670156; batch adversarial loss: 0.654692\n",
      "epoch 15; iter: 0; batch classifier loss: 0.598357; batch adversarial loss: 0.654046\n",
      "epoch 16; iter: 0; batch classifier loss: 0.576767; batch adversarial loss: 0.643887\n",
      "epoch 17; iter: 0; batch classifier loss: 0.611667; batch adversarial loss: 0.641831\n",
      "epoch 18; iter: 0; batch classifier loss: 0.617874; batch adversarial loss: 0.636979\n",
      "epoch 19; iter: 0; batch classifier loss: 0.618305; batch adversarial loss: 0.631285\n",
      "epoch 20; iter: 0; batch classifier loss: 0.587710; batch adversarial loss: 0.632335\n",
      "epoch 21; iter: 0; batch classifier loss: 0.632558; batch adversarial loss: 0.603480\n",
      "epoch 22; iter: 0; batch classifier loss: 0.630988; batch adversarial loss: 0.624109\n",
      "epoch 23; iter: 0; batch classifier loss: 0.585181; batch adversarial loss: 0.636386\n",
      "epoch 24; iter: 0; batch classifier loss: 0.591130; batch adversarial loss: 0.653086\n",
      "epoch 25; iter: 0; batch classifier loss: 0.621710; batch adversarial loss: 0.641904\n",
      "epoch 26; iter: 0; batch classifier loss: 0.650988; batch adversarial loss: 0.611925\n",
      "epoch 27; iter: 0; batch classifier loss: 0.676345; batch adversarial loss: 0.657357\n",
      "epoch 28; iter: 0; batch classifier loss: 0.557333; batch adversarial loss: 0.643688\n",
      "epoch 29; iter: 0; batch classifier loss: 0.606654; batch adversarial loss: 0.618621\n",
      "epoch 30; iter: 0; batch classifier loss: 0.593285; batch adversarial loss: 0.587965\n",
      "epoch 31; iter: 0; batch classifier loss: 0.587832; batch adversarial loss: 0.628116\n",
      "epoch 32; iter: 0; batch classifier loss: 0.592624; batch adversarial loss: 0.652449\n",
      "epoch 33; iter: 0; batch classifier loss: 0.627880; batch adversarial loss: 0.645378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.583092; batch adversarial loss: 0.658055\n",
      "epoch 35; iter: 0; batch classifier loss: 0.588571; batch adversarial loss: 0.644511\n",
      "epoch 36; iter: 0; batch classifier loss: 0.572490; batch adversarial loss: 0.613094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.681739; batch adversarial loss: 0.624616\n",
      "epoch 38; iter: 0; batch classifier loss: 0.593733; batch adversarial loss: 0.606180\n",
      "epoch 39; iter: 0; batch classifier loss: 0.569825; batch adversarial loss: 0.662897\n",
      "epoch 40; iter: 0; batch classifier loss: 0.627631; batch adversarial loss: 0.632783\n",
      "epoch 41; iter: 0; batch classifier loss: 0.552852; batch adversarial loss: 0.644515\n",
      "epoch 42; iter: 0; batch classifier loss: 0.652157; batch adversarial loss: 0.604909\n",
      "epoch 43; iter: 0; batch classifier loss: 0.640994; batch adversarial loss: 0.609148\n",
      "epoch 44; iter: 0; batch classifier loss: 0.662187; batch adversarial loss: 0.600049\n",
      "epoch 45; iter: 0; batch classifier loss: 0.664848; batch adversarial loss: 0.601907\n",
      "epoch 46; iter: 0; batch classifier loss: 0.673807; batch adversarial loss: 0.680793\n",
      "epoch 47; iter: 0; batch classifier loss: 0.637197; batch adversarial loss: 0.641368\n",
      "epoch 48; iter: 0; batch classifier loss: 0.586156; batch adversarial loss: 0.636340\n",
      "epoch 49; iter: 0; batch classifier loss: 0.664911; batch adversarial loss: 0.617995\n",
      "epoch 0; iter: 0; batch classifier loss: 1.176022; batch adversarial loss: 0.683416\n",
      "epoch 1; iter: 0; batch classifier loss: 0.771298; batch adversarial loss: 0.660754\n",
      "epoch 2; iter: 0; batch classifier loss: 0.729647; batch adversarial loss: 0.652191\n",
      "epoch 3; iter: 0; batch classifier loss: 0.657437; batch adversarial loss: 0.663615\n",
      "epoch 4; iter: 0; batch classifier loss: 0.765705; batch adversarial loss: 0.626964\n",
      "epoch 5; iter: 0; batch classifier loss: 0.699466; batch adversarial loss: 0.646167\n",
      "epoch 6; iter: 0; batch classifier loss: 0.707217; batch adversarial loss: 0.628182\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616415; batch adversarial loss: 0.624045\n",
      "epoch 8; iter: 0; batch classifier loss: 0.628338; batch adversarial loss: 0.699037\n",
      "epoch 9; iter: 0; batch classifier loss: 0.594890; batch adversarial loss: 0.626159\n",
      "epoch 10; iter: 0; batch classifier loss: 0.607730; batch adversarial loss: 0.632115\n",
      "epoch 11; iter: 0; batch classifier loss: 0.656066; batch adversarial loss: 0.646327\n",
      "epoch 12; iter: 0; batch classifier loss: 0.659275; batch adversarial loss: 0.629998\n",
      "epoch 13; iter: 0; batch classifier loss: 0.643714; batch adversarial loss: 0.597956\n",
      "epoch 14; iter: 0; batch classifier loss: 0.667944; batch adversarial loss: 0.596629\n",
      "epoch 15; iter: 0; batch classifier loss: 0.625469; batch adversarial loss: 0.609314\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571915; batch adversarial loss: 0.628739\n",
      "epoch 17; iter: 0; batch classifier loss: 0.637084; batch adversarial loss: 0.643554\n",
      "epoch 18; iter: 0; batch classifier loss: 0.594655; batch adversarial loss: 0.619477\n",
      "epoch 19; iter: 0; batch classifier loss: 0.606486; batch adversarial loss: 0.619007\n",
      "epoch 20; iter: 0; batch classifier loss: 0.604259; batch adversarial loss: 0.658597\n",
      "epoch 21; iter: 0; batch classifier loss: 0.629035; batch adversarial loss: 0.555935\n",
      "epoch 22; iter: 0; batch classifier loss: 0.581655; batch adversarial loss: 0.624381\n",
      "epoch 23; iter: 0; batch classifier loss: 0.660949; batch adversarial loss: 0.678144\n",
      "epoch 24; iter: 0; batch classifier loss: 0.623404; batch adversarial loss: 0.642306\n",
      "epoch 25; iter: 0; batch classifier loss: 0.679877; batch adversarial loss: 0.670043\n",
      "epoch 26; iter: 0; batch classifier loss: 0.691623; batch adversarial loss: 0.602862\n",
      "epoch 27; iter: 0; batch classifier loss: 0.656248; batch adversarial loss: 0.585196\n",
      "epoch 28; iter: 0; batch classifier loss: 0.584454; batch adversarial loss: 0.636554\n",
      "epoch 29; iter: 0; batch classifier loss: 0.599291; batch adversarial loss: 0.641886\n",
      "epoch 30; iter: 0; batch classifier loss: 0.651662; batch adversarial loss: 0.627558\n",
      "epoch 31; iter: 0; batch classifier loss: 0.603357; batch adversarial loss: 0.640471\n",
      "epoch 32; iter: 0; batch classifier loss: 0.609746; batch adversarial loss: 0.586152\n",
      "epoch 33; iter: 0; batch classifier loss: 0.567502; batch adversarial loss: 0.625255\n",
      "epoch 34; iter: 0; batch classifier loss: 0.595176; batch adversarial loss: 0.658448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.598808; batch adversarial loss: 0.663407\n",
      "epoch 36; iter: 0; batch classifier loss: 0.602664; batch adversarial loss: 0.650227\n",
      "epoch 37; iter: 0; batch classifier loss: 0.600766; batch adversarial loss: 0.615604\n",
      "epoch 38; iter: 0; batch classifier loss: 0.602667; batch adversarial loss: 0.645510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.663794; batch adversarial loss: 0.588070\n",
      "epoch 40; iter: 0; batch classifier loss: 0.623752; batch adversarial loss: 0.582874\n",
      "epoch 41; iter: 0; batch classifier loss: 0.569649; batch adversarial loss: 0.635685\n",
      "epoch 42; iter: 0; batch classifier loss: 0.648148; batch adversarial loss: 0.610946\n",
      "epoch 43; iter: 0; batch classifier loss: 0.626421; batch adversarial loss: 0.617811\n",
      "epoch 44; iter: 0; batch classifier loss: 0.581638; batch adversarial loss: 0.652792\n",
      "epoch 45; iter: 0; batch classifier loss: 0.586260; batch adversarial loss: 0.668406\n",
      "epoch 46; iter: 0; batch classifier loss: 0.545973; batch adversarial loss: 0.640926\n",
      "epoch 47; iter: 0; batch classifier loss: 0.642758; batch adversarial loss: 0.594748\n",
      "epoch 48; iter: 0; batch classifier loss: 0.574028; batch adversarial loss: 0.547362\n",
      "epoch 49; iter: 0; batch classifier loss: 0.625663; batch adversarial loss: 0.660381\n",
      "epoch 0; iter: 0; batch classifier loss: 3.260717; batch adversarial loss: 0.693157\n",
      "epoch 1; iter: 0; batch classifier loss: 0.911245; batch adversarial loss: 0.806059\n",
      "epoch 2; iter: 0; batch classifier loss: 0.750847; batch adversarial loss: 0.771401\n",
      "epoch 3; iter: 0; batch classifier loss: 0.801103; batch adversarial loss: 0.734157\n",
      "epoch 4; iter: 0; batch classifier loss: 0.769722; batch adversarial loss: 0.741341\n",
      "epoch 5; iter: 0; batch classifier loss: 0.639884; batch adversarial loss: 0.721591\n",
      "epoch 6; iter: 0; batch classifier loss: 0.637312; batch adversarial loss: 0.701472\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578688; batch adversarial loss: 0.692092\n",
      "epoch 8; iter: 0; batch classifier loss: 0.630233; batch adversarial loss: 0.693224\n",
      "epoch 9; iter: 0; batch classifier loss: 0.667180; batch adversarial loss: 0.676618\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612656; batch adversarial loss: 0.675245\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591574; batch adversarial loss: 0.672123\n",
      "epoch 12; iter: 0; batch classifier loss: 0.636715; batch adversarial loss: 0.652182\n",
      "epoch 13; iter: 0; batch classifier loss: 0.660410; batch adversarial loss: 0.675158\n",
      "epoch 14; iter: 0; batch classifier loss: 0.625727; batch adversarial loss: 0.657959\n",
      "epoch 15; iter: 0; batch classifier loss: 0.560149; batch adversarial loss: 0.626072\n",
      "epoch 16; iter: 0; batch classifier loss: 0.664606; batch adversarial loss: 0.670992\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592796; batch adversarial loss: 0.650611\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557137; batch adversarial loss: 0.646285\n",
      "epoch 19; iter: 0; batch classifier loss: 0.566318; batch adversarial loss: 0.663534\n",
      "epoch 20; iter: 0; batch classifier loss: 0.639724; batch adversarial loss: 0.618382\n",
      "epoch 21; iter: 0; batch classifier loss: 0.634090; batch adversarial loss: 0.612538\n",
      "epoch 22; iter: 0; batch classifier loss: 0.580471; batch adversarial loss: 0.627893\n",
      "epoch 23; iter: 0; batch classifier loss: 0.581653; batch adversarial loss: 0.637366\n",
      "epoch 24; iter: 0; batch classifier loss: 0.621188; batch adversarial loss: 0.655328\n",
      "epoch 25; iter: 0; batch classifier loss: 0.595261; batch adversarial loss: 0.675360\n",
      "epoch 26; iter: 0; batch classifier loss: 0.682716; batch adversarial loss: 0.598242\n",
      "epoch 27; iter: 0; batch classifier loss: 0.607871; batch adversarial loss: 0.605726\n",
      "epoch 28; iter: 0; batch classifier loss: 0.628933; batch adversarial loss: 0.661413\n",
      "epoch 29; iter: 0; batch classifier loss: 0.574448; batch adversarial loss: 0.593672\n",
      "epoch 30; iter: 0; batch classifier loss: 0.590795; batch adversarial loss: 0.666671\n",
      "epoch 31; iter: 0; batch classifier loss: 0.690496; batch adversarial loss: 0.614477\n",
      "epoch 32; iter: 0; batch classifier loss: 0.650745; batch adversarial loss: 0.634327\n",
      "epoch 33; iter: 0; batch classifier loss: 0.638494; batch adversarial loss: 0.637140\n",
      "epoch 34; iter: 0; batch classifier loss: 0.614273; batch adversarial loss: 0.658638\n",
      "epoch 35; iter: 0; batch classifier loss: 0.620037; batch adversarial loss: 0.631947\n",
      "epoch 36; iter: 0; batch classifier loss: 0.623986; batch adversarial loss: 0.630077\n",
      "epoch 37; iter: 0; batch classifier loss: 0.610036; batch adversarial loss: 0.615843\n",
      "epoch 38; iter: 0; batch classifier loss: 0.568661; batch adversarial loss: 0.620278\n",
      "epoch 39; iter: 0; batch classifier loss: 0.643678; batch adversarial loss: 0.660692\n",
      "epoch 40; iter: 0; batch classifier loss: 0.614655; batch adversarial loss: 0.664903\n",
      "epoch 41; iter: 0; batch classifier loss: 0.608171; batch adversarial loss: 0.630738\n",
      "epoch 42; iter: 0; batch classifier loss: 0.589498; batch adversarial loss: 0.645354\n",
      "epoch 43; iter: 0; batch classifier loss: 0.593341; batch adversarial loss: 0.612841\n",
      "epoch 44; iter: 0; batch classifier loss: 0.591172; batch adversarial loss: 0.616406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.612461; batch adversarial loss: 0.668812\n",
      "epoch 46; iter: 0; batch classifier loss: 0.620710; batch adversarial loss: 0.610524\n",
      "epoch 47; iter: 0; batch classifier loss: 0.585907; batch adversarial loss: 0.588194\n",
      "epoch 48; iter: 0; batch classifier loss: 0.594192; batch adversarial loss: 0.629031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.688742; batch adversarial loss: 0.644836\n",
      "epoch 0; iter: 0; batch classifier loss: 2.052474; batch adversarial loss: 0.712660\n",
      "epoch 1; iter: 0; batch classifier loss: 0.879971; batch adversarial loss: 0.659229\n",
      "epoch 2; iter: 0; batch classifier loss: 0.738427; batch adversarial loss: 0.667315\n",
      "epoch 3; iter: 0; batch classifier loss: 0.682619; batch adversarial loss: 0.633970\n",
      "epoch 4; iter: 0; batch classifier loss: 0.836607; batch adversarial loss: 0.651465\n",
      "epoch 5; iter: 0; batch classifier loss: 0.662817; batch adversarial loss: 0.614426\n",
      "epoch 6; iter: 0; batch classifier loss: 0.689318; batch adversarial loss: 0.648268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.652105; batch adversarial loss: 0.696741\n",
      "epoch 8; iter: 0; batch classifier loss: 0.677338; batch adversarial loss: 0.709132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.624418; batch adversarial loss: 0.649334\n",
      "epoch 10; iter: 0; batch classifier loss: 0.671735; batch adversarial loss: 0.644405\n",
      "epoch 11; iter: 0; batch classifier loss: 0.601953; batch adversarial loss: 0.622722\n",
      "epoch 12; iter: 0; batch classifier loss: 0.614773; batch adversarial loss: 0.649486\n",
      "epoch 13; iter: 0; batch classifier loss: 0.651522; batch adversarial loss: 0.677524\n",
      "epoch 14; iter: 0; batch classifier loss: 0.623509; batch adversarial loss: 0.646853\n",
      "epoch 15; iter: 0; batch classifier loss: 0.689583; batch adversarial loss: 0.643328\n",
      "epoch 16; iter: 0; batch classifier loss: 0.608831; batch adversarial loss: 0.639304\n",
      "epoch 17; iter: 0; batch classifier loss: 0.624862; batch adversarial loss: 0.638751\n",
      "epoch 18; iter: 0; batch classifier loss: 0.631008; batch adversarial loss: 0.676868\n",
      "epoch 19; iter: 0; batch classifier loss: 0.597445; batch adversarial loss: 0.604481\n",
      "epoch 20; iter: 0; batch classifier loss: 0.652115; batch adversarial loss: 0.663704\n",
      "epoch 21; iter: 0; batch classifier loss: 0.624810; batch adversarial loss: 0.652023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.576380; batch adversarial loss: 0.631734\n",
      "epoch 23; iter: 0; batch classifier loss: 0.608517; batch adversarial loss: 0.681910\n",
      "epoch 24; iter: 0; batch classifier loss: 0.575395; batch adversarial loss: 0.651050\n",
      "epoch 25; iter: 0; batch classifier loss: 0.657974; batch adversarial loss: 0.640023\n",
      "epoch 26; iter: 0; batch classifier loss: 0.626728; batch adversarial loss: 0.627232\n",
      "epoch 27; iter: 0; batch classifier loss: 0.580137; batch adversarial loss: 0.612133\n",
      "epoch 28; iter: 0; batch classifier loss: 0.602437; batch adversarial loss: 0.612077\n",
      "epoch 29; iter: 0; batch classifier loss: 0.502237; batch adversarial loss: 0.660343\n",
      "epoch 30; iter: 0; batch classifier loss: 0.610844; batch adversarial loss: 0.660112\n",
      "epoch 31; iter: 0; batch classifier loss: 0.533632; batch adversarial loss: 0.614562\n",
      "epoch 32; iter: 0; batch classifier loss: 0.639914; batch adversarial loss: 0.637215\n",
      "epoch 33; iter: 0; batch classifier loss: 0.580204; batch adversarial loss: 0.663080\n",
      "epoch 34; iter: 0; batch classifier loss: 0.604557; batch adversarial loss: 0.638994\n",
      "epoch 35; iter: 0; batch classifier loss: 0.640551; batch adversarial loss: 0.655352\n",
      "epoch 36; iter: 0; batch classifier loss: 0.585053; batch adversarial loss: 0.657037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.648146; batch adversarial loss: 0.591210\n",
      "epoch 38; iter: 0; batch classifier loss: 0.644703; batch adversarial loss: 0.675373\n",
      "epoch 39; iter: 0; batch classifier loss: 0.614283; batch adversarial loss: 0.654522\n",
      "epoch 40; iter: 0; batch classifier loss: 0.613010; batch adversarial loss: 0.648233\n",
      "epoch 41; iter: 0; batch classifier loss: 0.609495; batch adversarial loss: 0.642362\n",
      "epoch 42; iter: 0; batch classifier loss: 0.577935; batch adversarial loss: 0.635514\n",
      "epoch 43; iter: 0; batch classifier loss: 0.625208; batch adversarial loss: 0.675711\n",
      "epoch 44; iter: 0; batch classifier loss: 0.591122; batch adversarial loss: 0.670891\n",
      "epoch 45; iter: 0; batch classifier loss: 0.621020; batch adversarial loss: 0.634048\n",
      "epoch 46; iter: 0; batch classifier loss: 0.607945; batch adversarial loss: 0.587746\n",
      "epoch 47; iter: 0; batch classifier loss: 0.605406; batch adversarial loss: 0.642292\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603153; batch adversarial loss: 0.622622\n",
      "epoch 49; iter: 0; batch classifier loss: 0.592309; batch adversarial loss: 0.659770\n",
      "epoch 0; iter: 0; batch classifier loss: 1.171996; batch adversarial loss: 0.681851\n",
      "epoch 1; iter: 0; batch classifier loss: 0.822664; batch adversarial loss: 0.707138\n",
      "epoch 2; iter: 0; batch classifier loss: 0.763557; batch adversarial loss: 0.611381\n",
      "epoch 3; iter: 0; batch classifier loss: 0.726605; batch adversarial loss: 0.670338\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584350; batch adversarial loss: 0.680480\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630112; batch adversarial loss: 0.613473\n",
      "epoch 6; iter: 0; batch classifier loss: 0.650023; batch adversarial loss: 0.658701\n",
      "epoch 7; iter: 0; batch classifier loss: 0.634111; batch adversarial loss: 0.652474\n",
      "epoch 8; iter: 0; batch classifier loss: 0.650724; batch adversarial loss: 0.659729\n",
      "epoch 9; iter: 0; batch classifier loss: 0.653533; batch adversarial loss: 0.613324\n",
      "epoch 10; iter: 0; batch classifier loss: 0.633967; batch adversarial loss: 0.689778\n",
      "epoch 11; iter: 0; batch classifier loss: 0.685989; batch adversarial loss: 0.697451\n",
      "epoch 12; iter: 0; batch classifier loss: 0.629347; batch adversarial loss: 0.645109\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593205; batch adversarial loss: 0.654457\n",
      "epoch 14; iter: 0; batch classifier loss: 0.658015; batch adversarial loss: 0.674650\n",
      "epoch 15; iter: 0; batch classifier loss: 0.619800; batch adversarial loss: 0.673466\n",
      "epoch 16; iter: 0; batch classifier loss: 0.580577; batch adversarial loss: 0.628475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.604738; batch adversarial loss: 0.598126\n",
      "epoch 18; iter: 0; batch classifier loss: 0.696476; batch adversarial loss: 0.656291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.674058; batch adversarial loss: 0.647191\n",
      "epoch 20; iter: 0; batch classifier loss: 0.696427; batch adversarial loss: 0.661038\n",
      "epoch 21; iter: 0; batch classifier loss: 0.634424; batch adversarial loss: 0.633288\n",
      "epoch 22; iter: 0; batch classifier loss: 0.647985; batch adversarial loss: 0.631155\n",
      "epoch 23; iter: 0; batch classifier loss: 0.567101; batch adversarial loss: 0.637648\n",
      "epoch 24; iter: 0; batch classifier loss: 0.664425; batch adversarial loss: 0.623767\n",
      "epoch 25; iter: 0; batch classifier loss: 0.595265; batch adversarial loss: 0.605194\n",
      "epoch 26; iter: 0; batch classifier loss: 0.613994; batch adversarial loss: 0.624963\n",
      "epoch 27; iter: 0; batch classifier loss: 0.561373; batch adversarial loss: 0.622356\n",
      "epoch 28; iter: 0; batch classifier loss: 0.634072; batch adversarial loss: 0.646994\n",
      "epoch 29; iter: 0; batch classifier loss: 0.530830; batch adversarial loss: 0.630601\n",
      "epoch 30; iter: 0; batch classifier loss: 0.584549; batch adversarial loss: 0.608578\n",
      "epoch 31; iter: 0; batch classifier loss: 0.638340; batch adversarial loss: 0.636033\n",
      "epoch 32; iter: 0; batch classifier loss: 0.581589; batch adversarial loss: 0.644246\n",
      "epoch 33; iter: 0; batch classifier loss: 0.600908; batch adversarial loss: 0.648977\n",
      "epoch 34; iter: 0; batch classifier loss: 0.590272; batch adversarial loss: 0.628492\n",
      "epoch 35; iter: 0; batch classifier loss: 0.624759; batch adversarial loss: 0.682121\n",
      "epoch 36; iter: 0; batch classifier loss: 0.652522; batch adversarial loss: 0.682702\n",
      "epoch 37; iter: 0; batch classifier loss: 0.626792; batch adversarial loss: 0.663249\n",
      "epoch 38; iter: 0; batch classifier loss: 0.615597; batch adversarial loss: 0.584705\n",
      "epoch 39; iter: 0; batch classifier loss: 0.656226; batch adversarial loss: 0.607609\n",
      "epoch 40; iter: 0; batch classifier loss: 0.577793; batch adversarial loss: 0.685956\n",
      "epoch 41; iter: 0; batch classifier loss: 0.608666; batch adversarial loss: 0.685615\n",
      "epoch 42; iter: 0; batch classifier loss: 0.580039; batch adversarial loss: 0.688445\n",
      "epoch 43; iter: 0; batch classifier loss: 0.596582; batch adversarial loss: 0.649090\n",
      "epoch 44; iter: 0; batch classifier loss: 0.629014; batch adversarial loss: 0.614904\n",
      "epoch 45; iter: 0; batch classifier loss: 0.589563; batch adversarial loss: 0.618676\n",
      "epoch 46; iter: 0; batch classifier loss: 0.612258; batch adversarial loss: 0.624033\n",
      "epoch 47; iter: 0; batch classifier loss: 0.616125; batch adversarial loss: 0.638617\n",
      "epoch 48; iter: 0; batch classifier loss: 0.678396; batch adversarial loss: 0.643978\n",
      "epoch 49; iter: 0; batch classifier loss: 0.576631; batch adversarial loss: 0.619111\n",
      "epoch 0; iter: 0; batch classifier loss: 1.218112; batch adversarial loss: 0.681726\n",
      "epoch 1; iter: 0; batch classifier loss: 0.836066; batch adversarial loss: 0.588107\n",
      "epoch 2; iter: 0; batch classifier loss: 0.699575; batch adversarial loss: 0.710811\n",
      "epoch 3; iter: 0; batch classifier loss: 0.743184; batch adversarial loss: 0.636419\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579630; batch adversarial loss: 0.671081\n",
      "epoch 5; iter: 0; batch classifier loss: 0.659526; batch adversarial loss: 0.665722\n",
      "epoch 6; iter: 0; batch classifier loss: 0.676110; batch adversarial loss: 0.597196\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640903; batch adversarial loss: 0.639361\n",
      "epoch 8; iter: 0; batch classifier loss: 0.669222; batch adversarial loss: 0.675774\n",
      "epoch 9; iter: 0; batch classifier loss: 0.685355; batch adversarial loss: 0.639204\n",
      "epoch 10; iter: 0; batch classifier loss: 0.633170; batch adversarial loss: 0.646766\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585775; batch adversarial loss: 0.700678\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587867; batch adversarial loss: 0.668260\n",
      "epoch 13; iter: 0; batch classifier loss: 0.681537; batch adversarial loss: 0.612139\n",
      "epoch 14; iter: 0; batch classifier loss: 0.678070; batch adversarial loss: 0.632802\n",
      "epoch 15; iter: 0; batch classifier loss: 0.647577; batch adversarial loss: 0.697917\n",
      "epoch 16; iter: 0; batch classifier loss: 0.652179; batch adversarial loss: 0.655995\n",
      "epoch 17; iter: 0; batch classifier loss: 0.599238; batch adversarial loss: 0.676071\n",
      "epoch 18; iter: 0; batch classifier loss: 0.597073; batch adversarial loss: 0.623561\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592980; batch adversarial loss: 0.666460\n",
      "epoch 20; iter: 0; batch classifier loss: 0.629321; batch adversarial loss: 0.624464\n",
      "epoch 21; iter: 0; batch classifier loss: 0.542504; batch adversarial loss: 0.657738\n",
      "epoch 22; iter: 0; batch classifier loss: 0.609723; batch adversarial loss: 0.586993\n",
      "epoch 23; iter: 0; batch classifier loss: 0.642228; batch adversarial loss: 0.685047\n",
      "epoch 24; iter: 0; batch classifier loss: 0.628987; batch adversarial loss: 0.666462\n",
      "epoch 25; iter: 0; batch classifier loss: 0.606693; batch adversarial loss: 0.646122\n",
      "epoch 26; iter: 0; batch classifier loss: 0.579455; batch adversarial loss: 0.712988\n",
      "epoch 27; iter: 0; batch classifier loss: 0.635708; batch adversarial loss: 0.570850\n",
      "epoch 28; iter: 0; batch classifier loss: 0.624445; batch adversarial loss: 0.644476\n",
      "epoch 29; iter: 0; batch classifier loss: 0.602276; batch adversarial loss: 0.632270\n",
      "epoch 30; iter: 0; batch classifier loss: 0.590791; batch adversarial loss: 0.626894\n",
      "epoch 31; iter: 0; batch classifier loss: 0.657856; batch adversarial loss: 0.643419\n",
      "epoch 32; iter: 0; batch classifier loss: 0.663733; batch adversarial loss: 0.621100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.624175; batch adversarial loss: 0.666575\n",
      "epoch 34; iter: 0; batch classifier loss: 0.562814; batch adversarial loss: 0.662003\n",
      "epoch 35; iter: 0; batch classifier loss: 0.654861; batch adversarial loss: 0.671793\n",
      "epoch 36; iter: 0; batch classifier loss: 0.630887; batch adversarial loss: 0.622180\n",
      "epoch 37; iter: 0; batch classifier loss: 0.598822; batch adversarial loss: 0.632405\n",
      "epoch 38; iter: 0; batch classifier loss: 0.587937; batch adversarial loss: 0.647493\n",
      "epoch 39; iter: 0; batch classifier loss: 0.642675; batch adversarial loss: 0.629284\n",
      "epoch 40; iter: 0; batch classifier loss: 0.599767; batch adversarial loss: 0.626924\n",
      "epoch 41; iter: 0; batch classifier loss: 0.599748; batch adversarial loss: 0.660884\n",
      "epoch 42; iter: 0; batch classifier loss: 0.648484; batch adversarial loss: 0.615205\n",
      "epoch 43; iter: 0; batch classifier loss: 0.593277; batch adversarial loss: 0.620460\n",
      "epoch 44; iter: 0; batch classifier loss: 0.637249; batch adversarial loss: 0.666355\n",
      "epoch 45; iter: 0; batch classifier loss: 0.612558; batch adversarial loss: 0.592793\n",
      "epoch 46; iter: 0; batch classifier loss: 0.606715; batch adversarial loss: 0.663025\n",
      "epoch 47; iter: 0; batch classifier loss: 0.635338; batch adversarial loss: 0.649917\n",
      "epoch 48; iter: 0; batch classifier loss: 0.583582; batch adversarial loss: 0.609540\n",
      "epoch 49; iter: 0; batch classifier loss: 0.597687; batch adversarial loss: 0.603104\n",
      "epoch 0; iter: 0; batch classifier loss: 1.349018; batch adversarial loss: 0.658430\n",
      "epoch 1; iter: 0; batch classifier loss: 0.978975; batch adversarial loss: 0.636030\n",
      "epoch 2; iter: 0; batch classifier loss: 0.758066; batch adversarial loss: 0.673873\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629071; batch adversarial loss: 0.642700\n",
      "epoch 4; iter: 0; batch classifier loss: 0.707940; batch adversarial loss: 0.650697\n",
      "epoch 5; iter: 0; batch classifier loss: 0.729778; batch adversarial loss: 0.662584\n",
      "epoch 6; iter: 0; batch classifier loss: 0.601177; batch adversarial loss: 0.669340\n",
      "epoch 7; iter: 0; batch classifier loss: 0.653701; batch adversarial loss: 0.622668\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634774; batch adversarial loss: 0.693587\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555415; batch adversarial loss: 0.611627\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580279; batch adversarial loss: 0.617597\n",
      "epoch 11; iter: 0; batch classifier loss: 0.626736; batch adversarial loss: 0.630230\n",
      "epoch 12; iter: 0; batch classifier loss: 0.605268; batch adversarial loss: 0.642480\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555961; batch adversarial loss: 0.630666\n",
      "epoch 14; iter: 0; batch classifier loss: 0.594935; batch adversarial loss: 0.648826\n",
      "epoch 15; iter: 0; batch classifier loss: 0.639583; batch adversarial loss: 0.580108\n",
      "epoch 16; iter: 0; batch classifier loss: 0.602497; batch adversarial loss: 0.570692\n",
      "epoch 17; iter: 0; batch classifier loss: 0.599755; batch adversarial loss: 0.591543\n",
      "epoch 18; iter: 0; batch classifier loss: 0.582501; batch adversarial loss: 0.688817\n",
      "epoch 19; iter: 0; batch classifier loss: 0.624073; batch adversarial loss: 0.618584\n",
      "epoch 20; iter: 0; batch classifier loss: 0.597813; batch adversarial loss: 0.653954\n",
      "epoch 21; iter: 0; batch classifier loss: 0.569650; batch adversarial loss: 0.599371\n",
      "epoch 22; iter: 0; batch classifier loss: 0.632527; batch adversarial loss: 0.646461\n",
      "epoch 23; iter: 0; batch classifier loss: 0.589133; batch adversarial loss: 0.670844\n",
      "epoch 24; iter: 0; batch classifier loss: 0.623231; batch adversarial loss: 0.612784\n",
      "epoch 25; iter: 0; batch classifier loss: 0.644187; batch adversarial loss: 0.647163\n",
      "epoch 26; iter: 0; batch classifier loss: 0.715552; batch adversarial loss: 0.610464\n",
      "epoch 27; iter: 0; batch classifier loss: 0.654617; batch adversarial loss: 0.675776\n",
      "epoch 28; iter: 0; batch classifier loss: 0.613777; batch adversarial loss: 0.620318\n",
      "epoch 29; iter: 0; batch classifier loss: 0.661211; batch adversarial loss: 0.670036\n",
      "epoch 30; iter: 0; batch classifier loss: 0.653147; batch adversarial loss: 0.724090\n",
      "epoch 31; iter: 0; batch classifier loss: 0.610173; batch adversarial loss: 0.688189\n",
      "epoch 32; iter: 0; batch classifier loss: 0.665559; batch adversarial loss: 0.620053\n",
      "epoch 33; iter: 0; batch classifier loss: 0.618379; batch adversarial loss: 0.643598\n",
      "epoch 34; iter: 0; batch classifier loss: 0.599987; batch adversarial loss: 0.649240\n",
      "epoch 35; iter: 0; batch classifier loss: 0.657425; batch adversarial loss: 0.596821\n",
      "epoch 36; iter: 0; batch classifier loss: 0.602239; batch adversarial loss: 0.674967\n",
      "epoch 37; iter: 0; batch classifier loss: 0.586179; batch adversarial loss: 0.627673\n",
      "epoch 38; iter: 0; batch classifier loss: 0.672232; batch adversarial loss: 0.613222\n",
      "epoch 39; iter: 0; batch classifier loss: 0.660597; batch adversarial loss: 0.629756\n",
      "epoch 40; iter: 0; batch classifier loss: 0.606992; batch adversarial loss: 0.571255\n",
      "epoch 41; iter: 0; batch classifier loss: 0.590808; batch adversarial loss: 0.621661\n",
      "epoch 42; iter: 0; batch classifier loss: 0.579424; batch adversarial loss: 0.622265\n",
      "epoch 43; iter: 0; batch classifier loss: 0.619447; batch adversarial loss: 0.635833\n",
      "epoch 44; iter: 0; batch classifier loss: 0.649137; batch adversarial loss: 0.612952\n",
      "epoch 45; iter: 0; batch classifier loss: 0.620937; batch adversarial loss: 0.635290\n",
      "epoch 46; iter: 0; batch classifier loss: 0.568081; batch adversarial loss: 0.645970\n",
      "epoch 47; iter: 0; batch classifier loss: 0.612610; batch adversarial loss: 0.660113\n",
      "epoch 48; iter: 0; batch classifier loss: 0.579940; batch adversarial loss: 0.658457\n",
      "epoch 49; iter: 0; batch classifier loss: 0.614123; batch adversarial loss: 0.668106\n",
      "epoch 0; iter: 0; batch classifier loss: 1.711717; batch adversarial loss: 0.742748\n",
      "epoch 1; iter: 0; batch classifier loss: 0.845744; batch adversarial loss: 0.722437\n",
      "epoch 2; iter: 0; batch classifier loss: 0.765020; batch adversarial loss: 0.719870\n",
      "epoch 3; iter: 0; batch classifier loss: 0.647632; batch adversarial loss: 0.696797\n",
      "epoch 4; iter: 0; batch classifier loss: 0.708764; batch adversarial loss: 0.682505\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582731; batch adversarial loss: 0.671956\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600778; batch adversarial loss: 0.658846\n",
      "epoch 7; iter: 0; batch classifier loss: 0.622496; batch adversarial loss: 0.631967\n",
      "epoch 8; iter: 0; batch classifier loss: 0.597029; batch adversarial loss: 0.661768\n",
      "epoch 9; iter: 0; batch classifier loss: 0.652334; batch adversarial loss: 0.631139\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634699; batch adversarial loss: 0.612531\n",
      "epoch 11; iter: 0; batch classifier loss: 0.658776; batch adversarial loss: 0.626849\n",
      "epoch 12; iter: 0; batch classifier loss: 0.635737; batch adversarial loss: 0.651068\n",
      "epoch 13; iter: 0; batch classifier loss: 0.594706; batch adversarial loss: 0.676069\n",
      "epoch 14; iter: 0; batch classifier loss: 0.608554; batch adversarial loss: 0.655697\n",
      "epoch 15; iter: 0; batch classifier loss: 0.624670; batch adversarial loss: 0.641738\n",
      "epoch 16; iter: 0; batch classifier loss: 0.647130; batch adversarial loss: 0.639878\n",
      "epoch 17; iter: 0; batch classifier loss: 0.572180; batch adversarial loss: 0.616376\n",
      "epoch 18; iter: 0; batch classifier loss: 0.629266; batch adversarial loss: 0.657236\n",
      "epoch 19; iter: 0; batch classifier loss: 0.583229; batch adversarial loss: 0.660545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553652; batch adversarial loss: 0.628123\n",
      "epoch 21; iter: 0; batch classifier loss: 0.583073; batch adversarial loss: 0.617751\n",
      "epoch 22; iter: 0; batch classifier loss: 0.668952; batch adversarial loss: 0.641094\n",
      "epoch 23; iter: 0; batch classifier loss: 0.630336; batch adversarial loss: 0.655514\n",
      "epoch 24; iter: 0; batch classifier loss: 0.566535; batch adversarial loss: 0.658132\n",
      "epoch 25; iter: 0; batch classifier loss: 0.668668; batch adversarial loss: 0.637881\n",
      "epoch 26; iter: 0; batch classifier loss: 0.584025; batch adversarial loss: 0.574634\n",
      "epoch 27; iter: 0; batch classifier loss: 0.595344; batch adversarial loss: 0.674490\n",
      "epoch 28; iter: 0; batch classifier loss: 0.650702; batch adversarial loss: 0.654965\n",
      "epoch 29; iter: 0; batch classifier loss: 0.581522; batch adversarial loss: 0.580556\n",
      "epoch 30; iter: 0; batch classifier loss: 0.590446; batch adversarial loss: 0.593097\n",
      "epoch 31; iter: 0; batch classifier loss: 0.589797; batch adversarial loss: 0.638611\n",
      "epoch 32; iter: 0; batch classifier loss: 0.611080; batch adversarial loss: 0.624079\n",
      "epoch 33; iter: 0; batch classifier loss: 0.570557; batch adversarial loss: 0.609495\n",
      "epoch 34; iter: 0; batch classifier loss: 0.641890; batch adversarial loss: 0.685730\n",
      "epoch 35; iter: 0; batch classifier loss: 0.658967; batch adversarial loss: 0.586296\n",
      "epoch 36; iter: 0; batch classifier loss: 0.670512; batch adversarial loss: 0.640168\n",
      "epoch 37; iter: 0; batch classifier loss: 0.619256; batch adversarial loss: 0.647090\n",
      "epoch 38; iter: 0; batch classifier loss: 0.554480; batch adversarial loss: 0.671031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.598834; batch adversarial loss: 0.664157\n",
      "epoch 40; iter: 0; batch classifier loss: 0.590675; batch adversarial loss: 0.627903\n",
      "epoch 41; iter: 0; batch classifier loss: 0.603083; batch adversarial loss: 0.621199\n",
      "epoch 42; iter: 0; batch classifier loss: 0.562179; batch adversarial loss: 0.633140\n",
      "epoch 43; iter: 0; batch classifier loss: 0.589913; batch adversarial loss: 0.650006\n",
      "epoch 44; iter: 0; batch classifier loss: 0.635542; batch adversarial loss: 0.657524\n",
      "epoch 45; iter: 0; batch classifier loss: 0.615639; batch adversarial loss: 0.664436\n",
      "epoch 46; iter: 0; batch classifier loss: 0.626660; batch adversarial loss: 0.669471\n",
      "epoch 47; iter: 0; batch classifier loss: 0.620669; batch adversarial loss: 0.635707\n",
      "epoch 48; iter: 0; batch classifier loss: 0.725172; batch adversarial loss: 0.654414\n",
      "epoch 49; iter: 0; batch classifier loss: 0.578965; batch adversarial loss: 0.647132\n",
      "epoch 0; iter: 0; batch classifier loss: 0.911055; batch adversarial loss: 0.701340\n",
      "epoch 1; iter: 0; batch classifier loss: 0.863094; batch adversarial loss: 0.688828\n",
      "epoch 2; iter: 0; batch classifier loss: 0.691205; batch adversarial loss: 0.633994\n",
      "epoch 3; iter: 0; batch classifier loss: 0.724945; batch adversarial loss: 0.627715\n",
      "epoch 4; iter: 0; batch classifier loss: 0.668095; batch adversarial loss: 0.666357\n",
      "epoch 5; iter: 0; batch classifier loss: 0.650933; batch adversarial loss: 0.673876\n",
      "epoch 6; iter: 0; batch classifier loss: 0.675093; batch adversarial loss: 0.716279\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624137; batch adversarial loss: 0.707799\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567493; batch adversarial loss: 0.639719\n",
      "epoch 9; iter: 0; batch classifier loss: 0.642551; batch adversarial loss: 0.725964\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572019; batch adversarial loss: 0.640070\n",
      "epoch 11; iter: 0; batch classifier loss: 0.654595; batch adversarial loss: 0.653479\n",
      "epoch 12; iter: 0; batch classifier loss: 0.620432; batch adversarial loss: 0.649050\n",
      "epoch 13; iter: 0; batch classifier loss: 0.635345; batch adversarial loss: 0.682713\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601703; batch adversarial loss: 0.658102\n",
      "epoch 15; iter: 0; batch classifier loss: 0.590513; batch adversarial loss: 0.643949\n",
      "epoch 16; iter: 0; batch classifier loss: 0.682306; batch adversarial loss: 0.661824\n",
      "epoch 17; iter: 0; batch classifier loss: 0.628655; batch adversarial loss: 0.641529\n",
      "epoch 18; iter: 0; batch classifier loss: 0.567213; batch adversarial loss: 0.673015\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592896; batch adversarial loss: 0.637400\n",
      "epoch 20; iter: 0; batch classifier loss: 0.643735; batch adversarial loss: 0.656298\n",
      "epoch 21; iter: 0; batch classifier loss: 0.582993; batch adversarial loss: 0.639780\n",
      "epoch 22; iter: 0; batch classifier loss: 0.585686; batch adversarial loss: 0.645502\n",
      "epoch 23; iter: 0; batch classifier loss: 0.648401; batch adversarial loss: 0.642856\n",
      "epoch 24; iter: 0; batch classifier loss: 0.614855; batch adversarial loss: 0.706220\n",
      "epoch 25; iter: 0; batch classifier loss: 0.596627; batch adversarial loss: 0.623079\n",
      "epoch 26; iter: 0; batch classifier loss: 0.535215; batch adversarial loss: 0.641523\n",
      "epoch 27; iter: 0; batch classifier loss: 0.579093; batch adversarial loss: 0.576904\n",
      "epoch 28; iter: 0; batch classifier loss: 0.637074; batch adversarial loss: 0.629904\n",
      "epoch 29; iter: 0; batch classifier loss: 0.567938; batch adversarial loss: 0.666090\n",
      "epoch 30; iter: 0; batch classifier loss: 0.593829; batch adversarial loss: 0.648911\n",
      "epoch 31; iter: 0; batch classifier loss: 0.604561; batch adversarial loss: 0.636165\n",
      "epoch 32; iter: 0; batch classifier loss: 0.586636; batch adversarial loss: 0.616078\n",
      "epoch 33; iter: 0; batch classifier loss: 0.593232; batch adversarial loss: 0.624248\n",
      "epoch 34; iter: 0; batch classifier loss: 0.622786; batch adversarial loss: 0.652201\n",
      "epoch 35; iter: 0; batch classifier loss: 0.586549; batch adversarial loss: 0.614150\n",
      "epoch 36; iter: 0; batch classifier loss: 0.565073; batch adversarial loss: 0.668060\n",
      "epoch 37; iter: 0; batch classifier loss: 0.644830; batch adversarial loss: 0.589886\n",
      "epoch 38; iter: 0; batch classifier loss: 0.593153; batch adversarial loss: 0.670315\n",
      "epoch 39; iter: 0; batch classifier loss: 0.632982; batch adversarial loss: 0.631109\n",
      "epoch 40; iter: 0; batch classifier loss: 0.625386; batch adversarial loss: 0.637519\n",
      "epoch 41; iter: 0; batch classifier loss: 0.609868; batch adversarial loss: 0.661688\n",
      "epoch 42; iter: 0; batch classifier loss: 0.535050; batch adversarial loss: 0.635365\n",
      "epoch 43; iter: 0; batch classifier loss: 0.603620; batch adversarial loss: 0.585539\n",
      "epoch 44; iter: 0; batch classifier loss: 0.574285; batch adversarial loss: 0.665211\n",
      "epoch 45; iter: 0; batch classifier loss: 0.539635; batch adversarial loss: 0.626330\n",
      "epoch 46; iter: 0; batch classifier loss: 0.595246; batch adversarial loss: 0.624066\n",
      "epoch 47; iter: 0; batch classifier loss: 0.557816; batch adversarial loss: 0.617290\n",
      "epoch 48; iter: 0; batch classifier loss: 0.607896; batch adversarial loss: 0.649366\n",
      "epoch 49; iter: 0; batch classifier loss: 0.619104; batch adversarial loss: 0.619167\n",
      "epoch 0; iter: 0; batch classifier loss: 1.096213; batch adversarial loss: 0.783825\n",
      "epoch 1; iter: 0; batch classifier loss: 0.841483; batch adversarial loss: 0.728617\n",
      "epoch 2; iter: 0; batch classifier loss: 0.670075; batch adversarial loss: 0.697567\n",
      "epoch 3; iter: 0; batch classifier loss: 0.678737; batch adversarial loss: 0.700086\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603011; batch adversarial loss: 0.672204\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601922; batch adversarial loss: 0.668325\n",
      "epoch 6; iter: 0; batch classifier loss: 0.690828; batch adversarial loss: 0.676885\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581919; batch adversarial loss: 0.642318\n",
      "epoch 8; iter: 0; batch classifier loss: 0.625296; batch adversarial loss: 0.623619\n",
      "epoch 9; iter: 0; batch classifier loss: 0.640239; batch adversarial loss: 0.615880\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610456; batch adversarial loss: 0.650176\n",
      "epoch 11; iter: 0; batch classifier loss: 0.627163; batch adversarial loss: 0.645215\n",
      "epoch 12; iter: 0; batch classifier loss: 0.590736; batch adversarial loss: 0.670319\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570437; batch adversarial loss: 0.658435\n",
      "epoch 14; iter: 0; batch classifier loss: 0.620744; batch adversarial loss: 0.603268\n",
      "epoch 15; iter: 0; batch classifier loss: 0.647473; batch adversarial loss: 0.619651\n",
      "epoch 16; iter: 0; batch classifier loss: 0.651549; batch adversarial loss: 0.602217\n",
      "epoch 17; iter: 0; batch classifier loss: 0.642616; batch adversarial loss: 0.646051\n",
      "epoch 18; iter: 0; batch classifier loss: 0.647475; batch adversarial loss: 0.666033\n",
      "epoch 19; iter: 0; batch classifier loss: 0.550910; batch adversarial loss: 0.652505\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534800; batch adversarial loss: 0.658002\n",
      "epoch 21; iter: 0; batch classifier loss: 0.656833; batch adversarial loss: 0.630827\n",
      "epoch 22; iter: 0; batch classifier loss: 0.656010; batch adversarial loss: 0.579882\n",
      "epoch 23; iter: 0; batch classifier loss: 0.604907; batch adversarial loss: 0.617036\n",
      "epoch 24; iter: 0; batch classifier loss: 0.580991; batch adversarial loss: 0.631603\n",
      "epoch 25; iter: 0; batch classifier loss: 0.578914; batch adversarial loss: 0.599650\n",
      "epoch 26; iter: 0; batch classifier loss: 0.556532; batch adversarial loss: 0.624604\n",
      "epoch 27; iter: 0; batch classifier loss: 0.581865; batch adversarial loss: 0.560542\n",
      "epoch 28; iter: 0; batch classifier loss: 0.596942; batch adversarial loss: 0.556386\n",
      "epoch 29; iter: 0; batch classifier loss: 0.633256; batch adversarial loss: 0.664252\n",
      "epoch 30; iter: 0; batch classifier loss: 0.609461; batch adversarial loss: 0.652713\n",
      "epoch 31; iter: 0; batch classifier loss: 0.608588; batch adversarial loss: 0.640644\n",
      "epoch 32; iter: 0; batch classifier loss: 0.594536; batch adversarial loss: 0.629974\n",
      "epoch 33; iter: 0; batch classifier loss: 0.600656; batch adversarial loss: 0.598555\n",
      "epoch 34; iter: 0; batch classifier loss: 0.549976; batch adversarial loss: 0.627123\n",
      "epoch 35; iter: 0; batch classifier loss: 0.643329; batch adversarial loss: 0.665986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.608918; batch adversarial loss: 0.676081\n",
      "epoch 37; iter: 0; batch classifier loss: 0.625985; batch adversarial loss: 0.656902\n",
      "epoch 38; iter: 0; batch classifier loss: 0.614467; batch adversarial loss: 0.616878\n",
      "epoch 39; iter: 0; batch classifier loss: 0.604132; batch adversarial loss: 0.581761\n",
      "epoch 40; iter: 0; batch classifier loss: 0.626372; batch adversarial loss: 0.636452\n",
      "epoch 41; iter: 0; batch classifier loss: 0.561830; batch adversarial loss: 0.603182\n",
      "epoch 42; iter: 0; batch classifier loss: 0.635138; batch adversarial loss: 0.649449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.620791; batch adversarial loss: 0.635953\n",
      "epoch 44; iter: 0; batch classifier loss: 0.606290; batch adversarial loss: 0.630843\n",
      "epoch 45; iter: 0; batch classifier loss: 0.567411; batch adversarial loss: 0.575822\n",
      "epoch 46; iter: 0; batch classifier loss: 0.594091; batch adversarial loss: 0.636600\n",
      "epoch 47; iter: 0; batch classifier loss: 0.597694; batch adversarial loss: 0.602674\n",
      "epoch 48; iter: 0; batch classifier loss: 0.589025; batch adversarial loss: 0.576452\n",
      "epoch 49; iter: 0; batch classifier loss: 0.594553; batch adversarial loss: 0.578700\n",
      "epoch 0; iter: 0; batch classifier loss: 0.892811; batch adversarial loss: 0.715858\n",
      "epoch 1; iter: 0; batch classifier loss: 0.776408; batch adversarial loss: 0.729431\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611433; batch adversarial loss: 0.728414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.651635; batch adversarial loss: 0.720612\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605807; batch adversarial loss: 0.709420\n",
      "epoch 5; iter: 0; batch classifier loss: 0.664915; batch adversarial loss: 0.689395\n",
      "epoch 6; iter: 0; batch classifier loss: 0.621924; batch adversarial loss: 0.653709\n",
      "epoch 7; iter: 0; batch classifier loss: 0.600955; batch adversarial loss: 0.681128\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596350; batch adversarial loss: 0.668277\n",
      "epoch 9; iter: 0; batch classifier loss: 0.653858; batch adversarial loss: 0.653219\n",
      "epoch 10; iter: 0; batch classifier loss: 0.613483; batch adversarial loss: 0.639383\n",
      "epoch 11; iter: 0; batch classifier loss: 0.620555; batch adversarial loss: 0.655450\n",
      "epoch 12; iter: 0; batch classifier loss: 0.601981; batch adversarial loss: 0.605796\n",
      "epoch 13; iter: 0; batch classifier loss: 0.609794; batch adversarial loss: 0.643762\n",
      "epoch 14; iter: 0; batch classifier loss: 0.570069; batch adversarial loss: 0.629692\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556873; batch adversarial loss: 0.663305\n",
      "epoch 16; iter: 0; batch classifier loss: 0.598093; batch adversarial loss: 0.659798\n",
      "epoch 17; iter: 0; batch classifier loss: 0.639207; batch adversarial loss: 0.641838\n",
      "epoch 18; iter: 0; batch classifier loss: 0.568376; batch adversarial loss: 0.655644\n",
      "epoch 19; iter: 0; batch classifier loss: 0.560963; batch adversarial loss: 0.672457\n",
      "epoch 20; iter: 0; batch classifier loss: 0.575982; batch adversarial loss: 0.621591\n",
      "epoch 21; iter: 0; batch classifier loss: 0.630347; batch adversarial loss: 0.647789\n",
      "epoch 22; iter: 0; batch classifier loss: 0.672145; batch adversarial loss: 0.606585\n",
      "epoch 23; iter: 0; batch classifier loss: 0.603206; batch adversarial loss: 0.587312\n",
      "epoch 24; iter: 0; batch classifier loss: 0.634329; batch adversarial loss: 0.652655\n",
      "epoch 25; iter: 0; batch classifier loss: 0.582880; batch adversarial loss: 0.607874\n",
      "epoch 26; iter: 0; batch classifier loss: 0.600955; batch adversarial loss: 0.640218\n",
      "epoch 27; iter: 0; batch classifier loss: 0.615515; batch adversarial loss: 0.649869\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542804; batch adversarial loss: 0.611956\n",
      "epoch 29; iter: 0; batch classifier loss: 0.570527; batch adversarial loss: 0.620315\n",
      "epoch 30; iter: 0; batch classifier loss: 0.633509; batch adversarial loss: 0.620021\n",
      "epoch 31; iter: 0; batch classifier loss: 0.600210; batch adversarial loss: 0.669850\n",
      "epoch 32; iter: 0; batch classifier loss: 0.562332; batch adversarial loss: 0.653494\n",
      "epoch 33; iter: 0; batch classifier loss: 0.602766; batch adversarial loss: 0.643155\n",
      "epoch 34; iter: 0; batch classifier loss: 0.648686; batch adversarial loss: 0.594942\n",
      "epoch 35; iter: 0; batch classifier loss: 0.606541; batch adversarial loss: 0.631126\n",
      "epoch 36; iter: 0; batch classifier loss: 0.635834; batch adversarial loss: 0.662883\n",
      "epoch 37; iter: 0; batch classifier loss: 0.633813; batch adversarial loss: 0.665595\n",
      "epoch 38; iter: 0; batch classifier loss: 0.543330; batch adversarial loss: 0.629641\n",
      "epoch 39; iter: 0; batch classifier loss: 0.655463; batch adversarial loss: 0.674617\n",
      "epoch 40; iter: 0; batch classifier loss: 0.624058; batch adversarial loss: 0.655799\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598423; batch adversarial loss: 0.639309\n",
      "epoch 42; iter: 0; batch classifier loss: 0.576275; batch adversarial loss: 0.664177\n",
      "epoch 43; iter: 0; batch classifier loss: 0.628750; batch adversarial loss: 0.649354\n",
      "epoch 44; iter: 0; batch classifier loss: 0.585165; batch adversarial loss: 0.660406\n",
      "epoch 45; iter: 0; batch classifier loss: 0.616353; batch adversarial loss: 0.636762\n",
      "epoch 46; iter: 0; batch classifier loss: 0.620711; batch adversarial loss: 0.620172\n",
      "epoch 47; iter: 0; batch classifier loss: 0.622131; batch adversarial loss: 0.650432\n",
      "epoch 48; iter: 0; batch classifier loss: 0.601998; batch adversarial loss: 0.667938\n",
      "epoch 49; iter: 0; batch classifier loss: 0.577589; batch adversarial loss: 0.685012\n",
      "epoch 0; iter: 0; batch classifier loss: 1.415905; batch adversarial loss: 0.642957\n",
      "epoch 1; iter: 0; batch classifier loss: 0.846699; batch adversarial loss: 0.646750\n",
      "epoch 2; iter: 0; batch classifier loss: 0.791594; batch adversarial loss: 0.647282\n",
      "epoch 3; iter: 0; batch classifier loss: 0.725051; batch adversarial loss: 0.691059\n",
      "epoch 4; iter: 0; batch classifier loss: 0.683528; batch adversarial loss: 0.678857\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619039; batch adversarial loss: 0.665464\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568158; batch adversarial loss: 0.655177\n",
      "epoch 7; iter: 0; batch classifier loss: 0.768734; batch adversarial loss: 0.657254\n",
      "epoch 8; iter: 0; batch classifier loss: 0.623078; batch adversarial loss: 0.656814\n",
      "epoch 9; iter: 0; batch classifier loss: 0.638388; batch adversarial loss: 0.653648\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634126; batch adversarial loss: 0.651263\n",
      "epoch 11; iter: 0; batch classifier loss: 0.627950; batch adversarial loss: 0.669985\n",
      "epoch 12; iter: 0; batch classifier loss: 0.655994; batch adversarial loss: 0.663718\n",
      "epoch 13; iter: 0; batch classifier loss: 0.643061; batch adversarial loss: 0.638916\n",
      "epoch 14; iter: 0; batch classifier loss: 0.614543; batch adversarial loss: 0.627460\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584471; batch adversarial loss: 0.629690\n",
      "epoch 16; iter: 0; batch classifier loss: 0.659960; batch adversarial loss: 0.650281\n",
      "epoch 17; iter: 0; batch classifier loss: 0.571606; batch adversarial loss: 0.670772\n",
      "epoch 18; iter: 0; batch classifier loss: 0.629819; batch adversarial loss: 0.631168\n",
      "epoch 19; iter: 0; batch classifier loss: 0.661833; batch adversarial loss: 0.591966\n",
      "epoch 20; iter: 0; batch classifier loss: 0.610364; batch adversarial loss: 0.626255\n",
      "epoch 21; iter: 0; batch classifier loss: 0.584279; batch adversarial loss: 0.620247\n",
      "epoch 22; iter: 0; batch classifier loss: 0.649567; batch adversarial loss: 0.652308\n",
      "epoch 23; iter: 0; batch classifier loss: 0.618536; batch adversarial loss: 0.584387\n",
      "epoch 24; iter: 0; batch classifier loss: 0.639024; batch adversarial loss: 0.627024\n",
      "epoch 25; iter: 0; batch classifier loss: 0.559181; batch adversarial loss: 0.650467\n",
      "epoch 26; iter: 0; batch classifier loss: 0.661179; batch adversarial loss: 0.641390\n",
      "epoch 27; iter: 0; batch classifier loss: 0.641903; batch adversarial loss: 0.673989\n",
      "epoch 28; iter: 0; batch classifier loss: 0.575408; batch adversarial loss: 0.677899\n",
      "epoch 29; iter: 0; batch classifier loss: 0.624940; batch adversarial loss: 0.691488\n",
      "epoch 30; iter: 0; batch classifier loss: 0.600956; batch adversarial loss: 0.642512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.632718; batch adversarial loss: 0.608918\n",
      "epoch 32; iter: 0; batch classifier loss: 0.622641; batch adversarial loss: 0.591122\n",
      "epoch 33; iter: 0; batch classifier loss: 0.596330; batch adversarial loss: 0.625530\n",
      "epoch 34; iter: 0; batch classifier loss: 0.600846; batch adversarial loss: 0.676815\n",
      "epoch 35; iter: 0; batch classifier loss: 0.646934; batch adversarial loss: 0.633642\n",
      "epoch 36; iter: 0; batch classifier loss: 0.580978; batch adversarial loss: 0.650861\n",
      "epoch 37; iter: 0; batch classifier loss: 0.629491; batch adversarial loss: 0.668831\n",
      "epoch 38; iter: 0; batch classifier loss: 0.588605; batch adversarial loss: 0.618918\n",
      "epoch 39; iter: 0; batch classifier loss: 0.603360; batch adversarial loss: 0.619403\n",
      "epoch 40; iter: 0; batch classifier loss: 0.592934; batch adversarial loss: 0.609802\n",
      "epoch 41; iter: 0; batch classifier loss: 0.577082; batch adversarial loss: 0.664497\n",
      "epoch 42; iter: 0; batch classifier loss: 0.616534; batch adversarial loss: 0.622890\n",
      "epoch 43; iter: 0; batch classifier loss: 0.574752; batch adversarial loss: 0.571961\n",
      "epoch 44; iter: 0; batch classifier loss: 0.613604; batch adversarial loss: 0.662454\n",
      "epoch 45; iter: 0; batch classifier loss: 0.641838; batch adversarial loss: 0.648484\n",
      "epoch 46; iter: 0; batch classifier loss: 0.618643; batch adversarial loss: 0.615750\n",
      "epoch 47; iter: 0; batch classifier loss: 0.600719; batch adversarial loss: 0.656817\n",
      "epoch 48; iter: 0; batch classifier loss: 0.636539; batch adversarial loss: 0.658086\n",
      "epoch 49; iter: 0; batch classifier loss: 0.649192; batch adversarial loss: 0.638548\n",
      "epoch 0; iter: 0; batch classifier loss: 1.113732; batch adversarial loss: 0.714572\n",
      "epoch 1; iter: 0; batch classifier loss: 0.723948; batch adversarial loss: 0.722754\n",
      "epoch 2; iter: 0; batch classifier loss: 0.799686; batch adversarial loss: 0.685190\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610239; batch adversarial loss: 0.700142\n",
      "epoch 4; iter: 0; batch classifier loss: 0.635661; batch adversarial loss: 0.654374\n",
      "epoch 5; iter: 0; batch classifier loss: 0.605853; batch adversarial loss: 0.635508\n",
      "epoch 6; iter: 0; batch classifier loss: 0.626424; batch adversarial loss: 0.655973\n",
      "epoch 7; iter: 0; batch classifier loss: 0.647029; batch adversarial loss: 0.633734\n",
      "epoch 8; iter: 0; batch classifier loss: 0.707773; batch adversarial loss: 0.669961\n",
      "epoch 9; iter: 0; batch classifier loss: 0.607943; batch adversarial loss: 0.632543\n",
      "epoch 10; iter: 0; batch classifier loss: 0.654047; batch adversarial loss: 0.638982\n",
      "epoch 11; iter: 0; batch classifier loss: 0.643568; batch adversarial loss: 0.593475\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599463; batch adversarial loss: 0.648396\n",
      "epoch 13; iter: 0; batch classifier loss: 0.619673; batch adversarial loss: 0.646111\n",
      "epoch 14; iter: 0; batch classifier loss: 0.635225; batch adversarial loss: 0.606586\n",
      "epoch 15; iter: 0; batch classifier loss: 0.635934; batch adversarial loss: 0.676332\n",
      "epoch 16; iter: 0; batch classifier loss: 0.596161; batch adversarial loss: 0.602834\n",
      "epoch 17; iter: 0; batch classifier loss: 0.607817; batch adversarial loss: 0.625429\n",
      "epoch 18; iter: 0; batch classifier loss: 0.566367; batch adversarial loss: 0.619362\n",
      "epoch 19; iter: 0; batch classifier loss: 0.554149; batch adversarial loss: 0.599002\n",
      "epoch 20; iter: 0; batch classifier loss: 0.608178; batch adversarial loss: 0.610376\n",
      "epoch 21; iter: 0; batch classifier loss: 0.690236; batch adversarial loss: 0.634838\n",
      "epoch 22; iter: 0; batch classifier loss: 0.610894; batch adversarial loss: 0.605316\n",
      "epoch 23; iter: 0; batch classifier loss: 0.609055; batch adversarial loss: 0.627088\n",
      "epoch 24; iter: 0; batch classifier loss: 0.592472; batch adversarial loss: 0.669895\n",
      "epoch 25; iter: 0; batch classifier loss: 0.574402; batch adversarial loss: 0.624207\n",
      "epoch 26; iter: 0; batch classifier loss: 0.623544; batch adversarial loss: 0.682223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.553707; batch adversarial loss: 0.703860\n",
      "epoch 28; iter: 0; batch classifier loss: 0.603788; batch adversarial loss: 0.638911\n",
      "epoch 29; iter: 0; batch classifier loss: 0.581273; batch adversarial loss: 0.628285\n",
      "epoch 30; iter: 0; batch classifier loss: 0.597272; batch adversarial loss: 0.618890\n",
      "epoch 31; iter: 0; batch classifier loss: 0.588785; batch adversarial loss: 0.638843\n",
      "epoch 32; iter: 0; batch classifier loss: 0.623829; batch adversarial loss: 0.671617\n",
      "epoch 33; iter: 0; batch classifier loss: 0.581852; batch adversarial loss: 0.643761\n",
      "epoch 34; iter: 0; batch classifier loss: 0.614727; batch adversarial loss: 0.590699\n",
      "epoch 35; iter: 0; batch classifier loss: 0.580854; batch adversarial loss: 0.618075\n",
      "epoch 36; iter: 0; batch classifier loss: 0.591902; batch adversarial loss: 0.592566\n",
      "epoch 37; iter: 0; batch classifier loss: 0.623626; batch adversarial loss: 0.557533\n",
      "epoch 38; iter: 0; batch classifier loss: 0.495624; batch adversarial loss: 0.658901\n",
      "epoch 39; iter: 0; batch classifier loss: 0.618745; batch adversarial loss: 0.630201\n",
      "epoch 40; iter: 0; batch classifier loss: 0.521070; batch adversarial loss: 0.603258\n",
      "epoch 41; iter: 0; batch classifier loss: 0.534061; batch adversarial loss: 0.688954\n",
      "epoch 42; iter: 0; batch classifier loss: 0.550842; batch adversarial loss: 0.633522\n",
      "epoch 43; iter: 0; batch classifier loss: 0.621693; batch adversarial loss: 0.659976\n",
      "epoch 44; iter: 0; batch classifier loss: 0.592820; batch adversarial loss: 0.660390\n",
      "epoch 45; iter: 0; batch classifier loss: 0.591611; batch adversarial loss: 0.652875\n",
      "epoch 46; iter: 0; batch classifier loss: 0.608982; batch adversarial loss: 0.672346\n",
      "epoch 47; iter: 0; batch classifier loss: 0.630255; batch adversarial loss: 0.655102\n",
      "epoch 48; iter: 0; batch classifier loss: 0.573218; batch adversarial loss: 0.611434\n",
      "epoch 49; iter: 0; batch classifier loss: 0.554510; batch adversarial loss: 0.661482\n",
      "epoch 0; iter: 0; batch classifier loss: 1.080224; batch adversarial loss: 0.803170\n",
      "epoch 1; iter: 0; batch classifier loss: 0.994673; batch adversarial loss: 0.934735\n",
      "epoch 2; iter: 0; batch classifier loss: 0.763103; batch adversarial loss: 0.918163\n",
      "epoch 3; iter: 0; batch classifier loss: 0.793960; batch adversarial loss: 0.879937\n",
      "epoch 4; iter: 0; batch classifier loss: 0.714746; batch adversarial loss: 0.889415\n",
      "epoch 5; iter: 0; batch classifier loss: 0.755662; batch adversarial loss: 0.837011\n",
      "epoch 6; iter: 0; batch classifier loss: 0.594763; batch adversarial loss: 0.839877\n",
      "epoch 7; iter: 0; batch classifier loss: 0.656999; batch adversarial loss: 0.812952\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575903; batch adversarial loss: 0.775608\n",
      "epoch 9; iter: 0; batch classifier loss: 0.710158; batch adversarial loss: 0.743354\n",
      "epoch 10; iter: 0; batch classifier loss: 0.631408; batch adversarial loss: 0.708703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.595086; batch adversarial loss: 0.702266\n",
      "epoch 12; iter: 0; batch classifier loss: 0.595421; batch adversarial loss: 0.698800\n",
      "epoch 13; iter: 0; batch classifier loss: 0.597641; batch adversarial loss: 0.707630\n",
      "epoch 14; iter: 0; batch classifier loss: 0.623212; batch adversarial loss: 0.653385\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584842; batch adversarial loss: 0.652868\n",
      "epoch 16; iter: 0; batch classifier loss: 0.619601; batch adversarial loss: 0.652897\n",
      "epoch 17; iter: 0; batch classifier loss: 0.625170; batch adversarial loss: 0.688536\n",
      "epoch 18; iter: 0; batch classifier loss: 0.653712; batch adversarial loss: 0.645935\n",
      "epoch 19; iter: 0; batch classifier loss: 0.635172; batch adversarial loss: 0.674646\n",
      "epoch 20; iter: 0; batch classifier loss: 0.604043; batch adversarial loss: 0.667860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.619872; batch adversarial loss: 0.659717\n",
      "epoch 22; iter: 0; batch classifier loss: 0.627093; batch adversarial loss: 0.676005\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588940; batch adversarial loss: 0.644612\n",
      "epoch 24; iter: 0; batch classifier loss: 0.640027; batch adversarial loss: 0.608982\n",
      "epoch 25; iter: 0; batch classifier loss: 0.610362; batch adversarial loss: 0.645813\n",
      "epoch 26; iter: 0; batch classifier loss: 0.608350; batch adversarial loss: 0.630843\n",
      "epoch 27; iter: 0; batch classifier loss: 0.657609; batch adversarial loss: 0.683242\n",
      "epoch 28; iter: 0; batch classifier loss: 0.636954; batch adversarial loss: 0.670503\n",
      "epoch 29; iter: 0; batch classifier loss: 0.624875; batch adversarial loss: 0.593384\n",
      "epoch 30; iter: 0; batch classifier loss: 0.630531; batch adversarial loss: 0.625080\n",
      "epoch 31; iter: 0; batch classifier loss: 0.593869; batch adversarial loss: 0.698077\n",
      "epoch 32; iter: 0; batch classifier loss: 0.544611; batch adversarial loss: 0.617107\n",
      "epoch 33; iter: 0; batch classifier loss: 0.614117; batch adversarial loss: 0.630868\n",
      "epoch 34; iter: 0; batch classifier loss: 0.596884; batch adversarial loss: 0.636137\n",
      "epoch 35; iter: 0; batch classifier loss: 0.583679; batch adversarial loss: 0.665375\n",
      "epoch 36; iter: 0; batch classifier loss: 0.634832; batch adversarial loss: 0.644777\n",
      "epoch 37; iter: 0; batch classifier loss: 0.563616; batch adversarial loss: 0.633607\n",
      "epoch 38; iter: 0; batch classifier loss: 0.636583; batch adversarial loss: 0.681841\n",
      "epoch 39; iter: 0; batch classifier loss: 0.655120; batch adversarial loss: 0.619702\n",
      "epoch 40; iter: 0; batch classifier loss: 0.600413; batch adversarial loss: 0.594582\n",
      "epoch 41; iter: 0; batch classifier loss: 0.597747; batch adversarial loss: 0.613166\n",
      "epoch 42; iter: 0; batch classifier loss: 0.624112; batch adversarial loss: 0.675205\n",
      "epoch 43; iter: 0; batch classifier loss: 0.630446; batch adversarial loss: 0.659085\n",
      "epoch 44; iter: 0; batch classifier loss: 0.559444; batch adversarial loss: 0.643602\n",
      "epoch 45; iter: 0; batch classifier loss: 0.573563; batch adversarial loss: 0.667082\n",
      "epoch 46; iter: 0; batch classifier loss: 0.557478; batch adversarial loss: 0.651452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.631998; batch adversarial loss: 0.649236\n",
      "epoch 48; iter: 0; batch classifier loss: 0.663449; batch adversarial loss: 0.670961\n",
      "epoch 49; iter: 0; batch classifier loss: 0.579050; batch adversarial loss: 0.612314\n",
      "epoch 0; iter: 0; batch classifier loss: 1.325192; batch adversarial loss: 0.867745\n",
      "epoch 1; iter: 0; batch classifier loss: 0.825349; batch adversarial loss: 0.767134\n",
      "epoch 2; iter: 0; batch classifier loss: 0.819622; batch adversarial loss: 0.762217\n",
      "epoch 3; iter: 0; batch classifier loss: 0.733894; batch adversarial loss: 0.760589\n",
      "epoch 4; iter: 0; batch classifier loss: 0.715433; batch adversarial loss: 0.738865\n",
      "epoch 5; iter: 0; batch classifier loss: 0.648142; batch adversarial loss: 0.699924\n",
      "epoch 6; iter: 0; batch classifier loss: 0.658258; batch adversarial loss: 0.705291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640694; batch adversarial loss: 0.662919\n",
      "epoch 8; iter: 0; batch classifier loss: 0.687180; batch adversarial loss: 0.685615\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573510; batch adversarial loss: 0.634860\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634763; batch adversarial loss: 0.642894\n",
      "epoch 11; iter: 0; batch classifier loss: 0.658389; batch adversarial loss: 0.676129\n",
      "epoch 12; iter: 0; batch classifier loss: 0.633770; batch adversarial loss: 0.631202\n",
      "epoch 13; iter: 0; batch classifier loss: 0.610018; batch adversarial loss: 0.606785\n",
      "epoch 14; iter: 0; batch classifier loss: 0.626053; batch adversarial loss: 0.626593\n",
      "epoch 15; iter: 0; batch classifier loss: 0.599496; batch adversarial loss: 0.634283\n",
      "epoch 16; iter: 0; batch classifier loss: 0.615600; batch adversarial loss: 0.660993\n",
      "epoch 17; iter: 0; batch classifier loss: 0.552909; batch adversarial loss: 0.615030\n",
      "epoch 18; iter: 0; batch classifier loss: 0.603335; batch adversarial loss: 0.649713\n",
      "epoch 19; iter: 0; batch classifier loss: 0.655829; batch adversarial loss: 0.681314\n",
      "epoch 20; iter: 0; batch classifier loss: 0.590534; batch adversarial loss: 0.628803\n",
      "epoch 21; iter: 0; batch classifier loss: 0.566820; batch adversarial loss: 0.638050\n",
      "epoch 22; iter: 0; batch classifier loss: 0.551396; batch adversarial loss: 0.619954\n",
      "epoch 23; iter: 0; batch classifier loss: 0.601451; batch adversarial loss: 0.657649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.585488; batch adversarial loss: 0.648721\n",
      "epoch 25; iter: 0; batch classifier loss: 0.617325; batch adversarial loss: 0.642867\n",
      "epoch 26; iter: 0; batch classifier loss: 0.678636; batch adversarial loss: 0.619699\n",
      "epoch 27; iter: 0; batch classifier loss: 0.561135; batch adversarial loss: 0.633466\n",
      "epoch 28; iter: 0; batch classifier loss: 0.579568; batch adversarial loss: 0.681555\n",
      "epoch 29; iter: 0; batch classifier loss: 0.579616; batch adversarial loss: 0.623602\n",
      "epoch 30; iter: 0; batch classifier loss: 0.609099; batch adversarial loss: 0.625640\n",
      "epoch 31; iter: 0; batch classifier loss: 0.646596; batch adversarial loss: 0.671675\n",
      "epoch 32; iter: 0; batch classifier loss: 0.644858; batch adversarial loss: 0.585727\n",
      "epoch 33; iter: 0; batch classifier loss: 0.560079; batch adversarial loss: 0.640419\n",
      "epoch 34; iter: 0; batch classifier loss: 0.588066; batch adversarial loss: 0.631983\n",
      "epoch 35; iter: 0; batch classifier loss: 0.629008; batch adversarial loss: 0.657753\n",
      "epoch 36; iter: 0; batch classifier loss: 0.576097; batch adversarial loss: 0.566664\n",
      "epoch 37; iter: 0; batch classifier loss: 0.603594; batch adversarial loss: 0.655233\n",
      "epoch 38; iter: 0; batch classifier loss: 0.586272; batch adversarial loss: 0.609529\n",
      "epoch 39; iter: 0; batch classifier loss: 0.608887; batch adversarial loss: 0.628044\n",
      "epoch 40; iter: 0; batch classifier loss: 0.599081; batch adversarial loss: 0.593695\n",
      "epoch 41; iter: 0; batch classifier loss: 0.615224; batch adversarial loss: 0.674663\n",
      "epoch 42; iter: 0; batch classifier loss: 0.611242; batch adversarial loss: 0.574203\n",
      "epoch 43; iter: 0; batch classifier loss: 0.593489; batch adversarial loss: 0.657766\n",
      "epoch 44; iter: 0; batch classifier loss: 0.583063; batch adversarial loss: 0.595202\n",
      "epoch 45; iter: 0; batch classifier loss: 0.660836; batch adversarial loss: 0.606888\n",
      "epoch 46; iter: 0; batch classifier loss: 0.535670; batch adversarial loss: 0.581889\n",
      "epoch 47; iter: 0; batch classifier loss: 0.627906; batch adversarial loss: 0.636299\n",
      "epoch 48; iter: 0; batch classifier loss: 0.661506; batch adversarial loss: 0.590451\n",
      "epoch 49; iter: 0; batch classifier loss: 0.555560; batch adversarial loss: 0.645322\n",
      "epoch 0; iter: 0; batch classifier loss: 0.978657; batch adversarial loss: 0.684990\n",
      "epoch 1; iter: 0; batch classifier loss: 0.734937; batch adversarial loss: 0.668826\n",
      "epoch 2; iter: 0; batch classifier loss: 0.648909; batch adversarial loss: 0.670134\n",
      "epoch 3; iter: 0; batch classifier loss: 0.766103; batch adversarial loss: 0.694490\n",
      "epoch 4; iter: 0; batch classifier loss: 0.700030; batch adversarial loss: 0.626809\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594345; batch adversarial loss: 0.629092\n",
      "epoch 6; iter: 0; batch classifier loss: 0.647567; batch adversarial loss: 0.642396\n",
      "epoch 7; iter: 0; batch classifier loss: 0.677712; batch adversarial loss: 0.637116\n",
      "epoch 8; iter: 0; batch classifier loss: 0.563630; batch adversarial loss: 0.643826\n",
      "epoch 9; iter: 0; batch classifier loss: 0.627726; batch adversarial loss: 0.642517\n",
      "epoch 10; iter: 0; batch classifier loss: 0.667323; batch adversarial loss: 0.650643\n",
      "epoch 11; iter: 0; batch classifier loss: 0.649947; batch adversarial loss: 0.655565\n",
      "epoch 12; iter: 0; batch classifier loss: 0.596298; batch adversarial loss: 0.616955\n",
      "epoch 13; iter: 0; batch classifier loss: 0.621235; batch adversarial loss: 0.680179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.584503; batch adversarial loss: 0.664939\n",
      "epoch 15; iter: 0; batch classifier loss: 0.590368; batch adversarial loss: 0.714835\n",
      "epoch 16; iter: 0; batch classifier loss: 0.608964; batch adversarial loss: 0.662266\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568449; batch adversarial loss: 0.611040\n",
      "epoch 18; iter: 0; batch classifier loss: 0.656828; batch adversarial loss: 0.632591\n",
      "epoch 19; iter: 0; batch classifier loss: 0.583560; batch adversarial loss: 0.690373\n",
      "epoch 20; iter: 0; batch classifier loss: 0.582080; batch adversarial loss: 0.627028\n",
      "epoch 21; iter: 0; batch classifier loss: 0.666601; batch adversarial loss: 0.616665\n",
      "epoch 22; iter: 0; batch classifier loss: 0.606005; batch adversarial loss: 0.609219\n",
      "epoch 23; iter: 0; batch classifier loss: 0.643257; batch adversarial loss: 0.616227\n",
      "epoch 24; iter: 0; batch classifier loss: 0.576375; batch adversarial loss: 0.626732\n",
      "epoch 25; iter: 0; batch classifier loss: 0.582169; batch adversarial loss: 0.574668\n",
      "epoch 26; iter: 0; batch classifier loss: 0.576717; batch adversarial loss: 0.624846\n",
      "epoch 27; iter: 0; batch classifier loss: 0.646477; batch adversarial loss: 0.663177\n",
      "epoch 28; iter: 0; batch classifier loss: 0.607270; batch adversarial loss: 0.640352\n",
      "epoch 29; iter: 0; batch classifier loss: 0.561173; batch adversarial loss: 0.648409\n",
      "epoch 30; iter: 0; batch classifier loss: 0.602742; batch adversarial loss: 0.599877\n",
      "epoch 31; iter: 0; batch classifier loss: 0.622198; batch adversarial loss: 0.621888\n",
      "epoch 32; iter: 0; batch classifier loss: 0.580171; batch adversarial loss: 0.617058\n",
      "epoch 33; iter: 0; batch classifier loss: 0.582845; batch adversarial loss: 0.604143\n",
      "epoch 34; iter: 0; batch classifier loss: 0.574198; batch adversarial loss: 0.620494\n",
      "epoch 35; iter: 0; batch classifier loss: 0.569242; batch adversarial loss: 0.669902\n",
      "epoch 36; iter: 0; batch classifier loss: 0.571494; batch adversarial loss: 0.609040\n",
      "epoch 37; iter: 0; batch classifier loss: 0.599201; batch adversarial loss: 0.613037\n",
      "epoch 38; iter: 0; batch classifier loss: 0.559744; batch adversarial loss: 0.596035\n",
      "epoch 39; iter: 0; batch classifier loss: 0.626503; batch adversarial loss: 0.621962\n",
      "epoch 40; iter: 0; batch classifier loss: 0.578134; batch adversarial loss: 0.673527\n",
      "epoch 41; iter: 0; batch classifier loss: 0.578343; batch adversarial loss: 0.673545\n",
      "epoch 42; iter: 0; batch classifier loss: 0.605113; batch adversarial loss: 0.632943\n",
      "epoch 43; iter: 0; batch classifier loss: 0.622365; batch adversarial loss: 0.625105\n",
      "epoch 44; iter: 0; batch classifier loss: 0.582667; batch adversarial loss: 0.626053\n",
      "epoch 45; iter: 0; batch classifier loss: 0.662770; batch adversarial loss: 0.602076\n",
      "epoch 46; iter: 0; batch classifier loss: 0.557664; batch adversarial loss: 0.628834\n",
      "epoch 47; iter: 0; batch classifier loss: 0.609319; batch adversarial loss: 0.652996\n",
      "epoch 48; iter: 0; batch classifier loss: 0.614009; batch adversarial loss: 0.619847\n",
      "epoch 49; iter: 0; batch classifier loss: 0.588626; batch adversarial loss: 0.640204\n",
      "epoch 0; iter: 0; batch classifier loss: 0.881901; batch adversarial loss: 0.659032\n",
      "epoch 1; iter: 0; batch classifier loss: 0.837159; batch adversarial loss: 0.652472\n",
      "epoch 2; iter: 0; batch classifier loss: 0.748534; batch adversarial loss: 0.654345\n",
      "epoch 3; iter: 0; batch classifier loss: 0.728129; batch adversarial loss: 0.647864\n",
      "epoch 4; iter: 0; batch classifier loss: 0.705663; batch adversarial loss: 0.673632\n",
      "epoch 5; iter: 0; batch classifier loss: 0.599695; batch adversarial loss: 0.645707\n",
      "epoch 6; iter: 0; batch classifier loss: 0.628695; batch adversarial loss: 0.654748\n",
      "epoch 7; iter: 0; batch classifier loss: 0.646468; batch adversarial loss: 0.680672\n",
      "epoch 8; iter: 0; batch classifier loss: 0.645454; batch adversarial loss: 0.657299\n",
      "epoch 9; iter: 0; batch classifier loss: 0.666955; batch adversarial loss: 0.639403\n",
      "epoch 10; iter: 0; batch classifier loss: 0.615776; batch adversarial loss: 0.672185\n",
      "epoch 11; iter: 0; batch classifier loss: 0.590154; batch adversarial loss: 0.635884\n",
      "epoch 12; iter: 0; batch classifier loss: 0.644096; batch adversarial loss: 0.645166\n",
      "epoch 13; iter: 0; batch classifier loss: 0.641177; batch adversarial loss: 0.665027\n",
      "epoch 14; iter: 0; batch classifier loss: 0.648572; batch adversarial loss: 0.658133\n",
      "epoch 15; iter: 0; batch classifier loss: 0.639656; batch adversarial loss: 0.646903\n",
      "epoch 16; iter: 0; batch classifier loss: 0.577999; batch adversarial loss: 0.646758\n",
      "epoch 17; iter: 0; batch classifier loss: 0.645515; batch adversarial loss: 0.637601\n",
      "epoch 18; iter: 0; batch classifier loss: 0.620344; batch adversarial loss: 0.608610\n",
      "epoch 19; iter: 0; batch classifier loss: 0.597723; batch adversarial loss: 0.652721\n",
      "epoch 20; iter: 0; batch classifier loss: 0.618789; batch adversarial loss: 0.669276\n",
      "epoch 21; iter: 0; batch classifier loss: 0.605550; batch adversarial loss: 0.651228\n",
      "epoch 22; iter: 0; batch classifier loss: 0.588440; batch adversarial loss: 0.610393\n",
      "epoch 23; iter: 0; batch classifier loss: 0.599379; batch adversarial loss: 0.627871\n",
      "epoch 24; iter: 0; batch classifier loss: 0.705303; batch adversarial loss: 0.637728\n",
      "epoch 25; iter: 0; batch classifier loss: 0.602332; batch adversarial loss: 0.642869\n",
      "epoch 26; iter: 0; batch classifier loss: 0.602322; batch adversarial loss: 0.664035\n",
      "epoch 27; iter: 0; batch classifier loss: 0.672606; batch adversarial loss: 0.644546\n",
      "epoch 28; iter: 0; batch classifier loss: 0.543020; batch adversarial loss: 0.628764\n",
      "epoch 29; iter: 0; batch classifier loss: 0.584820; batch adversarial loss: 0.661912\n",
      "epoch 30; iter: 0; batch classifier loss: 0.592877; batch adversarial loss: 0.660847\n",
      "epoch 31; iter: 0; batch classifier loss: 0.676304; batch adversarial loss: 0.663433\n",
      "epoch 32; iter: 0; batch classifier loss: 0.588821; batch adversarial loss: 0.637329\n",
      "epoch 33; iter: 0; batch classifier loss: 0.576106; batch adversarial loss: 0.591551\n",
      "epoch 34; iter: 0; batch classifier loss: 0.641021; batch adversarial loss: 0.645506\n",
      "epoch 35; iter: 0; batch classifier loss: 0.634800; batch adversarial loss: 0.659653\n",
      "epoch 36; iter: 0; batch classifier loss: 0.574154; batch adversarial loss: 0.628075\n",
      "epoch 37; iter: 0; batch classifier loss: 0.580074; batch adversarial loss: 0.628178\n",
      "epoch 38; iter: 0; batch classifier loss: 0.555904; batch adversarial loss: 0.625788\n",
      "epoch 39; iter: 0; batch classifier loss: 0.608559; batch adversarial loss: 0.648972\n",
      "epoch 40; iter: 0; batch classifier loss: 0.643164; batch adversarial loss: 0.646629\n",
      "epoch 41; iter: 0; batch classifier loss: 0.642998; batch adversarial loss: 0.645568\n",
      "epoch 42; iter: 0; batch classifier loss: 0.636068; batch adversarial loss: 0.629030\n",
      "epoch 43; iter: 0; batch classifier loss: 0.613270; batch adversarial loss: 0.559063\n",
      "epoch 44; iter: 0; batch classifier loss: 0.594273; batch adversarial loss: 0.620390\n",
      "epoch 45; iter: 0; batch classifier loss: 0.562709; batch adversarial loss: 0.629742\n",
      "epoch 46; iter: 0; batch classifier loss: 0.632061; batch adversarial loss: 0.657020\n",
      "epoch 47; iter: 0; batch classifier loss: 0.576312; batch adversarial loss: 0.659787\n",
      "epoch 48; iter: 0; batch classifier loss: 0.639125; batch adversarial loss: 0.622708\n",
      "epoch 49; iter: 0; batch classifier loss: 0.669951; batch adversarial loss: 0.679577\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.675731  0.611391 -0.080135  0.817240 -0.088234 -0.056104\n",
      "std   0.013530  0.029329  0.073279  0.151087  0.082758  0.070218\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'race'\n",
    "privileged_value    = 0.0\n",
    "unprivileged_value  = 1.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_compas_race()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','race')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    "    scope_name='adv',           \n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.1)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "compas_race_metrics = pd.DataFrame(results)\n",
    "compas_race_metrics_agg = compas_race_metrics.agg(['mean','std'])\n",
    "\n",
    "print(compas_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62585541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, compas_race_metrics_agg, 'Baseline', 'Race', 'Default Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fce3f2",
   "metadata": {},
   "source": [
    "## default adversial debiaser, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d433b573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.897230; batch adversarial loss: 0.676816\n",
      "epoch 1; iter: 0; batch classifier loss: 0.780812; batch adversarial loss: 0.681758\n",
      "epoch 2; iter: 0; batch classifier loss: 0.744180; batch adversarial loss: 0.644158\n",
      "epoch 3; iter: 0; batch classifier loss: 0.723782; batch adversarial loss: 0.597934\n",
      "epoch 4; iter: 0; batch classifier loss: 0.639581; batch adversarial loss: 0.616916\n",
      "epoch 5; iter: 0; batch classifier loss: 0.677260; batch adversarial loss: 0.577898\n",
      "epoch 6; iter: 0; batch classifier loss: 0.625645; batch adversarial loss: 0.585234\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592586; batch adversarial loss: 0.624790\n",
      "epoch 8; iter: 0; batch classifier loss: 0.726660; batch adversarial loss: 0.575121\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576563; batch adversarial loss: 0.584692\n",
      "epoch 10; iter: 0; batch classifier loss: 0.635435; batch adversarial loss: 0.570003\n",
      "epoch 11; iter: 0; batch classifier loss: 0.596293; batch adversarial loss: 0.542045\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599151; batch adversarial loss: 0.529130\n",
      "epoch 13; iter: 0; batch classifier loss: 0.626701; batch adversarial loss: 0.461961\n",
      "epoch 14; iter: 0; batch classifier loss: 0.656664; batch adversarial loss: 0.526847\n",
      "epoch 15; iter: 0; batch classifier loss: 0.631816; batch adversarial loss: 0.539328\n",
      "epoch 16; iter: 0; batch classifier loss: 0.709550; batch adversarial loss: 0.470542\n",
      "epoch 17; iter: 0; batch classifier loss: 0.585951; batch adversarial loss: 0.485898\n",
      "epoch 18; iter: 0; batch classifier loss: 0.643159; batch adversarial loss: 0.538390\n",
      "epoch 19; iter: 0; batch classifier loss: 0.612393; batch adversarial loss: 0.492838\n",
      "epoch 20; iter: 0; batch classifier loss: 0.605722; batch adversarial loss: 0.549008\n",
      "epoch 21; iter: 0; batch classifier loss: 0.629796; batch adversarial loss: 0.535743\n",
      "epoch 22; iter: 0; batch classifier loss: 0.669056; batch adversarial loss: 0.487679\n",
      "epoch 23; iter: 0; batch classifier loss: 0.615661; batch adversarial loss: 0.450535\n",
      "epoch 24; iter: 0; batch classifier loss: 0.597933; batch adversarial loss: 0.574278\n",
      "epoch 25; iter: 0; batch classifier loss: 0.637475; batch adversarial loss: 0.464031\n",
      "epoch 26; iter: 0; batch classifier loss: 0.669900; batch adversarial loss: 0.493027\n",
      "epoch 27; iter: 0; batch classifier loss: 0.602710; batch adversarial loss: 0.492242\n",
      "epoch 28; iter: 0; batch classifier loss: 0.600756; batch adversarial loss: 0.468911\n",
      "epoch 29; iter: 0; batch classifier loss: 0.592063; batch adversarial loss: 0.523882\n",
      "epoch 30; iter: 0; batch classifier loss: 0.589939; batch adversarial loss: 0.470615\n",
      "epoch 31; iter: 0; batch classifier loss: 0.639292; batch adversarial loss: 0.523398\n",
      "epoch 32; iter: 0; batch classifier loss: 0.617350; batch adversarial loss: 0.523239\n",
      "epoch 33; iter: 0; batch classifier loss: 0.675902; batch adversarial loss: 0.525120\n",
      "epoch 34; iter: 0; batch classifier loss: 0.625543; batch adversarial loss: 0.557750\n",
      "epoch 35; iter: 0; batch classifier loss: 0.669957; batch adversarial loss: 0.453642\n",
      "epoch 36; iter: 0; batch classifier loss: 0.608339; batch adversarial loss: 0.517249\n",
      "epoch 37; iter: 0; batch classifier loss: 0.576045; batch adversarial loss: 0.551114\n",
      "epoch 38; iter: 0; batch classifier loss: 0.668862; batch adversarial loss: 0.538031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.580302; batch adversarial loss: 0.491620\n",
      "epoch 40; iter: 0; batch classifier loss: 0.586173; batch adversarial loss: 0.430336\n",
      "epoch 41; iter: 0; batch classifier loss: 0.581512; batch adversarial loss: 0.496592\n",
      "epoch 42; iter: 0; batch classifier loss: 0.574010; batch adversarial loss: 0.555027\n",
      "epoch 43; iter: 0; batch classifier loss: 0.626111; batch adversarial loss: 0.483665\n",
      "epoch 44; iter: 0; batch classifier loss: 0.649076; batch adversarial loss: 0.513387\n",
      "epoch 45; iter: 0; batch classifier loss: 0.628948; batch adversarial loss: 0.390318\n",
      "epoch 46; iter: 0; batch classifier loss: 0.639238; batch adversarial loss: 0.514618\n",
      "epoch 47; iter: 0; batch classifier loss: 0.626463; batch adversarial loss: 0.459376\n",
      "epoch 48; iter: 0; batch classifier loss: 0.679437; batch adversarial loss: 0.455555\n",
      "epoch 49; iter: 0; batch classifier loss: 0.587581; batch adversarial loss: 0.492731\n",
      "epoch 0; iter: 0; batch classifier loss: 0.814641; batch adversarial loss: 0.705209\n",
      "epoch 1; iter: 0; batch classifier loss: 0.825885; batch adversarial loss: 0.683628\n",
      "epoch 2; iter: 0; batch classifier loss: 0.712724; batch adversarial loss: 0.652249\n",
      "epoch 3; iter: 0; batch classifier loss: 0.697063; batch adversarial loss: 0.635032\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596598; batch adversarial loss: 0.616768\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681363; batch adversarial loss: 0.594300\n",
      "epoch 6; iter: 0; batch classifier loss: 0.677696; batch adversarial loss: 0.615305\n",
      "epoch 7; iter: 0; batch classifier loss: 0.667573; batch adversarial loss: 0.575335\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588608; batch adversarial loss: 0.584680\n",
      "epoch 9; iter: 0; batch classifier loss: 0.701264; batch adversarial loss: 0.582704\n",
      "epoch 10; iter: 0; batch classifier loss: 0.606404; batch adversarial loss: 0.575790\n",
      "epoch 11; iter: 0; batch classifier loss: 0.611089; batch adversarial loss: 0.564932\n",
      "epoch 12; iter: 0; batch classifier loss: 0.664656; batch adversarial loss: 0.587853\n",
      "epoch 13; iter: 0; batch classifier loss: 0.634230; batch adversarial loss: 0.571100\n",
      "epoch 14; iter: 0; batch classifier loss: 0.672194; batch adversarial loss: 0.561176\n",
      "epoch 15; iter: 0; batch classifier loss: 0.654680; batch adversarial loss: 0.513253\n",
      "epoch 16; iter: 0; batch classifier loss: 0.574871; batch adversarial loss: 0.540100\n",
      "epoch 17; iter: 0; batch classifier loss: 0.598240; batch adversarial loss: 0.524622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.615428; batch adversarial loss: 0.563556\n",
      "epoch 19; iter: 0; batch classifier loss: 0.633577; batch adversarial loss: 0.625307\n",
      "epoch 20; iter: 0; batch classifier loss: 0.651817; batch adversarial loss: 0.515151\n",
      "epoch 21; iter: 0; batch classifier loss: 0.639682; batch adversarial loss: 0.601861\n",
      "epoch 22; iter: 0; batch classifier loss: 0.686108; batch adversarial loss: 0.558317\n",
      "epoch 23; iter: 0; batch classifier loss: 0.646490; batch adversarial loss: 0.573860\n",
      "epoch 24; iter: 0; batch classifier loss: 0.663497; batch adversarial loss: 0.515982\n",
      "epoch 25; iter: 0; batch classifier loss: 0.614650; batch adversarial loss: 0.539278\n",
      "epoch 26; iter: 0; batch classifier loss: 0.586682; batch adversarial loss: 0.533861\n",
      "epoch 27; iter: 0; batch classifier loss: 0.619429; batch adversarial loss: 0.518924\n",
      "epoch 28; iter: 0; batch classifier loss: 0.656729; batch adversarial loss: 0.483707\n",
      "epoch 29; iter: 0; batch classifier loss: 0.565473; batch adversarial loss: 0.433219\n",
      "epoch 30; iter: 0; batch classifier loss: 0.684198; batch adversarial loss: 0.505258\n",
      "epoch 31; iter: 0; batch classifier loss: 0.632257; batch adversarial loss: 0.556316\n",
      "epoch 32; iter: 0; batch classifier loss: 0.613255; batch adversarial loss: 0.450854\n",
      "epoch 33; iter: 0; batch classifier loss: 0.623856; batch adversarial loss: 0.500550\n",
      "epoch 34; iter: 0; batch classifier loss: 0.631470; batch adversarial loss: 0.443419\n",
      "epoch 35; iter: 0; batch classifier loss: 0.657923; batch adversarial loss: 0.565171\n",
      "epoch 36; iter: 0; batch classifier loss: 0.627715; batch adversarial loss: 0.468414\n",
      "epoch 37; iter: 0; batch classifier loss: 0.577683; batch adversarial loss: 0.580324\n",
      "epoch 38; iter: 0; batch classifier loss: 0.615342; batch adversarial loss: 0.500014\n",
      "epoch 39; iter: 0; batch classifier loss: 0.602251; batch adversarial loss: 0.545963\n",
      "epoch 40; iter: 0; batch classifier loss: 0.616980; batch adversarial loss: 0.557370\n",
      "epoch 41; iter: 0; batch classifier loss: 0.593302; batch adversarial loss: 0.498503\n",
      "epoch 42; iter: 0; batch classifier loss: 0.590521; batch adversarial loss: 0.577054\n",
      "epoch 43; iter: 0; batch classifier loss: 0.683820; batch adversarial loss: 0.396669\n",
      "epoch 44; iter: 0; batch classifier loss: 0.647990; batch adversarial loss: 0.462111\n",
      "epoch 45; iter: 0; batch classifier loss: 0.688632; batch adversarial loss: 0.447172\n",
      "epoch 46; iter: 0; batch classifier loss: 0.616030; batch adversarial loss: 0.433385\n",
      "epoch 47; iter: 0; batch classifier loss: 0.552262; batch adversarial loss: 0.613297\n",
      "epoch 48; iter: 0; batch classifier loss: 0.636291; batch adversarial loss: 0.424166\n",
      "epoch 49; iter: 0; batch classifier loss: 0.607758; batch adversarial loss: 0.574940\n",
      "epoch 0; iter: 0; batch classifier loss: 1.214776; batch adversarial loss: 0.602881\n",
      "epoch 1; iter: 0; batch classifier loss: 0.827456; batch adversarial loss: 0.627258\n",
      "epoch 2; iter: 0; batch classifier loss: 0.758001; batch adversarial loss: 0.613763\n",
      "epoch 3; iter: 0; batch classifier loss: 0.697314; batch adversarial loss: 0.625554\n",
      "epoch 4; iter: 0; batch classifier loss: 0.759573; batch adversarial loss: 0.618684\n",
      "epoch 5; iter: 0; batch classifier loss: 0.677690; batch adversarial loss: 0.632695\n",
      "epoch 6; iter: 0; batch classifier loss: 0.620565; batch adversarial loss: 0.582484\n",
      "epoch 7; iter: 0; batch classifier loss: 0.673283; batch adversarial loss: 0.564264\n",
      "epoch 8; iter: 0; batch classifier loss: 0.746911; batch adversarial loss: 0.560550\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616800; batch adversarial loss: 0.609620\n",
      "epoch 10; iter: 0; batch classifier loss: 0.607546; batch adversarial loss: 0.550035\n",
      "epoch 11; iter: 0; batch classifier loss: 0.587197; batch adversarial loss: 0.535811\n",
      "epoch 12; iter: 0; batch classifier loss: 0.623968; batch adversarial loss: 0.573245\n",
      "epoch 13; iter: 0; batch classifier loss: 0.663264; batch adversarial loss: 0.571147\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601246; batch adversarial loss: 0.505124\n",
      "epoch 15; iter: 0; batch classifier loss: 0.696706; batch adversarial loss: 0.621055\n",
      "epoch 16; iter: 0; batch classifier loss: 0.644315; batch adversarial loss: 0.543617\n",
      "epoch 17; iter: 0; batch classifier loss: 0.689911; batch adversarial loss: 0.531907\n",
      "epoch 18; iter: 0; batch classifier loss: 0.618718; batch adversarial loss: 0.498791\n",
      "epoch 19; iter: 0; batch classifier loss: 0.662593; batch adversarial loss: 0.519139\n",
      "epoch 20; iter: 0; batch classifier loss: 0.602890; batch adversarial loss: 0.476057\n",
      "epoch 21; iter: 0; batch classifier loss: 0.647373; batch adversarial loss: 0.523061\n",
      "epoch 22; iter: 0; batch classifier loss: 0.645668; batch adversarial loss: 0.488199\n",
      "epoch 23; iter: 0; batch classifier loss: 0.618782; batch adversarial loss: 0.561802\n",
      "epoch 24; iter: 0; batch classifier loss: 0.634513; batch adversarial loss: 0.481345\n",
      "epoch 25; iter: 0; batch classifier loss: 0.621314; batch adversarial loss: 0.540745\n",
      "epoch 26; iter: 0; batch classifier loss: 0.671362; batch adversarial loss: 0.579994\n",
      "epoch 27; iter: 0; batch classifier loss: 0.674301; batch adversarial loss: 0.547383\n",
      "epoch 28; iter: 0; batch classifier loss: 0.661727; batch adversarial loss: 0.491460\n",
      "epoch 29; iter: 0; batch classifier loss: 0.633088; batch adversarial loss: 0.507135\n",
      "epoch 30; iter: 0; batch classifier loss: 0.599619; batch adversarial loss: 0.489594\n",
      "epoch 31; iter: 0; batch classifier loss: 0.627967; batch adversarial loss: 0.501332\n",
      "epoch 32; iter: 0; batch classifier loss: 0.613597; batch adversarial loss: 0.511070\n",
      "epoch 33; iter: 0; batch classifier loss: 0.660721; batch adversarial loss: 0.525137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.642183; batch adversarial loss: 0.481901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.599919; batch adversarial loss: 0.517012\n",
      "epoch 36; iter: 0; batch classifier loss: 0.585099; batch adversarial loss: 0.447793\n",
      "epoch 37; iter: 0; batch classifier loss: 0.637895; batch adversarial loss: 0.525085\n",
      "epoch 38; iter: 0; batch classifier loss: 0.597993; batch adversarial loss: 0.545323\n",
      "epoch 39; iter: 0; batch classifier loss: 0.543415; batch adversarial loss: 0.473405\n",
      "epoch 40; iter: 0; batch classifier loss: 0.609965; batch adversarial loss: 0.548570\n",
      "epoch 41; iter: 0; batch classifier loss: 0.602104; batch adversarial loss: 0.441493\n",
      "epoch 42; iter: 0; batch classifier loss: 0.625464; batch adversarial loss: 0.502783\n",
      "epoch 43; iter: 0; batch classifier loss: 0.575159; batch adversarial loss: 0.462408\n",
      "epoch 44; iter: 0; batch classifier loss: 0.613084; batch adversarial loss: 0.435975\n",
      "epoch 45; iter: 0; batch classifier loss: 0.688671; batch adversarial loss: 0.491164\n",
      "epoch 46; iter: 0; batch classifier loss: 0.576292; batch adversarial loss: 0.522980\n",
      "epoch 47; iter: 0; batch classifier loss: 0.596254; batch adversarial loss: 0.446242\n",
      "epoch 48; iter: 0; batch classifier loss: 0.532828; batch adversarial loss: 0.503839\n",
      "epoch 49; iter: 0; batch classifier loss: 0.622881; batch adversarial loss: 0.488735\n",
      "epoch 0; iter: 0; batch classifier loss: 2.984584; batch adversarial loss: 0.557778\n",
      "epoch 1; iter: 0; batch classifier loss: 0.793496; batch adversarial loss: 0.577235\n",
      "epoch 2; iter: 0; batch classifier loss: 0.789342; batch adversarial loss: 0.620828\n",
      "epoch 3; iter: 0; batch classifier loss: 0.730080; batch adversarial loss: 0.561801\n",
      "epoch 4; iter: 0; batch classifier loss: 0.667437; batch adversarial loss: 0.568306\n",
      "epoch 5; iter: 0; batch classifier loss: 0.719226; batch adversarial loss: 0.595273\n",
      "epoch 6; iter: 0; batch classifier loss: 0.694393; batch adversarial loss: 0.576858\n",
      "epoch 7; iter: 0; batch classifier loss: 0.729009; batch adversarial loss: 0.592441\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619289; batch adversarial loss: 0.585476\n",
      "epoch 9; iter: 0; batch classifier loss: 0.645608; batch adversarial loss: 0.509587\n",
      "epoch 10; iter: 0; batch classifier loss: 0.675897; batch adversarial loss: 0.575553\n",
      "epoch 11; iter: 0; batch classifier loss: 0.709262; batch adversarial loss: 0.579144\n",
      "epoch 12; iter: 0; batch classifier loss: 0.593701; batch adversarial loss: 0.518112\n",
      "epoch 13; iter: 0; batch classifier loss: 0.695117; batch adversarial loss: 0.578886\n",
      "epoch 14; iter: 0; batch classifier loss: 0.669201; batch adversarial loss: 0.508216\n",
      "epoch 15; iter: 0; batch classifier loss: 0.684286; batch adversarial loss: 0.482212\n",
      "epoch 16; iter: 0; batch classifier loss: 0.588423; batch adversarial loss: 0.556674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.606845; batch adversarial loss: 0.553155\n",
      "epoch 18; iter: 0; batch classifier loss: 0.617037; batch adversarial loss: 0.539323\n",
      "epoch 19; iter: 0; batch classifier loss: 0.640939; batch adversarial loss: 0.477420\n",
      "epoch 20; iter: 0; batch classifier loss: 0.608409; batch adversarial loss: 0.537625\n",
      "epoch 21; iter: 0; batch classifier loss: 0.694731; batch adversarial loss: 0.498254\n",
      "epoch 22; iter: 0; batch classifier loss: 0.656799; batch adversarial loss: 0.499548\n",
      "epoch 23; iter: 0; batch classifier loss: 0.556629; batch adversarial loss: 0.524852\n",
      "epoch 24; iter: 0; batch classifier loss: 0.618339; batch adversarial loss: 0.576864\n",
      "epoch 25; iter: 0; batch classifier loss: 0.635574; batch adversarial loss: 0.561813\n",
      "epoch 26; iter: 0; batch classifier loss: 0.637428; batch adversarial loss: 0.459808\n",
      "epoch 27; iter: 0; batch classifier loss: 0.612906; batch adversarial loss: 0.553972\n",
      "epoch 28; iter: 0; batch classifier loss: 0.560718; batch adversarial loss: 0.553674\n",
      "epoch 29; iter: 0; batch classifier loss: 0.713126; batch adversarial loss: 0.497949\n",
      "epoch 30; iter: 0; batch classifier loss: 0.658120; batch adversarial loss: 0.503092\n",
      "epoch 31; iter: 0; batch classifier loss: 0.693822; batch adversarial loss: 0.485073\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629487; batch adversarial loss: 0.485098\n",
      "epoch 33; iter: 0; batch classifier loss: 0.629488; batch adversarial loss: 0.556130\n",
      "epoch 34; iter: 0; batch classifier loss: 0.629244; batch adversarial loss: 0.573192\n",
      "epoch 35; iter: 0; batch classifier loss: 0.677995; batch adversarial loss: 0.520087\n",
      "epoch 36; iter: 0; batch classifier loss: 0.578086; batch adversarial loss: 0.422474\n",
      "epoch 37; iter: 0; batch classifier loss: 0.690897; batch adversarial loss: 0.520190\n",
      "epoch 38; iter: 0; batch classifier loss: 0.607339; batch adversarial loss: 0.441621\n",
      "epoch 39; iter: 0; batch classifier loss: 0.625551; batch adversarial loss: 0.512612\n",
      "epoch 40; iter: 0; batch classifier loss: 0.574377; batch adversarial loss: 0.517467\n",
      "epoch 41; iter: 0; batch classifier loss: 0.674068; batch adversarial loss: 0.475842\n",
      "epoch 42; iter: 0; batch classifier loss: 0.654335; batch adversarial loss: 0.392523\n",
      "epoch 43; iter: 0; batch classifier loss: 0.577259; batch adversarial loss: 0.474925\n",
      "epoch 44; iter: 0; batch classifier loss: 0.631354; batch adversarial loss: 0.443857\n",
      "epoch 45; iter: 0; batch classifier loss: 0.591863; batch adversarial loss: 0.452118\n",
      "epoch 46; iter: 0; batch classifier loss: 0.595948; batch adversarial loss: 0.468193\n",
      "epoch 47; iter: 0; batch classifier loss: 0.638105; batch adversarial loss: 0.528391\n",
      "epoch 48; iter: 0; batch classifier loss: 0.633451; batch adversarial loss: 0.479858\n",
      "epoch 49; iter: 0; batch classifier loss: 0.574226; batch adversarial loss: 0.463799\n",
      "epoch 0; iter: 0; batch classifier loss: 0.913384; batch adversarial loss: 0.809029\n",
      "epoch 1; iter: 0; batch classifier loss: 1.231367; batch adversarial loss: 0.984564\n",
      "epoch 2; iter: 0; batch classifier loss: 0.950514; batch adversarial loss: 0.916856\n",
      "epoch 3; iter: 0; batch classifier loss: 0.969788; batch adversarial loss: 0.929144\n",
      "epoch 4; iter: 0; batch classifier loss: 1.057335; batch adversarial loss: 0.894366\n",
      "epoch 5; iter: 0; batch classifier loss: 0.841306; batch adversarial loss: 0.779383\n",
      "epoch 6; iter: 0; batch classifier loss: 0.879768; batch adversarial loss: 0.758376\n",
      "epoch 7; iter: 0; batch classifier loss: 0.942845; batch adversarial loss: 0.753615\n",
      "epoch 8; iter: 0; batch classifier loss: 0.824788; batch adversarial loss: 0.703251\n",
      "epoch 9; iter: 0; batch classifier loss: 0.771345; batch adversarial loss: 0.668757\n",
      "epoch 10; iter: 0; batch classifier loss: 0.700705; batch adversarial loss: 0.598012\n",
      "epoch 11; iter: 0; batch classifier loss: 0.662925; batch adversarial loss: 0.589799\n",
      "epoch 12; iter: 0; batch classifier loss: 0.636517; batch adversarial loss: 0.565193\n",
      "epoch 13; iter: 0; batch classifier loss: 0.645365; batch adversarial loss: 0.584692\n",
      "epoch 14; iter: 0; batch classifier loss: 0.629990; batch adversarial loss: 0.585683\n",
      "epoch 15; iter: 0; batch classifier loss: 0.681643; batch adversarial loss: 0.578554\n",
      "epoch 16; iter: 0; batch classifier loss: 0.618526; batch adversarial loss: 0.517024\n",
      "epoch 17; iter: 0; batch classifier loss: 0.588092; batch adversarial loss: 0.464090\n",
      "epoch 18; iter: 0; batch classifier loss: 0.643995; batch adversarial loss: 0.573227\n",
      "epoch 19; iter: 0; batch classifier loss: 0.614242; batch adversarial loss: 0.550258\n",
      "epoch 20; iter: 0; batch classifier loss: 0.587638; batch adversarial loss: 0.542504\n",
      "epoch 21; iter: 0; batch classifier loss: 0.583548; batch adversarial loss: 0.516630\n",
      "epoch 22; iter: 0; batch classifier loss: 0.597581; batch adversarial loss: 0.560515\n",
      "epoch 23; iter: 0; batch classifier loss: 0.616956; batch adversarial loss: 0.524251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.659580; batch adversarial loss: 0.513362\n",
      "epoch 25; iter: 0; batch classifier loss: 0.611647; batch adversarial loss: 0.524747\n",
      "epoch 26; iter: 0; batch classifier loss: 0.659793; batch adversarial loss: 0.501318\n",
      "epoch 27; iter: 0; batch classifier loss: 0.655457; batch adversarial loss: 0.515366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.643867; batch adversarial loss: 0.523351\n",
      "epoch 29; iter: 0; batch classifier loss: 0.636182; batch adversarial loss: 0.566426\n",
      "epoch 30; iter: 0; batch classifier loss: 0.567761; batch adversarial loss: 0.520134\n",
      "epoch 31; iter: 0; batch classifier loss: 0.609601; batch adversarial loss: 0.488102\n",
      "epoch 32; iter: 0; batch classifier loss: 0.606422; batch adversarial loss: 0.440007\n",
      "epoch 33; iter: 0; batch classifier loss: 0.596984; batch adversarial loss: 0.549357\n",
      "epoch 34; iter: 0; batch classifier loss: 0.574014; batch adversarial loss: 0.510788\n",
      "epoch 35; iter: 0; batch classifier loss: 0.610723; batch adversarial loss: 0.520135\n",
      "epoch 36; iter: 0; batch classifier loss: 0.612172; batch adversarial loss: 0.504190\n",
      "epoch 37; iter: 0; batch classifier loss: 0.579197; batch adversarial loss: 0.484961\n",
      "epoch 38; iter: 0; batch classifier loss: 0.602331; batch adversarial loss: 0.479795\n",
      "epoch 39; iter: 0; batch classifier loss: 0.574299; batch adversarial loss: 0.512269\n",
      "epoch 40; iter: 0; batch classifier loss: 0.615238; batch adversarial loss: 0.529109\n",
      "epoch 41; iter: 0; batch classifier loss: 0.627508; batch adversarial loss: 0.473079\n",
      "epoch 42; iter: 0; batch classifier loss: 0.586678; batch adversarial loss: 0.462515\n",
      "epoch 43; iter: 0; batch classifier loss: 0.638525; batch adversarial loss: 0.461946\n",
      "epoch 44; iter: 0; batch classifier loss: 0.600481; batch adversarial loss: 0.439657\n",
      "epoch 45; iter: 0; batch classifier loss: 0.601252; batch adversarial loss: 0.432402\n",
      "epoch 46; iter: 0; batch classifier loss: 0.638694; batch adversarial loss: 0.485566\n",
      "epoch 47; iter: 0; batch classifier loss: 0.610934; batch adversarial loss: 0.530348\n",
      "epoch 48; iter: 0; batch classifier loss: 0.636841; batch adversarial loss: 0.502331\n",
      "epoch 49; iter: 0; batch classifier loss: 0.548511; batch adversarial loss: 0.536735\n",
      "epoch 0; iter: 0; batch classifier loss: 1.374188; batch adversarial loss: 0.756114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.818632; batch adversarial loss: 0.669282\n",
      "epoch 2; iter: 0; batch classifier loss: 0.785433; batch adversarial loss: 0.678239\n",
      "epoch 3; iter: 0; batch classifier loss: 0.676029; batch adversarial loss: 0.635612\n",
      "epoch 4; iter: 0; batch classifier loss: 0.709238; batch adversarial loss: 0.633588\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619921; batch adversarial loss: 0.617430\n",
      "epoch 6; iter: 0; batch classifier loss: 0.675283; batch adversarial loss: 0.607138\n",
      "epoch 7; iter: 0; batch classifier loss: 0.595478; batch adversarial loss: 0.589986\n",
      "epoch 8; iter: 0; batch classifier loss: 0.583159; batch adversarial loss: 0.582446\n",
      "epoch 9; iter: 0; batch classifier loss: 0.622403; batch adversarial loss: 0.575171\n",
      "epoch 10; iter: 0; batch classifier loss: 0.647004; batch adversarial loss: 0.569884\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579864; batch adversarial loss: 0.541963\n",
      "epoch 12; iter: 0; batch classifier loss: 0.649367; batch adversarial loss: 0.541237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.642661; batch adversarial loss: 0.537320\n",
      "epoch 14; iter: 0; batch classifier loss: 0.641168; batch adversarial loss: 0.559859\n",
      "epoch 15; iter: 0; batch classifier loss: 0.641927; batch adversarial loss: 0.565787\n",
      "epoch 16; iter: 0; batch classifier loss: 0.622041; batch adversarial loss: 0.579810\n",
      "epoch 17; iter: 0; batch classifier loss: 0.604980; batch adversarial loss: 0.588248\n",
      "epoch 18; iter: 0; batch classifier loss: 0.652033; batch adversarial loss: 0.510430\n",
      "epoch 19; iter: 0; batch classifier loss: 0.620550; batch adversarial loss: 0.514059\n",
      "epoch 20; iter: 0; batch classifier loss: 0.601523; batch adversarial loss: 0.489073\n",
      "epoch 21; iter: 0; batch classifier loss: 0.580145; batch adversarial loss: 0.519403\n",
      "epoch 22; iter: 0; batch classifier loss: 0.682290; batch adversarial loss: 0.519417\n",
      "epoch 23; iter: 0; batch classifier loss: 0.609837; batch adversarial loss: 0.541503\n",
      "epoch 24; iter: 0; batch classifier loss: 0.690321; batch adversarial loss: 0.488649\n",
      "epoch 25; iter: 0; batch classifier loss: 0.654737; batch adversarial loss: 0.466202\n",
      "epoch 26; iter: 0; batch classifier loss: 0.635256; batch adversarial loss: 0.494091\n",
      "epoch 27; iter: 0; batch classifier loss: 0.652841; batch adversarial loss: 0.495772\n",
      "epoch 28; iter: 0; batch classifier loss: 0.581327; batch adversarial loss: 0.525784\n",
      "epoch 29; iter: 0; batch classifier loss: 0.563823; batch adversarial loss: 0.458432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.683593; batch adversarial loss: 0.520181\n",
      "epoch 31; iter: 0; batch classifier loss: 0.639153; batch adversarial loss: 0.586270\n",
      "epoch 32; iter: 0; batch classifier loss: 0.620925; batch adversarial loss: 0.489454\n",
      "epoch 33; iter: 0; batch classifier loss: 0.589158; batch adversarial loss: 0.513020\n",
      "epoch 34; iter: 0; batch classifier loss: 0.602717; batch adversarial loss: 0.560263\n",
      "epoch 35; iter: 0; batch classifier loss: 0.672468; batch adversarial loss: 0.613620\n",
      "epoch 36; iter: 0; batch classifier loss: 0.602895; batch adversarial loss: 0.542756\n",
      "epoch 37; iter: 0; batch classifier loss: 0.677206; batch adversarial loss: 0.433097\n",
      "epoch 38; iter: 0; batch classifier loss: 0.619444; batch adversarial loss: 0.507236\n",
      "epoch 39; iter: 0; batch classifier loss: 0.651434; batch adversarial loss: 0.472574\n",
      "epoch 40; iter: 0; batch classifier loss: 0.671999; batch adversarial loss: 0.450405\n",
      "epoch 41; iter: 0; batch classifier loss: 0.690472; batch adversarial loss: 0.536983\n",
      "epoch 42; iter: 0; batch classifier loss: 0.604164; batch adversarial loss: 0.556225\n",
      "epoch 43; iter: 0; batch classifier loss: 0.640901; batch adversarial loss: 0.534922\n",
      "epoch 44; iter: 0; batch classifier loss: 0.615958; batch adversarial loss: 0.558444\n",
      "epoch 45; iter: 0; batch classifier loss: 0.580350; batch adversarial loss: 0.464627\n",
      "epoch 46; iter: 0; batch classifier loss: 0.606525; batch adversarial loss: 0.548542\n",
      "epoch 47; iter: 0; batch classifier loss: 0.645789; batch adversarial loss: 0.596442\n",
      "epoch 48; iter: 0; batch classifier loss: 0.624758; batch adversarial loss: 0.402839\n",
      "epoch 49; iter: 0; batch classifier loss: 0.665472; batch adversarial loss: 0.545826\n",
      "epoch 0; iter: 0; batch classifier loss: 1.179948; batch adversarial loss: 0.932162\n",
      "epoch 1; iter: 0; batch classifier loss: 1.254360; batch adversarial loss: 1.122095\n",
      "epoch 2; iter: 0; batch classifier loss: 1.041722; batch adversarial loss: 1.127296\n",
      "epoch 3; iter: 0; batch classifier loss: 0.995407; batch adversarial loss: 1.084459\n",
      "epoch 4; iter: 0; batch classifier loss: 0.981832; batch adversarial loss: 1.010095\n",
      "epoch 5; iter: 0; batch classifier loss: 1.026289; batch adversarial loss: 0.958429\n",
      "epoch 6; iter: 0; batch classifier loss: 1.055219; batch adversarial loss: 0.909407\n",
      "epoch 7; iter: 0; batch classifier loss: 1.124521; batch adversarial loss: 0.858624\n",
      "epoch 8; iter: 0; batch classifier loss: 1.087976; batch adversarial loss: 0.809807\n",
      "epoch 9; iter: 0; batch classifier loss: 1.213280; batch adversarial loss: 0.783534\n",
      "epoch 10; iter: 0; batch classifier loss: 1.126039; batch adversarial loss: 0.720465\n",
      "epoch 11; iter: 0; batch classifier loss: 1.056139; batch adversarial loss: 0.705156\n",
      "epoch 12; iter: 0; batch classifier loss: 0.999112; batch adversarial loss: 0.671841\n",
      "epoch 13; iter: 0; batch classifier loss: 0.893268; batch adversarial loss: 0.623163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.877472; batch adversarial loss: 0.630349\n",
      "epoch 15; iter: 0; batch classifier loss: 0.677185; batch adversarial loss: 0.582091\n",
      "epoch 16; iter: 0; batch classifier loss: 0.678972; batch adversarial loss: 0.557742\n",
      "epoch 17; iter: 0; batch classifier loss: 0.624391; batch adversarial loss: 0.552656\n",
      "epoch 18; iter: 0; batch classifier loss: 0.608455; batch adversarial loss: 0.545221\n",
      "epoch 19; iter: 0; batch classifier loss: 0.587413; batch adversarial loss: 0.539363\n",
      "epoch 20; iter: 0; batch classifier loss: 0.633110; batch adversarial loss: 0.540174\n",
      "epoch 21; iter: 0; batch classifier loss: 0.606121; batch adversarial loss: 0.556105\n",
      "epoch 22; iter: 0; batch classifier loss: 0.532653; batch adversarial loss: 0.522711\n",
      "epoch 23; iter: 0; batch classifier loss: 0.628747; batch adversarial loss: 0.546307\n",
      "epoch 24; iter: 0; batch classifier loss: 0.580878; batch adversarial loss: 0.546747\n",
      "epoch 25; iter: 0; batch classifier loss: 0.608446; batch adversarial loss: 0.548672\n",
      "epoch 26; iter: 0; batch classifier loss: 0.623183; batch adversarial loss: 0.536548\n",
      "epoch 27; iter: 0; batch classifier loss: 0.646276; batch adversarial loss: 0.531845\n",
      "epoch 28; iter: 0; batch classifier loss: 0.593848; batch adversarial loss: 0.484760\n",
      "epoch 29; iter: 0; batch classifier loss: 0.616822; batch adversarial loss: 0.498482\n",
      "epoch 30; iter: 0; batch classifier loss: 0.557189; batch adversarial loss: 0.489841\n",
      "epoch 31; iter: 0; batch classifier loss: 0.587314; batch adversarial loss: 0.550894\n",
      "epoch 32; iter: 0; batch classifier loss: 0.617584; batch adversarial loss: 0.631922\n",
      "epoch 33; iter: 0; batch classifier loss: 0.645889; batch adversarial loss: 0.460344\n",
      "epoch 34; iter: 0; batch classifier loss: 0.602063; batch adversarial loss: 0.503087\n",
      "epoch 35; iter: 0; batch classifier loss: 0.598363; batch adversarial loss: 0.548612\n",
      "epoch 36; iter: 0; batch classifier loss: 0.630304; batch adversarial loss: 0.465669\n",
      "epoch 37; iter: 0; batch classifier loss: 0.672930; batch adversarial loss: 0.557761\n",
      "epoch 38; iter: 0; batch classifier loss: 0.603936; batch adversarial loss: 0.501422\n",
      "epoch 39; iter: 0; batch classifier loss: 0.594989; batch adversarial loss: 0.474108\n",
      "epoch 40; iter: 0; batch classifier loss: 0.649746; batch adversarial loss: 0.473223\n",
      "epoch 41; iter: 0; batch classifier loss: 0.585211; batch adversarial loss: 0.517225\n",
      "epoch 42; iter: 0; batch classifier loss: 0.516663; batch adversarial loss: 0.502053\n",
      "epoch 43; iter: 0; batch classifier loss: 0.646095; batch adversarial loss: 0.542742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.539307; batch adversarial loss: 0.445030\n",
      "epoch 45; iter: 0; batch classifier loss: 0.619604; batch adversarial loss: 0.554855\n",
      "epoch 46; iter: 0; batch classifier loss: 0.650240; batch adversarial loss: 0.505059\n",
      "epoch 47; iter: 0; batch classifier loss: 0.649490; batch adversarial loss: 0.472131\n",
      "epoch 48; iter: 0; batch classifier loss: 0.628777; batch adversarial loss: 0.442384\n",
      "epoch 49; iter: 0; batch classifier loss: 0.593283; batch adversarial loss: 0.366152\n",
      "epoch 0; iter: 0; batch classifier loss: 1.887615; batch adversarial loss: 0.692668\n",
      "epoch 1; iter: 0; batch classifier loss: 0.994964; batch adversarial loss: 0.650709\n",
      "epoch 2; iter: 0; batch classifier loss: 0.721931; batch adversarial loss: 0.640595\n",
      "epoch 3; iter: 0; batch classifier loss: 0.747584; batch adversarial loss: 0.666714\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676818; batch adversarial loss: 0.652349\n",
      "epoch 5; iter: 0; batch classifier loss: 0.796938; batch adversarial loss: 0.618987\n",
      "epoch 6; iter: 0; batch classifier loss: 0.899490; batch adversarial loss: 0.610693\n",
      "epoch 7; iter: 0; batch classifier loss: 0.768479; batch adversarial loss: 0.631239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.726118; batch adversarial loss: 0.604961\n",
      "epoch 9; iter: 0; batch classifier loss: 0.653570; batch adversarial loss: 0.593607\n",
      "epoch 10; iter: 0; batch classifier loss: 0.696902; batch adversarial loss: 0.605033\n",
      "epoch 11; iter: 0; batch classifier loss: 0.659935; batch adversarial loss: 0.615026\n",
      "epoch 12; iter: 0; batch classifier loss: 0.678081; batch adversarial loss: 0.547117\n",
      "epoch 13; iter: 0; batch classifier loss: 0.633366; batch adversarial loss: 0.572955\n",
      "epoch 14; iter: 0; batch classifier loss: 0.652573; batch adversarial loss: 0.512901\n",
      "epoch 15; iter: 0; batch classifier loss: 0.622464; batch adversarial loss: 0.593283\n",
      "epoch 16; iter: 0; batch classifier loss: 0.657824; batch adversarial loss: 0.487866\n",
      "epoch 17; iter: 0; batch classifier loss: 0.657491; batch adversarial loss: 0.512700\n",
      "epoch 18; iter: 0; batch classifier loss: 0.601810; batch adversarial loss: 0.524719\n",
      "epoch 19; iter: 0; batch classifier loss: 0.642149; batch adversarial loss: 0.506515\n",
      "epoch 20; iter: 0; batch classifier loss: 0.632720; batch adversarial loss: 0.494166\n",
      "epoch 21; iter: 0; batch classifier loss: 0.664482; batch adversarial loss: 0.476212\n",
      "epoch 22; iter: 0; batch classifier loss: 0.566307; batch adversarial loss: 0.492531\n",
      "epoch 23; iter: 0; batch classifier loss: 0.675007; batch adversarial loss: 0.472881\n",
      "epoch 24; iter: 0; batch classifier loss: 0.594722; batch adversarial loss: 0.511587\n",
      "epoch 25; iter: 0; batch classifier loss: 0.631555; batch adversarial loss: 0.486271\n",
      "epoch 26; iter: 0; batch classifier loss: 0.648812; batch adversarial loss: 0.469701\n",
      "epoch 27; iter: 0; batch classifier loss: 0.709800; batch adversarial loss: 0.516350\n",
      "epoch 28; iter: 0; batch classifier loss: 0.598905; batch adversarial loss: 0.455400\n",
      "epoch 29; iter: 0; batch classifier loss: 0.650157; batch adversarial loss: 0.542925\n",
      "epoch 30; iter: 0; batch classifier loss: 0.601982; batch adversarial loss: 0.476377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.671393; batch adversarial loss: 0.476564\n",
      "epoch 32; iter: 0; batch classifier loss: 0.617608; batch adversarial loss: 0.489839\n",
      "epoch 33; iter: 0; batch classifier loss: 0.660584; batch adversarial loss: 0.469132\n",
      "epoch 34; iter: 0; batch classifier loss: 0.598117; batch adversarial loss: 0.515256\n",
      "epoch 35; iter: 0; batch classifier loss: 0.641546; batch adversarial loss: 0.462400\n",
      "epoch 36; iter: 0; batch classifier loss: 0.627857; batch adversarial loss: 0.497965\n",
      "epoch 37; iter: 0; batch classifier loss: 0.635558; batch adversarial loss: 0.462389\n",
      "epoch 38; iter: 0; batch classifier loss: 0.621840; batch adversarial loss: 0.447345\n",
      "epoch 39; iter: 0; batch classifier loss: 0.697026; batch adversarial loss: 0.434475\n",
      "epoch 40; iter: 0; batch classifier loss: 0.664951; batch adversarial loss: 0.500534\n",
      "epoch 41; iter: 0; batch classifier loss: 0.590436; batch adversarial loss: 0.548237\n",
      "epoch 42; iter: 0; batch classifier loss: 0.597121; batch adversarial loss: 0.483173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.610286; batch adversarial loss: 0.383636\n",
      "epoch 44; iter: 0; batch classifier loss: 0.585536; batch adversarial loss: 0.453564\n",
      "epoch 45; iter: 0; batch classifier loss: 0.594052; batch adversarial loss: 0.486546\n",
      "epoch 46; iter: 0; batch classifier loss: 0.634161; batch adversarial loss: 0.493686\n",
      "epoch 47; iter: 0; batch classifier loss: 0.576369; batch adversarial loss: 0.358795\n",
      "epoch 48; iter: 0; batch classifier loss: 0.664934; batch adversarial loss: 0.605583\n",
      "epoch 49; iter: 0; batch classifier loss: 0.623552; batch adversarial loss: 0.535947\n",
      "epoch 0; iter: 0; batch classifier loss: 0.971295; batch adversarial loss: 0.664352\n",
      "epoch 1; iter: 0; batch classifier loss: 0.715432; batch adversarial loss: 0.630126\n",
      "epoch 2; iter: 0; batch classifier loss: 0.722445; batch adversarial loss: 0.546805\n",
      "epoch 3; iter: 0; batch classifier loss: 0.676860; batch adversarial loss: 0.596922\n",
      "epoch 4; iter: 0; batch classifier loss: 0.669084; batch adversarial loss: 0.569240\n",
      "epoch 5; iter: 0; batch classifier loss: 0.673749; batch adversarial loss: 0.526459\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572753; batch adversarial loss: 0.566458\n",
      "epoch 7; iter: 0; batch classifier loss: 0.637624; batch adversarial loss: 0.600783\n",
      "epoch 8; iter: 0; batch classifier loss: 0.628581; batch adversarial loss: 0.514930\n",
      "epoch 9; iter: 0; batch classifier loss: 0.635072; batch adversarial loss: 0.570959\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581241; batch adversarial loss: 0.528638\n",
      "epoch 11; iter: 0; batch classifier loss: 0.649907; batch adversarial loss: 0.510107\n",
      "epoch 12; iter: 0; batch classifier loss: 0.632699; batch adversarial loss: 0.598761\n",
      "epoch 13; iter: 0; batch classifier loss: 0.634922; batch adversarial loss: 0.579894\n",
      "epoch 14; iter: 0; batch classifier loss: 0.662393; batch adversarial loss: 0.517282\n",
      "epoch 15; iter: 0; batch classifier loss: 0.603278; batch adversarial loss: 0.547991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.669456; batch adversarial loss: 0.495828\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576386; batch adversarial loss: 0.560624\n",
      "epoch 18; iter: 0; batch classifier loss: 0.627721; batch adversarial loss: 0.413733\n",
      "epoch 19; iter: 0; batch classifier loss: 0.596414; batch adversarial loss: 0.561414\n",
      "epoch 20; iter: 0; batch classifier loss: 0.648523; batch adversarial loss: 0.518314\n",
      "epoch 21; iter: 0; batch classifier loss: 0.638618; batch adversarial loss: 0.642037\n",
      "epoch 22; iter: 0; batch classifier loss: 0.686132; batch adversarial loss: 0.543813\n",
      "epoch 23; iter: 0; batch classifier loss: 0.641589; batch adversarial loss: 0.500811\n",
      "epoch 24; iter: 0; batch classifier loss: 0.668386; batch adversarial loss: 0.492086\n",
      "epoch 25; iter: 0; batch classifier loss: 0.649005; batch adversarial loss: 0.557491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.612036; batch adversarial loss: 0.500680\n",
      "epoch 27; iter: 0; batch classifier loss: 0.658275; batch adversarial loss: 0.478352\n",
      "epoch 28; iter: 0; batch classifier loss: 0.695424; batch adversarial loss: 0.506185\n",
      "epoch 29; iter: 0; batch classifier loss: 0.603879; batch adversarial loss: 0.533755\n",
      "epoch 30; iter: 0; batch classifier loss: 0.601701; batch adversarial loss: 0.507258\n",
      "epoch 31; iter: 0; batch classifier loss: 0.632226; batch adversarial loss: 0.523419\n",
      "epoch 32; iter: 0; batch classifier loss: 0.662546; batch adversarial loss: 0.504682\n",
      "epoch 33; iter: 0; batch classifier loss: 0.665937; batch adversarial loss: 0.511672\n",
      "epoch 34; iter: 0; batch classifier loss: 0.605462; batch adversarial loss: 0.450534\n",
      "epoch 35; iter: 0; batch classifier loss: 0.650900; batch adversarial loss: 0.484767\n",
      "epoch 36; iter: 0; batch classifier loss: 0.612185; batch adversarial loss: 0.622229\n",
      "epoch 37; iter: 0; batch classifier loss: 0.616509; batch adversarial loss: 0.446239\n",
      "epoch 38; iter: 0; batch classifier loss: 0.677001; batch adversarial loss: 0.493068\n",
      "epoch 39; iter: 0; batch classifier loss: 0.634267; batch adversarial loss: 0.446177\n",
      "epoch 40; iter: 0; batch classifier loss: 0.604093; batch adversarial loss: 0.541978\n",
      "epoch 41; iter: 0; batch classifier loss: 0.613506; batch adversarial loss: 0.477273\n",
      "epoch 42; iter: 0; batch classifier loss: 0.623781; batch adversarial loss: 0.493912\n",
      "epoch 43; iter: 0; batch classifier loss: 0.653044; batch adversarial loss: 0.535689\n",
      "epoch 44; iter: 0; batch classifier loss: 0.638053; batch adversarial loss: 0.476391\n",
      "epoch 45; iter: 0; batch classifier loss: 0.647462; batch adversarial loss: 0.528481\n",
      "epoch 46; iter: 0; batch classifier loss: 0.638521; batch adversarial loss: 0.532366\n",
      "epoch 47; iter: 0; batch classifier loss: 0.639488; batch adversarial loss: 0.574176\n",
      "epoch 48; iter: 0; batch classifier loss: 0.616225; batch adversarial loss: 0.447882\n",
      "epoch 49; iter: 0; batch classifier loss: 0.611632; batch adversarial loss: 0.555426\n",
      "epoch 0; iter: 0; batch classifier loss: 1.557349; batch adversarial loss: 0.718528\n",
      "epoch 1; iter: 0; batch classifier loss: 0.939082; batch adversarial loss: 0.683553\n",
      "epoch 2; iter: 0; batch classifier loss: 0.686232; batch adversarial loss: 0.657726\n",
      "epoch 3; iter: 0; batch classifier loss: 0.679434; batch adversarial loss: 0.638144\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630350; batch adversarial loss: 0.611786\n",
      "epoch 5; iter: 0; batch classifier loss: 0.744012; batch adversarial loss: 0.610654\n",
      "epoch 6; iter: 0; batch classifier loss: 0.704804; batch adversarial loss: 0.602188\n",
      "epoch 7; iter: 0; batch classifier loss: 0.693845; batch adversarial loss: 0.571607\n",
      "epoch 8; iter: 0; batch classifier loss: 0.628747; batch adversarial loss: 0.560257\n",
      "epoch 9; iter: 0; batch classifier loss: 0.640115; batch adversarial loss: 0.575415\n",
      "epoch 10; iter: 0; batch classifier loss: 0.631874; batch adversarial loss: 0.575013\n",
      "epoch 11; iter: 0; batch classifier loss: 0.599929; batch adversarial loss: 0.583155\n",
      "epoch 12; iter: 0; batch classifier loss: 0.593899; batch adversarial loss: 0.524228\n",
      "epoch 13; iter: 0; batch classifier loss: 0.577105; batch adversarial loss: 0.535846\n",
      "epoch 14; iter: 0; batch classifier loss: 0.672242; batch adversarial loss: 0.591226\n",
      "epoch 15; iter: 0; batch classifier loss: 0.651850; batch adversarial loss: 0.530271\n",
      "epoch 16; iter: 0; batch classifier loss: 0.623488; batch adversarial loss: 0.519541\n",
      "epoch 17; iter: 0; batch classifier loss: 0.687332; batch adversarial loss: 0.535406\n",
      "epoch 18; iter: 0; batch classifier loss: 0.644956; batch adversarial loss: 0.521738\n",
      "epoch 19; iter: 0; batch classifier loss: 0.715269; batch adversarial loss: 0.552520\n",
      "epoch 20; iter: 0; batch classifier loss: 0.654867; batch adversarial loss: 0.537049\n",
      "epoch 21; iter: 0; batch classifier loss: 0.623182; batch adversarial loss: 0.524604\n",
      "epoch 22; iter: 0; batch classifier loss: 0.653410; batch adversarial loss: 0.438040\n",
      "epoch 23; iter: 0; batch classifier loss: 0.599153; batch adversarial loss: 0.574223\n",
      "epoch 24; iter: 0; batch classifier loss: 0.608037; batch adversarial loss: 0.539553\n",
      "epoch 25; iter: 0; batch classifier loss: 0.649759; batch adversarial loss: 0.445003\n",
      "epoch 26; iter: 0; batch classifier loss: 0.601188; batch adversarial loss: 0.562580\n",
      "epoch 27; iter: 0; batch classifier loss: 0.603086; batch adversarial loss: 0.454804\n",
      "epoch 28; iter: 0; batch classifier loss: 0.584077; batch adversarial loss: 0.542894\n",
      "epoch 29; iter: 0; batch classifier loss: 0.607639; batch adversarial loss: 0.463185\n",
      "epoch 30; iter: 0; batch classifier loss: 0.627812; batch adversarial loss: 0.573889\n",
      "epoch 31; iter: 0; batch classifier loss: 0.612875; batch adversarial loss: 0.528910\n",
      "epoch 32; iter: 0; batch classifier loss: 0.571530; batch adversarial loss: 0.483888\n",
      "epoch 33; iter: 0; batch classifier loss: 0.587809; batch adversarial loss: 0.409971\n",
      "epoch 34; iter: 0; batch classifier loss: 0.594391; batch adversarial loss: 0.473620\n",
      "epoch 35; iter: 0; batch classifier loss: 0.646353; batch adversarial loss: 0.538049\n",
      "epoch 36; iter: 0; batch classifier loss: 0.616688; batch adversarial loss: 0.466655\n",
      "epoch 37; iter: 0; batch classifier loss: 0.672398; batch adversarial loss: 0.482612\n",
      "epoch 38; iter: 0; batch classifier loss: 0.654986; batch adversarial loss: 0.459797\n",
      "epoch 39; iter: 0; batch classifier loss: 0.598571; batch adversarial loss: 0.473674\n",
      "epoch 40; iter: 0; batch classifier loss: 0.604399; batch adversarial loss: 0.479302\n",
      "epoch 41; iter: 0; batch classifier loss: 0.616151; batch adversarial loss: 0.550784\n",
      "epoch 42; iter: 0; batch classifier loss: 0.643593; batch adversarial loss: 0.516186\n",
      "epoch 43; iter: 0; batch classifier loss: 0.623307; batch adversarial loss: 0.526407\n",
      "epoch 44; iter: 0; batch classifier loss: 0.681026; batch adversarial loss: 0.625258\n",
      "epoch 45; iter: 0; batch classifier loss: 0.640383; batch adversarial loss: 0.482112\n",
      "epoch 46; iter: 0; batch classifier loss: 0.625050; batch adversarial loss: 0.606140\n",
      "epoch 47; iter: 0; batch classifier loss: 0.586421; batch adversarial loss: 0.440769\n",
      "epoch 48; iter: 0; batch classifier loss: 0.613692; batch adversarial loss: 0.456059\n",
      "epoch 49; iter: 0; batch classifier loss: 0.658647; batch adversarial loss: 0.486525\n",
      "epoch 0; iter: 0; batch classifier loss: 0.959933; batch adversarial loss: 0.764806\n",
      "epoch 1; iter: 0; batch classifier loss: 0.960414; batch adversarial loss: 0.809636\n",
      "epoch 2; iter: 0; batch classifier loss: 0.859938; batch adversarial loss: 0.775100\n",
      "epoch 3; iter: 0; batch classifier loss: 0.892980; batch adversarial loss: 0.737822\n",
      "epoch 4; iter: 0; batch classifier loss: 0.922451; batch adversarial loss: 0.697173\n",
      "epoch 5; iter: 0; batch classifier loss: 0.691358; batch adversarial loss: 0.652101\n",
      "epoch 6; iter: 0; batch classifier loss: 0.623364; batch adversarial loss: 0.613068\n",
      "epoch 7; iter: 0; batch classifier loss: 0.646207; batch adversarial loss: 0.586413\n",
      "epoch 8; iter: 0; batch classifier loss: 0.654568; batch adversarial loss: 0.608572\n",
      "epoch 9; iter: 0; batch classifier loss: 0.547966; batch adversarial loss: 0.584881\n",
      "epoch 10; iter: 0; batch classifier loss: 0.618652; batch adversarial loss: 0.575888\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563954; batch adversarial loss: 0.608230\n",
      "epoch 12; iter: 0; batch classifier loss: 0.640016; batch adversarial loss: 0.547176\n",
      "epoch 13; iter: 0; batch classifier loss: 0.565647; batch adversarial loss: 0.550637\n",
      "epoch 14; iter: 0; batch classifier loss: 0.697293; batch adversarial loss: 0.565712\n",
      "epoch 15; iter: 0; batch classifier loss: 0.641496; batch adversarial loss: 0.555337\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571947; batch adversarial loss: 0.550174\n",
      "epoch 17; iter: 0; batch classifier loss: 0.647711; batch adversarial loss: 0.527573\n",
      "epoch 18; iter: 0; batch classifier loss: 0.665762; batch adversarial loss: 0.550904\n",
      "epoch 19; iter: 0; batch classifier loss: 0.608963; batch adversarial loss: 0.538891\n",
      "epoch 20; iter: 0; batch classifier loss: 0.582977; batch adversarial loss: 0.517095\n",
      "epoch 21; iter: 0; batch classifier loss: 0.591449; batch adversarial loss: 0.516344\n",
      "epoch 22; iter: 0; batch classifier loss: 0.644722; batch adversarial loss: 0.559267\n",
      "epoch 23; iter: 0; batch classifier loss: 0.568341; batch adversarial loss: 0.504495\n",
      "epoch 24; iter: 0; batch classifier loss: 0.600741; batch adversarial loss: 0.536800\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555675; batch adversarial loss: 0.556403\n",
      "epoch 26; iter: 0; batch classifier loss: 0.585437; batch adversarial loss: 0.518507\n",
      "epoch 27; iter: 0; batch classifier loss: 0.627770; batch adversarial loss: 0.484622\n",
      "epoch 28; iter: 0; batch classifier loss: 0.589254; batch adversarial loss: 0.471678\n",
      "epoch 29; iter: 0; batch classifier loss: 0.609154; batch adversarial loss: 0.473537\n",
      "epoch 30; iter: 0; batch classifier loss: 0.578624; batch adversarial loss: 0.516243\n",
      "epoch 31; iter: 0; batch classifier loss: 0.643039; batch adversarial loss: 0.461926\n",
      "epoch 32; iter: 0; batch classifier loss: 0.569306; batch adversarial loss: 0.438207\n",
      "epoch 33; iter: 0; batch classifier loss: 0.596431; batch adversarial loss: 0.439085\n",
      "epoch 34; iter: 0; batch classifier loss: 0.628605; batch adversarial loss: 0.498316\n",
      "epoch 35; iter: 0; batch classifier loss: 0.552322; batch adversarial loss: 0.509003\n",
      "epoch 36; iter: 0; batch classifier loss: 0.607191; batch adversarial loss: 0.496433\n",
      "epoch 37; iter: 0; batch classifier loss: 0.550154; batch adversarial loss: 0.480334\n",
      "epoch 38; iter: 0; batch classifier loss: 0.626576; batch adversarial loss: 0.530252\n",
      "epoch 39; iter: 0; batch classifier loss: 0.664732; batch adversarial loss: 0.494290\n",
      "epoch 40; iter: 0; batch classifier loss: 0.574274; batch adversarial loss: 0.466839\n",
      "epoch 41; iter: 0; batch classifier loss: 0.678748; batch adversarial loss: 0.567184\n",
      "epoch 42; iter: 0; batch classifier loss: 0.583786; batch adversarial loss: 0.541666\n",
      "epoch 43; iter: 0; batch classifier loss: 0.627914; batch adversarial loss: 0.478042\n",
      "epoch 44; iter: 0; batch classifier loss: 0.642138; batch adversarial loss: 0.437435\n",
      "epoch 45; iter: 0; batch classifier loss: 0.621630; batch adversarial loss: 0.454130\n",
      "epoch 46; iter: 0; batch classifier loss: 0.568161; batch adversarial loss: 0.500471\n",
      "epoch 47; iter: 0; batch classifier loss: 0.608856; batch adversarial loss: 0.499983\n",
      "epoch 48; iter: 0; batch classifier loss: 0.659892; batch adversarial loss: 0.548554\n",
      "epoch 49; iter: 0; batch classifier loss: 0.628024; batch adversarial loss: 0.496166\n",
      "epoch 0; iter: 0; batch classifier loss: 0.850412; batch adversarial loss: 0.703615\n",
      "epoch 1; iter: 0; batch classifier loss: 0.741179; batch adversarial loss: 0.675286\n",
      "epoch 2; iter: 0; batch classifier loss: 0.801174; batch adversarial loss: 0.658691\n",
      "epoch 3; iter: 0; batch classifier loss: 0.745882; batch adversarial loss: 0.633114\n",
      "epoch 4; iter: 0; batch classifier loss: 0.720394; batch adversarial loss: 0.640337\n",
      "epoch 5; iter: 0; batch classifier loss: 0.664525; batch adversarial loss: 0.616625\n",
      "epoch 6; iter: 0; batch classifier loss: 0.743049; batch adversarial loss: 0.611453\n",
      "epoch 7; iter: 0; batch classifier loss: 0.656029; batch adversarial loss: 0.624649\n",
      "epoch 8; iter: 0; batch classifier loss: 0.732169; batch adversarial loss: 0.582476\n",
      "epoch 9; iter: 0; batch classifier loss: 0.624902; batch adversarial loss: 0.599755\n",
      "epoch 10; iter: 0; batch classifier loss: 0.667987; batch adversarial loss: 0.603152\n",
      "epoch 11; iter: 0; batch classifier loss: 0.655302; batch adversarial loss: 0.583984\n",
      "epoch 12; iter: 0; batch classifier loss: 0.625616; batch adversarial loss: 0.574537\n",
      "epoch 13; iter: 0; batch classifier loss: 0.657357; batch adversarial loss: 0.562148\n",
      "epoch 14; iter: 0; batch classifier loss: 0.643606; batch adversarial loss: 0.602913\n",
      "epoch 15; iter: 0; batch classifier loss: 0.677272; batch adversarial loss: 0.579868\n",
      "epoch 16; iter: 0; batch classifier loss: 0.631995; batch adversarial loss: 0.480381\n",
      "epoch 17; iter: 0; batch classifier loss: 0.623325; batch adversarial loss: 0.557956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.594047; batch adversarial loss: 0.490054\n",
      "epoch 19; iter: 0; batch classifier loss: 0.627918; batch adversarial loss: 0.512586\n",
      "epoch 20; iter: 0; batch classifier loss: 0.647703; batch adversarial loss: 0.545254\n",
      "epoch 21; iter: 0; batch classifier loss: 0.651236; batch adversarial loss: 0.506133\n",
      "epoch 22; iter: 0; batch classifier loss: 0.638300; batch adversarial loss: 0.480097\n",
      "epoch 23; iter: 0; batch classifier loss: 0.635345; batch adversarial loss: 0.532947\n",
      "epoch 24; iter: 0; batch classifier loss: 0.610815; batch adversarial loss: 0.544910\n",
      "epoch 25; iter: 0; batch classifier loss: 0.627694; batch adversarial loss: 0.530340\n",
      "epoch 26; iter: 0; batch classifier loss: 0.606339; batch adversarial loss: 0.570005\n",
      "epoch 27; iter: 0; batch classifier loss: 0.578538; batch adversarial loss: 0.520024\n",
      "epoch 28; iter: 0; batch classifier loss: 0.606759; batch adversarial loss: 0.535120\n",
      "epoch 29; iter: 0; batch classifier loss: 0.677148; batch adversarial loss: 0.504104\n",
      "epoch 30; iter: 0; batch classifier loss: 0.570231; batch adversarial loss: 0.585209\n",
      "epoch 31; iter: 0; batch classifier loss: 0.651786; batch adversarial loss: 0.574497\n",
      "epoch 32; iter: 0; batch classifier loss: 0.565605; batch adversarial loss: 0.502840\n",
      "epoch 33; iter: 0; batch classifier loss: 0.642069; batch adversarial loss: 0.477612\n",
      "epoch 34; iter: 0; batch classifier loss: 0.630925; batch adversarial loss: 0.523457\n",
      "epoch 35; iter: 0; batch classifier loss: 0.620745; batch adversarial loss: 0.521263\n",
      "epoch 36; iter: 0; batch classifier loss: 0.588371; batch adversarial loss: 0.533998\n",
      "epoch 37; iter: 0; batch classifier loss: 0.578943; batch adversarial loss: 0.448671\n",
      "epoch 38; iter: 0; batch classifier loss: 0.595459; batch adversarial loss: 0.489248\n",
      "epoch 39; iter: 0; batch classifier loss: 0.652137; batch adversarial loss: 0.560019\n",
      "epoch 40; iter: 0; batch classifier loss: 0.665894; batch adversarial loss: 0.512151\n",
      "epoch 41; iter: 0; batch classifier loss: 0.654914; batch adversarial loss: 0.397011\n",
      "epoch 42; iter: 0; batch classifier loss: 0.647647; batch adversarial loss: 0.491100\n",
      "epoch 43; iter: 0; batch classifier loss: 0.593834; batch adversarial loss: 0.541915\n",
      "epoch 44; iter: 0; batch classifier loss: 0.569328; batch adversarial loss: 0.451522\n",
      "epoch 45; iter: 0; batch classifier loss: 0.656189; batch adversarial loss: 0.468516\n",
      "epoch 46; iter: 0; batch classifier loss: 0.596891; batch adversarial loss: 0.432498\n",
      "epoch 47; iter: 0; batch classifier loss: 0.573642; batch adversarial loss: 0.381033\n",
      "epoch 48; iter: 0; batch classifier loss: 0.619353; batch adversarial loss: 0.472834\n",
      "epoch 49; iter: 0; batch classifier loss: 0.575621; batch adversarial loss: 0.512015\n",
      "epoch 0; iter: 0; batch classifier loss: 3.315424; batch adversarial loss: 0.464469\n",
      "epoch 1; iter: 0; batch classifier loss: 0.997480; batch adversarial loss: 0.559895\n",
      "epoch 2; iter: 0; batch classifier loss: 0.792320; batch adversarial loss: 0.559405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.857112; batch adversarial loss: 0.595528\n",
      "epoch 4; iter: 0; batch classifier loss: 0.730409; batch adversarial loss: 0.591459\n",
      "epoch 5; iter: 0; batch classifier loss: 0.806665; batch adversarial loss: 0.546354\n",
      "epoch 6; iter: 0; batch classifier loss: 0.776445; batch adversarial loss: 0.530492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.702793; batch adversarial loss: 0.522269\n",
      "epoch 8; iter: 0; batch classifier loss: 0.775957; batch adversarial loss: 0.520682\n",
      "epoch 9; iter: 0; batch classifier loss: 0.665370; batch adversarial loss: 0.518631\n",
      "epoch 10; iter: 0; batch classifier loss: 0.612742; batch adversarial loss: 0.508634\n",
      "epoch 11; iter: 0; batch classifier loss: 0.626012; batch adversarial loss: 0.554597\n",
      "epoch 12; iter: 0; batch classifier loss: 0.595284; batch adversarial loss: 0.510169\n",
      "epoch 13; iter: 0; batch classifier loss: 0.661924; batch adversarial loss: 0.516401\n",
      "epoch 14; iter: 0; batch classifier loss: 0.632922; batch adversarial loss: 0.554776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.707710; batch adversarial loss: 0.562775\n",
      "epoch 16; iter: 0; batch classifier loss: 0.622149; batch adversarial loss: 0.514640\n",
      "epoch 17; iter: 0; batch classifier loss: 0.670573; batch adversarial loss: 0.524290\n",
      "epoch 18; iter: 0; batch classifier loss: 0.572315; batch adversarial loss: 0.482609\n",
      "epoch 19; iter: 0; batch classifier loss: 0.614823; batch adversarial loss: 0.588038\n",
      "epoch 20; iter: 0; batch classifier loss: 0.588184; batch adversarial loss: 0.462834\n",
      "epoch 21; iter: 0; batch classifier loss: 0.638900; batch adversarial loss: 0.449508\n",
      "epoch 22; iter: 0; batch classifier loss: 0.625192; batch adversarial loss: 0.515763\n",
      "epoch 23; iter: 0; batch classifier loss: 0.599332; batch adversarial loss: 0.483077\n",
      "epoch 24; iter: 0; batch classifier loss: 0.630773; batch adversarial loss: 0.434832\n",
      "epoch 25; iter: 0; batch classifier loss: 0.645082; batch adversarial loss: 0.517934\n",
      "epoch 26; iter: 0; batch classifier loss: 0.638539; batch adversarial loss: 0.477780\n",
      "epoch 27; iter: 0; batch classifier loss: 0.550977; batch adversarial loss: 0.521896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.638638; batch adversarial loss: 0.606283\n",
      "epoch 29; iter: 0; batch classifier loss: 0.590574; batch adversarial loss: 0.444611\n",
      "epoch 30; iter: 0; batch classifier loss: 0.609844; batch adversarial loss: 0.438014\n",
      "epoch 31; iter: 0; batch classifier loss: 0.612525; batch adversarial loss: 0.498308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.555439; batch adversarial loss: 0.453282\n",
      "epoch 33; iter: 0; batch classifier loss: 0.512193; batch adversarial loss: 0.508475\n",
      "epoch 34; iter: 0; batch classifier loss: 0.655670; batch adversarial loss: 0.460083\n",
      "epoch 35; iter: 0; batch classifier loss: 0.577070; batch adversarial loss: 0.552571\n",
      "epoch 36; iter: 0; batch classifier loss: 0.627989; batch adversarial loss: 0.474950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.616231; batch adversarial loss: 0.568297\n",
      "epoch 38; iter: 0; batch classifier loss: 0.656534; batch adversarial loss: 0.500238\n",
      "epoch 39; iter: 0; batch classifier loss: 0.613080; batch adversarial loss: 0.403519\n",
      "epoch 40; iter: 0; batch classifier loss: 0.595224; batch adversarial loss: 0.586751\n",
      "epoch 41; iter: 0; batch classifier loss: 0.587217; batch adversarial loss: 0.605573\n",
      "epoch 42; iter: 0; batch classifier loss: 0.619535; batch adversarial loss: 0.428281\n",
      "epoch 43; iter: 0; batch classifier loss: 0.607369; batch adversarial loss: 0.484685\n",
      "epoch 44; iter: 0; batch classifier loss: 0.593986; batch adversarial loss: 0.504888\n",
      "epoch 45; iter: 0; batch classifier loss: 0.630409; batch adversarial loss: 0.548594\n",
      "epoch 46; iter: 0; batch classifier loss: 0.578417; batch adversarial loss: 0.587686\n",
      "epoch 47; iter: 0; batch classifier loss: 0.582907; batch adversarial loss: 0.503798\n",
      "epoch 48; iter: 0; batch classifier loss: 0.635565; batch adversarial loss: 0.483963\n",
      "epoch 49; iter: 0; batch classifier loss: 0.642037; batch adversarial loss: 0.497232\n",
      "epoch 0; iter: 0; batch classifier loss: 1.612100; batch adversarial loss: 0.698601\n",
      "epoch 1; iter: 0; batch classifier loss: 0.870071; batch adversarial loss: 0.785960\n",
      "epoch 2; iter: 0; batch classifier loss: 0.811331; batch adversarial loss: 0.822192\n",
      "epoch 3; iter: 0; batch classifier loss: 0.857347; batch adversarial loss: 0.822450\n",
      "epoch 4; iter: 0; batch classifier loss: 0.847369; batch adversarial loss: 0.780925\n",
      "epoch 5; iter: 0; batch classifier loss: 0.817728; batch adversarial loss: 0.724687\n",
      "epoch 6; iter: 0; batch classifier loss: 0.802446; batch adversarial loss: 0.683164\n",
      "epoch 7; iter: 0; batch classifier loss: 0.855700; batch adversarial loss: 0.653691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.687112; batch adversarial loss: 0.611605\n",
      "epoch 9; iter: 0; batch classifier loss: 0.573743; batch adversarial loss: 0.602473\n",
      "epoch 10; iter: 0; batch classifier loss: 0.611814; batch adversarial loss: 0.599917\n",
      "epoch 11; iter: 0; batch classifier loss: 0.647566; batch adversarial loss: 0.589940\n",
      "epoch 12; iter: 0; batch classifier loss: 0.628555; batch adversarial loss: 0.562210\n",
      "epoch 13; iter: 0; batch classifier loss: 0.641135; batch adversarial loss: 0.557396\n",
      "epoch 14; iter: 0; batch classifier loss: 0.626599; batch adversarial loss: 0.547751\n",
      "epoch 15; iter: 0; batch classifier loss: 0.618673; batch adversarial loss: 0.540646\n",
      "epoch 16; iter: 0; batch classifier loss: 0.610338; batch adversarial loss: 0.561651\n",
      "epoch 17; iter: 0; batch classifier loss: 0.600207; batch adversarial loss: 0.494826\n",
      "epoch 18; iter: 0; batch classifier loss: 0.608131; batch adversarial loss: 0.568715\n",
      "epoch 19; iter: 0; batch classifier loss: 0.625894; batch adversarial loss: 0.525212\n",
      "epoch 20; iter: 0; batch classifier loss: 0.599135; batch adversarial loss: 0.505690\n",
      "epoch 21; iter: 0; batch classifier loss: 0.631902; batch adversarial loss: 0.489998\n",
      "epoch 22; iter: 0; batch classifier loss: 0.696612; batch adversarial loss: 0.537978\n",
      "epoch 23; iter: 0; batch classifier loss: 0.588764; batch adversarial loss: 0.570483\n",
      "epoch 24; iter: 0; batch classifier loss: 0.634880; batch adversarial loss: 0.543381\n",
      "epoch 25; iter: 0; batch classifier loss: 0.600316; batch adversarial loss: 0.543833\n",
      "epoch 26; iter: 0; batch classifier loss: 0.659691; batch adversarial loss: 0.539205\n",
      "epoch 27; iter: 0; batch classifier loss: 0.605142; batch adversarial loss: 0.515207\n",
      "epoch 28; iter: 0; batch classifier loss: 0.611331; batch adversarial loss: 0.506812\n",
      "epoch 29; iter: 0; batch classifier loss: 0.655767; batch adversarial loss: 0.540206\n",
      "epoch 30; iter: 0; batch classifier loss: 0.600416; batch adversarial loss: 0.513920\n",
      "epoch 31; iter: 0; batch classifier loss: 0.690822; batch adversarial loss: 0.493721\n",
      "epoch 32; iter: 0; batch classifier loss: 0.617469; batch adversarial loss: 0.480254\n",
      "epoch 33; iter: 0; batch classifier loss: 0.620301; batch adversarial loss: 0.484967\n",
      "epoch 34; iter: 0; batch classifier loss: 0.665690; batch adversarial loss: 0.453910\n",
      "epoch 35; iter: 0; batch classifier loss: 0.668504; batch adversarial loss: 0.470211\n",
      "epoch 36; iter: 0; batch classifier loss: 0.612807; batch adversarial loss: 0.506086\n",
      "epoch 37; iter: 0; batch classifier loss: 0.586985; batch adversarial loss: 0.542573\n",
      "epoch 38; iter: 0; batch classifier loss: 0.575603; batch adversarial loss: 0.465510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.539658; batch adversarial loss: 0.464250\n",
      "epoch 40; iter: 0; batch classifier loss: 0.604551; batch adversarial loss: 0.443264\n",
      "epoch 41; iter: 0; batch classifier loss: 0.624601; batch adversarial loss: 0.549748\n",
      "epoch 42; iter: 0; batch classifier loss: 0.594834; batch adversarial loss: 0.437127\n",
      "epoch 43; iter: 0; batch classifier loss: 0.603762; batch adversarial loss: 0.524516\n",
      "epoch 44; iter: 0; batch classifier loss: 0.535553; batch adversarial loss: 0.493485\n",
      "epoch 45; iter: 0; batch classifier loss: 0.545379; batch adversarial loss: 0.499001\n",
      "epoch 46; iter: 0; batch classifier loss: 0.633285; batch adversarial loss: 0.538977\n",
      "epoch 47; iter: 0; batch classifier loss: 0.614857; batch adversarial loss: 0.485660\n",
      "epoch 48; iter: 0; batch classifier loss: 0.548866; batch adversarial loss: 0.552641\n",
      "epoch 49; iter: 0; batch classifier loss: 0.569791; batch adversarial loss: 0.519884\n",
      "epoch 0; iter: 0; batch classifier loss: 1.936114; batch adversarial loss: 1.071019\n",
      "epoch 1; iter: 0; batch classifier loss: 1.242840; batch adversarial loss: 1.057719\n",
      "epoch 2; iter: 0; batch classifier loss: 0.892800; batch adversarial loss: 0.963229\n",
      "epoch 3; iter: 0; batch classifier loss: 1.083137; batch adversarial loss: 0.977064\n",
      "epoch 4; iter: 0; batch classifier loss: 1.025473; batch adversarial loss: 0.914807\n",
      "epoch 5; iter: 0; batch classifier loss: 1.049592; batch adversarial loss: 0.878906\n",
      "epoch 6; iter: 0; batch classifier loss: 1.109204; batch adversarial loss: 0.839943\n",
      "epoch 7; iter: 0; batch classifier loss: 0.880728; batch adversarial loss: 0.772076\n",
      "epoch 8; iter: 0; batch classifier loss: 1.028267; batch adversarial loss: 0.745952\n",
      "epoch 9; iter: 0; batch classifier loss: 0.898824; batch adversarial loss: 0.712070\n",
      "epoch 10; iter: 0; batch classifier loss: 0.844355; batch adversarial loss: 0.653662\n",
      "epoch 11; iter: 0; batch classifier loss: 0.735231; batch adversarial loss: 0.616182\n",
      "epoch 12; iter: 0; batch classifier loss: 0.668120; batch adversarial loss: 0.583057\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593732; batch adversarial loss: 0.576227\n",
      "epoch 14; iter: 0; batch classifier loss: 0.611668; batch adversarial loss: 0.588120\n",
      "epoch 15; iter: 0; batch classifier loss: 0.643857; batch adversarial loss: 0.562329\n",
      "epoch 16; iter: 0; batch classifier loss: 0.645538; batch adversarial loss: 0.601881\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533982; batch adversarial loss: 0.546481\n",
      "epoch 18; iter: 0; batch classifier loss: 0.638653; batch adversarial loss: 0.543155\n",
      "epoch 19; iter: 0; batch classifier loss: 0.648552; batch adversarial loss: 0.519546\n",
      "epoch 20; iter: 0; batch classifier loss: 0.599466; batch adversarial loss: 0.569076\n",
      "epoch 21; iter: 0; batch classifier loss: 0.571276; batch adversarial loss: 0.513850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.547461; batch adversarial loss: 0.540481\n",
      "epoch 23; iter: 0; batch classifier loss: 0.603591; batch adversarial loss: 0.525893\n",
      "epoch 24; iter: 0; batch classifier loss: 0.559358; batch adversarial loss: 0.489056\n",
      "epoch 25; iter: 0; batch classifier loss: 0.657210; batch adversarial loss: 0.502036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.560574; batch adversarial loss: 0.551385\n",
      "epoch 27; iter: 0; batch classifier loss: 0.605443; batch adversarial loss: 0.542785\n",
      "epoch 28; iter: 0; batch classifier loss: 0.645575; batch adversarial loss: 0.474535\n",
      "epoch 29; iter: 0; batch classifier loss: 0.662456; batch adversarial loss: 0.499600\n",
      "epoch 30; iter: 0; batch classifier loss: 0.584515; batch adversarial loss: 0.470513\n",
      "epoch 31; iter: 0; batch classifier loss: 0.624109; batch adversarial loss: 0.441305\n",
      "epoch 32; iter: 0; batch classifier loss: 0.562426; batch adversarial loss: 0.525070\n",
      "epoch 33; iter: 0; batch classifier loss: 0.620791; batch adversarial loss: 0.564132\n",
      "epoch 34; iter: 0; batch classifier loss: 0.634468; batch adversarial loss: 0.474881\n",
      "epoch 35; iter: 0; batch classifier loss: 0.575222; batch adversarial loss: 0.520577\n",
      "epoch 36; iter: 0; batch classifier loss: 0.577767; batch adversarial loss: 0.495982\n",
      "epoch 37; iter: 0; batch classifier loss: 0.617854; batch adversarial loss: 0.554384\n",
      "epoch 38; iter: 0; batch classifier loss: 0.646594; batch adversarial loss: 0.390006\n",
      "epoch 39; iter: 0; batch classifier loss: 0.623333; batch adversarial loss: 0.458334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.555988; batch adversarial loss: 0.499003\n",
      "epoch 41; iter: 0; batch classifier loss: 0.594620; batch adversarial loss: 0.452479\n",
      "epoch 42; iter: 0; batch classifier loss: 0.633859; batch adversarial loss: 0.574017\n",
      "epoch 43; iter: 0; batch classifier loss: 0.581118; batch adversarial loss: 0.415697\n",
      "epoch 44; iter: 0; batch classifier loss: 0.644479; batch adversarial loss: 0.635934\n",
      "epoch 45; iter: 0; batch classifier loss: 0.560485; batch adversarial loss: 0.508066\n",
      "epoch 46; iter: 0; batch classifier loss: 0.625500; batch adversarial loss: 0.490540\n",
      "epoch 47; iter: 0; batch classifier loss: 0.607339; batch adversarial loss: 0.430681\n",
      "epoch 48; iter: 0; batch classifier loss: 0.606774; batch adversarial loss: 0.520397\n",
      "epoch 49; iter: 0; batch classifier loss: 0.551320; batch adversarial loss: 0.465676\n",
      "epoch 0; iter: 0; batch classifier loss: 1.083329; batch adversarial loss: 0.840345\n",
      "epoch 1; iter: 0; batch classifier loss: 0.829334; batch adversarial loss: 0.803324\n",
      "epoch 2; iter: 0; batch classifier loss: 0.849509; batch adversarial loss: 0.776881\n",
      "epoch 3; iter: 0; batch classifier loss: 0.835331; batch adversarial loss: 0.746919\n",
      "epoch 4; iter: 0; batch classifier loss: 0.828783; batch adversarial loss: 0.706236\n",
      "epoch 5; iter: 0; batch classifier loss: 0.713602; batch adversarial loss: 0.660960\n",
      "epoch 6; iter: 0; batch classifier loss: 0.824375; batch adversarial loss: 0.636925\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624046; batch adversarial loss: 0.604670\n",
      "epoch 8; iter: 0; batch classifier loss: 0.664850; batch adversarial loss: 0.596071\n",
      "epoch 9; iter: 0; batch classifier loss: 0.630605; batch adversarial loss: 0.597330\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634963; batch adversarial loss: 0.567010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.675257; batch adversarial loss: 0.567662\n",
      "epoch 12; iter: 0; batch classifier loss: 0.643158; batch adversarial loss: 0.565548\n",
      "epoch 13; iter: 0; batch classifier loss: 0.640201; batch adversarial loss: 0.546276\n",
      "epoch 14; iter: 0; batch classifier loss: 0.626812; batch adversarial loss: 0.553985\n",
      "epoch 15; iter: 0; batch classifier loss: 0.615057; batch adversarial loss: 0.528268\n",
      "epoch 16; iter: 0; batch classifier loss: 0.646392; batch adversarial loss: 0.544536\n",
      "epoch 17; iter: 0; batch classifier loss: 0.602661; batch adversarial loss: 0.561928\n",
      "epoch 18; iter: 0; batch classifier loss: 0.645832; batch adversarial loss: 0.554473\n",
      "epoch 19; iter: 0; batch classifier loss: 0.630211; batch adversarial loss: 0.562185\n",
      "epoch 20; iter: 0; batch classifier loss: 0.596992; batch adversarial loss: 0.539869\n",
      "epoch 21; iter: 0; batch classifier loss: 0.643585; batch adversarial loss: 0.559413\n",
      "epoch 22; iter: 0; batch classifier loss: 0.671536; batch adversarial loss: 0.525619\n",
      "epoch 23; iter: 0; batch classifier loss: 0.707837; batch adversarial loss: 0.484367\n",
      "epoch 24; iter: 0; batch classifier loss: 0.621532; batch adversarial loss: 0.501241\n",
      "epoch 25; iter: 0; batch classifier loss: 0.645971; batch adversarial loss: 0.488232\n",
      "epoch 26; iter: 0; batch classifier loss: 0.611187; batch adversarial loss: 0.562244\n",
      "epoch 27; iter: 0; batch classifier loss: 0.615525; batch adversarial loss: 0.531648\n",
      "epoch 28; iter: 0; batch classifier loss: 0.691469; batch adversarial loss: 0.529565\n",
      "epoch 29; iter: 0; batch classifier loss: 0.674891; batch adversarial loss: 0.464952\n",
      "epoch 30; iter: 0; batch classifier loss: 0.635933; batch adversarial loss: 0.483256\n",
      "epoch 31; iter: 0; batch classifier loss: 0.650004; batch adversarial loss: 0.446419\n",
      "epoch 32; iter: 0; batch classifier loss: 0.714070; batch adversarial loss: 0.513762\n",
      "epoch 33; iter: 0; batch classifier loss: 0.597286; batch adversarial loss: 0.486126\n",
      "epoch 34; iter: 0; batch classifier loss: 0.632292; batch adversarial loss: 0.556621\n",
      "epoch 35; iter: 0; batch classifier loss: 0.609214; batch adversarial loss: 0.525284\n",
      "epoch 36; iter: 0; batch classifier loss: 0.644777; batch adversarial loss: 0.523086\n",
      "epoch 37; iter: 0; batch classifier loss: 0.609325; batch adversarial loss: 0.478813\n",
      "epoch 38; iter: 0; batch classifier loss: 0.587991; batch adversarial loss: 0.472319\n",
      "epoch 39; iter: 0; batch classifier loss: 0.580027; batch adversarial loss: 0.573450\n",
      "epoch 40; iter: 0; batch classifier loss: 0.622466; batch adversarial loss: 0.433863\n",
      "epoch 41; iter: 0; batch classifier loss: 0.624702; batch adversarial loss: 0.578145\n",
      "epoch 42; iter: 0; batch classifier loss: 0.588816; batch adversarial loss: 0.602385\n",
      "epoch 43; iter: 0; batch classifier loss: 0.654088; batch adversarial loss: 0.513123\n",
      "epoch 44; iter: 0; batch classifier loss: 0.622633; batch adversarial loss: 0.477941\n",
      "epoch 45; iter: 0; batch classifier loss: 0.626891; batch adversarial loss: 0.551890\n",
      "epoch 46; iter: 0; batch classifier loss: 0.676238; batch adversarial loss: 0.504292\n",
      "epoch 47; iter: 0; batch classifier loss: 0.586976; batch adversarial loss: 0.467915\n",
      "epoch 48; iter: 0; batch classifier loss: 0.585282; batch adversarial loss: 0.466286\n",
      "epoch 49; iter: 0; batch classifier loss: 0.630000; batch adversarial loss: 0.449365\n",
      "epoch 0; iter: 0; batch classifier loss: 1.523329; batch adversarial loss: 0.695269\n",
      "epoch 1; iter: 0; batch classifier loss: 0.778442; batch adversarial loss: 0.685915\n",
      "epoch 2; iter: 0; batch classifier loss: 0.700857; batch adversarial loss: 0.635644\n",
      "epoch 3; iter: 0; batch classifier loss: 0.708508; batch adversarial loss: 0.656800\n",
      "epoch 4; iter: 0; batch classifier loss: 0.746357; batch adversarial loss: 0.604826\n",
      "epoch 5; iter: 0; batch classifier loss: 0.690085; batch adversarial loss: 0.598981\n",
      "epoch 6; iter: 0; batch classifier loss: 0.656160; batch adversarial loss: 0.588246\n",
      "epoch 7; iter: 0; batch classifier loss: 0.645252; batch adversarial loss: 0.591864\n",
      "epoch 8; iter: 0; batch classifier loss: 0.623455; batch adversarial loss: 0.581739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.636008; batch adversarial loss: 0.587701\n",
      "epoch 10; iter: 0; batch classifier loss: 0.644818; batch adversarial loss: 0.554710\n",
      "epoch 11; iter: 0; batch classifier loss: 0.656116; batch adversarial loss: 0.541381\n",
      "epoch 12; iter: 0; batch classifier loss: 0.668112; batch adversarial loss: 0.516497\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600769; batch adversarial loss: 0.492975\n",
      "epoch 14; iter: 0; batch classifier loss: 0.608712; batch adversarial loss: 0.526226\n",
      "epoch 15; iter: 0; batch classifier loss: 0.620410; batch adversarial loss: 0.528677\n",
      "epoch 16; iter: 0; batch classifier loss: 0.641760; batch adversarial loss: 0.565488\n",
      "epoch 17; iter: 0; batch classifier loss: 0.684392; batch adversarial loss: 0.524444\n",
      "epoch 18; iter: 0; batch classifier loss: 0.592716; batch adversarial loss: 0.537912\n",
      "epoch 19; iter: 0; batch classifier loss: 0.603384; batch adversarial loss: 0.532149\n",
      "epoch 20; iter: 0; batch classifier loss: 0.511065; batch adversarial loss: 0.561966\n",
      "epoch 21; iter: 0; batch classifier loss: 0.598270; batch adversarial loss: 0.537126\n",
      "epoch 22; iter: 0; batch classifier loss: 0.670634; batch adversarial loss: 0.515557\n",
      "epoch 23; iter: 0; batch classifier loss: 0.663864; batch adversarial loss: 0.581649\n",
      "epoch 24; iter: 0; batch classifier loss: 0.620442; batch adversarial loss: 0.517284\n",
      "epoch 25; iter: 0; batch classifier loss: 0.615712; batch adversarial loss: 0.520098\n",
      "epoch 26; iter: 0; batch classifier loss: 0.666704; batch adversarial loss: 0.530738\n",
      "epoch 27; iter: 0; batch classifier loss: 0.566917; batch adversarial loss: 0.480253\n",
      "epoch 28; iter: 0; batch classifier loss: 0.624113; batch adversarial loss: 0.538520\n",
      "epoch 29; iter: 0; batch classifier loss: 0.692027; batch adversarial loss: 0.536846\n",
      "epoch 30; iter: 0; batch classifier loss: 0.689331; batch adversarial loss: 0.442570\n",
      "epoch 31; iter: 0; batch classifier loss: 0.633059; batch adversarial loss: 0.582851\n",
      "epoch 32; iter: 0; batch classifier loss: 0.666860; batch adversarial loss: 0.477766\n",
      "epoch 33; iter: 0; batch classifier loss: 0.693205; batch adversarial loss: 0.523642\n",
      "epoch 34; iter: 0; batch classifier loss: 0.667350; batch adversarial loss: 0.493776\n",
      "epoch 35; iter: 0; batch classifier loss: 0.662117; batch adversarial loss: 0.564496\n",
      "epoch 36; iter: 0; batch classifier loss: 0.655504; batch adversarial loss: 0.570234\n",
      "epoch 37; iter: 0; batch classifier loss: 0.641185; batch adversarial loss: 0.494037\n",
      "epoch 38; iter: 0; batch classifier loss: 0.622670; batch adversarial loss: 0.537648\n",
      "epoch 39; iter: 0; batch classifier loss: 0.609054; batch adversarial loss: 0.543784\n",
      "epoch 40; iter: 0; batch classifier loss: 0.646069; batch adversarial loss: 0.519217\n",
      "epoch 41; iter: 0; batch classifier loss: 0.611851; batch adversarial loss: 0.520316\n",
      "epoch 42; iter: 0; batch classifier loss: 0.592777; batch adversarial loss: 0.430616\n",
      "epoch 43; iter: 0; batch classifier loss: 0.681925; batch adversarial loss: 0.519625\n",
      "epoch 44; iter: 0; batch classifier loss: 0.623392; batch adversarial loss: 0.517112\n",
      "epoch 45; iter: 0; batch classifier loss: 0.640679; batch adversarial loss: 0.448680\n",
      "epoch 46; iter: 0; batch classifier loss: 0.574958; batch adversarial loss: 0.426323\n",
      "epoch 47; iter: 0; batch classifier loss: 0.663487; batch adversarial loss: 0.486206\n",
      "epoch 48; iter: 0; batch classifier loss: 0.571762; batch adversarial loss: 0.532440\n",
      "epoch 49; iter: 0; batch classifier loss: 0.613128; batch adversarial loss: 0.480705\n",
      "epoch 0; iter: 0; batch classifier loss: 2.084234; batch adversarial loss: 0.587053\n",
      "epoch 1; iter: 0; batch classifier loss: 0.717411; batch adversarial loss: 0.625303\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652144; batch adversarial loss: 0.606984\n",
      "epoch 3; iter: 0; batch classifier loss: 0.763441; batch adversarial loss: 0.621626\n",
      "epoch 4; iter: 0; batch classifier loss: 0.866983; batch adversarial loss: 0.612125\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616370; batch adversarial loss: 0.598674\n",
      "epoch 6; iter: 0; batch classifier loss: 0.651004; batch adversarial loss: 0.588835\n",
      "epoch 7; iter: 0; batch classifier loss: 0.759035; batch adversarial loss: 0.629187\n",
      "epoch 8; iter: 0; batch classifier loss: 0.601648; batch adversarial loss: 0.538725\n",
      "epoch 9; iter: 0; batch classifier loss: 0.637856; batch adversarial loss: 0.590735\n",
      "epoch 10; iter: 0; batch classifier loss: 0.648539; batch adversarial loss: 0.557914\n",
      "epoch 11; iter: 0; batch classifier loss: 0.637027; batch adversarial loss: 0.556014\n",
      "epoch 12; iter: 0; batch classifier loss: 0.619126; batch adversarial loss: 0.498697\n",
      "epoch 13; iter: 0; batch classifier loss: 0.649823; batch adversarial loss: 0.541385\n",
      "epoch 14; iter: 0; batch classifier loss: 0.650177; batch adversarial loss: 0.570211\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576528; batch adversarial loss: 0.550850\n",
      "epoch 16; iter: 0; batch classifier loss: 0.647070; batch adversarial loss: 0.573473\n",
      "epoch 17; iter: 0; batch classifier loss: 0.568190; batch adversarial loss: 0.532669\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557060; batch adversarial loss: 0.528324\n",
      "epoch 19; iter: 0; batch classifier loss: 0.592203; batch adversarial loss: 0.525453\n",
      "epoch 20; iter: 0; batch classifier loss: 0.631346; batch adversarial loss: 0.476542\n",
      "epoch 21; iter: 0; batch classifier loss: 0.614989; batch adversarial loss: 0.506433\n",
      "epoch 22; iter: 0; batch classifier loss: 0.609783; batch adversarial loss: 0.505713\n",
      "epoch 23; iter: 0; batch classifier loss: 0.619925; batch adversarial loss: 0.469909\n",
      "epoch 24; iter: 0; batch classifier loss: 0.575914; batch adversarial loss: 0.553456\n",
      "epoch 25; iter: 0; batch classifier loss: 0.631712; batch adversarial loss: 0.533891\n",
      "epoch 26; iter: 0; batch classifier loss: 0.625777; batch adversarial loss: 0.496909\n",
      "epoch 27; iter: 0; batch classifier loss: 0.584133; batch adversarial loss: 0.520501\n",
      "epoch 28; iter: 0; batch classifier loss: 0.670776; batch adversarial loss: 0.550296\n",
      "epoch 29; iter: 0; batch classifier loss: 0.660755; batch adversarial loss: 0.507954\n",
      "epoch 30; iter: 0; batch classifier loss: 0.634007; batch adversarial loss: 0.563787\n",
      "epoch 31; iter: 0; batch classifier loss: 0.617008; batch adversarial loss: 0.582886\n",
      "epoch 32; iter: 0; batch classifier loss: 0.615997; batch adversarial loss: 0.577777\n",
      "epoch 33; iter: 0; batch classifier loss: 0.566305; batch adversarial loss: 0.606262\n",
      "epoch 34; iter: 0; batch classifier loss: 0.628481; batch adversarial loss: 0.455656\n",
      "epoch 35; iter: 0; batch classifier loss: 0.654761; batch adversarial loss: 0.426910\n",
      "epoch 36; iter: 0; batch classifier loss: 0.617107; batch adversarial loss: 0.512411\n",
      "epoch 37; iter: 0; batch classifier loss: 0.654014; batch adversarial loss: 0.533620\n",
      "epoch 38; iter: 0; batch classifier loss: 0.610658; batch adversarial loss: 0.486483\n",
      "epoch 39; iter: 0; batch classifier loss: 0.613872; batch adversarial loss: 0.455086\n",
      "epoch 40; iter: 0; batch classifier loss: 0.568873; batch adversarial loss: 0.413368\n",
      "epoch 41; iter: 0; batch classifier loss: 0.596188; batch adversarial loss: 0.436645\n",
      "epoch 42; iter: 0; batch classifier loss: 0.595753; batch adversarial loss: 0.488012\n",
      "epoch 43; iter: 0; batch classifier loss: 0.585554; batch adversarial loss: 0.512414\n",
      "epoch 44; iter: 0; batch classifier loss: 0.575538; batch adversarial loss: 0.417097\n",
      "epoch 45; iter: 0; batch classifier loss: 0.570292; batch adversarial loss: 0.570595\n",
      "epoch 46; iter: 0; batch classifier loss: 0.558181; batch adversarial loss: 0.473539\n",
      "epoch 47; iter: 0; batch classifier loss: 0.606159; batch adversarial loss: 0.514612\n",
      "epoch 48; iter: 0; batch classifier loss: 0.594330; batch adversarial loss: 0.570679\n",
      "epoch 49; iter: 0; batch classifier loss: 0.599956; batch adversarial loss: 0.509325\n",
      "epoch 0; iter: 0; batch classifier loss: 1.061612; batch adversarial loss: 0.661911\n",
      "epoch 1; iter: 0; batch classifier loss: 0.790365; batch adversarial loss: 0.638475\n",
      "epoch 2; iter: 0; batch classifier loss: 0.755661; batch adversarial loss: 0.635927\n",
      "epoch 3; iter: 0; batch classifier loss: 0.783972; batch adversarial loss: 0.640451\n",
      "epoch 4; iter: 0; batch classifier loss: 0.667717; batch adversarial loss: 0.633366\n",
      "epoch 5; iter: 0; batch classifier loss: 0.683587; batch adversarial loss: 0.597924\n",
      "epoch 6; iter: 0; batch classifier loss: 0.647344; batch adversarial loss: 0.636631\n",
      "epoch 7; iter: 0; batch classifier loss: 0.752498; batch adversarial loss: 0.605119\n",
      "epoch 8; iter: 0; batch classifier loss: 0.638729; batch adversarial loss: 0.619939\n",
      "epoch 9; iter: 0; batch classifier loss: 0.608092; batch adversarial loss: 0.579455\n",
      "epoch 10; iter: 0; batch classifier loss: 0.694957; batch adversarial loss: 0.567723\n",
      "epoch 11; iter: 0; batch classifier loss: 0.687183; batch adversarial loss: 0.595358\n",
      "epoch 12; iter: 0; batch classifier loss: 0.693788; batch adversarial loss: 0.549648\n",
      "epoch 13; iter: 0; batch classifier loss: 0.653396; batch adversarial loss: 0.547777\n",
      "epoch 14; iter: 0; batch classifier loss: 0.623047; batch adversarial loss: 0.576932\n",
      "epoch 15; iter: 0; batch classifier loss: 0.651600; batch adversarial loss: 0.568460\n",
      "epoch 16; iter: 0; batch classifier loss: 0.717973; batch adversarial loss: 0.520035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.662100; batch adversarial loss: 0.557406\n",
      "epoch 18; iter: 0; batch classifier loss: 0.683348; batch adversarial loss: 0.480028\n",
      "epoch 19; iter: 0; batch classifier loss: 0.632233; batch adversarial loss: 0.516137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.652794; batch adversarial loss: 0.540737\n",
      "epoch 21; iter: 0; batch classifier loss: 0.609186; batch adversarial loss: 0.511446\n",
      "epoch 22; iter: 0; batch classifier loss: 0.669179; batch adversarial loss: 0.559783\n",
      "epoch 23; iter: 0; batch classifier loss: 0.592209; batch adversarial loss: 0.511370\n",
      "epoch 24; iter: 0; batch classifier loss: 0.676791; batch adversarial loss: 0.463380\n",
      "epoch 25; iter: 0; batch classifier loss: 0.645133; batch adversarial loss: 0.455260\n",
      "epoch 26; iter: 0; batch classifier loss: 0.628658; batch adversarial loss: 0.534592\n",
      "epoch 27; iter: 0; batch classifier loss: 0.602745; batch adversarial loss: 0.464883\n",
      "epoch 28; iter: 0; batch classifier loss: 0.580910; batch adversarial loss: 0.522890\n",
      "epoch 29; iter: 0; batch classifier loss: 0.602475; batch adversarial loss: 0.491316\n",
      "epoch 30; iter: 0; batch classifier loss: 0.594360; batch adversarial loss: 0.478531\n",
      "epoch 31; iter: 0; batch classifier loss: 0.645618; batch adversarial loss: 0.430770\n",
      "epoch 32; iter: 0; batch classifier loss: 0.593394; batch adversarial loss: 0.443957\n",
      "epoch 33; iter: 0; batch classifier loss: 0.673079; batch adversarial loss: 0.513728\n",
      "epoch 34; iter: 0; batch classifier loss: 0.669630; batch adversarial loss: 0.455269\n",
      "epoch 35; iter: 0; batch classifier loss: 0.587971; batch adversarial loss: 0.454169\n",
      "epoch 36; iter: 0; batch classifier loss: 0.651440; batch adversarial loss: 0.395060\n",
      "epoch 37; iter: 0; batch classifier loss: 0.596319; batch adversarial loss: 0.470758\n",
      "epoch 38; iter: 0; batch classifier loss: 0.556553; batch adversarial loss: 0.521849\n",
      "epoch 39; iter: 0; batch classifier loss: 0.632409; batch adversarial loss: 0.479980\n",
      "epoch 40; iter: 0; batch classifier loss: 0.612580; batch adversarial loss: 0.455061\n",
      "epoch 41; iter: 0; batch classifier loss: 0.616660; batch adversarial loss: 0.492660\n",
      "epoch 42; iter: 0; batch classifier loss: 0.631847; batch adversarial loss: 0.543923\n",
      "epoch 43; iter: 0; batch classifier loss: 0.561626; batch adversarial loss: 0.506065\n",
      "epoch 44; iter: 0; batch classifier loss: 0.584966; batch adversarial loss: 0.514444\n",
      "epoch 45; iter: 0; batch classifier loss: 0.604732; batch adversarial loss: 0.508052\n",
      "epoch 46; iter: 0; batch classifier loss: 0.597520; batch adversarial loss: 0.414967\n",
      "epoch 47; iter: 0; batch classifier loss: 0.605147; batch adversarial loss: 0.543361\n",
      "epoch 48; iter: 0; batch classifier loss: 0.589891; batch adversarial loss: 0.430789\n",
      "epoch 49; iter: 0; batch classifier loss: 0.543775; batch adversarial loss: 0.473282\n",
      "epoch 0; iter: 0; batch classifier loss: 1.776906; batch adversarial loss: 0.719599\n",
      "epoch 1; iter: 0; batch classifier loss: 0.915550; batch adversarial loss: 0.699248\n",
      "epoch 2; iter: 0; batch classifier loss: 0.866189; batch adversarial loss: 0.661078\n",
      "epoch 3; iter: 0; batch classifier loss: 0.676729; batch adversarial loss: 0.615050\n",
      "epoch 4; iter: 0; batch classifier loss: 0.834347; batch adversarial loss: 0.618438\n",
      "epoch 5; iter: 0; batch classifier loss: 0.668432; batch adversarial loss: 0.630367\n",
      "epoch 6; iter: 0; batch classifier loss: 0.736384; batch adversarial loss: 0.607104\n",
      "epoch 7; iter: 0; batch classifier loss: 0.667207; batch adversarial loss: 0.582797\n",
      "epoch 8; iter: 0; batch classifier loss: 0.675893; batch adversarial loss: 0.533251\n",
      "epoch 9; iter: 0; batch classifier loss: 0.718910; batch adversarial loss: 0.545238\n",
      "epoch 10; iter: 0; batch classifier loss: 0.654859; batch adversarial loss: 0.539637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.614635; batch adversarial loss: 0.552355\n",
      "epoch 12; iter: 0; batch classifier loss: 0.647771; batch adversarial loss: 0.476423\n",
      "epoch 13; iter: 0; batch classifier loss: 0.632789; batch adversarial loss: 0.498480\n",
      "epoch 14; iter: 0; batch classifier loss: 0.606380; batch adversarial loss: 0.600927\n",
      "epoch 15; iter: 0; batch classifier loss: 0.574456; batch adversarial loss: 0.487027\n",
      "epoch 16; iter: 0; batch classifier loss: 0.623216; batch adversarial loss: 0.509805\n",
      "epoch 17; iter: 0; batch classifier loss: 0.655096; batch adversarial loss: 0.552244\n",
      "epoch 18; iter: 0; batch classifier loss: 0.545615; batch adversarial loss: 0.513446\n",
      "epoch 19; iter: 0; batch classifier loss: 0.580532; batch adversarial loss: 0.527193\n",
      "epoch 20; iter: 0; batch classifier loss: 0.571724; batch adversarial loss: 0.520727\n",
      "epoch 21; iter: 0; batch classifier loss: 0.562560; batch adversarial loss: 0.435649\n",
      "epoch 22; iter: 0; batch classifier loss: 0.616436; batch adversarial loss: 0.502202\n",
      "epoch 23; iter: 0; batch classifier loss: 0.620876; batch adversarial loss: 0.584361\n",
      "epoch 24; iter: 0; batch classifier loss: 0.599265; batch adversarial loss: 0.465775\n",
      "epoch 25; iter: 0; batch classifier loss: 0.592280; batch adversarial loss: 0.625312\n",
      "epoch 26; iter: 0; batch classifier loss: 0.603522; batch adversarial loss: 0.495093\n",
      "epoch 27; iter: 0; batch classifier loss: 0.676531; batch adversarial loss: 0.487120\n",
      "epoch 28; iter: 0; batch classifier loss: 0.626263; batch adversarial loss: 0.543048\n",
      "epoch 29; iter: 0; batch classifier loss: 0.598259; batch adversarial loss: 0.488430\n",
      "epoch 30; iter: 0; batch classifier loss: 0.581249; batch adversarial loss: 0.465383\n",
      "epoch 31; iter: 0; batch classifier loss: 0.612613; batch adversarial loss: 0.560077\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568800; batch adversarial loss: 0.482168\n",
      "epoch 33; iter: 0; batch classifier loss: 0.611134; batch adversarial loss: 0.379393\n",
      "epoch 34; iter: 0; batch classifier loss: 0.549284; batch adversarial loss: 0.488689\n",
      "epoch 35; iter: 0; batch classifier loss: 0.610878; batch adversarial loss: 0.380029\n",
      "epoch 36; iter: 0; batch classifier loss: 0.587236; batch adversarial loss: 0.472630\n",
      "epoch 37; iter: 0; batch classifier loss: 0.612349; batch adversarial loss: 0.502423\n",
      "epoch 38; iter: 0; batch classifier loss: 0.640094; batch adversarial loss: 0.434890\n",
      "epoch 39; iter: 0; batch classifier loss: 0.582604; batch adversarial loss: 0.547566\n",
      "epoch 40; iter: 0; batch classifier loss: 0.575290; batch adversarial loss: 0.491627\n",
      "epoch 41; iter: 0; batch classifier loss: 0.600249; batch adversarial loss: 0.550106\n",
      "epoch 42; iter: 0; batch classifier loss: 0.596693; batch adversarial loss: 0.415742\n",
      "epoch 43; iter: 0; batch classifier loss: 0.639838; batch adversarial loss: 0.460956\n",
      "epoch 44; iter: 0; batch classifier loss: 0.587319; batch adversarial loss: 0.577937\n",
      "epoch 45; iter: 0; batch classifier loss: 0.560147; batch adversarial loss: 0.557876\n",
      "epoch 46; iter: 0; batch classifier loss: 0.601840; batch adversarial loss: 0.553652\n",
      "epoch 47; iter: 0; batch classifier loss: 0.592599; batch adversarial loss: 0.492219\n",
      "epoch 48; iter: 0; batch classifier loss: 0.606365; batch adversarial loss: 0.502957\n",
      "epoch 49; iter: 0; batch classifier loss: 0.580700; batch adversarial loss: 0.515108\n",
      "epoch 0; iter: 0; batch classifier loss: 1.344223; batch adversarial loss: 0.706488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.905373; batch adversarial loss: 0.663742\n",
      "epoch 2; iter: 0; batch classifier loss: 0.812564; batch adversarial loss: 0.630701\n",
      "epoch 3; iter: 0; batch classifier loss: 0.708164; batch adversarial loss: 0.628509\n",
      "epoch 4; iter: 0; batch classifier loss: 0.691451; batch adversarial loss: 0.610062\n",
      "epoch 5; iter: 0; batch classifier loss: 0.811513; batch adversarial loss: 0.618639\n",
      "epoch 6; iter: 0; batch classifier loss: 0.681034; batch adversarial loss: 0.593920\n",
      "epoch 7; iter: 0; batch classifier loss: 0.645042; batch adversarial loss: 0.584477\n",
      "epoch 8; iter: 0; batch classifier loss: 0.699348; batch adversarial loss: 0.598258\n",
      "epoch 9; iter: 0; batch classifier loss: 0.644420; batch adversarial loss: 0.589908\n",
      "epoch 10; iter: 0; batch classifier loss: 0.732388; batch adversarial loss: 0.543678\n",
      "epoch 11; iter: 0; batch classifier loss: 0.710420; batch adversarial loss: 0.557102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.679117; batch adversarial loss: 0.492119\n",
      "epoch 13; iter: 0; batch classifier loss: 0.668715; batch adversarial loss: 0.526081\n",
      "epoch 14; iter: 0; batch classifier loss: 0.655189; batch adversarial loss: 0.503364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.614564; batch adversarial loss: 0.592944\n",
      "epoch 16; iter: 0; batch classifier loss: 0.609348; batch adversarial loss: 0.529567\n",
      "epoch 17; iter: 0; batch classifier loss: 0.693072; batch adversarial loss: 0.538877\n",
      "epoch 18; iter: 0; batch classifier loss: 0.614200; batch adversarial loss: 0.532644\n",
      "epoch 19; iter: 0; batch classifier loss: 0.613165; batch adversarial loss: 0.563521\n",
      "epoch 20; iter: 0; batch classifier loss: 0.601589; batch adversarial loss: 0.447812\n",
      "epoch 21; iter: 0; batch classifier loss: 0.701328; batch adversarial loss: 0.595725\n",
      "epoch 22; iter: 0; batch classifier loss: 0.701187; batch adversarial loss: 0.523229\n",
      "epoch 23; iter: 0; batch classifier loss: 0.586017; batch adversarial loss: 0.489114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.590348; batch adversarial loss: 0.468080\n",
      "epoch 25; iter: 0; batch classifier loss: 0.633570; batch adversarial loss: 0.507076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.693908; batch adversarial loss: 0.624737\n",
      "epoch 27; iter: 0; batch classifier loss: 0.634410; batch adversarial loss: 0.441228\n",
      "epoch 28; iter: 0; batch classifier loss: 0.616338; batch adversarial loss: 0.502070\n",
      "epoch 29; iter: 0; batch classifier loss: 0.608660; batch adversarial loss: 0.448912\n",
      "epoch 30; iter: 0; batch classifier loss: 0.647503; batch adversarial loss: 0.417319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.630718; batch adversarial loss: 0.433023\n",
      "epoch 32; iter: 0; batch classifier loss: 0.695490; batch adversarial loss: 0.519410\n",
      "epoch 33; iter: 0; batch classifier loss: 0.636300; batch adversarial loss: 0.466114\n",
      "epoch 34; iter: 0; batch classifier loss: 0.576670; batch adversarial loss: 0.508187\n",
      "epoch 35; iter: 0; batch classifier loss: 0.605849; batch adversarial loss: 0.504320\n",
      "epoch 36; iter: 0; batch classifier loss: 0.571337; batch adversarial loss: 0.486032\n",
      "epoch 37; iter: 0; batch classifier loss: 0.613335; batch adversarial loss: 0.495983\n",
      "epoch 38; iter: 0; batch classifier loss: 0.603533; batch adversarial loss: 0.500902\n",
      "epoch 39; iter: 0; batch classifier loss: 0.627135; batch adversarial loss: 0.471165\n",
      "epoch 40; iter: 0; batch classifier loss: 0.657474; batch adversarial loss: 0.371469\n",
      "epoch 41; iter: 0; batch classifier loss: 0.572260; batch adversarial loss: 0.489922\n",
      "epoch 42; iter: 0; batch classifier loss: 0.690971; batch adversarial loss: 0.503766\n",
      "epoch 43; iter: 0; batch classifier loss: 0.723003; batch adversarial loss: 0.533057\n",
      "epoch 44; iter: 0; batch classifier loss: 0.615444; batch adversarial loss: 0.510456\n",
      "epoch 45; iter: 0; batch classifier loss: 0.663606; batch adversarial loss: 0.490007\n",
      "epoch 46; iter: 0; batch classifier loss: 0.562255; batch adversarial loss: 0.423390\n",
      "epoch 47; iter: 0; batch classifier loss: 0.517327; batch adversarial loss: 0.467046\n",
      "epoch 48; iter: 0; batch classifier loss: 0.648320; batch adversarial loss: 0.455052\n",
      "epoch 49; iter: 0; batch classifier loss: 0.664053; batch adversarial loss: 0.443317\n",
      "epoch 0; iter: 0; batch classifier loss: 1.746424; batch adversarial loss: 0.925516\n",
      "epoch 1; iter: 0; batch classifier loss: 1.216264; batch adversarial loss: 0.925259\n",
      "epoch 2; iter: 0; batch classifier loss: 1.036830; batch adversarial loss: 0.885914\n",
      "epoch 3; iter: 0; batch classifier loss: 0.857033; batch adversarial loss: 0.842415\n",
      "epoch 4; iter: 0; batch classifier loss: 0.851900; batch adversarial loss: 0.793962\n",
      "epoch 5; iter: 0; batch classifier loss: 0.904217; batch adversarial loss: 0.749267\n",
      "epoch 6; iter: 0; batch classifier loss: 0.964594; batch adversarial loss: 0.713543\n",
      "epoch 7; iter: 0; batch classifier loss: 0.712951; batch adversarial loss: 0.678170\n",
      "epoch 8; iter: 0; batch classifier loss: 0.834940; batch adversarial loss: 0.633283\n",
      "epoch 9; iter: 0; batch classifier loss: 0.702547; batch adversarial loss: 0.621590\n",
      "epoch 10; iter: 0; batch classifier loss: 0.665465; batch adversarial loss: 0.595003\n",
      "epoch 11; iter: 0; batch classifier loss: 0.597543; batch adversarial loss: 0.578767\n",
      "epoch 12; iter: 0; batch classifier loss: 0.619323; batch adversarial loss: 0.577189\n",
      "epoch 13; iter: 0; batch classifier loss: 0.613459; batch adversarial loss: 0.564410\n",
      "epoch 14; iter: 0; batch classifier loss: 0.592029; batch adversarial loss: 0.546613\n",
      "epoch 15; iter: 0; batch classifier loss: 0.619602; batch adversarial loss: 0.516299\n",
      "epoch 16; iter: 0; batch classifier loss: 0.669468; batch adversarial loss: 0.534478\n",
      "epoch 17; iter: 0; batch classifier loss: 0.637316; batch adversarial loss: 0.548475\n",
      "epoch 18; iter: 0; batch classifier loss: 0.636644; batch adversarial loss: 0.573660\n",
      "epoch 19; iter: 0; batch classifier loss: 0.568798; batch adversarial loss: 0.541133\n",
      "epoch 20; iter: 0; batch classifier loss: 0.635748; batch adversarial loss: 0.490372\n",
      "epoch 21; iter: 0; batch classifier loss: 0.581992; batch adversarial loss: 0.489723\n",
      "epoch 22; iter: 0; batch classifier loss: 0.625054; batch adversarial loss: 0.516896\n",
      "epoch 23; iter: 0; batch classifier loss: 0.665137; batch adversarial loss: 0.485457\n",
      "epoch 24; iter: 0; batch classifier loss: 0.614826; batch adversarial loss: 0.550740\n",
      "epoch 25; iter: 0; batch classifier loss: 0.634457; batch adversarial loss: 0.558842\n",
      "epoch 26; iter: 0; batch classifier loss: 0.567669; batch adversarial loss: 0.599234\n",
      "epoch 27; iter: 0; batch classifier loss: 0.675143; batch adversarial loss: 0.526122\n",
      "epoch 28; iter: 0; batch classifier loss: 0.645061; batch adversarial loss: 0.511947\n",
      "epoch 29; iter: 0; batch classifier loss: 0.556723; batch adversarial loss: 0.494630\n",
      "epoch 30; iter: 0; batch classifier loss: 0.645450; batch adversarial loss: 0.477331\n",
      "epoch 31; iter: 0; batch classifier loss: 0.686122; batch adversarial loss: 0.461330\n",
      "epoch 32; iter: 0; batch classifier loss: 0.661803; batch adversarial loss: 0.488768\n",
      "epoch 33; iter: 0; batch classifier loss: 0.648980; batch adversarial loss: 0.534300\n",
      "epoch 34; iter: 0; batch classifier loss: 0.619826; batch adversarial loss: 0.528324\n",
      "epoch 35; iter: 0; batch classifier loss: 0.585319; batch adversarial loss: 0.457873\n",
      "epoch 36; iter: 0; batch classifier loss: 0.584952; batch adversarial loss: 0.440140\n",
      "epoch 37; iter: 0; batch classifier loss: 0.636222; batch adversarial loss: 0.482773\n",
      "epoch 38; iter: 0; batch classifier loss: 0.630848; batch adversarial loss: 0.500396\n",
      "epoch 39; iter: 0; batch classifier loss: 0.619900; batch adversarial loss: 0.531888\n",
      "epoch 40; iter: 0; batch classifier loss: 0.582474; batch adversarial loss: 0.483396\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592686; batch adversarial loss: 0.491041\n",
      "epoch 42; iter: 0; batch classifier loss: 0.644891; batch adversarial loss: 0.556023\n",
      "epoch 43; iter: 0; batch classifier loss: 0.603857; batch adversarial loss: 0.486618\n",
      "epoch 44; iter: 0; batch classifier loss: 0.615031; batch adversarial loss: 0.470744\n",
      "epoch 45; iter: 0; batch classifier loss: 0.543007; batch adversarial loss: 0.498830\n",
      "epoch 46; iter: 0; batch classifier loss: 0.582969; batch adversarial loss: 0.503392\n",
      "epoch 47; iter: 0; batch classifier loss: 0.645090; batch adversarial loss: 0.495127\n",
      "epoch 48; iter: 0; batch classifier loss: 0.579029; batch adversarial loss: 0.456538\n",
      "epoch 49; iter: 0; batch classifier loss: 0.557464; batch adversarial loss: 0.580626\n",
      "epoch 0; iter: 0; batch classifier loss: 1.202108; batch adversarial loss: 0.686046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.882090; batch adversarial loss: 0.637933\n",
      "epoch 2; iter: 0; batch classifier loss: 0.753357; batch adversarial loss: 0.625090\n",
      "epoch 3; iter: 0; batch classifier loss: 0.742887; batch adversarial loss: 0.610140\n",
      "epoch 4; iter: 0; batch classifier loss: 0.725330; batch adversarial loss: 0.627294\n",
      "epoch 5; iter: 0; batch classifier loss: 0.756484; batch adversarial loss: 0.635935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.774283; batch adversarial loss: 0.597852\n",
      "epoch 7; iter: 0; batch classifier loss: 0.625416; batch adversarial loss: 0.613572\n",
      "epoch 8; iter: 0; batch classifier loss: 0.623839; batch adversarial loss: 0.584183\n",
      "epoch 9; iter: 0; batch classifier loss: 0.628678; batch adversarial loss: 0.599919\n",
      "epoch 10; iter: 0; batch classifier loss: 0.723560; batch adversarial loss: 0.560939\n",
      "epoch 11; iter: 0; batch classifier loss: 0.748121; batch adversarial loss: 0.515743\n",
      "epoch 12; iter: 0; batch classifier loss: 0.631023; batch adversarial loss: 0.560874\n",
      "epoch 13; iter: 0; batch classifier loss: 0.631604; batch adversarial loss: 0.515026\n",
      "epoch 14; iter: 0; batch classifier loss: 0.678021; batch adversarial loss: 0.599927\n",
      "epoch 15; iter: 0; batch classifier loss: 0.645612; batch adversarial loss: 0.505435\n",
      "epoch 16; iter: 0; batch classifier loss: 0.633692; batch adversarial loss: 0.512266\n",
      "epoch 17; iter: 0; batch classifier loss: 0.589014; batch adversarial loss: 0.527492\n",
      "epoch 18; iter: 0; batch classifier loss: 0.668929; batch adversarial loss: 0.595344\n",
      "epoch 19; iter: 0; batch classifier loss: 0.653148; batch adversarial loss: 0.440719\n",
      "epoch 20; iter: 0; batch classifier loss: 0.686034; batch adversarial loss: 0.472623\n",
      "epoch 21; iter: 0; batch classifier loss: 0.679731; batch adversarial loss: 0.527903\n",
      "epoch 22; iter: 0; batch classifier loss: 0.667326; batch adversarial loss: 0.543338\n",
      "epoch 23; iter: 0; batch classifier loss: 0.584887; batch adversarial loss: 0.487242\n",
      "epoch 24; iter: 0; batch classifier loss: 0.592241; batch adversarial loss: 0.512144\n",
      "epoch 25; iter: 0; batch classifier loss: 0.605577; batch adversarial loss: 0.471431\n",
      "epoch 26; iter: 0; batch classifier loss: 0.650616; batch adversarial loss: 0.520804\n",
      "epoch 27; iter: 0; batch classifier loss: 0.552933; batch adversarial loss: 0.508004\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601382; batch adversarial loss: 0.526819\n",
      "epoch 29; iter: 0; batch classifier loss: 0.617668; batch adversarial loss: 0.533021\n",
      "epoch 30; iter: 0; batch classifier loss: 0.597012; batch adversarial loss: 0.578335\n",
      "epoch 31; iter: 0; batch classifier loss: 0.607658; batch adversarial loss: 0.436959\n",
      "epoch 32; iter: 0; batch classifier loss: 0.587554; batch adversarial loss: 0.570387\n",
      "epoch 33; iter: 0; batch classifier loss: 0.638348; batch adversarial loss: 0.481144\n",
      "epoch 34; iter: 0; batch classifier loss: 0.702842; batch adversarial loss: 0.411507\n",
      "epoch 35; iter: 0; batch classifier loss: 0.604824; batch adversarial loss: 0.558664\n",
      "epoch 36; iter: 0; batch classifier loss: 0.650804; batch adversarial loss: 0.527700\n",
      "epoch 37; iter: 0; batch classifier loss: 0.537716; batch adversarial loss: 0.497514\n",
      "epoch 38; iter: 0; batch classifier loss: 0.596457; batch adversarial loss: 0.513525\n",
      "epoch 39; iter: 0; batch classifier loss: 0.667294; batch adversarial loss: 0.537120\n",
      "epoch 40; iter: 0; batch classifier loss: 0.588625; batch adversarial loss: 0.522917\n",
      "epoch 41; iter: 0; batch classifier loss: 0.652093; batch adversarial loss: 0.526962\n",
      "epoch 42; iter: 0; batch classifier loss: 0.609886; batch adversarial loss: 0.431400\n",
      "epoch 43; iter: 0; batch classifier loss: 0.672572; batch adversarial loss: 0.471224\n",
      "epoch 44; iter: 0; batch classifier loss: 0.620337; batch adversarial loss: 0.545154\n",
      "epoch 45; iter: 0; batch classifier loss: 0.529076; batch adversarial loss: 0.463803\n",
      "epoch 46; iter: 0; batch classifier loss: 0.617007; batch adversarial loss: 0.431699\n",
      "epoch 47; iter: 0; batch classifier loss: 0.568746; batch adversarial loss: 0.557686\n",
      "epoch 48; iter: 0; batch classifier loss: 0.598674; batch adversarial loss: 0.461300\n",
      "epoch 49; iter: 0; batch classifier loss: 0.597960; batch adversarial loss: 0.476562\n",
      "epoch 0; iter: 0; batch classifier loss: 2.245773; batch adversarial loss: 0.693112\n",
      "epoch 1; iter: 0; batch classifier loss: 0.863041; batch adversarial loss: 0.648276\n",
      "epoch 2; iter: 0; batch classifier loss: 0.774997; batch adversarial loss: 0.637747\n",
      "epoch 3; iter: 0; batch classifier loss: 0.754088; batch adversarial loss: 0.645189\n",
      "epoch 4; iter: 0; batch classifier loss: 0.771708; batch adversarial loss: 0.610862\n",
      "epoch 5; iter: 0; batch classifier loss: 0.796046; batch adversarial loss: 0.592486\n",
      "epoch 6; iter: 0; batch classifier loss: 0.765498; batch adversarial loss: 0.606164\n",
      "epoch 7; iter: 0; batch classifier loss: 0.743926; batch adversarial loss: 0.641435\n",
      "epoch 8; iter: 0; batch classifier loss: 0.736937; batch adversarial loss: 0.610608\n",
      "epoch 9; iter: 0; batch classifier loss: 0.711875; batch adversarial loss: 0.607612\n",
      "epoch 10; iter: 0; batch classifier loss: 0.686428; batch adversarial loss: 0.600520\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551939; batch adversarial loss: 0.556564\n",
      "epoch 12; iter: 0; batch classifier loss: 0.685537; batch adversarial loss: 0.583115\n",
      "epoch 13; iter: 0; batch classifier loss: 0.716730; batch adversarial loss: 0.580323\n",
      "epoch 14; iter: 0; batch classifier loss: 0.664637; batch adversarial loss: 0.578889\n",
      "epoch 15; iter: 0; batch classifier loss: 0.739709; batch adversarial loss: 0.550277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.618548; batch adversarial loss: 0.511056\n",
      "epoch 17; iter: 0; batch classifier loss: 0.691661; batch adversarial loss: 0.530205\n",
      "epoch 18; iter: 0; batch classifier loss: 0.666731; batch adversarial loss: 0.512700\n",
      "epoch 19; iter: 0; batch classifier loss: 0.636299; batch adversarial loss: 0.514754\n",
      "epoch 20; iter: 0; batch classifier loss: 0.622488; batch adversarial loss: 0.533670\n",
      "epoch 21; iter: 0; batch classifier loss: 0.628282; batch adversarial loss: 0.492253\n",
      "epoch 22; iter: 0; batch classifier loss: 0.679712; batch adversarial loss: 0.512576\n",
      "epoch 23; iter: 0; batch classifier loss: 0.611851; batch adversarial loss: 0.542096\n",
      "epoch 24; iter: 0; batch classifier loss: 0.609840; batch adversarial loss: 0.448929\n",
      "epoch 25; iter: 0; batch classifier loss: 0.624833; batch adversarial loss: 0.483988\n",
      "epoch 26; iter: 0; batch classifier loss: 0.623384; batch adversarial loss: 0.494490\n",
      "epoch 27; iter: 0; batch classifier loss: 0.639874; batch adversarial loss: 0.510935\n",
      "epoch 28; iter: 0; batch classifier loss: 0.668339; batch adversarial loss: 0.503867\n",
      "epoch 29; iter: 0; batch classifier loss: 0.665129; batch adversarial loss: 0.557569\n",
      "epoch 30; iter: 0; batch classifier loss: 0.633494; batch adversarial loss: 0.454829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.619079; batch adversarial loss: 0.528799\n",
      "epoch 32; iter: 0; batch classifier loss: 0.610200; batch adversarial loss: 0.496555\n",
      "epoch 33; iter: 0; batch classifier loss: 0.593428; batch adversarial loss: 0.560401\n",
      "epoch 34; iter: 0; batch classifier loss: 0.643100; batch adversarial loss: 0.466651\n",
      "epoch 35; iter: 0; batch classifier loss: 0.576562; batch adversarial loss: 0.538684\n",
      "epoch 36; iter: 0; batch classifier loss: 0.584563; batch adversarial loss: 0.463318\n",
      "epoch 37; iter: 0; batch classifier loss: 0.624670; batch adversarial loss: 0.528233\n",
      "epoch 38; iter: 0; batch classifier loss: 0.572599; batch adversarial loss: 0.527474\n",
      "epoch 39; iter: 0; batch classifier loss: 0.644208; batch adversarial loss: 0.460537\n",
      "epoch 40; iter: 0; batch classifier loss: 0.585779; batch adversarial loss: 0.448331\n",
      "epoch 41; iter: 0; batch classifier loss: 0.653023; batch adversarial loss: 0.449048\n",
      "epoch 42; iter: 0; batch classifier loss: 0.600846; batch adversarial loss: 0.451694\n",
      "epoch 43; iter: 0; batch classifier loss: 0.571535; batch adversarial loss: 0.527534\n",
      "epoch 44; iter: 0; batch classifier loss: 0.645244; batch adversarial loss: 0.529087\n",
      "epoch 45; iter: 0; batch classifier loss: 0.588382; batch adversarial loss: 0.437439\n",
      "epoch 46; iter: 0; batch classifier loss: 0.609588; batch adversarial loss: 0.530154\n",
      "epoch 47; iter: 0; batch classifier loss: 0.563998; batch adversarial loss: 0.479418\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603229; batch adversarial loss: 0.445680\n",
      "epoch 49; iter: 0; batch classifier loss: 0.620100; batch adversarial loss: 0.411126\n",
      "epoch 0; iter: 0; batch classifier loss: 1.326465; batch adversarial loss: 0.687980\n",
      "epoch 1; iter: 0; batch classifier loss: 0.711433; batch adversarial loss: 0.652724\n",
      "epoch 2; iter: 0; batch classifier loss: 0.705084; batch adversarial loss: 0.630569\n",
      "epoch 3; iter: 0; batch classifier loss: 0.649136; batch adversarial loss: 0.613059\n",
      "epoch 4; iter: 0; batch classifier loss: 0.635210; batch adversarial loss: 0.597182\n",
      "epoch 5; iter: 0; batch classifier loss: 0.629247; batch adversarial loss: 0.603913\n",
      "epoch 6; iter: 0; batch classifier loss: 0.639465; batch adversarial loss: 0.582385\n",
      "epoch 7; iter: 0; batch classifier loss: 0.690406; batch adversarial loss: 0.575254\n",
      "epoch 8; iter: 0; batch classifier loss: 0.624225; batch adversarial loss: 0.557154\n",
      "epoch 9; iter: 0; batch classifier loss: 0.621204; batch adversarial loss: 0.625126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.740377; batch adversarial loss: 0.610283\n",
      "epoch 11; iter: 0; batch classifier loss: 0.619785; batch adversarial loss: 0.561213\n",
      "epoch 12; iter: 0; batch classifier loss: 0.659581; batch adversarial loss: 0.516178\n",
      "epoch 13; iter: 0; batch classifier loss: 0.623520; batch adversarial loss: 0.566221\n",
      "epoch 14; iter: 0; batch classifier loss: 0.642471; batch adversarial loss: 0.514724\n",
      "epoch 15; iter: 0; batch classifier loss: 0.610443; batch adversarial loss: 0.483815\n",
      "epoch 16; iter: 0; batch classifier loss: 0.631762; batch adversarial loss: 0.603665\n",
      "epoch 17; iter: 0; batch classifier loss: 0.598802; batch adversarial loss: 0.507722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.650329; batch adversarial loss: 0.584017\n",
      "epoch 19; iter: 0; batch classifier loss: 0.583593; batch adversarial loss: 0.479296\n",
      "epoch 20; iter: 0; batch classifier loss: 0.640270; batch adversarial loss: 0.499198\n",
      "epoch 21; iter: 0; batch classifier loss: 0.719450; batch adversarial loss: 0.562626\n",
      "epoch 22; iter: 0; batch classifier loss: 0.633041; batch adversarial loss: 0.526093\n",
      "epoch 23; iter: 0; batch classifier loss: 0.646645; batch adversarial loss: 0.496783\n",
      "epoch 24; iter: 0; batch classifier loss: 0.683065; batch adversarial loss: 0.623160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561685; batch adversarial loss: 0.428683\n",
      "epoch 26; iter: 0; batch classifier loss: 0.593075; batch adversarial loss: 0.543512\n",
      "epoch 27; iter: 0; batch classifier loss: 0.576350; batch adversarial loss: 0.458425\n",
      "epoch 28; iter: 0; batch classifier loss: 0.639166; batch adversarial loss: 0.543691\n",
      "epoch 29; iter: 0; batch classifier loss: 0.575698; batch adversarial loss: 0.541146\n",
      "epoch 30; iter: 0; batch classifier loss: 0.661530; batch adversarial loss: 0.542253\n",
      "epoch 31; iter: 0; batch classifier loss: 0.625993; batch adversarial loss: 0.466593\n",
      "epoch 32; iter: 0; batch classifier loss: 0.636817; batch adversarial loss: 0.458416\n",
      "epoch 33; iter: 0; batch classifier loss: 0.636169; batch adversarial loss: 0.531840\n",
      "epoch 34; iter: 0; batch classifier loss: 0.617823; batch adversarial loss: 0.528091\n",
      "epoch 35; iter: 0; batch classifier loss: 0.641546; batch adversarial loss: 0.560443\n",
      "epoch 36; iter: 0; batch classifier loss: 0.647384; batch adversarial loss: 0.586677\n",
      "epoch 37; iter: 0; batch classifier loss: 0.606229; batch adversarial loss: 0.452293\n",
      "epoch 38; iter: 0; batch classifier loss: 0.623608; batch adversarial loss: 0.538190\n",
      "epoch 39; iter: 0; batch classifier loss: 0.542029; batch adversarial loss: 0.532855\n",
      "epoch 40; iter: 0; batch classifier loss: 0.659317; batch adversarial loss: 0.483665\n",
      "epoch 41; iter: 0; batch classifier loss: 0.647890; batch adversarial loss: 0.454061\n",
      "epoch 42; iter: 0; batch classifier loss: 0.599324; batch adversarial loss: 0.500907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.632888; batch adversarial loss: 0.498420\n",
      "epoch 44; iter: 0; batch classifier loss: 0.551476; batch adversarial loss: 0.499809\n",
      "epoch 45; iter: 0; batch classifier loss: 0.635324; batch adversarial loss: 0.571315\n",
      "epoch 46; iter: 0; batch classifier loss: 0.634556; batch adversarial loss: 0.457450\n",
      "epoch 47; iter: 0; batch classifier loss: 0.645987; batch adversarial loss: 0.415293\n",
      "epoch 48; iter: 0; batch classifier loss: 0.593693; batch adversarial loss: 0.548581\n",
      "epoch 49; iter: 0; batch classifier loss: 0.685820; batch adversarial loss: 0.445010\n",
      "      accuracy  f1_score       SPD        DI       EOD       AOD\n",
      "mean  0.669439  0.597801  0.012723  1.059044  0.033641  0.048563\n",
      "std   0.013716  0.022531  0.122113  0.334671  0.131728  0.121453\n"
     ]
    }
   ],
   "source": [
    "# 1) Retrieve data\n",
    "protected           = 'sex'\n",
    "privileged_value    = 0.0\n",
    "unprivileged_value  = 1.0\n",
    "privileged_groups   = [{protected: privileged_value}]\n",
    "unprivileged_groups = [{protected: unprivileged_value}]\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "ds, df = load_compas_sex()  \n",
    "feature_cols = [c for c in df.columns if c not in ('label','sex')]\n",
    "\n",
    "# 2) Run experiment, Evaluate\n",
    "sss = StratifiedShuffleSplit(n_splits=25, test_size=0.2, random_state=42)\n",
    "\n",
    "results = []\n",
    "for i, (train_idx, test_idx) in enumerate(sss.split(df, df['label'])):\n",
    "    test_df, y_test, y_pred = adversial_debiasing_train_and_predict(\n",
    "    df,\n",
    "    train_idx,\n",
    "    test_idx,\n",
    "    protected,\n",
    "    privileged_value,\n",
    "    unprivileged_value,\n",
    "    privileged_groups,\n",
    "    unprivileged_groups,\n",
    "    scope_name='adv',           \n",
    "    num_epochs=50,\n",
    "    batch_size=128,\n",
    "    adversary_loss_weight=0.1)\n",
    "    \n",
    "    m = compute_metrics(\n",
    "        test_df, y_test, y_pred,\n",
    "        protected, privileged_value, unprivileged_value\n",
    "    )\n",
    "    results.append(m)\n",
    "\n",
    "compas_sex_metrics = pd.DataFrame(results)\n",
    "compas_sex_metrics_agg = compas_sex_metrics.agg(['mean','std'])\n",
    "\n",
    "print(compas_race_metrics_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae1c513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_viz_metrics_2x3(baseline_race_agg, compas_sex_metrics_agg, 'Baseline', 'Race', 'Default Adversial Debiasing Adult: Baseline - Race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c3f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "955a28cb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
